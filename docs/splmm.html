<!DOCTYPE html><html><head><title>Help for package splmm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {splmm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#splmm-package'><p>Simultaneous Penalized Linear Mixed Effects Models</p></a></li>
<li><a href='#cognitive'><p>Kenya School Lunch Intervention Cognitive Dataset</p></a></li>
<li><a href='#plot.splmm'><p>Plot the tuning results of a <code>splmm.tuning</code> object</p></a></li>
<li><a href='#plot3D.splmm'><p>3D Plot the tuning results of a <code>'splmm.tuning'</code> object when tuning over both lambda 1 and lambda 2 grids</p></a></li>
<li><a href='#print.splmm'><p>Print a short summary of a splmm object.</p></a></li>
<li><a href='#simulated_data'><p>Dataset simulated for toy example</p></a></li>
<li><a href='#splmm'><p>Function to fit linear mixed-effects model with double penalty for fixed effects and random effects</p></a></li>
<li><a href='#splmmControl'><p>Options for the 'splmm' Algorithm</p></a></li>
<li><a href='#splmmTuning'><p>Tuning funtion of <code>'splmm'</code> object</p></a></li>
<li><a href='#summary.splmm'><p>Summarize an 'splmm' object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Simultaneous Penalized Linear Mixed Effects Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-08-17</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Luoying Yang &lt;lyang19@u.rochester.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions that fit linear mixed-effects models
        for high-dimensional data (p&gt;&gt;n) with penalty for both the fixed effects and random effects for variable selection. 
        The details of the algorithm can be found in Luoying Yang PhD thesis (Yang and Wu 2020). The algorithm implementation
        is based on the R package 'lmmlasso'. 
        Reference: Yang L, Wu TT (2020). Model-Based Clustering of Longitudinal Data in High-Dimensionality. Unpublished thesis.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.1), emulator, miscTools, penalized, ggplot2,
gridExtra, plot3D, MASS</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-07 15:29:59 UTC; lyang19</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Author:</td>
<td>Luoying Yang [aut, cre],
  Tong Tong Wu [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-08 10:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='splmm-package'>Simultaneous Penalized Linear Mixed Effects Models</h2><span id='topic+splmm-package'></span>

<h3>Description</h3>

<p>Contains functions that fit linear mixed-effects models
        for high-dimensional data (p&gt;&gt;n) with penalty for both the fixed effects and random effects for variable selection. 
        The details of the algorithm can be found in Luoying Yang PhD thesis (Yang and Wu 2020). The algorithm implementation
        is based on the R package 'lmmlasso'. 
        Reference: Yang L, Wu TT (2020). Model-Based Clustering of Longitudinal Data in High-Dimensionality. Unpublished thesis.</p>


<h3>Details</h3>

<p>The DESCRIPTION file: </p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> splmm</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Simultaneous Penalized Linear Mixed Effects Models</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.1.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2021-08-17</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person(given = "Luoying", family = "Yang",
		   role = c("aut", "cre"),
		   email = "lyang19@u.rochester.edu"),
		   person(given = "Tong Tong", family = "Wu",
		   role = c("aut"),
		   email = "tongtong_wu@urmc.rochester.edu"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Luoying Yang &lt;lyang19@u.rochester.edu&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Contains functions that fit linear mixed-effects models
        for high-dimensional data (p&gt;&gt;n) with penalty for both the fixed effects and random effects for variable selection. 
        The details of the algorithm can be found in Luoying Yang PhD thesis (Yang and Wu 2020). The algorithm implementation
        is based on the R package 'lmmlasso'. 
        Reference: Yang L, Wu TT (2020). Model-Based Clustering of Longitudinal Data in High-Dimensionality. Unpublished thesis.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> Rcpp (&gt;= 1.0.1), emulator, miscTools, penalized, ggplot2, gridExtra, plot3D, MASS</td>
</tr>
<tr>
 <td style="text-align: left;">
LinkingTo: </td><td style="text-align: left;"> Rcpp, RcppArmadillo</td>
</tr>
<tr>
 <td style="text-align: left;">
NeedsCompilation: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
Packaged: </td><td style="text-align: left;"> 2021-08-17 16:50:07 UTC; lyang19</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.5.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Luoying Yang [aut, cre],
  Tong Tong Wu [aut]</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
cognitive               Kenya School Lunch Intervention Cognitive
                        Dataset
plot.splmm              Plot the tuning results of a 'splmm.tuning'
                        object
plot3D.splmm            3D Plot the tuning results of a "splmm.tuning"
                        object when tuning over both lambda 1 and
                        lambda 2 grids
print.splmm             Print a short summary of a splmm object.
simulated_data          Dataset simulated for toy example
splmm                   Function to fit linear mixed-effects model with
                        double penalty for fixed effects and random
                        effects
splmm-package           Simultaneous Penalized Linear Mixed Effects
                        Models
splmmControl            Options for the 'splmm' Algorithm
splmmTuning             Tuning funtion of "splmm" object
summary.splmm           Summarize an 'splmm' object
</pre>
<p>Contains functions that fit linear mixed-effects models for high-dimensional data (p&gt;&gt;n) with penalty for both the fixed effects and random effects for variable selection.
</p>


<h3>Author(s)</h3>

<p>NA
</p>
<p>Maintainer: Luoying Yang &lt;lyang19@u.rochester.edu&gt;
</p>


<h3>References</h3>

<p>Luoying Yang PhD thesis
</p>
<p>SCHELLDORFER, J., BUHLMANN, P. and DE GEER, S.V. (2011), Estimation for High-Dimensional Linear Mixed-Effects Models Using L1-Penalization. Scandinavian Journal of Statistics, 38: 197-214. doi:10.1111/j.1467-9469.2011.00740.x
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Use splmm on the Kenya school cognitive data set


data(cognitive)

x &lt;- model.matrix(ravens ~schoolid+treatment+year+sex+age_at_time0
                  +height+weight+head_circ+ses+mom_read+mom_write
                  +mom_edu, cognitive)
z &lt;- x

fit &lt;- splmm(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1=0.1,
lam2=0.1,penalty.b="lasso", penalty.L="lasso")
summary(fit)


</code></pre>

<hr>
<h2 id='cognitive'>Kenya School Lunch Intervention Cognitive Dataset</h2><span id='topic+cognitive'></span>

<h3>Description</h3>

<p>In the Kenya school lunch intervention, children were given one of four school lunch interventions: meat, milk, calorie, or control. The first three groups were fed a school lunch of a stew called githeri supplemented with either meat, milk, or oil to create a lunch with a given caloric level, while the control group did not receive a lunch. Three schools were randomized to each group and the lunch program is the same for all children within a school. The data is available in <cite>modeling-longitudinal-data-rob-weiss</cite> and is broken up into sub data sets from four domains: Anthropometry, Cognitive, Morbidity, and Nutrition. We will be using the cognitive dataset for analyzing how the cognition level of the school children change over time and how the change is associated with other variables. The main cognitive measures is Raven's colored progressive matrices (Raven's), a measure of cognitive ability. There are three additional response variables: arithmetic score (arithmetic), verbal meaning (vmeaning), and total digit span score (dstotal) where digit span is a test of memory while others are considered measures of intelligence or education. The cognitive measurement baseline was taken prior to the lunch program onset and measurements were assessed at up to five times, called rounds, for each subject. More information about this dataset please see the reference:
</p>
<p>Robert E Weiss.Modeling longitudinal data.  Springer Science &amp; Business Media, 2005.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cognitive)</code></pre>


<h3>Format</h3>


<p>A data frame of 1562 observations and 26 variables.
</p>
<dl>
<dt>id</dt><dd><p>Grouping variable. Unique ID for each subject.</p>
</dd>
<dt>schoolid</dt><dd><p>School id 1-12.</p>
</dd>
<dt>treatment</dt><dd><p>Calorie, meat, milk, control</p>
</dd>
<dt>rn</dt><dd><p>round. </p>
</dd>
<dt>year</dt><dd><p>Time in years from baseline.</p>
</dd>
<dt>revans</dt><dd><p>Raven's colored matrices score.</p>
</dd>
<dt>arithmetic</dt><dd><p>Arithmetic score.</p>
</dd>
<dt>vmeaning</dt><dd><p>Verbal meaning.</p>
</dd>
<dt>dstotal</dt><dd><p>Total digit span score.</p>
</dd>
<dt>sex</dt><dd><p>Girl or Boy.</p>
</dd>
<dt>age_at_time0</dt><dd><p>age at baseline.</p>
</dd>
<dt>height</dt><dd><p>height at baseline. </p>
</dd>
<dt>weight</dt><dd><p>weight at baseline. </p>
</dd>
<dt>head_circ</dt><dd><p>Head circumference at baseline. </p>
</dd>
<dt>ses</dt><dd><p>Socio-Economic Status score. </p>
</dd>
<dt>mom_read</dt><dd><p>Mother's reading test. </p>
</dd>
<dt>mom_write</dt><dd><p>Mother's writing test. </p>
</dd>
<dt>mom_edu</dt><dd><p>Mother's years of educations. </p>
</dd>
<dt>morbscore</dt><dd><p>Morbidity score: none/mild/severe. </p>
</dd>
<dt>complete</dt><dd><p>Logical variable specifying whether the subject has all five rounds. 1-Yes, 0-No. </p>
</dd>
<dt>rnone</dt><dd><p>Logical variable specifying whether the observation is the baseline. 1-round one (baseline), 0-not round one. </p>
</dd>
<dt>relmonth</dt><dd><p>Time in months from baseline.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(cognitive)
</code></pre>

<hr>
<h2 id='plot.splmm'>Plot the tuning results of a <code>splmm.tuning</code> object</h2><span id='topic+plot.splmm'></span>

<h3>Description</h3>

<p>This function inputs an <code>splmm.tuning</code> object and plot the model selection criterion values over the tuning parameters grid.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'splmm'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.splmm_+3A_x">x</code></td>
<td>
<p>a <code>'splmm.tuning'</code> object</p>
</td></tr>
<tr><td><code id="plot.splmm_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A line plot of BIC, AIC, BICC, EBIC values against lam1 or lam2 depending on the inout. 
</p>


<h3>See Also</h3>

<p><code>plot.splmm</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(cognitive)

x &lt;- model.matrix(ravens ~schoolid+treatment+year+sex+age_at_time0
                  +height+weight+head_circ+ses+mom_read+mom_write
                  +mom_edu, cognitive)
z &lt;- x

## Tuning over lambda1 grid
lam1 = seq(0.1,0.5,0.1)
lam2 = 0.1
fit1 &lt;-splmmTuning(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1=lam1,
lam2=lam2,penalty.b="scad", penalty.L="scad")
plot.splmm(fit1)


</code></pre>

<hr>
<h2 id='plot3D.splmm'>3D Plot the tuning results of a <code>'splmm.tuning'</code> object when tuning over both lambda 1 and lambda 2 grids</h2><span id='topic+plot3D.splmm'></span>

<h3>Description</h3>

<p>This function inputs an <code>'splmm.tuning'</code> object and plot the model selection criterion values in a 3D plot over the lambda 1 and lambda 2 tuning parameters grid.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'splmm'
plot3D(x, criteria=c("BIC","AIC","BICC","EBIC"),type=c("line","surface"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot3D.splmm_+3A_x">x</code></td>
<td>
<p>a <code>'splmm.tuning'</code> object with both <code>lam1.tuning=TRUE</code> and <code>lam2.tuning=TRUE</code></p>
</td></tr>
<tr><td><code id="plot3D.splmm_+3A_criteria">criteria</code></td>
<td>
<p>A parameter specifying whether the criteria value the user want to plot is <code>BIC</code>, <code>AIC</code>, <code>BICC</code> or <code>EBIC</code>. The default is <code>BIC</code></p>
</td></tr>
<tr><td><code id="plot3D.splmm_+3A_type">type</code></td>
<td>
<p>A parameter specifying which type of 3D plot to use for plotting. Currently the available options include <code>line</code> plot and <code>surface</code> plot. The default is <code>surface</code> plot. </p>
</td></tr>
<tr><td><code id="plot3D.splmm_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 3D line/surface plot of BIC/AIC/BICC/EBIC values against lam1 and lam2. 
</p>


<h3>See Also</h3>

<p><code>plot3D</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


data(cognitive)

x &lt;- model.matrix(ravens ~schoolid+treatment+year+sex+age_at_time0
                  +height+weight+head_circ+ses+mom_read+mom_write
                  +mom_edu, cognitive)
z &lt;- x

## Tuning over lambda1 grid and lambda2 grid
lam1 = seq(0.1,0.5,0.1)
lam2 = seq(0.1,0.5,0.1)
fit1 &lt;-splmmTuning(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1=lam1,
lam2=lam2,penalty.b="scad", penalty.L="scad")
plot3D.splmm(fit1)


</code></pre>

<hr>
<h2 id='print.splmm'>Print a short summary of a splmm object.</h2><span id='topic+print.splmm'></span>

<h3>Description</h3>

<p>Prints a short summary of an <code>'splmm'</code> object
comprising information about the nonzero fixed-effects coefficients and the nonzero random effect variance components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'splmm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.splmm_+3A_x">x</code></td>
<td>
<p>a <code>'splmm'</code> object</p>
</td></tr>
<tr><td><code id="print.splmm_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, a print-out of a <code>'splmm'</code> object's short summary is produced. 
</p>


<h3>See Also</h3>

<p><code>print.splmm</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(simulated_data)

set.seed(144)
fit = splmm(x=simulated_data$x,y=simulated_data$y,
z=simulated_data$z,grp=simulated_data$grp,
lam1=0.1,lam2=0.01, penalty.b="scad", penalty.L="scad")
print(fit)


data(cognitive)

x &lt;- model.matrix(ravens ~schoolid+treatment+year+sex+age_at_time0
                  +height+weight+head_circ+ses+mom_read+mom_write
                  +mom_edu, cognitive)
z &lt;- x

fit &lt;- splmm(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1=0.1,
lam2=0.1,penalty.b="scad", penalty.L="scad")
print(fit)


</code></pre>

<hr>
<h2 id='simulated_data'>Dataset simulated for toy example</h2><span id='topic+simulated_data'></span>

<h3>Description</h3>

<p>A toy dataset simulated for demonstration for the <code>splmm</code> function. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(simulated_data)</code></pre>


<h3>Format</h3>


<dl>
<dt>y</dt><dd><p>Response variable.</p>
</dd>
<dt>x</dt><dd><p>Fixed-effects design matrix.</p>
</dd>
<dt>z</dt><dd><p>Random-effects design matrix</p>
</dd>
<dt>grp</dt><dd><p>Subject ID. </p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(simulated_data)
</code></pre>

<hr>
<h2 id='splmm'>Function to fit linear mixed-effects model with double penalty for fixed effects and random effects</h2><span id='topic+splmm'></span><span id='topic+splmm.default'></span>

<h3>Description</h3>

<p>All the details of the algorithm can be found in the manuscript.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splmm(x, y, z, grp, lam1, lam2, nonpen.b=1,nonpen.L=1,penalty.b=c("lasso","scad"),
      penalty.L=c("lasso","scad"),CovOpt=c("nlminb","optimize"),
      standardize=TRUE,control=splmmControl())

## Default S3 method:
splmm(x, y, z, grp, lam1, lam2, nonpen.b=1,nonpen.L=1,penalty.b=c("lasso","scad"),
      penalty.L=c("lasso","scad"),CovOpt=c("nlminb","optimize"),
      standardize=TRUE,control=splmmControl())</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splmm_+3A_x">x</code></td>
<td>
<p>matrix of dimension N x p including the fixed-effects covariables. An intercept has to be included in the first column as (1,...,1).</p>
</td></tr>
<tr><td><code id="splmm_+3A_y">y</code></td>
<td>
<p>response variable of length N.</p>
</td></tr>
<tr><td><code id="splmm_+3A_z">z</code></td>
<td>
<p>random effects matrix of dimension N x q. It has to be a matrix, even if q=1.</p>
</td></tr>
<tr><td><code id="splmm_+3A_grp">grp</code></td>
<td>
<p>grouping variable of length N</p>
</td></tr>
<tr><td><code id="splmm_+3A_lam1">lam1</code></td>
<td>
<p>regularization parameter for fixed effects penalization.</p>
</td></tr>
<tr><td><code id="splmm_+3A_lam2">lam2</code></td>
<td>
<p>regularization parameter for random effects penalization.</p>
</td></tr>
<tr><td><code id="splmm_+3A_nonpen.b">nonpen.b</code></td>
<td>
<p>Index of indices of fixed effects not penalized. The default value is 1, which means the fixed intercept is not penalized</p>
</td></tr>
<tr><td><code id="splmm_+3A_nonpen.l">nonpen.L</code></td>
<td>
<p>Index of indices of random effects not penalized. The default value is 1, which means the random intercept is not penalized</p>
</td></tr>
<tr><td><code id="splmm_+3A_penalty.b">penalty.b</code></td>
<td>
<p>The penalty method for fixed effects penalization. Currently available options include LASSO penalty and SCAD penalty. </p>
</td></tr>
<tr><td><code id="splmm_+3A_penalty.l">penalty.L</code></td>
<td>
<p>The penalty method for fixed effects penalization. Currently available options include LASSO penalty and SCAD penalty. </p>
</td></tr>
<tr><td><code id="splmm_+3A_covopt">CovOpt</code></td>
<td>
<p>which optimization routine should be used for updating the variance parameter. The available options include optimize and nlminb. nlminb uses the estimate of the last iteration as a starting value. nlminb is faster if there are many Gauss-Seidel iterations.</p>
</td></tr>
<tr><td><code id="splmm_+3A_standardize">standardize</code></td>
<td>
<p>A logical parameter specifying whether the fixed effects matrix x and random effects matrix z should  be standardized such that each column has mean 0 and standard deviation 1. The default value is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="splmm_+3A_control">control</code></td>
<td>
<p>control parameters for the algorithm and the Armijo Rule, see <code>'splmmControl'</code> for the details</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>'splmm'</code> object is returned, for which
<code>coef</code>,<code>resid</code>, <code>fitted</code>,
<code>print</code>, <code>summary</code> methods exist.
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>data set used for fitting the model, as a list with four components: x, y, z, grp (see
above)</p>
</td></tr>
<tr><td><code>coefInit</code></td>
<td>
<p>list of the starting values for beta, random effects covariance structure, and variance structure</p>
</td></tr>
<tr><td><code>penalty.b</code></td>
<td>
<p>The penalty method for fixed effects penalization.</p>
</td></tr>
<tr><td><code>penalty.L</code></td>
<td>
<p>The penalty method for random effects penalization.</p>
</td></tr>
<tr><td><code>nonpen.b</code></td>
<td>
<p>Index of indices of fixed effects not penalized.</p>
</td></tr>
<tr><td><code>nonpen.L</code></td>
<td>
<p>Index of indices of random effects not penalized.</p>
</td></tr>
<tr><td><code>lambda1</code></td>
<td>
<p>regularization parameter for fixed effects penalization scaled by the number of subjects.</p>
</td></tr>
<tr><td><code>lambda2</code></td>
<td>
<p>regularization parameter for random effects penalization the number of subjects.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>standard deviation <code class="reqn">\hat{\sigma}</code> of the errors</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>The estimates of the random effects covariance matrix <code class="reqn">\hat{D}</code>. </p>
</td></tr>
<tr><td><code>Lvec</code></td>
<td>
<p>Vectorized <code class="reqn">\hat{L}</code>, the lower triangular matrix of <code class="reqn">\hat{D}</code> from Cholesky Decomposition. </p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated fixed-effects coefficients <code class="reqn">\hat{\beta}</code></p>
</td></tr>
<tr><td><code>random</code></td>
<td>
<p>vector with random effects, sorted by groups</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>
<p>vector with random effects, sorted by effect</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>vector with the standardized random effects, sorted by effect</p>
</td></tr>
<tr><td><code>fixef</code></td>
<td>
<p>estimated fixed-effects coeffidients <code class="reqn">\hat{\beta}</code></p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>The fitted values <code class="reqn">\hat{y} = \hat{X} \beta +
  Z \hat{b}_i</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>raw residuals <code class="reqn">y-\hat{y}</code></p>
</td></tr>
<tr><td><code>corD</code></td>
<td>
<p>Correlation matrix of the random effects</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>value of the log-likelihood function</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>deviance=-2*logLik</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters. Corresponds to the cardinality
of the set of nonzero <code>coefficients</code> plus the number of nonzero variance in <code>D</code></p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>AIC</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>BIC</p>
</td></tr>
<tr><td><code>bicc</code></td>
<td>
<p>Modified BIC defined by Wang et al (2009)</p>
</td></tr>
<tr><td><code>ebic</code></td>
<td>
<p>Extended BIC defined by Chen and Chen (2008)</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Does the algorithm converge? 0: correct convergence ;
an odd number means that maxIter was reached ; an even number means
that the Armijo step was not succesful. For each unsuccessfull Armijo
step, 2 is added to converged. If converged is large compared to the
number of iterations <code>counter</code>, you may increase maxArmijo.</p>
</td></tr>
<tr><td><code>counter</code></td>
<td>
<p>The number of iterations used.</p>
</td></tr>
<tr><td><code>stopped</code></td>
<td>
<p>logical indicating whether the algorithm stopped due to too many parameters, if yes need to increase <code>lam1</code> or <code>lam2</code></p>
</td></tr>
<tr><td><code>CovOpt</code></td>
<td>
<p>optimization routine</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>see <code>splmmControl</code></p>
</td></tr>
<tr><td><code>objective</code></td>
<td>
<p>Value of the objective function at the final estimates</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>call</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Use splmm for a toy dataset.

data(simulated_data)

set.seed(144)
fit = splmm(x=simulated_data$x,y=simulated_data$y,
z=simulated_data$z,grp=simulated_data$grp,
lam1=0.1,lam2=0.01, penalty.b="scad", penalty.L="scad")
summary(fit)



## Use splmm on the Kenya school cognitive data set


data(cognitive)

x &lt;- model.matrix(ravens ~schoolid+treatment+year+sex+age_at_time0
                  +height+weight+head_circ+ses+mom_read+mom_write
                  +mom_edu, cognitive)
z &lt;- x

fit &lt;- splmm(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1=0.1,
lam2=0.1,penalty.b="lasso", penalty.L="lasso")
summary(fit)


</code></pre>

<hr>
<h2 id='splmmControl'>Options for the 'splmm' Algorithm</h2><span id='topic+splmmControl'></span>

<h3>Description</h3>

<p>Definition of various kinds of options in the
algorithm.</p>


<h3>Usage</h3>

<pre><code class='language-R'>splmmControl(tol=10^(-4),trace=1,maxIter=1000,maxArmijo=20,number=5,a_init=1,
           delta=0.1,rho=0.001,gamma=0,lower=10^(-6),upper=10^8,seed=532,VarInt=c(0,10),
           CovInt=c(-5,5),thres=10^(-4))</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splmmControl_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_trace">trace</code></td>
<td>
<p>integer. 1 prints no output, 2 prints warnings, 3 prints
the current function values and warnings (not recommended)</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_maxiter">maxIter</code></td>
<td>
<p>maximum number of (outer) iterations</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_maxarmijo">maxArmijo</code></td>
<td>
<p>maximum number of steps to be chosen in the Armijo Rule. If the maximum is reached, the algorithm continues with optimizing the next coordinate.</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_number">number</code></td>
<td>
<p>integer. Determines the active set algorithm. The zero
fixed-effects coefficients are only updated each number
iteration. It may be that a smaller number increases the speed of
the algorithm. Use <code class="reqn">0 \le number \le 5</code>.</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_a_init">a_init</code></td>
<td>
<p><code class="reqn">\alpha_{init}</code> in the Armijo step. See Schelldorfer et. al. (2010).</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_delta">delta</code></td>
<td>
<p><code class="reqn">\delta</code> in the Armijo step. See Schelldorfer et. al. (2010)</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_rho">rho</code></td>
<td>
<p><code class="reqn">\rho</code> in the Armijo step. See Schelldorfer et. al. (2010)</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_gamma">gamma</code></td>
<td>
<p><code class="reqn">\gamma</code> in the Armijo step. See Schelldorfer et. al. (2010)</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_lower">lower</code></td>
<td>
<p>lower bound for the Hessian</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_upper">upper</code></td>
<td>
<p>upper bound for the Hessian</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_seed">seed</code></td>
<td>
<p>set.seed for calculating the starting value, which
performs a 10-fold cross-validation.</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_varint">VarInt</code></td>
<td>
<p>Only for opt=&quot;optimize&quot;. The interval for the variance
parameters used in &quot;optimize&quot;. See help(&quot;optimize&quot;)</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_covint">CovInt</code></td>
<td>
<p>Only for opt=&quot;optimize&quot;. The interval for the covariance
parameters used in &quot;optimize&quot;. See help(&quot;optimize&quot;)</p>
</td></tr>
<tr><td><code id="splmmControl_+3A_thres">thres</code></td>
<td>
<p>If a variance or covariance parameter has smaller absolute value than thres, the parameter is set to exactly zero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the Armijo step parameters, see Bertsekas (2003)</p>


<h3>Value</h3>

<p>Exactly the same as <code>arguments</code>.
</p>

<hr>
<h2 id='splmmTuning'>Tuning funtion of <code>'splmm'</code> object</h2><span id='topic+splmmTuning'></span>

<h3>Description</h3>

<p>This function fits <code>'splmm'</code> function over grids of lambda1 and/or lambda2 and determine the best fit model based on model selection information criterion. 
The function takes a scalar or a grid of lambda1 and/or lambda2 and determine the optimal tuning parameter value for the best model fit. If both lambda1 and lambda2 are inputted as scalars, an <code>'splmm'</code> object is returned; if either or both lambda1 and lambda2 are inputted as grids, an <code>'splmm.tuning'</code> object is returned. Currently the model selection criterion include AIC and BIC, and BIC is used to determine the optimal model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splmmTuning(x, y, z, grp, lam1.seq, lam2.seq, nonpen.b=1,nonpen.L=1,
                          penalty.b=c("lasso","scad"),
                          penalty.L=c("lasso","scad"),
                          CovOpt=c("nlminb","optimize"),
                          standardize=TRUE,control=splmmControl())</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splmmTuning_+3A_x">x</code></td>
<td>
<p>matrix of dimension N x p including the fixed-effects covariables. An intercept has to be included in the first column as (1,...,1).</p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_y">y</code></td>
<td>
<p>response variable of length N.</p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_z">z</code></td>
<td>
<p>random effects matrix of dimension N x q. It has to be a matrix, even if q=1.</p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_grp">grp</code></td>
<td>
<p>grouping variable of length N</p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_lam1.seq">lam1.seq</code></td>
<td>
<p>a grid of regularization parameter for fixed effects penalization, could be a scalar if no need to tune. </p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_lam2.seq">lam2.seq</code></td>
<td>
<p>a grid of regularization parameter for random effects penalization, could be a scalar if no need to tune. </p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_nonpen.b">nonpen.b</code></td>
<td>
<p>Index of indices of fixed effects not penalized. The default value is 1, which means the fixed intercept is not penalized. </p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_nonpen.l">nonpen.L</code></td>
<td>
<p>Index of indices of random effects not penalized. The default value is 1, which means the random intercept is not penalized. </p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_penalty.b">penalty.b</code></td>
<td>
<p>The penalty method for fixed effects penalization. Currently available options include LASSO penalty and SCAD penalty. </p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_penalty.l">penalty.L</code></td>
<td>
<p>The penalty method for fixed effects penalization. Currently available options include LASSO penalty and SCAD penalty. </p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_covopt">CovOpt</code></td>
<td>
<p>which optimization routine should be used for updating the variance parameter. The available options include optimize and nlminb. nlminb uses the estimate                     of the last iteration as a starting value. nlminb is faster if there are many Gauss-Seidel iterations.</p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_standardize">standardize</code></td>
<td>
<p>A logical parameter specifying whether the fixed effects matrix x and random effects matrix z should  be standardized such that each column has mean 0 and standard deviation 1. The default value is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="splmmTuning_+3A_control">control</code></td>
<td>
<p>control parameters for the algorithm and the Armijo Rule, see <code>'splmmControl'</code> for the details. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>'splmm.tuning'</code> object is returned, for which <code>plot</code> method exist.
</p>
<table>
<tr><td><code>lam1.seq</code></td>
<td>
<p>lambda1 grid used for tuning. Only available when lambda1 is inputted as a vector.</p>
</td></tr>
<tr><td><code>lam2.seq</code></td>
<td>
<p>lambda2 grid used for tuning. Only available when lambda2 is inputted as a vector.</p>
</td></tr>
<tr><td><code>BIC.lam1</code></td>
<td>
<p>A vector of BIC values of splmm models fitting over a lambda1 grid.</p>
</td></tr>
<tr><td><code>BIC.lam2</code></td>
<td>
<p>A vector of BIC values of splmm models fitting over a lambda2 grid.</p>
</td></tr>
<tr><td><code>fit.BIC</code></td>
<td>
<p>An array of BIC values of splmm models fitting over lambda 1 grid x lambda2 grid.</p>
</td></tr>
<tr><td><code>AIC.lam1</code></td>
<td>
<p>A vector of AIC values of splmm models fitting over a lambda1 grid.</p>
</td></tr>
<tr><td><code>AIC.lam2</code></td>
<td>
<p>A vector of AIC values of splmm models fitting over a lambda2 grid.</p>
</td></tr>
<tr><td><code>fit.AIC</code></td>
<td>
<p>An array of AIC values of splmm models fitting over lambda 1 grid x lambda2 grid.</p>
</td></tr>
<tr><td><code>BICC.lam1</code></td>
<td>
<p>A vector of BICC values of splmm models fitting over a lambda1 grid.</p>
</td></tr>
<tr><td><code>BICC.lam2</code></td>
<td>
<p>A vector of BICC values of splmm models fitting over a lambda2 grid.</p>
</td></tr>
<tr><td><code>fit.BICC</code></td>
<td>
<p>An array of BICC values of splmm models fitting over lambda 1 grid x lambda2 grid.</p>
</td></tr>
<tr><td><code>EBIC.lam1</code></td>
<td>
<p>A vector of EBIC values of splmm models fitting over a lambda1 grid.</p>
</td></tr>
<tr><td><code>EBIC.lam2</code></td>
<td>
<p>A vector of EBIC values of splmm models fitting over a lambda2 grid.</p>
</td></tr>
<tr><td><code>fit.EBIC</code></td>
<td>
<p>An array of EBIC values of splmm models fitting over lambda 1 grid x lambda2 grid.</p>
</td></tr>
<tr><td><code>min.BIC</code></td>
<td>
<p>The minimum BIC value from tuning over a grid. This is only available when either lambda1 or lambda2 is a scalar. </p>
</td></tr>
<tr><td><code>min.AIC</code></td>
<td>
<p>The minimum AIC value from tuning over a grid. This is only available when either lambda1 or lambda2 is a scalar. </p>
</td></tr>
<tr><td><code>min.BICC</code></td>
<td>
<p>The minimum BICC value from tuning over a grid. This is only available when either lambda1 or lambda2 is a scalar. </p>
</td></tr>
<tr><td><code>min.EBIC</code></td>
<td>
<p>The minimum EBIC value from tuning over a grid. This is only available when either lambda1 or lambda2 is a scalar. </p>
</td></tr>
<tr><td><code>best.model</code></td>
<td>
<p>The index of the optimal model. This is only available when either lambda1 or lambda2 is a scalar. </p>
</td></tr>
<tr><td><code>best.fit</code></td>
<td>
<p>The optimal model chosen by the minimum BIC as an <code>splmm</code> object. </p>
</td></tr>
<tr><td><code>min.lam1</code></td>
<td>
<p>lambda1 value that results in the optimal model. This is only available when input lambda1 is a vector.</p>
</td></tr>
<tr><td><code>min.lam2</code></td>
<td>
<p>lambda2 value that results in the optimal model. This is only available when input lambda2 is a vector.</p>
</td></tr>
<tr><td><code>lam1.tuning</code></td>
<td>
<p>A <code>logical</code> parameter specifying if tuning is performed over lamdbda1 grid. <code>lam1.tuning=TRUE</code> if input lambda1 is a vector. </p>
</td></tr>
<tr><td><code>lam2.tuning</code></td>
<td>
<p>A <code>logical</code> parameter specifying if tuning is performed over lamdbda2 grid. <code>lam1.tuning=TRUE</code> if input lambda2 is a vector. </p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>

data(cognitive)

x &lt;- model.matrix(ravens ~schoolid+treatment+year+sex+age_at_time0
                  +height+weight+head_circ+ses+mom_read+mom_write
                  +mom_edu, cognitive)
z &lt;- x

## Tuning over lambda1 grid
lam1 = seq(0.1,0.5,0.1)
lam2 = 0.1
fit1 &lt;-splmmTuning(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1.seq=lam1,
lam2.seq=lam2,penalty.b="scad", penalty.L="scad")
plot.splmm(fit1)

## Tuning over lambda2 grid
lam1 = 0.1
lam2 = seq(0.1,0.5,0.1)
fit2 &lt;-splmmTuning(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1.seq=lam1,
lam2.seq=lam2,penalty.b="scad", penalty.L="scad")
plot.splmm(fit2)

## Tuning over both lambda1 and lambda2 grid
lam1 = seq(0.1,0.5,0.2)
lam2 = seq(0.1,0.5,0.2)
fit3 &lt;-splmmTuning(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1.seq=lam1,
lam2.seq=lam2,penalty.b="scad", penalty.L="scad")
plot.splmm(fit3)


</code></pre>

<hr>
<h2 id='summary.splmm'>Summarize an 'splmm' object</h2><span id='topic+summary.splmm'></span>

<h3>Description</h3>

<p>Providing an elaborate summary of a <code>'splmm'</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'splmm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.splmm_+3A_object">object</code></td>
<td>
<p>a <code>'splmm'</code> object</p>
</td></tr>
<tr><td><code id="summary.splmm_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions shows a detailed summary of a <code>'splmm'</code> object.</p>


<h3>Value</h3>

<p>No return value, a print-out of a <code>'splmm'</code> object's detailed summary is produced. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(simulated_data)

set.seed(144)
fit = splmm(x=simulated_data$x,y=simulated_data$y,
z=simulated_data$z,grp=simulated_data$grp,
lam1=0.1,lam2=0.01, penalty.b="scad", penalty.L="scad")
summary(fit)


data(cognitive)

x &lt;- model.matrix(ravens ~schoolid+treatment+year+sex+age_at_time0
                  +height+weight+head_circ+ses+mom_read+mom_write
                  +mom_edu, cognitive)
z &lt;- x

fit &lt;- splmm(x=x,y=cognitive$ravens,z=z,grp=cognitive$id,lam1=0.1,lam2=0.1,
penalty.b="scad", penalty.L="scad")
summary(fit)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
