<!DOCTYPE html><html><head><title>Help for package fastai</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fastai}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#*.fastai.torch_core.TensorMask'><p>Multiply</p></a></li>
<li><a href='#/.fastai.torch_core.TensorMask'><p>Div</p></a></li>
<li><a href='#&amp;.fastai.torch_core.TensorMask'><p>Logical_and</p></a></li>
<li><a href='#&gt;.fastai.torch_core.TensorMask'><p>Greater</p></a></li>
<li><a href='#&gt;=.fastai.torch_core.TensorMask'><p>Greater or equal</p></a></li>
<li><a href='#&lt;.fastai.torch_core.TensorMask'><p>Less</p></a></li>
<li><a href='#&lt;=.fastai.torch_core.TensorMask'><p>Less or equal</p></a></li>
<li><a href='#%/%.fastai.torch_core.TensorMask'><p>Floor divide</p></a></li>
<li><a href='#%%.fastai.torch_core.TensorMask'><p>Floor mod</p></a></li>
<li><a href='#%f%'><p>Fastai assignment</p></a></li>
<li><a href='#^.fastai.torch_core.TensorMask'><p>Pow</p></a></li>
<li><a href='#+.fastai.torch_core.TensorMask'><p>Add</p></a></li>
<li><a href='#+.torch.nn.modules.container.Sequential'><p>Add layers to Sequential</p></a></li>
<li><a href='#==.fastai.torch_core.TensorImage'><p>Equal</p></a></li>
<li><a href='#==.fastai.torch_core.TensorMask'><p>Equal</p></a></li>
<li><a href='#==.torch.Tensor'><p>Equal</p></a></li>
<li><a href='#abs'><p>Abs</p></a></li>
<li><a href='#abs.fastai.torch_core.TensorMask'><p>Abs</p></a></li>
<li><a href='#AccumMetric'><p>AccumMetric</p></a></li>
<li><a href='#accuracy'><p>Accuracy</p></a></li>
<li><a href='#accuracy_multi'><p>Accuracy_multi</p></a></li>
<li><a href='#accuracy_thresh_expand'><p>Accuracy threshold expand</p></a></li>
<li><a href='#Adam'><p>Adam</p></a></li>
<li><a href='#adam_step'><p>Adam_step</p></a></li>
<li><a href='#adaptive_pool'><p>Adaptive_pool</p></a></li>
<li><a href='#AdaptiveAvgPool'><p>AdaptiveAvgPool</p></a></li>
<li><a href='#AdaptiveConcatPool1d'><p>AdaptiveConcatPool1d</p></a></li>
<li><a href='#AdaptiveConcatPool2d'><p>AdaptiveConcatPool2d</p></a></li>
<li><a href='#AdaptiveGANSwitcher'><p>Adaptive GAN Switcher</p></a></li>
<li><a href='#AdaptiveLoss'><p>AdaptiveLoss</p></a></li>
<li><a href='#add'><p>Add</p></a></li>
<li><a href='#add_cyclic_datepart'><p>Add cyclic datepart</p></a></li>
<li><a href='#add_datepart'><p>Add datepart</p></a></li>
<li><a href='#AddChannels'><p>Add Channels</p></a></li>
<li><a href='#AddNoise'><p>Add Noise</p></a></li>
<li><a href='#affine_coord'><p>Aaffine_coord</p></a></li>
<li><a href='#affine_mat'><p>Affline mat</p></a></li>
<li><a href='#AffineCoordTfm'><p>AffineCoordTfm</p></a></li>
<li><a href='#alexnet'><p>Alexnet</p></a></li>
<li><a href='#apply_perspective'><p>Apply_perspective</p></a></li>
<li><a href='#APScoreBinary'><p>APScoreBinary</p></a></li>
<li><a href='#APScoreMulti'><p>APScoreMulti</p></a></li>
<li><a href='#as_array'><p>As_array</p></a></li>
<li><a href='#aspect'><p>Aspect</p></a></li>
<li><a href='#audio_extensions'><p>Audio_extensions</p></a></li>
<li><a href='#AudioBlock'><p>AudioBlock</p></a></li>
<li><a href='#AudioBlock_from_folder'><p>AudioBlock from folder</p></a></li>
<li><a href='#AudioGetter'><p>AudioGetter</p></a></li>
<li><a href='#AudioPadType'><p>AudioPadType module</p></a></li>
<li><a href='#AudioSpectrogram'><p>AudioSpectrogram module</p></a></li>
<li><a href='#AudioTensor'><p>Audio Tensor</p></a></li>
<li><a href='#AudioTensor_create'><p>AudioTensor create</p></a></li>
<li><a href='#AudioToMFCC'><p>AudioToMFCC</p></a></li>
<li><a href='#AudioToMFCC_from_cfg'><p>AudioToMFCC from cfg</p></a></li>
<li><a href='#AudioToSpec_from_cfg'><p>AudioToSpec from cfg</p></a></li>
<li><a href='#aug_transforms'><p>Augmentation</p></a></li>
<li><a href='#AutoConfig'><p>Auto configuration</p></a></li>
<li><a href='#average_grad'><p>Average_grad</p></a></li>
<li><a href='#average_sqr_grad'><p>Average_sqr_grad</p></a></li>
<li><a href='#AvgLoss'><p>AvgLoss</p></a></li>
<li><a href='#AvgPool'><p>AvgPool</p></a></li>
<li><a href='#AvgSmoothLoss'><p>AvgSmoothLoss</p></a></li>
<li><a href='#AWD_LSTM'><p>AWD_LSTM</p></a></li>
<li><a href='#awd_lstm_clas_split'><p>Awd_lstm_clas_split</p></a></li>
<li><a href='#awd_lstm_lm_split'><p>Awd_lstm_lm_split</p></a></li>
<li><a href='#AWD_QRNN'><p>AWD_QRNN</p></a></li>
<li><a href='#BalancedAccuracy'><p>BalancedAccuracy</p></a></li>
<li><a href='#BaseLoss'><p>BaseLoss</p></a></li>
<li><a href='#BaseTokenizer'><p>BaseTokenizer</p></a></li>
<li><a href='#basic_critic'><p>Basic critic</p></a></li>
<li><a href='#basic_generator'><p>Basic generator</p></a></li>
<li><a href='#BasicMelSpectrogram'><p>BasicMelSpectrogram</p></a></li>
<li><a href='#BasicMFCC'><p>Basic MFCC</p></a></li>
<li><a href='#BasicSpectrogram'><p>BasicSpectrogram</p></a></li>
<li><a href='#BatchNorm'><p>BatchNorm</p></a></li>
<li><a href='#BatchNorm1dFlat'><p>BatchNorm1dFlat</p></a></li>
<li><a href='#bb_pad'><p>Bb_pad</p></a></li>
<li><a href='#BBoxBlock'><p>BBoxBlock</p></a></li>
<li><a href='#BBoxLabeler'><p>BBoxLabeler</p></a></li>
<li><a href='#BBoxLblBlock'><p>BBoxLblBlock</p></a></li>
<li><a href='#BCELossFlat'><p>BCELossFlat</p></a></li>
<li><a href='#BCEWithLogitsLossFlat'><p>BCEWithLogitsLossFlat</p></a></li>
<li><a href='#blurr'><p>Hugging Face module</p></a></li>
<li><a href='#BrierScore'><p>BrierScore</p></a></li>
<li><a href='#BrierScoreMulti'><p>BrierScoreMulti</p></a></li>
<li><a href='#bs_find'><p>Bs_find</p></a></li>
<li><a href='#bs_finder'><p>Bs finder</p></a></li>
<li><a href='#bt'><p>Builtins module</p></a></li>
<li><a href='#calculate_rouge'><p>Calculate_rouge</p></a></li>
<li><a href='#Callback'><p>Callback module</p></a></li>
<li><a href='#Cat'><p>Cat</p></a></li>
<li><a href='#catalyst'><p>Catalyst module</p></a></li>
<li><a href='#catalyst_model'><p>Catalyst model</p></a></li>
<li><a href='#Categorify'><p>Categorify</p></a></li>
<li><a href='#CategoryBlock'><p>CategoryBlock</p></a></li>
<li><a href='#ceiling_'><p>Ceil</p></a></li>
<li><a href='#ceiling.fastai.torch_core.TensorMask'><p>Ceil</p></a></li>
<li><a href='#ChangeVolume'><p>Change Volume</p></a></li>
<li><a href='#children_and_parameters'><p>Children_and_parameters</p></a></li>
<li><a href='#ClassificationInterpretation_from_learner'><p>ClassificationInterpretation_from_learner</p></a></li>
<li><a href='#clean_raw_keys'><p>Clean_raw_keys</p></a></li>
<li><a href='#clip_remove_empty'><p>Clip_remove_empty</p></a></li>
<li><a href='#cm'><p>Cm module</p></a></li>
<li><a href='#cnn_config'><p>Cnn config</p></a></li>
<li><a href='#cnn_learner'><p>Cnn_learner</p></a></li>
<li><a href='#COCOMetric'><p>COCOMetric</p></a></li>
<li><a href='#COCOMetricType'><p>COCOMetricType</p></a></li>
<li><a href='#CohenKappa'><p>CohenKappa</p></a></li>
<li><a href='#collab'><p>Collab module</p></a></li>
<li><a href='#collab_learner'><p>Collab_learner</p></a></li>
<li><a href='#CollabDataLoaders_from_dblock'><p>CollabDataLoaders_from_dblock</p></a></li>
<li><a href='#CollabDataLoaders_from_df'><p>CollabDataLoaders_from_df</p></a></li>
<li><a href='#CollectDataCallback'><p>CollectDataCallback</p></a></li>
<li><a href='#colors'><p>Colors module</p></a></li>
<li><a href='#ColReader'><p>ColReader</p></a></li>
<li><a href='#ColSplitter'><p>ColSplitter</p></a></li>
<li><a href='#combined_flat_anneal'><p>Combined_flat_anneal</p></a></li>
<li><a href='#competition_download_file'><p>Competition download file</p></a></li>
<li><a href='#competition_download_files'><p>Competition download files</p></a></li>
<li><a href='#competition_leaderboard_download'><p>Competition leaderboard download</p></a></li>
<li><a href='#competition_list_files'><p>Competition list files</p></a></li>
<li><a href='#competition_submit'><p>Competition submit</p></a></li>
<li><a href='#competitions_list'><p>Competitions list</p></a></li>
<li><a href='#Contrast'><p>Contrast</p></a></li>
<li><a href='#conv_norm_lr'><p>Conv_norm_lr</p></a></li>
<li><a href='#ConvLayer'><p>ConvLayer</p></a></li>
<li><a href='#convT_norm_relu'><p>ConvT_norm_relu</p></a></li>
<li><a href='#CorpusBLEUMetric'><p>CorpusBLEUMetric</p></a></li>
<li><a href='#cos_'><p>Cos</p></a></li>
<li><a href='#cos.fastai.torch_core.TensorMask'><p>Cos</p></a></li>
<li><a href='#cosh_'><p>Cosh</p></a></li>
<li><a href='#cosh.fastai.torch_core.TensorMask'><p>Cosh</p></a></li>
<li><a href='#crap'><p>Crappify module</p></a></li>
<li><a href='#crappifier'><p>Crappifier</p></a></li>
<li><a href='#create_body'><p>Create_body</p></a></li>
<li><a href='#create_cnn_model'><p>Create_cnn_model</p></a></li>
<li><a href='#create_fcn'><p>Create_fcn</p></a></li>
<li><a href='#create_head'><p>Create_head</p></a></li>
<li><a href='#create_inception'><p>Create_inception</p></a></li>
<li><a href='#create_mlp'><p>Create_mlp</p></a></li>
<li><a href='#create_resnet'><p>Create_resnet</p></a></li>
<li><a href='#create_unet_model'><p>Create_unet_model</p></a></li>
<li><a href='#CropPad'><p>CropPad</p></a></li>
<li><a href='#CropTime'><p>Crop Time</p></a></li>
<li><a href='#CrossEntropyLossFlat'><p>CrossEntropyLossFlat</p></a></li>
<li><a href='#CSVLogger'><p>CSVLogger</p></a></li>
<li><a href='#CudaCallback'><p>CudaCallback</p></a></li>
<li><a href='#custom_loss'><p>Loss NN module</p></a></li>
<li><a href='#CutMix'><p>CutMix</p></a></li>
<li><a href='#cutout_gaussian'><p>Cutout_gaussian</p></a></li>
<li><a href='#cycle_learner'><p>Cycle_learner</p></a></li>
<li><a href='#CycleGAN'><p>CycleGAN</p></a></li>
<li><a href='#CycleGANLoss'><p>CycleGANLoss</p></a></li>
<li><a href='#CycleGANTrainer'><p>CycleGANTrainer</p></a></li>
<li><a href='#Data_Loaders'><p>Data Loaders</p></a></li>
<li><a href='#DataBlock'><p>DataBlock</p></a></li>
<li><a href='#dataloaders'><p>Dataloaders from dls object</p></a></li>
<li><a href='#Datasets'><p>Datasets</p></a></li>
<li><a href='#dcmread'><p>Read dicom</p></a></li>
<li><a href='#debias'><p>Debias</p></a></li>
<li><a href='#Debugger'><p>Debugger</p></a></li>
<li><a href='#decision_plot'><p>Decision_plot</p></a></li>
<li><a href='#decode_spec_tokens'><p>Decode_spec_tokens</p></a></li>
<li><a href='#default_split'><p>Default_split</p></a></li>
<li><a href='#Delta'><p>Delta</p></a></li>
<li><a href='#denormalize_imagenet'><p>Denormalize_imagenet</p></a></li>
<li><a href='#densenet121'><p>Densenet121</p></a></li>
<li><a href='#densenet161'><p>Densenet161</p></a></li>
<li><a href='#densenet169'><p>Densenet169</p></a></li>
<li><a href='#densenet201'><p>Densenet201</p></a></li>
<li><a href='#DenseResBlock'><p>Dense Res Block</p></a></li>
<li><a href='#dependence_plot'><p>Dependence_plot</p></a></li>
<li><a href='#DeterministicDihedral'><p>DeterministicDihedral</p></a></li>
<li><a href='#DeterministicDraw'><p>DeterministicDraw</p></a></li>
<li><a href='#DeterministicFlip'><p>DeterministicFlip</p></a></li>
<li><a href='#detuplify_pg'><p>Detuplify_pg</p></a></li>
<li><a href='#Dice'><p>Dice coefficient</p></a></li>
<li><a href='#Dicom'><p>Dicom class</p></a></li>
<li><a href='#dicom_windows'><p>Dicom_windows module</p></a></li>
<li><a href='#Dihedral'><p>Dihedral</p></a></li>
<li><a href='#dihedral_mat'><p>Dihedral_mat</p></a></li>
<li><a href='#DihedralItem'><p>DihedralItem</p></a></li>
<li><a href='#dim'><p>Dim</p></a></li>
<li><a href='#dim.fastai.torch_core.TensorMask'><p>Dim</p></a></li>
<li><a href='#discriminator'><p>Discriminator</p></a></li>
<li><a href='#div'><p>Div</p></a></li>
<li><a href='#DownmixMono'><p>Downmix Mono</p></a></li>
<li><a href='#dropout_mask'><p>Dropout_mask</p></a></li>
<li><a href='#dummy_eval'><p>Dummy_eval</p></a></li>
<li><a href='#DynamicUnet'><p>DynamicUnet</p></a></li>
<li><a href='#EarlyStoppingCallback'><p>EarlyStoppingCallback</p></a></li>
<li><a href='#efficientdet_infer_dl'><p>Efficientdet infer dataloader</p></a></li>
<li><a href='#efficientdet_learner'><p>MaskRCNN learner</p></a></li>
<li><a href='#efficientdet_model'><p>Eficientdet model</p></a></li>
<li><a href='#efficientdet_predict_dl'><p>Efficientdet predict dataloader</p></a></li>
<li><a href='#efficientdet_train_dl'><p>Efficientdet train dataloader</p></a></li>
<li><a href='#efficientdet_valid_dl'><p>Efficientdet valid dataloader</p></a></li>
<li><a href='#emb_sz_rule'><p>Emb_sz_rule</p></a></li>
<li><a href='#Embedding'><p>Embedding</p></a></li>
<li><a href='#EmbeddingDropout'><p>EmbeddingDropout</p></a></li>
<li><a href='#error_rate'><p>Error rate</p></a></li>
<li><a href='#exp'><p>Exp</p></a></li>
<li><a href='#exp_rmspe'><p>Exp_rmspe</p></a></li>
<li><a href='#exp.fastai.torch_core.TensorMask'><p>Exp</p></a></li>
<li><a href='#ExplainedVariance'><p>Explained Variance</p></a></li>
<li><a href='#expm1'><p>Expm1</p></a></li>
<li><a href='#expm1.fastai.torch_core.TensorMask'><p>Expm1</p></a></li>
<li><a href='#export_generator'><p>Export_generator</p></a></li>
<li><a href='#F1Score'><p>F1Score</p></a></li>
<li><a href='#F1ScoreMulti'><p>F1ScoreMulti</p></a></li>
<li><a href='#fa_collate'><p>Fa_collate</p></a></li>
<li><a href='#fa_convert'><p>Da_convert</p></a></li>
<li><a href='#fastai_version'><p>Fastai version</p></a></li>
<li><a href='#fastaudio'><p>Fastaudio module</p></a></li>
<li><a href='#faster_rcnn_infer_dl'><p>Faster RCNN infer dataloader</p></a></li>
<li><a href='#faster_rcnn_learner'><p>Faster RSNN learner</p></a></li>
<li><a href='#faster_rcnn_model'><p>Faster RSNN model</p></a></li>
<li><a href='#faster_rcnn_predict_dl'><p>Faster RCNN predict dataloader</p></a></li>
<li><a href='#faster_rcnn_train_dl'><p>Faster RSNN train dataloader</p></a></li>
<li><a href='#faster_rcnn_valid_dl'><p>Faster RSNN valid dataloader</p></a></li>
<li><a href='#fastinf'><p>Wandb module</p></a></li>
<li><a href='#FBeta'><p>FBeta</p></a></li>
<li><a href='#FBetaMulti'><p>FBetaMulti</p></a></li>
<li><a href='#FetchPredsCallback'><p>FetchPredsCallback</p></a></li>
<li><a href='#FileSplitter'><p>File Splitter</p></a></li>
<li><a href='#FillMissing'><p>Fill Missing</p></a></li>
<li><a href='#FillStrategy_COMMON'><p>COMMON</p></a></li>
<li><a href='#FillStrategy_CONSTANT'><p>CONSTANT</p></a></li>
<li><a href='#FillStrategy_MEDIAN'><p>MEDIAN</p></a></li>
<li><a href='#find_coeffs'><p>Find_coeffs</p></a></li>
<li><a href='#fine_tune'><p>Fine_tune</p></a></li>
<li><a href='#fit_flat_cos'><p>Fit_flat_cos</p></a></li>
<li><a href='#fit_flat_lin'><p>Fit_flat_lin</p></a></li>
<li><a href='#fit_one_cycle'><p>Fit one cycle</p></a></li>
<li><a href='#fit_sgdr'><p>Fit_sgdr</p></a></li>
<li><a href='#fit.fastai.learner.Learner'><p>Fit</p></a></li>
<li><a href='#fit.fastai.tabular.learner.TabularLearner'><p>Fit</p></a></li>
<li><a href='#fit.fastai.vision.gan.GANLearner'><p>Fit</p></a></li>
<li><a href='#fix_fit'><p>Fix fit</p></a></li>
<li><a href='#fix_html'><p>Fix_html</p></a></li>
<li><a href='#FixedGANSwitcher'><p>Fixed GAN Switcher</p></a></li>
<li><a href='#Flatten'><p>Flatten</p></a></li>
<li><a href='#flatten_check'><p>Flatten check</p></a></li>
<li><a href='#flatten_model'><p>Flatten_model</p></a></li>
<li><a href='#Flip'><p>Flip</p></a></li>
<li><a href='#flip_mat'><p>Flip_mat</p></a></li>
<li><a href='#FlipItem'><p>FlipItem</p></a></li>
<li><a href='#float'><p>Tensor to float</p></a></li>
<li><a href='#floor_'><p>Floor</p></a></li>
<li><a href='#floor_div'><p>Floor divide</p></a></li>
<li><a href='#floor_mod'><p>Floor mod</p></a></li>
<li><a href='#floor.fastai.torch_core.TensorMask'><p>Floor</p></a></li>
<li><a href='#fmodule'><p>Module</p></a></li>
<li><a href='#FolderDataset'><p>FolderDataset</p></a></li>
<li><a href='#force_plot'><p>Force_plot</p></a></li>
<li><a href='#foreground_acc'><p>Foreground accuracy</p></a></li>
<li><a href='#forget_mult_CPU'><p>Forget_mult_CPU</p></a></li>
<li><a href='#ForgetMultGPU'><p>ForgetMultGPU</p></a></li>
<li><a href='#freeze'><p>Freeze a model</p></a></li>
<li><a href='#FuncSplitter'><p>FuncSplitter</p></a></li>
<li><a href='#fView'><p>View</p></a></li>
<li><a href='#gan_critic'><p>Gan critic</p></a></li>
<li><a href='#gan_loss_from_func'><p>GAN loss from function</p></a></li>
<li><a href='#GANDiscriminativeLR'><p>GAN Discriminative LR</p></a></li>
<li><a href='#GANLearner_from_learners'><p>GAN Learner from learners</p></a></li>
<li><a href='#GANLearner_wgan'><p>Wgan</p></a></li>
<li><a href='#GANLoss'><p>GAN Loss</p></a></li>
<li><a href='#GANModule'><p>GAN Module</p></a></li>
<li><a href='#GANTrainer'><p>GAN Trainer</p></a></li>
<li><a href='#GatherPredsCallback'><p>GatherPredsCallback</p></a></li>
<li><a href='#gauss_blur2d'><p>Gauss_blur2d</p></a></li>
<li><a href='#generate_noise'><p>Generate noise</p></a></li>
<li><a href='#get_annotations'><p>Get_annotations</p></a></li>
<li><a href='#get_audio_files'><p>Get_audio_files</p></a></li>
<li><a href='#get_bias'><p>Get bias</p></a></li>
<li><a href='#get_c'><p>Get_c</p></a></li>
<li><a href='#get_confusion_matrix'><p>Extract confusion matrix</p></a></li>
<li><a href='#get_data_loaders'><p>Get data loaders</p></a></li>
<li><a href='#get_dcm_matrix'><p>Get image matrix</p></a></li>
<li><a href='#get_dicom_files'><p>get_dicom_files</p></a></li>
<li><a href='#get_dls'><p>Get dls</p></a></li>
<li><a href='#get_emb_sz'><p>Get_emb_sz</p></a></li>
<li><a href='#get_files'><p>Get_files</p></a></li>
<li><a href='#get_grid'><p>Get_grid</p></a></li>
<li><a href='#get_hf_objects'><p>Get_hf_objects</p></a></li>
<li><a href='#get_image_files'><p>Get image files</p></a></li>
<li><a href='#get_language_model'><p>Get_language_model</p></a></li>
<li><a href='#get_preds_cyclegan'><p>Get_preds_cyclegan</p></a></li>
<li><a href='#get_text_classifier'><p>Get_text_classifier</p></a></li>
<li><a href='#get_text_files'><p>Get_text_files</p></a></li>
<li><a href='#get_weights'><p>Get weights</p></a></li>
<li><a href='#GradientAccumulation'><p>GradientAccumulation</p></a></li>
<li><a href='#GrandparentSplitter'><p>GrandparentSplitter</p></a></li>
<li><a href='#grayscale'><p>Grayscale</p></a></li>
<li><a href='#greater'><p>Greater</p></a></li>
<li><a href='#greater_or_equal'><p>Greater or equal</p></a></li>
<li><a href='#HammingLoss'><p>HammingLoss</p></a></li>
<li><a href='#HammingLossMulti'><p>HammingLossMulti</p></a></li>
<li><a href='#has_params'><p>Has_params</p></a></li>
<li><a href='#has_pool_type'><p>Has_pool_type</p></a></li>
<li><a href='#helper'><p>BLURR_MODEL_HELPER</p></a></li>
<li><a href='#HF_ARCHITECTURES'><p>HF_ARCHITECTURES</p></a></li>
<li><a href='#HF_BaseInput'><p>HF_BaseInput</p></a></li>
<li><a href='#HF_BaseModelCallback'><p>HF_BaseModelCallback</p></a></li>
<li><a href='#HF_BaseModelWrapper'><p>HF_BaseModelWrapper</p></a></li>
<li><a href='#HF_BeforeBatchTransform'><p>HF_BeforeBatchTransform</p></a></li>
<li><a href='#HF_CausalLMBeforeBatchTransform'><p>HF_CausalLMBeforeBatchTransform</p></a></li>
<li><a href='#HF_load_dataset'><p>Load_dataset</p></a></li>
<li><a href='#HF_QABatchTransform'><p>HF_QABatchTransform</p></a></li>
<li><a href='#HF_QABeforeBatchTransform'><p>HF_QABeforeBatchTransform</p></a></li>
<li><a href='#HF_QstAndAnsModelCallback'><p>HF_QstAndAnsModelCallback</p></a></li>
<li><a href='#HF_QuestionAnswerInput'><p>HF_QuestionAnswerInput</p></a></li>
<li><a href='#hf_splitter'><p>Hf_splitter</p></a></li>
<li><a href='#HF_SummarizationBeforeBatchTransform'><p>HF_SummarizationBeforeBatchTransform</p></a></li>
<li><a href='#HF_SummarizationInput'><p>HF_SummarizationInput</p></a></li>
<li><a href='#HF_SummarizationModelCallback'><p>HF_SummarizationModelCallback</p></a></li>
<li><a href='#HF_TASKS_ALL'><p>HF_TASKS_ALL</p></a></li>
<li><a href='#HF_TASKS_AUTO'><p>HF_TASKS_AUTO</p></a></li>
<li><a href='#HF_Text2TextAfterBatchTransform'><p>HF_Text2TextAfterBatchTransform</p></a></li>
<li><a href='#HF_Text2TextBlock'><p>HF_Text2TextBlock</p></a></li>
<li><a href='#HF_TextBlock'><p>HF_TextBlock</p></a></li>
<li><a href='#HF_TokenCategorize'><p>HF_TokenCategorize</p></a></li>
<li><a href='#HF_TokenCategoryBlock'><p>HF_TokenCategoryBlock</p></a></li>
<li><a href='#HF_TokenClassBeforeBatchTransform'><p>HF_TokenClassBeforeBatchTransform</p></a></li>
<li><a href='#HF_TokenClassInput'><p>HF_TokenClassInput</p></a></li>
<li><a href='#HF_TokenTensorCategory'><p>HF_TokenTensorCategory</p></a></li>
<li><a href='#Hook'><p>Hook</p></a></li>
<li><a href='#hook_output'><p>Hook_output</p></a></li>
<li><a href='#hook_outputs'><p>Hook_outputs</p></a></li>
<li><a href='#HookCallback'><p>HookCallback</p></a></li>
<li><a href='#Hooks'><p>Hooks</p></a></li>
<li><a href='#hsv2rgb'><p>Hsv2rgb</p></a></li>
<li><a href='#Hue'><p>Hue</p></a></li>
<li><a href='#hug'><p>Transformer module</p></a></li>
<li><a href='#icevision'><p>Icevision module</p></a></li>
<li><a href='#icevision_Adapter'><p>Adapter</p></a></li>
<li><a href='#icevision_aug_tfms'><p>Aug_tfms</p></a></li>
<li><a href='#icevision_BasicIAATransform'><p>BasicIAATransform</p></a></li>
<li><a href='#icevision_BasicTransform'><p>BasicTransform</p></a></li>
<li><a href='#icevision_Blur'><p>Blur</p></a></li>
<li><a href='#icevision_ChannelDropout'><p>ChannelDropout</p></a></li>
<li><a href='#icevision_ChannelShuffle'><p>ChannelShuffle</p></a></li>
<li><a href='#icevision_CLAHE'><p>CLAHE</p></a></li>
<li><a href='#icevision_ClassMap'><p>ClassMap</p></a></li>
<li><a href='#icevision_CoarseDropout'><p>CoarseDropout</p></a></li>
<li><a href='#icevision_ColorJitter'><p>ColorJitter</p></a></li>
<li><a href='#icevision_Compose'><p>Compose</p></a></li>
<li><a href='#icevision_Crop'><p>Crop</p></a></li>
<li><a href='#icevision_CropNonEmptyMaskIfExists'><p>CropNonEmptyMaskIfExists</p></a></li>
<li><a href='#icevision_Cutout'><p>Cutout</p></a></li>
<li><a href='#icevision_Dataset'><p>Dataset</p></a></li>
<li><a href='#icevision_Dataset_from_images'><p>Icevision Dataset from images</p></a></li>
<li><a href='#icevision_Downscale'><p>Downscale</p></a></li>
<li><a href='#icevision_DualIAATransform'><p>DualIAATransform</p></a></li>
<li><a href='#icevision_DualTransform'><p>DualTransform</p></a></li>
<li><a href='#icevision_ElasticTransform'><p>ElasticTransform</p></a></li>
<li><a href='#icevision_Equalize'><p>Equalize</p></a></li>
<li><a href='#icevision_FancyPCA'><p>FancyPCA</p></a></li>
<li><a href='#icevision_FDA'><p>FDA</p></a></li>
<li><a href='#icevision_FixedSplitter'><p>FixedSplitter</p></a></li>
<li><a href='#icevision_Flip'><p>Flip</p></a></li>
<li><a href='#icevision_FromFloat'><p>FromFloat</p></a></li>
<li><a href='#icevision_GaussianBlur'><p>GaussianBlur</p></a></li>
<li><a href='#icevision_GaussNoise'><p>GaussNoise</p></a></li>
<li><a href='#icevision_GlassBlur'><p>GlassBlur</p></a></li>
<li><a href='#icevision_GridDistortion'><p>GridDistortion</p></a></li>
<li><a href='#icevision_GridDropout'><p>GridDropout</p></a></li>
<li><a href='#icevision_HistogramMatching'><p>HistogramMatching</p></a></li>
<li><a href='#icevision_HorizontalFlip'><p>HorizontalFlip</p></a></li>
<li><a href='#icevision_HueSaturationValue'><p>HueSaturationValue</p></a></li>
<li><a href='#icevision_IAAAdditiveGaussianNoise'><p>IAAAdditiveGaussianNoise</p></a></li>
<li><a href='#icevision_IAAAffine'><p>IAAAffine</p></a></li>
<li><a href='#icevision_IAACropAndPad'><p>IAACropAndPad</p></a></li>
<li><a href='#icevision_IAAEmboss'><p>IAAEmboss</p></a></li>
<li><a href='#icevision_IAAFliplr'><p>IAAFliplr</p></a></li>
<li><a href='#icevision_IAAFlipud'><p>IAAFlipud</p></a></li>
<li><a href='#icevision_IAAPerspective'><p>IAAPerspective</p></a></li>
<li><a href='#icevision_IAAPiecewiseAffine'><p>IAAPiecewiseAffine</p></a></li>
<li><a href='#icevision_IAASharpen'><p>IAASharpen</p></a></li>
<li><a href='#icevision_IAASuperpixels'><p>IAASuperpixels</p></a></li>
<li><a href='#icevision_ImageCompression'><p>ImageCompression</p></a></li>
<li><a href='#icevision_ImageOnlyIAATransform'><p>ImageOnlyIAATransform</p></a></li>
<li><a href='#icevision_ImageOnlyTransform'><p>ImageOnlyTransform</p></a></li>
<li><a href='#icevision_InvertImg'><p>InvertImg</p></a></li>
<li><a href='#icevision_ISONoise'><p>ISONoise</p></a></li>
<li><a href='#icevision_JpegCompression'><p>JpegCompression</p></a></li>
<li><a href='#icevision_LongestMaxSize'><p>LongestMaxSize</p></a></li>
<li><a href='#icevision_MaskDropout'><p>MaskDropout</p></a></li>
<li><a href='#icevision_MedianBlur'><p>MedianBlur</p></a></li>
<li><a href='#icevision_MotionBlur'><p>MotionBlur</p></a></li>
<li><a href='#icevision_MultiplicativeNoise'><p>MultiplicativeNoise</p></a></li>
<li><a href='#icevision_Normalize'><p>Normalize</p></a></li>
<li><a href='#icevision_OpticalDistortion'><p>OpticalDistortion</p></a></li>
<li><a href='#icevision_PadIfNeeded'><p>PadIfNeeded</p></a></li>
<li><a href='#icevision_parse'><p>Parse</p></a></li>
<li><a href='#icevision_Posterize'><p>Posterize</p></a></li>
<li><a href='#icevision_RandomBrightnessContrast'><p>RandomBrightnessContrast</p></a></li>
<li><a href='#icevision_RandomContrast'><p>RandomContrast</p></a></li>
<li><a href='#icevision_RandomCrop'><p>RandomCrop</p></a></li>
<li><a href='#icevision_RandomCropNearBBox'><p>RandomCropNearBBox</p></a></li>
<li><a href='#icevision_RandomFog'><p>RandomFog</p></a></li>
<li><a href='#icevision_RandomGamma'><p>RandomGamma</p></a></li>
<li><a href='#icevision_RandomGridShuffle'><p>RandomGridShuffle</p></a></li>
<li><a href='#icevision_RandomRain'><p>RandomRain</p></a></li>
<li><a href='#icevision_RandomResizedCrop'><p>RandomResizedCrop</p></a></li>
<li><a href='#icevision_RandomRotate90'><p>RandomRotate90</p></a></li>
<li><a href='#icevision_RandomScale'><p>RandomScale</p></a></li>
<li><a href='#icevision_RandomShadow'><p>RandomShadow</p></a></li>
<li><a href='#icevision_RandomSizedBBoxSafeCrop'><p>RandomSizedBBoxSafeCrop</p></a></li>
<li><a href='#icevision_RandomSizedCrop'><p>RandomSizedCrop</p></a></li>
<li><a href='#icevision_RandomSnow'><p>RandomSnow</p></a></li>
<li><a href='#icevision_RandomSplitter'><p>RandomSplitter</p></a></li>
<li><a href='#icevision_RandomSunFlare'><p>RandomSunFlare</p></a></li>
<li><a href='#icevision_read_bgr_image'><p>Read_bgr_image</p></a></li>
<li><a href='#icevision_read_rgb_image'><p>Read_rgb_image</p></a></li>
<li><a href='#icevision_Resize'><p>Resize</p></a></li>
<li><a href='#icevision_resize_and_pad'><p>Resize_and_pad</p></a></li>
<li><a href='#icevision_RGBShift'><p>RGBShift</p></a></li>
<li><a href='#icevision_Rotate'><p>Rotate</p></a></li>
<li><a href='#icevision_ShiftScaleRotate'><p>ShiftScaleRotate</p></a></li>
<li><a href='#icevision_SingleSplitSplitter'><p>SingleSplitSplitter</p></a></li>
<li><a href='#icevision_SmallestMaxSize'><p>SmallestMaxSize</p></a></li>
<li><a href='#icevision_Solarize'><p>Solarize</p></a></li>
<li><a href='#icevision_ToFloat'><p>ToFloat</p></a></li>
<li><a href='#icevision_ToGray'><p>ToGray</p></a></li>
<li><a href='#icevision_ToSepia'><p>ToSepia</p></a></li>
<li><a href='#icevision_Transpose'><p>Transpose</p></a></li>
<li><a href='#icevision_VerticalFlip'><p>VerticalFlip</p></a></li>
<li><a href='#icnr_init'><p>Icnr_init</p></a></li>
<li><a href='#IDMap'><p>IDMap</p></a></li>
<li><a href='#Image'><p>Image</p></a></li>
<li><a href='#Image_create'><p>Image_create</p></a></li>
<li><a href='#Image_open'><p>Image_open</p></a></li>
<li><a href='#Image_resize'><p>Resize</p></a></li>
<li><a href='#image2tensor'><p>Image2tensor</p></a></li>
<li><a href='#ImageBlock'><p>ImageBlock</p></a></li>
<li><a href='#ImageBW_create'><p>ImageBW_create</p></a></li>
<li><a href='#ImageDataLoaders_from_csv'><p>ImageDataLoaders from csv</p></a></li>
<li><a href='#ImageDataLoaders_from_dblock'><p>ImageDataLoaders from dblock</p></a></li>
<li><a href='#ImageDataLoaders_from_df'><p>ImageDataLoaders from df</p></a></li>
<li><a href='#ImageDataLoaders_from_folder'><p>ImageDataLoaders from folder</p></a></li>
<li><a href='#ImageDataLoaders_from_lists'><p>ImageDataLoaders from lists</p></a></li>
<li><a href='#ImageDataLoaders_from_name_re'><p>ImageDataLoaders from name regex</p></a></li>
<li><a href='#ImageDataLoaders_from_path_func'><p>ImageDataLoaders from path function</p></a></li>
<li><a href='#ImageDataLoaders_from_path_re'><p>ImageDataLoaders from path re</p></a></li>
<li><a href='#imagenet_stats'><p>Imagenet statistics</p></a></li>
<li><a href='#in_channels'><p>In_channels</p></a></li>
<li><a href='#InceptionModule'><p>InceptionModule</p></a></li>
<li><a href='#IndexSplitter'><p>Index Splitter</p></a></li>
<li><a href='#init'><p>Wandb init</p></a></li>
<li><a href='#init_default'><p>Init_default</p></a></li>
<li><a href='#init_linear'><p>Init_linear</p></a></li>
<li><a href='#install_fastai'><p>Install fastai</p></a></li>
<li><a href='#InstanceNorm'><p>InstanceNorm</p></a></li>
<li><a href='#IntToFloatTensor'><p>IntToFloatTensor</p></a></li>
<li><a href='#InvisibleTensor'><p>Invisible Tensor</p></a></li>
<li><a href='#is_rmarkdown'><p>Is Rmarkdown?</p></a></li>
<li><a href='#Jaccard'><p>Jaccard</p></a></li>
<li><a href='#JaccardCoeff'><p>JaccardCoeff</p></a></li>
<li><a href='#JaccardMulti'><p>JaccardMulti</p></a></li>
<li><a href='#kg'><p>Kaggle module</p></a></li>
<li><a href='#L'><p>L</p></a></li>
<li><a href='#L1LossFlat'><p>L1LossFlat</p></a></li>
<li><a href='#l2_reg'><p>L2_reg</p></a></li>
<li><a href='#LabeledBBox'><p>LabeledBBox</p></a></li>
<li><a href='#LabelSmoothingCrossEntropy'><p>LabelSmoothingCrossEntropy</p></a></li>
<li><a href='#LabelSmoothingCrossEntropyFlat'><p>LabelSmoothingCrossEntropyFlat</p></a></li>
<li><a href='#Lamb'><p>Lamb</p></a></li>
<li><a href='#lamb_step'><p>Lamb_step</p></a></li>
<li><a href='#Lambda'><p>Lambda</p></a></li>
<li><a href='#language_model_learner'><p>Language_model_learner</p></a></li>
<li><a href='#Larc'><p>Larc</p></a></li>
<li><a href='#larc_layer_lr'><p>Larc_layer_lr</p></a></li>
<li><a href='#larc_step'><p>Larc_step</p></a></li>
<li><a href='#layer_info'><p>Layer_info</p></a></li>
<li><a href='#Learner'><p>Learner</p></a></li>
<li><a href='#length'><p>Length</p></a></li>
<li><a href='#length.fastai.torch_core.TensorMask'><p>Length</p></a></li>
<li><a href='#less'><p>Less</p></a></li>
<li><a href='#less_or_equal'><p>Less or equal</p></a></li>
<li><a href='#LightingTfm'><p>LightingTfm</p></a></li>
<li><a href='#LinBnDrop'><p>LinBnDrop</p></a></li>
<li><a href='#LinearDecoder'><p>LinearDecoder</p></a></li>
<li><a href='#LitModel'><p>Lit Model</p></a></li>
<li><a href='#LMDataLoader'><p>LMDataLoader</p></a></li>
<li><a href='#LMLearner'><p>LMLearner</p></a></li>
<li><a href='#LMLearner_predict'><p>LMLearner_predict</p></a></li>
<li><a href='#load_dataset'><p>Load_dataset</p></a></li>
<li><a href='#load_ignore_keys'><p>Load_ignore_keys</p></a></li>
<li><a href='#load_image'><p>Load_image</p></a></li>
<li><a href='#load_learner'><p>Load_learner</p></a></li>
<li><a href='#load_model_text'><p>Load_model_text</p></a></li>
<li><a href='#load_pre_models'><p>Timm models</p></a></li>
<li><a href='#load_tokenized_csv'><p>Load_tokenized_csv</p></a></li>
<li><a href='#loaders'><p>Loaders</p></a></li>
<li><a href='#log'><p>Log</p></a></li>
<li><a href='#log.fastai.torch_core.TensorMask'><p>Log</p></a></li>
<li><a href='#log1p'><p>Log1p</p></a></li>
<li><a href='#log1p.fastai.torch_core.TensorMask'><p>Log1p</p></a></li>
<li><a href='#logical_and'><p>Logical_and</p></a></li>
<li><a href='#logical_not_'><p>Logical_not</p></a></li>
<li><a href='#logical_or'><p>Logical_or</p></a></li>
<li><a href='#login'><p>Wandb login</p></a></li>
<li><a href='#Lookahead'><p>Lookahead</p></a></li>
<li><a href='#LossMetric'><p>LossMetric</p></a></li>
<li><a href='#lr_find'><p>Lr_find</p></a></li>
<li><a href='#mae'><p>MAE</p></a></li>
<li><a href='#make_vocab'><p>Make_vocab</p></a></li>
<li><a href='#Mask_create'><p>Mask_create</p></a></li>
<li><a href='#mask_from_blur'><p>Mask from blur</p></a></li>
<li><a href='#mask_rcnn_infer_dl'><p>Mask RCNN infer dataloader</p></a></li>
<li><a href='#mask_rcnn_learner'><p>MaskRCNN learner</p></a></li>
<li><a href='#mask_rcnn_model'><p>MaskRCNN model</p></a></li>
<li><a href='#mask_rcnn_predict_dl'><p>Mask RCNN predict dataloader</p></a></li>
<li><a href='#mask_rcnn_train_dl'><p>MaskRCNN train dataloader</p></a></li>
<li><a href='#mask_rcnn_valid_dl'><p>MaskRSNN valid dataloader</p></a></li>
<li><a href='#mask_tensor'><p>Mask_tensor</p></a></li>
<li><a href='#mask2bbox'><p>Mask2bbox</p></a></li>
<li><a href='#MaskBlock'><p>MaskBlock</p></a></li>
<li><a href='#masked_concat_pool'><p>Masked_concat_pool</p></a></li>
<li><a href='#MaskFreq'><p>Mask Freq</p></a></li>
<li><a href='#MaskTime'><p>MaskTime</p></a></li>
<li><a href='#match_embeds'><p>Match_embeds</p></a></li>
<li><a href='#MatthewsCorrCoef'><p>MatthewsCorrCoef</p></a></li>
<li><a href='#MatthewsCorrCoefMulti'><p>MatthewsCorrCoefMulti</p></a></li>
<li><a href='#max'><p>Max</p></a></li>
<li><a href='#max.fastai.torch_core.TensorMask'><p>Max</p></a></li>
<li><a href='#MaxPool'><p>MaxPool</p></a></li>
<li><a href='#maybe_unsqueeze'><p>Maybe_unsqueeze</p></a></li>
<li><a href='#MCDropoutCallback'><p>MCDropoutCallback</p></a></li>
<li><a href='#mean.fastai.torch_core.TensorMask'><p>Mean of tensor</p></a></li>
<li><a href='#mean.torch.Tensor'><p>Mean of tensor</p></a></li>
<li><a href='#medical'><p>Medical module</p></a></li>
<li><a href='#MergeLayer'><p>MergeLayer</p></a></li>
<li><a href='#metrics'><p>Metrics module</p></a></li>
<li><a href='#migrating_ignite'><p>Ignite module</p></a></li>
<li><a href='#migrating_lightning'><p>Lightning module</p></a></li>
<li><a href='#migrating_pytorch'><p>Pytorch module</p></a></li>
<li><a href='#min'><p>Min</p></a></li>
<li><a href='#min.fastai.torch_core.TensorMask'><p>Min</p></a></li>
<li><a href='#mish'><p>Mish</p></a></li>
<li><a href='#Mish_'><p>Class Mish</p></a></li>
<li><a href='#MishJitAutoFn'><p>MishJitAutoFn</p></a></li>
<li><a href='#MixHandler'><p>MixHandler</p></a></li>
<li><a href='#MixUp'><p>MixUp</p></a></li>
<li><a href='#model_sizes'><p>Model_sizes</p></a></li>
<li><a href='#ModelResetter'><p>ModelResetter</p></a></li>
<li><a href='#Module'><p>Module module</p></a></li>
<li><a href='#Module_test'><p>NN module</p></a></li>
<li><a href='#momentum_step'><p>Momentum_step</p></a></li>
<li><a href='#most_confused'><p>Most_confused</p></a></li>
<li><a href='#mse'><p>MSE</p></a></li>
<li><a href='#MSELossFlat'><p>MSELossFlat</p></a></li>
<li><a href='#msle'><p>MSLE</p></a></li>
<li><a href='#MultiCategorize'><p>MultiCategorize</p></a></li>
<li><a href='#MultiCategoryBlock'><p>MultiCategoryBlock</p></a></li>
<li><a href='#multiplygit add -A &amp;&amp; git commit -m 'staging all files''><p>Multiply</p></a></li>
<li><a href='#MultiTargetLoss'><p>MultiTargetLoss</p></a></li>
<li><a href='#n_px'><p>N_px</p></a></li>
<li><a href='#narrow'><p>Modify tensor</p></a></li>
<li><a href='#Net'><p>Net</p></a></li>
<li><a href='#nn'><p>NN module</p></a></li>
<li><a href='#nn_loss'><p>Fastai custom loss</p></a></li>
<li><a href='#nn_module'><p>Fastai NN module</p></a></li>
<li><a href='#NoiseColor'><p>NoiseColor module</p></a></li>
<li><a href='#NoneReduce'><p>NoneReduce</p></a></li>
<li><a href='#noop'><p>Noop</p></a></li>
<li><a href='#norm_apply_denorm'><p>Norm_apply_denorm</p></a></li>
<li><a href='#Normalize'><p>Normalize</p></a></li>
<li><a href='#Normalize_from_stats'><p>Normalize from stats</p></a></li>
<li><a href='#NormalizeTS'><p>NormalizeTS</p></a></li>
<li><a href='#not__mask'><p>Logical_not</p></a></li>
<li><a href='#not_equal_to'><p>Not equal</p></a></li>
<li><a href='#not_equal_to_mask_'><p>Not equal</p></a></li>
<li><a href='#num_features_model'><p>Num_features_model</p></a></li>
<li><a href='#Numericalize'><p>Numericalize</p></a></li>
<li><a href='#OldRandomCrop'><p>OldRandomCrop</p></a></li>
<li><a href='#one_batch'><p>One batch</p></a></li>
<li><a href='#OpenAudio'><p>OpenAudio</p></a></li>
<li><a href='#optim_metric'><p>Optim metric</p></a></li>
<li><a href='#Optimizer'><p>Optimizer</p></a></li>
<li><a href='#OptimWrapper'><p>OptimWrapper</p></a></li>
<li><a href='#or_mask'><p>Logical_or</p></a></li>
<li><a href='#os'><p>Operating system</p></a></li>
<li><a href='#os_environ_tpu'><p>An environment supporting TPUs</p></a></li>
<li><a href='#pad_conv_norm_relu'><p>Pad_conv_norm_relu</p></a></li>
<li><a href='#pad_input'><p>Pad_input</p></a></li>
<li><a href='#pad_input_chunk'><p>Pad_input_chunk</p></a></li>
<li><a href='#parallel'><p>Parallel</p></a></li>
<li><a href='#parallel_tokenize'><p>Parallel_tokenize</p></a></li>
<li><a href='#params'><p>Params</p></a></li>
<li><a href='#ParamScheduler'><p>ParamScheduler</p></a></li>
<li><a href='#parent_label'><p>Parent_label</p></a></li>
<li><a href='#parsers_AreasMixin'><p>AreasMixin</p></a></li>
<li><a href='#parsers_BBoxesMixin'><p>BBoxesMixin</p></a></li>
<li><a href='#parsers_FasterRCNN'><p>Faster RCNN</p></a></li>
<li><a href='#parsers_FilepathMixin'><p>FilepathMixin</p></a></li>
<li><a href='#parsers_ImageidMixin'><p>Imageid Mixin</p></a></li>
<li><a href='#parsers_IsCrowdsMixin'><p>IsCrowdsMixin</p></a></li>
<li><a href='#parsers_LabelsMixin'><p>LabelsMixin</p></a></li>
<li><a href='#parsers_MaskRCNN'><p>Mask RCNN</p></a></li>
<li><a href='#parsers_MasksMixin'><p>MasksMixin</p></a></li>
<li><a href='#parsers_SizeMixin'><p>SizeMixin</p></a></li>
<li><a href='#parsers_voc'><p>Voc parser</p></a></li>
<li><a href='#partial'><p>Partial</p></a></li>
<li><a href='#PartialDL'><p>PartialDL</p></a></li>
<li><a href='#PartialLambda'><p>Partial Lambda</p></a></li>
<li><a href='#pca'><p>PCA</p></a></li>
<li><a href='#PearsonCorrCoef'><p>PearsonCorrCoef</p></a></li>
<li><a href='#Perplexity'><p>Perplexity</p></a></li>
<li><a href='#Pipeline'><p>Pipeline</p></a></li>
<li><a href='#PixelShuffle_ICNR'><p>PixelShuffle_ICNR</p></a></li>
<li><a href='#plot'><p>Plot dicom</p></a></li>
<li><a href='#plot_bs_find'><p>Plot_bs_find</p></a></li>
<li><a href='#plot_confusion_matrix'><p>Plot_confusion_matrix</p></a></li>
<li><a href='#plot_loss'><p>Plot_loss</p></a></li>
<li><a href='#plot_lr_find'><p>Plot_lr_find</p></a></li>
<li><a href='#plot_top_losses'><p>Plot_top_losses</p></a></li>
<li><a href='#PointBlock'><p>PointBlock</p></a></li>
<li><a href='#PointScaler'><p>PointScaler</p></a></li>
<li><a href='#PooledSelfAttention2d'><p>PooledSelfAttention2d</p></a></li>
<li><a href='#PoolFlatten'><p>PoolFlatten</p></a></li>
<li><a href='#PoolingLinearClassifier'><p>PoolingLinearClassifier</p></a></li>
<li><a href='#pow'><p>Pow</p></a></li>
<li><a href='#pre_process_squad'><p>Pre_process_squad</p></a></li>
<li><a href='#Precision'><p>Precision</p></a></li>
<li><a href='#PrecisionMulti'><p>PrecisionMulti</p></a></li>
<li><a href='#predict.fastai.learner.Learner'><p>Predict</p></a></li>
<li><a href='#predict.fastai.tabular.learner.TabularLearner'><p>Predict</p></a></li>
<li><a href='#preplexity'><p>Perplexity</p></a></li>
<li><a href='#preprocess_audio_folder'><p>Preprocess audio folder</p></a></li>
<li><a href='#PreprocessAudio'><p>Preprocess Audio</p></a></li>
<li><a href='#print.fastai.learner.Learner'><p>Print model</p></a></li>
<li><a href='#print.fastai.tabular.learner.TabularLearner'><p>Print tabular model</p></a></li>
<li><a href='#print.pydicom.dataset.FileDataset'><p>Dicom</p></a></li>
<li><a href='#py_apply'><p>Py_apply</p></a></li>
<li><a href='#python_path'><p>Python path</p></a></li>
<li><a href='#QHAdam'><p>QHAdam</p></a></li>
<li><a href='#qhadam_step'><p>Qhadam_step</p></a></li>
<li><a href='#QRNN'><p>QRNN</p></a></li>
<li><a href='#QRNNLayer'><p>QRNNLayer</p></a></li>
<li><a href='#R2Score'><p>R2Score</p></a></li>
<li><a href='#RAdam'><p>RAdam</p></a></li>
<li><a href='#radam_step'><p>Radam_step</p></a></li>
<li><a href='#RandomCrop'><p>RandomCrop</p></a></li>
<li><a href='#RandomErasing'><p>RandomErasing</p></a></li>
<li><a href='#RandomResizedCrop'><p>RandomResizedCrop</p></a></li>
<li><a href='#RandomResizedCropGPU'><p>RandomResizedCropGPU</p></a></li>
<li><a href='#RandomSplitter'><p>RandomSplitter</p></a></li>
<li><a href='#RandPair'><p>RandPair</p></a></li>
<li><a href='#RandTransform'><p>RandTransform</p></a></li>
<li><a href='#ranger'><p>Ranger</p></a></li>
<li><a href='#RatioResize'><p>RatioResize</p></a></li>
<li><a href='#ReadTSBatch'><p>ReadTSBatch</p></a></li>
<li><a href='#Recall'><p>Recall</p></a></li>
<li><a href='#RecallMulti'><p>RecallMulti</p></a></li>
<li><a href='#ReduceLROnPlateau'><p>ReduceLROnPlateau</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#RegressionBlock'><p>RegressionBlock</p></a></li>
<li><a href='#RemoveSilence'><p>Remove Silence</p></a></li>
<li><a href='#RemoveType'><p>RemoveType module</p></a></li>
<li><a href='#replace_all_caps'><p>Replace_all_caps</p></a></li>
<li><a href='#replace_maj'><p>Replace_maj</p></a></li>
<li><a href='#replace_rep'><p>Replace_rep</p></a></li>
<li><a href='#replace_wrep'><p>Replace_wrep</p></a></li>
<li><a href='#res_block_1d'><p>Res_block_1d</p></a></li>
<li><a href='#Resample'><p>Resample</p></a></li>
<li><a href='#ResBlock'><p>ResBlock</p></a></li>
<li><a href='#reshape'><p>Reshape</p></a></li>
<li><a href='#Resize'><p>Resize</p></a></li>
<li><a href='#resize_max'><p>Resize_max</p></a></li>
<li><a href='#ResizeBatch'><p>ResizeBatch</p></a></li>
<li><a href='#ResizeSignal'><p>Resize Signal</p></a></li>
<li><a href='#ResNet'><p>ResNet</p></a></li>
<li><a href='#resnet_generator'><p>Resnet_generator</p></a></li>
<li><a href='#resnet101'><p>Resnet101</p></a></li>
<li><a href='#resnet152'><p>Resnet152</p></a></li>
<li><a href='#resnet18'><p>Resnet18</p></a></li>
<li><a href='#resnet34'><p>Resnet34</p></a></li>
<li><a href='#resnet50'><p>Resnet50</p></a></li>
<li><a href='#ResnetBlock'><p>ResnetBlock</p></a></li>
<li><a href='#RetinaNet'><p>RetinaNet</p></a></li>
<li><a href='#retinanet_'><p>Retinanet module</p></a></li>
<li><a href='#RetinaNetFocalLoss'><p>RetinaNetFocalLoss</p></a></li>
<li><a href='#reverse_text'><p>Reverse_text</p></a></li>
<li><a href='#rgb2hsv'><p>Rgb2hsv</p></a></li>
<li><a href='#rm_useless_spaces'><p>Rm_useless_spaces</p></a></li>
<li><a href='#rms_prop_step'><p>Rms_prop_step</p></a></li>
<li><a href='#rmse'><p>RMSE</p></a></li>
<li><a href='#RMSProp'><p>RMSProp</p></a></li>
<li><a href='#RNNDropout'><p>RNNDropout</p></a></li>
<li><a href='#RNNRegularizer'><p>RNNRegularizer</p></a></li>
<li><a href='#RocAuc'><p>RocAuc</p></a></li>
<li><a href='#RocAucBinary'><p>RocAucBinary</p></a></li>
<li><a href='#RocAucMulti'><p>RocAucMulti</p></a></li>
<li><a href='#Rotate'><p>Rotate</p></a></li>
<li><a href='#rotate_mat'><p>Rotate_mat</p></a></li>
<li><a href='#round'><p>Round</p></a></li>
<li><a href='#round.fastai.torch_core.TensorMask'><p>Round</p></a></li>
<li><a href='#Saturation'><p>Saturation</p></a></li>
<li><a href='#SaveModelCallback'><p>SaveModelCallback</p></a></li>
<li><a href='#SchedCos'><p>SchedCos</p></a></li>
<li><a href='#SchedExp'><p>SchedExp</p></a></li>
<li><a href='#SchedLin'><p>SchedLin</p></a></li>
<li><a href='#SchedNo'><p>SchedNo</p></a></li>
<li><a href='#SchedPoly'><p>SchedPoly</p></a></li>
<li><a href='#SEBlock'><p>SEBlock</p></a></li>
<li><a href='#SegmentationDataLoaders_from_label_func'><p>SegmentationDataLoaders_from_label_func</p></a></li>
<li><a href='#SelfAttention'><p>SelfAttention</p></a></li>
<li><a href='#SEModule'><p>SEModule</p></a></li>
<li><a href='#SentenceEncoder'><p>SentenceEncoder</p></a></li>
<li><a href='#SentencePieceTokenizer'><p>SentencePieceTokenizer</p></a></li>
<li><a href='#SeparableBlock'><p>SeparableBlock</p></a></li>
<li><a href='#sequential'><p>Sequential</p></a></li>
<li><a href='#SequentialEx'><p>SequentialEx</p></a></li>
<li><a href='#SequentialRNN'><p>Sequential RNN</p></a></li>
<li><a href='#SEResNeXtBlock'><p>SEResNeXtBlock</p></a></li>
<li><a href='#set_freeze_model'><p>Set freeze model</p></a></li>
<li><a href='#set_item_pg'><p>Set_item_pg</p></a></li>
<li><a href='#setup_aug_tfms'><p>Setup_aug_tfms</p></a></li>
<li><a href='#SGD'><p>SGD</p></a></li>
<li><a href='#sgd_step'><p>Sgd_step</p></a></li>
<li><a href='#SGRoll'><p>SGRoll</p></a></li>
<li><a href='#shap'><p>Shap module</p></a></li>
<li><a href='#shape'><p>Shape</p></a></li>
<li><a href='#ShapInterpretation'><p>ShapInterpretation</p></a></li>
<li><a href='#Shortcut'><p>Shortcut</p></a></li>
<li><a href='#ShortEpochCallback'><p>ShortEpochCallback</p></a></li>
<li><a href='#show'><p>Show</p></a></li>
<li><a href='#show_array'><p>Show_array</p></a></li>
<li><a href='#show_batch'><p>Show_batch</p></a></li>
<li><a href='#show_image'><p>Show_image</p></a></li>
<li><a href='#show_images'><p>Show_images</p></a></li>
<li><a href='#show_preds'><p>Show_preds</p></a></li>
<li><a href='#show_results'><p>Show_results</p></a></li>
<li><a href='#show_samples'><p>Show_samples</p></a></li>
<li><a href='#ShowCycleGANImgsCallback'><p>ShowCycleGANImgsCallback</p></a></li>
<li><a href='#ShowGraphCallback'><p>ShowGraphCallback</p></a></li>
<li><a href='#sigmoid'><p>Sigmoid</p></a></li>
<li><a href='#sigmoid_'><p>Sigmoid_</p></a></li>
<li><a href='#sigmoid_range'><p>Sigmoid_range</p></a></li>
<li><a href='#SigmoidRange'><p>SigmoidRange</p></a></li>
<li><a href='#SignalCutout'><p>Signal Cutout</p></a></li>
<li><a href='#SignalLoss'><p>Signal Loss</p></a></li>
<li><a href='#SignalShifter'><p>Signal Shifter</p></a></li>
<li><a href='#SimpleCNN'><p>SimpleCNN</p></a></li>
<li><a href='#SimpleSelfAttention'><p>SimpleSelfAttention</p></a></li>
<li><a href='#sin_'><p>Sin</p></a></li>
<li><a href='#sin.fastai.torch_core.TensorMask'><p>Sin</p></a></li>
<li><a href='#sinh.fastai.torch_core.TensorMask'><p>Sinh</p></a></li>
<li><a href='#skm_to_fastai'><p>Skm to fastai</p></a></li>
<li><a href='#slice'><p>Slice</p></a></li>
<li><a href='#sort'><p>Sort</p></a></li>
<li><a href='#sort.fastai.torch_core.TensorMask'><p>Sort</p></a></li>
<li><a href='#SortedDL'><p>SortedDL</p></a></li>
<li><a href='#SpacyTokenizer'><p>SpacyTokenizer</p></a></li>
<li><a href='#SpearmanCorrCoef'><p>SpearmanCorrCoef</p></a></li>
<li><a href='#spec_add_spaces'><p>Spec_add_spaces</p></a></li>
<li><a href='#SpectrogramTransformer'><p>Spectrogram Transformer</p></a></li>
<li><a href='#sqrd'><p>Sqrt</p></a></li>
<li><a href='#sqrt.fastai.torch_core.TensorMask'><p>Sqrt</p></a></li>
<li><a href='#SqueezeNet'><p>SqueezeNet</p></a></li>
<li><a href='#squeezenet1_0'><p>Squeezenet1_0</p></a></li>
<li><a href='#squeezenet1_1'><p>Squeezenet1_1</p></a></li>
<li><a href='#stack_train_valid'><p>Stack_train_valid</p></a></li>
<li><a href='#step_stat'><p>Step_stat</p></a></li>
<li><a href='#sub'><p>Sub</p></a></li>
<li><a href='#sub_mask'><p>Sub</p></a></li>
<li><a href='#subplots'><p>Subplots</p></a></li>
<li><a href='#summarization_splitter'><p>Summarization_splitter</p></a></li>
<li><a href='#summary_plot'><p>Summary_plot</p></a></li>
<li><a href='#summary.fastai.learner.Learner'><p>Summary</p></a></li>
<li><a href='#summary.fastai.tabular.learner.TabularLearner'><p>Summary</p></a></li>
<li><a href='#swish'><p>Swish</p></a></li>
<li><a href='#Swish_'><p>Swish</p></a></li>
<li><a href='#tabular'><p>Tabular</p></a></li>
<li><a href='#tabular_config'><p>Tabular_config</p></a></li>
<li><a href='#tabular_learner'><p>Tabular learner</p></a></li>
<li><a href='#TabularDataTable'><p>TabularDataTable</p></a></li>
<li><a href='#TabularModel'><p>TabularModel</p></a></li>
<li><a href='#TabularTS'><p>TabularTS</p></a></li>
<li><a href='#TabularTSDataloader'><p>TabularTSDataloader</p></a></li>
<li><a href='#tar_extract_at_filename'><p>Tar_extract_at_filename</p></a></li>
<li><a href='#tensor'><p>Tensor</p></a></li>
<li><a href='#TensorBBox'><p>TensorBBox</p></a></li>
<li><a href='#TensorBBox_create'><p>TensorBBox_create</p></a></li>
<li><a href='#TensorImage'><p>TensorImage</p></a></li>
<li><a href='#TensorImageBW'><p>TensorImageBW</p></a></li>
<li><a href='#TensorMultiCategory'><p>TensorMultiCategory</p></a></li>
<li><a href='#TensorPoint'><p>TensorPoint</p></a></li>
<li><a href='#TensorPoint_create'><p>TensorPoint_create</p></a></li>
<li><a href='#TerminateOnNaNCallback'><p>TerminateOnNaNCallback</p></a></li>
<li><a href='#test_loader'><p>Test_loader</p></a></li>
<li><a href='#text'><p>Text module</p></a></li>
<li><a href='#text_classifier_learner'><p>Text_classifier_learner</p></a></li>
<li><a href='#TextBlock'><p>TextBlock</p></a></li>
<li><a href='#TextBlock_from_df'><p>TextBlock_from_df</p></a></li>
<li><a href='#TextBlock_from_folder'><p>TextBlock_from_folder</p></a></li>
<li><a href='#TextDataLoaders_from_csv'><p>TextDataLoaders_from_csv</p></a></li>
<li><a href='#TextDataLoaders_from_df'><p>TextDataLoaders_from_df</p></a></li>
<li><a href='#TextDataLoaders_from_folder'><p>TextDataLoaders_from_folder</p></a></li>
<li><a href='#TextLearner'><p>TextLearner</p></a></li>
<li><a href='#TextLearner_load_encoder'><p>Load_encoder</p></a></li>
<li><a href='#TextLearner_load_pretrained'><p>Load_pretrained</p></a></li>
<li><a href='#TextLearner_save_encoder'><p>Save_encoder</p></a></li>
<li><a href='#TfmdDL'><p>TfmdDL</p></a></li>
<li><a href='#TfmdLists'><p>TfmdLists</p></a></li>
<li><a href='#TfmResize'><p>TfmResize</p></a></li>
<li><a href='#timm'><p>Timm module</p></a></li>
<li><a href='#timm_learner'><p>Timm_learner</p></a></li>
<li><a href='#timm_list_models'><p>Timm models</p></a></li>
<li><a href='#tms'><p>Timeseries module</p></a></li>
<li><a href='#to_bytes_format'><p>To_bytes_format</p></a></li>
<li><a href='#to_image'><p>To_image</p></a></li>
<li><a href='#to_matrix'><p>To matrix</p></a></li>
<li><a href='#to_thumb'><p>To_thumb</p></a></li>
<li><a href='#to_xla'><p>Learn to XLA</p></a></li>
<li><a href='#tokenize_csv'><p>Tokenize_csv</p></a></li>
<li><a href='#tokenize_df'><p>Tokenize_df</p></a></li>
<li><a href='#tokenize_files'><p>Tokenize_files</p></a></li>
<li><a href='#tokenize_folder'><p>Tokenize_folder</p></a></li>
<li><a href='#tokenize_texts'><p>Tokenize_texts</p></a></li>
<li><a href='#tokenize1'><p>Tokenize1</p></a></li>
<li><a href='#Tokenizer'><p>Tokenizer</p></a></li>
<li><a href='#Tokenizer_from_df'><p>Tokenizer_from_df</p></a></li>
<li><a href='#TokenizeWithRules'><p>TokenizeWithRules</p></a></li>
<li><a href='#top_k_accuracy'><p>Top_k_accuracy</p></a></li>
<li><a href='#torch'><p>Builtins module</p></a></li>
<li><a href='#total_params'><p>Total_params</p></a></li>
<li><a href='#ToTensor'><p>ToTensor</p></a></li>
<li><a href='#TrackerCallback'><p>TrackerCallback</p></a></li>
<li><a href='#train_loader'><p>Train_loader</p></a></li>
<li><a href='#trainable_params'><p>Trainable_params</p></a></li>
<li><a href='#TrainEvalCallback'><p>TrainEvalCallback</p></a></li>
<li><a href='#Transform'><p>Transform</p></a></li>
<li><a href='#TransformBlock'><p>TransformBlock</p></a></li>
<li><a href='#transformers'><p>Transformers</p></a></li>
<li><a href='#TransformersDropOutput'><p>TransformersDropOutput</p></a></li>
<li><a href='#TransformersTokenizer'><p>TransformersTokenizer</p></a></li>
<li><a href='#trunc_normal_'><p>Trunc_normal_</p></a></li>
<li><a href='#TSBlock'><p>TSBlock</p></a></li>
<li><a href='#TSDataLoaders_from_dfs'><p>TSDataLoaders_from_dfs</p></a></li>
<li><a href='#TSDataTable'><p>TSDataTable</p></a></li>
<li><a href='#TSeries'><p>TSeries</p></a></li>
<li><a href='#TSeries_create'><p>TSeries_create</p></a></li>
<li><a href='#unet_config'><p>Unet_config</p></a></li>
<li><a href='#unet_learner'><p>Unet_learner</p></a></li>
<li><a href='#UnetBlock'><p>UnetBlock</p></a></li>
<li><a href='#unfreeze'><p>Unfreeze a model</p></a></li>
<li><a href='#uniform_blur2d'><p>Uniform_blur2d</p></a></li>
<li><a href='#upit'><p>Upit module</p></a></li>
<li><a href='#URLs_ADULT_SAMPLE'><p>ADULT_SAMPLE dataset</p></a></li>
<li><a href='#URLs_AG_NEWS'><p>AG_NEWS dataset</p></a></li>
<li><a href='#URLs_AMAZON_REVIEWS_POLARITY'><p>AMAZON_REVIEWS_POLARITY dataset</p></a></li>
<li><a href='#URLs_AMAZON_REVIEWSAMAZON_REVIEWS'><p>AMAZON_REVIEWSAMAZON_REVIEWS dataset</p></a></li>
<li><a href='#URLs_BIWI_HEAD_POSE'><p>BIWI_HEAD_POSE dataset</p></a></li>
<li><a href='#URLs_CALTECH_101'><p>CALTECH_101 dataset</p></a></li>
<li><a href='#URLs_CAMVID'><p>CAMVID dataset</p></a></li>
<li><a href='#URLs_CAMVID_TINY'><p>CAMVID_TINY dataset</p></a></li>
<li><a href='#URLs_CARS'><p>CARS dataset</p></a></li>
<li><a href='#URLs_CIFAR'><p>CIFAR dataset</p></a></li>
<li><a href='#URLs_CIFAR_100'><p>CIFAR_100 dataset</p></a></li>
<li><a href='#URLs_COCO_TINY'><p>COCO_TINY dataset</p></a></li>
<li><a href='#URLs_CUB_200_2011'><p>CUB_200_2011 dataset</p></a></li>
<li><a href='#URLs_DBPEDIA'><p>DBPEDIA dataset</p></a></li>
<li><a href='#URLs_DOGS'><p>DOGS dataset</p></a></li>
<li><a href='#URLs_FLOWERS'><p>FLOWERS dataset</p></a></li>
<li><a href='#URLs_FOOD'><p>FOOD dataset</p></a></li>
<li><a href='#URLs_HORSE_2_ZEBRA'><p>HORSE_2_ZEBRA dataset</p></a></li>
<li><a href='#URLs_HUMAN_NUMBERS'><p>HUMAN_NUMBERS dataset</p></a></li>
<li><a href='#URLs_IMAGENETTE'><p>IMAGENETTE dataset</p></a></li>
<li><a href='#URLs_IMAGENETTE_160'><p>IMAGENETTE_160 dataset</p></a></li>
<li><a href='#URLs_IMAGENETTE_320'><p>IMAGENETTE_320 dataset</p></a></li>
<li><a href='#URLs_IMAGEWOOF'><p>IMAGEWOOF dataset</p></a></li>
<li><a href='#URLs_IMAGEWOOF_160'><p>IMAGEWOOF_160 dataset</p></a></li>
<li><a href='#URLs_IMAGEWOOF_320'><p>IMAGEWOOF_320 dataset</p></a></li>
<li><a href='#URLs_IMDB'><p>IMDB dataset</p></a></li>
<li><a href='#URLs_IMDB_SAMPLE'><p>IMDB_SAMPLE dataset</p></a></li>
<li><a href='#URLs_LSUN_BEDROOMS'><p>LSUN_BEDROOMS dataset</p></a></li>
<li><a href='#URLs_ML_SAMPLE'><p>ML_SAMPLE dataset</p></a></li>
<li><a href='#URLs_MNIST'><p>MNIST dataset</p></a></li>
<li><a href='#URLs_MNIST_SAMPLE'><p>MNIST_SAMPLE dataset</p></a></li>
<li><a href='#URLs_MNIST_TINY'><p>MNIST_TINY dataset</p></a></li>
<li><a href='#URLs_MNIST_VAR_SIZE_TINY'><p>MNIST_VAR_SIZE_TINY dataset</p></a></li>
<li><a href='#URLs_MOVIE_LENS_ML_100k'><p>MOVIE_LENS_ML_100k dataset</p></a></li>
<li><a href='#URLs_MT_ENG_FRA'><p>MT_ENG_FRA dataset</p></a></li>
<li><a href='#URLs_OPENAI_TRANSFORMER'><p>OPENAI_TRANSFORMER dataset</p></a></li>
<li><a href='#URLs_PASCAL_2007'><p>PASCAL_2007 dataset</p></a></li>
<li><a href='#URLs_PASCAL_2012'><p>PASCAL_2012 dataset</p></a></li>
<li><a href='#URLs_PETS'><p>PETS dataset</p></a></li>
<li><a href='#URLs_PLANET_SAMPLE'><p>PLANET_SAMPLE dataset</p></a></li>
<li><a href='#URLs_PLANET_TINY'><p>PLANET_TINY dataset</p></a></li>
<li><a href='#URLs_S3_COCO'><p>S3_COCO dataset</p></a></li>
<li><a href='#URLs_S3_IMAGE'><p>S3_IMAGE dataset</p></a></li>
<li><a href='#URLs_S3_IMAGELOC'><p>S3_IMAGELOC dataset</p></a></li>
<li><a href='#URLs_S3_MODEL'><p>S3_MODEL dataset</p></a></li>
<li><a href='#URLs_S3_NLP'><p>S3_NLP dataset</p></a></li>
<li><a href='#URLs_SIIM_SMALL'><p>SIIM_SMALL</p></a></li>
<li><a href='#URLs_SKIN_LESION'><p>SKIN_LESION dataset</p></a></li>
<li><a href='#URLs_SOGOU_NEWS'><p>SOGOU_NEWS dataset</p></a></li>
<li><a href='#URLs_SPEAKERS10'><p>SPEAKERS10 dataset</p></a></li>
<li><a href='#URLs_SPEECHCOMMANDS'><p>SPEECHCOMMANDS dataset</p></a></li>
<li><a href='#URLs_WIKITEXT'><p>WIKITEXT dataset</p></a></li>
<li><a href='#URLs_WIKITEXT_TINY'><p>WIKITEXT_TINY dataset</p></a></li>
<li><a href='#URLs_WT103_BWD'><p>WT103_BWD dataset</p></a></li>
<li><a href='#URLs_WT103_FWD'><p>WT103_FWD dataset</p></a></li>
<li><a href='#URLs_YAHOO_ANSWERS'><p>YAHOO_ANSWERS dataset</p></a></li>
<li><a href='#URLs_YELP_REVIEWS'><p>YELP_REVIEWS dataset</p></a></li>
<li><a href='#URLs_YELP_REVIEWS_POLARITY'><p>YELP_REVIEWS_POLARITY dataset</p></a></li>
<li><a href='#vgg11_bn'><p>Vgg11_bn</p></a></li>
<li><a href='#vgg13_bn'><p>Vgg13_bn</p></a></li>
<li><a href='#vgg16_bn'><p>Vgg16_bn</p></a></li>
<li><a href='#vgg19_bn'><p>Vgg19_bn</p></a></li>
<li><a href='#vision'><p>Vision module</p></a></li>
<li><a href='#vleaky_relu'><p>Vleaky_relu</p></a></li>
<li><a href='#Voice'><p>Voice</p></a></li>
<li><a href='#wandb'><p>Wandb module</p></a></li>
<li><a href='#WandbCallback'><p>WandbCallback</p></a></li>
<li><a href='#Warp'><p>Warp</p></a></li>
<li><a href='#waterfall_plot'><p>Waterfall_plot</p></a></li>
<li><a href='#weight_decay'><p>Weight_decay</p></a></li>
<li><a href='#WeightDropout'><p>WeightDropout</p></a></li>
<li><a href='#WeightedDL'><p>WeightedDL</p></a></li>
<li><a href='#win_abdoment_soft'><p>Abdomen soft</p></a></li>
<li><a href='#win_brain'><p>Brain</p></a></li>
<li><a href='#win_brain_bone'><p>Brain bone</p></a></li>
<li><a href='#win_brain_soft'><p>Brain soft</p></a></li>
<li><a href='#win_liver'><p>Liver</p></a></li>
<li><a href='#win_lungs'><p>Lungs</p></a></li>
<li><a href='#win_mediastinum'><p>Mediastinum</p></a></li>
<li><a href='#win_spine_bone'><p>Spine bone</p></a></li>
<li><a href='#win_spine_soft'><p>Spine soft</p></a></li>
<li><a href='#win_stroke'><p>Stroke</p></a></li>
<li><a href='#win_subdural'><p>Subdural</p></a></li>
<li><a href='#xla'><p>XLA</p></a></li>
<li><a href='#XResNet'><p>XResNet</p></a></li>
<li><a href='#xresnet101'><p>Xresnet101</p></a></li>
<li><a href='#xresnet152'><p>Xresnet152</p></a></li>
<li><a href='#xresnet18'><p>Xresnet18</p></a></li>
<li><a href='#xresnet18_deep'><p>Xresnet18_deep</p></a></li>
<li><a href='#xresnet18_deeper'><p>Xresnet18_deeper</p></a></li>
<li><a href='#xresnet34'><p>Xresnet34</p></a></li>
<li><a href='#xresnet34_deep'><p>Xresnet34_deep</p></a></li>
<li><a href='#xresnet34_deeper'><p>Xresnet34_deeper</p></a></li>
<li><a href='#xresnet50'><p>Xresnet50</p></a></li>
<li><a href='#xresnet50_deep'><p>Xresnet50_deep</p></a></li>
<li><a href='#xresnet50_deeper'><p>Xresnet50_deeper</p></a></li>
<li><a href='#xresnext101'><p>xresnext101</p></a></li>
<li><a href='#xresnext18'><p>xresnext18</p></a></li>
<li><a href='#xresnext34'><p>xresnext34</p></a></li>
<li><a href='#xresnext50'><p>xresnext50</p></a></li>
<li><a href='#xse_resnet101'><p>xse_resnet101</p></a></li>
<li><a href='#xse_resnet152'><p>xse_resnet152</p></a></li>
<li><a href='#xse_resnet18'><p>xse_resnet18</p></a></li>
<li><a href='#xse_resnet34'><p>xse_resnet34</p></a></li>
<li><a href='#xse_resnet50'><p>xse_resnet50</p></a></li>
<li><a href='#xse_resnext101'><p>xse_resnext101</p></a></li>
<li><a href='#xse_resnext18'><p>xse_resnext18</p></a></li>
<li><a href='#xse_resnext18_deep'><p>xse_resnext18_deep</p></a></li>
<li><a href='#xse_resnext18_deeper'><p>xse_resnext18_deeper</p></a></li>
<li><a href='#xse_resnext34'><p>xse_resnext34</p></a></li>
<li><a href='#xse_resnext34_deep'><p>xse_resnext34_deep</p></a></li>
<li><a href='#xse_resnext34_deeper'><p>xse_resnext34_deeper</p></a></li>
<li><a href='#xse_resnext50'><p>xse_resnext50</p></a></li>
<li><a href='#xse_resnext50_deep'><p>xse_resnext50_deep</p></a></li>
<li><a href='#xse_resnext50_deeper'><p>xse_resnext50_deeper</p></a></li>
<li><a href='#xsenet154'><p>xsenet154</p></a></li>
<li><a href='#zoom'><p>Zoom</p></a></li>
<li><a href='#Zoom_'><p>Zoom</p></a></li>
<li><a href='#zoom_mat'><p>Zoom_mat</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Interface to 'fastai'</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Turgut Abdullayev &lt;turqut.a.314@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The 'fastai' <a href="https://docs.fast.ai/index.html">https://docs.fast.ai/index.html</a> library 
             simplifies training fast and accurate neural networks 
             using modern best practices. It is based on research 
             in to deep learning best practices undertaken 
             at 'fast.ai', including 'out of the box' support
             for vision, text, tabular, audio, time series, and 
             collaborative filtering models. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/EagerAI/fastai">https://github.com/EagerAI/fastai</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/EagerAI/fastai/issues">https://github.com/EagerAI/fastai/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>reticulate, generics, png, ggplot2, ggpubr, glue</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, testthat, rmarkdown, curl, magrittr, data.table,
vctrs, stats, utils, R.utils, viridis, zeallot</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-11 17:06:51 UTC; turgutabd</td>
</tr>
<tr>
<td>Author:</td>
<td>Turgut Abdullayev [ctb, cre, cph, aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-12 00:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+2A.fastai.torch_core.TensorMask'>Multiply</h2><span id='topic++2A.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Multiply
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a * b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2A.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B2A.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+2F.fastai.torch_core.TensorMask'>Div</h2><span id='topic++2F.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Div
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a / b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2F.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B2F.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+26amp+3B.fastai.torch_core.TensorMask'>Logical_and</h2><span id='topic++26.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Logical_and
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
x &amp; y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26amp+2B3B.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26amp+2B3B.fastai.torch_core.TensorMask_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+26gt+3B.fastai.torch_core.TensorMask'>Greater</h2><span id='topic++3E.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Greater
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a &gt; b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26gt+2B3B.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26gt+2B3B.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+26gt+3B+3D.fastai.torch_core.TensorMask'>Greater or equal</h2><span id='topic++3E+3D.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Greater or equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a &gt;= b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26gt+2B3B+2B3D.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26gt+2B3B+2B3D.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+26lt+3B.fastai.torch_core.TensorMask'>Less</h2><span id='topic++3C.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Less
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a &lt; b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26lt+2B3B.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26lt+2B3B.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+26lt+3B+3D.fastai.torch_core.TensorMask'>Less or equal</h2><span id='topic++3C+3D.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Less or equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a &lt;= b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26lt+2B3B+2B3D.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26lt+2B3B+2B3D.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+25+2F+25.fastai.torch_core.TensorMask'>Floor divide</h2><span id='topic++25+2F+25.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Floor divide
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
x %/% y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B2F+2B25.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B25+2B2F+2B25.fastai.torch_core.TensorMask_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+25+25.fastai.torch_core.TensorMask'>Floor mod</h2><span id='topic++25+25.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Floor mod
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
x %% y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B25.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B25+2B25.fastai.torch_core.TensorMask_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+25f+25'>Fastai assignment</h2><span id='topic++25f+25'></span>

<h3>Description</h3>

<p>The assignment has to be used for safe modification of the values inside tensors/layers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>left %f% right
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25f+2B25_+3A_left">left</code></td>
<td>
<p>left side object</p>
</td></tr>
<tr><td><code id="+2B25f+2B25_+3A_right">right</code></td>
<td>
<p>right side object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='+5E.fastai.torch_core.TensorMask'>Pow</h2><span id='topic++5E.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Pow
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a ^ b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5E.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B5E.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+2B.fastai.torch_core.TensorMask'>Add</h2><span id='topic++2B.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Add
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a + b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2B.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B2B.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+2B.torch.nn.modules.container.Sequential'>Add layers to Sequential</h2><span id='topic++2B.torch.nn.modules.container.Sequential'></span>

<h3>Description</h3>

<p>Add layers to Sequential
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.nn.modules.container.Sequential'
a + b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2B.torch.nn.modules.container.Sequential_+3A_a">a</code></td>
<td>
<p>sequential model</p>
</td></tr>
<tr><td><code id="+2B2B.torch.nn.modules.container.Sequential_+3A_b">b</code></td>
<td>
<p>layer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='+3D+3D.fastai.torch_core.TensorImage'>Equal</h2><span id='topic++3D+3D.fastai.torch_core.TensorImage'></span>

<h3>Description</h3>

<p>Equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorImage'
a == b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B3D+2B3D.fastai.torch_core.TensorImage_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B3D+2B3D.fastai.torch_core.TensorImage_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+3D+3D.fastai.torch_core.TensorMask'>Equal</h2><span id='topic++3D+3D.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a == b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B3D+2B3D.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B3D+2B3D.fastai.torch_core.TensorMask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='+3D+3D.torch.Tensor'>Equal</h2><span id='topic++3D+3D.torch.Tensor'></span>

<h3>Description</h3>

<p>Equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a == b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B3D+2B3D.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B3D+2B3D.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='abs'>Abs</h2><span id='topic+abs'></span><span id='topic+abs.torch.Tensor'></span>

<h3>Description</h3>

<p>Abs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
abs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='abs.fastai.torch_core.TensorMask'>Abs</h2><span id='topic+abs.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Abs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
abs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor, e.g.: tensor(-1:-10)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='AccumMetric'>AccumMetric</h2><span id='topic+AccumMetric'></span>

<h3>Description</h3>

<p>Stores predictions and targets on CPU in accumulate to perform final calculations with 'func'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AccumMetric(
  func,
  dim_argmax = NULL,
  activation = "no",
  thresh = NULL,
  to_np = FALSE,
  invert_arg = FALSE,
  flatten = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AccumMetric_+3A_func">func</code></td>
<td>
<p>function</p>
</td></tr>
<tr><td><code id="AccumMetric_+3A_dim_argmax">dim_argmax</code></td>
<td>
<p>dimension argmax</p>
</td></tr>
<tr><td><code id="AccumMetric_+3A_activation">activation</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="AccumMetric_+3A_thresh">thresh</code></td>
<td>
<p>threshold point</p>
</td></tr>
<tr><td><code id="AccumMetric_+3A_to_np">to_np</code></td>
<td>
<p>to matrix or not</p>
</td></tr>
<tr><td><code id="AccumMetric_+3A_invert_arg">invert_arg</code></td>
<td>
<p>invert arguments</p>
</td></tr>
<tr><td><code id="AccumMetric_+3A_flatten">flatten</code></td>
<td>
<p>flatten</p>
</td></tr>
<tr><td><code id="AccumMetric_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='accuracy'>Accuracy</h2><span id='topic+accuracy'></span>

<h3>Description</h3>

<p>Compute accuracy with 'targ' when 'pred' is bs * n_classes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accuracy(inp, targ, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accuracy_+3A_inp">inp</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="accuracy_+3A_targ">targ</code></td>
<td>
<p>targets</p>
</td></tr>
<tr><td><code id="accuracy_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='accuracy_multi'>Accuracy_multi</h2><span id='topic+accuracy_multi'></span>

<h3>Description</h3>

<p>Compute accuracy when 'inp' and 'targ' are the same size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accuracy_multi(inp, targ, thresh = 0.5, sigmoid = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accuracy_multi_+3A_inp">inp</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="accuracy_multi_+3A_targ">targ</code></td>
<td>
<p>targets</p>
</td></tr>
<tr><td><code id="accuracy_multi_+3A_thresh">thresh</code></td>
<td>
<p>threshold point</p>
</td></tr>
<tr><td><code id="accuracy_multi_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='accuracy_thresh_expand'>Accuracy threshold expand</h2><span id='topic+accuracy_thresh_expand'></span>

<h3>Description</h3>

<p>Compute accuracy after expanding 'y_true' to the size of 'y_pred'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accuracy_thresh_expand(y_pred, y_true, thresh = 0.5, sigmoid = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accuracy_thresh_expand_+3A_y_pred">y_pred</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="accuracy_thresh_expand_+3A_y_true">y_true</code></td>
<td>
<p>actuals</p>
</td></tr>
<tr><td><code id="accuracy_thresh_expand_+3A_thresh">thresh</code></td>
<td>
<p>threshold point</p>
</td></tr>
<tr><td><code id="accuracy_thresh_expand_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Adam'>Adam</h2><span id='topic+Adam'></span>

<h3>Description</h3>

<p>Adam
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Adam(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Adam_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='adam_step'>Adam_step</h2><span id='topic+adam_step'></span>

<h3>Description</h3>

<p>Step for Adam with 'lr' on 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adam_step_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="adam_step_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="adam_step_+3A_mom">mom</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="adam_step_+3A_step">step</code></td>
<td>
<p>step</p>
</td></tr>
<tr><td><code id="adam_step_+3A_sqr_mom">sqr_mom</code></td>
<td>
<p>sqr momentum</p>
</td></tr>
<tr><td><code id="adam_step_+3A_grad_avg">grad_avg</code></td>
<td>
<p>grad average</p>
</td></tr>
<tr><td><code id="adam_step_+3A_sqr_avg">sqr_avg</code></td>
<td>
<p>sqr average</p>
</td></tr>
<tr><td><code id="adam_step_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="adam_step_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='adaptive_pool'>Adaptive_pool</h2><span id='topic+adaptive_pool'></span>

<h3>Description</h3>

<p>Adaptive_pool
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaptive_pool(pool_type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adaptive_pool_+3A_pool_type">pool_type</code></td>
<td>
<p>pooling type</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonee
</p>

<hr>
<h2 id='AdaptiveAvgPool'>AdaptiveAvgPool</h2><span id='topic+AdaptiveAvgPool'></span>

<h3>Description</h3>

<p>nn()$AdaptiveAvgPool layer for 'ndim'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdaptiveAvgPool(sz = 1, ndim = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AdaptiveAvgPool_+3A_sz">sz</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="AdaptiveAvgPool_+3A_ndim">ndim</code></td>
<td>
<p>dimension size</p>
</td></tr>
</table>

<hr>
<h2 id='AdaptiveConcatPool1d'>AdaptiveConcatPool1d</h2><span id='topic+AdaptiveConcatPool1d'></span>

<h3>Description</h3>

<p>Layer that concats 'AdaptiveAvgPool1d' and 'AdaptiveMaxPool1d'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdaptiveConcatPool1d(size = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AdaptiveConcatPool1d_+3A_size">size</code></td>
<td>
<p>output size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AdaptiveConcatPool2d'>AdaptiveConcatPool2d</h2><span id='topic+AdaptiveConcatPool2d'></span>

<h3>Description</h3>

<p>Layer that concats 'AdaptiveAvgPool2d' and 'AdaptiveMaxPool2d'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdaptiveConcatPool2d(size = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AdaptiveConcatPool2d_+3A_size">size</code></td>
<td>
<p>output size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AdaptiveGANSwitcher'>Adaptive GAN Switcher</h2><span id='topic+AdaptiveGANSwitcher'></span>

<h3>Description</h3>

<p>Switcher that goes back to generator/critic when the loss goes below 'gen_thresh'/'crit_thresh'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdaptiveGANSwitcher(gen_thresh = NULL, critic_thresh = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AdaptiveGANSwitcher_+3A_gen_thresh">gen_thresh</code></td>
<td>
<p>generator threshold</p>
</td></tr>
<tr><td><code id="AdaptiveGANSwitcher_+3A_critic_thresh">critic_thresh</code></td>
<td>
<p>discriminator threshold</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AdaptiveLoss'>AdaptiveLoss</h2><span id='topic+AdaptiveLoss'></span>

<h3>Description</h3>

<p>Expand the 'target' to match the 'output' size before applying 'crit'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdaptiveLoss(crit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AdaptiveLoss_+3A_crit">crit</code></td>
<td>
<p>critic</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='add'>Add</h2><span id='topic+add'></span><span id='topic++2B.torch.Tensor'></span><span id='topic+sinh.torch.Tensor'></span>

<h3>Description</h3>

<p>Add
</p>
<p>Sinh
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a + b

## S3 method for class 'torch.Tensor'
sinh(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="add_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="add_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>
<p>tensor
</p>

<hr>
<h2 id='add_cyclic_datepart'>Add cyclic datepart</h2><span id='topic+add_cyclic_datepart'></span>

<h3>Description</h3>

<p>Helper function that adds trigonometric date/time features to a date in the column 'field_name' of 'df'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_cyclic_datepart(
  df,
  field_name,
  prefix = NULL,
  drop = TRUE,
  time = FALSE,
  add_linear = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_cyclic_datepart_+3A_df">df</code></td>
<td>
<p>df</p>
</td></tr>
<tr><td><code id="add_cyclic_datepart_+3A_field_name">field_name</code></td>
<td>
<p>field_name</p>
</td></tr>
<tr><td><code id="add_cyclic_datepart_+3A_prefix">prefix</code></td>
<td>
<p>prefix</p>
</td></tr>
<tr><td><code id="add_cyclic_datepart_+3A_drop">drop</code></td>
<td>
<p>drop</p>
</td></tr>
<tr><td><code id="add_cyclic_datepart_+3A_time">time</code></td>
<td>
<p>time</p>
</td></tr>
<tr><td><code id="add_cyclic_datepart_+3A_add_linear">add_linear</code></td>
<td>
<p>add_linear</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='add_datepart'>Add datepart</h2><span id='topic+add_datepart'></span>

<h3>Description</h3>

<p>Helper function that adds columns relevant to a date in the column 'field_name' of 'df'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_datepart(df, field_name, prefix = NULL, drop = TRUE, time = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_datepart_+3A_df">df</code></td>
<td>
<p>df</p>
</td></tr>
<tr><td><code id="add_datepart_+3A_field_name">field_name</code></td>
<td>
<p>field_name</p>
</td></tr>
<tr><td><code id="add_datepart_+3A_prefix">prefix</code></td>
<td>
<p>prefix</p>
</td></tr>
<tr><td><code id="add_datepart_+3A_drop">drop</code></td>
<td>
<p>drop</p>
</td></tr>
<tr><td><code id="add_datepart_+3A_time">time</code></td>
<td>
<p>time</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='AddChannels'>Add Channels</h2><span id='topic+AddChannels'></span>

<h3>Description</h3>

<p>Add 'n_dim' channels at the end of the input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AddChannels(n_dim)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AddChannels_+3A_n_dim">n_dim</code></td>
<td>
<p>number of dimensions</p>
</td></tr>
</table>

<hr>
<h2 id='AddNoise'>Add Noise</h2><span id='topic+AddNoise'></span>

<h3>Description</h3>

<p>Adds noise of specified color and level to the audio signal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AddNoise(noise_level = 0.05, color = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AddNoise_+3A_noise_level">noise_level</code></td>
<td>
<p>noise level</p>
</td></tr>
<tr><td><code id="AddNoise_+3A_color">color</code></td>
<td>
<p>int, color</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='affine_coord'>Aaffine_coord</h2><span id='topic+affine_coord'></span>

<h3>Description</h3>

<p>Aaffine_coord
</p>


<h3>Usage</h3>

<pre><code class='language-R'>affine_coord(
  x,
  mat = NULL,
  coord_tfm = NULL,
  sz = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  align_corners = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="affine_coord_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="affine_coord_+3A_mat">mat</code></td>
<td>
<p>mat</p>
</td></tr>
<tr><td><code id="affine_coord_+3A_coord_tfm">coord_tfm</code></td>
<td>
<p>coordinate tfm</p>
</td></tr>
<tr><td><code id="affine_coord_+3A_sz">sz</code></td>
<td>
<p>sz</p>
</td></tr>
<tr><td><code id="affine_coord_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="affine_coord_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="affine_coord_+3A_align_corners">align_corners</code></td>
<td>
<p>align corners</p>
</td></tr>
<tr><td><code id="affine_coord_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='affine_mat'>Affline mat</h2><span id='topic+affine_mat'></span>

<h3>Description</h3>

<p>Affline mat
</p>


<h3>Usage</h3>

<pre><code class='language-R'>affine_mat(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="affine_mat_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AffineCoordTfm'>AffineCoordTfm</h2><span id='topic+AffineCoordTfm'></span>

<h3>Description</h3>

<p>Combine and apply affine and coord transforms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AffineCoordTfm(
  aff_fs = NULL,
  coord_fs = NULL,
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  mode_mask = "nearest",
  align_corners = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AffineCoordTfm_+3A_aff_fs">aff_fs</code></td>
<td>
<p>aff fs</p>
</td></tr>
<tr><td><code id="AffineCoordTfm_+3A_coord_fs">coord_fs</code></td>
<td>
<p>coordinate fs</p>
</td></tr>
<tr><td><code id="AffineCoordTfm_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="AffineCoordTfm_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="AffineCoordTfm_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="AffineCoordTfm_+3A_mode_mask">mode_mask</code></td>
<td>
<p>mode mask</p>
</td></tr>
<tr><td><code id="AffineCoordTfm_+3A_align_corners">align_corners</code></td>
<td>
<p>align corners</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='alexnet'>Alexnet</h2><span id='topic+alexnet'></span>

<h3>Description</h3>

<p>AlexNet model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alexnet(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alexnet_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="alexnet_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;One weird trick...&quot; &lt;https://arxiv.org/abs/1404.5997&gt;
</p>


<h3>Value</h3>

<p>model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

alexnet(pretrained = FALSE, progress = TRUE)


## End(Not run)

</code></pre>

<hr>
<h2 id='apply_perspective'>Apply_perspective</h2><span id='topic+apply_perspective'></span>

<h3>Description</h3>

<p>Apply perspective tranfom on 'coords' with 'coeffs'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply_perspective(coords, coeffs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apply_perspective_+3A_coords">coords</code></td>
<td>
<p>coordinates</p>
</td></tr>
<tr><td><code id="apply_perspective_+3A_coeffs">coeffs</code></td>
<td>
<p>coefficient</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='APScoreBinary'>APScoreBinary</h2><span id='topic+APScoreBinary'></span>

<h3>Description</h3>

<p>Average Precision for single-label binary classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>APScoreBinary(
  axis = -1,
  average = "macro",
  pos_label = 1,
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APScoreBinary_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="APScoreBinary_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="APScoreBinary_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="APScoreBinary_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='APScoreMulti'>APScoreMulti</h2><span id='topic+APScoreMulti'></span>

<h3>Description</h3>

<p>Average Precision for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>APScoreMulti(
  sigmoid = TRUE,
  average = "macro",
  pos_label = 1,
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APScoreMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="APScoreMulti_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="APScoreMulti_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="APScoreMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='as_array'>As_array</h2><span id='topic+as_array'></span>

<h3>Description</h3>

<p>As_array
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_array(tensor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_array_+3A_tensor">tensor</code></td>
<td>
<p>tensor object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>array
</p>

<hr>
<h2 id='aspect'>Aspect</h2><span id='topic+aspect'></span>

<h3>Description</h3>

<p>Aspect
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aspect(img)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aspect_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='audio_extensions'>Audio_extensions</h2><span id='topic+audio_extensions'></span>

<h3>Description</h3>

<p>get all allowed audio extensions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audio_extensions()
</code></pre>


<h3>Value</h3>

<p>vector
</p>

<hr>
<h2 id='AudioBlock'>AudioBlock</h2><span id='topic+AudioBlock'></span>

<h3>Description</h3>

<p>A 'TransformBlock' for audios
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioBlock(
  cache_folder = NULL,
  sample_rate = 16000,
  force_mono = TRUE,
  crop_signal_to = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AudioBlock_+3A_cache_folder">cache_folder</code></td>
<td>
<p>cache folder</p>
</td></tr>
<tr><td><code id="AudioBlock_+3A_sample_rate">sample_rate</code></td>
<td>
<p>sample rate</p>
</td></tr>
<tr><td><code id="AudioBlock_+3A_force_mono">force_mono</code></td>
<td>
<p>force mono or not</p>
</td></tr>
<tr><td><code id="AudioBlock_+3A_crop_signal_to">crop_signal_to</code></td>
<td>
<p>int, crop signal</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AudioBlock_from_folder'>AudioBlock from folder</h2><span id='topic+AudioBlock_from_folder'></span>

<h3>Description</h3>

<p>Build a 'AudioBlock' from a 'path' and caches some intermediary results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioBlock_from_folder(
  path,
  sample_rate = 16000,
  force_mono = TRUE,
  crop_signal_to = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AudioBlock_from_folder_+3A_path">path</code></td>
<td>
<p>directory, path</p>
</td></tr>
<tr><td><code id="AudioBlock_from_folder_+3A_sample_rate">sample_rate</code></td>
<td>
<p>sample rate</p>
</td></tr>
<tr><td><code id="AudioBlock_from_folder_+3A_force_mono">force_mono</code></td>
<td>
<p>force mono or not</p>
</td></tr>
<tr><td><code id="AudioBlock_from_folder_+3A_crop_signal_to">crop_signal_to</code></td>
<td>
<p>int, crop signal</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AudioGetter'>AudioGetter</h2><span id='topic+AudioGetter'></span>

<h3>Description</h3>

<p>Create 'get_audio_files' partial function that searches path suffix 'suf'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioGetter(suf = "", recurse = TRUE, folders = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AudioGetter_+3A_suf">suf</code></td>
<td>
<p>suffix</p>
</td></tr>
<tr><td><code id="AudioGetter_+3A_recurse">recurse</code></td>
<td>
<p>recursive or not</p>
</td></tr>
<tr><td><code id="AudioGetter_+3A_folders">folders</code></td>
<td>
<p>vector, folders</p>
</td></tr>
</table>


<h3>Details</h3>

<p>and passes along 'kwargs', only in 'folders', if specified.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AudioPadType'>AudioPadType module</h2><span id='topic+AudioPadType'></span>

<h3>Description</h3>

<p>AudioPadType module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioPadType()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AudioSpectrogram'>AudioSpectrogram module</h2><span id='topic+AudioSpectrogram'></span>

<h3>Description</h3>

<p>AudioSpectrogram module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioSpectrogram()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AudioTensor'>Audio Tensor</h2><span id='topic+AudioTensor'></span>

<h3>Description</h3>

<p>Semantic torch tensor that represents an audio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioTensor(x, sr = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AudioTensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="AudioTensor_+3A_sr">sr</code></td>
<td>
<p>sr</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='AudioTensor_create'>AudioTensor create</h2><span id='topic+AudioTensor_create'></span>

<h3>Description</h3>

<p>Creates audio tensor from file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioTensor_create(
  fn,
  cache_folder = NULL,
  frame_offset = 0,
  num_frames = -1,
  normalize = TRUE,
  channels_first = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AudioTensor_create_+3A_fn">fn</code></td>
<td>
<p>function</p>
</td></tr>
<tr><td><code id="AudioTensor_create_+3A_cache_folder">cache_folder</code></td>
<td>
<p>cache folder</p>
</td></tr>
<tr><td><code id="AudioTensor_create_+3A_frame_offset">frame_offset</code></td>
<td>
<p>offset</p>
</td></tr>
<tr><td><code id="AudioTensor_create_+3A_num_frames">num_frames</code></td>
<td>
<p>number of frames</p>
</td></tr>
<tr><td><code id="AudioTensor_create_+3A_normalize">normalize</code></td>
<td>
<p>apply normalization or not</p>
</td></tr>
<tr><td><code id="AudioTensor_create_+3A_channels_first">channels_first</code></td>
<td>
<p>channels first/last</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AudioToMFCC'>AudioToMFCC</h2><span id='topic+AudioToMFCC'></span>

<h3>Description</h3>

<p>Transform to create MFCC features from audio tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioToMFCC(
  sample_rate = 16000,
  n_mfcc = 40,
  dct_type = 2,
  norm = "ortho",
  log_mels = FALSE,
  melkwargs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AudioToMFCC_+3A_sample_rate">sample_rate</code></td>
<td>
<p>sample rate</p>
</td></tr>
<tr><td><code id="AudioToMFCC_+3A_n_mfcc">n_mfcc</code></td>
<td>
<p>number of mel-frequency cepstral coefficients</p>
</td></tr>
<tr><td><code id="AudioToMFCC_+3A_dct_type">dct_type</code></td>
<td>
<p>dct type</p>
</td></tr>
<tr><td><code id="AudioToMFCC_+3A_norm">norm</code></td>
<td>
<p>normalization type</p>
</td></tr>
<tr><td><code id="AudioToMFCC_+3A_log_mels">log_mels</code></td>
<td>
<p>apply log to mels</p>
</td></tr>
<tr><td><code id="AudioToMFCC_+3A_melkwargs">melkwargs</code></td>
<td>
<p>additional arguments for mels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AudioToMFCC_from_cfg'>AudioToMFCC from cfg</h2><span id='topic+AudioToMFCC_from_cfg'></span>

<h3>Description</h3>

<p>Creates AudioToMFCC from configuration file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioToMFCC_from_cfg(audio_cfg)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AudioToMFCC_from_cfg_+3A_audio_cfg">audio_cfg</code></td>
<td>
<p>audio configuration</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AudioToSpec_from_cfg'>AudioToSpec from cfg</h2><span id='topic+AudioToSpec_from_cfg'></span>

<h3>Description</h3>

<p>Creates AudioToSpec from configuration file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AudioToSpec_from_cfg(audio_cfg)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AudioToSpec_from_cfg_+3A_audio_cfg">audio_cfg</code></td>
<td>
<p>audio configuration</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='aug_transforms'>Augmentation</h2><span id='topic+aug_transforms'></span>

<h3>Description</h3>

<p>Utility func to easily create a list of flip, rotate, zoom, warp, lighting transforms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aug_transforms(
  mult = 1,
  do_flip = TRUE,
  flip_vert = FALSE,
  max_rotate = 10,
  min_zoom = 1,
  max_zoom = 1.1,
  max_lighting = 0.2,
  max_warp = 0.2,
  p_affine = 0.75,
  p_lighting = 0.75,
  xtra_tfms = NULL,
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  align_corners = TRUE,
  batch = FALSE,
  min_scale = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aug_transforms_+3A_mult">mult</code></td>
<td>
<p>ratio</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_do_flip">do_flip</code></td>
<td>
<p>to do flip</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_flip_vert">flip_vert</code></td>
<td>
<p>flip vertical or not</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_max_rotate">max_rotate</code></td>
<td>
<p>maximum rotation</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_min_zoom">min_zoom</code></td>
<td>
<p>minimum zoom</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_max_zoom">max_zoom</code></td>
<td>
<p>maximum zoom</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_max_lighting">max_lighting</code></td>
<td>
<p>maximum lighting</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_max_warp">max_warp</code></td>
<td>
<p>maximum warp</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_p_affine">p_affine</code></td>
<td>
<p>probability affine</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_p_lighting">p_lighting</code></td>
<td>
<p>probability lighting</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_xtra_tfms">xtra_tfms</code></td>
<td>
<p>extra transformations</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_size">size</code></td>
<td>
<p>size of image</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_align_corners">align_corners</code></td>
<td>
<p>align_corners</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_batch">batch</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="aug_transforms_+3A_min_scale">min_scale</code></td>
<td>
<p>minimum scale</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_PETS()

path = 'oxford-iiit-pet'

path_img = 'oxford-iiit-pet/images'
fnames = get_image_files(path_img)

dls = ImageDataLoaders_from_name_re(
path, fnames, pat='(.+)_.jpg$',
item_tfms=Resize(size = 460), bs = 10,
batch_tfms=list(aug_transforms(size = 224, min_scale = 0.75),
                Normalize_from_stats( imagenet_stats() )
)
)


## End(Not run)

</code></pre>

<hr>
<h2 id='AutoConfig'>Auto configuration</h2><span id='topic+AutoConfig'></span>

<h3>Description</h3>

<p>Auto configuration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AutoConfig()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='average_grad'>Average_grad</h2><span id='topic+average_grad'></span>

<h3>Description</h3>

<p>Keeps track of the avg grads of 'p' in 'state' with 'mom'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>average_grad(p, mom, dampening = FALSE, grad_avg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="average_grad_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="average_grad_+3A_mom">mom</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="average_grad_+3A_dampening">dampening</code></td>
<td>
<p>dampening</p>
</td></tr>
<tr><td><code id="average_grad_+3A_grad_avg">grad_avg</code></td>
<td>
<p>grad average</p>
</td></tr>
<tr><td><code id="average_grad_+3A_...">...</code></td>
<td>
<p>additional args to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='average_sqr_grad'>Average_sqr_grad</h2><span id='topic+average_sqr_grad'></span>

<h3>Description</h3>

<p>Average_sqr_grad
</p>


<h3>Usage</h3>

<pre><code class='language-R'>average_sqr_grad(p, sqr_mom, dampening = TRUE, sqr_avg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="average_sqr_grad_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="average_sqr_grad_+3A_sqr_mom">sqr_mom</code></td>
<td>
<p>sqr momentum</p>
</td></tr>
<tr><td><code id="average_sqr_grad_+3A_dampening">dampening</code></td>
<td>
<p>dampening</p>
</td></tr>
<tr><td><code id="average_sqr_grad_+3A_sqr_avg">sqr_avg</code></td>
<td>
<p>sqr average</p>
</td></tr>
<tr><td><code id="average_sqr_grad_+3A_...">...</code></td>
<td>
<p>additional args to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AvgLoss'>AvgLoss</h2><span id='topic+AvgLoss'></span>

<h3>Description</h3>

<p>Flattens input and output, same as nn$AvgLoss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AvgLoss(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AvgLoss_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='AvgPool'>AvgPool</h2><span id='topic+AvgPool'></span>

<h3>Description</h3>

<p>nn$AvgPool layer for 'ndim'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AvgPool(ks = 2, stride = NULL, padding = 0, ndim = 2, ceil_mode = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AvgPool_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="AvgPool_+3A_stride">stride</code></td>
<td>
<p>the stride of the window. Default value is kernel_size</p>
</td></tr>
<tr><td><code id="AvgPool_+3A_padding">padding</code></td>
<td>
<p>implicit zero padding to be added on both sides</p>
</td></tr>
<tr><td><code id="AvgPool_+3A_ndim">ndim</code></td>
<td>
<p>dimension number</p>
</td></tr>
<tr><td><code id="AvgPool_+3A_ceil_mode">ceil_mode</code></td>
<td>
<p>when True, will use ceil instead of floor to compute the output shape</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AvgSmoothLoss'>AvgSmoothLoss</h2><span id='topic+AvgSmoothLoss'></span>

<h3>Description</h3>

<p>Smooth average of the losses (exponentially weighted with 'beta')
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AvgSmoothLoss(beta = 0.98)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AvgSmoothLoss_+3A_beta">beta</code></td>
<td>
<p>beta, defaults to 0.98</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='AWD_LSTM'>AWD_LSTM</h2><span id='topic+AWD_LSTM'></span>

<h3>Description</h3>

<p>AWD-LSTM inspired by https://arxiv.org/abs/1708.02182
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AWD_LSTM(
  vocab_sz,
  emb_sz,
  n_hid,
  n_layers,
  pad_token = 1,
  hidden_p = 0.2,
  input_p = 0.6,
  embed_p = 0.1,
  weight_p = 0.5,
  bidir = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AWD_LSTM_+3A_vocab_sz">vocab_sz</code></td>
<td>
<p>vocab_sz</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_emb_sz">emb_sz</code></td>
<td>
<p>emb_sz</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_n_hid">n_hid</code></td>
<td>
<p>n_hid</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_n_layers">n_layers</code></td>
<td>
<p>n_layers</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_pad_token">pad_token</code></td>
<td>
<p>pad_token</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_hidden_p">hidden_p</code></td>
<td>
<p>hidden_p</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_input_p">input_p</code></td>
<td>
<p>input_p</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_embed_p">embed_p</code></td>
<td>
<p>embed_p</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_weight_p">weight_p</code></td>
<td>
<p>weight_p</p>
</td></tr>
<tr><td><code id="AWD_LSTM_+3A_bidir">bidir</code></td>
<td>
<p>bidir</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='awd_lstm_clas_split'>Awd_lstm_clas_split</h2><span id='topic+awd_lstm_clas_split'></span>

<h3>Description</h3>

<p>Split a RNN 'model' in groups for differential learning rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>awd_lstm_clas_split(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="awd_lstm_clas_split_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='awd_lstm_lm_split'>Awd_lstm_lm_split</h2><span id='topic+awd_lstm_lm_split'></span>

<h3>Description</h3>

<p>Split a RNN 'model' in groups for differential learning rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>awd_lstm_lm_split(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="awd_lstm_lm_split_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='AWD_QRNN'>AWD_QRNN</h2><span id='topic+AWD_QRNN'></span>

<h3>Description</h3>

<p>Same as an AWD-LSTM, but using QRNNs instead of LSTMs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AWD_QRNN(
  vocab_sz,
  emb_sz,
  n_hid,
  n_layers,
  pad_token = 1,
  hidden_p = 0.2,
  input_p = 0.6,
  embed_p = 0.1,
  weight_p = 0.5,
  bidir = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AWD_QRNN_+3A_vocab_sz">vocab_sz</code></td>
<td>
<p>vocab_sz</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_emb_sz">emb_sz</code></td>
<td>
<p>emb_sz</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_n_hid">n_hid</code></td>
<td>
<p>n_hid</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_n_layers">n_layers</code></td>
<td>
<p>n_layers</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_pad_token">pad_token</code></td>
<td>
<p>pad_token</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_hidden_p">hidden_p</code></td>
<td>
<p>hidden_p</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_input_p">input_p</code></td>
<td>
<p>input_p</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_embed_p">embed_p</code></td>
<td>
<p>embed_p</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_weight_p">weight_p</code></td>
<td>
<p>weight_p</p>
</td></tr>
<tr><td><code id="AWD_QRNN_+3A_bidir">bidir</code></td>
<td>
<p>bidir</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BalancedAccuracy'>BalancedAccuracy</h2><span id='topic+BalancedAccuracy'></span>

<h3>Description</h3>

<p>Balanced Accuracy for single-label binary classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BalancedAccuracy(axis = -1, sample_weight = NULL, adjusted = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BalancedAccuracy_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="BalancedAccuracy_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
<tr><td><code id="BalancedAccuracy_+3A_adjusted">adjusted</code></td>
<td>
<p>adjusted</p>
</td></tr>
</table>


<h3>References</h3>

<p>None
</p>

<hr>
<h2 id='BaseLoss'>BaseLoss</h2><span id='topic+BaseLoss'></span>

<h3>Description</h3>

<p>Flattens input and output, same as nn$BaseLoss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BaseLoss(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BaseLoss_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='BaseTokenizer'>BaseTokenizer</h2><span id='topic+BaseTokenizer'></span>

<h3>Description</h3>

<p>Basic tokenizer that just splits on spaces
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BaseTokenizer(split_char = " ")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BaseTokenizer_+3A_split_char">split_char</code></td>
<td>
<p>separator</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='basic_critic'>Basic critic</h2><span id='topic+basic_critic'></span>

<h3>Description</h3>

<p>A basic critic for images 'n_channels' x 'in_size' x 'in_size'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basic_critic(in_size, n_channels, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="basic_critic_+3A_in_size">in_size</code></td>
<td>
<p>input size</p>
</td></tr>
<tr><td><code id="basic_critic_+3A_n_channels">n_channels</code></td>
<td>
<p>The number of channels</p>
</td></tr>
<tr><td><code id="basic_critic_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

critic    = basic_critic(in_size = 64, n_channels = 3, n_extra_layers = 1,
                        act_cls = partial(nn()$LeakyReLU, negative_slope = 0.2))


## End(Not run)

</code></pre>

<hr>
<h2 id='basic_generator'>Basic generator</h2><span id='topic+basic_generator'></span>

<h3>Description</h3>

<p>A basic generator from 'in_sz' to images 'n_channels' x 'out_size' x 'out_size'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basic_generator(out_size, n_channels, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="basic_generator_+3A_out_size">out_size</code></td>
<td>
<p>out_size</p>
</td></tr>
<tr><td><code id="basic_generator_+3A_n_channels">n_channels</code></td>
<td>
<p>n_channels</p>
</td></tr>
<tr><td><code id="basic_generator_+3A_...">...</code></td>
<td>
<p>additional params to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>generator object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

generator = basic_generator(out_size = 64, n_channels = 3, n_extra_layers = 1)


## End(Not run)

</code></pre>

<hr>
<h2 id='BasicMelSpectrogram'>BasicMelSpectrogram</h2><span id='topic+BasicMelSpectrogram'></span>

<h3>Description</h3>

<p>BasicMelSpectrogram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BasicMelSpectrogram(
  sample_rate = 16000,
  n_fft = 400,
  win_length = NULL,
  hop_length = NULL,
  f_min = 0,
  f_max = NULL,
  pad = 0,
  n_mels = 128,
  window_fn = torch()$hann_window,
  power = 2,
  normalized = FALSE,
  wkwargs = NULL,
  mel = TRUE,
  to_db = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BasicMelSpectrogram_+3A_sample_rate">sample_rate</code></td>
<td>
<p>sample rate</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_n_fft">n_fft</code></td>
<td>
<p>number of fast fourier transforms</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_win_length">win_length</code></td>
<td>
<p>windowing length</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_hop_length">hop_length</code></td>
<td>
<p>hopping length</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_f_min">f_min</code></td>
<td>
<p>minimum frequency</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_f_max">f_max</code></td>
<td>
<p>maximum frequency</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_pad">pad</code></td>
<td>
<p>padding</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_n_mels">n_mels</code></td>
<td>
<p>number of mel-spectrograms</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_window_fn">window_fn</code></td>
<td>
<p>window function</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_power">power</code></td>
<td>
<p>power</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_normalized">normalized</code></td>
<td>
<p>normalized or not</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_wkwargs">wkwargs</code></td>
<td>
<p>additional arguments</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_mel">mel</code></td>
<td>
<p>mel-spectrogram or not</p>
</td></tr>
<tr><td><code id="BasicMelSpectrogram_+3A_to_db">to_db</code></td>
<td>
<p>to decibels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BasicMFCC'>Basic MFCC</h2><span id='topic+BasicMFCC'></span>

<h3>Description</h3>

<p>Basic MFCC
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BasicMFCC(
  sample_rate = 16000,
  n_mfcc = 40,
  dct_type = 2,
  norm = "ortho",
  log_mels = FALSE,
  melkwargs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BasicMFCC_+3A_sample_rate">sample_rate</code></td>
<td>
<p>sample rate</p>
</td></tr>
<tr><td><code id="BasicMFCC_+3A_n_mfcc">n_mfcc</code></td>
<td>
<p>number of mel-frequency cepstral coefficients</p>
</td></tr>
<tr><td><code id="BasicMFCC_+3A_dct_type">dct_type</code></td>
<td>
<p>dct type</p>
</td></tr>
<tr><td><code id="BasicMFCC_+3A_norm">norm</code></td>
<td>
<p>normalization type</p>
</td></tr>
<tr><td><code id="BasicMFCC_+3A_log_mels">log_mels</code></td>
<td>
<p>apply log to mels</p>
</td></tr>
<tr><td><code id="BasicMFCC_+3A_melkwargs">melkwargs</code></td>
<td>
<p>additional arguments for mels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BasicSpectrogram'>BasicSpectrogram</h2><span id='topic+BasicSpectrogram'></span>

<h3>Description</h3>

<p>BasicSpectrogram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BasicSpectrogram(
  n_fft = 400,
  win_length = NULL,
  hop_length = NULL,
  pad = 0,
  window_fn = torch()$hann_window,
  power = 2,
  normalized = FALSE,
  wkwargs = NULL,
  mel = FALSE,
  to_db = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BasicSpectrogram_+3A_n_fft">n_fft</code></td>
<td>
<p>number of fast fourier transforms</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_win_length">win_length</code></td>
<td>
<p>windowing length</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_hop_length">hop_length</code></td>
<td>
<p>hopping length</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_pad">pad</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_window_fn">window_fn</code></td>
<td>
<p>window function</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_power">power</code></td>
<td>
<p>power</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_normalized">normalized</code></td>
<td>
<p>normalized or not</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_wkwargs">wkwargs</code></td>
<td>
<p>additional arguments</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_mel">mel</code></td>
<td>
<p>mel-spectrogram or not</p>
</td></tr>
<tr><td><code id="BasicSpectrogram_+3A_to_db">to_db</code></td>
<td>
<p>to decibels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BatchNorm'>BatchNorm</h2><span id='topic+BatchNorm'></span>

<h3>Description</h3>

<p>BatchNorm layer with 'nf' features and 'ndim' initialized depending on 'norm_type'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BatchNorm(
  nf,
  ndim = 2,
  norm_type = 1,
  eps = 1e-05,
  momentum = 0.1,
  affine = TRUE,
  track_running_stats = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BatchNorm_+3A_nf">nf</code></td>
<td>
<p>input shape</p>
</td></tr>
<tr><td><code id="BatchNorm_+3A_ndim">ndim</code></td>
<td>
<p>dimension number</p>
</td></tr>
<tr><td><code id="BatchNorm_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
<tr><td><code id="BatchNorm_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="BatchNorm_+3A_momentum">momentum</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="BatchNorm_+3A_affine">affine</code></td>
<td>
<p>affine</p>
</td></tr>
<tr><td><code id="BatchNorm_+3A_track_running_stats">track_running_stats</code></td>
<td>
<p>track running statistics</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BatchNorm1dFlat'>BatchNorm1dFlat</h2><span id='topic+BatchNorm1dFlat'></span>

<h3>Description</h3>

<p>'nn.BatchNorm1d', but first flattens leading dimensions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BatchNorm1dFlat(
  num_features,
  eps = 1e-05,
  momentum = 0.1,
  affine = TRUE,
  track_running_stats = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BatchNorm1dFlat_+3A_num_features">num_features</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="BatchNorm1dFlat_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="BatchNorm1dFlat_+3A_momentum">momentum</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="BatchNorm1dFlat_+3A_affine">affine</code></td>
<td>
<p>affine</p>
</td></tr>
<tr><td><code id="BatchNorm1dFlat_+3A_track_running_stats">track_running_stats</code></td>
<td>
<p>track running statistics</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='bb_pad'>Bb_pad</h2><span id='topic+bb_pad'></span>

<h3>Description</h3>

<p>Function that collect 'samples' of labelled bboxes and adds padding with 'pad_idx'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bb_pad(samples, pad_idx = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bb_pad_+3A_samples">samples</code></td>
<td>
<p>samples</p>
</td></tr>
<tr><td><code id="bb_pad_+3A_pad_idx">pad_idx</code></td>
<td>
<p>pad index</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BBoxBlock'>BBoxBlock</h2><span id='topic+BBoxBlock'></span>

<h3>Description</h3>

<p>A 'TransformBlock' for bounding boxes in an image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BBoxBlock()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BBoxLabeler'>BBoxLabeler</h2><span id='topic+BBoxLabeler'></span>

<h3>Description</h3>

<p>Delegates ('__call__','decode','setup') to ('encodes','decodes','setups') if 'split_idx' matches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BBoxLabeler(enc = NULL, dec = NULL, split_idx = NULL, order = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BBoxLabeler_+3A_enc">enc</code></td>
<td>
<p>encoder</p>
</td></tr>
<tr><td><code id="BBoxLabeler_+3A_dec">dec</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="BBoxLabeler_+3A_split_idx">split_idx</code></td>
<td>
<p>split by index</p>
</td></tr>
<tr><td><code id="BBoxLabeler_+3A_order">order</code></td>
<td>
<p>order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BBoxLblBlock'>BBoxLblBlock</h2><span id='topic+BBoxLblBlock'></span>

<h3>Description</h3>

<p>A 'TransformBlock' for labeled bounding boxes, potentially with 'vocab'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BBoxLblBlock(vocab = NULL, add_na = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BBoxLblBlock_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="BBoxLblBlock_+3A_add_na">add_na</code></td>
<td>
<p>add NA</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_COCO_TINY()

c(images, lbl_bbox) %&lt;-% get_annotations('coco_tiny/train.json')
timg = Transform(ImageBW_create)
idx = 49
c(coco_fn,bbox) %&lt;-% list(paste('coco_tiny/train',images[[idx]],sep = '/'),
                          lbl_bbox[[idx]])
coco_img = timg(coco_fn)

tbbox = LabeledBBox(TensorBBox(bbox[[1]]), bbox[[2]])

coco_bb = function(x) {
TensorBBox_create(bbox[[1]])
}

coco_lbl = function(x) {
  bbox[[2]]
}

coco_dsrc = Datasets(c(rep(coco_fn,10)),
                     list(Image_create(), list(coco_bb),
                          list( coco_lbl, MultiCategorize(add_na = TRUE) )
                     ), n_inp = 1)

coco_tdl = TfmdDL(coco_dsrc, bs = 9,
                  after_item = list(BBoxLabeler(), PointScaler(),
                                    ToTensor()),
                  after_batch = list(IntToFloatTensor(), aug_transforms())
)

coco_tdl %&gt;% show_batch(dpi = 200)


## End(Not run)

</code></pre>

<hr>
<h2 id='BCELossFlat'>BCELossFlat</h2><span id='topic+BCELossFlat'></span>

<h3>Description</h3>

<p>Flattens input and output, same as nn$BCELoss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BCELossFlat(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BCELossFlat_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='BCEWithLogitsLossFlat'>BCEWithLogitsLossFlat</h2><span id='topic+BCEWithLogitsLossFlat'></span>

<h3>Description</h3>

<p>BCEWithLogitsLossFlat
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BCEWithLogitsLossFlat(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BCEWithLogitsLossFlat_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='blurr'>Hugging Face module</h2><span id='topic+blurr'></span>

<h3>Description</h3>

<p>Hugging Face module
</p>
<p>Blurr module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blurr()

blurr()
</code></pre>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>

<hr>
<h2 id='BrierScore'>BrierScore</h2><span id='topic+BrierScore'></span>

<h3>Description</h3>

<p>Brier score for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BrierScore(axis = -1, sample_weight = NULL, pos_label = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BrierScore_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="BrierScore_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
<tr><td><code id="BrierScore_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='BrierScoreMulti'>BrierScoreMulti</h2><span id='topic+BrierScoreMulti'></span>

<h3>Description</h3>

<p>Brier score for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BrierScoreMulti(
  thresh = 0.5,
  sigmoid = TRUE,
  sample_weight = NULL,
  pos_label = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BrierScoreMulti_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="BrierScoreMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="BrierScoreMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
<tr><td><code id="BrierScoreMulti_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='bs_find'>Bs_find</h2><span id='topic+bs_find'></span>

<h3>Description</h3>

<p>Launch a mock training to find a good batch size to minimize training time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bs_find(
  object,
  lr,
  num_it = NULL,
  n_batch = 5,
  simulate_multi_gpus = TRUE,
  show_plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bs_find_+3A_object">object</code></td>
<td>
<p>model/learner</p>
</td></tr>
<tr><td><code id="bs_find_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="bs_find_+3A_num_it">num_it</code></td>
<td>
<p>number of iterations</p>
</td></tr>
<tr><td><code id="bs_find_+3A_n_batch">n_batch</code></td>
<td>
<p>number of batches</p>
</td></tr>
<tr><td><code id="bs_find_+3A_simulate_multi_gpus">simulate_multi_gpus</code></td>
<td>
<p>simulate on multi gpus or not</p>
</td></tr>
<tr><td><code id="bs_find_+3A_show_plot">show_plot</code></td>
<td>
<p>show plot or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>However, it may not be a good batch size to minimize the validation loss. A good batch size is where the Simple Noise Scale converge ignoring the small growing trend with the number of iterations if exists. The optimal batch size is about an order the magnitud
where Simple Noise scale converge. Typically, the optimal batch size in image classification problems will be 2-3 times lower where
</p>

<hr>
<h2 id='bs_finder'>Bs finder</h2><span id='topic+bs_finder'></span>

<h3>Description</h3>

<p>Bs finder
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bs_finder()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='bt'>Builtins module</h2><span id='topic+bt'></span>

<h3>Description</h3>

<p>Builtins module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bt()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='calculate_rouge'>Calculate_rouge</h2><span id='topic+calculate_rouge'></span>

<h3>Description</h3>

<p>Calculate_rouge
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate_rouge(
  predicted_txts,
  reference_txts,
  rouge_keys = c("rouge1", "rouge2", "rougeL"),
  use_stemmer = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate_rouge_+3A_predicted_txts">predicted_txts</code></td>
<td>
<p>predicted texts</p>
</td></tr>
<tr><td><code id="calculate_rouge_+3A_reference_txts">reference_txts</code></td>
<td>
<p>reference texts</p>
</td></tr>
<tr><td><code id="calculate_rouge_+3A_rouge_keys">rouge_keys</code></td>
<td>
<p>rouge keys</p>
</td></tr>
<tr><td><code id="calculate_rouge_+3A_use_stemmer">use_stemmer</code></td>
<td>
<p>use stemmer or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Callback'>Callback module</h2><span id='topic+Callback'></span>

<h3>Description</h3>

<p>Callback module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Callback()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Cat'>Cat</h2><span id='topic+Cat'></span>

<h3>Description</h3>

<p>Concatenate layers outputs over a given dim
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cat(layers, dim = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cat_+3A_layers">layers</code></td>
<td>
<p>layers</p>
</td></tr>
<tr><td><code id="Cat_+3A_dim">dim</code></td>
<td>
<p>dimension size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='catalyst'>Catalyst module</h2><span id='topic+catalyst'></span>

<h3>Description</h3>

<p>Catalyst module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catalyst()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='catalyst_model'>Catalyst model</h2><span id='topic+catalyst_model'></span>

<h3>Description</h3>

<p>Catalyst model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catalyst_model()
</code></pre>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='Categorify'>Categorify</h2><span id='topic+Categorify'></span>

<h3>Description</h3>

<p>Transform the categorical variables to that type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Categorify(cat_names, cont_names)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Categorify_+3A_cat_names">cat_names</code></td>
<td>
<p>The names of the categorical variables</p>
</td></tr>
<tr><td><code id="Categorify_+3A_cont_names">cont_names</code></td>
<td>
<p>The names of the continuous variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CategoryBlock'>CategoryBlock</h2><span id='topic+CategoryBlock'></span>

<h3>Description</h3>

<p>'TransformBlock' for single-label categorical targets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CategoryBlock(vocab = NULL, sort = TRUE, add_na = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CategoryBlock_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="CategoryBlock_+3A_sort">sort</code></td>
<td>
<p>sort or not</p>
</td></tr>
<tr><td><code id="CategoryBlock_+3A_add_na">add_na</code></td>
<td>
<p>add NA</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block object
</p>

<hr>
<h2 id='ceiling_'>Ceil</h2><span id='topic+ceiling_'></span><span id='topic+ceiling.torch.Tensor'></span>

<h3>Description</h3>

<p>Ceil
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
ceiling(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ceiling__+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='ceiling.fastai.torch_core.TensorMask'>Ceil</h2><span id='topic+ceiling.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Ceil
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
ceiling(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ceiling.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='ChangeVolume'>Change Volume</h2><span id='topic+ChangeVolume'></span>

<h3>Description</h3>

<p>Changes the volume of the signal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ChangeVolume(p = 0.5, lower = 0.5, upper = 1.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ChangeVolume_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="ChangeVolume_+3A_lower">lower</code></td>
<td>
<p>lower bound</p>
</td></tr>
<tr><td><code id="ChangeVolume_+3A_upper">upper</code></td>
<td>
<p>upper bound</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='children_and_parameters'>Children_and_parameters</h2><span id='topic+children_and_parameters'></span>

<h3>Description</h3>

<p>Return the children of 'm' and its direct parameters not registered in modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>children_and_parameters(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="children_and_parameters_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ClassificationInterpretation_from_learner'>ClassificationInterpretation_from_learner</h2><span id='topic+ClassificationInterpretation_from_learner'></span>

<h3>Description</h3>

<p>Construct interpretation object from a learner
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ClassificationInterpretation_from_learner(
  learn,
  ds_idx = 1,
  dl = NULL,
  act = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ClassificationInterpretation_from_learner_+3A_learn">learn</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="ClassificationInterpretation_from_learner_+3A_ds_idx">ds_idx</code></td>
<td>
<p>ds by index</p>
</td></tr>
<tr><td><code id="ClassificationInterpretation_from_learner_+3A_dl">dl</code></td>
<td>
<p>dataloader</p>
</td></tr>
<tr><td><code id="ClassificationInterpretation_from_learner_+3A_act">act</code></td>
<td>
<p>activation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>interpretation object
</p>

<hr>
<h2 id='clean_raw_keys'>Clean_raw_keys</h2><span id='topic+clean_raw_keys'></span>

<h3>Description</h3>

<p>Clean_raw_keys
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_raw_keys(wgts)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_raw_keys_+3A_wgts">wgts</code></td>
<td>
<p>wgts</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='clip_remove_empty'>Clip_remove_empty</h2><span id='topic+clip_remove_empty'></span>

<h3>Description</h3>

<p>Clip bounding boxes with image border and label background the empty ones
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clip_remove_empty(bbox, label)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clip_remove_empty_+3A_bbox">bbox</code></td>
<td>
<p>bbox</p>
</td></tr>
<tr><td><code id="clip_remove_empty_+3A_label">label</code></td>
<td>
<p>label</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='cm'>Cm module</h2><span id='topic+cm'></span>

<h3>Description</h3>

<p>Cm module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='cnn_config'>Cnn config</h2><span id='topic+cnn_config'></span>

<h3>Description</h3>

<p>Convenience function to easily create a config for 'create_cnn_model'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnn_config(
  cut = NULL,
  pretrained = TRUE,
  n_in = 3,
  init = nn()$init$kaiming_normal_,
  custom_head = NULL,
  concat_pool = TRUE,
  lin_ftrs = NULL,
  ps = 0.5,
  bn_final = FALSE,
  lin_first = FALSE,
  y_range = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cnn_config_+3A_cut">cut</code></td>
<td>
<p>cut</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_pretrained">pretrained</code></td>
<td>
<p>pre-trained or not</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_n_in">n_in</code></td>
<td>
<p>input shape</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_custom_head">custom_head</code></td>
<td>
<p>custom head</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_concat_pool">concat_pool</code></td>
<td>
<p>concatenate pooling</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_lin_ftrs">lin_ftrs</code></td>
<td>
<p>linear filters</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_ps">ps</code></td>
<td>
<p>parameter server</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_bn_final">bn_final</code></td>
<td>
<p>batch normalization final</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_lin_first">lin_first</code></td>
<td>
<p>linear first</p>
</td></tr>
<tr><td><code id="cnn_config_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='cnn_learner'>Cnn_learner</h2><span id='topic+cnn_learner'></span>

<h3>Description</h3>

<p>Build a convnet style learner from 'dls' and 'arch'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnn_learner(
  dls,
  arch,
  loss_func = NULL,
  pretrained = TRUE,
  cut = NULL,
  splitter = NULL,
  y_range = NULL,
  config = NULL,
  n_out = NULL,
  normalize = TRUE,
  opt_func = Adam(),
  lr = 0.001,
  cbs = NULL,
  metrics = NULL,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE,
  moms = list(0.95, 0.85, 0.95)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cnn_learner_+3A_dls">dls</code></td>
<td>
<p>data loader object</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_arch">arch</code></td>
<td>
<p>a model architecture</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_loss_func">loss_func</code></td>
<td>
<p>loss function</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_pretrained">pretrained</code></td>
<td>
<p>pre-trained or not</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_cut">cut</code></td>
<td>
<p>cut</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_splitter">splitter</code></td>
<td>
<p>It is a function that takes self.model and returns a list of parameter groups (or just one parameter group if there are no different parameter groups).</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_config">config</code></td>
<td>
<p>configuration</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_n_out">n_out</code></td>
<td>
<p>the number of out</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_normalize">normalize</code></td>
<td>
<p>normalize</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_opt_func">opt_func</code></td>
<td>
<p>The function used to create the optimizer</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_cbs">cbs</code></td>
<td>
<p>Cbs is one or a list of Callbacks to pass to the Learner.</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_metrics">metrics</code></td>
<td>
<p>It is an optional list of metrics, that can be either functions or Metrics.</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_model_dir">model_dir</code></td>
<td>
<p>Path and model_dir are used to save and/or load models.</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_wd">wd</code></td>
<td>
<p>It is the default weight decay used when training the model.</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>It controls if weight decay is applied to BatchNorm layers and bias.</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_train_bn">train_bn</code></td>
<td>
<p>It controls if BatchNorm layers are trained even when they are supposed to be frozen according to the splitter.</p>
</td></tr>
<tr><td><code id="cnn_learner_+3A_moms">moms</code></td>
<td>
<p>The default momentums used in Learner.fit_one_cycle.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>learner object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_MNIST_SAMPLE()
# transformations
tfms = aug_transforms(do_flip = FALSE)
path = 'mnist_sample'
bs = 20

#load into memory
data = ImageDataLoaders_from_folder(path, batch_tfms = tfms, size = 26, bs = bs)


learn = cnn_learner(data, resnet18(), metrics = accuracy, path = getwd())


## End(Not run)

</code></pre>

<hr>
<h2 id='COCOMetric'>COCOMetric</h2><span id='topic+COCOMetric'></span>

<h3>Description</h3>

<p>Wrapper around [cocoapi evaluator](https://github.com/cocodataset/cocoapi)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>COCOMetric(
  metric_type = COCOMetricType()$bbox,
  print_summary = FALSE,
  show_pbar = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="COCOMetric_+3A_metric_type">metric_type</code></td>
<td>
<p>Dependent on the task you're solving.</p>
</td></tr>
<tr><td><code id="COCOMetric_+3A_print_summary">print_summary</code></td>
<td>
<p>If 'TRUE', prints a table with statistics.</p>
</td></tr>
<tr><td><code id="COCOMetric_+3A_show_pbar">show_pbar</code></td>
<td>
<p>If 'TRUE' shows pbar when preparing the data for evaluation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates average precision. # Arguments metric_type: Dependent on the task you're solving. print_summary: If 'TRUE', prints a table with statistics. show_pbar: If 'TRUE' shows pbar when preparing the data for evaluation.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='COCOMetricType'>COCOMetricType</h2><span id='topic+COCOMetricType'></span>

<h3>Description</h3>

<p>Available options for 'COCOMetric'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>COCOMetricType()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CohenKappa'>CohenKappa</h2><span id='topic+CohenKappa'></span>

<h3>Description</h3>

<p>Cohen kappa for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CohenKappa(axis = -1, labels = NULL, weights = NULL, sample_weight = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CohenKappa_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="CohenKappa_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="CohenKappa_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="CohenKappa_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='collab'>Collab module</h2><span id='topic+collab'></span>

<h3>Description</h3>

<p>Collab module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collab()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='collab_learner'>Collab_learner</h2><span id='topic+collab_learner'></span>

<h3>Description</h3>

<p>Create a Learner for collaborative filtering on 'dls'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collab_learner(
  dls,
  n_factors = 50,
  use_nn = FALSE,
  emb_szs = NULL,
  layers = NULL,
  config = NULL,
  y_range = NULL,
  loss_func = NULL,
  opt_func = Adam(),
  lr = 0.001,
  splitter = trainable_params(),
  cbs = NULL,
  metrics = NULL,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE,
  moms = list(0.95, 0.85, 0.95)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collab_learner_+3A_dls">dls</code></td>
<td>
<p>a data loader object</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_n_factors">n_factors</code></td>
<td>
<p>The number of factors</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_use_nn">use_nn</code></td>
<td>
<p>use_nn</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_emb_szs">emb_szs</code></td>
<td>
<p>embedding size</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_layers">layers</code></td>
<td>
<p>list of layers</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_config">config</code></td>
<td>
<p>configuration</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_loss_func">loss_func</code></td>
<td>
<p>It can be any loss function you like. It needs to be one of fastai's if you want to use Learn.predict or Learn.get_preds, or you will have to implement special methods (see more details after the BaseLoss documentation).</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_opt_func">opt_func</code></td>
<td>
<p>The function used to create the optimizer</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_splitter">splitter</code></td>
<td>
<p>It is a function that takes self.model and returns a list of parameter groups (or just one parameter group if there are no different parameter groups).</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_cbs">cbs</code></td>
<td>
<p>Cbs is one or a list of Callbacks to pass to the Learner.</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_metrics">metrics</code></td>
<td>
<p>It is an optional list of metrics, that can be either functions or Metrics.</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_model_dir">model_dir</code></td>
<td>
<p>Path and model_dir are used to save and/or load models.</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_wd">wd</code></td>
<td>
<p>It is the default weight decay used when training the model.</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>It controls if weight decay is applied to BatchNorm layers and bias.</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_train_bn">train_bn</code></td>
<td>
<p>It controls if BatchNorm layers are trained even when they are supposed to be frozen according to the splitter.</p>
</td></tr>
<tr><td><code id="collab_learner_+3A_moms">moms</code></td>
<td>
<p>The default momentums used in Learner.fit_one_cycle.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>learner object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_MOVIE_LENS_ML_100k()
c(user,item,title)  %&lt;-% list('userId','movieId','title')
ratings = fread('ml-100k/u.data', col.names = c(user,item,'rating','timestamp'))
movies = fread('ml-100k/u.item', col.names = c(item, 'title', 'date', 'N', 'url',
                                               paste('g',1:19,sep = '')))
rating_movie = ratings[movies[, .SD, .SDcols=c(item,title)], on = item]
dls = CollabDataLoaders_from_df(rating_movie, seed = 42, valid_pct = 0.1, bs = 64,
item_name=title, path='ml-100k')

learn = collab_learner(dls, n_factors = 40, y_range=c(0, 5.5))

learn %&gt;% fit_one_cycle(1, 5e-3,  wd = 1e-1)


## End(Not run)

</code></pre>

<hr>
<h2 id='CollabDataLoaders_from_dblock'>CollabDataLoaders_from_dblock</h2><span id='topic+CollabDataLoaders_from_dblock'></span>

<h3>Description</h3>

<p>Create a dataloaders from a given 'dblock'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CollabDataLoaders_from_dblock(
  dblock,
  source,
  path = ".",
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CollabDataLoaders_from_dblock_+3A_dblock">dblock</code></td>
<td>
<p>dblock</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_dblock_+3A_source">source</code></td>
<td>
<p>source</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_dblock_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_dblock_+3A_bs">bs</code></td>
<td>
<p>The batch size</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_dblock_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_dblock_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_dblock_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CollabDataLoaders_from_df'>CollabDataLoaders_from_df</h2><span id='topic+CollabDataLoaders_from_df'></span>

<h3>Description</h3>

<p>Create a 'DataLoaders' suitable for collaborative filtering from 'ratings'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CollabDataLoaders_from_df(
  ratings,
  valid_pct = 0.2,
  user_name = NULL,
  item_name = NULL,
  rating_name = NULL,
  seed = NULL,
  path = ".",
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CollabDataLoaders_from_df_+3A_ratings">ratings</code></td>
<td>
<p>ratings</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_valid_pct">valid_pct</code></td>
<td>
<p>The random percentage of the dataset to set aside for validation (with an optional seed)</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_user_name">user_name</code></td>
<td>
<p>The name of the column containing the user (defaults to the first column)</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_item_name">item_name</code></td>
<td>
<p>The name of the column containing the item (defaults to the second column)</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_rating_name">rating_name</code></td>
<td>
<p>The name of the column containing the rating (defaults to the third column)</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_bs">bs</code></td>
<td>
<p>The batch size</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="CollabDataLoaders_from_df_+3A_device">device</code></td>
<td>
<p>the device, e.g. cpu, cuda, and etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_MOVIE_LENS_ML_100k()
c(user,item,title)  %&lt;-% list('userId','movieId','title')
ratings = fread('ml-100k/u.data', col.names = c(user,item,'rating','timestamp'))
movies = fread('ml-100k/u.item', col.names = c(item, 'title', 'date', 'N', 'url',
                                               paste('g',1:19,sep = '')))
rating_movie = ratings[movies[, .SD, .SDcols=c(item,title)], on = item]
dls = CollabDataLoaders_from_df(rating_movie, seed = 42, valid_pct = 0.1, bs = 64,
item_name=title, path='ml-100k')


## End(Not run)


</code></pre>

<hr>
<h2 id='CollectDataCallback'>CollectDataCallback</h2><span id='topic+CollectDataCallback'></span>

<h3>Description</h3>

<p>Collect all batches, along with pred and loss, into self.data. Mainly for testing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CollectDataCallback(...)

CollectDataCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CollectDataCallback_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>

<hr>
<h2 id='colors'>Colors module</h2><span id='topic+colors'></span>

<h3>Description</h3>

<p>Colors module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colors()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ColReader'>ColReader</h2><span id='topic+ColReader'></span>

<h3>Description</h3>

<p>Read 'cols' in 'row' with potential 'pref' and 'suff'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColReader(cols, pref = "", suff = "", label_delim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColReader_+3A_cols">cols</code></td>
<td>
<p>columns</p>
</td></tr>
<tr><td><code id="ColReader_+3A_pref">pref</code></td>
<td>
<p>pref</p>
</td></tr>
<tr><td><code id="ColReader_+3A_suff">suff</code></td>
<td>
<p>suffix</p>
</td></tr>
<tr><td><code id="ColReader_+3A_label_delim">label_delim</code></td>
<td>
<p>label separator</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ColSplitter'>ColSplitter</h2><span id='topic+ColSplitter'></span>

<h3>Description</h3>

<p>Split 'items' (supposed to be a dataframe) by value in 'col'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColSplitter(col = "is_valid")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColSplitter_+3A_col">col</code></td>
<td>
<p>column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='combined_flat_anneal'>Combined_flat_anneal</h2><span id='topic+combined_flat_anneal'></span>

<h3>Description</h3>

<p>Create a schedule with constant learning rate 'start_lr' for 'pct'
proportion of the training, and a 'curve_type' learning rate (till 'end_lr') for
remaining portion of training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combined_flat_anneal(pct, start_lr, end_lr = 0, curve_type = "linear")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combined_flat_anneal_+3A_pct">pct</code></td>
<td>
<p>Proportion of training with a constant learning rate.</p>
</td></tr>
<tr><td><code id="combined_flat_anneal_+3A_start_lr">start_lr</code></td>
<td>
<p>Desired starting learning rate, used for beginnning pct of training.</p>
</td></tr>
<tr><td><code id="combined_flat_anneal_+3A_end_lr">end_lr</code></td>
<td>
<p>Desired end learning rate, training will conclude at this learning rate.</p>
</td></tr>
<tr><td><code id="combined_flat_anneal_+3A_curve_type">curve_type</code></td>
<td>
<p>Curve type for learning rate annealing. Options are 'linear', 'cosine', and 'exponential'.</p>
</td></tr>
</table>

<hr>
<h2 id='competition_download_file'>Competition download file</h2><span id='topic+competition_download_file'></span>

<h3>Description</h3>

<p>download a competition file to a designated location, or use
</p>


<h3>Usage</h3>

<pre><code class='language-R'>competition_download_file(
  competition,
  file_name,
  path = NULL,
  force = FALSE,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="competition_download_file_+3A_competition">competition</code></td>
<td>
<p>the name of the competition</p>
</td></tr>
<tr><td><code id="competition_download_file_+3A_file_name">file_name</code></td>
<td>
<p>the configuration file name</p>
</td></tr>
<tr><td><code id="competition_download_file_+3A_path">path</code></td>
<td>
<p>a path to download the file to</p>
</td></tr>
<tr><td><code id="competition_download_file_+3A_force">force</code></td>
<td>
<p>force the download if the file already exists (default FALSE)</p>
</td></tr>
<tr><td><code id="competition_download_file_+3A_quiet">quiet</code></td>
<td>
<p>suppress verbose output (default is FALSE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

com_nm = 'titanic'

titanic_files = competition_list_files(com_nm)
titanic_files = lapply(1:length(titanic_files),
                      function(x) as.character(titanic_files[[x]]))

str(titanic_files)

if(!dir.exists(com_nm)) {
 dir.create(com_nm)
}

# download via api
competition_download_files(competition = com_nm, path = com_nm, unzip = TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='competition_download_files'>Competition download files</h2><span id='topic+competition_download_files'></span>

<h3>Description</h3>

<p>Competition download files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>competition_download_files(
  competition,
  path = NULL,
  force = FALSE,
  quiet = FALSE,
  unzip = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="competition_download_files_+3A_competition">competition</code></td>
<td>
<p>the name of the competition</p>
</td></tr>
<tr><td><code id="competition_download_files_+3A_path">path</code></td>
<td>
<p>a path to download the file to</p>
</td></tr>
<tr><td><code id="competition_download_files_+3A_force">force</code></td>
<td>
<p>force the download if the file already exists (default FALSE)</p>
</td></tr>
<tr><td><code id="competition_download_files_+3A_quiet">quiet</code></td>
<td>
<p>suppress verbose output (default is TRUE)</p>
</td></tr>
<tr><td><code id="competition_download_files_+3A_unzip">unzip</code></td>
<td>
<p>unzip downloaded files</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='competition_leaderboard_download'>Competition leaderboard download</h2><span id='topic+competition_leaderboard_download'></span>

<h3>Description</h3>

<p>Download competition leaderboards
</p>


<h3>Usage</h3>

<pre><code class='language-R'>competition_leaderboard_download(competition, path, quiet = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="competition_leaderboard_download_+3A_competition">competition</code></td>
<td>
<p>the name of the competition</p>
</td></tr>
<tr><td><code id="competition_leaderboard_download_+3A_path">path</code></td>
<td>
<p>a path to download the file to</p>
</td></tr>
<tr><td><code id="competition_leaderboard_download_+3A_quiet">quiet</code></td>
<td>
<p>suppress verbose output (default is TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='competition_list_files'>Competition list files</h2><span id='topic+competition_list_files'></span>

<h3>Description</h3>

<p>list files for competition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>competition_list_files(competition)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="competition_list_files_+3A_competition">competition</code></td>
<td>
<p>the name of the competition</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of files
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

com_nm = 'titanic'
titanic_files = competition_list_files(com_nm)



## End(Not run)
</code></pre>

<hr>
<h2 id='competition_submit'>Competition submit</h2><span id='topic+competition_submit'></span>

<h3>Description</h3>

<p>Competition submit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>competition_submit(file_name, message, competition, quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="competition_submit_+3A_file_name">file_name</code></td>
<td>
<p>the competition metadata file</p>
</td></tr>
<tr><td><code id="competition_submit_+3A_message">message</code></td>
<td>
<p>the submission description</p>
</td></tr>
<tr><td><code id="competition_submit_+3A_competition">competition</code></td>
<td>
<p>the competition name</p>
</td></tr>
<tr><td><code id="competition_submit_+3A_quiet">quiet</code></td>
<td>
<p>suppress verbose output (default is FALSE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='competitions_list'>Competitions list</h2><span id='topic+competitions_list'></span>

<h3>Description</h3>

<p>Competitions list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>competitions_list(
  group = NULL,
  category = NULL,
  sort_by = NULL,
  page = 1,
  search = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="competitions_list_+3A_group">group</code></td>
<td>
<p>group to filter result to</p>
</td></tr>
<tr><td><code id="competitions_list_+3A_category">category</code></td>
<td>
<p>category to filter result to</p>
</td></tr>
<tr><td><code id="competitions_list_+3A_sort_by">sort_by</code></td>
<td>
<p>how to sort the result, see valid_competition_sort_by for options</p>
</td></tr>
<tr><td><code id="competitions_list_+3A_page">page</code></td>
<td>
<p>the page to return (default is 1)</p>
</td></tr>
<tr><td><code id="competitions_list_+3A_search">search</code></td>
<td>
<p>a search term to use (default is empty string)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of competitions
</p>

<hr>
<h2 id='Contrast'>Contrast</h2><span id='topic+Contrast'></span>

<h3>Description</h3>

<p>Apply change in contrast of 'max_lighting' to batch of images with probability 'p'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Contrast(max_lighting = 0.2, p = 0.75, draw = NULL, batch = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contrast_+3A_max_lighting">max_lighting</code></td>
<td>
<p>maximum lighting</p>
</td></tr>
<tr><td><code id="Contrast_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="Contrast_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="Contrast_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='conv_norm_lr'>Conv_norm_lr</h2><span id='topic+conv_norm_lr'></span>

<h3>Description</h3>

<p>Conv_norm_lr
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conv_norm_lr(
  ch_in,
  ch_out,
  norm_layer = NULL,
  ks = 3,
  bias = TRUE,
  pad = 1,
  stride = 1,
  activ = TRUE,
  slope = 0.2,
  init = nn()$init$normal_,
  init_gain = 0.02
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conv_norm_lr_+3A_ch_in">ch_in</code></td>
<td>
<p>input</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_ch_out">ch_out</code></td>
<td>
<p>output</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_norm_layer">norm_layer</code></td>
<td>
<p>normalziation layer</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_bias">bias</code></td>
<td>
<p>bias</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_pad">pad</code></td>
<td>
<p>pad</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_stride">stride</code></td>
<td>
<p>stride</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_activ">activ</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_slope">slope</code></td>
<td>
<p>slope</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_init">init</code></td>
<td>
<p>inititializer</p>
</td></tr>
<tr><td><code id="conv_norm_lr_+3A_init_gain">init_gain</code></td>
<td>
<p>initializer gain</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ConvLayer'>ConvLayer</h2><span id='topic+ConvLayer'></span>

<h3>Description</h3>

<p>Create a sequence of convolutional ('ni' to 'nf'), ReLU (if 'use_activ') and 'norm_type' layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConvLayer(
  ni,
  nf,
  ks = 3,
  stride = 1,
  padding = NULL,
  bias = NULL,
  ndim = 2,
  norm_type = 1,
  bn_1st = TRUE,
  act_cls = nn()$ReLU,
  transpose = FALSE,
  init = "auto",
  xtra = NULL,
  bias_std = 0.01,
  dilation = 1,
  groups = 1,
  padding_mode = "zeros"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConvLayer_+3A_ni">ni</code></td>
<td>
<p>number of inputs</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_nf">nf</code></td>
<td>
<p>outputs/ number of features</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_stride">stride</code></td>
<td>
<p>stride</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_padding">padding</code></td>
<td>
<p>padding</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_bias">bias</code></td>
<td>
<p>bias</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_ndim">ndim</code></td>
<td>
<p>dimension number</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_bn_1st">bn_1st</code></td>
<td>
<p>batch normalization 1st</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_transpose">transpose</code></td>
<td>
<p>transpose</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_xtra">xtra</code></td>
<td>
<p>xtra</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_bias_std">bias_std</code></td>
<td>
<p>bias standard deviation</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_dilation">dilation</code></td>
<td>
<p>specify the dilation rate to use for dilated convolution</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_groups">groups</code></td>
<td>
<p>groups size</p>
</td></tr>
<tr><td><code id="ConvLayer_+3A_padding_mode">padding_mode</code></td>
<td>
<p>padding mode, e.g 'zeros'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='convT_norm_relu'>ConvT_norm_relu</h2><span id='topic+convT_norm_relu'></span>

<h3>Description</h3>

<p>ConvT_norm_relu
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convT_norm_relu(ch_in, ch_out, norm_layer, ks = 3, stride = 2, bias = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convT_norm_relu_+3A_ch_in">ch_in</code></td>
<td>
<p>input</p>
</td></tr>
<tr><td><code id="convT_norm_relu_+3A_ch_out">ch_out</code></td>
<td>
<p>output</p>
</td></tr>
<tr><td><code id="convT_norm_relu_+3A_norm_layer">norm_layer</code></td>
<td>
<p>normalziation layer</p>
</td></tr>
<tr><td><code id="convT_norm_relu_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="convT_norm_relu_+3A_stride">stride</code></td>
<td>
<p>stride size</p>
</td></tr>
<tr><td><code id="convT_norm_relu_+3A_bias">bias</code></td>
<td>
<p>bias true or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CorpusBLEUMetric'>CorpusBLEUMetric</h2><span id='topic+CorpusBLEUMetric'></span>

<h3>Description</h3>

<p>Blueprint for defining a metric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CorpusBLEUMetric(vocab_sz = 5000, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CorpusBLEUMetric_+3A_vocab_sz">vocab_sz</code></td>
<td>
<p>vocab_sz</p>
</td></tr>
<tr><td><code id="CorpusBLEUMetric_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='cos_'>Cos</h2><span id='topic+cos_'></span><span id='topic+cos.torch.Tensor'></span>

<h3>Description</h3>

<p>Cos
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
cos(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cos__+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='cos.fastai.torch_core.TensorMask'>Cos</h2><span id='topic+cos.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Cos
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
cos(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cos.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='cosh_'>Cosh</h2><span id='topic+cosh_'></span><span id='topic+cosh.torch.Tensor'></span>

<h3>Description</h3>

<p>Cosh
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
cosh(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cosh__+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='cosh.fastai.torch_core.TensorMask'>Cosh</h2><span id='topic+cosh.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Cosh
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
cosh(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cosh.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='crap'>Crappify module</h2><span id='topic+crap'></span>

<h3>Description</h3>

<p>Crappify module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crap()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='crappifier'>Crappifier</h2><span id='topic+crappifier'></span>

<h3>Description</h3>

<p>Crappifier
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crappifier(path_lr, path_hr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crappifier_+3A_path_lr">path_lr</code></td>
<td>
<p>path from (origin)</p>
</td></tr>
<tr><td><code id="crappifier_+3A_path_hr">path_hr</code></td>
<td>
<p>path to (destination)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

items = get_image_files(path_hr)
parallel(crappifier(path_lr, path_hr), items)


## End(Not run)

</code></pre>

<hr>
<h2 id='create_body'>Create_body</h2><span id='topic+create_body'></span>

<h3>Description</h3>

<p>Cut off the body of a typically pretrained 'arch' as determined by 'cut'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_body(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_body_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

encoder = create_body(resnet34(), pretrained = TRUE)


## End(Not run)

</code></pre>

<hr>
<h2 id='create_cnn_model'>Create_cnn_model</h2><span id='topic+create_cnn_model'></span>

<h3>Description</h3>

<p>Create custom convnet architecture using 'arch', 'n_in' and 'n_out'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_cnn_model(
  arch,
  n_out,
  cut = NULL,
  pretrained = TRUE,
  n_in = 3,
  init = nn()$init$kaiming_normal_,
  custom_head = NULL,
  concat_pool = TRUE,
  lin_ftrs = NULL,
  ps = 0.5,
  bn_final = FALSE,
  lin_first = FALSE,
  y_range = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_cnn_model_+3A_arch">arch</code></td>
<td>
<p>a model architecture</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_n_out">n_out</code></td>
<td>
<p>number of outs</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_cut">cut</code></td>
<td>
<p>cut</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained model or not</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_n_in">n_in</code></td>
<td>
<p>input shape</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_custom_head">custom_head</code></td>
<td>
<p>custom head</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_concat_pool">concat_pool</code></td>
<td>
<p>concatenate pooling</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_lin_ftrs">lin_ftrs</code></td>
<td>
<p>linear fiters</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_ps">ps</code></td>
<td>
<p>parameter server</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_bn_final">bn_final</code></td>
<td>
<p>batch normalization final</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_lin_first">lin_first</code></td>
<td>
<p>linear first</p>
</td></tr>
<tr><td><code id="create_cnn_model_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='create_fcn'>Create_fcn</h2><span id='topic+create_fcn'></span>

<h3>Description</h3>

<p>A bunch of convolutions stacked together.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_fcn(ni, nout, ks = 9, conv_sizes = c(128, 256, 128), stride = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_fcn_+3A_ni">ni</code></td>
<td>
<p>number of input channels</p>
</td></tr>
<tr><td><code id="create_fcn_+3A_nout">nout</code></td>
<td>
<p>output shape</p>
</td></tr>
<tr><td><code id="create_fcn_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="create_fcn_+3A_conv_sizes">conv_sizes</code></td>
<td>
<p>convolution sizes</p>
</td></tr>
<tr><td><code id="create_fcn_+3A_stride">stride</code></td>
<td>
<p>stride</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='create_head'>Create_head</h2><span id='topic+create_head'></span>

<h3>Description</h3>

<p>Model head that takes 'nf' features, runs through 'lin_ftrs', and out 'n_out' classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_head(
  nf,
  n_out,
  lin_ftrs = NULL,
  ps = 0.5,
  concat_pool = TRUE,
  bn_final = FALSE,
  lin_first = FALSE,
  y_range = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_head_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="create_head_+3A_n_out">n_out</code></td>
<td>
<p>number of out features</p>
</td></tr>
<tr><td><code id="create_head_+3A_lin_ftrs">lin_ftrs</code></td>
<td>
<p>linear features</p>
</td></tr>
<tr><td><code id="create_head_+3A_ps">ps</code></td>
<td>
<p>parameter server</p>
</td></tr>
<tr><td><code id="create_head_+3A_concat_pool">concat_pool</code></td>
<td>
<p>concatenate pooling</p>
</td></tr>
<tr><td><code id="create_head_+3A_bn_final">bn_final</code></td>
<td>
<p>batch normalization final</p>
</td></tr>
<tr><td><code id="create_head_+3A_lin_first">lin_first</code></td>
<td>
<p>linear first</p>
</td></tr>
<tr><td><code id="create_head_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='create_inception'>Create_inception</h2><span id='topic+create_inception'></span>

<h3>Description</h3>

<p>Creates an InceptionTime arch from 'ni' channels to 'nout' outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_inception(
  ni,
  nout,
  kss = c(39, 19, 9),
  depth = 6,
  bottleneck_size = 32,
  nb_filters = 32,
  head = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_inception_+3A_ni">ni</code></td>
<td>
<p>number of input channels</p>
</td></tr>
<tr><td><code id="create_inception_+3A_nout">nout</code></td>
<td>
<p>number of outputs, should be equal to the number of classes for classification tasks.</p>
</td></tr>
<tr><td><code id="create_inception_+3A_kss">kss</code></td>
<td>
<p>kernel sizes for the inception Block.</p>
</td></tr>
<tr><td><code id="create_inception_+3A_depth">depth</code></td>
<td>
<p>depth</p>
</td></tr>
<tr><td><code id="create_inception_+3A_bottleneck_size">bottleneck_size</code></td>
<td>
<p>The number of channels on the convolution bottleneck.</p>
</td></tr>
<tr><td><code id="create_inception_+3A_nb_filters">nb_filters</code></td>
<td>
<p>Channels on the convolution of each kernel.</p>
</td></tr>
<tr><td><code id="create_inception_+3A_head">head</code></td>
<td>
<p>TRUE if we want a head attached.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='create_mlp'>Create_mlp</h2><span id='topic+create_mlp'></span>

<h3>Description</h3>

<p>A simple model builder to create a bunch of BatchNorm1d, Dropout and
Linear layers, with &ldquo;'act_fn&ldquo;' activations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_mlp(ni, nout, linear_sizes = c(500, 500, 500))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_mlp_+3A_ni">ni</code></td>
<td>
<p>number of input channels</p>
</td></tr>
<tr><td><code id="create_mlp_+3A_nout">nout</code></td>
<td>
<p>output shape</p>
</td></tr>
<tr><td><code id="create_mlp_+3A_linear_sizes">linear_sizes</code></td>
<td>
<p>linear output sizes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='create_resnet'>Create_resnet</h2><span id='topic+create_resnet'></span>

<h3>Description</h3>

<p>Basic 11 Layer - 1D resnet builder
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_resnet(
  ni,
  nout,
  kss = c(9, 5, 3),
  conv_sizes = c(64, 128, 128),
  stride = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_resnet_+3A_ni">ni</code></td>
<td>
<p>number of input channels</p>
</td></tr>
<tr><td><code id="create_resnet_+3A_nout">nout</code></td>
<td>
<p>output shape</p>
</td></tr>
<tr><td><code id="create_resnet_+3A_kss">kss</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="create_resnet_+3A_conv_sizes">conv_sizes</code></td>
<td>
<p>convolution sizes</p>
</td></tr>
<tr><td><code id="create_resnet_+3A_stride">stride</code></td>
<td>
<p>stride</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='create_unet_model'>Create_unet_model</h2><span id='topic+create_unet_model'></span>

<h3>Description</h3>

<p>Create custom unet architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_unet_model(
  arch,
  n_out,
  img_size,
  pretrained = TRUE,
  cut = NULL,
  n_in = 3,
  blur = FALSE,
  blur_final = TRUE,
  self_attention = FALSE,
  y_range = NULL,
  last_cross = TRUE,
  bottle = FALSE,
  act_cls = nn()$ReLU,
  init = nn()$init$kaiming_normal_,
  norm_type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_unet_model_+3A_arch">arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_n_out">n_out</code></td>
<td>
<p>number of out features</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_img_size">img_size</code></td>
<td>
<p>imgage shape</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_cut">cut</code></td>
<td>
<p>cut</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_n_in">n_in</code></td>
<td>
<p>number of input</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_blur">blur</code></td>
<td>
<p>blur is used to avoid checkerboard artifacts at each layer.</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_blur_final">blur_final</code></td>
<td>
<p>blur final is specific to the last layer.</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_self_attention">self_attention</code></td>
<td>
<p>self_attention determines if we use a self attention layer at the third block before the end.</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_y_range">y_range</code></td>
<td>
<p>If y_range is passed, the last activations go through a sigmoid rescaled to that range.</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_last_cross">last_cross</code></td>
<td>
<p>last_cross</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_bottle">bottle</code></td>
<td>
<p>bottle</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_init">init</code></td>
<td>
<p>initialzier</p>
</td></tr>
<tr><td><code id="create_unet_model_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CropPad'>CropPad</h2><span id='topic+CropPad'></span>

<h3>Description</h3>

<p>Center crop or pad an image to 'size'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CropPad(size, pad_mode = "zeros", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CropPad_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="CropPad_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="CropPad_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CropTime'>Crop Time</h2><span id='topic+CropTime'></span>

<h3>Description</h3>

<p>Random crops full spectrogram to be length specified in ms by crop_duration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CropTime(duration, pad_mode = AudioPadType()$Zeros)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CropTime_+3A_duration">duration</code></td>
<td>
<p>int, duration</p>
</td></tr>
<tr><td><code id="CropTime_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode, by default 'AudioPadType$Zeros'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CrossEntropyLossFlat'>CrossEntropyLossFlat</h2><span id='topic+CrossEntropyLossFlat'></span>

<h3>Description</h3>

<p>Same as 'nn$Module', but no need for subclasses to call 'super().__init__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CrossEntropyLossFlat(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CrossEntropyLossFlat_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='CSVLogger'>CSVLogger</h2><span id='topic+CSVLogger'></span>

<h3>Description</h3>

<p>Basic class handling tweaks of the training loop by changing a 'Learner' in various events
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CSVLogger(fname = "history.csv", append = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CSVLogger_+3A_fname">fname</code></td>
<td>
<p>file name</p>
</td></tr>
<tr><td><code id="CSVLogger_+3A_append">append</code></td>
<td>
<p>append or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_MNIST_SAMPLE()
# transformations
tfms = aug_transforms(do_flip = FALSE)
path = 'mnist_sample'
bs = 20

#load into memory
data = ImageDataLoaders_from_folder(path, batch_tfms = tfms, size = 26, bs = bs)


learn = cnn_learner(data, resnet18(), metrics = accuracy, path = getwd())

learn %&gt;% fit_one_cycle(2, cbs = CSVLogger())


## End(Not run)

</code></pre>

<hr>
<h2 id='CudaCallback'>CudaCallback</h2><span id='topic+CudaCallback'></span>

<h3>Description</h3>

<p>Move data to CUDA device
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CudaCallback(device = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CudaCallback_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='custom_loss'>Loss NN module</h2><span id='topic+custom_loss'></span>

<h3>Description</h3>

<p>Loss NN module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>custom_loss()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CutMix'>CutMix</h2><span id='topic+CutMix'></span>

<h3>Description</h3>

<p>Implementation of 'https://arxiv.org/abs/1905.04899'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CutMix(alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CutMix_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='cutout_gaussian'>Cutout_gaussian</h2><span id='topic+cutout_gaussian'></span>

<h3>Description</h3>

<p>Replace all 'areas' in 'x' with N(0,1) noise
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutout_gaussian(x, areas)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cutout_gaussian_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="cutout_gaussian_+3A_areas">areas</code></td>
<td>
<p>areas</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='cycle_learner'>Cycle_learner</h2><span id='topic+cycle_learner'></span>

<h3>Description</h3>

<p>Initialize and return a 'Learner' object with the data in 'dls', CycleGAN model 'm', optimizer function 'opt_func', metrics 'metrics',
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cycle_learner(
  dls,
  m,
  opt_func = Adam(),
  show_imgs = TRUE,
  imgA = TRUE,
  imgB = TRUE,
  show_img_interval = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cycle_learner_+3A_dls">dls</code></td>
<td>
<p>dataloader</p>
</td></tr>
<tr><td><code id="cycle_learner_+3A_m">m</code></td>
<td>
<p>CycleGAN model</p>
</td></tr>
<tr><td><code id="cycle_learner_+3A_opt_func">opt_func</code></td>
<td>
<p>optimizer</p>
</td></tr>
<tr><td><code id="cycle_learner_+3A_show_imgs">show_imgs</code></td>
<td>
<p>show images</p>
</td></tr>
<tr><td><code id="cycle_learner_+3A_imga">imgA</code></td>
<td>
<p>image a (from)</p>
</td></tr>
<tr><td><code id="cycle_learner_+3A_imgb">imgB</code></td>
<td>
<p>image B (to)</p>
</td></tr>
<tr><td><code id="cycle_learner_+3A_show_img_interval">show_img_interval</code></td>
<td>
<p>show images interval rafe</p>
</td></tr>
<tr><td><code id="cycle_learner_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>and callbacks 'cbs'. Additionally, if 'show_imgs' is TRUE, it will show intermediate predictions during training. It will show domain
B-to-A predictions if 'imgA' is TRUE and/or domain A-to-B predictions if 'imgB' is TRUE. Additionally, it will show images every
'show_img_interval' epochs. ' Other 'Learner' arguments can be passed as well.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CycleGAN'>CycleGAN</h2><span id='topic+CycleGAN'></span>

<h3>Description</h3>

<p>CycleGAN model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CycleGAN(
  ch_in = 3,
  ch_out = 3,
  n_features = 64,
  disc_layers = 3,
  gen_blocks = 9,
  lsgan = TRUE,
  drop = 0,
  norm_layer = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CycleGAN_+3A_ch_in">ch_in</code></td>
<td>
<p>input</p>
</td></tr>
<tr><td><code id="CycleGAN_+3A_ch_out">ch_out</code></td>
<td>
<p>output</p>
</td></tr>
<tr><td><code id="CycleGAN_+3A_n_features">n_features</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="CycleGAN_+3A_disc_layers">disc_layers</code></td>
<td>
<p>discriminator layers</p>
</td></tr>
<tr><td><code id="CycleGAN_+3A_gen_blocks">gen_blocks</code></td>
<td>
<p>generator blocks</p>
</td></tr>
<tr><td><code id="CycleGAN_+3A_lsgan">lsgan</code></td>
<td>
<p>ls gan</p>
</td></tr>
<tr><td><code id="CycleGAN_+3A_drop">drop</code></td>
<td>
<p>dropout rate</p>
</td></tr>
<tr><td><code id="CycleGAN_+3A_norm_layer">norm_layer</code></td>
<td>
<p>normalziation layer</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators).
Also outputs identity images after passing the images into generators that outputs its domain type (needed for identity loss). Attributes: 'G_A' ('nn.Module'): takes real input B and generates fake input A 'G_B' ('nn.Module'): takes real input A and generates fake input B 'D_A' ('nn.Module'): trained to make the difference between real input A and fake input A 'D_B' ('nn.Module'): trained to make the difference between real input B and fake input B
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='CycleGANLoss'>CycleGANLoss</h2><span id='topic+CycleGANLoss'></span>

<h3>Description</h3>

<p>CycleGAN loss function. The individual loss terms are also atrributes
of this class that are accessed by fastai for recording during training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CycleGANLoss(cgan, l_A = 10, l_B = 10, l_idt = 0.5, lsgan = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CycleGANLoss_+3A_cgan">cgan</code></td>
<td>
<p>The CycleGAN model.</p>
</td></tr>
<tr><td><code id="CycleGANLoss_+3A_l_a">l_A</code></td>
<td>
<p>lambda_A, weight of domain A losses. (default=10)</p>
</td></tr>
<tr><td><code id="CycleGANLoss_+3A_l_b">l_B</code></td>
<td>
<p>lambda_B, weight of domain B losses. (default=10)</p>
</td></tr>
<tr><td><code id="CycleGANLoss_+3A_l_idt">l_idt</code></td>
<td>
<p>lambda_idt, weight of identity lossees. (default=0.5)</p>
</td></tr>
<tr><td><code id="CycleGANLoss_+3A_lsgan">lsgan</code></td>
<td>
<p>Whether or not to use LSGAN objective (default=True)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Attributes: 'self.cgan' ('nn.Module'): The CycleGAN model.
'self.l_A' ('float'): lambda_A, weight of domain A losses.
'self.l_B' ('float'): lambda_B, weight of domain B losses.
'self.l_idt' ('float'): lambda_idt, weight of identity lossees.
'self.crit' ('AdaptiveLoss'): The adversarial loss function
(either a BCE or MSE loss depending on 'lsgan' argument)
'self.real_A' and 'self.real_B' ('fastai.torch_core.TensorImage'): Real images from domain A and B.
'self.id_loss_A' ('torch.FloatTensor'): The identity loss for domain A calculated
in the forward function 'self.id_loss_B' ('torch.FloatTensor'): The identity loss for domain B calculated
in the forward function 'self.gen_loss' ('torch.FloatTensor'): The generator loss calculated
in the forward function 'self.cyc_loss' ('torch.FloatTensor'): The cyclic loss calculated
in the forward function
</p>

<hr>
<h2 id='CycleGANTrainer'>CycleGANTrainer</h2><span id='topic+CycleGANTrainer'></span>

<h3>Description</h3>

<p>Learner Callback for training a CycleGAN model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CycleGANTrainer(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CycleGANTrainer_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Data_Loaders'>Data Loaders</h2><span id='topic+Data_Loaders'></span>

<h3>Description</h3>

<p>Data Loaders
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Data_Loaders(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Data_Loaders_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>loader object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

data = Data_Loaders(train_loader, test_loader)

learn = Learner(data, Net(), loss_func = F$nll_loss,
                opt_func = Adam(), metrics = accuracy, cbs = CudaCallback())

learn %&gt;% fit_one_cycle(1, 1e-2)


## End(Not run)

</code></pre>

<hr>
<h2 id='DataBlock'>DataBlock</h2><span id='topic+DataBlock'></span>

<h3>Description</h3>

<p>Generic container to quickly build 'Datasets' and 'DataLoaders'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DataBlock(
  blocks = NULL,
  dl_type = NULL,
  getters = NULL,
  n_inp = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DataBlock_+3A_blocks">blocks</code></td>
<td>
<p>input blocks</p>
</td></tr>
<tr><td><code id="DataBlock_+3A_dl_type">dl_type</code></td>
<td>
<p>DL application</p>
</td></tr>
<tr><td><code id="DataBlock_+3A_getters">getters</code></td>
<td>
<p>how to get dataet</p>
</td></tr>
<tr><td><code id="DataBlock_+3A_n_inp">n_inp</code></td>
<td>
<p>n_inp is the number of elements in the tuples that should be considered part
of the input and will default to 1 if tfms consists of one set of transforms</p>
</td></tr>
<tr><td><code id="DataBlock_+3A_item_tfms">item_tfms</code></td>
<td>
<p>One or several transforms applied to the items before batching them</p>
</td></tr>
<tr><td><code id="DataBlock_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>One or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="DataBlock_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block object
</p>

<hr>
<h2 id='dataloaders'>Dataloaders from dls object</h2><span id='topic+dataloaders'></span>

<h3>Description</h3>

<p>Create a 'DataLoaders' object from 'source'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataloaders(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataloaders_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="dataloaders_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

dls = TabularDataTable(df, procs, cat_names, cont_names,
y_names = dep_var, splits = list(tr_idx, ts_idx) ) %&gt;%
  dataloaders(bs = 50)


## End(Not run)

</code></pre>

<hr>
<h2 id='Datasets'>Datasets</h2><span id='topic+Datasets'></span>

<h3>Description</h3>

<p>A dataset that creates a list from each 'tfms', passed thru 'item_tfms'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Datasets(
  items = NULL,
  tfms = NULL,
  tls = NULL,
  n_inp = NULL,
  dl_type = NULL,
  use_list = NULL,
  do_setup = TRUE,
  split_idx = NULL,
  train_setup = TRUE,
  splits = NULL,
  types = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Datasets_+3A_items">items</code></td>
<td>
<p>items</p>
</td></tr>
<tr><td><code id="Datasets_+3A_tfms">tfms</code></td>
<td>
<p>transformations</p>
</td></tr>
<tr><td><code id="Datasets_+3A_tls">tls</code></td>
<td>
<p>tls</p>
</td></tr>
<tr><td><code id="Datasets_+3A_n_inp">n_inp</code></td>
<td>
<p>n_inp</p>
</td></tr>
<tr><td><code id="Datasets_+3A_dl_type">dl_type</code></td>
<td>
<p>DL type</p>
</td></tr>
<tr><td><code id="Datasets_+3A_use_list">use_list</code></td>
<td>
<p>use list</p>
</td></tr>
<tr><td><code id="Datasets_+3A_do_setup">do_setup</code></td>
<td>
<p>do setup</p>
</td></tr>
<tr><td><code id="Datasets_+3A_split_idx">split_idx</code></td>
<td>
<p>split by index</p>
</td></tr>
<tr><td><code id="Datasets_+3A_train_setup">train_setup</code></td>
<td>
<p>train setup</p>
</td></tr>
<tr><td><code id="Datasets_+3A_splits">splits</code></td>
<td>
<p>splits</p>
</td></tr>
<tr><td><code id="Datasets_+3A_types">types</code></td>
<td>
<p>types</p>
</td></tr>
<tr><td><code id="Datasets_+3A_verbose">verbose</code></td>
<td>
<p>verbose</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='dcmread'>Read dicom</h2><span id='topic+dcmread'></span>

<h3>Description</h3>

<p>Open a 'DICOM' file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcmread(fn, force = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dcmread_+3A_fn">fn</code></td>
<td>
<p>file name</p>
</td></tr>
<tr><td><code id="dcmread_+3A_force">force</code></td>
<td>
<p>logical, force</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dicom object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

img = dcmread('hemorrhage.dcm')



## End(Not run)

</code></pre>

<hr>
<h2 id='debias'>Debias</h2><span id='topic+debias'></span>

<h3>Description</h3>

<p>Debias
</p>


<h3>Usage</h3>

<pre><code class='language-R'>debias(mom, damp, step)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="debias_+3A_mom">mom</code></td>
<td>
<p>mom</p>
</td></tr>
<tr><td><code id="debias_+3A_damp">damp</code></td>
<td>
<p>damp</p>
</td></tr>
<tr><td><code id="debias_+3A_step">step</code></td>
<td>
<p>step</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Debugger'>Debugger</h2><span id='topic+Debugger'></span>

<h3>Description</h3>

<p>A module to debug inside a model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Debugger(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Debugger_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='decision_plot'>Decision_plot</h2><span id='topic+decision_plot'></span>

<h3>Description</h3>

<p>Visualizes a model's decisions using cumulative SHAP values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decision_plot(object, class_id = 0, row_idx = -1, dpi = 200, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decision_plot_+3A_object">object</code></td>
<td>
<p>ShapInterpretation object</p>
</td></tr>
<tr><td><code id="decision_plot_+3A_class_id">class_id</code></td>
<td>
<p>is used to indicate the class of interest for a classification model.
It can either be an int or str representation for a class of choice. Each colored line in
the plot represents the model's prediction for a single observation.</p>
</td></tr>
<tr><td><code id="decision_plot_+3A_row_idx">row_idx</code></td>
<td>
<p>If no index is passed in to use from the data, it will default to the first ten samples
on the test set. Note:plotting too many samples at once can make the plot illegible.</p>
</td></tr>
<tr><td><code id="decision_plot_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
<tr><td><code id="decision_plot_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='decode_spec_tokens'>Decode_spec_tokens</h2><span id='topic+decode_spec_tokens'></span>

<h3>Description</h3>

<p>Decode the special tokens in 'tokens'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode_spec_tokens(tokens)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode_spec_tokens_+3A_tokens">tokens</code></td>
<td>
<p>tokens</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='default_split'>Default_split</h2><span id='topic+default_split'></span>

<h3>Description</h3>

<p>Default split of a model between body and head
</p>


<h3>Usage</h3>

<pre><code class='language-R'>default_split(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="default_split_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Delta'>Delta</h2><span id='topic+Delta'></span>

<h3>Description</h3>

<p>Creates delta with order 1 and 2 from spectrogram
and concatenate with the original
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Delta(width = 9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Delta_+3A_width">width</code></td>
<td>
<p>int, width</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='denormalize_imagenet'>Denormalize_imagenet</h2><span id='topic+denormalize_imagenet'></span>

<h3>Description</h3>

<p>Denormalize_imagenet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>denormalize_imagenet(img)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="denormalize_imagenet_+3A_img">img</code></td>
<td>
<p>img</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='densenet121'>Densenet121</h2><span id='topic+densenet121'></span>

<h3>Description</h3>

<p>Densenet121
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densenet121(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densenet121_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="densenet121_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Densely Connected Convolutional Networks&quot; &lt;https://arxiv.org/pdf/1608.06993.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='densenet161'>Densenet161</h2><span id='topic+densenet161'></span>

<h3>Description</h3>

<p>Densenet161
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densenet161(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densenet161_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="densenet161_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Densely Connected Convolutional Networks&quot; &lt;https://arxiv.org/pdf/1608.06993.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='densenet169'>Densenet169</h2><span id='topic+densenet169'></span>

<h3>Description</h3>

<p>Densenet169
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densenet169(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densenet169_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="densenet169_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Densely Connected Convolutional Networks&quot; &lt;https://arxiv.org/pdf/1608.06993.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='densenet201'>Densenet201</h2><span id='topic+densenet201'></span>

<h3>Description</h3>

<p>Densenet201
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densenet201(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densenet201_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="densenet201_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Densely Connected Convolutional Networks&quot; &lt;https://arxiv.org/pdf/1608.06993.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='DenseResBlock'>Dense Res Block</h2><span id='topic+DenseResBlock'></span>

<h3>Description</h3>

<p>Resnet block of 'nf' features. 'conv_kwargs' are passed to 'conv_layer'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DenseResBlock(
  nf,
  norm_type = 1,
  ks = 3,
  stride = 1,
  padding = NULL,
  bias = NULL,
  ndim = 2,
  bn_1st = TRUE,
  act_cls = nn()$ReLU,
  transpose = FALSE,
  init = "auto",
  xtra = NULL,
  bias_std = 0.01,
  dilation = 1,
  groups = 1,
  padding_mode = "zeros"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DenseResBlock_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_stride">stride</code></td>
<td>
<p>stride</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_padding">padding</code></td>
<td>
<p>padding</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_bias">bias</code></td>
<td>
<p>bias</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_ndim">ndim</code></td>
<td>
<p>number of dimensions</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_bn_1st">bn_1st</code></td>
<td>
<p>batch normalization 1st</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_transpose">transpose</code></td>
<td>
<p>transpose</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_init">init</code></td>
<td>
<p>initizalier</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_xtra">xtra</code></td>
<td>
<p>xtra</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_bias_std">bias_std</code></td>
<td>
<p>bias standard deviation</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_dilation">dilation</code></td>
<td>
<p>dilation number</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_groups">groups</code></td>
<td>
<p>groups number</p>
</td></tr>
<tr><td><code id="DenseResBlock_+3A_padding_mode">padding_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>block
</p>

<hr>
<h2 id='dependence_plot'>Dependence_plot</h2><span id='topic+dependence_plot'></span>

<h3>Description</h3>

<p>Plots the value of a variable on the x-axis and the SHAP value of the same
variable on the y-axis. Accepts a class_id and variable_name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dependence_plot(object, variable_name = "", class_id = 0, dpi = 200, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dependence_plot_+3A_object">object</code></td>
<td>
<p>ShapInterpretation object</p>
</td></tr>
<tr><td><code id="dependence_plot_+3A_variable_name">variable_name</code></td>
<td>
<p>the name of the column</p>
</td></tr>
<tr><td><code id="dependence_plot_+3A_class_id">class_id</code></td>
<td>
<p>is used to indicate the class of interest for a classification model.
It can either be an int or str representation for a class of choice. This plot shows how the
model depends on the given variable. Vertical dispersion of the datapoints represent
interaction effects. Gray ticks along the y-axis are datapoints where the variable's values were NaN.</p>
</td></tr>
<tr><td><code id="dependence_plot_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
<tr><td><code id="dependence_plot_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='DeterministicDihedral'>DeterministicDihedral</h2><span id='topic+DeterministicDihedral'></span>

<h3>Description</h3>

<p>Apply a random dihedral transformation to a batch of images with a probability 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DeterministicDihedral(
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  align_corners = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DeterministicDihedral_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="DeterministicDihedral_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="DeterministicDihedral_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="DeterministicDihedral_+3A_align_corners">align_corners</code></td>
<td>
<p>align corners</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='DeterministicDraw'>DeterministicDraw</h2><span id='topic+DeterministicDraw'></span>

<h3>Description</h3>

<p>DeterministicDraw
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DeterministicDraw(vals)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DeterministicDraw_+3A_vals">vals</code></td>
<td>
<p>values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='DeterministicFlip'>DeterministicFlip</h2><span id='topic+DeterministicFlip'></span>

<h3>Description</h3>

<p>Flip the batch every other call
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DeterministicFlip(
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  align_corners = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DeterministicFlip_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="DeterministicFlip_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="DeterministicFlip_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="DeterministicFlip_+3A_align_corners">align_corners</code></td>
<td>
<p>align corners</p>
</td></tr>
<tr><td><code id="DeterministicFlip_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='detuplify_pg'>Detuplify_pg</h2><span id='topic+detuplify_pg'></span>

<h3>Description</h3>

<p>Detuplify_pg
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detuplify_pg(d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detuplify_pg_+3A_d">d</code></td>
<td>
<p>d</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Dice'>Dice coefficient</h2><span id='topic+Dice'></span>

<h3>Description</h3>

<p>Dice coefficient metric for binary target in segmentation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dice(axis = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dice_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Dicom'>Dicom class</h2><span id='topic+Dicom'></span>

<h3>Description</h3>

<p>Dicom class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dicom()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='dicom_windows'>Dicom_windows module</h2><span id='topic+dicom_windows'></span>

<h3>Description</h3>

<p>Dicom_windows module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dicom_windows()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Dihedral'>Dihedral</h2><span id='topic+Dihedral'></span>

<h3>Description</h3>

<p>Apply a random dihedral transformation to a batch of images with a probability 'p'
</p>
<p>Apply a random dihedral transformation to a batch of images with a probability 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dihedral(
  p = 0.5,
  draw = NULL,
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  align_corners = NULL,
  batch = FALSE
)

Dihedral(
  p = 0.5,
  draw = NULL,
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  align_corners = NULL,
  batch = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dihedral_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="Dihedral_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="Dihedral_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="Dihedral_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="Dihedral_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="Dihedral_+3A_align_corners">align_corners</code></td>
<td>
<p>align corners</p>
</td></tr>
<tr><td><code id="Dihedral_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>

<hr>
<h2 id='dihedral_mat'>Dihedral_mat</h2><span id='topic+dihedral_mat'></span>

<h3>Description</h3>

<p>Return a random dihedral matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dihedral_mat(x, p = 0.5, draw = NULL, batch = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dihedral_mat_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="dihedral_mat_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="dihedral_mat_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="dihedral_mat_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='DihedralItem'>DihedralItem</h2><span id='topic+DihedralItem'></span>

<h3>Description</h3>

<p>Randomly flip with probability 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DihedralItem(p = 1, nm = NULL, before_call = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DihedralItem_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="DihedralItem_+3A_nm">nm</code></td>
<td>
<p>nm</p>
</td></tr>
<tr><td><code id="DihedralItem_+3A_before_call">before_call</code></td>
<td>
<p>before call</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='dim'>Dim</h2><span id='topic+dim'></span><span id='topic+dim.torch.Tensor'></span>

<h3>Description</h3>

<p>Dim
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
dim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dim_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='dim.fastai.torch_core.TensorMask'>Dim</h2><span id='topic+dim.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Dim
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
dim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dim.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='discriminator'>Discriminator</h2><span id='topic+discriminator'></span>

<h3>Description</h3>

<p>Discriminator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discriminator(
  ch_in,
  n_ftrs = 64,
  n_layers = 3,
  norm_layer = NULL,
  sigmoid = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discriminator_+3A_ch_in">ch_in</code></td>
<td>
<p>input</p>
</td></tr>
<tr><td><code id="discriminator_+3A_n_ftrs">n_ftrs</code></td>
<td>
<p>number of filters</p>
</td></tr>
<tr><td><code id="discriminator_+3A_n_layers">n_layers</code></td>
<td>
<p>number of layers</p>
</td></tr>
<tr><td><code id="discriminator_+3A_norm_layer">norm_layer</code></td>
<td>
<p>normalization layer</p>
</td></tr>
<tr><td><code id="discriminator_+3A_sigmoid">sigmoid</code></td>
<td>
<p>apply sigmoid  function or not</p>
</td></tr>
</table>

<hr>
<h2 id='div'>Div</h2><span id='topic+div'></span><span id='topic++2F.torch.Tensor'></span>

<h3>Description</h3>

<p>Div
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a / b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="div_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="div_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='DownmixMono'>Downmix Mono</h2><span id='topic+DownmixMono'></span>

<h3>Description</h3>

<p>Transform multichannel audios into single channel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DownmixMono(enc = NULL, dec = NULL, split_idx = NULL, order = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DownmixMono_+3A_enc">enc</code></td>
<td>
<p>encoder</p>
</td></tr>
<tr><td><code id="DownmixMono_+3A_dec">dec</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="DownmixMono_+3A_split_idx">split_idx</code></td>
<td>
<p>split by index</p>
</td></tr>
<tr><td><code id="DownmixMono_+3A_order">order</code></td>
<td>
<p>order, by default is NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='dropout_mask'>Dropout_mask</h2><span id='topic+dropout_mask'></span>

<h3>Description</h3>

<p>Return a dropout mask of the same type as 'x', size 'sz', with probability 'p' to cancel an element.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dropout_mask(x, sz, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dropout_mask_+3A_x">x</code></td>
<td>
<p>x</p>
</td></tr>
<tr><td><code id="dropout_mask_+3A_sz">sz</code></td>
<td>
<p>sz</p>
</td></tr>
<tr><td><code id="dropout_mask_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='dummy_eval'>Dummy_eval</h2><span id='topic+dummy_eval'></span>

<h3>Description</h3>

<p>Evaluate 'm' on a dummy input of a certain 'size'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dummy_eval(m, size = list(64, 64))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dummy_eval_+3A_m">m</code></td>
<td>
<p>m parameter</p>
</td></tr>
<tr><td><code id="dummy_eval_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='DynamicUnet'>DynamicUnet</h2><span id='topic+DynamicUnet'></span>

<h3>Description</h3>

<p>Create a U-Net from a given architecture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DynamicUnet(
  encoder,
  n_classes,
  img_size,
  blur = FALSE,
  blur_final = TRUE,
  self_attention = FALSE,
  y_range = NULL,
  last_cross = TRUE,
  bottle = FALSE,
  act_cls = nn()$ReLU,
  init = nn()$init$kaiming_normal_,
  norm_type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DynamicUnet_+3A_encoder">encoder</code></td>
<td>
<p>encoder</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_n_classes">n_classes</code></td>
<td>
<p>number of classes</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_img_size">img_size</code></td>
<td>
<p>image size</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_blur">blur</code></td>
<td>
<p>blur is used to avoid checkerboard artifacts at each layer.</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_blur_final">blur_final</code></td>
<td>
<p>blur final is specific to the last layer.</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_self_attention">self_attention</code></td>
<td>
<p>self_attention determines if we use a self attention layer at the third block before the end.</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_y_range">y_range</code></td>
<td>
<p>If y_range is passed, the last activations go through a sigmoid rescaled to that range.</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_last_cross">last_cross</code></td>
<td>
<p>last cross</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_bottle">bottle</code></td>
<td>
<p>bottle</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="DynamicUnet_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='EarlyStoppingCallback'>EarlyStoppingCallback</h2><span id='topic+EarlyStoppingCallback'></span>

<h3>Description</h3>

<p>EarlyStoppingCallback
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EarlyStoppingCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EarlyStoppingCallback_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='efficientdet_infer_dl'>Efficientdet infer dataloader</h2><span id='topic+efficientdet_infer_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for inferring the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efficientdet_infer_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efficientdet_infer_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="efficientdet_infer_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level. **dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
<tr><td><code id="efficientdet_infer_dl_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='efficientdet_learner'>MaskRCNN learner</h2><span id='topic+efficientdet_learner'></span>

<h3>Description</h3>

<p>Fastai 'Learner' adapted for MaskRCNN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efficientdet_learner(dls, model, cbs = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efficientdet_learner_+3A_dls">dls</code></td>
<td>
<p>'Sequence' of 'DataLoaders' passed to the 'Learner'.
The first one will be used for training and the second for validation.</p>
</td></tr>
<tr><td><code id="efficientdet_learner_+3A_model">model</code></td>
<td>
<p>The model to train.</p>
</td></tr>
<tr><td><code id="efficientdet_learner_+3A_cbs">cbs</code></td>
<td>
<p>Optional 'Sequence' of callbacks.</p>
</td></tr>
<tr><td><code id="efficientdet_learner_+3A_...">...</code></td>
<td>
<p>learner_kwargs: Keyword arguments that will be internally passed to 'Learner'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='efficientdet_model'>Eficientdet model</h2><span id='topic+efficientdet_model'></span>

<h3>Description</h3>

<p>Creates the efficientdet model specified by 'model_name'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efficientdet_model(model_name, num_classes, img_size, pretrained = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efficientdet_model_+3A_model_name">model_name</code></td>
<td>
<p>Specifies the model to create. For pretrained models, check [this](https://github.com/rwightman/efficientdet-pytorch#models) table.</p>
</td></tr>
<tr><td><code id="efficientdet_model_+3A_num_classes">num_classes</code></td>
<td>
<p>Number of classes of your dataset (including background).</p>
</td></tr>
<tr><td><code id="efficientdet_model_+3A_img_size">img_size</code></td>
<td>
<p>Image size that will be fed to the model. Must be squared and divisible by 128.</p>
</td></tr>
<tr><td><code id="efficientdet_model_+3A_pretrained">pretrained</code></td>
<td>
<p>If TRUE, use a pretrained backbone (on COCO).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='efficientdet_predict_dl'>Efficientdet predict dataloader</h2><span id='topic+efficientdet_predict_dl'></span>

<h3>Description</h3>

<p>Efficientdet predict dataloader
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efficientdet_predict_dl(model, infer_dl, show_pbar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efficientdet_predict_dl_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="efficientdet_predict_dl_+3A_infer_dl">infer_dl</code></td>
<td>
<p>infer_dl</p>
</td></tr>
<tr><td><code id="efficientdet_predict_dl_+3A_show_pbar">show_pbar</code></td>
<td>
<p>show_pbar</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='efficientdet_train_dl'>Efficientdet train dataloader</h2><span id='topic+efficientdet_train_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for training the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efficientdet_train_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efficientdet_train_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="efficientdet_train_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level.</p>
</td></tr>
<tr><td><code id="efficientdet_train_dl_+3A_...">...</code></td>
<td>
<p>dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='efficientdet_valid_dl'>Efficientdet valid dataloader</h2><span id='topic+efficientdet_valid_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for training the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efficientdet_valid_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efficientdet_valid_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="efficientdet_valid_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level.</p>
</td></tr>
<tr><td><code id="efficientdet_valid_dl_+3A_...">...</code></td>
<td>
<p>dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='emb_sz_rule'>Emb_sz_rule</h2><span id='topic+emb_sz_rule'></span>

<h3>Description</h3>

<p>Rule of thumb to pick embedding size corresponding to 'n_cat'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emb_sz_rule(n_cat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emb_sz_rule_+3A_n_cat">n_cat</code></td>
<td>
<p>n_cat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Embedding'>Embedding</h2><span id='topic+Embedding'></span>

<h3>Description</h3>

<p>Embedding layer with truncated normal initialization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Embedding(ni, nf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Embedding_+3A_ni">ni</code></td>
<td>
<p>inputs</p>
</td></tr>
<tr><td><code id="Embedding_+3A_nf">nf</code></td>
<td>
<p>outputs / number of features</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='EmbeddingDropout'>EmbeddingDropout</h2><span id='topic+EmbeddingDropout'></span>

<h3>Description</h3>

<p>Apply dropout with probability 'embed_p' to an embedding layer 'emb'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EmbeddingDropout(emb, embed_p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EmbeddingDropout_+3A_emb">emb</code></td>
<td>
<p>emb</p>
</td></tr>
<tr><td><code id="EmbeddingDropout_+3A_embed_p">embed_p</code></td>
<td>
<p>embed_p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='error_rate'>Error rate</h2><span id='topic+error_rate'></span>

<h3>Description</h3>

<p>1 - 'accuracy'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>error_rate(inp, targ, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="error_rate_+3A_inp">inp</code></td>
<td>
<p>The predictions of the model</p>
</td></tr>
<tr><td><code id="error_rate_+3A_targ">targ</code></td>
<td>
<p>The corresponding labels</p>
</td></tr>
<tr><td><code id="error_rate_+3A_axis">axis</code></td>
<td>
<p>Axis</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

learn = cnn_learner(dls, resnet34(), metrics = error_rate)



## End(Not run)


</code></pre>

<hr>
<h2 id='exp'>Exp</h2><span id='topic+exp'></span><span id='topic+exp.torch.Tensor'></span>

<h3>Description</h3>

<p>Exp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
exp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='exp_rmspe'>Exp_rmspe</h2><span id='topic+exp_rmspe'></span>

<h3>Description</h3>

<p>Root mean square percentage error of the exponential of predictions and targets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exp_rmspe(preds, targs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp_rmspe_+3A_preds">preds</code></td>
<td>
<p>predicitons</p>
</td></tr>
<tr><td><code id="exp_rmspe_+3A_targs">targs</code></td>
<td>
<p>targets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='exp.fastai.torch_core.TensorMask'>Exp</h2><span id='topic+exp.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Exp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
exp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='ExplainedVariance'>Explained Variance</h2><span id='topic+ExplainedVariance'></span>

<h3>Description</h3>

<p>Explained variance between predictions and targets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExplainedVariance(sample_weight = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ExplainedVariance_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='expm1'>Expm1</h2><span id='topic+expm1'></span><span id='topic+expm1.torch.Tensor'></span>

<h3>Description</h3>

<p>Expm1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
expm1(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expm1_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='expm1.fastai.torch_core.TensorMask'>Expm1</h2><span id='topic+expm1.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Expm1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
expm1(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expm1.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='export_generator'>Export_generator</h2><span id='topic+export_generator'></span>

<h3>Description</h3>

<p>Export_generator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>export_generator(
  learn,
  generator_name = "generator",
  path = ".",
  convert_to = "B"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="export_generator_+3A_learn">learn</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="export_generator_+3A_generator_name">generator_name</code></td>
<td>
<p>generator name</p>
</td></tr>
<tr><td><code id="export_generator_+3A_path">path</code></td>
<td>
<p>path (save dir)</p>
</td></tr>
<tr><td><code id="export_generator_+3A_convert_to">convert_to</code></td>
<td>
<p>convert to</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='F1Score'>F1Score</h2><span id='topic+F1Score'></span>

<h3>Description</h3>

<p>F1 score for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>F1Score(
  axis = -1,
  labels = NULL,
  pos_label = 1,
  average = "binary",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="F1Score_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="F1Score_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="F1Score_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="F1Score_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="F1Score_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='F1ScoreMulti'>F1ScoreMulti</h2><span id='topic+F1ScoreMulti'></span>

<h3>Description</h3>

<p>F1 score for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>F1ScoreMulti(
  thresh = 0.5,
  sigmoid = TRUE,
  labels = NULL,
  pos_label = 1,
  average = "macro",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="F1ScoreMulti_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="F1ScoreMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="F1ScoreMulti_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="F1ScoreMulti_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="F1ScoreMulti_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="F1ScoreMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fa_collate'>Fa_collate</h2><span id='topic+fa_collate'></span>

<h3>Description</h3>

<p>Fa_collate
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fa_collate(t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fa_collate_+3A_t">t</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fa_convert'>Da_convert</h2><span id='topic+fa_convert'></span>

<h3>Description</h3>

<p>Da_convert
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fa_convert(t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fa_convert_+3A_t">t</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fastai_version'>Fastai version</h2><span id='topic+fastai_version'></span>

<h3>Description</h3>

<p>Fastai version
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastai_version()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fastaudio'>Fastaudio module</h2><span id='topic+fastaudio'></span>

<h3>Description</h3>

<p>Fastaudio module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastaudio()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='faster_rcnn_infer_dl'>Faster RCNN infer dataloader</h2><span id='topic+faster_rcnn_infer_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for inferring the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faster_rcnn_infer_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faster_rcnn_infer_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="faster_rcnn_infer_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level. **dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
<tr><td><code id="faster_rcnn_infer_dl_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='faster_rcnn_learner'>Faster RSNN learner</h2><span id='topic+faster_rcnn_learner'></span>

<h3>Description</h3>

<p>Fastai 'Learner' adapted for Faster RCNN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faster_rcnn_learner(dls, model, cbs = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faster_rcnn_learner_+3A_dls">dls</code></td>
<td>
<p>'Sequence' of 'DataLoaders' passed to the 'Learner'.
The first one will be used for training and the second for validation.</p>
</td></tr>
<tr><td><code id="faster_rcnn_learner_+3A_model">model</code></td>
<td>
<p>The model to train.</p>
</td></tr>
<tr><td><code id="faster_rcnn_learner_+3A_cbs">cbs</code></td>
<td>
<p>Optional 'Sequence' of callbacks.</p>
</td></tr>
<tr><td><code id="faster_rcnn_learner_+3A_...">...</code></td>
<td>
<p>learner_kwargs: Keyword arguments that will be internally passed to 'Learner'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='faster_rcnn_model'>Faster RSNN model</h2><span id='topic+faster_rcnn_model'></span>

<h3>Description</h3>

<p>FasterRCNN model implemented by torchvision.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faster_rcnn_model(
  num_classes,
  backbone = NULL,
  remove_internal_transforms = TRUE,
  pretrained = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faster_rcnn_model_+3A_num_classes">num_classes</code></td>
<td>
<p>Number of classes.</p>
</td></tr>
<tr><td><code id="faster_rcnn_model_+3A_backbone">backbone</code></td>
<td>
<p>Backbone model to use. Defaults to a resnet50_fpn model.</p>
</td></tr>
<tr><td><code id="faster_rcnn_model_+3A_remove_internal_transforms">remove_internal_transforms</code></td>
<td>
<p>The torchvision model internally applies transforms like resizing and normalization, but we already do this at the &lsquo;Dataset' level, so it&rsquo;s safe to remove those internal transforms.</p>
</td></tr>
<tr><td><code id="faster_rcnn_model_+3A_pretrained">pretrained</code></td>
<td>
<p>Argument passed to 'fastercnn_resnet50_fpn' if 'backbone is NULL'. By default it is set to TRUE: this is generally used when training a new model (transfer learning). 'pretrained = FALSE' is used during inference (prediction) for cases where the users have their own pretrained weights. **faster_rcnn_kwargs: Keyword arguments that internally are going to be passed to 'torchvision.models.detection.faster_rcnn.FastRCNN'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='faster_rcnn_predict_dl'>Faster RCNN predict dataloader</h2><span id='topic+faster_rcnn_predict_dl'></span>

<h3>Description</h3>

<p>Faster RCNN predict dataloader
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faster_rcnn_predict_dl(model, infer_dl, show_pbar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faster_rcnn_predict_dl_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="faster_rcnn_predict_dl_+3A_infer_dl">infer_dl</code></td>
<td>
<p>infer_dl</p>
</td></tr>
<tr><td><code id="faster_rcnn_predict_dl_+3A_show_pbar">show_pbar</code></td>
<td>
<p>show_pbar</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='faster_rcnn_train_dl'>Faster RSNN train dataloader</h2><span id='topic+faster_rcnn_train_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for training the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faster_rcnn_train_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faster_rcnn_train_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="faster_rcnn_train_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level.</p>
</td></tr>
<tr><td><code id="faster_rcnn_train_dl_+3A_...">...</code></td>
<td>
<p>dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='faster_rcnn_valid_dl'>Faster RSNN valid dataloader</h2><span id='topic+faster_rcnn_valid_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for training the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faster_rcnn_valid_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faster_rcnn_valid_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="faster_rcnn_valid_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level.</p>
</td></tr>
<tr><td><code id="faster_rcnn_valid_dl_+3A_...">...</code></td>
<td>
<p>dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fastinf'>Wandb module</h2><span id='topic+fastinf'></span>

<h3>Description</h3>

<p>Wandb module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastinf()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FBeta'>FBeta</h2><span id='topic+FBeta'></span>

<h3>Description</h3>

<p>FBeta score with 'beta' for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBeta(
  beta,
  axis = -1,
  labels = NULL,
  pos_label = 1,
  average = "binary",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FBeta_+3A_beta">beta</code></td>
<td>
<p>beta</p>
</td></tr>
<tr><td><code id="FBeta_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="FBeta_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="FBeta_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="FBeta_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="FBeta_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FBetaMulti'>FBetaMulti</h2><span id='topic+FBetaMulti'></span>

<h3>Description</h3>

<p>FBeta score with 'beta' for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBetaMulti(
  beta,
  thresh = 0.5,
  sigmoid = TRUE,
  labels = NULL,
  pos_label = 1,
  average = "macro",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FBetaMulti_+3A_beta">beta</code></td>
<td>
<p>beta</p>
</td></tr>
<tr><td><code id="FBetaMulti_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="FBetaMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="FBetaMulti_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="FBetaMulti_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="FBetaMulti_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="FBetaMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FetchPredsCallback'>FetchPredsCallback</h2><span id='topic+FetchPredsCallback'></span>

<h3>Description</h3>

<p>A callback to fetch predictions during the training loop
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FetchPredsCallback(
  ds_idx = 1,
  dl = NULL,
  with_input = FALSE,
  with_decoded = FALSE,
  cbs = NULL,
  reorder = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FetchPredsCallback_+3A_ds_idx">ds_idx</code></td>
<td>
<p>dataset index</p>
</td></tr>
<tr><td><code id="FetchPredsCallback_+3A_dl">dl</code></td>
<td>
<p>DL application</p>
</td></tr>
<tr><td><code id="FetchPredsCallback_+3A_with_input">with_input</code></td>
<td>
<p>with input or not</p>
</td></tr>
<tr><td><code id="FetchPredsCallback_+3A_with_decoded">with_decoded</code></td>
<td>
<p>with decoded or not</p>
</td></tr>
<tr><td><code id="FetchPredsCallback_+3A_cbs">cbs</code></td>
<td>
<p>callbacks</p>
</td></tr>
<tr><td><code id="FetchPredsCallback_+3A_reorder">reorder</code></td>
<td>
<p>reorder or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FileSplitter'>File Splitter</h2><span id='topic+FileSplitter'></span>

<h3>Description</h3>

<p>Split 'items' by providing file 'fname' (contains names of valid items separated by newline).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FileSplitter(fname)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FileSplitter_+3A_fname">fname</code></td>
<td>
<p>file name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FillMissing'>Fill Missing</h2><span id='topic+FillMissing'></span>

<h3>Description</h3>

<p>Fill the missing values in continuous columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FillMissing(
  cat_names,
  cont_names,
  fill_strategy = FillStrategy_MEDIAN(),
  add_col = TRUE,
  fill_val = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FillMissing_+3A_cat_names">cat_names</code></td>
<td>
<p>The names of the categorical variables</p>
</td></tr>
<tr><td><code id="FillMissing_+3A_cont_names">cont_names</code></td>
<td>
<p>The names of the continuous variables</p>
</td></tr>
<tr><td><code id="FillMissing_+3A_fill_strategy">fill_strategy</code></td>
<td>
<p>The strategy of filling</p>
</td></tr>
<tr><td><code id="FillMissing_+3A_add_col">add_col</code></td>
<td>
<p>add_col</p>
</td></tr>
<tr><td><code id="FillMissing_+3A_fill_val">fill_val</code></td>
<td>
<p>fill_val</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

procs = list(FillMissing(),Categorify(),Normalize())


## End(Not run)

</code></pre>

<hr>
<h2 id='FillStrategy_COMMON'>COMMON</h2><span id='topic+FillStrategy_COMMON'></span>

<h3>Description</h3>

<p>An enumeration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FillStrategy_COMMON()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FillStrategy_CONSTANT'>CONSTANT</h2><span id='topic+FillStrategy_CONSTANT'></span>

<h3>Description</h3>

<p>An enumeration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FillStrategy_CONSTANT()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FillStrategy_MEDIAN'>MEDIAN</h2><span id='topic+FillStrategy_MEDIAN'></span>

<h3>Description</h3>

<p>An enumeration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FillStrategy_MEDIAN()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='find_coeffs'>Find_coeffs</h2><span id='topic+find_coeffs'></span>

<h3>Description</h3>

<p>Find coefficients for warp tfm from 'p1' to 'p2'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_coeffs(p1, p2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_coeffs_+3A_p1">p1</code></td>
<td>
<p>coefficient p1</p>
</td></tr>
<tr><td><code id="find_coeffs_+3A_p2">p2</code></td>
<td>
<p>coefficient p2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fine_tune'>Fine_tune</h2><span id='topic+fine_tune'></span>

<h3>Description</h3>

<p>Fine tune with 'freeze' for 'freeze_epochs' then
with 'unfreeze' from 'epochs' using discriminative LR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tune(
  object,
  epochs,
  base_lr = 0.002,
  freeze_epochs = 1,
  lr_mult = 100,
  pct_start = 0.3,
  div = 5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fine_tune_+3A_object">object</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="fine_tune_+3A_epochs">epochs</code></td>
<td>
<p>epoch number</p>
</td></tr>
<tr><td><code id="fine_tune_+3A_base_lr">base_lr</code></td>
<td>
<p>base learning rate</p>
</td></tr>
<tr><td><code id="fine_tune_+3A_freeze_epochs">freeze_epochs</code></td>
<td>
<p>freeze epochs number</p>
</td></tr>
<tr><td><code id="fine_tune_+3A_lr_mult">lr_mult</code></td>
<td>
<p>learning rate multiply</p>
</td></tr>
<tr><td><code id="fine_tune_+3A_pct_start">pct_start</code></td>
<td>
<p>start percentage</p>
</td></tr>
<tr><td><code id="fine_tune_+3A_div">div</code></td>
<td>
<p>divide</p>
</td></tr>
<tr><td><code id="fine_tune_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fit_flat_cos'>Fit_flat_cos</h2><span id='topic+fit_flat_cos'></span>

<h3>Description</h3>

<p>Fit_flat_cos
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_flat_cos(
  object,
  n_epoch,
  lr = NULL,
  div_final = 1e+05,
  pct_start = 0.75,
  wd = NULL,
  cbs = NULL,
  reset_opt = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_flat_cos_+3A_object">object</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="fit_flat_cos_+3A_n_epoch">n_epoch</code></td>
<td>
<p>number of epochs</p>
</td></tr>
<tr><td><code id="fit_flat_cos_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="fit_flat_cos_+3A_div_final">div_final</code></td>
<td>
<p>divide final value</p>
</td></tr>
<tr><td><code id="fit_flat_cos_+3A_pct_start">pct_start</code></td>
<td>
<p>start percentage</p>
</td></tr>
<tr><td><code id="fit_flat_cos_+3A_wd">wd</code></td>
<td>
<p>weight decay</p>
</td></tr>
<tr><td><code id="fit_flat_cos_+3A_cbs">cbs</code></td>
<td>
<p>callbacks</p>
</td></tr>
<tr><td><code id="fit_flat_cos_+3A_reset_opt">reset_opt</code></td>
<td>
<p>reset optimizer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fit_flat_lin'>Fit_flat_lin</h2><span id='topic+fit_flat_lin'></span>

<h3>Description</h3>

<p>Fit 'self.model' for 'n_epoch' at flat 'start_lr'
before 'curve_type' annealing to 'end_lr' with weight decay of 'wd' and
callbacks 'cbs'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_flat_lin(
  object,
  n_epochs = 100,
  n_epochs_decay = 100,
  start_lr = NULL,
  end_lr = 0,
  curve_type = "linear",
  wd = NULL,
  cbs = NULL,
  reset_opt = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_flat_lin_+3A_object">object</code></td>
<td>
<p>model / learner</p>
</td></tr>
<tr><td><code id="fit_flat_lin_+3A_n_epochs">n_epochs</code></td>
<td>
<p>number of epochs</p>
</td></tr>
<tr><td><code id="fit_flat_lin_+3A_n_epochs_decay">n_epochs_decay</code></td>
<td>
<p>number of epochs with decay</p>
</td></tr>
<tr><td><code id="fit_flat_lin_+3A_start_lr">start_lr</code></td>
<td>
<p>Desired starting learning rate, used for beginning pct of training.</p>
</td></tr>
<tr><td><code id="fit_flat_lin_+3A_end_lr">end_lr</code></td>
<td>
<p>Desired end learning rate, training will conclude at this learning rate.</p>
</td></tr>
<tr><td><code id="fit_flat_lin_+3A_curve_type">curve_type</code></td>
<td>
<p>Curve type for learning rate annealing. Options are 'linear', 'cosine', and 'exponential'.</p>
</td></tr>
<tr><td><code id="fit_flat_lin_+3A_wd">wd</code></td>
<td>
<p>weight decay</p>
</td></tr>
<tr><td><code id="fit_flat_lin_+3A_cbs">cbs</code></td>
<td>
<p>callbacks</p>
</td></tr>
<tr><td><code id="fit_flat_lin_+3A_reset_opt">reset_opt</code></td>
<td>
<p>reset optimizer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fit_one_cycle'>Fit one cycle</h2><span id='topic+fit_one_cycle'></span>

<h3>Description</h3>

<p>Fit one cycle
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_one_cycle(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_one_cycle_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="fit_one_cycle_+3A_...">...</code></td>
<td>
<p>parameters to pass, e.g. lr, n_epoch, wd, and etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fit_sgdr'>Fit_sgdr</h2><span id='topic+fit_sgdr'></span>

<h3>Description</h3>

<p>Fit_sgdr
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_sgdr(
  object,
  n_cycles,
  cycle_len,
  lr_max = NULL,
  cycle_mult = 2,
  cbs = NULL,
  reset_opt = FALSE,
  wd = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_sgdr_+3A_object">object</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="fit_sgdr_+3A_n_cycles">n_cycles</code></td>
<td>
<p>number of cycles</p>
</td></tr>
<tr><td><code id="fit_sgdr_+3A_cycle_len">cycle_len</code></td>
<td>
<p>length of cycle</p>
</td></tr>
<tr><td><code id="fit_sgdr_+3A_lr_max">lr_max</code></td>
<td>
<p>maximum learning rate</p>
</td></tr>
<tr><td><code id="fit_sgdr_+3A_cycle_mult">cycle_mult</code></td>
<td>
<p>cycle mult</p>
</td></tr>
<tr><td><code id="fit_sgdr_+3A_cbs">cbs</code></td>
<td>
<p>callbacks</p>
</td></tr>
<tr><td><code id="fit_sgdr_+3A_reset_opt">reset_opt</code></td>
<td>
<p>reset optimizer</p>
</td></tr>
<tr><td><code id="fit_sgdr_+3A_wd">wd</code></td>
<td>
<p>weight decay</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fit.fastai.learner.Learner'>Fit</h2><span id='topic+fit.fastai.learner.Learner'></span>

<h3>Description</h3>

<p>Fit the model on this learner with 'lr' learning rate,
'wd' weight decay for 'epochs' with 'callbacks' as cbs argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.learner.Learner'
fit(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.fastai.learner.Learner_+3A_object">object</code></td>
<td>
<p>a learner object</p>
</td></tr>
<tr><td><code id="fit.fastai.learner.Learner_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>train history
</p>

<hr>
<h2 id='fit.fastai.tabular.learner.TabularLearner'>Fit</h2><span id='topic+fit.fastai.tabular.learner.TabularLearner'></span>

<h3>Description</h3>

<p>Fit the model on this learner with 'lr' learning rate, 'wd' weight decay for 'epochs' with 'callbacks'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.tabular.learner.TabularLearner'
fit(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.fastai.tabular.learner.TabularLearner_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="fit.fastai.tabular.learner.TabularLearner_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='fit.fastai.vision.gan.GANLearner'>Fit</h2><span id='topic+fit.fastai.vision.gan.GANLearner'></span>

<h3>Description</h3>

<p>Fit the model on this learner with 'lr' learning rate, 'wd' weight decay for 'epochs' with 'callbacks'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.vision.gan.GANLearner'
fit(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.fastai.vision.gan.GANLearner_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="fit.fastai.vision.gan.GANLearner_+3A_...">...</code></td>
<td>
<p>additonal parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>train history
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

learn %&gt;% fit(1, 2e-4, wd = 0)


## End(Not run)

</code></pre>

<hr>
<h2 id='fix_fit'>Fix fit</h2><span id='topic+fix_fit'></span>

<h3>Description</h3>

<p>Fix fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fix_fit(disable_graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fix_fit_+3A_disable_graph">disable_graph</code></td>
<td>
<p>to remove dynamic plot, by default is FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fix_html'>Fix_html</h2><span id='topic+fix_html'></span>

<h3>Description</h3>

<p>Various messy things we've seen in documents
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fix_html(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fix_html_+3A_x">x</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>

<hr>
<h2 id='FixedGANSwitcher'>Fixed GAN Switcher</h2><span id='topic+FixedGANSwitcher'></span>

<h3>Description</h3>

<p>Switcher to do 'n_crit' iterations of the critic then 'n_gen' iterations of the generator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FixedGANSwitcher(n_crit = 1, n_gen = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FixedGANSwitcher_+3A_n_crit">n_crit</code></td>
<td>
<p>number of discriminator</p>
</td></tr>
<tr><td><code id="FixedGANSwitcher_+3A_n_gen">n_gen</code></td>
<td>
<p>number of generator</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Flatten'>Flatten</h2><span id='topic+Flatten'></span>

<h3>Description</h3>

<p>Flatten 'x' to a single dimension, e.g. at end of a model. 'full' for rank-1 tensor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Flatten(full = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Flatten_+3A_full">full</code></td>
<td>
<p>bool, full or not</p>
</td></tr>
</table>

<hr>
<h2 id='flatten_check'>Flatten check</h2><span id='topic+flatten_check'></span>

<h3>Description</h3>

<p>Check that 'out' and 'targ' have the same number of elements and flatten them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flatten_check(inp, targ)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flatten_check_+3A_inp">inp</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="flatten_check_+3A_targ">targ</code></td>
<td>
<p>targets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='flatten_model'>Flatten_model</h2><span id='topic+flatten_model'></span>

<h3>Description</h3>

<p>Return the list of all submodules and parameters of 'm'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flatten_model(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flatten_model_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Flip'>Flip</h2><span id='topic+Flip'></span>

<h3>Description</h3>

<p>Randomly flip a batch of images with a probability 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Flip(
  p = 0.5,
  draw = NULL,
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  align_corners = TRUE,
  batch = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Flip_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="Flip_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="Flip_+3A_size">size</code></td>
<td>
<p>size of image</p>
</td></tr>
<tr><td><code id="Flip_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="Flip_+3A_pad_mode">pad_mode</code></td>
<td>
<p>reflection, zeros, border as string parameter</p>
</td></tr>
<tr><td><code id="Flip_+3A_align_corners">align_corners</code></td>
<td>
<p>align corners ot not</p>
</td></tr>
<tr><td><code id="Flip_+3A_batch">batch</code></td>
<td>
<p>batch or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='flip_mat'>Flip_mat</h2><span id='topic+flip_mat'></span>

<h3>Description</h3>

<p>Return a random flip matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flip_mat(x, p = 0.5, draw = NULL, batch = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flip_mat_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="flip_mat_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="flip_mat_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="flip_mat_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FlipItem'>FlipItem</h2><span id='topic+FlipItem'></span>

<h3>Description</h3>

<p>Randomly flip with probability 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FlipItem(p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FlipItem_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='float'>Tensor to float</h2><span id='topic+float'></span>

<h3>Description</h3>

<p>Tensor to float
</p>


<h3>Usage</h3>

<pre><code class='language-R'>float(tensor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="float_+3A_tensor">tensor</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='floor_'>Floor</h2><span id='topic+floor_'></span><span id='topic+floor.torch.Tensor'></span>

<h3>Description</h3>

<p>Floor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
floor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="floor__+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='floor_div'>Floor divide</h2><span id='topic+floor_div'></span><span id='topic++25+2F+25.torch.Tensor'></span>

<h3>Description</h3>

<p>Floor divide
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
x %/% y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="floor_div_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="floor_div_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='floor_mod'>Floor mod</h2><span id='topic+floor_mod'></span><span id='topic++25+25.torch.Tensor'></span>

<h3>Description</h3>

<p>Floor mod
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
x %% y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="floor_mod_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="floor_mod_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='floor.fastai.torch_core.TensorMask'>Floor</h2><span id='topic+floor.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Floor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
floor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="floor.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='fmodule'>Module</h2><span id='topic+fmodule'></span>

<h3>Description</h3>

<p>Module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmodule(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fmodule_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Decorator to create an nn()$Module using f as forward method
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='FolderDataset'>FolderDataset</h2><span id='topic+FolderDataset'></span>

<h3>Description</h3>

<p>A PyTorch Dataset class that can be created from a folder 'path' of images, for the sole purpose of inference. Optional 'transforms'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FolderDataset(path, transforms = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FolderDataset_+3A_path">path</code></td>
<td>
<p>path to dir</p>
</td></tr>
<tr><td><code id="FolderDataset_+3A_transforms">transforms</code></td>
<td>
<p>transformations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>can be provided. Attributes: 'self.files': A list of the filenames in the folder. 'self.totensor': 'torchvision.transforms.ToTensor' transform. 'self.transform': The transforms passed in as 'transforms' to the constructor.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='force_plot'>Force_plot</h2><span id='topic+force_plot'></span>

<h3>Description</h3>

<p>Visualizes the SHAP values with an added force layout. Accepts a class_id which
is used to indicate the class of interest for a classification model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>force_plot(object, class_id = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="force_plot_+3A_object">object</code></td>
<td>
<p>ShapInterpretation object</p>
</td></tr>
<tr><td><code id="force_plot_+3A_class_id">class_id</code></td>
<td>
<p>Accepts a class_id which is used to indicate the class of interest for a
classification model. It can either be an int or str representation for a class of choice.</p>
</td></tr>
<tr><td><code id="force_plot_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='foreground_acc'>Foreground accuracy</h2><span id='topic+foreground_acc'></span>

<h3>Description</h3>

<p>Computes non-background accuracy for multiclass segmentation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>foreground_acc(inp, targ, bkg_idx = 0, axis = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="foreground_acc_+3A_inp">inp</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="foreground_acc_+3A_targ">targ</code></td>
<td>
<p>targets</p>
</td></tr>
<tr><td><code id="foreground_acc_+3A_bkg_idx">bkg_idx</code></td>
<td>
<p>bkg_idx</p>
</td></tr>
<tr><td><code id="foreground_acc_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='forget_mult_CPU'>Forget_mult_CPU</h2><span id='topic+forget_mult_CPU'></span>

<h3>Description</h3>

<p>ForgetMult gate applied to 'x' and 'f' on the CPU.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forget_mult_CPU(x, f, first_h = NULL, batch_first = TRUE, backward = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forget_mult_CPU_+3A_x">x</code></td>
<td>
<p>x</p>
</td></tr>
<tr><td><code id="forget_mult_CPU_+3A_f">f</code></td>
<td>
<p>f</p>
</td></tr>
<tr><td><code id="forget_mult_CPU_+3A_first_h">first_h</code></td>
<td>
<p>first_h</p>
</td></tr>
<tr><td><code id="forget_mult_CPU_+3A_batch_first">batch_first</code></td>
<td>
<p>batch_first</p>
</td></tr>
<tr><td><code id="forget_mult_CPU_+3A_backward">backward</code></td>
<td>
<p>backward</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ForgetMultGPU'>ForgetMultGPU</h2><span id='topic+ForgetMultGPU'></span>

<h3>Description</h3>

<p>Wrapper around the CUDA kernels for the ForgetMult gate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ForgetMultGPU(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ForgetMultGPU_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='freeze'>Freeze a model</h2><span id='topic+freeze'></span>

<h3>Description</h3>

<p>Freeze a model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freeze(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freeze_+3A_object">object</code></td>
<td>
<p>A model</p>
</td></tr>
<tr><td><code id="freeze_+3A_...">...</code></td>
<td>
<p>Additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
learnR %&gt;% freeze()

## End(Not run)
</code></pre>

<hr>
<h2 id='FuncSplitter'>FuncSplitter</h2><span id='topic+FuncSplitter'></span>

<h3>Description</h3>

<p>Split 'items' by result of 'func' ('TRUE' for validation, 'FALSE' for training set).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FuncSplitter(func)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FuncSplitter_+3A_func">func</code></td>
<td>
<p>function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='fView'>View</h2><span id='topic+fView'></span>

<h3>Description</h3>

<p>Reshape x to size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fView(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fView_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='gan_critic'>Gan critic</h2><span id='topic+gan_critic'></span>

<h3>Description</h3>

<p>Critic to train a 'GAN'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gan_critic(n_channels = 3, nf = 128, n_blocks = 3, p = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gan_critic_+3A_n_channels">n_channels</code></td>
<td>
<p>number of channels</p>
</td></tr>
<tr><td><code id="gan_critic_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="gan_critic_+3A_n_blocks">n_blocks</code></td>
<td>
<p>number of blocks</p>
</td></tr>
<tr><td><code id="gan_critic_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
</table>


<h3>Value</h3>

<p>GAN object
</p>

<hr>
<h2 id='gan_loss_from_func'>GAN loss from function</h2><span id='topic+gan_loss_from_func'></span>

<h3>Description</h3>

<p>Define loss functions for a GAN from 'loss_gen' and 'loss_crit'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gan_loss_from_func(loss_gen, loss_crit, weights_gen = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gan_loss_from_func_+3A_loss_gen">loss_gen</code></td>
<td>
<p>generator loss</p>
</td></tr>
<tr><td><code id="gan_loss_from_func_+3A_loss_crit">loss_crit</code></td>
<td>
<p>discriminator loss</p>
</td></tr>
<tr><td><code id="gan_loss_from_func_+3A_weights_gen">weights_gen</code></td>
<td>
<p>weight generator</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='GANDiscriminativeLR'>GAN Discriminative LR</h2><span id='topic+GANDiscriminativeLR'></span>

<h3>Description</h3>

<p>'Callback' that handles multiplying the learning rate by 'mult_lr' for the critic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GANDiscriminativeLR(mult_lr = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GANDiscriminativeLR_+3A_mult_lr">mult_lr</code></td>
<td>
<p>mult learning rate</p>
</td></tr>
</table>

<hr>
<h2 id='GANLearner_from_learners'>GAN Learner from learners</h2><span id='topic+GANLearner_from_learners'></span>

<h3>Description</h3>

<p>Create a GAN from 'learn_gen' and 'learn_crit'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GANLearner_from_learners(
  gen_learn,
  crit_learn,
  switcher = NULL,
  weights_gen = NULL,
  gen_first = FALSE,
  switch_eval = TRUE,
  show_img = TRUE,
  clip = NULL,
  cbs = NULL,
  metrics = NULL,
  loss_func = NULL,
  opt_func = Adam(),
  lr = 0.001,
  splitter = trainable_params(),
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE,
  moms = list(0.95, 0.85, 0.95)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GANLearner_from_learners_+3A_gen_learn">gen_learn</code></td>
<td>
<p>generator learner</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_crit_learn">crit_learn</code></td>
<td>
<p>discriminator learner</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_switcher">switcher</code></td>
<td>
<p>switcher</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_weights_gen">weights_gen</code></td>
<td>
<p>weights generator</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_gen_first">gen_first</code></td>
<td>
<p>generator first</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_switch_eval">switch_eval</code></td>
<td>
<p>switch evaluation</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_show_img">show_img</code></td>
<td>
<p>show image or not</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_clip">clip</code></td>
<td>
<p>clip value</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_cbs">cbs</code></td>
<td>
<p>Cbs is one or a list of Callbacks to pass to the Learner.</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_metrics">metrics</code></td>
<td>
<p>It is an optional list of metrics, that can be either functions or Metrics.</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_loss_func">loss_func</code></td>
<td>
<p>loss function</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_opt_func">opt_func</code></td>
<td>
<p>The function used to create the optimizer</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_splitter">splitter</code></td>
<td>
<p>It is a function that takes self.model and returns a list of parameter groups (or just one parameter group if there are no different parameter groups).</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_model_dir">model_dir</code></td>
<td>
<p>Path and model_dir are used to save and/or load models.</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_wd">wd</code></td>
<td>
<p>It is the default weight decay used when training the model.</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>It controls if weight decay is applied to BatchNorm layers and bias.</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_train_bn">train_bn</code></td>
<td>
<p>It controls if BatchNorm layers are trained even when they are supposed to be frozen according to the splitter.</p>
</td></tr>
<tr><td><code id="GANLearner_from_learners_+3A_moms">moms</code></td>
<td>
<p>The default momentums used in Learner$fit_one_cycle.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='GANLearner_wgan'>Wgan</h2><span id='topic+GANLearner_wgan'></span>

<h3>Description</h3>

<p>Create a WGAN from 'data', 'generator' and 'critic'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GANLearner_wgan(
  dls,
  generator,
  critic,
  switcher = NULL,
  clip = 0.01,
  switch_eval = FALSE,
  gen_first = FALSE,
  show_img = TRUE,
  cbs = NULL,
  metrics = NULL,
  opt_func = Adam(),
  lr = 0.001,
  splitter = trainable_params,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE,
  moms = list(0.95, 0.85, 0.95)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GANLearner_wgan_+3A_dls">dls</code></td>
<td>
<p>dataloader</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_generator">generator</code></td>
<td>
<p>generator</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_critic">critic</code></td>
<td>
<p>critic</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_switcher">switcher</code></td>
<td>
<p>switcher</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_clip">clip</code></td>
<td>
<p>clip value</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_switch_eval">switch_eval</code></td>
<td>
<p>switch evaluation</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_gen_first">gen_first</code></td>
<td>
<p>generator first</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_show_img">show_img</code></td>
<td>
<p>show image or not</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_cbs">cbs</code></td>
<td>
<p>callbacks</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_metrics">metrics</code></td>
<td>
<p>metrics</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_opt_func">opt_func</code></td>
<td>
<p>optimization function</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_splitter">splitter</code></td>
<td>
<p>splitter</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_model_dir">model_dir</code></td>
<td>
<p>model directory</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_wd">wd</code></td>
<td>
<p>weight decay</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>weight decay bn bias</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_train_bn">train_bn</code></td>
<td>
<p>It controls if BatchNorm layers are trained even when they are supposed to be frozen according to the splitter.</p>
</td></tr>
<tr><td><code id="GANLearner_wgan_+3A_moms">moms</code></td>
<td>
<p>momentums</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

learn = GANLearner_wgan(dls, generator, critic, opt_func = partial(Adam(), mom=0.))


## End(Not run)

</code></pre>

<hr>
<h2 id='GANLoss'>GAN Loss</h2><span id='topic+GANLoss'></span>

<h3>Description</h3>

<p>Wrapper around 'crit_loss_func' and 'gen_loss_func'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GANLoss(gen_loss_func, crit_loss_func, gan_model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GANLoss_+3A_gen_loss_func">gen_loss_func</code></td>
<td>
<p>generator loss funcion</p>
</td></tr>
<tr><td><code id="GANLoss_+3A_crit_loss_func">crit_loss_func</code></td>
<td>
<p>discriminator loss function</p>
</td></tr>
<tr><td><code id="GANLoss_+3A_gan_model">gan_model</code></td>
<td>
<p>GAN model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='GANModule'>GAN Module</h2><span id='topic+GANModule'></span>

<h3>Description</h3>

<p>Wrapper around a 'generator' and a 'critic' to create a GAN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GANModule(generator = NULL, critic = NULL, gen_mode = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GANModule_+3A_generator">generator</code></td>
<td>
<p>generator</p>
</td></tr>
<tr><td><code id="GANModule_+3A_critic">critic</code></td>
<td>
<p>critic</p>
</td></tr>
<tr><td><code id="GANModule_+3A_gen_mode">gen_mode</code></td>
<td>
<p>generator mode or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='GANTrainer'>GAN Trainer</h2><span id='topic+GANTrainer'></span>

<h3>Description</h3>

<p>Handles GAN Training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GANTrainer(
  switch_eval = FALSE,
  clip = NULL,
  beta = 0.98,
  gen_first = FALSE,
  show_img = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GANTrainer_+3A_switch_eval">switch_eval</code></td>
<td>
<p>switch evaluation</p>
</td></tr>
<tr><td><code id="GANTrainer_+3A_clip">clip</code></td>
<td>
<p>clip value</p>
</td></tr>
<tr><td><code id="GANTrainer_+3A_beta">beta</code></td>
<td>
<p>beta parameter</p>
</td></tr>
<tr><td><code id="GANTrainer_+3A_gen_first">gen_first</code></td>
<td>
<p>generator first</p>
</td></tr>
<tr><td><code id="GANTrainer_+3A_show_img">show_img</code></td>
<td>
<p>show image or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='GatherPredsCallback'>GatherPredsCallback</h2><span id='topic+GatherPredsCallback'></span>

<h3>Description</h3>

<p>'Callback' that saves the predictions and targets, optionally 'with_loss'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GatherPredsCallback(
  with_input = FALSE,
  with_loss = FALSE,
  save_preds = NULL,
  save_targs = NULL,
  concat_dim = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GatherPredsCallback_+3A_with_input">with_input</code></td>
<td>
<p>include inputs or not</p>
</td></tr>
<tr><td><code id="GatherPredsCallback_+3A_with_loss">with_loss</code></td>
<td>
<p>include loss or not</p>
</td></tr>
<tr><td><code id="GatherPredsCallback_+3A_save_preds">save_preds</code></td>
<td>
<p>save predictions</p>
</td></tr>
<tr><td><code id="GatherPredsCallback_+3A_save_targs">save_targs</code></td>
<td>
<p>save targets/actuals</p>
</td></tr>
<tr><td><code id="GatherPredsCallback_+3A_concat_dim">concat_dim</code></td>
<td>
<p>concatenate dimensions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='gauss_blur2d'>Gauss_blur2d</h2><span id='topic+gauss_blur2d'></span>

<h3>Description</h3>

<p>Apply gaussian_blur2d kornia filter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gauss_blur2d(x, s)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gauss_blur2d_+3A_x">x</code></td>
<td>
<p>image</p>
</td></tr>
<tr><td><code id="gauss_blur2d_+3A_s">s</code></td>
<td>
<p>effect</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='generate_noise'>Generate noise</h2><span id='topic+generate_noise'></span>

<h3>Description</h3>

<p>Generate noise
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_noise(fn, size = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_noise_+3A_fn">fn</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="generate_noise_+3A_size">size</code></td>
<td>
<p>the size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

generate_noise()


## End(Not run)

</code></pre>

<hr>
<h2 id='get_annotations'>Get_annotations</h2><span id='topic+get_annotations'></span>

<h3>Description</h3>

<p>Open a COCO style json in 'fname' and returns the lists of filenames (with maybe 'prefix') and labelled bboxes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_annotations(fname, prefix = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_annotations_+3A_fname">fname</code></td>
<td>
<p>folder name</p>
</td></tr>
<tr><td><code id="get_annotations_+3A_prefix">prefix</code></td>
<td>
<p>prefix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_audio_files'>Get_audio_files</h2><span id='topic+get_audio_files'></span>

<h3>Description</h3>

<p>Get audio files in 'path' recursively, only in 'folders', if specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_audio_files(path, recurse = TRUE, folders = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_audio_files_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="get_audio_files_+3A_recurse">recurse</code></td>
<td>
<p>recursive or not</p>
</td></tr>
<tr><td><code id="get_audio_files_+3A_folders">folders</code></td>
<td>
<p>vector, folders</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_bias'>Get bias</h2><span id='topic+get_bias'></span>

<h3>Description</h3>

<p>Bias for item or user (based on 'is_item') for all in 'arr'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_bias(object, arr, is_item = TRUE, convert = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_bias_+3A_object">object</code></td>
<td>
<p>extract bias</p>
</td></tr>
<tr><td><code id="get_bias_+3A_arr">arr</code></td>
<td>
<p>R data frame</p>
</td></tr>
<tr><td><code id="get_bias_+3A_is_item">is_item</code></td>
<td>
<p>logical, is item</p>
</td></tr>
<tr><td><code id="get_bias_+3A_convert">convert</code></td>
<td>
<p>to R matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

movie_bias = learn %&gt;% get_bias(top_movies, is_item = TRUE)


## End(Not run)

</code></pre>

<hr>
<h2 id='get_c'>Get_c</h2><span id='topic+get_c'></span>

<h3>Description</h3>

<p>Get_c
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_c(dls)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_c_+3A_dls">dls</code></td>
<td>
<p>dataloader object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>number of layers
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

get_c(dls)


## End(Not run)

</code></pre>

<hr>
<h2 id='get_confusion_matrix'>Extract confusion matrix</h2><span id='topic+get_confusion_matrix'></span>

<h3>Description</h3>

<p>Extract confusion matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_confusion_matrix(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_confusion_matrix_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

model %&gt;% get_confusion_matrix()


## End(Not run)

</code></pre>

<hr>
<h2 id='get_data_loaders'>Get data loaders</h2><span id='topic+get_data_loaders'></span>

<h3>Description</h3>

<p>Get data loaders
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_data_loaders(train_batch_size, val_batch_size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_data_loaders_+3A_train_batch_size">train_batch_size</code></td>
<td>
<p>train dataset batch size</p>
</td></tr>
<tr><td><code id="get_data_loaders_+3A_val_batch_size">val_batch_size</code></td>
<td>
<p>validation dataset batch size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_dcm_matrix'>Get image matrix</h2><span id='topic+get_dcm_matrix'></span>

<h3>Description</h3>

<p>Get image matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_dcm_matrix(img, type = "raw", scan = "", size = 50, convert = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_dcm_matrix_+3A_img">img</code></td>
<td>
<p>dicom file</p>
</td></tr>
<tr><td><code id="get_dcm_matrix_+3A_type">type</code></td>
<td>
<p>img transformation</p>
</td></tr>
<tr><td><code id="get_dcm_matrix_+3A_scan">scan</code></td>
<td>
<p>apply uniform or gaussian blur effects</p>
</td></tr>
<tr><td><code id="get_dcm_matrix_+3A_size">size</code></td>
<td>
<p>size of image</p>
</td></tr>
<tr><td><code id="get_dcm_matrix_+3A_convert">convert</code></td>
<td>
<p>to R matrix or keep tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

img = dcmread('hemorrhage.dcm')
img %&gt;% get_dcm_matrix(type = 'raw')


## End(Not run)

</code></pre>

<hr>
<h2 id='get_dicom_files'>get_dicom_files</h2><span id='topic+get_dicom_files'></span>

<h3>Description</h3>

<p>Get dicom files in 'path' recursively, only in 'folders', if specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_dicom_files(path, recurse = TRUE, folders = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_dicom_files_+3A_path">path</code></td>
<td>
<p>path to files</p>
</td></tr>
<tr><td><code id="get_dicom_files_+3A_recurse">recurse</code></td>
<td>
<p>recursive or not</p>
</td></tr>
<tr><td><code id="get_dicom_files_+3A_folders">folders</code></td>
<td>
<p>folder names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>lsit of files
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

items = get_dicom_files("siim_small/train/")



## End(Not run)

</code></pre>

<hr>
<h2 id='get_dls'>Get dls</h2><span id='topic+get_dls'></span>

<h3>Description</h3>

<p>Given image files from two domains ('pathA', 'pathB'), create 'DataLoaders' object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_dls(
  pathA,
  pathB,
  num_A = NULL,
  num_B = NULL,
  load_size = 512,
  crop_size = 256,
  bs = 4,
  num_workers = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_dls_+3A_patha">pathA</code></td>
<td>
<p>path A (from domain)</p>
</td></tr>
<tr><td><code id="get_dls_+3A_pathb">pathB</code></td>
<td>
<p>path B (to domain)</p>
</td></tr>
<tr><td><code id="get_dls_+3A_num_a">num_A</code></td>
<td>
<p>subset of A data</p>
</td></tr>
<tr><td><code id="get_dls_+3A_num_b">num_B</code></td>
<td>
<p>subset of B data</p>
</td></tr>
<tr><td><code id="get_dls_+3A_load_size">load_size</code></td>
<td>
<p>load size</p>
</td></tr>
<tr><td><code id="get_dls_+3A_crop_size">crop_size</code></td>
<td>
<p>crop size</p>
</td></tr>
<tr><td><code id="get_dls_+3A_bs">bs</code></td>
<td>
<p>bathc size</p>
</td></tr>
<tr><td><code id="get_dls_+3A_num_workers">num_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Loading and randomly cropped sizes of 'load_size' and 'crop_size' are set to defaults of 512 and 256.
Batch size is specified by 'bs' (default=4).
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_emb_sz'>Get_emb_sz</h2><span id='topic+get_emb_sz'></span>

<h3>Description</h3>

<p>Get default embedding size from 'TabularPreprocessor' 'proc' or the ones in 'sz_dict'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_emb_sz(to, sz_dict = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_emb_sz_+3A_to">to</code></td>
<td>
<p>to</p>
</td></tr>
<tr><td><code id="get_emb_sz_+3A_sz_dict">sz_dict</code></td>
<td>
<p>dictionary size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_files'>Get_files</h2><span id='topic+get_files'></span>

<h3>Description</h3>

<p>Get all the files in 'path' with optional 'extensions', optionally with 'recurse', only in 'folders', if specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_files(
  path,
  extensions = NULL,
  recurse = TRUE,
  folders = NULL,
  followlinks = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_files_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="get_files_+3A_extensions">extensions</code></td>
<td>
<p>extensions</p>
</td></tr>
<tr><td><code id="get_files_+3A_recurse">recurse</code></td>
<td>
<p>recurse</p>
</td></tr>
<tr><td><code id="get_files_+3A_folders">folders</code></td>
<td>
<p>folders</p>
</td></tr>
<tr><td><code id="get_files_+3A_followlinks">followlinks</code></td>
<td>
<p>followlinks</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='get_grid'>Get_grid</h2><span id='topic+get_grid'></span>

<h3>Description</h3>

<p>Return a grid of 'n' axes, 'rows' by 'cols'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_grid(
  n,
  nrows = NULL,
  ncols = NULL,
  add_vert = 0,
  figsize = NULL,
  double = FALSE,
  title = NULL,
  return_fig = FALSE,
  imsize = 3
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_grid_+3A_n">n</code></td>
<td>
<p>n</p>
</td></tr>
<tr><td><code id="get_grid_+3A_nrows">nrows</code></td>
<td>
<p>number of rows</p>
</td></tr>
<tr><td><code id="get_grid_+3A_ncols">ncols</code></td>
<td>
<p>number of columns</p>
</td></tr>
<tr><td><code id="get_grid_+3A_add_vert">add_vert</code></td>
<td>
<p>add vertical</p>
</td></tr>
<tr><td><code id="get_grid_+3A_figsize">figsize</code></td>
<td>
<p>figure size</p>
</td></tr>
<tr><td><code id="get_grid_+3A_double">double</code></td>
<td>
<p>double</p>
</td></tr>
<tr><td><code id="get_grid_+3A_title">title</code></td>
<td>
<p>title</p>
</td></tr>
<tr><td><code id="get_grid_+3A_return_fig">return_fig</code></td>
<td>
<p>return figure or not</p>
</td></tr>
<tr><td><code id="get_grid_+3A_imsize">imsize</code></td>
<td>
<p>image size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_hf_objects'>Get_hf_objects</h2><span id='topic+get_hf_objects'></span>

<h3>Description</h3>

<p>Returns the architecture (str), config (obj), tokenizer (obj), and model (obj) given at minimum a
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_hf_objects(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_hf_objects_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>'pre-trained model name or path'. Specify a 'task' to ensure the right &quot;AutoModelFor&lt;task&gt;&quot; is used to
create the model. Optionally, you can pass a config (obj), tokenizer (class), and/or model (class) (along with any
related kwargs for each) to get as specific as you want w/r/t what huggingface objects are returned.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_image_files'>Get image files</h2><span id='topic+get_image_files'></span>

<h3>Description</h3>

<p>Get image files in 'path' recursively, only in 'folders', if specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_image_files(path, recurse = TRUE, folders = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_image_files_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="get_image_files_+3A_recurse">recurse</code></td>
<td>
<p>recursive path</p>
</td></tr>
<tr><td><code id="get_image_files_+3A_folders">folders</code></td>
<td>
<p>folder names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_PETS()

path = 'oxford-iiit-pet'

path_img = 'oxford-iiit-pet/images'
fnames = get_image_files(path_img)


## End(Not run)

</code></pre>

<hr>
<h2 id='get_language_model'>Get_language_model</h2><span id='topic+get_language_model'></span>

<h3>Description</h3>

<p>Create a language model from 'arch' and its 'config'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_language_model(arch, vocab_sz, config = NULL, drop_mult = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_language_model_+3A_arch">arch</code></td>
<td>
<p>arch</p>
</td></tr>
<tr><td><code id="get_language_model_+3A_vocab_sz">vocab_sz</code></td>
<td>
<p>vocab_sz</p>
</td></tr>
<tr><td><code id="get_language_model_+3A_config">config</code></td>
<td>
<p>config</p>
</td></tr>
<tr><td><code id="get_language_model_+3A_drop_mult">drop_mult</code></td>
<td>
<p>drop_mult</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='get_preds_cyclegan'>Get_preds_cyclegan</h2><span id='topic+get_preds_cyclegan'></span>

<h3>Description</h3>

<p>A prediction function that takes the Learner object 'learn' with the trained model, the 'test_path' folder with the images to perform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_preds_cyclegan(
  learn,
  test_path,
  pred_path,
  bs = 4,
  num_workers = 4,
  suffix = "tif"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_preds_cyclegan_+3A_learn">learn</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="get_preds_cyclegan_+3A_test_path">test_path</code></td>
<td>
<p>testdat path</p>
</td></tr>
<tr><td><code id="get_preds_cyclegan_+3A_pred_path">pred_path</code></td>
<td>
<p>predict data path</p>
</td></tr>
<tr><td><code id="get_preds_cyclegan_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="get_preds_cyclegan_+3A_num_workers">num_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
<tr><td><code id="get_preds_cyclegan_+3A_suffix">suffix</code></td>
<td>
<p>suffix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>batch inference on, and the output folder 'pred_path' where the predictions will be saved, with a batch size 'bs', 'num_workers',
and suffix of the prediction images &lsquo;suffix' (default=&rsquo;png').
</p>

<hr>
<h2 id='get_text_classifier'>Get_text_classifier</h2><span id='topic+get_text_classifier'></span>

<h3>Description</h3>

<p>Create a text classifier from 'arch' and its 'config', maybe 'pretrained'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_text_classifier(
  arch,
  vocab_sz,
  n_class,
  seq_len = 72,
  config = NULL,
  drop_mult = 1,
  lin_ftrs = NULL,
  ps = NULL,
  pad_idx = 1,
  max_len = 1440,
  y_range = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_text_classifier_+3A_arch">arch</code></td>
<td>
<p>arch</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_vocab_sz">vocab_sz</code></td>
<td>
<p>vocab_sz</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_n_class">n_class</code></td>
<td>
<p>n_class</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_seq_len">seq_len</code></td>
<td>
<p>seq_len</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_config">config</code></td>
<td>
<p>config</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_drop_mult">drop_mult</code></td>
<td>
<p>drop_mult</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_lin_ftrs">lin_ftrs</code></td>
<td>
<p>lin_ftrs</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_ps">ps</code></td>
<td>
<p>ps</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_pad_idx">pad_idx</code></td>
<td>
<p>pad_idx</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_max_len">max_len</code></td>
<td>
<p>max_len</p>
</td></tr>
<tr><td><code id="get_text_classifier_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_text_files'>Get_text_files</h2><span id='topic+get_text_files'></span>

<h3>Description</h3>

<p>Get text files in 'path' recursively, only in 'folders', if specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_text_files(path, recurse = TRUE, folders = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_text_files_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="get_text_files_+3A_recurse">recurse</code></td>
<td>
<p>recurse</p>
</td></tr>
<tr><td><code id="get_text_files_+3A_folders">folders</code></td>
<td>
<p>folders</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='get_weights'>Get weights</h2><span id='topic+get_weights'></span>

<h3>Description</h3>

<p>Weight for item or user (based on 'is_item') for all in 'arr'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_weights(object, arr, is_item = TRUE, convert = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_weights_+3A_object">object</code></td>
<td>
<p>extract weights</p>
</td></tr>
<tr><td><code id="get_weights_+3A_arr">arr</code></td>
<td>
<p>R data frame</p>
</td></tr>
<tr><td><code id="get_weights_+3A_is_item">is_item</code></td>
<td>
<p>logical, is item</p>
</td></tr>
<tr><td><code id="get_weights_+3A_convert">convert</code></td>
<td>
<p>to R matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

movie_w = learn %&gt;% get_weights(top_movies, is_item = TRUE, convert = TRUE)


## End(Not run)

</code></pre>

<hr>
<h2 id='GradientAccumulation'>GradientAccumulation</h2><span id='topic+GradientAccumulation'></span>

<h3>Description</h3>

<p>Accumulate gradients before updating weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GradientAccumulation(n_acc = 32)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GradientAccumulation_+3A_n_acc">n_acc</code></td>
<td>
<p>number of acc</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='GrandparentSplitter'>GrandparentSplitter</h2><span id='topic+GrandparentSplitter'></span>

<h3>Description</h3>

<p>Split 'items' from the grand parent folder names ('train_name' and 'valid_name').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GrandparentSplitter(train_name = "train", valid_name = "valid")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GrandparentSplitter_+3A_train_name">train_name</code></td>
<td>
<p>train folder name</p>
</td></tr>
<tr><td><code id="GrandparentSplitter_+3A_valid_name">valid_name</code></td>
<td>
<p>validation folder name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='grayscale'>Grayscale</h2><span id='topic+grayscale'></span>

<h3>Description</h3>

<p>Tensor to grayscale tensor. Uses the ITU-R 601-2 luma transform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grayscale(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grayscale_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='greater'>Greater</h2><span id='topic+greater'></span><span id='topic++3E.torch.Tensor'></span>

<h3>Description</h3>

<p>Greater
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a &gt; b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="greater_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="greater_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='greater_or_equal'>Greater or equal</h2><span id='topic+greater_or_equal'></span><span id='topic++3E+3D.torch.Tensor'></span>

<h3>Description</h3>

<p>Greater or equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a &gt;= b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="greater_or_equal_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="greater_or_equal_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='HammingLoss'>HammingLoss</h2><span id='topic+HammingLoss'></span>

<h3>Description</h3>

<p>Hamming loss for single-label classification problems
</p>
<p>Hamming loss for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HammingLoss(axis = -1, sample_weight = NULL)

HammingLoss(axis = -1, sample_weight = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HammingLoss_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="HammingLoss_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>
<p>None
</p>

<hr>
<h2 id='HammingLossMulti'>HammingLossMulti</h2><span id='topic+HammingLossMulti'></span>

<h3>Description</h3>

<p>Hamming loss for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HammingLossMulti(
  thresh = 0.5,
  sigmoid = TRUE,
  labels = NULL,
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HammingLossMulti_+3A_thresh">thresh</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="HammingLossMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="HammingLossMulti_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="HammingLossMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='has_params'>Has_params</h2><span id='topic+has_params'></span>

<h3>Description</h3>

<p>Check if 'm' has at least one parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>has_params(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="has_params_+3A_m">m</code></td>
<td>
<p>m parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='has_pool_type'>Has_pool_type</h2><span id='topic+has_pool_type'></span>

<h3>Description</h3>

<p>Return 'TRUE' if 'm' is a pooling layer or has one in its children
</p>


<h3>Usage</h3>

<pre><code class='language-R'>has_pool_type(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="has_pool_type_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='helper'>BLURR_MODEL_HELPER</h2><span id='topic+helper'></span>

<h3>Description</h3>

<p>BLURR_MODEL_HELPER
</p>


<h3>Usage</h3>

<pre><code class='language-R'>helper()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_ARCHITECTURES'>HF_ARCHITECTURES</h2><span id='topic+HF_ARCHITECTURES'></span>

<h3>Description</h3>

<p>An enumeration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_ARCHITECTURES()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_BaseInput'>HF_BaseInput</h2><span id='topic+HF_BaseInput'></span>

<h3>Description</h3>

<p>A HF_BaseInput object is returned from the decodes method
of HF_BatchTransform as a mean to customize '@typedispatched' functions
like DataLoaders.show_batch and Learner.show_results. It represents the
&quot;input_ids&quot; of a huggingface sequence as a tensor with a show method that
requires a huggingface tokenizer for proper display.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_BaseInput(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_BaseInput_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_BaseModelCallback'>HF_BaseModelCallback</h2><span id='topic+HF_BaseModelCallback'></span>

<h3>Description</h3>

<p>HF_BaseModelCallback
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_BaseModelCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_BaseModelCallback_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_BaseModelWrapper'>HF_BaseModelWrapper</h2><span id='topic+HF_BaseModelWrapper'></span>

<h3>Description</h3>

<p>Same as 'nn.Module', but no need for subclasses to call 'super().__init__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_BaseModelWrapper(
  hf_model,
  output_hidden_states = FALSE,
  output_attentions = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_BaseModelWrapper_+3A_hf_model">hf_model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="HF_BaseModelWrapper_+3A_output_hidden_states">output_hidden_states</code></td>
<td>
<p>output hidden states</p>
</td></tr>
<tr><td><code id="HF_BaseModelWrapper_+3A_output_attentions">output_attentions</code></td>
<td>
<p>output attentions</p>
</td></tr>
<tr><td><code id="HF_BaseModelWrapper_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_BeforeBatchTransform'>HF_BeforeBatchTransform</h2><span id='topic+HF_BeforeBatchTransform'></span>

<h3>Description</h3>

<p>Handles everything you need to assemble a mini-batch of inputs and targets,
as well as decode the dictionary produced as a byproduct of the tokenization process in the 'encodes' method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_BeforeBatchTransform(
  hf_arch,
  hf_tokenizer,
  max_length = NULL,
  padding = TRUE,
  truncation = TRUE,
  is_split_into_words = FALSE,
  n_tok_inps = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_BeforeBatchTransform_+3A_hf_arch">hf_arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="HF_BeforeBatchTransform_+3A_hf_tokenizer">hf_tokenizer</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="HF_BeforeBatchTransform_+3A_max_length">max_length</code></td>
<td>
<p>maximum length</p>
</td></tr>
<tr><td><code id="HF_BeforeBatchTransform_+3A_padding">padding</code></td>
<td>
<p>padding or not</p>
</td></tr>
<tr><td><code id="HF_BeforeBatchTransform_+3A_truncation">truncation</code></td>
<td>
<p>truncation or not</p>
</td></tr>
<tr><td><code id="HF_BeforeBatchTransform_+3A_is_split_into_words">is_split_into_words</code></td>
<td>
<p>to split into words</p>
</td></tr>
<tr><td><code id="HF_BeforeBatchTransform_+3A_n_tok_inps">n_tok_inps</code></td>
<td>
<p>number tok inputs</p>
</td></tr>
<tr><td><code id="HF_BeforeBatchTransform_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_CausalLMBeforeBatchTransform'>HF_CausalLMBeforeBatchTransform</h2><span id='topic+HF_CausalLMBeforeBatchTransform'></span>

<h3>Description</h3>

<p>Handles everything you need to assemble a mini-batch of inputs and targets,
as well as decode the dictionary produced
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_CausalLMBeforeBatchTransform(
  hf_arch,
  hf_tokenizer,
  max_length = NULL,
  padding = TRUE,
  truncation = TRUE,
  is_split_into_words = FALSE,
  n_tok_inps = 1,
  ignore_token_id = -100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_hf_arch">hf_arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_hf_tokenizer">hf_tokenizer</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_max_length">max_length</code></td>
<td>
<p>maximum length</p>
</td></tr>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_padding">padding</code></td>
<td>
<p>padding or not</p>
</td></tr>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_truncation">truncation</code></td>
<td>
<p>truncation or not</p>
</td></tr>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_is_split_into_words">is_split_into_words</code></td>
<td>
<p>to split into words</p>
</td></tr>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_n_tok_inps">n_tok_inps</code></td>
<td>
<p>number tok inputs</p>
</td></tr>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_ignore_token_id">ignore_token_id</code></td>
<td>
<p>ignore token id</p>
</td></tr>
<tr><td><code id="HF_CausalLMBeforeBatchTransform_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>as a byproduct of the tokenization process in the 'encodes' method.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_load_dataset'>Load_dataset</h2><span id='topic+HF_load_dataset'></span>

<h3>Description</h3>

<p>Load a dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_load_dataset(
  path,
  name = NULL,
  data_dir = NULL,
  data_files = NULL,
  split = NULL,
  cache_dir = NULL,
  features = NULL,
  download_config = NULL,
  download_mode = NULL,
  ignore_verifications = FALSE,
  save_infos = FALSE,
  script_version = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_load_dataset_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_name">name</code></td>
<td>
<p>name</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_data_dir">data_dir</code></td>
<td>
<p>dataset dir</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_data_files">data_files</code></td>
<td>
<p>dataset files</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_split">split</code></td>
<td>
<p>split</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_cache_dir">cache_dir</code></td>
<td>
<p>cache directory</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_features">features</code></td>
<td>
<p>features</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_download_config">download_config</code></td>
<td>
<p>download configuration</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_download_mode">download_mode</code></td>
<td>
<p>download mode</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_ignore_verifications">ignore_verifications</code></td>
<td>
<p>ignore verifications or not</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_save_infos">save_infos</code></td>
<td>
<p>save information or not</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_script_version">script_version</code></td>
<td>
<p>script version</p>
</td></tr>
<tr><td><code id="HF_load_dataset_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method does the following under the hood:
1. Download and import in the library the dataset loading script from &ldquo;path&ldquo; if it's not
already cached inside the library. Processing scripts are small python scripts that define
the citation, info and format of the dataset, contain the URL to the original data files and
the code to load examples from the original data files. You can find some of the scripts
here: https://github.com/huggingface/datasets/datasets and easily upload yours to share
them using the CLI &ldquo;datasets-cli&ldquo;.
2. Run the dataset loading script which will: * Download the dataset file from the original
URL (see the script) if it's not already downloaded and cached. * Process and cache
the dataset in typed Arrow tables for caching. Arrow table are arbitrarily long, typed
tables which can store nested objects and be mapped to numpy/pandas/python standard types.
They can be directly access from drive, loaded in RAM or even streamed over the web.
3. Return a dataset build from the requested splits in &ldquo;split&ldquo; (default: all).
</p>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='HF_QABatchTransform'>HF_QABatchTransform</h2><span id='topic+HF_QABatchTransform'></span>

<h3>Description</h3>

<p>Handles everything you need to assemble a mini-batch of inputs and targets,
as well as decode the dictionary produced
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_QABatchTransform(
  hf_arch,
  hf_tokenizer,
  max_length = NULL,
  padding = TRUE,
  truncation = TRUE,
  is_split_into_words = FALSE,
  n_tok_inps = 1,
  hf_input_return_type = HF_QuestionAnswerInput(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_QABatchTransform_+3A_hf_arch">hf_arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="HF_QABatchTransform_+3A_hf_tokenizer">hf_tokenizer</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="HF_QABatchTransform_+3A_max_length">max_length</code></td>
<td>
<p>maximum length</p>
</td></tr>
<tr><td><code id="HF_QABatchTransform_+3A_padding">padding</code></td>
<td>
<p>padding</p>
</td></tr>
<tr><td><code id="HF_QABatchTransform_+3A_truncation">truncation</code></td>
<td>
<p>truncation</p>
</td></tr>
<tr><td><code id="HF_QABatchTransform_+3A_is_split_into_words">is_split_into_words</code></td>
<td>
<p>to split into words or not</p>
</td></tr>
<tr><td><code id="HF_QABatchTransform_+3A_n_tok_inps">n_tok_inps</code></td>
<td>
<p>number of tok inputs</p>
</td></tr>
<tr><td><code id="HF_QABatchTransform_+3A_hf_input_return_type">hf_input_return_type</code></td>
<td>
<p>input return type</p>
</td></tr>
<tr><td><code id="HF_QABatchTransform_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>as a byproduct of the tokenization process in the 'encodes' method.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_QABeforeBatchTransform'>HF_QABeforeBatchTransform</h2><span id='topic+HF_QABeforeBatchTransform'></span>

<h3>Description</h3>

<p>Handles everything you need to assemble a mini-batch of inputs and targets,
as well as decode the dictionary produced
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_QABeforeBatchTransform(
  hf_arch,
  hf_tokenizer,
  max_length = NULL,
  padding = TRUE,
  truncation = TRUE,
  is_split_into_words = FALSE,
  n_tok_inps = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_QABeforeBatchTransform_+3A_hf_arch">hf_arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="HF_QABeforeBatchTransform_+3A_hf_tokenizer">hf_tokenizer</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="HF_QABeforeBatchTransform_+3A_max_length">max_length</code></td>
<td>
<p>maximum length</p>
</td></tr>
<tr><td><code id="HF_QABeforeBatchTransform_+3A_padding">padding</code></td>
<td>
<p>padding or not</p>
</td></tr>
<tr><td><code id="HF_QABeforeBatchTransform_+3A_truncation">truncation</code></td>
<td>
<p>truncation or not</p>
</td></tr>
<tr><td><code id="HF_QABeforeBatchTransform_+3A_is_split_into_words">is_split_into_words</code></td>
<td>
<p>into split into words or not</p>
</td></tr>
<tr><td><code id="HF_QABeforeBatchTransform_+3A_n_tok_inps">n_tok_inps</code></td>
<td>
<p>number of tok inputs</p>
</td></tr>
<tr><td><code id="HF_QABeforeBatchTransform_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>as a byproduct of the tokenization process in the 'encodes' method.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_QstAndAnsModelCallback'>HF_QstAndAnsModelCallback</h2><span id='topic+HF_QstAndAnsModelCallback'></span>

<h3>Description</h3>

<p>HF_QstAndAnsModelCallback
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_QstAndAnsModelCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_QstAndAnsModelCallback_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_QuestionAnswerInput'>HF_QuestionAnswerInput</h2><span id='topic+HF_QuestionAnswerInput'></span>

<h3>Description</h3>

<p>HF_QuestionAnswerInput
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_QuestionAnswerInput(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_QuestionAnswerInput_+3A_...">...</code></td>
<td>
<p>parameters to apss</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='hf_splitter'>Hf_splitter</h2><span id='topic+hf_splitter'></span>

<h3>Description</h3>

<p>Splits the huggingface model based on various model architecture conventions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hf_splitter(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hf_splitter_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_SummarizationBeforeBatchTransform'>HF_SummarizationBeforeBatchTransform</h2><span id='topic+HF_SummarizationBeforeBatchTransform'></span>

<h3>Description</h3>

<p>Handles everything you need to assemble a mini-batch of inputs and targets,
as well as decode the dictionary produced as a byproduct of the tokenization process in the 'encodes' method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_SummarizationBeforeBatchTransform(
  hf_arch,
  hf_tokenizer,
  max_length = NULL,
  padding = TRUE,
  truncation = TRUE,
  is_split_into_words = FALSE,
  n_tok_inps = 2,
  ignore_token_id = -100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_hf_arch">hf_arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_hf_tokenizer">hf_tokenizer</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_max_length">max_length</code></td>
<td>
<p>maximum length</p>
</td></tr>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_padding">padding</code></td>
<td>
<p>padding or not</p>
</td></tr>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_truncation">truncation</code></td>
<td>
<p>truncation or not</p>
</td></tr>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_is_split_into_words">is_split_into_words</code></td>
<td>
<p>to split into words</p>
</td></tr>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_n_tok_inps">n_tok_inps</code></td>
<td>
<p>number tok inputs</p>
</td></tr>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_ignore_token_id">ignore_token_id</code></td>
<td>
<p>ignore token id</p>
</td></tr>
<tr><td><code id="HF_SummarizationBeforeBatchTransform_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_SummarizationInput'>HF_SummarizationInput</h2><span id='topic+HF_SummarizationInput'></span>

<h3>Description</h3>

<p>HF_SummarizationInput
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_SummarizationInput()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_SummarizationModelCallback'>HF_SummarizationModelCallback</h2><span id='topic+HF_SummarizationModelCallback'></span>

<h3>Description</h3>

<p>Basic class handling tweaks of the training loop by changing a 'Learner' in various events
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_SummarizationModelCallback(
  rouge_metrics = c("rouge1", "rouge2", "rougeL"),
  ignore_token_id = -100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_SummarizationModelCallback_+3A_rouge_metrics">rouge_metrics</code></td>
<td>
<p>rouge metrics</p>
</td></tr>
<tr><td><code id="HF_SummarizationModelCallback_+3A_ignore_token_id">ignore_token_id</code></td>
<td>
<p>integer, ignore token id</p>
</td></tr>
<tr><td><code id="HF_SummarizationModelCallback_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_TASKS_ALL'>HF_TASKS_ALL</h2><span id='topic+HF_TASKS_ALL'></span>

<h3>Description</h3>

<p>An enumeration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_TASKS_ALL()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_TASKS_AUTO'>HF_TASKS_AUTO</h2><span id='topic+HF_TASKS_AUTO'></span>

<h3>Description</h3>

<p>An enumeration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_TASKS_AUTO()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_Text2TextAfterBatchTransform'>HF_Text2TextAfterBatchTransform</h2><span id='topic+HF_Text2TextAfterBatchTransform'></span>

<h3>Description</h3>

<p>Delegates ('__call__','decode','setup') to (&lt;code&gt;encodes&lt;/code&gt;,&lt;code&gt;decodes&lt;/code&gt;,&lt;code&gt;setups&lt;/code&gt;) if 'split_idx' matches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_Text2TextAfterBatchTransform(
  hf_tokenizer,
  input_return_type = HF_BaseInput()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_Text2TextAfterBatchTransform_+3A_hf_tokenizer">hf_tokenizer</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="HF_Text2TextAfterBatchTransform_+3A_input_return_type">input_return_type</code></td>
<td>
<p>input return type</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_Text2TextBlock'>HF_Text2TextBlock</h2><span id='topic+HF_Text2TextBlock'></span>

<h3>Description</h3>

<p>A basic wrapper that links defaults transforms for the data block API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_Text2TextBlock(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_Text2TextBlock_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_TextBlock'>HF_TextBlock</h2><span id='topic+HF_TextBlock'></span>

<h3>Description</h3>

<p>A basic wrapper that links defaults transforms for the data block API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_TextBlock(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_TextBlock_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_TokenCategorize'>HF_TokenCategorize</h2><span id='topic+HF_TokenCategorize'></span>

<h3>Description</h3>

<p>Reversible transform of a list of category string to 'vocab' id
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_TokenCategorize(vocab = NULL, ignore_token = NULL, ignore_token_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_TokenCategorize_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="HF_TokenCategorize_+3A_ignore_token">ignore_token</code></td>
<td>
<p>ignore token</p>
</td></tr>
<tr><td><code id="HF_TokenCategorize_+3A_ignore_token_id">ignore_token_id</code></td>
<td>
<p>ignore token id</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_TokenCategoryBlock'>HF_TokenCategoryBlock</h2><span id='topic+HF_TokenCategoryBlock'></span>

<h3>Description</h3>

<p>'TransformBlock' for single-label categorical targets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_TokenCategoryBlock(
  vocab = NULL,
  ignore_token = NULL,
  ignore_token_id = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_TokenCategoryBlock_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="HF_TokenCategoryBlock_+3A_ignore_token">ignore_token</code></td>
<td>
<p>ignore token</p>
</td></tr>
<tr><td><code id="HF_TokenCategoryBlock_+3A_ignore_token_id">ignore_token_id</code></td>
<td>
<p>ignore token id</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_TokenClassBeforeBatchTransform'>HF_TokenClassBeforeBatchTransform</h2><span id='topic+HF_TokenClassBeforeBatchTransform'></span>

<h3>Description</h3>

<p>Handles everything you need to assemble a mini-batch of inputs and targets,
as well as decode the dictionary produced
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_TokenClassBeforeBatchTransform(
  hf_arch,
  hf_tokenizer,
  ignore_token_id = -100,
  max_length = NULL,
  padding = TRUE,
  truncation = TRUE,
  is_split_into_words = TRUE,
  n_tok_inps = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_hf_arch">hf_arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_hf_tokenizer">hf_tokenizer</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_ignore_token_id">ignore_token_id</code></td>
<td>
<p>ignore token id</p>
</td></tr>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_max_length">max_length</code></td>
<td>
<p>maximum length</p>
</td></tr>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_padding">padding</code></td>
<td>
<p>padding or not</p>
</td></tr>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_truncation">truncation</code></td>
<td>
<p>truncation or not</p>
</td></tr>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_is_split_into_words">is_split_into_words</code></td>
<td>
<p>to split into_words</p>
</td></tr>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_n_tok_inps">n_tok_inps</code></td>
<td>
<p>number tok inputs</p>
</td></tr>
<tr><td><code id="HF_TokenClassBeforeBatchTransform_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>as a byproduct of the tokenization process in the 'encodes' method.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_TokenClassInput'>HF_TokenClassInput</h2><span id='topic+HF_TokenClassInput'></span>

<h3>Description</h3>

<p>HF_TokenClassInput
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_TokenClassInput()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HF_TokenTensorCategory'>HF_TokenTensorCategory</h2><span id='topic+HF_TokenTensorCategory'></span>

<h3>Description</h3>

<p>HF_TokenTensorCategory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HF_TokenTensorCategory()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Hook'>Hook</h2><span id='topic+Hook'></span>

<h3>Description</h3>

<p>Create a hook on 'm' with 'hook_func'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hook(
  m,
  hook_func,
  is_forward = TRUE,
  detach = TRUE,
  cpu = FALSE,
  gather = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hook_+3A_m">m</code></td>
<td>
<p>m aprameter</p>
</td></tr>
<tr><td><code id="Hook_+3A_hook_func">hook_func</code></td>
<td>
<p>hook function</p>
</td></tr>
<tr><td><code id="Hook_+3A_is_forward">is_forward</code></td>
<td>
<p>is_forward or not</p>
</td></tr>
<tr><td><code id="Hook_+3A_detach">detach</code></td>
<td>
<p>detach or not</p>
</td></tr>
<tr><td><code id="Hook_+3A_cpu">cpu</code></td>
<td>
<p>cpu or not</p>
</td></tr>
<tr><td><code id="Hook_+3A_gather">gather</code></td>
<td>
<p>gather or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hooks are functions you can attach to a particular layer in your
model and that will be executed in the forward pass (for forward hooks)
or backward pass (for backward hooks).
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='hook_output'>Hook_output</h2><span id='topic+hook_output'></span>

<h3>Description</h3>

<p>Return a 'Hook' that stores activations of 'module' in 'self$stored'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_output(module, detach = TRUE, cpu = FALSE, grad = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_output_+3A_module">module</code></td>
<td>
<p>module</p>
</td></tr>
<tr><td><code id="hook_output_+3A_detach">detach</code></td>
<td>
<p>detach or not</p>
</td></tr>
<tr><td><code id="hook_output_+3A_cpu">cpu</code></td>
<td>
<p>cpu or not</p>
</td></tr>
<tr><td><code id="hook_output_+3A_grad">grad</code></td>
<td>
<p>grad or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='hook_outputs'>Hook_outputs</h2><span id='topic+hook_outputs'></span>

<h3>Description</h3>

<p>Return 'Hooks' that store activations of all 'modules' in 'self.stored'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_outputs(modules, detach = TRUE, cpu = FALSE, grad = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_outputs_+3A_modules">modules</code></td>
<td>
<p>modules</p>
</td></tr>
<tr><td><code id="hook_outputs_+3A_detach">detach</code></td>
<td>
<p>detach or not</p>
</td></tr>
<tr><td><code id="hook_outputs_+3A_cpu">cpu</code></td>
<td>
<p>cpu or not</p>
</td></tr>
<tr><td><code id="hook_outputs_+3A_grad">grad</code></td>
<td>
<p>grad or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='HookCallback'>HookCallback</h2><span id='topic+HookCallback'></span>

<h3>Description</h3>

<p>'Callback' that can be used to register hooks on 'modules'
</p>
<p>'Callback' that can be used to register hooks on 'modules'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HookCallback(
  modules = NULL,
  every = NULL,
  remove_end = TRUE,
  is_forward = TRUE,
  detach = TRUE,
  cpu = TRUE
)

HookCallback(
  modules = NULL,
  every = NULL,
  remove_end = TRUE,
  is_forward = TRUE,
  detach = TRUE,
  cpu = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HookCallback_+3A_modules">modules</code></td>
<td>
<p>modules</p>
</td></tr>
<tr><td><code id="HookCallback_+3A_every">every</code></td>
<td>
<p>every</p>
</td></tr>
<tr><td><code id="HookCallback_+3A_remove_end">remove_end</code></td>
<td>
<p>remove_end or not</p>
</td></tr>
<tr><td><code id="HookCallback_+3A_is_forward">is_forward</code></td>
<td>
<p>is_forward or not</p>
</td></tr>
<tr><td><code id="HookCallback_+3A_detach">detach</code></td>
<td>
<p>detach or not</p>
</td></tr>
<tr><td><code id="HookCallback_+3A_cpu">cpu</code></td>
<td>
<p>cpu or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>

<hr>
<h2 id='Hooks'>Hooks</h2><span id='topic+Hooks'></span>

<h3>Description</h3>

<p>Create several hooks on the modules in 'ms' with 'hook_func'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hooks(ms, hook_func, is_forward = TRUE, detach = TRUE, cpu = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hooks_+3A_ms">ms</code></td>
<td>
<p>ms parameter</p>
</td></tr>
<tr><td><code id="Hooks_+3A_hook_func">hook_func</code></td>
<td>
<p>hook function</p>
</td></tr>
<tr><td><code id="Hooks_+3A_is_forward">is_forward</code></td>
<td>
<p>is_forward or not</p>
</td></tr>
<tr><td><code id="Hooks_+3A_detach">detach</code></td>
<td>
<p>detach or not</p>
</td></tr>
<tr><td><code id="Hooks_+3A_cpu">cpu</code></td>
<td>
<p>cpu or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='hsv2rgb'>Hsv2rgb</h2><span id='topic+hsv2rgb'></span>

<h3>Description</h3>

<p>Converts a HSV image to an RGB image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hsv2rgb(img)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hsv2rgb_+3A_img">img</code></td>
<td>
<p>image object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Hue'>Hue</h2><span id='topic+Hue'></span>

<h3>Description</h3>

<p>Apply change in hue of 'max_hue' to batch of images with probability 'p'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hue(max_hue = 0.1, p = 0.75, draw = NULL, batch = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hue_+3A_max_hue">max_hue</code></td>
<td>
<p>maximum hue</p>
</td></tr>
<tr><td><code id="Hue_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="Hue_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="Hue_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='hug'>Transformer module</h2><span id='topic+hug'></span>

<h3>Description</h3>

<p>Transformer module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hug()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision'>Icevision module</h2><span id='topic+icevision'></span>

<h3>Description</h3>

<p>Icevision module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_Adapter'>Adapter</h2><span id='topic+icevision_Adapter'></span>

<h3>Description</h3>

<p>Adapter that enables the use of albumentations transforms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Adapter(tfms)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Adapter_+3A_tfms">tfms</code></td>
<td>
<p>'Sequence' of albumentation transforms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_aug_tfms'>Aug_tfms</h2><span id='topic+icevision_aug_tfms'></span>

<h3>Description</h3>

<p>Collection of useful augmentation transforms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_aug_tfms(
  size,
  presize = NULL,
  horizontal_flip = icevision_HorizontalFlip(always_apply = FALSE, p = 0.5),
  shift_scale_rotate = icevision_ShiftScaleRotate(always_apply = FALSE, p = 0.5,
    shift_limit_x = c(-0.0625, 0.0625), shift_limit_y = c(-0.0625, 0.0625), scale_limit =
    c(-0.1, 0.1), rotate_limit = c(-45, 45), interpolation = 1, border_mode = 4, value =
    NULL, mask_value = NULL),
  rgb_shift = icevision_RGBShift(always_apply = FALSE, p = 0.5, r_shift_limit = c(-20,
    20), g_shift_limit = c(-20, 20), b_shift_limit = c(-20, 20)),
  lightning = icevision_RandomBrightnessContrast(always_apply = FALSE, p = 0.5,
    brightness_limit = c(-0.2, 0.2), contrast_limit = c(-0.2, 0.2), brightness_by_max =
    TRUE),
  blur = icevision_Blur(always_apply = FALSE, p = 0.5, blur_limit = c(1, 3)),
  crop_fn = partial(icevision_RandomSizedBBoxSafeCrop, p = 0.5),
  pad = partial(icevision_PadIfNeeded, border_mode = 0, value = list(124, 116, 104))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_aug_tfms_+3A_size">size</code></td>
<td>
<p>The final size of the image. If an 'int' is given, the maximum size of the image is rescaled, maintaing aspect ratio. If a 'list' is given, the image is rescaled to have that exact size (height, width).</p>
</td></tr>
<tr><td><code id="icevision_aug_tfms_+3A_presize">presize</code></td>
<td>
<p>presize</p>
</td></tr>
<tr><td><code id="icevision_aug_tfms_+3A_horizontal_flip">horizontal_flip</code></td>
<td>
<p>Flip around the y-axis. If 'NULL' this transform is not applied.</p>
</td></tr>
<tr><td><code id="icevision_aug_tfms_+3A_shift_scale_rotate">shift_scale_rotate</code></td>
<td>
<p>Randomly shift, scale, and rotate. If 'NULL' this transform is not applied.</p>
</td></tr>
<tr><td><code id="icevision_aug_tfms_+3A_rgb_shift">rgb_shift</code></td>
<td>
<p>Randomly shift values for each channel of RGB image. If 'NULL' this transform is not applied.</p>
</td></tr>
<tr><td><code id="icevision_aug_tfms_+3A_lightning">lightning</code></td>
<td>
<p>Randomly changes Brightness and Contrast. If 'NULL' this transform is not applied.</p>
</td></tr>
<tr><td><code id="icevision_aug_tfms_+3A_blur">blur</code></td>
<td>
<p>Randomly blur the image. If 'NULL' this transform is not applied.</p>
</td></tr>
<tr><td><code id="icevision_aug_tfms_+3A_crop_fn">crop_fn</code></td>
<td>
<p>Randomly crop the image. If 'NULL' this transform is not applied. Use 'partial' to saturate other parameters of the class.</p>
</td></tr>
<tr><td><code id="icevision_aug_tfms_+3A_pad">pad</code></td>
<td>
<p>Pad the image to 'size', squaring the image if 'size' is an 'int'. If 'NULL' this transform is not applied. Use 'partial' to sature other parameters of the class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_BasicIAATransform'>BasicIAATransform</h2><span id='topic+icevision_BasicIAATransform'></span>

<h3>Description</h3>

<p>BasicIAATransform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_BasicIAATransform(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_BasicIAATransform_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_BasicIAATransform_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_BasicTransform'>BasicTransform</h2><span id='topic+icevision_BasicTransform'></span>

<h3>Description</h3>

<p>BasicTransform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_BasicTransform(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_BasicTransform_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_BasicTransform_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_Blur'>Blur</h2><span id='topic+icevision_Blur'></span>

<h3>Description</h3>

<p>Blur the input image using a random-sized kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Blur(blur_limit = 7, always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Blur_+3A_blur_limit">blur_limit</code></td>
<td>
<p>blur_limit</p>
</td></tr>
<tr><td><code id="icevision_Blur_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Blur_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_ChannelDropout'>ChannelDropout</h2><span id='topic+icevision_ChannelDropout'></span>

<h3>Description</h3>

<p>Randomly Drop Channels in the input Image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ChannelDropout(
  channel_drop_range = list(1, 1),
  fill_value = 0,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ChannelDropout_+3A_channel_drop_range">channel_drop_range</code></td>
<td>
<p>channel_drop_range</p>
</td></tr>
<tr><td><code id="icevision_ChannelDropout_+3A_fill_value">fill_value</code></td>
<td>
<p>fill_value</p>
</td></tr>
<tr><td><code id="icevision_ChannelDropout_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ChannelDropout_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, uint16, unit32, float32
</p>

<hr>
<h2 id='icevision_ChannelShuffle'>ChannelShuffle</h2><span id='topic+icevision_ChannelShuffle'></span>

<h3>Description</h3>

<p>Randomly rearrange channels of the input RGB image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ChannelShuffle(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ChannelShuffle_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ChannelShuffle_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_CLAHE'>CLAHE</h2><span id='topic+icevision_CLAHE'></span>

<h3>Description</h3>

<p>Apply Contrast Limited Adaptive Histogram Equalization to the input image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_CLAHE(
  clip_limit = 4,
  tile_grid_size = list(8, 8),
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_CLAHE_+3A_clip_limit">clip_limit</code></td>
<td>
<p>clip_limit</p>
</td></tr>
<tr><td><code id="icevision_CLAHE_+3A_tile_grid_size">tile_grid_size</code></td>
<td>
<p>tile_grid_size</p>
</td></tr>
<tr><td><code id="icevision_CLAHE_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_CLAHE_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8
</p>

<hr>
<h2 id='icevision_ClassMap'>ClassMap</h2><span id='topic+icevision_ClassMap'></span>

<h3>Description</h3>

<p>Utility class for mapping between class name and id.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ClassMap(classes, background = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ClassMap_+3A_classes">classes</code></td>
<td>
<p>classes</p>
</td></tr>
<tr><td><code id="icevision_ClassMap_+3A_background">background</code></td>
<td>
<p>background</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Python dictionary
</p>

<hr>
<h2 id='icevision_CoarseDropout'>CoarseDropout</h2><span id='topic+icevision_CoarseDropout'></span>

<h3>Description</h3>

<p>CoarseDropout of the rectangular regions in the image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_CoarseDropout(
  max_holes = 8,
  max_height = 8,
  max_width = 8,
  min_holes = NULL,
  min_height = NULL,
  min_width = NULL,
  fill_value = 0,
  mask_fill_value = NULL,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_CoarseDropout_+3A_max_holes">max_holes</code></td>
<td>
<p>max_holes</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_max_height">max_height</code></td>
<td>
<p>max_height</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_max_width">max_width</code></td>
<td>
<p>max_width</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_min_holes">min_holes</code></td>
<td>
<p>min_holes</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_min_height">min_height</code></td>
<td>
<p>min_height</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_min_width">min_width</code></td>
<td>
<p>min_width</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_fill_value">fill_value</code></td>
<td>
<p>fill_value</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_mask_fill_value">mask_fill_value</code></td>
<td>
<p>mask_fill_value</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_CoarseDropout_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>


<h3>Reference</h3>

<p>| https://arxiv.org/abs/1708.04552 | https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py | https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.py
</p>

<hr>
<h2 id='icevision_ColorJitter'>ColorJitter</h2><span id='topic+icevision_ColorJitter'></span>

<h3>Description</h3>

<p>Randomly changes the brightness, contrast, and saturation of an image. Compared to ColorJitter from torchvision,
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ColorJitter(
  brightness = 0.2,
  contrast = 0.2,
  saturation = 0.2,
  hue = 0.2,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ColorJitter_+3A_brightness">brightness</code></td>
<td>
<p>brightness</p>
</td></tr>
<tr><td><code id="icevision_ColorJitter_+3A_contrast">contrast</code></td>
<td>
<p>contrast</p>
</td></tr>
<tr><td><code id="icevision_ColorJitter_+3A_saturation">saturation</code></td>
<td>
<p>saturation</p>
</td></tr>
<tr><td><code id="icevision_ColorJitter_+3A_hue">hue</code></td>
<td>
<p>hue</p>
</td></tr>
<tr><td><code id="icevision_ColorJitter_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ColorJitter_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>this transform gives a little bit different results because Pillow (used in torchvision) and OpenCV (used in
Albumentations) transform an image to HSV format by different formulas. Another difference - Pillow uses uint8
overflow, but we use value saturation.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_Compose'>Compose</h2><span id='topic+icevision_Compose'></span>

<h3>Description</h3>

<p>Compose transforms and handle all transformations regrading bounding boxes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Compose(
  transforms,
  bbox_params = NULL,
  keypoint_params = NULL,
  additional_targets = NULL,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Compose_+3A_transforms">transforms</code></td>
<td>
<p>transforms</p>
</td></tr>
<tr><td><code id="icevision_Compose_+3A_bbox_params">bbox_params</code></td>
<td>
<p>bbox_params</p>
</td></tr>
<tr><td><code id="icevision_Compose_+3A_keypoint_params">keypoint_params</code></td>
<td>
<p>keypoint_params</p>
</td></tr>
<tr><td><code id="icevision_Compose_+3A_additional_targets">additional_targets</code></td>
<td>
<p>additional_targets</p>
</td></tr>
<tr><td><code id="icevision_Compose_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_Crop'>Crop</h2><span id='topic+icevision_Crop'></span>

<h3>Description</h3>

<p>Crop region from image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Crop(
  x_min = 0,
  y_min = 0,
  x_max = 1024,
  y_max = 1024,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Crop_+3A_x_min">x_min</code></td>
<td>
<p>x_min</p>
</td></tr>
<tr><td><code id="icevision_Crop_+3A_y_min">y_min</code></td>
<td>
<p>y_min</p>
</td></tr>
<tr><td><code id="icevision_Crop_+3A_x_max">x_max</code></td>
<td>
<p>x_max</p>
</td></tr>
<tr><td><code id="icevision_Crop_+3A_y_max">y_max</code></td>
<td>
<p>y_max</p>
</td></tr>
<tr><td><code id="icevision_Crop_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Crop_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_CropNonEmptyMaskIfExists'>CropNonEmptyMaskIfExists</h2><span id='topic+icevision_CropNonEmptyMaskIfExists'></span>

<h3>Description</h3>

<p>Crop area with mask if mask is non-empty, else make random crop.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_CropNonEmptyMaskIfExists(
  height,
  width,
  ignore_values = NULL,
  ignore_channels = NULL,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_CropNonEmptyMaskIfExists_+3A_height">height</code></td>
<td>
<p>height</p>
</td></tr>
<tr><td><code id="icevision_CropNonEmptyMaskIfExists_+3A_width">width</code></td>
<td>
<p>width</p>
</td></tr>
<tr><td><code id="icevision_CropNonEmptyMaskIfExists_+3A_ignore_values">ignore_values</code></td>
<td>
<p>ignore_values</p>
</td></tr>
<tr><td><code id="icevision_CropNonEmptyMaskIfExists_+3A_ignore_channels">ignore_channels</code></td>
<td>
<p>ignore_channels</p>
</td></tr>
<tr><td><code id="icevision_CropNonEmptyMaskIfExists_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_CropNonEmptyMaskIfExists_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_Cutout'>Cutout</h2><span id='topic+icevision_Cutout'></span>

<h3>Description</h3>

<p>CoarseDropout of the square regions in the image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Cutout(
  num_holes = 8,
  max_h_size = 8,
  max_w_size = 8,
  fill_value = 0,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Cutout_+3A_num_holes">num_holes</code></td>
<td>
<p>num_holes</p>
</td></tr>
<tr><td><code id="icevision_Cutout_+3A_max_h_size">max_h_size</code></td>
<td>
<p>max_h_size</p>
</td></tr>
<tr><td><code id="icevision_Cutout_+3A_max_w_size">max_w_size</code></td>
<td>
<p>max_w_size</p>
</td></tr>
<tr><td><code id="icevision_Cutout_+3A_fill_value">fill_value</code></td>
<td>
<p>fill_value</p>
</td></tr>
<tr><td><code id="icevision_Cutout_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Cutout_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>


<h3>Reference</h3>

<p>| https://arxiv.org/abs/1708.04552 | https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py | https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.py
</p>

<hr>
<h2 id='icevision_Dataset'>Dataset</h2><span id='topic+icevision_Dataset'></span>

<h3>Description</h3>

<p>Container for a list of records and transforms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Dataset(records, tfm = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Dataset_+3A_records">records</code></td>
<td>
<p>A list of records.</p>
</td></tr>
<tr><td><code id="icevision_Dataset_+3A_tfm">tfm</code></td>
<td>
<p>Transforms to be applied to each item.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Steps each time an item is requested (normally via directly indexing the 'Dataset'):
Grab a record from the internal list of records.
Prepare the record (open the image, open the mask, add metadata).
Apply transforms to the record.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_Dataset_from_images'>Icevision Dataset from images</h2><span id='topic+icevision_Dataset_from_images'></span>

<h3>Description</h3>

<p>Creates a 'Dataset' from a list of images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Dataset_from_images(images, tfm = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Dataset_from_images_+3A_images">images</code></td>
<td>
<p>'Sequence' of images in memory (numpy arrays).</p>
</td></tr>
<tr><td><code id="icevision_Dataset_from_images_+3A_tfm">tfm</code></td>
<td>
<p>Transforms to be applied to each item.</p>
</td></tr>
<tr><td><code id="icevision_Dataset_from_images_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_Downscale'>Downscale</h2><span id='topic+icevision_Downscale'></span>

<h3>Description</h3>

<p>Decreases image quality by downscaling and upscaling back.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Downscale(
  scale_min = 0.25,
  scale_max = 0.25,
  interpolation = 0,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Downscale_+3A_scale_min">scale_min</code></td>
<td>
<p>scale_min</p>
</td></tr>
<tr><td><code id="icevision_Downscale_+3A_scale_max">scale_max</code></td>
<td>
<p>scale_max</p>
</td></tr>
<tr><td><code id="icevision_Downscale_+3A_interpolation">interpolation</code></td>
<td>
<p>cv2 interpolation method. cv2.INTER_NEAREST by default</p>
</td></tr>
<tr><td><code id="icevision_Downscale_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Downscale_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_DualIAATransform'>DualIAATransform</h2><span id='topic+icevision_DualIAATransform'></span>

<h3>Description</h3>

<p>Transform for segmentation task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_DualIAATransform(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_DualIAATransform_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_DualIAATransform_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_DualTransform'>DualTransform</h2><span id='topic+icevision_DualTransform'></span>

<h3>Description</h3>

<p>Transform for segmentation task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_DualTransform(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_DualTransform_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_DualTransform_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_ElasticTransform'>ElasticTransform</h2><span id='topic+icevision_ElasticTransform'></span>

<h3>Description</h3>

<p>Elastic deformation of images as described in [Simard2003]_ (with modifications).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ElasticTransform(
  alpha = 1,
  sigma = 50,
  alpha_affine = 50,
  interpolation = 1,
  border_mode = 4,
  value = NULL,
  mask_value = NULL,
  always_apply = FALSE,
  approximate = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ElasticTransform_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_sigma">sigma</code></td>
<td>
<p>sigma</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_alpha_affine">alpha_affine</code></td>
<td>
<p>alpha_affine</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_border_mode">border_mode</code></td>
<td>
<p>border_mode</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_value">value</code></td>
<td>
<p>value</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_mask_value">mask_value</code></td>
<td>
<p>mask_value</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_approximate">approximate</code></td>
<td>
<p>approximate</p>
</td></tr>
<tr><td><code id="icevision_ElasticTransform_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5 .. [Simard2003] Simard, Steinkraus and Platt, &quot;Best Practices for Convolutional Neural Networks applied to Visual Document Analysis&quot;, in Proc. of the International Conference on Document Analysis and Recognition, 2003.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_Equalize'>Equalize</h2><span id='topic+icevision_Equalize'></span>

<h3>Description</h3>

<p>Equalize the image histogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Equalize(mode = "cv", by_channels = TRUE, mask = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Equalize_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="icevision_Equalize_+3A_by_channels">by_channels</code></td>
<td>
<p>by_channels</p>
</td></tr>
<tr><td><code id="icevision_Equalize_+3A_mask">mask</code></td>
<td>
<p>mask</p>
</td></tr>
<tr><td><code id="icevision_Equalize_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8
</p>

<hr>
<h2 id='icevision_FancyPCA'>FancyPCA</h2><span id='topic+icevision_FancyPCA'></span>

<h3>Description</h3>

<p>Augment RGB image using FancyPCA from Krizhevsky's paper
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_FancyPCA(alpha = 0.1, always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_FancyPCA_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
<tr><td><code id="icevision_FancyPCA_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_FancyPCA_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;ImageNet Classification with Deep Convolutional Neural Networks&quot;
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>3-channel uint8 images only
</p>


<h3>Credit</h3>

<p>http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf https://deshanadesai.github.io/notes/Fancy-PCA-with-Scikit-Image https://pixelatedbrian.github.io/2018-04-29-fancy_pca/
</p>

<hr>
<h2 id='icevision_FDA'>FDA</h2><span id='topic+icevision_FDA'></span>

<h3>Description</h3>

<p>Fourier Domain Adaptation from https://github.com/YanchaoYang/FDA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_FDA(
  reference_images,
  beta_limit = 0.1,
  read_fn = icevision_read_rgb_image(),
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_FDA_+3A_reference_images">reference_images</code></td>
<td>
<p>reference_images</p>
</td></tr>
<tr><td><code id="icevision_FDA_+3A_beta_limit">beta_limit</code></td>
<td>
<p>beta_limit</p>
</td></tr>
<tr><td><code id="icevision_FDA_+3A_read_fn">read_fn</code></td>
<td>
<p>read_fn</p>
</td></tr>
<tr><td><code id="icevision_FDA_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_FDA_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simple &quot;style transfer&quot;.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Fourier Domain Adaptation from https</h3>

<p>//github.com/YanchaoYang/FDA:
Simple &quot;style transfer&quot;.
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>


<h3>Reference</h3>

<p>https://github.com/YanchaoYang/FDA https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_FDA_Fourier_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2020_paper.pdf
</p>


<h3>Example</h3>

<p>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import albumentations as A
&gt;&gt;&gt; image = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)
&gt;&gt;&gt; target_image = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)
&gt;&gt;&gt; aug = A.Compose([A.FDA([target_image], p=1, read_fn=lambda x: x)])
&gt;&gt;&gt; result = aug(image=image)
</p>

<hr>
<h2 id='icevision_FixedSplitter'>FixedSplitter</h2><span id='topic+icevision_FixedSplitter'></span>

<h3>Description</h3>

<p>Split 'ids' based on predefined splits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_FixedSplitter(splits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_FixedSplitter_+3A_splits">splits</code></td>
<td>
<p>The predefined splits.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_Flip'>Flip</h2><span id='topic+icevision_Flip'></span>

<h3>Description</h3>

<p>Flip the input either horizontally, vertically or both horizontally and vertically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Flip(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Flip_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Flip_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_FromFloat'>FromFloat</h2><span id='topic+icevision_FromFloat'></span>

<h3>Description</h3>

<p>Take an input array where all values should lie in the range [0, 1.0], multiply them by 'max_value' and then
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_FromFloat(
  dtype = "uint16",
  max_value = NULL,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_FromFloat_+3A_dtype">dtype</code></td>
<td>
<p>dtype</p>
</td></tr>
<tr><td><code id="icevision_FromFloat_+3A_max_value">max_value</code></td>
<td>
<p>max_value</p>
</td></tr>
<tr><td><code id="icevision_FromFloat_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_FromFloat_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>cast the resulted value to a type specified by 'dtype'. If 'max_value' is NULL the transform will try to infer
the maximum value for the data type from the 'dtype' argument. This is the inverse transform for :class:'~albumentations.augmentations.transforms.ToFloat'.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>float32
</p>

<hr>
<h2 id='icevision_GaussianBlur'>GaussianBlur</h2><span id='topic+icevision_GaussianBlur'></span>

<h3>Description</h3>

<p>Blur the input image using a Gaussian filter with a random kernel size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_GaussianBlur(
  blur_limit = list(3, 7),
  sigma_limit = 0,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_GaussianBlur_+3A_blur_limit">blur_limit</code></td>
<td>
<p>blur_limit</p>
</td></tr>
<tr><td><code id="icevision_GaussianBlur_+3A_sigma_limit">sigma_limit</code></td>
<td>
<p>sigma_limit</p>
</td></tr>
<tr><td><code id="icevision_GaussianBlur_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_GaussianBlur_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_GaussNoise'>GaussNoise</h2><span id='topic+icevision_GaussNoise'></span>

<h3>Description</h3>

<p>Apply gaussian noise to the input image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_GaussNoise(
  var_limit = list(10, 50),
  mean = 0,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_GaussNoise_+3A_var_limit">var_limit</code></td>
<td>
<p>var_limit</p>
</td></tr>
<tr><td><code id="icevision_GaussNoise_+3A_mean">mean</code></td>
<td>
<p>mean</p>
</td></tr>
<tr><td><code id="icevision_GaussNoise_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_GaussNoise_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_GlassBlur'>GlassBlur</h2><span id='topic+icevision_GlassBlur'></span>

<h3>Description</h3>

<p>Apply glass noise to the input image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_GlassBlur(
  sigma = 0.7,
  max_delta = 4,
  iterations = 2,
  always_apply = FALSE,
  mode = "fast",
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_GlassBlur_+3A_sigma">sigma</code></td>
<td>
<p>sigma</p>
</td></tr>
<tr><td><code id="icevision_GlassBlur_+3A_max_delta">max_delta</code></td>
<td>
<p>max_delta</p>
</td></tr>
<tr><td><code id="icevision_GlassBlur_+3A_iterations">iterations</code></td>
<td>
<p>iterations</p>
</td></tr>
<tr><td><code id="icevision_GlassBlur_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_GlassBlur_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="icevision_GlassBlur_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>


<h3>Reference</h3>

<p>| https://arxiv.org/abs/1903.12261 | https://github.com/hendrycks/robustness/blob/master/ImageNet-C/create_c/make_imagenet_c.py
</p>

<hr>
<h2 id='icevision_GridDistortion'>GridDistortion</h2><span id='topic+icevision_GridDistortion'></span>

<h3>Description</h3>

<p>Args:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_GridDistortion(
  num_steps = 5,
  distort_limit = 0.3,
  interpolation = 1,
  border_mode = 4,
  value = NULL,
  mask_value = NULL,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_GridDistortion_+3A_num_steps">num_steps</code></td>
<td>
<p>num_steps</p>
</td></tr>
<tr><td><code id="icevision_GridDistortion_+3A_distort_limit">distort_limit</code></td>
<td>
<p>distort_limit</p>
</td></tr>
<tr><td><code id="icevision_GridDistortion_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_GridDistortion_+3A_border_mode">border_mode</code></td>
<td>
<p>border_mode</p>
</td></tr>
<tr><td><code id="icevision_GridDistortion_+3A_value">value</code></td>
<td>
<p>value</p>
</td></tr>
<tr><td><code id="icevision_GridDistortion_+3A_mask_value">mask_value</code></td>
<td>
<p>mask_value</p>
</td></tr>
<tr><td><code id="icevision_GridDistortion_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_GridDistortion_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>num_steps (int): count of grid cells on each side. distort_limit (float, (float, float)): If distort_limit is a single float, the range will be (-distort_limit, distort_limit). Default: (-0.03, 0.03). interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. border_mode (OpenCV flag): flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT. mask_value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. Targets: image, mask Image types: uint8, float32
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_GridDropout'>GridDropout</h2><span id='topic+icevision_GridDropout'></span>

<h3>Description</h3>

<p>GridDropout, drops out rectangular regions of an image and the corresponding mask in a grid fashion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_GridDropout(
  ratio = 0.5,
  unit_size_min = NULL,
  unit_size_max = NULL,
  holes_number_x = NULL,
  holes_number_y = NULL,
  shift_x = 0,
  shift_y = 0,
  random_offset = FALSE,
  fill_value = 0,
  mask_fill_value = NULL,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_GridDropout_+3A_ratio">ratio</code></td>
<td>
<p>ratio</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_unit_size_min">unit_size_min</code></td>
<td>
<p>unit_size_min</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_unit_size_max">unit_size_max</code></td>
<td>
<p>unit_size_max</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_holes_number_x">holes_number_x</code></td>
<td>
<p>holes_number_x</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_holes_number_y">holes_number_y</code></td>
<td>
<p>holes_number_y</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_shift_x">shift_x</code></td>
<td>
<p>shift_x</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_shift_y">shift_y</code></td>
<td>
<p>shift_y</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_random_offset">random_offset</code></td>
<td>
<p>random_offset</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_fill_value">fill_value</code></td>
<td>
<p>fill_value</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_mask_fill_value">mask_fill_value</code></td>
<td>
<p>mask_fill_value</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_GridDropout_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>


<h3>References</h3>

<p>https://arxiv.org/abs/2001.04086
</p>

<hr>
<h2 id='icevision_HistogramMatching'>HistogramMatching</h2><span id='topic+icevision_HistogramMatching'></span>

<h3>Description</h3>

<p>Apply histogram matching. It manipulates the pixels of an input image so that its histogram matches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_HistogramMatching(
  reference_images,
  blend_ratio = list(0.5, 1),
  read_fn = icevision_read_rgb_image(),
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_HistogramMatching_+3A_reference_images">reference_images</code></td>
<td>
<p>reference_images</p>
</td></tr>
<tr><td><code id="icevision_HistogramMatching_+3A_blend_ratio">blend_ratio</code></td>
<td>
<p>blend_ratio</p>
</td></tr>
<tr><td><code id="icevision_HistogramMatching_+3A_read_fn">read_fn</code></td>
<td>
<p>read_fn</p>
</td></tr>
<tr><td><code id="icevision_HistogramMatching_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_HistogramMatching_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the histogram of the reference image. If the images have multiple channels, the matching is done independently
for each channel, as long as the number of channels is equal in the input image and the reference. Histogram matching can be used as a lightweight normalisation for image processing,
such as feature matching, especially in circumstances where the images have been taken from different
sources or in different conditions (i.e. lighting). See: https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_histogram_matching.html
</p>


<h3>Value</h3>

<p>None
</p>


<h3>See</h3>

<p>https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_histogram_matching.html
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, uint16, float32
</p>

<hr>
<h2 id='icevision_HorizontalFlip'>HorizontalFlip</h2><span id='topic+icevision_HorizontalFlip'></span>

<h3>Description</h3>

<p>Flip the input horizontally around the y-axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_HorizontalFlip(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_HorizontalFlip_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_HorizontalFlip_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_HueSaturationValue'>HueSaturationValue</h2><span id='topic+icevision_HueSaturationValue'></span>

<h3>Description</h3>

<p>Randomly change hue, saturation and value of the input image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_HueSaturationValue(
  hue_shift_limit = 20,
  sat_shift_limit = 30,
  val_shift_limit = 20,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_HueSaturationValue_+3A_hue_shift_limit">hue_shift_limit</code></td>
<td>
<p>hue_shift_limit</p>
</td></tr>
<tr><td><code id="icevision_HueSaturationValue_+3A_sat_shift_limit">sat_shift_limit</code></td>
<td>
<p>sat_shift_limit</p>
</td></tr>
<tr><td><code id="icevision_HueSaturationValue_+3A_val_shift_limit">val_shift_limit</code></td>
<td>
<p>val_shift_limit</p>
</td></tr>
<tr><td><code id="icevision_HueSaturationValue_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_HueSaturationValue_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_IAAAdditiveGaussianNoise'>IAAAdditiveGaussianNoise</h2><span id='topic+icevision_IAAAdditiveGaussianNoise'></span>

<h3>Description</h3>

<p>Add gaussian noise to the input image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAAAdditiveGaussianNoise(
  loc = 0,
  scale = list(2.55, 12.75),
  per_channel = FALSE,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAAAdditiveGaussianNoise_+3A_loc">loc</code></td>
<td>
<p>loc</p>
</td></tr>
<tr><td><code id="icevision_IAAAdditiveGaussianNoise_+3A_scale">scale</code></td>
<td>
<p>scale</p>
</td></tr>
<tr><td><code id="icevision_IAAAdditiveGaussianNoise_+3A_per_channel">per_channel</code></td>
<td>
<p>per_channel</p>
</td></tr>
<tr><td><code id="icevision_IAAAdditiveGaussianNoise_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAAAdditiveGaussianNoise_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>

<hr>
<h2 id='icevision_IAAAffine'>IAAAffine</h2><span id='topic+icevision_IAAAffine'></span>

<h3>Description</h3>

<p>Place a regular grid of points on the input and randomly move the neighbourhood of these point around
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAAAffine(
  scale = 1,
  translate_percent = NULL,
  translate_px = NULL,
  rotate = 0,
  shear = 0,
  order = 1,
  cval = 0,
  mode = "reflect",
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAAAffine_+3A_scale">scale</code></td>
<td>
<p>scale</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_translate_percent">translate_percent</code></td>
<td>
<p>translate_percent</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_translate_px">translate_px</code></td>
<td>
<p>translate_px</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_rotate">rotate</code></td>
<td>
<p>rotate</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_shear">shear</code></td>
<td>
<p>shear</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_order">order</code></td>
<td>
<p>order</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_cval">cval</code></td>
<td>
<p>cval</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAAAffine_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>via affine transformations. Note: This class introduce interpolation artifacts to mask if it has values other than 0;1
</p>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>

<hr>
<h2 id='icevision_IAACropAndPad'>IAACropAndPad</h2><span id='topic+icevision_IAACropAndPad'></span>

<h3>Description</h3>

<p>Transform for segmentation task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAACropAndPad(
  px = NULL,
  percent = NULL,
  pad_mode = "constant",
  pad_cval = 0,
  keep_size = TRUE,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAACropAndPad_+3A_px">px</code></td>
<td>
<p>px</p>
</td></tr>
<tr><td><code id="icevision_IAACropAndPad_+3A_percent">percent</code></td>
<td>
<p>percent</p>
</td></tr>
<tr><td><code id="icevision_IAACropAndPad_+3A_pad_mode">pad_mode</code></td>
<td>
<p>pad_mode</p>
</td></tr>
<tr><td><code id="icevision_IAACropAndPad_+3A_pad_cval">pad_cval</code></td>
<td>
<p>pad_cval</p>
</td></tr>
<tr><td><code id="icevision_IAACropAndPad_+3A_keep_size">keep_size</code></td>
<td>
<p>keep_size</p>
</td></tr>
<tr><td><code id="icevision_IAACropAndPad_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAACropAndPad_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>

<hr>
<h2 id='icevision_IAAEmboss'>IAAEmboss</h2><span id='topic+icevision_IAAEmboss'></span>

<h3>Description</h3>

<p>Emboss the input image and overlays the result with the original image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAAEmboss(
  alpha = list(0.2, 0.5),
  strength = list(0.2, 0.7),
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAAEmboss_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
<tr><td><code id="icevision_IAAEmboss_+3A_strength">strength</code></td>
<td>
<p>strength</p>
</td></tr>
<tr><td><code id="icevision_IAAEmboss_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAAEmboss_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>

<hr>
<h2 id='icevision_IAAFliplr'>IAAFliplr</h2><span id='topic+icevision_IAAFliplr'></span>

<h3>Description</h3>

<p>Transform for segmentation task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAAFliplr(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAAFliplr_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAAFliplr_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_IAAFlipud'>IAAFlipud</h2><span id='topic+icevision_IAAFlipud'></span>

<h3>Description</h3>

<p>Transform for segmentation task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAAFlipud(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAAFlipud_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAAFlipud_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_IAAPerspective'>IAAPerspective</h2><span id='topic+icevision_IAAPerspective'></span>

<h3>Description</h3>

<p>Perform a random four point perspective transform of the input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAAPerspective(
  scale = list(0.05, 0.1),
  keep_size = TRUE,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAAPerspective_+3A_scale">scale</code></td>
<td>
<p>scale</p>
</td></tr>
<tr><td><code id="icevision_IAAPerspective_+3A_keep_size">keep_size</code></td>
<td>
<p>keep_size</p>
</td></tr>
<tr><td><code id="icevision_IAAPerspective_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAAPerspective_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note: This class introduce interpolation artifacts to mask if it has values other than 0;1
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>

<hr>
<h2 id='icevision_IAAPiecewiseAffine'>IAAPiecewiseAffine</h2><span id='topic+icevision_IAAPiecewiseAffine'></span>

<h3>Description</h3>

<p>Place a regular grid of points on the input and randomly move the neighbourhood of these point around
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAAPiecewiseAffine(
  scale = list(0.03, 0.05),
  nb_rows = 4,
  nb_cols = 4,
  order = 1,
  cval = 0,
  mode = "constant",
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAAPiecewiseAffine_+3A_scale">scale</code></td>
<td>
<p>scale</p>
</td></tr>
<tr><td><code id="icevision_IAAPiecewiseAffine_+3A_nb_rows">nb_rows</code></td>
<td>
<p>nb_rows</p>
</td></tr>
<tr><td><code id="icevision_IAAPiecewiseAffine_+3A_nb_cols">nb_cols</code></td>
<td>
<p>nb_cols</p>
</td></tr>
<tr><td><code id="icevision_IAAPiecewiseAffine_+3A_order">order</code></td>
<td>
<p>order</p>
</td></tr>
<tr><td><code id="icevision_IAAPiecewiseAffine_+3A_cval">cval</code></td>
<td>
<p>cval</p>
</td></tr>
<tr><td><code id="icevision_IAAPiecewiseAffine_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="icevision_IAAPiecewiseAffine_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAAPiecewiseAffine_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>via affine transformations. Note: This class introduce interpolation artifacts to mask if it has values other than 0;1
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>

<hr>
<h2 id='icevision_IAASharpen'>IAASharpen</h2><span id='topic+icevision_IAASharpen'></span>

<h3>Description</h3>

<p>Sharpen the input image and overlays the result with the original image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAASharpen(
  alpha = list(0.2, 0.5),
  lightness = list(0.5, 1),
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAASharpen_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
<tr><td><code id="icevision_IAASharpen_+3A_lightness">lightness</code></td>
<td>
<p>lightness</p>
</td></tr>
<tr><td><code id="icevision_IAASharpen_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAASharpen_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>

<hr>
<h2 id='icevision_IAASuperpixels'>IAASuperpixels</h2><span id='topic+icevision_IAASuperpixels'></span>

<h3>Description</h3>

<p>Completely or partially transform the input image to its superpixel representation. Uses skimage's version
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_IAASuperpixels(
  p_replace = 0.1,
  n_segments = 100,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_IAASuperpixels_+3A_p_replace">p_replace</code></td>
<td>
<p>p_replace</p>
</td></tr>
<tr><td><code id="icevision_IAASuperpixels_+3A_n_segments">n_segments</code></td>
<td>
<p>n_segments</p>
</td></tr>
<tr><td><code id="icevision_IAASuperpixels_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_IAASuperpixels_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>of the SLIC algorithm. May be slow.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>

<hr>
<h2 id='icevision_ImageCompression'>ImageCompression</h2><span id='topic+icevision_ImageCompression'></span>

<h3>Description</h3>

<p>Decrease Jpeg, WebP compression of an image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ImageCompression(
  quality_lower = 99,
  quality_upper = 100,
  compression_type = 0,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ImageCompression_+3A_quality_lower">quality_lower</code></td>
<td>
<p>quality_lower</p>
</td></tr>
<tr><td><code id="icevision_ImageCompression_+3A_quality_upper">quality_upper</code></td>
<td>
<p>quality_upper</p>
</td></tr>
<tr><td><code id="icevision_ImageCompression_+3A_compression_type">compression_type</code></td>
<td>
<p>compression_type</p>
</td></tr>
<tr><td><code id="icevision_ImageCompression_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ImageCompression_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_ImageOnlyIAATransform'>ImageOnlyIAATransform</h2><span id='topic+icevision_ImageOnlyIAATransform'></span>

<h3>Description</h3>

<p>Transform applied to image only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ImageOnlyIAATransform(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ImageOnlyIAATransform_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ImageOnlyIAATransform_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_ImageOnlyTransform'>ImageOnlyTransform</h2><span id='topic+icevision_ImageOnlyTransform'></span>

<h3>Description</h3>

<p>Transform applied to image only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ImageOnlyTransform(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ImageOnlyTransform_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ImageOnlyTransform_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_InvertImg'>InvertImg</h2><span id='topic+icevision_InvertImg'></span>

<h3>Description</h3>

<p>Invert the input image by subtracting pixel values from 255.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_InvertImg(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_InvertImg_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_InvertImg_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8
</p>

<hr>
<h2 id='icevision_ISONoise'>ISONoise</h2><span id='topic+icevision_ISONoise'></span>

<h3>Description</h3>

<p>Apply camera sensor noise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ISONoise(
  color_shift = list(0.01, 0.05),
  intensity = list(0.1, 0.5),
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ISONoise_+3A_color_shift">color_shift</code></td>
<td>
<p>color_shift</p>
</td></tr>
<tr><td><code id="icevision_ISONoise_+3A_intensity">intensity</code></td>
<td>
<p>intensity</p>
</td></tr>
<tr><td><code id="icevision_ISONoise_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ISONoise_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8
</p>

<hr>
<h2 id='icevision_JpegCompression'>JpegCompression</h2><span id='topic+icevision_JpegCompression'></span>

<h3>Description</h3>

<p>Decrease Jpeg compression of an image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_JpegCompression(
  quality_lower = 99,
  quality_upper = 100,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_JpegCompression_+3A_quality_lower">quality_lower</code></td>
<td>
<p>quality_lower</p>
</td></tr>
<tr><td><code id="icevision_JpegCompression_+3A_quality_upper">quality_upper</code></td>
<td>
<p>quality_upper</p>
</td></tr>
<tr><td><code id="icevision_JpegCompression_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_JpegCompression_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_LongestMaxSize'>LongestMaxSize</h2><span id='topic+icevision_LongestMaxSize'></span>

<h3>Description</h3>

<p>Rescale an image so that maximum side is equal to max_size, keeping the aspect ratio of the initial image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_LongestMaxSize(
  max_size = 1024,
  interpolation = 1,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_LongestMaxSize_+3A_max_size">max_size</code></td>
<td>
<p>max_size</p>
</td></tr>
<tr><td><code id="icevision_LongestMaxSize_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_LongestMaxSize_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_LongestMaxSize_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_MaskDropout'>MaskDropout</h2><span id='topic+icevision_MaskDropout'></span>

<h3>Description</h3>

<p>Image &amp; mask augmentation that zero out mask and image regions corresponding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_MaskDropout(
  max_objects = 1,
  image_fill_value = 0,
  mask_fill_value = 0,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_MaskDropout_+3A_max_objects">max_objects</code></td>
<td>
<p>max_objects</p>
</td></tr>
<tr><td><code id="icevision_MaskDropout_+3A_image_fill_value">image_fill_value</code></td>
<td>
<p>image_fill_value</p>
</td></tr>
<tr><td><code id="icevision_MaskDropout_+3A_mask_fill_value">mask_fill_value</code></td>
<td>
<p>mask_fill_value</p>
</td></tr>
<tr><td><code id="icevision_MaskDropout_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_MaskDropout_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>to randomly chosen object instance from mask. Mask must be single-channel image, zero values treated as background.
Image can be any number of channels. Inspired by https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/114254
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_MedianBlur'>MedianBlur</h2><span id='topic+icevision_MedianBlur'></span>

<h3>Description</h3>

<p>Blur the input image using a median filter with a random aperture linear size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_MedianBlur(blur_limit = 7, always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_MedianBlur_+3A_blur_limit">blur_limit</code></td>
<td>
<p>blur_limit</p>
</td></tr>
<tr><td><code id="icevision_MedianBlur_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_MedianBlur_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_MotionBlur'>MotionBlur</h2><span id='topic+icevision_MotionBlur'></span>

<h3>Description</h3>

<p>Apply motion blur to the input image using a random-sized kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_MotionBlur(blur_limit = 7, always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_MotionBlur_+3A_blur_limit">blur_limit</code></td>
<td>
<p>blur_limit</p>
</td></tr>
<tr><td><code id="icevision_MotionBlur_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_MotionBlur_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_MultiplicativeNoise'>MultiplicativeNoise</h2><span id='topic+icevision_MultiplicativeNoise'></span>

<h3>Description</h3>

<p>Multiply image to random number or array of numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_MultiplicativeNoise(
  multiplier = list(0.9, 1.1),
  per_channel = FALSE,
  elementwise = FALSE,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_MultiplicativeNoise_+3A_multiplier">multiplier</code></td>
<td>
<p>multiplier</p>
</td></tr>
<tr><td><code id="icevision_MultiplicativeNoise_+3A_per_channel">per_channel</code></td>
<td>
<p>per_channel</p>
</td></tr>
<tr><td><code id="icevision_MultiplicativeNoise_+3A_elementwise">elementwise</code></td>
<td>
<p>elementwise</p>
</td></tr>
<tr><td><code id="icevision_MultiplicativeNoise_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_MultiplicativeNoise_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>Any
</p>

<hr>
<h2 id='icevision_Normalize'>Normalize</h2><span id='topic+icevision_Normalize'></span>

<h3>Description</h3>

<p>Divide pixel values by 255 = 2**8 - 1, subtract mean per channel and divide by std per channel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Normalize(
  mean = list(0.485, 0.456, 0.406),
  std = list(0.229, 0.224, 0.225),
  max_pixel_value = 255,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Normalize_+3A_mean">mean</code></td>
<td>
<p>mean</p>
</td></tr>
<tr><td><code id="icevision_Normalize_+3A_std">std</code></td>
<td>
<p>std</p>
</td></tr>
<tr><td><code id="icevision_Normalize_+3A_max_pixel_value">max_pixel_value</code></td>
<td>
<p>max_pixel_value</p>
</td></tr>
<tr><td><code id="icevision_Normalize_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Normalize_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_OpticalDistortion'>OpticalDistortion</h2><span id='topic+icevision_OpticalDistortion'></span>

<h3>Description</h3>

<p>OpticalDistortion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_OpticalDistortion(
  distort_limit = 0.05,
  shift_limit = 0.05,
  interpolation = 1,
  border_mode = 4,
  value = NULL,
  mask_value = NULL,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_OpticalDistortion_+3A_distort_limit">distort_limit</code></td>
<td>
<p>distort_limit</p>
</td></tr>
<tr><td><code id="icevision_OpticalDistortion_+3A_shift_limit">shift_limit</code></td>
<td>
<p>shift_limit</p>
</td></tr>
<tr><td><code id="icevision_OpticalDistortion_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_OpticalDistortion_+3A_border_mode">border_mode</code></td>
<td>
<p>border_mode</p>
</td></tr>
<tr><td><code id="icevision_OpticalDistortion_+3A_value">value</code></td>
<td>
<p>value</p>
</td></tr>
<tr><td><code id="icevision_OpticalDistortion_+3A_mask_value">mask_value</code></td>
<td>
<p>mask_value</p>
</td></tr>
<tr><td><code id="icevision_OpticalDistortion_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_OpticalDistortion_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>distort_limit (float, (float, float)): If distort_limit is a single float, the range will be (-distort_limit, distort_limit). Default: (-0.05, 0.05). shift_limit (float, (float, float))): If shift_limit is a single float, the range will be (-shift_limit, shift_limit). Default: (-0.05, 0.05). interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. border_mode (OpenCV flag): flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT. mask_value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. Targets: image, mask Image types: uint8, float32
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_PadIfNeeded'>PadIfNeeded</h2><span id='topic+icevision_PadIfNeeded'></span>

<h3>Description</h3>

<p>Pad side of the image / max if side is less than desired number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_PadIfNeeded(
  min_height = 1024,
  min_width = 1024,
  pad_height_divisor = NULL,
  pad_width_divisor = NULL,
  border_mode = 4,
  value = NULL,
  mask_value = NULL,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_PadIfNeeded_+3A_min_height">min_height</code></td>
<td>
<p>min_height</p>
</td></tr>
<tr><td><code id="icevision_PadIfNeeded_+3A_min_width">min_width</code></td>
<td>
<p>min_width</p>
</td></tr>
<tr><td><code id="icevision_PadIfNeeded_+3A_pad_height_divisor">pad_height_divisor</code></td>
<td>
<p>pad_height_divisor</p>
</td></tr>
<tr><td><code id="icevision_PadIfNeeded_+3A_pad_width_divisor">pad_width_divisor</code></td>
<td>
<p>pad_width_divisor</p>
</td></tr>
<tr><td><code id="icevision_PadIfNeeded_+3A_border_mode">border_mode</code></td>
<td>
<p>border_mode</p>
</td></tr>
<tr><td><code id="icevision_PadIfNeeded_+3A_value">value</code></td>
<td>
<p>value</p>
</td></tr>
<tr><td><code id="icevision_PadIfNeeded_+3A_mask_value">mask_value</code></td>
<td>
<p>mask_value</p>
</td></tr>
<tr><td><code id="icevision_PadIfNeeded_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_PadIfNeeded_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Targets</h3>

<p>image, mask, bbox, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_parse'>Parse</h2><span id='topic+icevision_parse'></span>

<h3>Description</h3>

<p>Loops through all data points parsing the required fields.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_parse(
  data_splitter = NULL,
  idmap = NULL,
  autofix = TRUE,
  show_pbar = TRUE,
  cache_filepath = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_parse_+3A_data_splitter">data_splitter</code></td>
<td>
<p>How to split the parsed data, defaults to a [0.8, 0.2] random split.</p>
</td></tr>
<tr><td><code id="icevision_parse_+3A_idmap">idmap</code></td>
<td>
<p>Maps from filenames to unique ids, pass an 'IDMap()' if you need this information.</p>
</td></tr>
<tr><td><code id="icevision_parse_+3A_autofix">autofix</code></td>
<td>
<p>autofix</p>
</td></tr>
<tr><td><code id="icevision_parse_+3A_show_pbar">show_pbar</code></td>
<td>
<p>Whether or not to show a progress bar while parsing the data.</p>
</td></tr>
<tr><td><code id="icevision_parse_+3A_cache_filepath">cache_filepath</code></td>
<td>
<p>Path to save records in pickle format. Defaults to NULL, e.g. if the user does not specify a path, no saving nor loading happens.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of records for each split defined by data_splitter.
</p>

<hr>
<h2 id='icevision_Posterize'>Posterize</h2><span id='topic+icevision_Posterize'></span>

<h3>Description</h3>

<p>Reduce the number of bits for each color channel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Posterize(num_bits = 4, always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Posterize_+3A_num_bits">num_bits</code></td>
<td>
<p>num_bits</p>
</td></tr>
<tr><td><code id="icevision_Posterize_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Posterize_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8
</p>

<hr>
<h2 id='icevision_RandomBrightnessContrast'>RandomBrightnessContrast</h2><span id='topic+icevision_RandomBrightnessContrast'></span>

<h3>Description</h3>

<p>Randomly change brightness and contrast of the input image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomBrightnessContrast(
  brightness_limit = 0.2,
  contrast_limit = 0.2,
  brightness_by_max = TRUE,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomBrightnessContrast_+3A_brightness_limit">brightness_limit</code></td>
<td>
<p>brightness_limit</p>
</td></tr>
<tr><td><code id="icevision_RandomBrightnessContrast_+3A_contrast_limit">contrast_limit</code></td>
<td>
<p>contrast_limit</p>
</td></tr>
<tr><td><code id="icevision_RandomBrightnessContrast_+3A_brightness_by_max">brightness_by_max</code></td>
<td>
<p>brightness_by_max</p>
</td></tr>
<tr><td><code id="icevision_RandomBrightnessContrast_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomBrightnessContrast_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomContrast'>RandomContrast</h2><span id='topic+icevision_RandomContrast'></span>

<h3>Description</h3>

<p>Randomly change contrast of the input image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomContrast(limit = 0.2, always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomContrast_+3A_limit">limit</code></td>
<td>
<p>limit</p>
</td></tr>
<tr><td><code id="icevision_RandomContrast_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomContrast_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomCrop'>RandomCrop</h2><span id='topic+icevision_RandomCrop'></span>

<h3>Description</h3>

<p>Crop a random part of the input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomCrop(height, width, always_apply = FALSE, p = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomCrop_+3A_height">height</code></td>
<td>
<p>height</p>
</td></tr>
<tr><td><code id="icevision_RandomCrop_+3A_width">width</code></td>
<td>
<p>width</p>
</td></tr>
<tr><td><code id="icevision_RandomCrop_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomCrop_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomCropNearBBox'>RandomCropNearBBox</h2><span id='topic+icevision_RandomCropNearBBox'></span>

<h3>Description</h3>

<p>Crop bbox from image with random shift by x,y coordinates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomCropNearBBox(max_part_shift = 0.3, always_apply = FALSE, p = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomCropNearBBox_+3A_max_part_shift">max_part_shift</code></td>
<td>
<p>max_part_shift</p>
</td></tr>
<tr><td><code id="icevision_RandomCropNearBBox_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomCropNearBBox_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomFog'>RandomFog</h2><span id='topic+icevision_RandomFog'></span>

<h3>Description</h3>

<p>Simulates fog for the image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomFog(
  fog_coef_lower = 0.3,
  fog_coef_upper = 1,
  alpha_coef = 0.08,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomFog_+3A_fog_coef_lower">fog_coef_lower</code></td>
<td>
<p>fog_coef_lower</p>
</td></tr>
<tr><td><code id="icevision_RandomFog_+3A_fog_coef_upper">fog_coef_upper</code></td>
<td>
<p>fog_coef_upper</p>
</td></tr>
<tr><td><code id="icevision_RandomFog_+3A_alpha_coef">alpha_coef</code></td>
<td>
<p>alpha_coef</p>
</td></tr>
<tr><td><code id="icevision_RandomFog_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomFog_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From https://github.com/UjjwalSaxena/Automold&ndash;Road-Augmentation-Library
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomGamma'>RandomGamma</h2><span id='topic+icevision_RandomGamma'></span>

<h3>Description</h3>

<p>RandomGamma
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomGamma(
  gamma_limit = list(80, 120),
  eps = NULL,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomGamma_+3A_gamma_limit">gamma_limit</code></td>
<td>
<p>gamma_limit</p>
</td></tr>
<tr><td><code id="icevision_RandomGamma_+3A_eps">eps</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="icevision_RandomGamma_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomGamma_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>gamma_limit (float or (float, float)): If gamma_limit is a single float value, the range will be (-gamma_limit, gamma_limit). Default: (80, 120). eps: Deprecated. Targets: image Image types: uint8, float32
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomGridShuffle'>RandomGridShuffle</h2><span id='topic+icevision_RandomGridShuffle'></span>

<h3>Description</h3>

<p>Random shuffle grid's cells on image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomGridShuffle(grid = list(3, 3), always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomGridShuffle_+3A_grid">grid</code></td>
<td>
<p>grid</p>
</td></tr>
<tr><td><code id="icevision_RandomGridShuffle_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomGridShuffle_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomRain'>RandomRain</h2><span id='topic+icevision_RandomRain'></span>

<h3>Description</h3>

<p>Adds rain effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomRain(
  slant_lower = -10,
  slant_upper = 10,
  drop_length = 20,
  drop_width = 1,
  drop_color = list(200, 200, 200),
  blur_value = 7,
  brightness_coefficient = 0.7,
  rain_type = NULL,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomRain_+3A_slant_lower">slant_lower</code></td>
<td>
<p>should be in range [-20, 20].</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_slant_upper">slant_upper</code></td>
<td>
<p>should be in range [-20, 20].</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_drop_length">drop_length</code></td>
<td>
<p>should be in range [0, 100].</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_drop_width">drop_width</code></td>
<td>
<p>should be in range [1, 5]. drop_color (list of (r, g, b)): rain lines color. blur_value (int): rainy view are blurry brightness_coefficient (float): rainy days are usually shady. Should be in range [0, 1].</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_drop_color">drop_color</code></td>
<td>
<p>drop_color</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_blur_value">blur_value</code></td>
<td>
<p>blur_value</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_brightness_coefficient">brightness_coefficient</code></td>
<td>
<p>brightness_coefficient</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_rain_type">rain_type</code></td>
<td>
<p>One of [NULL, &quot;drizzle&quot;, &quot;heavy&quot;, &quot;torrestial&quot;]</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomRain_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From https://github.com/UjjwalSaxena/Automold&ndash;Road-Augmentation-Library
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomResizedCrop'>RandomResizedCrop</h2><span id='topic+icevision_RandomResizedCrop'></span>

<h3>Description</h3>

<p>Torchvision's variant of crop a random part of the input and rescale it to some size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomResizedCrop(
  height,
  width,
  scale = list(0.08, 1),
  ratio = list(0.75, 1.33333333333333),
  interpolation = 1,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomResizedCrop_+3A_height">height</code></td>
<td>
<p>height</p>
</td></tr>
<tr><td><code id="icevision_RandomResizedCrop_+3A_width">width</code></td>
<td>
<p>width</p>
</td></tr>
<tr><td><code id="icevision_RandomResizedCrop_+3A_scale">scale</code></td>
<td>
<p>scale</p>
</td></tr>
<tr><td><code id="icevision_RandomResizedCrop_+3A_ratio">ratio</code></td>
<td>
<p>ratio</p>
</td></tr>
<tr><td><code id="icevision_RandomResizedCrop_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_RandomResizedCrop_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomResizedCrop_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomRotate90'>RandomRotate90</h2><span id='topic+icevision_RandomRotate90'></span>

<h3>Description</h3>

<p>Randomly rotate the input by 90 degrees zero or more times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomRotate90(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomRotate90_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomRotate90_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomScale'>RandomScale</h2><span id='topic+icevision_RandomScale'></span>

<h3>Description</h3>

<p>Randomly resize the input. Output image size is different from the input image size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomScale(
  scale_limit = 0.1,
  interpolation = 1L,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomScale_+3A_scale_limit">scale_limit</code></td>
<td>
<p>scale_limit</p>
</td></tr>
<tr><td><code id="icevision_RandomScale_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_RandomScale_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomScale_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomShadow'>RandomShadow</h2><span id='topic+icevision_RandomShadow'></span>

<h3>Description</h3>

<p>Simulates shadows for the image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomShadow(
  shadow_roi = list(0, 0.5, 1, 1),
  num_shadows_lower = 1,
  num_shadows_upper = 2,
  shadow_dimension = 5,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomShadow_+3A_shadow_roi">shadow_roi</code></td>
<td>
<p>shadow_roi</p>
</td></tr>
<tr><td><code id="icevision_RandomShadow_+3A_num_shadows_lower">num_shadows_lower</code></td>
<td>
<p>num_shadows_lower</p>
</td></tr>
<tr><td><code id="icevision_RandomShadow_+3A_num_shadows_upper">num_shadows_upper</code></td>
<td>
<p>num_shadows_upper</p>
</td></tr>
<tr><td><code id="icevision_RandomShadow_+3A_shadow_dimension">shadow_dimension</code></td>
<td>
<p>shadow_dimension</p>
</td></tr>
<tr><td><code id="icevision_RandomShadow_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomShadow_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From https://github.com/UjjwalSaxena/Automold&ndash;Road-Augmentation-Library
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomSizedBBoxSafeCrop'>RandomSizedBBoxSafeCrop</h2><span id='topic+icevision_RandomSizedBBoxSafeCrop'></span>

<h3>Description</h3>

<p>Crop a random part of the input and rescale it to some size without loss of bboxes.
</p>
<p>Crop a random part of the input and rescale it to some size without loss of bboxes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomSizedBBoxSafeCrop(
  height,
  width,
  erosion_rate = 0,
  interpolation = 1,
  always_apply = FALSE,
  p = 1
)

icevision_RandomSizedBBoxSafeCrop(
  height,
  width,
  erosion_rate = 0,
  interpolation = 1,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomSizedBBoxSafeCrop_+3A_height">height</code></td>
<td>
<p>height</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedBBoxSafeCrop_+3A_width">width</code></td>
<td>
<p>width</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedBBoxSafeCrop_+3A_erosion_rate">erosion_rate</code></td>
<td>
<p>erosion_rate</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedBBoxSafeCrop_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedBBoxSafeCrop_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedBBoxSafeCrop_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes
</p>
<p>image, mask, bboxes
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>
<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomSizedCrop'>RandomSizedCrop</h2><span id='topic+icevision_RandomSizedCrop'></span>

<h3>Description</h3>

<p>Crop a random part of the input and rescale it to some size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomSizedCrop(
  min_max_height,
  height,
  width,
  w2h_ratio = 1,
  interpolation = 1,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomSizedCrop_+3A_min_max_height">min_max_height</code></td>
<td>
<p>min_max_height</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedCrop_+3A_height">height</code></td>
<td>
<p>height</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedCrop_+3A_width">width</code></td>
<td>
<p>width</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedCrop_+3A_w2h_ratio">w2h_ratio</code></td>
<td>
<p>w2h_ratio</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedCrop_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedCrop_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomSizedCrop_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomSnow'>RandomSnow</h2><span id='topic+icevision_RandomSnow'></span>

<h3>Description</h3>

<p>Bleach out some pixel values simulating snow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomSnow(
  snow_point_lower = 0.1,
  snow_point_upper = 0.3,
  brightness_coeff = 2.5,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomSnow_+3A_snow_point_lower">snow_point_lower</code></td>
<td>
<p>snow_point_lower</p>
</td></tr>
<tr><td><code id="icevision_RandomSnow_+3A_snow_point_upper">snow_point_upper</code></td>
<td>
<p>snow_point_upper</p>
</td></tr>
<tr><td><code id="icevision_RandomSnow_+3A_brightness_coeff">brightness_coeff</code></td>
<td>
<p>brightness_coeff</p>
</td></tr>
<tr><td><code id="icevision_RandomSnow_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomSnow_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From https://github.com/UjjwalSaxena/Automold&ndash;Road-Augmentation-Library
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_RandomSplitter'>RandomSplitter</h2><span id='topic+icevision_RandomSplitter'></span>

<h3>Description</h3>

<p>Randomly splits items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomSplitter(probs, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomSplitter_+3A_probs">probs</code></td>
<td>
<p>'Sequence' of probabilities that must sum to one. The length of
the 'Sequence' is the number of groups to to split the items into.</p>
</td></tr>
<tr><td><code id="icevision_RandomSplitter_+3A_seed">seed</code></td>
<td>
<p>Internal seed used for shuffling the items. Define this if you need reproducible results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_RandomSunFlare'>RandomSunFlare</h2><span id='topic+icevision_RandomSunFlare'></span>

<h3>Description</h3>

<p>Simulates Sun Flare for the image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RandomSunFlare(
  flare_roi = list(0, 0, 1, 0.5),
  angle_lower = 0,
  angle_upper = 1,
  num_flare_circles_lower = 6,
  num_flare_circles_upper = 10,
  src_radius = 400,
  src_color = list(255, 255, 255),
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RandomSunFlare_+3A_flare_roi">flare_roi</code></td>
<td>
<p>flare_roi</p>
</td></tr>
<tr><td><code id="icevision_RandomSunFlare_+3A_angle_lower">angle_lower</code></td>
<td>
<p>angle_lower</p>
</td></tr>
<tr><td><code id="icevision_RandomSunFlare_+3A_angle_upper">angle_upper</code></td>
<td>
<p>angle_upper</p>
</td></tr>
<tr><td><code id="icevision_RandomSunFlare_+3A_num_flare_circles_lower">num_flare_circles_lower</code></td>
<td>
<p>num_flare_circles_lower</p>
</td></tr>
<tr><td><code id="icevision_RandomSunFlare_+3A_num_flare_circles_upper">num_flare_circles_upper</code></td>
<td>
<p>num_flare_circles_upper</p>
</td></tr>
<tr><td><code id="icevision_RandomSunFlare_+3A_src_radius">src_radius</code></td>
<td>
<p>src_radius</p>
</td></tr>
<tr><td><code id="icevision_RandomSunFlare_+3A_src_color">src_color</code></td>
<td>
<p>src_color</p>
</td></tr>
<tr><td><code id="icevision_RandomSunFlare_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RandomSunFlare_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From https://github.com/UjjwalSaxena/Automold&ndash;Road-Augmentation-Library
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_read_bgr_image'>Read_bgr_image</h2><span id='topic+icevision_read_bgr_image'></span>

<h3>Description</h3>

<p>Read_bgr_image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_read_bgr_image(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_read_bgr_image_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_read_rgb_image'>Read_rgb_image</h2><span id='topic+icevision_read_rgb_image'></span>

<h3>Description</h3>

<p>Read_rgb_image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_read_rgb_image(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_read_rgb_image_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_Resize'>Resize</h2><span id='topic+icevision_Resize'></span>

<h3>Description</h3>

<p>Resize the input to the given height and width.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Resize(height, width, interpolation = 1, always_apply = FALSE, p = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Resize_+3A_height">height</code></td>
<td>
<p>height</p>
</td></tr>
<tr><td><code id="icevision_Resize_+3A_width">width</code></td>
<td>
<p>width</p>
</td></tr>
<tr><td><code id="icevision_Resize_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_Resize_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Resize_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_resize_and_pad'>Resize_and_pad</h2><span id='topic+icevision_resize_and_pad'></span>

<h3>Description</h3>

<p>Resize_and_pad
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_resize_and_pad(
  size,
  pad = partial(icevision_PadIfNeeded, border_mode = 0, value = c(124L, 116L, 104L))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_resize_and_pad_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="icevision_resize_and_pad_+3A_pad">pad</code></td>
<td>
<p>pad</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='icevision_RGBShift'>RGBShift</h2><span id='topic+icevision_RGBShift'></span>

<h3>Description</h3>

<p>Randomly shift values for each channel of the input RGB image.
</p>
<p>Randomly shift values for each channel of the input RGB image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_RGBShift(
  r_shift_limit = 20,
  g_shift_limit = 20,
  b_shift_limit = 20,
  always_apply = FALSE,
  p = 0.5
)

icevision_RGBShift(
  r_shift_limit = 20,
  g_shift_limit = 20,
  b_shift_limit = 20,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_RGBShift_+3A_r_shift_limit">r_shift_limit</code></td>
<td>
<p>r_shift_limit</p>
</td></tr>
<tr><td><code id="icevision_RGBShift_+3A_g_shift_limit">g_shift_limit</code></td>
<td>
<p>g_shift_limit</p>
</td></tr>
<tr><td><code id="icevision_RGBShift_+3A_b_shift_limit">b_shift_limit</code></td>
<td>
<p>b_shift_limit</p>
</td></tr>
<tr><td><code id="icevision_RGBShift_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_RGBShift_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>


<h3>Targets</h3>

<p>image
</p>
<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>
<p>uint8, float32
</p>

<hr>
<h2 id='icevision_Rotate'>Rotate</h2><span id='topic+icevision_Rotate'></span>

<h3>Description</h3>

<p>Rotate the input by an angle selected randomly from the uniform distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Rotate(
  limit = 90,
  interpolation = 1,
  border_mode = 4,
  value = NULL,
  mask_value = NULL,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Rotate_+3A_limit">limit</code></td>
<td>
<p>limit</p>
</td></tr>
<tr><td><code id="icevision_Rotate_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_Rotate_+3A_border_mode">border_mode</code></td>
<td>
<p>border_mode</p>
</td></tr>
<tr><td><code id="icevision_Rotate_+3A_value">value</code></td>
<td>
<p>value</p>
</td></tr>
<tr><td><code id="icevision_Rotate_+3A_mask_value">mask_value</code></td>
<td>
<p>mask_value</p>
</td></tr>
<tr><td><code id="icevision_Rotate_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Rotate_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_ShiftScaleRotate'>ShiftScaleRotate</h2><span id='topic+icevision_ShiftScaleRotate'></span>

<h3>Description</h3>

<p>Randomly apply affine transforms: translate, scale and rotate the input.
</p>
<p>Randomly apply affine transforms: translate, scale and rotate the input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ShiftScaleRotate(
  shift_limit = 0.0625,
  scale_limit = 0.1,
  rotate_limit = 45,
  interpolation = 1,
  border_mode = 4,
  value = NULL,
  mask_value = NULL,
  shift_limit_x = NULL,
  shift_limit_y = NULL,
  always_apply = FALSE,
  p = 0.5
)

icevision_ShiftScaleRotate(
  shift_limit = 0.0625,
  scale_limit = 0.1,
  rotate_limit = 45,
  interpolation = 1,
  border_mode = 4,
  value = NULL,
  mask_value = NULL,
  shift_limit_x = NULL,
  shift_limit_y = NULL,
  always_apply = FALSE,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_shift_limit">shift_limit</code></td>
<td>
<p>shift_limit</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_scale_limit">scale_limit</code></td>
<td>
<p>scale_limit</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_rotate_limit">rotate_limit</code></td>
<td>
<p>rotate_limit</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_border_mode">border_mode</code></td>
<td>
<p>border_mode</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_value">value</code></td>
<td>
<p>value</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_mask_value">mask_value</code></td>
<td>
<p>mask_value</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_shift_limit_x">shift_limit_x</code></td>
<td>
<p>shift_limit_x</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_shift_limit_y">shift_limit_y</code></td>
<td>
<p>shift_limit_y</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ShiftScaleRotate_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>


<h3>Targets</h3>

<p>image, mask, keypoints
</p>
<p>image, mask, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>
<p>uint8, float32
</p>

<hr>
<h2 id='icevision_SingleSplitSplitter'>SingleSplitSplitter</h2><span id='topic+icevision_SingleSplitSplitter'></span>

<h3>Description</h3>

<p>SingleSplitSplitter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_SingleSplitSplitter(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_SingleSplitSplitter_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>all items in a single group, without shuffling.
</p>

<hr>
<h2 id='icevision_SmallestMaxSize'>SmallestMaxSize</h2><span id='topic+icevision_SmallestMaxSize'></span>

<h3>Description</h3>

<p>Rescale an image so that minimum side is equal to max_size, keeping the aspect ratio of the initial image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_SmallestMaxSize(
  max_size = 1024,
  interpolation = 1,
  always_apply = FALSE,
  p = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_SmallestMaxSize_+3A_max_size">max_size</code></td>
<td>
<p>max_size</p>
</td></tr>
<tr><td><code id="icevision_SmallestMaxSize_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="icevision_SmallestMaxSize_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_SmallestMaxSize_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_Solarize'>Solarize</h2><span id='topic+icevision_Solarize'></span>

<h3>Description</h3>

<p>Invert all pixel values above a threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Solarize(threshold = 128, always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Solarize_+3A_threshold">threshold</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="icevision_Solarize_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Solarize_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>any
</p>

<hr>
<h2 id='icevision_ToFloat'>ToFloat</h2><span id='topic+icevision_ToFloat'></span>

<h3>Description</h3>

<p>Divide pixel values by 'max_value' to get a float32 output array where all values lie in the range [0, 1.0].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ToFloat(max_value = NULL, always_apply = FALSE, p = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ToFloat_+3A_max_value">max_value</code></td>
<td>
<p>max_value</p>
</td></tr>
<tr><td><code id="icevision_ToFloat_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ToFloat_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If 'max_value' is NULL the transform will try to infer the maximum value by inspecting the data type of the input
image. See Also: :class:'~albumentations.augmentations.transforms.FromFloat'
</p>


<h3>Value</h3>

<p>None
</p>


<h3>See Also</h3>

<p>:class:'~albumentations.augmentations.transforms.FromFloat'
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>any type
</p>

<hr>
<h2 id='icevision_ToGray'>ToGray</h2><span id='topic+icevision_ToGray'></span>

<h3>Description</h3>

<p>Convert the input RGB image to grayscale. If the mean pixel value for the resulting image is greater
than 127, invert the resulting grayscale image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ToGray(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ToGray_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ToGray_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_ToSepia'>ToSepia</h2><span id='topic+icevision_ToSepia'></span>

<h3>Description</h3>

<p>Applies sepia filter to the input RGB image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_ToSepia(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_ToSepia_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_ToSepia_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_Transpose'>Transpose</h2><span id='topic+icevision_Transpose'></span>

<h3>Description</h3>

<p>Transpose the input by swapping rows and columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_Transpose(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_Transpose_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_Transpose_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icevision_VerticalFlip'>VerticalFlip</h2><span id='topic+icevision_VerticalFlip'></span>

<h3>Description</h3>

<p>Flip the input vertically around the x-axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icevision_VerticalFlip(always_apply = FALSE, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icevision_VerticalFlip_+3A_always_apply">always_apply</code></td>
<td>
<p>always_apply</p>
</td></tr>
<tr><td><code id="icevision_VerticalFlip_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Targets</h3>

<p>image, mask, bboxes, keypoints
</p>


<h3>Image types</h3>

<p>uint8, float32
</p>

<hr>
<h2 id='icnr_init'>Icnr_init</h2><span id='topic+icnr_init'></span>

<h3>Description</h3>

<p>ICNR init of 'x', with 'scale' and 'init' function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icnr_init(x, scale = 2, init = nn()$init$kaiming_normal_)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icnr_init_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="icnr_init_+3A_scale">scale</code></td>
<td>
<p>int, scale</p>
</td></tr>
<tr><td><code id="icnr_init_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='IDMap'>IDMap</h2><span id='topic+IDMap'></span>

<h3>Description</h3>

<p>Works like a dictionary that automatically assign values for new keys.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IDMap(initial_names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IDMap_+3A_initial_names">initial_names</code></td>
<td>
<p>initial_names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Image'>Image</h2><span id='topic+Image'></span>

<h3>Description</h3>

<p>Image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Image(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Image_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Image_create'>Image_create</h2><span id='topic+Image_create'></span>

<h3>Description</h3>

<p>Open an 'Image' from path 'fn'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Image_create(fn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Image_create_+3A_fn">fn</code></td>
<td>
<p>file name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Image_open'>Image_open</h2><span id='topic+Image_open'></span>

<h3>Description</h3>

<p>Opens and identifies the given image file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Image_open(fp, mode = "r")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Image_open_+3A_fp">fp</code></td>
<td>
<p>fp</p>
</td></tr>
<tr><td><code id="Image_open_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Image_resize'>Resize</h2><span id='topic+Image_resize'></span>

<h3>Description</h3>

<p>Returns a resized copy of this image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Image_resize(img, size, resample = 3, box = NULL, reducing_gap = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Image_resize_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
<tr><td><code id="Image_resize_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="Image_resize_+3A_resample">resample</code></td>
<td>
<p>resample</p>
</td></tr>
<tr><td><code id="Image_resize_+3A_box">box</code></td>
<td>
<p>box</p>
</td></tr>
<tr><td><code id="Image_resize_+3A_reducing_gap">reducing_gap</code></td>
<td>
<p>reducing_gap</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='image2tensor'>Image2tensor</h2><span id='topic+image2tensor'></span>

<h3>Description</h3>

<p>Transform image to byte tensor in 'c*h*w' dim order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image2tensor(img)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="image2tensor_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ImageBlock'>ImageBlock</h2><span id='topic+ImageBlock'></span>

<h3>Description</h3>

<p>A 'TransformBlock' for images of 'cls'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageBlock(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageBlock_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>block
</p>

<hr>
<h2 id='ImageBW_create'>ImageBW_create</h2><span id='topic+ImageBW_create'></span>

<h3>Description</h3>

<p>Open an 'Image' from path 'fn'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageBW_create(fn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageBW_create_+3A_fn">fn</code></td>
<td>
<p>file name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ImageDataLoaders_from_csv'>ImageDataLoaders from csv</h2><span id='topic+ImageDataLoaders_from_csv'></span>

<h3>Description</h3>

<p>Create from 'path/csv_fname' using 'fn_col' and 'label_col'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageDataLoaders_from_csv(
  path,
  csv_fname = "labels.csv",
  header = "infer",
  delimiter = NULL,
  valid_pct = 0.2,
  seed = NULL,
  fn_col = 0,
  folder = NULL,
  suff = "",
  label_col = 1,
  label_delim = NULL,
  y_block = NULL,
  valid_col = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  bs = 64,
  val_bs = NULL,
  size = NULL,
  shuffle_train = TRUE,
  device = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_csv_fname">csv_fname</code></td>
<td>
<p>csv file name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_header">header</code></td>
<td>
<p>header</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_delimiter">delimiter</code></td>
<td>
<p>delimiter</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_valid_pct">valid_pct</code></td>
<td>
<p>validation percentage</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_fn_col">fn_col</code></td>
<td>
<p>column name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_folder">folder</code></td>
<td>
<p>folder name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_suff">suff</code></td>
<td>
<p>suff</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_label_col">label_col</code></td>
<td>
<p>label column</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_label_delim">label_delim</code></td>
<td>
<p>label delimiter</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_y_block">y_block</code></td>
<td>
<p>y_block</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_valid_col">valid_col</code></td>
<td>
<p>validation column</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_item_tfms">item_tfms</code></td>
<td>
<p>One or several transforms applied to the items before batching them</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>One or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_size">size</code></td>
<td>
<p>image size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_csv_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ImageDataLoaders_from_dblock'>ImageDataLoaders from dblock</h2><span id='topic+ImageDataLoaders_from_dblock'></span>

<h3>Description</h3>

<p>Create a dataloaders from a given 'dblock'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageDataLoaders_from_dblock(
  dblock,
  source,
  path = ".",
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageDataLoaders_from_dblock_+3A_dblock">dblock</code></td>
<td>
<p>dblock</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_dblock_+3A_source">source</code></td>
<td>
<p>source folder</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_dblock_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_dblock_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_dblock_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_dblock_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_dblock_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_dblock_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ImageDataLoaders_from_df'>ImageDataLoaders from df</h2><span id='topic+ImageDataLoaders_from_df'></span>

<h3>Description</h3>

<p>Create from 'df' using 'fn_col' and 'label_col'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageDataLoaders_from_df(
  df,
  path = ".",
  valid_pct = 0.2,
  seed = NULL,
  fn_col = 0,
  folder = NULL,
  suff = "",
  label_col = 1,
  label_delim = NULL,
  y_block = NULL,
  valid_col = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageDataLoaders_from_df_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_valid_pct">valid_pct</code></td>
<td>
<p>validation percentage</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_fn_col">fn_col</code></td>
<td>
<p>column name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_folder">folder</code></td>
<td>
<p>folder name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_suff">suff</code></td>
<td>
<p>suff</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_label_col">label_col</code></td>
<td>
<p>label column</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_label_delim">label_delim</code></td>
<td>
<p>label separator</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_y_block">y_block</code></td>
<td>
<p>y_block</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_valid_col">valid_col</code></td>
<td>
<p>validation column</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_item_tfms">item_tfms</code></td>
<td>
<p>One or several transforms applied to the items before batching them</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>One or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>shuffle_train</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_df_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ImageDataLoaders_from_folder'>ImageDataLoaders from folder</h2><span id='topic+ImageDataLoaders_from_folder'></span>

<h3>Description</h3>

<p>Create from imagenet style dataset in 'path' with 'train' and 'valid' subfolders (or provide 'valid_pct')
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageDataLoaders_from_folder(
  path,
  train = "train",
  valid = "valid",
  valid_pct = NULL,
  seed = NULL,
  vocab = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL,
  size = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_train">train</code></td>
<td>
<p>train data</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_valid">valid</code></td>
<td>
<p>validation data</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_valid_pct">valid_pct</code></td>
<td>
<p>validion percentage</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_item_tfms">item_tfms</code></td>
<td>
<p>One or several transforms applied to the items before batching them</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>One or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_size">size</code></td>
<td>
<p>image size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_folder_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>

<hr>
<h2 id='ImageDataLoaders_from_lists'>ImageDataLoaders from lists</h2><span id='topic+ImageDataLoaders_from_lists'></span>

<h3>Description</h3>

<p>Create from list of 'fnames' and 'labels' in 'path'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageDataLoaders_from_lists(
  path,
  fnames,
  labels,
  valid_pct = 0.2,
  seed = NULL,
  y_block = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_fnames">fnames</code></td>
<td>
<p>file names</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_valid_pct">valid_pct</code></td>
<td>
<p>validation percentage</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_y_block">y_block</code></td>
<td>
<p>y_block</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_item_tfms">item_tfms</code></td>
<td>
<p>One or several transforms applied to the items before batching them</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>One or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_lists_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ImageDataLoaders_from_name_re'>ImageDataLoaders from name regex</h2><span id='topic+ImageDataLoaders_from_name_re'></span>

<h3>Description</h3>

<p>Create from the name attrs of 'fnames' in 'path's with re expression 'pat'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageDataLoaders_from_name_re(
  path,
  fnames,
  pat,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_fnames">fnames</code></td>
<td>
<p>folder names</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_pat">pat</code></td>
<td>
<p>an argument that requires regex</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_bs">bs</code></td>
<td>
<p>The batch size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_item_tfms">item_tfms</code></td>
<td>
<p>One or several transforms applied to the items before batching them</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>One or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_name_re_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_PETS()

path = 'oxford-iiit-pet'

dls = ImageDataLoaders_from_name_re(
path, fnames, pat='(.+)_\\d+.jpg$',
item_tfms = RandomResizedCrop(460, min_scale=0.75), bs = 10,
batch_tfms = list(aug_transforms(size = 299, max_warp = 0),
                  Normalize_from_stats( imagenet_stats() )
),
device = 'cuda'
)


## End(Not run)

</code></pre>

<hr>
<h2 id='ImageDataLoaders_from_path_func'>ImageDataLoaders from path function</h2><span id='topic+ImageDataLoaders_from_path_func'></span>

<h3>Description</h3>

<p>Create from list of 'fnames' in 'path's with 'label_func'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageDataLoaders_from_path_func(
  path,
  fnames,
  label_func,
  valid_pct = 0.2,
  seed = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_fnames">fnames</code></td>
<td>
<p>file names</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_label_func">label_func</code></td>
<td>
<p>label function</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_valid_pct">valid_pct</code></td>
<td>
<p>The random percentage of the dataset to set aside for validation (with an optional seed)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_item_tfms">item_tfms</code></td>
<td>
<p>One or several transforms applied to the items before batching them</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>One or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_func_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ImageDataLoaders_from_path_re'>ImageDataLoaders from path re</h2><span id='topic+ImageDataLoaders_from_path_re'></span>

<h3>Description</h3>

<p>Create from list of 'fnames' in 'path's with re expression 'pat'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageDataLoaders_from_path_re(
  path,
  fnames,
  pat,
  valid_pct = 0.2,
  seed = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_path">path</code></td>
<td>
<p>The folder where to work</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_fnames">fnames</code></td>
<td>
<p>file names</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_pat">pat</code></td>
<td>
<p>an argument that requires regex</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_valid_pct">valid_pct</code></td>
<td>
<p>The random percentage of the dataset to set aside for validation (with an optional seed)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_item_tfms">item_tfms</code></td>
<td>
<p>One or several transforms applied to the items before batching them</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>One or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_val_bs">val_bs</code></td>
<td>
<p>The batch size for the validation DataLoader (defaults to bs)</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>If we shuffle the training DataLoader or not</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="ImageDataLoaders_from_path_re_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='imagenet_stats'>Imagenet statistics</h2><span id='topic+imagenet_stats'></span>

<h3>Description</h3>

<p>Imagenet statistics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imagenet_stats()
</code></pre>


<h3>Value</h3>

<p>vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

imagenet_stats()



## End(Not run)

</code></pre>

<hr>
<h2 id='in_channels'>In_channels</h2><span id='topic+in_channels'></span>

<h3>Description</h3>

<p>Return the shape of the first weight layer in 'm'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>in_channels(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="in_channels_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='InceptionModule'>InceptionModule</h2><span id='topic+InceptionModule'></span>

<h3>Description</h3>

<p>The inception Module from &lsquo;ni' inputs to len(&rsquo;kss')*'nb_filters'+'bottleneck_size'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InceptionModule(
  ni,
  nb_filters = 32,
  kss = c(39, 19, 9),
  bottleneck_size = 32,
  stride = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="InceptionModule_+3A_ni">ni</code></td>
<td>
<p>number of input channels</p>
</td></tr>
<tr><td><code id="InceptionModule_+3A_nb_filters">nb_filters</code></td>
<td>
<p>the number of filters</p>
</td></tr>
<tr><td><code id="InceptionModule_+3A_kss">kss</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="InceptionModule_+3A_bottleneck_size">bottleneck_size</code></td>
<td>
<p>bottleneck size</p>
</td></tr>
<tr><td><code id="InceptionModule_+3A_stride">stride</code></td>
<td>
<p>stride</p>
</td></tr>
</table>


<h3>Value</h3>

<p>module
</p>

<hr>
<h2 id='IndexSplitter'>Index Splitter</h2><span id='topic+IndexSplitter'></span>

<h3>Description</h3>

<p>Split 'items' so that 'val_idx' are in the validation set and the others in the training set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IndexSplitter(valid_idx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IndexSplitter_+3A_valid_idx">valid_idx</code></td>
<td>
<p>The indices to use for the validation set (defaults to a random split otherwise)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='init'>Wandb init</h2><span id='topic+init'></span>

<h3>Description</h3>

<p>Initialize a wandb Run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>wandb Run object
</p>
<p>None
</p>


<h3>see https</h3>

<p>//docs.wandb.com/library/init
</p>

<hr>
<h2 id='init_default'>Init_default</h2><span id='topic+init_default'></span>

<h3>Description</h3>

<p>Initialize 'm' weights with 'func' and set 'bias' to 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_default(m, func = nn()$init$kaiming_normal_)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_default_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
<tr><td><code id="init_default_+3A_func">func</code></td>
<td>
<p>function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='init_linear'>Init_linear</h2><span id='topic+init_linear'></span>

<h3>Description</h3>

<p>Init_linear
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_linear(m, act_func = NULL, init = "auto", bias_std = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_linear_+3A_m">m</code></td>
<td>
<p>parameter</p>
</td></tr>
<tr><td><code id="init_linear_+3A_act_func">act_func</code></td>
<td>
<p>activation function</p>
</td></tr>
<tr><td><code id="init_linear_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="init_linear_+3A_bias_std">bias_std</code></td>
<td>
<p>bias standard deviation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='install_fastai'>Install fastai</h2><span id='topic+install_fastai'></span>

<h3>Description</h3>

<p>Install fastai
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_fastai(
  version,
  gpu = FALSE,
  cuda_version = "11.6",
  overwrite = FALSE,
  extra_pkgs = c("timm", "fastinference[interp]"),
  TPU = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_fastai_+3A_version">version</code></td>
<td>
<p>specify version</p>
</td></tr>
<tr><td><code id="install_fastai_+3A_gpu">gpu</code></td>
<td>
<p>installation of gpu</p>
</td></tr>
<tr><td><code id="install_fastai_+3A_cuda_version">cuda_version</code></td>
<td>
<p>if gpu true, then cuda version is required. By default it is 11.6</p>
</td></tr>
<tr><td><code id="install_fastai_+3A_overwrite">overwrite</code></td>
<td>
<p>will install all the dependencies</p>
</td></tr>
<tr><td><code id="install_fastai_+3A_extra_pkgs">extra_pkgs</code></td>
<td>
<p>character vector of additional packages</p>
</td></tr>
<tr><td><code id="install_fastai_+3A_tpu">TPU</code></td>
<td>
<p>official way to install Pytorch-XLA 1.13</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='InstanceNorm'>InstanceNorm</h2><span id='topic+InstanceNorm'></span>

<h3>Description</h3>

<p>InstanceNorm layer with 'nf' features and 'ndim' initialized depending on 'norm_type'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InstanceNorm(
  nf,
  ndim = 2,
  norm_type = 5,
  affine = TRUE,
  eps = 1e-05,
  momentum = 0.1,
  track_running_stats = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="InstanceNorm_+3A_nf">nf</code></td>
<td>
<p>input shape</p>
</td></tr>
<tr><td><code id="InstanceNorm_+3A_ndim">ndim</code></td>
<td>
<p>dimension number</p>
</td></tr>
<tr><td><code id="InstanceNorm_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
<tr><td><code id="InstanceNorm_+3A_affine">affine</code></td>
<td>
<p>affine</p>
</td></tr>
<tr><td><code id="InstanceNorm_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="InstanceNorm_+3A_momentum">momentum</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="InstanceNorm_+3A_track_running_stats">track_running_stats</code></td>
<td>
<p>track running statistics</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='IntToFloatTensor'>IntToFloatTensor</h2><span id='topic+IntToFloatTensor'></span>

<h3>Description</h3>

<p>Transform image to float tensor, optionally dividing by 255 (e.g. for images).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IntToFloatTensor(div = 255, div_mask = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IntToFloatTensor_+3A_div">div</code></td>
<td>
<p>divide value</p>
</td></tr>
<tr><td><code id="IntToFloatTensor_+3A_div_mask">div_mask</code></td>
<td>
<p>divide mask</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='InvisibleTensor'>Invisible Tensor</h2><span id='topic+InvisibleTensor'></span>

<h3>Description</h3>

<p>Invisible Tensor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InvisibleTensor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="InvisibleTensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='is_rmarkdown'>Is Rmarkdown?</h2><span id='topic+is_rmarkdown'></span>

<h3>Description</h3>

<p>Is Rmarkdown?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_rmarkdown()
</code></pre>


<h3>Value</h3>

<p>logical True/False
</p>

<hr>
<h2 id='Jaccard'>Jaccard</h2><span id='topic+Jaccard'></span>

<h3>Description</h3>

<p>Jaccard score for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Jaccard(
  axis = -1,
  labels = NULL,
  pos_label = 1,
  average = "binary",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Jaccard_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="Jaccard_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="Jaccard_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="Jaccard_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="Jaccard_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='JaccardCoeff'>JaccardCoeff</h2><span id='topic+JaccardCoeff'></span>

<h3>Description</h3>

<p>Implementation of the Jaccard coefficient that is lighter in RAM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JaccardCoeff(axis = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="JaccardCoeff_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='JaccardMulti'>JaccardMulti</h2><span id='topic+JaccardMulti'></span>

<h3>Description</h3>

<p>Jaccard score for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JaccardMulti(
  thresh = 0.5,
  sigmoid = TRUE,
  labels = NULL,
  pos_label = 1,
  average = "macro",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="JaccardMulti_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="JaccardMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="JaccardMulti_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="JaccardMulti_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="JaccardMulti_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="JaccardMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='kg'>Kaggle module</h2><span id='topic+kg'></span>

<h3>Description</h3>

<p>Kaggle module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kg()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='L'>L</h2><span id='topic+L'></span>

<h3>Description</h3>

<p>Behaves like a list of 'items' but can also index with list of indices or masks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>

<hr>
<h2 id='L1LossFlat'>L1LossFlat</h2><span id='topic+L1LossFlat'></span>

<h3>Description</h3>

<p>Flattens input and output, same as nn$L1LossFlat
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L1LossFlat(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L1LossFlat_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='l2_reg'>L2_reg</h2><span id='topic+l2_reg'></span>

<h3>Description</h3>

<p>L2 regularization as adding 'wd*p' to 'p$grad'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>l2_reg(p, lr, wd, do_wd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="l2_reg_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="l2_reg_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="l2_reg_+3A_wd">wd</code></td>
<td>
<p>weight decay</p>
</td></tr>
<tr><td><code id="l2_reg_+3A_do_wd">do_wd</code></td>
<td>
<p>do_wd</p>
</td></tr>
<tr><td><code id="l2_reg_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

tst_param = function(val, grad = NULL) {
  "Create a tensor with `val` and a gradient of `grad` for testing"
  res = tensor(val) %&gt;% float()

  if(is.null(grad)) {
    grad = tensor(val / 10)
  } else {
    grad = tensor(grad)
  }

  res$grad = grad %&gt;% float()
  res
}
p = tst_param(1., 0.1)
l2_reg(p, 1., 0.1)


## End(Not run)

</code></pre>

<hr>
<h2 id='LabeledBBox'>LabeledBBox</h2><span id='topic+LabeledBBox'></span>

<h3>Description</h3>

<p>Basic type for a list of bounding boxes in an image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LabeledBBox(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LabeledBBox_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='LabelSmoothingCrossEntropy'>LabelSmoothingCrossEntropy</h2><span id='topic+LabelSmoothingCrossEntropy'></span>

<h3>Description</h3>

<p>Same as 'nn$Module', but no need for subclasses to call 'super()$__init__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LabelSmoothingCrossEntropy(eps = 0.1, reduction = "mean")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LabelSmoothingCrossEntropy_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="LabelSmoothingCrossEntropy_+3A_reduction">reduction</code></td>
<td>
<p>reduction, defaults to mean</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='LabelSmoothingCrossEntropyFlat'>LabelSmoothingCrossEntropyFlat</h2><span id='topic+LabelSmoothingCrossEntropyFlat'></span>

<h3>Description</h3>

<p>Same as 'nn$Module', but no need for subclasses to call 'super().__init__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LabelSmoothingCrossEntropyFlat(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LabelSmoothingCrossEntropyFlat_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='Lamb'>Lamb</h2><span id='topic+Lamb'></span>

<h3>Description</h3>

<p>Lamb
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lamb(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lamb_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='lamb_step'>Lamb_step</h2><span id='topic+lamb_step'></span>

<h3>Description</h3>

<p>Step for LAMB with 'lr' on 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lamb_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lamb_step_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="lamb_step_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="lamb_step_+3A_mom">mom</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="lamb_step_+3A_step">step</code></td>
<td>
<p>step</p>
</td></tr>
<tr><td><code id="lamb_step_+3A_sqr_mom">sqr_mom</code></td>
<td>
<p>sqr momentum</p>
</td></tr>
<tr><td><code id="lamb_step_+3A_grad_avg">grad_avg</code></td>
<td>
<p>gradient average</p>
</td></tr>
<tr><td><code id="lamb_step_+3A_sqr_avg">sqr_avg</code></td>
<td>
<p>sqr average</p>
</td></tr>
<tr><td><code id="lamb_step_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="lamb_step_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Lambda'>Lambda</h2><span id='topic+Lambda'></span>

<h3>Description</h3>

<p>An easy way to create a pytorch layer for a simple 'func'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lambda(func)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lambda_+3A_func">func</code></td>
<td>
<p>function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='language_model_learner'>Language_model_learner</h2><span id='topic+language_model_learner'></span>

<h3>Description</h3>

<p>Create a 'Learner' with a language model from 'dls' and 'arch'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>language_model_learner(
  dls,
  arch,
  config = NULL,
  drop_mult = 1,
  backwards = FALSE,
  pretrained = TRUE,
  pretrained_fnames = NULL,
  opt_func = Adam(),
  lr = 0.001,
  cbs = NULL,
  metrics = NULL,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE,
  moms = list(0.95, 0.85, 0.95),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="language_model_learner_+3A_dls">dls</code></td>
<td>
<p>dls</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_arch">arch</code></td>
<td>
<p>arch</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_config">config</code></td>
<td>
<p>config</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_drop_mult">drop_mult</code></td>
<td>
<p>drop_mult</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_pretrained_fnames">pretrained_fnames</code></td>
<td>
<p>pretrained_fnames</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_opt_func">opt_func</code></td>
<td>
<p>opt_func</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_lr">lr</code></td>
<td>
<p>lr</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_cbs">cbs</code></td>
<td>
<p>cbs</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_metrics">metrics</code></td>
<td>
<p>metrics</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_model_dir">model_dir</code></td>
<td>
<p>model_dir</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_wd">wd</code></td>
<td>
<p>wd</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>wd_bn_bias</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_train_bn">train_bn</code></td>
<td>
<p>train_bn</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_moms">moms</code></td>
<td>
<p>moms</p>
</td></tr>
<tr><td><code id="language_model_learner_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Larc'>Larc</h2><span id='topic+Larc'></span>

<h3>Description</h3>

<p>Larc
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Larc(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Larc_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='larc_layer_lr'>Larc_layer_lr</h2><span id='topic+larc_layer_lr'></span>

<h3>Description</h3>

<p>Computes the local lr before weight decay is applied
</p>


<h3>Usage</h3>

<pre><code class='language-R'>larc_layer_lr(p, lr, trust_coeff, wd, eps, clip = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="larc_layer_lr_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="larc_layer_lr_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="larc_layer_lr_+3A_trust_coeff">trust_coeff</code></td>
<td>
<p>trust_coeff</p>
</td></tr>
<tr><td><code id="larc_layer_lr_+3A_wd">wd</code></td>
<td>
<p>weight decay</p>
</td></tr>
<tr><td><code id="larc_layer_lr_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="larc_layer_lr_+3A_clip">clip</code></td>
<td>
<p>clip</p>
</td></tr>
<tr><td><code id="larc_layer_lr_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='larc_step'>Larc_step</h2><span id='topic+larc_step'></span>

<h3>Description</h3>

<p>Step for LARC 'local_lr' on 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>larc_step(p, local_lr, grad_avg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="larc_step_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="larc_step_+3A_local_lr">local_lr</code></td>
<td>
<p>local learning rate</p>
</td></tr>
<tr><td><code id="larc_step_+3A_grad_avg">grad_avg</code></td>
<td>
<p>gradient average</p>
</td></tr>
<tr><td><code id="larc_step_+3A_...">...</code></td>
<td>
<p>additional args to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='layer_info'>Layer_info</h2><span id='topic+layer_info'></span>

<h3>Description</h3>

<p>Return layer infos of 'model' on 'xb' (only support batch first inputs)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_info(learn, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_info_+3A_learn">learn</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="layer_info_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Learner'>Learner</h2><span id='topic+Learner'></span>

<h3>Description</h3>

<p>Learner
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Learner(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Learner_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

model = LitModel()

data = Data_Loaders(model$train_dataloader(), model$val_dataloader())$cuda()

learn = Learner(data, model, loss_func = F$cross_entropy, opt_func = Adam,
                metrics = accuracy)


## End(Not run)

</code></pre>

<hr>
<h2 id='length'>Length</h2><span id='topic+length'></span><span id='topic+length.torch.Tensor'></span>

<h3>Description</h3>

<p>Length
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
length(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="length_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='length.fastai.torch_core.TensorMask'>Length</h2><span id='topic+length.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Length
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
length(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="length.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='less'>Less</h2><span id='topic+less'></span><span id='topic++3C.torch.Tensor'></span>

<h3>Description</h3>

<p>Less
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a &lt; b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="less_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="less_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='less_or_equal'>Less or equal</h2><span id='topic+less_or_equal'></span><span id='topic++3C+3D.torch.Tensor'></span>

<h3>Description</h3>

<p>Less or equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a &lt;= b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="less_or_equal_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="less_or_equal_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='LightingTfm'>LightingTfm</h2><span id='topic+LightingTfm'></span>

<h3>Description</h3>

<p>Apply 'fs' to the logits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LightingTfm(fs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LightingTfm_+3A_fs">fs</code></td>
<td>
<p>fs</p>
</td></tr>
<tr><td><code id="LightingTfm_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='LinBnDrop'>LinBnDrop</h2><span id='topic+LinBnDrop'></span>

<h3>Description</h3>

<p>Module grouping 'BatchNorm1d', 'Dropout' and 'Linear' layers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LinBnDrop(n_in, n_out, bn = TRUE, p = 0, act = NULL, lin_first = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LinBnDrop_+3A_n_in">n_in</code></td>
<td>
<p>input shape</p>
</td></tr>
<tr><td><code id="LinBnDrop_+3A_n_out">n_out</code></td>
<td>
<p>output shape</p>
</td></tr>
<tr><td><code id="LinBnDrop_+3A_bn">bn</code></td>
<td>
<p>bn</p>
</td></tr>
<tr><td><code id="LinBnDrop_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="LinBnDrop_+3A_act">act</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="LinBnDrop_+3A_lin_first">lin_first</code></td>
<td>
<p>linear first</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='LinearDecoder'>LinearDecoder</h2><span id='topic+LinearDecoder'></span>

<h3>Description</h3>

<p>To go on top of a RNNCore module and create a Language Model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LinearDecoder(n_out, n_hid, output_p = 0.1, tie_encoder = NULL, bias = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LinearDecoder_+3A_n_out">n_out</code></td>
<td>
<p>n_out</p>
</td></tr>
<tr><td><code id="LinearDecoder_+3A_n_hid">n_hid</code></td>
<td>
<p>n_hid</p>
</td></tr>
<tr><td><code id="LinearDecoder_+3A_output_p">output_p</code></td>
<td>
<p>output_p</p>
</td></tr>
<tr><td><code id="LinearDecoder_+3A_tie_encoder">tie_encoder</code></td>
<td>
<p>tie_encoder</p>
</td></tr>
<tr><td><code id="LinearDecoder_+3A_bias">bias</code></td>
<td>
<p>bias</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='LitModel'>Lit Model</h2><span id='topic+LitModel'></span>

<h3>Description</h3>

<p>Lit Model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LitModel()
</code></pre>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='LMDataLoader'>LMDataLoader</h2><span id='topic+LMDataLoader'></span>

<h3>Description</h3>

<p>A 'DataLoader' suitable for language modeling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LMDataLoader(
  dataset,
  lens = NULL,
  cache = 2,
  bs = 64,
  seq_len = 72,
  num_workers = 0,
  shuffle = FALSE,
  verbose = FALSE,
  do_setup = TRUE,
  pin_memory = FALSE,
  timeout = 0L,
  batch_size = NULL,
  drop_last = FALSE,
  indexed = NULL,
  n = NULL,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LMDataLoader_+3A_dataset">dataset</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_lens">lens</code></td>
<td>
<p>lens</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_cache">cache</code></td>
<td>
<p>cache</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_bs">bs</code></td>
<td>
<p>bs</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_seq_len">seq_len</code></td>
<td>
<p>seq_len</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_num_workers">num_workers</code></td>
<td>
<p>num_workers</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_verbose">verbose</code></td>
<td>
<p>verbose</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_do_setup">do_setup</code></td>
<td>
<p>do_setup</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_pin_memory">pin_memory</code></td>
<td>
<p>pin_memory</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_timeout">timeout</code></td>
<td>
<p>timeout</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_batch_size">batch_size</code></td>
<td>
<p>batch_size</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_drop_last">drop_last</code></td>
<td>
<p>drop_last</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_indexed">indexed</code></td>
<td>
<p>indexed</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_n">n</code></td>
<td>
<p>n</p>
</td></tr>
<tr><td><code id="LMDataLoader_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
</table>


<h3>Value</h3>

<p>text loader
</p>

<hr>
<h2 id='LMLearner'>LMLearner</h2><span id='topic+LMLearner'></span>

<h3>Description</h3>

<p>Add functionality to 'TextLearner' when dealingwith a language model
</p>
<p>Add functionality to 'TextLearner' when dealing with a language model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LMLearner(
  dls,
  model,
  alpha = 2,
  beta = 1,
  moms = list(0.8, 0.7, 0.8),
  loss_func = NULL,
  opt_func = Adam(),
  lr = 0.001,
  splitter = trainable_params(),
  cbs = NULL,
  metrics = NULL,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE
)

LMLearner(
  dls,
  model,
  alpha = 2,
  beta = 1,
  moms = list(0.8, 0.7, 0.8),
  loss_func = NULL,
  opt_func = Adam(),
  lr = 0.001,
  splitter = trainable_params(),
  cbs = NULL,
  metrics = NULL,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LMLearner_+3A_dls">dls</code></td>
<td>
<p>dls</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_beta">beta</code></td>
<td>
<p>beta</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_moms">moms</code></td>
<td>
<p>moms</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_loss_func">loss_func</code></td>
<td>
<p>loss_func</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_opt_func">opt_func</code></td>
<td>
<p>opt_func</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_lr">lr</code></td>
<td>
<p>lr</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_splitter">splitter</code></td>
<td>
<p>splitter</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_cbs">cbs</code></td>
<td>
<p>cbs</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_metrics">metrics</code></td>
<td>
<p>metrics</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_model_dir">model_dir</code></td>
<td>
<p>model_dir</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_wd">wd</code></td>
<td>
<p>wd</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>wd_bn_bias</p>
</td></tr>
<tr><td><code id="LMLearner_+3A_train_bn">train_bn</code></td>
<td>
<p>train_bn</p>
</td></tr>
</table>


<h3>Value</h3>

<p>text loader
</p>
<p>None
</p>

<hr>
<h2 id='LMLearner_predict'>LMLearner_predict</h2><span id='topic+LMLearner_predict'></span>

<h3>Description</h3>

<p>Return 'text' and the 'n_words' that come after
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LMLearner_predict(
  text,
  n_words = 1,
  no_unk = TRUE,
  temperature = 1,
  min_p = NULL,
  no_bar = FALSE,
  decoder = decode_spec_tokens(),
  only_last_word = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LMLearner_predict_+3A_text">text</code></td>
<td>
<p>text</p>
</td></tr>
<tr><td><code id="LMLearner_predict_+3A_n_words">n_words</code></td>
<td>
<p>n_words</p>
</td></tr>
<tr><td><code id="LMLearner_predict_+3A_no_unk">no_unk</code></td>
<td>
<p>no_unk</p>
</td></tr>
<tr><td><code id="LMLearner_predict_+3A_temperature">temperature</code></td>
<td>
<p>temperature</p>
</td></tr>
<tr><td><code id="LMLearner_predict_+3A_min_p">min_p</code></td>
<td>
<p>min_p</p>
</td></tr>
<tr><td><code id="LMLearner_predict_+3A_no_bar">no_bar</code></td>
<td>
<p>no_bar</p>
</td></tr>
<tr><td><code id="LMLearner_predict_+3A_decoder">decoder</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="LMLearner_predict_+3A_only_last_word">only_last_word</code></td>
<td>
<p>only_last_word</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='load_dataset'>Load_dataset</h2><span id='topic+load_dataset'></span>

<h3>Description</h3>

<p>A helper function for getting a DataLoader for images in the folder 'test_path', with batch size 'bs', and number of workers 'num_workers'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_dataset(test_path, bs = 4, num_workers = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_dataset_+3A_test_path">test_path</code></td>
<td>
<p>test path (directory)</p>
</td></tr>
<tr><td><code id="load_dataset_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="load_dataset_+3A_num_workers">num_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='load_ignore_keys'>Load_ignore_keys</h2><span id='topic+load_ignore_keys'></span>

<h3>Description</h3>

<p>Load 'wgts' in 'model' ignoring the names of the keys, just taking parameters in order
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_ignore_keys(model, wgts)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_ignore_keys_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="load_ignore_keys_+3A_wgts">wgts</code></td>
<td>
<p>wgts</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='load_image'>Load_image</h2><span id='topic+load_image'></span>

<h3>Description</h3>

<p>Open and load a 'PIL.Image' and convert to 'mode'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_image(fn, mode = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_image_+3A_fn">fn</code></td>
<td>
<p>file name</p>
</td></tr>
<tr><td><code id="load_image_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='load_learner'>Load_learner</h2><span id='topic+load_learner'></span>

<h3>Description</h3>

<p>Load a 'Learner' object in 'fname', optionally putting it on the 'cpu'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_learner(fname, cpu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_learner_+3A_fname">fname</code></td>
<td>
<p>fname</p>
</td></tr>
<tr><td><code id="load_learner_+3A_cpu">cpu</code></td>
<td>
<p>cpu or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>learner object
</p>

<hr>
<h2 id='load_model_text'>Load_model_text</h2><span id='topic+load_model_text'></span>

<h3>Description</h3>

<p>Load 'model' from 'file' along with 'opt' (if available, and if 'with_opt')
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_model_text(
  file,
  model,
  opt,
  with_opt = NULL,
  device = NULL,
  strict = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_model_text_+3A_file">file</code></td>
<td>
<p>file</p>
</td></tr>
<tr><td><code id="load_model_text_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="load_model_text_+3A_opt">opt</code></td>
<td>
<p>opt</p>
</td></tr>
<tr><td><code id="load_model_text_+3A_with_opt">with_opt</code></td>
<td>
<p>with_opt</p>
</td></tr>
<tr><td><code id="load_model_text_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
<tr><td><code id="load_model_text_+3A_strict">strict</code></td>
<td>
<p>strict</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='load_pre_models'>Timm models</h2><span id='topic+load_pre_models'></span>

<h3>Description</h3>

<p>Timm models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_pre_models()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='load_tokenized_csv'>Load_tokenized_csv</h2><span id='topic+load_tokenized_csv'></span>

<h3>Description</h3>

<p>Utility function to quickly load a tokenized csv and the corresponding counter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_tokenized_csv(fname)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_tokenized_csv_+3A_fname">fname</code></td>
<td>
<p>file name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='loaders'>Loaders</h2><span id='topic+loaders'></span>

<h3>Description</h3>

<p>a loader from Catalyst
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loaders()
</code></pre>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# trigger download
loaders()


## End(Not run)

</code></pre>

<hr>
<h2 id='log'>Log</h2><span id='topic+log'></span><span id='topic+log.torch.Tensor'></span>

<h3>Description</h3>

<p>Log
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
log(x, base = exp(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="log_+3A_base">base</code></td>
<td>
<p>base parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='log.fastai.torch_core.TensorMask'>Log</h2><span id='topic+log.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Log
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
log(x, base = exp(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="log.fastai.torch_core.TensorMask_+3A_base">base</code></td>
<td>
<p>base parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='log1p'>Log1p</h2><span id='topic+log1p'></span><span id='topic+log1p.torch.Tensor'></span>

<h3>Description</h3>

<p>Log1p
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
log1p(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log1p_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='log1p.fastai.torch_core.TensorMask'>Log1p</h2><span id='topic+log1p.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Log1p
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
log1p(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log1p.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='logical_and'>Logical_and</h2><span id='topic+logical_and'></span><span id='topic++26.torch.Tensor'></span>

<h3>Description</h3>

<p>Logical_and
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
x &amp; y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logical_and_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="logical_and_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='logical_not_'>Logical_not</h2><span id='topic+logical_not_'></span><span id='topic++21.torch.Tensor'></span>

<h3>Description</h3>

<p>Logical_not
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
!x
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logical_not__+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='logical_or'>Logical_or</h2><span id='topic+logical_or'></span><span id='topic++7C.torch.Tensor'></span>

<h3>Description</h3>

<p>Logical_or
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
x | y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logical_or_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="logical_or_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='login'>Wandb login</h2><span id='topic+login'></span>

<h3>Description</h3>

<p>Log in to W&amp;B.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>login(anonymous = NULL, key = NULL, relogin = NULL, host = NULL, force = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="login_+3A_anonymous">anonymous</code></td>
<td>
<p>must,never,allow,false,true</p>
</td></tr>
<tr><td><code id="login_+3A_key">key</code></td>
<td>
<p>API key (secret)</p>
</td></tr>
<tr><td><code id="login_+3A_relogin">relogin</code></td>
<td>
<p>relogin or not</p>
</td></tr>
<tr><td><code id="login_+3A_host">host</code></td>
<td>
<p>host address</p>
</td></tr>
<tr><td><code id="login_+3A_force">force</code></td>
<td>
<p>whether to force a user to be logged into wandb when running a script</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Lookahead'>Lookahead</h2><span id='topic+Lookahead'></span>

<h3>Description</h3>

<p>Lookahead
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lookahead(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lookahead_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='LossMetric'>LossMetric</h2><span id='topic+LossMetric'></span>

<h3>Description</h3>

<p>Create a metric from 'loss_func.attr' named 'nm'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LossMetric(attr, nm = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LossMetric_+3A_attr">attr</code></td>
<td>
<p>attr</p>
</td></tr>
<tr><td><code id="LossMetric_+3A_nm">nm</code></td>
<td>
<p>nm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='lr_find'>Lr_find</h2><span id='topic+lr_find'></span>

<h3>Description</h3>

<p>Launch a mock training to find a good learning rate, return lr_min, lr_steep if 'suggestions' is TRUE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lr_find(
  object,
  start_lr = 1e-07,
  end_lr = 10,
  num_it = 100,
  stop_div = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lr_find_+3A_object">object</code></td>
<td>
<p>learner</p>
</td></tr>
<tr><td><code id="lr_find_+3A_start_lr">start_lr</code></td>
<td>
<p>starting learning rate</p>
</td></tr>
<tr><td><code id="lr_find_+3A_end_lr">end_lr</code></td>
<td>
<p>end learning rate</p>
</td></tr>
<tr><td><code id="lr_find_+3A_num_it">num_it</code></td>
<td>
<p>number of iterations</p>
</td></tr>
<tr><td><code id="lr_find_+3A_stop_div">stop_div</code></td>
<td>
<p>stop div or not</p>
</td></tr>
<tr><td><code id="lr_find_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

model %&gt;% lr_find()
model %&gt;% plot_lr_find(dpi = 200)


## End(Not run)

</code></pre>

<hr>
<h2 id='mae'>MAE</h2><span id='topic+mae'></span>

<h3>Description</h3>

<p>Mean absolute error between 'inp' and 'targ'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mae(inp, targ)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mae_+3A_inp">inp</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="mae_+3A_targ">targ</code></td>
<td>
<p>targets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='make_vocab'>Make_vocab</h2><span id='topic+make_vocab'></span>

<h3>Description</h3>

<p>Create a vocab of 'max_vocab' size from 'Counter' 'count' with items present more than 'min_freq'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_vocab(count, min_freq = 3, max_vocab = 60000, special_toks = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_vocab_+3A_count">count</code></td>
<td>
<p>count</p>
</td></tr>
<tr><td><code id="make_vocab_+3A_min_freq">min_freq</code></td>
<td>
<p>min_freq</p>
</td></tr>
<tr><td><code id="make_vocab_+3A_max_vocab">max_vocab</code></td>
<td>
<p>max_vocab</p>
</td></tr>
<tr><td><code id="make_vocab_+3A_special_toks">special_toks</code></td>
<td>
<p>special_toks</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Mask_create'>Mask_create</h2><span id='topic+Mask_create'></span>

<h3>Description</h3>

<p>Delegates ('__call__','decode','setup') to ('encodes','decodes','setups') if 'split_idx' matches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mask_create(enc = NULL, dec = NULL, split_idx = NULL, order = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mask_create_+3A_enc">enc</code></td>
<td>
<p>encoder</p>
</td></tr>
<tr><td><code id="Mask_create_+3A_dec">dec</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="Mask_create_+3A_split_idx">split_idx</code></td>
<td>
<p>split by index</p>
</td></tr>
<tr><td><code id="Mask_create_+3A_order">order</code></td>
<td>
<p>order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='mask_from_blur'>Mask from blur</h2><span id='topic+mask_from_blur'></span>

<h3>Description</h3>

<p>Mask from blur
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask_from_blur(img, window, sigma = 0.3, thresh = 0.05, remove_max = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask_from_blur_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
<tr><td><code id="mask_from_blur_+3A_window">window</code></td>
<td>
<p>windowing effect</p>
</td></tr>
<tr><td><code id="mask_from_blur_+3A_sigma">sigma</code></td>
<td>
<p>sigma</p>
</td></tr>
<tr><td><code id="mask_from_blur_+3A_thresh">thresh</code></td>
<td>
<p>thresholf point</p>
</td></tr>
<tr><td><code id="mask_from_blur_+3A_remove_max">remove_max</code></td>
<td>
<p>remove maximum or not</p>
</td></tr>
</table>

<hr>
<h2 id='mask_rcnn_infer_dl'>Mask RCNN infer dataloader</h2><span id='topic+mask_rcnn_infer_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for inferring the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask_rcnn_infer_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask_rcnn_infer_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="mask_rcnn_infer_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level. **dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
<tr><td><code id="mask_rcnn_infer_dl_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='mask_rcnn_learner'>MaskRCNN learner</h2><span id='topic+mask_rcnn_learner'></span>

<h3>Description</h3>

<p>Fastai 'Learner' adapted for MaskRCNN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask_rcnn_learner(dls, model, cbs = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask_rcnn_learner_+3A_dls">dls</code></td>
<td>
<p>'Sequence' of 'DataLoaders' passed to the 'Learner'.
The first one will be used for training and the second for validation.</p>
</td></tr>
<tr><td><code id="mask_rcnn_learner_+3A_model">model</code></td>
<td>
<p>The model to train.</p>
</td></tr>
<tr><td><code id="mask_rcnn_learner_+3A_cbs">cbs</code></td>
<td>
<p>Optional 'Sequence' of callbacks.</p>
</td></tr>
<tr><td><code id="mask_rcnn_learner_+3A_...">...</code></td>
<td>
<p>learner_kwargs: Keyword arguments that will be internally passed to 'Learner'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='mask_rcnn_model'>MaskRCNN model</h2><span id='topic+mask_rcnn_model'></span>

<h3>Description</h3>

<p>MaskRCNN model implemented by torchvision.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask_rcnn_model(
  num_classes,
  backbone = NULL,
  remove_internal_transforms = TRUE,
  pretrained = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask_rcnn_model_+3A_num_classes">num_classes</code></td>
<td>
<p>Number of classes.</p>
</td></tr>
<tr><td><code id="mask_rcnn_model_+3A_backbone">backbone</code></td>
<td>
<p>Backbone model to use. Defaults to a resnet50_fpn model.</p>
</td></tr>
<tr><td><code id="mask_rcnn_model_+3A_remove_internal_transforms">remove_internal_transforms</code></td>
<td>
<p>The torchvision model internally applies transforms like resizing and normalization, but we already do this at the &lsquo;Dataset' level, so it&rsquo;s safe to remove those internal transforms.</p>
</td></tr>
<tr><td><code id="mask_rcnn_model_+3A_pretrained">pretrained</code></td>
<td>
<p>Argument passed to 'maskrcnn_resnet50_fpn' if 'backbone is NULL'. By default it is set to TRUE: this is generally used when training a new model (transfer learning). 'pretrained = FALSE' is used during inference (prediction) for cases where the users have their own pretrained weights. **mask_rcnn_kwargs: Keyword arguments that internally are going to be passed to 'torchvision.models.detection.mask_rcnn.MaskRCNN'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='mask_rcnn_predict_dl'>Mask RCNN predict dataloader</h2><span id='topic+mask_rcnn_predict_dl'></span>

<h3>Description</h3>

<p>Mask RCNN predict dataloader
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask_rcnn_predict_dl(model, infer_dl, show_pbar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask_rcnn_predict_dl_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="mask_rcnn_predict_dl_+3A_infer_dl">infer_dl</code></td>
<td>
<p>infer_dl</p>
</td></tr>
<tr><td><code id="mask_rcnn_predict_dl_+3A_show_pbar">show_pbar</code></td>
<td>
<p>show_pbar</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='mask_rcnn_train_dl'>MaskRCNN train dataloader</h2><span id='topic+mask_rcnn_train_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for training the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask_rcnn_train_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask_rcnn_train_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="mask_rcnn_train_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level.</p>
</td></tr>
<tr><td><code id="mask_rcnn_train_dl_+3A_...">...</code></td>
<td>
<p>dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='mask_rcnn_valid_dl'>MaskRSNN valid dataloader</h2><span id='topic+mask_rcnn_valid_dl'></span>

<h3>Description</h3>

<p>A 'DataLoader' with a custom 'collate_fn' that batches items as required for training the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask_rcnn_valid_dl(dataset, batch_tfms = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask_rcnn_valid_dl_+3A_dataset">dataset</code></td>
<td>
<p>Possibly a 'Dataset' object, but more generally, any 'Sequence' that returns records.</p>
</td></tr>
<tr><td><code id="mask_rcnn_valid_dl_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>Transforms to be applied at the batch level.</p>
</td></tr>
<tr><td><code id="mask_rcnn_valid_dl_+3A_...">...</code></td>
<td>
<p>dataloader_kwargs: Keyword arguments that will be internally passed to a Pytorch 'DataLoader'. The parameter 'collate_fn' is already defined internally and cannot be passed here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='mask_tensor'>Mask_tensor</h2><span id='topic+mask_tensor'></span>

<h3>Description</h3>

<p>Mask elements of 'x' with 'neutral' with probability '1-p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask_tensor(x, p = 0.5, neutral = 0, batch = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask_tensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="mask_tensor_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="mask_tensor_+3A_neutral">neutral</code></td>
<td>
<p>neutral</p>
</td></tr>
<tr><td><code id="mask_tensor_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='mask2bbox'>Mask2bbox</h2><span id='topic+mask2bbox'></span>

<h3>Description</h3>

<p>Mask2bbox
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mask2bbox(mask, convert = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mask2bbox_+3A_mask">mask</code></td>
<td>
<p>mask</p>
</td></tr>
<tr><td><code id="mask2bbox_+3A_convert">convert</code></td>
<td>
<p>to R matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='MaskBlock'>MaskBlock</h2><span id='topic+MaskBlock'></span>

<h3>Description</h3>

<p>A 'TransformBlock' for segmentation masks, potentially with 'codes'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MaskBlock(codes = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MaskBlock_+3A_codes">codes</code></td>
<td>
<p>codes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>block
</p>

<hr>
<h2 id='masked_concat_pool'>Masked_concat_pool</h2><span id='topic+masked_concat_pool'></span>

<h3>Description</h3>

<p>Pool 'MultiBatchEncoder' outputs into one vector [last_hidden, max_pool, avg_pool]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>masked_concat_pool(output, mask, bptt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="masked_concat_pool_+3A_output">output</code></td>
<td>
<p>output</p>
</td></tr>
<tr><td><code id="masked_concat_pool_+3A_mask">mask</code></td>
<td>
<p>mask</p>
</td></tr>
<tr><td><code id="masked_concat_pool_+3A_bptt">bptt</code></td>
<td>
<p>bptt</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MaskFreq'>Mask Freq</h2><span id='topic+MaskFreq'></span>

<h3>Description</h3>

<p>Google SpecAugment frequency masking from https://arxiv.org/abs/1904.08779.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MaskFreq(num_masks = 1, size = 20, start = NULL, val = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MaskFreq_+3A_num_masks">num_masks</code></td>
<td>
<p>number of masks</p>
</td></tr>
<tr><td><code id="MaskFreq_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="MaskFreq_+3A_start">start</code></td>
<td>
<p>starting point</p>
</td></tr>
<tr><td><code id="MaskFreq_+3A_val">val</code></td>
<td>
<p>value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MaskTime'>MaskTime</h2><span id='topic+MaskTime'></span>

<h3>Description</h3>

<p>Google SpecAugment time masking from https://arxiv.org/abs/1904.08779.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MaskTime(num_masks = 1, size = 20, start = NULL, val = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MaskTime_+3A_num_masks">num_masks</code></td>
<td>
<p>number of masks</p>
</td></tr>
<tr><td><code id="MaskTime_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="MaskTime_+3A_start">start</code></td>
<td>
<p>starting point</p>
</td></tr>
<tr><td><code id="MaskTime_+3A_val">val</code></td>
<td>
<p>value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='match_embeds'>Match_embeds</h2><span id='topic+match_embeds'></span>

<h3>Description</h3>

<p>Convert the embedding in 'old_wgts' to go from 'old_vocab' to 'new_vocab'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match_embeds(old_wgts, old_vocab, new_vocab)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="match_embeds_+3A_old_wgts">old_wgts</code></td>
<td>
<p>old_wgts</p>
</td></tr>
<tr><td><code id="match_embeds_+3A_old_vocab">old_vocab</code></td>
<td>
<p>old_vocab</p>
</td></tr>
<tr><td><code id="match_embeds_+3A_new_vocab">new_vocab</code></td>
<td>
<p>new_vocab</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MatthewsCorrCoef'>MatthewsCorrCoef</h2><span id='topic+MatthewsCorrCoef'></span>

<h3>Description</h3>

<p>Matthews correlation coefficient for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MatthewsCorrCoef(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MatthewsCorrCoef_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MatthewsCorrCoefMulti'>MatthewsCorrCoefMulti</h2><span id='topic+MatthewsCorrCoefMulti'></span>

<h3>Description</h3>

<p>Matthews correlation coefficient for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MatthewsCorrCoefMulti(thresh = 0.5, sigmoid = TRUE, sample_weight = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MatthewsCorrCoefMulti_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="MatthewsCorrCoefMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="MatthewsCorrCoefMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='max'>Max</h2><span id='topic+max'></span><span id='topic+max.torch.Tensor'></span>

<h3>Description</h3>

<p>Max
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
max(a, ..., na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="max_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
<tr><td><code id="max_+3A_na.rm">na.rm</code></td>
<td>
<p>remove NAs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='max.fastai.torch_core.TensorMask'>Max</h2><span id='topic+max.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Max
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
max(a, ..., na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="max.fastai.torch_core.TensorMask_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
<tr><td><code id="max.fastai.torch_core.TensorMask_+3A_na.rm">na.rm</code></td>
<td>
<p>remove NAs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='MaxPool'>MaxPool</h2><span id='topic+MaxPool'></span>

<h3>Description</h3>

<p>nn.MaxPool layer for 'ndim'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MaxPool(ks = 2, stride = NULL, padding = 0, ndim = 2, ceil_mode = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MaxPool_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="MaxPool_+3A_stride">stride</code></td>
<td>
<p>the stride of the window. Default value is kernel_size</p>
</td></tr>
<tr><td><code id="MaxPool_+3A_padding">padding</code></td>
<td>
<p>implicit zero padding to be added on both sides</p>
</td></tr>
<tr><td><code id="MaxPool_+3A_ndim">ndim</code></td>
<td>
<p>dimension number</p>
</td></tr>
<tr><td><code id="MaxPool_+3A_ceil_mode">ceil_mode</code></td>
<td>
<p>when True, will use ceil instead of floor to compute the output shape</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='maybe_unsqueeze'>Maybe_unsqueeze</h2><span id='topic+maybe_unsqueeze'></span>

<h3>Description</h3>

<p>Add empty dimension if it is a rank 1 tensor/array
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maybe_unsqueeze(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maybe_unsqueeze_+3A_x">x</code></td>
<td>
<p>R array/matrix/tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>array
</p>

<hr>
<h2 id='MCDropoutCallback'>MCDropoutCallback</h2><span id='topic+MCDropoutCallback'></span>

<h3>Description</h3>

<p>Turns on dropout during inference, allowing you to call
Learner$get_preds multiple times to approximate your model
uncertainty using Monte Carlo Dropout. https://arxiv.org/pdf/1506.02142.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCDropoutCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCDropoutCallback_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='mean.fastai.torch_core.TensorMask'>Mean of tensor</h2><span id='topic+mean.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Mean of tensor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
mean(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mean.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="mean.fastai.torch_core.TensorMask_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='mean.torch.Tensor'>Mean of tensor</h2><span id='topic+mean.torch.Tensor'></span>

<h3>Description</h3>

<p>Mean of tensor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
mean(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mean.torch.Tensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="mean.torch.Tensor_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='medical'>Medical module</h2><span id='topic+medical'></span>

<h3>Description</h3>

<p>Medical module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medical()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MergeLayer'>MergeLayer</h2><span id='topic+MergeLayer'></span>

<h3>Description</h3>

<p>Merge a shortcut with the result of the module by adding them or concatenating them if 'dense=TRUE'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MergeLayer(dense = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MergeLayer_+3A_dense">dense</code></td>
<td>
<p>dense</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='metrics'>Metrics module</h2><span id='topic+metrics'></span>

<h3>Description</h3>

<p>Metrics module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metrics()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='migrating_ignite'>Ignite module</h2><span id='topic+migrating_ignite'></span>

<h3>Description</h3>

<p>Ignite module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>migrating_ignite()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='migrating_lightning'>Lightning module</h2><span id='topic+migrating_lightning'></span>

<h3>Description</h3>

<p>Lightning module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>migrating_lightning()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='migrating_pytorch'>Pytorch module</h2><span id='topic+migrating_pytorch'></span>

<h3>Description</h3>

<p>Pytorch module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>migrating_pytorch()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='min'>Min</h2><span id='topic+min'></span><span id='topic+min.torch.Tensor'></span>

<h3>Description</h3>

<p>Min
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
min(a, ..., na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="min_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="min_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
<tr><td><code id="min_+3A_na.rm">na.rm</code></td>
<td>
<p>remove NAs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='min.fastai.torch_core.TensorMask'>Min</h2><span id='topic+min.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Min
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
min(a, ..., na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="min.fastai.torch_core.TensorMask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="min.fastai.torch_core.TensorMask_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
<tr><td><code id="min.fastai.torch_core.TensorMask_+3A_na.rm">na.rm</code></td>
<td>
<p>remove NAs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='mish'>Mish</h2><span id='topic+mish'></span>

<h3>Description</h3>

<p>Mish
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mish(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mish_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Mish_'>Class Mish</h2><span id='topic+Mish_'></span>

<h3>Description</h3>

<p>Class Mish
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mish_(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mish__+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MishJitAutoFn'>MishJitAutoFn</h2><span id='topic+MishJitAutoFn'></span>

<h3>Description</h3>

<p>Records operation history and defines formulas for differentiating ops.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MishJitAutoFn(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MishJitAutoFn_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MixHandler'>MixHandler</h2><span id='topic+MixHandler'></span>

<h3>Description</h3>

<p>A handler class for implementing 'MixUp' style scheduling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MixHandler(alpha = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MixHandler_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MixUp'>MixUp</h2><span id='topic+MixUp'></span>

<h3>Description</h3>

<p>Implementation of https://arxiv.org/abs/1710.09412
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MixUp(alpha = 0.4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MixUp_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='model_sizes'>Model_sizes</h2><span id='topic+model_sizes'></span>

<h3>Description</h3>

<p>Pass a dummy input through the model 'm' to get the various sizes of activations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_sizes(m, size = list(64, 64))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_sizes_+3A_m">m</code></td>
<td>
<p>m parameter</p>
</td></tr>
<tr><td><code id="model_sizes_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ModelResetter'>ModelResetter</h2><span id='topic+ModelResetter'></span>

<h3>Description</h3>

<p>Callback that resets the model at each validation/training step
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ModelResetter(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ModelResetter_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Module'>Module module</h2><span id='topic+Module'></span>

<h3>Description</h3>

<p>Module module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Module()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Module_test'>NN module</h2><span id='topic+Module_test'></span>

<h3>Description</h3>

<p>NN module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Module_test()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='momentum_step'>Momentum_step</h2><span id='topic+momentum_step'></span>

<h3>Description</h3>

<p>Step for SGD with momentum with 'lr'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>momentum_step(p, lr, grad_avg, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="momentum_step_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="momentum_step_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="momentum_step_+3A_grad_avg">grad_avg</code></td>
<td>
<p>grad average</p>
</td></tr>
<tr><td><code id="momentum_step_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='most_confused'>Most_confused</h2><span id='topic+most_confused'></span>

<h3>Description</h3>

<p>Sorted descending list of largest non-diagonal entries of confusion matrix,
presented as actual, predicted, number of occurrences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>most_confused(interp, min_val = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="most_confused_+3A_interp">interp</code></td>
<td>
<p>interpretation object</p>
</td></tr>
<tr><td><code id="most_confused_+3A_min_val">min_val</code></td>
<td>
<p>minimum value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='mse'>MSE</h2><span id='topic+mse'></span>

<h3>Description</h3>

<p>Mean squared error between 'inp' and 'targ'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mse(inp, targ)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mse_+3A_inp">inp</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="mse_+3A_targ">targ</code></td>
<td>
<p>targets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

model = dls %&gt;% tabular_learner(layers=c(200,100,100,200),
metrics = list(mse(),rmse()) )


## End(Not run)

</code></pre>

<hr>
<h2 id='MSELossFlat'>MSELossFlat</h2><span id='topic+MSELossFlat'></span>

<h3>Description</h3>

<p>Flattens input and output, same as nn$MSELoss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSELossFlat(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSELossFlat_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss object
</p>

<hr>
<h2 id='msle'>MSLE</h2><span id='topic+msle'></span>

<h3>Description</h3>

<p>Mean squared logarithmic error between 'inp' and 'targ'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msle(inp, targ)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msle_+3A_inp">inp</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="msle_+3A_targ">targ</code></td>
<td>
<p>targets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MultiCategorize'>MultiCategorize</h2><span id='topic+MultiCategorize'></span>

<h3>Description</h3>

<p>Reversible transform of multi-category strings to 'vocab' id
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultiCategorize(vocab = NULL, add_na = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultiCategorize_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="MultiCategorize_+3A_add_na">add_na</code></td>
<td>
<p>add NA</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='MultiCategoryBlock'>MultiCategoryBlock</h2><span id='topic+MultiCategoryBlock'></span>

<h3>Description</h3>

<p>'TransformBlock' for multi-label categorical targets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultiCategoryBlock(encoded = FALSE, vocab = NULL, add_na = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultiCategoryBlock_+3A_encoded">encoded</code></td>
<td>
<p>encoded or not</p>
</td></tr>
<tr><td><code id="MultiCategoryBlock_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="MultiCategoryBlock_+3A_add_na">add_na</code></td>
<td>
<p>add NA</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block object
</p>

<hr>
<h2 id='multiplygit+20add+20-A+20+26amp+3B+26amp+3B+20git+20commit+20-m+20+27staging+20all+20files+27'>Multiply</h2><span id='topic+multiplygit+20add+20-A+20+26+26+20git+20commit+20-m+20+27staging+20all+20files+27'></span><span id='topic++2A.torch.Tensor'></span>

<h3>Description</h3>

<p>Multiply
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a * b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiplygit+2B20add+2B20-A+2B20+2B26amp+2B3B+2B26amp+2B3B+2B20git+2B20commit+2B20-m+2B20+2B27staging+2B20all+2B20files+2B27_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="multiplygit+2B20add+2B20-A+2B20+2B26amp+2B3B+2B26amp+2B3B+2B20git+2B20commit+2B20-m+2B20+2B27staging+2B20all+2B20files+2B27_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='MultiTargetLoss'>MultiTargetLoss</h2><span id='topic+MultiTargetLoss'></span>

<h3>Description</h3>

<p>Provides the ability to apply different loss functions to multi-modal targets/predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultiTargetLoss(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultiTargetLoss_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='n_px'>N_px</h2><span id='topic+n_px'></span>

<h3>Description</h3>

<p>int(x=0) -&gt; integer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_px(img)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_px_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='narrow'>Modify tensor</h2><span id='topic+narrow'></span>

<h3>Description</h3>

<p>Modify tensor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>narrow(tensor, slice)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="narrow_+3A_tensor">tensor</code></td>
<td>
<p>torch tensor</p>
</td></tr>
<tr><td><code id="narrow_+3A_slice">slice</code></td>
<td>
<p>dimension</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='Net'>Net</h2><span id='topic+Net'></span>

<h3>Description</h3>

<p>Net model from Migrating_Pytorch
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Net()
</code></pre>


<h3>Value</h3>

<p>model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

Net()


## End(Not run)

</code></pre>

<hr>
<h2 id='nn'>NN module</h2><span id='topic+nn'></span>

<h3>Description</h3>

<p>NN module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='nn_loss'>Fastai custom loss</h2><span id='topic+nn_loss'></span>

<h3>Description</h3>

<p>Fastai custom loss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_loss(loss_fn, name = "Custom_Loss")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_loss_+3A_loss_fn">loss_fn</code></td>
<td>
<p>pass custom model function</p>
</td></tr>
<tr><td><code id="nn_loss_+3A_name">name</code></td>
<td>
<p>set name for nn_module</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='nn_module'>Fastai NN module</h2><span id='topic+nn_module'></span>

<h3>Description</h3>

<p>Fastai NN module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_module(model_fn, name = "Custom_Model", gpu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_module_+3A_model_fn">model_fn</code></td>
<td>
<p>pass custom model function</p>
</td></tr>
<tr><td><code id="nn_module_+3A_name">name</code></td>
<td>
<p>set name for nn_module</p>
</td></tr>
<tr><td><code id="nn_module_+3A_gpu">gpu</code></td>
<td>
<p>move model to GPU</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='NoiseColor'>NoiseColor module</h2><span id='topic+NoiseColor'></span>

<h3>Description</h3>

<p>NoiseColor module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NoiseColor()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='NoneReduce'>NoneReduce</h2><span id='topic+NoneReduce'></span>

<h3>Description</h3>

<p>A context manager to evaluate 'loss_func' with none reduce.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NoneReduce(loss_func)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NoneReduce_+3A_loss_func">loss_func</code></td>
<td>
<p>loss function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='noop'>Noop</h2><span id='topic+noop'></span>

<h3>Description</h3>

<p>Noop
</p>


<h3>Usage</h3>

<pre><code class='language-R'>noop(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="noop_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='norm_apply_denorm'>Norm_apply_denorm</h2><span id='topic+norm_apply_denorm'></span>

<h3>Description</h3>

<p>Normalize 'x' with 'nrm', then apply 'f', then denormalize
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_apply_denorm(x, f, nrm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm_apply_denorm_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="norm_apply_denorm_+3A_f">f</code></td>
<td>
<p>function</p>
</td></tr>
<tr><td><code id="norm_apply_denorm_+3A_nrm">nrm</code></td>
<td>
<p>nrm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Normalize'>Normalize</h2><span id='topic+Normalize'></span>

<h3>Description</h3>

<p>Normalize the continuous variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Normalize(cat_names, cont_names)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Normalize_+3A_cat_names">cat_names</code></td>
<td>
<p>cat_names</p>
</td></tr>
<tr><td><code id="Normalize_+3A_cont_names">cont_names</code></td>
<td>
<p>cont_names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Normalize_from_stats'>Normalize from stats</h2><span id='topic+Normalize_from_stats'></span>

<h3>Description</h3>

<p>Normalize from stats
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Normalize_from_stats(mean, std, dim = 1, ndim = 4, cuda = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Normalize_from_stats_+3A_mean">mean</code></td>
<td>
<p>mean</p>
</td></tr>
<tr><td><code id="Normalize_from_stats_+3A_std">std</code></td>
<td>
<p>standard deviation</p>
</td></tr>
<tr><td><code id="Normalize_from_stats_+3A_dim">dim</code></td>
<td>
<p>dimension</p>
</td></tr>
<tr><td><code id="Normalize_from_stats_+3A_ndim">ndim</code></td>
<td>
<p>number of dimensions</p>
</td></tr>
<tr><td><code id="Normalize_from_stats_+3A_cuda">cuda</code></td>
<td>
<p>cuda or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='NormalizeTS'>NormalizeTS</h2><span id='topic+NormalizeTS'></span>

<h3>Description</h3>

<p>Normalize the x variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NormalizeTS(enc = NULL, dec = NULL, split_idx = NULL, order = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NormalizeTS_+3A_enc">enc</code></td>
<td>
<p>encoder</p>
</td></tr>
<tr><td><code id="NormalizeTS_+3A_dec">dec</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="NormalizeTS_+3A_split_idx">split_idx</code></td>
<td>
<p>split by index</p>
</td></tr>
<tr><td><code id="NormalizeTS_+3A_order">order</code></td>
<td>
<p>order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='not__mask'>Logical_not</h2><span id='topic+not__mask'></span><span id='topic++21.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Logical_not
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
!x
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="not__mask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='not_equal_to'>Not equal</h2><span id='topic+not_equal_to'></span><span id='topic++21+3D.torch.Tensor'></span>

<h3>Description</h3>

<p>Not equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a != b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="not_equal_to_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="not_equal_to_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='not_equal_to_mask_'>Not equal</h2><span id='topic+not_equal_to_mask_'></span><span id='topic++21+3D.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Not equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a != b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="not_equal_to_mask__+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="not_equal_to_mask__+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='num_features_model'>Num_features_model</h2><span id='topic+num_features_model'></span>

<h3>Description</h3>

<p>Return the number of output features for 'm'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>num_features_model(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="num_features_model_+3A_m">m</code></td>
<td>
<p>m parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Numericalize'>Numericalize</h2><span id='topic+Numericalize'></span>

<h3>Description</h3>

<p>Reversible transform of tokenized texts to numericalized ids
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Numericalize(
  vocab = NULL,
  min_freq = 3,
  max_vocab = 60000,
  special_toks = NULL,
  pad_tok = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Numericalize_+3A_vocab">vocab</code></td>
<td>
<p>vocab</p>
</td></tr>
<tr><td><code id="Numericalize_+3A_min_freq">min_freq</code></td>
<td>
<p>min_freq</p>
</td></tr>
<tr><td><code id="Numericalize_+3A_max_vocab">max_vocab</code></td>
<td>
<p>max_vocab</p>
</td></tr>
<tr><td><code id="Numericalize_+3A_special_toks">special_toks</code></td>
<td>
<p>special_toks</p>
</td></tr>
<tr><td><code id="Numericalize_+3A_pad_tok">pad_tok</code></td>
<td>
<p>pad_tok</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='OldRandomCrop'>OldRandomCrop</h2><span id='topic+OldRandomCrop'></span>

<h3>Description</h3>

<p>Randomly crop an image to 'size'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OldRandomCrop(size, pad_mode = "zeros", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OldRandomCrop_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="OldRandomCrop_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="OldRandomCrop_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='one_batch'>One batch</h2><span id='topic+one_batch'></span>

<h3>Description</h3>

<p>One batch
</p>


<h3>Usage</h3>

<pre><code class='language-R'>one_batch(object, convert = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="one_batch_+3A_object">object</code></td>
<td>
<p>data loader</p>
</td></tr>
<tr><td><code id="one_batch_+3A_convert">convert</code></td>
<td>
<p>to R matrix</p>
</td></tr>
<tr><td><code id="one_batch_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# get batch from data loader
batch = dls %&gt;% one_batch()


## End(Not run)

</code></pre>

<hr>
<h2 id='OpenAudio'>OpenAudio</h2><span id='topic+OpenAudio'></span>

<h3>Description</h3>

<p>Transform that creates AudioTensors from a list of files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OpenAudio(items)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OpenAudio_+3A_items">items</code></td>
<td>
<p>vector, items</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='optim_metric'>Optim metric</h2><span id='topic+optim_metric'></span>

<h3>Description</h3>

<p>Replace metric 'f' with a version that optimizes argument 'argname'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optim_metric(f, argname, bounds, tol = 0.01, do_neg = TRUE, get_x = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optim_metric_+3A_f">f</code></td>
<td>
<p>f</p>
</td></tr>
<tr><td><code id="optim_metric_+3A_argname">argname</code></td>
<td>
<p>argname</p>
</td></tr>
<tr><td><code id="optim_metric_+3A_bounds">bounds</code></td>
<td>
<p>bounds</p>
</td></tr>
<tr><td><code id="optim_metric_+3A_tol">tol</code></td>
<td>
<p>tol</p>
</td></tr>
<tr><td><code id="optim_metric_+3A_do_neg">do_neg</code></td>
<td>
<p>do_neg</p>
</td></tr>
<tr><td><code id="optim_metric_+3A_get_x">get_x</code></td>
<td>
<p>get_x</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Optimizer'>Optimizer</h2><span id='topic+Optimizer'></span>

<h3>Description</h3>

<p>Optimizer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Optimizer(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Optimizer_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='OptimWrapper'>OptimWrapper</h2><span id='topic+OptimWrapper'></span>

<h3>Description</h3>

<p>OptimWrapper
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptimWrapper(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptimWrapper_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='or_mask'>Logical_or</h2><span id='topic+or_mask'></span><span id='topic++7C.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Logical_or
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
x | y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="or_mask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="or_mask_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='os'>Operating system</h2><span id='topic+os'></span>

<h3>Description</h3>

<p>Operating system
</p>


<h3>Usage</h3>

<pre><code class='language-R'>os()
</code></pre>


<h3>Value</h3>

<p>vector
</p>

<hr>
<h2 id='os_environ_tpu'>An environment supporting TPUs</h2><span id='topic+os_environ_tpu'></span>

<h3>Description</h3>

<p>An environment supporting TPUs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>os_environ_tpu(text = "COLAB_TPU_ADDR")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="os_environ_tpu_+3A_text">text</code></td>
<td>
<p>string to pass to environment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='pad_conv_norm_relu'>Pad_conv_norm_relu</h2><span id='topic+pad_conv_norm_relu'></span>

<h3>Description</h3>

<p>Pad_conv_norm_relu
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pad_conv_norm_relu(
  ch_in,
  ch_out,
  pad_mode,
  norm_layer,
  ks = 3,
  bias = TRUE,
  pad = 1,
  stride = 1,
  activ = TRUE,
  init = nn()$init$kaiming_normal_,
  init_gain = 0.02
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pad_conv_norm_relu_+3A_ch_in">ch_in</code></td>
<td>
<p>input</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_ch_out">ch_out</code></td>
<td>
<p>output</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_norm_layer">norm_layer</code></td>
<td>
<p>normalization layer</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_bias">bias</code></td>
<td>
<p>bias</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_pad">pad</code></td>
<td>
<p>padding</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_stride">stride</code></td>
<td>
<p>stride</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_activ">activ</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="pad_conv_norm_relu_+3A_init_gain">init_gain</code></td>
<td>
<p>init gain</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='pad_input'>Pad_input</h2><span id='topic+pad_input'></span>

<h3>Description</h3>

<p>Function that collect 'samples' and adds padding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pad_input(
  samples,
  pad_idx = 1,
  pad_fields = 0,
  pad_first = FALSE,
  backwards = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pad_input_+3A_samples">samples</code></td>
<td>
<p>samples</p>
</td></tr>
<tr><td><code id="pad_input_+3A_pad_idx">pad_idx</code></td>
<td>
<p>pad_idx</p>
</td></tr>
<tr><td><code id="pad_input_+3A_pad_fields">pad_fields</code></td>
<td>
<p>pad_fields</p>
</td></tr>
<tr><td><code id="pad_input_+3A_pad_first">pad_first</code></td>
<td>
<p>pad_first</p>
</td></tr>
<tr><td><code id="pad_input_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='pad_input_chunk'>Pad_input_chunk</h2><span id='topic+pad_input_chunk'></span>

<h3>Description</h3>

<p>Pad 'samples' by adding padding by chunks of size 'seq_len'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pad_input_chunk(samples, pad_idx = 1, pad_first = TRUE, seq_len = 72)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pad_input_chunk_+3A_samples">samples</code></td>
<td>
<p>samples</p>
</td></tr>
<tr><td><code id="pad_input_chunk_+3A_pad_idx">pad_idx</code></td>
<td>
<p>pad_idx</p>
</td></tr>
<tr><td><code id="pad_input_chunk_+3A_pad_first">pad_first</code></td>
<td>
<p>pad_first</p>
</td></tr>
<tr><td><code id="pad_input_chunk_+3A_seq_len">seq_len</code></td>
<td>
<p>seq_len</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parallel'>Parallel</h2><span id='topic+parallel'></span>

<h3>Description</h3>

<p>Applies 'func' in parallel to 'items', using 'n_workers'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parallel(f, items, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parallel_+3A_f">f</code></td>
<td>
<p>file names</p>
</td></tr>
<tr><td><code id="parallel_+3A_items">items</code></td>
<td>
<p>items</p>
</td></tr>
<tr><td><code id="parallel_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parallel_tokenize'>Parallel_tokenize</h2><span id='topic+parallel_tokenize'></span>

<h3>Description</h3>

<p>Calls optional 'setup' on 'tok' before launching 'TokenizeWithRules' using 'parallel_gen
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parallel_tokenize(items, tok = NULL, rules = NULL, n_workers = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parallel_tokenize_+3A_items">items</code></td>
<td>
<p>items</p>
</td></tr>
<tr><td><code id="parallel_tokenize_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="parallel_tokenize_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="parallel_tokenize_+3A_n_workers">n_workers</code></td>
<td>
<p>n_workers</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='params'>Params</h2><span id='topic+params'></span>

<h3>Description</h3>

<p>Return all parameters of 'm'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>params(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="params_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ParamScheduler'>ParamScheduler</h2><span id='topic+ParamScheduler'></span>

<h3>Description</h3>

<p>Schedule hyper-parameters according to 'scheds'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ParamScheduler(scheds)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ParamScheduler_+3A_scheds">scheds</code></td>
<td>
<p>scheds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parent_label'>Parent_label</h2><span id='topic+parent_label'></span>

<h3>Description</h3>

<p>Label 'item' with the parent folder name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parent_label(o)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parent_label_+3A_o">o</code></td>
<td>
<p>string, dir path</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector
</p>

<hr>
<h2 id='parsers_AreasMixin'>AreasMixin</h2><span id='topic+parsers_AreasMixin'></span>

<h3>Description</h3>

<p>Adds areas method to parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_AreasMixin(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_AreasMixin_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_BBoxesMixin'>BBoxesMixin</h2><span id='topic+parsers_BBoxesMixin'></span>

<h3>Description</h3>

<p>Adds bboxes method to parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_BBoxesMixin(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_BBoxesMixin_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_FasterRCNN'>Faster RCNN</h2><span id='topic+parsers_FasterRCNN'></span>

<h3>Description</h3>

<p>Parser with required mixins for Faster RCNN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_FasterRCNN(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_FasterRCNN_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_FilepathMixin'>FilepathMixin</h2><span id='topic+parsers_FilepathMixin'></span>

<h3>Description</h3>

<p>Adds filepath method to parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_FilepathMixin(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_FilepathMixin_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_ImageidMixin'>Imageid Mixin</h2><span id='topic+parsers_ImageidMixin'></span>

<h3>Description</h3>

<p>Adds imageid method to parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_ImageidMixin(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_ImageidMixin_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_IsCrowdsMixin'>IsCrowdsMixin</h2><span id='topic+parsers_IsCrowdsMixin'></span>

<h3>Description</h3>

<p>Adds iscrowds method to parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_IsCrowdsMixin(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_IsCrowdsMixin_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_LabelsMixin'>LabelsMixin</h2><span id='topic+parsers_LabelsMixin'></span>

<h3>Description</h3>

<p>Adds labels method to parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_LabelsMixin(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_LabelsMixin_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_MaskRCNN'>Mask RCNN</h2><span id='topic+parsers_MaskRCNN'></span>

<h3>Description</h3>

<p>Parser with required mixins for Mask RCNN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_MaskRCNN(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_MaskRCNN_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_MasksMixin'>MasksMixin</h2><span id='topic+parsers_MasksMixin'></span>

<h3>Description</h3>

<p>Adds masks method to parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_MasksMixin(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_MasksMixin_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_SizeMixin'>SizeMixin</h2><span id='topic+parsers_SizeMixin'></span>

<h3>Description</h3>

<p>Adds image_width_height method to parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_SizeMixin(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_SizeMixin_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='parsers_voc'>Voc parser</h2><span id='topic+parsers_voc'></span>

<h3>Description</h3>

<p>Voc parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsers_voc(annotations_dir, images_dir, class_map, masks_dir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsers_voc_+3A_annotations_dir">annotations_dir</code></td>
<td>
<p>annotations_dir</p>
</td></tr>
<tr><td><code id="parsers_voc_+3A_images_dir">images_dir</code></td>
<td>
<p>images_dir</p>
</td></tr>
<tr><td><code id="parsers_voc_+3A_class_map">class_map</code></td>
<td>
<p>class_map</p>
</td></tr>
<tr><td><code id="parsers_voc_+3A_masks_dir">masks_dir</code></td>
<td>
<p>masks_dir</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='partial'>Partial</h2><span id='topic+partial'></span>

<h3>Description</h3>

<p>partial(func, *args, **keywords) - new function with partial application
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partial(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partial_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

generator = basic_generator(out_size = 64, n_channels = 3, n_extra_layers = 1)
critic    = basic_critic(in_size = 64, n_channels = 3, n_extra_layers = 1,
                         act_cls = partial(nn$LeakyReLU, negative_slope = 0.2))


## End(Not run)

</code></pre>

<hr>
<h2 id='PartialDL'>PartialDL</h2><span id='topic+PartialDL'></span>

<h3>Description</h3>

<p>Select randomly partial quantity of data at each epoch
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PartialDL(
  dataset = NULL,
  bs = NULL,
  partial_n = NULL,
  shuffle = FALSE,
  num_workers = NULL,
  verbose = FALSE,
  do_setup = TRUE,
  pin_memory = FALSE,
  timeout = 0,
  batch_size = NULL,
  drop_last = FALSE,
  indexed = NULL,
  n = NULL,
  device = NULL,
  persistent_workers = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PartialDL_+3A_dataset">dataset</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_bs">bs</code></td>
<td>
<p>bs</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_partial_n">partial_n</code></td>
<td>
<p>partial_n</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_num_workers">num_workers</code></td>
<td>
<p>num_workers</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_verbose">verbose</code></td>
<td>
<p>verbose</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_do_setup">do_setup</code></td>
<td>
<p>do_setup</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_pin_memory">pin_memory</code></td>
<td>
<p>pin_memory</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_timeout">timeout</code></td>
<td>
<p>timeout</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_batch_size">batch_size</code></td>
<td>
<p>batch_size</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_drop_last">drop_last</code></td>
<td>
<p>drop_last</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_indexed">indexed</code></td>
<td>
<p>indexed</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_n">n</code></td>
<td>
<p>n</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
<tr><td><code id="PartialDL_+3A_persistent_workers">persistent_workers</code></td>
<td>
<p>persistent_workers</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='PartialLambda'>Partial Lambda</h2><span id='topic+PartialLambda'></span>

<h3>Description</h3>

<p>Layer that applies 'partial(func, ...)'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PartialLambda(func)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PartialLambda_+3A_func">func</code></td>
<td>
<p>function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='pca'>PCA</h2><span id='topic+pca'></span>

<h3>Description</h3>

<p>Compute PCA of 'x' with 'k' dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pca(object, k = 3, convert = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pca_+3A_object">object</code></td>
<td>
<p>an object to apply PCA</p>
</td></tr>
<tr><td><code id="pca_+3A_k">k</code></td>
<td>
<p>number of dimensions</p>
</td></tr>
<tr><td><code id="pca_+3A_convert">convert</code></td>
<td>
<p>to R matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='PearsonCorrCoef'>PearsonCorrCoef</h2><span id='topic+PearsonCorrCoef'></span>

<h3>Description</h3>

<p>Pearson correlation coefficient for regression problem
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PearsonCorrCoef(
  dim_argmax = NULL,
  activation = "no",
  thresh = NULL,
  to_np = FALSE,
  invert_arg = FALSE,
  flatten = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PearsonCorrCoef_+3A_dim_argmax">dim_argmax</code></td>
<td>
<p>dim_argmax</p>
</td></tr>
<tr><td><code id="PearsonCorrCoef_+3A_activation">activation</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="PearsonCorrCoef_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="PearsonCorrCoef_+3A_to_np">to_np</code></td>
<td>
<p>to_np</p>
</td></tr>
<tr><td><code id="PearsonCorrCoef_+3A_invert_arg">invert_arg</code></td>
<td>
<p>invert_arg</p>
</td></tr>
<tr><td><code id="PearsonCorrCoef_+3A_flatten">flatten</code></td>
<td>
<p>flatten</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Perplexity'>Perplexity</h2><span id='topic+Perplexity'></span>

<h3>Description</h3>

<p>Perplexity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Perplexity(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Perplexity_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Pipeline'>Pipeline</h2><span id='topic+Pipeline'></span>

<h3>Description</h3>

<p>A pipeline of composed (for encode/decode) transforms, setup with types
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pipeline(funcs = NULL, split_idx = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pipeline_+3A_funcs">funcs</code></td>
<td>
<p>functions</p>
</td></tr>
<tr><td><code id="Pipeline_+3A_split_idx">split_idx</code></td>
<td>
<p>split by index</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='PixelShuffle_ICNR'>PixelShuffle_ICNR</h2><span id='topic+PixelShuffle_ICNR'></span>

<h3>Description</h3>

<p>Upsample by 'scale' from 'ni' filters to 'nf' (default 'ni'), using 'nn.PixelShuffle'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PixelShuffle_ICNR(
  ni,
  nf = NULL,
  scale = 2,
  blur = FALSE,
  norm_type = 3,
  act_cls = nn()$ReLU
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PixelShuffle_ICNR_+3A_ni">ni</code></td>
<td>
<p>input shape</p>
</td></tr>
<tr><td><code id="PixelShuffle_ICNR_+3A_nf">nf</code></td>
<td>
<p>number of features / outputs</p>
</td></tr>
<tr><td><code id="PixelShuffle_ICNR_+3A_scale">scale</code></td>
<td>
<p>scale</p>
</td></tr>
<tr><td><code id="PixelShuffle_ICNR_+3A_blur">blur</code></td>
<td>
<p>blur</p>
</td></tr>
<tr><td><code id="PixelShuffle_ICNR_+3A_norm_type">norm_type</code></td>
<td>
<p>normalziation type</p>
</td></tr>
<tr><td><code id="PixelShuffle_ICNR_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='plot'>Plot dicom</h2><span id='topic+plot'></span>

<h3>Description</h3>

<p>Plot dicom
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot(x, y, ..., dpi = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>y axis</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
<tr><td><code id="plot_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='plot_bs_find'>Plot_bs_find</h2><span id='topic+plot_bs_find'></span>

<h3>Description</h3>

<p>Plot_bs_find
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_bs_find(object, ..., dpi = 250)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_bs_find_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="plot_bs_find_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
<tr><td><code id="plot_bs_find_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='plot_confusion_matrix'>Plot_confusion_matrix</h2><span id='topic+plot_confusion_matrix'></span>

<h3>Description</h3>

<p>Plot the confusion matrix, with 'title' and using 'cmap'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_confusion_matrix(
  interp,
  normalize = FALSE,
  title = "Confusion matrix",
  cmap = "Blues",
  norm_dec = 2,
  plot_txt = TRUE,
  figsize = c(4, 4),
  ...,
  dpi = 120
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_confusion_matrix_+3A_interp">interp</code></td>
<td>
<p>interpretation object</p>
</td></tr>
<tr><td><code id="plot_confusion_matrix_+3A_normalize">normalize</code></td>
<td>
<p>normalize</p>
</td></tr>
<tr><td><code id="plot_confusion_matrix_+3A_title">title</code></td>
<td>
<p>title</p>
</td></tr>
<tr><td><code id="plot_confusion_matrix_+3A_cmap">cmap</code></td>
<td>
<p>color map</p>
</td></tr>
<tr><td><code id="plot_confusion_matrix_+3A_norm_dec">norm_dec</code></td>
<td>
<p>norm dec</p>
</td></tr>
<tr><td><code id="plot_confusion_matrix_+3A_plot_txt">plot_txt</code></td>
<td>
<p>plot text</p>
</td></tr>
<tr><td><code id="plot_confusion_matrix_+3A_figsize">figsize</code></td>
<td>
<p>plot size</p>
</td></tr>
<tr><td><code id="plot_confusion_matrix_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
<tr><td><code id="plot_confusion_matrix_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

interp = ClassificationInterpretation_from_learner(model)
interp %&gt;% plot_confusion_matrix(dpi = 90,figsize = c(6,6))


## End(Not run)

</code></pre>

<hr>
<h2 id='plot_loss'>Plot_loss</h2><span id='topic+plot_loss'></span>

<h3>Description</h3>

<p>Plot the losses from 'skip_start' and onward
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_loss(object, skip_start = 5, with_valid = TRUE, dpi = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_loss_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="plot_loss_+3A_skip_start">skip_start</code></td>
<td>
<p>n points to skip the start</p>
</td></tr>
<tr><td><code id="plot_loss_+3A_with_valid">with_valid</code></td>
<td>
<p>with validation</p>
</td></tr>
<tr><td><code id="plot_loss_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='plot_lr_find'>Plot_lr_find</h2><span id='topic+plot_lr_find'></span>

<h3>Description</h3>

<p>Plot the result of an LR Finder test
(won't work if you didn't do 'lr_find(learn)' before)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_lr_find(object, skip_end = 5, dpi = 250)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_lr_find_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="plot_lr_find_+3A_skip_end">skip_end</code></td>
<td>
<p>n points to skip the end</p>
</td></tr>
<tr><td><code id="plot_lr_find_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='plot_top_losses'>Plot_top_losses</h2><span id='topic+plot_top_losses'></span>

<h3>Description</h3>

<p>Plot_top_losses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_top_losses(interp, k, largest = TRUE, figsize = c(7, 5), ..., dpi = 90)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_top_losses_+3A_interp">interp</code></td>
<td>
<p>interpretation object</p>
</td></tr>
<tr><td><code id="plot_top_losses_+3A_k">k</code></td>
<td>
<p>number of images</p>
</td></tr>
<tr><td><code id="plot_top_losses_+3A_largest">largest</code></td>
<td>
<p>largest</p>
</td></tr>
<tr><td><code id="plot_top_losses_+3A_figsize">figsize</code></td>
<td>
<p>plot size</p>
</td></tr>
<tr><td><code id="plot_top_losses_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
<tr><td><code id="plot_top_losses_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# get interperetation from learn object, the model.
interp = ClassificationInterpretation_from_learner(learn)
interp %&gt;% plot_top_losses(k = 9, figsize = c(15,11))


## End(Not run)

</code></pre>

<hr>
<h2 id='PointBlock'>PointBlock</h2><span id='topic+PointBlock'></span>

<h3>Description</h3>

<p>A 'TransformBlock' for points in an image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PointBlock()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='PointScaler'>PointScaler</h2><span id='topic+PointScaler'></span>

<h3>Description</h3>

<p>Scale a tensor representing points
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PointScaler(do_scale = TRUE, y_first = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PointScaler_+3A_do_scale">do_scale</code></td>
<td>
<p>do scale</p>
</td></tr>
<tr><td><code id="PointScaler_+3A_y_first">y_first</code></td>
<td>
<p>y first</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='PooledSelfAttention2d'>PooledSelfAttention2d</h2><span id='topic+PooledSelfAttention2d'></span>

<h3>Description</h3>

<p>Pooled self attention layer for 2d.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PooledSelfAttention2d(n_channels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PooledSelfAttention2d_+3A_n_channels">n_channels</code></td>
<td>
<p>number of channels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='PoolFlatten'>PoolFlatten</h2><span id='topic+PoolFlatten'></span>

<h3>Description</h3>

<p>Combine 'nn.AdaptiveAvgPool2d' and 'Flatten'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoolFlatten(pool_type = "Avg")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoolFlatten_+3A_pool_type">pool_type</code></td>
<td>
<p>pooling type</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='PoolingLinearClassifier'>PoolingLinearClassifier</h2><span id='topic+PoolingLinearClassifier'></span>

<h3>Description</h3>

<p>Create a linear classifier with pooling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoolingLinearClassifier(dims, ps, bptt, y_range = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoolingLinearClassifier_+3A_dims">dims</code></td>
<td>
<p>dims</p>
</td></tr>
<tr><td><code id="PoolingLinearClassifier_+3A_ps">ps</code></td>
<td>
<p>ps</p>
</td></tr>
<tr><td><code id="PoolingLinearClassifier_+3A_bptt">bptt</code></td>
<td>
<p>bptt</p>
</td></tr>
<tr><td><code id="PoolingLinearClassifier_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='pow'>Pow</h2><span id='topic+pow'></span><span id='topic++5E.torch.Tensor'></span>

<h3>Description</h3>

<p>Pow
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a ^ b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pow_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="pow_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='pre_process_squad'>Pre_process_squad</h2><span id='topic+pre_process_squad'></span>

<h3>Description</h3>

<p>Pre_process_squad
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pre_process_squad(row, hf_arch, hf_tokenizer)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pre_process_squad_+3A_row">row</code></td>
<td>
<p>row in dataframe</p>
</td></tr>
<tr><td><code id="pre_process_squad_+3A_hf_arch">hf_arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="pre_process_squad_+3A_hf_tokenizer">hf_tokenizer</code></td>
<td>
<p>tokenizer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Precision'>Precision</h2><span id='topic+Precision'></span>

<h3>Description</h3>

<p>Precision for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Precision(
  axis = -1,
  labels = NULL,
  pos_label = 1,
  average = "binary",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Precision_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="Precision_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="Precision_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="Precision_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="Precision_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='PrecisionMulti'>PrecisionMulti</h2><span id='topic+PrecisionMulti'></span>

<h3>Description</h3>

<p>Precision for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrecisionMulti(
  thresh = 0.5,
  sigmoid = TRUE,
  labels = NULL,
  pos_label = 1,
  average = "macro",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrecisionMulti_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="PrecisionMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="PrecisionMulti_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="PrecisionMulti_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="PrecisionMulti_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="PrecisionMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='predict.fastai.learner.Learner'>Predict</h2><span id='topic+predict.fastai.learner.Learner'></span>

<h3>Description</h3>

<p>Prediction on 'item', fully decoded, loss function decoded and probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.learner.Learner'
predict(object, row, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.fastai.learner.Learner_+3A_object">object</code></td>
<td>
<p>the model</p>
</td></tr>
<tr><td><code id="predict.fastai.learner.Learner_+3A_row">row</code></td>
<td>
<p>row</p>
</td></tr>
<tr><td><code id="predict.fastai.learner.Learner_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='predict.fastai.tabular.learner.TabularLearner'>Predict</h2><span id='topic+predict.fastai.tabular.learner.TabularLearner'></span>

<h3>Description</h3>

<p>Prediction on 'item', fully decoded, loss function decoded and probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.tabular.learner.TabularLearner'
predict(object, row, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.fastai.tabular.learner.TabularLearner_+3A_object">object</code></td>
<td>
<p>the model</p>
</td></tr>
<tr><td><code id="predict.fastai.tabular.learner.TabularLearner_+3A_row">row</code></td>
<td>
<p>row</p>
</td></tr>
<tr><td><code id="predict.fastai.tabular.learner.TabularLearner_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='preplexity'>Perplexity</h2><span id='topic+preplexity'></span>

<h3>Description</h3>

<p>Perplexity (exponential of cross-entropy loss) for Language Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preplexity(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preplexity_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='preprocess_audio_folder'>Preprocess audio folder</h2><span id='topic+preprocess_audio_folder'></span>

<h3>Description</h3>

<p>Preprocess audio files in 'path' in parallel using 'n_workers'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocess_audio_folder(
  path,
  folders = NULL,
  output_dir = NULL,
  sample_rate = 16000,
  force_mono = TRUE,
  crop_signal_to = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocess_audio_folder_+3A_path">path</code></td>
<td>
<p>directory, path</p>
</td></tr>
<tr><td><code id="preprocess_audio_folder_+3A_folders">folders</code></td>
<td>
<p>folders</p>
</td></tr>
<tr><td><code id="preprocess_audio_folder_+3A_output_dir">output_dir</code></td>
<td>
<p>output directory</p>
</td></tr>
<tr><td><code id="preprocess_audio_folder_+3A_sample_rate">sample_rate</code></td>
<td>
<p>sample rate</p>
</td></tr>
<tr><td><code id="preprocess_audio_folder_+3A_force_mono">force_mono</code></td>
<td>
<p>force mono or not</p>
</td></tr>
<tr><td><code id="preprocess_audio_folder_+3A_crop_signal_to">crop_signal_to</code></td>
<td>
<p>int, crop signal</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='PreprocessAudio'>Preprocess Audio</h2><span id='topic+PreprocessAudio'></span>

<h3>Description</h3>

<p>Creates an audio tensor and run the basic preprocessing transforms on it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PreprocessAudio(sample_rate = 16000, force_mono = TRUE, crop_signal_to = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PreprocessAudio_+3A_sample_rate">sample_rate</code></td>
<td>
<p>sample rate</p>
</td></tr>
<tr><td><code id="PreprocessAudio_+3A_force_mono">force_mono</code></td>
<td>
<p>force mono or not</p>
</td></tr>
<tr><td><code id="PreprocessAudio_+3A_crop_signal_to">crop_signal_to</code></td>
<td>
<p>int, crop signal</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Used while preprocessing the audios, this is not a 'Transform'.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='print.fastai.learner.Learner'>Print model</h2><span id='topic+print.fastai.learner.Learner'></span>

<h3>Description</h3>

<p>Print model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.learner.Learner'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.fastai.learner.Learner_+3A_x">x</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="print.fastai.learner.Learner_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='print.fastai.tabular.learner.TabularLearner'>Print tabular model</h2><span id='topic+print.fastai.tabular.learner.TabularLearner'></span>

<h3>Description</h3>

<p>Print tabular model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.tabular.learner.TabularLearner'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.fastai.tabular.learner.TabularLearner_+3A_x">x</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="print.fastai.tabular.learner.TabularLearner_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='print.pydicom.dataset.FileDataset'>Dicom</h2><span id='topic+print.pydicom.dataset.FileDataset'></span>

<h3>Description</h3>

<p>prints dicom file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pydicom.dataset.FileDataset'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pydicom.dataset.FileDataset_+3A_x">x</code></td>
<td>
<p>dicom file</p>
</td></tr>
<tr><td><code id="print.pydicom.dataset.FileDataset_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='py_apply'>Py_apply</h2><span id='topic+py_apply'></span>

<h3>Description</h3>

<p>Pandas apply
</p>


<h3>Usage</h3>

<pre><code class='language-R'>py_apply(df, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="py_apply_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="py_apply_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe
</p>

<hr>
<h2 id='python_path'>Python path</h2><span id='topic+python_path'></span>

<h3>Description</h3>

<p>Python path
</p>


<h3>Usage</h3>

<pre><code class='language-R'>python_path()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='QHAdam'>QHAdam</h2><span id='topic+QHAdam'></span>

<h3>Description</h3>

<p>QHAdam
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QHAdam(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QHAdam_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='qhadam_step'>Qhadam_step</h2><span id='topic+qhadam_step'></span>

<h3>Description</h3>

<p>Qhadam_step
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qhadam_step(p, lr, mom, sqr_mom, sqr_avg, nu_1, nu_2, step, grad_avg, eps, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qhadam_step_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_mom">mom</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_sqr_mom">sqr_mom</code></td>
<td>
<p>sqr momentum</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_sqr_avg">sqr_avg</code></td>
<td>
<p>sqr average</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_nu_1">nu_1</code></td>
<td>
<p>nu_1</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_nu_2">nu_2</code></td>
<td>
<p>nu_2</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_step">step</code></td>
<td>
<p>step</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_grad_avg">grad_avg</code></td>
<td>
<p>gradient average</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="qhadam_step_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='QRNN'>QRNN</h2><span id='topic+QRNN'></span>

<h3>Description</h3>

<p>Apply a multiple layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QRNN(
  input_size,
  hidden_size,
  n_layers = 1,
  batch_first = TRUE,
  dropout = 0,
  bidirectional = FALSE,
  save_prev_x = FALSE,
  zoneout = 0,
  window = NULL,
  output_gate = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QRNN_+3A_input_size">input_size</code></td>
<td>
<p>input_size</p>
</td></tr>
<tr><td><code id="QRNN_+3A_hidden_size">hidden_size</code></td>
<td>
<p>hidden_size</p>
</td></tr>
<tr><td><code id="QRNN_+3A_n_layers">n_layers</code></td>
<td>
<p>n_layers</p>
</td></tr>
<tr><td><code id="QRNN_+3A_batch_first">batch_first</code></td>
<td>
<p>batch_first</p>
</td></tr>
<tr><td><code id="QRNN_+3A_dropout">dropout</code></td>
<td>
<p>dropout</p>
</td></tr>
<tr><td><code id="QRNN_+3A_bidirectional">bidirectional</code></td>
<td>
<p>bidirectional</p>
</td></tr>
<tr><td><code id="QRNN_+3A_save_prev_x">save_prev_x</code></td>
<td>
<p>save_prev_x</p>
</td></tr>
<tr><td><code id="QRNN_+3A_zoneout">zoneout</code></td>
<td>
<p>zoneout</p>
</td></tr>
<tr><td><code id="QRNN_+3A_window">window</code></td>
<td>
<p>window</p>
</td></tr>
<tr><td><code id="QRNN_+3A_output_gate">output_gate</code></td>
<td>
<p>output_gate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='QRNNLayer'>QRNNLayer</h2><span id='topic+QRNNLayer'></span>

<h3>Description</h3>

<p>Apply a single layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QRNNLayer(
  input_size,
  hidden_size = NULL,
  save_prev_x = FALSE,
  zoneout = 0,
  window = 1,
  output_gate = TRUE,
  batch_first = TRUE,
  backward = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QRNNLayer_+3A_input_size">input_size</code></td>
<td>
<p>input_size</p>
</td></tr>
<tr><td><code id="QRNNLayer_+3A_hidden_size">hidden_size</code></td>
<td>
<p>hidden_size</p>
</td></tr>
<tr><td><code id="QRNNLayer_+3A_save_prev_x">save_prev_x</code></td>
<td>
<p>save_prev_x</p>
</td></tr>
<tr><td><code id="QRNNLayer_+3A_zoneout">zoneout</code></td>
<td>
<p>zoneout</p>
</td></tr>
<tr><td><code id="QRNNLayer_+3A_window">window</code></td>
<td>
<p>window</p>
</td></tr>
<tr><td><code id="QRNNLayer_+3A_output_gate">output_gate</code></td>
<td>
<p>output_gate</p>
</td></tr>
<tr><td><code id="QRNNLayer_+3A_batch_first">batch_first</code></td>
<td>
<p>batch_first</p>
</td></tr>
<tr><td><code id="QRNNLayer_+3A_backward">backward</code></td>
<td>
<p>backward</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='R2Score'>R2Score</h2><span id='topic+R2Score'></span>

<h3>Description</h3>

<p>R2 score between predictions and targets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R2Score(sample_weight = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R2Score_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RAdam'>RAdam</h2><span id='topic+RAdam'></span>

<h3>Description</h3>

<p>RAdam
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RAdam(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RAdam_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='radam_step'>Radam_step</h2><span id='topic+radam_step'></span>

<h3>Description</h3>

<p>Step for RAdam with 'lr' on 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>radam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, beta, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="radam_step_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="radam_step_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="radam_step_+3A_mom">mom</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="radam_step_+3A_step">step</code></td>
<td>
<p>step</p>
</td></tr>
<tr><td><code id="radam_step_+3A_sqr_mom">sqr_mom</code></td>
<td>
<p>sqr momentum</p>
</td></tr>
<tr><td><code id="radam_step_+3A_grad_avg">grad_avg</code></td>
<td>
<p>grad average</p>
</td></tr>
<tr><td><code id="radam_step_+3A_sqr_avg">sqr_avg</code></td>
<td>
<p>sqr average</p>
</td></tr>
<tr><td><code id="radam_step_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="radam_step_+3A_beta">beta</code></td>
<td>
<p>beta</p>
</td></tr>
<tr><td><code id="radam_step_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RandomCrop'>RandomCrop</h2><span id='topic+RandomCrop'></span>

<h3>Description</h3>

<p>Randomly crop an image to 'size'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomCrop(size, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RandomCrop_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="RandomCrop_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RandomErasing'>RandomErasing</h2><span id='topic+RandomErasing'></span>

<h3>Description</h3>

<p>Randomly selects a rectangle region in an image and randomizes its pixels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomErasing(p = 0.5, sl = 0, sh = 0.3, min_aspect = 0.3, max_count = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RandomErasing_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="RandomErasing_+3A_sl">sl</code></td>
<td>
<p>sl</p>
</td></tr>
<tr><td><code id="RandomErasing_+3A_sh">sh</code></td>
<td>
<p>sh</p>
</td></tr>
<tr><td><code id="RandomErasing_+3A_min_aspect">min_aspect</code></td>
<td>
<p>minimum aspect</p>
</td></tr>
<tr><td><code id="RandomErasing_+3A_max_count">max_count</code></td>
<td>
<p>maximum count</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RandomResizedCrop'>RandomResizedCrop</h2><span id='topic+RandomResizedCrop'></span>

<h3>Description</h3>

<p>Picks a random scaled crop of an image and resize it to 'size'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomResizedCrop(
  size,
  min_scale = 0.08,
  ratio = list(0.75, 1.33333333333333),
  resamples = list(2, 0),
  val_xtra = 0.14
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RandomResizedCrop_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="RandomResizedCrop_+3A_min_scale">min_scale</code></td>
<td>
<p>minimum scale</p>
</td></tr>
<tr><td><code id="RandomResizedCrop_+3A_ratio">ratio</code></td>
<td>
<p>ratio</p>
</td></tr>
<tr><td><code id="RandomResizedCrop_+3A_resamples">resamples</code></td>
<td>
<p>resamples</p>
</td></tr>
<tr><td><code id="RandomResizedCrop_+3A_val_xtra">val_xtra</code></td>
<td>
<p>validation xtra</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RandomResizedCropGPU'>RandomResizedCropGPU</h2><span id='topic+RandomResizedCropGPU'></span>

<h3>Description</h3>

<p>Picks a random scaled crop of an image and resize it to 'size'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomResizedCropGPU(
  size,
  min_scale = 0.08,
  ratio = list(0.75, 1.33333333333333),
  mode = "bilinear",
  valid_scale = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RandomResizedCropGPU_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="RandomResizedCropGPU_+3A_min_scale">min_scale</code></td>
<td>
<p>minimum scale</p>
</td></tr>
<tr><td><code id="RandomResizedCropGPU_+3A_ratio">ratio</code></td>
<td>
<p>ratio</p>
</td></tr>
<tr><td><code id="RandomResizedCropGPU_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="RandomResizedCropGPU_+3A_valid_scale">valid_scale</code></td>
<td>
<p>validation scale</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RandomSplitter'>RandomSplitter</h2><span id='topic+RandomSplitter'></span>

<h3>Description</h3>

<p>Create function that splits 'items' between train/val with 'valid_pct' randomly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomSplitter(valid_pct = 0.2, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RandomSplitter_+3A_valid_pct">valid_pct</code></td>
<td>
<p>validation percenatge split</p>
</td></tr>
<tr><td><code id="RandomSplitter_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RandPair'>RandPair</h2><span id='topic+RandPair'></span>

<h3>Description</h3>

<p>a random image from domain B, resulting in a random pair of images from domain A and B.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandPair(itemsB)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RandPair_+3A_itemsb">itemsB</code></td>
<td>
<p>a random image from domain B</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RandTransform'>RandTransform</h2><span id='topic+RandTransform'></span>

<h3>Description</h3>

<p>A transform that before_call its state at each '__call__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandTransform(p = 1, nm = NULL, before_call = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RandTransform_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="RandTransform_+3A_nm">nm</code></td>
<td>
<p>nm</p>
</td></tr>
<tr><td><code id="RandTransform_+3A_before_call">before_call</code></td>
<td>
<p>before call</p>
</td></tr>
<tr><td><code id="RandTransform_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ranger'>Ranger</h2><span id='topic+ranger'></span>

<h3>Description</h3>

<p>Convenience method for 'Lookahead' with 'RAdam'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ranger(
  p,
  lr,
  mom = 0.95,
  wd = 0.01,
  eps = 1e-06,
  sqr_mom = 0.99,
  beta = 0,
  decouple_wd = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ranger_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="ranger_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="ranger_+3A_mom">mom</code></td>
<td>
<p>momentum</p>
</td></tr>
<tr><td><code id="ranger_+3A_wd">wd</code></td>
<td>
<p>weight decay</p>
</td></tr>
<tr><td><code id="ranger_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="ranger_+3A_sqr_mom">sqr_mom</code></td>
<td>
<p>sqr momentum</p>
</td></tr>
<tr><td><code id="ranger_+3A_beta">beta</code></td>
<td>
<p>beta</p>
</td></tr>
<tr><td><code id="ranger_+3A_decouple_wd">decouple_wd</code></td>
<td>
<p>decouple weight decay</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RatioResize'>RatioResize</h2><span id='topic+RatioResize'></span>

<h3>Description</h3>

<p>Resizes the biggest dimension of an image to 'max_sz' maintaining the aspect ratio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RatioResize(max_sz, resamples = list(2, 0), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RatioResize_+3A_max_sz">max_sz</code></td>
<td>
<p>maximum sz</p>
</td></tr>
<tr><td><code id="RatioResize_+3A_resamples">resamples</code></td>
<td>
<p>resamples</p>
</td></tr>
<tr><td><code id="RatioResize_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ReadTSBatch'>ReadTSBatch</h2><span id='topic+ReadTSBatch'></span>

<h3>Description</h3>

<p>A transform that always take lists as items
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadTSBatch(to)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadTSBatch_+3A_to">to</code></td>
<td>
<p>output from TSDataTable function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Recall'>Recall</h2><span id='topic+Recall'></span>

<h3>Description</h3>

<p>Recall for single-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Recall(
  axis = -1,
  labels = NULL,
  pos_label = 1,
  average = "binary",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Recall_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="Recall_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="Recall_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="Recall_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="Recall_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RecallMulti'>RecallMulti</h2><span id='topic+RecallMulti'></span>

<h3>Description</h3>

<p>Recall for multi-label classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RecallMulti(
  thresh = 0.5,
  sigmoid = TRUE,
  labels = NULL,
  pos_label = 1,
  average = "macro",
  sample_weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RecallMulti_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="RecallMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="RecallMulti_+3A_labels">labels</code></td>
<td>
<p>labels</p>
</td></tr>
<tr><td><code id="RecallMulti_+3A_pos_label">pos_label</code></td>
<td>
<p>pos_label</p>
</td></tr>
<tr><td><code id="RecallMulti_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="RecallMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ReduceLROnPlateau'>ReduceLROnPlateau</h2><span id='topic+ReduceLROnPlateau'></span>

<h3>Description</h3>

<p>ReduceLROnPlateau
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReduceLROnPlateau(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReduceLROnPlateau_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

URLs_MNIST_SAMPLE()
# transformations
tfms = aug_transforms(do_flip = FALSE)
path = 'mnist_sample'
bs = 20

#load into memory
data = ImageDataLoaders_from_folder(path, batch_tfms = tfms, size = 26, bs = bs)


learn = cnn_learner(data, resnet18(), metrics = accuracy, path = getwd())

learn %&gt;% fit_one_cycle(10, 1e-2, cbs = ReduceLROnPlateau(monitor='valid_loss', patience = 1))


## End(Not run)

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+fit'></span><span id='topic+predict'></span><span id='topic+median'></span><span id='topic+dev.off'></span><span id='topic+sd'></span><span id='topic+capture.output'></span><span id='topic+download.file'></span><span id='topic+array_reshape'></span><span id='topic+py_load_object'></span><span id='topic+PyClass'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+fit">fit</a></code></p>
</dd>
<dt>grDevices</dt><dd><p><code><a href="grDevices.html#topic+dev">dev.off</a></code></p>
</dd>
<dt>reticulate</dt><dd><p><code><a href="reticulate.html#topic+PyClass">PyClass</a></code>, <code><a href="reticulate.html#topic+array_reshape">array_reshape</a></code>, <code><a href="reticulate.html#topic+py_save_object">py_load_object</a></code></p>
</dd>
<dt>stats</dt><dd><p><code><a href="stats.html#topic+median">median</a></code>, <code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="stats.html#topic+sd">sd</a></code></p>
</dd>
<dt>utils</dt><dd><p><code><a href="utils.html#topic+capture.output">capture.output</a></code>, <code><a href="utils.html#topic+download.file">download.file</a></code></p>
</dd>
</dl>


<h3>Value</h3>

<p>None
</p>
<p>None
</p>
<p>None
</p>
<p>None
</p>
<p>None
</p>
<p>None
</p>
<p>None
</p>
<p>None
</p>
<p>None
</p>
<p>None
</p>

<hr>
<h2 id='RegressionBlock'>RegressionBlock</h2><span id='topic+RegressionBlock'></span>

<h3>Description</h3>

<p>'TransformBlock' for float targets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RegressionBlock(n_out = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RegressionBlock_+3A_n_out">n_out</code></td>
<td>
<p>number of out features</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block object
</p>

<hr>
<h2 id='RemoveSilence'>Remove Silence</h2><span id='topic+RemoveSilence'></span>

<h3>Description</h3>

<p>Split signal at points of silence greater than 2*pad_ms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RemoveSilence(
  remove_type = RemoveType()$Trim$value,
  threshold = 20,
  pad_ms = 20
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RemoveSilence_+3A_remove_type">remove_type</code></td>
<td>
<p>remove type from RemoveType module</p>
</td></tr>
<tr><td><code id="RemoveSilence_+3A_threshold">threshold</code></td>
<td>
<p>threshold point</p>
</td></tr>
<tr><td><code id="RemoveSilence_+3A_pad_ms">pad_ms</code></td>
<td>
<p>pad milliseconds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RemoveType'>RemoveType module</h2><span id='topic+RemoveType'></span>

<h3>Description</h3>

<p>RemoveType module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RemoveType()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='replace_all_caps'>Replace_all_caps</h2><span id='topic+replace_all_caps'></span>

<h3>Description</h3>

<p>Replace tokens in ALL CAPS by their lower version and add 'TK_UP' before.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_all_caps(t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_all_caps_+3A_t">t</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>

<hr>
<h2 id='replace_maj'>Replace_maj</h2><span id='topic+replace_maj'></span>

<h3>Description</h3>

<p>Replace tokens in ALL CAPS by their lower version and add 'TK_UP' before.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_maj(t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_maj_+3A_t">t</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>

<hr>
<h2 id='replace_rep'>Replace_rep</h2><span id='topic+replace_rep'></span>

<h3>Description</h3>

<p>Replace repetitions at the character level: cccc &ndash; TK_REP 4 c
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_rep(t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_rep_+3A_t">t</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>

<hr>
<h2 id='replace_wrep'>Replace_wrep</h2><span id='topic+replace_wrep'></span>

<h3>Description</h3>

<p>Replace word repetitions: word word word word &ndash; TK_WREP 4 word
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_wrep(t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_wrep_+3A_t">t</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>

<hr>
<h2 id='res_block_1d'>Res_block_1d</h2><span id='topic+res_block_1d'></span>

<h3>Description</h3>

<p>Resnet block as described in the paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>res_block_1d(nf, ks = c(5, 3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="res_block_1d_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="res_block_1d_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>block
</p>

<hr>
<h2 id='Resample'>Resample</h2><span id='topic+Resample'></span>

<h3>Description</h3>

<p>Resample using faster polyphase technique and avoiding FFT computation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Resample(sr_new)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Resample_+3A_sr_new">sr_new</code></td>
<td>
<p>input</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ResBlock'>ResBlock</h2><span id='topic+ResBlock'></span>

<h3>Description</h3>

<p>Resnet block from 'ni' to 'nh' with 'stride'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ResBlock(
  expansion,
  ni,
  nf,
  stride = 1,
  groups = 1,
  reduction = NULL,
  nh1 = NULL,
  nh2 = NULL,
  dw = FALSE,
  g2 = 1,
  sa = FALSE,
  sym = FALSE,
  norm_type = 1,
  act_cls = nn$ReLU,
  ndim = 2,
  ks = 3,
  pool = AvgPool(),
  pool_first = TRUE,
  padding = NULL,
  bias = NULL,
  bn_1st = TRUE,
  transpose = FALSE,
  init = "auto",
  xtra = NULL,
  bias_std = 0.01,
  dilation = 1,
  padding_mode = "zeros"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ResBlock_+3A_expansion">expansion</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_ni">ni</code></td>
<td>
<p>number of linear inputs</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_stride">stride</code></td>
<td>
<p>stride number</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_groups">groups</code></td>
<td>
<p>groups number</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_reduction">reduction</code></td>
<td>
<p>reduction</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_nh1">nh1</code></td>
<td>
<p>out channels 1</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_nh2">nh2</code></td>
<td>
<p>out channels 2</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_dw">dw</code></td>
<td>
<p>dw paramer</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_g2">g2</code></td>
<td>
<p>g2 block</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_sa">sa</code></td>
<td>
<p>sa parameter</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_sym">sym</code></td>
<td>
<p>symmetric</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_ndim">ndim</code></td>
<td>
<p>dimension number</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_pool">pool</code></td>
<td>
<p>pooling type, Average, Max</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_pool_first">pool_first</code></td>
<td>
<p>pooling first</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_padding">padding</code></td>
<td>
<p>padding</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_bias">bias</code></td>
<td>
<p>bias</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_bn_1st">bn_1st</code></td>
<td>
<p>batch normalization 1st</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_transpose">transpose</code></td>
<td>
<p>transpose</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_xtra">xtra</code></td>
<td>
<p>xtra</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_bias_std">bias_std</code></td>
<td>
<p>bias standard deviation</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_dilation">dilation</code></td>
<td>
<p>dilation number</p>
</td></tr>
<tr><td><code id="ResBlock_+3A_padding_mode">padding_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block object
</p>

<hr>
<h2 id='reshape'>Reshape</h2><span id='topic+reshape'></span>

<h3>Description</h3>

<p>resize x to (w,h)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reshape(x, h, w, resample = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reshape_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="reshape_+3A_h">h</code></td>
<td>
<p>height</p>
</td></tr>
<tr><td><code id="reshape_+3A_w">w</code></td>
<td>
<p>width</p>
</td></tr>
<tr><td><code id="reshape_+3A_resample">resample</code></td>
<td>
<p>resample value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Resize'>Resize</h2><span id='topic+Resize'></span>

<h3>Description</h3>

<p>A transform that before_call its state at each '__call__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Resize(size, method = "crop", pad_mode = "reflection", resamples = list(2, 0))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Resize_+3A_size">size</code></td>
<td>
<p>size of image</p>
</td></tr>
<tr><td><code id="Resize_+3A_method">method</code></td>
<td>
<p>method</p>
</td></tr>
<tr><td><code id="Resize_+3A_pad_mode">pad_mode</code></td>
<td>
<p>reflection, zeros, border as string parameter</p>
</td></tr>
<tr><td><code id="Resize_+3A_resamples">resamples</code></td>
<td>
<p>list of integers</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='resize_max'>Resize_max</h2><span id='topic+resize_max'></span>

<h3>Description</h3>

<p>'resize' 'x' to 'max_px', or 'max_h', or 'max_w'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resize_max(img, resample = 0, max_px = NULL, max_h = NULL, max_w = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resize_max_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
<tr><td><code id="resize_max_+3A_resample">resample</code></td>
<td>
<p>resample value</p>
</td></tr>
<tr><td><code id="resize_max_+3A_max_px">max_px</code></td>
<td>
<p>max px</p>
</td></tr>
<tr><td><code id="resize_max_+3A_max_h">max_h</code></td>
<td>
<p>max height</p>
</td></tr>
<tr><td><code id="resize_max_+3A_max_w">max_w</code></td>
<td>
<p>max width</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ResizeBatch'>ResizeBatch</h2><span id='topic+ResizeBatch'></span>

<h3>Description</h3>

<p>Reshape x to size, keeping batch dim the same size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ResizeBatch(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ResizeBatch_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ResizeSignal'>Resize Signal</h2><span id='topic+ResizeSignal'></span>

<h3>Description</h3>

<p>Crops signal to be length specified in ms by duration, padding if needed
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ResizeSignal(duration, pad_mode = AudioPadType()$Zeros)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ResizeSignal_+3A_duration">duration</code></td>
<td>
<p>int, duration</p>
</td></tr>
<tr><td><code id="ResizeSignal_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ResNet'>ResNet</h2><span id='topic+ResNet'></span>

<h3>Description</h3>

<p>Base class for all neural network modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ResNet(
  block,
  layers,
  num_classes = 1000,
  zero_init_residual = FALSE,
  groups = 1,
  width_per_group = 64,
  replace_stride_with_dilation = NULL,
  norm_layer = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ResNet_+3A_block">block</code></td>
<td>
<p>the blocks that need to passed to ResNet</p>
</td></tr>
<tr><td><code id="ResNet_+3A_layers">layers</code></td>
<td>
<p>the layers to pass to ResNet</p>
</td></tr>
<tr><td><code id="ResNet_+3A_num_classes">num_classes</code></td>
<td>
<p>the number of classes</p>
</td></tr>
<tr><td><code id="ResNet_+3A_zero_init_residual">zero_init_residual</code></td>
<td>
<p>logical, initializer</p>
</td></tr>
<tr><td><code id="ResNet_+3A_groups">groups</code></td>
<td>
<p>the groups</p>
</td></tr>
<tr><td><code id="ResNet_+3A_width_per_group">width_per_group</code></td>
<td>
<p>the width per group</p>
</td></tr>
<tr><td><code id="ResNet_+3A_replace_stride_with_dilation">replace_stride_with_dilation</code></td>
<td>
<p>logical, replace stride with dilation</p>
</td></tr>
<tr><td><code id="ResNet_+3A_norm_layer">norm_layer</code></td>
<td>
<p>norm_layer</p>
</td></tr>
</table>

<hr>
<h2 id='resnet_generator'>Resnet_generator</h2><span id='topic+resnet_generator'></span>

<h3>Description</h3>

<p>Resnet_generator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resnet_generator(
  ch_in,
  ch_out,
  n_ftrs = 64,
  norm_layer = NULL,
  dropout = 0,
  n_blocks = 9,
  pad_mode = "reflection"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resnet_generator_+3A_ch_in">ch_in</code></td>
<td>
<p>input</p>
</td></tr>
<tr><td><code id="resnet_generator_+3A_ch_out">ch_out</code></td>
<td>
<p>output</p>
</td></tr>
<tr><td><code id="resnet_generator_+3A_n_ftrs">n_ftrs</code></td>
<td>
<p>filter</p>
</td></tr>
<tr><td><code id="resnet_generator_+3A_norm_layer">norm_layer</code></td>
<td>
<p>normalziation layer</p>
</td></tr>
<tr><td><code id="resnet_generator_+3A_dropout">dropout</code></td>
<td>
<p>dropout rate</p>
</td></tr>
<tr><td><code id="resnet_generator_+3A_n_blocks">n_blocks</code></td>
<td>
<p>number of blocks</p>
</td></tr>
<tr><td><code id="resnet_generator_+3A_pad_mode">pad_mode</code></td>
<td>
<p>paddoing mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='resnet101'>Resnet101</h2><span id='topic+resnet101'></span>

<h3>Description</h3>

<p>ResNet-101 model from
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resnet101(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resnet101_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="resnet101_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='resnet152'>Resnet152</h2><span id='topic+resnet152'></span>

<h3>Description</h3>

<p>Resnet152
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resnet152(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resnet152_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="resnet152_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='resnet18'>Resnet18</h2><span id='topic+resnet18'></span>

<h3>Description</h3>

<p>Resnet18
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resnet18(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resnet18_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="resnet18_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='resnet34'>Resnet34</h2><span id='topic+resnet34'></span>

<h3>Description</h3>

<p>ResNet-34 model from
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resnet34(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resnet34_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="resnet34_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='resnet50'>Resnet50</h2><span id='topic+resnet50'></span>

<h3>Description</h3>

<p>Resnet50
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resnet50(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resnet50_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="resnet50_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='ResnetBlock'>ResnetBlock</h2><span id='topic+ResnetBlock'></span>

<h3>Description</h3>

<p>nn()$Module for the ResNet Block
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ResnetBlock(
  dim,
  pad_mode = "reflection",
  norm_layer = NULL,
  dropout = 0,
  bias = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ResnetBlock_+3A_dim">dim</code></td>
<td>
<p>dimension</p>
</td></tr>
<tr><td><code id="ResnetBlock_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="ResnetBlock_+3A_norm_layer">norm_layer</code></td>
<td>
<p>normalization layer</p>
</td></tr>
<tr><td><code id="ResnetBlock_+3A_dropout">dropout</code></td>
<td>
<p>dropout rate</p>
</td></tr>
<tr><td><code id="ResnetBlock_+3A_bias">bias</code></td>
<td>
<p>bias or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RetinaNet'>RetinaNet</h2><span id='topic+RetinaNet'></span>

<h3>Description</h3>

<p>Implements RetinaNet from https://arxiv.org/abs/1708.02002
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RetinaNet(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RetinaNet_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

encoder = create_body(resnet34(), pretrained = TRUE)
arch = RetinaNet(encoder, get_c(dls), final_bias=-4)


## End(Not run)


</code></pre>

<hr>
<h2 id='retinanet_'>Retinanet module</h2><span id='topic+retinanet_'></span>

<h3>Description</h3>

<p>Retinanet module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>retinanet_()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RetinaNetFocalLoss'>RetinaNetFocalLoss</h2><span id='topic+RetinaNetFocalLoss'></span>

<h3>Description</h3>

<p>Base class for all neural network modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RetinaNetFocalLoss(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RetinaNetFocalLoss_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes:: import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:'to', etc.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='reverse_text'>Reverse_text</h2><span id='topic+reverse_text'></span>

<h3>Description</h3>

<p>Reverse_text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reverse_text(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reverse_text_+3A_x">x</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>

<hr>
<h2 id='rgb2hsv'>Rgb2hsv</h2><span id='topic+rgb2hsv'></span>

<h3>Description</h3>

<p>Converts a RGB image to an HSV image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgb2hsv(img)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rgb2hsv_+3A_img">img</code></td>
<td>
<p>image object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note: Will not work on logit space images.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='rm_useless_spaces'>Rm_useless_spaces</h2><span id='topic+rm_useless_spaces'></span>

<h3>Description</h3>

<p>Remove multiple spaces
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rm_useless_spaces(t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rm_useless_spaces_+3A_t">t</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

rm_useless_spaces('hello,   Sir!')


## End(Not run)

</code></pre>

<hr>
<h2 id='rms_prop_step'>Rms_prop_step</h2><span id='topic+rms_prop_step'></span>

<h3>Description</h3>

<p>Step for SGD with momentum with 'lr'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rms_prop_step(p, lr, sqr_avg, eps, grad_avg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rms_prop_step_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="rms_prop_step_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="rms_prop_step_+3A_sqr_avg">sqr_avg</code></td>
<td>
<p>sqr average</p>
</td></tr>
<tr><td><code id="rms_prop_step_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="rms_prop_step_+3A_grad_avg">grad_avg</code></td>
<td>
<p>grad average</p>
</td></tr>
<tr><td><code id="rms_prop_step_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='rmse'>RMSE</h2><span id='topic+rmse'></span>

<h3>Description</h3>

<p>Root mean squared error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmse(preds, targs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmse_+3A_preds">preds</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="rmse_+3A_targs">targs</code></td>
<td>
<p>targets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

model = dls %&gt;% tabular_learner(layers=c(200,100,100,200),
metrics = list(mse(),rmse()) )


## End(Not run)

</code></pre>

<hr>
<h2 id='RMSProp'>RMSProp</h2><span id='topic+RMSProp'></span>

<h3>Description</h3>

<p>RMSProp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSProp(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSProp_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RNNDropout'>RNNDropout</h2><span id='topic+RNNDropout'></span>

<h3>Description</h3>

<p>Dropout with probability 'p' that is consistent on the seq_len dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RNNDropout(p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RNNDropout_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RNNRegularizer'>RNNRegularizer</h2><span id='topic+RNNRegularizer'></span>

<h3>Description</h3>

<p>'Callback' that adds AR and TAR regularization in RNN training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RNNRegularizer(alpha = 0, beta = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RNNRegularizer_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
<tr><td><code id="RNNRegularizer_+3A_beta">beta</code></td>
<td>
<p>beta</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RocAuc'>RocAuc</h2><span id='topic+RocAuc'></span>

<h3>Description</h3>

<p>Area Under the Receiver Operating Characteristic
Curve for single-label multiclass classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RocAuc(
  axis = -1,
  average = "macro",
  sample_weight = NULL,
  max_fpr = NULL,
  multi_class = "ovr"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RocAuc_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="RocAuc_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="RocAuc_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
<tr><td><code id="RocAuc_+3A_max_fpr">max_fpr</code></td>
<td>
<p>max_fpr</p>
</td></tr>
<tr><td><code id="RocAuc_+3A_multi_class">multi_class</code></td>
<td>
<p>multi_class</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='RocAucBinary'>RocAucBinary</h2><span id='topic+RocAucBinary'></span>

<h3>Description</h3>

<p>Area Under the Receiver Operating Characteristic Curve for single-label binary classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RocAucBinary(
  axis = -1,
  average = "macro",
  sample_weight = NULL,
  max_fpr = NULL,
  multi_class = "raise"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RocAucBinary_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="RocAucBinary_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="RocAucBinary_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
<tr><td><code id="RocAucBinary_+3A_max_fpr">max_fpr</code></td>
<td>
<p>max_fpr</p>
</td></tr>
<tr><td><code id="RocAucBinary_+3A_multi_class">multi_class</code></td>
<td>
<p>multi_class</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

model = dls %&gt;% tabular_learner(layers=c(200,100,100,200),
config = tabular_config(embed_p = 0.3, use_bn = FALSE),
metrics = list(accuracy, RocAucBinary(),
               Precision(), Recall(),
               F1Score()))


## End(Not run)

</code></pre>

<hr>
<h2 id='RocAucMulti'>RocAucMulti</h2><span id='topic+RocAucMulti'></span>

<h3>Description</h3>

<p>Area Under the Receiver Operating Characteristic Curve for multi-label binary classification problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RocAucMulti(
  sigmoid = TRUE,
  average = "macro",
  sample_weight = NULL,
  max_fpr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RocAucMulti_+3A_sigmoid">sigmoid</code></td>
<td>
<p>sigmoid</p>
</td></tr>
<tr><td><code id="RocAucMulti_+3A_average">average</code></td>
<td>
<p>average</p>
</td></tr>
<tr><td><code id="RocAucMulti_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample_weight</p>
</td></tr>
<tr><td><code id="RocAucMulti_+3A_max_fpr">max_fpr</code></td>
<td>
<p>max_fpr</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Rotate'>Rotate</h2><span id='topic+Rotate'></span>

<h3>Description</h3>

<p>Apply a random rotation of at most 'max_deg' with probability 'p' to a batch of images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rotate(
  max_deg = 10,
  p = 0.5,
  draw = NULL,
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  align_corners = TRUE,
  batch = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rotate_+3A_max_deg">max_deg</code></td>
<td>
<p>maximum degrees</p>
</td></tr>
<tr><td><code id="Rotate_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="Rotate_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="Rotate_+3A_size">size</code></td>
<td>
<p>size of image</p>
</td></tr>
<tr><td><code id="Rotate_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="Rotate_+3A_pad_mode">pad_mode</code></td>
<td>
<p>reflection, zeros, border as string parameter</p>
</td></tr>
<tr><td><code id="Rotate_+3A_align_corners">align_corners</code></td>
<td>
<p>align corners or not</p>
</td></tr>
<tr><td><code id="Rotate_+3A_batch">batch</code></td>
<td>
<p>batch or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='rotate_mat'>Rotate_mat</h2><span id='topic+rotate_mat'></span>

<h3>Description</h3>

<p>Return a random rotation matrix with 'max_deg' and 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rotate_mat(x, max_deg = 10, p = 0.5, draw = NULL, batch = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rotate_mat_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="rotate_mat_+3A_max_deg">max_deg</code></td>
<td>
<p>max_deg</p>
</td></tr>
<tr><td><code id="rotate_mat_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="rotate_mat_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="rotate_mat_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='round'>Round</h2><span id='topic+round'></span><span id='topic+round.torch.Tensor'></span>

<h3>Description</h3>

<p>Round
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
round(x, digits = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="round_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="round_+3A_digits">digits</code></td>
<td>
<p>decimal</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='round.fastai.torch_core.TensorMask'>Round</h2><span id='topic+round.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Round
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
round(x, digits = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="round.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="round.fastai.torch_core.TensorMask_+3A_digits">digits</code></td>
<td>
<p>decimal</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='Saturation'>Saturation</h2><span id='topic+Saturation'></span>

<h3>Description</h3>

<p>Apply change in saturation of 'max_lighting' to batch of images with probability 'p'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Saturation(max_lighting = 0.2, p = 0.75, draw = NULL, batch = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Saturation_+3A_max_lighting">max_lighting</code></td>
<td>
<p>maximum lighting</p>
</td></tr>
<tr><td><code id="Saturation_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="Saturation_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="Saturation_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SaveModelCallback'>SaveModelCallback</h2><span id='topic+SaveModelCallback'></span>

<h3>Description</h3>

<p>SaveModelCallback
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SaveModelCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SaveModelCallback_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SchedCos'>SchedCos</h2><span id='topic+SchedCos'></span>

<h3>Description</h3>

<p>Cosine schedule function from 'start' to 'end'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SchedCos(start, end)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SchedCos_+3A_start">start</code></td>
<td>
<p>start</p>
</td></tr>
<tr><td><code id="SchedCos_+3A_end">end</code></td>
<td>
<p>end</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SchedExp'>SchedExp</h2><span id='topic+SchedExp'></span>

<h3>Description</h3>

<p>Exponential schedule function from 'start' to 'end'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SchedExp(start, end)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SchedExp_+3A_start">start</code></td>
<td>
<p>start</p>
</td></tr>
<tr><td><code id="SchedExp_+3A_end">end</code></td>
<td>
<p>end</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SchedLin'>SchedLin</h2><span id='topic+SchedLin'></span>

<h3>Description</h3>

<p>Linear schedule function from 'start' to 'end'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SchedLin(start, end)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SchedLin_+3A_start">start</code></td>
<td>
<p>start</p>
</td></tr>
<tr><td><code id="SchedLin_+3A_end">end</code></td>
<td>
<p>end</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SchedNo'>SchedNo</h2><span id='topic+SchedNo'></span>

<h3>Description</h3>

<p>Constant schedule function with 'start' value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SchedNo(start, end)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SchedNo_+3A_start">start</code></td>
<td>
<p>start</p>
</td></tr>
<tr><td><code id="SchedNo_+3A_end">end</code></td>
<td>
<p>end</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SchedPoly'>SchedPoly</h2><span id='topic+SchedPoly'></span>

<h3>Description</h3>

<p>Polynomial schedule (of 'power') function from 'start' to 'end'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SchedPoly(start, end, power)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SchedPoly_+3A_start">start</code></td>
<td>
<p>start</p>
</td></tr>
<tr><td><code id="SchedPoly_+3A_end">end</code></td>
<td>
<p>end</p>
</td></tr>
<tr><td><code id="SchedPoly_+3A_power">power</code></td>
<td>
<p>power</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SEBlock'>SEBlock</h2><span id='topic+SEBlock'></span>

<h3>Description</h3>

<p>SEBlock
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SEBlock(expansion, ni, nf, groups = 1, reduction = 16, stride = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SEBlock_+3A_expansion">expansion</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="SEBlock_+3A_ni">ni</code></td>
<td>
<p>number of inputs</p>
</td></tr>
<tr><td><code id="SEBlock_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="SEBlock_+3A_groups">groups</code></td>
<td>
<p>number of groups</p>
</td></tr>
<tr><td><code id="SEBlock_+3A_reduction">reduction</code></td>
<td>
<p>number of reduction</p>
</td></tr>
<tr><td><code id="SEBlock_+3A_stride">stride</code></td>
<td>
<p>number of strides</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block object
</p>

<hr>
<h2 id='SegmentationDataLoaders_from_label_func'>SegmentationDataLoaders_from_label_func</h2><span id='topic+SegmentationDataLoaders_from_label_func'></span>

<h3>Description</h3>

<p>Create from list of 'fnames' in 'path's with 'label_func'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SegmentationDataLoaders_from_label_func(
  path,
  fnames,
  label_func,
  valid_pct = 0.2,
  seed = NULL,
  codes = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_fnames">fnames</code></td>
<td>
<p>file names</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_label_func">label_func</code></td>
<td>
<p>label function</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_valid_pct">valid_pct</code></td>
<td>
<p>validation percentage</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_seed">seed</code></td>
<td>
<p>seed</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_codes">codes</code></td>
<td>
<p>codes</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_item_tfms">item_tfms</code></td>
<td>
<p>item transformations</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>batch transformations</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_val_bs">val_bs</code></td>
<td>
<p>validation batch size</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>shuffle train</p>
</td></tr>
<tr><td><code id="SegmentationDataLoaders_from_label_func_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SelfAttention'>SelfAttention</h2><span id='topic+SelfAttention'></span>

<h3>Description</h3>

<p>Self attention layer for 'n_channels'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelfAttention(n_channels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SelfAttention_+3A_n_channels">n_channels</code></td>
<td>
<p>number of channels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SEModule'>SEModule</h2><span id='topic+SEModule'></span>

<h3>Description</h3>

<p>SEModule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SEModule(ch, reduction, act_cls = nn()$ReLU)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SEModule_+3A_ch">ch</code></td>
<td>
<p>ch</p>
</td></tr>
<tr><td><code id="SEModule_+3A_reduction">reduction</code></td>
<td>
<p>reduction</p>
</td></tr>
<tr><td><code id="SEModule_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SentenceEncoder'>SentenceEncoder</h2><span id='topic+SentenceEncoder'></span>

<h3>Description</h3>

<p>Create an encoder over 'module' that can process a full sentence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SentenceEncoder(bptt, module, pad_idx = 1, max_len = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SentenceEncoder_+3A_bptt">bptt</code></td>
<td>
<p>bptt</p>
</td></tr>
<tr><td><code id="SentenceEncoder_+3A_module">module</code></td>
<td>
<p>module</p>
</td></tr>
<tr><td><code id="SentenceEncoder_+3A_pad_idx">pad_idx</code></td>
<td>
<p>pad_idx</p>
</td></tr>
<tr><td><code id="SentenceEncoder_+3A_max_len">max_len</code></td>
<td>
<p>max_len</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SentencePieceTokenizer'>SentencePieceTokenizer</h2><span id='topic+SentencePieceTokenizer'></span>

<h3>Description</h3>

<p>SentencePiece tokenizer for 'lang'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SentencePieceTokenizer(
  lang = "en",
  special_toks = NULL,
  sp_model = NULL,
  vocab_sz = NULL,
  max_vocab_sz = 30000,
  model_type = "unigram",
  char_coverage = NULL,
  cache_dir = "tmp"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SentencePieceTokenizer_+3A_lang">lang</code></td>
<td>
<p>lang</p>
</td></tr>
<tr><td><code id="SentencePieceTokenizer_+3A_special_toks">special_toks</code></td>
<td>
<p>special_toks</p>
</td></tr>
<tr><td><code id="SentencePieceTokenizer_+3A_sp_model">sp_model</code></td>
<td>
<p>sp_model</p>
</td></tr>
<tr><td><code id="SentencePieceTokenizer_+3A_vocab_sz">vocab_sz</code></td>
<td>
<p>vocab_sz</p>
</td></tr>
<tr><td><code id="SentencePieceTokenizer_+3A_max_vocab_sz">max_vocab_sz</code></td>
<td>
<p>max_vocab_sz</p>
</td></tr>
<tr><td><code id="SentencePieceTokenizer_+3A_model_type">model_type</code></td>
<td>
<p>model_type</p>
</td></tr>
<tr><td><code id="SentencePieceTokenizer_+3A_char_coverage">char_coverage</code></td>
<td>
<p>char_coverage</p>
</td></tr>
<tr><td><code id="SentencePieceTokenizer_+3A_cache_dir">cache_dir</code></td>
<td>
<p>cache_dir</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SeparableBlock'>SeparableBlock</h2><span id='topic+SeparableBlock'></span>

<h3>Description</h3>

<p>SeparableBlock
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SeparableBlock(expansion, ni, nf, reduction = 16, stride = 1, base_width = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SeparableBlock_+3A_expansion">expansion</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="SeparableBlock_+3A_ni">ni</code></td>
<td>
<p>number of inputs</p>
</td></tr>
<tr><td><code id="SeparableBlock_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="SeparableBlock_+3A_reduction">reduction</code></td>
<td>
<p>number of reduction</p>
</td></tr>
<tr><td><code id="SeparableBlock_+3A_stride">stride</code></td>
<td>
<p>number of stride</p>
</td></tr>
<tr><td><code id="SeparableBlock_+3A_base_width">base_width</code></td>
<td>
<p>base width</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block object
</p>

<hr>
<h2 id='sequential'>Sequential</h2><span id='topic+sequential'></span>

<h3>Description</h3>

<p>Sequential
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sequential(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sequential_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SequentialEx'>SequentialEx</h2><span id='topic+SequentialEx'></span>

<h3>Description</h3>

<p>SequentialEx
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SequentialEx(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SequentialEx_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SequentialRNN'>Sequential RNN</h2><span id='topic+SequentialRNN'></span>

<h3>Description</h3>

<p>Sequential RNN
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SequentialRNN(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SequentialRNN_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>layer
</p>

<hr>
<h2 id='SEResNeXtBlock'>SEResNeXtBlock</h2><span id='topic+SEResNeXtBlock'></span>

<h3>Description</h3>

<p>SEResNeXtBlock
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SEResNeXtBlock(
  expansion,
  ni,
  nf,
  groups = 32,
  reduction = 16,
  stride = 1,
  base_width = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SEResNeXtBlock_+3A_expansion">expansion</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="SEResNeXtBlock_+3A_ni">ni</code></td>
<td>
<p>number of linear inputs</p>
</td></tr>
<tr><td><code id="SEResNeXtBlock_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="SEResNeXtBlock_+3A_groups">groups</code></td>
<td>
<p>groups number</p>
</td></tr>
<tr><td><code id="SEResNeXtBlock_+3A_reduction">reduction</code></td>
<td>
<p>reduction number</p>
</td></tr>
<tr><td><code id="SEResNeXtBlock_+3A_stride">stride</code></td>
<td>
<p>stride number</p>
</td></tr>
<tr><td><code id="SEResNeXtBlock_+3A_base_width">base_width</code></td>
<td>
<p>int, base width</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block object
</p>

<hr>
<h2 id='set_freeze_model'>Set freeze model</h2><span id='topic+set_freeze_model'></span>

<h3>Description</h3>

<p>Set freeze model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_freeze_model(m, rg)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_freeze_model_+3A_m">m</code></td>
<td>
<p>parameters</p>
</td></tr>
<tr><td><code id="set_freeze_model_+3A_rg">rg</code></td>
<td>
<p>rg</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='set_item_pg'>Set_item_pg</h2><span id='topic+set_item_pg'></span>

<h3>Description</h3>

<p>Set_item_pg
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_item_pg(pg, k, v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_item_pg_+3A_pg">pg</code></td>
<td>
<p>pg</p>
</td></tr>
<tr><td><code id="set_item_pg_+3A_k">k</code></td>
<td>
<p>k</p>
</td></tr>
<tr><td><code id="set_item_pg_+3A_v">v</code></td>
<td>
<p>v</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='setup_aug_tfms'>Setup_aug_tfms</h2><span id='topic+setup_aug_tfms'></span>

<h3>Description</h3>

<p>Go through 'tfms' and combines together affine/coord or lighting transforms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_aug_tfms(tfms)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setup_aug_tfms_+3A_tfms">tfms</code></td>
<td>
<p>transformations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SGD'>SGD</h2><span id='topic+SGD'></span>

<h3>Description</h3>

<p>SGD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SGD(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SGD_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sgd_step'>Sgd_step</h2><span id='topic+sgd_step'></span>

<h3>Description</h3>

<p>Sgd_step
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sgd_step(p, lr, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sgd_step_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="sgd_step_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="sgd_step_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

tst_param = function(val, grad = NULL) {
  "Create a tensor with `val` and a gradient of `grad` for testing"
  res = tensor(val) %&gt;% float()

  if(is.null(grad)) {
    grad = tensor(val / 10)
  } else {
    grad = tensor(grad)
  }

  res$grad = grad %&gt;% float()
  res
}
p = tst_param(1., 0.1)
sgd_step(p, 1.)


## End(Not run)

</code></pre>

<hr>
<h2 id='SGRoll'>SGRoll</h2><span id='topic+SGRoll'></span>

<h3>Description</h3>

<p>Shifts spectrogram along x-axis wrapping around to other side
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SGRoll(max_shift_pct = 0.5, direction = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SGRoll_+3A_max_shift_pct">max_shift_pct</code></td>
<td>
<p>maximum shift percentage</p>
</td></tr>
<tr><td><code id="SGRoll_+3A_direction">direction</code></td>
<td>
<p>direction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='shap'>Shap module</h2><span id='topic+shap'></span>

<h3>Description</h3>

<p>Shap module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shap()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='shape'>Shape</h2><span id='topic+shape'></span>

<h3>Description</h3>

<p>Shape
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shape(img)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shape_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ShapInterpretation'>ShapInterpretation</h2><span id='topic+ShapInterpretation'></span>

<h3>Description</h3>

<p>Base interpereter to use the 'SHAP' interpretation library
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ShapInterpretation(
  learn,
  test_data = NULL,
  link = "identity",
  l1_reg = "auto",
  n_samples = 128
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShapInterpretation_+3A_learn">learn</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="ShapInterpretation_+3A_test_data">test_data</code></td>
<td>
<p>should be either a Pandas dataframe or a TabularDataLoader. If not, 100 random rows of
the training data will be used instead.</p>
</td></tr>
<tr><td><code id="ShapInterpretation_+3A_link">link</code></td>
<td>
<p>link can either be &quot;identity&quot; or &quot;logit&quot;. A generalized linear model link to connect
the feature importance values to the model output. Since the feature importance values, phi, sum up
to the model output, it often makes sense to connect them to the ouput with a link function where
link(outout) = sum(phi). If the model output is a probability then the LogitLink link function makes
the feature importance values have log-odds units.</p>
</td></tr>
<tr><td><code id="ShapInterpretation_+3A_l1_reg">l1_reg</code></td>
<td>
<p>can be an integer value representing the number of features, &quot;auto&quot;, &quot;aic&quot;, &quot;bic&quot;, or
a float value. The l1 regularization to use for feature selection (the estimation procedure is based
on a debiased lasso). The auto option currently uses &quot;aic&quot; when less that 20
space is enumerated, otherwise it uses no regularization.</p>
</td></tr>
<tr><td><code id="ShapInterpretation_+3A_n_samples">n_samples</code></td>
<td>
<p>can either be &quot;auto&quot; or an integer value. This is the number of times to re-evaluate
the model when explaining each predictions. More samples leads to lower variance estimations of the SHAP values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Shortcut'>Shortcut</h2><span id='topic+Shortcut'></span>

<h3>Description</h3>

<p>Merge a shortcut with the result of the module by adding them. Adds Conv, BN and ReLU
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Shortcut(ni, nf, act_fn = nn$ReLU(inplace = TRUE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Shortcut_+3A_ni">ni</code></td>
<td>
<p>number of input channels</p>
</td></tr>
<tr><td><code id="Shortcut_+3A_nf">nf</code></td>
<td>
<p>number of features</p>
</td></tr>
<tr><td><code id="Shortcut_+3A_act_fn">act_fn</code></td>
<td>
<p>activation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ShortEpochCallback'>ShortEpochCallback</h2><span id='topic+ShortEpochCallback'></span>

<h3>Description</h3>

<p>Fit just 'pct' of an epoch, then stop
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ShortEpochCallback(pct = 0.01, short_valid = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShortEpochCallback_+3A_pct">pct</code></td>
<td>
<p>percentage</p>
</td></tr>
<tr><td><code id="ShortEpochCallback_+3A_short_valid">short_valid</code></td>
<td>
<p>short_valid or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='show'>Show</h2><span id='topic+show'></span>

<h3>Description</h3>

<p>Adds functionality to view dicom images where each file may have more than 1 frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show(img, frames = 1, scale = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_+3A_img">img</code></td>
<td>
<p>image object</p>
</td></tr>
<tr><td><code id="show_+3A_frames">frames</code></td>
<td>
<p>number of frames</p>
</td></tr>
<tr><td><code id="show_+3A_scale">scale</code></td>
<td>
<p>scale</p>
</td></tr>
<tr><td><code id="show_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='show_array'>Show_array</h2><span id='topic+show_array'></span>

<h3>Description</h3>

<p>Show an array on 'ax'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_array(
  array,
  ax = NULL,
  figsize = NULL,
  title = NULL,
  ctx = NULL,
  tx = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_array_+3A_array">array</code></td>
<td>
<p>R array</p>
</td></tr>
<tr><td><code id="show_array_+3A_ax">ax</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="show_array_+3A_figsize">figsize</code></td>
<td>
<p>figure size</p>
</td></tr>
<tr><td><code id="show_array_+3A_title">title</code></td>
<td>
<p>title, text</p>
</td></tr>
<tr><td><code id="show_array_+3A_ctx">ctx</code></td>
<td>
<p>ctx</p>
</td></tr>
<tr><td><code id="show_array_+3A_tx">tx</code></td>
<td>
<p>tx</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

arr = as.array(1:10)
show_array(arr,title = 'My R array') %&gt;% plot(dpi = 200)


## End(Not run)



</code></pre>

<hr>
<h2 id='show_batch'>Show_batch</h2><span id='topic+show_batch'></span>

<h3>Description</h3>

<p>Show_batch
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_batch(
  dls,
  b = NULL,
  max_n = 9,
  ctxs = NULL,
  figsize = c(6, 6),
  show = TRUE,
  unique = FALSE,
  dpi = 120,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_batch_+3A_dls">dls</code></td>
<td>
<p>dataloader object</p>
</td></tr>
<tr><td><code id="show_batch_+3A_b">b</code></td>
<td>
<p>defaults to one_batch</p>
</td></tr>
<tr><td><code id="show_batch_+3A_max_n">max_n</code></td>
<td>
<p>maximum images</p>
</td></tr>
<tr><td><code id="show_batch_+3A_ctxs">ctxs</code></td>
<td>
<p>ctxs parameter</p>
</td></tr>
<tr><td><code id="show_batch_+3A_figsize">figsize</code></td>
<td>
<p>figure size</p>
</td></tr>
<tr><td><code id="show_batch_+3A_show">show</code></td>
<td>
<p>show or not</p>
</td></tr>
<tr><td><code id="show_batch_+3A_unique">unique</code></td>
<td>
<p>unique images</p>
</td></tr>
<tr><td><code id="show_batch_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
<tr><td><code id="show_batch_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

dls %&gt;% show_batch()


## End(Not run)

</code></pre>

<hr>
<h2 id='show_image'>Show_image</h2><span id='topic+show_image'></span>

<h3>Description</h3>

<p>Show a PIL or PyTorch image on 'ax'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_image(
  im,
  ax = NULL,
  figsize = NULL,
  title = NULL,
  ctx = NULL,
  cmap = NULL,
  norm = NULL,
  aspect = NULL,
  interpolation = NULL,
  alpha = NULL,
  vmin = NULL,
  vmax = NULL,
  origin = NULL,
  extent = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_image_+3A_im">im</code></td>
<td>
<p>im</p>
</td></tr>
<tr><td><code id="show_image_+3A_ax">ax</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="show_image_+3A_figsize">figsize</code></td>
<td>
<p>figure size</p>
</td></tr>
<tr><td><code id="show_image_+3A_title">title</code></td>
<td>
<p>title</p>
</td></tr>
<tr><td><code id="show_image_+3A_ctx">ctx</code></td>
<td>
<p>ctx</p>
</td></tr>
<tr><td><code id="show_image_+3A_cmap">cmap</code></td>
<td>
<p>color maps</p>
</td></tr>
<tr><td><code id="show_image_+3A_norm">norm</code></td>
<td>
<p>normalization</p>
</td></tr>
<tr><td><code id="show_image_+3A_aspect">aspect</code></td>
<td>
<p>aspect</p>
</td></tr>
<tr><td><code id="show_image_+3A_interpolation">interpolation</code></td>
<td>
<p>interpolation</p>
</td></tr>
<tr><td><code id="show_image_+3A_alpha">alpha</code></td>
<td>
<p>alpha value</p>
</td></tr>
<tr><td><code id="show_image_+3A_vmin">vmin</code></td>
<td>
<p>value min</p>
</td></tr>
<tr><td><code id="show_image_+3A_vmax">vmax</code></td>
<td>
<p>value max</p>
</td></tr>
<tr><td><code id="show_image_+3A_origin">origin</code></td>
<td>
<p>origin</p>
</td></tr>
<tr><td><code id="show_image_+3A_extent">extent</code></td>
<td>
<p>extent</p>
</td></tr>
</table>

<hr>
<h2 id='show_images'>Show_images</h2><span id='topic+show_images'></span>

<h3>Description</h3>

<p>Show all images 'ims' as subplots with 'rows' using 'titles'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_images(
  ims,
  nrows = 1,
  ncols = NULL,
  titles = NULL,
  figsize = NULL,
  imsize = 3,
  add_vert = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_images_+3A_ims">ims</code></td>
<td>
<p>images</p>
</td></tr>
<tr><td><code id="show_images_+3A_nrows">nrows</code></td>
<td>
<p>number of rows</p>
</td></tr>
<tr><td><code id="show_images_+3A_ncols">ncols</code></td>
<td>
<p>number of columns</p>
</td></tr>
<tr><td><code id="show_images_+3A_titles">titles</code></td>
<td>
<p>titles</p>
</td></tr>
<tr><td><code id="show_images_+3A_figsize">figsize</code></td>
<td>
<p>figure size</p>
</td></tr>
<tr><td><code id="show_images_+3A_imsize">imsize</code></td>
<td>
<p>image size</p>
</td></tr>
<tr><td><code id="show_images_+3A_add_vert">add_vert</code></td>
<td>
<p>add vertical</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='show_preds'>Show_preds</h2><span id='topic+show_preds'></span>

<h3>Description</h3>

<p>Show_preds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_preds(
  predictions,
  idx,
  class_map = NULL,
  denormalize_fn = denormalize_imagenet(),
  display_label = TRUE,
  display_bbox = TRUE,
  display_mask = TRUE,
  ncols = 1,
  figsize = NULL,
  show = FALSE,
  dpi = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_preds_+3A_predictions">predictions</code></td>
<td>
<p>provide list of raw predictions</p>
</td></tr>
<tr><td><code id="show_preds_+3A_idx">idx</code></td>
<td>
<p>image indices</p>
</td></tr>
<tr><td><code id="show_preds_+3A_class_map">class_map</code></td>
<td>
<p>class_map</p>
</td></tr>
<tr><td><code id="show_preds_+3A_denormalize_fn">denormalize_fn</code></td>
<td>
<p>denormalize_fn</p>
</td></tr>
<tr><td><code id="show_preds_+3A_display_label">display_label</code></td>
<td>
<p>display_label</p>
</td></tr>
<tr><td><code id="show_preds_+3A_display_bbox">display_bbox</code></td>
<td>
<p>display_bbox</p>
</td></tr>
<tr><td><code id="show_preds_+3A_display_mask">display_mask</code></td>
<td>
<p>display_mask</p>
</td></tr>
<tr><td><code id="show_preds_+3A_ncols">ncols</code></td>
<td>
<p>ncols</p>
</td></tr>
<tr><td><code id="show_preds_+3A_figsize">figsize</code></td>
<td>
<p>figsize</p>
</td></tr>
<tr><td><code id="show_preds_+3A_show">show</code></td>
<td>
<p>show</p>
</td></tr>
<tr><td><code id="show_preds_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='show_results'>Show_results</h2><span id='topic+show_results'></span>

<h3>Description</h3>

<p>Show some predictions on 'ds_idx'-th dataset or 'dl'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_results(
  object,
  ds_idx = 1,
  dl = NULL,
  max_n = 9,
  shuffle = TRUE,
  dpi = 90,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_results_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="show_results_+3A_ds_idx">ds_idx</code></td>
<td>
<p>ds by index</p>
</td></tr>
<tr><td><code id="show_results_+3A_dl">dl</code></td>
<td>
<p>dataloader</p>
</td></tr>
<tr><td><code id="show_results_+3A_max_n">max_n</code></td>
<td>
<p>maximum number of images</p>
</td></tr>
<tr><td><code id="show_results_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle or not</p>
</td></tr>
<tr><td><code id="show_results_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
<tr><td><code id="show_results_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='show_samples'>Show_samples</h2><span id='topic+show_samples'></span>

<h3>Description</h3>

<p>Show_samples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_samples(
  dls,
  idx,
  class_map = NULL,
  denormalize_fn = denormalize_imagenet(),
  display_label = TRUE,
  display_bbox = TRUE,
  display_mask = TRUE,
  ncols = 1,
  figsize = NULL,
  show = FALSE,
  dpi = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_samples_+3A_dls">dls</code></td>
<td>
<p>dataloader</p>
</td></tr>
<tr><td><code id="show_samples_+3A_idx">idx</code></td>
<td>
<p>image indices</p>
</td></tr>
<tr><td><code id="show_samples_+3A_class_map">class_map</code></td>
<td>
<p>class_map</p>
</td></tr>
<tr><td><code id="show_samples_+3A_denormalize_fn">denormalize_fn</code></td>
<td>
<p>denormalize_fn</p>
</td></tr>
<tr><td><code id="show_samples_+3A_display_label">display_label</code></td>
<td>
<p>display_label</p>
</td></tr>
<tr><td><code id="show_samples_+3A_display_bbox">display_bbox</code></td>
<td>
<p>display_bbox</p>
</td></tr>
<tr><td><code id="show_samples_+3A_display_mask">display_mask</code></td>
<td>
<p>display_mask</p>
</td></tr>
<tr><td><code id="show_samples_+3A_ncols">ncols</code></td>
<td>
<p>ncols</p>
</td></tr>
<tr><td><code id="show_samples_+3A_figsize">figsize</code></td>
<td>
<p>figsize</p>
</td></tr>
<tr><td><code id="show_samples_+3A_show">show</code></td>
<td>
<p>show</p>
</td></tr>
<tr><td><code id="show_samples_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ShowCycleGANImgsCallback'>ShowCycleGANImgsCallback</h2><span id='topic+ShowCycleGANImgsCallback'></span>

<h3>Description</h3>

<p>Update the progress bar with input and prediction images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ShowCycleGANImgsCallback(imgA = FALSE, imgB = TRUE, show_img_interval = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShowCycleGANImgsCallback_+3A_imga">imgA</code></td>
<td>
<p>img from A domain</p>
</td></tr>
<tr><td><code id="ShowCycleGANImgsCallback_+3A_imgb">imgB</code></td>
<td>
<p>img from B domain</p>
</td></tr>
<tr><td><code id="ShowCycleGANImgsCallback_+3A_show_img_interval">show_img_interval</code></td>
<td>
<p>show image interval</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ShowGraphCallback'>ShowGraphCallback</h2><span id='topic+ShowGraphCallback'></span>

<h3>Description</h3>

<p>ShowGraphCallback
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ShowGraphCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShowGraphCallback_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sigmoid'>Sigmoid</h2><span id='topic+sigmoid'></span>

<h3>Description</h3>

<p>Same as 'torch$sigmoid', plus clamping to '(eps,1-eps)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sigmoid(input, eps = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sigmoid_+3A_input">input</code></td>
<td>
<p>inputs</p>
</td></tr>
<tr><td><code id="sigmoid_+3A_eps">eps</code></td>
<td>
<p>epsilon</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sigmoid_'>Sigmoid_</h2><span id='topic+sigmoid_'></span>

<h3>Description</h3>

<p>Same as 'torch$sigmoid_', plus clamping to '(eps,1-eps)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sigmoid_(input, eps = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sigmoid__+3A_input">input</code></td>
<td>
<p>input</p>
</td></tr>
<tr><td><code id="sigmoid__+3A_eps">eps</code></td>
<td>
<p>eps</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sigmoid_range'>Sigmoid_range</h2><span id='topic+sigmoid_range'></span>

<h3>Description</h3>

<p>Sigmoid function with range '(low, high)'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sigmoid_range(x, low, high)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sigmoid_range_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="sigmoid_range_+3A_low">low</code></td>
<td>
<p>low value</p>
</td></tr>
<tr><td><code id="sigmoid_range_+3A_high">high</code></td>
<td>
<p>high value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SigmoidRange'>SigmoidRange</h2><span id='topic+SigmoidRange'></span>

<h3>Description</h3>

<p>Sigmoid module with range '(low, high)'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SigmoidRange(low, high)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SigmoidRange_+3A_low">low</code></td>
<td>
<p>low value</p>
</td></tr>
<tr><td><code id="SigmoidRange_+3A_high">high</code></td>
<td>
<p>high value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SignalCutout'>Signal Cutout</h2><span id='topic+SignalCutout'></span>

<h3>Description</h3>

<p>Randomly zeros some portion of the signal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SignalCutout(p = 0.5, max_cut_pct = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SignalCutout_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="SignalCutout_+3A_max_cut_pct">max_cut_pct</code></td>
<td>
<p>max cut percentage</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SignalLoss'>Signal Loss</h2><span id='topic+SignalLoss'></span>

<h3>Description</h3>

<p>Randomly loses some portion of the signal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SignalLoss(p = 0.5, max_loss_pct = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SignalLoss_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="SignalLoss_+3A_max_loss_pct">max_loss_pct</code></td>
<td>
<p>max loss percentage</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SignalShifter'>Signal Shifter</h2><span id='topic+SignalShifter'></span>

<h3>Description</h3>

<p>Randomly shifts the audio signal by 'max_pct' 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SignalShifter(
  p = 0.5,
  max_pct = 0.2,
  max_time = NULL,
  direction = 0,
  roll = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SignalShifter_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="SignalShifter_+3A_max_pct">max_pct</code></td>
<td>
<p>max percentage</p>
</td></tr>
<tr><td><code id="SignalShifter_+3A_max_time">max_time</code></td>
<td>
<p>maximum time</p>
</td></tr>
<tr><td><code id="SignalShifter_+3A_direction">direction</code></td>
<td>
<p>direction</p>
</td></tr>
<tr><td><code id="SignalShifter_+3A_roll">roll</code></td>
<td>
<p>roll or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>direction must be -1(left) 0(bidirectional) or 1(right).
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SimpleCNN'>SimpleCNN</h2><span id='topic+SimpleCNN'></span>

<h3>Description</h3>

<p>Create a simple CNN with 'filters'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimpleCNN(filters, kernel_szs = NULL, strides = NULL, bn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimpleCNN_+3A_filters">filters</code></td>
<td>
<p>filters number</p>
</td></tr>
<tr><td><code id="SimpleCNN_+3A_kernel_szs">kernel_szs</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="SimpleCNN_+3A_strides">strides</code></td>
<td>
<p>strides</p>
</td></tr>
<tr><td><code id="SimpleCNN_+3A_bn">bn</code></td>
<td>
<p>batch normalization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SimpleSelfAttention'>SimpleSelfAttention</h2><span id='topic+SimpleSelfAttention'></span>

<h3>Description</h3>

<p>Same as 'nn()$Module', but no need for subclasses to call 'super()$__init__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimpleSelfAttention(n_in, ks = 1, sym = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimpleSelfAttention_+3A_n_in">n_in</code></td>
<td>
<p>inputs</p>
</td></tr>
<tr><td><code id="SimpleSelfAttention_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="SimpleSelfAttention_+3A_sym">sym</code></td>
<td>
<p>sym</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sin_'>Sin</h2><span id='topic+sin_'></span><span id='topic+sin.torch.Tensor'></span>

<h3>Description</h3>

<p>Sin
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
sin(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sin__+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='sin.fastai.torch_core.TensorMask'>Sin</h2><span id='topic+sin.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Sin
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
sin(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sin.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='sinh.fastai.torch_core.TensorMask'>Sinh</h2><span id='topic+sinh.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Sinh
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
sinh(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sinh.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='skm_to_fastai'>Skm to fastai</h2><span id='topic+skm_to_fastai'></span>

<h3>Description</h3>

<p>Convert 'func' from sklearn$metrics to a fastai metric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skm_to_fastai(
  func,
  is_class = TRUE,
  thresh = NULL,
  axis = -1,
  activation = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skm_to_fastai_+3A_func">func</code></td>
<td>
<p>function</p>
</td></tr>
<tr><td><code id="skm_to_fastai_+3A_is_class">is_class</code></td>
<td>
<p>is classification or not</p>
</td></tr>
<tr><td><code id="skm_to_fastai_+3A_thresh">thresh</code></td>
<td>
<p>threshold point</p>
</td></tr>
<tr><td><code id="skm_to_fastai_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="skm_to_fastai_+3A_activation">activation</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="skm_to_fastai_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='slice'>Slice</h2><span id='topic+slice'></span>

<h3>Description</h3>

<p>Slice
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slice(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="slice_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>slice(start, stop[, step]) Create a slice object. This is used for extended slicing (e.g. a[0:10:2]).
</p>


<h3>Value</h3>

<p>sliced object
</p>

<hr>
<h2 id='sort'>Sort</h2><span id='topic+sort'></span><span id='topic+sort.torch.Tensor'></span>

<h3>Description</h3>

<p>Sort
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
sort(x, decreasing = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="sort_+3A_decreasing">decreasing</code></td>
<td>
<p>the order</p>
</td></tr>
<tr><td><code id="sort_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>

<hr>
<h2 id='sort.fastai.torch_core.TensorMask'>Sort</h2><span id='topic+sort.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Sort
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
sort(x, decreasing = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="sort.fastai.torch_core.TensorMask_+3A_decreasing">decreasing</code></td>
<td>
<p>the order</p>
</td></tr>
<tr><td><code id="sort.fastai.torch_core.TensorMask_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='SortedDL'>SortedDL</h2><span id='topic+SortedDL'></span>

<h3>Description</h3>

<p>A 'DataLoader' that goes throught the item in the order given by 'sort_func'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SortedDL(
  dataset,
  sort_func = NULL,
  res = NULL,
  bs = 64,
  shuffle = FALSE,
  num_workers = NULL,
  verbose = FALSE,
  do_setup = TRUE,
  pin_memory = FALSE,
  timeout = 0,
  batch_size = NULL,
  drop_last = FALSE,
  indexed = NULL,
  n = NULL,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SortedDL_+3A_dataset">dataset</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_sort_func">sort_func</code></td>
<td>
<p>sort_func</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_res">res</code></td>
<td>
<p>res</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_bs">bs</code></td>
<td>
<p>bs</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_num_workers">num_workers</code></td>
<td>
<p>num_workers</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_verbose">verbose</code></td>
<td>
<p>verbose</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_do_setup">do_setup</code></td>
<td>
<p>do_setup</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_pin_memory">pin_memory</code></td>
<td>
<p>pin_memory</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_timeout">timeout</code></td>
<td>
<p>timeout</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_batch_size">batch_size</code></td>
<td>
<p>batch_size</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_drop_last">drop_last</code></td>
<td>
<p>drop_last</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_indexed">indexed</code></td>
<td>
<p>indexed</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_n">n</code></td>
<td>
<p>n</p>
</td></tr>
<tr><td><code id="SortedDL_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='SpacyTokenizer'>SpacyTokenizer</h2><span id='topic+SpacyTokenizer'></span>

<h3>Description</h3>

<p>Spacy tokenizer for 'lang'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpacyTokenizer(lang = "en", special_toks = NULL, buf_sz = 5000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SpacyTokenizer_+3A_lang">lang</code></td>
<td>
<p>language</p>
</td></tr>
<tr><td><code id="SpacyTokenizer_+3A_special_toks">special_toks</code></td>
<td>
<p>special tokenizers</p>
</td></tr>
<tr><td><code id="SpacyTokenizer_+3A_buf_sz">buf_sz</code></td>
<td>
<p>buffer size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>none
</p>

<hr>
<h2 id='SpearmanCorrCoef'>SpearmanCorrCoef</h2><span id='topic+SpearmanCorrCoef'></span>

<h3>Description</h3>

<p>Spearman correlation coefficient for regression problem
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpearmanCorrCoef(
  dim_argmax = NULL,
  axis = 0,
  nan_policy = "propagate",
  activation = "no",
  thresh = NULL,
  to_np = FALSE,
  invert_arg = FALSE,
  flatten = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SpearmanCorrCoef_+3A_dim_argmax">dim_argmax</code></td>
<td>
<p>dim_argmax</p>
</td></tr>
<tr><td><code id="SpearmanCorrCoef_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
<tr><td><code id="SpearmanCorrCoef_+3A_nan_policy">nan_policy</code></td>
<td>
<p>nan_policy</p>
</td></tr>
<tr><td><code id="SpearmanCorrCoef_+3A_activation">activation</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="SpearmanCorrCoef_+3A_thresh">thresh</code></td>
<td>
<p>thresh</p>
</td></tr>
<tr><td><code id="SpearmanCorrCoef_+3A_to_np">to_np</code></td>
<td>
<p>to_np</p>
</td></tr>
<tr><td><code id="SpearmanCorrCoef_+3A_invert_arg">invert_arg</code></td>
<td>
<p>invert_arg</p>
</td></tr>
<tr><td><code id="SpearmanCorrCoef_+3A_flatten">flatten</code></td>
<td>
<p>flatten</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='spec_add_spaces'>Spec_add_spaces</h2><span id='topic+spec_add_spaces'></span>

<h3>Description</h3>

<p>Add spaces around / and #
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spec_add_spaces(t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spec_add_spaces_+3A_t">t</code></td>
<td>
<p>text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>

<hr>
<h2 id='SpectrogramTransformer'>Spectrogram Transformer</h2><span id='topic+SpectrogramTransformer'></span>

<h3>Description</h3>

<p>Creates a factory for creating AudioToSpec
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpectrogramTransformer(mel = TRUE, to_db = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SpectrogramTransformer_+3A_mel">mel</code></td>
<td>
<p>mel-spectrogram or not</p>
</td></tr>
<tr><td><code id="SpectrogramTransformer_+3A_to_db">to_db</code></td>
<td>
<p>to decibels</p>
</td></tr>
</table>


<h3>Details</h3>

<p>transforms with different parameters
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sqrd'>Sqrt</h2><span id='topic+sqrd'></span><span id='topic+sqrt.torch.Tensor'></span>

<h3>Description</h3>

<p>Sqrt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
sqrt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sqrd_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='sqrt.fastai.torch_core.TensorMask'>Sqrt</h2><span id='topic+sqrt.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Sqrt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
sqrt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sqrt.fastai.torch_core.TensorMask_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='SqueezeNet'>SqueezeNet</h2><span id='topic+SqueezeNet'></span>

<h3>Description</h3>

<p>Base class for all neural network modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SqueezeNet(version = "1_0", num_classes = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SqueezeNet_+3A_version">version</code></td>
<td>
<p>version of SqueezeNet</p>
</td></tr>
<tr><td><code id="SqueezeNet_+3A_num_classes">num_classes</code></td>
<td>
<p>the number of classes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes:: import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:'to', etc.
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='squeezenet1_0'>Squeezenet1_0</h2><span id='topic+squeezenet1_0'></span>

<h3>Description</h3>

<p>SqueezeNet model architecture from the '&quot;SqueezeNet: AlexNet-level
</p>


<h3>Usage</h3>

<pre><code class='language-R'>squeezenet1_0(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="squeezenet1_0_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="squeezenet1_0_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>accuracy with 50x fewer parameters and &lt;0.5MB model size&quot;
&lt;https://arxiv.org/abs/1602.07360&gt;'_ paper.
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='squeezenet1_1'>Squeezenet1_1</h2><span id='topic+squeezenet1_1'></span>

<h3>Description</h3>

<p>SqueezeNet 1.1 model from the 'official SqueezeNet repo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>squeezenet1_1(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="squeezenet1_1_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="squeezenet1_1_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&lt;https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1&gt;'_.
SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters
than SqueezeNet 1.0, without sacrificing accuracy.
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='stack_train_valid'>Stack_train_valid</h2><span id='topic+stack_train_valid'></span>

<h3>Description</h3>

<p>Stack df_train and df_valid, adds 'valid_col'=TRUE/FALSE for df_valid/df_train
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stack_train_valid(df_train, df_valid)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stack_train_valid_+3A_df_train">df_train</code></td>
<td>
<p>train data</p>
</td></tr>
<tr><td><code id="stack_train_valid_+3A_df_valid">df_valid</code></td>
<td>
<p>validation data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>

<hr>
<h2 id='step_stat'>Step_stat</h2><span id='topic+step_stat'></span>

<h3>Description</h3>

<p>Register the number of steps done in 'state' for 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_stat(p, step = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_stat_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="step_stat_+3A_step">step</code></td>
<td>
<p>step</p>
</td></tr>
<tr><td><code id="step_stat_+3A_...">...</code></td>
<td>
<p>additional args to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sub'>Sub</h2><span id='topic+sub'></span><span id='topic+-.torch.Tensor'></span>

<h3>Description</h3>

<p>Sub
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a - b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sub_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="sub_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='sub_mask'>Sub</h2><span id='topic+sub_mask'></span><span id='topic+-.fastai.torch_core.TensorMask'></span>

<h3>Description</h3>

<p>Sub
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.torch_core.TensorMask'
a - b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sub_mask_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="sub_mask_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='subplots'>Subplots</h2><span id='topic+subplots'></span>

<h3>Description</h3>

<p>Subplots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subplots(nrows = 2, ncols = 2, figsize = NULL, imsize = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subplots_+3A_nrows">nrows</code></td>
<td>
<p>number of rows</p>
</td></tr>
<tr><td><code id="subplots_+3A_ncols">ncols</code></td>
<td>
<p>number of columns</p>
</td></tr>
<tr><td><code id="subplots_+3A_figsize">figsize</code></td>
<td>
<p>figure size</p>
</td></tr>
<tr><td><code id="subplots_+3A_imsize">imsize</code></td>
<td>
<p>image size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot object
</p>

<hr>
<h2 id='summarization_splitter'>Summarization_splitter</h2><span id='topic+summarization_splitter'></span>

<h3>Description</h3>

<p>Custom param splitter for summarization models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarization_splitter(m, arch)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarization_splitter_+3A_m">m</code></td>
<td>
<p>splitter parameter</p>
</td></tr>
<tr><td><code id="summarization_splitter_+3A_arch">arch</code></td>
<td>
<p>architecture</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='summary_plot'>Summary_plot</h2><span id='topic+summary_plot'></span>

<h3>Description</h3>

<p>Displays the SHAP values (which can be interpreted for feature importance)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary_plot(object, dpi = 200, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_plot_+3A_object">object</code></td>
<td>
<p>ShapInterpretation object</p>
</td></tr>
<tr><td><code id="summary_plot_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
<tr><td><code id="summary_plot_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='summary.fastai.learner.Learner'>Summary</h2><span id='topic+summary.fastai.learner.Learner'></span>

<h3>Description</h3>

<p>Summary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.learner.Learner'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.fastai.learner.Learner_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="summary.fastai.learner.Learner_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

summary(model)


## End(Not run)

</code></pre>

<hr>
<h2 id='summary.fastai.tabular.learner.TabularLearner'>Summary</h2><span id='topic+summary.fastai.tabular.learner.TabularLearner'></span>

<h3>Description</h3>

<p>Print a summary of 'm' using a output text width of 'n' chars
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fastai.tabular.learner.TabularLearner'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.fastai.tabular.learner.TabularLearner_+3A_object">object</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="summary.fastai.tabular.learner.TabularLearner_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='swish'>Swish</h2><span id='topic+swish'></span>

<h3>Description</h3>

<p>Swish
</p>


<h3>Usage</h3>

<pre><code class='language-R'>swish(x, inplace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="swish_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="swish_+3A_inplace">inplace</code></td>
<td>
<p>inplace or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Swish_'>Swish</h2><span id='topic+Swish_'></span>

<h3>Description</h3>

<p>Same as nn()$Module, but no need for subclasses to call super()$__init__
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Swish_(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Swish__+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tabular'>Tabular</h2><span id='topic+tabular'></span>

<h3>Description</h3>

<p>Tabular
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tabular()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tabular_config'>Tabular_config</h2><span id='topic+tabular_config'></span>

<h3>Description</h3>

<p>Convenience function to easily create a config for 'TabularModel'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tabular_config(
  ps = NULL,
  embed_p = 0,
  y_range = NULL,
  use_bn = TRUE,
  bn_final = FALSE,
  bn_cont = TRUE,
  act_cls = nn()$ReLU(inplace = TRUE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tabular_config_+3A_ps">ps</code></td>
<td>
<p>ps</p>
</td></tr>
<tr><td><code id="tabular_config_+3A_embed_p">embed_p</code></td>
<td>
<p>embed proportion</p>
</td></tr>
<tr><td><code id="tabular_config_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
<tr><td><code id="tabular_config_+3A_use_bn">use_bn</code></td>
<td>
<p>use batch normalization</p>
</td></tr>
<tr><td><code id="tabular_config_+3A_bn_final">bn_final</code></td>
<td>
<p>batch normalization final</p>
</td></tr>
<tr><td><code id="tabular_config_+3A_bn_cont">bn_cont</code></td>
<td>
<p>batch normalization</p>
</td></tr>
<tr><td><code id="tabular_config_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tabular_learner'>Tabular learner</h2><span id='topic+tabular_learner'></span>

<h3>Description</h3>

<p>Get a 'Learner' using 'dls', with 'metrics', including a 'TabularModel' created using the remaining params.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tabular_learner(
  dls,
  layers = NULL,
  emb_szs = NULL,
  config = NULL,
  n_out = NULL,
  y_range = NULL,
  loss_func = NULL,
  opt_func = Adam(),
  lr = 0.001,
  splitter = trainable_params(),
  cbs = NULL,
  metrics = NULL,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE,
  moms = list(0.95, 0.85, 0.95)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tabular_learner_+3A_dls">dls</code></td>
<td>
<p>It is a DataLoaders object.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_layers">layers</code></td>
<td>
<p>layers</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_emb_szs">emb_szs</code></td>
<td>
<p>emb_szs</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_config">config</code></td>
<td>
<p>config</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_n_out">n_out</code></td>
<td>
<p>n_out</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_loss_func">loss_func</code></td>
<td>
<p>It can be any loss function you like.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_opt_func">opt_func</code></td>
<td>
<p>It will be used to create an optimizer when Learner.fit is called.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_lr">lr</code></td>
<td>
<p>It is learning rate.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_splitter">splitter</code></td>
<td>
<p>It is a function that takes self.model and returns a list of parameter groups (or just one parameter group if there are no different parameter groups)</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_cbs">cbs</code></td>
<td>
<p>It is one or a list of Callbacks to pass to the Learner.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_metrics">metrics</code></td>
<td>
<p>It is an optional list of metrics, that can be either functions or Metrics.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_path">path</code></td>
<td>
<p>t is used to save and/or load models.Often path will be inferred from dls, but you can override it or pass a Path object to model_dir. Make sure you can write in path/model_dir!</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_model_dir">model_dir</code></td>
<td>
<p>t is used to save and/or load models.Often path will be inferred from dls, but you can override it or pass a Path object to model_dir. Make sure you can write in path/model_dir!</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_wd">wd</code></td>
<td>
<p>It is the default weight decay used when training the model.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>It controls if weight decay is applied to BatchNorm layers and bias.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_train_bn">train_bn</code></td>
<td>
<p>It controls if BatchNorm layers are trained even when they are supposed to be frozen according to the splitter.</p>
</td></tr>
<tr><td><code id="tabular_learner_+3A_moms">moms</code></td>
<td>
<p>The default momentums used in Learner.fit_one_cycle.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>learner object
</p>

<hr>
<h2 id='TabularDataTable'>TabularDataTable</h2><span id='topic+TabularDataTable'></span>

<h3>Description</h3>

<p>A 'Tabular' object with transforms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TabularDataTable(
  df,
  procs = NULL,
  cat_names = NULL,
  cont_names = NULL,
  y_names = NULL,
  y_block = NULL,
  splits = NULL,
  do_setup = TRUE,
  device = NULL,
  inplace = FALSE,
  reduce_memory = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TabularDataTable_+3A_df">df</code></td>
<td>
<p>A DataFrame of your data</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_procs">procs</code></td>
<td>
<p>list of preprocess functions</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_cat_names">cat_names</code></td>
<td>
<p>the names of the categorical variables</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_cont_names">cont_names</code></td>
<td>
<p>the names of the continuous variables</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_y_names">y_names</code></td>
<td>
<p>the names of the dependent variables</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_y_block">y_block</code></td>
<td>
<p>the TransformBlock to use for the target</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_splits">splits</code></td>
<td>
<p>How to split your data</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_do_setup">do_setup</code></td>
<td>
<p>A parameter for if Tabular will run the data through the procs upon initialization</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_device">device</code></td>
<td>
<p>cuda or cpu</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_inplace">inplace</code></td>
<td>
<p>If True, Tabular will not keep a separate copy of your original DataFrame in memory</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_reduce_memory">reduce_memory</code></td>
<td>
<p>fastai will attempt to reduce the overall memory usage</p>
</td></tr>
<tr><td><code id="TabularDataTable_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TabularModel'>TabularModel</h2><span id='topic+TabularModel'></span>

<h3>Description</h3>

<p>Basic model for tabular data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TabularModel(
  emb_szs,
  n_cont,
  out_sz,
  layers,
  ps = NULL,
  embed_p = 0,
  y_range = NULL,
  use_bn = TRUE,
  bn_final = FALSE,
  bn_cont = TRUE,
  act_cls = nn()$ReLU(inplace = TRUE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TabularModel_+3A_emb_szs">emb_szs</code></td>
<td>
<p>embedding size</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_n_cont">n_cont</code></td>
<td>
<p>number of cont</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_out_sz">out_sz</code></td>
<td>
<p>output size</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_layers">layers</code></td>
<td>
<p>layers</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_ps">ps</code></td>
<td>
<p>ps</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_embed_p">embed_p</code></td>
<td>
<p>embed proportion</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_y_range">y_range</code></td>
<td>
<p>y range</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_use_bn">use_bn</code></td>
<td>
<p>use batch normalization</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_bn_final">bn_final</code></td>
<td>
<p>batch normalization final</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_bn_cont">bn_cont</code></td>
<td>
<p>batch normalization cont</p>
</td></tr>
<tr><td><code id="TabularModel_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TabularTS'>TabularTS</h2><span id='topic+TabularTS'></span>

<h3>Description</h3>

<p>A 'DataFrame' wrapper that knows which cols are x/y, and returns rows in '__getitem__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TabularTS(
  df,
  procs = NULL,
  x_names = NULL,
  y_names = NULL,
  block_y = NULL,
  splits = NULL,
  do_setup = TRUE,
  device = NULL,
  inplace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TabularTS_+3A_df">df</code></td>
<td>
<p>A DataFrame of your data</p>
</td></tr>
<tr><td><code id="TabularTS_+3A_procs">procs</code></td>
<td>
<p>list of preprocess functions</p>
</td></tr>
<tr><td><code id="TabularTS_+3A_x_names">x_names</code></td>
<td>
<p>predictors names</p>
</td></tr>
<tr><td><code id="TabularTS_+3A_y_names">y_names</code></td>
<td>
<p>the names of the dependent variables</p>
</td></tr>
<tr><td><code id="TabularTS_+3A_block_y">block_y</code></td>
<td>
<p>the TransformBlock to use for the target</p>
</td></tr>
<tr><td><code id="TabularTS_+3A_splits">splits</code></td>
<td>
<p>How to split your data</p>
</td></tr>
<tr><td><code id="TabularTS_+3A_do_setup">do_setup</code></td>
<td>
<p>A parameter for if Tabular will run the data through the procs upon initialization</p>
</td></tr>
<tr><td><code id="TabularTS_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="TabularTS_+3A_inplace">inplace</code></td>
<td>
<p>If True, Tabular will not keep a separate copy of your original DataFrame in memory</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TabularTSDataloader'>TabularTSDataloader</h2><span id='topic+TabularTSDataloader'></span>

<h3>Description</h3>

<p>Transformed 'DataLoader'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TabularTSDataloader(
  dataset,
  bs = 16,
  shuffle = FALSE,
  after_batch = NULL,
  num_workers = 0,
  verbose = FALSE,
  do_setup = TRUE,
  pin_memory = FALSE,
  timeout = 0,
  batch_size = NULL,
  drop_last = FALSE,
  indexed = NULL,
  n = NULL,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TabularTSDataloader_+3A_dataset">dataset</code></td>
<td>
<p>data set</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle or not</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_after_batch">after_batch</code></td>
<td>
<p>after batch</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_num_workers">num_workers</code></td>
<td>
<p>the number of workers</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_verbose">verbose</code></td>
<td>
<p>verbose</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_do_setup">do_setup</code></td>
<td>
<p>A parameter for if Tabular will run the data through the procs upon initialization</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_pin_memory">pin_memory</code></td>
<td>
<p>pin memory or not</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_timeout">timeout</code></td>
<td>
<p>timeout</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_batch_size">batch_size</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_drop_last">drop_last</code></td>
<td>
<p>drop last</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_indexed">indexed</code></td>
<td>
<p>indexed</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_n">n</code></td>
<td>
<p>n</p>
</td></tr>
<tr><td><code id="TabularTSDataloader_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tar_extract_at_filename'>Tar_extract_at_filename</h2><span id='topic+tar_extract_at_filename'></span>

<h3>Description</h3>

<p>Extract 'fname' to 'dest'/'fname.name' folder using 'tarfile'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tar_extract_at_filename(fname, dest)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tar_extract_at_filename_+3A_fname">fname</code></td>
<td>
<p>folder name</p>
</td></tr>
<tr><td><code id="tar_extract_at_filename_+3A_dest">dest</code></td>
<td>
<p>destination</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tensor'>Tensor</h2><span id='topic+tensor'></span>

<h3>Description</h3>

<p>Like 'torch()$as_tensor', but handle lists too, and can pass multiple vector elements directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tensor(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tensor_+3A_...">...</code></td>
<td>
<p>image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TensorBBox'>TensorBBox</h2><span id='topic+TensorBBox'></span>

<h3>Description</h3>

<p>Basic type for a tensor of bounding boxes in an image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TensorBBox(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TensorBBox_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TensorBBox_create'>TensorBBox_create</h2><span id='topic+TensorBBox_create'></span>

<h3>Description</h3>

<p>TensorBBox_create
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TensorBBox_create(x, img_size = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TensorBBox_create_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="TensorBBox_create_+3A_img_size">img_size</code></td>
<td>
<p>image size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TensorImage'>TensorImage</h2><span id='topic+TensorImage'></span>

<h3>Description</h3>

<p>TensorImage
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TensorImage(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TensorImage_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TensorImageBW'>TensorImageBW</h2><span id='topic+TensorImageBW'></span>

<h3>Description</h3>

<p>TensorImageBW
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TensorImageBW(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TensorImageBW_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TensorMultiCategory'>TensorMultiCategory</h2><span id='topic+TensorMultiCategory'></span>

<h3>Description</h3>

<p>TensorMultiCategory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TensorMultiCategory(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TensorMultiCategory_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TensorPoint'>TensorPoint</h2><span id='topic+TensorPoint'></span>

<h3>Description</h3>

<p>Basic type for points in an image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TensorPoint(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TensorPoint_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TensorPoint_create'>TensorPoint_create</h2><span id='topic+TensorPoint_create'></span>

<h3>Description</h3>

<p>Delegates ('__call__','decode','setup') to ('encodes','decodes','setups') if 'split_idx' matches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TensorPoint_create(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TensorPoint_create_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TerminateOnNaNCallback'>TerminateOnNaNCallback</h2><span id='topic+TerminateOnNaNCallback'></span>

<h3>Description</h3>

<p>TerminateOnNaNCallback
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TerminateOnNaNCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TerminateOnNaNCallback_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='test_loader'>Test_loader</h2><span id='topic+test_loader'></span>

<h3>Description</h3>

<p>Data loader. Combines a dataset and a sampler, and provides an iterable over
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_loader()
</code></pre>


<h3>Details</h3>

<p>the given dataset. The :class:'~torch.utils.data.DataLoader' supports both map-style and
iterable-style datasets with single- or multi-process loading, customizing
loading order and optional automatic batching (collation) and memory pinning. See :py:mod:'torch.utils.data' documentation page for more details.
</p>


<h3>Value</h3>

<p>loader
</p>

<hr>
<h2 id='text'>Text module</h2><span id='topic+text'></span>

<h3>Description</h3>

<p>Text module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>text()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='text_classifier_learner'>Text_classifier_learner</h2><span id='topic+text_classifier_learner'></span>

<h3>Description</h3>

<p>Create a 'Learner' with a text classifier from 'dls' and 'arch'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>text_classifier_learner(
  dls,
  arch,
  seq_len = 72,
  config = NULL,
  backwards = FALSE,
  pretrained = TRUE,
  drop_mult = 0.5,
  n_out = NULL,
  lin_ftrs = NULL,
  ps = NULL,
  max_len = 1440,
  y_range = NULL,
  loss_func = NULL,
  opt_func = Adam(),
  lr = 0.001,
  splitter = trainable_params,
  cbs = NULL,
  metrics = NULL,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE,
  moms = list(0.95, 0.85, 0.95)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="text_classifier_learner_+3A_dls">dls</code></td>
<td>
<p>dls</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_arch">arch</code></td>
<td>
<p>arch</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_seq_len">seq_len</code></td>
<td>
<p>seq_len</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_config">config</code></td>
<td>
<p>config</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_drop_mult">drop_mult</code></td>
<td>
<p>drop_mult</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_n_out">n_out</code></td>
<td>
<p>n_out</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_lin_ftrs">lin_ftrs</code></td>
<td>
<p>lin_ftrs</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_ps">ps</code></td>
<td>
<p>ps</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_max_len">max_len</code></td>
<td>
<p>max_len</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_y_range">y_range</code></td>
<td>
<p>y_range</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_loss_func">loss_func</code></td>
<td>
<p>loss_func</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_opt_func">opt_func</code></td>
<td>
<p>opt_func</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_lr">lr</code></td>
<td>
<p>lr</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_splitter">splitter</code></td>
<td>
<p>splitter</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_cbs">cbs</code></td>
<td>
<p>cbs</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_metrics">metrics</code></td>
<td>
<p>metrics</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_model_dir">model_dir</code></td>
<td>
<p>model_dir</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_wd">wd</code></td>
<td>
<p>wd</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>wd_bn_bias</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_train_bn">train_bn</code></td>
<td>
<p>train_bn</p>
</td></tr>
<tr><td><code id="text_classifier_learner_+3A_moms">moms</code></td>
<td>
<p>moms</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TextBlock'>TextBlock</h2><span id='topic+TextBlock'></span>

<h3>Description</h3>

<p>A 'TransformBlock' for texts
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextBlock(
  tok_tfm,
  vocab = NULL,
  is_lm = FALSE,
  seq_len = 72,
  backwards = FALSE,
  min_freq = 3,
  max_vocab = 60000,
  special_toks = NULL,
  pad_tok = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextBlock_+3A_tok_tfm">tok_tfm</code></td>
<td>
<p>tok_tfm</p>
</td></tr>
<tr><td><code id="TextBlock_+3A_vocab">vocab</code></td>
<td>
<p>vocab</p>
</td></tr>
<tr><td><code id="TextBlock_+3A_is_lm">is_lm</code></td>
<td>
<p>is_lm</p>
</td></tr>
<tr><td><code id="TextBlock_+3A_seq_len">seq_len</code></td>
<td>
<p>seq_len</p>
</td></tr>
<tr><td><code id="TextBlock_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
<tr><td><code id="TextBlock_+3A_min_freq">min_freq</code></td>
<td>
<p>min_freq</p>
</td></tr>
<tr><td><code id="TextBlock_+3A_max_vocab">max_vocab</code></td>
<td>
<p>max_vocab</p>
</td></tr>
<tr><td><code id="TextBlock_+3A_special_toks">special_toks</code></td>
<td>
<p>special_toks</p>
</td></tr>
<tr><td><code id="TextBlock_+3A_pad_tok">pad_tok</code></td>
<td>
<p>pad_tok</p>
</td></tr>
</table>


<h3>Value</h3>

<p>block object
</p>

<hr>
<h2 id='TextBlock_from_df'>TextBlock_from_df</h2><span id='topic+TextBlock_from_df'></span>

<h3>Description</h3>

<p>Build a 'TextBlock' from a dataframe using 'text_cols'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextBlock_from_df(
  text_cols,
  vocab = NULL,
  is_lm = FALSE,
  seq_len = 72,
  backwards = FALSE,
  min_freq = 3,
  max_vocab = 60000,
  tok = NULL,
  rules = NULL,
  sep = " ",
  n_workers = 6,
  mark_fields = NULL,
  tok_text_col = "text"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextBlock_from_df_+3A_text_cols">text_cols</code></td>
<td>
<p>text columns</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_is_lm">is_lm</code></td>
<td>
<p>is_lm</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_seq_len">seq_len</code></td>
<td>
<p>sequence length</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_min_freq">min_freq</code></td>
<td>
<p>minimum frequency</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_max_vocab">max_vocab</code></td>
<td>
<p>max vocabulary</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_sep">sep</code></td>
<td>
<p>separator</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_n_workers">n_workers</code></td>
<td>
<p>number workers</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_mark_fields">mark_fields</code></td>
<td>
<p>mark_fields</p>
</td></tr>
<tr><td><code id="TextBlock_from_df_+3A_tok_text_col">tok_text_col</code></td>
<td>
<p>result column name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TextBlock_from_folder'>TextBlock_from_folder</h2><span id='topic+TextBlock_from_folder'></span>

<h3>Description</h3>

<p>Build a 'TextBlock' from a 'path'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextBlock_from_folder(
  path,
  vocab = NULL,
  is_lm = FALSE,
  seq_len = 72,
  backwards = FALSE,
  min_freq = 3,
  max_vocab = 60000,
  tok = NULL,
  rules = NULL,
  extensions = NULL,
  folders = NULL,
  output_dir = NULL,
  skip_if_exists = TRUE,
  output_names = NULL,
  n_workers = 6,
  encoding = "utf8"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextBlock_from_folder_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_vocab">vocab</code></td>
<td>
<p>vocabualry</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_is_lm">is_lm</code></td>
<td>
<p>is_lm</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_seq_len">seq_len</code></td>
<td>
<p>sequence length</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_min_freq">min_freq</code></td>
<td>
<p>minimum frequency</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_max_vocab">max_vocab</code></td>
<td>
<p>max vocabulary</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_extensions">extensions</code></td>
<td>
<p>extensions</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_folders">folders</code></td>
<td>
<p>folders</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_output_dir">output_dir</code></td>
<td>
<p>output_dir</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_skip_if_exists">skip_if_exists</code></td>
<td>
<p>skip_if_exists</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_output_names">output_names</code></td>
<td>
<p>output_names</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_n_workers">n_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
<tr><td><code id="TextBlock_from_folder_+3A_encoding">encoding</code></td>
<td>
<p>encoding</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TextDataLoaders_from_csv'>TextDataLoaders_from_csv</h2><span id='topic+TextDataLoaders_from_csv'></span>

<h3>Description</h3>

<p>Create from 'csv' file in 'path/csv_fname'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextDataLoaders_from_csv(
  path,
  csv_fname = "labels.csv",
  header = "infer",
  delimiter = NULL,
  valid_pct = 0.2,
  seed = NULL,
  text_col = 0,
  label_col = 1,
  label_delim = NULL,
  y_block = NULL,
  text_vocab = NULL,
  is_lm = FALSE,
  valid_col = NULL,
  tok_tfm = NULL,
  seq_len = 72,
  backwards = FALSE,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextDataLoaders_from_csv_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_csv_fname">csv_fname</code></td>
<td>
<p>csv file name</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_header">header</code></td>
<td>
<p>header</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_delimiter">delimiter</code></td>
<td>
<p>delimiter</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_valid_pct">valid_pct</code></td>
<td>
<p>valid_ation percentage</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_text_col">text_col</code></td>
<td>
<p>text column</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_label_col">label_col</code></td>
<td>
<p>label column</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_label_delim">label_delim</code></td>
<td>
<p>label separator</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_y_block">y_block</code></td>
<td>
<p>y_block</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_text_vocab">text_vocab</code></td>
<td>
<p>text vocabulary</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_is_lm">is_lm</code></td>
<td>
<p>is_lm</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_valid_col">valid_col</code></td>
<td>
<p>valid column</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_tok_tfm">tok_tfm</code></td>
<td>
<p>tok_tfm</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_seq_len">seq_len</code></td>
<td>
<p>seq_len</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_val_bs">val_bs</code></td>
<td>
<p>validation batch size</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>shuffle train data</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_csv_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
</table>


<h3>Value</h3>

<p>text loader
</p>

<hr>
<h2 id='TextDataLoaders_from_df'>TextDataLoaders_from_df</h2><span id='topic+TextDataLoaders_from_df'></span>

<h3>Description</h3>

<p>Create from 'df' in 'path' with 'valid_pct'
'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextDataLoaders_from_df(
  df,
  path = ".",
  valid_pct = 0.2,
  seed = NULL,
  text_col = 0,
  label_col = 1,
  label_delim = NULL,
  y_block = NULL,
  text_vocab = NULL,
  is_lm = FALSE,
  valid_col = NULL,
  tok_tfm = NULL,
  seq_len = 72,
  backwards = FALSE,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextDataLoaders_from_df_+3A_df">df</code></td>
<td>
<p>df</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_valid_pct">valid_pct</code></td>
<td>
<p>validation percentage</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_seed">seed</code></td>
<td>
<p>seed</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_text_col">text_col</code></td>
<td>
<p>text_col</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_label_col">label_col</code></td>
<td>
<p>label_col</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_label_delim">label_delim</code></td>
<td>
<p>label_delim</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_y_block">y_block</code></td>
<td>
<p>y_block</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_text_vocab">text_vocab</code></td>
<td>
<p>text_vocab</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_is_lm">is_lm</code></td>
<td>
<p>is_lm</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_valid_col">valid_col</code></td>
<td>
<p>valid_col</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_tok_tfm">tok_tfm</code></td>
<td>
<p>tok_tfm</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_seq_len">seq_len</code></td>
<td>
<p>seq_len</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_val_bs">val_bs</code></td>
<td>
<p>validation batch size, if not specified then val_bs is the same as bs.</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>shuffle_train</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_df_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
</table>


<h3>Value</h3>

<p>text loader
</p>

<hr>
<h2 id='TextDataLoaders_from_folder'>TextDataLoaders_from_folder</h2><span id='topic+TextDataLoaders_from_folder'></span>

<h3>Description</h3>

<p>Create from imagenet style dataset in 'path' with 'train' and 'valid' subfolders (or provide 'valid_pct')
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextDataLoaders_from_folder(
  path,
  train = "train",
  valid = "valid",
  valid_pct = NULL,
  seed = NULL,
  vocab = NULL,
  text_vocab = NULL,
  is_lm = FALSE,
  tok_tfm = NULL,
  seq_len = 72,
  backwards = FALSE,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextDataLoaders_from_folder_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_train">train</code></td>
<td>
<p>train data</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_valid">valid</code></td>
<td>
<p>validation data</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_valid_pct">valid_pct</code></td>
<td>
<p>validation percentage</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_seed">seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_vocab">vocab</code></td>
<td>
<p>vocabulary</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_text_vocab">text_vocab</code></td>
<td>
<p>text_vocab</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_is_lm">is_lm</code></td>
<td>
<p>is_lm</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_tok_tfm">tok_tfm</code></td>
<td>
<p>tok_tfm</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_seq_len">seq_len</code></td>
<td>
<p>seq_len</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_backwards">backwards</code></td>
<td>
<p>backwards</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_val_bs">val_bs</code></td>
<td>
<p>validation batch size</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>shuffle train data</p>
</td></tr>
<tr><td><code id="TextDataLoaders_from_folder_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
</table>


<h3>Value</h3>

<p>text loader
</p>

<hr>
<h2 id='TextLearner'>TextLearner</h2><span id='topic+TextLearner'></span>

<h3>Description</h3>

<p>Basic class for a 'Learner' in NLP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextLearner(
  dls,
  model,
  alpha = 2,
  beta = 1,
  moms = list(0.8, 0.7, 0.8),
  loss_func = NULL,
  opt_func = Adam(),
  lr = 0.001,
  splitter = trainable_params(),
  cbs = NULL,
  metrics = NULL,
  path = NULL,
  model_dir = "models",
  wd = NULL,
  wd_bn_bias = FALSE,
  train_bn = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextLearner_+3A_dls">dls</code></td>
<td>
<p>dls</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_alpha">alpha</code></td>
<td>
<p>alpha</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_beta">beta</code></td>
<td>
<p>beta</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_moms">moms</code></td>
<td>
<p>moms</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_loss_func">loss_func</code></td>
<td>
<p>loss_func</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_opt_func">opt_func</code></td>
<td>
<p>opt_func</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_lr">lr</code></td>
<td>
<p>lr</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_splitter">splitter</code></td>
<td>
<p>splitter</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_cbs">cbs</code></td>
<td>
<p>cbs</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_metrics">metrics</code></td>
<td>
<p>metrics</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_model_dir">model_dir</code></td>
<td>
<p>model_dir</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_wd">wd</code></td>
<td>
<p>wd</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_wd_bn_bias">wd_bn_bias</code></td>
<td>
<p>wd_bn_bias</p>
</td></tr>
<tr><td><code id="TextLearner_+3A_train_bn">train_bn</code></td>
<td>
<p>train_bn</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TextLearner_load_encoder'>Load_encoder</h2><span id='topic+TextLearner_load_encoder'></span>

<h3>Description</h3>

<p>Load the encoder &lsquo;file' from the model directory, optionally ensuring it&rsquo;s on 'device'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextLearner_load_encoder(file, device = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextLearner_load_encoder_+3A_file">file</code></td>
<td>
<p>file</p>
</td></tr>
<tr><td><code id="TextLearner_load_encoder_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TextLearner_load_pretrained'>Load_pretrained</h2><span id='topic+TextLearner_load_pretrained'></span>

<h3>Description</h3>

<p>Load a pretrained model and adapt it to the data vocabulary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextLearner_load_pretrained(wgts_fname, vocab_fname, model = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextLearner_load_pretrained_+3A_wgts_fname">wgts_fname</code></td>
<td>
<p>wgts_fname</p>
</td></tr>
<tr><td><code id="TextLearner_load_pretrained_+3A_vocab_fname">vocab_fname</code></td>
<td>
<p>vocab_fname</p>
</td></tr>
<tr><td><code id="TextLearner_load_pretrained_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TextLearner_save_encoder'>Save_encoder</h2><span id='topic+TextLearner_save_encoder'></span>

<h3>Description</h3>

<p>Save the encoder to 'file' in the model directory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextLearner_save_encoder(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextLearner_save_encoder_+3A_file">file</code></td>
<td>
<p>file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TfmdDL'>TfmdDL</h2><span id='topic+TfmdDL'></span>

<h3>Description</h3>

<p>Transformed 'DataLoader'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TfmdDL(
  dataset,
  bs = 64,
  shuffle = FALSE,
  num_workers = NULL,
  verbose = FALSE,
  do_setup = TRUE,
  pin_memory = FALSE,
  timeout = 0,
  batch_size = NULL,
  drop_last = FALSE,
  indexed = NULL,
  n = NULL,
  device = NULL,
  after_batch = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TfmdDL_+3A_dataset">dataset</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_num_workers">num_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_verbose">verbose</code></td>
<td>
<p>verbose</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_do_setup">do_setup</code></td>
<td>
<p>do setup</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_pin_memory">pin_memory</code></td>
<td>
<p>pin memory</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_timeout">timeout</code></td>
<td>
<p>timeout</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_batch_size">batch_size</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_drop_last">drop_last</code></td>
<td>
<p>drop last</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_indexed">indexed</code></td>
<td>
<p>indexed</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_n">n</code></td>
<td>
<p>int, n</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_after_batch">after_batch</code></td>
<td>
<p>after_batch</p>
</td></tr>
<tr><td><code id="TfmdDL_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TfmdLists'>TfmdLists</h2><span id='topic+TfmdLists'></span>

<h3>Description</h3>

<p>A 'Pipeline' of 'tfms' applied to a collection of 'items'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TfmdLists(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TfmdLists_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>

<hr>
<h2 id='TfmResize'>TfmResize</h2><span id='topic+TfmResize'></span>

<h3>Description</h3>

<p>Temporary fix to allow image resizing transform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TfmResize(size, interp_mode = "bilinear")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TfmResize_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="TfmResize_+3A_interp_mode">interp_mode</code></td>
<td>
<p>interpolation mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='timm'>Timm module</h2><span id='topic+timm'></span>

<h3>Description</h3>

<p>Timm module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timm()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='timm_learner'>Timm_learner</h2><span id='topic+timm_learner'></span>

<h3>Description</h3>

<p>Build a convnet style learner from 'dls' and 'arch' using the 'timm' library
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timm_learner(dls, arch, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timm_learner_+3A_dls">dls</code></td>
<td>
<p>dataloader</p>
</td></tr>
<tr><td><code id="timm_learner_+3A_arch">arch</code></td>
<td>
<p>model architecture</p>
</td></tr>
<tr><td><code id="timm_learner_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='timm_list_models'>Timm models</h2><span id='topic+timm_list_models'></span>

<h3>Description</h3>

<p>Timm models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timm_list_models(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timm_list_models_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector
</p>

<hr>
<h2 id='tms'>Timeseries module</h2><span id='topic+tms'></span>

<h3>Description</h3>

<p>Timeseries module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tms()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='to_bytes_format'>To_bytes_format</h2><span id='topic+to_bytes_format'></span>

<h3>Description</h3>

<p>Convert to bytes, default to PNG format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_bytes_format(img, format = "png")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_bytes_format_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
<tr><td><code id="to_bytes_format_+3A_format">format</code></td>
<td>
<p>format</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='to_image'>To_image</h2><span id='topic+to_image'></span>

<h3>Description</h3>

<p>Convert a tensor or array to a PIL int8 Image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_image(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_image_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='to_matrix'>To matrix</h2><span id='topic+to_matrix'></span>

<h3>Description</h3>

<p>To matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_matrix(obj, matrix = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_matrix_+3A_obj">obj</code></td>
<td>
<p>learner/model</p>
</td></tr>
<tr><td><code id="to_matrix_+3A_matrix">matrix</code></td>
<td>
<p>bool, to R matrix</p>
</td></tr>
</table>

<hr>
<h2 id='to_thumb'>To_thumb</h2><span id='topic+to_thumb'></span>

<h3>Description</h3>

<p>Same as 'thumbnail', but uses a copy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_thumb(img, h, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_thumb_+3A_img">img</code></td>
<td>
<p>image</p>
</td></tr>
<tr><td><code id="to_thumb_+3A_h">h</code></td>
<td>
<p>height</p>
</td></tr>
<tr><td><code id="to_thumb_+3A_w">w</code></td>
<td>
<p>width</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='to_xla'>Learn to XLA</h2><span id='topic+to_xla'></span>

<h3>Description</h3>

<p>Distribute the training across TPUs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_xla(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_xla_+3A_object">object</code></td>
<td>
<p>learner / model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tokenize_csv'>Tokenize_csv</h2><span id='topic+tokenize_csv'></span>

<h3>Description</h3>

<p>Tokenize texts in the 'text_cols' of the csv 'fname' in parallel using 'n_workers'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenize_csv(
  fname,
  text_cols,
  outname = NULL,
  n_workers = 4,
  rules = NULL,
  mark_fields = NULL,
  tok = NULL,
  header = "infer",
  chunksize = 50000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokenize_csv_+3A_fname">fname</code></td>
<td>
<p>file name</p>
</td></tr>
<tr><td><code id="tokenize_csv_+3A_text_cols">text_cols</code></td>
<td>
<p>text columns</p>
</td></tr>
<tr><td><code id="tokenize_csv_+3A_outname">outname</code></td>
<td>
<p>outname</p>
</td></tr>
<tr><td><code id="tokenize_csv_+3A_n_workers">n_workers</code></td>
<td>
<p>numeber of workers</p>
</td></tr>
<tr><td><code id="tokenize_csv_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="tokenize_csv_+3A_mark_fields">mark_fields</code></td>
<td>
<p>mark fields</p>
</td></tr>
<tr><td><code id="tokenize_csv_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="tokenize_csv_+3A_header">header</code></td>
<td>
<p>header</p>
</td></tr>
<tr><td><code id="tokenize_csv_+3A_chunksize">chunksize</code></td>
<td>
<p>chunk size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tokenize_df'>Tokenize_df</h2><span id='topic+tokenize_df'></span>

<h3>Description</h3>

<p>Tokenize texts in 'df[text_cols]' in parallel using 'n_workers'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenize_df(
  df,
  text_cols,
  n_workers = 6,
  rules = NULL,
  mark_fields = NULL,
  tok = NULL,
  tok_text_col = "text"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokenize_df_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="tokenize_df_+3A_text_cols">text_cols</code></td>
<td>
<p>text columns</p>
</td></tr>
<tr><td><code id="tokenize_df_+3A_n_workers">n_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
<tr><td><code id="tokenize_df_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="tokenize_df_+3A_mark_fields">mark_fields</code></td>
<td>
<p>mark_fields</p>
</td></tr>
<tr><td><code id="tokenize_df_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="tokenize_df_+3A_tok_text_col">tok_text_col</code></td>
<td>
<p>tok_text_col</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tokenize_files'>Tokenize_files</h2><span id='topic+tokenize_files'></span>

<h3>Description</h3>

<p>Tokenize text 'files' in parallel using 'n_workers'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenize_files(
  files,
  path,
  output_dir,
  output_names = NULL,
  n_workers = 6,
  rules = NULL,
  tok = NULL,
  encoding = "utf8",
  skip_if_exists = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokenize_files_+3A_files">files</code></td>
<td>
<p>files</p>
</td></tr>
<tr><td><code id="tokenize_files_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="tokenize_files_+3A_output_dir">output_dir</code></td>
<td>
<p>output_dir</p>
</td></tr>
<tr><td><code id="tokenize_files_+3A_output_names">output_names</code></td>
<td>
<p>output_names</p>
</td></tr>
<tr><td><code id="tokenize_files_+3A_n_workers">n_workers</code></td>
<td>
<p>n_workers</p>
</td></tr>
<tr><td><code id="tokenize_files_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="tokenize_files_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="tokenize_files_+3A_encoding">encoding</code></td>
<td>
<p>encoding</p>
</td></tr>
<tr><td><code id="tokenize_files_+3A_skip_if_exists">skip_if_exists</code></td>
<td>
<p>skip_if_exists</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tokenize_folder'>Tokenize_folder</h2><span id='topic+tokenize_folder'></span>

<h3>Description</h3>

<p>Tokenize text files in 'path' in parallel using 'n_workers'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenize_folder(
  path,
  extensions = NULL,
  folders = NULL,
  output_dir = NULL,
  skip_if_exists = TRUE,
  output_names = NULL,
  n_workers = 6,
  rules = NULL,
  tok = NULL,
  encoding = "utf8"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokenize_folder_+3A_path">path</code></td>
<td>
<p>path</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_extensions">extensions</code></td>
<td>
<p>extensions</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_folders">folders</code></td>
<td>
<p>folders</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_output_dir">output_dir</code></td>
<td>
<p>output_dir</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_skip_if_exists">skip_if_exists</code></td>
<td>
<p>skip_if_exists</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_output_names">output_names</code></td>
<td>
<p>output_names</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_n_workers">n_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="tokenize_folder_+3A_encoding">encoding</code></td>
<td>
<p>encoding</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tokenize_texts'>Tokenize_texts</h2><span id='topic+tokenize_texts'></span>

<h3>Description</h3>

<p>Tokenize 'texts' in parallel using 'n_workers'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenize_texts(texts, n_workers = 6, rules = NULL, tok = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokenize_texts_+3A_texts">texts</code></td>
<td>
<p>texts</p>
</td></tr>
<tr><td><code id="tokenize_texts_+3A_n_workers">n_workers</code></td>
<td>
<p>n_workers</p>
</td></tr>
<tr><td><code id="tokenize_texts_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="tokenize_texts_+3A_tok">tok</code></td>
<td>
<p>tok</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='tokenize1'>Tokenize1</h2><span id='topic+tokenize1'></span>

<h3>Description</h3>

<p>Call 'TokenizeWithRules' with a single text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenize1(text, tok, rules = NULL, post_rules = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokenize1_+3A_text">text</code></td>
<td>
<p>text</p>
</td></tr>
<tr><td><code id="tokenize1_+3A_tok">tok</code></td>
<td>
<p>tok</p>
</td></tr>
<tr><td><code id="tokenize1_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="tokenize1_+3A_post_rules">post_rules</code></td>
<td>
<p>post_rules</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Tokenizer'>Tokenizer</h2><span id='topic+Tokenizer'></span>

<h3>Description</h3>

<p>Provides a consistent 'Transform' interface to tokenizers operating on 'DataFrame's and folders
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tokenizer(
  tok,
  rules = NULL,
  counter = NULL,
  lengths = NULL,
  mode = NULL,
  sep = " "
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tokenizer_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="Tokenizer_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="Tokenizer_+3A_counter">counter</code></td>
<td>
<p>counter</p>
</td></tr>
<tr><td><code id="Tokenizer_+3A_lengths">lengths</code></td>
<td>
<p>lengths</p>
</td></tr>
<tr><td><code id="Tokenizer_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="Tokenizer_+3A_sep">sep</code></td>
<td>
<p>separator</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Tokenizer_from_df'>Tokenizer_from_df</h2><span id='topic+Tokenizer_from_df'></span>

<h3>Description</h3>

<p>Tokenizer_from_df
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tokenizer_from_df(
  text_cols,
  tok = NULL,
  rules = NULL,
  sep = " ",
  n_workers = 6,
  mark_fields = NULL,
  tok_text_col = "text"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tokenizer_from_df_+3A_text_cols">text_cols</code></td>
<td>
<p>text columns</p>
</td></tr>
<tr><td><code id="Tokenizer_from_df_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="Tokenizer_from_df_+3A_rules">rules</code></td>
<td>
<p>special rules</p>
</td></tr>
<tr><td><code id="Tokenizer_from_df_+3A_sep">sep</code></td>
<td>
<p>separator</p>
</td></tr>
<tr><td><code id="Tokenizer_from_df_+3A_n_workers">n_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
<tr><td><code id="Tokenizer_from_df_+3A_mark_fields">mark_fields</code></td>
<td>
<p>mark fields</p>
</td></tr>
<tr><td><code id="Tokenizer_from_df_+3A_tok_text_col">tok_text_col</code></td>
<td>
<p>output column name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TokenizeWithRules'>TokenizeWithRules</h2><span id='topic+TokenizeWithRules'></span>

<h3>Description</h3>

<p>A wrapper around 'tok' which applies 'rules', then tokenizes, then applies 'post_rules'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TokenizeWithRules(tok, rules = NULL, post_rules = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TokenizeWithRules_+3A_tok">tok</code></td>
<td>
<p>tokenizer</p>
</td></tr>
<tr><td><code id="TokenizeWithRules_+3A_rules">rules</code></td>
<td>
<p>rules</p>
</td></tr>
<tr><td><code id="TokenizeWithRules_+3A_post_rules">post_rules</code></td>
<td>
<p>post_rules</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='top_k_accuracy'>Top_k_accuracy</h2><span id='topic+top_k_accuracy'></span>

<h3>Description</h3>

<p>Computes the Top-k accuracy ('targ' is in the top 'k' predictions of 'inp')
</p>


<h3>Usage</h3>

<pre><code class='language-R'>top_k_accuracy(inp, targ, k = 5, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="top_k_accuracy_+3A_inp">inp</code></td>
<td>
<p>predictions</p>
</td></tr>
<tr><td><code id="top_k_accuracy_+3A_targ">targ</code></td>
<td>
<p>targets</p>
</td></tr>
<tr><td><code id="top_k_accuracy_+3A_k">k</code></td>
<td>
<p>k</p>
</td></tr>
<tr><td><code id="top_k_accuracy_+3A_axis">axis</code></td>
<td>
<p>axis</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

loaders = loaders()

data = Data_Loaders(loaders['train'], loaders['valid'])$cuda()

model = nn$Sequential() +
  nn$Flatten() +
  nn$Linear(28L * 28L, 10L)
metrics = list(accuracy,top_k_accuracy)
learn = Learner(data, model, loss_func = F$cross_entropy, opt_func = Adam,
                metrics = metrics)


## End(Not run)

</code></pre>

<hr>
<h2 id='torch'>Builtins module</h2><span id='topic+torch'></span>

<h3>Description</h3>

<p>Builtins module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>torch()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='total_params'>Total_params</h2><span id='topic+total_params'></span>

<h3>Description</h3>

<p>Give the number of parameters of a module and if it's trainable or not
</p>


<h3>Usage</h3>

<pre><code class='language-R'>total_params(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="total_params_+3A_m">m</code></td>
<td>
<p>m parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='ToTensor'>ToTensor</h2><span id='topic+ToTensor'></span>

<h3>Description</h3>

<p>Convert item to appropriate tensor class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ToTensor(enc = NULL, dec = NULL, split_idx = NULL, order = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ToTensor_+3A_enc">enc</code></td>
<td>
<p>encoder</p>
</td></tr>
<tr><td><code id="ToTensor_+3A_dec">dec</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="ToTensor_+3A_split_idx">split_idx</code></td>
<td>
<p>int, split by index</p>
</td></tr>
<tr><td><code id="ToTensor_+3A_order">order</code></td>
<td>
<p>order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TrackerCallback'>TrackerCallback</h2><span id='topic+TrackerCallback'></span>

<h3>Description</h3>

<p>A 'Callback' that keeps track of the best value in 'monitor'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TrackerCallback(monitor = "valid_loss", comp = NULL, min_delta = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TrackerCallback_+3A_monitor">monitor</code></td>
<td>
<p>monitor the loss</p>
</td></tr>
<tr><td><code id="TrackerCallback_+3A_comp">comp</code></td>
<td>
<p>comp</p>
</td></tr>
<tr><td><code id="TrackerCallback_+3A_min_delta">min_delta</code></td>
<td>
<p>minimum delta</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='train_loader'>Train_loader</h2><span id='topic+train_loader'></span>

<h3>Description</h3>

<p>Data loader. Combines a dataset and a sampler, and provides an iterable over
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_loader()
</code></pre>


<h3>Details</h3>

<p>the given dataset. The :class:'~torch.utils.data.DataLoader' supports both map-style and
iterable-style datasets with single- or multi-process loading, customizing
loading order and optional automatic batching (collation) and memory pinning.
</p>


<h3>Value</h3>

<p>loader
</p>

<hr>
<h2 id='trainable_params'>Trainable_params</h2><span id='topic+trainable_params'></span>

<h3>Description</h3>

<p>Return all trainable parameters of 'm'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trainable_params(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trainable_params_+3A_m">m</code></td>
<td>
<p>trainable parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TrainEvalCallback'>TrainEvalCallback</h2><span id='topic+TrainEvalCallback'></span>

<h3>Description</h3>

<p>TrainEvalCallback
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TrainEvalCallback(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TrainEvalCallback_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Transform'>Transform</h2><span id='topic+Transform'></span>

<h3>Description</h3>

<p>Delegates ('__call__','decode','setup') to ('encodes','decodes','setups') if 'split_idx' matches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Transform(enc = NULL, dec = NULL, split_idx = NULL, order = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Transform_+3A_enc">enc</code></td>
<td>
<p>encoder</p>
</td></tr>
<tr><td><code id="Transform_+3A_dec">dec</code></td>
<td>
<p>decoder</p>
</td></tr>
<tr><td><code id="Transform_+3A_split_idx">split_idx</code></td>
<td>
<p>split by index</p>
</td></tr>
<tr><td><code id="Transform_+3A_order">order</code></td>
<td>
<p>order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TransformBlock'>TransformBlock</h2><span id='topic+TransformBlock'></span>

<h3>Description</h3>

<p>A basic wrapper that links defaults transforms for the data block API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TransformBlock(
  type_tfms = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  dl_type = NULL,
  dls_kwargs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TransformBlock_+3A_type_tfms">type_tfms</code></td>
<td>
<p>transformation type</p>
</td></tr>
<tr><td><code id="TransformBlock_+3A_item_tfms">item_tfms</code></td>
<td>
<p>item transformation type</p>
</td></tr>
<tr><td><code id="TransformBlock_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>one or several transforms applied to the batches once they are formed</p>
</td></tr>
<tr><td><code id="TransformBlock_+3A_dl_type">dl_type</code></td>
<td>
<p>DL application</p>
</td></tr>
<tr><td><code id="TransformBlock_+3A_dls_kwargs">dls_kwargs</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>block
</p>

<hr>
<h2 id='transformers'>Transformers</h2><span id='topic+transformers'></span>

<h3>Description</h3>

<p>Transformers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformers()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TransformersDropOutput'>TransformersDropOutput</h2><span id='topic+TransformersDropOutput'></span>

<h3>Description</h3>

<p>TransformersDropOutput
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TransformersDropOutput()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TransformersTokenizer'>TransformersTokenizer</h2><span id='topic+TransformersTokenizer'></span>

<h3>Description</h3>

<p>TransformersTokenizer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TransformersTokenizer(tokenizer)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TransformersTokenizer_+3A_tokenizer">tokenizer</code></td>
<td>
<p>tokenizer object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='trunc_normal_'>Trunc_normal_</h2><span id='topic+trunc_normal_'></span>

<h3>Description</h3>

<p>Truncated normal initialization (approximation)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trunc_normal_(x, mean = 0, std = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trunc_normal__+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="trunc_normal__+3A_mean">mean</code></td>
<td>
<p>mean</p>
</td></tr>
<tr><td><code id="trunc_normal__+3A_std">std</code></td>
<td>
<p>standard deviation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>

<hr>
<h2 id='TSBlock'>TSBlock</h2><span id='topic+TSBlock'></span>

<h3>Description</h3>

<p>A TimeSeries Block to process one timeseries
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSBlock(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TSBlock_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TSDataLoaders_from_dfs'>TSDataLoaders_from_dfs</h2><span id='topic+TSDataLoaders_from_dfs'></span>

<h3>Description</h3>

<p>Create a DataLoader from a df_train and df_valid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSDataLoaders_from_dfs(
  df_train,
  df_valid,
  path = ".",
  x_cols = NULL,
  label_col = NULL,
  y_block = NULL,
  item_tfms = NULL,
  batch_tfms = NULL,
  bs = 64,
  val_bs = NULL,
  shuffle_train = TRUE,
  device = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_df_train">df_train</code></td>
<td>
<p>train data</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_df_valid">df_valid</code></td>
<td>
<p>validation data</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_path">path</code></td>
<td>
<p>path (optional)</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_x_cols">x_cols</code></td>
<td>
<p>predictors</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_label_col">label_col</code></td>
<td>
<p>label/output column</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_y_block">y_block</code></td>
<td>
<p>y_block</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_item_tfms">item_tfms</code></td>
<td>
<p>item transformations</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_batch_tfms">batch_tfms</code></td>
<td>
<p>batch transformations</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_bs">bs</code></td>
<td>
<p>batch size</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_val_bs">val_bs</code></td>
<td>
<p>validation batch size</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_shuffle_train">shuffle_train</code></td>
<td>
<p>shuffle train data</p>
</td></tr>
<tr><td><code id="TSDataLoaders_from_dfs_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TSDataTable'>TSDataTable</h2><span id='topic+TSDataTable'></span>

<h3>Description</h3>

<p>A 'DataFrame' wrapper that knows which cols are x/y, and returns rows in '__getitem__'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSDataTable(
  df,
  procs = NULL,
  x_names = NULL,
  y_names = NULL,
  block_y = NULL,
  splits = NULL,
  do_setup = TRUE,
  device = NULL,
  inplace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TSDataTable_+3A_df">df</code></td>
<td>
<p>A DataFrame of your data</p>
</td></tr>
<tr><td><code id="TSDataTable_+3A_procs">procs</code></td>
<td>
<p>list of preprocess functions</p>
</td></tr>
<tr><td><code id="TSDataTable_+3A_x_names">x_names</code></td>
<td>
<p>predictors names</p>
</td></tr>
<tr><td><code id="TSDataTable_+3A_y_names">y_names</code></td>
<td>
<p>the names of the dependent variables</p>
</td></tr>
<tr><td><code id="TSDataTable_+3A_block_y">block_y</code></td>
<td>
<p>the TransformBlock to use for the target</p>
</td></tr>
<tr><td><code id="TSDataTable_+3A_splits">splits</code></td>
<td>
<p>How to split your data</p>
</td></tr>
<tr><td><code id="TSDataTable_+3A_do_setup">do_setup</code></td>
<td>
<p>A parameter for if Tabular will run the data through the procs upon initialization</p>
</td></tr>
<tr><td><code id="TSDataTable_+3A_device">device</code></td>
<td>
<p>device name</p>
</td></tr>
<tr><td><code id="TSDataTable_+3A_inplace">inplace</code></td>
<td>
<p>If True, Tabular will not keep a separate copy of your original DataFrame in memory</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TSeries'>TSeries</h2><span id='topic+TSeries'></span>

<h3>Description</h3>

<p>Basic Time series wrapper
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSeries(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TSeries_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='TSeries_create'>TSeries_create</h2><span id='topic+TSeries_create'></span>

<h3>Description</h3>

<p>TSeries_create
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSeries_create(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TSeries_create_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="TSeries_create_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

res = TSeries_create(as.array(runif(100)))
res %&gt;% show(title = 'R array') %&gt;% plot(dpi = 200)


## End(Not run)


</code></pre>

<hr>
<h2 id='unet_config'>Unet_config</h2><span id='topic+unet_config'></span>

<h3>Description</h3>

<p>Convenience function to easily create a config for 'DynamicUnet'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unet_config(
  blur = FALSE,
  blur_final = TRUE,
  self_attention = FALSE,
  y_range = NULL,
  last_cross = TRUE,
  bottle = FALSE,
  act_cls = nn()$ReLU,
  init = nn()$init$kaiming_normal_,
  norm_type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unet_config_+3A_blur">blur</code></td>
<td>
<p>blur is used to avoid checkerboard artifacts at each layer.</p>
</td></tr>
<tr><td><code id="unet_config_+3A_blur_final">blur_final</code></td>
<td>
<p>blur final is specific to the last layer.</p>
</td></tr>
<tr><td><code id="unet_config_+3A_self_attention">self_attention</code></td>
<td>
<p>self_attention determines if we use a self attention layer at the third block before the end.</p>
</td></tr>
<tr><td><code id="unet_config_+3A_y_range">y_range</code></td>
<td>
<p>If y_range is passed, the last activations go through a sigmoid rescaled to that range.</p>
</td></tr>
<tr><td><code id="unet_config_+3A_last_cross">last_cross</code></td>
<td>
<p>last cros</p>
</td></tr>
<tr><td><code id="unet_config_+3A_bottle">bottle</code></td>
<td>
<p>bottle</p>
</td></tr>
<tr><td><code id="unet_config_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="unet_config_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="unet_config_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='unet_learner'>Unet_learner</h2><span id='topic+unet_learner'></span>

<h3>Description</h3>

<p>Build a unet learner from 'dls' and 'arch'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unet_learner(dls, arch, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unet_learner_+3A_dls">dls</code></td>
<td>
<p>dataloader</p>
</td></tr>
<tr><td><code id="unet_learner_+3A_arch">arch</code></td>
<td>
<p>architecture</p>
</td></tr>
<tr><td><code id="unet_learner_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='UnetBlock'>UnetBlock</h2><span id='topic+UnetBlock'></span>

<h3>Description</h3>

<p>A quasi-UNet block, using 'PixelShuffle_ICNR upsampling'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UnetBlock(
  up_in_c,
  x_in_c,
  hook,
  final_div = TRUE,
  blur = FALSE,
  act_cls = nn()$ReLU,
  self_attention = FALSE,
  init = nn()$init$kaiming_normal_,
  norm_type = NULL,
  ks = 3,
  stride = 1,
  padding = NULL,
  bias = NULL,
  ndim = 2,
  bn_1st = TRUE,
  transpose = FALSE,
  xtra = NULL,
  bias_std = 0.01,
  dilation = 1,
  groups = 1,
  padding_mode = "zeros"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UnetBlock_+3A_up_in_c">up_in_c</code></td>
<td>
<p>up_in_c parameter</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_x_in_c">x_in_c</code></td>
<td>
<p>x_in_c parameter</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_hook">hook</code></td>
<td>
<p>The hook is set to this intermediate layer to store the output needed for this block.</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_final_div">final_div</code></td>
<td>
<p>final div</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_blur">blur</code></td>
<td>
<p>blur is used to avoid checkerboard artifacts at each layer.</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_act_cls">act_cls</code></td>
<td>
<p>activation</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_self_attention">self_attention</code></td>
<td>
<p>self_attention determines if we use a self-attention layer</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_init">init</code></td>
<td>
<p>initializer</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_norm_type">norm_type</code></td>
<td>
<p>normalization type</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_ks">ks</code></td>
<td>
<p>kernel size</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_stride">stride</code></td>
<td>
<p>stride</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_padding">padding</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_bias">bias</code></td>
<td>
<p>bias</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_ndim">ndim</code></td>
<td>
<p>number of dimensions</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_bn_1st">bn_1st</code></td>
<td>
<p>batch normalization 1st</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_transpose">transpose</code></td>
<td>
<p>transpose</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_xtra">xtra</code></td>
<td>
<p>xtra</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_bias_std">bias_std</code></td>
<td>
<p>bias standard deviation</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_dilation">dilation</code></td>
<td>
<p>dilation</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_groups">groups</code></td>
<td>
<p>groups</p>
</td></tr>
<tr><td><code id="UnetBlock_+3A_padding_mode">padding_mode</code></td>
<td>
<p>The mode of padding</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='unfreeze'>Unfreeze a model</h2><span id='topic+unfreeze'></span>

<h3>Description</h3>

<p>Unfreeze a model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unfreeze(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unfreeze_+3A_object">object</code></td>
<td>
<p>A model</p>
</td></tr>
<tr><td><code id="unfreeze_+3A_...">...</code></td>
<td>
<p>Additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
learnR %&gt;% unfreeze()

## End(Not run)
</code></pre>

<hr>
<h2 id='uniform_blur2d'>Uniform_blur2d</h2><span id='topic+uniform_blur2d'></span>

<h3>Description</h3>

<p>Uniformly apply blurring
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniform_blur2d(x, s)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uniform_blur2d_+3A_x">x</code></td>
<td>
<p>image</p>
</td></tr>
<tr><td><code id="uniform_blur2d_+3A_s">s</code></td>
<td>
<p>effect</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='upit'>Upit module</h2><span id='topic+upit'></span>

<h3>Description</h3>

<p>Upit module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>upit()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_ADULT_SAMPLE'>ADULT_SAMPLE dataset</h2><span id='topic+URLs_ADULT_SAMPLE'></span>

<h3>Description</h3>

<p>download ADULT_SAMPLE dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_ADULT_SAMPLE(filename = "ADULT_SAMPLE", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_ADULT_SAMPLE_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_ADULT_SAMPLE_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

URLs_ADULT_SAMPLE()


## End(Not run)

</code></pre>

<hr>
<h2 id='URLs_AG_NEWS'>AG_NEWS dataset</h2><span id='topic+URLs_AG_NEWS'></span>

<h3>Description</h3>

<p>download AG_NEWS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_AG_NEWS(filename = "AG_NEWS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_AG_NEWS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_AG_NEWS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

URLs_AG_NEWS()


## End(Not run)

</code></pre>

<hr>
<h2 id='URLs_AMAZON_REVIEWS_POLARITY'>AMAZON_REVIEWS_POLARITY dataset</h2><span id='topic+URLs_AMAZON_REVIEWS_POLARITY'></span>

<h3>Description</h3>

<p>download AMAZON_REVIEWS_POLARITY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_AMAZON_REVIEWS_POLARITY(
  filename = "AMAZON_REVIEWS_POLARITY",
  untar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_AMAZON_REVIEWS_POLARITY_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_AMAZON_REVIEWS_POLARITY_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_AMAZON_REVIEWSAMAZON_REVIEWS'>AMAZON_REVIEWSAMAZON_REVIEWS dataset</h2><span id='topic+URLs_AMAZON_REVIEWSAMAZON_REVIEWS'></span>

<h3>Description</h3>

<p>download AMAZON_REVIEWSAMAZON_REVIEWS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_AMAZON_REVIEWSAMAZON_REVIEWS(
  filename = "AMAZON_REVIEWSAMAZON_REVIEWS",
  untar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_AMAZON_REVIEWSAMAZON_REVIEWS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_AMAZON_REVIEWSAMAZON_REVIEWS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_BIWI_HEAD_POSE'>BIWI_HEAD_POSE dataset</h2><span id='topic+URLs_BIWI_HEAD_POSE'></span>

<h3>Description</h3>

<p>download BIWI_HEAD_POSE dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_BIWI_HEAD_POSE(filename = "BIWI_HEAD_POSE", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_BIWI_HEAD_POSE_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_BIWI_HEAD_POSE_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_CALTECH_101'>CALTECH_101 dataset</h2><span id='topic+URLs_CALTECH_101'></span>

<h3>Description</h3>

<p>download CALTECH_101 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_CALTECH_101(filename = "CALTECH_101", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_CALTECH_101_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_CALTECH_101_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_CAMVID'>CAMVID dataset</h2><span id='topic+URLs_CAMVID'></span>

<h3>Description</h3>

<p>download CAMVID dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_CAMVID(filename = "CAMVID", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_CAMVID_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_CAMVID_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_CAMVID_TINY'>CAMVID_TINY dataset</h2><span id='topic+URLs_CAMVID_TINY'></span>

<h3>Description</h3>

<p>download CAMVID_TINY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_CAMVID_TINY(filename = "CAMVID_TINY", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_CAMVID_TINY_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_CAMVID_TINY_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_CARS'>CARS dataset</h2><span id='topic+URLs_CARS'></span>

<h3>Description</h3>

<p>download CARS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_CARS(filename = "CARS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_CARS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_CARS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_CIFAR'>CIFAR dataset</h2><span id='topic+URLs_CIFAR'></span>

<h3>Description</h3>

<p>download CIFAR dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_CIFAR(filename = "CIFAR", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_CIFAR_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_CIFAR_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_CIFAR_100'>CIFAR_100 dataset</h2><span id='topic+URLs_CIFAR_100'></span>

<h3>Description</h3>

<p>download CIFAR_100 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_CIFAR_100(filename = "CIFAR_100", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_CIFAR_100_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_CIFAR_100_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_COCO_TINY'>COCO_TINY dataset</h2><span id='topic+URLs_COCO_TINY'></span>

<h3>Description</h3>

<p>download COCO_TINY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_COCO_TINY(filename = "COCO_TINY", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_COCO_TINY_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_COCO_TINY_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_CUB_200_2011'>CUB_200_2011 dataset</h2><span id='topic+URLs_CUB_200_2011'></span>

<h3>Description</h3>

<p>download CUB_200_2011 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_CUB_200_2011(filename = "CUB_200_2011", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_CUB_200_2011_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_CUB_200_2011_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_DBPEDIA'>DBPEDIA dataset</h2><span id='topic+URLs_DBPEDIA'></span>

<h3>Description</h3>

<p>download DBPEDIA dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_DBPEDIA(filename = "DBPEDIA", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_DBPEDIA_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_DBPEDIA_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_DOGS'>DOGS dataset</h2><span id='topic+URLs_DOGS'></span>

<h3>Description</h3>

<p>download DOGS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_DOGS(filename = "DOGS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_DOGS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_DOGS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_FLOWERS'>FLOWERS dataset</h2><span id='topic+URLs_FLOWERS'></span>

<h3>Description</h3>

<p>download FLOWERS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_FLOWERS(filename = "FLOWERS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_FLOWERS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_FLOWERS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_FOOD'>FOOD dataset</h2><span id='topic+URLs_FOOD'></span>

<h3>Description</h3>

<p>download FOOD dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_FOOD(filename = "FOOD", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_FOOD_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_FOOD_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_HORSE_2_ZEBRA'>HORSE_2_ZEBRA dataset</h2><span id='topic+URLs_HORSE_2_ZEBRA'></span>

<h3>Description</h3>

<p>download HORSE_2_ZEBRA dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_HORSE_2_ZEBRA(filename = "horse2zebra", unzip = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_HORSE_2_ZEBRA_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_HORSE_2_ZEBRA_+3A_unzip">unzip</code></td>
<td>
<p>logical, whether to unzip the '.zip' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_HUMAN_NUMBERS'>HUMAN_NUMBERS dataset</h2><span id='topic+URLs_HUMAN_NUMBERS'></span>

<h3>Description</h3>

<p>download HUMAN_NUMBERS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_HUMAN_NUMBERS(filename = "HUMAN_NUMBERS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_HUMAN_NUMBERS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_HUMAN_NUMBERS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_IMAGENETTE'>IMAGENETTE dataset</h2><span id='topic+URLs_IMAGENETTE'></span>

<h3>Description</h3>

<p>download IMAGENETTE dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_IMAGENETTE(filename = "IMAGENETTE", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_IMAGENETTE_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_IMAGENETTE_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_IMAGENETTE_160'>IMAGENETTE_160 dataset</h2><span id='topic+URLs_IMAGENETTE_160'></span>

<h3>Description</h3>

<p>download IMAGENETTE_160 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_IMAGENETTE_160(filename = "IMAGENETTE_160", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_IMAGENETTE_160_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_IMAGENETTE_160_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_IMAGENETTE_320'>IMAGENETTE_320 dataset</h2><span id='topic+URLs_IMAGENETTE_320'></span>

<h3>Description</h3>

<p>download IMAGENETTE_320 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_IMAGENETTE_320(filename = "IMAGENETTE_320", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_IMAGENETTE_320_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_IMAGENETTE_320_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_IMAGEWOOF'>IMAGEWOOF dataset</h2><span id='topic+URLs_IMAGEWOOF'></span>

<h3>Description</h3>

<p>download IMAGEWOOF dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_IMAGEWOOF(filename = "IMAGEWOOF", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_IMAGEWOOF_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_IMAGEWOOF_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_IMAGEWOOF_160'>IMAGEWOOF_160 dataset</h2><span id='topic+URLs_IMAGEWOOF_160'></span>

<h3>Description</h3>

<p>download IMAGEWOOF_160 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_IMAGEWOOF_160(filename = "IMAGEWOOF_160", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_IMAGEWOOF_160_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_IMAGEWOOF_160_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_IMAGEWOOF_320'>IMAGEWOOF_320 dataset</h2><span id='topic+URLs_IMAGEWOOF_320'></span>

<h3>Description</h3>

<p>download IMAGEWOOF_320 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_IMAGEWOOF_320(filename = "IMAGEWOOF_320", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_IMAGEWOOF_320_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_IMAGEWOOF_320_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_IMDB'>IMDB dataset</h2><span id='topic+URLs_IMDB'></span>

<h3>Description</h3>

<p>download IMDB dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_IMDB(filename = "IMDB", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_IMDB_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_IMDB_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_IMDB_SAMPLE'>IMDB_SAMPLE dataset</h2><span id='topic+URLs_IMDB_SAMPLE'></span>

<h3>Description</h3>

<p>download IMDB_SAMPLE dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_IMDB_SAMPLE(filename = "IMDB_SAMPLE", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_IMDB_SAMPLE_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_IMDB_SAMPLE_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_LSUN_BEDROOMS'>LSUN_BEDROOMS dataset</h2><span id='topic+URLs_LSUN_BEDROOMS'></span>

<h3>Description</h3>

<p>download LSUN_BEDROOMS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_LSUN_BEDROOMS(filename = "LSUN_BEDROOMS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_LSUN_BEDROOMS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_LSUN_BEDROOMS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_ML_SAMPLE'>ML_SAMPLE dataset</h2><span id='topic+URLs_ML_SAMPLE'></span>

<h3>Description</h3>

<p>download ML_SAMPLE dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_ML_SAMPLE(filename = "ML_SAMPLE", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_ML_SAMPLE_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_ML_SAMPLE_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_MNIST'>MNIST dataset</h2><span id='topic+URLs_MNIST'></span>

<h3>Description</h3>

<p>download MNIST dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_MNIST(filename = "MNIST", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_MNIST_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_MNIST_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_MNIST_SAMPLE'>MNIST_SAMPLE dataset</h2><span id='topic+URLs_MNIST_SAMPLE'></span>

<h3>Description</h3>

<p>download MNIST_SAMPLE dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_MNIST_SAMPLE(filename = "MNIST_SAMPLE", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_MNIST_SAMPLE_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_MNIST_SAMPLE_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_MNIST_TINY'>MNIST_TINY dataset</h2><span id='topic+URLs_MNIST_TINY'></span>

<h3>Description</h3>

<p>download MNIST_TINY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_MNIST_TINY(filename = "MNIST_TINY", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_MNIST_TINY_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_MNIST_TINY_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_MNIST_VAR_SIZE_TINY'>MNIST_VAR_SIZE_TINY dataset</h2><span id='topic+URLs_MNIST_VAR_SIZE_TINY'></span>

<h3>Description</h3>

<p>download MNIST_VAR_SIZE_TINY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_MNIST_VAR_SIZE_TINY(filename = "MNIST_VAR_SIZE_TINY", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_MNIST_VAR_SIZE_TINY_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_MNIST_VAR_SIZE_TINY_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_MOVIE_LENS_ML_100k'>MOVIE_LENS_ML_100k dataset</h2><span id='topic+URLs_MOVIE_LENS_ML_100k'></span>

<h3>Description</h3>

<p>download MOVIE_LENS_ML_100k dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_MOVIE_LENS_ML_100k(filename = "ml-100k", unzip = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_MOVIE_LENS_ML_100k_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_MOVIE_LENS_ML_100k_+3A_unzip">unzip</code></td>
<td>
<p>logical, whether to unzip the '.zip' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_MT_ENG_FRA'>MT_ENG_FRA dataset</h2><span id='topic+URLs_MT_ENG_FRA'></span>

<h3>Description</h3>

<p>download MT_ENG_FRA dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_MT_ENG_FRA(filename = "MT_ENG_FRA", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_MT_ENG_FRA_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_MT_ENG_FRA_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_OPENAI_TRANSFORMER'>OPENAI_TRANSFORMER dataset</h2><span id='topic+URLs_OPENAI_TRANSFORMER'></span>

<h3>Description</h3>

<p>download OPENAI_TRANSFORMER dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_OPENAI_TRANSFORMER(filename = "OPENAI_TRANSFORMER", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_OPENAI_TRANSFORMER_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_OPENAI_TRANSFORMER_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_PASCAL_2007'>PASCAL_2007 dataset</h2><span id='topic+URLs_PASCAL_2007'></span>

<h3>Description</h3>

<p>download PASCAL_2007 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_PASCAL_2007(filename = "PASCAL_2007", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_PASCAL_2007_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_PASCAL_2007_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_PASCAL_2012'>PASCAL_2012 dataset</h2><span id='topic+URLs_PASCAL_2012'></span>

<h3>Description</h3>

<p>download PASCAL_2012 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_PASCAL_2012(filename = "PASCAL_2012", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_PASCAL_2012_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_PASCAL_2012_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_PETS'>PETS dataset</h2><span id='topic+URLs_PETS'></span>

<h3>Description</h3>

<p>download PETS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_PETS(filename = "PETS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_PETS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_PETS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_PLANET_SAMPLE'>PLANET_SAMPLE dataset</h2><span id='topic+URLs_PLANET_SAMPLE'></span>

<h3>Description</h3>

<p>download PLANET_SAMPLE dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_PLANET_SAMPLE(filename = "PLANET_SAMPLE", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_PLANET_SAMPLE_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_PLANET_SAMPLE_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_PLANET_TINY'>PLANET_TINY dataset</h2><span id='topic+URLs_PLANET_TINY'></span>

<h3>Description</h3>

<p>download PLANET_TINY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_PLANET_TINY(filename = "PLANET_TINY", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_PLANET_TINY_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_PLANET_TINY_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_S3_COCO'>S3_COCO dataset</h2><span id='topic+URLs_S3_COCO'></span>

<h3>Description</h3>

<p>download S3_COCO dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_S3_COCO(filename = "S3_COCO", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_S3_COCO_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_S3_COCO_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_S3_IMAGE'>S3_IMAGE dataset</h2><span id='topic+URLs_S3_IMAGE'></span>

<h3>Description</h3>

<p>download S3_IMAGE dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_S3_IMAGE(filename = "S3_IMAGE", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_S3_IMAGE_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_S3_IMAGE_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_S3_IMAGELOC'>S3_IMAGELOC dataset</h2><span id='topic+URLs_S3_IMAGELOC'></span>

<h3>Description</h3>

<p>download S3_IMAGELOC dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_S3_IMAGELOC(filename = "S3_IMAGELOC", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_S3_IMAGELOC_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_S3_IMAGELOC_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_S3_MODEL'>S3_MODEL dataset</h2><span id='topic+URLs_S3_MODEL'></span>

<h3>Description</h3>

<p>download S3_MODEL dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_S3_MODEL(filename = "S3_MODEL", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_S3_MODEL_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_S3_MODEL_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_S3_NLP'>S3_NLP dataset</h2><span id='topic+URLs_S3_NLP'></span>

<h3>Description</h3>

<p>download S3_NLP dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_S3_NLP(filename = "S3_NLP", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_S3_NLP_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_S3_NLP_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_SIIM_SMALL'>SIIM_SMALL</h2><span id='topic+URLs_SIIM_SMALL'></span>

<h3>Description</h3>

<p>download YELP_REVIEWS_POLARITY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_SIIM_SMALL(filename = "SIIM_SMALL", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_SIIM_SMALL_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_SIIM_SMALL_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_SKIN_LESION'>SKIN_LESION dataset</h2><span id='topic+URLs_SKIN_LESION'></span>

<h3>Description</h3>

<p>download SKIN_LESION dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_SKIN_LESION(filename = "SKIN_LESION", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_SKIN_LESION_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_SKIN_LESION_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_SOGOU_NEWS'>SOGOU_NEWS dataset</h2><span id='topic+URLs_SOGOU_NEWS'></span>

<h3>Description</h3>

<p>download SOGOU_NEWS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_SOGOU_NEWS(filename = "SOGOU_NEWS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_SOGOU_NEWS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_SOGOU_NEWS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_SPEAKERS10'>SPEAKERS10 dataset</h2><span id='topic+URLs_SPEAKERS10'></span>

<h3>Description</h3>

<p>download SPEAKERS10 dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_SPEAKERS10(filename = "SPEAKERS10", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_SPEAKERS10_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_SPEAKERS10_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

URLs_SPEAKERS10()


## End(Not run)

</code></pre>

<hr>
<h2 id='URLs_SPEECHCOMMANDS'>SPEECHCOMMANDS dataset</h2><span id='topic+URLs_SPEECHCOMMANDS'></span>

<h3>Description</h3>

<p>download SPEECHCOMMANDS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_SPEECHCOMMANDS(filename = "SPEECHCOMMANDS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_SPEECHCOMMANDS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_SPEECHCOMMANDS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

URLs_SPEECHCOMMANDS()


## End(Not run)

</code></pre>

<hr>
<h2 id='URLs_WIKITEXT'>WIKITEXT dataset</h2><span id='topic+URLs_WIKITEXT'></span>

<h3>Description</h3>

<p>download WIKITEXT dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_WIKITEXT(filename = "WIKITEXT", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_WIKITEXT_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_WIKITEXT_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_WIKITEXT_TINY'>WIKITEXT_TINY dataset</h2><span id='topic+URLs_WIKITEXT_TINY'></span>

<h3>Description</h3>

<p>download WIKITEXT_TINY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_WIKITEXT_TINY(filename = "WIKITEXT_TINY", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_WIKITEXT_TINY_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_WIKITEXT_TINY_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_WT103_BWD'>WT103_BWD dataset</h2><span id='topic+URLs_WT103_BWD'></span>

<h3>Description</h3>

<p>download WT103_BWD dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_WT103_BWD(filename = "WT103_BWD", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_WT103_BWD_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_WT103_BWD_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_WT103_FWD'>WT103_FWD dataset</h2><span id='topic+URLs_WT103_FWD'></span>

<h3>Description</h3>

<p>download WT103_FWD dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_WT103_FWD(filename = "WT103_FWD", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_WT103_FWD_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_WT103_FWD_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_YAHOO_ANSWERS'>YAHOO_ANSWERS dataset</h2><span id='topic+URLs_YAHOO_ANSWERS'></span>

<h3>Description</h3>

<p>download YAHOO_ANSWERS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_YAHOO_ANSWERS(filename = "YAHOO_ANSWERS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_YAHOO_ANSWERS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_YAHOO_ANSWERS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_YELP_REVIEWS'>YELP_REVIEWS dataset</h2><span id='topic+URLs_YELP_REVIEWS'></span>

<h3>Description</h3>

<p>download YELP_REVIEWS dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_YELP_REVIEWS(filename = "YELP_REVIEWS", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_YELP_REVIEWS_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_YELP_REVIEWS_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='URLs_YELP_REVIEWS_POLARITY'>YELP_REVIEWS_POLARITY dataset</h2><span id='topic+URLs_YELP_REVIEWS_POLARITY'></span>

<h3>Description</h3>

<p>download YELP_REVIEWS_POLARITY dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>URLs_YELP_REVIEWS_POLARITY(filename = "YELP_REVIEWS_POLARITY", untar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="URLs_YELP_REVIEWS_POLARITY_+3A_filename">filename</code></td>
<td>
<p>the name of the file</p>
</td></tr>
<tr><td><code id="URLs_YELP_REVIEWS_POLARITY_+3A_untar">untar</code></td>
<td>
<p>logical, whether to untar the '.tgz' file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='vgg11_bn'>Vgg11_bn</h2><span id='topic+vgg11_bn'></span>

<h3>Description</h3>

<p>VGG 11-layer model (configuration &quot;A&quot;) with batch normalization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vgg11_bn(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vgg11_bn_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="vgg11_bn_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Very Deep Convolutional Networks For Large-Scale Image Recognition&quot; &lt;https://arxiv.org/pdf/1409.1556.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='vgg13_bn'>Vgg13_bn</h2><span id='topic+vgg13_bn'></span>

<h3>Description</h3>

<p>VGG 13-layer model (configuration &quot;B&quot;) with batch normalization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vgg13_bn(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vgg13_bn_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="vgg13_bn_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Very Deep Convolutional Networks For Large-Scale Image Recognition&quot; &lt;https://arxiv.org/pdf/1409.1556.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='vgg16_bn'>Vgg16_bn</h2><span id='topic+vgg16_bn'></span>

<h3>Description</h3>

<p>VGG 16-layer model (configuration &quot;D&quot;) with batch normalization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vgg16_bn(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vgg16_bn_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="vgg16_bn_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Very Deep Convolutional Networks For Large-Scale Image Recognition&quot; &lt;https://arxiv.org/pdf/1409.1556.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='vgg19_bn'>Vgg19_bn</h2><span id='topic+vgg19_bn'></span>

<h3>Description</h3>

<p>VGG 19-layer model (configuration 'E') with batch normalization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vgg19_bn(pretrained = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vgg19_bn_+3A_pretrained">pretrained</code></td>
<td>
<p>pretrained or not</p>
</td></tr>
<tr><td><code id="vgg19_bn_+3A_progress">progress</code></td>
<td>
<p>to see progress bar or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Very Deep Convolutional Networks For Large-Scale Image Recognition&quot; &lt;https://arxiv.org/pdf/1409.1556.pdf&gt;
</p>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='vision'>Vision module</h2><span id='topic+vision'></span>

<h3>Description</h3>

<p>Vision module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vision()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='vleaky_relu'>Vleaky_relu</h2><span id='topic+vleaky_relu'></span>

<h3>Description</h3>

<p>'F$leaky_relu' with 0.3 slope
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vleaky_relu(input, inplace = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vleaky_relu_+3A_input">input</code></td>
<td>
<p>inputs</p>
</td></tr>
<tr><td><code id="vleaky_relu_+3A_inplace">inplace</code></td>
<td>
<p>inplace or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Voice'>Voice</h2><span id='topic+Voice'></span>

<h3>Description</h3>

<p>Voice
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Voice(
  sample_rate = 16000,
  n_fft = 1024,
  win_length = NULL,
  hop_length = 128,
  f_min = 50,
  f_max = 8000,
  pad = 0,
  n_mels = 128,
  window_fn = torch()$hann_window,
  power = 2,
  normalized = FALSE,
  wkwargs = NULL,
  mel = TRUE,
  to_db = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Voice_+3A_sample_rate">sample_rate</code></td>
<td>
<p>sample rate</p>
</td></tr>
<tr><td><code id="Voice_+3A_n_fft">n_fft</code></td>
<td>
<p>number of fast fourier transforms</p>
</td></tr>
<tr><td><code id="Voice_+3A_win_length">win_length</code></td>
<td>
<p>windowing length</p>
</td></tr>
<tr><td><code id="Voice_+3A_hop_length">hop_length</code></td>
<td>
<p>hopping length</p>
</td></tr>
<tr><td><code id="Voice_+3A_f_min">f_min</code></td>
<td>
<p>minimum frequency</p>
</td></tr>
<tr><td><code id="Voice_+3A_f_max">f_max</code></td>
<td>
<p>maximum frequency</p>
</td></tr>
<tr><td><code id="Voice_+3A_pad">pad</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="Voice_+3A_n_mels">n_mels</code></td>
<td>
<p>number of mel-spectrograms</p>
</td></tr>
<tr><td><code id="Voice_+3A_window_fn">window_fn</code></td>
<td>
<p>window function</p>
</td></tr>
<tr><td><code id="Voice_+3A_power">power</code></td>
<td>
<p>power</p>
</td></tr>
<tr><td><code id="Voice_+3A_normalized">normalized</code></td>
<td>
<p>normalized or not</p>
</td></tr>
<tr><td><code id="Voice_+3A_wkwargs">wkwargs</code></td>
<td>
<p>additional arguments</p>
</td></tr>
<tr><td><code id="Voice_+3A_mel">mel</code></td>
<td>
<p>mel-spectrogram or not</p>
</td></tr>
<tr><td><code id="Voice_+3A_to_db">to_db</code></td>
<td>
<p>to decibels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='wandb'>Wandb module</h2><span id='topic+wandb'></span>

<h3>Description</h3>

<p>Wandb module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wandb()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='WandbCallback'>WandbCallback</h2><span id='topic+WandbCallback'></span>

<h3>Description</h3>

<p>Saves model topology, losses &amp; metrics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WandbCallback(
  log = "gradients",
  log_preds = TRUE,
  log_model = TRUE,
  log_dataset = FALSE,
  dataset_name = NULL,
  valid_dl = NULL,
  n_preds = 36,
  seed = 12345,
  reorder = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WandbCallback_+3A_log">log</code></td>
<td>
<p>&quot;gradients&quot; (default), &quot;parameters&quot;, &quot;all&quot; or None. Losses &amp; metrics are always logged.</p>
</td></tr>
<tr><td><code id="WandbCallback_+3A_log_preds">log_preds</code></td>
<td>
<p>whether we want to log prediction samples (default to True).</p>
</td></tr>
<tr><td><code id="WandbCallback_+3A_log_model">log_model</code></td>
<td>
<p>whether we want to log our model (default to True). This also requires SaveModelCallback.</p>
</td></tr>
<tr><td><code id="WandbCallback_+3A_log_dataset">log_dataset</code></td>
<td>
<p>Options:
- False (default)
- True will log folder referenced by learn.dls.path.
- a path can be defined explicitly to reference which folder to log.
Note: subfolder &quot;models&quot; is always ignored.</p>
</td></tr>
<tr><td><code id="WandbCallback_+3A_dataset_name">dataset_name</code></td>
<td>
<p>name of logged dataset (default to folder name).</p>
</td></tr>
<tr><td><code id="WandbCallback_+3A_valid_dl">valid_dl</code></td>
<td>
<p>DataLoaders containing items used for prediction samples (default to random items from learn.dls.valid.</p>
</td></tr>
<tr><td><code id="WandbCallback_+3A_n_preds">n_preds</code></td>
<td>
<p>number of logged predictions (default to 36).</p>
</td></tr>
<tr><td><code id="WandbCallback_+3A_seed">seed</code></td>
<td>
<p>used for defining random samples.</p>
</td></tr>
<tr><td><code id="WandbCallback_+3A_reorder">reorder</code></td>
<td>
<p>reorder or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='Warp'>Warp</h2><span id='topic+Warp'></span>

<h3>Description</h3>

<p>Apply perspective warping with 'magnitude' and 'p' on a batch of matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Warp(
  magnitude = 0.2,
  p = 0.5,
  draw_x = NULL,
  draw_y = NULL,
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  batch = FALSE,
  align_corners = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Warp_+3A_magnitude">magnitude</code></td>
<td>
<p>magnitude</p>
</td></tr>
<tr><td><code id="Warp_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="Warp_+3A_draw_x">draw_x</code></td>
<td>
<p>draw x</p>
</td></tr>
<tr><td><code id="Warp_+3A_draw_y">draw_y</code></td>
<td>
<p>draw y</p>
</td></tr>
<tr><td><code id="Warp_+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="Warp_+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="Warp_+3A_pad_mode">pad_mode</code></td>
<td>
<p>padding mode</p>
</td></tr>
<tr><td><code id="Warp_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
<tr><td><code id="Warp_+3A_align_corners">align_corners</code></td>
<td>
<p>align corners</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='waterfall_plot'>Waterfall_plot</h2><span id='topic+waterfall_plot'></span>

<h3>Description</h3>

<p>Plots an explanation of a single prediction as a waterfall plot. Accepts a row_index and class_id.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>waterfall_plot(object, row_idx = NULL, class_id = 0, dpi = 200, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="waterfall_plot_+3A_object">object</code></td>
<td>
<p>ShapInterpretation object</p>
</td></tr>
<tr><td><code id="waterfall_plot_+3A_row_idx">row_idx</code></td>
<td>
<p>is the index of the row chosen in test_data to be analyzed, which defaults to zero.</p>
</td></tr>
<tr><td><code id="waterfall_plot_+3A_class_id">class_id</code></td>
<td>
<p>Accepts a class_id which is used to indicate the class of interest for a
classification model. It can either be an int or str representation for a class of choice.</p>
</td></tr>
<tr><td><code id="waterfall_plot_+3A_dpi">dpi</code></td>
<td>
<p>dots per inch</p>
</td></tr>
<tr><td><code id="waterfall_plot_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='weight_decay'>Weight_decay</h2><span id='topic+weight_decay'></span>

<h3>Description</h3>

<p>Weight decay as decaying 'p' with 'lr*wd'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weight_decay(p, lr, wd, do_wd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weight_decay_+3A_p">p</code></td>
<td>
<p>p</p>
</td></tr>
<tr><td><code id="weight_decay_+3A_lr">lr</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="weight_decay_+3A_wd">wd</code></td>
<td>
<p>weight decay</p>
</td></tr>
<tr><td><code id="weight_decay_+3A_do_wd">do_wd</code></td>
<td>
<p>do_wd</p>
</td></tr>
<tr><td><code id="weight_decay_+3A_...">...</code></td>
<td>
<p>additional args to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

tst_param = function(val, grad = NULL) {
  "Create a tensor with `val` and a gradient of `grad` for testing"
  res = tensor(val) %&gt;% float()

  if(is.null(grad)) {
    grad = tensor(val / 10)
  } else {
    grad = tensor(grad)
  }

  res$grad = grad %&gt;% float()
  res
}
p = tst_param(1., 0.1)
weight_decay(p, 1., 0.1)


## End(Not run)

</code></pre>

<hr>
<h2 id='WeightDropout'>WeightDropout</h2><span id='topic+WeightDropout'></span>

<h3>Description</h3>

<p>A module that wraps another layer in which some weights will be replaced by 0 during training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WeightDropout(module, weight_p, layer_names = "weight_hh_l0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WeightDropout_+3A_module">module</code></td>
<td>
<p>module</p>
</td></tr>
<tr><td><code id="WeightDropout_+3A_weight_p">weight_p</code></td>
<td>
<p>weight_p</p>
</td></tr>
<tr><td><code id="WeightDropout_+3A_layer_names">layer_names</code></td>
<td>
<p>layer_names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='WeightedDL'>WeightedDL</h2><span id='topic+WeightedDL'></span>

<h3>Description</h3>

<p>Transformed 'DataLoader'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WeightedDL(
  dataset = NULL,
  bs = NULL,
  wgts = NULL,
  shuffle = FALSE,
  num_workers = NULL,
  verbose = FALSE,
  do_setup = TRUE,
  pin_memory = FALSE,
  timeout = 0,
  batch_size = NULL,
  drop_last = FALSE,
  indexed = NULL,
  n = NULL,
  device = NULL,
  persistent_workers = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WeightedDL_+3A_dataset">dataset</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_bs">bs</code></td>
<td>
<p>bs</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_wgts">wgts</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_num_workers">num_workers</code></td>
<td>
<p>number of workers</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_verbose">verbose</code></td>
<td>
<p>verbose</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_do_setup">do_setup</code></td>
<td>
<p>do_setup</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_pin_memory">pin_memory</code></td>
<td>
<p>pin_memory</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_timeout">timeout</code></td>
<td>
<p>timeout</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_batch_size">batch_size</code></td>
<td>
<p>batch_size</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_drop_last">drop_last</code></td>
<td>
<p>drop_last</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_indexed">indexed</code></td>
<td>
<p>indexed</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_n">n</code></td>
<td>
<p>n</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_device">device</code></td>
<td>
<p>device</p>
</td></tr>
<tr><td><code id="WeightedDL_+3A_persistent_workers">persistent_workers</code></td>
<td>
<p>persistent_workers</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='win_abdoment_soft'>Abdomen soft</h2><span id='topic+win_abdoment_soft'></span>

<h3>Description</h3>

<p>Abdomen soft
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_abdoment_soft()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_brain'>Brain</h2><span id='topic+win_brain'></span>

<h3>Description</h3>

<p>Brain
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_brain()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_brain_bone'>Brain bone</h2><span id='topic+win_brain_bone'></span>

<h3>Description</h3>

<p>Brain bone
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_brain_bone()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_brain_soft'>Brain soft</h2><span id='topic+win_brain_soft'></span>

<h3>Description</h3>

<p>Brain soft
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_brain_soft()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_liver'>Liver</h2><span id='topic+win_liver'></span>

<h3>Description</h3>

<p>Liver
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_liver()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_lungs'>Lungs</h2><span id='topic+win_lungs'></span>

<h3>Description</h3>

<p>Lungs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_lungs()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_mediastinum'>Mediastinum</h2><span id='topic+win_mediastinum'></span>

<h3>Description</h3>

<p>Mediastinum
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_mediastinum()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_spine_bone'>Spine bone</h2><span id='topic+win_spine_bone'></span>

<h3>Description</h3>

<p>Spine bone
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_spine_bone()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_spine_soft'>Spine soft</h2><span id='topic+win_spine_soft'></span>

<h3>Description</h3>

<p>Spine soft
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_spine_soft()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_stroke'>Stroke</h2><span id='topic+win_stroke'></span>

<h3>Description</h3>

<p>Stroke
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_stroke()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='win_subdural'>Subdural</h2><span id='topic+win_subdural'></span>

<h3>Description</h3>

<p>Subdural
</p>


<h3>Usage</h3>

<pre><code class='language-R'>win_subdural()
</code></pre>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='xla'>XLA</h2><span id='topic+xla'></span>

<h3>Description</h3>

<p>XLA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xla()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='XResNet'>XResNet</h2><span id='topic+XResNet'></span>

<h3>Description</h3>

<p>A sequential container.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XResNet(block, expansion, layers, c_in = 3, c_out = 1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="XResNet_+3A_block">block</code></td>
<td>
<p>the blocks to pass to XResNet</p>
</td></tr>
<tr><td><code id="XResNet_+3A_expansion">expansion</code></td>
<td>
<p>argument for inputs and filters</p>
</td></tr>
<tr><td><code id="XResNet_+3A_layers">layers</code></td>
<td>
<p>the layers to pass to XResNet</p>
</td></tr>
<tr><td><code id="XResNet_+3A_c_in">c_in</code></td>
<td>
<p>number of inputs</p>
</td></tr>
<tr><td><code id="XResNet_+3A_c_out">c_out</code></td>
<td>
<p>number of outputs</p>
</td></tr>
<tr><td><code id="XResNet_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>

<hr>
<h2 id='xresnet101'>Xresnet101</h2><span id='topic+xresnet101'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet101(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet101_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet152'>Xresnet152</h2><span id='topic+xresnet152'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet152(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet152_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet18'>Xresnet18</h2><span id='topic+xresnet18'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet18(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet18_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet18_deep'>Xresnet18_deep</h2><span id='topic+xresnet18_deep'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet18_deep(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet18_deep_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet18_deeper'>Xresnet18_deeper</h2><span id='topic+xresnet18_deeper'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet18_deeper(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet18_deeper_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet34'>Xresnet34</h2><span id='topic+xresnet34'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet34(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet34_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet34_deep'>Xresnet34_deep</h2><span id='topic+xresnet34_deep'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet34_deep(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet34_deep_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet34_deeper'>Xresnet34_deeper</h2><span id='topic+xresnet34_deeper'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet34_deeper(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet34_deeper_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet50'>Xresnet50</h2><span id='topic+xresnet50'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet50(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet50_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet50_deep'>Xresnet50_deep</h2><span id='topic+xresnet50_deep'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet50_deep(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet50_deep_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnet50_deeper'>Xresnet50_deeper</h2><span id='topic+xresnet50_deeper'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnet50_deeper(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnet50_deeper_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnext101'>xresnext101</h2><span id='topic+xresnext101'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnext101(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnext101_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnext18'>xresnext18</h2><span id='topic+xresnext18'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnext18(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnext18_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnext34'>xresnext34</h2><span id='topic+xresnext34'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnext34(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnext34_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xresnext50'>xresnext50</h2><span id='topic+xresnext50'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xresnext50(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xresnext50_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnet101'>xse_resnet101</h2><span id='topic+xse_resnet101'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnet101(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnet101_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnet152'>xse_resnet152</h2><span id='topic+xse_resnet152'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnet152(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnet152_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnet18'>xse_resnet18</h2><span id='topic+xse_resnet18'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnet18(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnet18_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnet34'>xse_resnet34</h2><span id='topic+xse_resnet34'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnet34(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnet34_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnet50'>xse_resnet50</h2><span id='topic+xse_resnet50'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnet50(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnet50_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext101'>xse_resnext101</h2><span id='topic+xse_resnext101'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext101(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext101_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext18'>xse_resnext18</h2><span id='topic+xse_resnext18'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext18(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext18_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext18_deep'>xse_resnext18_deep</h2><span id='topic+xse_resnext18_deep'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext18_deep(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext18_deep_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext18_deeper'>xse_resnext18_deeper</h2><span id='topic+xse_resnext18_deeper'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext18_deeper(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext18_deeper_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext34'>xse_resnext34</h2><span id='topic+xse_resnext34'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext34(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext34_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext34_deep'>xse_resnext34_deep</h2><span id='topic+xse_resnext34_deep'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext34_deep(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext34_deep_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext34_deeper'>xse_resnext34_deeper</h2><span id='topic+xse_resnext34_deeper'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext34_deeper(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext34_deeper_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext50'>xse_resnext50</h2><span id='topic+xse_resnext50'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext50(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext50_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext50_deep'>xse_resnext50_deep</h2><span id='topic+xse_resnext50_deep'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext50_deep(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext50_deep_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xse_resnext50_deeper'>xse_resnext50_deeper</h2><span id='topic+xse_resnext50_deeper'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xse_resnext50_deeper(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xse_resnext50_deeper_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='xsenet154'>xsenet154</h2><span id='topic+xsenet154'></span>

<h3>Description</h3>

<p>Load model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xsenet154(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xsenet154_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model
</p>

<hr>
<h2 id='zoom'>Zoom</h2><span id='topic+zoom'></span>

<h3>Description</h3>

<p>Zoom
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zoom(img, ratio)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zoom_+3A_img">img</code></td>
<td>
<p>image files</p>
</td></tr>
<tr><td><code id="zoom_+3A_ratio">ratio</code></td>
<td>
<p>ratio</p>
</td></tr>
</table>


<h3>Value</h3>

<p>image
</p>

<hr>
<h2 id='Zoom_'>Zoom</h2><span id='topic+Zoom_'></span>

<h3>Description</h3>

<p>Apply a random zoom of at most 'max_zoom' with probability 'p' to a batch of images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Zoom_(
  min_zoom = 1,
  max_zoom = 1.1,
  p = 0.5,
  draw = NULL,
  draw_x = NULL,
  draw_y = NULL,
  size = NULL,
  mode = "bilinear",
  pad_mode = "reflection",
  batch = FALSE,
  align_corners = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zoom__+3A_min_zoom">min_zoom</code></td>
<td>
<p>minimum zoom</p>
</td></tr>
<tr><td><code id="Zoom__+3A_max_zoom">max_zoom</code></td>
<td>
<p>maximum zoom</p>
</td></tr>
<tr><td><code id="Zoom__+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="Zoom__+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="Zoom__+3A_draw_x">draw_x</code></td>
<td>
<p>draw x</p>
</td></tr>
<tr><td><code id="Zoom__+3A_draw_y">draw_y</code></td>
<td>
<p>draw y</p>
</td></tr>
<tr><td><code id="Zoom__+3A_size">size</code></td>
<td>
<p>size</p>
</td></tr>
<tr><td><code id="Zoom__+3A_mode">mode</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="Zoom__+3A_pad_mode">pad_mode</code></td>
<td>
<p>pad mode</p>
</td></tr>
<tr><td><code id="Zoom__+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
<tr><td><code id="Zoom__+3A_align_corners">align_corners</code></td>
<td>
<p>align  corners or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='zoom_mat'>Zoom_mat</h2><span id='topic+zoom_mat'></span>

<h3>Description</h3>

<p>Return a random zoom matrix with 'max_zoom' and 'p'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zoom_mat(
  x,
  min_zoom = 1,
  max_zoom = 1.1,
  p = 0.5,
  draw = NULL,
  draw_x = NULL,
  draw_y = NULL,
  batch = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zoom_mat_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="zoom_mat_+3A_min_zoom">min_zoom</code></td>
<td>
<p>minimum zoom</p>
</td></tr>
<tr><td><code id="zoom_mat_+3A_max_zoom">max_zoom</code></td>
<td>
<p>maximum zoom</p>
</td></tr>
<tr><td><code id="zoom_mat_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
<tr><td><code id="zoom_mat_+3A_draw">draw</code></td>
<td>
<p>draw</p>
</td></tr>
<tr><td><code id="zoom_mat_+3A_draw_x">draw_x</code></td>
<td>
<p>draw x</p>
</td></tr>
<tr><td><code id="zoom_mat_+3A_draw_y">draw_y</code></td>
<td>
<p>draw y</p>
</td></tr>
<tr><td><code id="zoom_mat_+3A_batch">batch</code></td>
<td>
<p>batch</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
