<!DOCTYPE html><html><head><title>Help for package COUNT</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {COUNT}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#affairs'><p>affairs</p></a></li>
<li><a href='#azcabgptca'><p>azcabgptca</p></a></li>
<li><a href='#azdrg112'><p>azdrg112</p></a></li>
<li><a href='#azpro'>
<p>azpro</p></a></li>
<li><a href='#azprocedure'><p>azprocedure</p></a></li>
<li><a href='#badhealth'><p>badhealth</p></a></li>
<li><a href='#fasttrakg'><p>fasttrakg</p></a></li>
<li><a href='#fishing'><p>fishing</p></a></li>
<li><a href='#lbw'><p>lbw</p></a></li>
<li><a href='#lbwgrp'><p>lbwgrp</p></a></li>
<li><a href='#logit_syn'>
<p>Logistic regression : generic synthetic binary/binomial logistic data and model</p></a></li>
<li><a href='#loomis'><p>loomis</p></a></li>
<li><a href='#mdvis'><p>mdvis</p></a></li>
<li><a href='#medpar'><p>medpar</p></a></li>
<li><a href='#ml.nb1'>
<p>NB1: maximum likelihood linear negative binomial regression</p></a></li>
<li><a href='#ml.nb2'>
<p>NB2: maximum likelihood linear negative binomial regression</p></a></li>
<li><a href='#ml.nbc'>
<p>NBC: maximum likelihood linear negative binomial regression</p></a></li>
<li><a href='#ml.pois'>
<p>NB2: maximum likelihood Poisson regression</p></a></li>
<li><a href='#modelfit'>
<p>Fit Statistics for generalized linear models</p></a></li>
<li><a href='#myTable'>
<p>Frequency table</p></a></li>
<li><a href='#nb1_syn'>
<p>Negative binomial (NB1): generic synthetic linear negative binomial data and model</p></a></li>
<li><a href='#nb2_syn'>
<p>Negative binomial (NB2): generic synthetic negative binomial data and model</p></a></li>
<li><a href='#nb2.obs.pred'>
<p>Table of negative binomial counts: observed vs predicted proportions and difference</p></a></li>
<li><a href='#nbc_syn'>
<p>Negative binomial (NB-C): generic synthetic canonical negative binomial data and model</p></a></li>
<li><a href='#nuts'><p>nuts</p></a></li>
<li><a href='#poi.obs.pred'>
<p>Table of Poisson counts: observed vs predicted proportions and difference</p></a></li>
<li><a href='#poisson_syn'>
<p>Poisson : generic synthetic Poisson data and model</p></a></li>
<li><a href='#probit_syn'>
<p>Probit regression : generic synthetic binary/binomial probit data and model</p></a></li>
<li><a href='#rwm'><p>rwm</p></a></li>
<li><a href='#rwm1984'><p>rwm1984</p></a></li>
<li><a href='#rwm5yr'><p>rwm5yr</p></a></li>
<li><a href='#ships'><p>ships</p></a></li>
<li><a href='#smoking'><p>smoking</p></a></li>
<li><a href='#titanic'><p>titanic</p></a></li>
<li><a href='#titanicgrp'><p>titanicgrp</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functions, Data and Code for Count Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-10-17</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10), msme, sandwich</td>
</tr>
<tr>
<td>Author:</td>
<td>Joseph M Hilbe &lt;hilbe@asu.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrew Robinson &lt;apro@unimelb.edu.au&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions, data and code for Hilbe, J.M. 2011. Negative Binomial Regression, 2nd Edition (Cambridge University Press) and Hilbe, J.M. 2014. Modeling Count Data (Cambridge University Press).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-10-19 00:40:37 UTC; andrewpr</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-10-19 13:07:05</td>
</tr>
</table>
<hr>
<h2 id='affairs'>affairs</h2><span id='topic+affairs'></span>

<h3>Description</h3>

<p>Data from Fair (1978). Although Fair used a tobit model with the 
data, the outcome measure can be modeled as a count. In fact, 
Greene (2003) modeled it as Poisson, but given the amount of 
overdispersion in the data, employing a negative binomial model 
is an appropriate strategy. The data is stored in the affairs 
data set. 
Naffairs is the response variable, indicating the number 
of affairs reported by the participant in the past year. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(affairs)</code></pre>


<h3>Format</h3>

<p>A data frame with 601 observations on the following 18 variables.
</p>

<dl>
<dt><code>naffairs</code></dt><dd><p>number of affairs within last year</p>
</dd>
<dt><code>kids</code></dt><dd><p>1=have children;0= no children</p>
</dd>
<dt><code>vryunhap</code></dt><dd><p>(1/0) very unhappily married</p>
</dd>
<dt><code>unhap</code></dt><dd><p>(1/0) unhappily married</p>
</dd>
<dt><code>avgmarr</code></dt><dd><p>(1/0) average married</p>
</dd>
<dt><code>hapavg</code></dt><dd><p>(1/0) happily married</p>
</dd>
<dt><code>vryhap</code></dt><dd><p>(1/0) very happily married</p>
</dd>
<dt><code>antirel</code></dt><dd><p>(1/0) anti religious</p>
</dd>
<dt><code>notrel</code></dt><dd><p>(1/0) not religious</p>
</dd>
<dt><code>slghtrel</code></dt><dd><p>(1/0) slightly religious</p>
</dd>
<dt><code>smerel</code></dt><dd><p>(1/0) somewhat religious</p>
</dd>
<dt><code>vryrel</code></dt><dd><p>(1/0) very religious</p>
</dd>
<dt><code>yrsmarr1</code></dt><dd><p>(1/0) &gt;0.75 yrs</p>
</dd>
<dt><code>yrsmarr2</code></dt><dd><p>(1/0) &gt;1.5 yrs</p>
</dd>
<dt><code>yrsmarr3</code></dt><dd><p>(1/0) &gt;4.0 yrs</p>
</dd>
<dt><code>yrsmarr4</code></dt><dd><p>(1/0) &gt;7.0 yrs</p>
</dd>
<dt><code>yrsmarr5</code></dt><dd><p>(1/0) &gt;10.0 yrs</p>
</dd>
<dt><code>yrsmarr6</code></dt><dd><p>(1/0) &gt;15.0 yrs</p>
</dd>   
</dl>



<h3>Details</h3>

<p>rwm5yr is saved as a data frame.
Count models use naffairs as response variable. 0 counts are included.
</p>


<h3>Source</h3>

<p>Fair, R. (1978). A Theory of Extramarital Affairs, Journal of Political Economy, 86: 45-61.
Greene, W.H. (2003). Econometric Analysis, Fifth Edition, New York: Macmillan.
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic regression Models, Chapman &amp; Hall/CRC
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(affairs)
glmaffp &lt;- glm(naffairs ~ kids + yrsmarr2 + yrsmarr3 + yrsmarr4 + yrsmarr5,
               family = poisson, data = affairs)
summary(glmaffp)
exp(coef(glmaffp))

require(MASS)
glmaffnb &lt;- glm.nb(naffairs ~ kids + yrsmarr2 + yrsmarr3 + yrsmarr4 + yrsmarr5,
                   data=affairs)
summary(glmaffnb)
exp(coef(glmaffnb))
</code></pre>

<hr>
<h2 id='azcabgptca'>azcabgptca</h2><span id='topic+azcabgptca'></span>

<h3>Description</h3>

<p>Random subset of the 1991 Arizona Medicare data for patients hospitalized 
subsequent to undergoing  a CABG (DRGs 106, 107) or PTCA (DRG 112) 
cardiovascular procedure. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(azcabgptca)</code></pre>


<h3>Format</h3>

<p>A data frame with 1959 observations on the following 6 variables.
</p>

<dl>
<dt><code>died</code></dt><dd><p>systolic blood pressure of subject</p>
</dd>
<dt><code>procedure</code></dt><dd><p>1=CABG; 0=PTCA</p>
</dd>
<dt><code>gender</code></dt><dd><p>1=male; 0=female</p>
</dd>
<dt><code>age</code></dt><dd><p>age of subject</p>
</dd>
<dt><code>los</code></dt><dd><p>hospital length of stay</p>
</dd>
<dt><code>type</code></dt><dd><p>1=emerg/urgent; 0=elective</p>
</dd>
</dl>



<h3>Details</h3>

<p>azcabgptca is saved as a data frame.
</p>


<h3>Source</h3>

<p>Hilbe, Negative Binomial Regression, 2nd ed, Cambridge Univ Press
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(azcabgptca); attach(azcabgptca)
table(los); table(procedure, type); table(los, procedure)
summary(los)
summary(c91a &lt;- glm(los ~ procedure+ type, family=poisson, data=azcabgptca))
modelfit(c91a)
summary(c91b &lt;- glm(los ~ procedure+ type, family=quasipoisson, data=azcabgptca))
modelfit(c91b)
library(sandwich)
sqrt(diag(vcovHC(c91a, type="HC0")))
</code></pre>

<hr>
<h2 id='azdrg112'>azdrg112</h2><span id='topic+azdrg112'></span>

<h3>Description</h3>

<p>The data set relates to the hospital length of stay for patients having 
a CABG or PTCA (typel) heart procedure. The data comes from the 1995 
Arizona Medicare data for DRG (Diagnostic Related Group) 112. Other predictors 
include gender(1=female) and age75 (1-age 75+). Type is labeled as 1=emergency 
or urgent admission; 0= elective. Length of stay (los) ranges from 1 to 53 days. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(azdrg112)</code></pre>


<h3>Format</h3>

<p>A data frame with 1,798 observations on the following 4 variables.
</p>

<dl>
<dt><code>los</code></dt><dd><p>hospital length of stay: 1-53 days</p>
</dd>
<dt><code>gender</code></dt><dd><p>1=male; 0=female</p>
</dd>
<dt><code>type1</code></dt><dd><p>1=emergency/urgent admission; 0=elective admission</p>
</dd>
<dt><code>age75</code></dt><dd><p>1=age&gt;75; 0=age&lt;=75</p>
</dd>
</dl>



<h3>Details</h3>

<p>azdrg112 is saved as a data frame.
Count models typically use los as response variable. 0 counts are not included
</p>


<h3>Source</h3>

<p>DRG 112 data from the 1995 Arizona Medicare (MedPar) State files
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(azdrg112)
glmazp &lt;- glm(los ~ type1 + gender + age75, family=poisson, data=azdrg112)
summary(glmazp)
exp(coef(glmazp))
library(MASS)
glmaznb &lt;- glm.nb(los ~ type1 + gender + age75, data=azdrg112)
summary(glmaznb)
exp(coef(glmaznb))
</code></pre>

<hr>
<h2 id='azpro'>
azpro
</h2><span id='topic+azpro'></span>

<h3>Description</h3>


<p>Data come from the 1991 Arizona cardiovascular patient files. A subset of the 
fields was selected to model the differential length of stay for patients entering 
the hospital to receive one of two standard cardiovascular procedures: CABG and PTCA. 
CABG is the standard acronym for Coronary Artery Bypass Graft, where the flow of 
blood in a diseased or blocked coronary artery or vein has been grafted to bypass 
the diseased sections. PTCA, or Percutaneous Transluminal Coronary Angioplasty, is 
a method of placing a balloon in a blocked coronary artery to open it to blood flow. 
It is a much less severe method of treatment for those having coronary blockage, with 
a corresponding reduction in risk. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(azpro)</code></pre>


<h3>Format</h3>

<p>A data frame with 3589 observations on the following 6 variables.
</p>

<dl>
<dt><code>los</code></dt><dd><p>length of hospital stay</p>
</dd>
<dt><code>procedure</code></dt><dd><p>1=CABG;0=PTCA</p>
</dd>
<dt><code>sex</code></dt><dd><p>1=Male; 0=female</p>
</dd>
<dt><code>admit</code></dt><dd><p>1=Urgent/Emerg; 0=elective (type of admission)</p>
</dd>
<dt><code>age75</code></dt><dd><p>1= Age&gt;75; 0=Age&lt;=75</p>
</dd>
<dt><code>hospital</code></dt><dd><p>encrypted facility code (string)</p>
</dd>
</dl>



<h3>Details</h3>


<p>azpro is saved as a data frame.
Count models use los as response variable. 0 counts are structurally excluded  
</p>


<h3>Source</h3>


<p>1991 Arizona Medpar data, cardiovascular patient files, 
National Health Economics &amp; Research Co.
</p>


<h3>References</h3>


<p>Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(azpro)
glmazp &lt;- glm(los ~ procedure + sex + admit, family=poisson, data=azpro)
summary(glmazp)
exp(coef(glmazp))
#glmaznb &lt; -glm.nb(los ~ procedure + sex + admit, data=azpro)
#summary(glmaznb)
#exp(coef(glmaznb))
</code></pre>

<hr>
<h2 id='azprocedure'>azprocedure</h2><span id='topic+azprocedure'></span>

<h3>Description</h3>

<p>Data come from the 1991 Arizona cardiovascular patient files. A subset of the 
fields was selected to model the differential length of stay for patients entering 
the hospital to receive one of two standard cardiovascular procedures: CABG and PTCA. 
CABG is the standard acronym for Coronary Artery Bypass Graft, where the flow of 
blood in a diseased or blocked coronary artery or vein has been grafted to bypass 
the diseased sections. PTCA, or Percutaneous Transluminal Coronary Angioplasty, is 
a method of placing a balloon in a blocked coronary artery to open it to blood flow. 
It is a much less severe method of treatment for those having coronary blockage, with 
a corresponding reduction in risk. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(azprocedure)</code></pre>


<h3>Format</h3>

<p>A data frame with 3589 observations on the following 6 variables.
</p>

<dl>
<dt><code>los</code></dt><dd><p>length of hospital stay</p>
</dd>
<dt><code>procedure</code></dt><dd><p>1=CABG;0=PTCA</p>
</dd>
<dt><code>sex</code></dt><dd><p>1=Male; 0=female</p>
</dd>
<dt><code>admit</code></dt><dd><p>1=Urgent/Emerg; 0=elective (type of admission)</p>
</dd>
<dt><code>age75</code></dt><dd><p>1= Age&gt;75; 0=Age&lt;=75</p>
</dd>
<dt><code>hospital</code></dt><dd><p>encrypted facility code (string)</p>
</dd>
</dl>



<h3>Details</h3>

<p>azprocedure is saved as a data frame.
Count models use los as response variable. 0 counts are structurally excluded  
</p>


<h3>Source</h3>

<p>1991 Arizona Medpar data, cardiovascular patient files, 
National Health Economics &amp; Research Co.
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
library(msme)

data(azprocedure)

glmazp &lt;- glm(los ~ procedure + sex + admit, family=poisson, data=azprocedure)
summary(glmazp)
exp(coef(glmazp))

nb2 &lt;- nbinomial(los ~ procedure + sex + admit, data=azprocedure)
summary(nb2)
exp(coef(nb2))

glmaznb &lt;- glm.nb(los ~ procedure + sex + admit, data=azprocedure)
summary(glmaznb)
exp(coef(glmaznb))
</code></pre>

<hr>
<h2 id='badhealth'>badhealth</h2><span id='topic+badhealth'></span>

<h3>Description</h3>

<p>From German health survey data for the year 1998 only. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(badhealth)</code></pre>


<h3>Format</h3>

<p>A data frame with 1,127 observations on the following 3 variables.
</p>

<dl>
<dt><code>numvisit</code></dt><dd><p>number of visits to doctor during 1998</p>
</dd>
<dt><code>badh</code></dt><dd><p>1=patient claims to be in bad health; 0=not in bad health</p>
</dd>
<dt><code>age</code></dt><dd><p>age of patient: 20-60</p>
</dd>
</dl>



<h3>Details</h3>

<p>badhealth is saved as a data frame.
Count models use numvisit as the response variable, 0 counts are included.
</p>


<h3>Source</h3>

<p>German Health Survey, amended in Hilbe and Greene (2008).
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press
Hilbe, J. and W. Greene (2008). Count Response Regression Models, in ed. 
C.R. Rao, J.P Miller, and D.C. Rao, Epidemiology and Medical Statistics, 
Elsevier Handbook of  Statistics Series. London, UK: Elsevier.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(badhealth)
glmbadp &lt;- glm(numvisit ~ badh + age, family=poisson, data=badhealth)
summary(glmbadp)
exp(coef(glmbadp))
library(MASS)
glmbadnb &lt;- glm.nb(numvisit ~ badh + age, data=badhealth)
summary(glmbadnb)
exp(coef(glmbadnb))
</code></pre>

<hr>
<h2 id='fasttrakg'>fasttrakg</h2><span id='topic+fasttrakg'></span>

<h3>Description</h3>

<p>Data are from the Canadian National Cardiovascular Disease registry 
called, FASTRAK. years covered at 1996-1998. They have been grouped 
by covariate patterns from individual observations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fasttrakg)</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 9 variables.
</p>

<dl>
<dt><code>die</code></dt><dd><p>number died from MI</p>
</dd>
<dt><code>cases</code></dt><dd><p>number of cases with same covariate pattern</p>
</dd>
<dt><code>anterior</code></dt><dd><p>1=anterior site MI; 0=inferior site MI</p>
</dd>
<dt><code>hcabg</code></dt><dd><p>1=history of CABG; 0=no history of CABG</p>
</dd>
<dt><code>killip</code></dt><dd><p>Killip level of cardiac event severity (1-4)age75</p>
</dd></dl>
<p>1= Age&gt;75; 0=Age&lt;=75
</p>
<dl>
<dt><code>kk1</code></dt><dd><p>(1/0) angina; not MI</p>
</dd>
<dt><code>kk2</code></dt><dd><p>(1/0) moderate severity cardiac event</p>
</dd>
<dt><code>kk3</code></dt><dd><p>(1/0) Severe cardiac event</p>
</dd>
<dt><code>kk4</code></dt><dd><p>(1/0) Severe cardiac event; death</p>
</dd>
</dl>



<h3>Details</h3>

<p>fasttrakg is saved as a data frame.
Count models use died as response numerator and cases as the demoninator  
</p>


<h3>Source</h3>

<p>1996-1998 FASTRAK data, Hoffman-LaRoche Canada,
National Health Economics &amp; Research Co.
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
data(fasttrakg)
glmfp &lt;- glm(die ~ anterior + factor(killip) + offset(log(cases)), family=poisson, data=fasttrakg)
summary(glmfp)
exp(coef(glmfp))

</code></pre>

<hr>
<h2 id='fishing'>fishing</h2><span id='topic+fishing'></span>

<h3>Description</h3>

<p>The fishing data is adapted from Zuur, Hilbe and Ieno (2013) to determine 
whether the data appears to be generated from more than one generating mechanism. 
The data are originally adapted from Bailey et al. (2008) who were interested in 
how certain deep-sea fish populations were impacted when commercial fishing 
began in locations with deeper water than in previous years. Given that there 
are 147 sites that were researched, the model is of (1) the total number of fish 
counted per site (totabund); ( 2)  on the mean water depth per site (meandepth); 
(3) adjusted by the area of the site (sweptarea); (4) the log of which is the 
model offset. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fishing)</code></pre>


<h3>Format</h3>

<p>A data frame with 147 observations on the following variables.
</p>

<dl>
<dt><code>totabund</code></dt><dd><p>total fish counted per site</p>
</dd>
<dt><code>meandepth</code></dt><dd><p>mean water depth per site</p>
</dd>
<dt><code>sweptarea</code></dt><dd><p>adjusted area of site</p>
</dd>
<dt><code>density</code></dt><dd><p>folage density index</p>
</dd>
<dt><code>site</code></dt><dd><p>catch site</p>
</dd>
<dt><code>year</code></dt><dd><p>1977-2002</p>
</dd>
<dt><code>period</code></dt><dd><p>0=1977-1989; 1=2000+</p>
</dd>
</dl>



<h3>Details</h3>

<p>fishing is saved as a data frame.
Count models use totabund as response variable. Counts start at 2  
</p>


<h3>Source</h3>

<p>Zuur, Hilbe, Ieno (2013), A Beginner's Guide to GLM and GLMM using R, 
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
Zuur, Hilbe, Ieno (2013), A Beginner's Guide to GLM and GLMM using R, Highlands.
Bailey M. et al (2008), &quot;Longterm changes in deep-water fish populations in 
the North East Atlantic&quot;, Proc Roy Soc B 275:1965-1969.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
library(MASS)
library(flexmix)
data(fishing)
attach(fishing)
fmm_pg &lt;- flexmix(totabund~meandepth + offset(log(sweptarea)), data=rwm1984, k=2,
         model=list(FLXMRglm(totabund~., family="NB1"), 
                    FLXMRglm(tpdocvis~., family="NB1")))
parameters(fmm_pg, component=1, model=1)
parameters(fmm_pg, component=2, model=1)
summary(fmm_pg)

## End(Not run)</code></pre>

<hr>
<h2 id='lbw'>lbw</h2><span id='topic+lbw'></span>

<h3>Description</h3>

<p>The data come to us from Hosmer and Lemeshow (2000). Called the low 
birth weight (lbw) data, the response is a binary variable, low, 
which indicates whether the birth weight of a baby is under 2500g 
(low=1), or over (low=0). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lbw)</code></pre>


<h3>Format</h3>

<p>A data frame with 189 observations on the following 10 variables.
</p>

<dl>
<dt><code>low</code></dt><dd><p>1=low birthweight baby; 0=norml weight</p>
</dd>
<dt><code>smoke</code></dt><dd><p>1=history of mother smoking; 0=mother nonsmoker</p>
</dd>
<dt><code>race</code></dt><dd><p>categorical 1-3: 1=white; 2-=black; 3=other</p>
</dd>
<dt><code>age</code></dt><dd><p>age of mother: 14-45</p>
</dd>
<dt><code>lwt</code></dt><dd><p>weight (lbs) at last menstrual period: 80-250 lbs</p>
</dd>
<dt><code>ptl</code></dt><dd><p>number of false of premature labors: 0-3</p>
</dd>
<dt><code>ht</code></dt><dd><p>1=history of hypertension; 0 =no hypertension</p>
</dd>
<dt><code>ui</code></dt><dd><p>1=uterine irritability; 0 no irritability</p>
</dd>
<dt><code>ftv</code></dt><dd><p>number of physician visits in 1st trimester: 0-6</p>
</dd>
<dt><code>bwt</code></dt><dd><p>birth weight in grams: 709 - 4990 gr</p>
</dd>
</dl>



<h3>Details</h3>

<p>lbw is saved as a data frame.
Count models can use ftv as a response variable, or convert it to grouped format
</p>


<h3>Source</h3>

<p>Hosmer, D and S. Lemeshow (2000), Applied Logistic Regression, Wiley 
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lbw)
glmbwp &lt;- glm(ftv ~ low + smoke + factor(race), family=poisson, data=lbw)
summary(glmbwp)
exp(coef(glmbwp))
library(MASS)
glmbwnb &lt;- glm.nb(ftv ~ low + smoke + factor(race), data=lbw)
summary(glmbwnb)
exp(coef(glmbwnb))
</code></pre>

<hr>
<h2 id='lbwgrp'>lbwgrp</h2><span id='topic+lbwgrp'></span>

<h3>Description</h3>

<p>grouped format of the lbw data. The observation level data come to us form 
Hosmer and Lemeshow (2000). Grouping is such that lowbw is the numerator, and 
cases the denominator of a binomial model, or cases may be an offset to the count
variable, lowbw.  Birthweights under 2500g classifies a low birthweight baby.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lbwgrp)</code></pre>


<h3>Format</h3>

<p>A data frame with 6 observations on the following 7 variables.
</p>

<dl>
<dt><code>lowbw</code></dt><dd><p>Number of low weight babies per covariate pattern: 12-60</p>
</dd>
<dt><code>cases</code></dt><dd><p>Number of observations with same covariate pattern: 30-165</p>
</dd>
<dt><code>smoke</code></dt><dd><p>1=history of mother smoking; 0=mother nonsmoker</p>
</dd>
<dt><code>race1</code></dt><dd><p>(1/0): Caucasian</p>
</dd>
<dt><code>race2</code></dt><dd><p>(1/0): Black</p>
</dd>
<dt><code>race3</code></dt><dd><p>(1/0): Other</p>
</dd>
<dt><code>low</code></dt><dd><p>low birth weight (not valid variable in grouped format)</p>
</dd>
</dl>



<h3>Details</h3>

<p>lbwgrp is saved as a data frame.
Count models: count response=lowbt; offset=log(cases); 
Binary: binomial numerator= lowbt; binomial denominator=cases
</p>


<h3>Source</h3>

<p>Hosmer, D and S. Lemeshow (2000), Applied Logistic Regression, Wiley 
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lbwgrp)
glmgp &lt;- glm(lowbw ~ smoke + race2 + race3 + offset(log(cases)), family=poisson, data=lbwgrp)
summary(glmgp)
exp(coef(glmgp))
library(MASS)
glmgnb &lt;- glm.nb(lowbw ~  smoke + race2 + race3, data=lbwgrp)
summary(glmgnb)
exp(coef(glmgnb))
</code></pre>

<hr>
<h2 id='logit_syn'>
Logistic regression : generic synthetic binary/binomial logistic data and model
</h2><span id='topic+logit_syn'></span>

<h3>Description</h3>

<p>logit_syn is a generic function for developing synthetic logistic regression data and 
a model given user defined specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit_syn(nobs=50000, d=1,  xv  = c(1, 0.5, -1.5))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit_syn_+3A_nobs">nobs</code></td>
<td>
<p>number of observations in model, Default is 50000</p>
</td></tr>
<tr><td><code id="logit_syn_+3A_d">d</code></td>
<td>
<p>binomial denominator, Default is 1, a binary logistic model. May 
use a variable containing different denominator values.</p>
</td></tr> 
<tr><td><code id="logit_syn_+3A_xv">xv</code></td>
<td>
<p>predictor coefficient values. First argument is intercept. Use as
xv =  c(intercept , x1_coef, x2_coef, ...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create a synthetic logistic regression model using the appropriate arguments. 
Binomial denominator must be declared. For a binary logistic model, d=1. A 
variable may be used as the denominator when values differ. See examples.
</p>


<h3>Value</h3>

<table>
<tr><td><code>by</code></td>
<td>
<p>binomial logistic numerator; number of successes</p>
</td></tr>
<tr><td><code>sim.data</code></td>
<td>
<p>synthetic data set</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
Andrew Robinson, Universty of Melbourne, Australia.
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
Hilbe, J.M. (2009), Logistic Regression Models, Chapman &amp; Hall/CRCD
</p>


<h3>See Also</h3>

<p><code><a href="#topic+probit_syn">probit_syn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Binary logistic regression (denominator=1)
sim.data &lt;-logit_syn(nobs = 500, d = 1, xv = c(1, .5, -1.5))
mylogit &lt;- glm(cbind(by,dby) ~ ., family=binomial(link="logit"), data = sim.data)
summary(mylogit)
confint(mylogit)

# Binary logistic regression with odds ratios (denominator=1); 3 predictors
sim.data &lt;-logit_syn(nobs = 500, d = 1, xv = c(1, .75, -1.5, 1.15))
mylogit &lt;- glm(cbind(by,dby) ~ ., family=binomial(link="logit"), data = sim.data)
exp(coef(mylogit))
exp(confint(mylogit))

# Binomial or grouped logistic regression with defined denominator, den
den &lt;- rep(1:5, each=100, times=1)*100
sim.data &lt;- logit_syn(nobs = 500, d = den, xv = c(1, .5, -1.5))
gby &lt;- glm(cbind(by,dby) ~ ., family=binomial(link="logit"), data = sim.data)
summary(gby)

## Not run: 
# default
sim.data &lt;- logit_syn(nobs=500, d=1,  xv = c(2, -.55, 1.15))
dlogit &lt;- glm(cbind(by,dby) ~ . , family=binomial(link="logit"), data = sim.data)
summary(dlogit)

## End(Not run)

</code></pre>

<hr>
<h2 id='loomis'>loomis</h2><span id='topic+loomis'></span>

<h3>Description</h3>

<p>Data are taken from Loomis (2003). The study relates to a survey taken on reported 
frequency of visits to national parks during the year. The survey was taken at park 
sites, thus incurring possible effects of endogenous stratification.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(loomis)</code></pre>


<h3>Format</h3>

<p>A data frame with 410 observations on the following 11 variables.
</p>

<dl>
<dt><code>anvisits</code></dt><dd><p>number of annual visits to park</p>
</dd>
<dt><code>gender</code></dt><dd><p>1=male;0=female</p>
</dd>
<dt><code>income</code></dt><dd><p>income in US dollars per year, categorical: 4 levels</p>
</dd>
<dt><code>income1</code></dt><dd><p>&lt;=$25000</p>
</dd>
<dt><code>income2</code></dt><dd><p>&gt;$25000 - $55000</p>
</dd>
<dt><code>income3</code></dt><dd><p>&gt;$55000 - $95000</p>
</dd>
<dt><code>income4</code></dt><dd><p>&gt;$95000</p>
</dd>
<dt><code>travel</code></dt><dd><p>travel time, categorical: 3 levels</p>
</dd>
<dt><code>travel1</code></dt><dd><p>&lt;.25 hrs</p>
</dd>
<dt><code>travel2</code></dt><dd><p>&gt;=.25 - &lt;4 hrs</p>
</dd>
<dt><code>travel3</code></dt><dd><p>&gt;=4 hrs</p>
</dd>
</dl>



<h3>Details</h3>

<p>loomis is saved as a data frame.
Count models typically use anvisits as response variable. 0 counts are included
</p>


<h3>Source</h3>

<p>from Loomis (2003)
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Loomis, J. B. (2003). Travel cost demand model based river recreation benefit 
estimates with on-site and household surveys: Comparative results and a 
correction procedure, Water Resources Research, 39(4): 1105
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(loomis)
glmlmp &lt;- glm(anvisits ~ gender + factor(income) + factor(travel), family=poisson, data=loomis)
summary(glmlmp)
exp(coef(glmlmp))
library(MASS)
glmlmnb &lt;- glm.nb(anvisits ~ gender + factor(income) + factor(travel), data=loomis)
summary(glmlmnb)
exp(coef(glmlmnb))
</code></pre>

<hr>
<h2 id='mdvis'>mdvis</h2><span id='topic+mdvis'></span>

<h3>Description</h3>

<p>Data from a subset of the German Socio-Economic Panel  (SOEP). The subset was created 
by Rabe-Hesketh and Skrondal (2005). Only working women are included in these data. 
Beginning in 1997, German health reform in part entailed a 200
co-payment as well as limits in provider reimbursement. Patients were surveyed for the 
one year panel (1996) prior to and the one year panel (1998) after reform to assess 
whether the number of physician visits by patients declined - which was the goal of 
reform legislation. 
The response, or variable to be explained by the model, is numvisit, which 
indicates the number of patient visits to a physician's office during a three month period.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mdvis)</code></pre>


<h3>Format</h3>

<p>A data frame with 2,227 observations on the following 13 variables.
</p>

<dl>
<dt><code>numvisit</code></dt><dd><p>visits to MD office 3mo prior</p>
</dd>
<dt><code>reform</code></dt><dd><p>1=interview yr post-reform: 1998;0=pre-reform:1996</p>
</dd>
<dt><code>badh</code></dt><dd><p>1=bad health; 0 = not bad health</p>
</dd>
<dt><code>age</code></dt><dd><p>Age(yrs 20-60)</p>
</dd>
<dt><code>educ</code></dt><dd><p>education(1:7-10;2=10.5-12;3=HSgrad+)</p>
</dd>
<dt><code>educ1</code></dt><dd><p>educ1= 7-10 years</p>
</dd>
<dt><code>educ2</code></dt><dd><p>educ2= 10.5-12 years</p>
</dd>
<dt><code>educ3</code></dt><dd><p>educ3= post secondary or high school</p>
</dd>
<dt><code>agegrp</code></dt><dd><p>age: 1=20-39; 2=40-49; 3=50-60</p>
</dd>
<dt><code>age1</code></dt><dd><p>age 20-39</p>
</dd>
<dt><code>age2</code></dt><dd><p>age 40-49</p>
</dd>
<dt><code>age3</code></dt><dd><p>age 50-60</p>
</dd>
<dt><code>loginc</code></dt><dd><p>log(household income in DM)</p>
</dd>
</dl>



<h3>Details</h3>

<p>mdvis is saved as a data frame.
Count models typically use docvis as response variable. 0 counts are included
</p>


<h3>Source</h3>

<p>German Socio-Economic Panel (SOEP), 1995 pre-reform; 1998 post reform. Created
by Rabe-Hesketh and Skrondal (2005).
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
Rabe-Hesketh, S. and A. Skrondal (2005). Multilevel and Longitudinal Modeling Using Stata, 
College Station: Stata Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mdvis)
glmmdp &lt;- glm(numvisit ~ reform + factor(educ) + factor(agegrp), family=poisson, data=mdvis)
summary(glmmdp)
exp(coef(glmmdp))
library(MASS)
glmmdnb &lt;- glm.nb(numvisit ~ reform + factor(educ) + factor(agegrp), data=mdvis)
summary(glmmdnb)
exp(coef(glmmdnb))
</code></pre>

<hr>
<h2 id='medpar'>medpar</h2><span id='topic+medpar'></span>

<h3>Description</h3>

<p>The US national Medicare inpatient hospital database is referred to as the Medpar data, 
which is prepared yearly from hospital filing records. Medpar files for each state are also 
prepared. The full Medpar data consists of 115 variables. The national Medpar has some 
14 million records, with one record for each hospilitiztion. The data in the medpar file comes 
from 1991 Medicare files for the state of Arizona. The data are limited to only one diagnostic 
group (DRG 112). Patient data have been randomly selected from the original data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(medpar)</code></pre>


<h3>Format</h3>

<p>A data frame with 1495 observations on the following 10 variables.
</p>

<dl>
<dt><code>los</code></dt><dd><p>length of hospital stay</p>
</dd>
<dt><code>hmo</code></dt><dd><p>Patient belongs to a Health Maintenance Organization, binary</p>
</dd>
<dt><code>white</code></dt><dd><p>Patient identifies themselves as Caucasian, binary</p>
</dd>
<dt><code>died</code></dt><dd><p>Patient died, binary</p>
</dd>
<dt><code>age80</code></dt><dd><p>Patient age 80 and over, binary</p>
</dd>
<dt><code>type</code></dt><dd><p>Type of admission, categorical</p>
</dd>
<dt><code>type1</code></dt><dd><p>Elective admission, binary</p>
</dd>
<dt><code>type2</code></dt><dd><p>Urgent admission,binary</p>
</dd>
<dt><code>type3</code></dt><dd><p>Elective admission, binary</p>
</dd>
<dt><code>provnum</code></dt><dd><p>Provider ID</p>
</dd>
</dl>



<h3>Details</h3>

<p>medpar is saved as a data frame.
Count models use los as response variable. 0 counts are structurally excluded  
</p>


<h3>Source</h3>

<p>1991 National Medpar data, National Health Economics &amp; Research Co.
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
first used in Hardin, JW and JM Hilbe (2001, 2007), Generalized Linear Models and Extensions, Stata Press
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
library(msme)
data(medpar)
glmp &lt;- glm(los ~ hmo + white + factor(type), family=poisson, data=medpar)
summary(glmp)
exp(coef(glmp))
nb2 &lt;- nbinomial(los ~ hmo + white + factor(type), data=medpar)
summary(nb2)
exp(coef(nb2))
glmnb &lt;- glm.nb(los ~ hmo + white + factor(type), data=medpar)
summary(glmnb)
exp(coef(glmnb))

</code></pre>

<hr>
<h2 id='ml.nb1'>
NB1: maximum likelihood linear negative binomial regression
</h2><span id='topic+ml.nb1'></span>

<h3>Description</h3>

<p>ml.nb1 is a maximum likelihood function for estimating linear 
negative binomial (NB1) data. Output consists of a table of parameter 
estimates, standard errors, z-value, and confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ml.nb1(formula, data, offset=0, start=NULL, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ml.nb1_+3A_formula">formula</code></td>
<td>

<p>an object of class '&quot;formula&quot;': a symbolic description of the 
model to be fitted.  The details of model specification are given under
'Details'.</p>
</td></tr>
<tr><td><code id="ml.nb1_+3A_data">data</code></td>
<td>
 
<p>a mandatory data frame containing the variables in the model.
</p>
</td></tr>
<tr><td><code id="ml.nb1_+3A_offset">offset</code></td>
<td>
 
<p>this can be used to specify an _a priori_ known component to
be included in the linear predictor during fitting.  The offset
should be provided on the log scale.
</p>
</td></tr>
<tr><td><code id="ml.nb1_+3A_start">start</code></td>
<td>

<p>an optional vector of starting values for the parameters.
</p>
</td></tr>
<tr><td><code id="ml.nb1_+3A_verbose">verbose</code></td>
<td>

<p>a logical flag to indicate whether the fit information should be printed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ml.nb1 is used like glm.nb, but without saving ancillary statistics. 
</p>


<h3>Value</h3>

<p>The function returns a dataframe with the following components:
</p>
<table>
<tr><td><code>Estimate</code></td>
<td>
<p>ML estimate of the parameter</p>
</td></tr>
<tr><td><code>SE</code></td>
<td>
<p>Asymptotic estimate of the standard error of the estimate
of the parameter</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>The Z statistic of the asymptotic hypothesis test that the
population value for the parameter is 0.</p>
</td></tr>
<tr><td><code>LCL</code></td>
<td>
<p>Lower 95% confidence interval for the parameter estimate.</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p>Upper 95% confidence interval for the parameter estimate.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrew Robinson, Universty of Melbourne, Australia, and
Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+ml.nbc">ml.nbc</a></code>, <code><a href="#topic+ml.nb2">ml.nb2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Table 10.8, Hilbe. J.M. (2011), Negative Binomial Regression, 
#   2nd ed. Cambridge University Press (adapted)
data(medpar)
medpar$type &lt;- factor(medpar$type)
med.nb1 &lt;- ml.nb1(los ~ hmo + white + type, data = medpar)
med.nb1
</code></pre>

<hr>
<h2 id='ml.nb2'>
NB2: maximum likelihood linear negative binomial regression
</h2><span id='topic+ml.nb2'></span>

<h3>Description</h3>

<p>ml.nb2 is a maximum likelihood function for estimating linear 
negative binomial (NB2) data. Output consists of a table of parameter 
estimates, standard errors, z-value, and confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ml.nb2(formula, data, offset=0, start=NULL, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ml.nb2_+3A_formula">formula</code></td>
<td>

<p>an object of class '&quot;formula&quot;': a symbolic description of the 
model to be fitted.  The details of model specification are given under
'Details'.</p>
</td></tr>
<tr><td><code id="ml.nb2_+3A_data">data</code></td>
<td>
 
<p>a mandatory data frame containing the variables in the model.
</p>
</td></tr>
<tr><td><code id="ml.nb2_+3A_offset">offset</code></td>
<td>
 
<p>this can be used to specify an _a priori_ known component to
be included in the linear predictor during fitting.  The offset
should be provided on the log scale.
</p>
</td></tr>
<tr><td><code id="ml.nb2_+3A_start">start</code></td>
<td>

<p>an optional vector of starting values for the parameters.
</p>
</td></tr>
<tr><td><code id="ml.nb2_+3A_verbose">verbose</code></td>
<td>

<p>a logical flag to indicate whether the fit information should be printed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ml.nb2 is used like glm.nb, but without saving ancillary statistics. 
</p>


<h3>Value</h3>

<p>The function returns a dataframe with the following components:
</p>
<table>
<tr><td><code>Estimate</code></td>
<td>
<p>ML estimate of the parameter</p>
</td></tr>
<tr><td><code>SE</code></td>
<td>
<p>Asymptotic estimate of the standard error of the estimate
of the parameter</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>The Z statistic of the asymptotic hypothesis test that the
population value for the parameter is 0.</p>
</td></tr>
<tr><td><code>LCL</code></td>
<td>
<p>Lower 95% confidence interval for the parameter estimate.</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p>Upper 95% confidence interval for the parameter estimate.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrew Robinson, Universty of Melbourne, Australia, and
Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+ml.nbc">ml.nbc</a></code>, <code><a href="#topic+ml.nb1">ml.nb1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Table 8.7, Hilbe. J.M. (2011), Negative Binomial Regression, 
#   2nd ed. Cambridge University Press (adapted)
data(medpar)
medpar$type &lt;- factor(medpar$type)
med.nb2 &lt;- ml.nb2(los ~ hmo + white + type, data = medpar)
med.nb2
</code></pre>

<hr>
<h2 id='ml.nbc'>
NBC: maximum likelihood linear negative binomial regression
</h2><span id='topic+ml.nbc'></span>

<h3>Description</h3>

<p>ml.nbc is a maximum likelihood function for estimating canonical linear 
negative binomial (NB-C) data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ml.nbc(formula, data, start=NULL, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ml.nbc_+3A_formula">formula</code></td>
<td>

<p>an object of class '&quot;formula&quot;': a symbolic description of the 
model to be fitted.  The details of model specification are given under
'Details'.</p>
</td></tr>
<tr><td><code id="ml.nbc_+3A_data">data</code></td>
<td>
 
<p>a mandatory data frame containing the variables in the model.
</p>
</td></tr>
<tr><td><code id="ml.nbc_+3A_start">start</code></td>
<td>

<p>an optional vector of starting values for the parameters.
</p>
</td></tr>
<tr><td><code id="ml.nbc_+3A_verbose">verbose</code></td>
<td>

<p>a logical flag to indicate whether the fit information should be printed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ml.nbc is used like glm.nb, but without saving ancillary statistics. 
</p>


<h3>Value</h3>

<p>The function returns a dataframe with the following components:
</p>
<table>
<tr><td><code>Estimate</code></td>
<td>
<p>ML estimate of the parameter</p>
</td></tr>
<tr><td><code>SE</code></td>
<td>
<p>Asymptotic estimate of the standard error of the estimate
of the parameter</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>The Z statistic of the asymptotic hypothesis test that the
population value for the parameter is 0.</p>
</td></tr>
<tr><td><code>LCL</code></td>
<td>
<p>Lower 95% confidence interval for the parameter estimate.</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p>Upper 95% confidence interval for the parameter estimate.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrew Robinson, Universty of Melbourne, Australia, and
Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+ml.nb1">ml.nb1</a></code>, <code><a href="#topic+ml.nb2">ml.nb2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Table 10.12, Hilbe. J.M. (2011), Negative Binomial Regression, 
#   2nd ed. Cambridge University Press (adapted)

## Not run: 
data(medpar)
nobs &lt;- 50000
x2 &lt;- runif(nobs)
x1 &lt;- runif(nobs)
xb &lt;- 1.25*x1 + .1*x2 - 1.5
mu &lt;- 1/(exp(-xb)-1)
p &lt;- 1/(1+mu)
r &lt;- 1
gcy &lt;- rnbinom(nobs, size=r, prob = p)
test &lt;- data.frame(gcy, x1, x2)
nbc &lt;- ml.nbc(gcy ~ x1 + x2, data=test)
nbc

## End(Not run)
</code></pre>

<hr>
<h2 id='ml.pois'>
NB2: maximum likelihood Poisson regression
</h2><span id='topic+ml.pois'></span>

<h3>Description</h3>

<p>ml.pois is a maximum likelihood function for estimating
Poisson data. Output consists of a table of parameter estimates,
standard errors, z-value, and confidence intervals. An offset may be
declared as an option.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ml.pois(formula, data, offset=0, start=NULL, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ml.pois_+3A_formula">formula</code></td>
<td>

<p>an object of class '&quot;formula&quot;': a symbolic description of the 
model to be fitted. </p>
</td></tr>
<tr><td><code id="ml.pois_+3A_data">data</code></td>
<td>
 
<p>a mandatory data frame containing the variables in the model.
</p>
</td></tr>
<tr><td><code id="ml.pois_+3A_offset">offset</code></td>
<td>
 
<p>this can be used to specify an _a priori_ known component to
be included in the linear predictor during fitting.  The offset
should be provided on the log scale.
</p>
</td></tr>
<tr><td><code id="ml.pois_+3A_start">start</code></td>
<td>

<p>an optional vector of starting values for the parameters.
</p>
</td></tr>
<tr><td><code id="ml.pois_+3A_verbose">verbose</code></td>
<td>

<p>a logical flag to indicate whether the fit information should be printed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ml.pois is used like glm, but does not provide ancillary statistics.
</p>


<h3>Value</h3>

<p>The function returns a dataframe with the following components:
</p>
<table>
<tr><td><code>Estimate</code></td>
<td>
<p>ML estimate of the parameters</p>
</td></tr>
<tr><td><code>SE</code></td>
<td>
<p>Asymptotic estimate of the standard error of the estimate
of the parameter</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>The Z statistic of the asymptotic hypothesis test that the
population value for the parameter is 0.</p>
</td></tr>
<tr><td><code>LCL</code></td>
<td>
<p>Lower 95% confidence interval for the parameter estimates.</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p>Upper 95% confidence interval for the parameter estimates.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrew Robinson, Universty of Melbourne, Australia, and
Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+ml.nbc">ml.nbc</a></code>, <code><a href="#topic+ml.nb1">ml.nb1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Table 8.7, Hilbe. J.M. (2011), Negative Binomial Regression, 
#   2nd ed. Cambridge University Press (adapted)
data(medpar)
medpar$type &lt;- factor(medpar$type)
med.pois &lt;- ml.pois(los ~ hmo + white + type, data = medpar)
med.pois

data(rwm5yr)
lyear &lt;- log(rwm5yr$year)
rwm.poi &lt;- ml.pois(docvis ~ outwork + age + female, offset=lyear, data =
rwm5yr)
rwm.poi
exp(rwm.poi$Estimate)
exp(rwm.poi$LCL)
exp(rwm.poi$UCL)

</code></pre>

<hr>
<h2 id='modelfit'>
Fit Statistics for generalized linear models
</h2><span id='topic+modelfit'></span>

<h3>Description</h3>

<p>modelfit is used following a glm() or glm.nb() model to produce a list of model fit statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelfit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelfit_+3A_x">x</code></td>
<td>

<p>the only argument is the name of the fitted glm or glm.nb function model</p>
</td></tr>
</table>


<h3>Details</h3>

<p>modelfit is to be used as a post-estimation function, following the use of glm() or glm.nb(). 
</p>


<h3>Value</h3>

<table>
<tr><td><code>obs</code></td>
<td>
<p>number of model observatiions</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>AIC statistic</p>
</td></tr>
<tr><td><code>xvars</code></td>
<td>
<p>number of model predictors</p>
</td></tr>
<tr><td><code>rdof</code></td>
<td>
<p>residial degrees of freedom</p>
</td></tr>
<tr><td><code>aic_n</code></td>
<td>
<p>AIC, 'aic'/'obs'</p>
</td></tr>
<tr><td><code>ll</code></td>
<td>
<p>log-likelihood</p>
</td></tr>
<tr><td><code>bic_r</code></td>
<td>
<p>BIC - Raftery parameterization</p>
</td></tr>
<tr><td><code>bic_l</code></td>
<td>
<p>BIC - log-likelihood Standard definition (Stata)</p>
</td></tr>
<tr><td><code>bic_qh</code></td>
<td>
<p>Hannan-Quinn IC statistic (Limdep)</p>
</td></tr>

</table>


<h3>Note</h3>

<p>modelfit.r must be loaded into memory in order to be effectve. 
Users may past modelfit.r into script editor to run, as well as load it.
</p>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of technology 
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>
<p>Hilbe, J.M. (2009), Logistic Regression Models, Chapman  Hall/CRC
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Hilbe (2011), Table 9.17
library(MASS)
data(lbwgrp)
nb9_3 &lt;- glm.nb(lowbw ~ smoke + race2 + race3 + offset(log(cases)), data=lbwgrp)
summary(nb9_3)
exp(coef(nb9_3))
modelfit(nb9_3) 
</code></pre>

<hr>
<h2 id='myTable'>
Frequency table 
</h2><span id='topic+myTable'></span>

<h3>Description</h3>

 
<p>mytable is used to produce a table of frequencies, proportion and cumulative proportions for a count variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>myTable(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="myTable_+3A_x">x</code></td>
<td>

<p>the only argument is the name of the count variable</p>
</td></tr>
</table>


<h3>Details</h3>

<p>myTable is used as either a diagnostic to view the distribution of a count variable, or as a 
frequency distribution display in its own right. myTable is given in Table 9.40 in Hilbe (2011).
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>count value</p>
</td></tr>
<tr><td><code>Freq</code></td>
<td>
<p>Frequency of count</p>
</td></tr>
<tr><td><code>Prop</code></td>
<td>
<p>Proportion</p>
</td></tr>
<tr><td><code>CumProp</code></td>
<td>
<p>Cumulative proportion</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
Hilbe, J.M. (2009), Logistic Regression Models, Chapman  Hall/CRC
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modelfit">modelfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(medpar)
myTable(medpar$los)
</code></pre>

<hr>
<h2 id='nb1_syn'>
Negative binomial (NB1): generic synthetic linear negative binomial data and model
</h2><span id='topic+nb1_syn'></span>

<h3>Description</h3>

<p>nb1_syn is a generic function for developing synthetic NB1 data and a model given
user defined specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb1_syn(nobs=50000, delta=1, xv = c(1, 0.75, -1.25))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nb1_syn_+3A_nobs">nobs</code></td>
<td>
<p>number of observations in model, Default is 50000</p>
</td></tr>
<tr><td><code id="nb1_syn_+3A_delta">delta</code></td>
<td>
<p>NB1 heterogeneity or ancillary parameter</p>
</td></tr>
<tr><td><code id="nb1_syn_+3A_xv">xv</code></td>
<td>
<p>predictor coefficient values. First argument is intercept. Use as
xv =  c(intercept , x1_coef, x2_coef, ...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create a synthetic linear negative binomial (NB1) regression model using the 
appropriate arguments. Model data with predictors indicated as a group with 
a period (.). See examples.
</p>
<p>Data can be modeled using the ml.nb1.r function in the COUNT package, or by using the 
gamlss function in the gamlss package, using the &quot;family=NBII&quot; option. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>nb1y</code></td>
<td>
<p>Negative binomial (NB1) response; number of counts</p>
</td></tr>
<tr><td><code>sim.data</code></td>
<td>
<p>synthetic data set</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
Andrew Robinson, Universty of Melbourne, Australia.
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nb2_syn">nb2_syn</a></code>,   <code><a href="#topic+nbc_syn">nbc_syn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim.data &lt;- nb1_syn(nobs = 5000, delta = .5, xv = c(.5, 1.25, -1.5))
mynb1 &lt;- ml.nb1(nb1y ~ . , data = sim.data)
mynb1

## Not run: 
# use gamlss to model NB1 data
library(gamlss)         
sim.data &lt;- nb1_syn(nobs = 5000, delta = .5, xv = c(.5, 1.25, -1.5))
mynb1 &lt;- gamlss( nb1y ~ . , family=NBII, data = sim.data)
mynb1

## End(Not run)

## Not run: 
# default
sim.data &lt;- nb1_syn()
dnb1 &lt;- ml.nb1(nb1y ~ . , data = sim.data)
dnb1

## End(Not run)

</code></pre>

<hr>
<h2 id='nb2_syn'>
Negative binomial (NB2): generic synthetic negative binomial data and model
</h2><span id='topic+nb2_syn'></span>

<h3>Description</h3>

<p>nb2_syn is a generic function for developing synthetic NB2 data and a model given
user defined specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb2_syn(nobs = 50000, off = 0, alpha = 1, xv = c(1, 0.75, -1.5))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nb2_syn_+3A_nobs">nobs</code></td>
<td>
<p>number of observations in model, Default is 50000</p>
</td></tr>
<tr><td><code id="nb2_syn_+3A_alpha">alpha</code></td>
<td>
<p>NB2 heterogeneity or ancillary parameter</p>
</td></tr>
<tr><td><code id="nb2_syn_+3A_off">off</code></td>
<td>
<p>optional: log of offset variable</p>
</td></tr>
<tr><td><code id="nb2_syn_+3A_xv">xv</code></td>
<td>
<p>predictor coefficient values. First argument is intercept. Use as
xv =  c(intercept , x1_coef, x2_coef, ...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create a synthetic negative binomial (NB2) regression model using the appropriate 
arguments. Model data with predictors indicated as a group with a period (.).  
Offset optional. If no offset is desired, drop &quot;off= loff&quot; from nb2_syn function 
call and  &quot;+ loff&quot; from glm.nb function call. See examples.
</p>
<p>Data can be estimated using the glm.nb() function, or the ml.nb2() function in 
the COUNT package, or by using the gamlss function in the gamlss package, with 
&quot;family=NBI&quot; option.
</p>


<h3>Value</h3>

<table>
<tr><td><code>nby</code></td>
<td>
<p>Negative binomial response; number of counts</p>
</td></tr>
<tr><td><code>sim.data</code></td>
<td>
<p>synthetic data set</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Andrew Robinson, Universty of Melbourne, Australia, and
Joseph M. Hilbe, Arizona State University, 
Jet Propulsion Laboratory, California Institute of Technology 
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+poisson_syn">poisson_syn</a>, <a href="#topic+nb1_syn">nb1_syn</a></code>,   <code><a href="#topic+nbc_syn">nbc_syn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)           

sim.data &lt;- nb2_syn(nobs = 500, alpha = .5, xv = c(2, .75, -1.25))
mynb2 &lt;- glm.nb(nby ~ . , data = sim.data)
summary(mynb2)
confint(mynb2)

# with offset
oset &lt;- rep(1:5, each=100, times=1)*100 
loff &lt;- log(oset)   
sim.data &lt;- nb2_syn(nobs = 500, off = loff, alpha = .5, xv = c(1.2, -.75, .25, -1.3))
mypof &lt;- glm.nb(nby ~ . + loff, data = sim.data)
summary(mypof)
confint(mypof)

# without offset, exponentiated coefficients, CI's
sim.data &lt;- nb2_syn(nobs = 500, alpha = .75, xv = c(1, .5, -1.4))
mynbf &lt;- glm.nb(nby ~ . , data = sim.data)
exp(coef(mynbf))
exp(confint(mynbf))

## Not run: 
# default, without offset
sim.data &lt;- nb2_syn()
dnb2 &lt;- glm.nb(nby ~ . , data = sim.data)
summary(dnb2)

## End(Not run)

# use ml.nb2.r function
sim.data &lt;- nb2_syn(nobs = 500, alpha = .5, xv = c(2, .75, -1.25))
mynb2x &lt;- ml.nb2(nby ~ . , data = sim.data)
mynb2x

## Not run: 
# use gamlss function for modeling data after sim.data created
library(gamlss)
sim.data &lt;- nb2_syn(nobs = 500, alpha = .5, xv = c(2, .75, -1.25))
gamnb &lt;- gamlss(nby ~ ., family=NBI, data = sim.data)
gamnb

## End(Not run)
</code></pre>

<hr>
<h2 id='nb2.obs.pred'>
Table of negative binomial counts: observed vs predicted proportions and difference
</h2><span id='topic+nb2.obs.pred'></span>

<h3>Description</h3>

 
<p>nb2.obs.pred is used to produce a table of a negative binomial model count response with mean observed 
vs mean predicted proportions, and their difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb2.obs.pred(len, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nb2.obs.pred_+3A_len">len</code></td>
<td>
<p> highest count for the table</p>
</td></tr>
<tr><td><code id="nb2.obs.pred_+3A_model">model</code></td>
<td>
<p> name of the negative binomial model created</p>
</td></tr>
</table>


<h3>Details</h3>

<p>nb2.obs.pred is used to determine where disparities exist in the mean observed and predicted proportions 
in the range of model counts. nb2.obs.pred is used in Table 9.28 and other places in Hilbe (2011).
nb2.obs.pred follows glm.nb(), where both y=TRUE and model=TRUE options must be used. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Count</code></td>
<td>
<p>count value</p>
</td></tr>
<tr><td><code>obsPropFreq</code></td>
<td>
<p>Observed proportion of counts</p>
</td></tr>
<tr><td><code>avgp</code></td>
<td>
<p>Predicted proportion of counts</p>
</td></tr>
<tr><td><code>Diff</code></td>
<td>
<p>Difference in observed vs predicted</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
Andrew Robinson, University of Melbourne, Australia
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+myTable">myTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)

data(medpar)
mdpar &lt;- glm.nb(los ~ hmo+white+type2+type3, data=medpar, y=TRUE, model=TRUE)
nb2.obs.pred(len=25, model=mdpar)
</code></pre>

<hr>
<h2 id='nbc_syn'>
Negative binomial (NB-C): generic synthetic canonical negative binomial data and model
</h2><span id='topic+nbc_syn'></span>

<h3>Description</h3>

<p>nbc_syn is a generic function for developing synthetic NB-C data and a model given
user defined specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nbc_syn(nobs=50000, alpha=1.15, xv = c(-1.5, -1.25, -.1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nbc_syn_+3A_nobs">nobs</code></td>
<td>
<p>number of observations in model, Default is 50000</p>
</td></tr>
<tr><td><code id="nbc_syn_+3A_alpha">alpha</code></td>
<td>
<p>NB-C heterogeneity or ancillary parameter</p>
</td></tr>
<tr><td><code id="nbc_syn_+3A_xv">xv</code></td>
<td>
<p>predictor coefficient values. First argument is intercept. Use as
xv =  c(intercept , x1_coef, x2_coef, ...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create a synthetic canonial negative binomial (NB-C) regression model using the 
appropriate arguments. Model data with predictors indicated as a group with 
a period (.). Data can be modeled using the ml.nbc.r function in the COUNT 
package. See examples.
</p>


<h3>Value</h3>

<table>
<tr><td><code>nbcy</code></td>
<td>
<p>Canonical negative binomial (NB-C) response; number of counts</p>
</td></tr>
<tr><td><code>sim.data</code></td>
<td>
<p>synthetic data set</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
Andrew Robinson, Universty of Melbourne, Australia.
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nb2_syn">nb2_syn</a></code>,   <code><a href="#topic+nb1_syn">nb1_syn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
sim.data &lt;- nbc_syn(nobs = 50000, alpha = 1.15, xv = c(-1.5, -1.25, -.1))
mynbc &lt;- ml.nbc(nbcy ~ . , data = sim.data)
mynbc

# default
sim.data &lt;- nbc_syn()
dnbc &lt;- ml.nbc(nbcy ~ . , data = sim.data)
dnbc

## End(Not run)
</code></pre>

<hr>
<h2 id='nuts'>nuts</h2><span id='topic+nuts'></span>

<h3>Description</h3>

<p>Squirrel data set (nuts) from Zuur, Hilbe, and Ieno (2013).  As originally 
reported by Flaherty et al (2012), researchers recorded information about 
squirrel behavior and forest attributes across various plots in 
Scotland's Abernathy Forest. The study focused on the following variables.
response      cones	 number of cones stripped by red squirrels per plot
predictor  	sntrees  standardized number of trees per plot
sheight standardized mean tree height per plot
scover   standardized percentage of canopy cover per plot
The stripped cone count was only taken when the mean diameter of trees was under 0.6m (dbh). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nuts)</code></pre>


<h3>Format</h3>

<p>A data frame with 52 observations on the following 8 variables.
</p>

<dl>
<dt><code>cones</code></dt><dd><p>number cones stripped by squirrels</p>
</dd>
<dt><code>ntrees</code></dt><dd><p>number of trees per plot</p>
</dd>
<dt><code>dbh</code></dt><dd><p>number DBH per plot</p>
</dd>
<dt><code>height</code></dt><dd><p>mean tree height per plot</p>
</dd>
<dt><code>cover</code></dt><dd><p>canopy closure (as a percentage)</p>
</dd>
<dt><code>sntrees</code></dt><dd><p>standardized number of trees per plot</p>
</dd>
<dt><code>sheight</code></dt><dd><p>standardized mean tree height per plot</p>
</dd>
<dt><code>scover</code></dt><dd><p>standardized canopy closure (as a percentage)</p>
</dd>
</dl>



<h3>Details</h3>

<p>nuts is saved as a data frame.
Count models use ntrees as response variable. Counts start at 3  
</p>


<h3>Source</h3>

<p>Zuur, Hilbe, Ieno (2013), A Beginner's Guide to GLM and GLMM using R, Highlands
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
Zuur, Hilbe, Ieno (2013), A Beginner's Guide to GLM and GLMM using R, Highlands.
Flaherty, S et al (2012), &quot;The impact of forest stand structure on red 
squirrels habitat use&quot;, Forestry 85:437-444.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(nuts)
nut &lt;- subset(nuts, dbh &lt; 0.6)
# sntrees &lt;- scale(nuts$ntrees)
# sheigtht &lt;- scale(nuts$height)
# scover &lt;- scale(nuts$cover)
summary(PO &lt;- glm(cones ~ sntrees + sheight + scover, family=quasipoisson, data=nut))
</code></pre>

<hr>
<h2 id='poi.obs.pred'>
Table of Poisson counts: observed vs predicted proportions and difference
</h2><span id='topic+poi.obs.pred'></span>

<h3>Description</h3>

 
<p>poi.obs.pred is used to produce a table of a Poisson model count response with mean observed 
vs mean predicted proportions, and their difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poi.obs.pred(len, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poi.obs.pred_+3A_len">len</code></td>
<td>
<p> highest count for the table</p>
</td></tr>
<tr><td><code id="poi.obs.pred_+3A_model">model</code></td>
<td>
<p> name of the Poisson model created</p>
</td></tr>
</table>


<h3>Details</h3>

<p>poi.obs.pred is used to determine where disparities exist in the mean observed and predicted proportions 
in the range of model counts. poi.obs.pred is used in Table 6.15 and other places in Hilbe (2011).
poi.obs.pred follows glm(), where both y=TRUE and model=TRUE options must be used. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Count</code></td>
<td>
<p>count value</p>
</td></tr>
<tr><td><code>obsPropFreq</code></td>
<td>
<p>Observed proportion of counts</p>
</td></tr>
<tr><td><code>avgp</code></td>
<td>
<p>Predicted proportion of counts</p>
</td></tr>
<tr><td><code>Diff</code></td>
<td>
<p>Difference in observed vs predicted</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
Andrew Robinson, University of Melbourne, Australia
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+myTable">myTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(medpar)
mdpar &lt;- glm(los ~ hmo+white+type2+type3, family=poisson, data=medpar, y=TRUE, model=TRUE)
poi.obs.pred(len=25, model=mdpar)
</code></pre>

<hr>
<h2 id='poisson_syn'>
Poisson : generic synthetic Poisson data and model
</h2><span id='topic+poisson_syn'></span>

<h3>Description</h3>

<p>poisson_syn is a generic function for developing synthetic Poisson data and a model given
user defined specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisson_syn(nobs = 50000, off = 0, xv = c(1, -.5,  1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poisson_syn_+3A_nobs">nobs</code></td>
<td>
<p>number of observations in model, Default is 50000</p>
</td></tr>
<tr><td><code id="poisson_syn_+3A_off">off</code></td>
<td>
<p>optional: log of offset variable</p>
</td></tr>
<tr><td><code id="poisson_syn_+3A_xv">xv</code></td>
<td>
<p>predictor coefficient values. First argument is intercept. Use as xv =  c(intercept , x1_coef, x2_coef, ...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create a synthetic Poisson regression model using the appropriate arguments. 
Offset optional. Model data with predictors indicated as a group with a 
period (.).  See examples.
</p>


<h3>Value</h3>

<table>
<tr><td><code>py</code></td>
<td>
<p>Poisson response; number of counts</p>
</td></tr>
<tr><td><code>sim.data</code></td>
<td>
<p>synthetic data set</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
Andrew Robinson, Universty of Melbourne, Australia.
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nb2_syn">nb2_syn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# standard Poisson model with two predictors and intercept
sim.data &lt;- poisson_syn(nobs = 500, xv = c(2, .75, -1.25))
mypo &lt;- glm(py ~ . , family=poisson, data = sim.data)
summary(mypo)
confint(mypo)

# Poisson with offset and three predictors
oset &lt;- rep(1:5, each=100, times=1)*100 
loff &lt;- log(oset)   
sim.data &lt;- poisson_syn(nobs = 500, off = loff, xv = c(1.2, -.75, .25, -1.3))
mypof &lt;- glm(py ~ . + loff, family=poisson, data = sim.data)
summary(mypof)
confint(mypof)

# Poisson without offset, exponentiated coefficients, CI's
sim.data &lt;- poisson_syn(nobs = 500, xv = c(2, .75, -1.25))
mypo &lt;- glm(py ~ . , family=poisson, data = sim.data)
exp(coef(mypo))
exp(confint(mypo))

## Not run: 
# default (without offset)
sim.data &lt;- poisson_syn()
dmypo &lt;- glm( py ~ . , family=poisson, data = sim.data)
summary(dmypo)

## End(Not run)

</code></pre>

<hr>
<h2 id='probit_syn'>
Probit regression : generic synthetic binary/binomial probit data and model
</h2><span id='topic+probit_syn'></span>

<h3>Description</h3>

<p>probit_syn is a generic function for developing synthetic probit regression data and 
a model given user defined specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probit_syn(nobs=50000, d=1,  xv = c(1, 0.5, -1.5))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probit_syn_+3A_nobs">nobs</code></td>
<td>
<p>number of observations in model, Default is 50000</p>
</td></tr>
<tr><td><code id="probit_syn_+3A_d">d</code></td>
<td>
<p>binomial denominator, Default is 1, a binary probit model. May 
use a variable containing different denominator values.</p>
</td></tr> 
<tr><td><code id="probit_syn_+3A_xv">xv</code></td>
<td>
<p>predictor coefficient values. First argument is intercept. Use as
xv =  c(intercept , x1_coef, x2_coef, ...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create a synthetic probit regression model using the appropriate arguments. 
Binomial denominator must be declared. For a binary probit model, d=1. A 
variable may be used as the denominator when values differ. See examples.
</p>


<h3>Value</h3>

<table>
<tr><td><code>py</code></td>
<td>
<p>binomial probit numerator; number of successes</p>
</td></tr>
<tr><td><code>sim.data</code></td>
<td>
<p>synthetic data set</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Joseph M. Hilbe, Arizona State University, and 
Jet Propulsion Laboratory, California Institute of Technology 
Andrew Robinson, Universty of Melbourne, Australia.
</p>


<h3>References</h3>

<p>Hilbe, J.M. (2011), Negative Binomial Regression, second edition, Cambridge University Press. 
Hilbe, J.M. (2009), Logistic Regression Models, Chapman &amp; Hall/CRCD
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logit_syn">logit_syn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Binary probit regression (denominator=1)
sim.data &lt;-probit_syn(nobs = 5000, d = 1, xv = c(1, .5, -1.5))
myprobit &lt;- glm(cbind(py,dpy) ~ ., family=binomial(link="probit"), data = sim.data)
summary(myprobit)
confint(myprobit)

# Binary probit regression with 3 predictors (denominator=1)
sim.data &lt;-probit_syn(nobs = 5000, d = 1, xv = c(1, .75, -1.5, 1.15))
myprobit &lt;- glm(cbind(py,dpy) ~ ., family=binomial(link="probit"), data = sim.data)
summary(myprobit)
confint(myprobit)

# Binomial or grouped probit regression with defined denominator, den
den &lt;- rep(1:5, each=1000, times=1)*100
sim.data &lt;- probit_syn(nobs = 5000, d = den, xv = c(1, .5, -1.5))
gpy &lt;- glm(cbind(py,dpy) ~ ., family=binomial(link="probit"), data = sim.data)
summary(gpy)

## Not run: 
# default
sim.data &lt;- probit_syn()
dprobit &lt;- glm(cbind(py,dpy) ~ . , family=binomial(link="probit"), data = sim.data)
summary(dprobit)

## End(Not run)

</code></pre>

<hr>
<h2 id='rwm'>rwm</h2><span id='topic+rwm'></span>

<h3>Description</h3>

<p>German health registry for the years 1984-1988. Health information for 
years prior to health reform. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rwm)</code></pre>


<h3>Format</h3>

<p>A data frame with 27,326 observations on the following 4 variables.
</p>

<dl>
<dt><code>docvis</code></dt><dd><p>number of visits to doctor during year (0-121)</p>
</dd>
<dt><code>age</code></dt><dd><p>age: 25-64</p>
</dd>
<dt><code>educ</code></dt><dd><p>years of formal education (7-18)</p>
</dd>
<dt><code>hhninc</code></dt><dd><p>household yearly income in DM/1000)</p>
</dd>
</dl>



<h3>Details</h3>

<p>rwm is saved as a data frame.
Count models typically use docvis as response variable. 0 counts are included
</p>


<h3>Source</h3>

<p>German Health Reform Registry, years pre-reform 1984-1988, 
From Hilbe and Greene (2008)
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press
Hilbe, J.M. and W.H. Greene (2008), &quot;Count Response Regression Models&quot;, in Rao, CR, 
JP Miller and DC Rao (eds), Handbook of Statistics 27: Epidemiology and Medical 
Statistics, Amsterdam: Elsevier.  pp. 210-252.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rwm)
glmrwp &lt;- glm(docvis ~ age + educ + hhninc, family=poisson, data=rwm)
summary(glmrwp)
exp(coef(glmrwp))
library(MASS)
glmrwnb &lt;- glm.nb(docvis ~ age + educ + hhninc, data=rwm)
summary(glmrwnb)
exp(coef(glmrwnb))
</code></pre>

<hr>
<h2 id='rwm1984'>rwm1984</h2><span id='topic+rwm1984'></span>

<h3>Description</h3>

<p>German health registry for the year 1984. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rwm1984)</code></pre>


<h3>Format</h3>

<p>A data frame with 3,874 observations on the following 17 variables.
</p>

<dl>
<dt><code>docvis</code></dt><dd><p>number of visits to doctor during year (0-121)</p>
</dd>
<dt><code>hospvis</code></dt><dd><p>number of days in hospital during year (0-51)</p>
</dd>

<dt><code>edlevel</code></dt><dd><p>educational level (categorical: 1-4)</p>
</dd>
<dt><code>age</code></dt><dd><p>age: 25-64</p>
</dd>
<dt><code>outwork</code></dt><dd><p>out of work=1; 0=working</p>
</dd>
<dt><code>female</code></dt><dd><p>female=1; 0=male</p>
</dd>
<dt><code>married</code></dt><dd><p>married=1; 0=not married</p>
</dd>
<dt><code>kids</code></dt><dd><p>have children=1; no children=0</p>
</dd>
<dt><code>hhninc</code></dt><dd><p>household yearly income in marks (in Marks)</p>
</dd>
<dt><code>educ</code></dt><dd><p>years of formal education (7-18)</p>
</dd>
<dt><code>self</code></dt><dd><p>self-employed=1; not self employed=0</p>
</dd>
<dt><code>edlevel1</code></dt><dd><p>(1/0) not high school graduate</p>
</dd>
<dt><code>edlevel2</code></dt><dd><p>(1/0) high school graduate</p>
</dd>
<dt><code>edlevel3</code></dt><dd><p>(1/0) university/college</p>
</dd> 
<dt><code>edlevel4</code></dt><dd><p>(1/0) graduate school</p>
</dd>
</dl>



<h3>Details</h3>

<p>rwm1984 is saved as a data frame.
Count models typically use docvis as response variable. 0 counts are included
</p>


<h3>Source</h3>

<p>German Health Reform Registry, year=1984, in Hilbe and Greene (2007)
</p>


<h3>References</h3>

<p>Hilbe, Joseph, M (2014), Modeling Count Data, Cambridge University Press
Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press
Hilbe, J. and W. Greene (2008). Count Response Regression Models, in ed. 
C.R. Rao, J.P Miller, and D.C. Rao, Epidemiology and Medical Statistics, 
Elsevier Handbook of  Statistics Series. London, UK: Elsevier.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
library(msme)
data(rwm1984)

glmrp &lt;- glm(docvis ~ outwork + female + age + factor(edlevel), family=poisson, data=rwm1984)
summary(glmrp)
exp(coef(glmrp))

summary(nb2 &lt;- nbinomial(docvis ~ outwork + female + age + factor(edlevel), data=rwm1984))
exp(coef(nb2))

summary(glmrnb &lt;- glm.nb(docvis ~ outwork + female + age + factor(edlevel), data=rwm1984))
exp(coef(glmrnb))
</code></pre>

<hr>
<h2 id='rwm5yr'>rwm5yr</h2><span id='topic+rwm5yr'></span>

<h3>Description</h3>

<p>German health registry for the years 1984-1988. Health 
information for years immediately prior to health reform. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rwm5yr)</code></pre>


<h3>Format</h3>

<p>A data frame with 19,609 observations on the following 17 variables.
</p>

<dl>
<dt><code>id</code></dt><dd><p>patient ID  (1=7028)</p>
</dd>
<dt><code>docvis</code></dt><dd><p>number of visits to doctor during year (0-121)</p>
</dd>
<dt><code>hospvis</code></dt><dd><p>number of days in hospital during year (0-51)</p>
</dd>
<dt><code>year</code></dt><dd><p>year; (categorical: 1984, 1985, 1986, 1987, 1988)</p>
</dd>
<dt><code>edlevel</code></dt><dd><p>educational level (categorical: 1-4)</p>
</dd>
<dt><code>age</code></dt><dd><p>age: 25-64</p>
</dd>
<dt><code>outwork</code></dt><dd><p>out of work=1; 0=working</p>
</dd>
<dt><code>female</code></dt><dd><p>female=1; 0=male</p>
</dd>
<dt><code>married</code></dt><dd><p>married=1; 0=not married</p>
</dd>
<dt><code>kids</code></dt><dd><p>have children=1; no children=0</p>
</dd>
<dt><code>hhninc</code></dt><dd><p>household yearly income in marks (in Marks)</p>
</dd>
<dt><code>educ</code></dt><dd><p>years of formal education (7-18)</p>
</dd>
<dt><code>self</code></dt><dd><p>self-employed=1; not self employed=0</p>
</dd>
<dt><code>edlevel1</code></dt><dd><p>(1/0) not high school graduate</p>
</dd>
<dt><code>edlevel2</code></dt><dd><p>(1/0) high school graduate</p>
</dd>
<dt><code>edlevel3</code></dt><dd><p>(1/0) university/college</p>
</dd> 
<dt><code>edlevel4</code></dt><dd><p>(1/0) graduate school</p>
</dd>
</dl>



<h3>Details</h3>

<p>rwm5yr is saved as a data frame.
Count models typically use docvis as response variable. 0 counts are included
</p>


<h3>Source</h3>

<p>German Health Reform Registry, years pre-reform 1984-1988, in Hilbe and Greene (2007)
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press
Hilbe, J. and W. Greene (2008). Count Response Regression Models, in ed. 
C.R. Rao, J.P Miller, and D.C. Rao, Epidemiology and Medical Statistics, 
Elsevier Handbook of  Statistics Series. London, UK: Elsevier.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
data(rwm5yr)

glmrp &lt;- glm(docvis ~ outwork + female + age + factor(edlevel), family=poisson, data=rwm5yr)
summary(glmrp)
exp(coef(glmrp))

## Not run: 
library(msme)
nb2 &lt;- nbinomial(docvis ~ outwork + female + age + factor(edlevel), data=rwm5yr)
summary(nb2)
exp(coef(nb2)) 

glmrnb &lt;- glm.nb(docvis ~ outwork + female + age + factor(edlevel), data=rwm5yr)
summary(glmrnb)
exp(coef(glmrnb))

## End(Not run)
</code></pre>

<hr>
<h2 id='ships'>ships</h2><span id='topic+ships'></span>

<h3>Description</h3>

<p>Data set used in McCullagh &amp; Nelder (1989), Hardin &amp; Hilbe (2003), 
and other sources. The data contains values on the number of reported 
accidents for ships belonging to a company over a given time period. 
When a ship was constructed is also recorded. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ships)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 7 variables.
</p>

<dl>
<dt><code>accident</code></dt><dd><p>number of shipping accidents</p>
</dd>
<dt><code>op</code></dt><dd><p>1=ship operated 1975-1979;0=1965-74</p>
</dd>
<dt><code>co.65.69</code></dt><dd><p>ship was in construction 1965-1969 (1/0)</p>
</dd>
<dt><code>co.70.74</code></dt><dd><p>ship was in construction 1970-1974 (1/0)</p>
</dd>
<dt><code>co.75.79</code></dt><dd><p>ship was in construction 1975-1979 (1/0)</p>
</dd>
<dt><code>service</code></dt><dd><p>months in service</p>
</dd>
<dt><code>ship</code></dt><dd><p>ship identification : 1-5</p>
</dd>
</dl>



<h3>Details</h3>

<p>ships is saved as a data frame.
Count models use accident as the response variable, with log(service) as the 
offset. ship can be used as a panel identifier.  
</p>


<h3>Source</h3>

<p>McCullagh and Nelder, 1989.
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
Hardin, JW and JM Hilbe (2001, 2007), Generalized Linear Models and Extensions, Stata Press
McCullagh, P.A, and J. Nelder (1989), Generalized Linear Models, Chapman &amp; Hall
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ships)
glmshp &lt;- glm(accident ~ op + co.70.74 + co.75.79 + offset(log(service)),
              family=poisson, data=ships)
summary(glmshp)
exp(coef(glmshp))
library(MASS)
glmshnb &lt;- glm.nb(accident ~ op + co.70.74 + co.75.79 + offset(log(service)),
                   data=ships)
summary(glmshnb)
exp(coef(glmshnb))
## Not run: 
library(gee)
shipgee &lt;- gee(accident ~ op + co.70.74 + co.75.79 + offset(log(service)),
              data=ships, family=poisson, corstr="exchangeable", id=ship)
summary(shipgee)

## End(Not run)
</code></pre>

<hr>
<h2 id='smoking'>smoking</h2><span id='topic+smoking'></span>

<h3>Description</h3>

<p>A simple data set with only 6 observations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(smoking)</code></pre>


<h3>Format</h3>

<p>A data frame with 6 observations on the following 4 variables.
</p>

<dl>
<dt><code>sbp</code></dt><dd><p>systolic blood pressure of subject</p>
</dd>
<dt><code>male</code></dt><dd><p>1=male; 0=female</p>
</dd>
<dt><code>smoker</code></dt><dd><p>1=hist of smoking; 0= no hist of smoking</p>
</dd>
<dt><code>age</code></dt><dd><p>age of subject</p>
</dd>
</dl>



<h3>Details</h3>

<p>smoking is saved as a data frame.
</p>


<h3>Source</h3>

<p>none 
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sbp    &lt;- c(131,132,122,119,123,115)
male   &lt;- c(1,1,1,0,0,0)
smoker &lt;- c(1,1,0,0,1,0)
age    &lt;- c(34,36,30,32,26,23)
summary(reg1 &lt;- lm(sbp~ male+smoker+age))
</code></pre>

<hr>
<h2 id='titanic'>titanic</h2><span id='topic+titanic'></span>

<h3>Description</h3>

<p>The data is an observation-based version of the 1912 Titanic passenger survival 
log, 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(titanic)</code></pre>


<h3>Format</h3>

<p>A data frame with 1316 observations on the following 4 variables.
</p>

<dl>
<dt><code>class</code></dt><dd><p>a factor with levels <code>1st class</code> <code>2nd class</code> <code>3rd class</code> <code>crew</code></p>
</dd>
<dt><code>age</code></dt><dd><p>a factor with levels <code>child</code> <code>adults</code></p>
</dd>
<dt><code>sex</code></dt><dd><p>a factor with levels <code>women</code> <code>man</code></p>
</dd>
<dt><code>survived</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>titanic is saved as a data frame.
Used to assess risk ratios   
</p>


<h3>Source</h3>

<p>Found in many other texts
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(titanic)
titanic$survival &lt;- titanic$survived == "yes"
glmlr &lt;- glm(survival ~ age + sex + factor(class), family=binomial, data=titanic)
summary(glmlr)

</code></pre>

<hr>
<h2 id='titanicgrp'>titanicgrp</h2><span id='topic+titanicgrp'></span>

<h3>Description</h3>

<p>The data is an grouped version of the 1912 Titanic passenger survival 
log, 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(titanicgrp)</code></pre>


<h3>Format</h3>

<p>A data frame with 12 observations on the following 5 variables.
</p>

<dl>
<dt><code>survive</code></dt><dd><p>number of passengers who survived</p>
</dd>
<dt><code>cases</code></dt><dd><p>number of passengers with same pattern of covariates</p>
</dd>
<dt><code>age</code></dt><dd><p>1=adult; 0=child</p>
</dd>
<dt><code>sex</code></dt><dd><p>1=Male; 0=female</p>
</dd>
<dt><code>class</code></dt><dd><p>ticket class 1= 1st class; 2= second class; 3= third class</p>
</dd>
</dl>



<h3>Details</h3>

<p>titanicgrp is saved as a data frame.
Used to assess risk ratios   
</p>


<h3>Source</h3>

<p>Found in many other texts
</p>


<h3>References</h3>

<p>Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press
Hilbe, Joseph M (2009), Logistic Regression Models, Chapman &amp; Hall/CRC
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
library(msme)
data(titanicgrp)
glmlr &lt;- glm(survive ~ age + sex + factor(class) + offset(log(cases)),
             family=poisson, data=titanicgrp)
summary(glmlr)
exp(coef(glmlr))

lcases &lt;- titanicgrp$cases
nb2o &lt;- nbinomial(survive ~ age + sex + factor(class), 
                                        formula2 =~ age + sex,
                                        offset = lcases,
                                        mean.link="log",
                                        scale.link="log_s",
                                        data=titanicgrp)
summary(nb2o)
exp(coef(nb2o))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
