<!DOCTYPE html><html><head><title>Help for package fmcmc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fmcmc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#append_chains'><p>Append MCMC chains (objects of class coda::mcmc)</p></a></li>
<li><a href='#check_initial'><p>Checks the initial values of the MCMC</p></a></li>
<li><a href='#convergence-checker'><p>Convergence Monitoring</p></a></li>
<li><a href='#cov_recursive'><p>Recursive algorithms for computing variance and mean</p></a></li>
<li><a href='#fmcmc'><p>A friendly MCMC framework</p></a></li>
<li><a href='#fmcmc-deprecated'><p>Deprecated methods in fmcmc</p></a></li>
<li><a href='#kernel_adapt'><p>Adaptive Metropolis (AM) Transition Kernel</p></a></li>
<li><a href='#kernel_mirror'><p>Mirror Transition Kernels</p></a></li>
<li><a href='#kernel_new'><p>Transition Kernels for MCMC</p></a></li>
<li><a href='#kernel_normal'><p>Gaussian Transition Kernel</p></a></li>
<li><a href='#kernel_ram'><p>Robust Adaptive Metropolis (RAM) Transition Kernel</p></a></li>
<li><a href='#kernel_unif'><p>Uniform Transition Kernel</p></a></li>
<li><a href='#lifeexpect'><p>Life expectancy in the US (2020)</p></a></li>
<li><a href='#MCMC'><p>Markov Chain Monte Carlo</p></a></li>
<li><a href='#mcmc-loop'><p>Functions to interact with the main loop</p></a></li>
<li><a href='#mcmc-output'><p>Information about the last <code>MCMC</code> call</p></a></li>
<li><a href='#new_progress_bar'><p>Progress bar</p></a></li>
<li><a href='#plan_update_sequence'><p>Parameters' update sequence</p></a></li>
<li><a href='#reflect_on_boundaries'><p>Reflective Boundaries</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>A friendly MCMC framework</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-29</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a friendly (flexible) Markov Chain Monte Carlo (MCMC)
         framework for implementing Metropolis-Hastings algorithm in a modular way
         allowing users to specify automatic convergence checker, personalized
         transition kernels, and out-of-the-box multiple MCMC chains using
         parallel computing. Most of the methods implemented in this package can
         be found in Brooks et al. (2011, ISBN 9781420079425). Among the methods
         included, we have: Haario (2001) &lt;<a href="https://doi.org/10.1007%2Fs11222-011-9269-5">doi:10.1007/s11222-011-9269-5</a>&gt;
         Adaptive Metropolis, Vihola (2012) &lt;<a href="https://doi.org/10.1007%2Fs11222-011-9269-5">doi:10.1007/s11222-011-9269-5</a>&gt;
         Robust Adaptive Metropolis, and Thawornwattana et
         al. (2018) &lt;<a href="https://doi.org/10.1214%2F17-BA1084">doi:10.1214/17-BA1084</a>&gt; Mirror transition kernels.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/USCbiostats/fmcmc">https://github.com/USCbiostats/fmcmc</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/USCbiostats/fmcmc/issues">https://github.com/USCbiostats/fmcmc/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, knitr, rmarkdown, mcmc, tinytest, mvtnorm,</td>
</tr>
<tr>
<td>Imports:</td>
<td>parallel, coda, stats, methods, MASS, Matrix</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-29 23:20:58 UTC; george</td>
</tr>
<tr>
<td>Author:</td>
<td>George Vega Yon <a href="https://orcid.org/0000-0002-3171-0844"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Paul Marjoram <a href="https://orcid.org/0000-0003-0824-7449"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb, ths],
  National Cancer Institute (NCI) [fnd] (Grant Number 5P01CA196569-02),
  Fabian Scheipl <a href="https://orcid.org/0000-0001-8172-3603"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [rev] (JOSS reviewer)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>George Vega Yon &lt;g.vegayon@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-29 23:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='append_chains'>Append MCMC chains (objects of class <a href="coda.html#topic+mcmc">coda::mcmc</a>)</h2><span id='topic+append_chains'></span>

<h3>Description</h3>

<p>Combines two or more MCMC runs into a single run. If runs have
multiple chains, it will check that all have the same number of chains, and
it will join chains using the <a href="base.html#topic+rbind">rbind</a> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>append_chains(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="append_chains_+3A_...">...</code></td>
<td>
<p>A list of <code>mcmc</code> or <code>mcmc.list</code> class objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>mcmc.list</code>, an object of class <code>mcmc.list</code>, otherwise,
an object of class <code>mcmc</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Appending two chains
data("lifeexpect")
logpost &lt;- function(p) {
  sum(with(lifeexpect, dnorm(
    age - p[1] - smoke * p[2] - female * p[3],
    sd = p[4], log = TRUE)
  ))
}

# Using the RAM kernel
kern &lt;- kernel_ram(lb = c(-100, -100, -100, .00001))

init &lt;- c(
  avg_age = 70,
  smoke   = 0,
  female  = 0,
  sd      = 1
)

ans0 &lt;- MCMC(initial = init, fun = logpost, nsteps = 1000, seed = 22, kernel = kern)
ans1 &lt;- MCMC(initial = ans0, fun = logpost, nsteps = 2000, seed = 55, kernel = kern)
ans2 &lt;- MCMC(initial = ans1, fun = logpost, nsteps = 2000, seed = 1155, kernel = kern)
ans_tot &lt;- append_chains(ans0, ans1, ans2)

# Looking at the posterior distributions (see ?lifeexpect for info about
# the model). Only the trace
op &lt;- par(mfrow = c(2,2))
for (i in 1:4)
  coda::traceplot(ans_tot[, i, drop=FALSE])
par(op)


</code></pre>

<hr>
<h2 id='check_initial'>Checks the initial values of the MCMC</h2><span id='topic+check_initial'></span>

<h3>Description</h3>

<p>This function is for internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_initial(initial, nchains)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_initial_+3A_initial">initial</code></td>
<td>
<p>Either a vector or matrix,.</p>
</td></tr>
<tr><td><code id="check_initial_+3A_nchains">nchains</code></td>
<td>
<p>Integer scalar. Number of chains.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>initial</code> is a vector, the values are recycled to form a matrix of
size <code>nchains * length(initial)</code>.
</p>


<h3>Value</h3>

<p>A named matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>init &lt;- c(.4, .1)
check_initial(init, 1)
check_initial(init, 2)

init &lt;- matrix(1:9, ncol=3)
check_initial(init, 3)

# check_initial(init, 2) # Returns an error

</code></pre>

<hr>
<h2 id='convergence-checker'>Convergence Monitoring</h2><span id='topic+convergence-checker'></span><span id='topic+automatic-stop'></span><span id='topic+LAST_CONV_CHECK'></span><span id='topic+convergence_data_set'></span><span id='topic+convergence_data_get'></span><span id='topic+convergence_msg_set'></span><span id='topic+convergence_msg_get'></span><span id='topic+convergence_gelman'></span><span id='topic+convergence_geweke'></span><span id='topic+convergence_heildel'></span><span id='topic+convergence_auto'></span>

<h3>Description</h3>

<p>Built-in set of functions to be used in companion with the argument
<code>conv_checker</code> in <a href="#topic+MCMC">MCMC</a>. These functions are not intended to be used
in a context other than the <code>MCMC</code> function.
</p>
<p>The object <code>LAST_CONV_CHECK</code> is an environment that holds
information regarding the convergence checker used. This information can be
updated every time that the <code>conv_checker</code> function is called by <code>MCMC</code> using
the functions <code>convergence_data_set</code> and <code>convergence_msg_set</code>. The function
<code>convergence_data_get</code> is just a wrapper of <code><a href="base.html#topic+get">get()</a></code>.
</p>
<p>The <code>msg</code> member of <code>LAST_CONV_CHECK</code> is resetted before <code>conv_checker</code> is
called.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LAST_CONV_CHECK

convergence_data_set(x)

convergence_data_get(x)

convergence_msg_set(msg = NA_character_)

convergence_msg_get()

convergence_gelman(freq = 1000L, threshold = 1.1, check_invariant = TRUE, ...)

convergence_geweke(
  freq = 1000L,
  threshold = 0.025,
  check_invariant = TRUE,
  ...
)

convergence_heildel(freq = 1000L, ..., check_invariant = TRUE)

convergence_auto(freq = 1000L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convergence-checker_+3A_x">x</code></td>
<td>
<p>In the case of <code>convergence_data_set</code>, a named list. For
<code>convergence_data_get</code>, a character vector.</p>
</td></tr>
<tr><td><code id="convergence-checker_+3A_msg">msg</code></td>
<td>
<p>Character scalar. Personalized message to print.</p>
</td></tr>
<tr><td><code id="convergence-checker_+3A_freq">freq</code></td>
<td>
<p>Integer scalar. Frequency of checking.</p>
</td></tr>
<tr><td><code id="convergence-checker_+3A_threshold">threshold</code></td>
<td>
<p>Numeric value. A Gelman statistic below the threshold
will return <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="convergence-checker_+3A_check_invariant">check_invariant</code></td>
<td>
<p>Logical. When <code>TRUE</code> the function only computes
the Gelman diagnostic using variables with greater than <code>1e-10</code> variance.</p>
</td></tr>
<tr><td><code id="convergence-checker_+3A_...">...</code></td>
<td>
<p>Further arguments passed to the method.</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>fmcmc_output_conv_check</code> (inherits from <code>environment</code>) of length 1.
</p>


<h3>Details</h3>

<p><code>convergence_gelman</code> is a wrapper of <code><a href="coda.html#topic+gelman.diag">coda::gelman.diag()</a></code>.
</p>
<p>In the case of <code>convergence_geweke</code>, <code>threshold</code> sets the p-value
for the null <code class="reqn">H_0: Z = 0</code>, i.e. equal means between the first and last
chunks of the chain. See <a href="coda.html#topic+geweke.diag">coda::geweke.diag</a>. This implies that the higher
the threshold, the lower the probability of stopping the chain.
</p>
<p>In the case that the chain has more than one parameter, the algorithm will
return true if and only if the test fails to reject the null for all the
parameters.
</p>
<p>For the <code>convergence_heildel</code>, see <a href="coda.html#topic+heidel.diag">coda::heidel.diag</a> for details.
</p>
<p>The <code>convergence_auto</code> function is the default and is just a wrapper
for <code>convergence_gelman</code> and <code>convergence_geweke</code>. This function returns a
convergence checker that will be either of the other two depending on whether
<code>nchains</code> in <code>MCMC</code> is greater than one&ndash;in which case it will use the Gelman
test&ndash;or not&ndash;in which case it will use the Geweke test.
</p>


<h3>Value</h3>

<p>A function passed to <a href="#topic+MCMC">MCMC</a> to check automatic convergence.
</p>


<h3>Building a convergence checker</h3>

<p>Convergence checkers are simply a function that receives as argument a matrix
(or list of them) with sampled values, and returns a logical scalar with the
value <code>TRUE</code> if the chain converged. An example of a personalized convergence
checker is provided below. The frequency with which the check is performed is
retrieved from the attribute <code>"freq"</code> from the convergence checker function,
i.e., <code>attr(..., "freq")</code>. If missing, convergence will be checked halfway
the number of steps in the chain, i.e., <code>floor(nsteps/2)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Presonalized conv checker --------------------------------------
# Dummy rule, if acceptance rate is near between .2 and .3.
convergence_example &lt;- function(x) {
  arate &lt;- 1 - coda::rejectionRate(x)
  all(
    abs(arate - .25) &lt; .05
  )
}

# Tell fmcmc::MCMC what is the frequency
attr(convergence_example, "freq") &lt;- 2e3

set.seed(223)
x &lt;- rnorm(1000)
y &lt;- x * 2 + rnorm(1000)
logpost &lt;- function(p) {
  sum(dnorm(y, mean = x * p, log = TRUE))
}

ans &lt;- MCMC(
  initial = 0, fun = logpost, nsteps = 5e4,
  kernel= kernel_ram(),
  conv_checker = convergence_example
)

# Example 2: Adding information ---------------------------------------------
# Here we do two things: Save a value and set a message for the user
convergence_example_with_info &lt;- structure(function(x) {
  arate &lt;- 1 - coda::rejectionRate(x)
  
  # Saving a value
  if (!exists("arates", envir = LAST_CONV_CHECK, inherits = FALSE)) {
    convergence_data_set(list(arates = arate))
  } else {
    convergence_data_set(list(
      arates = rbind(convergence_data_get("arates"), arate)
    ))
  }
  
  # Setting up the message
  convergence_msg_set(
    sprintf("Current Avg. Accept. Rate: %.2f", mean(arate))
  )
  
  all(
    abs(arate - .25) &lt; .05
  )
}, freq = 2000)


ans &lt;- MCMC(
  initial = 0, fun = logpost, nsteps = 5e4,
  kernel= kernel_ram(),
  conv_checker = convergence_example_with_info,
  seed = 112,
  progress = FALSE
)
</code></pre>

<hr>
<h2 id='cov_recursive'>Recursive algorithms for computing variance and mean</h2><span id='topic+cov_recursive'></span><span id='topic+mean_recursive'></span>

<h3>Description</h3>

<p>These algorithms are used in <code><a href="#topic+kernel_adapt">kernel_adapt()</a></code> to simplify variance-covariance
recalculation at every step of the algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_recursive(
  X_t,
  Cov_t,
  Mean_t_prev,
  t.,
  Mean_t = NULL,
  eps = 0,
  Sd = 1,
  Ik = diag(ncol(Cov_t))
)

mean_recursive(X_t, Mean_t_prev, t.)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cov_recursive_+3A_x_t">X_t</code></td>
<td>
<p>Last value of the sample</p>
</td></tr>
<tr><td><code id="cov_recursive_+3A_cov_t">Cov_t</code></td>
<td>
<p>Covariance in t</p>
</td></tr>
<tr><td><code id="cov_recursive_+3A_t.">t.</code></td>
<td>
<p>Sample size up to <code>t-1</code>.</p>
</td></tr>
<tr><td><code id="cov_recursive_+3A_mean_t">Mean_t</code>, <code id="cov_recursive_+3A_mean_t_prev">Mean_t_prev</code></td>
<td>
<p>Vectors of averages in time <code>t</code> and <code>t-1</code> respectively.</p>
</td></tr>
<tr><td><code id="cov_recursive_+3A_sd">Sd</code>, <code id="cov_recursive_+3A_eps">eps</code>, <code id="cov_recursive_+3A_ik">Ik</code></td>
<td>
<p>See <code><a href="#topic+kernel_adapt">kernel_adapt()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance covariance algorithm was described in Haario, Saksman and
Tamminen (2002).
</p>


<h3>References</h3>

<p>Haario, H., Saksman, E., &amp; Tamminen, J. (2001). An adaptive Metropolis algorithm.
Bernoulli, 7(2), 223–242.
<a href="https://projecteuclid.org/euclid.bj/1080222083">https://projecteuclid.org/euclid.bj/1080222083</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generating random data (only four points to see the difference)
set.seed(1231)
n &lt;- 3
X &lt;- matrix(rnorm(n*4), ncol = 4)

# These two should be equal
mean_recursive(
  X_t         = X[1,],
  Mean_t_prev = colMeans(X[-1,]),
  t.          = n - 1
)
colMeans(X)

# These two should be equal
cov_recursive(
  X_t         = X[1, ], 
  Cov_t       = cov(X[-1,]), 
  Mean_t      = colMeans(X),
  Mean_t_prev = colMeans(X[-1, ]),
  t           = n-1
)
cov(X)

# Speed example -------------------------------------------------------------
set.seed(13155511)
X &lt;- matrix(rnorm(1e3*100), ncol = 100)

ans0 &lt;- cov(X[-1,])
t0 &lt;- system.time({
  ans1 &lt;- cov(X)
})

t1 &lt;- system.time(ans2 &lt;- cov_recursive(
  X[1, ], ans0,
  Mean_t      = colMeans(X),
  Mean_t_prev = colMeans(X[-1,]),
  t. = 1e3 - 1
))

# Comparing accuracy and speed
range(ans1 - ans2)
t0/t1

</code></pre>

<hr>
<h2 id='fmcmc'>A friendly MCMC framework</h2><span id='topic+fmcmc'></span><span id='topic+fmcmc-package'></span>

<h3>Description</h3>

<p>The <code>fmcmc</code> package provides a flexible framework for implementing MCMC models
using a lightweight in terms of dependencies. Among its main features, <code>fmcmc</code>
allows:
</p>


<h3>Details</h3>


<ul>
<li><p> Implementing arbitrary transition kernels.
</p>
</li>
<li><p> Incorporating convergence monitors for automatic stop.
</p>
</li>
<li><p> Out-of-the-box parallel computing implementation for running multiple chains
simultaneously.
</p>
</li></ul>

<p>For more information see the packages vignettes:
</p>
<div class="sourceCode"><pre>vignette("workflow-with-fmcmc", "fmcmc")

vignette("user-defined-kernels", "fmcmc")
</pre></div>


<h3>References</h3>

<p>Vega Yon et al., (2019). fmcmc: A friendly MCMC framework. Journal of Open
Source Software, 4(39), 1427, <a href="https://doi.org/10.21105/joss.01427">doi:10.21105/joss.01427</a>
</p>

<hr>
<h2 id='fmcmc-deprecated'>Deprecated methods in fmcmc</h2><span id='topic+fmcmc-deprecated'></span><span id='topic+last_elapsed'></span><span id='topic+LAST_MCMC'></span><span id='topic+last_nsteps'></span><span id='topic+last_nchains'></span><span id='topic+last_kernel'></span><span id='topic+last_conv_checker'></span><span id='topic+last_'></span>

<h3>Description</h3>

<p>These functions will no longer be included starting version 0.6-0. Instead,
use the functions in <a href="#topic+mcmc-output">mcmc-output</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>last_elapsed()

LAST_MCMC

last_nsteps()

last_nchains()

last_kernel()

last_conv_checker()

last_(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fmcmc-deprecated_+3A_x">x</code></td>
<td>
<p>Name of the object to retrieve.</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>fmcmc_last_mcmc</code> of length 0.
</p>


<h3>Value</h3>

<p>The function <code>last_elapsed</code> returns the elapsed time of the last call
to <a href="#topic+MCMC">MCMC</a>. In particular, the <code>MCMC</code> function records the running time of R
at the beginning and end of the function using <code><a href="base.html#topic+proc.time">proc.time()</a></code>. So this function
returns the difference between the two (<code>time_end - time_start</code>).
</p>

<hr>
<h2 id='kernel_adapt'>Adaptive Metropolis (AM) Transition Kernel</h2><span id='topic+kernel_adapt'></span><span id='topic+kernel_am'></span>

<h3>Description</h3>

<p>Implementation of Haario et al. (2001)'s Adaptive Metropolis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel_adapt(
  mu = 0,
  bw = 0L,
  lb = -.Machine$double.xmax,
  ub = .Machine$double.xmax,
  freq = 1L,
  warmup = 500L,
  Sigma = NULL,
  Sd = NULL,
  eps = 1e-04,
  fixed = FALSE,
  until = Inf
)

kernel_am(
  mu = 0,
  bw = 0L,
  lb = -.Machine$double.xmax,
  ub = .Machine$double.xmax,
  freq = 1L,
  warmup = 500L,
  Sigma = NULL,
  Sd = NULL,
  eps = 1e-04,
  fixed = FALSE,
  until = Inf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernel_adapt_+3A_mu">mu</code></td>
<td>
<p>Either a numeric vector or a scalar. Proposal mean.
If scalar, values are recycled to match the number of parameters in the
objective function.</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_bw">bw</code></td>
<td>
<p>Integer scalar. The bandwidth, is the number of observations to
include in the computation of the variance-covariance matrix.</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_lb">lb</code>, <code id="kernel_adapt_+3A_ub">ub</code></td>
<td>
<p>Either a numeric vector or a scalar. Lower and upper bounds for
bounded kernels. When of length 1, the values are recycled to match the number
of parameters in the objective function.</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_freq">freq</code></td>
<td>
<p>Integer scalar. Frequency of updates. How often the
variance-covariance matrix is updated. The implementation is different from that
described in the original paper (see details).</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_warmup">warmup</code></td>
<td>
<p>Integer scalar. The number of iterations that the algorithm has
to wait before starting to do the updates.</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_sigma">Sigma</code></td>
<td>
<p>The variance-covariance matrix. By default this will be an
identity matrix during the warmup period.</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_sd">Sd</code></td>
<td>
<p>Overall scale for the algorithm. By default, the variance-covariance
is scaled to <code class="reqn">2.4^2/d</code>, with <code class="reqn">d</code> the number of dimensions.</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_eps">eps</code></td>
<td>
<p>Double scalar. Default size of the initial step (see details).</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_fixed">fixed</code></td>
<td>
<p>Logical scalar or vector of length <code>k</code>. Indicates which parameters
will be treated as fixed or not. Single values are recycled.</p>
</td></tr>
<tr><td><code id="kernel_adapt_+3A_until">until</code></td>
<td>
<p>Integer scalar. Last step at which adaptation takes place (see
details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>While it has been shown that under regular conditions this transition kernel
generates ergodic chains even when the adaptation does not stop, some
practitioners may want to stop adaptation at some point.
</p>
<p><code>kernel_adapt</code> Implements the adaptive Metropolis (AM) algorithm of Haario
et al. (2001). If the value of bw is greater than zero, then the algorithm
folds back AP, a  previous version which is known to have ergodicity problems.
</p>
<p>The parameter <code>eps</code> has two functions. The first one is to set the initial
scale for the multivariate normal kernel, which is replaced after <code>warmup</code>
steps with the actual variance-covariance computed by the main algorithm.
The second usage is in the equation that ensures that the variance-covariance
is greater than zero, this is, the <code class="reqn">\varepsilon</code> parameter in the
original paper.
</p>
<p>The update of the covariance matrix is done using <code><a href="#topic+cov_recursive">cov_recursive()</a></code> function,
which makes the updates faster. The <code>freq</code> parameter, besides of indicating the
frequency with which the updates are done, it specifies what are the samples
included in each update, in other words, like a thinning parameter, only every
<code>freq</code> samples will be used to compute the covariance matrix. Since this
implementation uses the recursive formula for updating the covariance, there is
no practical need to set <code>freq != 1</code>.
</p>
<p><code>kernel_am</code> is just an alias for <code>kernel_adapt</code>.
</p>


<h3>Value</h3>

<p>An object of class <a href="#topic+fmcmc_kernel">fmcmc_kernel</a>. <code>fmcmc_kernel</code> objects are intended
to be used with the <code><a href="#topic+MCMC">MCMC()</a></code> function.
</p>


<h3>References</h3>

<p>Haario, H., Saksman, E., &amp; Tamminen, J. (2001). An adaptive Metropolis algorithm.
Bernoulli, 7(2), 223–242.
<a href="https://projecteuclid.org/euclid.bj/1080222083">https://projecteuclid.org/euclid.bj/1080222083</a>
</p>


<h3>See Also</h3>

<p>Other kernels: 
<code><a href="#topic+kernel_mirror">kernel_mirror</a></code>,
<code><a href="#topic+kernel_new">kernel_new</a>()</code>,
<code><a href="#topic+kernel_normal">kernel_normal</a>()</code>,
<code><a href="#topic+kernel_ram">kernel_ram</a>()</code>,
<code><a href="#topic+kernel_unif">kernel_unif</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Update every-step and wait 1,000 steps before starting to adapt
kern &lt;- kernel_adapt(freq = 1, warmup = 1000)

# Two parameters model, the second parameter with a restricted range, i.e.
# a lower bound of 1
kern &lt;- kernel_adapt(lb = c(-.Machine$double.xmax, 0))
</code></pre>

<hr>
<h2 id='kernel_mirror'>Mirror Transition Kernels</h2><span id='topic+kernel_mirror'></span><span id='topic+kernel_nmirror'></span><span id='topic+kernel_umirror'></span>

<h3>Description</h3>

<p>NMirror and UMirror transition kernels described in Thawornwattana et al.
(2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel_nmirror(
  mu = 0,
  scale = 1,
  warmup = 500L,
  nadapt = 4L,
  arate = 0.4,
  lb = -.Machine$double.xmax,
  ub = .Machine$double.xmax,
  fixed = FALSE,
  scheme = "joint"
)

kernel_umirror(
  mu = 0,
  scale = 1,
  warmup = 500L,
  nadapt = 4L,
  arate = 0.4,
  lb = -.Machine$double.xmax,
  ub = .Machine$double.xmax,
  fixed = FALSE,
  scheme = "joint"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernel_mirror_+3A_mu">mu</code>, <code id="kernel_mirror_+3A_scale">scale</code></td>
<td>
<p>Either a numeric vector or a scalar. Proposal mean and scale.
If scalar, values are recycled to match the number of parameters in the
objective function.</p>
</td></tr>
<tr><td><code id="kernel_mirror_+3A_warmup">warmup</code></td>
<td>
<p>Integer. Number of steps required before starting adapting the
chains.</p>
</td></tr>
<tr><td><code id="kernel_mirror_+3A_nadapt">nadapt</code></td>
<td>
<p>Integer. Number of times the scale is adjusted for adaptation
during the warmup (burn-in) period.</p>
</td></tr>
<tr><td><code id="kernel_mirror_+3A_arate">arate</code></td>
<td>
<p>Double. Target acceptance rate used as a reference during the
adaptation process.</p>
</td></tr>
<tr><td><code id="kernel_mirror_+3A_lb">lb</code>, <code id="kernel_mirror_+3A_ub">ub</code></td>
<td>
<p>Either a numeric vector or a scalar. Lower and upper bounds for
bounded kernels. When of length 1, the values are recycled to match the number
of parameters in the objective function.</p>
</td></tr>
<tr><td><code id="kernel_mirror_+3A_fixed">fixed</code>, <code id="kernel_mirror_+3A_scheme">scheme</code></td>
<td>
<p>For multivariate functions, sets the update plan.
See <code><a href="#topic+plan_update_sequence">plan_update_sequence()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>kernel_nmirror</code> and <code>kernel_umirror</code> functions implement simple symmetric
transition kernels that pivot around an approximation of the asymptotic mean.
</p>
<p>In the multidimensional case, this implementation just draws a vector of
independent draws from the proposal kernel, instead of using, for example,
a multivariate distribution of some kind. This will be implemented in the
next update of the package.
</p>
<p>During the warmup period (or burnin as described in the paper), the algorithm
adapts both the scale and the reference mean of the proposal distribution.
While the mean is adapted continuously, the scale is updated only a handful
of times, in particular, <code>nadapt</code> times during the warmup time. The adaptation
is done as proposed by Yang and Rodriguez (2013) in which the
scale is adapted four times.
</p>


<h3>Value</h3>

<p>An object of class <a href="#topic+fmcmc_kernel">fmcmc_kernel</a>. <code>fmcmc_kernel</code> objects are intended
to be used with the <code><a href="#topic+MCMC">MCMC()</a></code> function.
</p>


<h3>References</h3>

<p>Thawornwattana, Y., Dalquen, D., &amp; Yang, Z. (2018). Designing Simple and
Efficient Markov Chain Monte Carlo Proposal Kernels. Bayesian Analysis, 13(4),
1037–1063. <a href="https://doi.org/10.1214/17-BA1084">doi:10.1214/17-BA1084</a>
</p>
<p>Yang, Z., &amp; Rodriguez, C. E. (2013). Searching for efficient Markov chain
Monte Carlo proposal kernels. Proceedings of the National Academy of Sciences,
110(48), 19307–19312. <a href="https://doi.org/10.1073/pnas.1311790110">doi:10.1073/pnas.1311790110</a>
</p>


<h3>See Also</h3>

<p>Other kernels: 
<code><a href="#topic+kernel_adapt">kernel_adapt</a>()</code>,
<code><a href="#topic+kernel_new">kernel_new</a>()</code>,
<code><a href="#topic+kernel_normal">kernel_normal</a>()</code>,
<code><a href="#topic+kernel_ram">kernel_ram</a>()</code>,
<code><a href="#topic+kernel_unif">kernel_unif</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Normal mirror kernel with 5 adaptations and 1000 steps of warmup (burnin)
kern &lt;- kernel_nmirror(nadapt = 5, warmup = 1000)

# Same as before but using a uniform mirror and choosing a target acceptance
# rate of 24 %
kern &lt;- kernel_umirror(nadapt = 5, warmup = 1000, arate = .24)
</code></pre>

<hr>
<h2 id='kernel_new'>Transition Kernels for MCMC</h2><span id='topic+kernel_new'></span><span id='topic+fmcmc_kernel'></span><span id='topic+kernels'></span>

<h3>Description</h3>

<p>The function <code>kernel_new</code> is a helper function that allows creating
<code>fmcmc_kernel</code> objects which are passed to the <code><a href="#topic+MCMC">MCMC()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel_new(proposal, ..., logratio = NULL, kernel_env = new.env(hash = TRUE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernel_new_+3A_proposal">proposal</code>, <code id="kernel_new_+3A_logratio">logratio</code></td>
<td>
<p>Functions. Both receive a single argument, an environment.
This functions are called later within <a href="#topic+MCMC">MCMC</a> (see details).</p>
</td></tr>
<tr><td><code id="kernel_new_+3A_...">...</code></td>
<td>
<p>In the case of <code>kernel_new</code>, further arguments to be stored with
the kernel.</p>
</td></tr>
<tr><td><code id="kernel_new_+3A_kernel_env">kernel_env</code></td>
<td>
<p>Environment. This will be used as the main container of the
kernel's components. It is returned as an object of class <code>c("environment", "fmcmc_kernel")</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The objects <code>fmcmc_kernels</code> are environments that in general contain the
following objects:
</p>

<ul>
<li> <p><code>proposal</code>: The function used to propose changes in the chain based
on the current state. The function must return a vector of length equal
to the number of parameters in the model.
</p>
</li>
<li> <p><code>logratio</code>: This function is called after a new state has been proposed,
and is used to compute the log of the Hastings ratio.
</p>
<p>In the case that the <code>logratio</code> function is not specified, then it is assumed
that the transition kernel is symmetric, this is, log-ratio is then implemented
as <code>function(env) {env$f1 - env$f0}</code>
</p>
</li>
<li> <p><code>...</code>: Further objects that are used within those functions.
</p>
</li></ul>

<p>Both functions, <code>proposal</code> and <code>logratio</code>, receive a single argument, an
environment, which is passed by the <code><a href="#topic+MCMC">MCMC()</a></code> function during each step using
the function <code><a href="base.html#topic+environment">environment()</a></code>.
</p>
<p>The passed environment is actually the environment in which the <code>MCMC</code>
function is running, in particular, this environment contains the following
objects:
</p>

<table>
<tr>
 <td style="text-align: left;">
<strong>Object</strong> </td><td style="text-align: center;"> </td><td style="text-align: left;"> <strong>Description</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>i</code> </td><td style="text-align: center;"> </td><td style="text-align: left;"> Integer. The current iteration. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>theta1</code> </td><td style="text-align: center;"> </td><td style="text-align: left;"> Numeric vector. The last proposed state. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>theta0</code> </td><td style="text-align: center;"> </td><td style="text-align: left;"> Numeric vector. The current state </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>f</code></td><td style="text-align: center;"> </td><td style="text-align: left;"> The log-unnormalized posterior function (a wrapper of <code>fun</code> passed
to <a href="#topic+MCMC">MCMC</a>). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>f1</code> </td><td style="text-align: center;"> </td><td style="text-align: left;"> The last value of <code>f(theta1)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>f0</code> </td><td style="text-align: center;"> </td><td style="text-align: left;"> The last value of <code>f(theta0)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>kernel</code> </td><td style="text-align: center;"> </td><td style="text-align: left;"> The actual <code>fmcmc_kernel</code> object. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ans</code> </td><td style="text-align: center;"> </td><td style="text-align: left;"> The matrix of samples defined up to <code>i - 1</code>.
</td>
</tr>

</table>

<p>These are the core component of the <code>MCMC</code> function. The following block
of code is how this is actually implemented in the package:
</p>
<div class="sourceCode"><pre>for (i in 1L:nsteps) {
  # Step 1. Propose
  theta1[] &lt;- kernel$proposal(environment())
  f1       &lt;- f(theta1)
  
  # Checking f(theta1) (it must be a number, can be Inf)
  if (is.nan(f1) | is.na(f1) | is.null(f1)) 
    stop(
      "fun(par) is undefined (", f1, ")",
      "Check either -fun- or the -lb- and -ub- parameters.",
      call. = FALSE
    )
  
  # Step 2. Hastings ratio
  if (R[i] &lt; kernel$logratio(environment())) {
    theta0 &lt;- theta1
    f0     &lt;- f1
  }
  
  # Step 3. Saving the state
  ans[i,] &lt;- theta0
  
}
</pre></div>
<p>For an extensive example on how to create new kernel objects see the vignette
<code>vignette("user-defined-kernels", "fmcmc")</code>.
</p>


<h3>Value</h3>

<p>An environment of class <code>fmcmc_kernel</code> which contains the following:
</p>

<ul>
<li> <p><code>proposal</code> A function that receives a single argument, an environment. This
is the proposal function used within <code><a href="#topic+MCMC">MCMC()</a></code>.
</p>
</li>
<li> <p><code>logratio</code> A function to compute log ratios of the current vs the proposed
step of the chain. Also used within <code><a href="#topic+MCMC">MCMC()</a></code>.
</p>
</li>
<li> <p><code>...</code> Further arguments passed to <code>kernel_new</code>.
</p>
</li></ul>



<h3>Behavior</h3>

<p>In some cases, calls to the <code>proposal()</code> and <code>logratio()</code> functions in
<code>fmcmc_kernels</code> can trigger changes or updates of variables stored within them.
A concrete example is with adaptive kernels.
</p>
<p>Adaptive Metropolis and Robust Adaptive Metropolis implemented in the functions
<code><a href="#topic+kernel_adapt">kernel_adapt()</a></code> and <code><a href="#topic+kernel_ram">kernel_ram()</a></code> both update a covariance matrix used
during the proposal stage, and furthermore, have a <code>warmup</code> stage that sets
the point at which both will start adapting. Because of this, both kernels
have internal counters of the absolute step count which allows them activating,
scaling, etc. the proposals correctly.
</p>

<ol>
<li><p> When running multiple chains, <code>MCMC</code> will create independent copies of a
baseline passed <code>fmcmc_kernel</code> object. These are managed together in a
<code>fmcmc_kernel_list</code> object.
</p>
</li>
<li><p> Even if the chains are run in parallel, if a predefined kernel object is
passed it will be updated to reflect the last state of the kernels
before the <code>MCMC</code> call returns.
</p>
</li></ol>



<h3>References</h3>

<p>Brooks, S., Gelman, A., Jones, G. L., &amp; Meng, X. L. (2011). Handbook of
Markov Chain Monte Carlo. Handbook of Markov Chain Monte Carlo.
</p>


<h3>See Also</h3>

<p>Other kernels: 
<code><a href="#topic+kernel_adapt">kernel_adapt</a>()</code>,
<code><a href="#topic+kernel_mirror">kernel_mirror</a></code>,
<code><a href="#topic+kernel_normal">kernel_normal</a>()</code>,
<code><a href="#topic+kernel_ram">kernel_ram</a>()</code>,
<code><a href="#topic+kernel_unif">kernel_unif</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example creating a multivariate normal kernel using the mvtnorm R package
# for a bivariate normal distribution
library(mvtnorm)

# Define your Sigma
sigma &lt;- matrix(c(1, .2, .2, 1), ncol = 2)

# How does it looks like?
sigma
#      [,1] [,2]
# [1,]  1.0  0.2
# [2,]  0.2  1.0

# Create the kernel
kernel_mvn &lt;- kernel_new(
  proposal = function(env) {
  env$theta0 + as.vector(mvtnorm::rmvnorm(1, mean = 0, sigma = sigma.))
  },
  sigma. = sigma
)

# As you can see, in the previous call we passed sigma as it will be used by
# the proposal function
# The logaratio function was not necesary to be passed since this kernel is
# symmetric.

</code></pre>

<hr>
<h2 id='kernel_normal'>Gaussian Transition Kernel</h2><span id='topic+kernel_normal'></span><span id='topic+kernel_normal_reflective'></span>

<h3>Description</h3>

<p>Gaussian Transition Kernel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel_normal(mu = 0, scale = 1, fixed = FALSE, scheme = "joint")

kernel_normal_reflective(
  mu = 0,
  scale = 1,
  lb = -.Machine$double.xmax,
  ub = .Machine$double.xmax,
  fixed = FALSE,
  scheme = "joint"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernel_normal_+3A_mu">mu</code>, <code id="kernel_normal_+3A_scale">scale</code></td>
<td>
<p>Either a numeric vector or a scalar. Proposal mean and scale.
If scalar, values are recycled to match the number of parameters in the
objective function.</p>
</td></tr>
<tr><td><code id="kernel_normal_+3A_fixed">fixed</code>, <code id="kernel_normal_+3A_scheme">scheme</code></td>
<td>
<p>For multivariate functions, sets the update plan.
See <code><a href="#topic+plan_update_sequence">plan_update_sequence()</a></code>.</p>
</td></tr>
<tr><td><code id="kernel_normal_+3A_lb">lb</code>, <code id="kernel_normal_+3A_ub">ub</code></td>
<td>
<p>Either a numeric vector or a scalar. Lower and upper bounds for
bounded kernels. When of length 1, the values are recycled to match the number
of parameters in the objective function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>kernel_normal</code> function provides the canonical normal kernel
with symmetric transition probabilities.
</p>
<p>The <code>kernel_normal_reflective</code> implements the normal kernel with reflective
boundaries. Lower and upper bounds are treated using reflecting boundaries, this is,
if the proposed <code class="reqn">\theta'</code> is greater than the <code>ub</code>, then <code class="reqn">\theta' - ub</code>
is subtracted from <code class="reqn">ub</code>. At the same time, if it is less than <code>lb</code>, then
<code class="reqn">lb - \theta'</code> is added to <code>lb</code> iterating until <code class="reqn">\theta</code> is within
<code>[lb, ub]</code>.
</p>
<p>In this case, the transition probability is symmetric (just like the normal
kernel).
</p>


<h3>Value</h3>

<p>An object of class <a href="#topic+fmcmc_kernel">fmcmc_kernel</a>. <code>fmcmc_kernel</code> objects are intended
to be used with the <code><a href="#topic+MCMC">MCMC()</a></code> function.
</p>


<h3>See Also</h3>

<p>Other kernels: 
<code><a href="#topic+kernel_adapt">kernel_adapt</a>()</code>,
<code><a href="#topic+kernel_mirror">kernel_mirror</a></code>,
<code><a href="#topic+kernel_new">kernel_new</a>()</code>,
<code><a href="#topic+kernel_ram">kernel_ram</a>()</code>,
<code><a href="#topic+kernel_unif">kernel_unif</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Normal kernel with a small scale (sd) of 0.05
kern &lt;- kernel_normal(scale = 0.05)

# Using boundaries for the second parameter of a two parameter chain
# to have values in [0, 100].
kern &lt;- kernel_normal_reflective(
  ub = c(.Machine$double.xmax, 100),
  lb = c(-.Machine$double.xmax, 0)
  )
</code></pre>

<hr>
<h2 id='kernel_ram'>Robust Adaptive Metropolis (RAM) Transition Kernel</h2><span id='topic+kernel_ram'></span>

<h3>Description</h3>

<p>Implementation of Vihola (2012)'s Robust Adaptive Metropolis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel_ram(
  mu = 0,
  eta = function(i, k) min(c(1, i^(-2/3) * k)),
  qfun = function(k) stats::rt(k, k),
  arate = 0.234,
  freq = 1L,
  warmup = 0L,
  Sigma = NULL,
  eps = 1e-04,
  lb = -.Machine$double.xmax,
  ub = .Machine$double.xmax,
  fixed = FALSE,
  until = Inf,
  constr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernel_ram_+3A_mu">mu</code></td>
<td>
<p>Either a numeric vector or a scalar. Proposal mean.
If scalar, values are recycled to match the number of parameters in the
objective function.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_eta">eta</code></td>
<td>
<p>A function that receives the MCMC environment. This is to calculate
the scaling factor for the adaptation.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_qfun">qfun</code></td>
<td>
<p>Function. As described in Vihola (2012)'s, the <code>qfun</code> function is
a symmetric function used to generate random numbers.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_arate">arate</code></td>
<td>
<p>Numeric scalar. Objective acceptance rate.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_freq">freq</code></td>
<td>
<p>Integer scalar. Frequency of updates. How often the
variance-covariance matrix is updated.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_warmup">warmup</code></td>
<td>
<p>Integer scalar. The number of iterations that the algorithm has
to wait before starting to do the updates.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_sigma">Sigma</code></td>
<td>
<p>The variance-covariance matrix. By default this will be an
identity matrix during the warmup period.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_eps">eps</code></td>
<td>
<p>Double scalar. Default size of the initial step (see details).</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_lb">lb</code>, <code id="kernel_ram_+3A_ub">ub</code></td>
<td>
<p>Either a numeric vector or a scalar. Lower and upper bounds for
bounded kernels. When of length 1, the values are recycled to match the number
of parameters in the objective function.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_fixed">fixed</code></td>
<td>
<p>Logical scalar or vector of length <code>k</code>. Indicates which parameters
will be treated as fixed or not. Single values are recycled.</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_until">until</code></td>
<td>
<p>Integer scalar. Last step at which adaptation takes place (see
details).</p>
</td></tr>
<tr><td><code id="kernel_ram_+3A_constr">constr</code></td>
<td>
<p>Logical lower-diagonal square matrix of size <code>k</code>. <strong>Not</strong> in the
original paper, but rather a tweak that imposes a constraint on the <code>S_n</code>
matrix. If different from <code>NULL</code>, the kernel multiplates <code>S_n</code> by this
constraint so that zero elements are pre-imposed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>While it has been shown that under regular conditions this transition kernel
generates ergodic chains even when the adaptation does not stop, some
practitioners may want to stop adaptation at some point.
</p>
<p>The idea is similar to that of the Adaptive Metropolis algorithm (AM implemented
as <code><a href="#topic+kernel_adapt">kernel_adapt()</a></code> here) with the difference that it takes into account a
target acceptance rate.
</p>
<p>The <code>eta</code> function regulates the rate of adaptation. The default implementation
will decrease the rate of adaptation exponentially as a function of the iteration
number.
</p>
<p style="text-align: center;"><code class="reqn">%latex
Y_n\equiv X_{n-1} + S_{n-1}U_n,\quad\mbox{where }U_n\sim q\mbox{ (the \texttt{qfun})}%
</code>
</p>

<p>And the <code class="reqn">S_n</code> matrix is updated according to the following equation:
</p>
<p style="text-align: center;"><code class="reqn">% latex
S_nS_n^T = S_{n-1}\left(I + \eta_n(\alpha_n - \alpha_*)\frac{U_nU_n^T}{\|U_n\|^2}\right)S_{n-1}^T%
</code>
</p>



<h3>Value</h3>

<p>An object of class <a href="#topic+fmcmc_kernel">fmcmc_kernel</a>.
</p>


<h3>References</h3>

<p>Vihola, M. (2012). Robust adaptive Metropolis algorithm with coerced acceptance
rate. Statistics and Computing, 22(5), 997–1008.
<a href="https://doi.org/10.1007/s11222-011-9269-5">doi:10.1007/s11222-011-9269-5</a>
</p>


<h3>See Also</h3>

<p>Other kernels: 
<code><a href="#topic+kernel_adapt">kernel_adapt</a>()</code>,
<code><a href="#topic+kernel_mirror">kernel_mirror</a></code>,
<code><a href="#topic+kernel_new">kernel_new</a>()</code>,
<code><a href="#topic+kernel_normal">kernel_normal</a>()</code>,
<code><a href="#topic+kernel_unif">kernel_unif</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Setting the acceptance rate to 30 % and deferring the updates until
# after 1000 steps
kern &lt;- kernel_ram(arate = .3, warmup = 1000)
</code></pre>

<hr>
<h2 id='kernel_unif'>Uniform Transition Kernel</h2><span id='topic+kernel_unif'></span><span id='topic+kernel_unif_reflective'></span>

<h3>Description</h3>

<p>Uniform Transition Kernel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel_unif(min. = -1, max. = 1, fixed = FALSE, scheme = "joint")

kernel_unif_reflective(
  min. = -1,
  max. = 1,
  lb = min.,
  ub = max.,
  fixed = FALSE,
  scheme = "joint"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernel_unif_+3A_min.">min.</code>, <code id="kernel_unif_+3A_max.">max.</code></td>
<td>
<p>Passed to <code><a href="stats.html#topic+Uniform">runif</a></code>.</p>
</td></tr>
<tr><td><code id="kernel_unif_+3A_fixed">fixed</code>, <code id="kernel_unif_+3A_scheme">scheme</code></td>
<td>
<p>For multivariate functions, sets the update plan.
See <code><a href="#topic+plan_update_sequence">plan_update_sequence()</a></code>.</p>
</td></tr>
<tr><td><code id="kernel_unif_+3A_lb">lb</code>, <code id="kernel_unif_+3A_ub">ub</code></td>
<td>
<p>Either a numeric vector or a scalar. Lower and upper bounds for
bounded kernels. When of length 1, the values are recycled to match the number
of parameters in the objective function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>kernel_unif</code> function provides a uniform transition kernel. This (symmetric)
kernel function by default adds the current status values between [-1,1].
</p>
<p>The <code>kernel_unif_reflective</code> is similar to <code>kernel_unif</code> with the
main difference that proposals are bounded to be within <code style="white-space: pre;">&#8288;[lb, ub]&#8288;</code>.
</p>


<h3>Value</h3>

<p>An object of class <a href="#topic+fmcmc_kernel">fmcmc_kernel</a>. <code>fmcmc_kernel</code> objects are intended
to be used with the <code><a href="#topic+MCMC">MCMC()</a></code> function.
</p>


<h3>See Also</h3>

<p>Other kernels: 
<code><a href="#topic+kernel_adapt">kernel_adapt</a>()</code>,
<code><a href="#topic+kernel_mirror">kernel_mirror</a></code>,
<code><a href="#topic+kernel_new">kernel_new</a>()</code>,
<code><a href="#topic+kernel_normal">kernel_normal</a>()</code>,
<code><a href="#topic+kernel_ram">kernel_ram</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Multivariate setting with 4 parameters in which we set the kernel to make
# proposals one parameter at-a-time in a random ordering.
kern &lt;- kernel_unif(scheme = "random")
</code></pre>

<hr>
<h2 id='lifeexpect'>Life expectancy in the US (2020)</h2><span id='topic+lifeexpect'></span>

<h3>Description</h3>

<p>A simulated data set based on statistics of life expectancy in the US at birth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lifeexpect
</code></pre>


<h3>Format</h3>

<p>A 1,000 rows data frame with three columns:
</p>

<ul>
<li> <p><code>age</code>: Years lived.
</p>
</li>
<li> <p><code>smoke</code>: 0/1 variable equal to 1 if the individual smokes.
</p>
</li>
<li> <p><code>female</code>: 0/1 variable equal to 1 if the individual is a female at birth.
</p>
</li></ul>



<h3>Details</h3>

<p>The data was generated using official statistics from the CDC and a
study of life expectancy of smokers in the US published in the New England
Journal of Medicine (see references).
</p>
<p>According to the CDC, data from 2020 indicates that the average life expectancy
of females in the US is 80.5 years vs 75.1 years for males (which declined
with respect to 2019 after COVID hit the US). In Jha et al. (2013), evidence
is presented indicating that individuals who smoke have at least ten years
left of life expectancy compared to non-smokers.
</p>
<p>The parameter estimates for the data generating process where:
</p>

<ul>
<li><p> An average of life expectancy of 80.1.
</p>
</li>
<li><p> Smokers live 10 years less than non-smokers.
</p>
</li>
<li><p> Females live 5.4 years longer than males.
</p>
</li></ul>



<h3>References</h3>

<p>Jha, P., Ramasundarahettige, C., Landsman, V., Rostron, B., Thun, M., Anderson, R. N.,
... Peto, R. (2013). 21st-Century Hazards of Smoking and Benefits of Cessation
in the United States. New England Journal of Medicine, 368(4), 341–350.
<a href="https://doi.org/10.1056/NEJMsa1211128">doi:10.1056/NEJMsa1211128</a>
</p>
<p>Arias, E., Tejada-Vera, B., &amp; Ahmad, F. (2021). Provisional life expectancy
estimates for January through June, 2020.
<a href="https://www.cdc.gov/nchs/data/vsrr/VSRR10-508.pdf">https://www.cdc.gov/nchs/data/vsrr/VSRR10-508.pdf</a>
</p>

<hr>
<h2 id='MCMC'>Markov Chain Monte Carlo</h2><span id='topic+MCMC'></span><span id='topic+Metropolis-Hastings'></span><span id='topic+MCMC_without_conv_checker'></span><span id='topic+MCMC_OUTPUT'></span>

<h3>Description</h3>

<p>A flexible implementation of the Metropolis-Hastings MCMC algorithm, users
can utilize arbitrary transition kernels as well as set-up an automatic
stop criterion using a convergence check test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCMC(
  initial,
  fun,
  nsteps,
  ...,
  seed = NULL,
  nchains = 1L,
  burnin = 0L,
  thin = 1L,
  kernel = kernel_normal(),
  multicore = FALSE,
  conv_checker = NULL,
  cl = NULL,
  progress = interactive() &amp;&amp; !multicore,
  chain_id = 1L
)

MCMC_without_conv_checker(
  initial,
  fun,
  nsteps,
  ...,
  nchains = 1L,
  burnin = 0L,
  thin = 1L,
  kernel = kernel_normal(),
  multicore = FALSE,
  conv_checker = NULL,
  cl = NULL,
  progress = interactive() &amp;&amp; !multicore,
  chain_id = 1L
)

MCMC_OUTPUT
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCMC_+3A_initial">initial</code></td>
<td>
<p>Either a numeric matrix or vector, or an object of class <a href="coda.html#topic+mcmc">coda::mcmc</a>
or <a href="coda.html#topic+mcmc.list">coda::mcmc.list</a> (see details).
initial values of the parameters for each chain (See details).</p>
</td></tr>
<tr><td><code id="MCMC_+3A_fun">fun</code></td>
<td>
<p>A function. Returns the log-likelihood.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_nsteps">nsteps</code></td>
<td>
<p>Integer scalar. Length of each chain.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>fun</code>.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_seed">seed</code></td>
<td>
<p>If not null, passed to <a href="base.html#topic+set.seed">set.seed</a>.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_nchains">nchains</code></td>
<td>
<p>Integer scalar. Number of chains to run (in parallel).</p>
</td></tr>
<tr><td><code id="MCMC_+3A_burnin">burnin</code></td>
<td>
<p>Integer scalar. Length of burn-in. Passed to
<a href="coda.html#topic+mcmc">coda::mcmc</a> as <code>start</code>.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_thin">thin</code></td>
<td>
<p>Integer scalar. Passed to <a href="coda.html#topic+mcmc">coda::mcmc</a>.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_kernel">kernel</code></td>
<td>
<p>An object of class <a href="#topic+fmcmc_kernel">fmcmc_kernel</a>.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_multicore">multicore</code></td>
<td>
<p>Logical. If <code>FALSE</code> then chains will be executed in serial.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_conv_checker">conv_checker</code></td>
<td>
<p>A function that receives an object of class <a href="coda.html#topic+mcmc.list">coda::mcmc.list</a>,
and returns a logical value with <code>TRUE</code> indicating convergence. See the
&quot;Automatic stop&quot; section and the <a href="#topic+convergence-checker">convergence-checker</a> manual.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_cl">cl</code></td>
<td>
<p>A <code>cluster</code> object passed to <a href="parallel.html#topic+clusterApply">parallel::clusterApply</a>.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_progress">progress</code></td>
<td>
<p>Logical scalar. When set to <code>TRUE</code> shows a progress bar. A new
bar will be show every time that the convergence checker is called.</p>
</td></tr>
<tr><td><code id="MCMC_+3A_chain_id">chain_id</code></td>
<td>
<p>Integer scalar (internal use only). This is an argument
passed to the kernel function and it allows it identify in which of the
chains the process is taking place. This could be relevant for some kernels
(see <code><a href="#topic+kernel_new">kernel_new()</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements Markov Chain Monte Carlo (MCMC) using the
Metropolis-Hastings ratio with
flexible transition kernels. Users can specify either one of the available
transition kernels or define one of their own (see <a href="#topic+kernels">kernels</a>). Furthermore,
it allows easy parallel implementation running multiple chains in parallel.
The function also allows using convergence diagnostics tests to set-up a
criterion for automatically stopping the algorithm  (see <a href="#topic+convergence-checker">convergence-checker</a>).
</p>
<p>The canonical form of the Metropolis Hastings algorithm consists on accepting
a move from state <code class="reqn">x</code> to state <code class="reqn">y</code> based on the Hastings ratio <code class="reqn">r(x,y)</code>:
</p>
<p style="text-align: center;"><code class="reqn">%
r(x,y) = \frac{h(y)q(y,x)}{h(x)q(x,y)},%
</code>
</p>

<p>where <code class="reqn">h</code> is the unnormalized density of the specified distribution (
the posterior probability), and <code class="reqn">q</code> has the conditional probability of
moving from state <code class="reqn">x</code> to <code class="reqn">y</code> (the proposal density). The move
<code class="reqn">x \to y</code> is then accepted with probability
</p>
<p style="text-align: center;"><code class="reqn">%
\alpha(x,y) = \min\left(1, r(x,y)\right)%
</code>
</p>

<p>Observe that, in the case that <code class="reqn">q()</code> is symmetric, meaning <code class="reqn">q(x, y) = q(y, x)</code>,
the Hastings ration reduces to <code class="reqn">h(y)/h(x)</code>. Starting version 0.5-0, the value
of the log unnormalized density and the proposed states <code>y</code> can be accessed using
the functions <code><a href="#topic+get_logpost">get_logpost()</a></code> and <code><a href="#topic+get_draws">get_draws()</a></code>.
</p>
<p>We now give details of the
various options included in the function.
</p>
<p>The function <code>MCMC_without_conv_checker</code> is for internal use
only.
</p>


<h3>Value</h3>

<p><code>MCMC</code> returns an object of class <a href="coda.html#topic+mcmc">coda::mcmc</a> from the <a href="https://CRAN.R-project.org/package=coda"><span class="pkg">coda</span></a>
package. The <code>mcmc</code> object is a matrix with one column per parameter,
and <code>nsteps</code> rows. If <code>nchains &gt; 1</code>, then it returns a <a href="coda.html#topic+mcmc.list">coda::mcmc.list</a>.
</p>
<p>While the main output of <code>MCMC</code> is the <code>mcmc</code>(<code>.list</code>) object, other information
and intermediate outputs of the process are stored in <code>MCMC_OUTPUT</code>. For information
about how to retrieve/set data, see <a href="#topic+mcmc-output">mcmc-output</a>.
</p>


<h3>Starting point</h3>

<p>By default, if <code>initial</code> is of class <code>mcmc</code>, <code>MCMC</code> will take the last <code>nchains</code>
points from the chain as starting point for the new sequence. If <code>initial</code> is
of class <code>mcmc.list</code>, the number of chains in <code>initial</code> must match the <code>nchains</code>
parameter.
</p>
<p>If <code>initial</code> is a vector, then it must be of length equal to the number of
parameters used in the model. When using multiple chains, if <code>initial</code> is not
an object of class <code>mcmc</code> or <code>mcmc.list</code>, then it must be a numeric matrix
with as many rows as chains, and as many columns as parameters in the model.
</p>


<h3>Multiple chains</h3>

<p>When <code>nchains &gt; 1</code>, the function will run multiple chains. Furthermore,
if <code>cl</code> is not passed, <code>MCMC</code> will create a <code>PSOCK</code> cluster
using <code><a href="parallel.html#topic+makeCluster">makePSOCKcluster</a></code> with
<a href="parallel.html#topic+detectCores">parallel::detectCores</a>
clusters and attempt to execute using multiple cores. Internally, the function does
the following:
</p>
<pre>
  # Creating the cluster
  ncores &lt;- parallel::detectCores()
  ncores &lt;- ifelse(nchains &lt; ncores, nchains, ncores)
  cl     &lt;- parallel::makePSOCKcluster(ncores)
  
  # Loading the package and setting the seed using clusterRNGStream
  invisible(parallel::clusterEvalQ(cl, library(fmcmc)))
  parallel::clusterSetRNGStream(cl, .Random.seed)
</pre>
<p>When running in parallel, objects that are
used within <code>fun</code> must be passed through <code>...</code>, otherwise the cluster
will return with an error.
</p>
<p>The user controls the initial value of the parameters of the MCMC algorithm
using the argument <code>initial</code>. When using multiple chains, i.e., <code>nchains &gt; 1</code>,
the user can specify multiple starting points, which is recommended. In such a
case, each row of <code>initial</code> is use as a starting point for each of the
chains. If <code>initial</code> is a vector and <code>nchains &gt; 1</code>, the value is recycled, so
all chains start from the same point (not recommended, the function throws a
warning message).
</p>


<h3>Automatic stop</h3>

<p>By default, no automatic stop is implemented. If one of the functions in
<a href="#topic+convergence-checker">convergence-checker</a> is used, then the MCMC is done by bulks as specified
by the convergence checker function, and thus the algorithm will stop if,
the <code>conv_checker</code> returns <code>TRUE</code>. For more information see <a href="#topic+convergence-checker">convergence-checker</a>.
</p>


<h3>References</h3>

<p>Brooks, S., Gelman, A., Jones, G. L., &amp; Meng, X. L. (2011). Handbook of
Markov Chain Monte Carlo. Handbook of Markov Chain Monte Carlo.
</p>
<p>Vega Yon, G., &amp; Marjoram, P. (2019). fmcmc: A friendly MCMC framework.
Journal of Open Source Software, 4(39), 1427. <a href="https://doi.org/10.21105/joss.01427">doi:10.21105/joss.01427</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_logpost">get_logpost()</a></code>, <code><a href="#topic+get_logpost">get_logpost()</a></code> (<a href="#topic+mcmc-output">mcmc-output</a>) for post execution of <code>MCMC</code>, and
<code><a href="#topic+ith_step">ith_step()</a></code> for accessing objects within an <code>MCMC</code> call.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Univariate distributed data with multiple parameters ----------------------
# Parameters
set.seed(1231)
n &lt;- 1e3
pars &lt;- c(mean = 2.6, sd = 3)

# Generating data and writing the log likelihood function
D &lt;- rnorm(n, pars[1], pars[2])
fun &lt;- function(x) {
  x &lt;- log(dnorm(D, x[1], x[2]))
  sum(x)
}

# Calling MCMC, but first, loading the coda R package for
# diagnostics
library(coda)
ans &lt;- MCMC(
  fun, initial = c(mu=1, sigma=1), nsteps = 2e3,
  kernel = kernel_normal_reflective(scale = .1, ub = 10, lb = 0)
  )

# Ploting the output
oldpar &lt;- par(no.readonly = TRUE)
par(mfrow = c(1,2))
boxplot(as.matrix(ans), 
        main = expression("Posterior distribution of"~mu~and~sigma),
        names =  expression(mu, sigma), horizontal = TRUE,
        col  = blues9[c(4,9)],
        sub = bquote(mu == .(pars[1])~", and"~sigma == .(pars[2]))
)
abline(v = pars, col  = blues9[c(4,9)], lwd = 2, lty = 2)

plot(apply(as.matrix(ans), 1, fun), type = "l",
     main = "LogLikelihood",
     ylab = expression(L("{"~mu,sigma~"}"~"|"~D)) 
)
par(oldpar)


# In this example we estimate the parameter for a dataset with ----------------
# With 5,000 draws from a MVN() with parameters M and S.

# Loading the required packages
library(mvtnorm)
library(coda)

# Parameters and data simulation
S &lt;- cbind(c(.8, .2), c(.2, 1))
M &lt;- c(0, 1)

set.seed(123)
D &lt;- rmvnorm(5e3, mean = M, sigma = S)

# Function to pass to MCMC
fun &lt;- function(pars) {
  # Putting the parameters in a sensible way
  m &lt;- pars[1:2]
  s &lt;- cbind( c(pars[3], pars[4]), c(pars[4], pars[5]) )
  
  # Computing the unnormalized log likelihood
  sum(log(dmvnorm(D, m, s)))
}

# Calling MCMC
ans &lt;- MCMC(
  initial = c(mu0=5, mu1=5, s0=5, s01=0, s2=5), 
  fun,
  kernel  = kernel_normal_reflective(
    lb    = c(-10, -10, .01, -5, .01),
    ub    = 5,
    scale = 0.01
  ),
  nsteps  = 1e3,
  thin    = 10,
  burnin  = 5e2
)

# Checking out the outcomes
plot(ans)
summary(ans)

# Multiple chains -----------------------------------------------------------

# As we want to run -fun- in multiple cores, we have to
# pass -D- explicitly (unless using Fork Clusters)
# just like specifying that we are calling a function from the
# -mvtnorm- package.
  
fun &lt;- function(pars, D) {
  # Putting the parameters in a sensible way
  m &lt;- pars[1:2]
  s &lt;- cbind( c(pars[3], pars[4]), c(pars[4], pars[5]) )
  
  # Computing the unnormalized log likelihood
  sum(log(mvtnorm::dmvnorm(D, m, s)))
}

# Two chains
ans &lt;- MCMC(
  initial = c(mu0=5, mu1=5, s0=5, s01=0, s2=5), 
  fun,
  nchains = 2,
  kernel  = kernel_normal_reflective(
    lb    = c(-10, -10, .01, -5, .01),
    ub    = 5,
    scale = 0.01
  ),
  nsteps  = 1e3,
  thin    = 10,
  burnin  = 5e2,
  D       = D
)

summary(ans)


</code></pre>

<hr>
<h2 id='mcmc-loop'>Functions to interact with the main loop</h2><span id='topic+mcmc-loop'></span><span id='topic+ith_step'></span><span id='topic+set_userdata'></span><span id='topic+get_userdata'></span>

<h3>Description</h3>

<p>You can use these functions to read variables, store, and retrieve data
during the MCMC process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ith_step(x)

set_userdata(...)

get_userdata()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcmc-loop_+3A_x">x</code></td>
<td>
<p>Name of the element to retrieve. If missing, it will return the entire
environment in which the main MCMC loop is running.</p>
</td></tr>
<tr><td><code id="mcmc-loop_+3A_...">...</code></td>
<td>
<p>Named values to be appended to the user data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>ith_step()</code> provides access to the following elements:
</p>

<ul>
<li> <p><code>i</code>            : (int) Step (iteration) number.
</p>
</li>
<li> <p><code>nsteps</code>       : (int) Number of steps.
</p>
</li>
<li> <p><code>chain_id</code>     : (int) Id of the chain (goes from 1 to -nchains-)
</p>
</li>
<li> <p><code>theta0</code>       : (double vector) Current state of the chain.
</p>
</li>
<li> <p><code>theta1</code>       : (double vector) Proposed state of the chain.
</p>
</li>
<li> <p><code>ans</code>          : (double matrix) Set of accepted states (it will be NA for rows &gt;= i).
</p>
</li>
<li> <p><code>draws</code>        : (double matrix) Set of proposed states (it will be NA for rows &gt;= i).
</p>
</li>
<li> <p><code>logpost</code>      : (double vector) Value of -fun- (it will be NA for elements &gt;= i).
</p>
</li>
<li> <p><code>R</code>            : (double vector) Random values from U(0,1). This is used with the Hastings ratio.
</p>
</li>
<li> <p><code>thin</code>         : (int) Thinning (applied after the last step).
</p>
</li>
<li> <p><code>burnin</code>       : (int) Burn-in (applied after the last step).
</p>
</li>
<li> <p><code>conv_checker</code> : (function) Convergence checker function.
</p>
</li>
<li> <p><code>kernel</code>       : (fmcmc_kernel) Kernel object.
</p>
</li>
<li> <p><code>fun</code>          : (function) Passed function to MCMC.
</p>
</li>
<li> <p><code>f</code>            : (function) Wrapper of -fun-.
</p>
</li>
<li> <p><code>initial</code>      : (double vector) Starting point of the chain.
</p>
</li></ul>

<p>The following objects always have fixed values (see ?ith_step): nchains, cl, multicore
</p>
<p>Other available objects: cnames, funargs, MCMC_OUTPUT, passedargs, progress
</p>
<p>The function <code><a href="#topic+set_userdata">set_userdata()</a></code> returns <code><a href="base.html#topic+invisible">invisible()</a></code>. The only side
effect is appending the information by row.
</p>


<h3>Advanced usage</h3>

<p>The function <code><a href="#topic+ith_step">ith_step()</a></code> is a convenience function that provides
access to the environment within which the main loop of the MCMC call is
being evaluated. This is a wrapper of <code>MCMC_OUTPUT$loop_envir</code> that will
either return the value <code>x</code> or, if missing, the entire environment. If
<code>ith_step()</code> is called outside of the <code>MCMC</code> call, then it will return with
an error.
</p>
<p>For example, if you wanted to print information if the current value
of logpost is greater than the previous value of logpost, you could define
the objective function as follows:
</p>
<div class="sourceCode"><pre>f &lt;- function(p) {

  i            &lt;- ith_step("i")
  logpost_prev &lt;- ith_step("logpost")[i - 1L]
  logpost_curr &lt;- sum(dnorm(y - x*p, log = TRUE))
  
  if (logpost_prev &lt; logpost_curr)
    cat("At a higher point!\n")
    
  return(logpost_curr)

}
</pre></div>
<p>In the case of the objects <code>nchains</code>, <code>cl</code>, and <code>multicore</code>, the function will
always return the default values <code>1</code>, <code>NULL</code>, and <code>FALSE</code>, respectively. Thus, the
user shouldn't rely on these objects to provide information regarding runs
using multiple chains. More examples below.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' # Getting the logpost -------------------------------------------------------
set.seed(23133)
x &lt;- rnorm(200)
y &lt;- x*2 + rnorm(200)
f &lt;- function(p) {
  sum(dnorm(y - x*p, log = TRUE))
}

ans &lt;- MCMC(fun = f, initial = c(0), nsteps=2000)
plot(get_logpost(), type = "l") # Plotting the logpost from the last run


# Printing information every 500 step ---------------------------------------
# for this we use ith_step()

f &lt;- function(p) {

  # Capturing info from within the loop
  i      &lt;- ith_step("i")
  nsteps &lt;- ith_step("nsteps")
  
  if (!(i %% 500)) {
  
    cat(
      "////////////////////////////////////////////////////\n",
      "Step ", i, " of ", nsteps,". Values in the loop:\n",
      "theta0: ", ith_step("theta0"), "\n",
      "theta1: ", ith_step()$theta1, "\n",
      sep = ""
    )
  }
    

  sum(dnorm(y - x*p, log = TRUE))
}

ans0 &lt;- MCMC(fun = f, initial = c(0), nsteps=2000, progress = FALSE, seed = 22)
# ////////////////////////////////////////////////////
# Step 500 of 2000. Values in the loop:
# theta0: 2.025379
# theta1: 1.04524
# ////////////////////////////////////////////////////
# Step 1000 of 2000. Values in the loop:
# theta0: 2.145967
# theta1: 0.2054037
# ////////////////////////////////////////////////////
# Step 1500 of 2000. Values in the loop:
# theta0: 2.211691
# theta1: 2.515361
# ////////////////////////////////////////////////////
# Step 2000 of 2000. Values in the loop:
# theta0: 1.998789
# theta1: 1.33034


# Printing information if the current logpost is greater than max -----------
f &lt;- function(p) {

  i            &lt;- ith_step("i")
  logpost_prev &lt;- max(ith_step("logpost")[1:(i-1)])
  logpost_curr &lt;- sum(dnorm(y - x*p, log = TRUE))
  
  # Only worthwhile after the first step
  if ((i &gt; 1L) &amp;&amp; logpost_prev &lt; logpost_curr)
    cat("At a higher point!:", logpost_curr, ", step:", i,"\n")
    
  return(logpost_curr)

}
ans1 &lt;- MCMC(fun = f, initial = c(0), nsteps=1000, progress = FALSE, seed = 22)
# At a higher point!: -357.3584 , step: 2 
# At a higher point!: -272.6816 , step: 6 
# At a higher point!: -270.9969 , step: 7 
# At a higher point!: -269.8128 , step: 24 
# At a higher point!: -269.7435 , step: 46 
# At a higher point!: -269.7422 , step: 543 
# At a higher point!: -269.7421 , step: 788 
# Saving extra information --------------------------------------------------
data("lifeexpect")

# Defining the logposterior
logpost &lt;- function(p) {

  # Reconding the sum of the parameters (just because) 
  # and the number of step.
  set_userdata(i = ith_step("i"), sum_of_p = sum(p))

  with(lifeexpect, {
    sum(dnorm(age - (p[1] + p[2]*smoke + p[3]*female), sd = p[4], log = TRUE))
  })
  
}

# A kernel where sd is positive, the first is average age, so we 
# make it positive too
kern &lt;- kernel_ram(lb = c(10, -20, -20, .0001), eps = .01)
ans &lt;- MCMC(
  initial = c(70, -2, 2, 1), fun = logpost, kernel = kern, nsteps = 1000, seed = 1
  )

# Retrieving the data
head(get_userdata())

# It also works using multiple chains
ans_two &lt;- MCMC(
  initial = c(70, -2, 2, 1), fun = logpost, kernel = kern, nsteps = 1000, seed = 1, nchains = 2
  )
  
user_dat &lt;- get_userdata()
lapply(user_dat, head)

</code></pre>

<hr>
<h2 id='mcmc-output'>Information about the last <code>MCMC</code> call</h2><span id='topic+mcmc-output'></span><span id='topic+get_'></span><span id='topic+get_logpost'></span><span id='topic+get_draws'></span><span id='topic+get_elapsed'></span><span id='topic+get_initial'></span><span id='topic+get_fun'></span><span id='topic+get_nsteps'></span><span id='topic+get_seed'></span><span id='topic+get_nchains'></span><span id='topic+get_burnin'></span><span id='topic+get_thin'></span><span id='topic+get_kernel'></span><span id='topic+get_multicore'></span><span id='topic+get_conv_checker'></span><span id='topic+get_cl'></span><span id='topic+get_progress'></span><span id='topic+get_chain_id'></span>

<h3>Description</h3>

<p>This environment holds a copy of the last call to <a href="#topic+MCMC">MCMC</a>, including the start
and end time (to compute total elapsed time) of the call. Since the resulting
object of <code>MCMC</code> is an object of class <a href="coda.html#topic+mcmc">coda::mcmc</a>, this is a way to capture
more information in case the user needs it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_(x)

get_logpost()

get_draws()

get_elapsed()

get_initial()

get_fun()

get_nsteps()

get_seed()

get_nchains()

get_burnin()

get_thin()

get_kernel()

get_multicore()

get_conv_checker()

get_cl()

get_progress()

get_chain_id()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcmc-output_+3A_x">x</code></td>
<td>
<p>Character scalar. Name of an argument to retrieve. If <code>x</code> was not
passed to the last call, the function returns with an error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>get_logpost</code> returns the <code>logposterior</code> value at each
iteration. The values correspond to a named numeric vector. If <code>nchains &gt; 1</code>
then it will return a list of length <code>nchains</code> with the corresponding logpost
values for each chain.
</p>
<p>The function <code>get_draws()</code> retrieves the proposed states from the
kernel function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Getting the logpost -------------------------------------------------------
set.seed(23133)
x &lt;- rnorm(200)
y &lt;- -4 + x*2 + rnorm(200)
f &lt;- function(p) {
  sum(dnorm(y - p[1] - x*p[2], log = TRUE))
}

# Setting a RAM kernel
kern &lt;- kernel_am(eps = 1e-2)

ans &lt;- MCMC(fun = f, initial = c(0, 1), nsteps = 2000, kernel = kern)
plot(
  # Plotting the logpost from the last run
  -get_logpost(), 
  # Getting the number of chains
  main = paste0("nchains: ", get_nchains()),
  
  # And the elapsed time
  sub  = sprintf("Run time: %.4f(s)", get_elapsed()[3]),
  type = "l",
  log = "y"
) 

# This also works using multiple chains
ans &lt;- MCMC(fun = f, initial = c(0, 0), nsteps=2000, nchains = 2, kernel = kern)

# In this case, just like -ans-, 
draws &lt;- get_draws()

# Plotting proposed points vs accepted
plot(
  draws[[1]], pch = 20,
  col = adjustcolor("gray", alpha = .5),
  main = "Accepted vs proposed states\n(chain 1)"
  )
lines(ans[[1]], pch = 20, col = "tomato", lwd = 2)
legend(
  "topleft", legend = c("Accepted", "Proposed"), pch = c(NA, 20),
  col = c("tomato", "black"), lty = c(1, NA), lwd = c(2, NA)
)

</code></pre>

<hr>
<h2 id='new_progress_bar'>Progress bar</h2><span id='topic+new_progress_bar'></span>

<h3>Description</h3>

<p>A simple progress bar. This function is used in <a href="#topic+MCMC">MCMC</a> when the function has
been called with a single processor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>new_progress_bar(
  n,
  probs = c(0, 0.25, 0.5, 0.75, 1),
  width = getOption("width", 80),
  symbol = "/",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="new_progress_bar_+3A_n">n</code></td>
<td>
<p>Integer. Number of steps.</p>
</td></tr>
<tr><td><code id="new_progress_bar_+3A_probs">probs</code></td>
<td>
<p>Double vector. Quantiles where to put marks</p>
</td></tr>
<tr><td><code id="new_progress_bar_+3A_width">width</code></td>
<td>
<p>Integer. Width of the bar in characters.</p>
</td></tr>
<tr><td><code id="new_progress_bar_+3A_symbol">symbol</code></td>
<td>
<p>Character. Single character symbol to print each bar.</p>
</td></tr>
<tr><td><code id="new_progress_bar_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="base.html#topic+cat">cat()</a></code> such as <code>file</code> and <code>append</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function that can be included at the interior of a loop to
mark the progress of the loop. It receives a single argument, <code>i</code>,
which is the number of the current step.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- new_progress_bar(20)
for (i in 1:20) {
  Sys.sleep(2/20)
  x(i)
}

</code></pre>

<hr>
<h2 id='plan_update_sequence'>Parameters' update sequence</h2><span id='topic+plan_update_sequence'></span>

<h3>Description</h3>

<p>Parameters' update sequence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plan_update_sequence(k, nsteps, fixed, scheme)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plan_update_sequence_+3A_k">k</code></td>
<td>
<p>Integer. Number of parameters</p>
</td></tr>
<tr><td><code id="plan_update_sequence_+3A_nsteps">nsteps</code></td>
<td>
<p>Integer. Number of steps.</p>
</td></tr>
<tr><td><code id="plan_update_sequence_+3A_fixed">fixed</code></td>
<td>
<p>Logical scalar or vector of length <code>k</code>. Indicates which parameters
will be treated as fixed or not. Single values are recycled.</p>
</td></tr>
<tr><td><code id="plan_update_sequence_+3A_scheme">scheme</code></td>
<td>
<p>Scheme in which the proposals are made (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameter <code>scheme</code> present on the currently available kernels sets the way
in which proposals are made. By default, <code>scheme = "joint"</code>, proposals are done
jointly, this is, at each step of the chain we are proposing new states for
each parameter of the model. When <code>scheme = "ordered"</code>, a sequential update schema
is followed, in which, at each step of the chain, proposals are made one
variable at a time, If <code>scheme = "random"</code>, proposals are also made one
variable at a time but in a random scheme.
</p>
<p>Finally, users can specify their own sequence of proposals for the variables
by passing a numeric vector to <code>scheme</code>, for example, if the user wants to make
sequential proposals following the scheme 2, 1, 3, then scheme must be set to
be <code>scheme = c(2, 1, 3)</code>.
</p>


<h3>Value</h3>

<p>A logical vector of size <code>nsteps</code> x <code>k</code>.
</p>

<hr>
<h2 id='reflect_on_boundaries'>Reflective Boundaries</h2><span id='topic+reflect_on_boundaries'></span>

<h3>Description</h3>

<p>Adjust a proposal according to its support by reflecting it. This is the workhorse
of <a href="#topic+kernel_normal_reflective">kernel_normal_reflective</a> and <a href="#topic+kernel_unif_reflective">kernel_unif_reflective</a>. It is intended
for internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reflect_on_boundaries(x, lb, ub, which)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reflect_on_boundaries_+3A_x">x</code></td>
<td>
<p>A numeric vector. The proposal</p>
</td></tr>
<tr><td><code id="reflect_on_boundaries_+3A_lb">lb</code>, <code id="reflect_on_boundaries_+3A_ub">ub</code></td>
<td>
<p>Numeric vectors of length <code>length(x)</code>. Lower and upper bounds.</p>
</td></tr>
<tr><td><code id="reflect_on_boundaries_+3A_which">which</code></td>
<td>
<p>Integer vector. Index of variables to be updated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An adjusted proposal vector.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
