<!DOCTYPE html><html lang="en"><head><title>Help for package mnorm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mnorm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cmnorm'><p>Parameters of conditional multivariate normal distribution</p></a></li>
<li><a href='#dmnorm'><p>Density of (conditional) multivariate normal distribution</p></a></li>
<li><a href='#fromBase'><p>Convert base representation of a number into integer</p></a></li>
<li><a href='#halton'><p>Halton sequence</p></a></li>
<li><a href='#pbetaDiff'><p>Differentiate Regularized Incomplete Beta Function.</p></a></li>
<li><a href='#pmnorm'><p>Probabilities of (conditional) multivariate normal distribution</p></a></li>
<li><a href='#qnormFast'><p>Quantile function of a normal distribution</p></a></li>
<li><a href='#rmnorm'><p>Random number generator for (conditional) multivariate normal distribution</p></a></li>
<li><a href='#seqPrimes'><p>Sequence of prime numbers</p></a></li>
<li><a href='#stdt'><p>Standardized Student t Distribution</p></a></li>
<li><a href='#toBase'><p>Convert integer value to other base</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multivariate Normal Distribution</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-29</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculates and differentiates probabilities and density of (conditional) multivariate normal distribution and Gaussian copula (with various marginal distributions) using methods described in A. Genz (2004) &lt;<a href="https://doi.org/10.1023%2FB%3ASTCO.0000035304.20635.31">doi:10.1023/B:STCO.0000035304.20635.31</a>&gt;, A. Genz, F. Bretz (2009) &lt;<a href="https://doi.org/10.1007%2F978-3-642-01689-9">doi:10.1007/978-3-642-01689-9</a>&gt;, H. I. Gassmann (2003) &lt;<a href="https://doi.org/10.1198%2F1061860032283">doi:10.1198/1061860032283</a>&gt; and E. Kossova, B. Potanin (2018) <a href="https://ideas.repec.org/a/ris/apltrx/0346.html">https://ideas.repec.org/a/ris/apltrx/0346.html</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.10), hpa (&ge; 1.3.1)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, hpa</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-29 05:14:15 UTC; Bogdan</td>
</tr>
<tr>
<td>Author:</td>
<td>Bogdan Potanin [aut, cre, ctb],
  Sofiia Dolgikh [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Bogdan Potanin &lt;bogdanpotanin@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-29 07:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cmnorm'>Parameters of conditional multivariate normal distribution</h2><span id='topic+cmnorm'></span>

<h3>Description</h3>

<p>This function calculates mean (expectation) and covariance 
matrix of conditional multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmnorm(
  mean,
  sigma,
  given_ind,
  given_x,
  dependent_ind = numeric(),
  is_validation = TRUE,
  is_names = TRUE,
  control = NULL,
  n_cores = 1L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cmnorm_+3A_mean">mean</code></td>
<td>
<p>numeric vector representing expectation of multivariate
normal vector (distribution).</p>
</td></tr>
<tr><td><code id="cmnorm_+3A_sigma">sigma</code></td>
<td>
<p>positively defined numeric matrix representing covariance
matrix of multivariate normal vector (distribution).</p>
</td></tr>
<tr><td><code id="cmnorm_+3A_given_ind">given_ind</code></td>
<td>
<p>numeric vector representing indexes of multivariate
normal vector which are conditioned at values given by 
<code>given_x</code> argument.</p>
</td></tr>
<tr><td><code id="cmnorm_+3A_given_x">given_x</code></td>
<td>
<p>numeric vector which <code>i</code>-th element corresponds to
the given value of the <code>given_ind[i]</code>-th element (component) of 
multivariate normal vector. If <code>given_x</code> is numeric matrix then it's 
rows are such vectors of given values.</p>
</td></tr>
<tr><td><code id="cmnorm_+3A_dependent_ind">dependent_ind</code></td>
<td>
<p>numeric vector representing indexes of unconditional
elements (components) of multivariate normal vector.</p>
</td></tr>
<tr><td><code id="cmnorm_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether input 
arguments should be validated.  Set it to <code>FALSE</code> to get
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="cmnorm_+3A_is_names">is_names</code></td>
<td>
<p>logical value indicating whether output 
values should have row and column names. Set it to <code>FALSE</code> to get
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="cmnorm_+3A_control">control</code></td>
<td>
<p>a list of control parameters. See Details.</p>
</td></tr>
<tr><td><code id="cmnorm_+3A_n_cores">n_cores</code></td>
<td>
<p>positive integer representing the number of CPU cores
used for parallel computing. Currently it is not recommended to set
<code>n_cores &gt; 1</code> if vectorized arguments include less then 100000 elements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider <code class="reqn">m</code>-dimensional multivariate normal vector 
<code class="reqn">X=(X_{1},...,X_{m})^{T}~\sim N(\mu,\Sigma)</code>, where <code class="reqn">E(X)=\mu</code> and 
<code class="reqn">Cov(X)=\Sigma</code> are expectation (mean) and covariance matrix 
respectively.
</p>
<p>Let's denote vectors of indexes of conditioned and unconditioned elements of <code class="reqn">X</code>
by <code class="reqn">I_{g}</code> and <code class="reqn">I_{d}</code> respectively. By <code class="reqn">x^{(g)}</code> denote 
deterministic (column) vector of given values of <code class="reqn">X_{I_{g}}</code>. The 
function calculates expected value and covariance matrix of conditioned
multivariate normal vector <code class="reqn">X_{I_{d}} | X_{I_{g}} = x^{(g)}</code>. For example
if <code class="reqn">I_{g}=(1, 3)</code> and <code class="reqn">x^{(g)}=(-1, 1)</code> then <code class="reqn">I_{d}=(2, 4, 5)</code> 
so the function calculates:
</p>
<p style="text-align: center;"><code class="reqn">\mu_{c}=E\left(\left(X_{2}, X_{4}, X_{5}\right) | X_{1} = -1, X_{3} = 1\right)</code>
</p>

<p style="text-align: center;"><code class="reqn">\Sigma_{c}=Cov\left(\left(X_{2}, X_{4}, X_{5}\right) | 
      X_{1} = -1, X_{3} = 1\right)</code>
</p>

<p>In general case:
</p>
<p style="text-align: center;"><code class="reqn">\mu_{c} = E\left(X_{I_{d}} | X_{I_{g}} = x^{(g)}\right) = 
                \mu_{I_{d}} + 
                \left(x^{(g)} - \mu_{I_{g}}\right)
                \left(\Sigma_{(I_{d}, I_{g})}
                      \Sigma_{(I_{g}, I_{g})}^{-1}\right)^{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\Sigma_{c} = Cov\left(X_{I_{d}} | X_{I_{g}} = x^{(g)}\right) = 
                   \Sigma_{(I_{d}, I_{d})} - 
                   \Sigma_{(I_{d}, I_{g})}
                   \Sigma_{(I_{g}, I_{g})}^{-1}
                   \Sigma_{(I_{g}, I_{d})}</code>
</p>

<p>Note that <code class="reqn">\Sigma_{(A, B)}</code>, where <code class="reqn">A,B\in\{d, g\}</code>, 
is a submatrix of <code class="reqn">\Sigma</code> generated by intersection of <code class="reqn">I_{A}</code> 
rows and <code class="reqn">I_{B}</code> columns of <code class="reqn">\Sigma</code>. 
</p>
<p>Below there is a correspondence between aforementioned theoretical
(mathematical) notations and function arguments:
</p>

<ul>
<li> <p><code>mean</code> - <code class="reqn">\mu</code>.
</p>
</li>
<li> <p><code>sigma</code> - <code class="reqn">\Sigma</code>.
</p>
</li>
<li> <p><code>given_ind</code> - <code class="reqn">I_{g}</code>.
</p>
</li>
<li> <p><code>given_x</code> - <code class="reqn">x^{(g)}</code>.
</p>
</li>
<li> <p><code>dependent_ind</code> - <code class="reqn">I_{d}</code></p>
</li></ul>

<p>Moreover <code class="reqn">\Sigma_{(I_{g}, I_{d})}</code> is a theoretical (mathematical)
notation for <code>sigma[given_ind, dependent_ind]</code>. Similarly <code class="reqn">\mu_{g}</code>
represents <code>mean[given_ind]</code>.
</p>
<p>By default <code>dependent_ind</code> contains all indexes that are not
in <code>given_ind</code>. It is possible to omit and duplicate indexes of 
<code>dependent_ind</code>. But at least single index should be provided for 
<code>given_ind</code> without any duplicates. Also <code>dependent_ind</code> and 
<code>given_ind</code> should not have the same elements. Moreover <code>given_ind</code>
should not be of the same length as <code>mean</code> so at least one component
should be unconditioned.
</p>
<p>If <code>given_x</code> is a vector then (if possible) it will be treated as 
a matrix with the number of columns equal to the length of <code>mean</code>.
</p>
<p>Currently <code>control</code> has no input arguments intended for
the users. This argument is used for some internal purposes
of the package.
</p>


<h3>Value</h3>

<p>This function returns an object of class &quot;mnorm_cmnorm&quot;.<br /> <br />
An object of class &quot;mnorm_cmnorm&quot; is a list containing the 
following components:
</p>

<ul>
<li> <p><code>mean</code> - conditional mean.
</p>
</li>
<li> <p><code>sigma</code> - conditional covariance matrix.
</p>
</li>
<li> <p><code>sigma_d</code> - covariance matrix of unconditioned elements.
</p>
</li>
<li> <p><code>sigma_g</code> - covariance matrix of conditioned elements.
</p>
</li>
<li> <p><code>sigma_dg</code> - matrix of covariances between unconditioned
and conditioned elements.
</p>
</li>
<li> <p><code>s12s22</code> - equals to the matrix product of <code>sigma_dg</code>
and <code>solve(sigma_g)</code>.
</p>
</li></ul>

<p>Note that <code>mean</code> corresponds to <code class="reqn">\mu_{c}</code> while <code>sigma</code>
represents <code class="reqn">\Sigma_{c}</code>. Moreover <code>sigma_d</code> is 
<code class="reqn">\Sigma_{I_{d}, I_{d}}</code>, <code>sigma_g</code> is <code class="reqn">\Sigma_{I_{g}, I_{g}}</code> 
and <code>sigma_dg</code> is <code class="reqn">\Sigma_{I_{d}, I_{g}}</code>.
</p>
<p>Since <code class="reqn">\Sigma_{c}</code> do not depend on
<code class="reqn">X^{(g)}</code> the output <code>sigma</code> does not depend on <code>given_x</code>.
In particular output <code>sigma</code> remains the same independent of whether 
<code>given_x</code> is a matrix or vector. Oppositely if <code>given_x</code> is
a matrix then output <code>mean</code> is a matrix which rows correspond
to conditional means associated with given values provided by corresponding
rows of <code>given_x</code>.
</p>
<p>The order of elements of output <code>mean</code> and output <code>sigma</code> depends 
on the order of <code>dependet_ind</code> elements that is ascending by default.
The order of <code>given_ind</code> elements does not matter. But, please, check 
that the order of <code>given_ind</code> match the order of given values i.e. 
the order of <code>given_x</code> columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Consider multivariate normal vector:
# X = (X1, X2, X3, X4, X5) ~ N(mean, sigma)

# Prepare multivariate normal vector parameters
  # expected value
mean &lt;- c(-2, -1, 0, 1, 2)
n_dim &lt;- length(mean)
  # correlation matrix
cor &lt;- c(   1,  0.1,  0.2,   0.3,  0.4,
          0.1,    1, -0.1,  -0.2, -0.3,
          0.2, -0.1,    1,   0.3,  0.2,
          0.3, -0.2,  0.3,     1, -0.05,
          0.4, -0.3,  0.2, -0.05,     1)
cor &lt;- matrix(cor, ncol = n_dim, nrow = n_dim, byrow = TRUE)
  # covariance matrix
sd_mat &lt;- diag(c(1, 1.5, 2, 2.5, 3))
sigma &lt;- sd_mat %*% cor %*% t(sd_mat)

# Estimate parameters of conditional distribution i.e.
# when the first and the third components of X are conditioned:
# (X2, X4, X5 | X1 = -1, X3 = 1)
given_ind &lt;- c(1, 3)
given_x &lt;- c(-1, 1)
par &lt;- cmnorm(mean = mean, sigma = sigma,
              given_ind = given_ind,
              given_x = given_x)
  # E(X2, X4, X5 | X1 = -1, X3 = 1)
par$mean
  # Cov(X2, X4, X5 | X1 = -1, X3 = 1)
par$sigma

# Additionally calculate E(X2, X4, X5 | X1 = 2, X3 = 3)
given_x_mat &lt;- rbind(given_x, c(2, 3))
par1 &lt;- cmnorm(mean = mean, sigma = sigma,
               given_ind = given_ind,
               given_x = given_x_mat)
par1$mean

# Duplicates and omitted indexes are allowed for dependent_ind
# For given_ind duplicates are not allowed
# Let's calculate conditional parameters for (X5, X2, X5 | X1 = -1, X3 = 1):
dependent_ind &lt;- c(5, 2, 5)
par2 &lt;- cmnorm(mean = mean, sigma = sigma,
               given_ind = given_ind,
               given_x = given_x,
               dependent_ind = dependent_ind)
  # E(X5, X2, X5 | X1 = -1, X3 = 1)
par2$mean
  # Cov(X5, X2, X5 | X1 = -1, X3 = 1)
par2$sigma
</code></pre>

<hr>
<h2 id='dmnorm'>Density of (conditional) multivariate normal distribution</h2><span id='topic+dmnorm'></span>

<h3>Description</h3>

<p>This function calculates and differentiates density of 
(conditional) multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmnorm(
  x,
  mean,
  sigma,
  given_ind = numeric(),
  log = FALSE,
  grad_x = FALSE,
  grad_sigma = FALSE,
  is_validation = TRUE,
  control = NULL,
  n_cores = 1L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dmnorm_+3A_x">x</code></td>
<td>
<p>numeric vector representing the point at which density
should be calculated. If <code>x</code> is a matrix then each row determines
a new point.</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_mean">mean</code></td>
<td>
<p>numeric vector representing expectation of multivariate
normal vector (distribution).</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_sigma">sigma</code></td>
<td>
<p>positively defined numeric matrix representing covariance
matrix of multivariate normal vector (distribution).</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_given_ind">given_ind</code></td>
<td>
<p>numeric vector representing indexes of multivariate
normal vector which are conditioned at values of <code>x</code> with corresponding 
indexes i.e. <code>x[given_x]</code> or <code>x[, given_x]</code> if 
<code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_log">log</code></td>
<td>
<p>logical; if <code>TRUE</code> then probabilities (or densities) p are 
given as log(p) and derivatives will be given respect to log(p).</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_grad_x">grad_x</code></td>
<td>
<p>logical; if <code>TRUE</code> then the vector of partial derivatives
of the density function will be calculated respect to each
element of <code>x</code>. If <code>x</code> is a matrix then gradients will be
estimated for each row of <code>x</code>.</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_grad_sigma">grad_sigma</code></td>
<td>
<p>logical; if <code>TRUE</code> then the vector of partial
derivatives (gradient) of the density function will be calculated respect 
to each element of <code>sigma</code>. If <code>x</code> is a matrix then gradients 
will be estimated for each row of <code>x</code>.</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether input 
arguments should be validated.  Set it to <code>FALSE</code> to get
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_control">control</code></td>
<td>
<p>a list of control parameters. See Details.</p>
</td></tr>
<tr><td><code id="dmnorm_+3A_n_cores">n_cores</code></td>
<td>
<p>positive integer representing the number of CPU cores
used for parallel computing. Currently it is not recommended to set
<code>n_cores &gt; 1</code> if vectorized arguments include less then 100000 elements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider notations from the Details section of 
<code><a href="#topic+cmnorm">cmnorm</a></code>. The function calculates density 
<code class="reqn">f(x^{(d)}|x^{(g)})</code> of conditioned multivariate normal vector 
<code class="reqn">X_{I_{d}} | X_{I_{g}} = x^{(g)}</code>. Where <code class="reqn">x^{(d)}</code> is a subvector of
<code class="reqn">x</code> associated with <code class="reqn">X_{I_{d}}</code> i.e. unconditioned components.
Therefore <code>x[given_ind]</code> represents <code class="reqn">x^{(g)}</code> while
<code>x[-given_ind]</code> is <code class="reqn">x^{(d)}</code>.
</p>
<p>If <code>grad_x</code> is <code>TRUE</code> then function additionally estimates the
gradient respect to both unconditioned and conditioned components:
</p>
<p style="text-align: center;"><code class="reqn">\nabla f(x^{(d)}|x^{(g)})=
\left(\frac{\partial f(x^{(d)}|x^{(g)})}{\partial x_{1}}
,..., 
\frac{\partial f(x^{(d)}|x^{(g)})}{\partial x_{m}}\right),</code>
</p>

<p>where each <code class="reqn">x_{i}</code> belongs either to <code class="reqn">x^{(d)}</code> or <code class="reqn">x^{(g)}</code>
depending on whether <code class="reqn">i\in I_{d}</code> or <code class="reqn">i\in I_{g}</code> correspondingly.
In particular subgradients of density function respect to <code class="reqn">x^{(d)}</code> 
and <code class="reqn">x^{(g)}</code> are of the form:
</p>
<p style="text-align: center;"><code class="reqn">\nabla_{x^{(d)}}\ln f(x^{(d)}|x^{(g)}) =
-\left(x^{(d)}-\mu_{c}\right)\Sigma_{c}^{-1}</code>
</p>

<p style="text-align: center;"><code class="reqn">\nabla_{x^{(g)}}\ln f(x^{(d)}|x^{(g)}) =
-\nabla_{x^{(d)}}f(x^{(d)}|x^{(g)})\Sigma_{d,g}\Sigma_{g,g}^{-1}</code>
</p>

<p>If <code>grad_sigma</code> is <code>TRUE</code> then function additionally estimates
the gradient respect to the elements of covariance matrix <code class="reqn">\Sigma</code>.
For <code class="reqn">i\in I_{d}</code> and <code class="reqn">j\in I_{d}</code> the function calculates:
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial \ln f(x^{(d)}|x^{(g)})}{\partial \Sigma_{i, j}} = 
\left(\frac{\partial \ln f(x^{(d)}|x^{(g)})}{\partial x_{i}} \times 
\frac{\partial \ln f(x^{(d)}|x^{(g)})}{\partial x_{j}} -
\Sigma_{c,(i, j)}^{-1}\right) / 
\left(1 + I(i=j)\right),
</code>
</p>

<p>where <code class="reqn">I(i=j)</code> is an indicator function which equals <code class="reqn">1</code> when
the condition <code class="reqn">i=j</code> is satisfied and <code class="reqn">0</code> otherwise.
</p>
<p>For <code class="reqn">i\in I_{d}</code> and <code class="reqn">j\in I_{g}</code> the following formula is used:
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial \ln f(x^{(d)}|x^{(g)})}{\partial \Sigma_{i, j}} = 
-\frac{\partial \ln f(x^{(d)}|x^{(g)})}{\partial x_{i}} \times 
\left(\left(x^{(g)}-\mu_{g}\right)\Sigma_{g,g}^{-1}\right)_{q_{g}(j)}-
</code>
</p>
<p style="text-align: center;"><code class="reqn">
-\sum\limits_{k=1}^{n_{d}}(1+I(q_{d}(i)=k))\times
(\Sigma_{d,g}\Sigma_{g,g}^{-1})_{k,q_{g}(j)}\times
\frac{\partial \ln f(x^{(d)}|x^{(g)})}{\partial \Sigma_{i, q^{-1}_{d}(k)}},
</code>
</p>

<p>where <code class="reqn">q_{g}(j)=\sum\limits_{k=1}^{m} I\left(I_{g,k} \leq j\right)</code>
and <code class="reqn">q_{d}(i)=\sum\limits_{k=1}^{m} I\left(I_{d,k} \leq i\right)</code>
represent the order of the <code class="reqn">i</code>-th and <code class="reqn">j</code>-th elements 
in <code class="reqn">I_{g}</code> and <code class="reqn">I_{d}</code> correspondingly i.e. 
<code class="reqn">x_{i}=x^{(d)}_{q_{d}(i)}=x_{I_{d, q_{d}(i)}}</code> and 
<code class="reqn">x_{j}=x^{(g)}_{q_{g}(j)}=x_{I_{g, q_{g}(j)}}</code>.
Note that <code class="reqn">q_{g}(j)^{-1}</code> and <code class="reqn">q_{d}(i)^{-1}</code> are inverse functions.
Number of conditioned and unconditioned components are denoted by
<code class="reqn">n_{g}=\sum\limits_{k=1}^{m}I(k\in I_{g})</code> and 
<code class="reqn">n_{d}=\sum\limits_{k=1}^{m}I(k\in I_{d})</code> respectively.
For the case <code class="reqn">i\in I_{g}</code> and <code class="reqn">j\in I_{d}</code> the formula is similar.
</p>
<p>For <code class="reqn">i\in I_{g}</code> and <code class="reqn">j\in I_{g}</code> the following formula is used:
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial \ln f(x^{(d)}|x^{(g)})}{\partial \Sigma_{i, j}} = 
-\nabla_{x^{(d)}}\ln f(x^{(d)}|x^{(g)})\times
\left(x^{(g)}\times(\Sigma_{d,g} \times \Sigma_{g,g}^{-1} \times I_{g}^{*} \times 
\Sigma_{g,g}^{-1})^{T}\right)^T -
</code>
</p>
<p style="text-align: center;"><code class="reqn">
-\sum\limits_{k_{1}=1}^{n_{d}}\sum\limits_{k_{2}=k_{1}}^{n_{d}}
\frac{\partial \ln f(x^{(d)}|x^{(g)})}
{\partial \Sigma_{q_{d}(k_{1})^{-1}, q_{d}(k_{2})^{-1}}}
\left(\Sigma_{d,g} \times \Sigma_{g,g}^{-1} \times I_{g}^{*} \times 
\Sigma_{g,g}^{-1}\times\Sigma_{d,g}^T\right)_{q_{d}(k_{1})^{-1}, 
q_{d}(k_{2})^{-1}},
</code>
</p>

<p>where <code class="reqn">I_{g}^{*}</code> is a square <code class="reqn">n_{g}</code>-dimensional matrix of 
zeros except <code class="reqn">I_{g,(i,j)}^{*}=I_{g,(j,i)}^{*}=1</code>.
</p>
<p>Argument <code>given_ind</code> represents <code class="reqn">I_{g}</code> and it should not 
contain any duplicates. The order of <code>given_ind</code> elements
does not matter so it has no impact on the output.
</p>
<p>More details on abovementioned differentiation formulas could
be found in the appendix of E. Kossova and B. Potanin (2018).
</p>
<p>Currently <code>control</code> has no input arguments intended for
the users. This argument is used for some internal purposes
of the package.
</p>


<h3>Value</h3>

<p>This function returns an object of class &quot;mnorm_dmnorm&quot;.<br /> <br />
An object of class &quot;mnorm_dmnorm&quot; is a list containing the 
following components:
</p>

<ul>
<li> <p><code>den</code> - density function value at <code>x</code>.
</p>
</li>
<li> <p><code>grad_x</code> - gradient of density respect to <code>x</code> if 
<code>grad_x</code> or <code>grad_sigma</code> input argument is set to <code>TRUE</code>. 
</p>
</li>
<li> <p><code>grad_sigma</code> - gradient respect to the elements of <code>sigma</code>
if <code>grad_sigma</code> input argument is set to <code>TRUE</code>.
</p>
</li></ul>

<p>If <code>log</code> is <code>TRUE</code> then <code>den</code> is a log-density
so output <code>grad_x</code> and <code>grad_sigma</code> are calculated respect 
to the log-density.
</p>
<p>Output <code>grad_x</code> is a Jacobian matrix which rows are gradients of 
the density function calculated for each row of <code>x</code>. Therefore
<code>grad_x[i, j]</code> is a derivative of the density function respect to the
<code>j</code>-th argument at point <code>x[i, ]</code>.
</p>
<p>Output <code>grad_sigma</code> is a 3D array such that <code>grad_sigma[i, j, k]</code> 
is a partial derivative of the density function respect to the 
<code>sigma[i, j]</code> estimated for the observation <code>x[k, ]</code>.
</p>


<h3>References</h3>

<p>E. Kossova., B. Potanin (2018). 
Heckman method and switching regression model multivariate generalization.
Applied Econometrics, vol. 50, pages 114-143.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Consider multivariate normal vector:
# X = (X1, X2, X3, X4, X5) ~ N(mean, sigma)

# Prepare multivariate normal vector parameters
  # expected value
mean &lt;- c(-2, -1, 0, 1, 2)
n_dim &lt;- length(mean)
  # correlation matrix
cor &lt;- c(   1,  0.1,  0.2,   0.3,  0.4,
          0.1,    1, -0.1,  -0.2, -0.3,
          0.2, -0.1,    1,   0.3,  0.2,
          0.3, -0.2,  0.3,     1, -0.05,
          0.4, -0.3,  0.2, -0.05,     1)
cor &lt;- matrix(cor, ncol = n_dim, nrow = n_dim, byrow = TRUE)
  # covariance matrix
sd_mat &lt;- diag(c(1, 1.5, 2, 2.5, 3))
sigma &lt;- sd_mat %*% cor %*% t(sd_mat)

# Estimate the density of X at point (-1, 0, 1, 2, 3)
x &lt;- c(-1, 0, 1, 2, 3)
d.list &lt;- dmnorm(x = x, mean = mean, sigma = sigma)
d &lt;- d.list$den
print(d)

# Estimate the density of X at points
# x=(-1, 0, 1, 2, 3) and y=(-1.2, -1.5, 0, 1.2, 1.5)
y &lt;- c(-1.5, -1.2, 0, 1.2, 1.5)
xy &lt;- rbind(x, y)
d.list.1 &lt;- dmnorm(x = xy, mean = mean, sigma = sigma)
d.1 &lt;- d.list.1$den
print(d.1)

# Estimate the density of Xc=(X2, X4, X5 | X1 = -1, X3 = 1) at 
# point xd=(0, 2, 3) given conditioning values xg=(-1, 1)
given_ind &lt;- c(1, 3)
d.list.2 &lt;- dmnorm(x = x, mean = mean, sigma = sigma, 
                   given_ind = given_ind)
d.2 &lt;- d.list.2$den
print(d.2)

# Estimate the gradient of density respect to the argument and 
# covariance matrix at points 'x' and 'y'
d.list.3 &lt;- dmnorm(x = xy, mean = mean, sigma = sigma,
                   grad_x = TRUE, grad_sigma = TRUE)
# Gradient respect to the argument
grad_x.3 &lt;- d.list.3$grad_x
   # at point 'x'
print(grad_x.3[1, ])
   # at point 'y'
print(grad_x.3[2, ])
# Partial derivative at point 'y' respect 
# to the 3-rd argument
print(grad_x.3[2, 3])
# Gradient respect to the covariance matrix
grad_sigma.3 &lt;- d.list.3$grad_sigma
# Partial derivative respect to sigma(3, 5) at 
# point 'y'
print(grad_sigma.3[3, 5, 2])

# Estimate the gradient of the log-density function of 
# Xc=(X2, X4, X5 | X1 = -1, X3 = 1) and Yc=(X2, X4, X5 | X1 = -1.5, X3 = 0)
# respect to the argument and covariance matrix at 
# points xd=(0, 2, 3) and yd=(-1.2, 0, 1.5) respectively given
# conditioning values xg=(-1, 1) and yg=(-1.5, 0) correspondingly
d.list.4 &lt;- dmnorm(x = xy, mean = mean, sigma = sigma,
                   grad_x = TRUE, grad_sigma = TRUE,
                   given_ind = given_ind, log = TRUE)
# Gradient respect to the argument
grad_x.4 &lt;- d.list.4$grad_x
   # at point 'xd'
print(grad_x.4[1, ])
   # at point 'yd'
print(grad_x.4[2, ])
# Partial derivative at point 'xd' respect to 'xg[2]'
print(grad_x.4[1, 3])
# Partial derivative at point 'yd' respect to 'yd[5]'
print(grad_x.4[2, 5])
# Gradient respect to the covariance matrix
grad_sigma.4 &lt;- d.list.4$grad_sigma
# Partial derivative respect to sigma(3, 5) at 
# point 'yd'
print(grad_sigma.4[3, 5, 2])

# Compare analytical gradients from the previous example with
# their numeric (forward difference) analogues at point 'xd'
# given conditioning 'xg'
delta &lt;- 1e-6
grad_x.num &lt;- rep(NA, 5)
grad_sigma.num &lt;- matrix(NA, nrow = 5, ncol = 5)
for (i in 1:5)
{
  x.delta &lt;- x
  x.delta[i] &lt;- x[i] + delta
  d.list.delta &lt;- dmnorm(x = x.delta, mean = mean, sigma = sigma,
                         grad_x = TRUE, grad_sigma = TRUE,
                         given_ind = given_ind, log = TRUE)
  grad_x.num[i] &lt;- (d.list.delta$den - d.list.4$den[1]) / delta
   for(j in 1:5)
   {
     sigma.delta &lt;- sigma
     sigma.delta[i, j] &lt;- sigma[i, j] + delta 
     sigma.delta[j, i] &lt;- sigma[j, i] + delta 
     d.list.delta &lt;- dmnorm(x = x, mean = mean, sigma = sigma.delta,
                            grad_x = TRUE, grad_sigma = TRUE,
                            given_ind = given_ind, log = TRUE)
     grad_sigma.num[i, j] &lt;- (d.list.delta$den - d.list.4$den[1]) / delta
   }
}
# Comparison of gradients respect to the argument
h.x &lt;- cbind(analytical = grad_x.4[1, ], numeric = grad_x.num)
rownames(h.x) &lt;- c("xg[1]", "xd[1]", "xg[2]", "xd[3]", "xd[4]")
print(h.x)
# Comparison of gradients respect to the covariance matrix
h.sigma &lt;- list(analytical = grad_sigma.4[, , 1], numeric = grad_sigma.num)
print(h.sigma)
</code></pre>

<hr>
<h2 id='fromBase'>Convert base representation of a number into integer</h2><span id='topic+fromBase'></span>

<h3>Description</h3>

<p>Converts base representation of a number into integer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fromBase(x, base = 2L)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fromBase_+3A_x">x</code></td>
<td>
<p>vector of positive integer coefficients representing the number
in base that is <code>base</code>.</p>
</td></tr>
<tr><td><code id="fromBase_+3A_base">base</code></td>
<td>
<p>positive integer representing the base.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a positive integer that is a
conversion from <code>base</code> under given coefficients <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fromBase(c(1, 2, 0, 2, 3), 5)
</code></pre>

<hr>
<h2 id='halton'>Halton sequence</h2><span id='topic+halton'></span>

<h3>Description</h3>

<p>Calculate elements of the Halton sequence and of
some other pseudo-random sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>halton(
  n = 1L,
  base = as.integer(c(2)),
  start = 1L,
  random = "NO",
  type = "halton",
  scrambler = "NO",
  is_validation = TRUE,
  n_cores = 1L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="halton_+3A_n">n</code></td>
<td>
<p>positive integer representing the number of sequence elements.</p>
</td></tr>
<tr><td><code id="halton_+3A_base">base</code></td>
<td>
<p>vector of positive integers greater then one representing
the bases for each of the sequences.</p>
</td></tr>
<tr><td><code id="halton_+3A_start">start</code></td>
<td>
<p>non-negative integer representing the index of the first 
element of the sequence to be included in the output sequence.</p>
</td></tr>
<tr><td><code id="halton_+3A_random">random</code></td>
<td>
<p>string representing the method of randomization to be
applied to the sequence. If <code>random = "NO"</code> (default) then
there is no randomization. If <code>random = "Tuffin"</code> then standard uniform
random variable will be added to each element of the sequence and 
the difference between this sum and it's 'floor' will be returned as
a new element of the sequence.</p>
</td></tr>
<tr><td><code id="halton_+3A_type">type</code></td>
<td>
<p>string representing type of the sequence. Default is &quot;halton&quot;
that is Halton sequence. The alternative is &quot;richtmyer&quot; corresponding 
to Richtmyer sequence.</p>
</td></tr>
<tr><td><code id="halton_+3A_scrambler">scrambler</code></td>
<td>
<p>string representing scrambling method for the 
Halton sequence. Possible options are <code>"NO"</code> (default), <code>"root"</code>
and <code>"negroot"</code> which described in S. Kolenikov (2012).</p>
</td></tr>
<tr><td><code id="halton_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether input 
arguments should be validated.  Set it to <code>FALSE</code> to get
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="halton_+3A_n_cores">n_cores</code></td>
<td>
<p>positive integer representing the number of CPU cores
used for parallel computing. Currently it is not recommended to set
<code>n_cores &gt; 1</code> if vectorized arguments include less then 100000 elements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code><a href="#topic+seqPrimes">seqPrimes</a></code> could be used to
provide the prime numbers for the <code>base</code> input argument.
</p>


<h3>Value</h3>

<p>The function returns a matrix which <code>i</code>-th column
is a sequence with base <code>base[i]</code> and elements with indexes
from <code>start</code> to <code>start + n</code>.
</p>


<h3>References</h3>

<p>J. Halton (1964) &lt;doi:10.2307/2347972&gt;
</p>
<p>S. Kolenikov (2012) &lt;doi:10.1177/1536867X1201200103&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>halton(n = 100, base = c(2, 3, 5), start = 10)
</code></pre>

<hr>
<h2 id='pbetaDiff'>Differentiate Regularized Incomplete Beta Function.</h2><span id='topic+pbetaDiff'></span>

<h3>Description</h3>

<p>Calculate derivatives of the regularized incomplete 
beta function that is a cumulative distribution function of the beta
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbetaDiff(x, p = 10, q = 0.5, n = 10L, is_validation = TRUE, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pbetaDiff_+3A_x">x</code></td>
<td>
<p>numeric vector of values between 0 and 1. It is similar to
<code>q</code> argument of <code><a href="stats.html#topic+pbeta">pbeta</a></code> function.</p>
</td></tr>
<tr><td><code id="pbetaDiff_+3A_p">p</code></td>
<td>
<p>similar to <code>shape1</code> argument of 
<code><a href="stats.html#topic+pbeta">pbeta</a></code> function.</p>
</td></tr>
<tr><td><code id="pbetaDiff_+3A_q">q</code></td>
<td>
<p>similar to <code>shape2</code> argument of 
<code><a href="stats.html#topic+pbeta">pbeta</a></code> function.</p>
</td></tr>
<tr><td><code id="pbetaDiff_+3A_n">n</code></td>
<td>
<p>positive integer representing the number of iterations used
to calculate the derivatives. Greater values provide higher accuracy by the
cost of more computational resources.</p>
</td></tr>
<tr><td><code id="pbetaDiff_+3A_is_validation">is_validation</code></td>
<td>
<p>logical; if <code>TRUE</code> then input arguments are
validated. Set to <code>FALSE</code> to slightly increase the performance
of the function.</p>
</td></tr>
<tr><td><code id="pbetaDiff_+3A_control">control</code></td>
<td>
<p>list of control parameters. Currently not intended 
for the users.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements differentiation algorithm of 
R. Boik and J. Robinson-Cox (1998). 
Currently only first-order derivatives are considered.
</p>


<h3>Value</h3>

<p>The function returns a list which has the following elements:
</p>

<ul>
<li> <p><code>dx</code> - numeric vector of derivatives respect to each 
element of <code>x</code>.
</p>
</li>
<li> <p><code>dp</code> - numeric vector of derivatives respect to <code>p</code> for
each element of <code>x</code>.
</p>
</li>
<li> <p><code>dq</code> - numeric vector of derivatives respect to <code>q</code> for
each element of <code>x</code>.
</p>
</li></ul>



<h3>References</h3>

<p>Boik, R. J. and Robinson-Cox, J. F. (1998). Derivatives of the 
Incomplete Beta Function. Journal of Statistical Software, 3 (1),
pages 1-20.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Some values from Table 1 of R. Boik and J. Robinson-Cox (1998)
pbetaDiff(x = 0.001,  p = 1.5, q = 11)
pbetaDiff(x = 0.5,  p = 1.5, q = 11)

# Compare analytical and numeric derivatives
delta &lt;- 1e-6
x &lt;- c(0.01, 0.25, 0.5, 0.75, 0.99)
p &lt;- 5
q &lt;- 10
out &lt;- pbetaDiff(x = x, p = p, q = q)
p0 &lt;- pbeta(q = x, shape1 = p, shape2 = q)

# Derivatives respect to x
p1 &lt;- pbeta(q = x + delta, shape1 = p, shape2 = q)
data.frame(numeric = (p1 - p0) / delta, analytical = out$dx)
  
# Derivatives respect to p
p1 &lt;- pbeta(q = x, shape1 = p + delta, shape2 = q)
data.frame(numeric = (p1 - p0) / delta, analytical = out$dp)

# Derivatives respect to q
p1 &lt;- pbeta(q = x, shape1 = p, shape2 = q + delta)
data.frame(numeric = (p1 - p0) / delta, analytical = out$dq)

</code></pre>

<hr>
<h2 id='pmnorm'>Probabilities of (conditional) multivariate normal distribution</h2><span id='topic+pmnorm'></span>

<h3>Description</h3>

<p>This function calculates and differentiates probabilities of
(conditional) multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmnorm(
  lower,
  upper,
  given_x = numeric(),
  mean = numeric(),
  sigma = matrix(),
  given_ind = numeric(),
  n_sim = 1000L,
  method = "default",
  ordering = "mean",
  log = FALSE,
  grad_lower = FALSE,
  grad_upper = FALSE,
  grad_sigma = FALSE,
  grad_given = FALSE,
  is_validation = TRUE,
  control = NULL,
  n_cores = 1L,
  marginal = NULL,
  grad_marginal = FALSE,
  grad_marginal_prob = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pmnorm_+3A_lower">lower</code></td>
<td>
<p>numeric vector representing lower integration limits.
If <code>lower</code> is a matrix then each row determines new limits. Negative
infinite values are allowed while positive infinite values are prohibited.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_upper">upper</code></td>
<td>
<p>numeric vector representing upper integration limits.
If <code>upper</code> is a matrix then each row determines new limits. Positive
infinite values are allowed while negative infinite values are prohibited.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_given_x">given_x</code></td>
<td>
<p>numeric vector which <code>i</code>-th element corresponds to
the given value of the <code>given_ind[i]</code>-th element (component) of 
multivariate normal vector. If <code>given_x</code> is numeric matrix then it's 
rows are such vectors of given values.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_mean">mean</code></td>
<td>
<p>numeric vector representing expectation of multivariate
normal vector (distribution).</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_sigma">sigma</code></td>
<td>
<p>positively defined numeric matrix representing covariance
matrix of multivariate normal vector (distribution).</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_given_ind">given_ind</code></td>
<td>
<p>numeric vector representing indexes of multivariate
normal vector which are conditioned at values given by 
<code>given_x</code> argument.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_n_sim">n_sim</code></td>
<td>
<p>positive integer representing the number of draws from Richtmyer 
sequence in GHK algorithm. More draws provide more accurate results by the 
cost of additional computational burden. Alternative types of sequences
could be provided via <code>random_sequence</code> argument.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_method">method</code></td>
<td>
<p>string representing the method to be used to calculate
multivariate normal probabilities. Possible options are <code>"GHK"</code> and 
<code>"Gassmann"</code> recommended for high dimensional (more than 5) and 
low dimensional probabilities correspondingly.
Additional option <code>"default"</code> selects optimal method depending on
the number of dimensions. See 'Details' for additional information.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_ordering">ordering</code></td>
<td>
<p>string representing the method to be used to 
order the integrals. See Details section below.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_log">log</code></td>
<td>
<p>logical; if <code>TRUE</code> then probabilities (or densities) p are 
given as log(p) and derivatives will be given respect to log(p).</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_grad_lower">grad_lower</code></td>
<td>
<p>logical; if <code>TRUE</code> then the vector of partial 
derivatives of the probability will be calculated respect to each
element of <code>lower</code>. If <code>lower</code> is a matrix then gradients will be
estimated for each row of <code>lower</code>.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_grad_upper">grad_upper</code></td>
<td>
<p>logical; if <code>TRUE</code> then the vector of partial 
derivatives of the probability will be calculated respect to each
element of <code>upper</code>. If <code>upper</code> is a matrix then gradients will be
estimated for each row of <code>upper</code>.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_grad_sigma">grad_sigma</code></td>
<td>
<p>logical; if <code>TRUE</code> then the vector of partial
derivatives (gradient) of the probability will be calculated respect 
to each element of <code>sigma</code>. If <code>lower</code> and <code>upper</code> are
matrices then gradients will be estimated for each row of these matrices.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_grad_given">grad_given</code></td>
<td>
<p>logical; if <code>TRUE</code> then the vector of partial 
derivatives of the density function will be calculated respect to each
element of <code>given_x</code>. If <code>given_x</code> is a matrix then gradients 
will be estimated for each row of <code>given_x</code>.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether input 
arguments should be validated.  Set it to <code>FALSE</code> to get
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_control">control</code></td>
<td>
<p>a list of control parameters. See Details.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_n_cores">n_cores</code></td>
<td>
<p>positive integer representing the number of CPU cores
used for parallel computing. Currently it is not recommended to set
<code>n_cores &gt; 1</code> if vectorized arguments include less then 100000 elements.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_marginal">marginal</code></td>
<td>
<p>list such that <code>marginal[[i]]</code>
represents parameters of marginal distribution of the <code>i</code>-th component
of the random vector and <code>names(marginal)[i]</code> is a name of
this distribution. 
If <code>names(marginal)[i] = "logistic"</code> 
or <code>names(marginal)[i] = "normal"</code> 
then <code>marginal[[i]]</code> should be an empty vector or <code>NULL</code>. 
If <code>names(marginal)[i] = "student"</code> then
<code>marginal[[i]]</code> should contain a single element representing
degrees of freedom.
If <code>names(marginal)[i] = "PGN"</code>
or <code>names(marginal)[i] = "hpa"</code> then 
<code>marginal[[i]]</code> should be a numeric vector which elements
correspond to <code>pc</code> argument of <code><a href="hpa.html#topic+phpa0">phpa0</a></code>.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_grad_marginal">grad_marginal</code></td>
<td>
<p>logical; if <code>TRUE</code> then the vector of partial
derivatives (gradient) of probability will be calculated respect to 
each parameter of marginal distributions i.e. respect to
each element of <code>marginal</code>. The gradient respect to the parameters
of the <code>i</code>-th marginal distribution will be stored in the
<code>grad_marginal[[i]]</code> output matrix which <code>j</code>-th column
stores derivatives respect to <code>marginal[[i]][j]</code>.</p>
</td></tr>
<tr><td><code id="pmnorm_+3A_grad_marginal_prob">grad_marginal_prob</code></td>
<td>
<p>logical; if <code>TRUE</code> then the vector of partial
derivatives (gradient) of probability will be calculated respect to 
each cumulative marginal probability of marginal distributions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider notations from the Details sections of 
<code><a href="#topic+cmnorm">cmnorm</a></code> and <code><a href="#topic+dmnorm">dmnorm</a></code>. 
The function calculates probabilities of the form:
</p>
<p style="text-align: center;"><code class="reqn">P\left(x^{(l)}\leq X_{I_{d}}\leq 
x^{(u)}|X_{I_{g}}=x^{(g)}\right)</code>
</p>

<p>where <code class="reqn">x^{(l)}</code> and <code class="reqn">x^{(u)}</code> are lower and upper integration
limits respectively i.e. <code>lower</code> and 
<code>upper</code> correspondingly. Also <code class="reqn">x^{(g)}</code> represents <code>given_x</code>.
Note that <code>lower</code> and <code>upper</code> should be matrices of the same size.
Also <code>given_x</code> should have the same number of rows as <code>lower</code>
and <code>upper</code>.
</p>
<p>To calculate bivariate probabilities the function applies the method 
of Drezner and Wesolowsky
described in A. Genz (2004). In contrast to the classical implementation of 
this method the function applies Gauss-Legendre quadrature with 30 
sample points to approximate integral (1) of A. Genz (2004). Classical
implementations of this method use up to 20 points but requires some 
additional transformations of (1). During preliminary testing it has been 
found that approach with 30 points provides similar accuracy being 
slightly faster because of better vectorization capabilities.
</p>
<p>To calculate trivariate probabilities the function uses Drezner method
following formula (14) of A. Genz (2004). Similarly to bivariate
case 30 points are used in Gauss-Legendre quadrature.
</p>
<p>The function may apply the method of Gassmann (2003) for estimation of
<code class="reqn">m&gt;3</code> dimensional normal probabilities. It uses
matrix <code class="reqn">5</code> representation of Gassmann (2003) and 30 points of 
Gauss-Legendre quadrature.
</p>
<p>For <code class="reqn">m</code>-variate probabilities, where <code class="reqn">m &gt; 1</code>, the function may apply
GHK algorithm described in section 4.2 of A. Genz and F. Bretz (2009).
The implementation of GHK is based on deterministic Halton sequence 
with <code>n_sim</code> draws and uses variable reordering suggested in 
section 4.1.3 of A. Genz and F. Bretz (2009). The ordering algorithm may
be determined via <code>ordering</code> argument. Available options 
are <code>"NO"</code>, <code>"mean"</code> (default), and <code>"variance"</code>.
</p>
<p>Univariate probabilities are always calculated via standard approach so in
this case <code>method</code> will not affect the output.
If <code>method = "Gassmann"</code> then the function uses fast (aforementioned) 
algorithms for bivariate and trivariate probabilities or the method of 
Gassmann for <code class="reqn">m&gt;3</code> dimensional probabilities.
If <code>method = "GHK"</code> then GHK algorithm is used.
If <code>method = "default"</code> then <code>"Gassmann"</code> is used for bivariate
and trivariate probabilities while <code>"GHK"</code> is used for <code class="reqn">m&gt;3</code>
dimensional probabilities. During future updates <code>"Gassmann"</code> may become
a default method for calculation of the <code class="reqn">4-5</code> dimensional probabilities.
</p>
<p>We are going to provide alternative estimation algorithms during
future updates. These methods will be available via <code>method</code> argument.
</p>
<p>The function is optimized to perform much faster when all upper integration 
limits <code>upper</code> are finite while all lower integration limits 
<code>lower</code> are negative infinite. The derivatives could be also calculated
much faster when some integration limits are infinite.
</p>
<p>For simplicity of notations further let's consider 
unconditioned probabilities. Derivatives respect to conditioned components 
are similar to those mentioned in Details section 
of <code><a href="#topic+dmnorm">dmnorm</a></code>. We also provide formulas for <code class="reqn">m \geq 3</code>.
But the function may calculate derivatives for <code class="reqn">m \leq 2</code> using some
simplifications of the formulas mentioned below.
</p>
<p>If <code>grad_upper</code> is <code>TRUE</code> then function additionally estimates the
gradient respect to <code>upper</code>:
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial P\left(x^{(l)}\leq X\leq 
x^{(u)}\right)}{\partial x^{(u)}_{i}}=
P\left(x^{(l)}_{(-i)}\leq X_{(-i)}\leq x^{(u)}_{(-i)}|
X_{i}=x^{(u)}_{i}\right)
f_{X_{i}}\left(x^{(u)}_{i};\mu_{i},\Sigma_{i,i}\right)
</code>
</p>

<p>If <code>grad_lower</code> is <code>TRUE</code> then function additionally estimates the
gradient respect to <code>lower</code>:
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial P\left(x^{(l)}\leq X\leq 
x^{(u)}\right)}{\partial x^{(l)}_{i}}=
-P\left(x^{(l)}_{(-i)}\leq X_{(-i)}\leq x^{(u)}_{(-i)}|
X_{i}=x^{(l)}_{i}\right)
f_{X_{i}}\left(x^{(l)}_{i};\mu_{i},\Sigma_{i,i}\right)
</code>
</p>

<p>If <code>grad_sigma</code> is <code>TRUE</code> then function additionally estimates the
gradient respect to <code>sigma</code>. For <code class="reqn">i\ne j</code> the function 
calculates derivatives respect to the covariances:
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial P\left(x^{(l)}\leq X\leq 
x^{(u)}\right)}{\partial \Sigma_{i, j}}=</code>
</p>

<p style="text-align: center;"><code class="reqn">
=P\left(x^{(l)}_{(-(i, j))}\leq X_{-(i, j)}\leq x^{(u)}_{(-(i, j))}|
X_{i}=x^{(u)}_{i}, X_{j}=x^{(u)}_{j}\right)
f_{X_{i}, X_{j}}\left(x^{(u)}_{i}, x^{(u)}_{j};
\mu_{(i,j)},\Sigma_{(i, j),(i, j)}\right) -
</code>
</p>

<p style="text-align: center;"><code class="reqn">
-P\left(x^{(l)}_{(-(i, j))}\leq X_{-(i, j)}\leq x^{(u)}_{(-(i, j))}|
X_{i}=x^{(l)}_{i}, X_{j}=x^{(u)}_{j}\right)
f_{X_{i}, X_{j}}\left(x^{(l)}_{i}, x^{(u)}_{j};
\mu_{(i,j)},\Sigma_{(i, j),(i, j)}\right) -
</code>
</p>

<p style="text-align: center;"><code class="reqn">
-P\left(x^{(l)}_{(-(i, j))}\leq X_{-(i, j)}\leq x^{(u)}_{(-(i, j))}|
X_{i}=x^{(u)}_{i}, X_{j}=x^{(l)}_{j}\right)
f_{X_{i}, X_{j}}\left(x^{(u)}_{i}, x^{(l)}_{j};
\mu_{(i,j)},\Sigma_{(i, j),(i, j)}\right) +
</code>
</p>

<p style="text-align: center;"><code class="reqn">
+P\left(x^{(l)}_{(-(i, j))}\leq X_{-(i, j)}\leq x^{(u)}_{(-(i, j))}|
X_{i}=x^{(l)}_{i}, X_{j}=x^{(l)}_{j}\right)
f_{X_{i}, X_{j}}\left(x^{(l)}_{i}, x^{(l)}_{j};
\mu_{(i,j)},\Sigma_{(i, j),(i, j)}\right)
</code>
</p>

<p>Note that if some of integration limits are infinite then some elements
of this equation converge to zero which highly simplifies the calculations.
</p>
<p>Derivatives respect to variances are calculated using derivatives
respect to covariances and integration limits:
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial P\left(x^{(l)}\leq X\leq 
x^{(u)}\right)}{\partial \Sigma_{i, i}}=
</code>
</p>

<p style="text-align: center;"><code class="reqn">
-\frac{\partial P\left(x^{(l)}\leq X\leq 
x^{(u)}\right)}{\partial x^{(l)}_{i}} \frac{x^{(l)}_{i}}{2\Sigma_{i, i}}
-\frac{\partial P\left(x^{(l)}\leq X\leq 
x^{(u)}\right)}{\partial x^{(u)}_{i}} \frac{x^{(u)}_{i}}{2\Sigma_{i, i}}-
</code>
</p>

<p style="text-align: center;"><code class="reqn">
-\sum\limits_{j\ne i}\frac{\partial P\left(x^{(l)}\leq X\leq 
x^{(u)}\right)}{\partial \Sigma_{i, j}}
\frac{\Sigma_{i, j}}{2\Sigma_{i, i}}
</code>
</p>

<p>If <code>grad_given</code> is <code>TRUE</code> then function additionally estimates the
gradient respect to <code>given_x</code> using formulas similar to those
described in Details section of <code><a href="#topic+dmnorm">dmnorm</a></code>.
</p>
<p>More details on abovementioned differentiation formulas could
be found in the appendix of E. Kossova and B. Potanin (2018).
</p>
<p>If <code>marginal</code> is not empty then Gaussian copula will be used instead of
a classical multivariate normal distribution. Without loss of generality
let's assume that <code class="reqn">\mu</code> is a vector of zeros and introduce some
additional notations:
</p>
<p style="text-align: center;"><code class="reqn">
q_{i}^{(u)} = \Phi^{-1}\left(P_{i}\left(\frac{x_{i}^{(u)}}{\sigma_{i}}\right)\right)
</code>
</p>

<p style="text-align: center;"><code class="reqn">
q_{i}^{(l)} = \Phi^{-1}\left(P_{i}\left(\frac{x_{i}^{(l)}}{\sigma_{i}}\right)\right)
</code>
</p>

<p>where <code class="reqn">\Phi(.)^{-1}</code> is a quantile function of a standard
normal distribution and <code class="reqn">P_{i}</code> is a cumulative distribution function
of the standartized (to zero mean and unit variance) marginal distribution 
which name and parameters are defined by 
<code>names(marginal)[i]</code> and <code>marginal[[i]]</code> correspondingly. 
For example if <code>marginal[i] = "logistic"</code> then:
</p>
<p style="text-align: center;"><code class="reqn">
P_{i}(t) = \frac{1}{1+e^{-\pi t / \sqrt{3}}}
</code>
</p>

<p>Let's denote by <code class="reqn">X^{*}</code> random vector which is distributed
with Gaussian (its covariance matrix is <code class="reqn">\Sigma</code>) copula and 
marginals defined by <code>marginal</code>.
Then probabilities for these random vector are calculated as follows:
</p>
<p style="text-align: center;"><code class="reqn">P\left(x^{(l)}\leq X^{*}\leq 
x^{(u)}\right) = 
P\left(\sigma q^{(l)}\leq X\leq 
\sigma q^{(u)}\right) = P_{0}\left(\sigma q^{(l)}, \sigma q^{(u)}\right)</code>
</p>

<p>where <code class="reqn">q^{(l)} = (q_{1}^{(l)},...,q_{m}^{(l)})</code>,
<code class="reqn">q^{(u)} = (q_{1}^{(u)},...,q_{m}^{(u)})</code> and 
<code class="reqn">\sigma = (\sqrt{\Sigma_{1, 1}},...,\sqrt{\Sigma_{m, m}})</code>. Therefore
probabilities of <code class="reqn">X^{*}</code> may be calculated using probabilities
of multivariate normal random vector <code class="reqn">X</code> (with the same
covariance matrix) by
substituting lower and upper integration limits <code class="reqn">x^{(l)}</code> and
<code class="reqn">x^{(u)}</code> with <code class="reqn">\sigma q^{(l)}</code> and <code class="reqn">\sigma q^{(u)}</code> 
correspondingly. Therefore differentiation formulas are similar to
those mentioned above and will be automatically adjusted if
<code>marginal</code> is not empty (including conditional probabilities).
</p>
<p>Argument <code>control</code> is a list with the following input parameters:
</p>

<ul>
<li> <p><code>random_sequence</code> &ndash; numeric matrix of uniform pseudo random numbers 
(like Halton sequence). The number of columns should be equal to
the number of dimensions of multivariate random vector. If omitted than 
this matrix will be generated automatically using <code>n_sim</code> number 
of simulations.</p>
</li></ul>



<h3>Value</h3>

<p>This function returns an object of class &quot;mnorm_pmnorm&quot;.<br /> <br />
An object of class &quot;mnorm_pmnorm&quot; is a list containing the 
following components:
</p>

<ul>
<li> <p><code>prob</code> - probability that multivariate normal random variable 
will be between <code>lower</code> and <code>upper</code> bounds.
</p>
</li>
<li> <p><code>grad_lower</code> - gradient of probability respect to <code>lower</code> if 
<code>grad_lower</code> or <code>grad_sigma</code> input argument is set to <code>TRUE</code>.
</p>
</li>
<li> <p><code>grad_upper</code> - gradient of probability respect to <code>upper</code> if 
<code>grad_upper</code> or <code>grad_sigma</code> input argument is set to <code>TRUE</code>.  
</p>
</li>
<li> <p><code>grad_sigma</code> - gradient respect to the elements of <code>sigma</code>
if <code>grad_sigma</code> input argument is set to <code>TRUE</code>.
</p>
</li>
<li> <p><code>grad_given</code> - gradient respect to the elements of <code>given_x</code>
if <code>grad_given</code> input argument is set to <code>TRUE</code>.
</p>
</li>
<li> <p><code>grad_marginal</code> - gradient respect to the elements of 
<code>marginal_par</code> if <code>grad_marginal</code> input argument is set 
to <code>TRUE</code>. Currently only derivatives respect to the parameters
of <code>"PGN"</code> distribution are available.
</p>
</li></ul>

<p>If <code>log</code> is <code>TRUE</code> then <code>prob</code> is a log-probability
so output <code>grad_lower</code>, <code>grad_upper</code>, <code>grad_sigma</code> and
<code>grad_given</code> are calculated respect to the log-probability.
</p>
<p>Output <code>grad_lower</code> and <code>grad_upper</code> are Jacobian matrices which 
rows are gradients of the probabilities calculated for each row of 
<code>lower</code> and <code>upper</code> correspondingly. Similarly <code>grad_given</code>
is a Jacobian matrix respect to <code>given_x</code>.
</p>
<p>Output <code>grad_sigma</code> is a 3D array such that <code>grad_sigma[i, j, k]</code> 
is a partial derivative of the probability function respect to the 
<code>sigma[i, j]</code> estimated for <code>k</code>-th observation.
</p>
<p>Output <code>grad_marginal</code> is a list such that <code>grad_marginal[[i]]</code> 
is a Jacobian matrice which rows are gradients of the probabilities 
calculated for each row of <code>lower</code> and <code>upper</code> correspondingly
respect to the elements of <code>marginal_par[[i]]</code>.
</p>


<h3>References</h3>

<p>Genz, A. (2004), Numerical computation of rectangular bivariate 
and trivariate normal and t-probabilities, Statistics and 
Computing, 14, 251-260.
</p>
<p>Genz, A. and Bretz, F. (2009), Computation of Multivariate 
Normal and t Probabilities. Lecture Notes in Statistics, Vol. 195. 
Springer-Verlag, Heidelberg.
</p>
<p>E. Kossova, B. Potanin (2018). 
Heckman method and switching regression model multivariate generalization.
Applied Econometrics, vol. 50, pages 114-143.
</p>
<p>H. I. Gassmann (2003). 
Multivariate Normal Probabilities: Implementing an Old Idea of Plackett's.
Journal of Computational and Graphical Statistics, vol. 12 (3),
pages 731-752.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Consider multivariate normal vector:
# X = (X1, X2, X3, X4, X5) ~ N(mean, sigma)

# Prepare multivariate normal vector parameters
  # expected value
mean &lt;- c(-2, -1, 0, 1, 2)
n_dim &lt;- length(mean)
  # correlation matrix
cor &lt;- c(   1,  0.1,  0.2,   0.3,  0.4,
          0.1,    1, -0.1,  -0.2, -0.3,
          0.2, -0.1,    1,   0.3,  0.2,
          0.3, -0.2,  0.3,     1, -0.05,
          0.4, -0.3,  0.2, -0.05,     1)
cor &lt;- matrix(cor, ncol = n_dim, nrow = n_dim, byrow = TRUE)
  # covariance matrix
sd_mat &lt;- diag(c(1, 1.5, 2, 2.5, 3))
sigma &lt;- sd_mat %*% cor %*% t(sd_mat)

# Estimate probability:
# P(-3 &lt; X1 &lt; 1, -2.5 &lt; X2 &lt; 1.5, -2 &lt; X3 &lt; 2, -1.5 &lt; X4 &lt; 2.5, -1 &lt; X5 &lt; 3)
lower &lt;- c(-3, -2.5, -2, -1.5, -1)
upper &lt;- c(1, 1.5, 2, 2.5, 3)
p.list &lt;- pmnorm(lower = lower, upper = upper,
                 mean = mean, sigma = sigma)
p &lt;- p.list$prob
print(p)

# Additionally estimate a probability
lower.1 &lt;- c(-Inf, 0, -Inf, 1, -Inf)
upper.1 &lt;- c(Inf, Inf, 3, 4, 5)
lower.mat &lt;- rbind(lower, lower.1)
upper.mat &lt;- rbind(upper, upper.1)
p.list.1 &lt;- pmnorm(lower = lower.mat, upper = upper.mat,
                   mean = mean, sigma = sigma)
p.1 &lt;- p.list.1$prob
print(p.1)

# Estimate the probabilities
# P(-1 &lt; X1 &lt; 1, -3 &lt; X3 &lt; 3, -5 &lt; X5 &lt; 5 | X2 = -2, X4 = 4)
lower.2 &lt;- c(-1, -3, -5)
upper.2 &lt;- c(1, 3, 5)
given_ind &lt;- c(2, 4)
given_x &lt;- c(-2, 4)
p.list.2 &lt;- pmnorm(lower = lower.2, upper = upper.2,
                   mean = mean, sigma = sigma,
                   given_ind = given_ind, given_x = given_x)
p.2 &lt;- p.list.2$prob
print(p.2)

# Additionally estimate the probability
# P(-Inf &lt; X1 &lt; 1, -3 &lt; X3 &lt; Inf, -Inf &lt; X5 &lt; Inf | X2 = 4, X4 = -2)
lower.3 &lt;- c(-Inf, -3, -Inf)
upper.3 &lt;- c(1, Inf, Inf)
given_x.1 &lt;- c(-2, 4)
lower.mat.2 &lt;- rbind(lower.2, lower.3)
upper.mat.2 &lt;- rbind(upper.2, upper.3)
given_x.mat &lt;- rbind(given_x, given_x.1)
p.list.3 &lt;- pmnorm(lower = lower.mat.2, upper = upper.mat.2,
                   mean = mean, sigma = sigma,
                   given_ind = given_ind, given_x = given_x.mat)
p.3 &lt;- p.list.3$prob
print(p.3)

# Estimate the gradient of previous probabilities respect various arguments
p.list.4 &lt;- pmnorm(lower = lower.mat.2, upper = upper.mat.2,
                   mean = mean, sigma = sigma,
                   given_ind = given_ind, given_x = given_x.mat,
                   grad_lower = TRUE, grad_upper = TRUE,
                   grad_sigma = TRUE, grad_given = TRUE)
p.4 &lt;- p.list.4$prob
print(p.4)
# Gradient respect to 'lower'
grad_lower &lt;- p.list.4$grad_lower
   # for the first probability
print(grad_lower[1, ])
   # for the second probability
print(grad_lower[2, ])
# Gradient respect to 'upper'
grad_upper &lt;- p.list.4$grad_upper
   # for the first probability
print(grad_upper[1, ])
   # for the second probability
print(grad_upper[2, ])
# Gradient respect to 'given_x'
grad_given &lt;- p.list.4$grad_given
   # for the first probability
print(grad_given[1, ])
   # for the second probability
print(grad_given[2, ])
# Gradient respect to 'sigma'
grad_given &lt;- p.list.4$grad_given
   # for the first probability
print(grad_given[1, ])
   # for the second probability
print(grad_given[2, ])


# Compare analytical gradients from the previous example with
# their numeric (forward difference) analogues for the first probability
n_dependent &lt;- length(lower.2)
n_given &lt;- length(given_x)
n_dim &lt;- n_dependent + n_given
delta &lt;- 1e-6
grad_lower.num &lt;- rep(NA, n_dependent)
grad_upper.num &lt;- rep(NA, n_dependent)
grad_given.num &lt;- rep(NA, n_given)
grad_sigma.num &lt;- matrix(NA, nrow = n_dim, ncol = n_dim)
for (i in 1:n_dependent)
{
  # respect to lower
  lower.delta &lt;- lower.2
  lower.delta[i] &lt;- lower.2[i] + delta
  p.list.delta &lt;- pmnorm(lower = lower.delta, upper = upper.2,
                         given_x = given_x,
                         mean = mean, sigma = sigma,
                         given_ind = given_ind)
  grad_lower.num[i] &lt;- (p.list.delta$prob - p.list.4$prob[1]) / delta
  # respect to upper
  upper.delta &lt;- upper.2
  upper.delta[i] &lt;- upper.2[i] + delta
  p.list.delta &lt;- pmnorm(lower = lower.2, upper = upper.delta,
                         given_x = given_x,
                         mean = mean, sigma = sigma,
                         given_ind = given_ind)
  grad_upper.num[i] &lt;- (p.list.delta$prob - p.list.4$prob[1]) / delta
}
for (i in 1:n_given)
{
  # respect to lower
  given_x.delta &lt;- given_x
  given_x.delta[i] &lt;- given_x[i] + delta
  p.list.delta &lt;- pmnorm(lower = lower.2, upper = upper.2,
                         given_x = given_x.delta,
                         mean = mean, sigma = sigma,
                         given_ind = given_ind)
  grad_given.num[i] &lt;- (p.list.delta$prob - p.list.4$prob[1]) / delta
}
for (i in 1:n_dim)
{
  for(j in 1:n_dim)
  {
    # respect to sigma
    sigma.delta &lt;- sigma
    sigma.delta[i, j] &lt;- sigma[i, j] + delta 
    sigma.delta[j, i] &lt;- sigma[j, i] + delta 
    p.list.delta &lt;- pmnorm(lower = lower.2, upper = upper.2,
                           given_x = given_x,
                           mean = mean, sigma = sigma.delta,
                           given_ind = given_ind)
    grad_sigma.num[i, j] &lt;- (p.list.delta$prob - p.list.4$prob[1]) / delta
  }
}
# Comparison of gradients respect to lower integration limits
h.lower &lt;- cbind(analytical = p.list.4$grad_lower[1, ], 
                 numeric = grad_lower.num)
print(h.lower)
# Comparison of gradients respect to upper integration limits
h.upper &lt;- cbind(analytical = p.list.4$grad_upper[1, ], 
                 numeric = grad_upper.num)
print(h.upper)
# Comparison of gradients respect to given values
h.given &lt;- cbind(analytical = p.list.4$grad_given[1, ], 
                 numeric = grad_given.num)
print(h.given)
# Comparison of gradients respect to the covariance matrix
h.sigma &lt;- list(analytical = p.list.4$grad_sigma[, , 1], 
                numeric = grad_sigma.num)
print(h.sigma)

# Let's again estimate probability
# P(-1 &lt; X1 &lt; 1, -3 &lt; X3 &lt; 3, -5 &lt; X5 &lt; 5 | X2 = -2, X4 = 4)
# But assume that standardized (to zero mean and unit variance): 
# 1) X1 and X2 have standardized PGN distribution with coefficients vectors
#    pc1 = (0.5, -0.2, 0.1) and pc2 = (0.2, 0.05) correspondingly.
# 2) X3 has standardized student distribution with 5 degrees of freedom
# 3) X4 has standardized logistic distribution
# 4) X5 has standard normal distribution
marginal &lt;- list(PGN = c(0.5, -0.2, 0.1), hpa = c(0.2, 0.05), 
                 student = 5, logistic = numeric(), normal = NULL)
p.list.5 &lt;- pmnorm(lower = lower.2, upper = upper.2,
                   mean = mean, sigma = sigma,
                   given_ind = given_ind, given_x = given_x,
                   grad_lower = TRUE, grad_upper = TRUE,
                   grad_sigma = TRUE, grad_given = TRUE,
                   marginal = marginal, grad_marginal = TRUE)     
# Lets investigate derivatives respect to parameters
# of marginal distributions
  # respect to pc1 of X1
p.list.5$grad_marginal[[1]]              
  # respect to pc2 of X2
p.list.5$grad_marginal[[2]]  
  # derivative respect to degrees of freedom of X5 is
  # currently unavailable and will be set to 0
p.list.5$grad_marginal[[3]]                    
</code></pre>

<hr>
<h2 id='qnormFast'>Quantile function of a normal distribution</h2><span id='topic+qnormFast'></span>

<h3>Description</h3>

<p>Calculate quantile of a normal distribution using
one of the available methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qnormFast(
  p,
  mean = 0L,
  sd = 1L,
  method = "Voutier",
  is_validation = TRUE,
  n_cores = 1L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qnormFast_+3A_p">p</code></td>
<td>
<p>numeric vector of values between 0 and 1 representing levels of
the quantiles.</p>
</td></tr>
<tr><td><code id="qnormFast_+3A_mean">mean</code></td>
<td>
<p>numeric value representing the expectation of a
normal distribution.</p>
</td></tr>
<tr><td><code id="qnormFast_+3A_sd">sd</code></td>
<td>
<p>positive numeric value representing standard deviation of a
normal distribution.</p>
</td></tr>
<tr><td><code id="qnormFast_+3A_method">method</code></td>
<td>
<p>character representing the method to be used for
quantile calculation. Available options are &quot;Voutier&quot; (default) and &quot;Shore&quot;.</p>
</td></tr>
<tr><td><code id="qnormFast_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether input 
arguments should be validated.  Set it to <code>FALSE</code> to get
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="qnormFast_+3A_n_cores">n_cores</code></td>
<td>
<p>positive integer representing the number of CPU cores
used for parallel computing. Currently it is not recommended to set
<code>n_cores &gt; 1</code> if vectorized arguments include less then 100000 elements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "Voutier"</code> then the method of P. Voutier (2010)
is used which maximum absolute error is about <code class="reqn">0.000025</code>.
If <code>method = "Shore"</code> then the approach proposed
by H. Shore (1982) is applied which maximum absolute error is about
<code class="reqn">0.026</code> for quantiles of level between <code class="reqn">0.0001</code> 
and <code class="reqn">0.9999</code>.
</p>


<h3>Value</h3>

<p>The function returns a vector of <code>p</code>-level quantiles of a
normal distribution with mean equal to <code>mean</code> and standard 
deviation equal to <code>sd</code>.
</p>


<h3>References</h3>

<p>H. Shore (1982) &lt;doi:10.2307/2347972&gt;
</p>
<p>P. Voutier (2010) &lt;doi:10.48550/arXiv.1002.0567&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>qnormFast(c(0.1, 0.9), mean = 1, sd = 2)
</code></pre>

<hr>
<h2 id='rmnorm'>Random number generator for (conditional) multivariate normal distribution</h2><span id='topic+rmnorm'></span>

<h3>Description</h3>

<p>This function generates random numbers (i.e. variates) from 
(conditional) multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmnorm(
  n,
  mean,
  sigma,
  given_ind = numeric(),
  given_x = numeric(),
  dependent_ind = numeric(),
  is_validation = TRUE,
  n_cores = 1L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmnorm_+3A_n">n</code></td>
<td>
<p>positive integer representing the number of random variates
to be generated from (conditional) multivariate normal distribution.
If <code>given_ind</code> is not empty vector then <code>n</code> should be
be equal to <code>nrow(given_x)</code>.</p>
</td></tr>
<tr><td><code id="rmnorm_+3A_mean">mean</code></td>
<td>
<p>numeric vector representing expectation of multivariate
normal vector (distribution).</p>
</td></tr>
<tr><td><code id="rmnorm_+3A_sigma">sigma</code></td>
<td>
<p>positively defined numeric matrix representing covariance
matrix of multivariate normal vector (distribution).</p>
</td></tr>
<tr><td><code id="rmnorm_+3A_given_ind">given_ind</code></td>
<td>
<p>numeric vector representing indexes of multivariate
normal vector which are conditioned at values given by 
<code>given_x</code> argument.</p>
</td></tr>
<tr><td><code id="rmnorm_+3A_given_x">given_x</code></td>
<td>
<p>numeric vector which <code>i</code>-th element corresponds to
the given value of the <code>given_ind[i]</code>-th element (component) of 
multivariate normal vector. If <code>given_x</code> is numeric matrix then it's 
rows are such vectors of given values.</p>
</td></tr>
<tr><td><code id="rmnorm_+3A_dependent_ind">dependent_ind</code></td>
<td>
<p>numeric vector representing indexes of unconditional
elements (components) of multivariate normal vector.</p>
</td></tr>
<tr><td><code id="rmnorm_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether input 
arguments should be validated.  Set it to <code>FALSE</code> to get
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="rmnorm_+3A_n_cores">n_cores</code></td>
<td>
<p>positive integer representing the number of CPU cores
used for parallel computing. Currently it is not recommended to set
<code>n_cores &gt; 1</code> if vectorized arguments include less then 100000 elements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses Cholesky decomposition to generate multivariate
normal variates from independent standard normal variates.
</p>


<h3>Value</h3>

<p>This function returns a numeric matrix which rows a random variates
from (conditional) multivariate normal distribution with mean equal to
<code>mean</code> and covariance equal to <code>sigma</code>. If <code>given_x</code> and 
<code>given_ind</code> are also provided then random variates will be from
conditional multivariate normal distribution. Please, see details section
of <code><a href="#topic+cmnorm">cmnorm</a></code> to get additional information on the 
conditioning procedure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Consider multivariate normal vector:
# X = (X1, X2, X3, X4, X5) ~ N(mean, sigma)

# Prepare multivariate normal vector parameters
  # expected value
mean &lt;- c(-2, -1, 0, 1, 2)
n_dim &lt;- length(mean)
  # correlation matrix
cor &lt;- c(   1,  0.1,  0.2,   0.3,  0.4,
          0.1,    1, -0.1,  -0.2, -0.3,
          0.2, -0.1,    1,   0.3,  0.2,
          0.3, -0.2,  0.3,     1, -0.05,
          0.4, -0.3,  0.2, -0.05,     1)
cor &lt;- matrix(cor, ncol = n_dim, nrow = n_dim, byrow = TRUE)
  # covariance matrix
sd_mat &lt;- diag(c(1, 1.5, 2, 2.5, 3))
sigma &lt;- sd_mat %*% cor %*% t(sd_mat)

# Simulate random variates from this distribution
rmnorm(n = 3, mean = mean, sigma = sigma)

# Simulate random variate from (X1, X3, X5 | X1 = -1, X4 = 1)
given_x &lt;- c(-1, 1)
given_ind = c(1, 4)
rmnorm(n = 1, mean = mean, sigma = sigma, 
       given_x = given_x, given_ind = given_ind)

# Simulate random variate from (X1, X3, X5 | X1 = -1, X4 = 1)
# and (X1, X3, X5 | X1 = 2, X4 = 3)
given_x = rbind(c(-1, 1), c(2, 3))
rmnorm(n = nrow(given_x), mean = mean, sigma = sigma, 
       given_x = given_x, given_ind = given_ind)
</code></pre>

<hr>
<h2 id='seqPrimes'>Sequence of prime numbers</h2><span id='topic+seqPrimes'></span>

<h3>Description</h3>

<p>Calculates the sequence of prime numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seqPrimes(n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seqPrimes_+3A_n">n</code></td>
<td>
<p>positive integer representing the number of sequence elements.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a numeric vector containing 
first <code>n</code> prime numbers. The current (naive) implementation of the 
algorithm is not efficient in terms of speed so it is suited for low 
<code>n &lt; 10000</code> but requires just O(n) memory usage.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>seqPrimes(10)
</code></pre>

<hr>
<h2 id='stdt'>Standardized Student t Distribution</h2><span id='topic+stdt'></span><span id='topic+dt0'></span><span id='topic+pt0'></span><span id='topic+rt0'></span><span id='topic+qt0'></span>

<h3>Description</h3>

<p>These functions calculate and differentiate a cumulative 
distribution function and density function of the standardized 
(to zero mean and unit variance) Student distribution. Quantile function 
and random numbers generator are also provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dt0(x, df = 10, log = FALSE, grad_x = FALSE, grad_df = FALSE)

pt0(x, df = 10, log = FALSE, grad_x = FALSE, grad_df = FALSE, n = 10L)

rt0(n = 1L, df = 10)

qt0(x = 1L, df = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stdt_+3A_x">x</code></td>
<td>
<p>numeric vector of quantiles.</p>
</td></tr>
<tr><td><code id="stdt_+3A_df">df</code></td>
<td>
<p>positive real value representing the number of degrees of freedom.
Since this function deals with standardized Student distribution, argument
<code>df</code> should be greater than <code>2</code> because otherwise variance is
undefined.</p>
</td></tr>
<tr><td><code id="stdt_+3A_log">log</code></td>
<td>
<p>logical; if <code>TRUE</code> then probabilities (or densities) p 
are given as log(p) and derivatives will be given respect to log(p).</p>
</td></tr>
<tr><td><code id="stdt_+3A_grad_x">grad_x</code></td>
<td>
<p>logical; if <code>TRUE</code> then function returns a derivative
respect to <code>x</code>.</p>
</td></tr>
<tr><td><code id="stdt_+3A_grad_df">grad_df</code></td>
<td>
<p>logical; if <code>TRUE</code> then function returns a derivative
respect to <code>df</code>.</p>
</td></tr>
<tr><td><code id="stdt_+3A_n">n</code></td>
<td>
<p>positive integer. If <code>rt0</code> function is used then this 
argument represents the number of random draws. Otherwise <code>n</code> states 
for the number of iterations used to calculate the derivatives associated 
with <code>pt0</code> function via <code><a href="#topic+pbetaDiff">pbetaDiff</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standardized (to zero mean and unit variance) Student distribution 
has the following density and cumulative distribution functions:
</p>
<p style="text-align: center;"><code class="reqn">
f(x) = \frac{\Gamma\left(\frac{v + 1}{2}\right)}{
\sqrt{(v - 2)\pi}\Gamma\left(\frac{v}{2}\right)}
\left(1 + \frac{x^2}{v - 2}\right)^{-\frac{v+1}{2}},
</code>
</p>

<p style="text-align: center;"><code class="reqn">
F(x) = 
\begin{cases}
1 - \frac{1}{2}I(\frac{v - 2}{x^2 + v - 2}, 
\frac{v}{2}, \frac{1}{2})\text{, if }x \geq 0\\
\frac{1}{2}I(\frac{v - 2}{x^2 + v - 2}, 
\frac{v}{2}, \frac{1}{2})\text{, if }x &lt; 0
\end{cases},
</code>
</p>

<p>where <code class="reqn">v &gt; 2</code> is the number of degrees of freedom <code>df</code> and 
<code class="reqn">I(.)</code> is a cumulative distribution function of beta distribution 
which is calculated by <code><a href="stats.html#topic+pbeta">pbeta</a></code> function.
</p>


<h3>Value</h3>

<p>Function <code>rt0</code> returns a numeric vector of random numbers. 
Function <code>qt0</code> returns a numeric vector of quantiles. 
Functions <code>pt0</code> and <code>dt0</code> return a list which may contain the 
following elements:
</p>

<ul>
<li> <p><code>prob</code> - numeric vector of probabilities calculated for each 
element of <code>x</code>. Exclusively for <code>pt0</code> function.
</p>
</li>
<li> <p><code>den</code> - numeric vector of densities calculated for each 
each element of <code>x</code>. Exclusively for <code>dt0</code> function.
</p>
</li>
<li> <p><code>grad_x</code> - numeric vector of derivatives respect to <code>p</code> for
each element of <code>x</code>. 
This element appears only if input argument <code>grad_x</code> is <code>TRUE</code>.
</p>
</li>
<li> <p><code>grad_df</code> - numeric vector of derivatives respect to <code>q</code> for
each element of <code>x</code>.
This element appears only if input argument <code>grad_df</code> is <code>TRUE</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Simple examples
pt0(x = 0.3, df = 10, log = FALSE, grad_x = TRUE, grad_df = TRUE)
dt0(x = 0.3, df = 10, log = FALSE, grad_x = TRUE, grad_df = TRUE)
qt0(x = 0.3, df = 10)

# Compare analytical and numeric derivatives
delta &lt;- 1e-6
x &lt;- c(-2, -1, 0, 1, 2)
df &lt;- 5

# For probabilities
out &lt;- pt0(x, df = df, grad_x = TRUE, grad_df = TRUE)
p0 &lt;- out$prob
  # grad_x
p1 &lt;- pt0(x + delta, df = df)$prob
data.frame(numeric = (p1 - p0) / delta, analytical = out$grad_x)
  # grad_df
p1 &lt;- pt0(x, df = df + delta)$prob
data.frame(numeric = (p1 - p0) / delta, analytical = out$grad_df)

# For densities
out &lt;- dt0(x, df = df, grad_x = TRUE, grad_df = TRUE)
p0 &lt;- out$den
  # grad_x
p1 &lt;- dt0(x + delta, df = df)$den
data.frame(numeric = (p1 - p0) / delta, analytical = out$grad_x)
  # grad_df
p1 &lt;- dt0(x, df = df + delta)$den
data.frame(numeric = (p1 - p0) / delta, analytical = out$grad_df)

</code></pre>

<hr>
<h2 id='toBase'>Convert integer value to other base</h2><span id='topic+toBase'></span>

<h3>Description</h3>

<p>Converts integer value to other base.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toBase(x, base = 2L)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="toBase_+3A_x">x</code></td>
<td>
<p>positive integer representing the number to convert.</p>
</td></tr>
<tr><td><code id="toBase_+3A_base">base</code></td>
<td>
<p>positive integer representing the base.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a numeric vector containing 
representation of <code>x</code> in a base given in <code>base</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toBase(888, 5)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
