<!DOCTYPE html><html><head><title>Help for package scar</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {scar}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#scar-package'>
<p>Shape-Constrained Additive (index) Regression: a maximum likelihood approach</p></a></li>
<li><a href='#decathlon'><p>Men's decathlon athletes in 2012</p></a></li>
<li><a href='#decathlon_raw'><p>Men's decathlon in 2012</p></a></li>
<li><a href='#PhDPublications'><p>Doctoral Publications</p></a></li>
<li><a href='#plot.scair'><p>Plot additive index components of a &quot;scair&quot; object</p></a></li>
<li><a href='#plot.scar'><p>Plot components of a &quot;scar&quot; object</p></a></li>
<li><a href='#predict.scair'>
<p>Predict method for <code>scair</code> fits</p></a></li>
<li><a href='#predict.scar'>
<p>Predict method for <code>scar</code> fits</p></a></li>
<li><a href='#scair'>
<p>Maximizing the likelihood of the generalised additive index model</p>
with shape constraints</a></li>
<li><a href='#scar'>
<p>Compute the maximum likelihood estimator of the generalised additive regression</p>
with shape constraints</a></li>
<li><a href='#scar-internal'><p>Internal shape-constrained additive regression functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.2-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-05-25</td>
</tr>
<tr>
<td>Title:</td>
<td>Shape-Constrained Additive Regression: a Maximum Likelihood
Approach</td>
</tr>
<tr>
<td>Author:</td>
<td>Yining Chen and Richard Samworth</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yining Chen &lt;y.chen101@lse.ac.uk&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gam, mgcv, scam</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes the maximum likelihood estimator of the generalised additive and index regression with shape constraints. Each additive component function is assumed to obey one of the nine possible shape restrictions: linear, increasing, decreasing, convex, convex increasing, convex decreasing, concave, concave increasing, or concave decreasing. For details, see Chen and Samworth (2016) &lt;<a href="https://doi.org/10.1111%2Frssb.12137">doi:10.1111/rssb.12137</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-25 16:13:43 UTC; chen</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-25 22:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='scar-package'>
Shape-Constrained Additive (index) Regression: a maximum likelihood approach
</h2><span id='topic+scar-package'></span>

<h3>Description</h3>

<p><span class="pkg">scar</span> computes the maximum likelihood estimator of the generalised additive 
and index regression with shape constraints. Each component of the additive function of the 
predictors is assumed to belong to one of the nine possible shape restrictions: 
linear, increasing, decreasing, convex, convex and increasing, convex and decreasing, 
concave, concave and increasing, or concave and decreasing. 
For the generalised additive regression, the problem is transformed into a convex 
optimisation problem and the active set algorithm is used to find the optimum. 
We emphasise that unlike most of the other nonparametric methods, this approach is free 
of tuning parameters. 
</p>
<p>Furthermore, we can extend our findings to the generalised additive index regression, 
where a stochastic search algorithm is proposed to solve the problem. 
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
    Package: </td><td style="text-align: left;"> scar</td>
</tr>
<tr>
 <td style="text-align: left;">
    Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
    Version: </td><td style="text-align: left;"> 0.2-2</td>
</tr>
<tr>
 <td style="text-align: left;">
    Date: </td><td style="text-align: left;"> 2022-05-25</td>
</tr>
<tr>
 <td style="text-align: left;">
    License: </td><td style="text-align: left;"> GPL(&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>This package contains a selection of functions for maximum likelihood
estimation of the generalised additive (and additive index) regression under shape constraints:
</p>
<p><code><a href="#topic+scar">scar</a></code> computes the maximum likelihood estimator
(specified via its value at the observed covariates).  Output is a list of class
<code><a href="#topic+scar">scar</a></code> which is used as input to various auxiliary functions.
</p>
<p><code><a href="#topic+plot.scar">plot.scar</a></code> produces plots of the maximum likelihood
estimator produced by <code><a href="#topic+scar">scar</a></code> on the scale of the additive predictors.
</p>
<p><code><a href="#topic+predict.scar">predict.scar</a></code> obtains predictions either on the scale of the additive 
predictors or on the scale of the response variable from a fitted <code><a href="#topic+scar">scar</a></code> object.
</p>
<p><code><a href="#topic+scair">scair</a></code> tries to find the maximum likelihood estimator
(specified via its value at the observed indices).  Output is a list of class
<code><a href="#topic+scair">scair</a></code> which is used as input to various auxiliary functions.
</p>
<p><code><a href="#topic+plot.scair">plot.scair</a></code> produces plots of the maximum likelihood
estimator produced by <code><a href="#topic+scair">scair</a></code> on the scale of the additive index predictors.
</p>
<p><code><a href="#topic+predict.scair">predict.scair</a></code> obtains predictions either on the scale of the additive 
index predictors or on the scale of the response variable from a fitted <code><a href="#topic+scair">scair</a></code> object.
</p>
<p>The methods proposed here were applied to the following datasets: 
<code><a href="#topic+PhDPublications">PhDPublications</a></code>, <code><a href="#topic+decathlon">decathlon</a></code>.
</p>


<h3>Note</h3>

<p>The authors gratefully acknowledge the assistance of Ming Yuan for his insights into this problem.
</p>
<p>Thanks also go to Mary Meyer for kindly providing the authors with 
her manuscript prior to its publication.
</p>


<h3>Author(s)</h3>

<p>Yining Chen (maintainer) <a href="mailto:y.chen101@lse.ac.uk">y.chen101@lse.ac.uk</a>
</p>
<p>Richard Samworth <a href="mailto:r.samworth@statslab.cam.ac.uk">r.samworth@statslab.cam.ac.uk</a>
</p>


<h3>References</h3>

<p>Chen, Y. and Samworth, R. J. (2016).  Generalized additive and index models with shape constraints.
Journal of the Royal Statistical Society: Series B, 78, 729-754.
</p>
<p>Groeneboom, P., Jongbloed, G. and Wellner, J.A. (2008).
The support reduction algorithm for computing non-parametric function 
estimates in mixture models. Scandinavian Journal of Statistics, 35, 385-399.
</p>
<p>Hastie, T. and Tibshirani, R. (1990) Generalized Additive Models. 
Chapman and Hall, London.
</p>
<p>Meyer, M. C. (2013)  Semi-parametric additive constrained regression.
Journal of nonparametric statistics, 25, 715-743.
</p>
<p>Nocedal, J., and Wright, S. J. (2006) Numerical Optimization, 2nd edition. 
Springer, New York.
</p>
<p>Robertson, T., Wright, F. T. and Dykstra, R. L. (1988). 
Order Restricted Statistical Inference. Wiley, New York.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) Modern Applied
Statistics with S. Springer, New York.
</p>
<p>Wood, S. N. (2004) Stable and efficient multiple smoothing parameter estimation 
for generalized additive models. Journal of American Statistical Association, 
99, 673-686.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scar">scar</a></code>, <code><a href="#topic+scair">scair</a></code>, <code><a href="scam.html#topic+scam-package">scam</a></code>,  
<code><a href="stats.html#topic+glm">glm</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See examples provided in functions scar and scair
</code></pre>

<hr>
<h2 id='decathlon'>Men's decathlon athletes in 2012</h2><span id='topic+decathlon'></span>

<h3>Description</h3>

<p>This dataset consists of men's decathlon athletes who scored at least 6500 points in at least one athletic competition in 2012 and scored points in every event there. To avoid data dependency, we include only one performance from each athlete, namely their 2012 personal best (over the whole decathlon).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("decathlon")</code></pre>


<h3>Format</h3>

<p>A data frame containing 614 observations on 10 variables. Different rows represent results of different athletes.
</p>

<dl>
<dt>X100m</dt><dd><p>Points scored in 100 metres.</p>
</dd>
<dt>LJ</dt><dd><p>Points scored in long jump.</p>
</dd>
<dt>SP</dt><dd><p>Points scored in shot put.</p>
</dd>
<dt>HJ</dt><dd><p>Points scored in high jump.</p>
</dd>
<dt>X400m</dt><dd><p>Points scored in 400 metres.</p>
</dd>
<dt>X110H</dt><dd><p>Points scored in 110 metres hurdles.</p>
</dd>
<dt>DT</dt><dd><p>Points scored in discus throw.</p>
</dd>
<dt>PV</dt><dd><p>Points scored in polt vault.</p>
</dd>
<dt>JT</dt><dd><p>Points scored in javelin throw.</p>
</dd>
<dt>X1500m</dt><dd><p>Points scored in 1500 metres.</p>
</dd>
</dl>

<p>The point system (on how to convert results to scores) can be found at 
</p>
<p>http://en.wikipedia.org/wiki/Decathlon
</p>


<h3>Source</h3>

<p>Compiled from the dataset <code><a href="#topic+decathlon_raw">decathlon_raw</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(decathlon)
dat = as.matrix(decathlon[,c("X100m","SP","DT")]); y = decathlon$JT

## We consider the problem of predicting a decathlete's javelin performance 
## from their performances in the other decathlon disciplines.
## As an illustration, we only select 100m, shot put and discus throw
## also, we reduce the number of iterations here to shorten the run time
set.seed(1)
object = scair(dat,y,shape=c("in","in"),iter=40, allnonneg=TRUE)
object$index

## Here we can treat the obtained index matrix as a warm start and perform 
## further optimization using e.g. the default R optimisation routine.
## The result is actually only slightly different from the warm start.
## The optimisation itself takes around 5-10 seconds.
## Code provided but commented out here because CRAN team requires all the 
## examples running here to be completed in a few seconds.
# fn&lt;-function(w){
#  wnew = matrix(0,nrow=3,ncol=2)
#  wnew[1,1] = w[1]
#  wnew[2,1] = w[2]
#  wnew[3,1] = 1 - abs(w[1]) - abs(w[2]) 
#  wnew[1,2] = w[3]
#  wnew[2,2] = w[4]
#  wnew[3,2] = 1 - abs(w[3]) - abs(w[4])
#  if ((wnew[3,1] &lt; 0)|| (wnew[3,2] &lt; 0)) {dev = Inf}
#  else if ((w[1] &lt; 0) || (w[2] &lt; 0) || (w[3] &lt; 0) || (w[4] &lt; 0)) {dev = Inf}
#  else {
#    datnew = dat %*% wnew
#    dev = scar(datnew,y,shape=c("in","in"))$deviance
#  }
#  return (dev)
# }
#
# index123 = optim(c(object$index[1:2,1],object$index[1:2,2]),fn)$par
# newindex = matrix(0,nrow=3,ncol=2)
# newindex[1:2,1] = index123[1:2]; newindex[1:2,2] = index123[3:4]
# newindex[3,1] = 1 - sum(abs(index123[1:2]))
# newindex[3,2] = 1 - sum(abs(index123[3:4]))
# newindex

</code></pre>

<hr>
<h2 id='decathlon_raw'>Men's decathlon in 2012</h2><span id='topic+decathlon_raw'></span>

<h3>Description</h3>

<p>This dataset consists of men's decathlon results of at least 6500 points in 2012. Only those with athletes scored points in every event are included.
Most men's decathlons are divided into a two-day competition. First day events include 100 metres, long jump, shot put, high jump and 400 metres. Second day events include 110 metres hurdles, discus throw, pole vault, javelin throw and 1500 metres.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("decathlon_raw")</code></pre>


<h3>Format</h3>

<p>A data frame containing 1075 observations on 15 variables.
</p>

<dl>
<dt>Total</dt><dd><p>Total (decathlon) score.</p>
</dd>
<dt>Name</dt><dd><p>First name of the athlete.</p>
</dd>
<dt>Surname</dt><dd><p>Surname of the athlete.</p>
</dd>
<dt>X100m</dt><dd><p>Result of 100 metres, in seconds.</p>
</dd>
<dt>LJ</dt><dd><p>Result of long jump, in metres.</p>
</dd>
<dt>SP</dt><dd><p>Result of shot put, in metres.</p>
</dd>
<dt>HJ</dt><dd><p>Result of high jump, in metres.</p>
</dd>
<dt>X400m</dt><dd><p>Result of 400 metres, in seconds.</p>
</dd>
<dt>X110H</dt><dd><p>Result of 110 metres hurdles, in seconds.</p>
</dd>
<dt>DT</dt><dd><p>Result of discus throw, in metres.</p>
</dd>
<dt>PV</dt><dd><p>Result of polt vault, in metres.</p>
</dd>
<dt>JT</dt><dd><p>Result of javelin throw, in metres.</p>
</dd>
<dt>X1500m</dt><dd><p>Result of 1500 metres, in seconds.</p>
</dd>
<dt>First.day</dt><dd><p>Total points scored in the first day.</p>
</dd>
<dt>Second.day</dt><dd><p>Total points scored in the second day.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data compiled from the following sources:
</p>
<p>www.decathlon2000.com/
</p>
<p>www.iaaf.org/
</p>
<p>www.ceskydesetiboj.wz.cz/statistika.html
</p>


<h3>See Also</h3>

<p><code><a href="#topic+decathlon">decathlon</a></code></p>

<hr>
<h2 id='PhDPublications'>Doctoral Publications</h2><span id='topic+PhDPublications'></span>

<h3>Description</h3>

<p>Data on the scientific productivity of PhD students in biochemistry. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PhDPublications")</code></pre>


<h3>Format</h3>

<p>A data frame containing 915 observations on 6 variables:
</p>

<dl>
<dt>articles</dt><dd><p>Number of articles published during last 3 years of PhD.</p>
</dd>
<dt>gender</dt><dd><p>Factor indicating gender.</p>
</dd>
<dt>married</dt><dd><p>Factor indicating the marital status.</p>
</dd>
<dt>kids</dt><dd><p>Number of children less than 6 years old.</p>
</dd>
<dt>prestige</dt><dd><p>Prestige of the graduate program.</p>
</dd>
<dt>mentor</dt><dd><p>Number of articles published by student's mentor.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Imported directly from CRAN package AER (Kleiber and Zeileis, 2013) for the sake of convenience.
</p>


<h3>References</h3>

<p>Chen, Y. and Samworth, R. J. (2016).  Generalized additive and index models with shape constraints.
Journal of the Royal Statistical Society: Series B, 78, 729-754.
</p>
<p>Kleiber, C. and  Zeileis, A. (2013).
<em>AER: applied econometrics with R</em>.
R package version 1.2-0, http://cran.r-project.org/web/packages/AER/
</p>
<p>Long, J.S. (1990).
<em>Regression Models for Categorical and Limited Dependent Variables</em>.
Thousand Oaks: Sage Publications.
</p>
<p>Long, J.S. (1997). The origin of sex differences in science.
<em>Social Forces</em>, 68, 1297&ndash;1315.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Some data pre-processing
data(PhDPublications)
dat = matrix(0,ncol=4,nrow=nrow(PhDPublications))
dat[,1] = as.numeric(PhDPublications$gender == "female")
dat[,2] = as.numeric(PhDPublications$married == "yes")
dat[,3] = as.numeric(PhDPublications$kids)
dat[,4] = as.numeric(PhDPublications$mentor)
y = PhDPublications$articles

## Run scar on the dataset
object = scar(dat,y,shape=c("l","l","de","ccv"),family=poisson())

## Check the effects of mentor
plot(object,which=c(4))
</code></pre>

<hr>
<h2 id='plot.scair'>Plot additive index components of a &quot;scair&quot; object</h2><span id='topic+plot.scair'></span>

<h3>Description</h3>

<p>This function takes a fitted <code>scair</code> object produced 
by <code><a href="#topic+scair">scair</a></code> and plots the component functions of the additive indices
that make it up, on the scale of the additive index predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'scair'
plot(x, whichplot = 1:m, addp = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.scair_+3A_x">x</code></td>
<td>
<p>A fitted <code>scair</code> object produced 
by <code><a href="#topic+scair">scair</a></code>.</p>
</td></tr>
<tr><td><code id="plot.scair_+3A_whichplot">whichplot</code></td>
<td>
<p>A numeric vector indicates the required plots.</p>
</td></tr>
<tr><td><code id="plot.scair_+3A_addp">addp</code></td>
<td>
<p>A <code>logical</code> scalar that indicates whether the data points 
should be plotted as circles on the fitted curves of each component.</p>
</td></tr>
<tr><td><code id="plot.scair_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A plot is produced for each additive index component function in the fitted 
<code>scair</code> object. Each function is plotted in the range of the observed indices, 
with the identifiability condition satisfied (see Details of <code><a href="#topic+scar">scar</a></code> 
and <code><a href="#topic+scair">scair</a></code>).
</p>


<h3>Author(s)</h3>

<p>Yining Chen and Richard Samworth</p>


<h3>See Also</h3>

<p><code><a href="#topic+scair">scair</a></code>, <code><a href="#topic+predict.scair">predict.scair</a></code>, <code><a href="#topic+plot.scar">plot.scar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## See examples for the function scair
</code></pre>

<hr>
<h2 id='plot.scar'>Plot components of a &quot;scar&quot; object</h2><span id='topic+plot.scar'></span>

<h3>Description</h3>

<p>This function takes a fitted <code>scar</code> object produced 
by <code><a href="#topic+scar">scar</a></code> and plots the component functions that make it 
up, on the scale of the additive predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'scar'
plot(x, whichplot = 1:d, addp = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.scar_+3A_x">x</code></td>
<td>
<p>A fitted <code>scar</code> object produced 
by <code><a href="#topic+scar">scar</a></code>.</p>
</td></tr>
<tr><td><code id="plot.scar_+3A_whichplot">whichplot</code></td>
<td>
<p>A numeric vector indicates the required plots.</p>
</td></tr>
<tr><td><code id="plot.scar_+3A_addp">addp</code></td>
<td>
<p>A <code>logical</code> scalar that indicates whether the data points 
should be plotted as circles on the fitted curves of each component.</p>
</td></tr>
<tr><td><code id="plot.scar_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A plot is produced for each additive component in the fitted <code>scar</code> 
object. Each function is plotted in the range of the observed covariates, 
with the identifiability condition satisfied (see Details of <code><a href="#topic+scar">scar</a></code>).
</p>
<p>It can be invoked by calling <code>"plot(x)"</code> for an object <code>x</code> of the
<code>scar</code> class, or directly by calling <code>"plot.scar(x)"</code> regardless
of the class of the object.
</p>


<h3>Author(s)</h3>

<p>Yining Chen and Richard Samworth</p>


<h3>See Also</h3>

<p><code><a href="#topic+scar">scar</a></code>, <code><a href="#topic+predict.scar">predict.scar</a></code>, <code><a href="#topic+plot.scair">plot.scair</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## See examples for the function scar
</code></pre>

<hr>
<h2 id='predict.scair'>
Predict method for <code>scair</code> fits
</h2><span id='topic+predict.scair'></span>

<h3>Description</h3>

<p>This function obtains predictions from a fitted <code>scair</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'scair'
predict(object, newdata, type = c("link", "response"), rule=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.scair_+3A_object">object</code></td>
<td>
<p>A fitted <code>scair</code> object produced by <code><a href="#topic+scair">scair</a></code>.</p>
</td></tr>
<tr><td><code id="predict.scair_+3A_newdata">newdata</code></td>
<td>
<p>An optional numeric <code>matrix</code> of <code class="reqn">d</code> columns, with each row 
specifying a location at which prediction is required. This argument can be 
missing, in which case predictions are made at the same values of the 
covariates used to compute the object.</p>
</td></tr>
<tr><td><code id="predict.scair_+3A_type">type</code></td>
<td>
<p>Type of predictions, with choices &quot;link&quot; (the default),
or &quot;response&quot;. The default produces predictions on the scale of the index 
predictors. If &quot;response&quot; is selected, the predictions are on the scale of the 
response (i.e. mean of the exponential family), and are monotone 
transformations of the index predictors using the inverse link function.</p>
</td></tr>
<tr><td><code id="predict.scair_+3A_rule">rule</code></td>
<td>
<p>An integer describing how to handle the new data outside the range of the 
observed indices (computed via linear combination of observed covariates). 
If <code>rule=1</code>, then we use linear interpolation to get 
the value of each fitted component function outside the range of observed 
covariates. Otherwise if <code>rule=2</code>, then the value at the closest data 
extreme is used. Note that if there is convex/concave component, the choice of 
the first rule can lead to somewhat unsatifactary performance 
on/outside the &quot;boundary&quot; of the data  (when comparing to the second rule).</p>
</td></tr>
<tr><td><code id="predict.scair_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of predictions.</p>


<h3>Author(s)</h3>

<p>Yining Chen and Richard Samworth</p>


<h3>See Also</h3>

<p><code><a href="#topic+scair">scair</a></code>, <code><a href="#topic+plot.scair">plot.scair</a></code>, <code><a href="#topic+predict.scar">predict.scar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## See examples for the function scair
</code></pre>

<hr>
<h2 id='predict.scar'>
Predict method for <code>scar</code> fits
</h2><span id='topic+predict.scar'></span>

<h3>Description</h3>

<p>This function obtains predictions from a fitted <code>scar</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'scar'
predict(object, newdata, type = c("link", "response"), rule=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.scar_+3A_object">object</code></td>
<td>
<p>A fitted <code>scar</code> object produced by <code><a href="#topic+scar">scar</a></code>.</p>
</td></tr>
<tr><td><code id="predict.scar_+3A_newdata">newdata</code></td>
<td>
<p>An optional numeric <code>matrix</code> of <code class="reqn">d</code> columns, with each row 
specifying a location at which prediction is required. This argument can be 
missing, in which case predictions are made at the same values of the 
covariates used to compute the object.</p>
</td></tr>
<tr><td><code id="predict.scar_+3A_type">type</code></td>
<td>
<p>Type of predictions, with choices &quot;link&quot; (the default),
or &quot;response&quot;. The default produces predictions on the scale of the additive 
predictors. If &quot;response&quot; is selected, the predictions are on the scale of the 
response (i.e. mean of the exponential family), and are monotone 
transformations of the additive predictors using the inverse link function.</p>
</td></tr>
<tr><td><code id="predict.scar_+3A_rule">rule</code></td>
<td>
<p>An integer describing how to handle the new data outside the range of the 
observed covariates. If <code>rule=1</code>, then we use linear interpolation to get 
the value of each fitted component function outside the range of observed 
covariates. Otherwise if <code>rule=2</code>, then the value at the closest data 
extreme is used. Note that if there is convex/concave component, the choice of 
the first rule can lead to somewhat unsatifactary performance 
on/outside the boundary of the data (when comparing to the second rule).</p>
</td></tr>
<tr><td><code id="predict.scar_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of predictions.</p>


<h3>Author(s)</h3>

<p>Yining Chen and Richard Samworth</p>


<h3>See Also</h3>

<p><code><a href="#topic+scar">scar</a></code>, <code><a href="#topic+plot.scar">plot.scar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## See examples for the function scar
</code></pre>

<hr>
<h2 id='scair'>
Maximizing the likelihood of the generalised additive index model 
with shape constraints
</h2><span id='topic+scair'></span>

<h3>Description</h3>

<p>This function searches for a maximum likelihood estimator (mle) of the 
generalised additive index regression with shape constraints. A stochastic search 
strategy is used here. 
</p>
<p>Each index is a linear combination of some (or all) the covariates. 
Each additive component function of these index predictors is assumed to belong 
to one of the nine possible shape restrictions. 
</p>
<p>The output is an object of class <code>scair</code> which contains all the information 
needed to plot the estimator using the <code><a href="#topic+plot.scair">plot</a></code> method, or 
to evaluate it using the <code><a href="#topic+predict.scair">predict</a></code> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scair(x,y,shape=rep("l",1), family=gaussian(), weights=rep(1,length(y)), 
  epsilon=1e-8, delta=0.1, indexgen=c("unif", "norm"), iter = 200, 
  allnonneg = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scair_+3A_x">x</code></td>
<td>
<p>Observed covariates in <code class="reqn">R^d</code>, in the form of an <code class="reqn">n \times d</code> 
numeric <code>matrix</code>.</p>
</td></tr>  
<tr><td><code id="scair_+3A_y">y</code></td>
<td>
<p>Observed responses, in the form of a numeric <code>vector</code> of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="scair_+3A_shape">shape</code></td>
<td>
<p>A vector that specifies the shape restrictions for additive component function
of each index (also called the ridge function), in the form of a string vector of 
length <code class="reqn">m</code>. Here for the sake of identifiability, we require the number of 
indices <code class="reqn">m \le d</code>. The shape constraints we considered (with their 
coresponding abbreviations used in <code>shape</code>) are listed below:
</p>
<p><code>l</code>:	 linear
</p>
<p><code>in</code>:	 monotonically increasing
</p>
<p><code>de</code>:	 monotonically decreasing
</p>
<p><code>cvx</code>:	 convex
</p>
<p><code>cvxin</code>:	 convex and increasing	
</p>
<p><code>cvxde</code>:	 convex and decreasing	
</p>
<p><code>ccv</code>:	 concave
</p>
<p><code>ccvin</code>:	 concave and increasing	
</p>
<p><code>ccvde</code>:	 concave and decreasing</p>
</td></tr>
<tr><td><code id="scair_+3A_family">family</code></td>
<td>
<p>A description of the error distribution and link function to
be used in the model. This can be a character string naming a
family function, a family function or the result of a call to
a family function.  Currently only the following five common 
exponential families are allowed: Gaussian, Binomial, Poisson,
and Gamma. By default the canonical link function is used.</p>
</td></tr>
<tr><td><code id="scair_+3A_weights">weights</code></td>
<td>
<p>An optional vector of prior weights to be used when maximising the 
likelihood. It is a numeric vector of length <code class="reqn">n</code>. By default 
equal weights are used.</p>
</td></tr>
<tr><td><code id="scair_+3A_epsilon">epsilon</code></td>
<td>
<p>Positive convergence tolerance epsilon when performing the 
iteratively reweighted least squares (IRLS) method at each iteration of 
the active set algorithm in <code>scar</code>.  See <code><a href="#topic+scar">scar</a></code> 
for more details.</p>
</td></tr>
<tr><td><code id="scair_+3A_delta">delta</code></td>
<td>
<p>A tuning parameter used to avoid the perfect fit phenomenon, and to 
ensure identifiability. It represents the lower bound of the minimum 
eigenvalue of all possible <code class="reqn">A^T A</code> subject to identiability 
conditions, where <code class="reqn">A</code> is an index matrix. It should be smaller than 1. 
This parameter is NOT needed when <code class="reqn">d=1</code>, or the prediction function is
convex or concave, or all the entries of the index matrix are non-negative
if all ridge functions are increasing or decreasing.</p>
</td></tr>
<tr><td><code id="scair_+3A_indexgen">indexgen</code></td>
<td>
<p>It determines how the index matrices are generated in the stochastic
search. If its value is &quot;<code>unif</code>&quot;, then entries of the index matrices are drawn 
from uniform distribution; otherwise, if its value is &quot;<code>norm</code>&quot;, entries are 
drawn from normal.</p>
</td></tr>
<tr><td><code id="scair_+3A_iter">iter</code></td>
<td>
<p>Number of iterations of the stochastic search.</p>
</td></tr>
<tr><td><code id="scair_+3A_allnonneg">allnonneg</code></td>
<td>
<p>A boolean variable that specifies whether all the entries of the 
index matrices are non-negative. If it is true, then <code>delta</code> is no
longer needed in case the ridge functions are either all increasing, or all 
decreasing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code class="reqn">i = 1,\ldots,n</code>, let <code class="reqn">X_i</code> be the <code class="reqn">d</code>-dimensional
covariates, <code class="reqn">Y_i</code> be the corresponding one-dimensional response and 
<code class="reqn">w_i</code> be its weight. The generalised additive index model can be written as 
</p>
<p style="text-align: center;"><code class="reqn">g(\mu) = f(x),</code>
</p>
<p> where <code class="reqn">x=(x_1,\ldots,x_d)^T</code>,
<code class="reqn">g</code> is a known link function, <code class="reqn">A</code> is an <code class="reqn">d \times m</code> index matrix,  and 
<code class="reqn">f</code> is an additive function. Our task is to estimate both the index matrix and the 
additive function. 
</p>
<p>Assume the canonical link function is used here, then the maximum likelihood estimator 
of the generalised additive index model based on observations 
<code class="reqn">(X_1,Y_1), \ldots, (X_n,Y_n)</code> 
is the function that maximises 
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \sum_{i=1}^n w_i \{Y_i f(A^T X_i) - B(f(A^T X_i))\}</code>
</p>
 
<p>subject to the restrictions that for every <code class="reqn">j = 1,\ldots,m</code>, 
the <code class="reqn">j</code>-th additive component of <code class="reqn">f</code> satisfies the constraint indicated by the  
<code class="reqn">j</code>-th element of <code>shape</code>. Here <code class="reqn">B(.)</code> is the log-partition function of 
the specified exponential family distribution, and <code class="reqn">w_i</code> are the weights. For i.i.d. data, 
<code class="reqn">w_i</code> should be <code class="reqn">1</code> for each <code class="reqn">i</code>.
</p>
<p>For any given <code class="reqn">A</code>, the optimization problem can solved using the active set algorithm 
implemented in <code>scar</code>. Therefore, this problem can be reduced to a finite-dimensional 
optimisation problem. Here we apply a simple stochastic search strategy is proposed, though other methods, 
such as downhill simplex, is also possible (and sometimes offers competitive performance).
All the implementaton details can be found in <cite>Chen and Samworth (2016)</cite>, where theoretical 
justification of our estimator (i.e. uniform consistency) is also given.
</p>
<p>For the identifiability of additive index models, we refer to <cite>Yuan (2011)</cite>.
</p>


<h3>Value</h3>

<p>An object of class <code>scair</code>, with the following components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>Covariates copied from input.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Response copied from input.</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>
<p>Shape vector copied from input.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>Vector of weights copied from input.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>The exponential family copied from input.</p>
</td></tr>
<tr><td><code>componentfit</code></td>
<td>
<p>Value of the fitted component function at each observed 
index (computed using the estimated index matrix), in the form of an 
<code class="reqn">n \times m</code> numeric <code>matrix</code>, where the element at 
the <code class="reqn">i</code>-th row and the <code class="reqn">j</code>-th column is the value of <code class="reqn">f_j</code> 
at the <code class="reqn">j</code>-th coordinate of <code class="reqn">A^T X_i</code>,
with the identifiability condition satisfied (see details of <code><a href="#topic+scar">scar</a></code>).</p>
</td></tr>
<tr><td><code>constant</code></td>
<td>
<p>The estimated value of the constant <code class="reqn">c</code> in the 
additive function <code class="reqn">f</code> (see details of <code><a href="#topic+scar">scar</a></code>)).</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>Up to a constant, minus twice the maximised log-likelihood.
Where applicable, the constant is chosen to make the saturated
model to have zero deviance. See also <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
<tr><td><code>nulldeviance</code></td>
<td>
<p>The deviance for the null model.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>A parameter copied from input.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Total number of iterations of the stochastic search algorithm</p>
</td></tr>
<tr><td><code>allnonneg</code></td>
<td>
<p>specifies whether all entris of the index matrix is non-negative, 
copied from input.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yining Chen and Richard Samworth</p>


<h3>References</h3>

<p>Chen, Y. and Samworth, R. J. (2016).  Generalized additive and index models with shape constraints.
Journal of the Royal Statistical Society: Series B, 78, 729-754.
</p>
<p>Yuan, M. (2011). On the identifiability of additive index models. Statistica Sinica, 21, 1901-1911.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.scair">plot.scair</a></code>, <code><a href="#topic+predict.scair">predict.scair</a></code>, <code><a href="#topic+scar">scar</a></code>, <code><a href="#topic+decathlon">decathlon</a></code>   
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## An example in the Gaussian additive index regression setting:
## Define the additive function f on the scale of the predictors
f&lt;-function(x){
  return((0.5*x[,1]+0.25*x[,2]-0.25*x[,3])^2) 
}

## Simulate the covariates and the responses
## covariates are drawn uniformly from [-1,1]^3
set.seed(10)
d = 3
n = 500
x = matrix(runif(n*d)*2-1,nrow=n,ncol=d) 
y = f(x) + rnorm(n,sd=0.5)

## Single index model so no delta is required here
shape=c("cvx")
object = scair(x,y,shape=shape, family=gaussian(),iter = 100)

## Estimated index matrix
object$index

## Root squared error for the estimated index
sqrt(sum((object$index - c(0.5,0.25,-0.25))^2))

## Plot the estimatied additive function for the single index
plot(object)

## Evaluate the estimated prediction function at 10^4 random points 
## drawing from the interior of the support
testx = matrix((runif(10000*d)*1.96-0.98),ncol=d)
testf = predict(object,testx)

## and calculate the (estimated) absolute prediction error
mean(abs(testf-f(testx))) 

## Here we can treat the obtained index matrix as a warm start and perform 
## further optimization (on the second and third entry of the index)
## using e.g. the default R optimisation routine.
fn&lt;-function(w){
    dev = Inf
    if (abs(w[1])+abs(w[2])&gt;1) return(dev)
    else {
      wnew = matrix(c(1-abs(w[1])-abs(w[2]),w[1],w[2]),ncol=1)
      dev = scar(x %*% wnew, y, shape = "cvx")$deviance
      return (dev)
    } 
}
index23 = optim(object$index[2:3],fn)$par
newindex = matrix(c(1-sum(abs(index23)),index23),ncol=1); newindex

## Root squared error for the new estimated index
sqrt(sum((newindex - c(0.5,0.25,-0.25))^2))

## A further example is provided in decathlon dataset

</code></pre>

<hr>
<h2 id='scar'>
Compute the maximum likelihood estimator of the generalised additive regression 
with shape constraints
</h2><span id='topic+scar'></span>

<h3>Description</h3>

<p>This function uses the active set algorithm to compute the maximum likelihood 
estimator (mle) of the generalised additive regression with shape constraints. 
Each component function of the additive predictors is assumed to belong 
to one of the nine possible shape restrictions. The estimator's value at the 
data points is unique.
</p>
<p>The output is an object of class <code>scar</code> which contains all the information 
needed to plot the estimator using the <code><a href="#topic+plot.scar">plot</a></code> method, or 
to evaluate it using the <code><a href="#topic+predict.scar">predict</a></code> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scar(x, y, shape = rep("l", d), family = gaussian(),
  weights = rep(1, length(y)), epsilon = 1e-08)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scar_+3A_x">x</code></td>
<td>
<p>Observed covariates in <code class="reqn">R^d</code>, in the form of an <code class="reqn">n \times d</code> 
numeric <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="scar_+3A_y">y</code></td>
<td>
<p>Observed responses, in the form of a numeric <code>vector</code> of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="scar_+3A_shape">shape</code></td>
<td>
<p>A vector that specifies the shape restrictions for each component function,
in the form of a string vector of length <code class="reqn">d</code>. The string allowed and its 
corresponding shape constraint is listed as follows (see Details):
</p>
<p><code>l</code>:	 linear
</p>
<p><code>in</code>:	 monotonically increasing
</p>
<p><code>de</code>:	 monotonically decreasing
</p>
<p><code>cvx</code>:	 convex
</p>
<p><code>cvxin</code>:	 convex and increasing	
</p>
<p><code>cvxde</code>:	 convex and decreasing	
</p>
<p><code>ccv</code>:	 concave
</p>
<p><code>ccvin</code>:	 concave and increasing	
</p>
<p><code>ccvde</code>:	 concave and decreasing</p>
</td></tr>
<tr><td><code id="scar_+3A_family">family</code></td>
<td>
<p>A description of the error distribution and link function to
be used in the model. This can be a character string naming a
family function, a family function or the result of a call to
a family function.  Currently only the following five common 
exponential families are allowed: Gaussian, Binomial, Poisson,
and Gamma. By default the canonical link function is used.</p>
</td></tr>
<tr><td><code id="scar_+3A_weights">weights</code></td>
<td>
<p>An optional vector of prior weights to be used when maximising the 
likelihood. It is a numeric vector of length <code class="reqn">n</code>. By default 
equal weights are used.</p>
</td></tr>
<tr><td><code id="scar_+3A_epsilon">epsilon</code></td>
<td>
<p>Positive convergence tolerance epsilon when performing the 
iteratively reweighted least squares (IRLS) method at each iteration of 
the active set algorithm.  See <code><a href="stats.html#topic+glm.control">glm.control</a></code> 
for more details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code class="reqn">i = 1,\ldots,n</code>, let <code class="reqn">X_i</code> be the <code class="reqn">d</code>-dimensional
covariates, <code class="reqn">Y_i</code> be the corresponding one-dimensional response and 
<code class="reqn">w_i</code> be its weight. The generalised additive model can be written as 
</p>
<p style="text-align: center;"><code class="reqn">g(\mu) = f(x),</code>
</p>
<p> where <code class="reqn">x=(x_1,\ldots,x_d)^T</code>,
<code class="reqn">g</code> is a known link function and <code class="reqn">f</code> is an additive function (to be estimated). 
</p>
<p>Assume the canonical link function is used here, then the maximum likelihood estimator 
of the generalised additive model based on observations 
<code class="reqn">(X_1,Y_1), \ldots, (X_n,Y_n)</code> 
is the function that maximises 
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \sum_{i=1}^n w_i \{Y_i f(X_i) - B(f(X_i))\}</code>
</p>
 
<p>subject to the restrictions that for every <code class="reqn">j = 1,\ldots,d</code>, 
the <code class="reqn">j</code>-th additive component of <code class="reqn">f</code> satisfies the constraint indicated by the  
<code class="reqn">j</code>-th element of <code>shape</code>. Here <code class="reqn">B(.)</code> is the log-partition function of 
the specified exponential family distribution, and <code class="reqn">w_i</code> are the weights. For i.i.d. data, 
<code class="reqn">w_i</code> should be <code class="reqn">1</code> for each <code class="reqn">i</code>.
</p>
<p>To make each component of <code class="reqn">f</code> identifiable, we write
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \sum_{j=1}^d f_j(x_j) + c</code>
</p>
  
<p>and let <code class="reqn">f_j(0) = 0</code> for every <code class="reqn">j = 1,\ldots,d</code>. 
In case zero is outside the range of the <code class="reqn">j</code>-th observed covariate, 
for the sake of convenience, we set <code class="reqn">f_j</code> to be zero at the sample mean of
the <code class="reqn">j</code>-th predictor.
</p>
<p>This problem can then be re-written as a concave optimisation problem, and 
our function uses the active set algorithm to find out the maximum likelihood estimator. 
A general introduction can be found in <cite>Nocedal and Wright (2006)</cite>. 
A detailed description of our algorithm can be found in <cite>Chen and Samworth (2016)</cite>.
See also <cite>Groeneboom, Jongbloed and Wellner (2008)</cite> for some theoretical supports.
</p>


<h3>Value</h3>

<p>An object of class <code>scar</code>, with the following components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>Covariates copied from input.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Response copied from input.</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>
<p>Shape vector copied from input.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>The vector of weights copied from input.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>The exponential family copied from input.</p>
</td></tr>
<tr><td><code>componentfit</code></td>
<td>
<p>Value of the fitted component function at each observed 
covariate, in the form of an <code class="reqn">n \times d</code> numeric <code>matrix</code>,
where the element at the <code class="reqn">i</code>-th row and the <code class="reqn">j</code>-th column
is the value of <code class="reqn">f_j</code> at the <code class="reqn">j</code>-th coordinate of <code class="reqn">X_i</code>,
with the identifiability condition satisfied (see Details)</p>
</td></tr>
<tr><td><code>constant</code></td>
<td>
<p>The estimated value of the constant <code class="reqn">c</code> in the 
additive function <code class="reqn">f</code> (see Details).</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>Up to a constant, minus twice the maximised log-likelihood.
Where applicable, the constant is chosen to make the saturated
model to have zero deviance. See also <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
<tr><td><code>nulldeviance</code></td>
<td>
<p>The deviance for the null model.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Total number of iterations of the active set algorithm</p>
</td></tr></table>
<p>.
</p>


<h3>Note</h3>

<p>We acknowledge that <code><a href="stats.html#topic+glm.fit">glm.fit</a></code> from the R package 
<span class="pkg">stats</span> is called to perform the method of iterated reweighted least squares 
(IRLS) in our routine. It is possible to speed up the implementation considerably
by simply suppressing all the run-time checks there. 
</p>
<p>If all the component functions are linear, then it is prefered to call directly 
the function <code><a href="stats.html#topic+glm">glm</a></code>.
</p>
<p>For the one-dimensional covariate, see the pool adjacent violators algorithm (PAVA)
of <cite>Robertson, Wright and Dykstra (1998)</cite> and the support reduction method of 
<cite>Groeneboom, Jongbloed and Wellner (2008)</cite>. 
</p>
<p>A different approach to tackle this problem is to use splines. See the R package 
<code><a href="scam.html#topic+scam-package">scam</a></code>. We stress here that our approach is free 
of tuning parameters while <code><a href="scam.html#topic+scam-package">scam</a></code> is not, which 
can be viewed as a major difference.
</p>
<p>To estimate the generalised additive regression function without any shape 
restrictions, see <cite>Wood (2004)</cite> and <cite>Hastie and Tibshirani (1990)</cite>.
Their corresponding R implementations are <code><a href="mgcv.html#topic+mgcv-package">mgcv</a></code>
and <code><a href="gam.html#topic+gam">gam</a></code>.
</p>


<h3>Author(s)</h3>

<p>Yining Chen and Richard Samworth</p>


<h3>References</h3>

<p>Chen, Y. and Samworth, R. J. (2016).  Generalized additive and index models with shape constraints.
Journal of the Royal Statistical Society: Series B, 78, 729-754.
</p>
<p>Groeneboom, P., Jongbloed, G. and Wellner, J.A. (2008).
The support reduction algorithm for computing non-parametric function 
estimates in mixture models. Scandinavian Journal of Statistics, 35, 385-399.
</p>
<p>Hastie, T. and Tibshirani, R. (1990). Generalized Additive Models. 
Chapman and Hall, London.
</p>
<p>Meyer, M. C. (2013).  Semi-parametric additive constrained regression.
Journal of nonparametric statistics, 25, 715-743.
</p>
<p>Nocedal, J., and Wright, S. J. (2006). Numerical Optimization, 2nd edition. 
Springer, New York.
</p>
<p>Robertson, T., Wright, F. T. and Dykstra, R. L. (1988). 
Order Restricted Statistical Inference. Wiley, New York.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002). Modern Applied
Statistics with S. Springer, New York.
</p>
<p>Wood, S.N. (2004). Stable and efficient multiple smoothing parameter estimation 
for generalized additive models. Journal of American Statistical Association, 
99, 673-686.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.scar">plot.scar</a></code>, <code><a href="#topic+predict.scar">predict.scar</a></code>, <code><a href="#topic+scair">scair</a></code>, 
<code><a href="scam.html#topic+scam-package">scam</a></code>, <code><a href="mgcv.html#topic+mgcv-package">mgcv</a></code>,
<code><a href="gam.html#topic+gam">gam</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## An example in the Poission additive regression setting:
## Define the additive function f on the scale of the predictors
f&lt;-function(x){
  return(1*abs(x[,1]) + 2*(x[,2])^2 + 3*(abs(x[,3]))^3) 
}

## Simulate the covariates and the responses
## covariates are drawn uniformly from [-1,1]^3
set.seed(0)
d = 3
n = 500
x = matrix(runif(n*d)*2-1,nrow=n,ncol=d) 
rpoisson &lt;- function(m){rpois(1,exp(m))}
y = sapply(f(x),rpoisson)

## All the components are convex so one can use scar
shape=c("cvx","cvx","cvx")
object = scar(x,y,shape=shape, family=poisson())

## Plot each component of the estimatied additive function
plot(object)

## Evaluate the estimated additive function at 10^4 random points 
## drawing from the interior of the support
testx = matrix((runif(10000*d)*1.96-0.98),ncol=d)
testf = predict(object,testx)

## and calculate the (estimated) absolute prediction error
mean(abs(testf-f(testx))) 
</code></pre>

<hr>
<h2 id='scar-internal'>Internal shape-constrained additive regression functions</h2><span id='topic+aggsum'></span>

<h3>Description</h3>

<p>Internal functions for the package <span class="pkg">scar</span>
</p>


<h3>Details</h3>

<p>These internal functions are not to be called by the user. 
</p>
<p>For a given real sequence <code class="reqn">a_1,..., a_n</code>, the function <code><a href="#topic+aggsum">aggsum</a></code> 
returns the partial sums 
<code class="reqn">a_1, a_1+a_2, a_1+a_2+a_3,..., \sum_{i=1}^n a_i</code>. 
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
