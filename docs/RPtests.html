<!DOCTYPE html><html lang="en"><head><title>Help for package RPtests</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RPtests}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#pval'><p>Compute p-values for <code>RPtest</code> output</p></a></li>
<li><a href='#RPtest'><p>Goodness of fit tests for potentially high-dimensional linear models</p></a></li>
<li><a href='#RPtest_single'><p>Test significance of single predictors</p></a></li>
<li><a href='#sparse_proj'><p>Sparse projections using the square-root Lasso</p></a></li>
<li><a href='#sqrt_lasso'><p>Square-root Lasso regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Goodness of Fit Tests for High-Dimensional Linear Regression
Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs goodness of fits tests for both high and low-dimensional linear models.
    It can test for a variety of model misspecifications including nonlinearity and heteroscedasticity.
    In addition one can test the significance of potentially large groups of variables, and also
    produce p-values for the significance of individual variables in high-dimensional linear
    regression.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, parallel, randomForest, Rcpp, stats</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12234">https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12234</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-07-10 19:48:13 UTC; thera</td>
</tr>
<tr>
<td>Author:</td>
<td>Rajen Shah [aut, cre],
  Peter Buhlmann [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Rajen Shah &lt;r.shah@statslab.cam.ac.uk&gt;</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-07-10 20:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='pval'>Compute p-values for <code>RPtest</code> output</h2><span id='topic+pval'></span>

<h3>Description</h3>

<p>Produces p-values given a list of simulated test statistics and the true test
statistic (which may be a vector if it is the output of multiple RP
functions).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pval(test, test_sim)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pval_+3A_test">test</code></td>
<td>
<p>A numeric vector of test statistics.</p>
</td></tr>
<tr><td><code id="pval_+3A_test_sim">test_sim</code></td>
<td>
<p>A list of test statisitcs, each component of which is a
numeric vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case where the individual test statistics are vectors, the
first component of test is compared against the first components of
<code>test_sim[[1]]</code>, <code>test_sim[[2]]</code> etc. and the results of these
multiple comparisons are combined into a single p-value (see the
reference). When the lengths of the test statistics differ, the final
components are first discarded to make all the test statistics have equal
length.
</p>


<h3>Value</h3>

<p>A single p-value.
</p>


<h3>References</h3>

<p>Shah, R. D., Buhlmann, P. (2017) <em>Goodness of fit tests for
high-dimensional linear models</em> <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12234">https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12234</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RPtest">RPtest</a></code> the output of which this would typically be
applied to.
</p>

<hr>
<h2 id='RPtest'>Goodness of fit tests for potentially high-dimensional linear models</h2><span id='topic+RPtest'></span>

<h3>Description</h3>

<p>Can test for the significance of (potentially large) groups of predictors and
the presence of nonlinearity or heteroscedasticity in the context of both low
and high-dimensional linear models. Outputs a p-value. Also allows for the
calibration of arbitrary goodness of fit tests via specification of
<code>RPfunction</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RPtest(
  x,
  y,
  resid_type = c("Lasso", "OLS"),
  test = c("nonlin", "group", "hetero"),
  x_alt,
  RPfunction = NULL,
  B = 49L,
  rand_gen = rnorm,
  noise_matrix = NULL,
  mc.cores = 1L,
  nfolds = 5L,
  nperms = 2L,
  beta_est = NULL,
  resid_only = FALSE,
  output_all = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RPtest_+3A_x">x</code></td>
<td>
<p>Input matrix with <code>nobs</code> rows, each an observation vector.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_resid_type">resid_type</code></td>
<td>
<p>Type of residuals used for the test (see details below).
Use <code>Lasso</code> when the null model is high-dimensional; otherwise use
<code>OLS</code>.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_test">test</code></td>
<td>
<p>Type of departure from the linear model to test for (see details
below). Ignored if <code>RPfunction</code> is given.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_x_alt">x_alt</code></td>
<td>
<p>If <code>test</code> is <code>group</code>, this gives the set of variables
whose significance we wish to ascertain, after controlling for those in
<code>x</code>. If <code>RPfunction</code> is given, it is the input matrix passed to
the function <code>RPfunction</code>.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_rpfunction">RPfunction</code></td>
<td>
<p>A residual prediction (RP) function that must permit
calling as <code>RPfunction(x_alt, resid)</code> where <code>resid</code> is a numeric
vector with <code>nobs</code> components. The output must be either a single
number or a numeric vector (in the latter case <code>RPfunction</code> would
encode a number of RP functions).</p>
</td></tr>
<tr><td><code id="RPtest_+3A_b">B</code></td>
<td>
<p>The number of bootstrap samples to use - note the p-value produced
will always be at least 1/B.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_rand_gen">rand_gen</code></td>
<td>
<p>A function to generate the simulated errors up to an unknown
scale factor. It must permit calling as <code>rand_gen(nobs*B)</code>. Determines
the form of errors in the null model. The default <code>rnorm</code> equates to a
null of a (sparse) Gaussian linear model. Setting <code>rand_gen=NULL</code>
resamples residuals to generate simulated errors and approximates a null of
i.i.d. errors with unknown distribution.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_noise_matrix">noise_matrix</code></td>
<td>
<p>An optional matrix whose columns are the simulated errors to use.
Note that <code>B</code> and <code>rand_gen</code> will be ignored if this is supplied.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of cores to use. Will always be 1 in Windows.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds to use when performing cross-validation to
obtain <code>beta_est</code>, the initial estimate of the vector of regression
coefficients, via Lasso estimation.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_nperms">nperms</code></td>
<td>
<p>Number of permutations of the data for which <code>nfolds</code>
cross-validation is to be performed. Thus in total prediction errors on
<code>nfolds*nperms</code> folds are averaged over.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_beta_est">beta_est</code></td>
<td>
<p>An optional user-supplied estimate.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_resid_only">resid_only</code></td>
<td>
<p>If <code>TRUE</code> only outputs the residuals without applying
an RP function.</p>
</td></tr>
<tr><td><code id="RPtest_+3A_output_all">output_all</code></td>
<td>
<p>In addition to the p-value, gives further output (see Value
below).</p>
</td></tr>
<tr><td><code id="RPtest_+3A_verbose">verbose</code></td>
<td>
<p>Whether to print addition information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works by first computing residuals from a regression of
y on x. Next <code>B</code> sets of errors generated through <code>rand_gen</code> are
added to a signal derived from <code>beta_est</code> and aritificial residuals
are computed. The option <code>resid_only=TRUE</code> then outputs these
residuals along with the original residuals, scaled to have l_2-norm
squared equal to <code>nobs</code>. The residuals in question are OLS residuals
when <code>resid_type=OLS</code> (case a - for use when the null hypothesis is
low-dimensional so the number of columns of <code>x</code> is smaller than
<code>nobs-1</code>), and square-root / scaled Lasso residuals otherwise (case
b). The options for <code>test</code> then apply different functions to the
residuals as described below.
</p>

<dl>
<dt><code>nonlin</code></dt><dd><p>In case (a), the test statistic is the RSS (residual
sum of squares) of a <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> fit from
regressing the residuals on to <code>x</code>; case (b) is similar but the OOB
error is used and the regression is carried out on the equicorrelation set
rather than all of <code>x</code>.</p>
</dd>
<dt><code>group</code></dt><dd><p><code>x_alt</code> is first residualised with
respect to <code>x</code> by (a) OLS or (b) <code><a href="#topic+sparse_proj">sparse_proj</a></code>. Then the
RSS from Lasso fits from regressions of the residuals on to <code>x_alt</code>
are used.</p>
</dd>
<dt><code>hetero</code></dt><dd><p>Uses the RSS from Lasso fits from
regressions of the squared residuals to the equicorrelation set (b) or all
of <code>x</code> (a).</p>
</dd>
</dl>



<h3>Value</h3>

<p>When <code>resid_only=FALSE</code> and <code>output_all=FALSE</code>, the output
is a single p-value. Otherwise, a list with some of the following
components is returned (<code>resid_only=FALSE</code> causes the last two
components to be omitted):
</p>

<dl>
<dt><code>p-value</code></dt><dd><p>p-value</p>
</dd>
<dt><code>beta_est</code></dt><dd><p>estimated vector of regression coefficients
<code>beta_est</code></p>
</dd>
<dt><code>sigma_est</code></dt><dd><p>set to 1 when <code>resid_type=OLS</code>;
otherwise the normalised root-RSS derived from
<code>beta_est</code> used in generated the simulated errors</p>
</dd>
<dt><code>resid</code></dt><dd><p>scaled residuals</p>
</dd>
<dt><code>resid_sim</code></dt><dd><p>simulated scaled residuals</p>
</dd>
<dt><code>test</code></dt><dd><p>the test statistic(s) - may be a vector if multiple RP
functions are being used such as when <code>test=group</code></p>
</dd>
<dt><code>test_sim</code></dt><dd><p>a list of simulated test statistics</p>
</dd>
</dl>



<h3>References</h3>

<p>Shah, R. D., Buhlmann, P. (2017) <em>Goodness-of-fit tests for
high dimensional linear models</em> <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12234">https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12234</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RPtest_single">RPtest_single</a></code> and <code><a href="#topic+sqrt_lasso">sqrt_lasso</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Testing for nonlinearity
set.seed(1)
x &lt;- scale(matrix(runif(100*200), 100, 200))
y &lt;- x[, 1] + x[, 1]^4 + rnorm(nrow(x))
out &lt;- RPtest(x, y, test="nonlin", B=9L, nperms=2, resid_type = "Lasso")

# Testing significance of a group
y &lt;- x[, 1:5] %*% rep(1, 5) + x[, 151] + rnorm(nrow(x))
(out &lt;- RPtest(x[, 1:150], y, test="group", x_alt = x[, 151:200], B=9L, nperms=1))

# Testing for heteroscedasticity
x &lt;- scale(matrix(runif(250*100), 250, 100))
hetero_sig &lt;- x[, 1] + x[, 2]
var_vec &lt;- hetero_sig - min(hetero_sig) + 0.01
var_vec &lt;- var_vec / mean(var_vec)
sd_vec &lt;- sqrt(var_vec)
y &lt;- x[, 1:5] %*% rep(1, 5) + sd_vec*rnorm(nrow(x))
(out &lt;- RPtest(x, y, test="hetero", B=9L, nperms=1))
</code></pre>

<hr>
<h2 id='RPtest_single'>Test significance of single predictors</h2><span id='topic+RPtest_single'></span>

<h3>Description</h3>

<p>Compute p-values for the significance of each variable in <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RPtest_single(x, y, x_alt, B = 100L, rand_gen = rnorm, mc.cores = 1L)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RPtest_single_+3A_x">x</code></td>
<td>
<p>Input matrix with <code>nobs</code> rows, each an observation vector.</p>
</td></tr>
<tr><td><code id="RPtest_single_+3A_y">y</code></td>
<td>
<p>Response variable; shoud be a numeric vector.</p>
</td></tr>
<tr><td><code id="RPtest_single_+3A_x_alt">x_alt</code></td>
<td>
<p>Optional: a matrix with jth column the sparse projection of the
jth column of x on all its other columns i.e. the output of
<code><a href="#topic+sparse_proj">sparse_proj</a></code>. If not supplied this is computed by the
function.</p>
</td></tr>
<tr><td><code id="RPtest_single_+3A_b">B</code></td>
<td>
<p>Number of bootstrap samples. If set to 0, the asymptotic ditribution
is used for calibration.</p>
</td></tr>
<tr><td><code id="RPtest_single_+3A_rand_gen">rand_gen</code></td>
<td>
<p>A function to generate the simulated errors up to an unknown
scale factor. It must permit calling as <code>rand_gen(nobs*B)</code>. Determines
the form of errors in each of the null models, though the results are
broadly insensitive to this choice. The default <code>rnorm</code> equates to
null hypotheses of (sparse) Gaussian linear models. Setting
<code>rand_gen=NULL</code> resamples residuals to generate simulated errors and
approximates nulls of i.i.d. errors with unknown distributions.</p>
</td></tr>
<tr><td><code id="RPtest_single_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Number of cores to use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of p-values for each variable.
</p>


<h3>References</h3>

<p>Shah, R. D., Buhlmann, P. (2017) <em>Goodness of fit tests for
high-dimensional linear models</em> <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12234">https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12234</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RPtest">RPtest</a></code> and <code><a href="#topic+sparse_proj">sparse_proj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- scale(matrix(rnorm(50*100), 50, 100))
x &lt;- scale(x)
y &lt;- as.numeric(x[, 1:5] %*% rep(1, 5) + rnorm(nrow(x)))
out &lt;- RPtest_single(x=x, y=y, B=25)
</code></pre>

<hr>
<h2 id='sparse_proj'>Sparse projections using the square-root Lasso</h2><span id='topic+sparse_proj'></span>

<h3>Description</h3>

<p>Regresses each column of <code>x</code> against all others in turn, using the
square-root Lasso, and outputs residuals from the regressions. Thus it
outputs a form of sparse projection of each column on all others.
Alternatively, given two matrices <code>x_null</code> and <code>x_alt</code>, it
regresses each column of <code>x_null</code> on <code>x_alt</code> in a similar fashion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparse_proj(x, x_null, x_alt, mc.cores = 1L, rescale = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparse_proj_+3A_x">x</code></td>
<td>
<p>Matrix with each row an observation vector. Need not be supplied if
<code>x_alt</code> and <code>x_null</code> are given.</p>
</td></tr>
<tr><td><code id="sparse_proj_+3A_x_null">x_null</code></td>
<td>
<p>Matrix whose columns are to be regressed on to <code>x_alt</code>.</p>
</td></tr>
<tr><td><code id="sparse_proj_+3A_x_alt">x_alt</code></td>
<td>
<p>Matrix which the columns of <code>x_null</code> are regressed on to.
Must be specified if <code>x_null</code> is given.</p>
</td></tr>
<tr><td><code id="sparse_proj_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of cores to use. Will always be 1 in Windows.</p>
</td></tr>
<tr><td><code id="sparse_proj_+3A_rescale">rescale</code></td>
<td>
<p>Should the columns of the output be rescaled to have l_2-norm
the square-root of the number of observations? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="sparse_proj_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code>sqrt_lasso</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix where each column gives the residuals.
</p>


<h3>References</h3>

<p>A. Belloni, V. Chernozhukov, and L. Wang. (2011)
<em>Square-root lasso: pivotal recovery of sparse signals via conic
programming. Biometrika, 98(4):791-806.</em>
</p>
<p>T. Sun and C.-H. Zhang. (2012) <em>Scaled sparse linear regression. Biometrika,
99(4):879-898.</em>
</p>
<p>T. Sun and C.-H. Zhang. (2013) <em>Sparse matrix inversion with scaled
lasso. The Journal of Machine Learning Research, 14(1):3385-3418.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sqrt_lasso">sqrt_lasso</a></code> and <code><a href="#topic+RPtest_single">RPtest_single</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(50*100), 50, 100)
out &lt;- sparse_proj(x)
</code></pre>

<hr>
<h2 id='sqrt_lasso'>Square-root Lasso regression</h2><span id='topic+sqrt_lasso'></span>

<h3>Description</h3>

<p>Fits a linear model to potentially high-dimensional data using the
square-root Lasso, also known as the scaled Lasso. The Lasso path is computed
using the <span class="pkg">glmnet</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sqrt_lasso(x, y, lam0 = NULL, exclude = integer(0), output_all = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sqrt_lasso_+3A_x">x</code></td>
<td>
<p>Input matrix of dimension nobs by nvars; each row is an observation
vector.</p>
</td></tr>
<tr><td><code id="sqrt_lasso_+3A_y">y</code></td>
<td>
<p>Response variable; shoud be a numeric vector.</p>
</td></tr>
<tr><td><code id="sqrt_lasso_+3A_lam0">lam0</code></td>
<td>
<p>Tuning parameter for the square-root / scaled Lasso. If left
blank (recommended) this is chosen using the method of Sun &amp; Zhang (2013)
implemented in the <span class="pkg">scalreg</span> package.</p>
</td></tr>
<tr><td><code id="sqrt_lasso_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the model; default is
none.</p>
</td></tr>
<tr><td><code id="sqrt_lasso_+3A_output_all">output_all</code></td>
<td>
<p>In addition to the vector of coefficients, if <code>TRUE</code>,
also outputs the intercept, an estimate of the noise standard deviation,
and the output of <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.</p>
</td></tr>
<tr><td><code id="sqrt_lasso_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First the Lasso path is computed using <code>glmnet</code> from
<span class="pkg">glmnet</span>. Next the particular point on the path corresponding to the
square-root Lasso solution is found. As the path is only computed on a grid
of points, the square-root Lasso solution is approximate.
</p>


<h3>Value</h3>

<p>Either an estimated vector of regression coefficients with nvars
components or, if <code>output_all</code> is <code>true</code>, a list with components
</p>

<dl>
<dt><code>beta</code></dt><dd><p>the vector of regression coefficents</p>
</dd>
<dt><code>a0</code></dt><dd><p>an intercept term</p>
</dd>
<dt><code>sigma_hat</code></dt><dd><p>an estimate of
the noise standard deviation; this is calculated as square-root of the
average residual sums of squares</p>
</dd>
<dt><code>glmnet_obj</code></dt><dd><p>the fitted <code>glmnet</code> object, an S3 class &ldquo;<code>glmnet</code>&quot;</p>
</dd>
<dt><code>lamda_index</code></dt><dd><p>the index of the lambda vector in the <code>glmnet</code> object
corresponding to the square-root Lasso solution</p>
</dd>
</dl>



<h3>References</h3>

<p>A. Belloni, V. Chernozhukov, and L. Wang. (2011)
<em>Square-root lasso: pivotal recovery of sparse signals via conic
programming. Biometrika, 98(4):791-806.</em>
</p>
<p>T. Sun and C.-H. Zhang. (2012) <em>Scaled sparse linear regression. Biometrika,
99(4):879-898.</em>
</p>
<p>T. Sun and C.-H. Zhang. (2013) <em>Sparse matrix inversion with scaled
lasso. The Journal of Machine Learning Research, 14(1):3385-3418.</em>
</p>


<h3>See Also</h3>

<p><code><a href="glmnet.html#topic+glmnet">glmnet</a></code> and <code><a href="scalreg.html#topic+scalreg">scalreg</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*250), 100, 250)
y &lt;- x[, 1] + x[, 2] + rnorm(100)
out &lt;- sqrt_lasso(x, y)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
