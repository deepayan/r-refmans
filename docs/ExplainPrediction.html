<!DOCTYPE html><html lang="en"><head><title>Help for package ExplainPrediction</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ExplainPrediction}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ExplainPrediction-package'><p>Explanation of individual predictions and models</p></a></li>
<li><a href='#explanation'><p>Explanation of predictions on instance and model level</p></a></li>
<li><a href='#wrap4Explanation'><p>Wrap prediction model for explanations</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Explanation of Predictions for Classification and Regression
Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-12-27</td>
</tr>
<tr>
<td>Author:</td>
<td>Marko Robnik-Sikonja</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marko Robnik-Sikonja &lt;marko.robnik@fri.uni-lj.si&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Generates explanations for classification and regression models and visualizes them.
 Explanations are generated for individual predictions as well as for models as a whole. Two explanation methods
 are included, EXPLAIN and IME. The EXPLAIN method is fast but might miss explanations expressed redundantly
 in the model. The IME method is slower as it samples from all feature subsets.
 For the EXPLAIN method see Robnik-Sikonja and Kononenko (2008) &lt;<a href="https://doi.org/10.1109%2FTKDE.2007.190734">doi:10.1109/TKDE.2007.190734</a>&gt;, 
 and the IME method is described in Strumbelj and Kononenko (2010, JMLR, vol. 11:1-18).
 All models in package 'CORElearn' are natively supported, for other prediction models a wrapper function is provided 
 and illustrated for models from packages 'randomForest', 'nnet', and 'e1071'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://lkm.fri.uni-lj.si/rmarko/software/">http://lkm.fri.uni-lj.si/rmarko/software/</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>CORElearn (&ge; 1.52.0),semiArtificial (&ge; 2.2.5)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>nnet,e1071,randomForest</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-12-27 17:33:14 UTC; rmarko</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-01-07 07:56:37 UTC</td>
</tr>
</table>
<hr>
<h2 id='ExplainPrediction-package'>Explanation of individual predictions and models</h2><span id='topic+ExplainPrediction-package'></span><span id='topic+ExplainPrediction'></span>

<h3>Description</h3>

<p>The package ExplainPrediction contains methods to generate explanations for individual predictions of 
classification and regression models. 
</p>


<h3>Details</h3>

<p>The explanation methodology used is based on measuring contributions of individual features on
an individual predictions. The contributions of all attributes present an explanation of individual prediction.
Explanations can be visualized with a nomogram. If we average the explanations, we get an explanation of the 
whole model. Two explanation methods are implemented:
</p>

<ul>
<li><p> EXPLAIN (described in <em>Explaining Classifications For Individual Instances</em>). The EXPLAIN method is much faster 
than IME and works for any number of attributes in the model, but cannot explain dependencies expressed disjunctively
in the model. For details see <code><a href="#topic+explainVis">explainVis</a></code>. 
</p>
</li>
<li><p> IME can in principle explain any type of dependencies in the model. 
It uses sampling based method to avoid exhaustive search for dependencies and 
works reasonably fast for up to a few dozen attributes in the model. The details see the references.
</p>
</li></ul>

<p>Currently prediction models implemented in package <a href="CORElearn.html#topic+CORElearn">CORElearn</a> are supported, 
for other models a wrapper of class <code><a href="CORElearn.html#topic+CoreModel">CoreModel</a></code> has to be created. 
The wrapper has to present the model with a list with the following components:
</p>

<ul>
<li> <p><code>formula</code> of class <code><a href="stats.html#topic+formula">formula</a></code> representing the response and predictive variables,
</p>
</li>
<li> <p><code>noClasses</code> number of class values in class of classification model, 0 in case of regression,
</p>
</li>
<li> <p><code>class.lev</code> the levels used in representation of class values (see <code><a href="base.html#topic+factor">factor</a></code>),
</p>
</li></ul>

<p>Additionally it has to implement function <code><a href="stats.html#topic+predict">predict</a></code> which returns the same components as the function
<code><a href="CORElearn.html#topic+predict.CoreModel">predict.CoreModel</a></code> in the package <a href="CORElearn.html#topic+CORElearn">CORElearn</a>.
</p>
<p>Further software and development versions of the package are available at <a href="http://lkm.fri.uni-lj.si/rmarko/software">http://lkm.fri.uni-lj.si/rmarko/software</a>. 
</p>


<h3>Author(s)</h3>

<p>Marko Robnik-Sikonja 
</p>


<h3>References</h3>

<p>Marko Robnik-Sikonja, Igor Kononenko: Explaining Classifications For Individual Instances.
<em>IEEE Transactions on Knowledge and Data Engineering</em>, 20:589-600, 2008
</p>
<p>Erik Strumbelj, Igor Kononenko, Igor, Marko Robnik-Sikonja: Explaining Instance Classifications with Interactions of 
Subsets of Feature Values. <em>Data and Knowledge Engineering</em>, 68(10):886-904, Oct. 2009
</p>
<p>Erik Strumbelj, Igor Kononenko:  An Eficient Explanation of Individual Classifications using Game Theory, 
<em>Journal of Machine Learning Research</em>, 11(1):1-18, 2010. 
</p>
<p>Some references are available from <a href="http://lkm.fri.uni-lj.si/rmarko/papers/">http://lkm.fri.uni-lj.si/rmarko/papers/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+explainVis">explainVis</a></code>
</p>

<hr>
<h2 id='explanation'>Explanation of predictions on instance and model level</h2><span id='topic+explain'></span><span id='topic+prepareForExplanations'></span><span id='topic+explanationAverages'></span><span id='topic+explainVis'></span>

<h3>Description</h3>

<p>Using general explanation methodology EXPLAIN or IME, the function <code>explainVis</code> explains
predictions of given model and visualizes the  explanations.
An explanation of a prediction is given for individual instances; aggregation of instance explanations 
gives a model explanation. The details are given in the description and references.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explainVis(model, trainData, testData,  
   method=c("EXPLAIN", "IME"), classValue=1,
   fileType=c("none","pdf","eps","emf","jpg","png","bmp","tif","tiff"), 
   dirName=getwd(), fileName="explainVis", visLevel=c("both","model","instance"),
   explainType=c("WE","infGain","predDiff"), naMode=c("avg", "na"), 
   nLaplace=nrow(trainData), estimator=NULL,	
   pError=0.05, err=0.05, batchSize=40, maxIter=1000, 
   genType=c("rf", "rbf", "indAttr"), noAvgBins=20, 
   displayAttributes=NULL, modelVisCompact=FALSE, 
   displayThreshold=0.0, normalizeTo=0, 
   colors=c("navyblue", "darkred", "blue", "red", "lightblue", "orange"), 
   noDecimalsInValueName=2,
   modelTitle=ifelse(model$noClasses==0,"Explaining %R\nmodel: %M", 
      "Explaining %R=%V\nmodel: %M"), 
   modelSubtitle="Method: %E, type: %X", 
   instanceTitle=ifelse(model$noClasses==0, 
      "Explaining %R\ninstance: %I, model: %M",
      "Explaining %R=%V\ninstance: %I, model: %M"), 
   instanceSubtitle=ifelse(model$noClasses==0, 
	  "Method: %E\nf(%I)=%P, true %R=%T",
      "Method: %E, type: %X\nP(%R=%V)=%P, true %R=%T"),
   recall=NULL) 		                                    
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="explanation_+3A_model">model</code></td>
<td>
<p> The model as returned by <code><a href="CORElearn.html#topic+CoreModel">CoreModel</a></code> function. </p>
</td></tr>
<tr><td><code id="explanation_+3A_traindata">trainData</code></td>
<td>
<p> Data frame with data, which is used to extract average explanations, discretization, 
and other information needed for explanation of instances and model. Typically this is the data set 
which was used to train the <code>model</code>.</p>
</td></tr>
<tr><td><code id="explanation_+3A_testdata">testData</code></td>
<td>
<p> Data frame with instances which will be explained. 
The <code>testData</code> data frame shall contain the same columns as <code>trainData</code>, with possible exception
of target variable, which can be omitted.</p>
</td></tr>
<tr><td><code id="explanation_+3A_method">method</code></td>
<td>
<p> The explanation method; two methods are available, EXPLAIN and IME. The EXPLAIN is much faster 
and works for any number of attributes in the model,
but cannot explain dependencies expressed disjunctively in the model (for details see references). 
The IME can in principle explain any type of dependencies
in the model. It uses sampling based method to avoid exhaustive search for dependencies and 
works reasonably fast for up to a few dozen attributes in the model.</p>
</td></tr>
<tr><td><code id="explanation_+3A_classvalue">classValue</code></td>
<td>
<p> For classification models this parameter determines for which class value the explanations will be generated.
The <code>classValue</code> can be given as a factor, character string or class index. 
By default the first class value is chosen.</p>
</td></tr>
<tr><td><code id="explanation_+3A_filetype">fileType</code></td>
<td>
<p>The parameter determines the graphical format of the visualization file(s). 
If <code>fileType="none"</code> (default) visualizations are generated in a
graphical window. Other possible choices are <code>"pdf","eps","emf","jpg","png","bmp","tif"</code> and <code>"tiff"</code>. </p>
</td></tr>         
<tr><td><code id="explanation_+3A_dirname">dirName</code></td>
<td>
<p> A name of the folder where resulting visualization files will be saved if <code>fileType</code> other than <code>"none"</code> is chosen.</p>
</td></tr>
<tr><td><code id="explanation_+3A_filename">fileName</code></td>
<td>
<p> A file name of the resulting visualization files, in case <code>fileType</code> other than <code>"none"</code> is chosen.</p>
</td></tr>
<tr><td><code id="explanation_+3A_vislevel">visLevel</code></td>
<td>
<p> The level of explanations desired. If <code>visLevel="model"</code> the model explanation is 
generated, meaning that instance explanations obtained on <code>trainData</code> are aggregated. 
If <code>visLevel="instance"</code>  instance explanations are generated  for each row in testData. 
The default value <code>visLevel="both"</code> generates both, the model explanation and explanations for the instances.</p>
</td></tr>
<tr><td><code id="explanation_+3A_explaintype">explainType</code></td>
<td>
<p>For method EXPLAIN this parameter determines how the prediction with knowledge about 
given feature and prediction
without knowledge of this feature are combined into the final explanation. 
Values <code>"WE"</code>, <code>"infGain"</code>, and <code>"predDiff"</code> mean that the difference
is interpreted as weight of evidence, information gain, or plain difference, respectively.
For regression problem only the difference of predictions is available.</p>
</td></tr>
<tr><td><code id="explanation_+3A_namode">naMode</code></td>
<td>
<p>For method EXPLAIN this parameter determines how the impact of missing information about certain feature value is
estimated. If <code>naMode="avg"</code>, the effect is estimated by the weighted average of predictions 
over all possible feature's values.
If <code>naMode="na"</code>, the effect is estimated by inserting NA value as feature value. 
The <code>"na"</code> method is faster but we are 
left to the mercy of adequate treatment of missing values in the function <code><a href="stats.html#topic+predict">predict</a></code> for a given model. </p>
</td></tr>
<tr><td><code id="explanation_+3A_nlaplace">nLaplace</code></td>
<td>
<p> For EXPLAIN method and classification problems the predicted probabilities are corrected with Laplace correction,
pushing them away from 0 and 1 and towards uniform distribution. Larger values imply smaller effect. The default value is equal
to the number of instances in <code>trainData</code>. The value 0 means that Laplace correction is not used and probabilities
are estimated with relative frequency.</p>
</td></tr>
<tr><td><code id="explanation_+3A_estimator">estimator</code></td>
<td>
<p> The name of feature evaluation method used to greedily discretize attributes 
when averaging explanation over intervals.
The default value <code>NULL</code> means that <code>"ReliefFexpRank"</code> will be used in classification problems and 
<code>"RReliefFexpRank"</code> will be used in regression problems. See <code><a href="CORElearn.html#topic+discretize">discretize</a></code> for details.</p>
</td></tr>
<tr><td><code id="explanation_+3A_perror">pError</code></td>
<td>
<p>For method IME the estimated probability of an error in explanations. Together with
parameter <code>err</code> this determines the number of needed samples.</p>
</td></tr>
<tr><td><code id="explanation_+3A_err">err</code></td>
<td>
<p>For method IME the parameter controls the size of tolerable error. 
Together with parameter <code>pError</code> this determines the number of needed samples. 
See the paper <em>An Efficient Explanation of Individual Classifications using Game Theory</em> for details.</p>
</td></tr>
<tr><td><code id="explanation_+3A_batchsize">batchSize</code></td>
<td>
<p>For method IME the number of samples processed in batch mode for each explanation. Larger sizes cause
less overhead in processing but may process more samples than required.</p>
</td></tr>
<tr><td><code id="explanation_+3A_maxiter">maxIter</code></td>
<td>
<p>The maximal number of iterations in IME method allowed for a single explanation.</p>
</td></tr>
<tr><td><code id="explanation_+3A_gentype">genType</code></td>
<td>
<p>The type of data generator used to generate random part of instances in method IME. 
The generators from package <code><a href="semiArtificial.html#topic+semiArtificial-package">semiArtificial-package</a></code> are used: 
<code>"rf"</code> stands for random forest based generator, 
<code>"rbf"</code> invokes RBF network based generator, and
<code>"indAttr"</code> assumes independent attributes and generates values 
for each attribute independently.</p>
</td></tr>
<tr><td><code id="explanation_+3A_noavgbins">noAvgBins</code></td>
<td>
<p>For IME method the number of discretization bins used to present model level explanations
and average explanations.</p>
</td></tr>
<tr><td><code id="explanation_+3A_displayattributes">displayAttributes</code></td>
<td>
<p> The vector of attribute names which are visualized, subject to <code>displayThreshold</code>) and value <code>modelVisCompact</code>.
The default value <code>displayThreshold=NULL</code> displays all attributes and their values.</p>
</td></tr>
<tr><td><code id="explanation_+3A_modelviscompact">modelVisCompact</code></td>
<td>
<p> The logical value controlling if attribute values are displayed
in model level visualization. The default value <code>modelVisCompact=FALSE</code> displays all values of
attributes (subject to <code>displayThreshold</code>), and value <code>modelVisCompact=TRUE</code>
displays only contributions on the level of attributes (without their values).</p>
</td></tr> 
<tr><td><code id="explanation_+3A_displaythreshold">displayThreshold</code></td>
<td>
<p> The threshold value for absolute values of explanations 
below which feature contributions are not displayed in instance and model explanation graphs. 
The threshold applies after the values are normalized, see the explanation for parameter <code>normalizeTo</code>.
The default value <code>displayThreshold=0</code> displays contributions of all attributes.</p>
</td></tr>
<tr><td><code id="explanation_+3A_normalizeto">normalizeTo</code></td>
<td>
<p> For instance level visualization the absolute values of feature contributions are 
summed and normalized to the value of <code>normalizeTo</code>.
In model level explanation the normalization depends  on parameter <code>modelVisCompact</code>. If its value is <code>TRUE</code>,
the absolute values of all feature explanations are summed up and normalized to <code>normalizeTo</code>, otherwise
the absolute values of all feature values' contributions are summed up.
The value of <code>normalizeTo</code> common in some areas ( e.g., in medicine) is 100. The default value 0 implies no normalization.
The <code>displayThreshold</code> parameter refers to already normalized values.</p>
</td></tr>
<tr><td><code id="explanation_+3A_colors">colors</code></td>
<td>
<p>A vector with 6 colors names, giving 6 colors used in visualization (average positive impact of attribute, average negative impact of attribute, 
positive instance explanation, negative instance explanation, average positive impact of attribute value, average negative impact of attribute value).
If set to NULL sensible grayscale defaults are used i.e., (gray30,gray30,gray60,gray60,gray90,gray90). </p>
</td></tr>
<tr><td><code id="explanation_+3A_nodecimalsinvaluename">noDecimalsInValueName</code></td>
<td>
<p>How many decimal places will numeric feature values use in visualizations.The default value is 2.</p>
</td></tr>
<tr><td><code id="explanation_+3A_modeltitle">modelTitle</code></td>
<td>
<p>A character string for title template of model visualization. See the details. If <code>modelTitle=NULL</code> the title is not shown. </p>
</td></tr>  
<tr><td><code id="explanation_+3A_modelsubtitle">modelSubtitle</code></td>
<td>
<p>A character string for subtitle template of model visualization. See the details. If <code>modelSubtitle=NULL</code> the subtitle is not shown. </p>
</td></tr>     
<tr><td><code id="explanation_+3A_instancetitle">instanceTitle</code></td>
<td>
<p>A character string for title template of instance visualization. See the details. If <code>instanceTitle=NULL</code> the title is not shown. </p>
</td></tr>  
<tr><td><code id="explanation_+3A_instancesubtitle">instanceSubtitle</code></td>
<td>
<p>A character string for subtitle template of instance visualization. See the details. If <code>instanceSubtitle=NULL</code> the subtitle is not shown. </p>
</td></tr>       
<tr><td><code id="explanation_+3A_recall">recall</code></td>
<td>
<p>If parameter is different from NULL, it shall contain the list invisibly returned by one of previous calls to function <code>explainVis</code>. In this case the function reuses already computed explanations,
average explanations, discretization, etc.,  and only display data differently according to other supplied parameters. 
In this case values of parameters <code>model</code>, <code>testData</code> and <code>classValue</code>should be identical to the original call.
Values of parameters <code>trainData</code>, <code>method</code>, <code>naMode</code>, <code>explainType</code>, <code>nLaplace</code>, <code>estimator</code>,
<code>pError</code>, <code>err</code>, <code>batchSize</code>, <code>maxIter</code>, <code>genType</code>, and <code>noAvgBins</code>   are ignored.    
The parameters that do matter in this case are the ones that affect the display of already precomputed
results: <code>visLevel</code>,<code>dirName</code>, <code>fileType</code>, 
<code>displayAttributes</code>, <code>modelVisCompact</code>, <code>displayThreshold</code>, <code>normalizeTo</code>,
<code>colors</code>, <code>noDecimalsInValueName</code>, <code>modelTitle</code>, <code>modelSubtitle</code>, <code>instanceTitle</code>, and <code>instanceSubtitle</code>.

</p>
</td></tr>                                    
</table>


<h3>Details</h3>

<p>The function <code>explainVis</code> generates explanations and their visualizations given the trained model, 
its training data, and data for which we want explanations. This is the frontend explanation function which takes
care of everything, internally calling other functions.
The produced visualizations are output to a graphical device or saved to a file. 
If one requires internal information about the explanations, they are returned invisibly. 
Separate calls to internal functions (<code>explain</code>, <code>ime</code>, 
<code>prepareForExplanations</code>, and <code>explanationAverages</code>) are also possible.
</p>
<p>In the model explanation all feature values  of nominal attributes and intervals of numeric attributes are visualized, as
well as weighted summary over all these values. 
In the instance level visualizations the contributions of each feature are presented (thick bars) as well as average contributions of these
feature values in the <code>trainData</code> (thin bars above them). For details see the references below.
</p>
<p>The titles and subtitles of model and instance explanation graphs use templates which allows insertion of the following values:
</p>

<ul>
<li><p> 	Response variable: %R
</p>
</li>
<li><p> Selected class value for explanation (in case of classification): %V 
</p>
</li>
<li><p> Type of model: %M
</p>
</li>
<li><p> Explanation method (see parameter <code>method</code>):: %E
</p>
</li>
<li><p> Explanation type (only for method EXPLAIN): %X
</p>
</li></ul>

<p>Title and subtitle of instance explanation graphs can additionally use the following information:
</p>

<ul>
<li><p> Instance name (extracted from <code><a href="base.html#topic+row.names">row.names</a></code> in <code>testData</code>): %I
</p>
</li>
<li><p> Predicted value/probability of the response: %P 
</p>
</li>
<li><p> True (class) value of the response: %T
</p>
</li></ul>

<p>Default templates for regression and classification models are provided. For example, the default template for title of model explanation is
&quot;Explaining %R=%V\nmodel: %M&quot;, meaning that information about response variable, selected class value, and model are displayed in the title. 
</p>


<h3>Value</h3>

<p>The function <code>explainVis</code> generates explanations and saves their visualizations to a file or 
outputs them to graphical device,  based on the value of <code>fileType</code>. It invisibly returns a list with three components containing
explanations, average explanations, and additional data like discretization used and data generator.
The main ingredients of these three components are:
</p>

<ul>
<li> <p><code>expl</code>, a matrix of generated explanations  (of size <code>dim(testData)</code>), 
</p>
</li>
<li> <p><code>pCXA</code>, a vector of predictions,
</p>
</li>
<li> <p><code>stddev</code>, (for method IME only) a matrix with standard deviations of explanations,
</p>
</li>
<li> <p><code>noIter</code>, (for method IME only) a matrix with number of iterations executed for each explanation,
</p>
</li>
<li>  <p><code>discPoints</code>, (for method EXPLAIN only) a list containing values of discrete features 
or centers of discretization intervals for numeric features,
</p>
</li>
<li> <p><code>pAV</code>, (for method EXPLAIN only) a list with probabilities for discrete values or 
discretization intervals in case of numeric features,
</p>
</li>
<li> <p><code>discretization</code>, a list with discretization intervals output by <code><a href="CORElearn.html#topic+discretize">discretize</a></code> function,
used in estimating averages and model based explanations,
</p>
</li>
<li> <p><code>avNames</code>, a list containing the names of discrete values/intervals,
</p>
</li>
<li> <p><code>generator</code>, (for IME method only) a generator used to generate random part of instances in IME method,
</p>
</li>
<li> <p><code>explAvg</code>, a list with several components giving average explanations on the <code>trainingData</code>.
Averages are given for 
attributes, their values (for discrete attributes) and discretization intervals (for numeric features). 
These average explanations are used in visualization to give impression how the model works on average. This can be contrasted 
with explanation for the specific instance.
</p>
</li></ul>



<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja </p>


<h3>References</h3>

<p>Marko Robnik-Sikonja, Igor Kononenko: Explaining Classifications For Individual Instances.
<em>IEEE Transactions on Knowledge and Data Engineering</em>, 20:589-600, 2008
</p>
<p>Erik Strumbelj, Igor Kononenko, Igor, Marko Robnik-Sikonja: Explaining Instance Classifications with Interactions of 
Subsets of Feature Values. <em>Data and Knowledge Engineering</em>, 68(10):886-904, Oct. 2009
</p>
<p>Erik Strumbelj, Igor Kononenko:  An Efficient Explanation of Individual Classifications using Game Theory, 
<em>Journal of Machine Learning Research</em>, 11(1):1-18, 2010. 
</p>
<p>Marko Robnik-Sikonja, Igor Kononenko: Discretization of continuous attributes using ReliefF.
<em>Proceedings of ERK'95</em>, B149-152, Ljubljana, 1995
</p>
<p>Some references are available from <a href="http://lkm.fri.uni-lj.si/rmarko/papers/">http://lkm.fri.uni-lj.si/rmarko/papers/</a>
</p>


<h3>See Also</h3>

<p><code><a href="CORElearn.html#topic+CORElearn">CORElearn</a></code>,
<code><a href="CORElearn.html#topic+predict.CoreModel">predict.CoreModel</a></code>,
<code><a href="CORElearn.html#topic+attrEval">attrEval</a></code>,
<code><a href="CORElearn.html#topic+discretize">discretize</a></code>,
<code><a href="semiArtificial.html#topic+semiArtificial-package">semiArtificial-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(CORElearn)
# use iris data set, split it randomly into a training and testing set
trainIdxs &lt;- sample(x=nrow(iris), size=0.7*nrow(iris), replace=FALSE)
testIdxs &lt;- c(1:nrow(iris))[-trainIdxs]
# build random forests model with certain parameters
modelRF &lt;- CoreModel(Species ~ ., iris[trainIdxs,], model="rf",
              selectionEstimator="MDL",minNodeWeightRF=5,
              rfNoTrees=100, maxThreads=1)

# generate model explanation and visualization
# turn on history in the visualization window to see all graphs
explainVis(modelRF, iris[trainIdxs,], iris[testIdxs,], method="EXPLAIN",visLevel="both",
           fileType="none", naMode="avg", explainType="WE", classValue=1) 
## Not run: 
#store instance explanations in grayscale to file in PDF format
explainVis(modelRF, iris[trainIdxs,], iris[testIdxs,], method="EXPLAIN", visLevel="instance",
           fileType="pdf", naMode="avg", explainType="WE", classValue=1, colors=NULL) 
destroyModels(modelRF) # clean up

# build a regression tree 
trainReg &lt;- regDataGen(100)
testReg &lt;- regDataGen(20)
modelRT &lt;- CoreModel(response~., trainReg, model="regTree", modelTypeReg=1)
# generate both model and instance level explanation using defaults
explainVis(modelRT, trainReg, testReg) 
destroyModels(modelRT) #clean up

## End(Not run)
</code></pre>

<hr>
<h2 id='wrap4Explanation'>Wrap prediction model for explanations</h2><span id='topic+wrap4Explanation'></span>

<h3>Description</h3>

<p>The function wraps given prediction model to be used with ExplainPrediction package.
Currently <code><a href="nnet.html#topic+nnet">nnet</a></code> from <code>nnet</code> package and models of class <code>svm</code> 
from package <code>e1071</code> are supported, but others can easily be added. Please, note that models from
<code><a href="CORElearn.html#topic+CORElearn-package">CORElearn-package</a></code> can be used directly and need no wrapper.
If inclusion of other models into ExplainPrediction is desired, please, contact the author.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  wrap4Explanation(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wrap4Explanation_+3A_model">model</code></td>
<td>
<p> The model as returned by <code><a href="nnet.html#topic+nnet">nnet</a></code> or any of <code>svm</code> functions in <code>e1071</code></p>
</td></tr></table>
<p> package.                                    
</p>


<h3>Details</h3>

<p>The function adds necessary components to the prediction model so that function <code><a href="#topic+explainVis">explainVis</a></code> 
can generate explanations and their visualizations.
Currently, four components are added:
</p>

<ul>
<li> <p><code>formula</code>, a formula specifying the dependent and independent variables used by the supplied model.
</p>
</li>
<li> <p><code>model</code>, a name of the supplied model.
</p>
</li>
<li> <p><code>noClasses</code>, a number of class values for classification problems and 0 for regression.
</p>
</li>
<li> <p><code>class.lev</code>, for classification problem a vector of class value names.
</p>
</li></ul>

<p>If for a given <code>model</code> the method <code><a href="stats.html#topic+predict">predict</a></code> returns the class value probabilities
as matrix or in a list with component <code>probabilities</code>, nothing else is needed, otherwise
the internal function <code>getPredictions</code> has to be adequately modified.
</p>


<h3>Value</h3>

<p>The function returns unchanged <code>model</code> with the components described in Details. 
</p>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja </p>


<h3>See Also</h3>

<p><code><a href="#topic+explainVis">explainVis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# use iris data set, split it randomly into a training and testing set
trainIdxs &lt;- sample(x=nrow(iris), size=0.7*nrow(iris), replace=FALSE)
testIdxs &lt;- c(1:nrow(iris))[-trainIdxs]
# build a nnet model with certain parameters
require(nnet)
modelNN &lt;- nnet(Species ~ ., iris[trainIdxs,], size=20)

# use wrapper
modelNNet &lt;- wrap4Explanation(modelNN)

# generate model explanation and visualization
# turn on history in the visualization window to see all graphs
explainVis(modelNNet, iris[trainIdxs,], iris[testIdxs,], method="EXPLAIN",visLevel="both",
           problemName="iris", fileType="none", 
           naMode="avg", explainType="WE", classValue=1) 

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
