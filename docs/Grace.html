<!DOCTYPE html><html><head><title>Help for package Grace</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Grace}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#grace'>

<p>Graph-Constrained Estimation</p></a></li>
<li><a href='#grace.test'>

<p>Graph-Constrained Hypothesis Testing Procedure</p></a></li>
<li><a href='#graceI.test'>

<p>Graph-Constrained Hypothesis Testing Procedure</p></a></li>
<li><a href='#make.L'>

<p>Graph Laplacian Matrix Builder</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Graph-Constrained Estimation and Hypothesis Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-4-8</td>
</tr>
<tr>
<td>Author:</td>
<td>Sen Zhao</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sen Zhao &lt;sen-zhao@sen-zhao.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Use the graph-constrained estimation (Grace) procedure (Zhao and Shojaie, 2016 &lt;<a href="https://doi.org/10.1111%2Fbiom.12418">doi:10.1111/biom.12418</a>&gt;) to estimate graph-guided linear regression coefficients and use the Grace/GraceI/GraceR tests to perform graph-guided hypothesis tests on the association between the response and the predictors.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>MASS, glmnet, scalreg</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://onlinelibrary.wiley.com/doi/10.1111/biom.12418/abstract">http://onlinelibrary.wiley.com/doi/10.1111/biom.12418/abstract</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-04-09 20:56:18 UTC; senzhao</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-04-09 21:14:22 UTC</td>
</tr>
</table>
<hr>
<h2 id='grace'>

Graph-Constrained Estimation
</h2><span id='topic+grace'></span>

<h3>Description</h3>


<p>Calculate coefficient estimates of Grace based on methods described in Li and Li (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  grace(Y, X, L, lambda.L, lambda.1=0, lambda.2=0, normalize.L=FALSE, K=10, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grace_+3A_y">Y</code></td>
<td>

<p>outcome vector.
</p>
</td></tr>
<tr><td><code id="grace_+3A_x">X</code></td>
<td>

<p>matrix of predictors.
</p>
</td></tr>
<tr><td><code id="grace_+3A_l">L</code></td>
<td>

<p>penalty weight matrix L.
</p>
</td></tr>
<tr><td><code id="grace_+3A_lambda.l">lambda.L</code></td>
<td>

<p>tuning parameter value for the penalty induced by the L matrix (see details). If a sequence of lambda.L values is supplied, K-fold cross-validation is performed.
</p>
</td></tr>
<tr><td><code id="grace_+3A_lambda.1">lambda.1</code></td>
<td>

<p>tuning parameter value for the lasso penalty (see details). If a sequence of lambda.1 values is supplied, K-fold cross-validation is performed.
</p>
</td></tr>
<tr><td><code id="grace_+3A_lambda.2">lambda.2</code></td>
<td>

<p>tuning parameter value for the ridge penalty (see details). If a sequence of lambda.2 values is supplied, K-fold cross-validation is performed.
</p>
</td></tr>
<tr><td><code id="grace_+3A_normalize.l">normalize.L</code></td>
<td>

<p>whether the penalty weight matrix L should be normalized.
</p>
</td></tr>
<tr><td><code id="grace_+3A_k">K</code></td>
<td>

<p>number of folds in cross-validation.
</p>
</td></tr>
<tr><td><code id="grace_+3A_verbose">verbose</code></td>
<td>

<p>whether computation progress should be printed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Grace estimator is defined as
</p>
<p style="text-align: center;"><code class="reqn">(\hat\alpha, \hat\beta) = \arg\min_{\alpha, \beta}{\|Y-\alpha 1 -X\beta\|_2^2+lambda.L(\beta^T L\beta)+lambda.1\|\beta\|_1+lambda.2\|\beta\|_2^2}</code>
</p>

<p>In the formulation, L is the penalty weight matrix. Tuning parameters lambda.L, lambda.1 and lambda.2 may be chosen by cross-validation. In practice, X and Y are standardized and centered, respectively, before estimating <code class="reqn">\hat\beta</code>. The resulting estimate is then rescaled back into the original scale. Note that the intercept <code class="reqn">\hat\alpha</code> is not penalized.
</p>
<p>The Grace estimator could be considered as a generalized elastic net estimator (Zou and Hastie, 2005). It penalizes the regression coefficient towards the space spanned by eigenvectors of L with the smallest eigenvalues. Therefore, if L is informative in the sense that <code class="reqn">L\beta</code> is small, then the Grace estimator could be less biased than the elastic net.
</p>


<h3>Value</h3>

<p>An R &lsquo;list&rsquo; with elements:
</p>
<table>
<tr><td><code>intercept</code></td>
<td>
<p>fitted intercept.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>fitted regression coefficients.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sen Zhao
</p>


<h3>References</h3>

<p>Zou, H., and Hastie, T. (2005). Regularization and variable selection via the elastic net. Journal of the Royal Statistical Society: Series B, 67, 301-320.
</p>
<p>Li, C., and Li, H. (2008). Network-constrained regularization and variable selection for analysis of genomic data. Bioinformatics, 24, 1175-1182.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(120)
n &lt;- 100
p &lt;- 200

L &lt;- matrix(0, nrow = p, ncol = p)
for(i in 1:10){
	L[((i - 1) * p / 10 + 1), ((i - 1) * p / 10 + 1):(i * (p / 10))] &lt;- -1
}
diag(L) &lt;- 0
ind &lt;- lower.tri(L, diag = FALSE)
L[ind] &lt;- t(L)[ind]
diag(L) &lt;- -rowSums(L)

beta &lt;- c(rep(1, 10), rep(0, p - 10))

Sigma &lt;- solve(L + 0.1 * diag(p))
sigma.error &lt;- sqrt(t(beta) %*% Sigma %*% beta) / 2

X &lt;- mvrnorm(n, mu = rep(0, p), Sigma = Sigma)
Y &lt;- c(X %*% beta + rnorm(n, sd = sigma.error))

grace(Y, X, L, lambda.L = c(0.08, 0.12), lambda.2 = c(0.08, 0.12))
</code></pre>

<hr>
<h2 id='grace.test'>

Graph-Constrained Hypothesis Testing Procedure
</h2><span id='topic+grace.test'></span>

<h3>Description</h3>


<p>Test for the association between Y and each column of X using the Grace test based on Zhao and Shojaie (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  grace.test(Y, X, L=NULL, lambda.L=NULL, lambda.2=0, normalize.L=FALSE,
  eta=0.05, C=4*sqrt(3), K=10, sigma.error=NULL, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grace.test_+3A_y">Y</code></td>
<td>

<p>outcome vector.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_x">X</code></td>
<td>

<p>matrix of predictors.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_l">L</code></td>
<td>

<p>penalty weight matrix L.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_lambda.l">lambda.L</code></td>
<td>

<p>tuning parameter value for the penalty induced by the L matrix (see details). If a sequence of lambda.L values is supplied, K-fold cross-validation is performed.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_lambda.2">lambda.2</code></td>
<td>

<p>tuning parameter value for the ridge penalty (see details). If a sequence of lambda.2 values is supplied, K-fold cross-validation is performed.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_normalize.l">normalize.L</code></td>
<td>

<p>whether the penalty weight matrix L should be normalized.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_eta">eta</code></td>
<td>

<p>sparsity parameter <code class="reqn">\eta</code> (see details).
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_c">C</code></td>
<td>

<p>parameter for the initial estimator (see details). It could also be &quot;cv&quot; or &quot;scaled.lasso&quot;, in which case cross-validation or the scaled lasso are applied to estimate the initial estimator.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_k">K</code></td>
<td>

<p>number of folds in cross-validation.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_sigma.error">sigma.error</code></td>
<td>

<p>error standard deviation. If NULL, scaled lasso is then applied to estimate it.
</p>
</td></tr>
<tr><td><code id="grace.test_+3A_verbose">verbose</code></td>
<td>

<p>whether computation progress should be printed
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the Grace test (if lambda.2 = 0), the GraceI test (if lambda.L = 0) and the GraceR test as introduced in Zhao and Shojaie (2016). The Grace tests examine the null hypothesis <code class="reqn">\beta_j=0</code> conditional on all other covariates, even if the design matrix <code class="reqn">X</code> has more covariates (columns) than observations (rows). Network information on associations between covariates, which is represented by the <code class="reqn">L</code> matrix, could be used to improve the power of the test. When <code class="reqn">L</code> is informative (see Zhao and Shojaie (2016) for details), the Grace test is expected to deliver higher power than the GraceI test and other competing methods which ignores the network information (see e.g. Buhlmann (2013), van de Geer et al. (2014), Zhang and Zhang (2014)). When <code class="reqn">L</code> is potentially uninformative or inaccurate, the GraceR test could be used. Using data-adaptive choices (e.g. by cross-validation) of lambda.L and lambda.2, the GraceR test could adaptively choose the amount of outside information to be incorporated, which leads to more robust performance. Regardless of the informativeness of <code class="reqn">L</code>, type-I error rates of the Grace, GraceI and GraceR tests are asymptotically controlled.
</p>
<p>The Grace tests are based on the following Grace estimator:
</p>
<p style="text-align: center;"><code class="reqn">(\hat\alpha, \hat\beta) = \arg\min_{\alpha, \beta}{\|Y-\alpha 1 -X\beta\|_2^2+lambda.L(\beta^T L\beta)+lambda.2\|\beta\|_2^2}</code>
</p>

<p>In the formulation, L is the penalty weight matrix. Tuning parameters lambda.L and lambda.2 may be chosen by cross-validation. In practice, X and Y are standardized and centered, respectively, before estimating <code class="reqn">\hat\beta</code>. The resulting estimate is then rescaled back into the original scale. Note that the intercept <code class="reqn">\hat\alpha</code> is not penalized.
</p>
<p>To perform the Grace tests, the lasso initial estimator is calculated using lasso tuning parameter <code class="reqn">\sigma_\epsilon C\sqrt{\log(p)/n}</code>. The Grace test requires C to be larger than <code class="reqn">2\sqrt{2}</code>. <code class="reqn">\sigma_\epsilon</code> is the error standard deviation, which is estimated using the scaled lasso (Sun and Zhang, 2012).
</p>
<p><code class="reqn">\eta&lt;0.5</code> is the sparsity parameter of <code class="reqn">\beta</code>, which controls the level of bias correction. It is assumed that the number of nonzero elements in <code class="reqn">\beta</code>, <code class="reqn">s=o([n/\log(p)]^\eta)</code>. This parameter is usually unknown. Using larger values of <code class="reqn">\eta</code> leads to more conservative results.
</p>


<h3>Value</h3>

<p>An R &lsquo;list&rsquo; with elements:
</p>
<table>
<tr><td><code>intercept</code></td>
<td>
<p>fitted intercept.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>fitted regression coefficients.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>p-values based on the Grace tests.</p>
</td></tr>
<tr><td><code>group.test</code></td>
<td>
<p>function to perform the group test, with the null hypothesis being that all the regression coefficients in the group equal zero. The argument of this function needs to be an index vector of variables. There is an optimal second argument, which specifies whether the group test should be performed based on the &quot;holm&quot; procedure (default), or based on the &quot;max&quot; test statstic. The output is the p-value of the group test. See examples below.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sen Zhao
</p>


<h3>References</h3>

<p>Li, C., and Li, H. (2008). Network-constrained regularization and variable selection for analysis of genomic data. Bioinformatics, 24, 1175-1182.
</p>
<p>Sun, T., and Zhang, C.-H. (2012). Scaled sparse linear regression. Biometrika, 99, 879-898.
</p>
<p>Buhlmann, P. (2013). Statistical significance in high-dimensional linear models. Bernoulli, 19, 1212-1242.
</p>
<p>van de Geer, S., Buhlmann, P., Rotiv, Y., and Dezeure, R. (2014). On asymptotically optimal confidence regions and tests for high-dimensional models. The Annals of Statistics, 42, 1166-1202.
</p>
<p>Zhang, C.-H., and Zhang, S.S. (2014). Confidence intervals for low dimensional parameters in high dimensional linear models. Journal of the Royal Statistical Society: Series B, 76, 217-242.
</p>
<p>Zhao, S., and Shojaie, A. (2016). A signifiance test for graph-constrained estimation. Biometrics, 72, 484-493.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(120)
n &lt;- 100
p &lt;- 200

L &lt;- matrix(0, nrow = p, ncol = p)
for(i in 1:10){
	L[((i - 1) * p / 10 + 1), ((i - 1) * p / 10 + 1):(i * (p / 10))] &lt;- -1
}
diag(L) &lt;- 0
ind &lt;- lower.tri(L, diag = FALSE)
L[ind] &lt;- t(L)[ind]
diag(L) &lt;- -rowSums(L)

beta &lt;- c(rep(1, 10), rep(0, p - 10))

Sigma &lt;- solve(L + 0.1 * diag(p))
sigma.error &lt;- sqrt(t(beta) %*% Sigma %*% beta) / 2

X &lt;- mvrnorm(n, mu = rep(0, p), Sigma = Sigma)
Y &lt;- c(X %*% beta + rnorm(n, sd = sigma.error))

grace.test.result &lt;- grace.test(Y, X, L, lambda.L = c(0.08, 0.12),
                                lambda.2 = c(0.08, 0.12))
mean(grace.test.result$pvalue[beta == 0] &lt; 0.05)

grace.test.result$group.test(1:2)
grace.test.result$group.test(3:50)
grace.test.result$group.test(11:100)
grace.test.result$group.test(1:5, method = "max")

grace.test.result &lt;- grace.test(Y, X, L, lambda.L = 0.08,
                                lambda.2 = 0.08, C = "cv")
mean(grace.test.result$pvalue[beta == 0] &lt; 0.05)
</code></pre>

<hr>
<h2 id='graceI.test'>

Graph-Constrained Hypothesis Testing Procedure
</h2><span id='topic+graceI.test'></span>

<h3>Description</h3>


<p>Test for the association between Y and each column of X using the GraceI test based on Zhao and Shojaie (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  graceI.test(Y,X,lambda.2,eta=0.05,C=4*sqrt(3),K=10,sigma.error=NULL,verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graceI.test_+3A_y">Y</code></td>
<td>

<p>outcome vector.
</p>
</td></tr>
<tr><td><code id="graceI.test_+3A_x">X</code></td>
<td>

<p>matrix of predictors.
</p>
</td></tr>
<tr><td><code id="graceI.test_+3A_lambda.2">lambda.2</code></td>
<td>

<p>tuning parameter value for the ridge penalty (see details). If a sequence of lambda.2 values is supplied, K-fold cross-validation is performed.
</p>
</td></tr>
<tr><td><code id="graceI.test_+3A_eta">eta</code></td>
<td>

<p>sparsity parameter <code class="reqn">\eta</code> (see details).
</p>
</td></tr>
<tr><td><code id="graceI.test_+3A_c">C</code></td>
<td>

<p>parameter for the initial estimator (see details). It could also be &quot;cv&quot; or &quot;scaled.lasso&quot;, in which case cross-validation or the scaled lasso are applied to estimate the initial estimator.
</p>
</td></tr>
<tr><td><code id="graceI.test_+3A_k">K</code></td>
<td>

<p>number of folds in cross-validation.
</p>
</td></tr>
<tr><td><code id="graceI.test_+3A_sigma.error">sigma.error</code></td>
<td>

<p>error standard deviation. If NULL, scaled lasso is then applied to estimate it.
</p>
</td></tr>
<tr><td><code id="graceI.test_+3A_verbose">verbose</code></td>
<td>

<p>whether computation progress should be printed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the GraceI test. See the documentation for grace.test.
</p>


<h3>Value</h3>

<p>An R &lsquo;list&rsquo; with elements:
</p>
<table>
<tr><td><code>intercept</code></td>
<td>
<p>fitted intercept.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>fitted regression coefficients.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>p-values based on the Grace tests.</p>
</td></tr>
<tr><td><code>group.test</code></td>
<td>
<p>function to perform the group test, with the null hypothesis being that all the regression coefficients in the group equal zero. The argument of this function needs to be an index vector of variables. There is an optimal second argument, which specifies whether the group test should be performed based on the &quot;holm&quot; procedure (default), or based on the &quot;max&quot; test statstic. The output is the p-value of the group test. See examples below.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sen Zhao
</p>


<h3>References</h3>

<p>Li, C., and Li, H. (2008). Network-constrained regularization and variable selection for analysis of genomic data. Bioinformatics, 24, 1175-1182.
</p>
<p>Sun, T., and Zhang, C.-H. (2012). Scaled sparse linear regression. Biometrika, 99, 879-898.
</p>
<p>Buhlmann, P. (2013). Statistical significance in high-dimensional linear models. Bernoulli, 19, 1212-1242.
</p>
<p>van de Geer, S., Buhlmann, P., Rotiv, Y., and Dezeure, R. (2014). On asymptotically optimal confidence regions and tests for high-dimensional models. The Annals of Statistics, 42, 1166-1202.
</p>
<p>Zhang, C.-H., and Zhang, S.S. (2014). Confidence intervals for low dimensional parameters in high dimensional linear models. Journal of the Royal Statistical Society: Series B, 76, 217-242.
</p>
<p>Zhao, S., and Shojaie, A. (2016). A signifiance test for graph-constrained estimation. Biometrics, 72, 484-493.
</p>

<hr>
<h2 id='make.L'>

Graph Laplacian Matrix Builder
</h2><span id='topic+make.L'></span>

<h3>Description</h3>


<p>This function builds the graph Laplacian matrix from an adjacency matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  make.L(adj,normalize.Laplacian=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.L_+3A_adj">adj</code></td>
<td>

<p>adjacency matrix of the graph.
</p>
</td></tr>
<tr><td><code id="make.L_+3A_normalize.laplacian">normalize.Laplacian</code></td>
<td>

<p>whether the graph Laplacian matrix should be normalized to make all diagonal entries equal to 1. Grace test with the normalized Laplacian matrix is more powerful in identifying hub-covariates.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix object of the graph Laplacian matrix.
</p>


<h3>Author(s)</h3>

<p>Sen Zhao
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
