<!DOCTYPE html><html><head><title>Help for package changepoints</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {changepoints}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#changepoints'><p>changepoints-package: A Collections of Change-Point Detection Methods</p></a></li>
<li><a href='#aARC'><p>Automatic adversarially robust univariate mean change point detection.</p></a></li>
<li><a href='#ARC'><p>Adversarially robust univariate mean change point detection.</p></a></li>
<li><a href='#BD_U'><p>Backward detection with a robust bootstrap change point test using U-statistics for univariate mean change.</p></a></li>
<li><a href='#BS.cov'><p>Binary Segmentation for covariance change points detection through Operator Norm.</p></a></li>
<li><a href='#BS.uni.nonpar'><p>Standard binary segmentation for univariate nonparametric change points detection.</p></a></li>
<li><a href='#BS.univar'><p>Standard binary segmentation for univariate mean change points detection.</p></a></li>
<li><a href='#calibrate.online.network.missing'><p>Calibrate step for online change point detection for network data with missing values.</p></a></li>
<li><a href='#CI.regression'><p>Confidence interval construction of change points for regression settings with change points.</p></a></li>
<li><a href='#CV.search.DP.LR.regression'><p>Grid search based on Cross-Validation of all tuning parameters (gamma, lambda and zeta) for regression.</p></a></li>
<li><a href='#CV.search.DP.poly'><p>Grid search for dynamic programming to select the tuning parameter through Cross-Validation.</p></a></li>
<li><a href='#CV.search.DP.regression'><p>Grid search based on cross-validation of dynamic programming for regression change points localisation with <code class="reqn">l_0</code> penalisation.</p></a></li>
<li><a href='#CV.search.DP.univar'><p>Grid search for dynamic programming to select the tuning parameter through Cross-Validation.</p></a></li>
<li><a href='#CV.search.DP.VAR1'><p>Grid search based on cross-validation of dynamic programming for VAR change points detection via <code class="reqn">l_0</code> penalty.</p></a></li>
<li><a href='#CV.search.DPDU.regression'><p>Grid search based on cross-validation of dynamic programming for regression change points localisation with <code class="reqn">l_0</code> penalisation.</p></a></li>
<li><a href='#DP.poly'><p>Dynamic programming algorithm for univariate polynomials change points detection.</p></a></li>
<li><a href='#DP.regression'><p>Dynamic programming algorithm for regression change points localisation with <code class="reqn">l_0</code> penalisation.</p></a></li>
<li><a href='#DP.SEPP'><p>Dynamic programming for SEPP change points detection through <code class="reqn">l_0</code> penalty.</p></a></li>
<li><a href='#DP.univar'><p>Dynamic programming for univariate mean change points detection through <code class="reqn">l_0</code> penalty.</p></a></li>
<li><a href='#DP.VAR1'><p>Dynamic programming for VAR1 change points detection through <code class="reqn">l_0</code> penalty.</p></a></li>
<li><a href='#DPDU.regression'><p>Dynamic programming with dynamic update algorithm for regression change points localisation with <code class="reqn">l_0</code> penalisation.</p></a></li>
<li><a href='#gen.cov.mat'><p>Generate population covariance matrix with dimension p.</p></a></li>
<li><a href='#gen.missing'><p>Function to generate a matrix with values 0 or 1, where 0 indicating the entry is missing</p></a></li>
<li><a href='#gen.piece.poly'><p>Generate univariate data from piecewise polynomials of degree at most r.</p></a></li>
<li><a href='#gen.piece.poly.noiseless'><p>Mean function of piecewise polynomials.</p></a></li>
<li><a href='#Hausdorff.dist'><p>Bidirectional Hausdorff distance.</p></a></li>
<li><a href='#huber_mean'><p>Element-wise adaptive Huber mean estimator.</p></a></li>
<li><a href='#lambda.network.missing'><p>Function to compute the default thresholding parameter for leading singular value in the soft-impute algorithm.</p></a></li>
<li><a href='#local.refine.CV.VAR1'><p>Local refinement for VAR1 change points detection.</p></a></li>
<li><a href='#local.refine.DPDU.regression'><p>Local refinement for DPDU regression change points localisation.</p></a></li>
<li><a href='#local.refine.network'><p>Local refinement for network change points detection.</p></a></li>
<li><a href='#local.refine.poly'><p>Local refinement for univariate polynomials change point detection.</p></a></li>
<li><a href='#local.refine.regression'><p>Local refinement for regression change points localisation.</p></a></li>
<li><a href='#local.refine.univar'><p>Local refinement of an initial estimator for univariate mean change points detection.</p></a></li>
<li><a href='#local.refine.VAR1'><p>Local refinement for VAR1 change points detection.</p></a></li>
<li><a href='#lowertri2mat'><p>Transform a vector containing lower diagonal entries into a symmetric matrix of dimension p.</p></a></li>
<li><a href='#LRV.regression'><p>Long-run variance estimation for regression settings with change points.</p></a></li>
<li><a href='#online.network'><p>Online change point detection for network data.</p></a></li>
<li><a href='#online.network.missing'><p>Online change point detection for network data with missing values.</p></a></li>
<li><a href='#online.univar'><p>Online change point detection with controlled false alarm rate or average run length.</p></a></li>
<li><a href='#online.univar.multi'><p>Online change point detection with potentially multiple change points.</p></a></li>
<li><a href='#simu.change.regression'><p>Simulate a sparse regression model with change points in coefficients.</p></a></li>
<li><a href='#simu.RDPG'><p>Simulate a dot product graph (without change point).</p></a></li>
<li><a href='#simu.SBM'><p>Simulate a Stochastic Block Model (without change point).</p></a></li>
<li><a href='#simu.SEPP'><p>Simulate a (stable) SEPP model (without change point).</p></a></li>
<li><a href='#simu.VAR1'><p>Simulate from a VAR1 model (without change point).</p></a></li>
<li><a href='#softImpute.network.missing'><p>Estimate graphon matrix by soft-impute for independent adjacency matrices with missing values.</p></a></li>
<li><a href='#thresholdBS'><p>Thresholding a BS object with threshold value tau.</p></a></li>
<li><a href='#trim_interval'><p>Interval trimming based on initial change point localisation.</p></a></li>
<li><a href='#tuneBSmultinonpar'><p>A function to compute change points based on the multivariate nonparametic method with tuning parameter selected by FDR control.</p></a></li>
<li><a href='#tuneBSnonparRDPG'><p>Change points detection for dependent dynamic random dot product graph models.</p></a></li>
<li><a href='#tuneBSuninonpar'><p>Wild binary segmentation for univariate nonparametric change points detection with tuning parameter selection.</p></a></li>
<li><a href='#tuneBSunivar'><p>Univariate mean change points detection based on standard or wild binary segmentation with tuning parameter selected by sSIC.</p></a></li>
<li><a href='#WBS.intervals'><p>Generate random intervals for WBS.</p></a></li>
<li><a href='#WBS.multi.nonpar'><p>Wild binary segmentation for multivariate nonparametric change points detection.</p></a></li>
<li><a href='#WBS.network'><p>Wild binary segmentation for network change points detection.</p></a></li>
<li><a href='#WBS.nonpar.RDPG'><p>Wild binary segmentation for dependent dynamic random dot product graph models.</p></a></li>
<li><a href='#WBS.uni.nonpar'><p>Wild binary segmentation for univariate nonparametric change points detection.</p></a></li>
<li><a href='#WBS.uni.rob'><p>Robust wild binary segmentation for univariate mean change points detection.</p></a></li>
<li><a href='#WBS.univar'><p>Wild binary segmentation for univariate mean change points detection.</p></a></li>
<li><a href='#WBSIP.cov'><p>Wild binary segmentation for covariance change points detection through Independent Projection.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Collection of Change-Point Detection Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-08-25</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Haotian Xu &lt;haotian.xu@uclouvain.be&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs a series of offline and/or online change-point detection algorithms for 1) univariate mean: &lt;<a href="https://doi.org/10.1214%2F20-EJS1710">doi:10.1214/20-EJS1710</a>&gt;, &lt;<a href="https://doi.org/10.48550/arXiv.2006.03283">doi:10.48550/arXiv.2006.03283</a>&gt;; 2) univariate polynomials: &lt;<a href="https://doi.org/10.1214%2F21-EJS1963">doi:10.1214/21-EJS1963</a>&gt;; 3) univariate and multivariate nonparametric settings: &lt;<a href="https://doi.org/10.1214%2F21-EJS1809">doi:10.1214/21-EJS1809</a>&gt;, &lt;<a href="https://doi.org/10.1109%2FTIT.2021.3130330">doi:10.1109/TIT.2021.3130330</a>&gt;; 4) high-dimensional covariances: &lt;<a href="https://doi.org/10.3150%2F20-BEJ1249">doi:10.3150/20-BEJ1249</a>&gt;; 5) high-dimensional networks with and without missing values: &lt;<a href="https://doi.org/10.1214%2F20-AOS1953">doi:10.1214/20-AOS1953</a>&gt;, &lt;<a href="https://doi.org/10.48550/arXiv.2101.05477">doi:10.48550/arXiv.2101.05477</a>&gt;, &lt;<a href="https://doi.org/10.48550/arXiv.2110.06450">doi:10.48550/arXiv.2110.06450</a>&gt;; 6) high-dimensional linear regression models: &lt;<a href="https://doi.org/10.48550/arXiv.2010.10410">doi:10.48550/arXiv.2010.10410</a>&gt;, &lt;<a href="https://doi.org/10.48550/arXiv.2207.12453">doi:10.48550/arXiv.2207.12453</a>&gt;; 7) high-dimensional vector autoregressive models: &lt;<a href="https://doi.org/10.48550/arXiv.1909.06359">doi:10.48550/arXiv.1909.06359</a>&gt;; 8) high-dimensional self exciting point processes: &lt;<a href="https://doi.org/10.48550/arXiv.2006.03572">doi:10.48550/arXiv.2006.03572</a>&gt;; 9) dependent dynamic nonparametric random dot product graphs: &lt;<a href="https://doi.org/10.48550/arXiv.1911.07494">doi:10.48550/arXiv.1911.07494</a>&gt;; 10) univariate mean against adversarial attacks: &lt;<a href="https://doi.org/10.48550/arXiv.2105.10417">doi:10.48550/arXiv.2105.10417</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, gglasso, glmnet, ks, MASS, data.tree, Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, abind, DiagrammeR, rmarkdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/HaotianXu/changepoints">https://github.com/HaotianXu/changepoints</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-25 15:59:18 UTC; haotianxu</td>
</tr>
<tr>
<td>Author:</td>
<td>Haotian Xu [aut, cre],
  Oscar Padilla [aut],
  Daren Wang [aut],
  Mengchu Li [aut],
  Qin Wen [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-09-04 14:30:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='changepoints'>changepoints-package: A Collections of Change-Point Detection Methods</h2><span id='topic+changepoints'></span><span id='topic+changepoints-package'></span>

<h3>Description</h3>

<p>Performs a series of offline and/or online change-point detection algorithms for 1) univariate mean; 2) univariate polynomials; 3) univariate and multivariate nonparametric settings; 4) high-dimensional covariances; 5) high-dimensional networks with and without missing values; 6) high-dimensional linear regression models; 7) high-dimensional vector autoregressive models; 8) high-dimensional self exciting point processes; 9) dependent dynamic nonparametric random dot product graphs; 10) univariate mean against adversarial attacks. For more informations, see Wang et al. (2020) &lt;arXiv:1810.09498&gt;; Yu et al. (2020) &lt;arXiv:2006.03283&gt;; Yu and Chatterjee (2020) &lt;arXiv:2007.09910&gt;; Padilla et al. (2021) &lt;arXiv:1905.10019&gt;; Padilla et al. (2019) &lt;arXiv:1910.13289&gt;; Wang et al. (2021) &lt;arXiv:1712.09912&gt;; Wang et al. (2018) &lt;arXiv:1809.09602&gt;; Padilla et al. (2019) &lt;arXiv:1911.07494&gt;; Yu et al. (2021) &lt;arXiv:2101.05477&gt;; Rinaldo et al. (2020) &lt;arXiv:2010.10410&gt;; Wang et al. (2019) &lt;arXiv:1909.06359&gt;; Wang et al. (2020) &lt;arXiv:2006.03572&gt;; Dubey et al. (2021) &lt;arXiv:2110.06450&gt;; Li and Yu (2021) &lt;arXiv:2105.10417&gt;.
</p>

<hr>
<h2 id='aARC'>Automatic adversarially robust univariate mean change point detection.</h2><span id='topic+aARC'></span>

<h3>Description</h3>

<p>Perform the adversarially robust change point detection method with automatic selection of the contamination proportion epsilon when treating the inliner distributions as Gaussian.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aARC(y, t_dat, guess_true = 0.05, h, block_num = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aARC_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="aARC_+3A_t_dat">t_dat</code></td>
<td>
<p>A <code>numeric</code> vector of observations that is used to select epsilon in the Huber contamination model.</p>
</td></tr>
<tr><td><code id="aARC_+3A_guess_true">guess_true</code></td>
<td>
<p>A <code>numeric</code> scalar representing a guess of epsilon value.</p>
</td></tr>
<tr><td><code id="aARC_+3A_h">h</code></td>
<td>
<p>An <code>integer</code> scalar representing block size.</p>
</td></tr>
<tr><td><code id="aARC_+3A_block_num">block_num</code></td>
<td>
<p>An <code>integer</code> scalar representing number of blocks used when searching for local maximiser.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>numeric</code> vector of estimated change point locations.
</p>


<h3>Author(s)</h3>

<p>Mengchu Li
</p>


<h3>References</h3>

<p>Li and Yu (2021) &lt;arXiv:2105.10417&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' ### simulate data with contamination
obs_num = 1000
D = 2
noise = 0.1 # proportion of contamination
mu0 = 0
mu1 = 1
sd =1
idmixture = rbinom(obs_num/D, 1, 1-noise)
dat = NULL
for (j in 1:D){
  for (i in 1:(obs_num/(2*D))){
    if (idmixture[i] == 1){
      dat = c(dat,rnorm(1,mu0,sd))
    }
    else{
      dat = c(dat,rnorm(1,mu1/(2*noise),0))
    }
  }
  for (i in (obs_num/(2*D)+1):(obs_num/D)){
    if (idmixture[i] == 1){
      dat = c(dat,rnorm(1,mu1,sd))
    }
    else{
      dat = c(dat,rnorm(1,mu1/(2*noise)-(1-noise)*mu1/noise,0))
    }
  }
}
plot(dat)
### perform aARC
aARC(dat, dat[1:200], h = 120)
</code></pre>

<hr>
<h2 id='ARC'>Adversarially robust univariate mean change point detection.</h2><span id='topic+ARC'></span>

<h3>Description</h3>

<p>Perform the adversarially robust change point detection method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ARC(y, h, block_num = 1, epsilon, gaussian = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ARC_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="ARC_+3A_h">h</code></td>
<td>
<p>An <code>integer</code> scalar representing block size.</p>
</td></tr>
<tr><td><code id="ARC_+3A_block_num">block_num</code></td>
<td>
<p>An <code>integer</code> scalar representing number of blocks used when searching for local maximiser.</p>
</td></tr>
<tr><td><code id="ARC_+3A_epsilon">epsilon</code></td>
<td>
<p>A <code>numeric</code> scalar in (0,1) representing contamination proportion.</p>
</td></tr>
<tr><td><code id="ARC_+3A_gaussian">gaussian</code></td>
<td>
<p>A <code>logical</code> scalar representing whether to treat the inlier distribution (F) as Gaussian distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>numeric</code> vector of estimated change point locations
</p>


<h3>Author(s)</h3>

<p>Mengchu Li
</p>


<h3>References</h3>

<p>Li and Yu (2021) &lt;arXiv:2105.10417&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### simulate data with contamination
obs_num = 1000
D = 2
noise = 0.1 # proportion of contamination
mu0 = 0
mu1 = 1
sd =1
idmixture = rbinom(obs_num/D, 1, 1-noise)
dat = NULL
for (j in 1:D){
  for (i in 1:(obs_num/(2*D))){
    if (idmixture[i] == 1){
      dat = c(dat,rnorm(1,mu0,sd))
    }
    else{
      dat = c(dat,rnorm(1,mu1/(2*noise),0))
    }
  }
  for (i in (obs_num/(2*D)+1):(obs_num/D)){
    if (idmixture[i] == 1){
      dat = c(dat,rnorm(1,mu1,sd))
    }
    else{
      dat = c(dat,rnorm(1,mu1/(2*noise)-(1-noise)*mu1/noise,0))
    }
  }
}
plot(dat)
### perform ARC
ARC(dat,h = 120, epsilon = 0.1)
</code></pre>

<hr>
<h2 id='BD_U'>Backward detection with a robust bootstrap change point test using U-statistics for univariate mean change.</h2><span id='topic+BD_U'></span>

<h3>Description</h3>

<p>Perform the backward detection method with a robust bootstrap change point test using U-statistics on univariate data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BD_U(y, M, B = 100, inter = NULL, inter_ini = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BD_U_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="BD_U_+3A_m">M</code></td>
<td>
<p>An <code>integer</code> scalar representing initial block size of the backward detection algorithm.</p>
</td></tr>
<tr><td><code id="BD_U_+3A_b">B</code></td>
<td>
<p>An <code>integer</code> scalar representing the number of bootstrapped samples.</p>
</td></tr>
<tr><td><code id="BD_U_+3A_inter">inter</code></td>
<td>
<p>A nuisance parameter.</p>
</td></tr>
<tr><td><code id="BD_U_+3A_inter_ini">inter_ini</code></td>
<td>
<p>A nuisance parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>numeric</code> vector of estimated change point locations.
</p>


<h3>Author(s)</h3>

<p>Mengchu Li
</p>


<h3>References</h3>

<p>Yu and Chen (2019) &lt;arXiv:1904.03372&gt;.
</p>

<hr>
<h2 id='BS.cov'>Binary Segmentation for covariance change points detection through Operator Norm.</h2><span id='topic+BS.cov'></span>

<h3>Description</h3>

<p>Perform binary segmentation for covariance change points detection through Operator Norm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BS.cov(X, s, e, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BS.cov_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and vertical axis being dimensions.</p>
</td></tr>
<tr><td><code id="BS.cov_+3A_s">s</code></td>
<td>
<p>A <code>integer</code> scalar of starting index.</p>
</td></tr>
<tr><td><code id="BS.cov_+3A_e">e</code></td>
<td>
<p>A <code>integer</code> scalar of ending index.</p>
</td></tr>
<tr><td><code id="BS.cov_+3A_level">level</code></td>
<td>
<p>A parameter for tracking the level at which a change point is detected. Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the structure:
</p>

<ul>
<li><p> S:           A vector of estimated changepoints (sorted in strictly increasing order).
</p>
</li>
<li><p> Dval:        A vector of values of CUSUM statistic based on KS distance.
</p>
</li>
<li><p> Level:       A vector representing the levels at which each change point is detected.
</p>
</li>
<li><p> Parent:      A matrix with the starting indices on the first row and the ending indices on the second row.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2021) &lt;doi:10.3150/20-BEJ1249&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtain change points estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 10
A1 = gen.cov.mat(p, 1, "equal")
A2 = gen.cov.mat(p, 2, "diagonal")
A3 = gen.cov.mat(p, 3, "power")
X = cbind(t(MASS::mvrnorm(100, mu = rep(0, p), A1)), 
          t(MASS::mvrnorm(150, mu = rep(0, p), A2)), 
          t(MASS::mvrnorm(200, mu = rep(0, p), A3)))
temp = BS.cov(X, 1, 450)
thresholdBS(temp, 10)
</code></pre>

<hr>
<h2 id='BS.uni.nonpar'>Standard binary segmentation for univariate nonparametric change points detection.</h2><span id='topic+BS.uni.nonpar'></span>

<h3>Description</h3>

<p>Perform standard binary segmentation for univariate nonparametric change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BS.uni.nonpar(Y, s, e, N, delta, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BS.uni.nonpar_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with horizontal axis being time, and vertical axis being multiple observations on each time point.</p>
</td></tr>
<tr><td><code id="BS.uni.nonpar_+3A_s">s</code></td>
<td>
<p>A <code>integer</code> scalar of starting index.</p>
</td></tr>
<tr><td><code id="BS.uni.nonpar_+3A_e">e</code></td>
<td>
<p>A <code>integer</code> scalar of ending index.</p>
</td></tr>
<tr><td><code id="BS.uni.nonpar_+3A_n">N</code></td>
<td>
<p>A <code>integer</code> vector representing number of multiple observations on each time point.</p>
</td></tr>
<tr><td><code id="BS.uni.nonpar_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="BS.uni.nonpar_+3A_level">level</code></td>
<td>
<p>Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change points (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic based on KS distance.</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected.</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Padilla, Yu, Wang and Rinaldo (2021) &lt;doi:10.1214/21-EJS1809&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtaining change points estimation, <code><a href="#topic+tuneBSuninonpar">tuneBSuninonpar</a></code> for a tuning version.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y = t(as.matrix(c(rnorm(100, 0, 1), rnorm(100, 0, 10), rnorm(100, 0, 40))))
N = rep(1, 300)
temp = BS.uni.nonpar(Y, 1, 300, N, 5)
plot.ts(t(Y))
points(x = tail(temp$S[order(temp$Dval)],4), y = Y[,tail(temp$S[order(temp$Dval)],4)], col = "red")
</code></pre>

<hr>
<h2 id='BS.univar'>Standard binary segmentation for univariate mean change points detection.</h2><span id='topic+BS.univar'></span>

<h3>Description</h3>

<p>Perform standard binary segmentation for univariate mean change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BS.univar(y, s, e, delta = 2, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BS.univar_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="BS.univar_+3A_s">s</code></td>
<td>
<p>A <code>integer</code> scalar of starting index.</p>
</td></tr>
<tr><td><code id="BS.univar_+3A_e">e</code></td>
<td>
<p>A <code>integer</code> scalar of ending index.</p>
</td></tr>
<tr><td><code id="BS.univar_+3A_delta">delta</code></td>
<td>
<p>A positive <code>numeric</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="BS.univar_+3A_level">level</code></td>
<td>
<p>Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change point locations (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic.</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected.</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2020) &lt;doi:10.1214/20-EJS1710&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtaining change points estimation, <code><a href="#topic+tuneBSunivar">tuneBSunivar</a></code> for a tuning version.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(2,30),rep(0,120),rep(2,130))
temp = BS.univar(y, 1, length(y), delta = 5)
plot.ts(y)
points(x = tail(temp$S[order(temp$Dval)],4),
       y = y[tail(temp$S[order(temp$Dval)],4)], col = "red")
BS_result = thresholdBS(temp, tau = 4)
BS_result
print(BS_result$BS_tree, "value")
print(BS_result$BS_tree_trimmed, "value")
cpt_hat = sort(BS_result$cpt_hat[,1]) # the threshold tau is specified to be 4
Hausdorff.dist(cpt_hat, cpt_true)
cpt_LR = local.refine.univar(cpt_hat, y)
Hausdorff.dist(cpt_LR, cpt_true)
</code></pre>

<hr>
<h2 id='calibrate.online.network.missing'>Calibrate step for online change point detection for network data with missing values.</h2><span id='topic+calibrate.online.network.missing'></span>

<h3>Description</h3>

<p>Calibrate step for online change point detection for network data by controlling the false alarm rate at level alpha.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrate.online.network.missing(
  train_miss_list,
  train_eta_list,
  threshold_len,
  alpha_grid,
  permu_num,
  pi_lb_hat,
  pi_ub_hat,
  rho_hat,
  rank_hat,
  C_lambda = 2/3,
  delta = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate.online.network.missing_+3A_train_miss_list">train_miss_list</code></td>
<td>
<p>A <code>list</code> of adjacency matrices (with entries being 0 or 1) with missing values being coercing to 0.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_train_eta_list">train_eta_list</code></td>
<td>
<p>A <code>list</code> of matrices associated with data_incomplete_list, each matrix indicates the missing entries in corresponding adjacency matrix.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_threshold_len">threshold_len</code></td>
<td>
<p>An <code>integer</code> scalar of the length of tuned thresholds.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_alpha_grid">alpha_grid</code></td>
<td>
<p>A <code>numeric</code> vector in (0,1) representing the desired false alarm rate.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_permu_num">permu_num</code></td>
<td>
<p>An <code>integer</code> scalar of number of random permutation for calibration.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_pi_lb_hat">pi_lb_hat</code></td>
<td>
<p>A <code>numeric</code> scalar of the lower bound of the missing probability.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_pi_ub_hat">pi_ub_hat</code></td>
<td>
<p>A <code>numeric</code> scalar of the upper bound of the missing probability.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_rho_hat">rho_hat</code></td>
<td>
<p>A <code>numeric</code> scalar of the sparsity parameter.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_rank_hat">rank_hat</code></td>
<td>
<p>An <code>integer</code> scalar of the rank of the underlying graphon matrix.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_c_lambda">C_lambda</code></td>
<td>
<p>A <code>numeric</code> scalar of an absolute constant, which is set to be 2/3 by default.</p>
</td></tr>
<tr><td><code id="calibrate.online.network.missing_+3A_delta">delta</code></td>
<td>
<p>An <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>C_lambda</code></td>
<td>
<p>The absolute constant</p>
</td></tr>
<tr><td><code>rho_hat</code></td>
<td>
<p>the (estimated) sparsity parameter</p>
</td></tr>
<tr><td><code>rank_hat</code></td>
<td>
<p>the (estimated) rank of underlying graphon matrix</p>
</td></tr>
<tr><td><code>pi_lb_hat</code></td>
<td>
<p>the (estimated) lower bound of the missing probability</p>
</td></tr>
<tr><td><code>pi_ub_hat</code></td>
<td>
<p>the (estimated) upper bound of the missing probability</p>
</td></tr>
<tr><td><code>thresholds_array</code></td>
<td>
<p>A <code>numeric</code> array of calibrated threshold</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Dubey, Xu and Yu (2021) &lt;arxiv:2110.06450&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+online.network.missing">online.network.missing</a></code> for detecting online change point.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 6 # number of nodes
rho = 0.5 # sparsity parameter
block_num = 3 # number of groups for SBM
train_obs_num = 150 # sample size for each segment
conn1_mat = rho * matrix(c(0.6,1,0.6,1,0.6,0.5,0.6,0.5,0.6), nrow = 3) # connectivity matrix 
set.seed(1)
can_vec = sample(1:p, replace = FALSE) # randomly assign nodes into groups
sbm = simu.SBM(conn1_mat, can_vec, train_obs_num, symm = TRUE, self = TRUE)
train_mat = sbm$obs_mat
train_list = lapply(1:ncol(train_mat), function(t) lowertri2mat(train_mat[,t], p, diag = TRUE))
pi_mat = matrix(0.9, p, p)
train_eta_list = lapply(1:length(train_list), function(t) gen.missing(pi_mat, symm = TRUE))
train_miss_list = lapply(1:length(train_list), function(t) train_eta_list[[t]] * train_list[[t]])
pi_lb_hat = quantile(Reduce("+", train_eta_list)/train_obs_num, 0.05) # estimator of pi_lb
pi_ub_hat = quantile(Reduce("+", train_eta_list)/train_obs_num, 0.95) # estimator of pi_ub
C_lambda = 2/3
lambda = lambda.network.missing(1, length(train_miss_list), length(train_miss_list), 0.05, 
                                rho = 0.509, pi_ub = pi_ub_hat, p, C_lambda)
graphon_miss_impute = softImpute.network.missing(train_miss_list, train_eta_list, lambda, 1)
graphon_miss_hat = graphon_miss_impute$u %*% diag(as.numeric(graphon_miss_impute$d)) %*% 
                   t(graphon_miss_impute$v)
rho_hat = quantile(graphon_miss_hat, 0.95)
rank_hat = sum(graphon_miss_impute$d != 0)
alpha_grid = c(0.05)
permu_num = 10
threshold_len = 30
temp = calibrate.online.network.missing(train_miss_list, train_eta_list, threshold_len, alpha_grid, 
                   permu_num, pi_lb_hat, pi_ub_hat, rho_hat, rank_hat, C_lambda, delta = 5)
</code></pre>

<hr>
<h2 id='CI.regression'>Confidence interval construction of change points for regression settings with change points.</h2><span id='topic+CI.regression'></span>

<h3>Description</h3>

<p>Construct element-wise confidence interval for change points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CI.regression(
  cpt_init,
  cpt_LR,
  beta_hat,
  y,
  X,
  w = 0.9,
  B = 1000,
  M,
  alpha_vec,
  rounding = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CI.regression_+3A_cpt_init">cpt_init</code></td>
<td>
<p>An <code>integer</code> vector of initial changepoints estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_cpt_lr">cpt_LR</code></td>
<td>
<p>An <code>integer</code> vector of refined changepoints estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_beta_hat">beta_hat</code></td>
<td>
<p>A <code>numeric</code> (px(K_hat+1))matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time.</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_w">w</code></td>
<td>
<p>A <code>numeric</code> scalar in (0,1) representing the weight for interval truncation.</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_b">B</code></td>
<td>
<p>An <code>integer</code> scalar corresponding to the number of simulated two-sided Brownian motion with drift.</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_m">M</code></td>
<td>
<p>An <code>integer</code> scalar corresponding to the length for each side of the limiting distribution, i.e. the two-sided Brownian motion with drift.</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_alpha_vec">alpha_vec</code></td>
<td>
<p>An <code>numeric</code> vector in (0,1) representing the vector of significance levels.</p>
</td></tr>
<tr><td><code id="CI.regression_+3A_rounding">rounding</code></td>
<td>
<p>A <code>boolean</code> scalar representing if the confidence intervals need to be rounded into integer intervals.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An length(cpt_init)-2-length(alpha_vec) array of confidence intervals.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>
<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 5
p = 10
n = 200
cpt_true = c(70, 140)
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
lambda_set = c(0.1, 0.5, 1, 2)
zeta_set = c(10, 15, 20)
temp = CV.search.DPDU.regression(y = data$y, X = data$X, lambda_set, zeta_set)
temp$test_error # test error result
# find the indices of lambda_set and zeta_set which minimizes the test error
min_idx = as.vector(arrayInd(which.min(temp$test_error), dim(temp$test_error))) 
lambda_set[min_idx[2]]
zeta_set[min_idx[1]]
cpt_init = unlist(temp$cpt_hat[min_idx[1], min_idx[2]])
beta_hat = matrix(unlist(temp$beta_hat[min_idx[1], min_idx[2]]), ncol = length(cpt_init)+1)
cpt_LR = local.refine.DPDU.regression(cpt_init, beta_hat, data$y, data$X, w = 0.9)
alpha_vec = c(0.01, 0.05, 0.1)
CI.regression(cpt_init, cpt_LR, beta_hat, data$y, data$X, w = 0.9, B = 1000, M = n, alpha_vec)
</code></pre>

<hr>
<h2 id='CV.search.DP.LR.regression'>Grid search based on Cross-Validation of all tuning parameters (gamma, lambda and zeta) for regression.</h2><span id='topic+CV.search.DP.LR.regression'></span>

<h3>Description</h3>

<p>Perform grid search based on Cross-Validation of all tuning parameters (gamma, lambda and zeta)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.search.DP.LR.regression(
  y,
  X,
  gamma_set,
  lambda_set,
  zeta_set,
  delta,
  eps = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV.search.DP.LR.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="CV.search.DP.LR.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time.</p>
</td></tr>
<tr><td><code id="CV.search.DP.LR.regression_+3A_gamma_set">gamma_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameter associated with the l0 penalty.</p>
</td></tr>
<tr><td><code id="CV.search.DP.LR.regression_+3A_lambda_set">lambda_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameter for the lasso penalty.</p>
</td></tr>
<tr><td><code id="CV.search.DP.LR.regression_+3A_zeta_set">zeta_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameter for the group lasso.</p>
</td></tr>
<tr><td><code id="CV.search.DP.LR.regression_+3A_delta">delta</code></td>
<td>
<p>A strictly positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="CV.search.DP.LR.regression_+3A_eps">eps</code></td>
<td>
<p>A <code>numeric</code> scalar of precision level for convergence of lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_hat</code></td>
<td>
<p>A list of vector of estimated changepoints (sorted in strictly increasing order)</p>
</td></tr>
<tr><td><code>K_hat</code></td>
<td>
<p>A list of scalar of number of estimated changepoints</p>
</td></tr>
<tr><td><code>test_error</code></td>
<td>
<p>A list of vector of testing errors (each row corresponding to each gamma, and each column corresponding to each lambda)</p>
</td></tr>
<tr><td><code>train_error</code></td>
<td>
<p>A list of vector of training errors</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Rinaldo, Wang, Wen, Willett and Yu (2020) &lt;arxiv:2010.10410&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
d0 = 8
p = 15
n = 100
cpt_true = c(30, 70)
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
gamma_set = c(0.01, 0.1)
lambda_set = c(0.01, 0.1)
temp = CV.search.DP.regression(y = data$y, X = data$X, gamma_set, lambda_set, delta = 2)
temp$test_error # test error result
# find the indices of gamma_set and lambda_set which minimizes the test error
min_idx = as.vector(arrayInd(which.min(temp$test_error), dim(temp$test_error))) 
gamma_set[min_idx[1]]
lambda_set[min_idx[2]]
cpt_init = unlist(temp$cpt_hat[min_idx[1], min_idx[2]])
zeta_set = c(0.1, 1)
temp_zeta = CV.search.DP.LR.regression(data$y, data$X, gamma_set[min_idx[1]],
                  lambda_set[min_idx[2]], zeta_set, delta = 2, eps = 0.001)
min_zeta_idx = which.min(unlist(temp_zeta$test_error))
cpt_LR = local.refine.regression(cpt_init, data$y, X = data$X, zeta = zeta_set[min_zeta_idx])
Hausdorff.dist(cpt_init, cpt_true)
Hausdorff.dist(cpt_LR, cpt_true)
</code></pre>

<hr>
<h2 id='CV.search.DP.poly'>Grid search for dynamic programming to select the tuning parameter through Cross-Validation.</h2><span id='topic+CV.search.DP.poly'></span>

<h3>Description</h3>

<p>Perform grid search for dynamic programming to select the tuning parameter through Cross-Validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.search.DP.poly(y, r, gamma_set, delta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV.search.DP.poly_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="CV.search.DP.poly_+3A_r">r</code></td>
<td>
<p>An <code>integer</code> scalar order of polynomials.</p>
</td></tr>
<tr><td><code id="CV.search.DP.poly_+3A_gamma_set">gamma_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameter associated with the l0 penalty.</p>
</td></tr>
<tr><td><code id="CV.search.DP.poly_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_hat</code></td>
<td>
<p>A list of vector of estimated change points locations (sorted in strictly increasing order)</p>
</td></tr>
<tr><td><code>K_hat</code></td>
<td>
<p>A list of scalar of number of estimated change points</p>
</td></tr>
<tr><td><code>test_error</code></td>
<td>
<p>A list of vector of testing errors</p>
</td></tr>
<tr><td><code>train_error</code></td>
<td>
<p>A list of vector of training errors</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Yu and Chatterjee (2020) &lt;arXiv:2007.09910&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(2,30),rep(0,120),rep(2,130))
plot.ts(y)
gamma_set = 3:9
DP_result = CV.search.DP.poly(y, r = 2, gamma_set, delta = 5)
min_idx = which.min(DP_result$test_error)
cpt_init = unlist(DP_result$cpt_hat[min_idx])
local.refine.poly(cpt_init, y, r = 2, delta_lr = 5)
</code></pre>

<hr>
<h2 id='CV.search.DP.regression'>Grid search based on cross-validation of dynamic programming for regression change points localisation with <code class="reqn">l_0</code> penalisation.</h2><span id='topic+CV.search.DP.regression'></span>

<h3>Description</h3>

<p>Perform grid search to select tuning parameters gamma (for <code class="reqn">l_0</code> penalty of DP) and lambda (for lasso penalty) based on cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.search.DP.regression(y, X, gamma_set, lambda_set, delta, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV.search.DP.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="CV.search.DP.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time.</p>
</td></tr>
<tr><td><code id="CV.search.DP.regression_+3A_gamma_set">gamma_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameters associated with <code class="reqn">l_0</code> penalty of DP.</p>
</td></tr>
<tr><td><code id="CV.search.DP.regression_+3A_lambda_set">lambda_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameters for lasso penalty.</p>
</td></tr>
<tr><td><code id="CV.search.DP.regression_+3A_delta">delta</code></td>
<td>
<p>A strictly positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="CV.search.DP.regression_+3A_eps">eps</code></td>
<td>
<p>A <code>numeric</code> scalar of precision level for convergence of lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_hat</code></td>
<td>
<p>A list of vector of estimated change points</p>
</td></tr>
<tr><td><code>K_hat</code></td>
<td>
<p>A list of scalar of number of estimated change points</p>
</td></tr>
<tr><td><code>test_error</code></td>
<td>
<p>A list of vector of testing errors (each row corresponding to each gamma, and each column corresponding to each lambda)</p>
</td></tr>
<tr><td><code>train_error</code></td>
<td>
<p>A list of vector of training errors</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang
</p>


<h3>References</h3>

<p>Rinaldo, Wang, Wen, Willett and Yu (2020) &lt;arxiv:2010.10410&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 10
p = 20
n = 100
cpt_true = c(30, 70)
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
gamma_set = c(0.01, 0.1, 1)
lambda_set = c(0.01, 0.1, 1, 3)
temp = CV.search.DP.regression(y = data$y, X = data$X, gamma_set, lambda_set, delta = 2)
temp$test_error # test error result
# find the indices of gamma_set and lambda_set which minimizes the test error
min_idx = as.vector(arrayInd(which.min(temp$test_error), dim(temp$test_error))) 
gamma_set[min_idx[1]]
lambda_set[min_idx[2]]
cpt_init = unlist(temp$cpt_hat[min_idx[1], min_idx[2]])
</code></pre>

<hr>
<h2 id='CV.search.DP.univar'>Grid search for dynamic programming to select the tuning parameter through Cross-Validation.</h2><span id='topic+CV.search.DP.univar'></span>

<h3>Description</h3>

<p>Perform grid search for dynamic programming to select the tuning parameter through Cross-Validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.search.DP.univar(y, gamma_set, delta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV.search.DP.univar_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="CV.search.DP.univar_+3A_gamma_set">gamma_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameter associated with the <code class="reqn">l_0</code> penalty.</p>
</td></tr>
<tr><td><code id="CV.search.DP.univar_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_hat</code></td>
<td>
<p>A list of vector of estimated change points (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>K_hat</code></td>
<td>
<p>A list of scalar of number of estimated change points.</p>
</td></tr>
<tr><td><code>test_error</code></td>
<td>
<p>A list of vector of testing errors.</p>
</td></tr>
<tr><td><code>train_error</code></td>
<td>
<p>A list of vector of training errors.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2020) &lt;doi:10.1214/20-EJS1710&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(2,30),rep(0,120),rep(2,130))
gamma_set = 1:5
DP_result = CV.search.DP.univar(y, gamma_set, delta = 5)
min_idx = which.min(DP_result$test_error)
cpt_hat = unlist(DP_result$cpt_hat[min_idx])
Hausdorff.dist(cpt_hat, cpt_true)
</code></pre>

<hr>
<h2 id='CV.search.DP.VAR1'>Grid search based on cross-validation of dynamic programming for VAR change points detection via <code class="reqn">l_0</code> penalty.</h2><span id='topic+CV.search.DP.VAR1'></span>

<h3>Description</h3>

<p>Perform grid search based on cross-validation of dynamic programming for VAR change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.search.DP.VAR1(DATA, gamma_set, lambda_set, delta, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV.search.DP.VAR1_+3A_data">DATA</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with horizontal axis being time, and vertical axis being dimensions.</p>
</td></tr>
<tr><td><code id="CV.search.DP.VAR1_+3A_gamma_set">gamma_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameters associated with the <code class="reqn">l_0</code> penalty.</p>
</td></tr>
<tr><td><code id="CV.search.DP.VAR1_+3A_lambda_set">lambda_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameters for lasso penalty.</p>
</td></tr>
<tr><td><code id="CV.search.DP.VAR1_+3A_delta">delta</code></td>
<td>
<p>A strictly <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="CV.search.DP.VAR1_+3A_eps">eps</code></td>
<td>
<p>A <code>numeric</code> scalar of precision level for convergence of lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_hat</code></td>
<td>
<p>A list of vector of estimated change points</p>
</td></tr>
<tr><td><code>K_hat</code></td>
<td>
<p>A list of scalar of number of estimated change points</p>
</td></tr>
<tr><td><code>test_error</code></td>
<td>
<p>A list of vector of testing errors (each row corresponding to each gamma, and each column corresponding to each lambda)</p>
</td></tr>
<tr><td><code>train_error</code></td>
<td>
<p>A list of vector of training errors</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu, Rinaldo and Willett (2019) &lt;arxiv:1909.06359&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
p = 10
sigma = 1
n = 20
v1 = 2*(seq(1,p,1)%%2) - 1
v2 = -v1
AA = matrix(0, nrow = p, ncol = p-2)
A1 = cbind(v1,v2,AA)*0.1
A2 = cbind(v2,v1,AA)*0.1
A3 = A1
cpt_true = c(40, 80)
data = simu.VAR1(sigma, p, 2*n+1, A1)
data = cbind(data, simu.VAR1(sigma, p, 2*n, A2, vzero=c(data[,ncol(data)])))
data = cbind(data, simu.VAR1(sigma, p, 2*n, A3, vzero=c(data[,ncol(data)])))
gamma_set = c(0.1, 0.5, 1)
lambda_set = c(0.1, 1, 3.2)
temp = CV.search.DP.VAR1(data, gamma_set, lambda_set, delta = 5)
temp$test_error # test error result
# find the indices of gamma.set and lambda.set which minimizes the test error
min_idx = as.vector(arrayInd(which.min(temp$test_error), dim(temp$test_error)))
cpt_init = unlist(temp$cpt_hat[min_idx[1], min_idx[2]])
Hausdorff.dist(cpt_init, cpt_true)
</code></pre>

<hr>
<h2 id='CV.search.DPDU.regression'>Grid search based on cross-validation of dynamic programming for regression change points localisation with <code class="reqn">l_0</code> penalisation.</h2><span id='topic+CV.search.DPDU.regression'></span>

<h3>Description</h3>

<p>Perform grid search to select tuning parameters gamma (for <code class="reqn">l_0</code> penalty of DP) and lambda (for lasso penalty) based on cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.search.DPDU.regression(y, X, lambda_set, zeta_set, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV.search.DPDU.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="CV.search.DPDU.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time.</p>
</td></tr>
<tr><td><code id="CV.search.DPDU.regression_+3A_lambda_set">lambda_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameters for lasso penalty.</p>
</td></tr>
<tr><td><code id="CV.search.DPDU.regression_+3A_zeta_set">zeta_set</code></td>
<td>
<p>An <code>integer</code> vector of tuning parameter associated with <code class="reqn">l_0</code> penalty (minimum interval size).</p>
</td></tr>
<tr><td><code id="CV.search.DPDU.regression_+3A_eps">eps</code></td>
<td>
<p>A <code>numeric</code> scalar of precision level for convergence of lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_hat</code></td>
<td>
<p>A list of vectors of estimated change points</p>
</td></tr>
<tr><td><code>K_hat</code></td>
<td>
<p>A list of scalars of number of estimated change points</p>
</td></tr>
<tr><td><code>test_error</code></td>
<td>
<p>A matrix of testing errors (each row corresponding to each gamma, and each column corresponding to each lambda)</p>
</td></tr>
<tr><td><code>train_error</code></td>
<td>
<p>A matrix of training errors</p>
</td></tr>
<tr><td><code>beta_hat</code></td>
<td>
<p>A list of matrices of estimated regression coefficients</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 5
p = 30
n = 200
cpt_true = 100
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
lambda_set = c(0.01, 0.1, 1, 2)
zeta_set = c(10, 15, 20)
temp = CV.search.DPDU.regression(y = data$y, X = data$X, lambda_set, zeta_set)
temp$test_error # test error result
# find the indices of lambda_set and zeta_set which minimizes the test error
min_idx = as.vector(arrayInd(which.min(temp$test_error), dim(temp$test_error))) 
lambda_set[min_idx[2]]
zeta_set[min_idx[1]]
cpt_init = unlist(temp$cpt_hat[min_idx[1], min_idx[2]])
beta_hat = matrix(unlist(temp$beta_hat[min_idx[1], min_idx[2]]), ncol = length(cpt_init)+1)
</code></pre>

<hr>
<h2 id='DP.poly'>Dynamic programming algorithm for univariate polynomials change points detection.</h2><span id='topic+DP.poly'></span>

<h3>Description</h3>

<p>Perform dynamic programming algorithm for univariate polynomials change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DP.poly(y, r, gamma, delta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DP.poly_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="DP.poly_+3A_r">r</code></td>
<td>
<p>An <code>integer</code> scalar order of polynomials.</p>
</td></tr>
<tr><td><code id="DP.poly_+3A_gamma">gamma</code></td>
<td>
<p>A <code>numeric</code> scalar of the tuning parameter associated with the <code class="reqn">l_0</code> penalty.</p>
</td></tr>
<tr><td><code id="DP.poly_+3A_delta">delta</code></td>
<td>
<p>A strictly <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;DP&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>partition</code></td>
<td>
<p>A vector of the best partition.</p>
</td></tr>
<tr><td><code>yhat</code></td>
<td>
<p>A vector of mean estimation for corresponding to the best partition.</p>
</td></tr>
<tr><td><code>cpt</code></td>
<td>
<p>A vector of change points estimation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Yu and Chatterjee (2020) &lt;arXiv:2007.09910&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(2,30),rep(0,120),rep(2,130))
plot.ts(y)
temp = DP.poly(y, r = 2, gamma = 15, delta = 5)
temp$cpt
</code></pre>

<hr>
<h2 id='DP.regression'>Dynamic programming algorithm for regression change points localisation with <code class="reqn">l_0</code> penalisation.</h2><span id='topic+DP.regression'></span>

<h3>Description</h3>

<p>Perform dynamic programming algorithm for regression change points localisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DP.regression(y, X, gamma, lambda, delta, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DP.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="DP.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time.</p>
</td></tr>
<tr><td><code id="DP.regression_+3A_gamma">gamma</code></td>
<td>
<p>A positive <code>numeric</code> scalar stands for tuning parameter associated with <code class="reqn">l_0</code> penalty.</p>
</td></tr>
<tr><td><code id="DP.regression_+3A_lambda">lambda</code></td>
<td>
<p>A positive <code>numeric</code> scalar stands for tuning parameter associated with the lasso penalty.</p>
</td></tr>
<tr><td><code id="DP.regression_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar stands for minimum spacing.</p>
</td></tr>
<tr><td><code id="DP.regression_+3A_eps">eps</code></td>
<td>
<p>A <code>numeric</code> scalar of precision level for convergence of lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;DP&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>partition</code></td>
<td>
<p>A vector of the best partition.</p>
</td></tr>
<tr><td><code>cpt</code></td>
<td>
<p>A vector of change points estimation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Rinaldo, Wang, Wen, Willett and Yu (2020) &lt;arxiv:2010.10410&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 10
p = 20
n = 100
cpt_true = c(30, 70)
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
temp = DP.regression(y = data$y, X = data$X, gamma = 2, lambda = 1, delta = 5)
cpt_hat = temp$cpt
</code></pre>

<hr>
<h2 id='DP.SEPP'>Dynamic programming for SEPP change points detection through <code class="reqn">l_0</code> penalty.</h2><span id='topic+DP.SEPP'></span>

<h3>Description</h3>

<p>Perform dynamic programming for SEPP change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DP.SEPP(DATA, gamma, lambda, delta, delta2, intercept, threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DP.SEPP_+3A_data">DATA</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with horizontal axis being time.</p>
</td></tr>
<tr><td><code id="DP.SEPP_+3A_gamma">gamma</code></td>
<td>
<p>A <code>numeric</code> scalar of tuning parameter associated with the <code class="reqn">l_0</code> penalty.</p>
</td></tr>
<tr><td><code id="DP.SEPP_+3A_lambda">lambda</code></td>
<td>
<p>A <code>numeric</code> scalar of tuning parameter for lasso penalty.</p>
</td></tr>
<tr><td><code id="DP.SEPP_+3A_delta">delta</code></td>
<td>
<p>An <code>integer</code> scalar of minimum spacing for dynamic programming.</p>
</td></tr>
<tr><td><code id="DP.SEPP_+3A_delta2">delta2</code></td>
<td>
<p>An <code>integer</code> scalar representing the maximal of the change point spacing (for reducing computation cost).</p>
</td></tr>
<tr><td><code id="DP.SEPP_+3A_intercept">intercept</code></td>
<td>
<p>A <code>numeric</code> scalar representing the intercept of the model, which is assumed to be known.</p>
</td></tr>
<tr><td><code id="DP.SEPP_+3A_threshold">threshold</code></td>
<td>
<p>A <code>numeric</code> scalar representing the upper bound for each coordinate of X_t (for stability).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;DP&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>partition</code></td>
<td>
<p>A vector of the best partition.</p>
</td></tr>
<tr><td><code>cpt</code></td>
<td>
<p>A vector of change points estimation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, D., Yu, Y., &amp; Willett, R. (2020). Detecting Abrupt Changes in High-Dimensional Self-Exciting Poisson Processes. arXiv preprint arXiv:2006.03572.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 8 # dimension
n = 15
s = 3 # s is sparsity
factor = 0.2 # large factor gives exact recovery
threshold = 4 # thresholding makes the process stable
intercept = 1/2 # intercept of the model. Assume to be known as in the existing literature
A1 = A2 = A3 = matrix(0, p, p)
diag(A1[,-1]) = 1
diag(A1) = 1
diag(A1[-1,]) = -1
A1 = A1*factor
A1[(s+1):p, (s+1):p] = 0
diag(A2[,-1]) = 1
diag(A2) = -1
diag(A2[-1,]) = 1
A2 = A2*factor
A2[(s+1):p, (s+1):p] = 0
data1 = simu.SEPP(intercept, n, A1, threshold, vzero = NULL)
data2 = simu.SEPP(intercept, n, A2, threshold, vzero = data1[,n])
data = cbind(data1, data2)
gamma = 0.1
delta = 0.5*n
delta2 = 1.5*n
intercept = 1/2
threshold = 6
DP_result = DP.SEPP(data, gamma = gamma, lambda = 0.03, delta, delta2, intercept, threshold)
cpt_hat = DP_result$cpt
</code></pre>

<hr>
<h2 id='DP.univar'>Dynamic programming for univariate mean change points detection through <code class="reqn">l_0</code> penalty.</h2><span id='topic+DP.univar'></span>

<h3>Description</h3>

<p>Perform dynamic programming for univariate mean change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DP.univar(y, gamma, delta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DP.univar_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="DP.univar_+3A_gamma">gamma</code></td>
<td>
<p>A <code>numeric</code> scalar of the tuning parameter associated with <code class="reqn">l_0</code> penalty.</p>
</td></tr>
<tr><td><code id="DP.univar_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;DP&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>partition</code></td>
<td>
<p>A vector of the best partition.</p>
</td></tr>
<tr><td><code>yhat</code></td>
<td>
<p>A vector of mean estimation for corresponding to the best partition.</p>
</td></tr>
<tr><td><code>cpt</code></td>
<td>
<p>A vector of change points estimation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2020) &lt;doi:10.1214/20-EJS1710&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(1,30),rep(0,120),rep(1,130))
DP_result = DP.univar(y, gamma = 5, delta = 5)
cpt_hat = DP_result$cpt
Hausdorff.dist(cpt_hat, cpt_true)
</code></pre>

<hr>
<h2 id='DP.VAR1'>Dynamic programming for VAR1 change points detection through <code class="reqn">l_0</code> penalty.</h2><span id='topic+DP.VAR1'></span>

<h3>Description</h3>

<p>Perform dynamic programming for VAR1 change points detection through <code class="reqn">l_0</code> penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DP.VAR1(X_futu, X_curr, gamma, lambda, delta, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DP.VAR1_+3A_x_futu">X_futu</code></td>
<td>
<p>A <code>numeric</code> matrix of time series at one step ahead, with horizontal axis being time.</p>
</td></tr>
<tr><td><code id="DP.VAR1_+3A_x_curr">X_curr</code></td>
<td>
<p>A <code>numeric</code> matrix of time series at current step, with horizontal axis being time.</p>
</td></tr>
<tr><td><code id="DP.VAR1_+3A_gamma">gamma</code></td>
<td>
<p>A <code>numeric</code> scalar of the tuning parameter associated with <code class="reqn">l_0</code> penalty.</p>
</td></tr>
<tr><td><code id="DP.VAR1_+3A_lambda">lambda</code></td>
<td>
<p>A <code>numeric</code> scalar of the tuning parameter for lasso penalty.</p>
</td></tr>
<tr><td><code id="DP.VAR1_+3A_delta">delta</code></td>
<td>
<p>A strictly <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="DP.VAR1_+3A_eps">eps</code></td>
<td>
<p>A <code>numeric</code> scalar of precision level for convergence of lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;DP&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>partition</code></td>
<td>
<p>A vector of the best partition.</p>
</td></tr>
<tr><td><code>cpt</code></td>
<td>
<p>A vector of change points estimation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu, Rinaldo and Willett (2019) &lt;arxiv:1909.06359&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 10
sigma = 1
n = 20
v1 = 2*(seq(1,p,1)%%2) - 1
v2 = -v1
AA = matrix(0, nrow = p, ncol = p-2)
A1 = cbind(v1,v2,AA)*0.1
A2 = cbind(v2,v1,AA)*0.1
A3 = A1
data = simu.VAR1(sigma, p, 2*n+1, A1)
data = cbind(data, simu.VAR1(sigma, p, 2*n, A2, vzero=c(data[,ncol(data)])))
data = cbind(data, simu.VAR1(sigma, p, 2*n, A3, vzero=c(data[,ncol(data)])))
N = ncol(data)
X_curr = data[,1:(N-1)]
X_futu = data[,2:N]
DP_result = DP.VAR1(X_futu, X_curr, gamma = 1, lambda = 1, delta = 5)
DP_result$cpt
</code></pre>

<hr>
<h2 id='DPDU.regression'>Dynamic programming with dynamic update algorithm for regression change points localisation with <code class="reqn">l_0</code> penalisation.</h2><span id='topic+DPDU.regression'></span>

<h3>Description</h3>

<p>Perform DPDU algorithm for regression change points localisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPDU.regression(y, X, lambda, zeta, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DPDU.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="DPDU.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time.</p>
</td></tr>
<tr><td><code id="DPDU.regression_+3A_lambda">lambda</code></td>
<td>
<p>A positive <code>numeric</code> scalar of tuning parameter for lasso penalty.</p>
</td></tr>
<tr><td><code id="DPDU.regression_+3A_zeta">zeta</code></td>
<td>
<p>A positive <code>integer</code> scalar of tuning parameter associated with <code class="reqn">l_0</code> penalty (minimum interval size).</p>
</td></tr>
<tr><td><code id="DPDU.regression_+3A_eps">eps</code></td>
<td>
<p>A <code>numeric</code> scalar of precision level for convergence of lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;DP&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>partition</code></td>
<td>
<p>A vector of the best partition.</p>
</td></tr>
<tr><td><code>cpt</code></td>
<td>
<p>A vector of change points estimation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 10
p = 20
n = 100
cpt_true = c(30, 70)
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
temp = DPDU.regression(y = data$y, X = data$X, lambda = 1, zeta = 20)
cpt_hat = temp$cpt
</code></pre>

<hr>
<h2 id='gen.cov.mat'>Generate population covariance matrix with dimension p.</h2><span id='topic+gen.cov.mat'></span>

<h3>Description</h3>

<p>Generate population covariance matrix with dimension p.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.cov.mat(p, sigma2, type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.cov.mat_+3A_p">p</code></td>
<td>
<p>A <code>integer</code> scalar of dimensionality.</p>
</td></tr>
<tr><td><code id="gen.cov.mat_+3A_sigma2">sigma2</code></td>
<td>
<p>A positive <code>numeric</code> scalar representing the variance of each entry.</p>
</td></tr>
<tr><td><code id="gen.cov.mat_+3A_type">type</code></td>
<td>
<p>Specify the type of a covariance matrix: Diagonal structure (&quot;diagonal&quot;); Equal correlation structure (&quot;equal&quot;); Power decay structure (&quot;power&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>numeric</code> p-by-p matrix.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gen.cov.mat(p = 5, sigma2 = 1, type = "diagonal")
</code></pre>

<hr>
<h2 id='gen.missing'>Function to generate a matrix with values 0 or 1, where 0 indicating the entry is missing</h2><span id='topic+gen.missing'></span>

<h3>Description</h3>

<p>Function to generate a matrix with values 0 or 1, where 0 indicating the entry is missing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.missing(pi_mat, symm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.missing_+3A_pi_mat">pi_mat</code></td>
<td>
<p>A <code>numeric</code> pxp matrix, for each entry, the value representing the probability of missing.</p>
</td></tr>
<tr><td><code id="gen.missing_+3A_symm">symm</code></td>
<td>
<p>A <code>logic</code> scalar indicating if the output matrix needs to be symmetric.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>numeric</code> p x p matrix.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 5
pi_mat = matrix(0.9, p, p)
eta_mat = gen.missing(pi_mat, symm = TRUE)
</code></pre>

<hr>
<h2 id='gen.piece.poly'>Generate univariate data from piecewise polynomials of degree at most r.</h2><span id='topic+gen.piece.poly'></span>

<h3>Description</h3>

<p>Generate univariate data from piecewise polynomials (currently, only the linear, quadratic functions and cubic functions are considered).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.piece.poly(init_coef_vec, cpt_vec, kappa_mat, n, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.piece.poly_+3A_init_coef_vec">init_coef_vec</code></td>
<td>
<p>A (r+1)-dim <code>numeric</code> vector of coefficients for the first segment.</p>
</td></tr>
<tr><td><code id="gen.piece.poly_+3A_cpt_vec">cpt_vec</code></td>
<td>
<p>A K-dim <code>integer</code> vector of change points.</p>
</td></tr>
<tr><td><code id="gen.piece.poly_+3A_kappa_mat">kappa_mat</code></td>
<td>
<p>A (r+1)xK <code>numeric</code> matrix where the i-th column represents the jump sizes for coefficients associated with the i-th change point.</p>
</td></tr>
<tr><td><code id="gen.piece.poly_+3A_n">n</code></td>
<td>
<p>An <code>integer</code> scalar of sample size.</p>
</td></tr>
<tr><td><code id="gen.piece.poly_+3A_sigma">sigma</code></td>
<td>
<p>A <code>numeric</code> scalar of standard deviation of error terms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of data generated from piecewise polynomials.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Yu and Chatterjee (2020) &lt;arXiv:2007.09910&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r = 2
init_coef_vec = c(-2, 2, 9)
cpt_true = c(100, 200)
n = 300
sigma = 1
kappa_mat = cbind(c(3, 9, -27), c(-3, 9, -27))
plot.ts(gen.piece.poly(init_coef_vec, cpt_true, kappa_mat, n, sigma), ylab = "y")
</code></pre>

<hr>
<h2 id='gen.piece.poly.noiseless'>Mean function of piecewise polynomials.</h2><span id='topic+gen.piece.poly.noiseless'></span>

<h3>Description</h3>

<p>Compute mean function of piecewise polynomials (currently, only the linear, quadratic functions and cubic functions are considered).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.piece.poly.noiseless(init_coef_vec, cpt_vec, kappa_mat, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.piece.poly.noiseless_+3A_init_coef_vec">init_coef_vec</code></td>
<td>
<p>A <code>numeric</code> vector of coefficients for the first segment.</p>
</td></tr>
<tr><td><code id="gen.piece.poly.noiseless_+3A_cpt_vec">cpt_vec</code></td>
<td>
<p>An <code>integer</code> vector of change points.</p>
</td></tr>
<tr><td><code id="gen.piece.poly.noiseless_+3A_kappa_mat">kappa_mat</code></td>
<td>
<p>A <code>numeric</code> matrix where the i-th column represents the jump sizes for coefficients associated with the i-th change point.</p>
</td></tr>
<tr><td><code id="gen.piece.poly.noiseless_+3A_n">n</code></td>
<td>
<p>An <code>integer</code> scalar of sample size.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of mean function of piecewise polynomials.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Yu and Chatterjee (2020) &lt;arXiv:2007.09910&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r = 2
init_coef_vec = c(-2, 2, 9)
cpt_true = c(100, 200)
n = 300
kappa_mat = cbind(c(3, 9, -27), c(-3, 9, -27))
plot.ts(gen.piece.poly.noiseless(init_coef_vec, cpt_true, kappa_mat, n), 
        ylab = "Values of piecewise polynomials")
</code></pre>

<hr>
<h2 id='Hausdorff.dist'>Bidirectional Hausdorff distance.</h2><span id='topic+Hausdorff.dist'></span>

<h3>Description</h3>

<p>Compute the bidirectional Hausdorff distance between two sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hausdorff.dist(vec1, vec2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hausdorff.dist_+3A_vec1">vec1</code></td>
<td>
<p>A <code>integer</code> vector forms a subset of 1, 2, ..., n.</p>
</td></tr>
<tr><td><code id="Hausdorff.dist_+3A_vec2">vec2</code></td>
<td>
<p>A <code>integer</code> vector forms a subset of 1, 2, ..., n.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer scalar of bidirectional Hausdorff distance.
</p>


<h3>Author(s)</h3>

<p>Daren Wang
</p>


<h3>Examples</h3>

<pre><code class='language-R'>vec1 = sample.int(1000, size = 50)
vec2 = sample.int(2000, size = 100)
Hausdorff.dist(vec1, vec2)
</code></pre>

<hr>
<h2 id='huber_mean'>Element-wise adaptive Huber mean estimator.</h2><span id='topic+huber_mean'></span>

<h3>Description</h3>

<p>Computes the element-wise adaptive Huber mean estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber_mean(x, tau)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="huber_mean_+3A_x">x</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="huber_mean_+3A_tau">tau</code></td>
<td>
<p>A <code>numeric</code> scalar corresponding to the robustification parameter (larger than 0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>numeric</code> scalar corresponding to the adaptive Huber mean estimator.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
y = rnorm(100)
mean(y)
huber_mean(y, 1.345)
</code></pre>

<hr>
<h2 id='lambda.network.missing'>Function to compute the default thresholding parameter for leading singular value in the soft-impute algorithm.</h2><span id='topic+lambda.network.missing'></span>

<h3>Description</h3>

<p>Function to compute the default thresholding parameter for leading singular value in the soft-impute algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda.network.missing(s, e, t, alpha, rho, pi_ub, p, C_lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda.network.missing_+3A_s">s</code></td>
<td>
<p>An <code>integer</code> scalar of the starting index.</p>
</td></tr>
<tr><td><code id="lambda.network.missing_+3A_e">e</code></td>
<td>
<p>An <code>integer</code> scalar of the ending index.</p>
</td></tr>
<tr><td><code id="lambda.network.missing_+3A_t">t</code></td>
<td>
<p>An <code>integer</code> scalar of the splitting index.</p>
</td></tr>
<tr><td><code id="lambda.network.missing_+3A_alpha">alpha</code></td>
<td>
<p>A <code>numeric</code> scalar in (0,1) representing the desired false alarm rate.</p>
</td></tr>
<tr><td><code id="lambda.network.missing_+3A_rho">rho</code></td>
<td>
<p>A <code>numeric</code> scalar of the sparsity parameter.</p>
</td></tr>
<tr><td><code id="lambda.network.missing_+3A_pi_ub">pi_ub</code></td>
<td>
<p>A <code>numeric</code> scalar of the upper bound of the missing probability.</p>
</td></tr>
<tr><td><code id="lambda.network.missing_+3A_p">p</code></td>
<td>
<p>An <code>integer</code> scalar of the dimensionality of the graphon matrix.</p>
</td></tr>
<tr><td><code id="lambda.network.missing_+3A_c_lambda">C_lambda</code></td>
<td>
<p>A <code>numeric</code> scalar of an absolute constant, which is set to be 2/3 by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default thresholding parameter is given in Theorem 2 of the reference.
</p>


<h3>Value</h3>

<p>The default thresholding parameter for leading singular value in the soft-impute algorithm
</p>


<h3>References</h3>

<p>Dubey, Xu and Yu (2021) &lt;arxiv:2110.06450&gt;
</p>

<hr>
<h2 id='local.refine.CV.VAR1'>Local refinement for VAR1 change points detection.</h2><span id='topic+local.refine.CV.VAR1'></span>

<h3>Description</h3>

<p>Perform local refinement for VAR1 change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local.refine.CV.VAR1(cpt_init, DATA, zeta_set, delta_local)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local.refine.CV.VAR1_+3A_cpt_init">cpt_init</code></td>
<td>
<p>A <code>integer</code> vector of initial change points estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="local.refine.CV.VAR1_+3A_data">DATA</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and vertical axis being dimensions.</p>
</td></tr>
<tr><td><code id="local.refine.CV.VAR1_+3A_zeta_set">zeta_set</code></td>
<td>
<p>A <code>numeric</code> vector of candidate tuning parameters for group lasso penalty.</p>
</td></tr>
<tr><td><code id="local.refine.CV.VAR1_+3A_delta_local">delta_local</code></td>
<td>
<p>A strictly <code>integer</code> scalar of minimum spacing for group lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_hat</code></td>
<td>
<p>A vector of estimated change point locations (sorted in strictly increasing order)</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>A scalar of selected zeta by cross-validation</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu, Rinaldo and Willett (2019) &lt;arxiv:1909.06359&gt;
</p>

<hr>
<h2 id='local.refine.DPDU.regression'>Local refinement for DPDU regression change points localisation.</h2><span id='topic+local.refine.DPDU.regression'></span>

<h3>Description</h3>

<p>Perform local refinement for regression change points localisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local.refine.DPDU.regression(cpt_init, beta_hat, y, X, w = 0.9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local.refine.DPDU.regression_+3A_cpt_init">cpt_init</code></td>
<td>
<p>An <code>integer</code> vector of initial changepoints estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="local.refine.DPDU.regression_+3A_beta_hat">beta_hat</code></td>
<td>
<p>A <code>numeric</code> (px(K_hat+1))matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code id="local.refine.DPDU.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="local.refine.DPDU.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time..</p>
</td></tr>
<tr><td><code id="local.refine.DPDU.regression_+3A_w">w</code></td>
<td>
<p>A <code>numeric</code> scalar in (0,1) representing the weight for interval truncation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of locally refined change points estimation.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>
<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 5
p = 30
n = 200
cpt_true = 100
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
lambda_set = c(0.01, 0.1, 1, 2)
zeta_set = c(10, 15, 20)
temp = CV.search.DPDU.regression(y = data$y, X = data$X, lambda_set, zeta_set)
temp$test_error # test error result
# find the indices of lambda_set and zeta_set which minimizes the test error
min_idx = as.vector(arrayInd(which.min(temp$test_error), dim(temp$test_error))) 
lambda_set[min_idx[2]]
zeta_set[min_idx[1]]
cpt_init = unlist(temp$cpt_hat[min_idx[1], min_idx[2]])
beta_hat = matrix(unlist(temp$beta_hat[min_idx[1], min_idx[2]]), ncol = length(cpt_init)+1)
cpt_refined = local.refine.DPDU.regression(cpt_init, beta_hat, data$y, data$X, w = 0.9)
</code></pre>

<hr>
<h2 id='local.refine.network'>Local refinement for network change points detection.</h2><span id='topic+local.refine.network'></span>

<h3>Description</h3>

<p>Perform local refinement for network change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local.refine.network(
  cpt_init,
  data_mat1,
  data_mat2,
  self = FALSE,
  w = 0.5,
  tau2,
  tau3 = Inf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local.refine.network_+3A_cpt_init">cpt_init</code></td>
<td>
<p>A <code>integer</code> vector of initial change points estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="local.refine.network_+3A_data_mat1">data_mat1</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and with each column be the vectorized adjacency matrix.</p>
</td></tr>
<tr><td><code id="local.refine.network_+3A_data_mat2">data_mat2</code></td>
<td>
<p>A independent copy of data_mat1.</p>
</td></tr>
<tr><td><code id="local.refine.network_+3A_self">self</code></td>
<td>
<p>A <code>logic</code> scalar indicating if adjacency matrices are required to have self-loop.</p>
</td></tr>
<tr><td><code id="local.refine.network_+3A_w">w</code></td>
<td>
<p>A <code>numeric</code> scalar in (0,1) indicating the level of shrinkage (large shrinkage if w is small) on the interval between the (k-1)th and (k+1)th preliminary changepoint estimator.</p>
</td></tr>
<tr><td><code id="local.refine.network_+3A_tau2">tau2</code></td>
<td>
<p>A positive <code>numeric</code> scalar for USVT corresponding to the threshold for singular values of input matrix.</p>
</td></tr>
<tr><td><code id="local.refine.network_+3A_tau3">tau3</code></td>
<td>
<p>A positive <code>numeric</code> scalar for USVT corresponding to the threshold for entries of output matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>numeric</code> vector of locally refined change point locations.
</p>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2018) &lt;arxiv:1809.09602&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 15 # number of nodes
rho = 0.5 # sparsity parameter
block_num = 3 # number of groups for SBM
n = 100 # sample size for each segment
# connectivity matrix for the first and the third segments
conn1_mat = rho * matrix(c(0.6,1,0.6,1,0.6,0.5,0.6,0.5,0.6), nrow = 3) 
# connectivity matrix for the second segment
conn2_mat = rho * matrix(c(0.6,0.5,0.6,0.5,0.6,1,0.6,1,0.6), nrow = 3) 
set.seed(1)
can_vec = sample(1:p, replace = FALSE) # randomly assign nodes into groups
sbm1 = simu.SBM(conn1_mat, can_vec, n, symm = TRUE, self = TRUE)
sbm2 = simu.SBM(conn2_mat, can_vec, n, symm = TRUE, self = TRUE)
data_mat = cbind(sbm1$obs_mat, sbm2$obs_mat)
data_mat1 = data_mat[,seq(1,ncol(data_mat),2)]
data_mat2 = data_mat[,seq(2,ncol(data_mat),2)]
M = 10
intervals = WBS.intervals(M = M, lower = 1, upper = ncol(data_mat1))
temp = WBS.network(data_mat1, data_mat2, 1, ncol(data_mat1), intervals$Alpha, 
                   intervals$Beta, delta = 5)
rho_hat = quantile(rowMeans(data_mat), 0.95)
tau = p*rho_hat*(log(n))^2/20 # default threshold given in the paper
cpt_init = unlist(thresholdBS(temp, tau)$cpt_hat[,1])
cpt_refined = local.refine.network(cpt_init, data_mat1, data_mat2, self = TRUE, 
                                   tau2 = p*rho_hat/3, tau3 = Inf)
cpt_WBS = 2*cpt_init
cpt_refined = 2*cpt_refined
</code></pre>

<hr>
<h2 id='local.refine.poly'>Local refinement for univariate polynomials change point detection.</h2><span id='topic+local.refine.poly'></span>

<h3>Description</h3>

<p>Perform local refinement for univariate polynomials change point detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local.refine.poly(cpt_init, y, r, delta_lr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local.refine.poly_+3A_cpt_init">cpt_init</code></td>
<td>
<p>An <code>integer</code> vector of initial change points estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="local.refine.poly_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of univariate time series.</p>
</td></tr>
<tr><td><code id="local.refine.poly_+3A_r">r</code></td>
<td>
<p>An <code>integer</code> scalar order of polynomials.</p>
</td></tr>
<tr><td><code id="local.refine.poly_+3A_delta_lr">delta_lr</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing for local refinement.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>integer</code> vector of locally refined change point estimation.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Yu and Chatterjee (2020) &lt;arXiv:2007.09910&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(2,30),rep(0,120),rep(2,130))
plot.ts(y)
gamma_set = 3:9
DP_result = CV.search.DP.poly(y, r = 2, gamma_set, delta = 5)
min_idx = which.min(DP_result$test_error)
cpt_init = unlist(DP_result$cpt_hat[min_idx])
local.refine.poly(cpt_init, y, r = 2, delta_lr = 5)
</code></pre>

<hr>
<h2 id='local.refine.regression'>Local refinement for regression change points localisation.</h2><span id='topic+local.refine.regression'></span>

<h3>Description</h3>

<p>Perform local refinement for regression change points localisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local.refine.regression(cpt_init, y, X, zeta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local.refine.regression_+3A_cpt_init">cpt_init</code></td>
<td>
<p>An <code>integer</code> vector of initial changepoints estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="local.refine.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="local.refine.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time..</p>
</td></tr>
<tr><td><code id="local.refine.regression_+3A_zeta">zeta</code></td>
<td>
<p>A <code>numeric</code> scalar of tuning parameter for the group lasso.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of locally refined change points estimation.
</p>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Rinaldo, A., Wang, D., Wen, Q., Willett, R., &amp; Yu, Y. (2021, March). Localizing changes in high-dimensional regression models. In International Conference on Artificial Intelligence and Statistics (pp. 2089-2097). PMLR.
</p>
<p>Rinaldo, Wang, Wen, Willett and Yu (2020) &lt;arxiv:2010.10410&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 10
p = 20
n = 100
cpt_true = c(30, 70)
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
gamma_set = c(0.01, 0.1, 1)
lambda_set = c(0.01, 0.1, 1, 3)
temp = CV.search.DP.regression(y = data$y, X = data$X, gamma_set, lambda_set, delta = 2)
temp$test_error # test error result
# find the indices of gamma_set and lambda_set which minimizes the test error
min_idx = as.vector(arrayInd(which.min(temp$test_error), dim(temp$test_error)))
gamma_set[min_idx[1]]
lambda_set[min_idx[2]]
cpt_init = unlist(temp$cpt_hat[min_idx[1], min_idx[2]])
local.refine.regression(cpt_init, data$y, X = data$X, zeta = 0.5)
</code></pre>

<hr>
<h2 id='local.refine.univar'>Local refinement of an initial estimator for univariate mean change points detection.</h2><span id='topic+local.refine.univar'></span>

<h3>Description</h3>

<p>Perform local refinement for univariate mean change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local.refine.univar(cpt_init, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local.refine.univar_+3A_cpt_init">cpt_init</code></td>
<td>
<p>An <code>integer</code> vector of initial change points estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="local.refine.univar_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of univariate time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>integer</code> vector of locally refined change point estimation.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2020) &lt;doi:10.1214/20-EJS1710&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(2,30),rep(0,120),rep(2,130))
gamma_set = 1:5
DP_result = CV.search.DP.univar(y, gamma_set, delta = 5)
min_idx = which.min(DP_result$test_error)
cpt_hat = unlist(DP_result$cpt_hat[min_idx])
Hausdorff.dist(cpt_hat, cpt_true)
cpt_LR = local.refine.univar(cpt_hat, y)
Hausdorff.dist(cpt_LR, cpt_true)
</code></pre>

<hr>
<h2 id='local.refine.VAR1'>Local refinement for VAR1 change points detection.</h2><span id='topic+local.refine.VAR1'></span>

<h3>Description</h3>

<p>Perform local refinement for VAR1 change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local.refine.VAR1(cpt_init, DATA, zeta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local.refine.VAR1_+3A_cpt_init">cpt_init</code></td>
<td>
<p>A <code>integer</code> vector of initial change points estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="local.refine.VAR1_+3A_data">DATA</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and vertical axis being dimensions.</p>
</td></tr>
<tr><td><code id="local.refine.VAR1_+3A_zeta">zeta</code></td>
<td>
<p>A <code>numeric</code> scalar of lasso penalty.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>integer</code> vector of locally refined change points estimation.
</p>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu, Rinaldo and Willett (2019) &lt;arxiv:1909.06359&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+local.refine.CV.VAR1">local.refine.CV.VAR1</a></code>.
</p>

<hr>
<h2 id='lowertri2mat'>Transform a vector containing lower diagonal entries into a symmetric matrix of dimension p.</h2><span id='topic+lowertri2mat'></span>

<h3>Description</h3>

<p>Transform a vector containing lower diagonal entries into a symmetric matrix of dimension p.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lowertri2mat(lowertri_vec, p, diag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lowertri2mat_+3A_lowertri_vec">lowertri_vec</code></td>
<td>
<p>A <code>numeric</code> vector containing lower diagonal entries.</p>
</td></tr>
<tr><td><code id="lowertri2mat_+3A_p">p</code></td>
<td>
<p>A <code>integer</code> scalar of dimensionality.</p>
</td></tr>
<tr><td><code id="lowertri2mat_+3A_diag">diag</code></td>
<td>
<p>A <code>logic</code> scalar indicating if the diagonal entries are contained in lowertri_vec.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>numeric</code> p x p symmetric matrix.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A = matrix(1:16, 4, 4)
B = lowertri2mat(A[lower.tri(A)], 4, diag = FALSE)
C = lowertri2mat(A[lower.tri(A, diag = TRUE)], 4, diag = TRUE)
</code></pre>

<hr>
<h2 id='LRV.regression'>Long-run variance estimation for regression settings with change points.</h2><span id='topic+LRV.regression'></span>

<h3>Description</h3>

<p>Estimating long-run variance for regression settings with change points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRV.regression(cpt_init, beta_hat, y, X, w = 0.9, block_size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRV.regression_+3A_cpt_init">cpt_init</code></td>
<td>
<p>An <code>integer</code> vector of initial changepoints estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="LRV.regression_+3A_beta_hat">beta_hat</code></td>
<td>
<p>A <code>numeric</code> (px(K_hat+1))matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code id="LRV.regression_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of response variable.</p>
</td></tr>
<tr><td><code id="LRV.regression_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> matrix of covariates with vertical axis being time.</p>
</td></tr>
<tr><td><code id="LRV.regression_+3A_w">w</code></td>
<td>
<p>A <code>numeric</code> scalar in (0,1) representing the weight for interval truncation.</p>
</td></tr>
<tr><td><code id="LRV.regression_+3A_block_size">block_size</code></td>
<td>
<p>An <code>integer</code> scalar corresponding to the block size S in the paper.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of long-run variance estimators associated with all local refined intervals.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>
<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 5
p = 10
n = 200
cpt_true = c(70, 140)
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
lambda_set = c(0.1, 0.5, 1, 2)
zeta_set = c(10, 15, 20)
temp = CV.search.DPDU.regression(y = data$y, X = data$X, lambda_set, zeta_set)
temp$test_error # test error result
# find the indices of lambda_set and zeta_set which minimizes the test error
min_idx = as.vector(arrayInd(which.min(temp$test_error), dim(temp$test_error))) 
lambda_set[min_idx[2]]
zeta_set[min_idx[1]]
cpt_init = unlist(temp$cpt_hat[min_idx[1], min_idx[2]])
beta_hat = matrix(unlist(temp$beta_hat[min_idx[1], min_idx[2]]), ncol = length(cpt_init)+1)
interval_refine = trim_interval(n, cpt_init)
# choose S
block_size = ceiling(sqrt(min(floor(interval_refine[,2]) - ceiling(interval_refine[,1])))/2)
LRV_est = LRV.regression(cpt_init, beta_hat, data$y, data$X, w = 0.9, block_size)
</code></pre>

<hr>
<h2 id='online.network'>Online change point detection for network data.</h2><span id='topic+online.network'></span>

<h3>Description</h3>

<p>Perform online change point detection for network data by controlling the false alarm rate at level alpha or controlling the average run length gamma. The default choice of the tuning parameters tau1, tau2 and tau3 are used (see Section 4.1 of the reference).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>online.network(
  data_mat1,
  data_mat2,
  self = TRUE,
  b_vec = NULL,
  train_mat = NULL,
  alpha = NULL,
  gamma = NULL,
  permu_num = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="online.network_+3A_data_mat1">data_mat1</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and with each column be the vectorized adjacency matrix.</p>
</td></tr>
<tr><td><code id="online.network_+3A_data_mat2">data_mat2</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and with each column be the vectorized adjacency matrix (data_mat1 and data_mat2 are independent and have the same dimensions ).</p>
</td></tr>
<tr><td><code id="online.network_+3A_self">self</code></td>
<td>
<p>A <code>logic</code> scalar indicating if adjacency matrices are required to have self-loop.</p>
</td></tr>
<tr><td><code id="online.network_+3A_b_vec">b_vec</code></td>
<td>
<p>A <code>numeric</code> vector of thresholds b_t with t &gt;= 2.</p>
</td></tr>
<tr><td><code id="online.network_+3A_train_mat">train_mat</code></td>
<td>
<p>A <code>numeric</code> matrix of training data from a pre-change distribution(no change point), which is only needed to when b_vec is NULL in order to calibrate b_t.</p>
</td></tr>
<tr><td><code id="online.network_+3A_alpha">alpha</code></td>
<td>
<p>A <code>numeric</code> scalar in (0,1) representing the level.</p>
</td></tr>
<tr><td><code id="online.network_+3A_gamma">gamma</code></td>
<td>
<p>An <code>integer</code> scalar of desired average run length.</p>
</td></tr>
<tr><td><code id="online.network_+3A_permu_num">permu_num</code></td>
<td>
<p>An <code>integer</code> scalar of number of random permutation for calibration.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt</code></td>
<td>
<p>Estimated change point</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>A <code>numeric</code> vector of computed cumsum statistics</p>
</td></tr>
<tr><td><code>b_vec</code></td>
<td>
<p>A <code>numeric</code> vector of thresholds b_t with t &gt;= 2</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Yu, Padilla, Wang and Rinaldo (2021) &lt;arxiv:2101.05477&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
p = 15 # number of nodes
rho = 0.5 # sparsity parameter
block_num = 3 # number of groups for SBM
n = 100 # sample size for each segment
# connectivity matrix for the first and the third segments
conn1_mat = rho * matrix(c(0.6,1,0.6,1,0.6,0.5,0.6,0.5,0.6), nrow = 3) 
# connectivity matrix for the second segment
conn2_mat = rho * matrix(c(0.6,0.5,0.6,0.5,0.6,1,0.6,1,0.6), nrow = 3) 
set.seed(1)
can_vec = sample(1:p, replace = FALSE) # randomly assign nodes into groups
sbm1 = simu.SBM(conn1_mat, can_vec, n, symm = TRUE, self = TRUE)
sbm2 = simu.SBM(conn2_mat, can_vec, n, symm = TRUE, self = TRUE)
data_mat = cbind(sbm1$obs_mat, sbm2$obs_mat)
data_mat1 = data_mat[,seq(1,ncol(data_mat),2)]
data_mat2 = data_mat[,seq(2,ncol(data_mat),2)]
train_mat = simu.SBM(conn1_mat, can_vec, n = 150, symm = TRUE, self = TRUE)$obs_mat
temp = online.network(data_mat1, data_mat2, self = TRUE, b_vec = NULL, train_mat, alpha = 0.05, 
                      gamma = NULL, permu_num = 20)
cpt_hat = 2 * temp$cpt
</code></pre>

<hr>
<h2 id='online.network.missing'>Online change point detection for network data with missing values.</h2><span id='topic+online.network.missing'></span>

<h3>Description</h3>

<p>Perform online change point detection for network with missing values by controlling the false alarm rate at level alpha.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>online.network.missing(
  data_incomplete_list,
  eta_list,
  alpha_grid,
  thresholds_array,
  rho_hat,
  pi_ub_hat,
  C_lambda = 2/3,
  delta = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="online.network.missing_+3A_data_incomplete_list">data_incomplete_list</code></td>
<td>
<p>A <code>list</code> of adjacency matrices (with entries being 0 or 1) with missing values being coercing to 0.</p>
</td></tr>
<tr><td><code id="online.network.missing_+3A_eta_list">eta_list</code></td>
<td>
<p>A <code>list</code> of matrices associated with data_incomplete_list, each matrix indicates the missing entries in corresponding adjacency matrix.</p>
</td></tr>
<tr><td><code id="online.network.missing_+3A_alpha_grid">alpha_grid</code></td>
<td>
<p>A <code>numeric</code> vector in (0,1) representing the desired false alarm rate.</p>
</td></tr>
<tr><td><code id="online.network.missing_+3A_thresholds_array">thresholds_array</code></td>
<td>
<p>A <code>numeric</code> array of calibrated thresholds.</p>
</td></tr>
<tr><td><code id="online.network.missing_+3A_rho_hat">rho_hat</code></td>
<td>
<p>A <code>numeric</code> scalar of the sparsity parameter.</p>
</td></tr>
<tr><td><code id="online.network.missing_+3A_pi_ub_hat">pi_ub_hat</code></td>
<td>
<p>A <code>numeric</code> scalar of the upper bound of the missing probability.</p>
</td></tr>
<tr><td><code id="online.network.missing_+3A_c_lambda">C_lambda</code></td>
<td>
<p>A <code>numeric</code> scalar of an absolute constant, which is set to be 2/3 by default.</p>
</td></tr>
<tr><td><code id="online.network.missing_+3A_delta">delta</code></td>
<td>
<p>An <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Online change point estimator.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Dubey, Xu and Yu (2021) &lt;arxiv:2110.06450&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calibrate.online.network.missing">calibrate.online.network.missing</a></code> for calibrating thresholds.
</p>

<hr>
<h2 id='online.univar'>Online change point detection with controlled false alarm rate or average run length.</h2><span id='topic+online.univar'></span>

<h3>Description</h3>

<p>Perform online change point detection with controlled false alarm rate or average run length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>online.univar(
  y_vec,
  b_vec = NULL,
  train_vec = NULL,
  alpha = NULL,
  gamma = NULL,
  permu_num = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="online.univar_+3A_y_vec">y_vec</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="online.univar_+3A_b_vec">b_vec</code></td>
<td>
<p>A <code>numeric</code> vector of thresholds b_t with t &gt;= 2.</p>
</td></tr>
<tr><td><code id="online.univar_+3A_train_vec">train_vec</code></td>
<td>
<p>A <code>numeric</code> vector of training data from a pre-change distribution (no change point), which is only needed to when b_vec is NULL in order to calibrate b_t.</p>
</td></tr>
<tr><td><code id="online.univar_+3A_alpha">alpha</code></td>
<td>
<p>A <code>numeric</code> scalar of desired false alarm rate.</p>
</td></tr>
<tr><td><code id="online.univar_+3A_gamma">gamma</code></td>
<td>
<p>An <code>integer</code> scalar of desired average run length.</p>
</td></tr>
<tr><td><code id="online.univar_+3A_permu_num">permu_num</code></td>
<td>
<p>An <code>integer</code> scalar of number of random permutation for calibration.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_hat</code></td>
<td>
<p>An <code>integer</code> scalar of estimated change point location</p>
</td></tr>
<tr><td><code>b_vec</code></td>
<td>
<p>A <code>numeric</code> vector of thresholds b_t with t &gt;= 2</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Yu, Padilla, Wang and Rinaldo (2020) &lt;arxiv:2006.03283&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y_vec = rnorm(150) + c(rep(0, 100), rep(1, 50))
train_vec = rnorm(100)
# control the false alarm rate
temp1 = online.univar(y_vec = y_vec, train_vec = train_vec, alpha = 0.05, permu_num = 20)
temp1$cpt_hat
temp1$b_vec # calibrated threshold
</code></pre>

<hr>
<h2 id='online.univar.multi'>Online change point detection with potentially multiple change points.</h2><span id='topic+online.univar.multi'></span>

<h3>Description</h3>

<p>Perform Online change point detection with potentially multiple change points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>online.univar.multi(
  y_vec,
  b_vec = NULL,
  train_vec = NULL,
  alpha = NULL,
  gamma = NULL,
  permu_num = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="online.univar.multi_+3A_y_vec">y_vec</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="online.univar.multi_+3A_b_vec">b_vec</code></td>
<td>
<p>A <code>numeric</code> vector of thresholds b_t with t &gt;= 2.</p>
</td></tr>
<tr><td><code id="online.univar.multi_+3A_train_vec">train_vec</code></td>
<td>
<p>A <code>numeric</code> vector of training data from a pre-change distribution (no change point), which is only needed to when b_vec is NULL in order to calibrate b_t.</p>
</td></tr>
<tr><td><code id="online.univar.multi_+3A_alpha">alpha</code></td>
<td>
<p>A <code>numeric</code> scalar of desired false alarm rate.</p>
</td></tr>
<tr><td><code id="online.univar.multi_+3A_gamma">gamma</code></td>
<td>
<p>An <code>integer</code> scalar of desired average run length.</p>
</td></tr>
<tr><td><code id="online.univar.multi_+3A_permu_num">permu_num</code></td>
<td>
<p>An <code>integer</code> scalar of number of random permutation for calibration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>#' @title Online change point detection with controlled average run length.
#' @description  Perform online change point detection via CUSUM (single change point, type 2).
#' @param y_vec       A <code>numeric</code> vector of observations.
#' @param gamma       A <code>integer</code> scalar of interval length (&gt;= 2).
#' @param tau_gamma   A <code>numeric</code> scalar of threshold.
#' @param ...         Additional arguments.
#' @return  An <code>integer</code> scalar of estimated change points location.
#' @export
#' @author Haotian Xu
#' @examples
#' TO DO
online.univar.one2 = function(y_vec, gamma, tau_gamma, ...)
t = 1
FLAG = 0
while(FLAG == 0 &amp; t &lt;= length(y_vec))
t = t + 1
e = max(t-gamma, 0)
cusum_vec = sapply((e+1):(t-1), function(s) sqrt((t-s)*(s-e)/(t-e)) * abs(mean(y_vec[(e+1):s]) - mean(y_vec[(s+1):t])))
FLAG = 1 - prod(cusum_vec &lt;= tau_gamma)

return(t)

</p>
<p>#' @title Online change point detection via CUSUM (single change point, type 3).
#' @description Perform online change point detection via CUSUM (single change point, type 3).
#' @param y_vec       A <code>numeric</code> vector of observations.
#' @param tau_vec     A <code>numeric</code> vector of thresholds at time t&gt;= 1.
#' @param ...         Additional arguments.
#' @return  An <code>integer</code> scalar of estimated change point location.
#' @export
#' @author Haotian Xu
#' @examples
#' TO DO
online.univar.one3 = function(y_vec, tau_vec, ...)
if(length(y_vec) != length(tau_vec))
stop(&quot;y_vec and tau_vec should have the same length.&quot;)

t = 1
FLAG = 0
while(FLAG == 0 &amp; t &lt;= length(y_vec))
t = t + 1
J = floor(log2(t))
j = 0
while(j &lt; J &amp; FLAG == 0)
j = j + 1
s_j = t - 2^(j-1)
cusum = sqrt((t-s_j)*s_j/t) * abs(mean(y_vec[1:s_j]) - mean(y_vec[(s_j+1):t]))
FLAG = (cusum &gt; tau_vec[t])


return(t)

</p>


<h3>Value</h3>

<p>An <code>integer</code> vector of estimated change points.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Yu, Padilla, Wang and Rinaldo (2020) &lt;arxiv:2006.03283&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y_vec = rnorm(200) + c(rep(0, 50), rep(1, 100), rep(0, 50))
train_vec = rnorm(150)
# control the false alarm rate
temp1 = online.univar.multi(y_vec = y_vec, train_vec = train_vec, alpha = 0.05, permu_num = 20)
temp1
</code></pre>

<hr>
<h2 id='simu.change.regression'>Simulate a sparse regression model with change points in coefficients.</h2><span id='topic+simu.change.regression'></span>

<h3>Description</h3>

<p>Simulate a sparse regression model with change points in coefficients under temporal dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simu.change.regression(
  d0,
  cpt_true,
  p,
  n,
  sigma,
  kappa,
  cov_type = "I",
  mod_X = "IID",
  mod_e = "IID"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simu.change.regression_+3A_d0">d0</code></td>
<td>
<p>A <code>numeric</code> scalar stands for the number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="simu.change.regression_+3A_cpt_true">cpt_true</code></td>
<td>
<p>An <code>integer</code> vector contains true change points (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="simu.change.regression_+3A_p">p</code></td>
<td>
<p>An <code>integer</code> scalar stands for the dimensionality.</p>
</td></tr>
<tr><td><code id="simu.change.regression_+3A_n">n</code></td>
<td>
<p>An <code>integer</code> scalar stands for the sample size.</p>
</td></tr>
<tr><td><code id="simu.change.regression_+3A_sigma">sigma</code></td>
<td>
<p>A <code>numeric</code> scalar stands for error standard deviation.</p>
</td></tr>
<tr><td><code id="simu.change.regression_+3A_kappa">kappa</code></td>
<td>
<p>A <code>numeric</code> scalar stands for the minimum jump size of coefficient vector in <code class="reqn">l_2</code> norm.</p>
</td></tr>
<tr><td><code id="simu.change.regression_+3A_cov_type">cov_type</code></td>
<td>
<p>A <code>character</code> string stands for the type of covariance matrix of covariates. 'I': Identity; 'T': Toeplitz; 'E': Equal-correlation.</p>
</td></tr>
<tr><td><code id="simu.change.regression_+3A_mod_x">mod_X</code></td>
<td>
<p>A <code>character</code> string stands for the time series model followed by the covariates. 'IID': IID multivariate Gaussian; 'AR': Multivariate AR1 with rho = 0.3; Multivariate MA1 theta = 0.3.</p>
</td></tr>
<tr><td><code id="simu.change.regression_+3A_mod_e">mod_e</code></td>
<td>
<p>A <code>character</code> string stands for the time series model followed by the errors 'IID': IID univariate Gaussian; 'AR': Univariate AR1 with rho = 0.3; Univariate MA1 theta = 0.3.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt_true</code></td>
<td>
<p>A vector of true changepoints (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>An n-by-p design matrix.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>An n-dim vector of response variable.</p>
</td></tr>
<tr><td><code>betafullmat</code></td>
<td>
<p>A p-by-n matrix of coefficients.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang, Zifeng Zhao &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Rinaldo, Wang, Wen, Willett and Yu (2020) &lt;arxiv:2010.10410&gt;; Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d0 = 10
p = 30
n = 100
cpt_true = c(10, 30, 40, 70, 90)
data = simu.change.regression(d0, cpt_true, p, n, sigma = 1, kappa = 9)
</code></pre>

<hr>
<h2 id='simu.RDPG'>Simulate a dot product graph (without change point).</h2><span id='topic+simu.RDPG'></span>

<h3>Description</h3>

<p>Simulate a dot product graph (without change point). The generated data is a matrix with each column corresponding to the vectorized adjacency (sub)matrix at a time point. For example, if the network matrix is required to be symmetric and without self-loop, only the strictly lower diagonal entries are considered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simu.RDPG(x_mat, n, symm = TRUE, self = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simu.RDPG_+3A_x_mat">x_mat</code></td>
<td>
<p>A <code>numeric</code> matrix representing the latent positions with horizontal axis being latent dimensions and vertical axis being nodes (each entry takes value in <code class="reqn">[0,1]</code>).</p>
</td></tr>
<tr><td><code id="simu.RDPG_+3A_n">n</code></td>
<td>
<p>A <code>integer</code> scalar representing the number of observations.</p>
</td></tr>
<tr><td><code id="simu.RDPG_+3A_symm">symm</code></td>
<td>
<p>A <code>logic</code> scalar indicating if adjacency matrices are required to be symmetric.</p>
</td></tr>
<tr><td><code id="simu.RDPG_+3A_self">self</code></td>
<td>
<p>A <code>logic</code> scalar indicating if adjacency matrices are required to have self-loop.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>obs_mat</code></td>
<td>
<p>A matrix, with each column be the vectorized adjacency (sub)matrix. For example, if &quot;symm = TRUE&quot; and &quot;self = FALSE&quot;, only the strictly lower triangular matrix is considered.</p>
</td></tr>
<tr><td><code>graphon_mat</code></td>
<td>
<p>Underlying graphon matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 20 # number of nodes
n = 50 # sample size for each segment
lat_dim_num = 5 # number of latent dimensions
set.seed(1)
x_mat = matrix(runif(p*lat_dim_num), nrow = p, ncol = lat_dim_num)
x_tilde_mat = matrix(runif(p*lat_dim_num), nrow = p, ncol = lat_dim_num)
y_mat = rbind(x_tilde_mat[1:floor(p/4),], x_mat[(floor(p/4)+1):p,])
rdpg1 = simu.RDPG(x_mat, n, symm = TRUE, self = FALSE)
rdpg2 = simu.RDPG(y_mat, n, symm = TRUE, self = FALSE)
data1_mat = rdpg1$obs_mat
data2_mat = rdpg2$obs_mat
data_mat = cbind(data1_mat, data2_mat)
</code></pre>

<hr>
<h2 id='simu.SBM'>Simulate a Stochastic Block Model (without change point).</h2><span id='topic+simu.SBM'></span>

<h3>Description</h3>

<p>Simulate a Stochastic Block Model (without change point). The generated data is a matrix with each column corresponding to the vectorized adjacency (sub)matrix at a time point. For example, if the network matrix is required to be symmetric and without self-loop, only the strictly lower diagonal entries are considered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simu.SBM(connec_mat, can_vec, n, symm = FALSE, self = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simu.SBM_+3A_connec_mat">connec_mat</code></td>
<td>
<p>A <code>numeric</code> symmetric matrix representing the connectivity matrix (each entry takes value in <code class="reqn">[0,1]</code>).</p>
</td></tr>
<tr><td><code id="simu.SBM_+3A_can_vec">can_vec</code></td>
<td>
<p>A <code>integer</code> p-dim vector of node indices. can_vec is then divided into subvectors corresponding to blocks.</p>
</td></tr>
<tr><td><code id="simu.SBM_+3A_n">n</code></td>
<td>
<p>A <code>integer</code> scalar representing the number of observations.</p>
</td></tr>
<tr><td><code id="simu.SBM_+3A_symm">symm</code></td>
<td>
<p>A <code>logic</code> scalar indicating if adjacency matrices are required to be symmetric.</p>
</td></tr>
<tr><td><code id="simu.SBM_+3A_self">self</code></td>
<td>
<p>A <code>logic</code> scalar indicating if adjacency matrices are required to have self-loop.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>obs_mat</code></td>
<td>
<p>A matrix, with each column be the vectorized adjacency (sub)matrix. For example, if &quot;symm = TRUE&quot; and &quot;self = FALSE&quot;, only the strictly lower triangular matrix is considered.</p>
</td></tr>
<tr><td><code>graphon_mat</code></td>
<td>
<p>Underlying graphon matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2018) &lt;arxiv:1809.09602&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 15 # number of nodes
rho = 0.5 # sparsity parameter
block_num = 3 # number of groups for SBM
n = 100 # sample size for each segment
# connectivity matrix for the first and the third segments
conn1_mat = rho * matrix(c(0.6,1,0.6,1,0.6,0.5,0.6,0.5,0.6), nrow = 3) 
# connectivity matrix for the second segment
conn2_mat = rho * matrix(c(0.6,0.5,0.6,0.5,0.6,1,0.6,1,0.6), nrow = 3) 
set.seed(1)
can_vec = sample(1:p, replace = FALSE) # randomly assign nodes into groups
sbm1 = simu.SBM(conn1_mat, can_vec, n, symm = TRUE, self = TRUE)
sbm2 = simu.SBM(conn2_mat, can_vec, n, symm = TRUE, self = TRUE)
data_mat = cbind(sbm1$obs_mat, sbm2$obs_mat)
</code></pre>

<hr>
<h2 id='simu.SEPP'>Simulate a (stable) SEPP model (without change point).</h2><span id='topic+simu.SEPP'></span>

<h3>Description</h3>

<p>Simulate a (stable) SEPP model (without change point).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simu.SEPP(intercept, n, A, threshold, vzero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simu.SEPP_+3A_intercept">intercept</code></td>
<td>
<p>A <code>numeric</code> scalar representing the intercept of the model.</p>
</td></tr>
<tr><td><code id="simu.SEPP_+3A_n">n</code></td>
<td>
<p>An <code>integer</code> scalar representing sample size.</p>
</td></tr>
<tr><td><code id="simu.SEPP_+3A_a">A</code></td>
<td>
<p>A <code>numeric</code> pXp matrix representing the coefficient matrix.</p>
</td></tr>
<tr><td><code id="simu.SEPP_+3A_threshold">threshold</code></td>
<td>
<p>A <code>numeric</code> scalar representing the upper bound for each coordinate of X_t (for stability).</p>
</td></tr>
<tr><td><code id="simu.SEPP_+3A_vzero">vzero</code></td>
<td>
<p>A <code>numeric</code> vector representing the observation at time 0. If <code>vzero = NULL</code>, each coordinate is generated from a Poisson distribution with mean <code>lambda</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A p-by-n matrix.
</p>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu, &amp; Willett (2020). Detecting Abrupt Changes in High-Dimensional Self-Exciting Poisson Processes. &lt;arXiv:2006.03572&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 10 # dimension
n = 50
s = 5 # sparsity
factor = 0.12 # large factor gives exact recovery
threshold = 4 # thresholding makes the process stable
intercept = 1/2 # intercept of the model. Assume to be known as in the existing literature
A1 = A2 = A3 = matrix(0, p, p)
diag(A1[,-1]) = 1
diag(A1) = 1
diag(A1[-1,]) = -1
A1 = A1*factor
A1[(s+1):p, (s+1):p] = 0
diag(A2[,-1]) = 1
diag(A2) = -1
diag(A2[-1,]) = 1
A2 = A2*factor
A2[(s+1):p, (s+1):p] = 0
diag(A3[,-1]) = 1
diag(A3) = 1
diag(A3[-1,]) = -1
A3 = A3*factor
A3[(s+1):p, (s+1):p] = 0
data1 = simu.SEPP(intercept, n, A1, threshold, vzero = NULL)
data2 = simu.SEPP(intercept, n, A2, threshold, vzero = data1[,n])
data3 = simu.SEPP(intercept, n, A3, threshold, vzero = data2[,n])
data = cbind(data1, data2, data3)
dim(data)
</code></pre>

<hr>
<h2 id='simu.VAR1'>Simulate from a VAR1 model (without change point).</h2><span id='topic+simu.VAR1'></span>

<h3>Description</h3>

<p>Simulate data of size n and dimension p from a VAR1 model (without change point) with Gaussian i.i.d. error terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simu.VAR1(sigma, p, n, A, vzero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simu.VAR1_+3A_sigma">sigma</code></td>
<td>
<p>A <code>numeric</code> scalar representing the standard deviation of error terms.</p>
</td></tr>
<tr><td><code id="simu.VAR1_+3A_p">p</code></td>
<td>
<p>An <code>integer</code> scalar representing dimension.</p>
</td></tr>
<tr><td><code id="simu.VAR1_+3A_n">n</code></td>
<td>
<p>An <code>integer</code> scalar representing sample size.</p>
</td></tr>
<tr><td><code id="simu.VAR1_+3A_a">A</code></td>
<td>
<p>A <code>numeric</code> p-by-p matrix representing the transition matrix of the VAR1 model.</p>
</td></tr>
<tr><td><code id="simu.VAR1_+3A_vzero">vzero</code></td>
<td>
<p>A <code>numeric</code> vector representing the observation at time 0. If <code>vzero = NULL</code>,it is generated following the distribution of the error terms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A p-by-n matrix.
</p>


<h3>Author(s)</h3>

<p>Daren Wang
</p>


<h3>References</h3>

<p>Wang, Yu, Rinaldo and Willett (2019) &lt;arxiv:1909.06359&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 10
sigma = 1
n = 100
A = matrix(rnorm(p*p), nrow = p)*0.1  # transition matrix
simu.VAR1(sigma, p, n, A)
</code></pre>

<hr>
<h2 id='softImpute.network.missing'>Estimate graphon matrix by soft-impute for independent adjacency matrices with missing values.</h2><span id='topic+softImpute.network.missing'></span>

<h3>Description</h3>

<p>Estimate graphon matrix by soft-impute for independent adjacency matrices with missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softImpute.network.missing(
  data_incomplete_list,
  eta_list,
  lambda,
  a,
  it_max = 10000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="softImpute.network.missing_+3A_data_incomplete_list">data_incomplete_list</code></td>
<td>
<p>A <code>list</code> of adjacency matrices (with entries being 0 or 1) with missing values being coercing to 0.</p>
</td></tr>
<tr><td><code id="softImpute.network.missing_+3A_eta_list">eta_list</code></td>
<td>
<p>A <code>list</code> of matrices associated with data_incomplete_list, each matrix indicates the missing entries in corresponding adjacency matrix.</p>
</td></tr>
<tr><td><code id="softImpute.network.missing_+3A_lambda">lambda</code></td>
<td>
<p>A <code>numeric</code> scalar of thresholding parameter for leading singular value in the soft-impute algorithm.</p>
</td></tr>
<tr><td><code id="softImpute.network.missing_+3A_a">a</code></td>
<td>
<p>A <code>numeric</code> scalar of truncation parameter in the soft-impute algorithm.</p>
</td></tr>
<tr><td><code id="softImpute.network.missing_+3A_it_max">it_max</code></td>
<td>
<p>An <code>integer</code> scalar of maximum iteration for the soft-impute algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimated graphon matrix
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Dubey, Xu and Yu (2021) &lt;arxiv:2110.06450&gt;
</p>

<hr>
<h2 id='thresholdBS'>Thresholding a BS object with threshold value tau.</h2><span id='topic+thresholdBS'></span>

<h3>Description</h3>

<p>Given a BS object, perform thresholding to find the change point locations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thresholdBS(BS_object, tau)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thresholdBS_+3A_bs_object">BS_object</code></td>
<td>
<p>A <code>BS</code> object.</p>
</td></tr>
<tr><td><code id="thresholdBS_+3A_tau">tau</code></td>
<td>
<p>A positive <code>numeric</code> scalar of thresholding value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>BS_tree_trimmed</code></td>
<td>
<p>BS_tree with change points which do not satisfy the thresholding criteria removed</p>
</td></tr>
<tr><td><code>cpt_hat</code></td>
<td>
<p>A matrix contains change point locations, values of corresponding statistic, and levels at which each change point is detected</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BS.univar">BS.univar</a></code>, <code><a href="#topic+BS.uni.nonpar">BS.uni.nonpar</a></code>, <code><a href="#topic+BS.cov">BS.cov</a></code>, <code><a href="#topic+WBS.univar">WBS.univar</a></code>, <code><a href="#topic+WBS.uni.nonpar">WBS.uni.nonpar</a></code>, <code><a href="#topic+WBS.multi.nonpar">WBS.multi.nonpar</a></code>, <code><a href="#topic+WBS.network">WBS.network</a></code>, <code><a href="#topic+WBSIP.cov">WBSIP.cov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y = c(rnorm(100, 0, 1), rnorm(100, 10, 10), rnorm(100, 40, 10))
temp = BS.univar(y, 1, 300, 5)
plot.ts(y)
points(x = tail(temp$S[order(temp$Dval)],4), y = y[tail(temp$S[order(temp$Dval)],4)], col = "red")
thresholdBS(temp, 20)
</code></pre>

<hr>
<h2 id='trim_interval'>Interval trimming based on initial change point localisation.</h2><span id='topic+trim_interval'></span>

<h3>Description</h3>

<p>Performing the interval trimming for local refinement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim_interval(n, cpt_init, w = 0.9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trim_interval_+3A_n">n</code></td>
<td>
<p>An <code>integer</code> scalar corresponding to the sample size.</p>
</td></tr>
<tr><td><code id="trim_interval_+3A_cpt_init">cpt_init</code></td>
<td>
<p>An <code>integer</code> vector of initial changepoints estimation (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code id="trim_interval_+3A_w">w</code></td>
<td>
<p>A <code>numeric</code> scalar in (0,1) representing the weight for interval truncation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with each row be a trimmed interval.
</p>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Xu, Wang, Zhao and Yu (2022) &lt;arXiv:2207.12453&gt;.
</p>

<hr>
<h2 id='tuneBSmultinonpar'>A function to compute change points based on the multivariate nonparametic method with tuning parameter selected by FDR control.</h2><span id='topic+tuneBSmultinonpar'></span>

<h3>Description</h3>

<p>A function to compute change points based on the multivariate nonparametic method with tuning parameter selected by FDR control.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneBSmultinonpar(BS_object, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneBSmultinonpar_+3A_bs_object">BS_object</code></td>
<td>
<p>A &quot;BS&quot; object produced by <code>WBS.multi.nonpar</code>.</p>
</td></tr>
<tr><td><code id="tuneBSmultinonpar_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and vertical axis being dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of estimated change points.
</p>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Padilla, Yu, Wang and Rinaldo (2019) &lt;arxiv:1910.13289&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WBS.multi.nonpar">WBS.multi.nonpar</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 70
v = c(floor(n/3), 2*floor(n/3)) # location of change points
p = 4
Y = matrix(0, p, n) # matrix for data
mu0 = rep(0, p) # mean of the data
mu1 = rep(0, p)
mu1[1:floor(p/2)] = 2
Sigma0 = diag(p) #Covariance matrices of the data
Sigma1 = diag(p)*2
# Generate data
for(t in 1:n){
  if(t &lt; v[1] || t &gt; v[2]){
     Y[,t] = MASS::mvrnorm(n = 1, mu0, Sigma0)
  }
  if(t &gt;= v[1] &amp;&amp; t &lt; v[2]){
     Y[,t] = MASS::mvrnorm(n = 1, mu1, Sigma1)
  }
}## close for generate data
M = 8
intervals = WBS.intervals(M = M, lower = 1, upper = ncol(Y)) #Random intervals
K_max = 30
h = 5*(K_max*log(n)/n)^{1/p} # bandwith
temp = WBS.multi.nonpar(Y, Y, 1, ncol(Y), intervals$Alpha, intervals$Beta, h, delta = 10)
S = tuneBSmultinonpar(temp, Y)
</code></pre>

<hr>
<h2 id='tuneBSnonparRDPG'>Change points detection for dependent dynamic random dot product graph models.</h2><span id='topic+tuneBSnonparRDPG'></span>

<h3>Description</h3>

<p>Perform Change points detection for dependent dynamic random dot product graph models. The tuning parameter tau for WBS is automatically selected based on the BIC-type scores defined in Equation (2.4) in Zou et al. (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneBSnonparRDPG(BS_object, data_mat, lowerdiag = FALSE, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneBSnonparRDPG_+3A_bs_object">BS_object</code></td>
<td>
<p>A &quot;BS&quot; object produced by <code>WBS.nonpar.RDPG</code>.</p>
</td></tr>
<tr><td><code id="tuneBSnonparRDPG_+3A_data_mat">data_mat</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with horizontal axis being time, and vertical axis being vectorized adjacency matrix.</p>
</td></tr>
<tr><td><code id="tuneBSnonparRDPG_+3A_lowerdiag">lowerdiag</code></td>
<td>
<p>A <code>logic</code> scalar. TRUE, if each row of data_mat is the vectorization of the strictly lower diagonal elements in an adjacency matrix. FALSE, if each row of data_mat is the vectorization of all elements in an adjacency matrix.</p>
</td></tr>
<tr><td><code id="tuneBSnonparRDPG_+3A_d">d</code></td>
<td>
<p>A <code>numeric</code> scalar of the number of leading singular values of an adjacency matrix considered in the scaled PCA algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>numeric</code> vector of estimated change points.
</p>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Padilla, Yu and Priebe (2019) &lt;arxiv:1911.07494&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WBS.nonpar.RDPG">WBS.nonpar.RDPG</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### generate data 
p = 20 # number of nodes
n = 50 # sample size for each segment
lat_dim_num = 5 # number of latent dimensions
set.seed(1)
x_mat = matrix(runif(p*lat_dim_num), nrow = p, ncol = lat_dim_num)
x_tilde_mat = matrix(runif(p*lat_dim_num), nrow = p, ncol = lat_dim_num)
y_mat = rbind(x_tilde_mat[1:floor(p/4),], x_mat[(floor(p/4)+1):p,])
rdpg1 = simu.RDPG(x_mat, n, symm = TRUE, self = FALSE)
rdpg2 = simu.RDPG(y_mat, n, symm = TRUE, self = FALSE)
data1_mat = rdpg1$obs_mat
data2_mat = rdpg2$obs_mat
data_mat = cbind(data1_mat, data2_mat)
### detect change points
M = 20 # number of random intervals for WBS
d = 10 # parameter for scaled PCA algorithm
delta = 5
intervals = WBS.intervals(M = M, lower = 1, upper = ncol(data_mat))
WBS_result = WBS.nonpar.RDPG(data_mat, lowerdiag = TRUE, d, 
             Alpha = intervals$Alpha, Beta = intervals$Beta, delta)
cpt_hat = tuneBSnonparRDPG(WBS_result, data_mat, lowerdiag = TRUE, d)
</code></pre>

<hr>
<h2 id='tuneBSuninonpar'>Wild binary segmentation for univariate nonparametric change points detection with tuning parameter selection.</h2><span id='topic+tuneBSuninonpar'></span>

<h3>Description</h3>

<p>Perform wild binary segmentation with tuning parameter selection based on sample splitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneBSuninonpar(BS_object, Y, N)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneBSuninonpar_+3A_bs_object">BS_object</code></td>
<td>
<p>A &quot;BS&quot; object produced by <code>BS.uni.nonpar</code> or <code>WBS.uni.nonpar</code>.</p>
</td></tr>
<tr><td><code id="tuneBSuninonpar_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with horizontal axis being time, and vertical axis being multiple observations on each time point.</p>
</td></tr>
<tr><td><code id="tuneBSuninonpar_+3A_n">N</code></td>
<td>
<p>A <code>integer</code> vector representing number of multiple observations on each time point.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of estimated change points (sorted in strictly increasing order).
</p>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Padilla, Yu, Wang and Rinaldo (2021) &lt;doi:10.1214/21-EJS1809&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BS.uni.nonpar">BS.uni.nonpar</a></code> and <code><a href="#topic+WBS.uni.nonpar">WBS.uni.nonpar</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y = t(as.matrix(c(rnorm(100, 0, 1), rnorm(100, 0, 10), rnorm(50, 0, 40))))
W = Y # W is a copy of the matrix Y, it can be Y itself.
N = rep(1, 250)
M = 5
set.seed(123)
intervals = WBS.intervals(M = M, lower = 1, upper = ncol(Y))
BS_object = WBS.uni.nonpar(W, 1, ncol(Y), intervals$Alpha, intervals$Beta, N, delta = 5)
cpt_hat = tuneBSuninonpar(BS_object, Y, N)
</code></pre>

<hr>
<h2 id='tuneBSunivar'>Univariate mean change points detection based on standard or wild binary segmentation with tuning parameter selected by sSIC.</h2><span id='topic+tuneBSunivar'></span>

<h3>Description</h3>

<p>Perform univariate mean change points detection based on standard or wild binary segmentation. The threshold parameter tau for WBS is automatically selected based on the sSIC score defined in Equation (4) in Fryzlewicz (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneBSunivar(BS_object, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneBSunivar_+3A_bs_object">BS_object</code></td>
<td>
<p>A &quot;BS&quot; object produced by <code>BS.univar</code> or <code>WBS.univar</code>.</p>
</td></tr>
<tr><td><code id="tuneBSunivar_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>cpt</code></td>
<td>
<p>A vector of estimated change point locations (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>A scalar of selected threshold tau based on sSIC.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2020) &lt;doi:10.1214/20-EJS1710&gt;;
Fryzlewicz (2014), Wild binary segmentation for multiple change-point detection, &lt;DOI: 10.1214/14-AOS1245&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BS.univar">BS.univar</a></code> and <code><a href="#topic+WBS.univar">WBS.univar</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(2,30),rep(0,120),rep(2,130))
## change points detection by WBS
intervals = WBS.intervals(M = 100, lower = 1, upper = length(y))
temp2 = WBS.univar(y, 1, length(y), intervals$Alpha, intervals$Beta, delta = 5)
WBS_result = tuneBSunivar(temp2, y)
cpt_WBS = WBS_result$cpt
Hausdorff.dist(cpt_WBS, cpt_true)
</code></pre>

<hr>
<h2 id='WBS.intervals'>Generate random intervals for WBS.</h2><span id='topic+WBS.intervals'></span>

<h3>Description</h3>

<p>Generate random intervals for WBS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WBS.intervals(M, lower = 1, upper)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WBS.intervals_+3A_m">M</code></td>
<td>
<p>A positive <code>integer</code> scalar of number of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.intervals_+3A_lower">lower</code></td>
<td>
<p>A positive <code>integer</code> scalar of lower bound of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.intervals_+3A_upper">upper</code></td>
<td>
<p>A positive <code>integer</code> scalar of upper bound of random intervals.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>Alpha</code></td>
<td>
<p>A M-dim vector representing the starting indices of random intervals</p>
</td></tr>
<tr><td><code>Beta</code></td>
<td>
<p>A M-dim vector representing the ending indices of random intervals</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla
</p>


<h3>Examples</h3>

<pre><code class='language-R'>WBS.intervals(120, lower = 1, upper = 300)
</code></pre>

<hr>
<h2 id='WBS.multi.nonpar'>Wild binary segmentation for multivariate nonparametric change points detection.</h2><span id='topic+WBS.multi.nonpar'></span>

<h3>Description</h3>

<p>Perform wild binary segmentation for multivariate nonparametric change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WBS.multi.nonpar(Y, W, s, e, Alpha, Beta, h, delta, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WBS.multi.nonpar_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and vertical axis being dimension.</p>
</td></tr>
<tr><td><code id="WBS.multi.nonpar_+3A_w">W</code></td>
<td>
<p>A copy of the matrix Y, it can be Y itself.</p>
</td></tr>
<tr><td><code id="WBS.multi.nonpar_+3A_s">s</code></td>
<td>
<p>A <code>integer</code> scalar of starting index.</p>
</td></tr>
<tr><td><code id="WBS.multi.nonpar_+3A_e">e</code></td>
<td>
<p>A <code>integer</code> scalar of ending index.</p>
</td></tr>
<tr><td><code id="WBS.multi.nonpar_+3A_alpha">Alpha</code></td>
<td>
<p>A <code>integer</code> vector of starting indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.multi.nonpar_+3A_beta">Beta</code></td>
<td>
<p>A <code>integer</code> vector of ending indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.multi.nonpar_+3A_h">h</code></td>
<td>
<p>A <code>numeric</code> scalar of bandwidth parameter.</p>
</td></tr>
<tr><td><code id="WBS.multi.nonpar_+3A_delta">delta</code></td>
<td>
<p>A <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="WBS.multi.nonpar_+3A_level">level</code></td>
<td>
<p>Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change points (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic based on KS distance.</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected.</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Padilla, Yu, Wang and Rinaldo (2019) &lt;arxiv:1910.13289&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtain change points estimation, <code><a href="#topic+tuneBSmultinonpar">tuneBSmultinonpar</a></code> for a tuning version.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 70
v = c(floor(n/3), 2*floor(n/3)) # location of change points
p = 4
Y = matrix(0, p, n) # matrix for data
mu0 = rep(0, p) # mean of the data
mu1 = rep(0, p)
mu1[1:floor(p/2)] = 2
Sigma0 = diag(p) #Covariance matrices of the data
Sigma1 = diag(p)*2
# Generate data
for(t in 1:n){
  if(t &lt; v[1] || t &gt; v[2]){
     Y[,t] = MASS::mvrnorm(n = 1, mu0, Sigma0)
  }
  if(t &gt;= v[1] &amp;&amp; t &lt; v[2]){
     Y[,t] = MASS::mvrnorm(n = 1, mu1, Sigma1)
  }
}## close for generate data
M = 10
intervals = WBS.intervals(M = M, lower = 1, upper = ncol(Y)) #Random intervals
K_max = 30
h = 5*(K_max*log(n)/n)^{1/p} # bandwith
temp = WBS.multi.nonpar(Y, Y, 1, ncol(Y), intervals$Alpha, intervals$Beta, h, delta = 10)
result = thresholdBS(temp, median(temp$Dval))
</code></pre>

<hr>
<h2 id='WBS.network'>Wild binary segmentation for network change points detection.</h2><span id='topic+WBS.network'></span>

<h3>Description</h3>

<p>Perform wild binary segmentation for network change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WBS.network(data_mat1, data_mat2, s, e, Alpha, Beta, delta, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WBS.network_+3A_data_mat1">data_mat1</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with with horizontal axis being time, and with each column be the vectorized adjacency matrix.</p>
</td></tr>
<tr><td><code id="WBS.network_+3A_data_mat2">data_mat2</code></td>
<td>
<p>An independent copy of data_mat1.</p>
</td></tr>
<tr><td><code id="WBS.network_+3A_s">s</code></td>
<td>
<p>A <code>integer</code> scalar of starting index.</p>
</td></tr>
<tr><td><code id="WBS.network_+3A_e">e</code></td>
<td>
<p>A <code>integer</code> scalar of ending index.</p>
</td></tr>
<tr><td><code id="WBS.network_+3A_alpha">Alpha</code></td>
<td>
<p>A <code>integer</code> vector of starting indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.network_+3A_beta">Beta</code></td>
<td>
<p>A <code>integer</code> vector of ending indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.network_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="WBS.network_+3A_level">level</code></td>
<td>
<p>Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change points (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic based on KS distance.</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected.</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daren Wang &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2018) &lt;arxiv:1809.09602&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtaining change points estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 15 # number of nodes
rho = 0.5 # sparsity parameter
block_num = 3 # number of groups for SBM
n = 100 # sample size for each segment
# connectivity matrix for the first and the third segments
conn1_mat = rho * matrix(c(0.6,1,0.6,1,0.6,0.5,0.6,0.5,0.6), nrow = 3) 
# connectivity matrix for the second segment
conn2_mat = rho * matrix(c(0.6,0.5,0.6,0.5,0.6,1,0.6,1,0.6), nrow = 3) 
set.seed(1)
can_vec = sample(1:p, replace = FALSE) # randomly assign nodes into groups
sbm1 = simu.SBM(conn1_mat, can_vec, n, symm = TRUE, self = TRUE)
sbm2 = simu.SBM(conn2_mat, can_vec, n, symm = TRUE, self = TRUE)
data_mat = cbind(sbm1$obs_mat, sbm2$obs_mat)
data_mat1 = data_mat[,seq(1,ncol(data_mat),2)]
data_mat2 = data_mat[,seq(2,ncol(data_mat),2)]
M = 10
intervals = WBS.intervals(M = M, lower = 1, upper = ncol(data_mat1))
temp = WBS.network(data_mat1, data_mat2, 1, ncol(data_mat1), 
                   intervals$Alpha, intervals$Beta, delta = 5)
rho_hat = quantile(rowMeans(data_mat), 0.95)
tau = p*rho_hat*(log(n))^2/20 # default threshold given in the paper
cpt_init = unlist(thresholdBS(temp, tau)$cpt_hat[,1])
cpt_refined = local.refine.network(cpt_init, data_mat1, data_mat2, 
                      self = TRUE, tau2 = p*rho_hat/3, tau3 = Inf)
cpt_WBS = 2*cpt_init
cpt_refined = 2*cpt_refined
</code></pre>

<hr>
<h2 id='WBS.nonpar.RDPG'>Wild binary segmentation for dependent dynamic random dot product graph models.</h2><span id='topic+WBS.nonpar.RDPG'></span>

<h3>Description</h3>

<p>Perform wild binary segmentation for dependent dynamic random dot product graph models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WBS.nonpar.RDPG(data_mat, lowerdiag = FALSE, d, Alpha, Beta, delta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WBS.nonpar.RDPG_+3A_data_mat">data_mat</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with horizontal axis being time, and vertical axis being vectorized adjacency matrix.</p>
</td></tr>
<tr><td><code id="WBS.nonpar.RDPG_+3A_lowerdiag">lowerdiag</code></td>
<td>
<p>A <code>logic</code> scalar. TRUE, if each row of data_mat is the vectorization of the strictly lower diagonal elements in an adjacency matrix. FALSE, if each row of data_mat is the vectorization of all elements in an adjacency matrix.</p>
</td></tr>
<tr><td><code id="WBS.nonpar.RDPG_+3A_d">d</code></td>
<td>
<p>A <code>numeric</code> scalar of the number of leading singular values of an adjacency matrix considered in the scaled PCA algorithm.</p>
</td></tr>
<tr><td><code id="WBS.nonpar.RDPG_+3A_alpha">Alpha</code></td>
<td>
<p>A <code>integer</code> vector of starting indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.nonpar.RDPG_+3A_beta">Beta</code></td>
<td>
<p>A <code>integer</code> vector of ending indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.nonpar.RDPG_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change point locations (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic.</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected.</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla, Haotian Xu
</p>


<h3>References</h3>

<p>Padilla, Yu and Priebe (2019) &lt;arxiv:1911.07494&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtaining change points estimation, <code><a href="#topic+tuneBSnonparRDPG">tuneBSnonparRDPG</a></code> for a tuning version.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### generate data 
p = 20 # number of nodes
n = 50 # sample size for each segment
lat_dim_num = 5 # number of latent dimensions
set.seed(1)
x_mat = matrix(runif(p*lat_dim_num), nrow = p, ncol = lat_dim_num)
x_tilde_mat = matrix(runif(p*lat_dim_num), nrow = p, ncol = lat_dim_num)
y_mat = rbind(x_tilde_mat[1:floor(p/4),], x_mat[(floor(p/4)+1):p,])
rdpg1 = simu.RDPG(x_mat, n, symm = TRUE, self = FALSE)
rdpg2 = simu.RDPG(y_mat, n, symm = TRUE, self = FALSE)
data1_mat = rdpg1$obs_mat
data2_mat = rdpg2$obs_mat
data_mat = cbind(data1_mat, data2_mat)
### detect change points
M = 30 # number of random intervals for WBS
d = 10 # parameter for scaled PCA algorithm
delta = 5
intervals = WBS.intervals(M = M, lower = 1, upper = ncol(data_mat))
WBS_result = WBS.nonpar.RDPG(data_mat, lowerdiag = TRUE, d, 
             Alpha = intervals$Alpha, Beta = intervals$Beta, delta)
</code></pre>

<hr>
<h2 id='WBS.uni.nonpar'>Wild binary segmentation for univariate nonparametric change points detection.</h2><span id='topic+WBS.uni.nonpar'></span>

<h3>Description</h3>

<p>Perform wild binary segmentation for univariate nonparametric change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WBS.uni.nonpar(Y, s, e, Alpha, Beta, N, delta, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WBS.uni.nonpar_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> matrix of observations with horizontal axis being time, and vertical axis being multiple observations on each time point.</p>
</td></tr>
<tr><td><code id="WBS.uni.nonpar_+3A_s">s</code></td>
<td>
<p>A <code>integer</code> scalar of starting index.</p>
</td></tr>
<tr><td><code id="WBS.uni.nonpar_+3A_e">e</code></td>
<td>
<p>A <code>integer</code> scalar of ending index.</p>
</td></tr>
<tr><td><code id="WBS.uni.nonpar_+3A_alpha">Alpha</code></td>
<td>
<p>A <code>integer</code> vector of starting indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.uni.nonpar_+3A_beta">Beta</code></td>
<td>
<p>A <code>integer</code> vector of ending indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.uni.nonpar_+3A_n">N</code></td>
<td>
<p>A <code>integer</code> vector representing number of multiple observations on each time point.</p>
</td></tr>
<tr><td><code id="WBS.uni.nonpar_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="WBS.uni.nonpar_+3A_level">level</code></td>
<td>
<p>Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change points (sorted in strictly increasing order)</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic based on KS distance</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Oscar Hernan Madrid Padilla, Haotian Xu
</p>


<h3>References</h3>

<p>Padilla, Yu, Wang and Rinaldo (2021) &lt;doi:10.1214/21-EJS1809&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtaining change points estimation, <code><a href="#topic+tuneBSuninonpar">tuneBSuninonpar</a></code> for a tuning version.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y = t(as.matrix(c(rnorm(100, 0, 1), rnorm(100, 0, 10), rnorm(100, 0, 40))))
N = rep(1, 300)
M = 20
intervals = WBS.intervals(M = M, lower = 1, upper = ncol(Y))
temp = WBS.uni.nonpar(Y, 1, 300, intervals$Alpha, intervals$Beta, N, 5)
plot.ts(t(Y))
points(x = tail(temp$S[order(temp$Dval)], 4), y = Y[,tail(temp$S[order(temp$Dval)],4)], col = "red")
thresholdBS(temp, 2)
</code></pre>

<hr>
<h2 id='WBS.uni.rob'>Robust wild binary segmentation for univariate mean change points detection.</h2><span id='topic+WBS.uni.rob'></span>

<h3>Description</h3>

<p>Perform a robust version of the wild binary segmentation method using Huber loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WBS.uni.rob(y, s, e, Alpha, Beta, K = 1.345, delta, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WBS.uni.rob_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="WBS.uni.rob_+3A_s">s</code></td>
<td>
<p>A <code>numeric</code> scalar representing the starting index of an interval.</p>
</td></tr>
<tr><td><code id="WBS.uni.rob_+3A_e">e</code></td>
<td>
<p>A <code>numeric</code> scalar representing the ending index of an interval.</p>
</td></tr>
<tr><td><code id="WBS.uni.rob_+3A_alpha">Alpha</code></td>
<td>
<p>An <code>integer</code> vector of starting indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.uni.rob_+3A_beta">Beta</code></td>
<td>
<p>An <code>integer</code> vector of ending indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.uni.rob_+3A_k">K</code></td>
<td>
<p>A <code>numeric</code> scalar representing the robustification parameter in the Huber loss.</p>
</td></tr>
<tr><td><code id="WBS.uni.rob_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="WBS.uni.rob_+3A_level">level</code></td>
<td>
<p>Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change points (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic based on KS distance.</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected.</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mengchu Li &amp; Haotian Xu
</p>


<h3>References</h3>

<p>Fearnhead &amp; Rigaill (2019) &lt;doi:10.1080/01621459.2017.1385466&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtaining change points estimation.
</p>

<hr>
<h2 id='WBS.univar'>Wild binary segmentation for univariate mean change points detection.</h2><span id='topic+WBS.univar'></span>

<h3>Description</h3>

<p>Perform wild binary segmentation for univariate mean change points detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WBS.univar(y, s, e, Alpha, Beta, delta = 2, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WBS.univar_+3A_y">y</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="WBS.univar_+3A_s">s</code></td>
<td>
<p>A <code>integer</code> scalar of starting index.</p>
</td></tr>
<tr><td><code id="WBS.univar_+3A_e">e</code></td>
<td>
<p>A <code>integer</code> scalar of ending index.</p>
</td></tr>
<tr><td><code id="WBS.univar_+3A_alpha">Alpha</code></td>
<td>
<p>A <code>integer</code> vector of starting indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.univar_+3A_beta">Beta</code></td>
<td>
<p>A <code>integer</code> vector of ending indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBS.univar_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="WBS.univar_+3A_level">level</code></td>
<td>
<p>Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change point locations (sorted in strictly increasing order).</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic.</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected.</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2020) &lt;doi:10.1214/20-EJS1710&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtaining change points estimation, <code><a href="#topic+tuneBSunivar">tuneBSunivar</a></code> for a tuning version.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
cpt_true = c(20, 50, 170)
y = rnorm(300) + c(rep(0,20),rep(2,30),rep(0,120),rep(2,130))
intervals = WBS.intervals(M = 300, lower = 1, upper = length(y))
temp = WBS.univar(y, 1, length(y), intervals$Alpha, intervals$Beta, delta = 5)
plot.ts(y)
points(x = tail(temp$S[order(temp$Dval)],4),
       y = y[tail(temp$S[order(temp$Dval)],4)], col = "red")
WBS_result = thresholdBS(temp, tau = 4)
print(WBS_result$BS_tree, "value")
plot(WBS_result$BS_tree)
print(WBS_result$BS_tree_trimmed, "value")
plot(WBS_result$BS_tree_trimmed)
cpt_hat = sort(WBS_result$cpt_hat[,1]) # the threshold tau is specified to be 4
Hausdorff.dist(cpt_hat, cpt_true)
cpt_LR = local.refine.univar(cpt_hat, y)
Hausdorff.dist(cpt_LR, cpt_true)
</code></pre>

<hr>
<h2 id='WBSIP.cov'>Wild binary segmentation for covariance change points detection through Independent Projection.</h2><span id='topic+WBSIP.cov'></span>

<h3>Description</h3>

<p>Perform wild binary segmentation for covariance change points detection through Independent Projection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WBSIP.cov(X, X_prime, s, e, Alpha, Beta, delta, level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WBSIP.cov_+3A_x">X</code></td>
<td>
<p>A <code>numeric</code> vector of observations.</p>
</td></tr>
<tr><td><code id="WBSIP.cov_+3A_x_prime">X_prime</code></td>
<td>
<p>A <code>numeric</code> vector of observations which are independent copy of X.</p>
</td></tr>
<tr><td><code id="WBSIP.cov_+3A_s">s</code></td>
<td>
<p>A <code>integer</code> scalar of starting index.</p>
</td></tr>
<tr><td><code id="WBSIP.cov_+3A_e">e</code></td>
<td>
<p>A <code>integer</code> scalar of ending index.</p>
</td></tr>
<tr><td><code id="WBSIP.cov_+3A_alpha">Alpha</code></td>
<td>
<p>A <code>integer</code> vector of starting indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBSIP.cov_+3A_beta">Beta</code></td>
<td>
<p>A <code>integer</code> vector of ending indices of random intervals.</p>
</td></tr>
<tr><td><code id="WBSIP.cov_+3A_delta">delta</code></td>
<td>
<p>A positive <code>integer</code> scalar of minimum spacing.</p>
</td></tr>
<tr><td><code id="WBSIP.cov_+3A_level">level</code></td>
<td>
<p>A parameter for tracking the level at which a change point is detected. Should be fixed as 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> &quot;BS&quot;, which is a <code>list</code> with the following structure:
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>A vector of estimated change points (sorted in strictly increasing order)</p>
</td></tr>
<tr><td><code>Dval</code></td>
<td>
<p>A vector of values of CUSUM statistic based on KS distance</p>
</td></tr>
<tr><td><code>Level</code></td>
<td>
<p>A vector representing the levels at which each change point is detected</p>
</td></tr>
<tr><td><code>Parent</code></td>
<td>
<p>A matrix with the starting indices on the first row and the ending indices on the second row</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haotian Xu
</p>


<h3>References</h3>

<p>Wang, Yu and Rinaldo (2021) &lt;doi:10.3150/20-BEJ1249&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thresholdBS">thresholdBS</a></code> for obtain change points estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p = 10
A1 = gen.cov.mat(p, 1, "equal")
A2 = gen.cov.mat(p, 3, "power")
A3 = A1
set.seed(1234)
X = cbind(t(MASS::mvrnorm(50, mu = rep(0, p), A1)), 
          t(MASS::mvrnorm(50, mu = rep(0, p), A2)), 
          t(MASS::mvrnorm(50, mu = rep(0, p), A3)))
X_prime = cbind(t(MASS::mvrnorm(50, mu = rep(0, p), A1)), 
                t(MASS::mvrnorm(50, mu = rep(0, p), A2)), 
                t(MASS::mvrnorm(50, mu = rep(0, p), A3)))
intervals = WBS.intervals(M = 120, lower = 1, upper = dim(X)[2])
temp = WBSIP.cov(X, X_prime, 1, dim(X)[2], intervals$Alpha, intervals$Beta, delta = 5)
tau = sqrt(p*log(ncol(X)))*1.5
sort(thresholdBS(temp, tau)$cpt_hat[,1])
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
