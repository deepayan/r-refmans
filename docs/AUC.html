<!DOCTYPE html><html><head><title>Help for package AUC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {AUC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AUC-package'>
<p>Threshold independent performance measures for probabilistic classifiers.</p></a></li>
<li><a href='#accuracy'><p>Compute the accuracy curve.</p></a></li>
<li><a href='#auc'><p>Compute the area under the curve of a given performance measure.</p></a></li>
<li><a href='#AUCNews'><p>Display the NEWS file</p></a></li>
<li><a href='#churn'><p> Churn data</p></a></li>
<li><a href='#plot.AUC'><p>Plot the sensitivity, specificity, accuracy and roc curves.</p></a></li>
<li><a href='#roc'><p>Compute the receiver operating characteristic (ROC) curve.</p></a></li>
<li><a href='#sensitivity'><p>Compute the sensitivity curve.</p></a></li>
<li><a href='#specificity'><p>Compute the specificity curve.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Threshold Independent Performance Measures for Probabilistic
Classifiers</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-04-04</td>
</tr>
<tr>
<td>Author:</td>
<td>Michel Ballings and Dirk Van den Poel</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michel Ballings &lt;Michel.Ballings@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Various functions to compute the area under the curve of selected measures: The area under the sensitivity curve (AUSEC), the area under the specificity curve (AUSPC), the area under the accuracy curve (AUACC), and the area under the receiver operating characteristic curve (AUROC). Support for visualization and partial areas is included.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-04 13:03:28 UTC; mballin2</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-04 15:40:17 UTC</td>
</tr>
</table>
<hr>
<h2 id='AUC-package'>
Threshold independent performance measures for probabilistic classifiers.
</h2><span id='topic+AUC-package'></span><span id='topic+AUC'></span>

<h3>Description</h3>

<p>Summary and plotting functions for threshold independent performance measures for probabilistic classifiers.
</p>


<h3>Details</h3>

<p>This package includes functions to compute the area under the curve (function <code>auc</code>) of selected measures: The area under 
the sensitivity curve (AUSEC) (function <code>sensitivity</code>), the area under the specificity curve
(AUSPC) (function <code>specificity</code>), the area under the accuracy curve (AUACC) (function <code>accuracy</code>), and
the area under the receiver operating characteristic curve (AUROC) (function <code>roc</code>). The curves can also be 
visualized using the function <code>plot</code>. Support for partial areas is provided.
</p>
<p>Auxiliary code in this package is adapted from the <code>ROCR</code> package. The measures available in this package are not available in the 
ROCR package or vice versa (except for the AUROC). As for the AUROC, we adapted the <code>ROCR</code> code to increase computational speed 
(so it can be used more effectively in objective functions). As a result less funtionality is offered (e.g., averaging cross validation runs). 
Please use the <code>ROCR</code> package for that purposes.
</p>


<h3>Author(s)</h3>

<p>Michel Ballings and Dirk Van den Poel, Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sensitivity">sensitivity</a></code>, <code><a href="#topic+specificity">specificity</a></code>, <code><a href="#topic+accuracy">accuracy</a></code>, <code><a href="#topic+roc">roc</a></code>, <code><a href="#topic+auc">auc</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(churn)

auc(sensitivity(churn$predictions,churn$labels))
auc(specificity(churn$predictions,churn$labels))
auc(accuracy(churn$predictions,churn$labels))
auc(roc(churn$predictions,churn$labels))

plot(sensitivity(churn$predictions,churn$labels))
plot(specificity(churn$predictions,churn$labels))
plot(accuracy(churn$predictions,churn$labels))
plot(roc(churn$predictions,churn$labels))

</code></pre>

<hr>
<h2 id='accuracy'>Compute the accuracy curve.</h2><span id='topic+accuracy'></span>

<h3>Description</h3>

<p>This function computes the accuracy curve required for the <code>auc</code> function and the <code>plot</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accuracy(predictions, labels, perc.rank = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accuracy_+3A_predictions">predictions</code></td>
<td>
<p>A numeric vector of classification probabilities (confidences, scores) of the positive event.</p>
</td></tr>
<tr><td><code id="accuracy_+3A_labels">labels</code></td>
<td>
<p>A factor of observed class labels (responses) with the only allowed values {0,1}.</p>
</td></tr>
<tr><td><code id="accuracy_+3A_perc.rank">perc.rank</code></td>
<td>
<p>A logical. If TRUE (default) the percentile rank of the predictions is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>cutoffs</code></td>
<td>
<p>A numeric vector of threshold values</p>
</td></tr>
<tr><td><code>measure</code></td>
<td>
<p>A numeric vector of accuracy values corresponding to the threshold values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Authors: Michel Ballings and Dirk Van den Poel, Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sensitivity">sensitivity</a></code>, <code><a href="#topic+specificity">specificity</a></code>, <code><a href="#topic+accuracy">accuracy</a></code>, <code><a href="#topic+roc">roc</a></code>, <code><a href="#topic+auc">auc</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(churn)

accuracy(churn$predictions,churn$labels)

</code></pre>

<hr>
<h2 id='auc'>Compute the area under the curve of a given performance measure.</h2><span id='topic+auc'></span>

<h3>Description</h3>

<p>This function computes the area under the sensitivity curve (AUSEC), the area under the specificity curve (AUSPC), 
the area under the accuracy curve (AUACC), or the area under the receiver operating characteristic curve (AUROC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auc(x, min = 0, max = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auc_+3A_x">x</code></td>
<td>
<p>an object produced by one of the functions <code>sensitivity</code>, <code>specificity</code>,  <code>accuracy</code>, or <code>roc</code></p>
</td></tr>
<tr><td><code id="auc_+3A_min">min</code></td>
<td>
<p>a numeric value between 0 and 1, denoting the cutoff that defines the start of the area under the curve</p>
</td></tr>
<tr><td><code id="auc_+3A_max">max</code></td>
<td>
<p>a numeric value between 0 and 1, denoting the cutoff that defines the end of the area under the curve</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value between zero and one denoting the area under the curve
</p>


<h3>Author(s)</h3>

<p>Authors: Michel Ballings and Dirk Van den Poel, Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sensitivity">sensitivity</a></code>, <code><a href="#topic+specificity">specificity</a></code>, <code><a href="#topic+accuracy">accuracy</a></code>, <code><a href="#topic+roc">roc</a></code>, <code><a href="#topic+auc">auc</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(churn)

auc(sensitivity(churn$predictions,churn$labels))

auc(specificity(churn$predictions,churn$labels))

auc(accuracy(churn$predictions,churn$labels))

auc(roc(churn$predictions,churn$labels))


</code></pre>

<hr>
<h2 id='AUCNews'>Display the NEWS file
</h2><span id='topic+AUCNews'></span>

<h3>Description</h3>

<p><code>AUCNews</code> shows the NEWS file of the AUC package.</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUCNews()
</code></pre>


<h3>Value</h3>

<p>None.
</p>

<hr>
<h2 id='churn'> Churn data
</h2><span id='topic+churn'></span>

<h3>Description</h3>

<p><code>churn</code> contains three variables: the churn predictions (probabilities) of two models, and observed churn
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(churn)</code></pre>


<h3>Format</h3>

<p>A data frame with 1302 observations, and 3 variables: <code>predictions</code>, <code>predictions2</code>, <code>churn</code>.
</p>


<h3>Author(s)</h3>

<p>Authors: Michel Ballings and Dirk Van den Poel,
Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(churn)
str(churn)
</code></pre>

<hr>
<h2 id='plot.AUC'>Plot the sensitivity, specificity, accuracy and roc curves.</h2><span id='topic+plot.AUC'></span>

<h3>Description</h3>

<p>This function plots the (partial) sensitivity, specificity, accuracy and roc curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'AUC'
plot(x, y = NULL, ..., type = "l", add = FALSE, min = 0, max = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.AUC_+3A_x">x</code></td>
<td>
<p>an object produced by one of the functions <code>sensitivity</code>, <code>specificity</code>,  <code>accuracy</code>, or <code>roc</code></p>
</td></tr>
<tr><td><code id="plot.AUC_+3A_y">y</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="plot.AUC_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to methods, such as graphical parameters. See ?plot</p>
</td></tr>
<tr><td><code id="plot.AUC_+3A_type">type</code></td>
<td>
<p>Type of plot. Default is line plot.</p>
</td></tr>
<tr><td><code id="plot.AUC_+3A_add">add</code></td>
<td>
<p>Logical. If TRUE the curve is added to an existing plot. If FALSE a new plot is created.</p>
</td></tr>
<tr><td><code id="plot.AUC_+3A_min">min</code></td>
<td>
<p>a numeric value between 0 and 1, denoting the cutoff that defines the start of the area under the curve</p>
</td></tr>
<tr><td><code id="plot.AUC_+3A_max">max</code></td>
<td>
<p>a numeric value between 0 and 1, denoting the cutoff that defines the end of the area under the curve</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Authors: Michel Ballings and Dirk Van den Poel, Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sensitivity">sensitivity</a></code>, <code><a href="#topic+specificity">specificity</a></code>, <code><a href="#topic+accuracy">accuracy</a></code>, <code><a href="#topic+roc">roc</a></code>, <code><a href="#topic+auc">auc</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(churn)

plot(sensitivity(churn$predictions,churn$labels))

plot(specificity(churn$predictions,churn$labels))

plot(accuracy(churn$predictions,churn$labels))

plot(roc(churn$predictions,churn$labels))


</code></pre>

<hr>
<h2 id='roc'>Compute the receiver operating characteristic (ROC) curve.</h2><span id='topic+roc'></span>

<h3>Description</h3>

<p>This function computes the receiver operating characteristic (ROC) curve required for the <code>auc</code> function and the <code>plot</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roc(predictions, labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roc_+3A_predictions">predictions</code></td>
<td>
<p>A numeric vector of classification probabilities (confidences, scores) of the positive event.</p>
</td></tr>
<tr><td><code id="roc_+3A_labels">labels</code></td>
<td>
<p>A factor of observed class labels (responses) with the only allowed values {0,1}.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>cutoffs</code></td>
<td>
<p>A numeric vector of threshold values</p>
</td></tr>
<tr><td><code>fpr</code></td>
<td>
<p>A numeric vector of false positive rates corresponding to the threshold values</p>
</td></tr>
<tr><td><code>tpr</code></td>
<td>
<p>A numeric vector of true positive rates corresponding to the threshold values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Authors: Michel Ballings and Dirk Van den Poel, Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sensitivity">sensitivity</a></code>, <code><a href="#topic+specificity">specificity</a></code>, <code><a href="#topic+accuracy">accuracy</a></code>, <code><a href="#topic+roc">roc</a></code>, <code><a href="#topic+auc">auc</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(churn)

roc(churn$predictions,churn$labels)

</code></pre>

<hr>
<h2 id='sensitivity'>Compute the sensitivity curve.</h2><span id='topic+sensitivity'></span>

<h3>Description</h3>

<p>This function computes the sensitivity curve required for the <code>auc</code> function and the <code>plot</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sensitivity(predictions, labels, perc.rank = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sensitivity_+3A_predictions">predictions</code></td>
<td>
<p>A numeric vector of classification probabilities (confidences, scores) of the positive event.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_labels">labels</code></td>
<td>
<p>A factor of observed class labels (responses) with the only allowed values {0,1}.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_perc.rank">perc.rank</code></td>
<td>
<p>A logical. If TRUE (default) the percentile rank of the predictions is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>cutoffs</code></td>
<td>
<p>A numeric vector of threshold values</p>
</td></tr>
<tr><td><code>measure</code></td>
<td>
<p>A numeric vector of sensitivity values corresponding to the threshold values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Authors: Michel Ballings and Dirk Van den Poel, Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sensitivity">sensitivity</a></code>, <code><a href="#topic+specificity">specificity</a></code>, <code><a href="#topic+accuracy">accuracy</a></code>, <code><a href="#topic+roc">roc</a></code>, <code><a href="#topic+auc">auc</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(churn)

sensitivity(churn$predictions,churn$labels)

</code></pre>

<hr>
<h2 id='specificity'>Compute the specificity curve.</h2><span id='topic+specificity'></span>

<h3>Description</h3>

<p>This function computes the specificity curve required for the <code>auc</code> function and the <code>plot</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specificity(predictions, labels, perc.rank = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="specificity_+3A_predictions">predictions</code></td>
<td>
<p>A numeric vector of classification probabilities (confidences, scores) of the positive event.</p>
</td></tr>
<tr><td><code id="specificity_+3A_labels">labels</code></td>
<td>
<p>A factor of observed class labels (responses) with the only allowed values {0,1}.</p>
</td></tr>
<tr><td><code id="specificity_+3A_perc.rank">perc.rank</code></td>
<td>
<p>A logical. If TRUE (default) the percentile rank of the predictions is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>cutoffs</code></td>
<td>
<p>A numeric vector of threshold values</p>
</td></tr>
<tr><td><code>measure</code></td>
<td>
<p>A numeric vector of specificity values corresponding to the threshold values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Authors: Michel Ballings and Dirk Van den Poel, Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sensitivity">sensitivity</a></code>, <code><a href="#topic+specificity">specificity</a></code>, <code><a href="#topic+accuracy">accuracy</a></code>, <code><a href="#topic+roc">roc</a></code>, <code><a href="#topic+auc">auc</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(churn)

specificity(churn$predictions,churn$labels)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
