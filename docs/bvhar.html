<!DOCTYPE html><html><head><title>Help for package bvhar</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bvhar}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%&gt;%'><p>Pipe operator</p></a></li>
<li><a href='#AIC.varlse'><p>Akaike's Information Criterion of Multivariate Time Series Model</p></a></li>
<li><a href='#analyze_ir.varlse'><p>Impulse Response Analysis</p></a></li>
<li><a href='#autoplot.bvharirf'><p>Plot Impulse Responses</p></a></li>
<li><a href='#autoplot.bvharsp'><p>Plot the Result of BVAR and BVHAR MCMC</p></a></li>
<li><a href='#autoplot.normaliw'><p>Residual Plot for Minnesota Prior VAR Model</p></a></li>
<li><a href='#autoplot.predbvhar'><p>Plot Forecast Result</p></a></li>
<li><a href='#autoplot.summary.bvharsp'><p>Plot the Heatmap of SSVS Coefficients</p></a></li>
<li><a href='#autoplot.summary.normaliw'><p>Density Plot for Minnesota Prior VAR Model</p></a></li>
<li><a href='#BIC.varlse'><p>Bayesian Information Criterion of Multivariate Time Series Model</p></a></li>
<li><a href='#bound_bvhar'><p>Setting Empirical Bayes Optimization Bounds</p></a></li>
<li><a href='#bvar_adding_dummy'><p>Adding Dummy Observations</p></a></li>
<li><a href='#bvar_flat'><p>Fitting Bayesian VAR(p) of Flat Prior</p></a></li>
<li><a href='#bvar_horseshoe'><p>Fitting Bayesian VAR(p) of Horseshoe Prior</p></a></li>
<li><a href='#bvar_minnesota'><p>Fitting Bayesian VAR(p) of Minnesota Prior</p></a></li>
<li><a href='#bvar_niwhm'><p>Fitting Hierarchical Bayesian VAR(p)</p></a></li>
<li><a href='#bvar_predictive_density'><p>Predictive Density of Bayesian Models</p></a></li>
<li><a href='#bvar_ssvs'><p>Fitting Bayesian VAR(p) of SSVS Prior</p></a></li>
<li><a href='#bvar_sv'><p>Fitting Bayesian VAR-SV</p></a></li>
<li><a href='#bvhar_horseshoe'><p>Fitting Bayesian VHAR of Horseshoe Prior</p></a></li>
<li><a href='#bvhar_minnesota'><p>Fitting Bayesian VHAR of Minnesota Prior</p></a></li>
<li><a href='#bvhar_ssvs'><p>Fitting Bayesian VHAR of SSVS Prior</p></a></li>
<li><a href='#bvhar_sv'><p>Fitting Bayesian VHAR-SV</p></a></li>
<li><a href='#bvhar-package'><p>bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling</p></a></li>
<li><a href='#choose_bayes'><p>Finding the Set of Hyperparameters of Bayesian Model</p></a></li>
<li><a href='#choose_bvar'><p>Finding the Set of Hyperparameters of Individual Bayesian Model</p></a></li>
<li><a href='#choose_ssvs'><p>Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach</p></a></li>
<li><a href='#choose_var'><p>Choose the Best VAR based on Information Criteria</p></a></li>
<li><a href='#coef.varlse'><p>Coefficient Matrix of Multivariate Time Series Models</p></a></li>
<li><a href='#compute_dic'><p>Deviance Information Criterion of Multivariate Time Series Model</p></a></li>
<li><a href='#compute_logml'><p>Extracting Log of Marginal Likelihood</p></a></li>
<li><a href='#conf_fdr'><p>Evaluate the Sparsity Estimation Based on FDR</p></a></li>
<li><a href='#conf_fnr'><p>Evaluate the Sparsity Estimation Based on FNR</p></a></li>
<li><a href='#conf_fscore'><p>Evaluate the Sparsity Estimation Based on F1 Score</p></a></li>
<li><a href='#conf_prec'><p>Evaluate the Sparsity Estimation Based on Precision</p></a></li>
<li><a href='#conf_recall'><p>Evaluate the Sparsity Estimation Based on Recall</p></a></li>
<li><a href='#confusion'><p>Evaluate the Sparsity Estimation Based on Confusion Matrix</p></a></li>
<li><a href='#divide_ts'><p>Split a Time Series Dataset into Train-Test Set</p></a></li>
<li><a href='#etf_vix'><p>CBOE ETF Volatility Index Dataset</p></a></li>
<li><a href='#financial_history_appendix'><p>Time points and Financial Events</p></a></li>
<li><a href='#fitted.varlse'><p>Fitted Matrix from Multivariate Time Series Models</p></a></li>
<li><a href='#forecast_expand'><p>Out-of-sample Forecasting based on Expanding Window</p></a></li>
<li><a href='#forecast_roll'><p>Out-of-sample Forecasting based on Rolling Window</p></a></li>
<li><a href='#FPE'><p>Final Prediction Error Criterion</p></a></li>
<li><a href='#FPE.varlse'><p>Final Prediction Error Criterion of Multivariate Time Series Model</p></a></li>
<li><a href='#fromse'><p>Evaluate the Estimation Based on Frobenius Norm</p></a></li>
<li><a href='#geom_eval'><p>Adding Test Data Layer</p></a></li>
<li><a href='#gg_loss'><p>Compare Lists of Models</p></a></li>
<li><a href='#horseshoe_bvar_algo'><p>Horseshoe Prior in BVAR</p></a></li>
<li><a href='#HQ'><p>Hannan-Quinn Criterion</p></a></li>
<li><a href='#HQ.varlse'><p>Hannan-Quinn Criterion of Multivariate Time Series Model</p></a></li>
<li><a href='#init_ssvs'><p>Initial Parameters of Stochastic Search Variable Selection (SSVS) Model</p></a></li>
<li><a href='#is.stable'><p>Stability of the process</p></a></li>
<li><a href='#is.stable.varlse'><p>Stability of VAR Coefficient Matrix</p></a></li>
<li><a href='#is.varlse'><p>See if the Object a class in this package</p></a></li>
<li><a href='#logLik.varlse'><p>Extract Log-Likelihood of Multivariate Time Series Model</p></a></li>
<li><a href='#lpl'><p>Evaluate the Model Based on Log Predictive Likelihood</p></a></li>
<li><a href='#mae'><p>Evaluate the Model Based on MAE (Mean Absolute Error)</p></a></li>
<li><a href='#mape'><p>Evaluate the Model Based on MAPE (Mean Absolute Percentage Error)</p></a></li>
<li><a href='#mase'><p>Evaluate the Model Based on MASE (Mean Absolute Scaled Error)</p></a></li>
<li><a href='#mrae'><p>Evaluate the Model Based on MRAE (Mean Relative Absolute Error)</p></a></li>
<li><a href='#mse'><p>Evaluate the Model Based on MSE (Mean Square Error)</p></a></li>
<li><a href='#oxfordman'><p>Oxford-Man Institute Realized Library</p></a></li>
<li><a href='#predict.varlse'><p>Forecasting Multivariate Time Series</p></a></li>
<li><a href='#print.summary.bvharsp'><p>Summarizing BVAR and BVHAR with Shrinkage Priors</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#relmae'><p>Evaluate the Model Based on RelMAE (Relative MAE)</p></a></li>
<li><a href='#relspne'><p>Evaluate the Estimation Based on Relative Spectral Norm Error</p></a></li>
<li><a href='#residuals.varlse'><p>Residual Matrix from Multivariate Time Series Models</p></a></li>
<li><a href='#rmafe'><p>Evaluate the Model Based on RMAFE</p></a></li>
<li><a href='#rmape'><p>Evaluate the Model Based on RMAPE (Relative MAPE)</p></a></li>
<li><a href='#rmase'><p>Evaluate the Model Based on RMASE (Relative MASE)</p></a></li>
<li><a href='#rmsfe'><p>Evaluate the Model Based on RMSFE</p></a></li>
<li><a href='#set_bvar'><p>Hyperparameters for Bayesian Models</p></a></li>
<li><a href='#set_horseshoe'><p>Horseshoe Prior Specification</p></a></li>
<li><a href='#set_intercept'><p>Prior for Constant Term</p></a></li>
<li><a href='#set_lambda'><p>Hyperpriors for Bayesian Models</p></a></li>
<li><a href='#set_ssvs'><p>Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor</p></a></li>
<li><a href='#set_sv'><p>Stochastic Volatility Specification</p></a></li>
<li><a href='#sim_horseshoe_var'><p>Generate Horseshoe Parameters</p></a></li>
<li><a href='#sim_iw'><p>Generate Inverse-Wishart Random Matrix</p></a></li>
<li><a href='#sim_matgaussian'><p>Generate Matrix Normal Random Matrix</p></a></li>
<li><a href='#sim_mncoef'><p>Generate Minnesota BVAR Parameters</p></a></li>
<li><a href='#sim_mniw'><p>Generate Normal-IW Random Family</p></a></li>
<li><a href='#sim_mnormal'><p>Generate Multivariate Normal Random Vector</p></a></li>
<li><a href='#sim_mnvhar_coef'><p>Generate Minnesota BVAR Parameters</p></a></li>
<li><a href='#sim_mvt'><p>Generate Multivariate t Random Vector</p></a></li>
<li><a href='#sim_ssvs_var'><p>Generate SSVS Parameters</p></a></li>
<li><a href='#sim_var'><p>Generate Multivariate Time Series Process Following VAR(p)</p></a></li>
<li><a href='#sim_vhar'><p>Generate Multivariate Time Series Process Following VAR(p)</p></a></li>
<li><a href='#split_coef'><p>Splitting Coefficient Matrix into List</p></a></li>
<li><a href='#spne'><p>Evaluate the Estimation Based on Spectral Norm Error</p></a></li>
<li><a href='#ssvs_bvar_algo'><p>Stochastic Search Variable Selection in VAR</p></a></li>
<li><a href='#ssvs_bvhar_algo'><p>Stochastic Search Variable Selection in VHAR</p></a></li>
<li><a href='#stableroot'><p>Roots of characteristic polynomial</p></a></li>
<li><a href='#stableroot.varlse'><p>Characteristic polynomial roots for VAR Coefficient Matrix</p></a></li>
<li><a href='#summary.normaliw'><p>Summarizing Bayesian Multivariate Time Series Model</p></a></li>
<li><a href='#summary.varlse'><p>Summarizing Vector Autoregressive Model</p></a></li>
<li><a href='#summary.vharlse'><p>Summarizing Vector HAR Model</p></a></li>
<li><a href='#ts_forecasting_cv'><p>Time Series Cross-Validation</p></a></li>
<li><a href='#var_design_formulation'><p>Ordinary Least Squares Model Formulation</p></a></li>
<li><a href='#var_lm'><p>Fitting Vector Autoregressive Model of Order p Model</p></a></li>
<li><a href='#var_vec_formulation'><p>Vectorized OLS Formulation</p></a></li>
<li><a href='#VARtoVMA'><p>Convert VAR to VMA(infinite)</p></a></li>
<li><a href='#vhar_lm'><p>Fitting Vector Heterogeneous Autoregressive Model</p></a></li>
<li><a href='#VHARtoVMA'><p>Convert VHAR to VMA(infinite)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Vector Heterogeneous Autoregressive Modeling</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools to research Bayesian Vector heterogeneous autoregressive (VHAR) model,
    referring to Kim &amp; Baek (2023) (&lt;<a href="https://doi.org/10.1080%2F00949655.2023.2281644">doi:10.1080/00949655.2023.2281644</a>&gt;).
    'bvhar' can model Vector Autoregressive (VAR), VHAR, Bayesian VAR (BVAR), and Bayesian VHAR (BVHAR) models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://ygeunkim.github.io/package/bvhar/">https://ygeunkim.github.io/package/bvhar/</a>,
<a href="https://github.com/ygeunkim/bvhar">https://github.com/ygeunkim/bvhar</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ygeunkim/bvhar/issues">https://github.com/ygeunkim/bvhar/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, knitr, parallel, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>lifecycle, magrittr, Rcpp, ggplot2, tidyr, tibble, dplyr,
foreach, purrr, stats, optimParallel, posterior, bayesplot</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH, Rcpp, RcppEigen(&ge; 0.3.4.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-01 13:23:58 UTC; ygeunmini</td>
</tr>
<tr>
<td>Author:</td>
<td>Young Geun Kim <a href="https://orcid.org/0000-0001-8651-1167"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Changryong Baek [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Young Geun Kim &lt;ygeunkimstat@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-01 14:22:37 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling <code>rhs(lhs)</code>.
</p>

<hr>
<h2 id='AIC.varlse'>Akaike's Information Criterion of Multivariate Time Series Model</h2><span id='topic+AIC.varlse'></span><span id='topic+AIC.vharlse'></span><span id='topic+AIC.bvarmn'></span><span id='topic+AIC.bvarflat'></span><span id='topic+AIC.bvharmn'></span>

<h3>Description</h3>

<p>Compute AIC of VAR(p), VHAR, BVAR(p), and BVHAR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
AIC(object, ...)

## S3 method for class 'vharlse'
AIC(object, ...)

## S3 method for class 'bvarmn'
AIC(object, ...)

## S3 method for class 'bvarflat'
AIC(object, ...)

## S3 method for class 'bvharmn'
AIC(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AIC.varlse_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="AIC.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\tilde{\Sigma}_e</code> be the MLE
and let <code class="reqn">\hat{\Sigma}_e</code> be the unbiased estimator (<code>covmat</code>) for <code class="reqn">\Sigma_e</code>.
Note that
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\Sigma}_e = \frac{s - k}{s} \hat{\Sigma}_e</code>
</p>

<p>Then
</p>
<p style="text-align: center;"><code class="reqn">AIC(p) = \log \det \Sigma_e + \frac{2}{s}(\text{number of freely estimated parameters})</code>
</p>

<p>where the number of freely estimated parameters is <code class="reqn">mk</code>, i.e. <code class="reqn">pm^2</code> or <code class="reqn">pm^2 + m</code>.
</p>


<h3>Value</h3>

<p>AIC value.
</p>


<h3>References</h3>

<p>Akaike, H. (1969). <em>Fitting autoregressive models for prediction</em>. Ann Inst Stat Math 21, 243–247.
</p>
<p>Akaike, H. (1971). <em>Autoregressive model fitting for control</em>. Ann Inst Stat Math 23, 163–180.
</p>
<p>Akaike H. (1974). <em>A new look at the statistical model identification</em>. IEEE Transactions on Automatic Control, vol. 19, no. 6, pp. 716-723.
</p>
<p>Akaike H. (1998). <em>Information Theory and an Extension of the Maximum Likelihood Principle</em>. In: Parzen E., Tanabe K., Kitagawa G. (eds) Selected Papers of Hirotugu Akaike. Springer Series in Statistics (Perspectives in Statistics). Springer, New York, NY.
</p>
<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='analyze_ir.varlse'>Impulse Response Analysis</h2><span id='topic+analyze_ir.varlse'></span><span id='topic+analyze_ir.vharlse'></span><span id='topic+print.bvharirf'></span><span id='topic+analyze_ir'></span><span id='topic+knit_print.bvharirf'></span>

<h3>Description</h3>

<p>Computes responses to impulses or orthogonal impulses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
analyze_ir(
  object,
  lag_max = 10,
  orthogonal = TRUE,
  impulse_var,
  response_var,
  ...
)

## S3 method for class 'vharlse'
analyze_ir(
  object,
  lag_max = 10,
  orthogonal = TRUE,
  impulse_var,
  response_var,
  ...
)

## S3 method for class 'bvharirf'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

analyze_ir(object, lag_max, orthogonal, impulse_var, response_var, ...)

## S3 method for class 'bvharirf'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="analyze_ir.varlse_+3A_object">object</code></td>
<td>
<p>Model object</p>
</td></tr>
<tr><td><code id="analyze_ir.varlse_+3A_lag_max">lag_max</code></td>
<td>
<p>Maximum lag to investigate the impulse responses (By default, <code>10</code>)</p>
</td></tr>
<tr><td><code id="analyze_ir.varlse_+3A_orthogonal">orthogonal</code></td>
<td>
<p>Orthogonal impulses (<code>TRUE</code>) or just impulses (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="analyze_ir.varlse_+3A_impulse_var">impulse_var</code></td>
<td>
<p>Impulse variables character vector. If not specified, use every variable.</p>
</td></tr>
<tr><td><code id="analyze_ir.varlse_+3A_response_var">response_var</code></td>
<td>
<p>Response variables character vector. If not specified, use every variable.</p>
</td></tr>
<tr><td><code id="analyze_ir.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="analyze_ir.varlse_+3A_x">x</code></td>
<td>
<p><code>bvharirf</code> object</p>
</td></tr>
<tr><td><code id="analyze_ir.varlse_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>bvharirf</code> <a href="base.html#topic+class">class</a>
</p>


<h3>Responses to forecast errors</h3>

<p>If <code>orthogonal = FALSE</code>, the function gives <code class="reqn">W_j</code> VMA representation of the process such that
</p>
<p style="text-align: center;"><code class="reqn">Y_t = \sum_{j = 0}^\infty W_j \epsilon_{t - j}</code>
</p>



<h3>Responses to orthogonal impulses</h3>

<p>If <code>orthogonal = TRUE</code>, it gives orthogonalized VMA representation </p>
<p style="text-align: center;"><code class="reqn">\Theta</code>
</p>
<p>.
Based on variance decomposition (Cholesky decomposition)
</p>
<p style="text-align: center;"><code class="reqn">\Sigma = P P^T</code>
</p>

<p>where <code class="reqn">P</code> is lower triangular matrix,
impulse response analysis if performed under MA representation
</p>
<p style="text-align: center;"><code class="reqn">y_t = \sum_{i = 0}^\infty \Theta_i v_{t - i}</code>
</p>

<p>Here,
</p>
<p style="text-align: center;"><code class="reqn">\Theta_i = W_i P</code>
</p>

<p>and <code class="reqn">v_t = P^{-1} \epsilon_t</code> are orthogonal.
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VARtoVMA">VARtoVMA()</a></code>
</p>
<p><code><a href="#topic+VHARtoVMA">VHARtoVMA()</a></code>
</p>

<hr>
<h2 id='autoplot.bvharirf'>Plot Impulse Responses</h2><span id='topic+autoplot.bvharirf'></span>

<h3>Description</h3>

<p>Draw impulse responses of response ~ impulse in the facet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bvharirf'
autoplot(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.bvharirf_+3A_object">object</code></td>
<td>
<p><code>bvharirf</code> object</p>
</td></tr>
<tr><td><code id="autoplot.bvharirf_+3A_...">...</code></td>
<td>
<p>Other arguments passed on the <code><a href="ggplot2.html#topic+geom_path">ggplot2::geom_path()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object
</p>


<h3>See Also</h3>

<p><code><a href="#topic+analyze_ir">analyze_ir()</a></code>
</p>

<hr>
<h2 id='autoplot.bvharsp'>Plot the Result of BVAR and BVHAR MCMC</h2><span id='topic+autoplot.bvharsp'></span>

<h3>Description</h3>

<p>Draw BVAR and BVHAR MCMC plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bvharsp'
autoplot(
  object,
  type = c("coef", "trace", "dens", "area"),
  pars = character(),
  regex_pars = character(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.bvharsp_+3A_object">object</code></td>
<td>
<p><code>bvharsp</code> object</p>
</td></tr>
<tr><td><code id="autoplot.bvharsp_+3A_type">type</code></td>
<td>
<p>The type of the plot. Posterior coefficient (<code>"coef"</code>), Trace plot (<code>"trace"</code>), kernel density plot (<code>"dens"</code>), and interval estimates plot (<code>"area"</code>).</p>
</td></tr>
<tr><td><code id="autoplot.bvharsp_+3A_pars">pars</code></td>
<td>
<p>Parameter names to draw.</p>
</td></tr>
<tr><td><code id="autoplot.bvharsp_+3A_regex_pars">regex_pars</code></td>
<td>
<p>Regular expression parameter names to draw.</p>
</td></tr>
<tr><td><code id="autoplot.bvharsp_+3A_...">...</code></td>
<td>
<p>Other options for each <code><a href="bayesplot.html#topic+MCMC-traces">bayesplot::mcmc_trace()</a></code>, <code><a href="bayesplot.html#topic+MCMC-distributions">bayesplot::mcmc_dens()</a></code>, and <code><a href="bayesplot.html#topic+MCMC-intervals">bayesplot::mcmc_areas()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object
</p>

<hr>
<h2 id='autoplot.normaliw'>Residual Plot for Minnesota Prior VAR Model</h2><span id='topic+autoplot.normaliw'></span>

<h3>Description</h3>

<p>This function draws residual plot for covariance matrix of Minnesota prior VAR model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'normaliw'
autoplot(object, hcol = "grey", hsize = 1.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.normaliw_+3A_object">object</code></td>
<td>
<p><code>normaliw</code> object</p>
</td></tr>
<tr><td><code id="autoplot.normaliw_+3A_hcol">hcol</code></td>
<td>
<p>color of horizontal line = 0 (By default, grey)</p>
</td></tr>
<tr><td><code id="autoplot.normaliw_+3A_hsize">hsize</code></td>
<td>
<p>size of horizontal line = 0 (By default, 1.5)</p>
</td></tr>
<tr><td><code id="autoplot.normaliw_+3A_...">...</code></td>
<td>
<p>additional options for geom_point</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object
</p>

<hr>
<h2 id='autoplot.predbvhar'>Plot Forecast Result</h2><span id='topic+autoplot.predbvhar'></span><span id='topic+autolayer.predbvhar'></span>

<h3>Description</h3>

<p>Plots the forecasting result with forecast regions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predbvhar'
autoplot(
  object,
  type = c("grid", "wrap"),
  ci_alpha = 0.7,
  alpha_scale = 0.3,
  x_cut = 1,
  viridis = FALSE,
  viridis_option = "D",
  NROW = NULL,
  NCOL = NULL,
  ...
)

## S3 method for class 'predbvhar'
autolayer(object, ci_fill = "grey70", ci_alpha = 0.5, alpha_scale = 0.3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.predbvhar_+3A_object">object</code></td>
<td>
<p><code>predbvhar</code> object</p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_type">type</code></td>
<td>
<p>Divide variables using <code><a href="ggplot2.html#topic+facet_grid">ggplot2::facet_grid()</a></code> (&quot;grid&quot;: default) or <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code> (&quot;wrap&quot;)</p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_ci_alpha">ci_alpha</code></td>
<td>
<p>Transparency of CI</p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_alpha_scale">alpha_scale</code></td>
<td>
<p>Scale of transparency parameter (<code>alpha</code>) between the two layers. <code>alpha</code> of CI ribbon = <code>alpha_scale</code> * <code>alpha</code> of path (By default, .5)</p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_x_cut">x_cut</code></td>
<td>
<p>plot x axes from <code>x_cut</code> for visibility</p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_viridis">viridis</code></td>
<td>
<p>If <code>TRUE</code>, scale CI and forecast line using <code><a href="ggplot2.html#topic+scale_viridis">ggplot2::scale_fill_viridis_d()</a></code> and <a href="ggplot2.html#topic+scale_viridis">ggplot2::scale_colour_viridis_d</a>, respectively.</p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_viridis_option">viridis_option</code></td>
<td>
<p>Option for viridis string. See <code>option</code> of <a href="ggplot2.html#topic+scale_viridis">ggplot2::scale_colour_viridis_d</a>. Choose one of <code>c("A", "B", "C", "D", "E")</code>. By default, <code>"D"</code>.</p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_nrow">NROW</code></td>
<td>
<p><code>nrow</code> of <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code></p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_ncol">NCOL</code></td>
<td>
<p><code>ncol</code> of <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code></p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_...">...</code></td>
<td>
<p>additional option for <code><a href="ggplot2.html#topic+geom_path">ggplot2::geom_path()</a></code></p>
</td></tr>
<tr><td><code id="autoplot.predbvhar_+3A_ci_fill">ci_fill</code></td>
<td>
<p>color of CI</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object
</p>
<p>A ggplot layer
</p>

<hr>
<h2 id='autoplot.summary.bvharsp'>Plot the Heatmap of SSVS Coefficients</h2><span id='topic+autoplot.summary.bvharsp'></span>

<h3>Description</h3>

<p>Draw heatmap for SSVS prior coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.bvharsp'
autoplot(object, point = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.summary.bvharsp_+3A_object">object</code></td>
<td>
<p><code>summary.bvharsp</code> object</p>
</td></tr>
<tr><td><code id="autoplot.summary.bvharsp_+3A_point">point</code></td>
<td>
<p>Use point for sparsity representation</p>
</td></tr>
<tr><td><code id="autoplot.summary.bvharsp_+3A_...">...</code></td>
<td>
<p>Other arguments passed on the <code><a href="ggplot2.html#topic+geom_tile">ggplot2::geom_tile()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object
</p>

<hr>
<h2 id='autoplot.summary.normaliw'>Density Plot for Minnesota Prior VAR Model</h2><span id='topic+autoplot.summary.normaliw'></span>

<h3>Description</h3>

<p>This function draws density plot for coefficient matrices of Minnesota prior VAR model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.normaliw'
autoplot(
  object,
  type = c("trace", "dens", "area"),
  pars = character(),
  regex_pars = character(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.summary.normaliw_+3A_object">object</code></td>
<td>
<p><code>summary.normaliw</code> object</p>
</td></tr>
<tr><td><code id="autoplot.summary.normaliw_+3A_type">type</code></td>
<td>
<p>The type of the plot. Trace plot (<code>"trace"</code>), kernel density plot (<code>"dens"</code>), and interval estimates plot (<code>"area"</code>).</p>
</td></tr>
<tr><td><code id="autoplot.summary.normaliw_+3A_pars">pars</code></td>
<td>
<p>Parameter names to draw.</p>
</td></tr>
<tr><td><code id="autoplot.summary.normaliw_+3A_regex_pars">regex_pars</code></td>
<td>
<p>Regular expression parameter names to draw.</p>
</td></tr>
<tr><td><code id="autoplot.summary.normaliw_+3A_...">...</code></td>
<td>
<p>Other options for each <code><a href="bayesplot.html#topic+MCMC-traces">bayesplot::mcmc_trace()</a></code>, <code><a href="bayesplot.html#topic+MCMC-distributions">bayesplot::mcmc_dens()</a></code>, and <code><a href="bayesplot.html#topic+MCMC-intervals">bayesplot::mcmc_areas()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object
</p>

<hr>
<h2 id='BIC.varlse'>Bayesian Information Criterion of Multivariate Time Series Model</h2><span id='topic+BIC.varlse'></span><span id='topic+BIC.vharlse'></span><span id='topic+BIC.bvarmn'></span><span id='topic+BIC.bvarflat'></span><span id='topic+BIC.bvharmn'></span>

<h3>Description</h3>

<p>Compute BIC of VAR(p), VHAR, BVAR(p), and BVHAR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
BIC(object, ...)

## S3 method for class 'vharlse'
BIC(object, ...)

## S3 method for class 'bvarmn'
BIC(object, ...)

## S3 method for class 'bvarflat'
BIC(object, ...)

## S3 method for class 'bvharmn'
BIC(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BIC.varlse_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="BIC.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\tilde{\Sigma}_e</code> be the MLE
and let <code class="reqn">\hat{\Sigma}_e</code> be the unbiased estimator (<code>covmat</code>) for <code class="reqn">\Sigma_e</code>.
Note that
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\Sigma}_e = \frac{s - k}{n} \hat{\Sigma}_e</code>
</p>

<p>Then
</p>
<p style="text-align: center;"><code class="reqn">BIC(p) = \log \det \Sigma_e + \frac{\log s}{s}(\text{number of freely estimated parameters})</code>
</p>

<p>where the number of freely estimated parameters is <code class="reqn">pm^2</code>.
</p>


<h3>Value</h3>

<p>BIC value.
</p>


<h3>References</h3>

<p>Gideon Schwarz. (1978). <em>Estimating the Dimension of a Model</em>. Ann. Statist. 6 (2) 461 - 464.
</p>
<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='bound_bvhar'>Setting Empirical Bayes Optimization Bounds</h2><span id='topic+bound_bvhar'></span><span id='topic+print.boundbvharemp'></span><span id='topic+knit_print.boundbvharemp'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> This function sets lower and upper bounds for <code><a href="#topic+set_bvar">set_bvar()</a></code>, <code><a href="#topic+set_bvhar">set_bvhar()</a></code>, or <code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bound_bvhar(
  init_spec = set_bvhar(),
  lower_spec = set_bvhar(),
  upper_spec = set_bvhar()
)

## S3 method for class 'boundbvharemp'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'boundbvharemp'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bound_bvhar_+3A_init_spec">init_spec</code></td>
<td>
<p>Initial Bayes model specification</p>
</td></tr>
<tr><td><code id="bound_bvhar_+3A_lower_spec">lower_spec</code></td>
<td>
<p>Lower bound Bayes model specification</p>
</td></tr>
<tr><td><code id="bound_bvhar_+3A_upper_spec">upper_spec</code></td>
<td>
<p>Upper bound Bayes model specification</p>
</td></tr>
<tr><td><code id="bound_bvhar_+3A_x">x</code></td>
<td>
<p><code>boundbvharemp</code> object</p>
</td></tr>
<tr><td><code id="bound_bvhar_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bound_bvhar_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>boundbvharemp</code> <a href="base.html#topic+class">class</a>
</p>

<hr>
<h2 id='bvar_adding_dummy'>Adding Dummy Observations</h2><span id='topic+bvar_adding_dummy'></span>

<h3>Description</h3>

<p>This page notes how to define dummy observation matrices in Bayesian VAR and VHAR models.
</p>


<h3>Bayesian VAR</h3>

<p>Consider BVAR and its hyperparameters in <code><a href="#topic+set_bvar">set_bvar()</a></code>.
</p>

<ul>
<li> <p><code>sigma</code>: <code class="reqn">\sigma_1, \ldots, \sigma_m</code>
</p>
</li>
<li> <p><code>lambda</code>: <code class="reqn">\lambda</code>
</p>
</li>
<li> <p><code>delta</code>: <code class="reqn">\delta_1, \ldots, \delta_m</code>
</p>
</li>
<li> <p><code>eps</code>: <code class="reqn">\epsilon</code>
</p>
</li></ul>

<p>This package implements adding-dummy-observations approach of Bańbura et al. (2010).
Let <code class="reqn">J_p = diag(1, 2, \ldots, p)</code>.
For each response and design matrix <code class="reqn">Y_0</code> and <code class="reqn">X_0</code>, we define dummy observation named by <code class="reqn">Y_p</code> and <code class="reqn">X_p</code>.
Response dummy matrix <code class="reqn">Y_p</code> is (m + k) x m matrix:
</p>
<p style="text-align: center;"><code class="reqn">
  Y_p = \left[\begin{array}{c}
diag\left( \delta_1 \sigma_1, \ldots, \delta_m \sigma_m \right) / \lambda \\
0_{m(p - 1) \times m} \\ \hline
diag\left( \sigma_1, \ldots, \sigma_m \right) \\ \hline
0_m^\intercal
\end{array}\right]
</code>
</p>

<p>Design dummy matrix <code class="reqn">X_p</code> is (m + k) x k matrix:
</p>
<p style="text-align: center;"><code class="reqn">
  X_p = \left[\begin{array}{c|c}
J_p \otimes diag\left( \sigma_1, \ldots, \sigma_m \right) / \lambda &amp; 0_{mp} \\ \hline
0_{m \times mp} &amp; 0_m \\ \hline
0_{mp}^\intercal &amp; \epsilon
\end{array}\right]
</code>
</p>

<p>These two matrices define Minnesota prior distribution of BVAR.
</p>


<h3>Bayesian VHAR</h3>

<p>Consider BVHAR and its hyperparameter in <code><a href="#topic+set_bvhar">set_bvhar()</a></code>.
First, VAR-type minnesota prior:
</p>

<ul>
<li> <p><code>sigma</code>: <code class="reqn">\sigma_1, \ldots, \sigma_m</code>
</p>
</li>
<li> <p><code>lambda</code>: <code class="reqn">\lambda</code>
</p>
</li>
<li> <p><code>delta</code>: <code class="reqn">\delta_1, \ldots, \delta_m</code>
</p>
</li>
<li> <p><code>eps</code>: <code class="reqn">\epsilon</code>
For response matrix <code class="reqn">Y_0</code>, define (m + h) x m matrix <code class="reqn">Y_{HAR}</code>
</p>
<p style="text-align: center;"><code class="reqn">
  Y_{HAR} = \left[\begin{array}{c}
  diag\left( \delta_1 \sigma_1, \ldots, \delta_m \sigma_m \right) / \lambda \\
  0_{2m \times m} \\ \hline
  diag\left( \sigma_1, \ldots, \sigma_m \right) \\ \hline
  0_m^\intercal
\end{array}\right]
</code>
</p>

<p>For design matrix <code class="reqn">X_0</code>, define (m + h) x h matrix <code class="reqn">X_{HAR}</code>
</p>
<p style="text-align: center;"><code class="reqn">
  X_{HAR} = \left[\begin{array}{c|c}
  J_3 \otimes diag\left( \sigma_1, \ldots, \sigma_m \right) / \lambda &amp; 0_{3m} \\ \hline
  0_{m \times 3m} &amp; 0_m \\ \hline
  0_{3m}^\intercal &amp; \epsilon
\end{array}\right]
</code>
</p>

<p>In case of VHAR-type minnesota prior, <code>delta</code> is replaced with the following three:
</p>
</li>
<li> <p><code>daily</code>: <code class="reqn">d_1, \ldots, d_m</code>
</p>
</li>
<li> <p><code>weekly</code>: <code class="reqn">w_1, \ldots, w_m</code>
</p>
</li>
<li> <p><code>monthly</code>: <code class="reqn">m_1, \ldots, m_m</code>
and <code class="reqn">Y_{HAR}</code> is changed.
</p>
<p style="text-align: center;"><code class="reqn">
  Y_{HAR} = \left[\begin{array}{c}
  diag\left( d_1 \sigma_1, \ldots, d_m \sigma_m \right) / \lambda \\
  diag\left( w_1 \sigma_1, \ldots, w_m \sigma_m \right) / \lambda \\
  diag\left( m_1 \sigma_1, \ldots, m_m \sigma_m \right) / \lambda \\ \hline
  diag\left( \sigma_1, \ldots, \sigma_m \right) \\ \hline
  0_m^\intercal
\end{array}\right]
</code>
</p>

</li></ul>

<p>These two dummy matrices define minnesota prior distribution of BVHAR.
</p>


<h3>References</h3>

<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>

<hr>
<h2 id='bvar_flat'>Fitting Bayesian VAR(p) of Flat Prior</h2><span id='topic+bvar_flat'></span><span id='topic+print.bvarflat'></span><span id='topic+knit_print.bvarflat'></span>

<h3>Description</h3>

<p>This function fits BVAR(p) with flat prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvar_flat(y, p, bayes_spec = set_bvar_flat(), include_mean = TRUE)

## S3 method for class 'bvarflat'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvarflat'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvar_flat_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvar_flat_+3A_p">p</code></td>
<td>
<p>VAR lag</p>
</td></tr>
<tr><td><code id="bvar_flat_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A BVAR model specification by <code><a href="#topic+set_bvar_flat">set_bvar_flat()</a></code>.</p>
</td></tr>
<tr><td><code id="bvar_flat_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvar_flat_+3A_x">x</code></td>
<td>
<p><code>bvarflat</code> object</p>
</td></tr>
<tr><td><code id="bvar_flat_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvar_flat_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ghosh et al. (2018) gives flat prior for residual matrix in BVAR.
</p>
<p>Under this setting, there are many models such as hierarchical or non-hierarchical.
This function chooses the most simple non-hierarchical matrix normal prior in Section 3.1.
</p>
<p style="text-align: center;"><code class="reqn">A \mid \Sigma_e \sim MN(0, U^{-1}, \Sigma_e)</code>
</p>

<p>where U: precision matrix (MN: <a href="https://en.wikipedia.org/wiki/Matrix_normal_distribution">matrix normal</a>).
</p>
<p style="text-align: center;"><code class="reqn">p (\Sigma_e) \propto 1</code>
</p>



<h3>Value</h3>

<p><code>bvar_flat()</code> returns an object <code>bvarflat</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>coefficients</dt><dd><p>Posterior Mean matrix of Matrix Normal distribution</p>
</dd>
<dt>fitted.values</dt><dd><p>Fitted values</p>
</dd>
<dt>residuals</dt><dd><p>Residuals</p>
</dd>
<dt>mn_prec</dt><dd><p>Posterior precision matrix of Matrix Normal distribution</p>
</dd>
<dt>iw_scale</dt><dd><p>Posterior scale matrix of posterior inverse-wishart distribution</p>
</dd>
<dt>iw_shape</dt><dd><p>Posterior shape of inverse-wishart distribution</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: mp + 1 or mp</p>
</dd>
<dt>p</dt><dd><p>Lag of VAR</p>
</dd>
<dt>m</dt><dd><p>Dimension of the time series</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>process</dt><dd><p>Process string in the <code>bayes_spec</code>: <code>"BVAR_Flat"</code></p>
</dd>
<dt>spec</dt><dd><p>Model specification (<code>bvharspec</code>)</p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>prior_mean</dt><dd><p>Prior mean matrix of Matrix Normal distribution: zero matrix</p>
</dd>
<dt>prior_precision</dt><dd><p>Prior precision matrix of Matrix Normal distribution: <code class="reqn">U^{-1}</code></p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input (<code>matrix</code>)</p>
</dd>
</dl>



<h3>References</h3>

<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>
<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+set_bvar_flat">set_bvar_flat()</a></code> to specify the hyperparameters of BVAR flat prior.
</p>
</li>
<li> <p><code><a href="#topic+coef.bvarflat">coef.bvarflat()</a></code>, <code><a href="#topic+residuals.bvarflat">residuals.bvarflat()</a></code>, and <code><a href="#topic+fitted.bvarflat">fitted.bvarflat()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+predict.bvarflat">predict.bvarflat()</a></code> to forecast the BVHAR process
</p>
</li></ul>


<hr>
<h2 id='bvar_horseshoe'>Fitting Bayesian VAR(p) of Horseshoe Prior</h2><span id='topic+bvar_horseshoe'></span><span id='topic+print.bvarhs'></span><span id='topic+knit_print.bvarhs'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> This function fits BVAR(p) with horseshoe prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvar_horseshoe(
  y,
  p,
  num_chains = 1,
  num_iter = 1000,
  num_burn = floor(num_iter/2),
  thinning = 1,
  bayes_spec = set_horseshoe(),
  include_mean = TRUE,
  minnesota = FALSE,
  algo = c("block", "gibbs"),
  verbose = FALSE,
  num_thread = 1
)

## S3 method for class 'bvarhs'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvarhs'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvar_horseshoe_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_p">p</code></td>
<td>
<p>VAR lag</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_num_chains">num_chains</code></td>
<td>
<p>Number of MCMC chains</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_num_iter">num_iter</code></td>
<td>
<p>MCMC iteration number</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in (warm-up). Half of the iteration is the default choice.</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_thinning">thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>Horseshoe initialization specification by <code><a href="#topic+set_horseshoe">set_horseshoe()</a></code>.</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_minnesota">minnesota</code></td>
<td>
<p>Minnesota type</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_algo">algo</code></td>
<td>
<p>Ordinary gibbs sampling (<code>"gibbs"</code>) or blocked gibbs (Default: <code>"block"</code>).</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_verbose">verbose</code></td>
<td>
<p>Print the progress bar in the console. By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_num_thread">num_thread</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Number of threads</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_x">x</code></td>
<td>
<p><code>bvarhs</code> object</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvar_horseshoe_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>bvar_horseshoe</code> returns an object named <code>bvarhs</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>alpha_record</dt><dd><p>MCMC trace for vectorized coefficients (alpha <code class="reqn">\alpha</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>lambda_record</dt><dd><p>MCMC trace for local shrinkage level (lambda <code class="reqn">\lambda</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>tau_record</dt><dd><p>MCMC trace for global shrinkage level (tau <code class="reqn">\tau</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>psi_record</dt><dd><p>MCMC trace for precision matrix (psi <code class="reqn">\Psi</code>) with <a href="base.html#topic+list">list</a> format.</p>
</dd>
<dt>chain</dt><dd><p>The numer of chains</p>
</dd>
<dt>coefficients</dt><dd><p>Posterior mean of VAR coefficients.</p>
</dd>
<dt>psi_posterior</dt><dd><p>Posterior mean of precision matrix <code class="reqn">\Psi</code></p>
</dd>
<dt>covmat</dt><dd><p>Posterior mean of covariance matrix</p>
</dd>
<dt>omega_record</dt><dd><p>MCMC trace for diagonal element of <code class="reqn">\Psi</code> (omega) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>eta_record</dt><dd><p>MCMC trace for upper triangular element of <code class="reqn">\Psi</code> (eta) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>param</dt><dd><p><a href="posterior.html#topic+draws_df">posterior::draws_df</a> with every variable: alpha, lambda, tau, omega, and eta</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: <code>mp + 1</code> or <code>mp</code></p>
</dd>
<dt>p</dt><dd><p>Lag of VAR</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Description of the model, e.g. <code>"VAR_Horseshoe"</code></p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>algo</dt><dd><p>Usual Gibbs sampling (<code>"gibbs"</code>) or fast sampling (<code>"fast"</code>)</p>
</dd>
<dt>spec</dt><dd><p>Horseshoe specification defined by <code><a href="#topic+set_horseshoe">set_horseshoe()</a></code></p>
</dd>
<dt>iter</dt><dd><p>Total iterations</p>
</dd>
<dt>burn</dt><dd><p>Burn-in</p>
</dd>
<dt>thin</dt><dd><p>Thinning</p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>



<h3>References</h3>

<p>Carvalho, C. M., Polson, N. G., &amp; Scott, J. G. (2010). <em>The horseshoe estimator for sparse signals</em>. Biometrika, 97(2), 465–480.
</p>
<p>Makalic, E., &amp; Schmidt, D. F. (2016). <em>A Simple Sampler for the Horseshoe Estimator</em>. IEEE Signal Processing Letters, 23(1), 179–182.
</p>

<hr>
<h2 id='bvar_minnesota'>Fitting Bayesian VAR(p) of Minnesota Prior</h2><span id='topic+bvar_minnesota'></span><span id='topic+print.bvarmn'></span><span id='topic+knit_print.bvarmn'></span>

<h3>Description</h3>

<p>This function fits BVAR(p) with Minnesota prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvar_minnesota(y, p = 1, bayes_spec = set_bvar(), include_mean = TRUE)

## S3 method for class 'bvarmn'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvarmn'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvar_minnesota_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvar_minnesota_+3A_p">p</code></td>
<td>
<p>VAR lag (Default: 1)</p>
</td></tr>
<tr><td><code id="bvar_minnesota_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A BVAR model specification by <code><a href="#topic+set_bvar">set_bvar()</a></code>.</p>
</td></tr>
<tr><td><code id="bvar_minnesota_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvar_minnesota_+3A_x">x</code></td>
<td>
<p><code>bvarmn</code> object</p>
</td></tr>
<tr><td><code id="bvar_minnesota_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvar_minnesota_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Minnesota prior gives prior to parameters <code class="reqn">A</code> (VAR matrices) and <code class="reqn">\Sigma_e</code> (residual covariance).
</p>
<p style="text-align: center;"><code class="reqn">A \mid \Sigma_e \sim MN(A_0, \Omega_0, \Sigma_e)</code>
</p>

<p style="text-align: center;"><code class="reqn">\Sigma_e \sim IW(S_0, \alpha_0)</code>
</p>

<p>(MN: <a href="https://en.wikipedia.org/wiki/Matrix_normal_distribution">matrix normal</a>, IW: <a href="https://en.wikipedia.org/wiki/Inverse-Wishart_distribution">inverse-wishart</a>)
</p>


<h3>Value</h3>

<p><code>bvar_minnesota()</code> returns an object <code>bvarmn</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>coefficients</dt><dd><p>Posterior Mean matrix of Matrix Normal distribution</p>
</dd>
<dt>fitted.values</dt><dd><p>Fitted values</p>
</dd>
<dt>residuals</dt><dd><p>Residuals</p>
</dd>
<dt>mn_prec</dt><dd><p>Posterior precision matrix of Matrix Normal distribution</p>
</dd>
<dt>iw_scale</dt><dd><p>Posterior scale matrix of posterior inverse-Wishart distribution</p>
</dd>
<dt>iw_shape</dt><dd><p>Posterior shape of inverse-Wishart distribution (<code class="reqn">alpha_0</code> - obs + 2). <code class="reqn">\alpha_0</code>: nrow(Dummy observation) - k</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: mp + 1 or mp</p>
</dd>
<dt>p</dt><dd><p>Lag of VAR</p>
</dd>
<dt>m</dt><dd><p>Dimension of the time series</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Process string in the <code>bayes_spec</code>: <code>"BVAR_Minnesota"</code></p>
</dd>
<dt>spec</dt><dd><p>Model specification (<code>bvharspec</code>)</p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>prior_mean</dt><dd><p>Prior mean matrix of Matrix Normal distribution: <code class="reqn">A_0</code></p>
</dd>
<dt>prior_precision</dt><dd><p>Prior precision matrix of Matrix Normal distribution: <code class="reqn">\Omega_0^{-1}</code></p>
</dd>
<dt>prior_scale</dt><dd><p>Prior scale matrix of inverse-Wishart distribution: <code class="reqn">S_0</code></p>
</dd>
<dt>prior_shape</dt><dd><p>Prior shape of inverse-Wishart distribution: <code class="reqn">\alpha_0</code></p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input (<code>matrix</code>)</p>
</dd>
</dl>

<p>It is also <code>normaliw</code> and <code>bvharmod</code> class.
</p>


<h3>References</h3>

<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>
<p>Giannone, D., Lenza, M., &amp; Primiceri, G. E. (2015). <em>Prior Selection for Vector Autoregressions</em>. Review of Economics and Statistics, 97(2).
</p>
<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>
<p>KADIYALA, K.R. and KARLSSON, S. (1997), <em>NUMERICAL METHODS FOR ESTIMATION AND INFERENCE IN BAYESIAN VAR-MODELS</em>. J. Appl. Econ., 12: 99-132.
</p>
<p>Karlsson, S. (2013). <em>Chapter 15 Forecasting with Bayesian Vector Autoregression</em>. Handbook of Economic Forecasting, 2, 791–897.
</p>
<p>Sims, C. A., &amp; Zha, T. (1998). <em>Bayesian Methods for Dynamic Multivariate Models</em>. International Economic Review, 39(4), 949–968.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+set_bvar">set_bvar()</a></code> to specify the hyperparameters of Minnesota prior.
</p>
</li>
<li> <p><code><a href="#topic+coef.bvarmn">coef.bvarmn()</a></code>, <code><a href="#topic+residuals.bvarmn">residuals.bvarmn()</a></code>, and <code><a href="#topic+fitted.bvarmn">fitted.bvarmn()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+summary.normaliw">summary.normaliw()</a></code> to summarize BVAR model
</p>
</li>
<li> <p><code><a href="#topic+predict.bvarmn">predict.bvarmn()</a></code> to forecast the BVAR process
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Perform the function using etf_vix dataset
fit &lt;- bvar_minnesota(y = etf_vix[,1:3], p = 2)
class(fit)

# Extract coef, fitted values, and residuals
coef(fit)
head(residuals(fit))
head(fitted(fit))
</code></pre>

<hr>
<h2 id='bvar_niwhm'>Fitting Hierarchical Bayesian VAR(p)</h2><span id='topic+bvar_niwhm'></span><span id='topic+print.bvarhm'></span><span id='topic+knit_print.bvarhm'></span>

<h3>Description</h3>

<p>This function fits hierarchical BVAR(p) with general Minnesota prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvar_niwhm(
  y,
  p,
  num_iter = 1000,
  num_burn = floor(num_iter/2),
  thinning = 1,
  bayes_spec = set_bvar(sigma = set_psi(), lambda = set_lambda()),
  scale_variance = 0.05,
  include_mean = TRUE,
  parallel = list(),
  verbose = FALSE
)

## S3 method for class 'bvarhm'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvarhm'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvar_niwhm_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_p">p</code></td>
<td>
<p>VAR lag</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_num_iter">num_iter</code></td>
<td>
<p>MCMC iteration number</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in (warm-up). Half of the iteration is the default choice.</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_thinning">thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A BVAR model specification by <code><a href="#topic+set_ssvs">set_ssvs()</a></code>.</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_scale_variance">scale_variance</code></td>
<td>
<p>Proposal distribution scaling constant to adjust an acceptance rate</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_parallel">parallel</code></td>
<td>
<p>List the same argument of <code><a href="optimParallel.html#topic+optimParallel">optimParallel::optimParallel()</a></code>. By default, this is empty, and the function does not execute parallel computation.</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_verbose">verbose</code></td>
<td>
<p>Print the progress bar in the console. By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_x">x</code></td>
<td>
<p><code>bvarhm</code> object</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvar_niwhm_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SSVS prior gives prior to parameters <code class="reqn">\alpha = vec(A)</code> (VAR coefficient) and <code class="reqn">\Sigma_e^{-1} = \Psi \Psi^T</code> (residual covariance).
</p>
<p style="text-align: center;"><code class="reqn">\alpha_j \mid \gamma_j \sim (1 - \gamma_j) N(0, \kappa_{0j}^2) + \gamma_j N(0, \kappa_{1j}^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma_j \sim Bernoulli(q_j)</code>
</p>

<p>and for upper triangular matrix <code class="reqn">\Psi</code>,
</p>
<p style="text-align: center;"><code class="reqn">\psi_{jj}^2 \sim Gamma(shape = a_j, rate = b_j)</code>
</p>

<p style="text-align: center;"><code class="reqn">\psi_{ij} \mid w_{ij} \sim (1 - w_{ij}) N(0, \kappa_{0,ij}^2) + w_{ij} N(0, \kappa_{1,ij}^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">w_{ij} \sim Bernoulli(q_{ij})</code>
</p>

<p>Gibbs sampler is used for the estimation.
See <a href="#topic+ssvs_bvar_algo">ssvs_bvar_algo</a> how it works.
</p>


<h3>Value</h3>

<p><code>bvar_niwhm</code> returns an object named <code>bvarhm</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>coefficients</dt><dd><p>Coefficient Matrix</p>
</dd>
<dt>p</dt><dd><p>Lag of VAR</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>



<h3>References</h3>

<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>
<p>Giannone, D., Lenza, M., &amp; Primiceri, G. E. (2015). <em>Prior Selection for Vector Autoregressions</em>. Review of Economics and Statistics, 97(2).
</p>
<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>

<hr>
<h2 id='bvar_predictive_density'>Predictive Density of Bayesian Models</h2><span id='topic+bvar_predictive_density'></span>

<h3>Description</h3>

<p>This page explains the simulation algorithm for predictive distribution of BVAR and BVHAR.
</p>


<h3>Simulating predictive distribution of BVAR</h3>

<p>This simulation process is required because we do not know the closed form of h-step ahead forecasting density.
For given number of simulation (<code>n_iter</code>),
</p>

<ol>
<li><p> Generate <code class="reqn">(A^{(b)}, \Sigma_e^{(b)}) \sim MIW</code> (posterior)
</p>
</li>
<li><p> Recursively, <code class="reqn">j = 1, \ldots, h</code> (<code>n_ahead</code>)
</p>

<ul>
<li><p> Point forecast: Use <code class="reqn">\hat{A}</code>
</p>
</li>
<li><p> Predictive distribution: Again generate <code class="reqn">\tilde{Y}_{n + j}^{(b)} \sim A^{(b)}, \Sigma_e^{(b)} \sim MN</code>
</p>
</li>
<li><p> tilde notation indicates simulated ones
</p>
</li></ul>

</li></ol>

<p>Simulating predictive distribution of BVHAR
</p>
<p>We extend the similar procedure in BVAR to the BVHAR.
</p>
<p>For given number of simulation (<code>n_iter</code>),
</p>

<ol>
<li><p> Generate <code class="reqn">(\Phi^{(b)}, \Sigma_e^{(b)}) \sim MIW</code> (posterior)
</p>
</li>
<li><p> Recursively, <code class="reqn">j = 1, \ldots, h</code> (<code>n_ahead</code>)
</p>

<ul>
<li><p> Point forecast: Use <code class="reqn">\hat\Phi</code>
</p>
</li>
<li><p> Predictive distribution: Again generate <code class="reqn">\tilde{Y}_{n + j}^{(b)} \sim \Phi^{(b)}, \Sigma_e^{(b)} \sim MN</code>
</p>
</li>
<li><p> tilde notation indicates simulated ones
</p>
</li></ul>

</li></ol>



<h3>References</h3>

<p>Giannone, D., Lenza, M., &amp; Primiceri, G. E. (2015). <em>Prior Selection for Vector Autoregressions</em>. Review of Economics and Statistics, 97(2).
</p>
<p>Karlsson, S. (2013). <em>Chapter 15 Forecasting with Bayesian Vector Autoregression</em>. Handbook of Economic Forecasting, 2, 791–897.
</p>

<hr>
<h2 id='bvar_ssvs'>Fitting Bayesian VAR(p) of SSVS Prior</h2><span id='topic+bvar_ssvs'></span><span id='topic+print.bvarssvs'></span><span id='topic+knit_print.bvarssvs'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> This function fits BVAR(p) with stochastic search variable selection (SSVS) prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvar_ssvs(
  y,
  p,
  num_chains = 1,
  num_iter = 1000,
  num_burn = floor(num_iter/2),
  thinning = 1,
  bayes_spec = choose_ssvs(y = y, ord = p, type = "VAR", param = c(0.1, 10), include_mean
    = include_mean, gamma_param = c(0.01, 0.01), mean_non = 0, sd_non = 0.1),
  init_spec = init_ssvs(type = "auto"),
  include_mean = TRUE,
  minnesota = FALSE,
  verbose = FALSE,
  num_thread = 1
)

## S3 method for class 'bvarssvs'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvarssvs'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvar_ssvs_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_p">p</code></td>
<td>
<p>VAR lag</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_num_chains">num_chains</code></td>
<td>
<p>Number of MCMC chains</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_num_iter">num_iter</code></td>
<td>
<p>MCMC iteration number</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in (warm-up). Half of the iteration is the default choice.</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_thinning">thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A SSVS model specification by <code><a href="#topic+set_ssvs">set_ssvs()</a></code>. By default, use a default semiautomatic approach <code><a href="#topic+choose_ssvs">choose_ssvs()</a></code>.</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_init_spec">init_spec</code></td>
<td>
<p>SSVS initialization specification by <code><a href="#topic+init_ssvs">init_ssvs()</a></code>. By default, use OLS for coefficient and cholesky factor while 1 for dummies.</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_minnesota">minnesota</code></td>
<td>
<p>Apply cross-variable shrinkage structure (Minnesota-way). By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_verbose">verbose</code></td>
<td>
<p>Print the progress bar in the console. By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_num_thread">num_thread</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Number of threads</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_x">x</code></td>
<td>
<p><code>bvarssvs</code> object</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvar_ssvs_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SSVS prior gives prior to parameters <code class="reqn">\alpha = vec(A)</code> (VAR coefficient) and <code class="reqn">\Sigma_e^{-1} = \Psi \Psi^T</code> (residual covariance).
</p>
<p style="text-align: center;"><code class="reqn">\alpha_j \mid \gamma_j \sim (1 - \gamma_j) N(0, \kappa_{0j}^2) + \gamma_j N(0, \kappa_{1j}^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma_j \sim Bernoulli(q_j)</code>
</p>

<p>and for upper triangular matrix <code class="reqn">\Psi</code>,
</p>
<p style="text-align: center;"><code class="reqn">\psi_{jj}^2 \sim Gamma(shape = a_j, rate = b_j)</code>
</p>

<p style="text-align: center;"><code class="reqn">\psi_{ij} \mid w_{ij} \sim (1 - w_{ij}) N(0, \kappa_{0,ij}^2) + w_{ij} N(0, \kappa_{1,ij}^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">w_{ij} \sim Bernoulli(q_{ij})</code>
</p>

<p>Gibbs sampler is used for the estimation.
See <a href="#topic+ssvs_bvar_algo">ssvs_bvar_algo</a> how it works.
</p>


<h3>Value</h3>

<p><code>bvar_ssvs</code> returns an object named <code>bvarssvs</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>alpha_record</dt><dd><p>MCMC trace for vectorized coefficients (alpha <code class="reqn">\alpha</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>eta_record</dt><dd><p>MCMC trace for upper triangular element of cholesky factor (eta <code class="reqn">\eta</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>psi_record</dt><dd><p>MCMC trace for diagonal element of cholesky factor (psi <code class="reqn">\psi</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>omega_record</dt><dd><p>MCMC trace for indicator variable for <code class="reqn">eta</code> (omega <code class="reqn">\omega</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>gamma_record</dt><dd><p>MCMC trace for indicator variable for <code class="reqn">alpha</code> (gamma <code class="reqn">\gamma</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>chol_record</dt><dd><p>MCMC trace for cholesky factor matrix <code class="reqn">\Psi</code> with <a href="base.html#topic+list">list</a> format.</p>
</dd>
<dt>ols_coef</dt><dd><p>OLS estimates for VAR coefficients.</p>
</dd>
<dt>ols_cholesky</dt><dd><p>OLS estimates for cholesky factor</p>
</dd>
<dt>coefficients</dt><dd><p>Posterior mean of VAR coefficients.</p>
</dd>
<dt>omega_posterior</dt><dd><p>Posterior mean of omega</p>
</dd>
<dt>pip</dt><dd><p>Posterior inclusion probability</p>
</dd>
<dt>param</dt><dd><p><a href="posterior.html#topic+draws_df">posterior::draws_df</a> with every variable: alpha, eta, psi, omega, and gamma</p>
</dd>
<dt>chol_posterior</dt><dd><p>Posterior mean of cholesky factor matrix</p>
</dd>
<dt>covmat</dt><dd><p>Posterior mean of covariance matrix</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: <code>mp + 1</code> or <code>mp</code></p>
</dd>
<dt>p</dt><dd><p>Lag of VAR</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Description of the model, e.g. <code>"VAR_SSVS"</code></p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>spec</dt><dd><p>SSVS specification defined by <code><a href="#topic+set_ssvs">set_ssvs()</a></code></p>
</dd>
<dt>init</dt><dd><p>Initial specification defined by <code><a href="#topic+init_ssvs">init_ssvs()</a></code></p>
</dd>
<dt>iter</dt><dd><p>Total iterations</p>
</dd>
<dt>burn</dt><dd><p>Burn-in</p>
</dd>
<dt>thin</dt><dd><p>Thinning</p>
</dd>
<dt>chain</dt><dd><p>The numer of chains</p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>



<h3>References</h3>

<p>George, E. I., &amp; McCulloch, R. E. (1993). <em>Variable Selection via Gibbs Sampling</em>. Journal of the American Statistical Association, 88(423), 881–889.
</p>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions</em>. Journal of Econometrics, 142(1), 553–580.
</p>
<p>Koop, G., &amp; Korobilis, D. (2009). <em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>. Foundations and Trends® in Econometrics, 3(4), 267–358.
</p>


<h3>See Also</h3>


<ul>
<li><p> Vectorization formulation <a href="#topic+var_vec_formulation">var_vec_formulation</a>
</p>
</li>
<li><p> Gibbs sampler algorithm <a href="#topic+ssvs_bvar_algo">ssvs_bvar_algo</a>
</p>
</li></ul>


<hr>
<h2 id='bvar_sv'>Fitting Bayesian VAR-SV</h2><span id='topic+bvar_sv'></span><span id='topic+print.bvarsv'></span><span id='topic+knit_print.bvarsv'></span>

<h3>Description</h3>

<p>This function fits VAR-SV.
It can have Minnesota, SSVS, and Horseshoe prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvar_sv(
  y,
  p,
  num_chains = 1,
  num_iter = 1000,
  num_burn = floor(num_iter/2),
  thinning = 1,
  bayes_spec = set_bvar(),
  sv_spec = set_sv(),
  intercept = set_intercept(),
  include_mean = TRUE,
  minnesota = TRUE,
  save_init = FALSE,
  verbose = FALSE,
  num_thread = 1
)

## S3 method for class 'bvarsv'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvarsv'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvar_sv_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_p">p</code></td>
<td>
<p>VAR lag</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_num_chains">num_chains</code></td>
<td>
<p>Number of MCMC chains</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_num_iter">num_iter</code></td>
<td>
<p>MCMC iteration number</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in (warm-up). Half of the iteration is the default choice.</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_thinning">thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A BVAR model specification by <code><a href="#topic+set_bvar">set_bvar()</a></code>, <code><a href="#topic+set_ssvs">set_ssvs()</a></code>, or <code><a href="#topic+set_horseshoe">set_horseshoe()</a></code>.</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_sv_spec">sv_spec</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> SV specification by <code><a href="#topic+set_sv">set_sv()</a></code>.</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_intercept">intercept</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Prior for the constant term by <code><a href="#topic+set_intercept">set_intercept()</a></code>.</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_minnesota">minnesota</code></td>
<td>
<p>Apply cross-variable shrinkage structure (Minnesota-way). By default, <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_save_init">save_init</code></td>
<td>
<p>Save every record starting from the initial values (<code>TRUE</code>).
By default, exclude the initial values in the record (<code>FALSE</code>), even when <code>num_burn = 0</code> and <code>thinning = 1</code>.
If <code>num_burn &gt; 0</code> or <code>thinning != 1</code>, this option is ignored.</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_verbose">verbose</code></td>
<td>
<p>Print the progress bar in the console. By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_num_thread">num_thread</code></td>
<td>
<p>Number of threads</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_x">x</code></td>
<td>
<p><code>bvarsv</code> object</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvar_sv_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cholesky stochastic volatility modeling for VAR based on
</p>
<p style="text-align: center;"><code class="reqn">\Sigma_t = L^T D_t^{-1} L</code>
</p>



<h3>Value</h3>

<p><code>bvar_sv()</code> returns an object named <code>bvarsv</code> <a href="base.html#topic+class">class</a>.
</p>

<dl>
<dt>alpha_record</dt><dd><p>MCMC trace for vectorized coefficients (<code class="reqn">\alpha</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>h_record</dt><dd><p>MCMC trace for log-volatilities.</p>
</dd>
<dt>a_record</dt><dd><p>MCMC trace for contemporaneous coefficients.</p>
</dd>
<dt>h0_record</dt><dd><p>MCMC trace for initial log-volatilities.</p>
</dd>
<dt>sigh_record</dt><dd><p>MCMC trace for log-volatilities variance.</p>
</dd>
<dt>coefficients</dt><dd><p>Posterior mean of coefficients.</p>
</dd>
<dt>chol_posterior</dt><dd><p>Posterior mean of contemporaneous effects.</p>
</dd>
<dt>pip</dt><dd><p>Posterior inclusion probabilities.</p>
</dd>
<dt>param</dt><dd><p>Every set of MCMC trace.</p>
</dd>
<dt>group</dt><dd><p>Indicators for group.</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: <code style="white-space: pre;">&#8288;3m + 1&#8288;</code> or <code style="white-space: pre;">&#8288;3m&#8288;</code></p>
</dd>
<dt>p</dt><dd><p>VAR lag</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Description of the model, e.g. <code style="white-space: pre;">&#8288;"VHAR_SSVS_SV", &#8288;</code>&quot;VHAR_Horseshoe_SV&quot;, or <code style="white-space: pre;">&#8288;"VHAR_minnesota-part_SV"} \item{type}{include constant term (&#8288;</code>&quot;const&quot;<code style="white-space: pre;">&#8288;) or not (&#8288;</code>&quot;none&quot;')</p>
</dd>
<dt>spec</dt><dd><p>Coefficients prior specification</p>
</dd>
<dt>sv</dt><dd><p>log volatility prior specification</p>
</dd>
<dt>chain</dt><dd><p>The numer of chains</p>
</dd>
<dt>iter</dt><dd><p>Total iterations</p>
</dd>
<dt>burn</dt><dd><p>Burn-in</p>
</dd>
<dt>thin</dt><dd><p>Thinning</p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>

<p>Different members are added according to priors. If it is SSVS:
</p>

<dl>
<dt>gamma_record</dt><dd><p>MCMC trace for dummy variable.</p>
</dd>
</dl>

<p>Horseshoe:
</p>

<dl>
<dt>lambda_record</dt><dd><p>MCMC trace for local shrinkage level.</p>
</dd>
<dt>tau_record</dt><dd><p>MCMC trace for global shrinkage level.</p>
</dd>
<dt>kappa_record</dt><dd><p>MCMC trace for shrinkage factor.</p>
</dd>
</dl>



<h3>References</h3>

<p>Carriero, A., Chan, J., Clark, T. E., &amp; Marcellino, M. (2022). <em>Corrigendum to “Large Bayesian vector autoregressions with stochastic volatility and non-conjugate priors” [J. Econometrics 212 (1)(2019) 137–154]</em>. Journal of Econometrics, 227(2), 506-512.
</p>
<p>Chan, J., Koop, G., Poirier, D., &amp; Tobias, J. (2019). <em>Bayesian Econometric Methods (2nd ed., Econometric Exercises)</em>. Cambridge: Cambridge University Press.
</p>
<p>Cogley, T., &amp; Sargent, T. J. (2005). <em>Drifts and volatilities: monetary policies and outcomes in the post WWII US</em>. Review of Economic Dynamics, 8(2), 262–302.
</p>
<p>Gruber, L., &amp; Kastner, G. (2022). <em>Forecasting macroeconomic data with Bayesian VARs: Sparse or dense? It depends!</em> arXiv.
</p>

<hr>
<h2 id='bvhar_horseshoe'>Fitting Bayesian VHAR of Horseshoe Prior</h2><span id='topic+bvhar_horseshoe'></span><span id='topic+print.bvharhs'></span><span id='topic+knit_print.bvharhs'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> This function fits VHAR with horseshoe prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvhar_horseshoe(
  y,
  har = c(5, 22),
  num_chains = 1,
  num_iter = 1000,
  num_burn = floor(num_iter/2),
  thinning = 1,
  bayes_spec = set_horseshoe(),
  include_mean = TRUE,
  minnesota = c("no", "short", "longrun"),
  algo = c("block", "gibbs"),
  verbose = FALSE,
  num_thread = 1
)

## S3 method for class 'bvharhs'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvharhs'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvhar_horseshoe_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_har">har</code></td>
<td>
<p>Numeric vector for weekly and monthly order. By default, <code>c(5, 22)</code>.</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_num_chains">num_chains</code></td>
<td>
<p>Number of MCMC chains</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_num_iter">num_iter</code></td>
<td>
<p>MCMC iteration number</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in (warm-up). Half of the iteration is the default choice.</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_thinning">thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>Horseshoe initialization specification by <code><a href="#topic+set_horseshoe">set_horseshoe()</a></code>.</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_minnesota">minnesota</code></td>
<td>
<p>Minnesota type</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_algo">algo</code></td>
<td>
<p>Ordinary gibbs sampling (<code>"gibbs"</code>) or blocked gibbs (Default: <code>"block"</code>).</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_verbose">verbose</code></td>
<td>
<p>Print the progress bar in the console. By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_num_thread">num_thread</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Number of threads</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_x">x</code></td>
<td>
<p><code>bvharhs</code> object</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvhar_horseshoe_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>bvhar_horseshoe</code> returns an object named <code>bvarhs</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>phi_record</dt><dd><p>MCMC trace for vectorized coefficients (alpha <code class="reqn">\phi</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>lambda_record</dt><dd><p>MCMC trace for local shrinkage level (lambda <code class="reqn">\lambda</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>tau_record</dt><dd><p>MCMC trace for global shrinkage level (tau <code class="reqn">\tau</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>psi_record</dt><dd><p>MCMC trace for precision matrix (psi <code class="reqn">\Psi</code>) with <a href="base.html#topic+list">list</a> format.</p>
</dd>
<dt>chain</dt><dd><p>The numer of chains</p>
</dd>
<dt>coefficients</dt><dd><p>Posterior mean of VHAR coefficients.</p>
</dd>
<dt>psi_posterior</dt><dd><p>Posterior mean of precision matrix <code class="reqn">\Psi</code></p>
</dd>
<dt>covmat</dt><dd><p>Posterior mean of covariance matrix</p>
</dd>
<dt>omega_record</dt><dd><p>MCMC trace for diagonal element of <code class="reqn">\Psi</code> (omega) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>eta_record</dt><dd><p>MCMC trace for upper triangular element of <code class="reqn">\Psi</code> (eta) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>param</dt><dd><p><a href="posterior.html#topic+draws_df">posterior::draws_df</a> with every variable: alpha, lambda, tau, omega, and eta</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: <code style="white-space: pre;">&#8288;3m + 1&#8288;</code> or <code style="white-space: pre;">&#8288;3m&#8288;</code></p>
</dd>
<dt>p</dt><dd><p>3 (The number of terms. It contains this element for usage in other functions.)</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Description of the model, e.g. <code>"VHAR_Horseshoe"</code></p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>algo</dt><dd><p>Usual Gibbs sampling (<code>"gibbs"</code>) or fast sampling (<code>"fast"</code>)</p>
</dd>
<dt>spec</dt><dd><p>Horseshoe specification defined by <code><a href="#topic+set_horseshoe">set_horseshoe()</a></code></p>
</dd>
<dt>iter</dt><dd><p>Total iterations</p>
</dd>
<dt>burn</dt><dd><p>Burn-in</p>
</dd>
<dt>thin</dt><dd><p>Thinning</p>
</dd>
<dt>HARtrans</dt><dd><p>VHAR linear transformation matrix</p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>



<h3>References</h3>

<p>Kim, Y. G., and Baek, C. (2023). <em>Bayesian vector heterogeneous autoregressive modeling</em>. Journal of Statistical Computation and Simulation.
</p>
<p>Kim, Y. G., and Baek, C. (n.d.). Working paper.
</p>

<hr>
<h2 id='bvhar_minnesota'>Fitting Bayesian VHAR of Minnesota Prior</h2><span id='topic+bvhar_minnesota'></span><span id='topic+print.bvharmn'></span><span id='topic+knit_print.bvharmn'></span>

<h3>Description</h3>

<p>This function fits BVHAR with Minnesota prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvhar_minnesota(
  y,
  har = c(5, 22),
  bayes_spec = set_bvhar(),
  include_mean = TRUE
)

## S3 method for class 'bvharmn'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvharmn'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvhar_minnesota_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvhar_minnesota_+3A_har">har</code></td>
<td>
<p>Numeric vector for weekly and monthly order. By default, <code>c(5, 22)</code>.</p>
</td></tr>
<tr><td><code id="bvhar_minnesota_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A BVHAR model specification by <code><a href="#topic+set_bvhar">set_bvhar()</a></code> (default) or <code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code>.</p>
</td></tr>
<tr><td><code id="bvhar_minnesota_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvhar_minnesota_+3A_x">x</code></td>
<td>
<p><code>bvarmn</code> object</p>
</td></tr>
<tr><td><code id="bvhar_minnesota_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvhar_minnesota_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Apply Minnesota prior to Vector HAR: <code class="reqn">\Phi</code> (VHAR matrices) and <code class="reqn">\Sigma_e</code> (residual covariance).
</p>
<p style="text-align: center;"><code class="reqn">\Phi \mid \Sigma_e \sim MN(M_0, \Omega_0, \Sigma_e)</code>
</p>

<p style="text-align: center;"><code class="reqn">\Sigma_e \sim IW(\Psi_0, \nu_0)</code>
</p>

<p>(MN: <a href="https://en.wikipedia.org/wiki/Matrix_normal_distribution">matrix normal</a>, IW: <a href="https://en.wikipedia.org/wiki/Inverse-Wishart_distribution">inverse-wishart</a>)
</p>
<p>There are two types of Minnesota priors for BVHAR:
</p>

<ul>
<li><p> VAR-type Minnesota prior specified by <code><a href="#topic+set_bvhar">set_bvhar()</a></code>, so-called BVHAR-S model.
</p>
</li>
<li><p> VHAR-type Minnesota prior specified by <code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code>, so-called BVHAR-L model.
</p>
</li></ul>

<p>Two types of Minnesota priors builds different dummy variables for Y0.
See <a href="#topic+var_design_formulation">var_design_formulation</a>.
</p>


<h3>Value</h3>

<p><code>bvhar_minnesota()</code> returns an object <code>bvharmn</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>coefficients</dt><dd><p>Posterior Mean matrix of Matrix Normal distribution</p>
</dd>
<dt>fitted.values</dt><dd><p>Fitted values</p>
</dd>
<dt>residuals</dt><dd><p>Residuals</p>
</dd>
<dt>mn_prec</dt><dd><p>Posterior precision matrix of Matrix Normal distribution</p>
</dd>
<dt>iw_scale</dt><dd><p>Posterior scale matrix of posterior inverse-wishart distribution</p>
</dd>
<dt>iw_shape</dt><dd><p>Posterior shape of inverse-Wishart distribution (<code class="reqn">\nu_0</code> - obs + 2). <code class="reqn">\nu_0</code>: nrow(Dummy observation) - k</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: 3m + 1 or 3m</p>
</dd>
<dt>p</dt><dd><p>3, this element exists to run the other functions</p>
</dd>
<dt>week</dt><dd><p>Order for weekly term</p>
</dd>
<dt>month</dt><dd><p>Order for monthly term</p>
</dd>
<dt>m</dt><dd><p>Dimension of the time series</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - 22</p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Process string in the <code>bayes_spec</code>: <code>"BVHAR_MN_VAR"</code> (BVHAR-S) or <code>"BVHAR_MN_VHAR"</code> (BVHAR-L)</p>
</dd>
<dt>spec</dt><dd><p>Model specification (<code>bvharspec</code>)</p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>prior_mean</dt><dd><p>Prior mean matrix of Matrix Normal distribution: <code class="reqn">M_0</code></p>
</dd>
<dt>prior_precision</dt><dd><p>Prior precision matrix of Matrix Normal distribution: <code class="reqn">\Omega_0^{-1}</code></p>
</dd>
<dt>prior_scale</dt><dd><p>Prior scale matrix of inverse-Wishart distribution: <code class="reqn">\Psi_0</code></p>
</dd>
<dt>prior_shape</dt><dd><p>Prior shape of inverse-Wishart distribution: <code class="reqn">\nu_0</code></p>
</dd>
<dt>HARtrans</dt><dd><p>VHAR linear transformation matrix: <code class="reqn">C_{HAR}</code></p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input (<code>matrix</code>)</p>
</dd>
</dl>

<p>It is also <code>normaliw</code> and <code>bvharmod</code> class.
</p>


<h3>References</h3>

<p>Kim, Y. G., and Baek, C. (2023). <em>Bayesian vector heterogeneous autoregressive modeling</em>. Journal of Statistical Computation and Simulation.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+set_bvhar">set_bvhar()</a></code> to specify the hyperparameters of BVHAR-S
</p>
</li>
<li> <p><code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code> to specify the hyperparameters of BVHAR-L
</p>
</li>
<li> <p><code><a href="#topic+coef.bvharmn">coef.bvharmn()</a></code>, <code><a href="#topic+residuals.bvharmn">residuals.bvharmn()</a></code>, and <code><a href="#topic+fitted.bvharmn">fitted.bvharmn()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+summary.normaliw">summary.normaliw()</a></code> to summarize BVHAR model
</p>
</li>
<li> <p><code><a href="#topic+predict.bvharmn">predict.bvharmn()</a></code> to forecast the BVHAR process
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Perform the function using etf_vix dataset
fit &lt;- bvhar_minnesota(y = etf_vix[,1:3])
class(fit)

# Extract coef, fitted values, and residuals
coef(fit)
head(residuals(fit))
head(fitted(fit))
</code></pre>

<hr>
<h2 id='bvhar_ssvs'>Fitting Bayesian VHAR of SSVS Prior</h2><span id='topic+bvhar_ssvs'></span><span id='topic+print.bvharssvs'></span><span id='topic+knit_print.bvharssvs'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> This function fits BVAR(p) with stochastic search variable selection (SSVS) prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvhar_ssvs(
  y,
  har = c(5, 22),
  num_chains = 1,
  num_iter = 1000,
  num_burn = floor(num_iter/2),
  thinning = 1,
  bayes_spec = choose_ssvs(y = y, ord = har, type = "VHAR", param = c(0.1, 10),
    include_mean = include_mean, gamma_param = c(0.01, 0.01), mean_non = 0, sd_non = 0.1),
  init_spec = init_ssvs(type = "auto"),
  include_mean = TRUE,
  minnesota = c("no", "short", "longrun"),
  verbose = FALSE,
  num_thread = 1
)

## S3 method for class 'bvharssvs'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvharssvs'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvhar_ssvs_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_har">har</code></td>
<td>
<p>Numeric vector for weekly and monthly order. By default, <code>c(5, 22)</code>.</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_num_chains">num_chains</code></td>
<td>
<p>Number of MCMC chains</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_num_iter">num_iter</code></td>
<td>
<p>MCMC iteration number</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of warm-up (burn-in). Half of the iteration is the default choice.</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_thinning">thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A SSVS model specification by <code><a href="#topic+set_ssvs">set_ssvs()</a></code>. By default, use a default semiautomatic approach <code><a href="#topic+choose_ssvs">choose_ssvs()</a></code>.</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_init_spec">init_spec</code></td>
<td>
<p>SSVS initialization specification by <code><a href="#topic+init_ssvs">init_ssvs()</a></code>. By default, use OLS for coefficient and cholesky factor while 1 for dummies.</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_minnesota">minnesota</code></td>
<td>
<p>Apply cross-variable shrinkage structure (Minnesota-way). Two type: <code>"short"</code> type and <code>"longrun"</code> type. By default, <code>"no"</code>.</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_verbose">verbose</code></td>
<td>
<p>Print the progress bar in the console. By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_num_thread">num_thread</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Number of threads</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_x">x</code></td>
<td>
<p><code>bvharssvs</code> object</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvhar_ssvs_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SSVS prior gives prior to parameters <code class="reqn">\alpha = vec(A)</code> (VAR coefficient) and <code class="reqn">\Sigma_e^{-1} = \Psi \Psi^T</code> (residual covariance).
</p>
<p style="text-align: center;"><code class="reqn">\alpha_j \mid \gamma_j \sim (1 - \gamma_j) N(0, \kappa_{0j}^2) + \gamma_j N(0, \kappa_{1j}^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma_j \sim Bernoulli(q_j)</code>
</p>

<p>and for upper triangular matrix <code class="reqn">\Psi</code>,
</p>
<p style="text-align: center;"><code class="reqn">\psi_{jj}^2 \sim Gamma(shape = a_j, rate = b_j)</code>
</p>

<p style="text-align: center;"><code class="reqn">\psi_{ij} \mid w_{ij} \sim (1 - w_{ij}) N(0, \kappa_{0,ij}^2) + w_{ij} N(0, \kappa_{1,ij}^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">w_{ij} \sim Bernoulli(q_{ij})</code>
</p>

<p>Gibbs sampler is used for the estimation.
See <a href="#topic+ssvs_bvar_algo">ssvs_bvar_algo</a> how it works.
</p>


<h3>Value</h3>

<p><code>bvhar_ssvs</code> returns an object named <code>bvharssvs</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>phi_record</dt><dd><p>MCMC trace for vectorized coefficients (phi <code class="reqn">\phi</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>eta_record</dt><dd><p>MCMC trace for upper triangular element of cholesky factor (eta <code class="reqn">\eta</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>psi_record</dt><dd><p>MCMC trace for diagonal element of cholesky factor (psi <code class="reqn">\psi</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>omega_record</dt><dd><p>MCMC trace for indicator variable for <code class="reqn">eta</code> (omega <code class="reqn">\omega</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>gamma_record</dt><dd><p>MCMC trace for indicator variable for <code class="reqn">alpha</code> (gamma <code class="reqn">\gamma</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>chol_record</dt><dd><p>MCMC trace for cholesky factor matrix <code class="reqn">\Psi</code> with <a href="base.html#topic+list">list</a> format.</p>
</dd>
<dt>ols_coef</dt><dd><p>OLS estimates for VAR coefficients.</p>
</dd>
<dt>ols_cholesky</dt><dd><p>OLS estimates for cholesky factor</p>
</dd>
<dt>coefficients</dt><dd><p>Posterior mean of VAR coefficients.</p>
</dd>
<dt>omega_posterior</dt><dd><p>Posterior mean of omega</p>
</dd>
<dt>pip</dt><dd><p>Posterior inclusion probability</p>
</dd>
<dt>param</dt><dd><p><a href="posterior.html#topic+draws_df">posterior::draws_df</a> with every variable: alpha, eta, psi, omega, and gamma</p>
</dd>
<dt>chol_posterior</dt><dd><p>Posterior mean of cholesky factor matrix</p>
</dd>
<dt>covmat</dt><dd><p>Posterior mean of covariance matrix</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: <code style="white-space: pre;">&#8288;3m + 1&#8288;</code> or <code style="white-space: pre;">&#8288;3m&#8288;</code></p>
</dd>
<dt>p</dt><dd><p>3 (The number of terms. It contains this element for usage in other functions.)</p>
</dd>
<dt>week</dt><dd><p>Order for weekly term</p>
</dd>
<dt>month</dt><dd><p>Order for monthly term</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Description of the model, e.g. <code>"VHAR_SSVS"</code></p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>spec</dt><dd><p>SSVS specification defined by <code><a href="#topic+set_ssvs">set_ssvs()</a></code></p>
</dd>
<dt>init</dt><dd><p>Initial specification defined by <code><a href="#topic+init_ssvs">init_ssvs()</a></code></p>
</dd>
<dt>iter</dt><dd><p>Total iterations</p>
</dd>
<dt>burn</dt><dd><p>Burn-in</p>
</dd>
<dt>thin</dt><dd><p>Thinning</p>
</dd>
<dt>chain</dt><dd><p>The numer of chains</p>
</dd>
<dt>HARtrans</dt><dd><p>VHAR linear transformation matrix</p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>



<h3>References</h3>

<p>Kim, Y. G., and Baek, C. (2023). <em>Bayesian vector heterogeneous autoregressive modeling</em>. Journal of Statistical Computation and Simulation.
</p>
<p>Kim, Y. G., and Baek, C. (n.d.). Working paper.
</p>


<h3>See Also</h3>


<ul>
<li><p> Vectorization formulation <a href="#topic+var_vec_formulation">var_vec_formulation</a>
</p>
</li>
<li><p> Gibbs sampler algorithm <a href="#topic+ssvs_bvar_algo">ssvs_bvar_algo</a>
</p>
</li></ul>


<hr>
<h2 id='bvhar_sv'>Fitting Bayesian VHAR-SV</h2><span id='topic+bvhar_sv'></span><span id='topic+print.bvharsv'></span><span id='topic+knit_print.bvharsv'></span>

<h3>Description</h3>

<p>This function fits VHAR-SV.
It can have Minnesota, SSVS, and Horseshoe prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvhar_sv(
  y,
  har = c(5, 22),
  num_chains = 1,
  num_iter = 1000,
  num_burn = floor(num_iter/2),
  thinning = 1,
  bayes_spec = set_bvhar(),
  sv_spec = set_sv(),
  intercept = set_intercept(),
  include_mean = TRUE,
  minnesota = c("longrun", "short", "no"),
  save_init = FALSE,
  verbose = FALSE,
  num_thread = 1
)

## S3 method for class 'bvharsv'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvharsv'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvhar_sv_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_har">har</code></td>
<td>
<p>Numeric vector for weekly and monthly order. By default, <code>c(5, 22)</code>.</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_num_chains">num_chains</code></td>
<td>
<p>Number of MCMC chains</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_num_iter">num_iter</code></td>
<td>
<p>MCMC iteration number</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in (warm-up). Half of the iteration is the default choice.</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_thinning">thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A BVHAR model specification by <code><a href="#topic+set_bvhar">set_bvhar()</a></code> (default) <code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code>, <code><a href="#topic+set_ssvs">set_ssvs()</a></code>, or <code><a href="#topic+set_horseshoe">set_horseshoe()</a></code>.</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_sv_spec">sv_spec</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> SV specification by <code><a href="#topic+set_sv">set_sv()</a></code>.</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_intercept">intercept</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Prior for the constant term by <code><a href="#topic+set_intercept">set_intercept()</a></code>.</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_minnesota">minnesota</code></td>
<td>
<p>Apply cross-variable shrinkage structure (Minnesota-way). Two type: <code>"short"</code> type and <code>"longrun"</code> (default) type.
You can also set <code>"no"</code>.</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_save_init">save_init</code></td>
<td>
<p>Save every record starting from the initial values (<code>TRUE</code>).
By default, exclude the initial values in the record (<code>FALSE</code>), even when <code>num_burn = 0</code> and <code>thinning = 1</code>.
If <code>num_burn &gt; 0</code> or <code>thinning != 1</code>, this option is ignored.</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_verbose">verbose</code></td>
<td>
<p>Print the progress bar in the console. By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_num_thread">num_thread</code></td>
<td>
<p>Number of threads</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_x">x</code></td>
<td>
<p><code>bvarsv</code> object</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="bvhar_sv_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cholesky stochastic volatility modeling for VHAR based on
</p>
<p style="text-align: center;"><code class="reqn">\Sigma_t = L^T D_t^{-1} L</code>
</p>



<h3>Value</h3>

<p><code>bvhar_sv()</code> returns an object named <code>bvharsv</code> <a href="base.html#topic+class">class</a>. It is a list with the following components:
</p>

<dl>
<dt>phi_record</dt><dd><p>MCMC trace for vectorized coefficients (<code class="reqn">\phi</code>) with <a href="posterior.html#topic+draws_df">posterior::draws_df</a> format.</p>
</dd>
<dt>h_record</dt><dd><p>MCMC trace for log-volatilities.</p>
</dd>
<dt>a_record</dt><dd><p>MCMC trace for contemporaneous coefficients.</p>
</dd>
<dt>h0_record</dt><dd><p>MCMC trace for initial log-volatilities.</p>
</dd>
<dt>sigh_record</dt><dd><p>MCMC trace for log-volatilities variance.</p>
</dd>
<dt>coefficients</dt><dd><p>Posterior mean of coefficients.</p>
</dd>
<dt>chol_posterior</dt><dd><p>Posterior mean of contemporaneous effects.</p>
</dd>
<dt>pip</dt><dd><p>Posterior inclusion probabilities.</p>
</dd>
<dt>param</dt><dd><p>Every set of MCMC trace.</p>
</dd>
<dt>group</dt><dd><p>Indicators for group.</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: <code style="white-space: pre;">&#8288;3m + 1&#8288;</code> or <code style="white-space: pre;">&#8288;3m&#8288;</code></p>
</dd>
<dt>p</dt><dd><p>3 (The number of terms. It contains this element for usage in other functions.)</p>
</dd>
<dt>week</dt><dd><p>Order for weekly term</p>
</dd>
<dt>month</dt><dd><p>Order for monthly term</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Description of the model, e.g. <code style="white-space: pre;">&#8288;"VHAR_SSVS_SV", &#8288;</code>&quot;VHAR_Horseshoe_SV&quot;, or <code style="white-space: pre;">&#8288;"VHAR_minnesota-part_SV"} \item{type}{include constant term (&#8288;</code>&quot;const&quot;<code style="white-space: pre;">&#8288;) or not (&#8288;</code>&quot;none&quot;')</p>
</dd>
<dt>spec</dt><dd><p>Coefficients prior specification</p>
</dd>
<dt>sv</dt><dd><p>log volatility prior specification</p>
</dd>
<dt>chain</dt><dd><p>The numer of chains</p>
</dd>
<dt>iter</dt><dd><p>Total iterations</p>
</dd>
<dt>burn</dt><dd><p>Burn-in</p>
</dd>
<dt>thin</dt><dd><p>Thinning</p>
</dd>
<dt>HARtrans</dt><dd><p>VHAR linear transformation matrix</p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>

<p>Different members are added according to priors. If it is SSVS:
</p>

<dl>
<dt>gamma_record</dt><dd><p>MCMC trace for dummy variable.</p>
</dd>
</dl>

<p>Horseshoe:
</p>

<dl>
<dt>lambda_record</dt><dd><p>MCMC trace for local shrinkage level.</p>
</dd>
<dt>tau_record</dt><dd><p>MCMC trace for global shrinkage level.</p>
</dd>
<dt>kappa_record</dt><dd><p>MCMC trace for shrinkage factor.</p>
</dd>
</dl>



<h3>References</h3>

<p>Kim, Y. G., and Baek, C. (2023+). <em>Bayesian vector heterogeneous autoregressive modeling</em>. Journal of Statistical Computation and Simulation.
</p>
<p>Kim, Y. G., and Baek, C. (n.d.). Working paper.
</p>

<hr>
<h2 id='bvhar-package'>bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling</h2><span id='topic+bvhar'></span><span id='topic+bvhar-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Tools to research Bayesian Vector heterogeneous autoregressive (VHAR) model, referring to Kim &amp; Baek (2023) (<a href="https://doi.org/10.1080/00949655.2023.2281644">doi:10.1080/00949655.2023.2281644</a>). 'bvhar' can model Vector Autoregressive (VAR), VHAR, Bayesian VAR (BVAR), and Bayesian VHAR (BVHAR) models.
</p>


<h3>Details</h3>

<p>The bvhar package provides function to analyze and forecast multivariate time series data via vector autoregressive modelling.
Here, vector autoregressive modelling includes:
</p>

<ul>
<li><p> Vector autoregressive (VAR) model: <code><a href="#topic+var_lm">var_lm()</a></code>
</p>
</li>
<li><p> Vector heterogeneous autoregressive (VHAR) model: <code><a href="#topic+vhar_lm">vhar_lm()</a></code>
</p>
</li>
<li><p> Bayesian VAR (BVAR) model: <code><a href="#topic+bvar_minnesota">bvar_minnesota()</a></code>, <code><a href="#topic+bvar_flat">bvar_flat()</a></code>
</p>
</li>
<li><p> Bayesian VHAR (BVHAR) model: <code><a href="#topic+bvhar_minnesota">bvhar_minnesota()</a></code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Young Geun Kim <a href="mailto:ygeunkimstat@gmail.com">ygeunkimstat@gmail.com</a> (<a href="https://orcid.org/0000-0001-8651-1167">ORCID</a>) [copyright holder]
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Changryong Baek [contributor]
</p>
</li></ul>



<h3>References</h3>

<p>Kim, Y. G., and Baek, C. (2023). <em>Bayesian vector heterogeneous autoregressive modeling</em>. Journal of Statistical Computation and Simulation.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://ygeunkim.github.io/package/bvhar/">https://ygeunkim.github.io/package/bvhar/</a>
</p>
</li>
<li> <p><a href="https://github.com/ygeunkim/bvhar">https://github.com/ygeunkim/bvhar</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/ygeunkim/bvhar/issues">https://github.com/ygeunkim/bvhar/issues</a>
</p>
</li></ul>


<hr>
<h2 id='choose_bayes'>Finding the Set of Hyperparameters of Bayesian Model</h2><span id='topic+choose_bayes'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> This function chooses the set of hyperparameters of Bayesian model using <code><a href="stats.html#topic+optim">stats::optim()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choose_bayes(
  bayes_bound = bound_bvhar(),
  ...,
  eps = 1e-04,
  y,
  order = c(5, 22),
  include_mean = TRUE,
  parallel = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choose_bayes_+3A_bayes_bound">bayes_bound</code></td>
<td>
<p>Empirical Bayes optimization bound specification defined by <code><a href="#topic+bound_bvhar">bound_bvhar()</a></code>.</p>
</td></tr>
<tr><td><code id="choose_bayes_+3A_...">...</code></td>
<td>
<p>Additional arguments for <code><a href="stats.html#topic+optim">stats::optim()</a></code>.</p>
</td></tr>
<tr><td><code id="choose_bayes_+3A_eps">eps</code></td>
<td>
<p>Hyperparameter <code>eps</code> is fixed. By default, <code>1e-04</code>.</p>
</td></tr>
<tr><td><code id="choose_bayes_+3A_y">y</code></td>
<td>
<p>Time series data</p>
</td></tr>
<tr><td><code id="choose_bayes_+3A_order">order</code></td>
<td>
<p>Order for BVAR or BVHAR. <code>p</code> of <code><a href="#topic+bvar_minnesota">bvar_minnesota()</a></code> or <code>har</code> of <code><a href="#topic+bvhar_minnesota">bvhar_minnesota()</a></code>. By default, <code>c(5, 22)</code> for <code>har</code>.</p>
</td></tr>
<tr><td><code id="choose_bayes_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="choose_bayes_+3A_parallel">parallel</code></td>
<td>
<p>List the same argument of <code><a href="optimParallel.html#topic+optimParallel">optimParallel::optimParallel()</a></code>. By default, this is empty, and the function does not execute parallel computation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>bvharemp</code> <a href="base.html#topic+class">class</a> is a list that has
</p>

<dl>
<dt>...</dt><dd><p>Many components of <code><a href="stats.html#topic+optim">stats::optim()</a></code> or <code><a href="optimParallel.html#topic+optimParallel">optimParallel::optimParallel()</a></code></p>
</dd>
<dt>spec</dt><dd><p>Corresponding <code>bvharspec</code></p>
</dd>
<dt>fit</dt><dd><p>Chosen Bayesian model</p>
</dd>
<dt>ml</dt><dd><p>Marginal likelihood of the final model</p>
</dd>
</dl>



<h3>References</h3>

<p>Giannone, D., Lenza, M., &amp; Primiceri, G. E. (2015). <em>Prior Selection for Vector Autoregressions</em>. Review of Economics and Statistics, 97(2).
</p>
<p>Kim, Y. G., and Baek, C. (n.d.). <em>Bayesian vector heterogeneous autoregressive modeling</em>. submitted.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+bound_bvhar">bound_bvhar()</a></code> to define L-BFGS-B optimization bounds.
</p>
</li>
<li><p> Individual functions: <code><a href="#topic+choose_bvar">choose_bvar()</a></code>
</p>
</li></ul>


<hr>
<h2 id='choose_bvar'>Finding the Set of Hyperparameters of Individual Bayesian Model</h2><span id='topic+choose_bvar'></span><span id='topic+choose_bvhar'></span><span id='topic+print.bvharemp'></span><span id='topic+knit_print.bvharemp'></span>

<h3>Description</h3>

<p>Instead of these functions, you can use <code><a href="#topic+choose_bayes">choose_bayes()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choose_bvar(
  bayes_spec = set_bvar(),
  lower = 0.01,
  upper = 10,
  ...,
  eps = 1e-04,
  y,
  p,
  include_mean = TRUE,
  parallel = list()
)

choose_bvhar(
  bayes_spec = set_bvhar(),
  lower = 0.01,
  upper = 10,
  ...,
  eps = 1e-04,
  y,
  har = c(5, 22),
  include_mean = TRUE,
  parallel = list()
)

## S3 method for class 'bvharemp'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvharemp'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choose_bvar_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>Initial Bayes model specification.</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_lower">lower</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Lower bound. By default, <code>.01</code>.</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_upper">upper</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Upper bound. By default, <code>10</code>.</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_eps">eps</code></td>
<td>
<p>Hyperparameter <code>eps</code> is fixed. By default, <code>1e-04</code>.</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_y">y</code></td>
<td>
<p>Time series data</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_p">p</code></td>
<td>
<p>BVAR lag</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_parallel">parallel</code></td>
<td>
<p>List the same argument of <code><a href="optimParallel.html#topic+optimParallel">optimParallel::optimParallel()</a></code>. By default, this is empty, and the function does not execute parallel computation.</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_har">har</code></td>
<td>
<p>Numeric vector for weekly and monthly order. By default, <code>c(5, 22)</code>.</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_x">x</code></td>
<td>
<p><code>bvharemp</code> object</p>
</td></tr>
<tr><td><code id="choose_bvar_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Empirical Bayes method maximizes marginal likelihood and selects the set of hyperparameters.
These functions implement <code>"L-BFGS-B"</code> method of <code><a href="stats.html#topic+optim">stats::optim()</a></code> to find the maximum of marginal likelihood.
</p>
<p>If you want to set <code>lower</code> and <code>upper</code> option more carefully,
deal with them like as in <code><a href="stats.html#topic+optim">stats::optim()</a></code> in order of <code><a href="#topic+set_bvar">set_bvar()</a></code>, <code><a href="#topic+set_bvhar">set_bvhar()</a></code>, or <code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code>'s argument (except <code>eps</code>).
In other words, just arrange them in a vector.
</p>


<h3>Value</h3>

<p><code>bvharemp</code> <a href="base.html#topic+class">class</a> is a list that has
</p>

<ul>
<li> <p><code><a href="stats.html#topic+optim">stats::optim()</a></code> or <code><a href="optimParallel.html#topic+optimParallel">optimParallel::optimParallel()</a></code>
</p>
</li>
<li><p> chosen <code>bvharspec</code> set
</p>
</li>
<li><p> Bayesian model fit result with chosen specification
</p>

<dl>
<dt>...</dt><dd><p>Many components of <code><a href="stats.html#topic+optim">stats::optim()</a></code> or <code><a href="optimParallel.html#topic+optimParallel">optimParallel::optimParallel()</a></code></p>
</dd>
<dt>spec</dt><dd><p>Corresponding <code>bvharspec</code></p>
</dd>
<dt>fit</dt><dd><p>Chosen Bayesian model</p>
</dd>
<dt>ml</dt><dd><p>Marginal likelihood of the final model</p>
</dd>
</dl>

</li></ul>



<h3>References</h3>

<p>Byrd, R. H., Lu, P., Nocedal, J., &amp; Zhu, C. (1995). <em>A limited memory algorithm for bound constrained optimization</em>. SIAM Journal on scientific computing, 16(5), 1190-1208.
</p>
<p>Gelman, A., Carlin, J. B., Stern, H. S., &amp; Rubin, D. B. (2013). <em>Bayesian data analysis</em>. Chapman and Hall/CRC.
</p>
<p>Giannone, D., Lenza, M., &amp; Primiceri, G. E. (2015). <em>Prior Selection for Vector Autoregressions</em>. Review of Economics and Statistics, 97(2).
</p>
<p>Kim, Y. G., and Baek, C. (2023+). <em>Bayesian vector heterogeneous autoregressive modeling</em>. Journal of Statistical Computation and Simulation.
</p>

<hr>
<h2 id='choose_ssvs'>Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach</h2><span id='topic+choose_ssvs'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
This function chooses <code class="reqn">(\tau_{0i}, \tau_{1i})</code> and <code class="reqn">(\kappa_{0i}, \kappa_{1i})</code>
using a default semiautomatic approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choose_ssvs(
  y,
  ord,
  type = c("VAR", "VHAR"),
  param = c(0.1, 10),
  include_mean = TRUE,
  gamma_param = c(0.01, 0.01),
  mean_non = 0,
  sd_non = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choose_ssvs_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables.</p>
</td></tr>
<tr><td><code id="choose_ssvs_+3A_ord">ord</code></td>
<td>
<p>Order for VAR or VHAR.</p>
</td></tr>
<tr><td><code id="choose_ssvs_+3A_type">type</code></td>
<td>
<p>Model type (Default: <code>"VAR"</code> or <code>"VHAR"</code>).</p>
</td></tr>
<tr><td><code id="choose_ssvs_+3A_param">param</code></td>
<td>
<p>Preselected constants <code class="reqn">c_0 &lt;&lt; c_1</code>. By default, <code>0.1</code> and <code>10</code> (See Details).</p>
</td></tr>
<tr><td><code id="choose_ssvs_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="choose_ssvs_+3A_gamma_param">gamma_param</code></td>
<td>
<p>Parameters (shape, rate) for Gamma distribution. This is for the output.</p>
</td></tr>
<tr><td><code id="choose_ssvs_+3A_mean_non">mean_non</code></td>
<td>
<p>Prior mean of unrestricted coefficients. This is for the output.</p>
</td></tr>
<tr><td><code id="choose_ssvs_+3A_sd_non">sd_non</code></td>
<td>
<p>Standard deviance of unrestricted coefficients. This is for the output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of using subjective values of <code class="reqn">(\tau_{0i}, \tau_{1i})</code>, we can use
</p>
<p style="text-align: center;"><code class="reqn">\tau_{ki} = c_k \hat{VAR(OLS)}</code>
</p>

<p>It must be <code class="reqn">c_0 &lt;&lt; c_1</code>.
</p>
<p>In case of <code class="reqn">(\omega_{0ij}, \omega_{1ij})</code>,
</p>
<p style="text-align: center;"><code class="reqn">\omega_{kij} = c_k = \hat{VAR(OLS)}</code>
</p>

<p>similarly.
</p>


<h3>Value</h3>

<p><code>ssvsinput</code> object
</p>


<h3>References</h3>

<p>George, E. I., &amp; McCulloch, R. E. (1993). <em>Variable Selection via Gibbs Sampling</em>. Journal of the American Statistical Association, 88(423), 881–889.
</p>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions</em>. Journal of Econometrics, 142(1), 553–580.
</p>
<p>Koop, G., &amp; Korobilis, D. (2009). <em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>. Foundations and Trends® in Econometrics, 3(4), 267–358.
</p>

<hr>
<h2 id='choose_var'>Choose the Best VAR based on Information Criteria</h2><span id='topic+choose_var'></span>

<h3>Description</h3>

<p>This function computes AIC, FPE, BIC, and HQ up to p = <code>lag_max</code> of VAR model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choose_var(y, lag_max = 5, include_mean = TRUE, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choose_var_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="choose_var_+3A_lag_max">lag_max</code></td>
<td>
<p>Maximum Var lag to explore (default = 5)</p>
</td></tr>
<tr><td><code id="choose_var_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="choose_var_+3A_parallel">parallel</code></td>
<td>
<p>Parallel computation using <code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code>? By default, <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Minimum order and information criteria values
</p>

<hr>
<h2 id='coef.varlse'>Coefficient Matrix of Multivariate Time Series Models</h2><span id='topic+coef.varlse'></span><span id='topic+coef.vharlse'></span><span id='topic+coef.bvarmn'></span><span id='topic+coef.bvarflat'></span><span id='topic+coef.bvharmn'></span><span id='topic+coef.bvharsp'></span><span id='topic+coef.summary.bvharsp'></span>

<h3>Description</h3>

<p>By defining <code><a href="stats.html#topic+coef">stats::coef()</a></code> for each model, this function returns coefficient matrix estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
coef(object, ...)

## S3 method for class 'vharlse'
coef(object, ...)

## S3 method for class 'bvarmn'
coef(object, ...)

## S3 method for class 'bvarflat'
coef(object, ...)

## S3 method for class 'bvharmn'
coef(object, ...)

## S3 method for class 'bvharsp'
coef(object, ...)

## S3 method for class 'summary.bvharsp'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.varlse_+3A_object">object</code></td>
<td>
<p>Model object</p>
</td></tr>
<tr><td><code id="coef.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+matrix">matrix</a> object with appropriate dimension.
</p>

<hr>
<h2 id='compute_dic'>Deviance Information Criterion of Multivariate Time Series Model</h2><span id='topic+compute_dic'></span><span id='topic+compute_dic.bvarmn'></span>

<h3>Description</h3>

<p>Compute DIC of BVAR and BVHAR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_dic(object, ...)

## S3 method for class 'bvarmn'
compute_dic(object, n_iter = 100L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_dic_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="compute_dic_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="compute_dic_+3A_n_iter">n_iter</code></td>
<td>
<p>Number to sample</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Deviance information criteria (DIC) is
</p>
<p style="text-align: center;"><code class="reqn">- 2 \log p(y \mid \hat\theta_{bayes}) + 2 p_{DIC}</code>
</p>

<p>where <code class="reqn">p_{DIC}</code> is the effective number of parameters defined by
</p>
<p style="text-align: center;"><code class="reqn">p_{DIC} = 2 ( \log p(y \mid \hat\theta_{bayes}) - E_{post} \log p(y \mid \theta) )</code>
</p>

<p>Random sampling from posterior distribution gives its computation, <code class="reqn">\theta_i \sim \theta \mid y, i = 1, \ldots, M</code>
</p>
<p style="text-align: center;"><code class="reqn">p_{DIC}^{computed} = 2 ( \log p(y \mid \hat\theta_{bayes}) - \frac{1}{M} \sum_i \log p(y \mid \theta_i) )</code>
</p>



<h3>Value</h3>

<p>DIC value.
</p>


<h3>References</h3>

<p>Gelman, A., Carlin, J. B., Stern, H. S., &amp; Rubin, D. B. (2013). <em>Bayesian data analysis</em>. Chapman and Hall/CRC.
</p>
<p>Spiegelhalter, D.J., Best, N.G., Carlin, B.P. and Van Der Linde, A. (2002). <em>Bayesian measures of model complexity and fit</em>. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 64: 583-639.
</p>

<hr>
<h2 id='compute_logml'>Extracting Log of Marginal Likelihood</h2><span id='topic+compute_logml'></span><span id='topic+compute_logml.bvarmn'></span><span id='topic+compute_logml.bvharmn'></span>

<h3>Description</h3>

<p>Compute log of marginal likelihood of Bayesian Fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_logml(object, ...)

## S3 method for class 'bvarmn'
compute_logml(object, ...)

## S3 method for class 'bvharmn'
compute_logml(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_logml_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="compute_logml_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Closed form of Marginal Likelihood of BVAR can be derived by
</p>
<p style="text-align: center;"><code class="reqn">p(Y_0) = \pi^{-ms / 2} \frac{\Gamma_m ((\alpha_0 + s) / 2)}{\Gamma_m (\alpha_0 / 2)} \det(\Omega_0)^{-m / 2} \det(S_0)^{\alpha_0 / 2} \det(\hat{V})^{- m / 2} \det(\hat{\Sigma}_e)^{-(\alpha_0 + s) / 2}</code>
</p>

<p>Closed form of Marginal Likelihood of BVHAR can be derived by
</p>
<p style="text-align: center;"><code class="reqn">p(Y_0) = \pi^{-ms_0 / 2} \frac{\Gamma_m ((d_0 + s) / 2)}{\Gamma_m (d_0 / 2)} \det(P_0)^{-m / 2} \det(U_0)^{d_0 / 2} \det(\hat{V}_{HAR})^{- m / 2} \det(\hat{\Sigma}_e)^{-(d_0 + s) / 2}</code>
</p>



<h3>Value</h3>

<p>log likelihood of Minnesota prior model.
</p>


<h3>References</h3>

<p>Giannone, D., Lenza, M., &amp; Primiceri, G. E. (2015). <em>Prior Selection for Vector Autoregressions</em>. Review of Economics and Statistics, 97(2).
</p>

<hr>
<h2 id='conf_fdr'>Evaluate the Sparsity Estimation Based on FDR</h2><span id='topic+conf_fdr'></span><span id='topic+conf_fdr.summary.bvharsp'></span>

<h3>Description</h3>

<p>This function computes false discovery rate (FDR) for sparse element of the true coefficients given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf_fdr(x, y, ...)

## S3 method for class 'summary.bvharsp'
conf_fdr(x, y, truth_thr = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf_fdr_+3A_x">x</code></td>
<td>
<p><code>summary.bvharsp</code> object.</p>
</td></tr>
<tr><td><code id="conf_fdr_+3A_y">y</code></td>
<td>
<p>True inclusion variable.</p>
</td></tr>
<tr><td><code id="conf_fdr_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="conf_fdr_+3A_truth_thr">truth_thr</code></td>
<td>
<p>Threshold value when using non-sparse true coefficient matrix. By default, <code>0</code> for sparse matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When using this function, the true coefficient matrix <code class="reqn">\Phi</code> should be sparse.
False discovery rate (FDR) is computed by
</p>
<p style="text-align: center;"><code class="reqn">FDR = \frac{FP}{TP + FP}</code>
</p>

<p>where TP is true positive, and FP is false positive.
</p>


<h3>Value</h3>

<p>FDR value in confusion table
</p>


<h3>References</h3>

<p>Bai, R., &amp; Ghosh, M. (2018). High-dimensional multivariate posterior consistency under global–local shrinkage priors. Journal of Multivariate Analysis, 167, 157–170.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion()</a></code>
</p>

<hr>
<h2 id='conf_fnr'>Evaluate the Sparsity Estimation Based on FNR</h2><span id='topic+conf_fnr'></span><span id='topic+conf_fnr.summary.bvharsp'></span>

<h3>Description</h3>

<p>This function computes false negative rate (FNR) for sparse element of the true coefficients given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf_fnr(x, y, ...)

## S3 method for class 'summary.bvharsp'
conf_fnr(x, y, truth_thr = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf_fnr_+3A_x">x</code></td>
<td>
<p><code>summary.bvharsp</code> object.</p>
</td></tr>
<tr><td><code id="conf_fnr_+3A_y">y</code></td>
<td>
<p>True inclusion variable.</p>
</td></tr>
<tr><td><code id="conf_fnr_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="conf_fnr_+3A_truth_thr">truth_thr</code></td>
<td>
<p>Threshold value when using non-sparse true coefficient matrix. By default, <code>0</code> for sparse matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>False negative rate (FNR) is computed by
</p>
<p style="text-align: center;"><code class="reqn">FNR = \frac{FN}{TP + FN}</code>
</p>

<p>where TP is true positive, and FN is false negative.
</p>


<h3>Value</h3>

<p>FNR value in confusion table
</p>


<h3>References</h3>

<p>Bai, R., &amp; Ghosh, M. (2018). High-dimensional multivariate posterior consistency under global–local shrinkage priors. Journal of Multivariate Analysis, 167, 157–170.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion()</a></code>
</p>

<hr>
<h2 id='conf_fscore'>Evaluate the Sparsity Estimation Based on F1 Score</h2><span id='topic+conf_fscore'></span><span id='topic+conf_fscore.summary.bvharsp'></span>

<h3>Description</h3>

<p>This function computes F1 score for sparse element of the true coefficients given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf_fscore(x, y, ...)

## S3 method for class 'summary.bvharsp'
conf_fscore(x, y, truth_thr = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf_fscore_+3A_x">x</code></td>
<td>
<p><code>summary.bvharsp</code> object.</p>
</td></tr>
<tr><td><code id="conf_fscore_+3A_y">y</code></td>
<td>
<p>True inclusion variable.</p>
</td></tr>
<tr><td><code id="conf_fscore_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="conf_fscore_+3A_truth_thr">truth_thr</code></td>
<td>
<p>Threshold value when using non-sparse true coefficient matrix. By default, <code>0</code> for sparse matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The F1 score is computed by
</p>
<p style="text-align: center;"><code class="reqn">F_1 = \frac{2 precision \times recall}{precision + recall}</code>
</p>



<h3>Value</h3>

<p>F1 score in confusion table
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion()</a></code>
</p>

<hr>
<h2 id='conf_prec'>Evaluate the Sparsity Estimation Based on Precision</h2><span id='topic+conf_prec'></span><span id='topic+conf_prec.summary.bvharsp'></span>

<h3>Description</h3>

<p>This function computes precision for sparse element of the true coefficients given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf_prec(x, y, ...)

## S3 method for class 'summary.bvharsp'
conf_prec(x, y, truth_thr = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf_prec_+3A_x">x</code></td>
<td>
<p><code>summary.bvharsp</code> object.</p>
</td></tr>
<tr><td><code id="conf_prec_+3A_y">y</code></td>
<td>
<p>True inclusion variable.</p>
</td></tr>
<tr><td><code id="conf_prec_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="conf_prec_+3A_truth_thr">truth_thr</code></td>
<td>
<p>Threshold value when using non-sparse true coefficient matrix. By default, <code>0</code> for sparse matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the element of the estimate <code class="reqn">\hat\Phi</code> is smaller than some threshold,
it is treated to be zero.
Then the precision is computed by
</p>
<p style="text-align: center;"><code class="reqn">precision = \frac{TP}{TP + FP}</code>
</p>

<p>where TP is true positive, and FP is false positive.
</p>


<h3>Value</h3>

<p>Precision value in confusion table
</p>


<h3>References</h3>

<p>Bai, R., &amp; Ghosh, M. (2018). High-dimensional multivariate posterior consistency under global–local shrinkage priors. Journal of Multivariate Analysis, 167, 157–170.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion()</a></code>
</p>

<hr>
<h2 id='conf_recall'>Evaluate the Sparsity Estimation Based on Recall</h2><span id='topic+conf_recall'></span><span id='topic+conf_recall.summary.bvharsp'></span>

<h3>Description</h3>

<p>This function computes recall for sparse element of the true coefficients given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf_recall(x, y, ...)

## S3 method for class 'summary.bvharsp'
conf_recall(x, y, truth_thr = 0L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf_recall_+3A_x">x</code></td>
<td>
<p><code>summary.bvharsp</code> object.</p>
</td></tr>
<tr><td><code id="conf_recall_+3A_y">y</code></td>
<td>
<p>True inclusion variable.</p>
</td></tr>
<tr><td><code id="conf_recall_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="conf_recall_+3A_truth_thr">truth_thr</code></td>
<td>
<p>Threshold value when using non-sparse true coefficient matrix. By default, <code>0</code> for sparse matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Precision is computed by
</p>
<p style="text-align: center;"><code class="reqn">recall = \frac{TP}{TP + FN}</code>
</p>

<p>where TP is true positive, and FN is false negative.
</p>


<h3>Value</h3>

<p>Recall value in confusion table
</p>


<h3>References</h3>

<p>Bai, R., &amp; Ghosh, M. (2018). High-dimensional multivariate posterior consistency under global–local shrinkage priors. Journal of Multivariate Analysis, 167, 157–170.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion()</a></code>
</p>

<hr>
<h2 id='confusion'>Evaluate the Sparsity Estimation Based on Confusion Matrix</h2><span id='topic+confusion'></span><span id='topic+confusion.summary.bvharsp'></span>

<h3>Description</h3>

<p>This function computes FDR (false discovery rate) and FNR (false negative rate) for sparse element of the true coefficients given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion(x, y, ...)

## S3 method for class 'summary.bvharsp'
confusion(x, y, truth_thr = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusion_+3A_x">x</code></td>
<td>
<p><code>summary.bvharsp</code> object.</p>
</td></tr>
<tr><td><code id="confusion_+3A_y">y</code></td>
<td>
<p>True inclusion variable.</p>
</td></tr>
<tr><td><code id="confusion_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="confusion_+3A_truth_thr">truth_thr</code></td>
<td>
<p>Threshold value when using non-sparse true coefficient matrix. By default, <code>0</code> for sparse matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When using this function, the true coefficient matrix <code class="reqn">\Phi</code> should be sparse.
</p>
<p>In this confusion matrix, positive (0) means sparsity.
FP is false positive, and TP is true positive.
FN is false negative, and FN is false negative.
</p>


<h3>Value</h3>

<p>Confusion table as following.</p>

<table>
<tr>
 <td style="text-align: center;">
   True-estimate </td><td style="text-align: center;"> Positive (0) </td><td style="text-align: center;"> Negative (1) </td>
</tr>
<tr>
 <td style="text-align: center;">
   Positive (0) </td><td style="text-align: center;"> TP </td><td style="text-align: center;"> FN </td>
</tr>
<tr>
 <td style="text-align: center;">
   Negative (1) </td><td style="text-align: center;"> FP </td><td style="text-align: center;"> TN </td>
</tr>
<tr>
 <td style="text-align: center;">
</td>
</tr>

</table>



<h3>References</h3>

<p>Bai, R., &amp; Ghosh, M. (2018). High-dimensional multivariate posterior consistency under global–local shrinkage priors. Journal of Multivariate Analysis, 167, 157–170.
</p>

<hr>
<h2 id='divide_ts'>Split a Time Series Dataset into Train-Test Set</h2><span id='topic+divide_ts'></span>

<h3>Description</h3>

<p>Split a given time series dataset into train and test set for evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divide_ts(y, n_ahead)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="divide_ts_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="divide_ts_+3A_n_ahead">n_ahead</code></td>
<td>
<p>step to evaluate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of two datasets, train and test.
</p>

<hr>
<h2 id='etf_vix'>CBOE ETF Volatility Index Dataset</h2><span id='topic+etf_vix'></span>

<h3>Description</h3>

<p>Chicago Board Options Exchage (CBOE) Exchange Traded Funds (ETFs) volatility index from FRED.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>etf_vix
</code></pre>


<h3>Format</h3>

<p>A data frame of 1006 row and 9 columns:
</p>
<p>From 2012-01-09 to 2015-06-27,
33 missing observations were interpolated by <code><a href="stats.html#topic+approxfun">stats::approx()</a></code> with <code>linear</code>.
</p>

<dl>
<dt>GVZCLS</dt><dd><p>Gold ETF volatility index</p>
</dd>
<dt>VXFXICLS</dt><dd><p>China ETF volatility index</p>
</dd>
<dt>OVXCLS</dt><dd><p>Crude Oil ETF volatility index</p>
</dd>
<dt>VXEEMCLS</dt><dd><p>Emerging Markets ETF volatility index</p>
</dd>
<dt>EVZCLS</dt><dd><p>EuroCurrency ETF volatility index</p>
</dd>
<dt>VXSLVCLS</dt><dd><p>Silver ETF volatility index</p>
</dd>
<dt>VXGDXCLS</dt><dd><p>Gold Miners ETF volatility index</p>
</dd>
<dt>VXXLECLS</dt><dd><p>Energy Sector ETF volatility index</p>
</dd>
<dt>VXEWZCLS</dt><dd><p>Brazil ETF volatility index</p>
</dd>
</dl>



<h3>Details</h3>

<p>Copyright, 2016, Chicago Board Options Exchange, Inc.
</p>
<p>Note that, in this data frame, dates column is removed.
This dataset interpolated 36 missing observations (nontrading dates) using <code>imputeTS::na_interpolation()</code>.
</p>


<h3>Source</h3>

<p>Source: <a href="https://www.cboe.com">https://www.cboe.com</a>
</p>
<p>Release: <a href="https://www.cboe.com/us/options/market_statistics/daily/">https://www.cboe.com/us/options/market_statistics/daily/</a>
</p>


<h3>References</h3>

<p>Chicago Board Options Exchange, CBOE Gold ETF Volatility Index (GVZCLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/GVZCLS">https://fred.stlouisfed.org/series/GVZCLS</a>, July 31, 2021.
</p>
<p>Chicago Board Options Exchange, CBOE China ETF Volatility Index (VXFXICLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/VXFXICLS">https://fred.stlouisfed.org/series/VXFXICLS</a>, August 1, 2021.
</p>
<p>Chicago Board Options Exchange, CBOE Crude Oil ETF Volatility Index (OVXCLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/OVXCLS">https://fred.stlouisfed.org/series/OVXCLS</a>, August 1, 2021.
</p>
<p>Chicago Board Options Exchange, CBOE Emerging Markets ETF Volatility Index (VXEEMCLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/VXEEMCLS">https://fred.stlouisfed.org/series/VXEEMCLS</a>, August 1, 2021.
</p>
<p>Chicago Board Options Exchange, CBOE EuroCurrency ETF Volatility Index (EVZCLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/EVZCLS">https://fred.stlouisfed.org/series/EVZCLS</a>, August 2, 2021.
</p>
<p>Chicago Board Options Exchange, CBOE Silver ETF Volatility Index (VXSLVCLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/VXSLVCLS">https://fred.stlouisfed.org/series/VXSLVCLS</a>, August 1, 2021.
</p>
<p>Chicago Board Options Exchange, CBOE Gold Miners ETF Volatility Index (VXGDXCLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/VXGDXCLS">https://fred.stlouisfed.org/series/VXGDXCLS</a>, August 1, 2021.
</p>
<p>Chicago Board Options Exchange, CBOE Energy Sector ETF Volatility Index (VXXLECLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/VXXLECLS">https://fred.stlouisfed.org/series/VXXLECLS</a>, August 1, 2021.
</p>
<p>Chicago Board Options Exchange, CBOE Brazil ETF Volatility Index (VXEWZCLS), retrieved from FRED, Federal Reserve Bank of St. Louis; <a href="https://fred.stlouisfed.org/series/VXEWZCLS">https://fred.stlouisfed.org/series/VXEWZCLS</a>, August 2, 2021.
</p>

<hr>
<h2 id='financial_history_appendix'>Time points and Financial Events</h2><span id='topic+financial_history_appendix'></span><span id='topic+trading_day'></span>

<h3>Description</h3>

<p>This page describes about some important financial events in 20th century.
This might give some hint when cutting data and why we provides datasets in limited period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trading_day
</code></pre>


<h3>Format</h3>

<p>A vector <code>trading_day</code> saves dates of each <a href="#topic+etf_vix">etf_vix</a> and <a href="#topic+oxfordman">oxfordman</a>.
</p>


<h3>Outline</h3>


<ul>
<li><p> 2000: Dot-com bubble
</p>
</li>
<li><p> 2001: September 11 terror and Enron scandal
</p>
</li>
<li><p> 2003: Iraq war (until 2011)
</p>
</li>
<li><p> 2007 to 2008: Financial crisis (US)
</p>

<ul>
<li><p> 2007: Subprime morgage crisis
</p>
</li>
<li><p> 2008: Bankrupcy of Lehman Brothers
</p>
</li></ul>

</li>
<li><p> 2010 to 2016: European sovereign dept crisis
</p>

<ul>
<li><p> 2010: Greek debt crisis
</p>
</li>
<li><p> 2011: Italian default
</p>
</li>
<li><p> 2015: Greek default
</p>
</li>
<li><p> 2016: Brexit
</p>
</li></ul>

</li>
<li><p> 2018: US-China trade war
</p>
</li>
<li><p> 2019: Brexit
</p>
</li>
<li><p> 2020: COVID-19
</p>
</li></ul>



<h3>About Datasets in this package</h3>

<p><a href="#topic+etf_vix">etf_vix</a> and <a href="#topic+oxfordman">oxfordman</a> range from 2012-01-09 to 2015-06-27 (only weekdays).
Each year corresponds to Italian default and Grexit.
If you wonder the exact vector of the date, see <a href="#topic+trading_day">trading_day</a> vector.
</p>


<h3>Notice</h3>

<p>If you want other time period, see codes in the Github repo for the dataset.
</p>

<ul>
<li> <p><code>etf_vix</code>: <a href="https://github.com/ygeunkim/bvhar/blob/master/data-raw/etf_vix.R">ygeunkim/bvhar/data-raw/etf_vix.R</a>
</p>
</li>
<li> <p><code>oxfordman</code>: <a href="https://github.com/ygeunkim/bvhar/blob/master/data-raw/oxfordman_long.R">ygeunkim/bvhar/data-raw/oxfordman_long.R</a>
</p>
</li></ul>

<p>You can download what you want by changing a few lines.
</p>

<hr>
<h2 id='fitted.varlse'>Fitted Matrix from Multivariate Time Series Models</h2><span id='topic+fitted.varlse'></span><span id='topic+fitted.vharlse'></span><span id='topic+fitted.bvarmn'></span><span id='topic+fitted.bvarflat'></span><span id='topic+fitted.bvharmn'></span>

<h3>Description</h3>

<p>By defining <code><a href="stats.html#topic+fitted.values">stats::fitted()</a></code> for each model, this function returns fitted matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
fitted(object, ...)

## S3 method for class 'vharlse'
fitted(object, ...)

## S3 method for class 'bvarmn'
fitted(object, ...)

## S3 method for class 'bvarflat'
fitted(object, ...)

## S3 method for class 'bvharmn'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.varlse_+3A_object">object</code></td>
<td>
<p>Model object</p>
</td></tr>
<tr><td><code id="fitted.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+matrix">matrix</a> object.
</p>

<hr>
<h2 id='forecast_expand'>Out-of-sample Forecasting based on Expanding Window</h2><span id='topic+forecast_expand'></span>

<h3>Description</h3>

<p>This function conducts expanding window forecasting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forecast_expand(object, n_ahead, y_test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forecast_expand_+3A_object">object</code></td>
<td>
<p>Model object</p>
</td></tr>
<tr><td><code id="forecast_expand_+3A_n_ahead">n_ahead</code></td>
<td>
<p>Step to forecast in rolling window scheme</p>
</td></tr>
<tr><td><code id="forecast_expand_+3A_y_test">y_test</code></td>
<td>
<p>Test data to be compared. Use <code><a href="#topic+divide_ts">divide_ts()</a></code> if you don't have separate evaluation dataset.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Expanding windows forecasting fixes the starting period.
It moves the window ahead and forecast h-ahead in <code>y_test</code> set.
</p>


<h3>Value</h3>

<p><code>predbvhar_expand</code> <a href="base.html#topic+class">class</a>
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Athanasopoulos, G. (2021). <em>Forecasting: Principles and practice</em> (3rd ed.). OTEXTS. <a href="https://otexts.com/fpp3/">https://otexts.com/fpp3/</a>
</p>


<h3>See Also</h3>

<p>See <a href="#topic+ts_forecasting_cv">ts_forecasting_cv</a> for out-of-sample forecasting methods.
</p>

<hr>
<h2 id='forecast_roll'>Out-of-sample Forecasting based on Rolling Window</h2><span id='topic+forecast_roll'></span><span id='topic+print.bvharcv'></span><span id='topic+knit_print.bvharcv'></span>

<h3>Description</h3>

<p>This function conducts rolling window forecasting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forecast_roll(object, n_ahead, y_test, roll_thread = 1, mod_thread = 1)

## S3 method for class 'bvharcv'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvharcv'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forecast_roll_+3A_object">object</code></td>
<td>
<p>Model object</p>
</td></tr>
<tr><td><code id="forecast_roll_+3A_n_ahead">n_ahead</code></td>
<td>
<p>Step to forecast in rolling window scheme</p>
</td></tr>
<tr><td><code id="forecast_roll_+3A_y_test">y_test</code></td>
<td>
<p>Test data to be compared. Use <code><a href="#topic+divide_ts">divide_ts()</a></code> if you don't have separate evaluation dataset.</p>
</td></tr>
<tr><td><code id="forecast_roll_+3A_roll_thread">roll_thread</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Number of threads when rolling window</p>
</td></tr>
<tr><td><code id="forecast_roll_+3A_mod_thread">mod_thread</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Number of threads when fitting the models</p>
</td></tr>
<tr><td><code id="forecast_roll_+3A_x">x</code></td>
<td>
<p><code>bvharcv</code> object</p>
</td></tr>
<tr><td><code id="forecast_roll_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="forecast_roll_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rolling windows forecasting fixes window size.
It moves the window ahead and forecast h-ahead in <code>y_test</code> set.
</p>


<h3>Value</h3>

<p><code>predbvhar_roll</code> <a href="base.html#topic+class">class</a>
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Athanasopoulos, G. (2021). <em>Forecasting: Principles and practice</em> (3rd ed.). OTEXTS.
</p>


<h3>See Also</h3>

<p>See <a href="#topic+ts_forecasting_cv">ts_forecasting_cv</a> for out-of-sample forecasting methods.
</p>

<hr>
<h2 id='FPE'>Final Prediction Error Criterion</h2><span id='topic+FPE'></span>

<h3>Description</h3>

<p>Generic function that computes FPE criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FPE(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FPE_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="FPE_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>FPE value.
</p>

<hr>
<h2 id='FPE.varlse'>Final Prediction Error Criterion of Multivariate Time Series Model</h2><span id='topic+FPE.varlse'></span><span id='topic+FPE.vharlse'></span>

<h3>Description</h3>

<p>Compute FPE of VAR(p), VHAR, BVAR(p), and BVHAR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
FPE(object, ...)

## S3 method for class 'vharlse'
FPE(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FPE.varlse_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="FPE.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\tilde{\Sigma}_e</code> be the MLE
and let <code class="reqn">\hat{\Sigma}_e</code> be the unbiased estimator (<code>covmat</code>) for <code class="reqn">\Sigma_e</code>.
Note that
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\Sigma}_e = \frac{s - k}{n} \hat{\Sigma}_e</code>
</p>

<p>Then
</p>
<p style="text-align: center;"><code class="reqn">FPE(p) = (\frac{s + k}{s - k})^m \det \tilde{\Sigma}_e</code>
</p>



<h3>Value</h3>

<p>FPE value.
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='fromse'>Evaluate the Estimation Based on Frobenius Norm</h2><span id='topic+fromse'></span><span id='topic+fromse.bvharsp'></span>

<h3>Description</h3>

<p>This function computes estimation error given estimated model and true coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fromse(x, y, ...)

## S3 method for class 'bvharsp'
fromse(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fromse_+3A_x">x</code></td>
<td>
<p>Estimated model.</p>
</td></tr>
<tr><td><code id="fromse_+3A_y">y</code></td>
<td>
<p>Coefficient matrix to be compared.</p>
</td></tr>
<tr><td><code id="fromse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider the Frobenius Norm <code class="reqn">\lVert \cdot \rVert_F</code>.
let <code class="reqn">\hat{\Phi}</code> be nrow x k the estimates,
and let <code class="reqn">\Phi</code> be the true coefficients matrix.
Then the function computes estimation error by
</p>
<p style="text-align: center;"><code class="reqn">MSE = 100 \frac{\lVert \hat{\Phi} - \Phi \rVert_F}{nrow \times k}</code>
</p>



<h3>Value</h3>

<p>Frobenius norm value
</p>


<h3>References</h3>

<p>Bai, R., &amp; Ghosh, M. (2018). High-dimensional multivariate posterior consistency under global–local shrinkage priors. Journal of Multivariate Analysis, 167, 157–170.
</p>

<hr>
<h2 id='geom_eval'>Adding Test Data Layer</h2><span id='topic+geom_eval'></span>

<h3>Description</h3>

<p>This function adds a layer of test dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geom_eval(data, colour = "red", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geom_eval_+3A_data">data</code></td>
<td>
<p>Test data to draw, which has the same format with the train data.</p>
</td></tr>
<tr><td><code id="geom_eval_+3A_colour">colour</code></td>
<td>
<p>Color of the line (By default, <code>"red"</code>).</p>
</td></tr>
<tr><td><code id="geom_eval_+3A_...">...</code></td>
<td>
<p>Other arguments passed on the <code><a href="ggplot2.html#topic+geom_path">ggplot2::geom_path()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot layer
</p>

<hr>
<h2 id='gg_loss'>Compare Lists of Models</h2><span id='topic+gg_loss'></span>

<h3>Description</h3>

<p>Draw plot of test error for given models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_loss(
  mod_list,
  y,
  type = c("mse", "mae", "mape", "mase"),
  mean_line = FALSE,
  line_param = list(),
  mean_param = list(),
  viridis = FALSE,
  viridis_option = "D",
  NROW = NULL,
  NCOL = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_loss_+3A_mod_list">mod_list</code></td>
<td>
<p>Lists of forecast results (<code>predbvhar</code> objects)</p>
</td></tr>
<tr><td><code id="gg_loss_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data and predict$forecast.</p>
</td></tr>
<tr><td><code id="gg_loss_+3A_type">type</code></td>
<td>
<p>Loss function to be used (<code>"mse"</code>: MSE, <code>"mae"</code>: MAE, <code>mape</code>: MAPE, <code>"mase"</code>: MASE)</p>
</td></tr>
<tr><td><code id="gg_loss_+3A_mean_line">mean_line</code></td>
<td>
<p>Whether to draw average loss. By default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gg_loss_+3A_line_param">line_param</code></td>
<td>
<p>Parameter lists for <code><a href="ggplot2.html#topic+geom_path">ggplot2::geom_path()</a></code>.</p>
</td></tr>
<tr><td><code id="gg_loss_+3A_mean_param">mean_param</code></td>
<td>
<p>Parameter lists for average loss with <code><a href="ggplot2.html#topic+geom_abline">ggplot2::geom_hline()</a></code>.</p>
</td></tr>
<tr><td><code id="gg_loss_+3A_viridis">viridis</code></td>
<td>
<p>If <code>TRUE</code>, scale CI and forecast line using <code><a href="ggplot2.html#topic+scale_viridis">ggplot2::scale_fill_viridis_d()</a></code> and <a href="ggplot2.html#topic+scale_viridis">ggplot2::scale_colour_viridis_d</a>, respectively.</p>
</td></tr>
<tr><td><code id="gg_loss_+3A_viridis_option">viridis_option</code></td>
<td>
<p>Option for viridis string. See <code>option</code> of <a href="ggplot2.html#topic+scale_viridis">ggplot2::scale_colour_viridis_d</a>. Choose one of <code>c("A", "B", "C", "D", "E")</code>. By default, <code>"D"</code>.</p>
</td></tr>
<tr><td><code id="gg_loss_+3A_nrow">NROW</code></td>
<td>
<p><code>nrow</code> of <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code></p>
</td></tr>
<tr><td><code id="gg_loss_+3A_ncol">NCOL</code></td>
<td>
<p><code>ncol</code> of <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code></p>
</td></tr>
<tr><td><code id="gg_loss_+3A_...">...</code></td>
<td>
<p>Additional options for <code>geom_loss</code> (<code>inherit.aes</code> and <code>show.legend</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+mse">mse()</a></code> to compute MSE for given forecast result
</p>
</li>
<li> <p><code><a href="#topic+mae">mae()</a></code> to compute MAE for given forecast result
</p>
</li>
<li> <p><code><a href="#topic+mape">mape()</a></code> to compute MAPE for given forecast result
</p>
</li>
<li> <p><code><a href="#topic+mase">mase()</a></code> to compute MASE for given forecast result
</p>
</li></ul>


<hr>
<h2 id='horseshoe_bvar_algo'>Horseshoe Prior in BVAR</h2><span id='topic+horseshoe_bvar_algo'></span>

<h3>Description</h3>

<p>This page describes Horseshoe prior and its Gibbs sampler
in a VAR model.
</p>


<h3>References</h3>

<p>Carvalho, C. M., Polson, N. G., &amp; Scott, J. G. (2010). The horseshoe estimator for sparse signals. Biometrika, 97(2), 465–480.
</p>
<p>Makalic, E., &amp; Schmidt, D. F. (2016). <em>A Simple Sampler for the Horseshoe Estimator</em>. IEEE Signal Processing Letters, 23(1), 179–182.
</p>

<hr>
<h2 id='HQ'>Hannan-Quinn Criterion</h2><span id='topic+HQ'></span><span id='topic+HQ.logLik'></span>

<h3>Description</h3>

<p>Generic function that computes HQ criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HQ(object, ...)

## S3 method for class 'logLik'
HQ(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HQ_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="HQ_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula is
</p>
<p style="text-align: center;"><code class="reqn">HQ = -2 \log p(y \mid \hat\theta) + k \log\log(n)</code>
</p>

<p>whic can be computed by
<code>AIC(object, ..., k = 2 * log(log(nobs(object))))</code> with <code><a href="stats.html#topic+AIC">stats::AIC()</a></code>.
</p>


<h3>Value</h3>

<p>HQ value.
</p>


<h3>References</h3>

<p>Hannan, E.J. and Quinn, B.G. (1979). <em>The Determination of the Order of an Autoregression</em>. Journal of the Royal Statistical Society: Series B (Methodological), 41: 190-195.
</p>

<hr>
<h2 id='HQ.varlse'>Hannan-Quinn Criterion of Multivariate Time Series Model</h2><span id='topic+HQ.varlse'></span><span id='topic+HQ.vharlse'></span><span id='topic+HQ.bvarmn'></span><span id='topic+HQ.bvarflat'></span><span id='topic+HQ.bvharmn'></span>

<h3>Description</h3>

<p>Compute HQ of VAR(p), VHAR, BVAR(p), and BVHAR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
HQ(object, ...)

## S3 method for class 'vharlse'
HQ(object, ...)

## S3 method for class 'bvarmn'
HQ(object, ...)

## S3 method for class 'bvarflat'
HQ(object, ...)

## S3 method for class 'bvharmn'
HQ(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HQ.varlse_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="HQ.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\tilde{\Sigma}_e</code> be the MLE
and let <code class="reqn">\hat{\Sigma}_e</code> be the unbiased estimator (<code>covmat</code>) for <code class="reqn">\Sigma_e</code>.
Note that
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\Sigma}_e = \frac{s - k}{n} \hat{\Sigma}_e</code>
</p>

<p>Then
</p>
<p style="text-align: center;"><code class="reqn">HQ(p) = \log \det \Sigma_e + \frac{2 \log \log s}{s}(\text{number of freely estimated parameters})</code>
</p>

<p>where the number of freely estimated parameters is <code class="reqn">pm^2</code>.
</p>


<h3>Value</h3>

<p>HQ value.
</p>


<h3>References</h3>

<p>Hannan, E.J. and Quinn, B.G. (1979). <em>The Determination of the Order of an Autoregression</em>. Journal of the Royal Statistical Society: Series B (Methodological), 41: 190-195.
</p>
<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>
<p>Quinn, B.G. (1980). <em>Order Determination for a Multivariate Autoregression</em>. Journal of the Royal Statistical Society: Series B (Methodological), 42: 182-185.
</p>

<hr>
<h2 id='init_ssvs'>Initial Parameters of Stochastic Search Variable Selection (SSVS) Model</h2><span id='topic+init_ssvs'></span><span id='topic+print.ssvsinit'></span><span id='topic+knit_print.ssvsinit'></span>

<h3>Description</h3>

<p>Set initial parameters before starting Gibbs sampler for SSVS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_ssvs(
  init_coef,
  init_coef_dummy,
  init_chol,
  init_chol_dummy,
  type = c("user", "auto")
)

## S3 method for class 'ssvsinit'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'ssvsinit'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_ssvs_+3A_init_coef">init_coef</code></td>
<td>
<p>Initial coefficient matrix. Initialize with an array or list for multiple chains.</p>
</td></tr>
<tr><td><code id="init_ssvs_+3A_init_coef_dummy">init_coef_dummy</code></td>
<td>
<p>Initial indicator matrix (1-0) corresponding to each component of coefficient. Initialize with an array or list for multiple chains.</p>
</td></tr>
<tr><td><code id="init_ssvs_+3A_init_chol">init_chol</code></td>
<td>
<p>Initial cholesky factor (upper triangular). Initialize with an array or list for multiple chains.</p>
</td></tr>
<tr><td><code id="init_ssvs_+3A_init_chol_dummy">init_chol_dummy</code></td>
<td>
<p>Initial indicator matrix (1-0) corresponding to each component of cholesky factor. Initialize with an array or list for multiple chains.</p>
</td></tr>
<tr><td><code id="init_ssvs_+3A_type">type</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Type to choose initial values. One of <code>"user"</code> (User-given) and <code>"auto"</code> (OLS for coefficients and 1 for dummy).</p>
</td></tr>
<tr><td><code id="init_ssvs_+3A_x">x</code></td>
<td>
<p><code>ssvsinit</code></p>
</td></tr>
<tr><td><code id="init_ssvs_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="init_ssvs_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Set SSVS initialization for the VAR model.
</p>

<ul>
<li> <p><code>init_coef</code>: (kp + 1) x m <code class="reqn">A</code> coefficient matrix.
</p>
</li>
<li> <p><code>init_coef_dummy</code>: kp x m <code class="reqn">\Gamma</code> dummy matrix to restrict the coefficients.
</p>
</li>
<li> <p><code>init_chol</code>: k x k <code class="reqn">\Psi</code> upper triangular cholesky factor, which <code class="reqn">\Psi \Psi^\intercal = \Sigma_e^{-1}</code>.
</p>
</li>
<li> <p><code>init_chol_dummy</code>: k x k <code class="reqn">\Omega</code> upper triangular dummy matrix to restrict the cholesky factor.
</p>
</li></ul>

<p>Denote that <code>init_chol</code> and <code>init_chol_dummy</code> should be upper_triangular or the function gives error.
</p>
<p>For parallel chain initialization, assign three-dimensional array or three-length list.
</p>


<h3>Value</h3>

<p><code>ssvsinit</code> object
</p>


<h3>References</h3>

<p>George, E. I., &amp; McCulloch, R. E. (1993). <em>Variable Selection via Gibbs Sampling</em>. Journal of the American Statistical Association, 88(423), 881–889.
</p>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions</em>. Journal of Econometrics, 142(1), 553–580.
</p>
<p>Koop, G., &amp; Korobilis, D. (2009). <em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>. Foundations and Trends® in Econometrics, 3(4), 267–358.
</p>

<hr>
<h2 id='is.stable'>Stability of the process</h2><span id='topic+is.stable'></span>

<h3>Description</h3>

<p>Stability of the process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.stable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.stable_+3A_x">x</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="is.stable_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical class
</p>

<hr>
<h2 id='is.stable.varlse'>Stability of VAR Coefficient Matrix</h2><span id='topic+is.stable.varlse'></span><span id='topic+is.stable.vharlse'></span><span id='topic+is.stable.bvarmn'></span><span id='topic+is.stable.bvarflat'></span><span id='topic+is.stable.bvharmn'></span>

<h3>Description</h3>

<p>Check the stability condition of VAR(p) coefficient matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
is.stable(x, ...)

## S3 method for class 'vharlse'
is.stable(x, ...)

## S3 method for class 'bvarmn'
is.stable(x, ...)

## S3 method for class 'bvarflat'
is.stable(x, ...)

## S3 method for class 'bvharmn'
is.stable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.stable.varlse_+3A_x">x</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="is.stable.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>VAR(p) is stable if
</p>
<p style="text-align: center;"><code class="reqn">\det(I_m - A z) \neq 0</code>
</p>

<p>for <code class="reqn">\lvert z \rvert \le 1</code>.
</p>


<h3>Value</h3>

<p>logical class
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='is.varlse'>See if the Object a class in this package</h2><span id='topic+is.varlse'></span><span id='topic+is.vharlse'></span><span id='topic+is.bvarmn'></span><span id='topic+is.bvarflat'></span><span id='topic+is.bvharmn'></span><span id='topic+is.predbvhar'></span><span id='topic+is.bvharcv'></span><span id='topic+is.bvharspec'></span><span id='topic+is.bvharpriorspec'></span><span id='topic+is.bvharemp'></span><span id='topic+is.boundbvharemp'></span><span id='topic+is.interceptspec'></span><span id='topic+is.ssvsinput'></span><span id='topic+is.ssvsinit'></span><span id='topic+is.horseshoespec'></span><span id='topic+is.svspec'></span>

<h3>Description</h3>

<p>This function returns <code>TRUE</code> if the input is the <a href="base.html#topic+class">class</a> defined by this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.varlse(x)

is.vharlse(x)

is.bvarmn(x)

is.bvarflat(x)

is.bvharmn(x)

is.predbvhar(x)

is.bvharcv(x)

is.bvharspec(x)

is.bvharpriorspec(x)

is.bvharemp(x)

is.boundbvharemp(x)

is.interceptspec(x)

is.ssvsinput(x)

is.ssvsinit(x)

is.bvharpriorspec(x)

is.horseshoespec(x)

is.svspec(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.varlse_+3A_x">x</code></td>
<td>
<p>Object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical class
</p>

<hr>
<h2 id='logLik.varlse'>Extract Log-Likelihood of Multivariate Time Series Model</h2><span id='topic+logLik.varlse'></span><span id='topic+logLik.vharlse'></span><span id='topic+logLik.bvarmn'></span><span id='topic+logLik.bvarflat'></span><span id='topic+logLik.bvharmn'></span>

<h3>Description</h3>

<p>Compute log-likelihood function value of VAR(p), VHAR, BVAR(p), and BVHAR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
logLik(object, ...)

## S3 method for class 'vharlse'
logLik(object, ...)

## S3 method for class 'bvarmn'
logLik(object, ...)

## S3 method for class 'bvarflat'
logLik(object, ...)

## S3 method for class 'bvharmn'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.varlse_+3A_object">object</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="logLik.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider the response matrix <code class="reqn">Y_0</code>.
Let <code class="reqn">n</code> be the total number of sample,
let <code class="reqn">m</code> be the dimension of the time series,
let <code class="reqn">p</code> be the order of the model,
and let <code class="reqn">s = n - p</code>.
Likelihood of VAR(p) has
</p>
<p style="text-align: center;"><code class="reqn">Y_0 \mid B, \Sigma_e \sim MN(X_0 B, I_s, \Sigma_e)</code>
</p>

<p>where <code class="reqn">X_0</code> is the design matrix,
and MN is <a href="https://en.wikipedia.org/wiki/Matrix_normal_distribution">matrix normal distribution</a>.
</p>
<p>Then log-likelihood of vector autoregressive model family is specified by
</p>
<p style="text-align: center;"><code class="reqn">\log p(Y_0 \mid B, \Sigma_e) = - \frac{sm}{2} \log 2\pi - \frac{s}{2} \log \det \Sigma_e - \frac{1}{2} tr( (Y_0 - X_0 B) \Sigma_e^{-1} (Y_0 - X_0 B)^T )</code>
</p>

<p>In addition, recall that the OLS estimator for the matrix coefficient matrix is the same as MLE under the Gaussian assumption.
MLE for <code class="reqn">\Sigma_e</code> has different denominator, <code class="reqn">s</code>.
</p>
<p style="text-align: center;"><code class="reqn">\hat{B} = \hat{B}^{LS} = \hat{B}^{ML} = (X_0^T X_0)^{-1} X_0^T Y_0</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat\Sigma_e = \frac{1}{s - k} (Y_0 - X_0 \hat{B})^T (Y_0 - X_0 \hat{B})</code>
</p>

<p style="text-align: center;"><code class="reqn">\tilde\Sigma_e = \frac{1}{s} (Y_0 - X_0 \hat{B})^T (Y_0 - X_0 \hat{B}) = \frac{s - k}{s} \hat\Sigma_e</code>
</p>

<p>In case of VHAR, just consider the linear relationship.
</p>
<p>While frequentist models use OLS and MLE for coefficient and covariance matrices, Bayesian models implement posterior means.
</p>


<h3>Value</h3>

<p>A <code>logLik</code> object.
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>
<p>Corsi, F. (2008). <em>A Simple Approximate Long-Memory Model of Realized Volatility</em>. Journal of Financial Econometrics, 7(2), 174–196.
</p>
<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>
<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>
<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+var_lm">var_lm()</a></code>
</p>
</li>
<li> <p><a href="#topic+var_design_formulation">var_design_formulation</a>
</p>
</li></ul>

<p><code><a href="#topic+vhar_lm">vhar_lm()</a></code>
</p>
<p><code><a href="#topic+bvar_minnesota">bvar_minnesota()</a></code>
</p>
<p><code><a href="#topic+bvar_flat">bvar_flat()</a></code>
</p>
<p><code><a href="#topic+bvhar_minnesota">bvhar_minnesota()</a></code>
</p>

<hr>
<h2 id='lpl'>Evaluate the Model Based on Log Predictive Likelihood</h2><span id='topic+lpl'></span><span id='topic+lpl.predsv'></span>

<h3>Description</h3>

<p>This function computes LPL given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpl(x, y, ...)

## S3 method for class 'predsv'
lpl(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpl_+3A_x">x</code></td>
<td>
<p>Forecasting object</p>
</td></tr>
<tr><td><code id="lpl_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="lpl_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cross, J. L., Hou, C., &amp; Poon, A. (2020). <em>Macroeconomic forecasting with large Bayesian VARs: Global-local priors and the illusion of sparsity</em>. International Journal of Forecasting, 36(3), 899–915.
</p>
<p>Gruber, L., &amp; Kastner, G. (2022). <em>Forecasting macroeconomic data with Bayesian VARs: Sparse or dense? It depends!</em> arXiv.
</p>

<hr>
<h2 id='mae'>Evaluate the Model Based on MAE (Mean Absolute Error)</h2><span id='topic+mae'></span><span id='topic+mae.predbvhar'></span><span id='topic+mae.bvharcv'></span>

<h3>Description</h3>

<p>This function computes MAE given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mae(x, y, ...)

## S3 method for class 'predbvhar'
mae(x, y, ...)

## S3 method for class 'bvharcv'
mae(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mae_+3A_x">x</code></td>
<td>
<p>Forecasting object</p>
</td></tr>
<tr><td><code id="mae_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="mae_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">e_t = y_t - \hat{y}_t</code>.
MAE is defined by
</p>
<p style="text-align: center;"><code class="reqn">MSE = mean(\lvert e_t \rvert)</code>
</p>

<p>Some researchers prefer MAE to MSE because it is less sensitive to outliers.
</p>


<h3>Value</h3>

<p>MAE vector corressponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>

<hr>
<h2 id='mape'>Evaluate the Model Based on MAPE (Mean Absolute Percentage Error)</h2><span id='topic+mape'></span><span id='topic+mape.predbvhar'></span><span id='topic+mape.bvharcv'></span>

<h3>Description</h3>

<p>This function computes MAPE given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mape(x, y, ...)

## S3 method for class 'predbvhar'
mape(x, y, ...)

## S3 method for class 'bvharcv'
mape(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mape_+3A_x">x</code></td>
<td>
<p>Forecasting object</p>
</td></tr>
<tr><td><code id="mape_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="mape_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">e_t = y_t - \hat{y}_t</code>.
Percentage error is defined by <code class="reqn">p_t = 100 e_t / Y_t</code> (100 can be omitted since comparison is the focus).
</p>
<p style="text-align: center;"><code class="reqn">MAPE = mean(\lvert p_t \rvert)</code>
</p>



<h3>Value</h3>

<p>MAPE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>

<hr>
<h2 id='mase'>Evaluate the Model Based on MASE (Mean Absolute Scaled Error)</h2><span id='topic+mase'></span><span id='topic+mase.predbvhar'></span><span id='topic+mase.bvharcv'></span>

<h3>Description</h3>

<p>This function computes MASE given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mase(x, y, ...)

## S3 method for class 'predbvhar'
mase(x, y, ...)

## S3 method for class 'bvharcv'
mase(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mase_+3A_x">x</code></td>
<td>
<p>Forecasting object</p>
</td></tr>
<tr><td><code id="mase_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="mase_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">e_t = y_t - \hat{y}_t</code>.
Scaled error is defined by
</p>
<p style="text-align: center;"><code class="reqn">q_t = \frac{e_t}{\sum_{i = 2}^{n} \lvert Y_i - Y_{i - 1} \rvert / (n - 1)}</code>
</p>

<p>so that the error can be free of the data scale.
Then
</p>
<p style="text-align: center;"><code class="reqn">MASE = mean(\lvert q_t \rvert)</code>
</p>

<p>Here, <code class="reqn">Y_i</code> are the points in the sample, i.e. errors are scaled by the in-sample mean absolute error (<code class="reqn">mean(\lvert e_t \rvert)</code>) from the naive random walk forecasting.
</p>


<h3>Value</h3>

<p>MASE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>

<hr>
<h2 id='mrae'>Evaluate the Model Based on MRAE (Mean Relative Absolute Error)</h2><span id='topic+mrae'></span><span id='topic+mrae.predbvhar'></span><span id='topic+mrae.bvharcv'></span>

<h3>Description</h3>

<p>This function computes MRAE given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrae(x, pred_bench, y, ...)

## S3 method for class 'predbvhar'
mrae(x, pred_bench, y, ...)

## S3 method for class 'bvharcv'
mrae(x, pred_bench, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mrae_+3A_x">x</code></td>
<td>
<p>Forecasting object to use</p>
</td></tr>
<tr><td><code id="mrae_+3A_pred_bench">pred_bench</code></td>
<td>
<p>The same forecasting object from benchmark model</p>
</td></tr>
<tr><td><code id="mrae_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="mrae_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">e_t = y_t - \hat{y}_t</code>.
MRAE implements benchmark model as scaling method.
Relative error is defined by
</p>
<p style="text-align: center;"><code class="reqn">r_t = \frac{e_t}{e_t^{\ast}}</code>
</p>

<p>where <code class="reqn">e_t^\ast</code> is the error from the benchmark method.
Then
</p>
<p style="text-align: center;"><code class="reqn">MRAE = mean(\lvert r_t \rvert)</code>
</p>



<h3>Value</h3>

<p>MRAE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>

<hr>
<h2 id='mse'>Evaluate the Model Based on MSE (Mean Square Error)</h2><span id='topic+mse'></span><span id='topic+mse.predbvhar'></span><span id='topic+mse.bvharcv'></span>

<h3>Description</h3>

<p>This function computes MSE given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mse(x, y, ...)

## S3 method for class 'predbvhar'
mse(x, y, ...)

## S3 method for class 'bvharcv'
mse(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mse_+3A_x">x</code></td>
<td>
<p>Forecasting object</p>
</td></tr>
<tr><td><code id="mse_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="mse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">e_t = y_t - \hat{y}_t</code>. Then
</p>
<p style="text-align: center;"><code class="reqn">MSE = mean(e_t^2)</code>
</p>

<p>MSE is the most used accuracy measure.
</p>


<h3>Value</h3>

<p>MSE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>

<hr>
<h2 id='oxfordman'>Oxford-Man Institute Realized Library</h2><span id='topic+oxfordman'></span><span id='topic+oxfordman_rv'></span><span id='topic+oxfordman_rk'></span>

<h3>Description</h3>

<p>The realized measure of financial assets dataset provided by <a href="https://oxford-man.ox.ac.uk/research/realized-library/">Oxford-man Institute of Quantitative Finance</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oxfordman_rv

oxfordman_rk
</code></pre>


<h3>Format</h3>

<p><code>oxfordman_long</code> is the raw data frame of 53507 rows and 20 columns (You cannot call this dataset.):
</p>

<dl>
<dt>date</dt><dd><p>Date - From 2012-01-09 to 2015-06-27</p>
</dd>
<dt>Symbol</dt><dd><p>Name of the Assets - See below for each name</p>
</dd>
<dt>nobs</dt><dd><p>Number of observations</p>
</dd>
<dt>by_ss</dt><dd><p>Bipower Variation (5-min Sub-sampled)</p>
</dd>
<dt>rsv</dt><dd><p>Realized Semi-variance (5-min)</p>
</dd>
<dt>rk_parzen</dt><dd><p>Realized Kernel Variance (Non-Flat Parzen)</p>
</dd>
<dt>rv10</dt><dd><p>Realized Variance (10-min)</p>
</dd>
<dt>rv5_ss</dt><dd><p>Realized Variance (5-min Sub-sampled)</p>
</dd>
<dt>rv5</dt><dd><p>Realized Variance (5-min)</p>
</dd>
<dt>rv10_ss</dt><dd><p>Realized Variance (10-min Sub-sampled)</p>
</dd>
<dt>rk_twoscale</dt><dd><p>Realized Kernel Variance (Two-Scale/Bartlett)</p>
</dd>
<dt>close_price</dt><dd><p>Closing (Last) Price</p>
</dd>
<dt>rsv_ss</dt><dd><p>Realized Semi-variance (5-min Sub-sampled)</p>
</dd>
<dt>rk_th2</dt><dd><p>Realized Kernel Variance (Tukey-Hanning(2))</p>
</dd>
<dt>open_time</dt><dd><p>Opening Time</p>
</dd>
<dt>medrv</dt><dd><p>Median Realized Variance (5-min)</p>
</dd>
<dt>open_price</dt><dd><p>Opening (First) Price</p>
</dd>
<dt>bv</dt><dd><p>Bipower Variation (5-min)</p>
</dd>
<dt>open_to_close</dt><dd><p>Open to Close Return</p>
</dd>
<dt>close_time</dt><dd><p>Closing Time</p>
</dd>
</dl>

<p><code>oxfordman_rv</code> is a data frame that interpolates <code>NA</code> values of <code>oxfordman_wide_rv</code>.
Also, it does not have <code>date</code> column for fitting.
The number of rows is 905 and the number of columns is 30 (except date).
</p>

<dl>
<dt>date</dt><dd><p>Date - From 2012-01-09 to 2015-06-27</p>
</dd>
<dt>AEX</dt><dd><p>AEX index</p>
</dd>
<dt>AORD</dt><dd><p>All Ordinaries</p>
</dd>
<dt>BFX</dt><dd><p>Bell 20 Index</p>
</dd>
<dt>BSESN</dt><dd><p>S&amp;P BSE Sensex</p>
</dd>
<dt>BVLG</dt><dd><p>PSI All-Share Index (excluded because this index is observed from 2012-10-15)</p>
</dd>
<dt>BVSP</dt><dd><p>BVSP BOVESPA Index</p>
</dd>
<dt>DJI</dt><dd><p>Dow Jones Industrial Average</p>
</dd>
<dt>FCHI</dt><dd><p>CAC 40</p>
</dd>
<dt>FTMIB</dt><dd><p>FTSE MIB</p>
</dd>
<dt>FTSE</dt><dd><p>FTSE 100</p>
</dd>
<dt>GDAXI</dt><dd><p>DAX</p>
</dd>
<dt>GSPTSE</dt><dd><p>S&amp;P/TSX Composite index</p>
</dd>
<dt>HSI</dt><dd><p>HANG SENG Index</p>
</dd>
<dt>IBEX</dt><dd><p>IBEX 35 Index</p>
</dd>
<dt>IXIC</dt><dd><p>Nasdaq 100</p>
</dd>
<dt>KS11</dt><dd><p>Korea Composite Stock Price Index (KOSPI)</p>
</dd>
<dt>KSE</dt><dd><p>Karachi SE 100 Index</p>
</dd>
<dt>MXX</dt><dd><p>IPC Mexico</p>
</dd>
<dt>N225</dt><dd><p>Nikkei 225</p>
</dd>
<dt>NSEI</dt><dd><p>NIFTY 50</p>
</dd>
<dt>OMXC20</dt><dd><p>OMX Copenhagen 20 Index</p>
</dd>
<dt>OMXHPI</dt><dd><p>OMX Helsinki All Share Index</p>
</dd>
<dt>OMXSPI</dt><dd><p>OMX Stockholm All Share Index</p>
</dd>
<dt>OSEAX</dt><dd><p>Oslo Exchange All-share Index</p>
</dd>
<dt>RUT</dt><dd><p>Russel 2000</p>
</dd>
<dt>SMSI</dt><dd><p>Madrid General Index</p>
</dd>
<dt>SPX</dt><dd><p>S&amp;P 500 Index</p>
</dd>
<dt>SSEC</dt><dd><p>Shanghai Composite Index</p>
</dd>
<dt>SSMI</dt><dd><p>Swiss Stock Market Index</p>
</dd>
<dt>STI</dt><dd><p>Straits Times Index (excluded because this index is NA in the period)</p>
</dd>
<dt>STOXX50E</dt><dd><p>EURO STOXX 50</p>
</dd>
</dl>

<p><code>oxfordman_rk</code> is a data frame that interpolates <code>NA</code> values of <code>oxfordman_wide_rk</code>.
Also, it does not have <code>DATE</code> column for fitting.
The number of rows is 1826 and the number of columns is 31.
</p>


<h3>Details</h3>


<ul>
<li><p> As a raw dataset, we have internal dataset of long format <code>oxfordman_long</code>. It contains every realized measure.
</p>
</li>
<li><p> Denote that non-trading dates are excluded in <code>oxfordman_long</code>, not in <code>NA</code>. So be careful when dealing this set directly.
</p>
</li>
<li><p> For analysis, we widened the data for 5-min realized volatility (<code>rv5</code>) and realized kernel variance (<code>rk_parzen</code>), respectively.
</p>

<ul>
<li> <p><code>oxfordman_wide_rv</code>
</p>
</li>
<li> <p><code>oxfordman_wide_rk</code>
</p>
</li></ul>

</li>
<li> <p><code>oxford_rv</code> and <code>oxford_rk</code> are the sets whose <code>NA</code> values interpolated using <code>imputeTS::na_interpolation()</code>.
</p>
</li>
<li><p> First three datasets should be called using <code><a href="utils.html#topic+data">data()</a></code> function: <code>data(..., package = "bvhar")</code>.
</p>
</li>
<li><p> Only <code>oxford_rv</code> and <code>oxford_rk</code> is lazy loaded.
</p>
</li></ul>



<h3>Source</h3>

<p>Realized library of oxford-man had been discontinued, so the source could not be listed.
</p>

<hr>
<h2 id='predict.varlse'>Forecasting Multivariate Time Series</h2><span id='topic+predict.varlse'></span><span id='topic+predict.vharlse'></span><span id='topic+predict.bvarmn'></span><span id='topic+predict.bvharmn'></span><span id='topic+predict.bvarflat'></span><span id='topic+predict.bvarssvs'></span><span id='topic+predict.bvharssvs'></span><span id='topic+predict.bvarhs'></span><span id='topic+predict.bvharhs'></span><span id='topic+predict.bvarsv'></span><span id='topic+predict.bvharsv'></span><span id='topic+print.predbvhar'></span><span id='topic+knit_print.predbvhar'></span>

<h3>Description</h3>

<p>Forecasts multivariate time series using given model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
predict(object, n_ahead, level = 0.05, ...)

## S3 method for class 'vharlse'
predict(object, n_ahead, level = 0.05, ...)

## S3 method for class 'bvarmn'
predict(object, n_ahead, n_iter = 100L, level = 0.05, ...)

## S3 method for class 'bvharmn'
predict(object, n_ahead, n_iter = 100L, level = 0.05, ...)

## S3 method for class 'bvarflat'
predict(object, n_ahead, n_iter = 100L, level = 0.05, ...)

## S3 method for class 'bvarssvs'
predict(object, n_ahead, level = 0.05, ...)

## S3 method for class 'bvharssvs'
predict(object, n_ahead, level = 0.05, ...)

## S3 method for class 'bvarhs'
predict(object, n_ahead, level = 0.05, ...)

## S3 method for class 'bvharhs'
predict(object, n_ahead, level = 0.05, ...)

## S3 method for class 'bvarsv'
predict(object, n_ahead, level = 0.05, ...)

## S3 method for class 'bvharsv'
predict(object, n_ahead, level = 0.05, ...)

## S3 method for class 'predbvhar'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'predbvhar'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.varlse_+3A_object">object</code></td>
<td>
<p>Model object</p>
</td></tr>
<tr><td><code id="predict.varlse_+3A_n_ahead">n_ahead</code></td>
<td>
<p>step to forecast</p>
</td></tr>
<tr><td><code id="predict.varlse_+3A_level">level</code></td>
<td>
<p>Specify alpha of confidence interval level 100(1 - alpha) percentage. By default, .05.</p>
</td></tr>
<tr><td><code id="predict.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="predict.varlse_+3A_n_iter">n_iter</code></td>
<td>
<p>Number to sample residual matrix from inverse-wishart distribution. By default, 100.</p>
</td></tr>
<tr><td><code id="predict.varlse_+3A_x">x</code></td>
<td>
<p><code>predbvhar</code> object</p>
</td></tr>
<tr><td><code id="predict.varlse_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predbvhar</code> <a href="base.html#topic+class">class</a> with the following components:
</p>

<dl>
<dt>process</dt><dd><p>object$process</p>
</dd>
<dt>forecast</dt><dd><p>forecast matrix</p>
</dd>
<dt>se</dt><dd><p>standard error matrix</p>
</dd>
<dt>lower</dt><dd><p>lower confidence interval</p>
</dd>
<dt>upper</dt><dd><p>upper confidence interval</p>
</dd>
<dt>lower_joint</dt><dd><p>lower CI adjusted (Bonferroni)</p>
</dd>
<dt>upper_joint</dt><dd><p>upper CI adjusted (Bonferroni)</p>
</dd>
<dt>y</dt><dd><p>object$y</p>
</dd>
</dl>



<h3>n-step ahead forecasting VAR(p)</h3>

<p>See pp35 of Lütkepohl (2007).
Consider h-step ahead forecasting (e.g. n + 1, ... n + h).
</p>
<p>Let <code class="reqn">y_{(n)}^T = (y_n^T, ..., y_{n - p + 1}^T, 1)</code>.
Then one-step ahead (point) forecasting:
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}_{n + 1}^T = y_{(n)}^T \hat{B}</code>
</p>

<p>Recursively, let <code class="reqn">\hat{y}_{(n + 1)}^T = (\hat{y}_{n + 1}^T, y_n^T, ..., y_{n - p + 2}^T, 1)</code>.
Then two-step ahead (point) forecasting:
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}_{n + 2}^T = \hat{y}_{(n + 1)}^T \hat{B}</code>
</p>

<p>Similarly, h-step ahead (point) forecasting:
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}_{n + h}^T = \hat{y}_{(n + h - 1)}^T \hat{B}</code>
</p>

<p>How about confident region?
Confidence interval at h-period is
</p>
<p style="text-align: center;"><code class="reqn">y_{k,t}(h) \pm z_(\alpha / 2) \sigma_k (h)</code>
</p>

<p>Joint forecast region of <code class="reqn">100(1-\alpha)</code>% can be computed by
</p>
<p style="text-align: center;"><code class="reqn">\{ (y_{k, 1}, y_{k, h}) \mid y_{k, n}(i) - z_{(\alpha / 2h)} \sigma_n(i) \le y_{n, i} \le y_{k, n}(i) + z_{(\alpha / 2h)} \sigma_k(i), i = 1, \ldots, h \}</code>
</p>

<p>See the pp41 of Lütkepohl (2007).
</p>
<p>To compute covariance matrix, it needs VMA representation:
</p>
<p style="text-align: center;"><code class="reqn">Y_{t}(h) = c + \sum_{i = h}^{\infty} W_{i} \epsilon_{t + h - i} = c + \sum_{i = 0}^{\infty} W_{h + i} \epsilon_{t - i}</code>
</p>

<p>Then
</p>
<p style="text-align: center;"><code class="reqn">\Sigma_y(h) = MSE [ y_t(h) ] = \sum_{i = 0}^{h - 1} W_i \Sigma_{\epsilon} W_i^T = \Sigma_y(h - 1) + W_{h - 1} \Sigma_{\epsilon} W_{h - 1}^T</code>
</p>



<h3>n-step ahead forecasting VHAR</h3>

<p>Let <code class="reqn">T_{HAR}</code> is VHAR linear transformation matrix (See <a href="#topic+var_design_formulation">var_design_formulation</a>).
Since VHAR is the linearly transformed VAR(22),
let <code class="reqn">y_{(n)}^T = (y_n^T, y_{n - 1}^T, ..., y_{n - 21}^T, 1)</code>.
</p>
<p>Then one-step ahead (point) forecasting:
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}_{n + 1}^T = y_{(n)}^T T_{HAR} \hat{\Phi}</code>
</p>

<p>Recursively, let <code class="reqn">\hat{y}_{(n + 1)}^T = (\hat{y}_{n + 1}^T, y_n^T, ..., y_{n - 20}^T, 1)</code>.
Then two-step ahead (point) forecasting:
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}_{n + 2}^T = \hat{y}_{(n + 1)}^T T_{HAR} \hat{\Phi}</code>
</p>

<p>and h-step ahead (point) forecasting:
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}_{n + h}^T = \hat{y}_{(n + h - 1)}^T T_{HAR} \hat{\Phi}</code>
</p>



<h3>n-step ahead forecasting BVAR(p) with minnesota prior</h3>

<p>Point forecasts are computed by posterior mean of the parameters.
See Section 3 of Bańbura et al. (2010).
</p>
<p>Let <code class="reqn">\hat{B}</code> be the posterior MN mean
and let <code class="reqn">\hat{V}</code> be the posterior MN precision.
</p>
<p>Then predictive posterior for each step
</p>
<p style="text-align: center;"><code class="reqn">y_{n + 1} \mid \Sigma_e, y \sim N( vec(y_{(n)}^T A), \Sigma_e \otimes (1 + y_{(n)}^T \hat{V}^{-1} y_{(n)}) )</code>
</p>

<p style="text-align: center;"><code class="reqn">y_{n + 2} \mid \Sigma_e, y \sim N( vec(\hat{y}_{(n + 1)}^T A), \Sigma_e \otimes (1 + \hat{y}_{(n + 1)}^T \hat{V}^{-1} \hat{y}_{(n + 1)}) )</code>
</p>

<p>and recursively,
</p>
<p style="text-align: center;"><code class="reqn">y_{n + h} \mid \Sigma_e, y \sim N( vec(\hat{y}_{(n + h - 1)}^T A), \Sigma_e \otimes (1 + \hat{y}_{(n + h - 1)}^T \hat{V}^{-1} \hat{y}_{(n + h - 1)}) )</code>
</p>

<p>See <a href="#topic+bvar_predictive_density">bvar_predictive_density</a> how to generate the predictive distribution.
</p>


<h3>n-step ahead forecasting BVHAR</h3>

<p>Let <code class="reqn">\hat\Phi</code> be the posterior MN mean
and let <code class="reqn">\hat\Psi</code> be the posterior MN precision.
</p>
<p>Then predictive posterior for each step
</p>
<p style="text-align: center;"><code class="reqn">y_{n + 1} \mid \Sigma_e, y \sim N( vec(y_{(n)}^T \tilde{T}^T \Phi), \Sigma_e \otimes (1 + y_{(n)}^T \tilde{T} \hat\Psi^{-1} \tilde{T} y_{(n)}) )</code>
</p>

<p style="text-align: center;"><code class="reqn">y_{n + 2} \mid \Sigma_e, y \sim N( vec(y_{(n + 1)}^T \tilde{T}^T \Phi), \Sigma_e \otimes (1 + y_{(n + 1)}^T \tilde{T} \hat\Psi^{-1} \tilde{T} y_{(n + 1)}) )</code>
</p>

<p>and recursively,
</p>
<p style="text-align: center;"><code class="reqn">y_{n + h} \mid \Sigma_e, y \sim N( vec(y_{(n + h - 1)}^T \tilde{T}^T \Phi), \Sigma_e \otimes (1 + y_{(n + h - 1)}^T \tilde{T} \hat\Psi^{-1} \tilde{T} y_{(n + h - 1)}) )</code>
</p>

<p>See <a href="#topic+bvar_predictive_density">bvar_predictive_density</a> how to generate the predictive distribution.
</p>


<h3>n-step ahead forecasting VAR(p) with SSVS and Horseshoe</h3>

<p>The process of the computing point estimate is the same.
However, predictive interval is achieved from each Gibbs sampler sample.
</p>
<p style="text-align: center;"><code class="reqn">y_{n + 1} \mid A, \Sigma_e, y \sim N( vec(y_{(n)}^T A), \Sigma_e )</code>
</p>

<p style="text-align: center;"><code class="reqn">y_{n + h} \mid A, \Sigma_e, y \sim N( vec(\hat{y}_{(n + h - 1)}^T A), \Sigma_e )</code>
</p>



<h3>n-step ahead forecasting VHAR with SSVS and Horseshoe</h3>

<p>The process of the computing point estimate is the same.
However, predictive interval is achieved from each Gibbs sampler sample.
</p>
<p style="text-align: center;"><code class="reqn">y_{n + 1} \mid \Sigma_e, y \sim N( vec(y_{(n)}^T \tilde{T}^T \Phi), \Sigma_e \otimes (1 + y_{(n)}^T \tilde{T} \hat\Psi^{-1} \tilde{T} y_{(n)}) )</code>
</p>

<p style="text-align: center;"><code class="reqn">y_{n + h} \mid \Sigma_e, y \sim N( vec(y_{(n + h - 1)}^T \tilde{T}^T \Phi), \Sigma_e \otimes (1 + y_{(n + h - 1)}^T \tilde{T} \hat\Psi^{-1} \tilde{T} y_{(n + h - 1)}) )</code>
</p>



<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>
<p>Corsi, F. (2008). <em>A Simple Approximate Long-Memory Model of Realized Volatility</em>. Journal of Financial Econometrics, 7(2), 174–196.
</p>
<p>Baek, C. and Park, M. (2021). <em>Sparse vector heterogeneous autoregressive modeling for realized volatility</em>. J. Korean Stat. Soc. 50, 495–510.
</p>
<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>
<p>Gelman, A., Carlin, J. B., Stern, H. S., &amp; Rubin, D. B. (2013). <em>Bayesian data analysis</em>. Chapman and Hall/CRC.
</p>
<p>Karlsson, S. (2013). <em>Chapter 15 Forecasting with Bayesian Vector Autoregression</em>. Handbook of Economic Forecasting, 2, 791–897.
</p>
<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>
<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions</em>. Journal of Econometrics, 142(1), 553–580.
</p>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions</em>. Journal of Econometrics, 142(1), 553–580.
</p>

<hr>
<h2 id='print.summary.bvharsp'>Summarizing BVAR and BVHAR with Shrinkage Priors</h2><span id='topic+print.summary.bvharsp'></span><span id='topic+knit_print.summary.ssvsmod'></span><span id='topic+summary.ssvsmod'></span><span id='topic+summary.hsmod'></span>

<h3>Description</h3>

<p>Conduct variable selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.bvharsp'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'summary.ssvsmod'
knit_print(x, ...)

## S3 method for class 'ssvsmod'
summary(object, method = c("pip", "ci"), threshold = 0.5, level = 0.05, ...)

## S3 method for class 'hsmod'
summary(object, method = c("ci", "pip"), threshold = 0.5, level = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.bvharsp_+3A_x">x</code></td>
<td>
<p><code>summary.ssvsmod</code> object</p>
</td></tr>
<tr><td><code id="print.summary.bvharsp_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="print.summary.bvharsp_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="print.summary.bvharsp_+3A_object">object</code></td>
<td>
<p><code>ssvsmod</code> object</p>
</td></tr>
<tr><td><code id="print.summary.bvharsp_+3A_method">method</code></td>
<td>
<p>Use PIP (<code>"pip"</code>) or credible interval (<code>"ci"</code>).</p>
</td></tr>
<tr><td><code id="print.summary.bvharsp_+3A_threshold">threshold</code></td>
<td>
<p>Threshold for posterior inclusion probability</p>
</td></tr>
<tr><td><code id="print.summary.bvharsp_+3A_level">level</code></td>
<td>
<p>Specify alpha of credible interval level 100(1 - alpha) percentage. By default, <code>.05</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.ssvsmod</code> object
</p>
<p><code>summary.hsmod</code> object
</p>


<h3>References</h3>

<p>George, E. I., &amp; McCulloch, R. E. (1993). <em>Variable Selection via Gibbs Sampling</em>. Journal of the American Statistical Association, 88(423), 881–889.
</p>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions</em>. Journal of Econometrics, 142(1), 553–580.
</p>
<p>Koop, G., &amp; Korobilis, D. (2009). <em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>. Foundations and Trends® in Econometrics, 3(4), 267–358.
</p>
<p>O’Hara, R. B., &amp; Sillanpää, M. J. (2009). <em>A review of Bayesian variable selection methods: what, how and which</em>. Bayesian Analysis, 4(1), 85–117.
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+autoplot'></span><span id='topic+autolayer'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>ggplot2</dt><dd><p><code><a href="ggplot2.html#topic+autolayer">autolayer</a></code>, <code><a href="ggplot2.html#topic+autoplot">autoplot</a></code></p>
</dd>
</dl>

<hr>
<h2 id='relmae'>Evaluate the Model Based on RelMAE (Relative MAE)</h2><span id='topic+relmae'></span><span id='topic+relmae.predbvhar'></span><span id='topic+relmae.bvharcv'></span>

<h3>Description</h3>

<p>This function computes RelMAE given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>relmae(x, pred_bench, y, ...)

## S3 method for class 'predbvhar'
relmae(x, pred_bench, y, ...)

## S3 method for class 'bvharcv'
relmae(x, pred_bench, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="relmae_+3A_x">x</code></td>
<td>
<p>Forecasting object to use</p>
</td></tr>
<tr><td><code id="relmae_+3A_pred_bench">pred_bench</code></td>
<td>
<p>The same forecasting object from benchmark model</p>
</td></tr>
<tr><td><code id="relmae_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="relmae_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">e_t = y_t - \hat{y}_t</code>.
RelMAE implements MAE of benchmark model as relative measures.
Let <code class="reqn">MAE_b</code> be the MAE of the benchmark model.
Then
</p>
<p style="text-align: center;"><code class="reqn">RelMAE = \frac{MAE}{MAE_b}</code>
</p>

<p>where <code class="reqn">MAE</code> is the MAE of our model.
</p>


<h3>Value</h3>

<p>RelMAE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>

<hr>
<h2 id='relspne'>Evaluate the Estimation Based on Relative Spectral Norm Error</h2><span id='topic+relspne'></span><span id='topic+relspne.bvharsp'></span>

<h3>Description</h3>

<p>This function computes relative estimation error given estimated model and true coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>relspne(x, y, ...)

## S3 method for class 'bvharsp'
relspne(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="relspne_+3A_x">x</code></td>
<td>
<p>Estimated model.</p>
</td></tr>
<tr><td><code id="relspne_+3A_y">y</code></td>
<td>
<p>Coefficient matrix to be compared.</p>
</td></tr>
<tr><td><code id="relspne_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\lVert \cdot \rVert_2</code> be the spectral norm of a matrix,
let <code class="reqn">\hat{\Phi}</code> be the estimates,
and let <code class="reqn">\Phi</code> be the true coefficients matrix.
Then the function computes relative estimation error by
</p>
<p style="text-align: center;"><code class="reqn">\frac{\lVert \hat{\Phi} - \Phi \rVert_2}{\lVert \Phi \rVert_2}</code>
</p>



<h3>Value</h3>

<p>Spectral norm value
</p>


<h3>References</h3>

<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>

<hr>
<h2 id='residuals.varlse'>Residual Matrix from Multivariate Time Series Models</h2><span id='topic+residuals.varlse'></span><span id='topic+residuals.vharlse'></span><span id='topic+residuals.bvarmn'></span><span id='topic+residuals.bvarflat'></span><span id='topic+residuals.bvharmn'></span>

<h3>Description</h3>

<p>By defining <code><a href="stats.html#topic+residuals">stats::residuals()</a></code> for each model, this function returns residual.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
residuals(object, ...)

## S3 method for class 'vharlse'
residuals(object, ...)

## S3 method for class 'bvarmn'
residuals(object, ...)

## S3 method for class 'bvarflat'
residuals(object, ...)

## S3 method for class 'bvharmn'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.varlse_+3A_object">object</code></td>
<td>
<p>Model object</p>
</td></tr>
<tr><td><code id="residuals.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+matrix">matrix</a> object.
</p>

<hr>
<h2 id='rmafe'>Evaluate the Model Based on RMAFE</h2><span id='topic+rmafe'></span><span id='topic+rmafe.predbvhar'></span><span id='topic+rmafe.bvharcv'></span>

<h3>Description</h3>

<p>This function computes RMAFE (Mean Absolute Forecast Error Relative to the Benchmark)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmafe(x, pred_bench, y, ...)

## S3 method for class 'predbvhar'
rmafe(x, pred_bench, y, ...)

## S3 method for class 'bvharcv'
rmafe(x, pred_bench, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmafe_+3A_x">x</code></td>
<td>
<p>Forecasting object to use</p>
</td></tr>
<tr><td><code id="rmafe_+3A_pred_bench">pred_bench</code></td>
<td>
<p>The same forecasting object from benchmark model</p>
</td></tr>
<tr><td><code id="rmafe_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="rmafe_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">e_t = y_t - \hat{y}_t</code>.
RMAFE is the ratio of L1 norm of <code class="reqn">e_t</code> from forecasting object and from benchmark model.
</p>
<p style="text-align: center;"><code class="reqn">RMAFE = \frac{sum(\lVert e_t \rVert)}{sum(\lVert e_t^{(b)} \rVert)}</code>
</p>

<p>where <code class="reqn">e_t^{(b)}</code> is the error from the benchmark model.
</p>


<h3>Value</h3>

<p>RMAFE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>
<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>
<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>

<hr>
<h2 id='rmape'>Evaluate the Model Based on RMAPE (Relative MAPE)</h2><span id='topic+rmape'></span><span id='topic+rmape.predbvhar'></span><span id='topic+rmape.bvharcv'></span>

<h3>Description</h3>

<p>This function computes RMAPE given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmape(x, pred_bench, y, ...)

## S3 method for class 'predbvhar'
rmape(x, pred_bench, y, ...)

## S3 method for class 'bvharcv'
rmape(x, pred_bench, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmape_+3A_x">x</code></td>
<td>
<p>Forecasting object to use</p>
</td></tr>
<tr><td><code id="rmape_+3A_pred_bench">pred_bench</code></td>
<td>
<p>The same forecasting object from benchmark model</p>
</td></tr>
<tr><td><code id="rmape_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="rmape_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RMAPE is the ratio of MAPE of given model and the benchmark one.
Let <code class="reqn">MAPE_b</code> be the MAPE of the benchmark model.
Then
</p>
<p style="text-align: center;"><code class="reqn">RMAPE = \frac{mean(MAPE)}{mean(MAPE_b)}</code>
</p>

<p>where <code class="reqn">MAPE</code> is the MAPE of our model.
</p>


<h3>Value</h3>

<p>RMAPE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>

<hr>
<h2 id='rmase'>Evaluate the Model Based on RMASE (Relative MASE)</h2><span id='topic+rmase'></span><span id='topic+rmase.predbvhar'></span><span id='topic+rmase.bvharcv'></span>

<h3>Description</h3>

<p>This function computes RMASE given prediction result versus evaluation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmase(x, pred_bench, y, ...)

## S3 method for class 'predbvhar'
rmase(x, pred_bench, y, ...)

## S3 method for class 'bvharcv'
rmase(x, pred_bench, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmase_+3A_x">x</code></td>
<td>
<p>Forecasting object to use</p>
</td></tr>
<tr><td><code id="rmase_+3A_pred_bench">pred_bench</code></td>
<td>
<p>The same forecasting object from benchmark model</p>
</td></tr>
<tr><td><code id="rmase_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="rmase_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RMASE is the ratio of MAPE of given model and the benchmark one.
Let <code class="reqn">MASE_b</code> be the MAPE of the benchmark model.
Then
</p>
<p style="text-align: center;"><code class="reqn">RMASE = \frac{mean(MASE)}{mean(MASE_b)}</code>
</p>

<p>where <code class="reqn">MASE</code> is the MASE of our model.
</p>


<h3>Value</h3>

<p>RMASE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>

<hr>
<h2 id='rmsfe'>Evaluate the Model Based on RMSFE</h2><span id='topic+rmsfe'></span><span id='topic+rmsfe.predbvhar'></span><span id='topic+rmsfe.bvharcv'></span>

<h3>Description</h3>

<p>This function computes RMSFE (Mean Squared Forecast Error Relative to the Benchmark)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmsfe(x, pred_bench, y, ...)

## S3 method for class 'predbvhar'
rmsfe(x, pred_bench, y, ...)

## S3 method for class 'bvharcv'
rmsfe(x, pred_bench, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmsfe_+3A_x">x</code></td>
<td>
<p>Forecasting object to use</p>
</td></tr>
<tr><td><code id="rmsfe_+3A_pred_bench">pred_bench</code></td>
<td>
<p>The same forecasting object from benchmark model</p>
</td></tr>
<tr><td><code id="rmsfe_+3A_y">y</code></td>
<td>
<p>Test data to be compared. should be the same format with the train data.</p>
</td></tr>
<tr><td><code id="rmsfe_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">e_t = y_t - \hat{y}_t</code>.
RMSFE is the ratio of L2 norm of <code class="reqn">e_t</code> from forecasting object and from benchmark model.
</p>
<p style="text-align: center;"><code class="reqn">RMSFE = \frac{sum(\lVert e_t \rVert)}{sum(\lVert e_t^{(b)} \rVert)}</code>
</p>

<p>where <code class="reqn">e_t^{(b)}</code> is the error from the benchmark model.
</p>


<h3>Value</h3>

<p>RMSFE vector corresponding to each variable.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Koehler, A. B. (2006). <em>Another look at measures of forecast accuracy</em>. International Journal of Forecasting, 22(4), 679–688.
</p>
<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>
<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>

<hr>
<h2 id='set_bvar'>Hyperparameters for Bayesian Models</h2><span id='topic+set_bvar'></span><span id='topic+set_bvar_flat'></span><span id='topic+set_bvhar'></span><span id='topic+set_weight_bvhar'></span><span id='topic+print.bvharspec'></span><span id='topic+knit_print.bvharspec'></span>

<h3>Description</h3>

<p>Set hyperparameters of Bayesian VAR and VHAR models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_bvar(sigma, lambda = 0.1, delta, eps = 1e-04)

set_bvar_flat(U)

set_bvhar(sigma, lambda = 0.1, delta, eps = 1e-04)

set_weight_bvhar(sigma, lambda = 0.1, eps = 1e-04, daily, weekly, monthly)

## S3 method for class 'bvharspec'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvharspec'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_bvar_+3A_sigma">sigma</code></td>
<td>
<p>Standard error vector for each variable (Default: sd)</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_lambda">lambda</code></td>
<td>
<p>Tightness of the prior around a random walk or white noise (Default: .1)</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_delta">delta</code></td>
<td>
<p>Persistence (Default: Litterman sets 1 = random walk prior, White noise prior = 0)</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_eps">eps</code></td>
<td>
<p>Very small number (Default: 1e-04)</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_u">U</code></td>
<td>
<p>Positive definite matrix. By default, identity matrix of dimension ncol(X0)</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_daily">daily</code></td>
<td>
<p>Same as delta in VHAR type (Default: 1 as Litterman)</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_weekly">weekly</code></td>
<td>
<p>Fill the second part in the first block (Default: 1)</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_monthly">monthly</code></td>
<td>
<p>Fill the third part in the first block (Default: 1)</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_x">x</code></td>
<td>
<p><code>bvharspec</code> object</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="set_bvar_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> Missing arguments will be set to be default values in each model function mentioned above.
</p>
</li>
<li> <p><code>set_bvar()</code> sets hyperparameters for <code><a href="#topic+bvar_minnesota">bvar_minnesota()</a></code>.
</p>
</li>
<li><p> Each <code>delta</code> (vector), <code>lambda</code> (length of 1), <code>sigma</code> (vector), <code>eps</code> (vector) corresponds to <code class="reqn">\delta_j</code>, <code class="reqn">\lambda</code>, <code class="reqn">\delta_j</code>, <code class="reqn">\epsilon</code>.
</p>
</li></ul>

<p><code class="reqn">\delta_i</code> are related to the belief to random walk.
</p>

<ul>
<li><p> If <code class="reqn">\delta_i = 1</code> for all i, random walk prior
</p>
</li>
<li><p> If <code class="reqn">\delta_i = 0</code> for all i, white noise prior
</p>
</li></ul>

<p><code class="reqn">\lambda</code> controls the overall tightness of the prior around these two prior beliefs.
</p>

<ul>
<li><p> If <code class="reqn">\lambda = 0</code>, the posterior is equivalent to prior and the data do not influence the estimates.
</p>
</li>
<li><p> If <code class="reqn">\lambda = \infty</code>, the posterior mean becomes OLS estimates (VAR).
</p>
</li></ul>

<p><code class="reqn">\sigma_i^2 / \sigma_j^2</code> in Minnesota moments explain the data scales.
</p>

<ul>
<li> <p><code>set_bvar_flat</code> sets hyperparameters for <code><a href="#topic+bvar_flat">bvar_flat()</a></code>.
</p>
</li></ul>


<ul>
<li> <p><code>set_bvhar()</code> sets hyperparameters for <code><a href="#topic+bvhar_minnesota">bvhar_minnesota()</a></code> with VAR-type Minnesota prior, i.e. BVHAR-S model.
</p>
</li></ul>


<ul>
<li> <p><code>set_weight_bvhar()</code> sets hyperparameters for <code><a href="#topic+bvhar_minnesota">bvhar_minnesota()</a></code> with VHAR-type Minnesota prior, i.e. BVHAR-L model.
</p>
</li></ul>



<h3>Value</h3>

<p>Every function returns <code>bvharspec</code> <a href="base.html#topic+class">class</a>.
It is the list of which the components are the same as the arguments provided.
If the argument is not specified, <code>NULL</code> is assigned here.
The default values mentioned above will be considered in each fitting function.
</p>

<dl>
<dt>process</dt><dd><p>Model name: <code>BVAR</code>, <code>BVHAR</code></p>
</dd>
<dt>prior</dt><dd>
<p>Prior name: <code>Minnesota</code> (Minnesota prior for BVAR),
<code>Hierarchical</code> (Hierarchical prior for BVAR),
<code>MN_VAR</code> (BVHAR-S),
<code>MN_VHAR</code> (BVHAR-L),
<code>Flat</code> (Flat prior for BVAR)
</p>
</dd>
<dt>sigma</dt><dd><p>Vector value (or <code>bvharpriorspec</code> class) assigned for sigma</p>
</dd>
<dt>lambda</dt><dd><p>Value (or <code>bvharpriorspec</code> class) assigned for lambda</p>
</dd>
<dt>delta</dt><dd><p>Vector value assigned for delta</p>
</dd>
<dt>eps</dt><dd><p>Value assigned for epsilon</p>
</dd>
</dl>

<p><code>set_weight_bvhar()</code> has different component with <code>delta</code> due to its different construction.
</p>

<dl>
<dt>daily</dt><dd><p>Vector value assigned for daily weight</p>
</dd>
<dt>weekly</dt><dd><p>Vector value assigned for weekly weight</p>
</dd>
<dt>monthly</dt><dd><p>Vector value assigned for monthly weight</p>
</dd>
</dl>



<h3>Note</h3>

<p>By using <code><a href="#topic+set_psi">set_psi()</a></code> and <code><a href="#topic+set_lambda">set_lambda()</a></code> each, hierarchical modeling is available.
</p>


<h3>References</h3>

<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>
<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>
<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>
<p>Kim, Y. G., and Baek, C. (2023+). <em>Bayesian vector heterogeneous autoregressive modeling</em>. Journal of Statistical Computation and Simulation.
</p>
<p>Kim, Y. G., and Baek, C. (2023+). <em>Bayesian vector heterogeneous autoregressive modeling</em>. Journal of Statistical Computation and Simulation.
</p>


<h3>See Also</h3>


<ul>
<li><p> lambda hyperprior specification <code><a href="#topic+set_lambda">set_lambda()</a></code>
</p>
</li>
<li><p> sigma hyperprior specification <code><a href="#topic+set_psi">set_psi()</a></code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Minnesota BVAR specification------------------------
bvar_spec &lt;- set_bvar(
  sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)
  lambda = .2, # lambda = .2
  delta = rep(.1, 3), # delta1 = .1, delta2 = .1, delta3 = .1
  eps = 1e-04 # eps = 1e-04
)
class(bvar_spec)
str(bvar_spec)
# Flat BVAR specification-------------------------
# 3-dim
# p = 5 with constant term
# U = 500 * I(mp + 1)
bvar_flat_spec &lt;- set_bvar_flat(U = 500 * diag(16))
class(bvar_flat_spec)
str(bvar_flat_spec)
# BVHAR-S specification-----------------------
bvhar_var_spec &lt;- set_bvhar(
  sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)
  lambda = .2, # lambda = .2
  delta = rep(.1, 3), # delta1 = .1, delta2 = .1, delta3 = .1
  eps = 1e-04 # eps = 1e-04
)
class(bvhar_var_spec)
str(bvhar_var_spec)
# BVHAR-L specification---------------------------
bvhar_vhar_spec &lt;- set_weight_bvhar(
  sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)
  lambda = .2, # lambda = .2
  eps = 1e-04, # eps = 1e-04
  daily = rep(.2, 3), # daily1 = .2, daily2 = .2, daily3 = .2
  weekly = rep(.1, 3), # weekly1 = .1, weekly2 = .1, weekly3 = .1
  monthly = rep(.05, 3) # monthly1 = .05, monthly2 = .05, monthly3 = .05
)
class(bvhar_vhar_spec)
str(bvhar_vhar_spec)
</code></pre>

<hr>
<h2 id='set_horseshoe'>Horseshoe Prior Specification</h2><span id='topic+set_horseshoe'></span><span id='topic+print.horseshoespec'></span><span id='topic+knit_print.horseshoespec'></span>

<h3>Description</h3>

<p>Set initial hyperparameters and parameter before starting Gibbs sampler for Horseshoe prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_horseshoe(local_sparsity = 1, global_sparsity = 1)

## S3 method for class 'horseshoespec'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'horseshoespec'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_horseshoe_+3A_local_sparsity">local_sparsity</code></td>
<td>
<p>Initial local shrinkage hyperparameters</p>
</td></tr>
<tr><td><code id="set_horseshoe_+3A_global_sparsity">global_sparsity</code></td>
<td>
<p>Initial global shrinkage hyperparameter</p>
</td></tr>
<tr><td><code id="set_horseshoe_+3A_x">x</code></td>
<td>
<p><code>horseshoespec</code></p>
</td></tr>
<tr><td><code id="set_horseshoe_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="set_horseshoe_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Set horseshoe prior initialization for VAR family.
</p>

<ul>
<li> <p><code>local_sparsity</code>: Local shrinkage for each row of coefficients matrix.
</p>
</li>
<li> <p><code>global_sparsity</code>: (Initial) global shrinkage.
</p>
</li>
<li> <p><code>init_cov</code>: Initial covariance matrix.
</p>
</li></ul>

<p>In this package, horseshoe prior model is estimated by Gibbs sampling,
initial means initial values for that gibbs sampler.
</p>


<h3>References</h3>

<p>Carvalho, C. M., Polson, N. G., &amp; Scott, J. G. (2010). The horseshoe estimator for sparse signals. Biometrika, 97(2), 465–480.
</p>
<p>Makalic, E., &amp; Schmidt, D. F. (2016). <em>A Simple Sampler for the Horseshoe Estimator</em>. IEEE Signal Processing Letters, 23(1), 179–182.
</p>

<hr>
<h2 id='set_intercept'>Prior for Constant Term</h2><span id='topic+set_intercept'></span><span id='topic+print.interceptspec'></span><span id='topic+knit_print.interceptspec'></span>

<h3>Description</h3>

<p>Set Normal prior hyperparameters for constant term
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_intercept(mean = 0, sd = 0.1)

## S3 method for class 'interceptspec'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'interceptspec'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_intercept_+3A_mean">mean</code></td>
<td>
<p>Normal mean of constant term</p>
</td></tr>
<tr><td><code id="set_intercept_+3A_sd">sd</code></td>
<td>
<p>Normal standard deviance for constant term</p>
</td></tr>
<tr><td><code id="set_intercept_+3A_x">x</code></td>
<td>
<p><code>interceptspec</code> object</p>
</td></tr>
<tr><td><code id="set_intercept_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="set_intercept_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>

<hr>
<h2 id='set_lambda'>Hyperpriors for Bayesian Models</h2><span id='topic+set_lambda'></span><span id='topic+set_psi'></span><span id='topic+print.bvharpriorspec'></span><span id='topic+knit_print.bvharpriorspec'></span>

<h3>Description</h3>

<p>Set hyperpriors of Bayesian VAR and VHAR models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_lambda(mode = 0.2, sd = 0.4, lower = 1e-05, upper = 3)

set_psi(shape = 4e-04, scale = 4e-04, lower = 1e-05, upper = 3)

## S3 method for class 'bvharpriorspec'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'bvharpriorspec'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_lambda_+3A_mode">mode</code></td>
<td>
<p>Mode of Gamma distribution. By default, <code>.2</code>.</p>
</td></tr>
<tr><td><code id="set_lambda_+3A_sd">sd</code></td>
<td>
<p>Standard deviation of Gamma distribution. By default, <code>.4</code>.</p>
</td></tr>
<tr><td><code id="set_lambda_+3A_lower">lower</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Lower bound for <code><a href="stats.html#topic+optim">stats::optim()</a></code>. By default, <code>1e-5</code>.</p>
</td></tr>
<tr><td><code id="set_lambda_+3A_upper">upper</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Upper bound for <code><a href="stats.html#topic+optim">stats::optim()</a></code>. By default, <code>3</code>.</p>
</td></tr>
<tr><td><code id="set_lambda_+3A_shape">shape</code></td>
<td>
<p>Shape of Inverse Gamma distribution. By default, <code>(.02)^2</code>.</p>
</td></tr>
<tr><td><code id="set_lambda_+3A_scale">scale</code></td>
<td>
<p>Scale of Inverse Gamma distribution. By default, <code>(.02)^2</code>.</p>
</td></tr>
<tr><td><code id="set_lambda_+3A_x">x</code></td>
<td>
<p><code>bvharpriorspec</code> object</p>
</td></tr>
<tr><td><code id="set_lambda_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="set_lambda_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In addition to Normal-IW priors <code><a href="#topic+set_bvar">set_bvar()</a></code>, <code><a href="#topic+set_bvhar">set_bvhar()</a></code>, and <code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code>,
these functions give hierarchical structure to the model.
</p>

<ul>
<li> <p><code>set_lambda()</code> specifies hyperprior for <code class="reqn">\lambda</code> (<code>lambda</code>), which is Gamma distribution.
</p>
</li>
<li> <p><code>set_psi()</code> specifies hyperprior for <code class="reqn">\psi / (\nu_0 - k - 1) = \sigma^2</code> (<code>sigma</code>), which is Inverse gamma distribution.
</p>
</li></ul>

<p>The following set of <code style="white-space: pre;">&#8288;(mode, sd)&#8288;</code> are recommended by Sims and Zha (1998) for <code>set_lambda()</code>.
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;(mode = .2, sd = .4)&#8288;</code>: default
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;(mode = 1, sd = 1)&#8288;</code>
</p>
</li></ul>

<p>Giannone et al. (2015) suggested data-based selection for <code>set_psi()</code>.
It chooses (0.02)^2 based on its empirical data set.
</p>


<h3>Value</h3>

<p><code>bvharpriorspec</code> object
</p>


<h3>References</h3>

<p>Giannone, D., Lenza, M., &amp; Primiceri, G. E. (2015). <em>Prior Selection for Vector Autoregressions</em>. Review of Economics and Statistics, 97(2).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Hirearchical BVAR specification------------------------
set_bvar(
  sigma = set_psi(shape = 4e-4, scale = 4e-4),
  lambda = set_lambda(mode = .2, sd = .4),
  delta = rep(1, 3),
  eps = 1e-04 # eps = 1e-04
)
</code></pre>

<hr>
<h2 id='set_ssvs'>Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor</h2><span id='topic+set_ssvs'></span><span id='topic+print.ssvsinput'></span><span id='topic+knit_print.ssvsinput'></span>

<h3>Description</h3>

<p>Set SSVS hyperparameters for VAR or VHAR coefficient matrix and Cholesky factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_ssvs(
  coef_spike = 0.1,
  coef_slab = 5,
  coef_mixture = 0.5,
  coef_s1 = 1,
  coef_s2 = 1,
  mean_non = 0,
  sd_non = 0.1,
  shape = 0.01,
  rate = 0.01,
  chol_spike = 0.1,
  chol_slab = 5,
  chol_mixture = 0.5,
  chol_s1 = 1,
  chol_s2 = 1
)

## S3 method for class 'ssvsinput'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'ssvsinput'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_ssvs_+3A_coef_spike">coef_spike</code></td>
<td>
<p>Standard deviance for Spike normal distribution (See Details).</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_coef_slab">coef_slab</code></td>
<td>
<p>Standard deviance for Slab normal distribution (See Details).</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_coef_mixture">coef_mixture</code></td>
<td>
<p>Bernoulli parameter for sparsity proportion (See Details).</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_coef_s1">coef_s1</code></td>
<td>
<p>First shape of coefficients prior beta distribution</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_coef_s2">coef_s2</code></td>
<td>
<p>Second shape of coefficients prior beta distribution</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_mean_non">mean_non</code></td>
<td>
<p>Prior mean of unrestricted coefficients</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_sd_non">sd_non</code></td>
<td>
<p>Standard deviance for unrestricted coefficients</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_shape">shape</code></td>
<td>
<p>Gamma shape parameters for precision matrix (See Details).</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_rate">rate</code></td>
<td>
<p>Gamma rate parameters for precision matrix (See Details).</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_chol_spike">chol_spike</code></td>
<td>
<p>Standard deviance for Spike normal distribution, in the cholesky factor (See Details).</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_chol_slab">chol_slab</code></td>
<td>
<p>Standard deviance for Slab normal distribution, in the cholesky factor (See Details).</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_chol_mixture">chol_mixture</code></td>
<td>
<p>Bernoulli parameter for sparsity proportion, in the cholesky factor (See Details).</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_chol_s1">chol_s1</code></td>
<td>
<p>First shape of cholesky factor prior beta distribution</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_chol_s2">chol_s2</code></td>
<td>
<p>Second shape of cholesky factor prior beta distribution</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_x">x</code></td>
<td>
<p><code>ssvsinput</code></p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="set_ssvs_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\alpha</code> be the vectorized coefficient, <code class="reqn">\alpha = vec(A)</code>.
Spike-slab prior is given using two normal distributions.
</p>
<p style="text-align: center;"><code class="reqn">\alpha_j \mid \gamma_j \sim (1 - \gamma_j) N(0, \tau_{0j}^2) + \gamma_j N(0, \tau_{1j}^2)</code>
</p>

<p>As spike-slab prior itself suggests, set <code class="reqn">\tau_{0j}</code> small (point mass at zero: spike distribution)
and set <code class="reqn">\tau_{1j}</code> large (symmetric by zero: slab distribution).
</p>
<p><code class="reqn">\gamma_j</code> is the proportion of the nonzero coefficients and it follows
</p>
<p style="text-align: center;"><code class="reqn">\gamma_j \sim Bernoulli(p_j)</code>
</p>


<ul>
<li> <p><code>coef_spike</code>: <code class="reqn">\tau_{0j}</code>
</p>
</li>
<li> <p><code>coef_slab</code>: <code class="reqn">\tau_{1j}</code>
</p>
</li>
<li> <p><code>coef_mixture</code>: <code class="reqn">p_j</code>
</p>
</li>
<li> <p><code class="reqn">j = 1, \ldots, mk</code>: vectorized format corresponding to coefficient matrix
</p>
</li>
<li><p> If one value is provided, model function will read it by replicated value.
</p>
</li>
<li> <p><code>coef_non</code>: vectorized constant term is given prior Normal distribution with variance <code class="reqn">cI</code>. Here, <code>coef_non</code> is <code class="reqn">\sqrt{c}</code>.
</p>
</li></ul>

<p>Next for precision matrix <code class="reqn">\Sigma_e^{-1}</code>, SSVS applies Cholesky decomposition.
</p>
<p style="text-align: center;"><code class="reqn">\Sigma_e^{-1} = \Psi \Psi^T</code>
</p>

<p>where <code class="reqn">\Psi = \{\psi_{ij}\}</code> is upper triangular.
</p>
<p>Diagonal components follow the gamma distribution.
</p>
<p style="text-align: center;"><code class="reqn">\psi_{jj}^2 \sim Gamma(shape = a_j, rate = b_j)</code>
</p>

<p>For each row of off-diagonal (upper-triangular) components, we apply spike-slab prior again.
</p>
<p style="text-align: center;"><code class="reqn">\psi_{ij} \mid w_{ij} \sim (1 - w_{ij}) N(0, \kappa_{0,ij}^2) + w_{ij} N(0, \kappa_{1,ij}^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">w_{ij} \sim Bernoulli(q_{ij})</code>
</p>


<ul>
<li> <p><code>shape</code>: <code class="reqn">a_j</code>
</p>
</li>
<li> <p><code>rate</code>: <code class="reqn">b_j</code>
</p>
</li>
<li> <p><code>chol_spike</code>: <code class="reqn">\kappa_{0,ij}</code>
</p>
</li>
<li> <p><code>chol_slab</code>: <code class="reqn">\kappa_{1,ij}</code>
</p>
</li>
<li> <p><code>chol_mixture</code>: <code class="reqn">q_{ij}</code>
</p>
</li>
<li> <p><code class="reqn">j = 1, \ldots, mk</code>: vectorized format corresponding to coefficient matrix
</p>
</li>
<li> <p><code class="reqn">i = 1, \ldots, j - 1</code> and <code class="reqn">j = 2, \ldots, m</code>: <code class="reqn">\eta = (\psi_{12}, \psi_{13}, \psi_{23}, \psi_{14}, \ldots, \psi_{34}, \ldots, \psi_{1m}, \ldots, \psi_{m - 1, m})^T</code>
</p>
</li>
<li> <p><code>chol_</code> arguments can be one value for replication, vector, or upper triangular matrix.
</p>
</li></ul>



<h3>Value</h3>

<p><code>ssvsinput</code> object
</p>


<h3>References</h3>

<p>George, E. I., &amp; McCulloch, R. E. (1993). <em>Variable Selection via Gibbs Sampling</em>. Journal of the American Statistical Association, 88(423), 881–889.
</p>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions</em>. Journal of Econometrics, 142(1), 553–580.
</p>
<p>Koop, G., &amp; Korobilis, D. (2009). <em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>. Foundations and Trends® in Econometrics, 3(4), 267–358.
</p>

<hr>
<h2 id='set_sv'>Stochastic Volatility Specification</h2><span id='topic+set_sv'></span><span id='topic+print.svspec'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Set SV hyperparameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_sv(ig_shape = 3, ig_scl = 0.01, initial_mean = 1, initial_prec = 0.1)

## S3 method for class 'svspec'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_sv_+3A_ig_shape">ig_shape</code></td>
<td>
<p>Inverse-Gamma shape of state variance.</p>
</td></tr>
<tr><td><code id="set_sv_+3A_ig_scl">ig_scl</code></td>
<td>
<p>Inverse-Gamma scale of state variance.</p>
</td></tr>
<tr><td><code id="set_sv_+3A_initial_mean">initial_mean</code></td>
<td>
<p>Prior mean of initial state.</p>
</td></tr>
<tr><td><code id="set_sv_+3A_initial_prec">initial_prec</code></td>
<td>
<p>Prior precision of initial state.</p>
</td></tr>
<tr><td><code id="set_sv_+3A_x">x</code></td>
<td>
<p><code>svspec</code></p>
</td></tr>
<tr><td><code id="set_sv_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="set_sv_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>References</h3>

<p>Carriero, A., Chan, J., Clark, T. E., &amp; Marcellino, M. (2022). <em>Corrigendum to “Large Bayesian vector autoregressions with stochastic volatility and non-conjugate priors” [J. Econometrics 212 (1)(2019) 137–154]</em>. Journal of Econometrics, 227(2), 506-512.
</p>
<p>Chan, J., Koop, G., Poirier, D., &amp; Tobias, J. (2019). <em>Bayesian Econometric Methods (2nd ed., Econometric Exercises)</em>. Cambridge: Cambridge University Press.
</p>

<hr>
<h2 id='sim_horseshoe_var'>Generate Horseshoe Parameters</h2><span id='topic+sim_horseshoe_var'></span><span id='topic+sim_horseshoe_vhar'></span>

<h3>Description</h3>

<p>This function generates parameters of VAR with Horseshoe prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_horseshoe_var(
  p,
  dim_data = NULL,
  include_mean = TRUE,
  minnesota = FALSE,
  method = c("eigen", "chol")
)

sim_horseshoe_vhar(
  har = c(5, 22),
  dim_data = NULL,
  include_mean = TRUE,
  minnesota = c("no", "short", "longrun"),
  method = c("eigen", "chol")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_horseshoe_var_+3A_p">p</code></td>
<td>
<p>VAR lag</p>
</td></tr>
<tr><td><code id="sim_horseshoe_var_+3A_dim_data">dim_data</code></td>
<td>
<p>Specify the dimension of the data if hyperparameters of <code>bayes_spec</code> have constant values.</p>
</td></tr>
<tr><td><code id="sim_horseshoe_var_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="sim_horseshoe_var_+3A_minnesota">minnesota</code></td>
<td>
<p>Only use off-diagonal terms of each coefficient matrices for restriction.
In <code>sim_horseshoe_var()</code> function, use <code>TRUE</code> or <code>FALSE</code> (default).
In <code>sim_horseshoe_vhar()</code> function, <code>"no"</code> (default), <code>"short"</code> type, or <code>"longrun"</code> type.</p>
</td></tr>
<tr><td><code id="sim_horseshoe_var_+3A_method">method</code></td>
<td>
<p>Method to compute <code class="reqn">\Sigma^{1/2}</code>.</p>
</td></tr>
<tr><td><code id="sim_horseshoe_var_+3A_har">har</code></td>
<td>
<p>Numeric vector for weekly and monthly order. By default, <code>c(5, 22)</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='sim_iw'>Generate Inverse-Wishart Random Matrix</h2><span id='topic+sim_iw'></span>

<h3>Description</h3>

<p>This function samples one matrix IW matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_iw(mat_scale, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_iw_+3A_mat_scale">mat_scale</code></td>
<td>
<p>Scale matrix</p>
</td></tr>
<tr><td><code id="sim_iw_+3A_shape">shape</code></td>
<td>
<p>Shape</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider <code class="reqn">\Sigma \sim IW(\Psi, \nu)</code>.
</p>

<ol>
<li><p> Upper triangular Bartlett decomposition: k x k matrix <code class="reqn">Q = [q_{ij}]</code> upper triangular with
</p>

<ol>
<li> <p><code class="reqn">q_{ii}^2 \chi_{\nu - i + 1}^2</code>
</p>
</li>
<li> <p><code class="reqn">q_{ij} \sim N(0, 1)</code> with i &lt; j (upper triangular)
</p>
</li></ol>

</li>
<li><p> Lower triangular Cholesky decomposition: <code class="reqn">\Psi = L L^T</code>
</p>
</li>
<li> <p><code class="reqn">A = L (Q^{-1})^T</code>
</p>
</li>
<li> <p><code class="reqn">\Sigma = A A^T \sim IW(\Psi, \nu)</code>
</p>
</li></ol>



<h3>Value</h3>

<p>One k x k matrix following IW distribution
</p>

<hr>
<h2 id='sim_matgaussian'>Generate Matrix Normal Random Matrix</h2><span id='topic+sim_matgaussian'></span>

<h3>Description</h3>

<p>This function samples one matrix gaussian matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_matgaussian(mat_mean, mat_scale_u, mat_scale_v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_matgaussian_+3A_mat_mean">mat_mean</code></td>
<td>
<p>Mean matrix</p>
</td></tr>
<tr><td><code id="sim_matgaussian_+3A_mat_scale_u">mat_scale_u</code></td>
<td>
<p>First scale matrix</p>
</td></tr>
<tr><td><code id="sim_matgaussian_+3A_mat_scale_v">mat_scale_v</code></td>
<td>
<p>Second scale matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider n x k matrix <code class="reqn">Y_1, \ldots, Y_n \sim MN(M, U, V)</code> where M is n x k, U is n x n, and V is k x k.
</p>

<ol>
<li><p> Lower triangular Cholesky decomposition: <code class="reqn">U = P P^T</code> and <code class="reqn">V = L L^T</code>
</p>
</li>
<li><p> Standard normal generation: s x m matrix <code class="reqn">Z_i = [z_{ij} \sim N(0, 1)]</code> in row-wise direction.
</p>
</li>
<li> <p><code class="reqn">Y_i = M + P Z_i L^T</code>
</p>
</li></ol>

<p>This function only generates one matrix, i.e. <code class="reqn">Y_1</code>.
</p>


<h3>Value</h3>

<p>One n x k matrix following MN distribution.
</p>

<hr>
<h2 id='sim_mncoef'>Generate Minnesota BVAR Parameters</h2><span id='topic+sim_mncoef'></span>

<h3>Description</h3>

<p>This function generates parameters of BVAR with Minnesota prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_mncoef(p, bayes_spec = set_bvar(), full = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_mncoef_+3A_p">p</code></td>
<td>
<p>VAR lag</p>
</td></tr>
<tr><td><code id="sim_mncoef_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A BVAR model specification by <code><a href="#topic+set_bvar">set_bvar()</a></code>.</p>
</td></tr>
<tr><td><code id="sim_mncoef_+3A_full">full</code></td>
<td>
<p>Generate variance matrix from IW (default: <code>TRUE</code>) or not (<code>FALSE</code>)?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implementing dummy observation constructions,
Bańbura et al. (2010) sets Normal-IW prior.
</p>
<p style="text-align: center;"><code class="reqn">A \mid \Sigma_e \sim MN(A_0, \Omega_0, \Sigma_e)</code>
</p>

<p style="text-align: center;"><code class="reqn">\Sigma_e \sim IW(S_0, \alpha_0)</code>
</p>

<p>If <code>full = FALSE</code>, the result of <code class="reqn">\Sigma_e</code> is the same as input (<code>diag(sigma)</code>).
</p>


<h3>Value</h3>

<p>List with the following component.
</p>

<dl>
<dt>coefficients</dt><dd><p>BVAR coefficient (MN)</p>
</dd>
<dt>covmat</dt><dd><p>BVAR variance (IW or diagonal matrix of <code>sigma</code> of <code>bayes_spec</code>)</p>
</dd>
</dl>



<h3>References</h3>

<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>
<p>Karlsson, S. (2013). <em>Chapter 15 Forecasting with Bayesian Vector Autoregression</em>. Handbook of Economic Forecasting, 2, 791–897.
</p>
<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+set_bvar">set_bvar()</a></code> to specify the hyperparameters of Minnesota prior.
</p>
</li>
<li> <p><a href="#topic+bvar_adding_dummy">bvar_adding_dummy</a> for dummy observations definition.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Generate (A, Sigma)
# BVAR(p = 2)
# sigma: 1, 1, 1
# lambda: .1
# delta: .1, .1, .1
# epsilon: 1e-04
set.seed(1)
sim_mncoef(
  p = 2,
  bayes_spec = set_bvar(
    sigma = rep(1, 3),
    lambda = .1,
    delta = rep(.1, 3),
    eps = 1e-04
  ),
  full = TRUE
)
</code></pre>

<hr>
<h2 id='sim_mniw'>Generate Normal-IW Random Family</h2><span id='topic+sim_mniw'></span>

<h3>Description</h3>

<p>This function samples normal inverse-wishart matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_mniw(num_sim, mat_mean, mat_scale_u, mat_scale, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_mniw_+3A_num_sim">num_sim</code></td>
<td>
<p>Number to generate</p>
</td></tr>
<tr><td><code id="sim_mniw_+3A_mat_mean">mat_mean</code></td>
<td>
<p>Mean matrix of MN</p>
</td></tr>
<tr><td><code id="sim_mniw_+3A_mat_scale_u">mat_scale_u</code></td>
<td>
<p>First scale matrix of MN</p>
</td></tr>
<tr><td><code id="sim_mniw_+3A_mat_scale">mat_scale</code></td>
<td>
<p>Scale matrix of IW</p>
</td></tr>
<tr><td><code id="sim_mniw_+3A_shape">shape</code></td>
<td>
<p>Shape of IW</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider <code class="reqn">(Y_i, \Sigma_i) \sim MIW(M, U, \Psi, \nu)</code>.
</p>

<ol>
<li><p> Generate upper triangular factor of <code class="reqn">\Sigma_i = C_i C_i^T</code> in the upper triangular Bartlett decomposition.
</p>
</li>
<li><p> Standard normal generation: n x k matrix <code class="reqn">Z_i = [z_{ij} \sim N(0, 1)]</code> in row-wise direction.
</p>
</li>
<li><p> Lower triangular Cholesky decomposition: <code class="reqn">U = P P^T</code>
</p>
</li>
<li> <p><code class="reqn">A_i = M + P Z_i C_i^T</code>
</p>
</li></ol>



<h3>Value</h3>

<p>List of MN and IW matrices.
Multiple samples are column-stacked.
</p>

<hr>
<h2 id='sim_mnormal'>Generate Multivariate Normal Random Vector</h2><span id='topic+sim_mnormal'></span>

<h3>Description</h3>

<p>This function samples n x muti-dimensional normal random matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_mnormal(
  num_sim,
  mu = rep(0, 5),
  sig = diag(5),
  method = c("eigen", "chol")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_mnormal_+3A_num_sim">num_sim</code></td>
<td>
<p>Number to generate process</p>
</td></tr>
<tr><td><code id="sim_mnormal_+3A_mu">mu</code></td>
<td>
<p>Mean vector</p>
</td></tr>
<tr><td><code id="sim_mnormal_+3A_sig">sig</code></td>
<td>
<p>Variance matrix</p>
</td></tr>
<tr><td><code id="sim_mnormal_+3A_method">method</code></td>
<td>
<p>Method to compute <code class="reqn">\Sigma^{1/2}</code>.
Choose between <code>"eigen"</code> (spectral decomposition) and <code>"chol"</code> (cholesky decomposition).
By default, <code>"eigen"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider <code class="reqn">x_1, \ldots, x_n \sim N_m (\mu, \Sigma)</code>.
</p>

<ol>
<li><p> Lower triangular Cholesky decomposition: <code class="reqn">\Sigma = L L^T</code>
</p>
</li>
<li><p> Standard normal generation: <code class="reqn">Z_{i1}, Z_{in} \stackrel{iid}{\sim} N(0, 1)</code>
</p>
</li>
<li> <p><code class="reqn">Z_i = (Z_{i1}, \ldots, Z_{in})^T</code>
</p>
</li>
<li> <p><code class="reqn">X_i = L Z_i + \mu</code>
</p>
</li></ol>



<h3>Value</h3>

<p>T x k matrix
</p>

<hr>
<h2 id='sim_mnvhar_coef'>Generate Minnesota BVAR Parameters</h2><span id='topic+sim_mnvhar_coef'></span>

<h3>Description</h3>

<p>This function generates parameters of BVAR with Minnesota prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_mnvhar_coef(bayes_spec = set_bvhar(), full = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_mnvhar_coef_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A BVHAR model specification by <code><a href="#topic+set_bvhar">set_bvhar()</a></code> (default) or <code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code>.</p>
</td></tr>
<tr><td><code id="sim_mnvhar_coef_+3A_full">full</code></td>
<td>
<p>Generate variance matrix from IW (default: <code>TRUE</code>) or not (<code>FALSE</code>)?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Normal-IW family for vector HAR model:
</p>
<p style="text-align: center;"><code class="reqn">\Phi \mid \Sigma_e \sim MN(M_0, \Omega_0, \Sigma_e)</code>
</p>

<p style="text-align: center;"><code class="reqn">\Sigma_e \sim IW(\Psi_0, \nu_0)</code>
</p>



<h3>Value</h3>

<p>List with the following component.
</p>

<dl>
<dt>coefficients</dt><dd><p>BVHAR coefficient (MN)</p>
</dd>
<dt>covmat</dt><dd><p>BVHAR variance (IW or diagonal matrix of <code>sigma</code> of <code>bayes_spec</code>)</p>
</dd>
</dl>



<h3>References</h3>

<p>Kim, Y. G., and Baek, C. (n.d.). <em>Bayesian vector heterogeneous autoregressive modeling</em>. submitted.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+set_bvhar">set_bvhar()</a></code> to specify the hyperparameters of VAR-type Minnesota prior.
</p>
</li>
<li> <p><code><a href="#topic+set_weight_bvhar">set_weight_bvhar()</a></code> to specify the hyperparameters of HAR-type Minnesota prior.
</p>
</li>
<li> <p><a href="#topic+bvar_adding_dummy">bvar_adding_dummy</a> for dummy observations definition.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Generate (Phi, Sigma)
# BVHAR-S
# sigma: 1, 1, 1
# lambda: .1
# delta: .1, .1, .1
# epsilon: 1e-04
set.seed(1)
sim_mnvhar_coef(
  bayes_spec = set_bvhar(
    sigma = rep(1, 3),
    lambda = .1,
    delta = rep(.1, 3),
    eps = 1e-04
  ),
  full = TRUE
)
</code></pre>

<hr>
<h2 id='sim_mvt'>Generate Multivariate t Random Vector</h2><span id='topic+sim_mvt'></span>

<h3>Description</h3>

<p>This function samples n x multi-dimensional t-random matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_mvt(num_sim, df, mu, sig, method = c("eigen", "chol"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_mvt_+3A_num_sim">num_sim</code></td>
<td>
<p>Number to generate process.</p>
</td></tr>
<tr><td><code id="sim_mvt_+3A_df">df</code></td>
<td>
<p>Degrees of freedom.</p>
</td></tr>
<tr><td><code id="sim_mvt_+3A_mu">mu</code></td>
<td>
<p>Location vector</p>
</td></tr>
<tr><td><code id="sim_mvt_+3A_sig">sig</code></td>
<td>
<p>Scale matrix.</p>
</td></tr>
<tr><td><code id="sim_mvt_+3A_method">method</code></td>
<td>
<p>Method to compute <code class="reqn">\Sigma^{1/2}</code>.
Choose between <code>"eigen"</code> (spectral decomposition) and <code>"chol"</code> (cholesky decomposition).
By default, <code>"eigen"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>T x k matrix
</p>

<hr>
<h2 id='sim_ssvs_var'>Generate SSVS Parameters</h2><span id='topic+sim_ssvs_var'></span><span id='topic+sim_ssvs_vhar'></span>

<h3>Description</h3>

<p>This function generates parameters of VAR with SSVS prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_ssvs_var(
  bayes_spec,
  p,
  dim_data = NULL,
  include_mean = TRUE,
  minnesota = FALSE,
  mn_prob = 1,
  method = c("eigen", "chol")
)

sim_ssvs_vhar(
  bayes_spec,
  har = c(5, 22),
  dim_data = NULL,
  include_mean = TRUE,
  minnesota = c("no", "short", "longrun"),
  mn_prob = 1,
  method = c("eigen", "chol")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_ssvs_var_+3A_bayes_spec">bayes_spec</code></td>
<td>
<p>A SSVS model specification by <code><a href="#topic+set_ssvs">set_ssvs()</a></code>.</p>
</td></tr>
<tr><td><code id="sim_ssvs_var_+3A_p">p</code></td>
<td>
<p>VAR lag</p>
</td></tr>
<tr><td><code id="sim_ssvs_var_+3A_dim_data">dim_data</code></td>
<td>
<p>Specify the dimension of the data if hyperparameters of <code>bayes_spec</code> have constant values.</p>
</td></tr>
<tr><td><code id="sim_ssvs_var_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="sim_ssvs_var_+3A_minnesota">minnesota</code></td>
<td>
<p>Only use off-diagonal terms of each coefficient matrices for restriction.
In <code>sim_ssvs_var()</code> function, use <code>TRUE</code> or <code>FALSE</code> (default).
In <code>sim_ssvs_vhar()</code> function, <code>"no"</code> (default), <code>"short"</code> type, or <code>"longrun"</code> type.</p>
</td></tr>
<tr><td><code id="sim_ssvs_var_+3A_mn_prob">mn_prob</code></td>
<td>
<p>Probability for own-lags.</p>
</td></tr>
<tr><td><code id="sim_ssvs_var_+3A_method">method</code></td>
<td>
<p>Method to compute <code class="reqn">\Sigma^{1/2}</code>.</p>
</td></tr>
<tr><td><code id="sim_ssvs_var_+3A_har">har</code></td>
<td>
<p>Numeric vector for weekly and monthly order. By default, <code>c(5, 22)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List including coefficients.
</p>


<h3>VAR(p) with SSVS prior</h3>

<p>Let <code class="reqn">\alpha</code> be the vectorized coefficient of VAR(p).
</p>
<p style="text-align: center;"><code class="reqn">(\alpha \mid \gamma)</code>
</p>

<p style="text-align: center;"><code class="reqn">(\gamma_i)</code>
</p>

<p style="text-align: center;"><code class="reqn">(\eta_j \mid \omega_j)</code>
</p>

<p style="text-align: center;"><code class="reqn">(\omega_{ij})</code>
</p>

<p style="text-align: center;"><code class="reqn">(\psi_{ii}^2)</code>
</p>



<h3>VHAR with SSVS prior</h3>

<p>Let <code class="reqn">\phi</code> be the vectorized coefficient of VHAR.
</p>
<p style="text-align: center;"><code class="reqn">(\phi \mid \gamma)</code>
</p>

<p style="text-align: center;"><code class="reqn">(\gamma_i)</code>
</p>

<p style="text-align: center;"><code class="reqn">(\eta_j \mid \omega_j)</code>
</p>

<p style="text-align: center;"><code class="reqn">(\omega_{ij})</code>
</p>

<p style="text-align: center;"><code class="reqn">(\psi_{ii}^2)</code>
</p>



<h3>References</h3>

<p>George, E. I., &amp; McCulloch, R. E. (1993). <em>Variable Selection via Gibbs Sampling</em>. Journal of the American Statistical Association, 88(423), 881–889.
</p>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions</em>. Journal of Econometrics, 142(1), 553–580.
</p>
<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>
<p>Koop, G., &amp; Korobilis, D. (2009). <em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>. Foundations and Trends® in Econometrics, 3(4), 267–358.
</p>

<hr>
<h2 id='sim_var'>Generate Multivariate Time Series Process Following VAR(p)</h2><span id='topic+sim_var'></span>

<h3>Description</h3>

<p>This function generates multivariate time series dataset that follows VAR(p).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_var(
  num_sim,
  num_burn,
  var_coef,
  var_lag,
  sig_error = diag(ncol(var_coef)),
  init = matrix(0L, nrow = var_lag, ncol = ncol(var_coef)),
  method = c("eigen", "chol"),
  process = c("gaussian", "student"),
  t_param = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_var_+3A_num_sim">num_sim</code></td>
<td>
<p>Number to generated process</p>
</td></tr>
<tr><td><code id="sim_var_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in</p>
</td></tr>
<tr><td><code id="sim_var_+3A_var_coef">var_coef</code></td>
<td>
<p>VAR coefficient. The format should be the same as the output of <code><a href="#topic+coef.varlse">coef.varlse()</a></code> from <code><a href="#topic+var_lm">var_lm()</a></code></p>
</td></tr>
<tr><td><code id="sim_var_+3A_var_lag">var_lag</code></td>
<td>
<p>Lag of VAR</p>
</td></tr>
<tr><td><code id="sim_var_+3A_sig_error">sig_error</code></td>
<td>
<p>Variance matrix of the error term. By default, <code>diag(dim)</code>.</p>
</td></tr>
<tr><td><code id="sim_var_+3A_init">init</code></td>
<td>
<p>Initial y1, ..., yp matrix to simulate VAR model. Try <code>matrix(0L, nrow = var_lag, ncol = dim)</code>.</p>
</td></tr>
<tr><td><code id="sim_var_+3A_method">method</code></td>
<td>
<p>Method to compute <code class="reqn">\Sigma^{1/2}</code>.
Choose between <code>"eigen"</code> (spectral decomposition) and <code>"chol"</code> (cholesky decomposition).
By default, <code>"eigen"</code>.</p>
</td></tr>
<tr><td><code id="sim_var_+3A_process">process</code></td>
<td>
<p>Process to generate error term.
<code>"gaussian"</code>: Normal distribution (default) or <code>"student"</code>: Multivariate t-distribution.</p>
</td></tr>
<tr><td><code id="sim_var_+3A_t_param">t_param</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> argument for MVT, e.g. DF: 5.</p>
</td></tr>
</table>


<h3>Details</h3>


<ol>
<li><p> Generate <code class="reqn">\epsilon_1, \epsilon_n \sim N(0, \Sigma)</code>
</p>
</li>
<li><p> For i = 1, ... n,
</p>
<p style="text-align: center;"><code class="reqn">y_{p + i} = (y_{p + i - 1}^T, \ldots, y_i^T, 1)^T B + \epsilon_i</code>
</p>

</li>
<li><p> Then the output is <code class="reqn">(y_{p + 1}, \ldots, y_{n + p})^T</code>
</p>
</li></ol>

<p>Initial values might be set to be zero vector or <code class="reqn">(I_m - A_1 - \cdots - A_p)^{-1} c</code>.
</p>


<h3>Value</h3>

<p>T x k matrix
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='sim_vhar'>Generate Multivariate Time Series Process Following VAR(p)</h2><span id='topic+sim_vhar'></span>

<h3>Description</h3>

<p>This function generates multivariate time series dataset that follows VAR(p).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_vhar(
  num_sim,
  num_burn,
  vhar_coef,
  week = 5L,
  month = 22L,
  sig_error = diag(ncol(vhar_coef)),
  init = matrix(0L, nrow = month, ncol = ncol(vhar_coef)),
  method = c("eigen", "chol"),
  process = c("gaussian", "student"),
  t_param = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_vhar_+3A_num_sim">num_sim</code></td>
<td>
<p>Number to generated process</p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in</p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_vhar_coef">vhar_coef</code></td>
<td>
<p>VAR coefficient. The format should be the same as the output of <code><a href="#topic+coef.varlse">coef.varlse()</a></code> from <code><a href="#topic+var_lm">var_lm()</a></code></p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_week">week</code></td>
<td>
<p>Weekly order of VHAR. By default, <code>5</code>.</p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_month">month</code></td>
<td>
<p>Weekly order of VHAR. By default, <code>22</code>.</p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_sig_error">sig_error</code></td>
<td>
<p>Variance matrix of the error term. By default, <code>diag(dim)</code>.</p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_init">init</code></td>
<td>
<p>Initial y1, ..., yp matrix to simulate VAR model. Try <code>matrix(0L, nrow = month, ncol = dim)</code>.</p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_method">method</code></td>
<td>
<p>Method to compute <code class="reqn">\Sigma^{1/2}</code>.
Choose between <code>"eigen"</code> (spectral decomposition) and <code>"chol"</code> (cholesky decomposition).
By default, <code>"eigen"</code>.</p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_process">process</code></td>
<td>
<p>Process to generate error term.
<code>"gaussian"</code>: Normal distribution (default) or <code>"student"</code>: Multivariate t-distribution.</p>
</td></tr>
<tr><td><code id="sim_vhar_+3A_t_param">t_param</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> argument for MVT, e.g. DF: 5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">M</code> be the month order, e.g. <code class="reqn">M = 22</code>.
</p>

<ol>
<li><p> Generate <code class="reqn">\epsilon_1, \epsilon_n \sim N(0, \Sigma)</code>
</p>
</li>
<li><p> For i = 1, ... n,
</p>
<p style="text-align: center;"><code class="reqn">y_{M + i} = (y_{M + i - 1}^T, \ldots, y_i^T, 1)^T C_{HAR}^T \Phi + \epsilon_i</code>
</p>

</li>
<li><p> Then the output is <code class="reqn">(y_{M + 1}, \ldots, y_{n + M})^T</code>
</p>
</li>
<li><p> For i = 1, ... n,
</p>
<p style="text-align: center;"><code class="reqn">y_{p + i} = (y_{p + i - 1}^T, \ldots, y_i^T, 1)^T B + \epsilon_i</code>
</p>

</li>
<li><p> Then the output is <code class="reqn">(y_{p + 1}, \ldots, y_{n + p})^T</code>
</p>
</li></ol>

<p>Initial values might be set to be zero vector or <code class="reqn">(I_m - A_1 - \cdots - A_p)^{-1} c</code>.
</p>


<h3>Value</h3>

<p>T x k matrix
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='split_coef'>Splitting Coefficient Matrix into List</h2><span id='topic+split_coef'></span><span id='topic+split_coef.bvharmod'></span><span id='topic+split_coef.bvharirf'></span>

<h3>Description</h3>

<p>Split <code>coefficients</code> into matrix list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_coef(object, ...)

## S3 method for class 'bvharmod'
split_coef(object, ...)

## S3 method for class 'bvharirf'
split_coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_coef_+3A_object">object</code></td>
<td>
<p><code>bvharmod</code> object</p>
</td></tr>
<tr><td><code id="split_coef_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each result of <code><a href="#topic+var_lm">var_lm()</a></code>, <code><a href="#topic+vhar_lm">vhar_lm()</a></code>, <code><a href="#topic+bvar_minnesota">bvar_minnesota()</a></code>, <code><a href="#topic+bvar_flat">bvar_flat()</a></code>, and <code><a href="#topic+bvhar_minnesota">bvhar_minnesota()</a></code> is a subclass of <code>bvharmod</code>.
For example,
<code>c("varlse", "bvharmod")</code>.
</p>


<h3>Value</h3>

<p>A <code>list</code> object
</p>

<hr>
<h2 id='spne'>Evaluate the Estimation Based on Spectral Norm Error</h2><span id='topic+spne'></span><span id='topic+spne.bvharsp'></span>

<h3>Description</h3>

<p>This function computes estimation error given estimated model and true coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spne(x, y, ...)

## S3 method for class 'bvharsp'
spne(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spne_+3A_x">x</code></td>
<td>
<p>Estimated model.</p>
</td></tr>
<tr><td><code id="spne_+3A_y">y</code></td>
<td>
<p>Coefficient matrix to be compared.</p>
</td></tr>
<tr><td><code id="spne_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\lVert \cdot \rVert_2</code> be the spectral norm of a matrix,
let <code class="reqn">\hat{\Phi}</code> be the estimates,
and let <code class="reqn">\Phi</code> be the true coefficients matrix.
Then the function computes estimation error by
</p>
<p style="text-align: center;"><code class="reqn">\lVert \hat{\Phi} - \Phi \rVert_2</code>
</p>



<h3>Value</h3>

<p>Spectral norm value
</p>


<h3>References</h3>

<p>Ghosh, S., Khare, K., &amp; Michailidis, G. (2018). <em>High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models</em>. Journal of the American Statistical Association, 114(526).
</p>

<hr>
<h2 id='ssvs_bvar_algo'>Stochastic Search Variable Selection in VAR</h2><span id='topic+ssvs_bvar_algo'></span>

<h3>Description</h3>

<p>This page describes a stochastic search variable selection (SSVS) MCMC algorithm
in a VAR model.
</p>


<h3>SSVS Prior</h3>

<p>Consider the vectorized formulation <code class="reqn">vec(Y_0) = (I_k \otimes X_0) vec(A) + vec(Z_0)</code>.
As the other Bayesian VAR model, this model handles coefficients <code class="reqn">A</code> and variance matrix <code class="reqn">\Sigma_e</code>.
To shrink <code class="reqn">\Sigma_e^{-1}</code>, however, upper cholesky factor is used as the alternative <code class="reqn">\Sigma_e^{-1} = \Psi \Psi^\intercal</code> in this context.
</p>


<h4>Prior of coefficients</h4>

<p>Each <code class="reqn">vec(A) = \alpha = (\alpha_1, \ldots, \alpha_{k^2 p + k})</code> except constant-corresponding term is restricted by
<code class="reqn">\gamma = (\gamma_1, \ldots, \gamma_{k^2 p})^\intercal</code>, which is dummy vector.
Then
</p>
<p style="text-align: center;"><code class="reqn">
  h_i = \begin{cases}
    \tau_{0i} &amp; \text{if } \gamma_i = 0 \\
    \tau_{1i} &amp; \text{if } \gamma_i = 1
  \end{cases}
</code>
</p>

<p>with small <code class="reqn">\tau_{0j}</code> and large <code class="reqn">\tau_{1j}</code>.
In turn, <code class="reqn">D = diag(h_1, \ldots, h_{k^2 p})</code>.
</p>
<p>Let <code class="reqn">\alpha_{coef}</code> be the restricted coefficients vector
and let <code class="reqn">\alpha_{non}</code> be the not-restricted coefficients vector, i.e. vectorized constant term.
Each term has its own prior.
</p>
<p style="text-align: center;"><code class="reqn">
  \alpha_{coef} \mid \gamma \sim N(0_{k^2 p}, DD),
  \quad
  \alpha_{non} \sim N(0_k, c I_k)
</code>
</p>

<p>If <code class="reqn">c</code> is large, then prior influence to <code class="reqn">\alpha_{non}</code> decreases.
By combining each term in appropriate order,
</p>
<p style="text-align: center;"><code class="reqn">\alpha \mid \gamma \sim N(0_{k^2 p + k}, M)</code>
</p>

<p>is acquired by
</p>
<p style="text-align: center;"><code class="reqn">
  M_0 = I_{k p + 1} \otimes \begin{bmatrix}
    DD &amp; 0_{k^2 p} \\
    0_{k^2 p}^\intercal &amp; c
  \end{bmatrix}
</code>
</p>

<p>Sometimes nonzero prior mean <code class="reqn">\alpha_0</code> is also considered.
</p>



<h4>Prior of Coefficients Restrictions</h4>

<p>It is natural that 0-1 <code class="reqn">\gamma_{j}</code> has Bernoulli distribution.
</p>
<p style="text-align: center;"><code class="reqn">\gamma_j \sim Bernoulli(p_j)</code>
</p>

<p>If there is no information, set <code class="reqn">p_j = 0.5</code>.
</p>



<h4>Prior of Cholesky Factor</h4>

<p>Let <code class="reqn">\Psi = [\psi_{ij}] \in \mathbb{R}^{k \times k}</code>.
Recall that <code class="reqn">\Psi</code> is an upper triangular matrix such that <code class="reqn">\Sigma_e^{-1} = \Psi \Psi^\intercal</code>.
</p>
<p>To define the prior distribution, George et al. (2008) divide the matrix in two parts
</p>

<ul>
<li><p> Diagnonal element: <code class="reqn">\psi = (\psi_{11}, \ldots, \psi_{kk})^\intercal</code>
</p>
</li>
<li><p> Off-diagonal element: <code class="reqn">\eta_j = (\psi_{1j}, \ldots, \psi_{j-1, j})^\intercal, j = 2, \ldots, k</code>
</p>
</li></ul>




<h4>Prior of off-diagonal element</h4>

<p>To restrict cholesky factor, dummy vector <code class="reqn">\omega_j = (\omega_{1j}, \ldots, \omega_{j - 1, j})^\intercal</code>
corresponding to off-diagonal elements are defined.
Then the matrix <code class="reqn">D_j = diag(h_{1j}, \ldots, h_{j-1, j})</code> is defined by
</p>
<p style="text-align: center;"><code class="reqn">
  h_{ij} = \begin{cases}
    \kappa_{0ij} &amp; \text{if } \omega_{ij} = 0 \\
    \kappa_{1ij} &amp; \text{if } \omega_{ij} = 1
  \end{cases}
</code>
</p>

<p>with small <code class="reqn">\kappa_{0ij}</code> and large <code class="reqn">\kappa_{1ij}</code>.
As coefficients vector, <code class="reqn">\eta_j</code> has normal distribution
</p>
<p style="text-align: center;"><code class="reqn">\eta_j \mid \omega_j \sim N(0_{j - 1}, D_j D_j), j = 2, \ldots, k</code>
</p>




<h4>Prior of off-diagonal element restrictions</h4>

<p>As <code class="reqn">\gamma_j</code>, <code class="reqn">\omega_{ij}</code> has Bernoulli distribution.
</p>
<p style="text-align: center;"><code class="reqn">\omega_{ij} \sim Bernoulli(q_{ij})</code>
</p>

<p><code class="reqn">q_{ij} = 0.5</code> is the most common choice.
</p>



<h4>Prior of diagonal element</h4>

<p>Since cholesky factor is positive definite, diagonal element of the matrix is given Gamma distribution.
</p>
<p style="text-align: center;"><code class="reqn">\psi_{jj}^2 \sim Gamma(shape = a_j, rate = b_j)</code>
</p>




<h3>Gibbs Sampling</h3>



<h4>Full Conditional</h4>

<p>George et al. (2008) presents every full conditionals.
Let SSE matrix be <code class="reqn">S(\hat{A}) = (Y_0 - X_0 \hat{A})^\intercal (Y_0 - X_0 \hat{A}) \in \mathbb{R}^{k \times k}</code>,
let <code class="reqn">S_j</code> be the upper-left j x j block matrix of <code class="reqn">S(A)</code>,
and let <code class="reqn">s_j = (s_{1j}, \ldots, s_{j - 1, j})^\intercal</code> of <code class="reqn">S(A)</code>.
</p>
<p>For specified shape and rate of Gamma distribution <code class="reqn">a_j</code> and <code class="reqn">b_j</code>,
</p>
<p style="text-align: center;"><code class="reqn">
  \psi_{jj}^2 \mid \alpha, \gamma, \omega, Y_0 \sim \gamma(a_i + n / 2, B_i)
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  B_i = \begin{cases}
    b_1 + s_{11} / 2 &amp; \text{if } i = 1 \\
    b_i + (s_{ii} - s_i^\intercal ( S_{i - 1} + (D_i R_i D_i)^(-1) )^(-1) s_i) &amp; \text{if } i = 2, \ldots, k
  \end{cases}
</code>
</p>

<p>, and <code class="reqn">D_i = diag(h_{1j}, \ldots, h_{i - 1, i}) \in \mathbb{R}^{(j - 1) \times (j - 1)}</code>.
</p>
<p>For every <code class="reqn">j = 1, \ldots, k</code>,
</p>
<p style="text-align: center;"><code class="reqn">
  \eta_j \mid \alpha, \gamma, \omega, \psi, Y_0 \sim N (\mu_j, \Delta_j)
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  \mu_j = -\psi_{jj} (S_{j - 1} + (D_j R_j D_j)^{-1})^{-1} s_j \in \mathbb{R}^{j - 1},
  \Delta_j = (S_{j - 1} + (D_j R_j D_j)^{-1})^{-1} \in \mathbb{R}^{(j - 1) \times (j - 1)}
</code>
</p>

<p>Consider restriction dummy vectors.
</p>
<p style="text-align: center;"><code class="reqn">
  \omega_{ij} \mid \eta_j, \psi_j, \alpha, \gamma, \omega_{j}^{(previous)} \sim Bernoulli(\frac{u_{ij1}}{u_{ij1} + u_{ij2}})
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  u_{ij1} = \frac{1}{\kappa_{1ij}} \exp(- \frac{\psi_{ij}^2}{2 \kappa_{1ij}^2}) q_{ij},
  u_{ij2} = \frac{1}{\kappa_{0ij}} \exp(- \frac{\psi_{ij}^2}{2 \kappa_{0ij}^2}) (1 - q_{ij})
</code>
</p>

<p>Also,
</p>
<p style="text-align: center;"><code class="reqn">
  \gamma_j \mid \alpha, \psi, \eta, \omega, Y_0 \sim Bernoulli(\frac{u_{i1}}{u_{j1} + u_{j2}})
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  u_{j1} = \frac{1}{\tau_{1j}} \exp(- \frac{\alpha_j^2}{2 \tau_{1j}^2})p_i,
  u_{j2} = \frac{1}{\tau_{0j}} \exp(- \frac{\alpha_j^2}{2 \tau_{0j}^2})(1 - p_i)
</code>
</p>

<p>In case of coefficients vector,
</p>
<p style="text-align: center;"><code class="reqn">\alpha \mid \gamma, \eta, \omega, \psi, Y_0 \sim N (\mu, \Delta)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  \mu = (
'     (\Psi \Psi^\intercal) \otimes (X_0 X_0^\intercal) + M^{-1}
  )^{-1} (
'     ( (\Psi \Psi^\intercal) \otimes (X_0 X_0^\intercal) ) \hat{\alpha} + M^{-1} \alpha_0
  )
</code>
</p>

<p>where <code class="reqn">\alpha_0</code> is the prior mean for <code class="reqn">\alpha \mid \gamma</code>,
and <code class="reqn">\hat{\alpha}</code> is MLE (equivalently, OLS).
</p>
<p style="text-align: center;"><code class="reqn">
  \Delta = ((\Psi \Psi^\intercal) \otimes (X_0 X_0^\intercal) + M^{-1})^{-1}
</code>
</p>




<h4>Gibbs Sampling</h4>

<p>Data: <code class="reqn">X_0</code>, <code class="reqn">Y_0</code>
</p>
<p>Input:
</p>

<ul>
<li><p> VAR order p
</p>
</li>
<li><p> MCMC iteration number
</p>
</li>
<li><p> Weight of each slab: Bernoulli distribution parameters
</p>

<ul>
<li> <p><code class="reqn">p_j</code>: of coefficients
</p>
</li>
<li> <p><code class="reqn">q_{ij}</code>: of cholesky factor
</p>
</li></ul>

</li>
<li><p> Gamma distribution parameters for cholesky factor diagonal elements <code class="reqn">\psi_{jj}</code>
</p>

<ul>
<li> <p><code class="reqn">a_j</code>: shape
</p>
</li>
<li> <p><code class="reqn">b_j</code>: rate
</p>
</li></ul>

</li>
<li><p> Correlation matrix of coefficient vector: <code class="reqn">R = I_{k^2p}</code>
</p>
</li>
<li><p> Correlation matrix to restrict cholesky factor (of <code class="reqn">\eta_j</code>): <code class="reqn">R_j = I_{j - 1}</code>
</p>
</li>
<li><p> Tuning parameters for spike-and-slab sd semi-automatic approach
</p>

<ul>
<li> <p><code class="reqn">c_0</code>: small value (0.1)
</p>
</li>
<li> <p><code class="reqn">c_1</code>: large value (10)
</p>
</li></ul>

</li>
<li><p> Constant to reduce prior influence on constant term: <code class="reqn">c</code>
</p>
</li></ul>

<p>Algorithm:
</p>

<ol>
<li><p> Initialize <code class="reqn">\Psi</code>, <code class="reqn">\omega</code>, <code class="reqn">\alpha</code>, <code class="reqn">\gamma</code>
</p>
</li>
<li><p> Iterate
</p>

<ol>
<li><p> Diagonal elements of cholesky factor: <code class="reqn">\psi^{(t)} \mid \alpha^{(t - 1)}, \gamma^{(t - 1)}, \omega^{(t - 1)}, Y_0</code>
</p>
</li>
<li><p> Off-diagonal elements of cholesky factor: <code class="reqn">\eta^{(t)} \mid \psi^{(t)} \alpha^{(t - 1)}, \gamma^{(t - 1)}, \omega^{(t - 1)}, Y_0</code>
</p>
</li>
<li><p> Dummy vector for cholesky factor: <code class="reqn">\omega^{(t)} \mid \eta^{(t)}, \psi^{(t)} \alpha^{(t - 1)}, \gamma^{(t - 1)}, \omega^{(t - 1)}, Y_0</code>
</p>
</li>
<li><p> Coefficient vector: <code class="reqn">\alpha^{(t)} \mid \gamma^{(t - 1)}, \Sigma^{(t)}, \omega^{(t)}, Y_0</code>
</p>
</li>
<li><p> Dummy vector for coefficient vector: <code class="reqn">\gamma^{(t)} \mid \alpha^{(t)}, \psi^{(t)}, \eta^{(t)}, \omega^{(t)}, Y_0</code>
</p>
</li></ol>

</li></ol>

<p>Output:
</p>

<ul>
<li><p> Parameter trace
</p>
</li>
<li><p> Update results
</p>
</li>
<li><p> OLS
</p>
</li></ul>




<h3>References</h3>

<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions. Journal of Econometrics</em>, 142(1), 553–580.
</p>
<p>Koop, G., &amp; Korobilis, D. (2009). <em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>. Foundations and Trends® in Econometrics, 3(4), 267–358.
</p>

<hr>
<h2 id='ssvs_bvhar_algo'>Stochastic Search Variable Selection in VHAR</h2><span id='topic+ssvs_bvhar_algo'></span>

<h3>Description</h3>

<p>This page describes a stochastic search variable selection (SSVS) MCMC algorithm
in a VHAR model.
Recall that <code class="reqn">\Sigma_e = \Psi \Psi^\intercal</code>.
</p>


<h3>SSVS Prior</h3>



<h4>Prior of coefficients</h4>

<p>Among <code class="reqn">vec(\Phi) = \phi = (\phi_1, \ldots, \phi_{3 k^2 + k})</code>,
non-constant terms are restricted by dummy vector <code class="reqn">\gamma = (\gamma_1, \ldots, \gamma_{3 k^2})^\intercal</code>.
This defines the diagonal matrix <code class="reqn">D = diag(h_1, \ldots, h_{k^2 p})</code> by
</p>
<p style="text-align: center;"><code class="reqn">
  h_i = \begin{cases}
    \tau_{0i} &amp; \text{if } \gamma_i = 0 \\
    \tau_{1i} &amp; \text{if } \gamma_i = 1
  \end{cases}
</code>
</p>

<p>with small <code class="reqn">\tau_{0j}</code> and large <code class="reqn">\tau_{1j}</code>.
</p>
<p>Let <code class="reqn">\phi_{coef}</code> be the restricted coefficients vector
and let <code class="reqn">\phi_{non}</code> be the not-restricted coefficients vector, i.e. vectorized constant term.
Each term has its own prior.
</p>
<p style="text-align: center;"><code class="reqn">
  \phi_{coef} \mid \gamma \sim N(\phi_{0, coef}, DD),
  \quad
  \alpha_{non} \sim N(\phi_{0, non}, c I_k)
</code>
</p>

<p>If <code class="reqn">c</code> is large, then prior influence to <code class="reqn">\phi_{non}</code> decreases.
By combining each term in appropriate order,
</p>
<p style="text-align: center;"><code class="reqn">\phi \mid \gamma \sim N(0_{3 k^2 + k}, M)</code>
</p>

<p>with
</p>
<p style="text-align: center;"><code class="reqn">
  M = I_{k p + 1} \otimes \begin{bmatrix}
    DD &amp; 0_{k^2 p} \\
    0_{k^2 p}^\intercal &amp; c
  \end{bmatrix}
</code>
</p>

<p>and <code class="reqn">\phi_0</code> combined in the same way.
</p>



<h4>Prior of Other Parameters</h4>

<p>We are using the the notations for the other parameters, so see <a href="#topic+ssvs_bvar_algo">ssvs_bvar_algo</a>.
</p>



<h3>Gibbs Sampling</h3>

<p>Data: <code class="reqn">X_0</code>, <code class="reqn">Y_0</code>, VAR linear transformation
</p>
<p>Input:
</p>

<ul>
<li><p> VHAR order (week, month)
</p>
</li>
<li><p> MCMC iteration number
</p>
</li>
<li><p> Weight of each slab: Bernoulli distribution parameters
</p>

<ul>
<li> <p><code class="reqn">p_j</code>: of coefficients
</p>
</li>
<li> <p><code class="reqn">q_{ij}</code>: of cholesky factor
</p>
</li></ul>

</li>
<li><p> Gamma distribution parameters for cholesky factor diagonal elements <code class="reqn">\psi_{jj}</code>
</p>

<ul>
<li> <p><code class="reqn">a_j</code>: shape
</p>
</li>
<li> <p><code class="reqn">b_j</code>: rate
</p>
</li></ul>

</li>
<li><p> Correlation matrix of coefficient vector: <code class="reqn">R = I_{k^2p}</code>
</p>
</li>
<li><p> Correlation matrix to restrict cholesky factor (of <code class="reqn">\eta_j</code>): <code class="reqn">R_j = I_{j - 1}</code>
</p>
</li>
<li><p> Tuning parameters for spike-and-slab sd semi-automatic approach
</p>

<ul>
<li> <p><code class="reqn">c_0</code>: small value (0.1)
</p>
</li>
<li> <p><code class="reqn">c_1</code>: large value (10)
</p>
</li></ul>

</li>
<li><p> Constant to reduce prior influence on constant term: <code class="reqn">c</code>
</p>
</li></ul>

<p>Algorithm:
</p>

<ol>
<li><p> Initialize <code class="reqn">\Psi</code>, <code class="reqn">\omega</code>, <code class="reqn">\phi</code>, <code class="reqn">\gamma</code>
</p>
</li>
<li><p> Iterate
</p>

<ol>
<li><p> Diagonal elements of cholesky factor: <code class="reqn">\psi^{(t)} \mid \phi^{(t - 1)}, \gamma^{(t - 1)}, \omega^{(t - 1)}, Y_0</code>
</p>
</li>
<li><p> Off-diagonal elements of cholesky factor: <code class="reqn">\eta^{(t)} \mid \psi^{(t)} \phi^{(t - 1)}, \gamma^{(t - 1)}, \omega^{(t - 1)}, Y_0</code>
</p>
</li>
<li><p> Dummy vector for cholesky factor: <code class="reqn">\omega^{(t)} \mid \eta^{(t)}, \psi^{(t)} \phi^{(t - 1)}, \gamma^{(t - 1)}, \omega^{(t - 1)}, Y_0</code>
</p>
</li>
<li><p> Coefficient vector: <code class="reqn">\phi^{(t)} \mid \gamma^{(t - 1)}, \Sigma^{(t)}, \omega^{(t)}, Y_0 \sim \mu, \Delta)</code>
</p>

<ul>
<li><p> where <code class="reqn">\mu = ((\Psi \Psi^\intercal) \otimes (X_1 X_1^\intercal) + M^{-1})^{-1} (( (\Psi \Psi^\intercal) \otimes (X_1 X_1^\intercal) ) \hat{\phi} + M^{-1} \phi_0)</code>
</p>
</li>
<li><p> and <code class="reqn">\Delta = ((\Psi \Psi^\intercal) \otimes (X_1 X_1^\intercal) + M^{-1})^{-1}</code>
</p>
</li></ul>

</li>
<li><p> Dummy vector for coefficient vector: <code class="reqn">\gamma^{(t)} \mid \phi^{(t)}, \psi^{(t)}, \eta^{(t)}, \omega^{(t)}, Y_0</code>
</p>
</li></ol>

</li></ol>

<p>Output:
</p>

<ul>
<li><p> Parameter trace
</p>
</li>
<li><p> Update results
</p>
</li>
<li><p> OLS
</p>
</li></ul>



<h3>References</h3>

<p>George, E. I., Sun, D., &amp; Ni, S. (2008). <em>Bayesian stochastic search for VAR model restrictions. Journal of Econometrics</em>, 142(1), 553–580.
</p>
<p>Koop, G., &amp; Korobilis, D. (2009). <em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>. Foundations and Trends® in Econometrics, 3(4), 267–358.
</p>

<hr>
<h2 id='stableroot'>Roots of characteristic polynomial</h2><span id='topic+stableroot'></span>

<h3>Description</h3>

<p>Roots of characteristic polynomial
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stableroot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stableroot_+3A_x">x</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="stableroot_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector.
</p>

<hr>
<h2 id='stableroot.varlse'>Characteristic polynomial roots for VAR Coefficient Matrix</h2><span id='topic+stableroot.varlse'></span><span id='topic+stableroot.vharlse'></span><span id='topic+stableroot.bvarmn'></span><span id='topic+stableroot.bvarflat'></span><span id='topic+stableroot.bvharmn'></span>

<h3>Description</h3>

<p>Compute the character polynomial of VAR(p) coefficient matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
stableroot(x, ...)

## S3 method for class 'vharlse'
stableroot(x, ...)

## S3 method for class 'bvarmn'
stableroot(x, ...)

## S3 method for class 'bvarflat'
stableroot(x, ...)

## S3 method for class 'bvharmn'
stableroot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stableroot.varlse_+3A_x">x</code></td>
<td>
<p>Model fit</p>
</td></tr>
<tr><td><code id="stableroot.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To know whether the process is stable or not, make characteristic polynomial.
</p>
<p style="text-align: center;"><code class="reqn">\det(I_m - A z) = 0</code>
</p>

<p>where <code class="reqn">A</code> is VAR(1) coefficient matrix representation.
</p>


<h3>Value</h3>

<p>Numeric vector.
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='summary.normaliw'>Summarizing Bayesian Multivariate Time Series Model</h2><span id='topic+summary.normaliw'></span><span id='topic+print.summary.normaliw'></span><span id='topic+knit_print.summary.normaliw'></span>

<h3>Description</h3>

<p><code>summary</code> method for <code>normaliw</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'normaliw'
summary(
  object,
  num_iter = 10000L,
  num_burn = floor(num_iter/2),
  thinning = 1L,
  ...
)

## S3 method for class 'summary.normaliw'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'summary.normaliw'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.normaliw_+3A_object">object</code></td>
<td>
<p><code>normaliw</code> object</p>
</td></tr>
<tr><td><code id="summary.normaliw_+3A_num_iter">num_iter</code></td>
<td>
<p>Number to sample MNIW distribution</p>
</td></tr>
<tr><td><code id="summary.normaliw_+3A_num_burn">num_burn</code></td>
<td>
<p>Number of burn-in</p>
</td></tr>
<tr><td><code id="summary.normaliw_+3A_thinning">thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td></tr>
<tr><td><code id="summary.normaliw_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="summary.normaliw_+3A_x">x</code></td>
<td>
<p><code>summary.normaliw</code> object</p>
</td></tr>
<tr><td><code id="summary.normaliw_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From Minnesota prior, set of coefficient matrices and residual covariance matrix have matrix Normal Inverse-Wishart distribution.
</p>
<p>BVAR:
</p>
<p style="text-align: center;"><code class="reqn">(A, \Sigma_e) \sim MNIW(\hat{A}, \hat{V}^{-1}, \hat\Sigma_e, \alpha_0 + n)</code>
</p>

<p>where <code class="reqn">\hat{V} = X_\ast^T X_\ast</code> is the posterior precision of MN.
</p>
<p>BVHAR:
</p>
<p style="text-align: center;"><code class="reqn">(\Phi, \Sigma_e) \sim MNIW(\hat\Phi, \hat{V}_H^{-1}, \hat\Sigma_e, \nu + n)</code>
</p>

<p>where <code class="reqn">\hat{V}_H = X_{+}^T X_{+}</code> is the posterior precision of MN.
</p>


<h3>Value</h3>

<p><code>summary.normaliw</code> <a href="base.html#topic+class">class</a> has the following components:
</p>

<dl>
<dt>names</dt><dd><p>Variable names</p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>p</dt><dd><p>Lag of VAR</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>spec</dt><dd><p>Model specification (<code>bvharspec</code>)</p>
</dd>
<dt>mn_mean</dt><dd><p>MN Mean of posterior distribution (MN-IW)</p>
</dd>
<dt>mn_prec</dt><dd><p>MN Precision of posterior distribution (MN-IW)</p>
</dd>
<dt>iw_scale</dt><dd><p>IW scale of posterior distribution (MN-IW)</p>
</dd>
<dt>iw_shape</dt><dd><p>IW df of posterior distribution (MN-IW)</p>
</dd>
<dt>iter</dt><dd><p>Number of MCMC iterations</p>
</dd>
<dt>burn</dt><dd><p>Number of MCMC burn-in</p>
</dd>
<dt>thin</dt><dd><p>MCMC thinning</p>
</dd>
<dt>alpha_record (BVAR) and phi_record (BVHAR)</dt><dd><p>MCMC record of coefficients vector</p>
</dd>
<dt>psi_record</dt><dd><p>MCMC record of upper cholesky factor</p>
</dd>
<dt>omega_record</dt><dd><p>MCMC record of diagonal of cholesky factor</p>
</dd>
<dt>eta_record</dt><dd><p>MCMC record of upper part of cholesky factor</p>
</dd>
<dt>param</dt><dd><p>MCMC record of every parameter</p>
</dd>
<dt>coefficients</dt><dd><p>Posterior mean of coefficients</p>
</dd>
<dt>covmat</dt><dd><p>Posterior mean of covariance</p>
</dd>
</dl>



<h3>References</h3>

<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>
<p>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>

<hr>
<h2 id='summary.varlse'>Summarizing Vector Autoregressive Model</h2><span id='topic+summary.varlse'></span><span id='topic+print.summary.varlse'></span><span id='topic+knit_print.summary.varlse'></span>

<h3>Description</h3>

<p><code>summary</code> method for <code>varlse</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varlse'
summary(object, ...)

## S3 method for class 'summary.varlse'
print(x, digits = max(3L, getOption("digits") - 3L), signif_code = TRUE, ...)

## S3 method for class 'summary.varlse'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.varlse_+3A_object">object</code></td>
<td>
<p><code>varlse</code> object</p>
</td></tr>
<tr><td><code id="summary.varlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="summary.varlse_+3A_x">x</code></td>
<td>
<p><code>summary.varlse</code> object</p>
</td></tr>
<tr><td><code id="summary.varlse_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="summary.varlse_+3A_signif_code">signif_code</code></td>
<td>
<p>Check significant rows (Default: <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.varlse</code> <a href="base.html#topic+class">class</a> additionally computes the following
</p>
<table>
<tr><td><code>names</code></td>
<td>
<p>Variable names</p>
</td></tr>
<tr><td><code>totobs</code></td>
<td>
<p>Total number of the observation</p>
</td></tr>
<tr><td><code>obs</code></td>
<td>
<p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>Lag of VAR</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>Coefficient Matrix</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>Matched call</p>
</td></tr>
<tr><td><code>process</code></td>
<td>
<p>Process: VAR</p>
</td></tr>
<tr><td><code>covmat</code></td>
<td>
<p>Covariance matrix of the residuals</p>
</td></tr>
<tr><td><code>corrmat</code></td>
<td>
<p>Correlation matrix of the residuals</p>
</td></tr>
<tr><td><code>roots</code></td>
<td>
<p>Roots of characteristic polynomials</p>
</td></tr>
<tr><td><code>is_stable</code></td>
<td>
<p>Whether the process is stable or not based on <code>roots</code></p>
</td></tr>
<tr><td><code>log_lik</code></td>
<td>
<p>log-likelihood</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>Information criteria vector</p>
</td></tr>
</table>

<ul>
<li><p><code>AIC</code> - AIC
</p>
</li>
<li><p><code>BIC</code> - BIC
</p>
</li>
<li><p><code>HQ</code> - HQ
</p>
</li>
<li><p><code>FPE</code> - FPE
</p>
</li></ul>



<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='summary.vharlse'>Summarizing Vector HAR Model</h2><span id='topic+summary.vharlse'></span><span id='topic+print.summary.vharlse'></span><span id='topic+knit_print.summary.vharlse'></span>

<h3>Description</h3>

<p><code>summary</code> method for <code>vharlse</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'vharlse'
summary(object, ...)

## S3 method for class 'summary.vharlse'
print(x, digits = max(3L, getOption("digits") - 3L), signif_code = TRUE, ...)

## S3 method for class 'summary.vharlse'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.vharlse_+3A_object">object</code></td>
<td>
<p><code>vharlse</code> object</p>
</td></tr>
<tr><td><code id="summary.vharlse_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="summary.vharlse_+3A_x">x</code></td>
<td>
<p><code>summary.vharlse</code> object</p>
</td></tr>
<tr><td><code id="summary.vharlse_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="summary.vharlse_+3A_signif_code">signif_code</code></td>
<td>
<p>Check significant rows (Default: <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.vharlse</code> <a href="base.html#topic+class">class</a> additionally computes the following
</p>
<table>
<tr><td><code>names</code></td>
<td>
<p>Variable names</p>
</td></tr>
<tr><td><code>totobs</code></td>
<td>
<p>Total number of the observation</p>
</td></tr>
<tr><td><code>obs</code></td>
<td>
<p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>3</p>
</td></tr>
<tr><td><code>week</code></td>
<td>
<p>Order for weekly term</p>
</td></tr>
<tr><td><code>month</code></td>
<td>
<p>Order for monthly term</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>Coefficient Matrix</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>Matched call</p>
</td></tr>
<tr><td><code>process</code></td>
<td>
<p>Process: VAR</p>
</td></tr>
<tr><td><code>covmat</code></td>
<td>
<p>Covariance matrix of the residuals</p>
</td></tr>
<tr><td><code>corrmat</code></td>
<td>
<p>Correlation matrix of the residuals</p>
</td></tr>
<tr><td><code>roots</code></td>
<td>
<p>Roots of characteristic polynomials</p>
</td></tr>
<tr><td><code>is_stable</code></td>
<td>
<p>Whether the process is stable or not based on <code>roots</code></p>
</td></tr>
<tr><td><code>log_lik</code></td>
<td>
<p>log-likelihood</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>Information criteria vector</p>
</td></tr>
</table>

<ul>
<li><p><code>AIC</code> - AIC
</p>
</li>
<li><p><code>BIC</code> - BIC
</p>
</li>
<li><p><code>HQ</code> - HQ
</p>
</li>
<li><p><code>FPE</code> - FPE
</p>
</li></ul>



<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>
<p>Corsi, F. (2008). <em>A Simple Approximate Long-Memory Model of Realized Volatility</em>. Journal of Financial Econometrics, 7(2), 174–196.
</p>
<p>Baek, C. and Park, M. (2021). <em>Sparse vector heterogeneous autoregressive modeling for realized volatility</em>. J. Korean Stat. Soc. 50, 495–510.
</p>

<hr>
<h2 id='ts_forecasting_cv'>Time Series Cross-Validation</h2><span id='topic+ts_forecasting_cv'></span>

<h3>Description</h3>

<p>This page describes the out-of-sample forecasting method in time series scheme.
While the most simple way to compute test error is splitting training-test set,
but popular approach in time series literature is out-of-sample forecasting.
</p>


<h3>Rolling Window Forecasting</h3>

<p>Rolling window forecasting fixes its window size.
The window is used as training set.
This window will be moved to the end as possible as it can be.
</p>
<p>The step should set the same step ahead forecasting at every iteration, saying one-step or h-step.
After fitting the model in the window, researcher should forecast next one-step or h-step ahead.
The longest forecast horizon is <code>(final_period - window_size) - h + 1</code>.
</p>
<p>After this window, move the window one step ahead and do the same process.
Get forecasted values until possible (longest forecast horizon).
</p>


<h3>Expanding Windows</h3>

<p>Expanding window forecasting fixes its starting period.
Rolling window method moves the window with constant size,
but expanding window method just literally expands window the window fixing the starting period.
</p>
<p>The other procedure is the same.
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Athanasopoulos, G. (2021). <em>Forecasting: Principles and practice</em> (3rd ed.). OTEXTS. <a href="https://otexts.com/fpp3/">https://otexts.com/fpp3/</a>
</p>

<hr>
<h2 id='var_design_formulation'>Ordinary Least Squares Model Formulation</h2><span id='topic+var_design_formulation'></span>

<h3>Description</h3>

<p>This page specifies the formulation for ordinary least squares (OLS) that VAR-family model.
Notation and format here will be used in this entire package document.
</p>


<h3>Vector Autoregressive Model</h3>

<p>As mentioned in <code><a href="#topic+var_lm">var_lm()</a></code>, we specify VAR(p) model by
</p>
<p style="text-align: center;"><code class="reqn">Y_t = A_1 Y_{t - 1} + \cdots + A_p Y_{t - p} + c + \epsilon_t</code>
</p>

<p>Consider sample of T size, <code class="reqn">y_1, \ldots, y_n</code>.
Let <code class="reqn">n = T - p</code>.
<code class="reqn">y_1, \ldots, y_T</code> data are rearranged as follows.
</p>
<p style="text-align: center;"><code class="reqn">Y_j = (y_j, y_{j + 1}, \ldots, y_{j + n - 1})^\intercal</code>
</p>

<p>and <code class="reqn">Z_j = (\epsilon_j, \epsilon_{j + 1}, \ldots, \epsilon_{j + n - 1})^\intercal</code>
For ordinary least squares (OLS) estimation,
we define each response matrix and design matrix in multivariate OLS as follows.
First, response matrix:
</p>
<p style="text-align: center;"><code class="reqn">Y_0 = Y_{p + 1}</code>
</p>

<p>Next, design matrix:
</p>
<p style="text-align: center;"><code class="reqn">X_0 = [Y_p, \ldots, Y_1, 1]</code>
</p>

<p>Then we now have OLS model
</p>
<p style="text-align: center;"><code class="reqn">Y_0 = X_0 A + Z_0</code>
</p>

<p>where <code class="reqn">Z_0 = Z_{p + 1}</code>
Here,
</p>
<p style="text-align: center;"><code class="reqn">A = [A_1, A_2, \ldots, A_p, c]^T</code>
</p>

<p>This gives that
</p>
<p style="text-align: center;"><code class="reqn">\hat{A} = (X_0^\intercal X_0)^{-1} X_0^\intercal Y_0</code>
</p>



<h3>Vector Heterogeneous Autoregressive Model</h3>


<ul>
<li><p> VHAR model is linearly restricted VAR(22).
</p>
</li>
<li><p> Let <code class="reqn">Y_0 = X_1 \Phi + Z_0</code> be the OLS formula of VHAR.
</p>
</li>
<li><p> Let <code class="reqn">T_0</code> be 3m x 22m matrix.
</p>
</li></ul>

<p style="text-align: center;"><code class="reqn">
  C_0 = \begin{bmatrix}
  1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\
  1 / 5 &amp; 1 / 5 &amp; 1 / 5 &amp; 1 / 5 &amp; 1 / 5 &amp; 0 &amp; \cdots &amp; 0 \\
  1 / 22 &amp; 1 / 22 &amp; 1 / 22 &amp; 1 / 22 &amp; 1 / 22 &amp; 1 / 22 &amp; \cdots &amp; 1 / 22
\end{bmatrix} \otimes I_m
</code>
</p>

<p>Define (3m + 1) x (22m + 1) matrix <code class="reqn">C_{HAR}</code> by
</p>
<p style="text-align: center;"><code class="reqn">
  C_{HAR} = \begin{bmatrix}
  C_0 &amp; 0_{3m} \\
  0_{3m}^\intercal &amp; 1
\end{bmatrix}
</code>
</p>

<p>Then by construction,
</p>
<p style="text-align: center;"><code class="reqn">Y_0 = X_1 \Phi + Z_0 = (X_0 C_{HAR}^\intercal) \Phi + Z_0</code>
</p>

<p>i.e.
</p>
<p style="text-align: center;"><code class="reqn">X_1 = X_0 C_{HAR}^\intercal</code>
</p>

<p>It follows that
</p>
<p style="text-align: center;"><code class="reqn">\hat\Phi = (X_1^\intercal X_1)^{-1} X_1^\intercal Y_0</code>
</p>



<h3>References</h3>

<p>Baek, C. and Park, M. (2021). <em>Sparse vector heterogeneous autoregressive modeling for realized volatility</em>. J. Korean Stat. Soc. 50, 495–510.
</p>
<p>Bubák, V., Kočenda, E., &amp; Žikeš, F. (2011). <em>Volatility transmission in emerging European foreign exchange markets</em>. Journal of Banking &amp; Finance, 35(11), 2829–2841.
</p>
<p>Corsi, F. (2008). <em>A Simple Approximate Long-Memory Model of Realized Volatility</em>. Journal of Financial Econometrics, 7(2), 174–196.
</p>
<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='var_lm'>Fitting Vector Autoregressive Model of Order p Model</h2><span id='topic+var_lm'></span><span id='topic+print.varlse'></span><span id='topic+knit_print.varlse'></span>

<h3>Description</h3>

<p>This function fits VAR(p) using OLS method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_lm(y, p = 1, include_mean = TRUE, method = c("nor", "chol", "qr"))

## S3 method for class 'varlse'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'varlse'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_lm_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="var_lm_+3A_p">p</code></td>
<td>
<p>Lag of VAR (Default: 1)</p>
</td></tr>
<tr><td><code id="var_lm_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="var_lm_+3A_method">method</code></td>
<td>
<p>Method to solve linear equation system.
(<code>"nor"</code>: normal equation (default), <code>"chol"</code>: Cholesky, and <code>"qr"</code>: HouseholderQR)</p>
</td></tr>
<tr><td><code id="var_lm_+3A_x">x</code></td>
<td>
<p><code>varlse</code> object</p>
</td></tr>
<tr><td><code id="var_lm_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="var_lm_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This package specifies VAR(p) model as
</p>
<p style="text-align: center;"><code class="reqn">Y_{t} = A_1 Y_{t - 1} + \cdots + A_p Y_{t - p} + c + \epsilon_t</code>
</p>

<p>If <code>include_type = TRUE</code>, there is <code class="reqn">c</code> term.
Otherwise (<code>include_type = FALSE</code>), there is no <code class="reqn">c</code> term.
The function estimates every coefficient matrix <code class="reqn">A_1, \ldots, A_p, c</code>.
</p>

<ul>
<li><p> Response matrix, <code class="reqn">Y_0</code> in <a href="#topic+var_design_formulation">var_design_formulation</a>
</p>
</li>
<li><p> Design matrix, <code class="reqn">X_0</code> in <a href="#topic+var_design_formulation">var_design_formulation</a>
</p>
</li>
<li><p> Coefficient matrix is the form of <code class="reqn">A = [A_1, A_2, \ldots, A_p, c]^T</code>.
</p>
</li></ul>

<p>Then perform least squares to the following multivariate regression model
</p>
<p style="text-align: center;"><code class="reqn">Y_0 = X_0 A + error</code>
</p>

<p>which gives
</p>
<p style="text-align: center;"><code class="reqn">\hat{A} = (X_0^T X_0)^{-1} X_0^T Y_0</code>
</p>



<h3>Value</h3>

<p><code>var_lm()</code> returns an object named <code>varlse</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>coefficients</dt><dd><p>Coefficient Matrix</p>
</dd>
<dt>fitted.values</dt><dd><p>Fitted response values</p>
</dd>
<dt>residuals</dt><dd><p>Residuals</p>
</dd>
<dt>covmat</dt><dd><p>LS estimate for covariance matrix</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: mp + 1 or mp</p>
</dd>
<dt>p</dt><dd><p>Lag of VAR</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Process: VAR</p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>

<p>It is also a <code>bvharmod</code> class.
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+coef.varlse">coef.varlse()</a></code>, <code><a href="#topic+residuals.varlse">residuals.varlse()</a></code>, and <code><a href="#topic+fitted.varlse">fitted.varlse()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+summary.varlse">summary.varlse()</a></code> to summarize VAR model
</p>
</li>
<li> <p><code><a href="#topic+predict.varlse">predict.varlse()</a></code> to forecast the VAR process
</p>
</li>
<li> <p><a href="#topic+var_design_formulation">var_design_formulation</a> for the model design
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Perform the function using etf_vix dataset
fit &lt;- var_lm(y = etf_vix, p = 2)
class(fit)
str(fit)

# Extract coef, fitted values, and residuals
coef(fit)
head(residuals(fit))
head(fitted(fit))
</code></pre>

<hr>
<h2 id='var_vec_formulation'>Vectorized OLS Formulation</h2><span id='topic+var_vec_formulation'></span>

<h3>Description</h3>

<p>This page specifies the OLS formulation, which is vectorized of <a href="#topic+var_design_formulation">var_design_formulation</a>.
Notation and format here will be used in this entire package document.
</p>


<h3>Vector Autoregressive Model</h3>

<p>Recall k-dim VAR model <code class="reqn">Y_0 = X_0 A + Z_0</code>.
Applying <code class="reqn">vec</code> operation, we have
</p>
<p style="text-align: center;"><code class="reqn">vec(Y_0) = (I_k \otimes X_0) vec(A) + vec(Z_0)</code>
</p>

<p>Estimating <code class="reqn">\alpha = vec(A)</code> is equivalent to estimating usual OLS.
</p>


<h3>Vector Heterogeneous Autoregressive Model</h3>

<p>Recall k-dim VHAR model </p>
<p style="text-align: center;"><code class="reqn">Y_0 = X_1 \Phi + Z_0 = (X_0 C_{HAR}^\intercal) \Phi + Z_0</code>
</p>
<p>.
Then
</p>
<p style="text-align: center;"><code class="reqn">vec(Y_0) = (I_k \otimes X_0 C_{HAR}^\intercal) vec(\Phi) + vec(Z_0) = (I_k \otimes X_1) vec(\Phi) + vec(Z_0)</code>
</p>



<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='VARtoVMA'>Convert VAR to VMA(infinite)</h2><span id='topic+VARtoVMA'></span>

<h3>Description</h3>

<p>Convert VAR process to infinite vector MA process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VARtoVMA(object, lag_max)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VARtoVMA_+3A_object">object</code></td>
<td>
<p><code>varlse</code> object</p>
</td></tr>
<tr><td><code id="VARtoVMA_+3A_lag_max">lag_max</code></td>
<td>
<p>Maximum lag for VMA</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let VAR(p) be stable.
</p>
<p style="text-align: center;"><code class="reqn">Y_t = c + \sum_{j = 0} W_j Z_{t - j}</code>
</p>

<p>For VAR coefficient <code class="reqn">B_1, B_2, \ldots, B_p</code>,
</p>
<p style="text-align: center;"><code class="reqn">I = (W_0 + W_1 L + W_2 L^2 + \cdots + ) (I - B_1 L - B_2 L^2 - \cdots - B_p L^p)</code>
</p>

<p>Recursively,
</p>
<p style="text-align: center;"><code class="reqn">W_0 = I</code>
</p>

<p style="text-align: center;"><code class="reqn">W_1 = W_0 B_1 (W_1^T = B_1^T W_0^T)</code>
</p>

<p style="text-align: center;"><code class="reqn">W_2 = W_1 B_1 + W_0 B_2 (W_2^T = B_1^T W_1^T + B_2^T W_0^T)</code>
</p>

<p style="text-align: center;"><code class="reqn">W_j = \sum_{j = 1}^k W_{k - j} B_j (W_j^T = \sum_{j = 1}^k B_j^T W_{k - j}^T)</code>
</p>



<h3>Value</h3>

<p>VMA coefficient of k(lag-max + 1) x k dimension
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

<hr>
<h2 id='vhar_lm'>Fitting Vector Heterogeneous Autoregressive Model</h2><span id='topic+vhar_lm'></span><span id='topic+print.vharlse'></span><span id='topic+knit_print.vharlse'></span>

<h3>Description</h3>

<p>This function fits VHAR using OLS method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vhar_lm(
  y,
  har = c(5, 22),
  include_mean = TRUE,
  method = c("nor", "chol", "qr")
)

## S3 method for class 'vharlse'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'vharlse'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vhar_lm_+3A_y">y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td></tr>
<tr><td><code id="vhar_lm_+3A_har">har</code></td>
<td>
<p>Numeric vector for weekly and monthly order. By default, <code>c(5, 22)</code>.</p>
</td></tr>
<tr><td><code id="vhar_lm_+3A_include_mean">include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="vhar_lm_+3A_method">method</code></td>
<td>
<p>Method to solve linear equation system.
(<code>"nor"</code>: normal equation (default), <code>"chol"</code>: Cholesky, and <code>"qr"</code>: HouseholderQR)</p>
</td></tr>
<tr><td><code id="vhar_lm_+3A_x">x</code></td>
<td>
<p><code>vharlse</code> object</p>
</td></tr>
<tr><td><code id="vhar_lm_+3A_digits">digits</code></td>
<td>
<p>digit option to print</p>
</td></tr>
<tr><td><code id="vhar_lm_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For VHAR model
</p>
<p style="text-align: center;"><code class="reqn">Y_{t} = \Phi^{(d)} Y_{t - 1} + \Phi^{(w)} Y_{t - 1}^{(w)} + \Phi^{(m)} Y_{t - 1}^{(m)} + \epsilon_t</code>
</p>

<p>the function gives basic values.
</p>


<h3>Value</h3>

<p><code>vhar_lm()</code> returns an object named <code>vharlse</code> <a href="base.html#topic+class">class</a>.
It is a list with the following components:
</p>

<dl>
<dt>coefficients</dt><dd><p>Coefficient Matrix</p>
</dd>
<dt>fitted.values</dt><dd><p>Fitted response values</p>
</dd>
<dt>residuals</dt><dd><p>Residuals</p>
</dd>
<dt>covmat</dt><dd><p>LS estimate for covariance matrix</p>
</dd>
<dt>df</dt><dd><p>Numer of Coefficients: 3m + 1 or 3m</p>
</dd>
<dt>p</dt><dd><p>3 (The number of terms. <code>vharlse</code> contains this element for usage in other functions.)</p>
</dd>
<dt>week</dt><dd><p>Order for weekly term</p>
</dd>
<dt>month</dt><dd><p>Order for monthly term</p>
</dd>
<dt>m</dt><dd><p>Dimension of the data</p>
</dd>
<dt>obs</dt><dd><p>Sample size used when training = <code>totobs</code> - 22</p>
</dd>
<dt>totobs</dt><dd><p>Total number of the observation</p>
</dd>
<dt>call</dt><dd><p>Matched call</p>
</dd>
<dt>process</dt><dd><p>Process: VHAR</p>
</dd>
<dt>type</dt><dd><p>include constant term (<code>"const"</code>) or not (<code>"none"</code>)</p>
</dd>
<dt>HARtrans</dt><dd><p>VHAR linear transformation matrix: <code class="reqn">C_{HAR}</code></p>
</dd>
<dt>y0</dt><dd><p><code class="reqn">Y_0</code></p>
</dd>
<dt>design</dt><dd><p><code class="reqn">X_0</code></p>
</dd>
<dt>y</dt><dd><p>Raw input</p>
</dd>
</dl>

<p>It is also a <code>bvharmod</code> class.
</p>


<h3>References</h3>

<p>Baek, C. and Park, M. (2021). <em>Sparse vector heterogeneous autoregressive modeling for realized volatility</em>. J. Korean Stat. Soc. 50, 495–510.
</p>
<p>Bubák, V., Kočenda, E., &amp; Žikeš, F. (2011). <em>Volatility transmission in emerging European foreign exchange markets</em>. Journal of Banking &amp; Finance, 35(11), 2829–2841.
</p>
<p>Corsi, F. (2008). <em>A Simple Approximate Long-Memory Model of Realized Volatility</em>. Journal of Financial Econometrics, 7(2), 174–196.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+coef.vharlse">coef.vharlse()</a></code>, <code><a href="#topic+residuals.vharlse">residuals.vharlse()</a></code>, and <code><a href="#topic+fitted.vharlse">fitted.vharlse()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+summary.vharlse">summary.vharlse()</a></code> to summarize VHAR model
</p>
</li>
<li> <p><code><a href="#topic+predict.vharlse">predict.vharlse()</a></code> to forecast the VHAR process
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Perform the function using etf_vix dataset
fit &lt;- vhar_lm(y = etf_vix)
class(fit)
str(fit)

# Extract coef, fitted values, and residuals
coef(fit)
head(residuals(fit))
head(fitted(fit))
</code></pre>

<hr>
<h2 id='VHARtoVMA'>Convert VHAR to VMA(infinite)</h2><span id='topic+VHARtoVMA'></span>

<h3>Description</h3>

<p>Convert VHAR process to infinite vector MA process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VHARtoVMA(object, lag_max)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VHARtoVMA_+3A_object">object</code></td>
<td>
<p><code>vharlse</code> object</p>
</td></tr>
<tr><td><code id="VHARtoVMA_+3A_lag_max">lag_max</code></td>
<td>
<p>Maximum lag for VMA</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let VAR(p) be stable
and let VAR(p) be
<code class="reqn">Y_0 = X_0 B + Z</code>
</p>
<p>VHAR is VAR(22) with
</p>
<p style="text-align: center;"><code class="reqn">Y_0 = X_1 B + Z = ((X_0 \tilde{T}^T)) \Phi + Z</code>
</p>

<p>Observe that
</p>
<p style="text-align: center;"><code class="reqn">B = \tilde{T}^T \Phi</code>
</p>



<h3>Value</h3>

<p>VMA coefficient of k(lag-max + 1) x k dimension
</p>


<h3>References</h3>

<p>Lütkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
