<!DOCTYPE html><html lang="en"><head><title>Help for package EMAR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EMAR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#fitstat'><p>Fit statistics for model assessment</p></a></li>
<li><a href='#valstat'><p>Validation statistics for model assessment</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Empirical Model Assessment</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-10</td>
</tr>
<tr>
<td>Description:</td>
<td>A tool that allows users to generate various indices for evaluating statistical models. The fitstat() function computes indices based on the fitting data. The valstat() function computes indices based on the validation data set. Both fitstat() and valstat() will return 16 indices SSR: residual sum of squares, TRE: total relative error, Bias: mean bias, MRB: mean relative bias, MAB: mean absolute bias, MAPE: mean absolute percentage error, MSE: mean squared	error, RMSE: root mean square error, Percent.RMSE: percentage root mean squared error, R2: coefficient of determination, R2adj: adjusted coefficient of determination, APC: Amemiya's prediction criterion, logL: Log-likelihood, AIC: Akaike information criterion, AICc: corrected Akaike information criterion, BIC: Bayesian information criterion, HQC: Hannan-Quin information criterion. The	lower the better for the SSR, TRE, Bias, MRB, MAB, MAPE, MSE, RMSE, Percent.RMSE, APC, AIC, AICc, BIC and HQC indices. The higher the better for R2 and R2adj indices. Petre Stoica, P., Sel√©n, Y. (2004) &lt;<a href="https://doi.org/10.1109%2FMSP.2004.1311138">doi:10.1109/MSP.2004.1311138</a>&gt;\n Zhou et al. (2023) &lt;<a href="https://doi.org/10.3389%2Ffpls.2023.1186250">doi:10.3389/fpls.2023.1186250</a>&gt;\n Ogana, F.N., Ercanli, I. (2021) &lt;<a href="https://doi.org/10.1007%2Fs11676-021-01373-1">doi:10.1007/s11676-021-01373-1</a>&gt;\n Musabbikhah et al. (2019) &lt;<a href="https://doi.org/10.1088%2F1742-6596%2F1175%2F1%2F012270">doi:10.1088/1742-6596/1175/1/012270</a>&gt;.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-10 10:11:52 UTC; fnogana23</td>
</tr>
<tr>
<td>Author:</td>
<td>Friday Nwabueze Ogana
    <a href="https://orcid.org/0000-0002-8388-204X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Sacramento Corral-Rivas
    <a href="https://orcid.org/0000-0001-7624-0623"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Friday Nwabueze Ogana &lt;ogana_fry@yahoo.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-10 19:33:22 UTC</td>
</tr>
</table>
<hr>
<h2 id='fitstat'>Fit statistics for model assessment</h2><span id='topic+fitstat'></span>

<h3>Description</h3>

<p>This function helps users to generate 16 fit indices for model assessment. Once a model(s) is fitted, users can apply the function <code><a href="#topic+fitstat">fitstat()</a></code> to get the indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitstat(obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitstat_+3A_obj">obj</code></td>
<td>
<p>fitted model of the class lm, nls, gls, gnls, lme, or nlme.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Model.name: fitted model name, p: number of parameters in the fitted model, n: number of observation, SSR: residual sum of squares, TRE: total relative error, Bias: mean bias, MRB: mean relative bias, MAB: mean absolute bias, MAPE: mean absolute percentage error, MSE: mean squared error, RMSE: root mean square error, Percent.RMSE: percentage root mean squared error, R2: coefficient of determination, R2adj: adjusted coefficient of determination, APC: Amemiya's prediction criterion, logL: Log-likelihood, AIC: Akaike information criterion, AICc: corrected Akaike information criterion, BIC: Bayesian information criterion, HQC: Hannan-Quin information criterion.
</p>


<h3>Note</h3>

<p>The lower the better for the SSR, TRE, Bias, MRB, MAB, MAPE, MSE, RMSE, Percent.RMSE, APC, AIC, AICc, BIC and HQC indices. The higher the better for R2 and R2adj indices. Users can choose which indices to use to evaluate their models from the output.
</p>


<h3>Author(s)</h3>

<p>Ogana F.N. and Corral-Rivas S.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+valstat">valstat()</a></code>, which gives the fit indices of the model based on the independent/validation data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(EMAR)

# sample data
Age &lt;- 1:50
Yield &lt;- exp(6.5 - 39.5/Age)
fit_data &lt;- data.frame(Age, Yield)

# fit your model(s)
Eq01 &lt;- lm(Yield ~ Age, data=fit_data)
Eq02 &lt;- nls(Yield ~ b0 * Age ^ b1, data=fit_data, start=list(b0 = 2, b1 = 1))

# Get the fit statistics for the model(s)
fitstat(Eq01)
fitstat(Eq02)

# with the 'rbind' function, Users can generate output for multiple models at once.
indices &lt;- rbind(fitstat(Eq01), fitstat(Eq02))
print(indices)
</code></pre>

<hr>
<h2 id='valstat'>Validation statistics for model assessment</h2><span id='topic+valstat'></span>

<h3>Description</h3>

<p>This function helps users to generate 16 fit indices for model assessment based on independent/validation data set. In addition to empirical models, the function <code><a href="#topic+valstat">valstat()</a></code> can generate fit indices for AI-based models such as artificial neural network, supervise vector machine, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>valstat(obs.y, pred.y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="valstat_+3A_obs.y">obs.y</code></td>
<td>
<p>observed values from the independent/validation data</p>
</td></tr>
<tr><td><code id="valstat_+3A_pred.y">pred.y</code></td>
<td>
<p>predicted values from the model</p>
</td></tr>
<tr><td><code id="valstat_+3A_p">p</code></td>
<td>
<p>number of parameters in the model. This is needed to compute the 'criteria-based indices' and adjusted coefficient of determination. Users could enter any value for AI-based models with an unknown number of parameters (p) and assess their models using the indices that are invariant of p. See the section on note.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n: number of observation in the validation data, SSR: residual sum of squares, TRE: total relative error, Bias: mean bias, MRB: mean relative bias, MAB: mean absolute bias, MAPE: mean absolute percentage error, MSE: mean squared error, RMSE: root mean squared error, Percent.RMSE: percentage root mean squared error, R2: coefficient of determination, R2adj: adjusted coefficient of determination, APC: Amemiya's prediction criterion, logL: Log-likelihood, AIC: Akaike information criterion, AICc: corrected Akaike information criterion, BIC: Bayesian information criterion, HQC: Hannan-Quin information criterion.
</p>


<h3>Note</h3>

<p>The lower the better for the SSR, TRE, Bias, MRB, MAB, MAPE, MSE, RMSE, Percent.RMSE, APC, logL, AIC, AICc, BIC and HQC indices. The higher the better for R2 and R2adj indices. Users can choose which indices to use to evaluate their models from the output. Given the difficulty of determining the number of parameters (p) in AI-based models, users might consider using error-based indices, and coefficients of determination (R2).
</p>


<h3>Author(s)</h3>

<p>Ogana F.N. and Corral-Rivas S.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fitstat">fitstat()</a></code>, which gives the fit indices of the model based on the fitting data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(EMAR)

# fitting data
Age &lt;- 1:50
Yield &lt;- exp(6.5 - 39.5/Age)
dat &lt;- data.frame(Age, Yield)

# fit the model to the fitting data
Eq01 &lt;- lm(Yield ~ Age, data=dat)

# independent/validation data
test_data &lt;- data.frame(Age=1:50, Yield=2.5*Age^1.4)

# predict with the model i.e. Eq01, using the independent/validation data
test_data$pred.Yield &lt;- predict(Eq01, test_data)

# Evaluate the quality of the prediction using the 'valstat' function.
# You need the observed and predicted values. Specify the number of parameters in the model.

valstat(test_data$Yield, test_data$pred.Yield, 2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
