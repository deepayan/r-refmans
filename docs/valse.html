<!DOCTYPE html><html><head><title>Help for package valse</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {valse}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#valse-package'>
<p>Variable Selection with Mixture of Models</p></a></li>
<li><a href='#computeGridLambda'><p>computeGridLambda</p></a></li>
<li><a href='#constructionModelesLassoMLE'><p>constructionModelesLassoMLE</p></a></li>
<li><a href='#constructionModelesLassoRank'><p>constructionModelesLassoRank</p></a></li>
<li><a href='#EMGLLF'><p>EMGLLF</p></a></li>
<li><a href='#EMGrank'><p>EMGrank</p></a></li>
<li><a href='#generateXY'><p>generateXY</p></a></li>
<li><a href='#initSmallEM'><p>initSmallEM</p></a></li>
<li><a href='#plot_valse'><p>Plot</p></a></li>
<li><a href='#runValse'><p>runValse</p></a></li>
<li><a href='#selectVariables'><p>selectVariables</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Variable Selection with Mixture of Models</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-05-16</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1-0</td>
</tr>
<tr>
<td>Description:</td>
<td>Two methods are implemented to cluster data with finite mixture
    regression models. Those procedures deal with high-dimensional covariates and
    responses through a variable selection procedure based on the Lasso estimator.
    A low-rank constraint could be added, computed for the Lasso-Rank procedure.
    A collection of models is constructed, varying the level of sparsity and the
    number of clusters, and a model is selected using a model selection criterion
    (slope heuristic, BIC or AIC). Details of the procedure are provided in
    "Model-based clustering for high-dimensional data. Application to functional data"
    by Emilie Devijver (2016) &lt;<a href="https://doi.org/10.48550/arXiv.1409.1333">doi:10.48550/arXiv.1409.1333</a>&gt;,
    published in Advances in Data Analysis and Clustering.</td>
</tr>
<tr>
<td>Author:</td>
<td>Benjamin Auder &lt;benjamin.auder@universite-paris-saclay.fr&gt; [aut,cre],
    Emilie Devijver &lt;Emilie.Devijver@kuleuven.be&gt; [aut],
    Benjamin Goehry &lt;Benjamin.Goehry@math.u-psud.fr&gt; [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Benjamin Auder &lt;benjamin.auder@universite-paris-saclay.fr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, parallel, cowplot, ggplot2, reshape2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>capushe, roxygen2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://git.auder.net/?p=valse.git">https://git.auder.net/?p=valse.git</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Collate:</td>
<td>'plot_valse.R' 'main.R' 'selectVariables.R'
'constructionModelesLassoRank.R'
'constructionModelesLassoMLE.R' 'computeGridLambda.R'
'initSmallEM.R' 'EMGrank.R' 'EMGLLF.R' 'generateXY.R'
'A_NAMESPACE.R' 'util.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-28 10:43:13 UTC; auder</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-31 08:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='valse-package'>
Variable Selection with Mixture of Models
</h2><span id='topic+valse-package'></span><span id='topic+valse'></span>

<h3>Description</h3>

<p>Two methods are implemented to cluster data with finite mixture
    regression models. Those procedures deal with high-dimensional covariates and
    responses through a variable selection procedure based on the Lasso estimator.
    A low-rank constraint could be added, computed for the Lasso-Rank procedure.
    A collection of models is constructed, varying the level of sparsity and the
    number of clusters, and a model is selected using a model selection criterion
    (slope heuristic, BIC or AIC). Details of the procedure are provided in
    &quot;Model-based clustering for high-dimensional data. Application to functional data&quot;
    by Emilie Devijver (2016) &lt;arXiv:1409.1333v2&gt;,
    published in Advances in Data Analysis and Clustering.
</p>


<h3>Details</h3>

<p>Two methods are implemented to cluster data with finite mixture
regression models. Those procedures deal with high-dimensional covariates and
responses through a variable selection procedure based on the Lasso estimator.
</p>
<p>The main function is runValse(), which calls all other functions.
See also plot_valse() which plots the relevant parameters after a run.
</p>


<h3>Author(s)</h3>

<p>Benjamin Auder &lt;benjamin.auder@universite-paris-saclay.fr&gt; [aut,cre],
    Emilie Devijver &lt;Emilie.Devijver@kuleuven.be&gt; [aut],
    Benjamin Goehry &lt;Benjamin.Goehry@math.u-psud.fr&gt; [ctb]
</p>
<p>Maintainer: Benjamin Auder &lt;benjamin.auder@universite-paris-saclay.fr&gt;
</p>

<hr>
<h2 id='computeGridLambda'>computeGridLambda</h2><span id='topic+computeGridLambda'></span>

<h3>Description</h3>

<p>Construct the data-driven grid for the regularization parameters used for the Lasso estimator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeGridLambda(
  phiInit,
  rhoInit,
  piInit,
  gamInit,
  X,
  Y,
  gamma,
  mini,
  maxi,
  eps,
  fast
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computeGridLambda_+3A_phiinit">phiInit</code></td>
<td>
<p>value for phi</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_rhoinit">rhoInit</code></td>
<td>
<p>for rho</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_piinit">piInit</code></td>
<td>
<p>for pi</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_gaminit">gamInit</code></td>
<td>
<p>value for gamma</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_x">X</code></td>
<td>
<p>matrix of covariates (of size n*p)</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_y">Y</code></td>
<td>
<p>matrix of responses (of size n*m)</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_gamma">gamma</code></td>
<td>
<p>power of weights in the penalty</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_mini">mini</code></td>
<td>
<p>minimum number of iterations in EM algorithm</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_maxi">maxi</code></td>
<td>
<p>maximum number of iterations in EM algorithm</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_eps">eps</code></td>
<td>
<p>threshold to stop EM algorithm</p>
</td></tr>
<tr><td><code id="computeGridLambda_+3A_fast">fast</code></td>
<td>
<p>boolean to enable or not the C function call</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the grid of regularization parameters for the Lasso estimator. The output is a vector with nonnegative values that are relevant
to be considered as regularization parameter as they are equivalent to a 0 in the regression parameter.
</p>

<hr>
<h2 id='constructionModelesLassoMLE'>constructionModelesLassoMLE</h2><span id='topic+constructionModelesLassoMLE'></span>

<h3>Description</h3>

<p>Construct a collection of models with the Lasso-MLE procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constructionModelesLassoMLE(
  phiInit,
  rhoInit,
  piInit,
  gamInit,
  mini,
  maxi,
  gamma,
  X,
  Y,
  eps,
  S,
  ncores,
  fast,
  verbose
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constructionModelesLassoMLE_+3A_phiinit">phiInit</code></td>
<td>
<p>an initialization for phi, get by initSmallEM.R</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_rhoinit">rhoInit</code></td>
<td>
<p>an initialization for rho, get by initSmallEM.R</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_piinit">piInit</code></td>
<td>
<p>an initialization for pi, get by initSmallEM.R</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_gaminit">gamInit</code></td>
<td>
<p>an initialization for gam, get by initSmallEM.R</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_mini">mini</code></td>
<td>
<p>integer, minimum number of iterations in the EM algorithm, by default = 10</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_maxi">maxi</code></td>
<td>
<p>integer, maximum number of iterations in the EM algorithm, by default = 100</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_gamma">gamma</code></td>
<td>
<p>integer for the power in the penaly, by default = 1</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_x">X</code></td>
<td>
<p>matrix of covariates (of size n*p)</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_y">Y</code></td>
<td>
<p>matrix of responses (of size n*m)</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_eps">eps</code></td>
<td>
<p>real, threshold to say the EM algorithm converges, by default = 1e-4</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_s">S</code></td>
<td>
<p>output of selectVariables.R</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores, by default = 3</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_fast">fast</code></td>
<td>
<p>TRUE to use compiled C code, FALSE for R code only</p>
</td></tr>
<tr><td><code id="constructionModelesLassoMLE_+3A_verbose">verbose</code></td>
<td>
<p>TRUE to show some execution traces</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with several models, defined by phi (the regression parameter reparametrized),
rho (the covariance parameter reparametrized), pi (the proportion parameter is the mixture model), llh
(the value of the loglikelihood function for this estimator on the training dataset). The list is given
for several levels of sparsity, given by several regularization parameters computed automatically.
</p>

<hr>
<h2 id='constructionModelesLassoRank'>constructionModelesLassoRank</h2><span id='topic+constructionModelesLassoRank'></span>

<h3>Description</h3>

<p>Construct a collection of models with the Lasso-Rank procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constructionModelesLassoRank(
  S,
  k,
  mini,
  maxi,
  X,
  Y,
  eps,
  rank.min,
  rank.max,
  ncores,
  fast,
  verbose
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constructionModelesLassoRank_+3A_s">S</code></td>
<td>
<p>output of selectVariables.R</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_k">k</code></td>
<td>
<p>number of components</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_mini">mini</code></td>
<td>
<p>integer, minimum number of iterations in the EM algorithm, by default = 10</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_maxi">maxi</code></td>
<td>
<p>integer, maximum number of iterations in the EM algorithm, by default = 100</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_x">X</code></td>
<td>
<p>matrix of covariates (of size n*p)</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_y">Y</code></td>
<td>
<p>matrix of responses (of size n*m)</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_eps">eps</code></td>
<td>
<p>real, threshold to say the EM algorithm converges, by default = 1e-4</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_rank.min">rank.min</code></td>
<td>
<p>integer, minimum rank in the low rank procedure, by default = 1</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_rank.max">rank.max</code></td>
<td>
<p>integer, maximum rank in the low rank procedure, by default = 5</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores, by default = 3</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_fast">fast</code></td>
<td>
<p>TRUE to use compiled C code, FALSE for R code only</p>
</td></tr>
<tr><td><code id="constructionModelesLassoRank_+3A_verbose">verbose</code></td>
<td>
<p>TRUE to show some execution traces</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with several models, defined by phi (the regression parameter reparametrized),
rho (the covariance parameter reparametrized), pi (the proportion parameter is the mixture model), llh
(the value of the loglikelihood function for this estimator on the training dataset). The list is given
for several levels of sparsity, given by several regularization parameters computed automatically,
and several ranks (between rank.min and rank.max).
</p>

<hr>
<h2 id='EMGLLF'>EMGLLF</h2><span id='topic+EMGLLF'></span>

<h3>Description</h3>

<p>Run a generalized EM algorithm developped for mixture of Gaussian regression
models with variable selection by an extension of the Lasso estimator (regularization parameter lambda).
Reparametrization is done to ensure invariance by homothetic transformation.
It returns a collection of models, varying the number of clusters and the sparsity in the regression mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMGLLF(
  phiInit,
  rhoInit,
  piInit,
  gamInit,
  mini,
  maxi,
  gamma,
  lambda,
  X,
  Y,
  eps,
  fast
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EMGLLF_+3A_phiinit">phiInit</code></td>
<td>
<p>an initialization for phi</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_rhoinit">rhoInit</code></td>
<td>
<p>an initialization for rho</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_piinit">piInit</code></td>
<td>
<p>an initialization for pi</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_gaminit">gamInit</code></td>
<td>
<p>initialization for the a posteriori probabilities</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_mini">mini</code></td>
<td>
<p>integer, minimum number of iterations in the EM algorithm, by default = 10</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_maxi">maxi</code></td>
<td>
<p>integer, maximum number of iterations in the EM algorithm, by default = 100</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_gamma">gamma</code></td>
<td>
<p>integer for the power in the penaly, by default = 1</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_lambda">lambda</code></td>
<td>
<p>regularization parameter in the Lasso estimation</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_x">X</code></td>
<td>
<p>matrix of covariates (of size n*p)</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_y">Y</code></td>
<td>
<p>matrix of responses (of size n*m)</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_eps">eps</code></td>
<td>
<p>real, threshold to say the EM algorithm converges, by default = 1e-4</p>
</td></tr>
<tr><td><code id="EMGLLF_+3A_fast">fast</code></td>
<td>
<p>boolean to enable or not the C function call</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (corresponding to the model collection) defined by (phi,rho,pi,llh,S,affec):
phi : regression mean for each cluster, an array of size p*m*k
rho : variance (homothetic) for each cluster, an array of size m*m*k
pi : proportion for each cluster, a vector of size k
llh : log likelihood with respect to the training set
S : selected variables indexes, an array of size p*m*k
affec : cluster affectation for each observation (of the training set)
</p>

<hr>
<h2 id='EMGrank'>EMGrank</h2><span id='topic+EMGrank'></span>

<h3>Description</h3>

<p>Run an generalized EM algorithm developped for mixture of Gaussian regression
models with variable selection by an extension of the low rank estimator.
Reparametrization is done to ensure invariance by homothetic transformation.
It returns a collection of models, varying the number of clusters and the rank of the regression mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMGrank(Pi, Rho, mini, maxi, X, Y, eps, rank, fast)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EMGrank_+3A_pi">Pi</code></td>
<td>
<p>An initialization for pi</p>
</td></tr>
<tr><td><code id="EMGrank_+3A_rho">Rho</code></td>
<td>
<p>An initialization for rho, the variance parameter</p>
</td></tr>
<tr><td><code id="EMGrank_+3A_mini">mini</code></td>
<td>
<p>integer, minimum number of iterations in the EM algorithm, by default = 10</p>
</td></tr>
<tr><td><code id="EMGrank_+3A_maxi">maxi</code></td>
<td>
<p>integer, maximum number of iterations in the EM algorithm, by default = 100</p>
</td></tr>
<tr><td><code id="EMGrank_+3A_x">X</code></td>
<td>
<p>matrix of covariates (of size n*p)</p>
</td></tr>
<tr><td><code id="EMGrank_+3A_y">Y</code></td>
<td>
<p>matrix of responses (of size n*m)</p>
</td></tr>
<tr><td><code id="EMGrank_+3A_eps">eps</code></td>
<td>
<p>real, threshold to say the EM algorithm converges, by default = 1e-4</p>
</td></tr>
<tr><td><code id="EMGrank_+3A_rank">rank</code></td>
<td>
<p>vector of possible ranks</p>
</td></tr>
<tr><td><code id="EMGrank_+3A_fast">fast</code></td>
<td>
<p>boolean to enable or not the C function call</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (corresponding to the model collection) defined by (phi,LLF):
phi : regression mean for each cluster, an array of size p*m*k
LLF : log likelihood with respect to the training set
</p>

<hr>
<h2 id='generateXY'>generateXY</h2><span id='topic+generateXY'></span>

<h3>Description</h3>

<p>Generate a sample of (X,Y) of size n
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateXY(n, prop, meanX, beta, covX, covY)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateXY_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="generateXY_+3A_prop">prop</code></td>
<td>
<p>proportion for each cluster</p>
</td></tr>
<tr><td><code id="generateXY_+3A_meanx">meanX</code></td>
<td>
<p>matrix of group means for covariates (of size p)</p>
</td></tr>
<tr><td><code id="generateXY_+3A_beta">beta</code></td>
<td>
<p>regression matrix, of size p*m*k</p>
</td></tr>
<tr><td><code id="generateXY_+3A_covx">covX</code></td>
<td>
<p>covariance for covariates (of size p*p)</p>
</td></tr>
<tr><td><code id="generateXY_+3A_covy">covY</code></td>
<td>
<p>covariance for the response vector (of size m*m)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with X (of size n*p) and Y (of size n*m)
</p>

<hr>
<h2 id='initSmallEM'>initSmallEM</h2><span id='topic+initSmallEM'></span>

<h3>Description</h3>

<p>initialization of the EM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initSmallEM(k, X, Y, fast)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initSmallEM_+3A_k">k</code></td>
<td>
<p>number of components</p>
</td></tr>
<tr><td><code id="initSmallEM_+3A_x">X</code></td>
<td>
<p>matrix of covariates (of size n*p)</p>
</td></tr>
<tr><td><code id="initSmallEM_+3A_y">Y</code></td>
<td>
<p>matrix of responses (of size n*m)</p>
</td></tr>
<tr><td><code id="initSmallEM_+3A_fast">fast</code></td>
<td>
<p>boolean to enable or not the C function call</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with phiInit (the regression parameter reparametrized),
rhoInit (the covariance parameter reparametrized), piInit (the proportion parameter is the
mixture model), gamInit (the conditional expectation)
</p>

<hr>
<h2 id='plot_valse'>Plot</h2><span id='topic+plot_valse'></span>

<h3>Description</h3>

<p>A function which plots relevant parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_valse(X, Y, model, comp = FALSE, k1 = NA, k2 = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_valse_+3A_x">X</code></td>
<td>
<p>matrix of covariates (of size n*p)</p>
</td></tr>
<tr><td><code id="plot_valse_+3A_y">Y</code></td>
<td>
<p>matrix of responses (of size n*m)</p>
</td></tr>
<tr><td><code id="plot_valse_+3A_model">model</code></td>
<td>
<p>the model constructed by valse procedure</p>
</td></tr>
<tr><td><code id="plot_valse_+3A_comp">comp</code></td>
<td>
<p>TRUE to enable pairwise clusters comparison</p>
</td></tr>
<tr><td><code id="plot_valse_+3A_k1">k1</code></td>
<td>
<p>index of the first cluster to be compared</p>
</td></tr>
<tr><td><code id="plot_valse_+3A_k2">k2</code></td>
<td>
<p>index of the second cluster to be compared</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value (only plotting).
</p>

<hr>
<h2 id='runValse'>runValse</h2><span id='topic+runValse'></span>

<h3>Description</h3>

<p>Main function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runValse(
  X,
  Y,
  procedure = "LassoMLE",
  selecMod = "DDSE",
  gamma = 1,
  mini = 10,
  maxi = 50,
  eps = 1e-04,
  kmin = 2,
  kmax = 3,
  rank.min = 1,
  rank.max = 5,
  ncores_outer = 1,
  ncores_inner = 1,
  thresh = 1e-08,
  grid_lambda = numeric(0),
  size_coll_mod = 50,
  fast = TRUE,
  verbose = FALSE,
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runValse_+3A_x">X</code></td>
<td>
<p>matrix of covariates (of size n*p)</p>
</td></tr>
<tr><td><code id="runValse_+3A_y">Y</code></td>
<td>
<p>matrix of responses (of size n*m)</p>
</td></tr>
<tr><td><code id="runValse_+3A_procedure">procedure</code></td>
<td>
<p>among 'LassoMLE' or 'LassoRank'</p>
</td></tr>
<tr><td><code id="runValse_+3A_selecmod">selecMod</code></td>
<td>
<p>method to select a model among 'DDSE', 'DJump', 'BIC' or 'AIC'</p>
</td></tr>
<tr><td><code id="runValse_+3A_gamma">gamma</code></td>
<td>
<p>integer for the power in the penaly, by default = 1</p>
</td></tr>
<tr><td><code id="runValse_+3A_mini">mini</code></td>
<td>
<p>integer, minimum number of iterations in the EM algorithm, by default = 10</p>
</td></tr>
<tr><td><code id="runValse_+3A_maxi">maxi</code></td>
<td>
<p>integer, maximum number of iterations in the EM algorithm, by default = 100</p>
</td></tr>
<tr><td><code id="runValse_+3A_eps">eps</code></td>
<td>
<p>real, threshold to say the EM algorithm converges, by default = 1e-4</p>
</td></tr>
<tr><td><code id="runValse_+3A_kmin">kmin</code></td>
<td>
<p>integer, minimum number of clusters, by default = 2</p>
</td></tr>
<tr><td><code id="runValse_+3A_kmax">kmax</code></td>
<td>
<p>integer, maximum number of clusters, by default = 10</p>
</td></tr>
<tr><td><code id="runValse_+3A_rank.min">rank.min</code></td>
<td>
<p>integer, minimum rank in the low rank procedure, by default = 1</p>
</td></tr>
<tr><td><code id="runValse_+3A_rank.max">rank.max</code></td>
<td>
<p>integer, maximum rank in the low rank procedure, by default = 5</p>
</td></tr>
<tr><td><code id="runValse_+3A_ncores_outer">ncores_outer</code></td>
<td>
<p>Number of cores for the outer loop on k</p>
</td></tr>
<tr><td><code id="runValse_+3A_ncores_inner">ncores_inner</code></td>
<td>
<p>Number of cores for the inner loop on lambda</p>
</td></tr>
<tr><td><code id="runValse_+3A_thresh">thresh</code></td>
<td>
<p>real, threshold to say a variable is relevant, by default = 1e-8</p>
</td></tr>
<tr><td><code id="runValse_+3A_grid_lambda">grid_lambda</code></td>
<td>
<p>a vector with regularization parameters if known, by default numeric(0)</p>
</td></tr>
<tr><td><code id="runValse_+3A_size_coll_mod">size_coll_mod</code></td>
<td>
<p>(Maximum) size of a collection of models, by default 50</p>
</td></tr>
<tr><td><code id="runValse_+3A_fast">fast</code></td>
<td>
<p>TRUE to use compiled C code, FALSE for R code only</p>
</td></tr>
<tr><td><code id="runValse_+3A_verbose">verbose</code></td>
<td>
<p>TRUE to show some execution traces</p>
</td></tr>
<tr><td><code id="runValse_+3A_plot">plot</code></td>
<td>
<p>TRUE to plot the selected models after run</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The selected model (except if the collection of models
has less than 11 models, the function returns the collection as it can not select one using Capushe)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 50; m = 10; p = 5
beta = array(0, dim=c(p,m,2))
beta[,,1] = 1
beta[,,2] = 2
data = generateXY(n, c(0.4,0.6), rep(0,p), beta, diag(0.5, p), diag(0.5, m))
X = data$X
Y = data$Y
res = runValse(X, Y, kmax = 5, plot=FALSE)
X &lt;- matrix(runif(100), nrow=50)
Y &lt;- matrix(runif(100), nrow=50)
res = runValse(X, Y, plot=FALSE)

</code></pre>

<hr>
<h2 id='selectVariables'>selectVariables</h2><span id='topic+selectVariables'></span>

<h3>Description</h3>

<p>For a given lambda, construct the sets of relevant variables for each cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectVariables(
  phiInit,
  rhoInit,
  piInit,
  gamInit,
  mini,
  maxi,
  gamma,
  glambda,
  X,
  Y,
  thresh = 1e-08,
  eps,
  ncores = 3,
  fast
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectVariables_+3A_phiinit">phiInit</code></td>
<td>
<p>an initial estimator for phi (size: p*m*k)</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_rhoinit">rhoInit</code></td>
<td>
<p>an initial estimator for rho (size: m*m*k)</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_piinit">piInit</code></td>
<td>
<p>an initial estimator for pi (size : k)</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_gaminit">gamInit</code></td>
<td>
<p>an initial estimator for gamma</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_mini">mini</code></td>
<td>
<p>minimum number of iterations in EM algorithm</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_maxi">maxi</code></td>
<td>
<p>maximum number of iterations in EM algorithm</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_gamma">gamma</code></td>
<td>
<p>power in the penalty</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_glambda">glambda</code></td>
<td>
<p>grid of regularization parameters</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_x">X</code></td>
<td>
<p>matrix of regressors</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_y">Y</code></td>
<td>
<p>matrix of responses</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_thresh">thresh</code></td>
<td>
<p>real, threshold to say a variable is relevant, by default = 1e-8</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_eps">eps</code></td>
<td>
<p>threshold to say that EM algorithm has converged</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_ncores">ncores</code></td>
<td>
<p>Number or cores for parallel execution (1 to disable)</p>
</td></tr>
<tr><td><code id="selectVariables_+3A_fast">fast</code></td>
<td>
<p>boolean to enable or not the C function call</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list, varying lambda in a grid, with selected (the indices of variables that are selected),
Rho (the covariance parameter, reparametrized), Pi (the proportion parameter)
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
