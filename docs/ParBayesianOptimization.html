<!DOCTYPE html><html><head><title>Help for package ParBayesianOptimization</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ParBayesianOptimization}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#addIterations'><p>Run Additional Optimization Iterations</p></a></li>
<li><a href='#bayesOpt'><p>Bayesian Optimization with Gaussian Processes</p></a></li>
<li><a href='#changeSaveFile'><p>Change Save File Location</p></a></li>
<li><a href='#getBestPars'><p>Get the Best Parameter Set</p></a></li>
<li><a href='#getLocalOptimums'><p>Get Local Optimums of acq From a bayesOpt Object</p></a></li>
<li><a href='#plot.bayesOpt'><p>Plot a <code>bayesOpt</code> object</p></a></li>
<li><a href='#print.bayesOpt'><p>Print a <code>bayesOpt</code> object</p></a></li>
<li><a href='#updateGP'><p>Update Gaussian Processes in a bayesOpt Object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Parallel Bayesian Optimization of Hyperparameters</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.6</td>
</tr>
<tr>
<td>Description:</td>
<td>Fast, flexible framework for implementing Bayesian optimization of model 
	hyperparameters according to the methods described in Snoek et al. &lt;<a href="https://arxiv.org/abs/1206.2944">arXiv:1206.2944</a>&gt;.
	The package allows the user to run scoring function in parallel, save intermediary 
	results, and tweak other aspects of the process to fully utilize the computing resources
	available to the user.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/AnotherSamWilson/ParBayesianOptimization">https://github.com/AnotherSamWilson/ParBayesianOptimization</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/AnotherSamWilson/ParBayesianOptimization/issues">https://github.com/AnotherSamWilson/ParBayesianOptimization/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table (&ge; 1.11.8), DiceKriging, stats, foreach, dbscan,
lhs, crayon, ggplot2, ggpubr (&ge; 0.2.4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, xgboost, doParallel, testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Samuel Wilson &lt;samwilson303@gmail.com&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-18 14:15:20 UTC; swilson</td>
</tr>
<tr>
<td>Author:</td>
<td>Samuel Wilson [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-18 14:47:54 UTC</td>
</tr>
</table>
<hr>
<h2 id='addIterations'>Run Additional Optimization Iterations</h2><span id='topic+addIterations'></span>

<h3>Description</h3>

<p>Use this function to continue optimization of a bayesOpt object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addIterations(
  optObj,
  iters.n = 1,
  iters.k = 1,
  otherHalting = list(timeLimit = Inf, minUtility = 0),
  bounds = optObj$bounds,
  acq = optObj$optPars$acq,
  kappa = optObj$optPars$kappa,
  eps = optObj$optPars$eps,
  gsPoints = optObj$optPars$gsPoints,
  convThresh = optObj$optPars$convThresh,
  acqThresh = optObj$optPars$acqThresh,
  errorHandling = "stop",
  saveFile = optObj$saveFile,
  parallel = FALSE,
  plotProgress = FALSE,
  verbose = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addIterations_+3A_optobj">optObj</code></td>
<td>
<p>an object of class <code>bayesOpt</code>.</p>
</td></tr>
<tr><td><code id="addIterations_+3A_iters.n">iters.n</code></td>
<td>
<p>The total number of additional times to sample the scoring function.</p>
</td></tr>
<tr><td><code id="addIterations_+3A_iters.k">iters.k</code></td>
<td>
<p>integer that specifies the number of times to sample FUN
at each Epoch (optimization step). If running in parallel, good practice
is to set <code>iters.k</code> to some multiple of the number of cores you have designated
for this process. Must belower than, and preferrably some multiple of <code>iters.n</code>.</p>
</td></tr>
<tr><td><code id="addIterations_+3A_otherhalting">otherHalting</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_bounds">bounds</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_acq">acq</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_kappa">kappa</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_eps">eps</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_gspoints">gsPoints</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_convthresh">convThresh</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_acqthresh">acqThresh</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_errorhandling">errorHandling</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_savefile">saveFile</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_parallel">parallel</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_plotprogress">plotProgress</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_verbose">verbose</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="addIterations_+3A_...">...</code></td>
<td>
<p>Same as <code>bayesOpt()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, this function uses the original parameters used to create
<code>optObj</code>, however the parameters (including the bounds) can be customized.
If new bounds are used which cause some of the prior runs to fall outside of
the bounds, these samples are removed from the optimization procedure, but
will remain in <code>scoreSummary</code>. <code>FUN</code> should return the same elements
and accept the same inputs as the original, or this function may fail.
</p>


<h3>Value</h3>

<p>An object of class <code>bayesOpt</code> having run additional iterations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>scoringFunction &lt;- function(x) {
  a &lt;- exp(-(2-x)^2)*1.5
  b &lt;- exp(-(4-x)^2)*2
  c &lt;- exp(-(6-x)^2)*1
  return(list(Score = a+b+c))
}

bounds &lt;- list(x = c(0,8))

Results &lt;- bayesOpt(
    FUN = scoringFunction
  , bounds = bounds
  , initPoints = 3
  , iters.n = 1
  , gsPoints = 10
)
Results &lt;- addIterations(Results,iters.n=1)
</code></pre>

<hr>
<h2 id='bayesOpt'>Bayesian Optimization with Gaussian Processes</h2><span id='topic+bayesOpt'></span>

<h3>Description</h3>

<p>Maximizes a user defined function within a set of bounds. After the function
is sampled a pre-determined number of times, a Gaussian process is fit to
the results. An acquisition function is then maximized to determine the most
likely location of the global maximum of the user defined function.  This
process is repeated for a set number of iterations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayesOpt(
  FUN,
  bounds,
  saveFile = NULL,
  initGrid,
  initPoints = 4,
  iters.n = 3,
  iters.k = 1,
  otherHalting = list(timeLimit = Inf, minUtility = 0),
  acq = "ucb",
  kappa = 2.576,
  eps = 0,
  parallel = FALSE,
  gsPoints = pmax(100, length(bounds)^3),
  convThresh = 1e+08,
  acqThresh = 1,
  errorHandling = "stop",
  plotProgress = FALSE,
  verbose = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayesOpt_+3A_fun">FUN</code></td>
<td>
<p>the function to be maximized. This function should return a
named list with at least 1 component. The first component must be named
<code>Score</code> and should contain the metric to be maximized. You may
return other named scalar elements that you wish to include in the final
summary table.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_bounds">bounds</code></td>
<td>
<p>named list of lower and upper bounds for each <code>FUN</code> input.
The names of the list should be arguments passed to <code>FUN</code>.
Use &quot;L&quot; suffix to indicate integers.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_savefile">saveFile</code></td>
<td>
<p>character filepath (including file name and extension, .RDS) that
specifies the location to save results as they are obtained. A <code>bayesOpt</code>
object is saved to the file after each epoch.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_initgrid">initGrid</code></td>
<td>
<p>user specified points to sample the scoring function, should
be a <code>data.frame</code> or <code>data.table</code> with identical column names as bounds.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_initpoints">initPoints</code></td>
<td>
<p>Number of points to initialize the process with. Points are
chosen with latin hypercube sampling within the bounds supplied.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_iters.n">iters.n</code></td>
<td>
<p>The total number of times FUN will be run after initialization.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_iters.k">iters.k</code></td>
<td>
<p>integer that specifies the number of times to sample FUN
at each Epoch (optimization step). If running in parallel, good practice
is to set <code>iters.k</code> to some multiple of the number of cores you have designated
for this process. Must be lower than, and preferrably some multiple of <code>iters.n</code>.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_otherhalting">otherHalting</code></td>
<td>
<p>A list of other halting specifications. The process will stop if any of
the following is true. These checks are only performed in between optimization steps:
</p>

<ul>
<li><p> The elapsed seconds is greater than the list element <code>timeLimit</code>.
</p>
</li>
<li><p> The utility expected from the Gaussian process is less than the list element
<code>minUtility</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bayesOpt_+3A_acq">acq</code></td>
<td>
<p>acquisition function type to be used. Can be &quot;ucb&quot;, &quot;ei&quot;, &quot;eips&quot; or &quot;poi&quot;.
</p>

<ul>
<li> <p><code>ucb</code>   Upper Confidence Bound
</p>
</li>
<li> <p><code>ei</code>    Expected Improvement
</p>
</li>
<li> <p><code>eips</code>  Expected Improvement Per Second
</p>
</li>
<li> <p><code>poi</code>   Probability of Improvement
</p>
</li></ul>
</td></tr>
<tr><td><code id="bayesOpt_+3A_kappa">kappa</code></td>
<td>
<p>tunable parameter kappa of the upper confidence bound.
Adjusts exploitation/exploration. Increasing kappa will increase the
importance that uncertainty (unexplored space) has, therefore incentivising
exploration. This number represents the standard deviations above 0 of your upper
confidence bound. Default is 2.56, which corresponds to the ~99th percentile.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_eps">eps</code></td>
<td>
<p>tunable parameter epsilon of ei, eips and poi. Adjusts exploitation/exploration.
This value is added to y_max after the scaling, so should between -0.1 and 0.1.
Increasing eps will make the &quot;improvement&quot; threshold for new points higher, therefore
incentivising exploitation.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_parallel">parallel</code></td>
<td>
<p>should the process run in parallel? If TRUE, several criteria must be met:
</p>

<ul>
<li><p> A parallel backend must be registered
</p>
</li>
<li><p> Objects required by <code>FUN</code> must be loaded into each cluster.
</p>
</li>
<li><p> Packages required by <code>FUN</code> must be loaded into each cluster. See vignettes.
</p>
</li>
<li> <p><code>FUN</code> must be thread safe.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bayesOpt_+3A_gspoints">gsPoints</code></td>
<td>
<p>integer that specifies how many initial points to try when
searching for the optimum of the acquisition function. Increase this for a higher
chance to find global optimum, at the expense of more time.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_convthresh">convThresh</code></td>
<td>
<p>convergence threshold passed to <code>factr</code> when the
<code>optim</code> function (L-BFGS-B) is called. Lower values will take longer
to converge, but may be more accurate.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_acqthresh">acqThresh</code></td>
<td>
<p>number 0-1. Represents the minimum percentage
of the global optimal utility required for a local optimum to
be included as a candidate parameter set in the next scoring function.
If 1.0, only the global optimum will be used as a candidate
parameter set. If 0.5, only local optimums with 50 percent of the utility
of the global optimum will be used.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_errorhandling">errorHandling</code></td>
<td>
<p>If FUN returns an error, how to proceed. All errors are
stored in <code>scoreSummary</code>. Can be one of 3 options: &quot;stop&quot; stops the
function running and returns results. &quot;continue&quot; keeps the process running.
Passing an integer will allow the process to continue until that many errors
have occured, after which the results will be returned.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_plotprogress">plotProgress</code></td>
<td>
<p>Should the progress of the Bayesian optimization be
printed? Top graph shows the score(s) obtained at each iteration.
The bottom graph shows the estimated utility of each point.
This is useful to display how much utility the Gaussian Process is
assuming still exists. If your utility is approaching 0, then you
can be confident you are close to an optimal parameter set.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_verbose">verbose</code></td>
<td>
<p>Whether or not to print progress to the console.
If 0, nothing will be printed. If 1, progress will be printed.
If 2, progress and information about new parameter-score pairs will be printed.</p>
</td></tr>
<tr><td><code id="bayesOpt_+3A_...">...</code></td>
<td>
<p>Other parameters passed to <code>DiceKriging::km()</code>. All FUN inputs and scores
are scaled from 0-1 before being passed to km. FUN inputs are scaled within <code>bounds</code>,
and scores are scaled by 0 = min(scores), 1 = max(scores).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>bayesOpt</code> containing information about the process.
</p>

<ul>
<li> <p><code>FUN</code>          The scoring function.
</p>
</li>
<li> <p><code>bounds</code>       The bounds originally supplied.
</p>
</li>
<li> <p><code>iters</code>        The total iterations that have been run.
</p>
</li>
<li> <p><code>initPars</code>     The initialization parameters.
</p>
</li>
<li> <p><code>optPars</code>      The optimization parameters.
</p>
</li>
<li> <p><code>GauProList</code>   A list containing information on the Gaussian Processes used in optimization.
</p>
</li>
<li> <p><code>scoreSummary</code> A <code>data.table</code> with results from the execution of <code>FUN</code>
at different inputs. Includes information on the epoch, iteration, function inputs, score, and any other
information returned by <code>FUN</code>.
</p>
</li>
<li> <p><code>stopStatus</code>   Information on what caused the function to stop running. Possible explenations are
time limit, minimum utility not met, errors in <code>FUN</code>, iters.n was reached, or the Gaussian Process encountered
an error.
</p>
</li>
<li> <p><code>elapsedTime</code> The total time in seconds the function was executing.
</p>
</li></ul>



<h3>Vignettes</h3>

<p>It is highly recommended to read the <a href="https://github.com/AnotherSamWilson/ParBayesianOptimization">GitHub</a> for examples.
There are also several vignettes available from the official <a href="https://CRAN.R-project.org/package=ParBayesianOptimization">CRAN Listing</a>.
</p>


<h3>References</h3>

<p>Jasper Snoek, Hugo Larochelle, Ryan P. Adams (2012) <em>Practical Bayesian Optimization of Machine Learning Algorithms</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1 - Optimization of a continuous single parameter function
scoringFunction &lt;- function(x) {
  a &lt;- exp(-(2-x)^2)*1.5
  b &lt;- exp(-(4-x)^2)*2
  c &lt;- exp(-(6-x)^2)*1
  return(list(Score = a+b+c))
}

bounds &lt;- list(x = c(0,8))

Results &lt;- bayesOpt(
    FUN = scoringFunction
  , bounds = bounds
  , initPoints = 3
  , iters.n = 2
  , gsPoints = 10
)

## Not run: 
# Example 2 - Hyperparameter Tuning in xgboost
if (requireNamespace('xgboost', quietly = TRUE)) {
  library("xgboost")

  data(agaricus.train, package = "xgboost")

  Folds &lt;- list(
      Fold1 = as.integer(seq(1,nrow(agaricus.train$data),by = 3))
    , Fold2 = as.integer(seq(2,nrow(agaricus.train$data),by = 3))
    , Fold3 = as.integer(seq(3,nrow(agaricus.train$data),by = 3))
  )

  scoringFunction &lt;- function(max_depth, min_child_weight, subsample) {

    dtrain &lt;- xgb.DMatrix(agaricus.train$data,label = agaricus.train$label)

    Pars &lt;- list(
        booster = "gbtree"
      , eta = 0.01
      , max_depth = max_depth
      , min_child_weight = min_child_weight
      , subsample = subsample
      , objective = "binary:logistic"
      , eval_metric = "auc"
    )

    xgbcv &lt;- xgb.cv(
         params = Pars
       , data = dtrain
       , nround = 100
       , folds = Folds
       , prediction = TRUE
       , showsd = TRUE
       , early_stopping_rounds = 5
       , maximize = TRUE
       , verbose = 0
    )

    return(
      list(
          Score = max(xgbcv$evaluation_log$test_auc_mean)
        , nrounds = xgbcv$best_iteration
      )
    )
  }

  bounds &lt;- list(
      max_depth = c(2L, 10L)
    , min_child_weight = c(1, 100)
    , subsample = c(0.25, 1)
  )

  ScoreResult &lt;- bayesOpt(
      FUN = scoringFunction
    , bounds = bounds
    , initPoints = 3
    , iters.n = 2
    , iters.k = 1
    , acq = "ei"
    , gsPoints = 10
    , parallel = FALSE
    , verbose = 1
  )
}

## End(Not run)
</code></pre>

<hr>
<h2 id='changeSaveFile'>Change Save File Location</h2><span id='topic+changeSaveFile'></span>

<h3>Description</h3>

<p>Use this to change the saveFile parameter in a pre-existing bayesOpt object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>changeSaveFile(optObj, saveFile = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="changeSaveFile_+3A_optobj">optObj</code></td>
<td>
<p>An object of class bayesOpt</p>
</td></tr>
<tr><td><code id="changeSaveFile_+3A_savefile">saveFile</code></td>
<td>
<p>A filepath stored as a character. Must include the
filename and extension as a .RDS.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The same <code>optObj</code> with the updated saveFile.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
scoringFunction &lt;- function(x) {
  a &lt;- exp(-(2-x)^2)*1.5
  b &lt;- exp(-(4-x)^2)*2
  c &lt;- exp(-(6-x)^2)*1
  return(list(Score = a+b+c))
}

bounds &lt;- list(x = c(0,8))

Results &lt;- bayesOpt(
    FUN = scoringFunction
  , bounds = bounds
  , initPoints = 3
  , iters.n = 2
  , gsPoints = 10
  , saveFile = "filepath.RDS"
)
Results &lt;- changeSaveFile(Results,saveFile = "DifferentFile.RDS")

## End(Not run)
</code></pre>

<hr>
<h2 id='getBestPars'>Get the Best Parameter Set</h2><span id='topic+getBestPars'></span>

<h3>Description</h3>

<p>Returns the N parameter sets which resulted in the maximum scores from <code>FUN</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBestPars(optObj, N = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBestPars_+3A_optobj">optObj</code></td>
<td>
<p>An object of class <code>bayesOpt</code></p>
</td></tr>
<tr><td><code id="getBestPars_+3A_n">N</code></td>
<td>
<p>The number of parameter sets to return</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the <code>FUN</code> inputs which resulted in the highest returned Score.
If N &gt; 1, a <code>data.table</code> is returned. Each row is a result from <code>FUN</code>, with results ordered by
descending Score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>scoringFunction &lt;- function(x) {
  a &lt;- exp(-(2-x)^2)*1.5
  b &lt;- exp(-(4-x)^2)*2
  c &lt;- exp(-(6-x)^2)*1
  return(list(Score = a+b+c))
}

bounds &lt;- list(x = c(0,8))

Results &lt;- bayesOpt(
    FUN = scoringFunction
  , bounds = bounds
  , initPoints = 3
  , iters.n = 2
  , gsPoints = 10
)
print(getBestPars(Results))
</code></pre>

<hr>
<h2 id='getLocalOptimums'>Get Local Optimums of acq From a bayesOpt Object</h2><span id='topic+getLocalOptimums'></span>

<h3>Description</h3>

<p>Returns all local optimums of the acquisition function, no matter the utility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLocalOptimums(
  optObj,
  bounds = optObj$bounds,
  acq = optObj$optPars$acq,
  kappa = optObj$optPars$kappa,
  eps = optObj$optPars$eps,
  convThresh = optObj$optPars$convThresh,
  gsPoints = optObj$optPars$gsPoints,
  parallel = FALSE,
  verbose = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLocalOptimums_+3A_optobj">optObj</code></td>
<td>
<p>an object of class <code>bayesOpt</code>. The following parameters are all defaulted to
the options provided in this object, but can be manually specified.</p>
</td></tr>
<tr><td><code id="getLocalOptimums_+3A_bounds">bounds</code></td>
<td>
<p>Same as in <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="getLocalOptimums_+3A_acq">acq</code></td>
<td>
<p>Same as in <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="getLocalOptimums_+3A_kappa">kappa</code></td>
<td>
<p>Same as in <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="getLocalOptimums_+3A_eps">eps</code></td>
<td>
<p>Same as in <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="getLocalOptimums_+3A_convthresh">convThresh</code></td>
<td>
<p>Same as in <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="getLocalOptimums_+3A_gspoints">gsPoints</code></td>
<td>
<p>Same as in <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="getLocalOptimums_+3A_parallel">parallel</code></td>
<td>
<p>Same as in <code>bayesOpt()</code></p>
</td></tr>
<tr><td><code id="getLocalOptimums_+3A_verbose">verbose</code></td>
<td>
<p>Should warnings be shown before results are returned prematurely?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gsPoints</code> points in the parameter space are randomly initialized, and
the L-BFGS-B method is used to find the closest local optimum to each point.
dbscan is then used to cluster points together which converged to the same
optimum - only unique optimums are returned.
</p>


<h3>Value</h3>

<p>A data table of local optimums, including the utility (gpUtility), the
utility relative to the max utility (relUtility), and the steps taken in the
L-BFGS-B method (gradCount).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>scoringFunction &lt;- function(x) {
  a &lt;- exp(-(2-x)^2)*1.5
  b &lt;- exp(-(4-x)^2)*2
  c &lt;- exp(-(6-x)^2)*1
  return(list(Score = a+b+c))
}

bounds &lt;- list(x = c(0,8))

Results &lt;- bayesOpt(
    FUN = scoringFunction
  , bounds = bounds
  , initPoints = 3
  , iters.n = 2
  , gsPoints = 10
)
print(getLocalOptimums(Results))
</code></pre>

<hr>
<h2 id='plot.bayesOpt'>Plot a <code>bayesOpt</code> object</h2><span id='topic+plot.bayesOpt'></span>

<h3>Description</h3>

<p>Returns 2 stacked plots - the top shows the results from FUN at each iteration.
The bottom shows the utility from each point before the search took place.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayesOpt'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.bayesOpt_+3A_x">x</code></td>
<td>
<p>An object of class bayesOpt</p>
</td></tr>
<tr><td><code id="plot.bayesOpt_+3A_...">...</code></td>
<td>
<p>Passed to <code>ggarrange()</code> when plots are stacked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>ggarrange</code> from the <code>ggpubr</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>scoringFunction &lt;- function(x) {
  a &lt;- exp(-(2-x)^2)*1.5
  b &lt;- exp(-(4-x)^2)*2
  c &lt;- exp(-(6-x)^2)*1
  return(list(Score = a+b+c))
}

bounds &lt;- list(x = c(0,8))

Results &lt;- bayesOpt(
    FUN = scoringFunction
  , bounds = bounds
  , initPoints = 3
  , iters.n = 2
  , gsPoints = 10
)
# This plot will also show in real time with parameter plotProgress = TRUE in bayesOpt()
plot(Results)
</code></pre>

<hr>
<h2 id='print.bayesOpt'>Print a <code>bayesOpt</code> object</h2><span id='topic+print.bayesOpt'></span>

<h3>Description</h3>

<p>Print a <code>bayesOpt</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayesOpt'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bayesOpt_+3A_x">x</code></td>
<td>
<p>Object of class <code>bayesOpt</code></p>
</td></tr>
<tr><td><code id="print.bayesOpt_+3A_...">...</code></td>
<td>
<p>required to use S3 method</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code>
</p>

<hr>
<h2 id='updateGP'>Update Gaussian Processes in a bayesOpt Object</h2><span id='topic+updateGP'></span>

<h3>Description</h3>

<p>To save time, Gaussian processes are not updated after the last iteration
in <code>addIterations()</code>. The user can do this manually, using this function
if they wish. This is not necessary to continue optimization using <code>addIterations</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updateGP(optObj, bounds = optObj$bounds, verbose = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="updateGP_+3A_optobj">optObj</code></td>
<td>
<p>an object of class bayesOpt</p>
</td></tr>
<tr><td><code id="updateGP_+3A_bounds">bounds</code></td>
<td>
<p>The bounds to scale the parameters within.</p>
</td></tr>
<tr><td><code id="updateGP_+3A_verbose">verbose</code></td>
<td>
<p>Should the user be warned if the GP is already up to date?</p>
</td></tr>
<tr><td><code id="updateGP_+3A_...">...</code></td>
<td>
<p>passed to <code>DiceKriging::km()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>bayesOpt</code> with updated Gaussian processes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create initial object
scoringFunction &lt;- function(x) {
  a &lt;- exp(-(2-x)^2)*1.5
  b &lt;- exp(-(4-x)^2)*2
  c &lt;- exp(-(6-x)^2)*1
  return(list(Score = a+b+c))
}

bounds &lt;- list(x = c(0,8))

Results &lt;- bayesOpt(
    FUN = scoringFunction
  , bounds = bounds
  , initPoints = 3
  , iters.n = 2
  , gsPoints = 10
)

# At this point, the Gaussian Process has not been updated
# with the most recent results. We can update it manually:
Results &lt;- updateGP(Results)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
