<!DOCTYPE html><html><head><title>Help for package ale</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ale}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ale-package'><p>Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)</p></a></li>
<li><a href='#ale'><p>Create and return ALE data, statistics, and plots</p></a></li>
<li><a href='#ale_ixn'><p>Create and return ALE interaction data, statistics, and plots</p></a></li>
<li><a href='#census'><p>Census Income</p></a></li>
<li><a href='#create_p_funs'><p>Create a p-value functions object that can be used to generate p-values</p></a></li>
<li><a href='#model_bootstrap'><p>model_bootstrap.R</p></a></li>
<li><a href='#var_cars'><p>Multi-variable transformation of the mtcars dataset.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Interpretable Machine Learning and Statistical Inference with
Accumulated Local Effects (ALE)</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Accumulated Local Effects (ALE) were initially developed as a model-agnostic approach for global explanations of the results of black-box machine learning algorithms. ALE has a key advantage over other approaches like partial dependency plots (PDP) and SHapley Additive exPlanations (SHAP): its values represent a clean functional decomposition of the model. As such, ALE values are not affected by the presence or absence of interactions among variables in a mode. Moreover, its computation is relatively rapid. This package rewrites the original code from the 'ALEPlot' package for calculating ALE data and it completely reimplements the plotting of ALE values. It also extends the original ALE concept to add bootstrap-based confidence intervals and ALE-based statistics that can be used for statistical inference. For more details, see Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning and Classical Techniques Based on Accumulated Local Effects (ALE).” arXiv. &lt;<a href="https://doi.org/10.48550/arXiv.2310.09877">doi:10.48550/arXiv.2310.09877</a>&gt;. &lt;<a href="https://doi.org/10.48550%2FarXiv.2310.09877">doi:10.48550/arXiv.2310.09877</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-ca</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ALEPlot, knitr, mgcv, patchwork, readr, rmarkdown, testthat
(&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>assertthat, broom, dplyr, ellipsis, furrr, future, ggplot2,
ggpubr, glue, grDevices, insight, labeling, progressr, purrr,
rlang, stats, stringr, tidyr, univariateML, yaImpute</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tripartio/ale">https://github.com/tripartio/ale</a>, <a href="https://tripartio.github.io/ale/">https://tripartio.github.io/ale/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tripartio/ale/issues">https://github.com/tripartio/ale/issues</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-13 17:09:59 UTC; chitu</td>
</tr>
<tr>
<td>Author:</td>
<td>Chitu Okoli <a href="https://orcid.org/0000-0001-5574-7572"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Dan Apley [cph] (The current code for calculating ALE interaction
    values is copied with few changes from Dan Apley's ALEPlot package.
    We gratefully acknowledge his open-source contribution. However, he
    was not directly involved in the development of this ale package.)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Chitu Okoli &lt;Chitu.Okoli@skema.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-14 00:04:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='ale-package'>Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)</h2><span id='topic+ale-package'></span>

<h3>Description</h3>

<p>Accumulated Local Effects (ALE) were initially developed as a model-agnostic
approach for global explanations of the results of black-box machine learning
algorithms. ALE has a key advantage over other approaches like partial
dependency plots (PDP) and SHapley Additive exPlanations (SHAP): its values
represent a clean functional decomposition of the model. As such, ALE values
are not affected by the presence or absence of interactions among variables
in a mode. Moreover, its computation is relatively rapid. This package
rewrites the original code from the <a href="https://CRAN.r-project.org/package=ALEPlot"><code>{ALEPlot}</code> package</a>
for calculating ALE data
and it completely reimplements the plotting of ALE values. It also extends
the original ALE concept to add bootstrap-based confidence intervals and
ALE-based statistics that can be used for statistical inference.
For more details, see Okoli, Chitu. 2023. “Statistical Inference Using
Machine Learning and Classical Techniques Based on Accumulated Local Effects (ALE).”
arXiv. <a href="https://arxiv.org/abs/2310.09877">https://arxiv.org/abs/2310.09877</a>.
</p>


<h3>Author(s)</h3>

<p>Chitu Okoli <a href="mailto:Chitu.Okoli@skema.edu">Chitu.Okoli@skema.edu</a>
</p>


<h3>References</h3>

<p>Okoli, Chitu. 2023.
“Statistical Inference Using Machine Learning and Classical Techniques Based
on Accumulated Local Effects (ALE).” arXiv. <a href="https://arxiv.org/abs/2310.09877">https://arxiv.org/abs/2310.09877</a>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tripartio/ale">https://github.com/tripartio/ale</a>
</p>
</li>
<li> <p><a href="https://tripartio.github.io/ale/">https://tripartio.github.io/ale/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tripartio/ale/issues">https://github.com/tripartio/ale/issues</a>
</p>
</li></ul>


<hr>
<h2 id='ale'>Create and return ALE data, statistics, and plots</h2><span id='topic+ale'></span>

<h3>Description</h3>

<p><code>ale()</code> is the central function that manages the creation of ALE data and plots
for one-way ALE. For two-way interactions, see <code><a href="#topic+ale_ixn">ale_ixn()</a></code>. This function calls
<code>ale_core</code> (a non-exported function) that manages the ALE data and plot creation in detail. For details, see
the introductory vignette for this package or the details and examples below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ale(
  data,
  model,
  x_cols = NULL,
  y_col = NULL,
  ...,
  parallel = parallel::detectCores(logical = FALSE) - 1,
  model_packages = as.character(NA),
  output = c("plots", "data", "stats", "conf_regions"),
  pred_fun = function(object, newdata, type = pred_type) {
     stats::predict(object =
    object, newdata = newdata, type = type)
 },
  pred_type = "response",
  p_values = NULL,
  p_alpha = c(0.01, 0.05),
  x_intervals = 100,
  boot_it = 0,
  seed = 0,
  boot_alpha = 0.05,
  boot_centre = "mean",
  relative_y = "median",
  y_type = NULL,
  median_band_pct = c(0.05, 0.5),
  rug_sample_size = 500,
  min_rug_per_interval = 1,
  ale_xs = NULL,
  ale_ns = NULL,
  compact_plots = FALSE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ale_+3A_data">data</code></td>
<td>
<p>dataframe. Dataset from which to create predictions for the ALE.</p>
</td></tr>
<tr><td><code id="ale_+3A_model">model</code></td>
<td>
<p>model object. Model for which ALE should be calculated.
May be any kind of R object that can make predictions from data.</p>
</td></tr>
<tr><td><code id="ale_+3A_x_cols">x_cols</code></td>
<td>
<p>character. Vector of column names from <code>data</code> for which
one-way ALE data is to be calculated (that is, simple ALE without interactions).
If not provided, ALE will be created for all columns in <code>data</code> except <code>y_col</code>.</p>
</td></tr>
<tr><td><code id="ale_+3A_y_col">y_col</code></td>
<td>
<p>character length 1. Name of the outcome target label (y) variable.
If not provided, <code>ale()</code> will try to detect it automatically. For non-standard
models, <code>y_col</code> should be provided. For survival models, set <code>y_col</code> to the
name of the binary event column; in that case, <code>pred_type</code> should also be specified.</p>
</td></tr>
<tr><td><code id="ale_+3A_...">...</code></td>
<td>
<p>not used. Inserted to require explicit naming of subsequent arguments.</p>
</td></tr>
<tr><td><code id="ale_+3A_parallel">parallel</code></td>
<td>
<p>non-negative integer length 1. Number of parallel threads
(workers or tasks) for parallel execution of the function. See details.</p>
</td></tr>
<tr><td><code id="ale_+3A_model_packages">model_packages</code></td>
<td>
<p>character. Character vector of names of
packages that <code>model</code> depends on that might not be obvious.
The <code>{ale}</code> package should be able to automatically recognize and load most
packages that are needed, but with parallel processing enabled (which is the
default), some packages might not be properly loaded. If you get a strange error
message that mentions something somewhere about 'future', try adding the
package for your model to this vector, especially if you see such errors after
the progress bars begin displaying (assuming you did not disable progress bars
with <code>silent = TRUE</code>).</p>
</td></tr>
<tr><td><code id="ale_+3A_output">output</code></td>
<td>
<p>character in c('plots', 'data', 'stats', 'conf_regions'). Vector of types of results to return.
'plots' will return an ALE plot; 'data' will return the source ALE data;
'stats' will return ALE statistics. Each option must be listed to return the
specified component. By default, all are returned.</p>
</td></tr>
<tr><td><code id="ale_+3A_pred_fun">pred_fun</code>, <code id="ale_+3A_pred_type">pred_type</code></td>
<td>
<p>function,character length 1. <code>pred_fun</code> is a function that
returns a vector of predicted values of type <code>pred_type</code> from <code>model</code> on <code>data</code>.
See details.</p>
</td></tr>
<tr><td><code id="ale_+3A_p_values">p_values</code></td>
<td>
<p>instructions for calculating p-values and to determine the
median band. If <code>NULL</code> (default), no p-values are calculated and
<code>median_band_pct</code> is used to determine the median band.
To calculate p-values, an object generated by the
<code><a href="#topic+create_p_funs">create_p_funs()</a></code> function must be provided here. If <code>p_values</code> is set to 'auto',
this <code>ale()</code> function will try to automatically create the p-values function;
this only works with standard R model types. Any error message will be given
if p-values cannot be generated. Any other input provided to this argument
will result in an error. For more details about creating p-values,
see documentation for <code><a href="#topic+create_p_funs">create_p_funs()</a></code>. Note that p-values will not be
generated if 'stats' are not included as an option in the <code>output</code> argument.</p>
</td></tr>
<tr><td><code id="ale_+3A_p_alpha">p_alpha</code></td>
<td>
<p>numeric length 2 from 0 to 1. Alpha for &quot;confidence interval&quot; ranges
for printing bands around the median for single-variable plots. These are the
default values used if <code>p_values</code> are provided. If <code>p_values</code> are not provided,
then <code>median_band_pct</code> is used instead.
The inner band range will be the median value of y ± <code>p_alpha[2]</code> of the relevant
ALE statistic (usually ALE range or normalized ALE range).
For plots with a second outer band, its range will be the median ± <code>p_alpha[1]</code>.
For example, in the ALE plots, for the default <code>p_alpha = c(0.01, 0.05)</code>,
the inner band will be the median ± ALE minimum or maximum at p = 0.05 and
the outer band will be the median ± ALE minimum or maximum at p = 0.01.</p>
</td></tr>
<tr><td><code id="ale_+3A_x_intervals">x_intervals</code></td>
<td>
<p>positive integer length 1. Maximum number of intervals on the x-axis
for the ALE data for each column in <code>x_cols</code>. The number of intervals that the algorithm generates
might eventually be fewer than what the user specifies if the data values for
a given x value do not support that many intervals.</p>
</td></tr>
<tr><td><code id="ale_+3A_boot_it">boot_it</code></td>
<td>
<p>non-negative integer length 1. Number of bootstrap iterations for the
ALE values. If <code>boot_it = 0</code> (default), then ALE will be calculated on the entire dataset
with no bootstrapping.</p>
</td></tr>
<tr><td><code id="ale_+3A_seed">seed</code></td>
<td>
<p>integer length 1. Random seed. Supply this between runs to assure that
identical random ALE data is generated each time</p>
</td></tr>
<tr><td><code id="ale_+3A_boot_alpha">boot_alpha</code></td>
<td>
<p>numeric length 1 from 0 to 1. Alpha for percentile-based confidence
interval range for the bootstrap intervals; the bootstrap confidence intervals
will be the lowest and highest <code>(1 - 0.05) / 2</code> percentiles. For example,
if <code>boot_alpha = 0.05</code> (default), the intervals will be from the 2.5 and 97.5
percentiles.</p>
</td></tr>
<tr><td><code id="ale_+3A_boot_centre">boot_centre</code></td>
<td>
<p>character length 1 in c('mean', 'median'). When bootstrapping, the
main estimate for <code>ale_y</code> is considered to be <code>boot_centre</code>. Regardless of the
value specified here, both the mean and median will be available.</p>
</td></tr>
<tr><td><code id="ale_+3A_relative_y">relative_y</code></td>
<td>
<p>character length 1 in c('median', 'mean', 'zero'). The ale_y values will
be adjusted relative to this value. 'median' is the default. 'zero' will maintain the
default of <code><a href="ALEPlot.html#topic+ALEPlot">ALEPlot::ALEPlot()</a></code>, which is not shifted.</p>
</td></tr>
<tr><td><code id="ale_+3A_y_type">y_type</code></td>
<td>
<p>character length 1. Datatype of the y (outcome) variable.
Must be one of c('binary', 'numeric', 'multinomial', 'ordinal'). Normally
determined automatically; only provide for complex non-standard models that
require it.</p>
</td></tr>
<tr><td><code id="ale_+3A_median_band_pct">median_band_pct</code></td>
<td>
<p>numeric length 2 from 0 to 1. Alpha for &quot;confidence interval&quot; ranges
for printing bands around the median for single-variable plots. These are the
default values used if <code>p_values</code> are not provided. If <code>p_values</code> are provided,
then <code>median_band_pct</code> is ignored.
The inner band range will be the median value of y ± <code>median_band_pct[1]/2</code>.
For plots with a second outer band, its range will be the median ± <code>median_band_pct[2]/2</code>.
For example, for the default <code>median_band_pct = c(0.05, 0.5)</code>, the inner band
will be the median ± 2.5% and the outer band will be the median ± 25%.</p>
</td></tr>
<tr><td><code id="ale_+3A_rug_sample_size">rug_sample_size</code>, <code id="ale_+3A_min_rug_per_interval">min_rug_per_interval</code></td>
<td>
<p>single non-negative integer length 1.
Rug plots are normally
down-sampled otherwise they are too slow. <code>rug_sample_size</code> specifies the size
of this sample. To prevent down-sampling, set to <code>Inf</code>. To suppress rug plots,
set to 0. When down-sampling, the rug plots maintain representativeness of the
data by guaranteeing that each of the <code>x_intervals</code> intervals will retain at least
<code>min_rug_per_interval</code> elements; usually set to just 1 or 2.</p>
</td></tr>
<tr><td><code id="ale_+3A_ale_xs">ale_xs</code>, <code id="ale_+3A_ale_ns">ale_ns</code></td>
<td>
<p>list of ale_x and ale_n vectors. If provided, these vectors will be used to
set the intervals of the ALE x axis for each variable. By default (NULL), the
function automatically calculates the ale_x intervals. <code>ale_xs</code> is normally used
in advanced analyses where the ale_x intervals from a previous analysis are
reused for subsequent analyses (for example, for full model bootstrapping;
see the <code><a href="#topic+model_bootstrap">model_bootstrap()</a></code> function).</p>
</td></tr>
<tr><td><code id="ale_+3A_compact_plots">compact_plots</code></td>
<td>
<p>logical length 1, default <code>FALSE</code>. When <code>output</code> includes
'plots', the returned <code>ggplot</code> objects each include the environments of the plots.
This lets the user modify the plots with all the flexibility of <code>ggplot</code>, but it
can result in very large return objects (sometimes even hundreds of megabytes
large). To compact the plots to their bare minimum, set <code>compact_plots = TRUE</code>.
However, returned plots will not be easily modifiable, so this should only be
used if you do not want to subsequently modify the plots.</p>
</td></tr>
<tr><td><code id="ale_+3A_silent">silent</code></td>
<td>
<p>logical length 1, default <code>FALSE.</code> If <code>TRUE</code>, do not display any
non-essential messages during execution (such as progress bars).
Regardless, any warnings and errors will always display. See details for how
to enable progress bars.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ale_core.R
</p>
<p>Core functions for the ale package: ale, ale_ixn, and ale_core
</p>


<h3>Value</h3>

<p>list with the following elements:
</p>

<ul>
<li> <p><code>data</code>: a list whose elements, named by each requested x variable, are each
a tibble with the following columns:
</p>

<ul>
<li> <p><code>ale_x</code>: the values of each of the ALE x intervals or categories.
</p>
</li>
<li> <p><code>ale_n</code>: the number of rows of data in each <code>ale_x</code> interval or category.
</p>
</li>
<li> <p><code>ale_y</code>: the ALE function value calculated for that interval or category.
For bootstrapped ALE, this is the same as <code>ale_y_mean</code> by default
or <code>ale_y_median</code> if the <code>boot_centre = 'median'</code> argument is specified.
Regardless, both <code>ale_y_mean</code> and <code>ale_y_median</code> are returned as columns here.
</p>
</li>
<li> <p><code>ale_y_lo</code>, <code>ale_y_hi</code>: the lower and upper confidence intervals, respectively,
for the bootstrapped <code>ale_y</code> value.
Note: regardless what options are requested in the <code>output</code> argument, this
<code>data</code> element is always returned.
</p>
</li></ul>

</li>
<li> <p><code>stats</code>: if <code>stats</code> are requested in the <code>output</code> argument (as is the default),
returns a list. If not requested, returns <code>NULL</code>. The returned list provides
ALE statistics of the <code>data</code> element duplicated and presented from various
perspectives in the following elements:
</p>

<ul>
<li> <p><code>by_term</code>: a list named by each requested x variable, each of whose elements
is a tibble with the following columns:
</p>

<ul>
<li> <p><code>statistic</code>: the ALE statistic specified in the row (see
the <code>by_statistic</code> element below).
</p>
</li>
<li> <p><code>estimate</code>: the bootstrapped <code>mean</code> or <code>median</code> of the <code>statistic</code>,
depending on the <code>boot_centre</code> argument to the <code><a href="#topic+ale">ale()</a></code> function.
Regardless, both <code>mean</code> and <code>median</code> are returned as columns here.
</p>
</li>
<li> <p><code>conf.low</code>, <code>conf.high</code>: the lower and upper confidence intervals,
respectively, for the bootstrapped <code>estimate</code>.
</p>
</li></ul>

</li>
<li> <p><code>by_statistic</code>: list named by each of the following ALE statistics:
<code>aled</code>, <code>aler_min</code>, <code>aler_max</code>, <code>naled</code>, <code>naler_min</code>, <code>naler_max</code>. See
<code>vignette('ale-statistics')</code> for details.
</p>
</li>
<li> <p><code>estimate</code>: a tibble whose data consists of the <code>estimate</code> values from the
<code>by_term</code> element above. The columns are <code>term</code> (the variable name) and the
statistic for which the estimate is given:
<code>aled</code>, <code>aler_min</code>, <code>aler_max</code>, <code>naled</code>, <code>naler_min</code>, <code>naler_max</code>.
</p>
</li>
<li> <p><code>effects_plot</code>: a <code>ggplot</code> object which is the ALE effects plot for all the
x variables.
</p>
</li></ul>

</li>
<li> <p><code>plots</code>: if <code>plots</code> are requested in the <code>output</code> argument (as is the default),
returns a list whose elements, named by each requested x variable, are each
a <code>ggplot</code> object of the ALE y values plotted against the x variable intervals.
If <code>plots</code> is not included in <code>output</code>, this element is <code>NULL</code>.
</p>
</li>
<li> <p><code>conf_regions</code>: if <code>conf_regions</code> are requested in the <code>output</code> argument (as is the default),
returns a list. If not requested, returns <code>NULL</code>. The returned list provides
summaries of the confidence regions of the relevant ALE statistics of the <code>data</code>
element.
The list has the following elements:
</p>

<ul>
<li> <p><code>by_term</code>: a list named by each requested x variable, each of whose elements
is a tibble with the relevant data for the confidence regions.
(See <code>vignette('ale-statistics')</code> for details about confidence regions.)
</p>
</li>
<li> <p><code>significant</code>: a tibble that summarizes the <code>by_term</code> to only show confidence
regions that are statistically significant. Its columns are those from
<code>by_term</code> plus a <code>term</code> column to specify which x variable is indicated
by the respective row.
</p>
</li>
<li> <p><code>sig_criterion</code>: a length-one character vector that reports which values
were used to determine statistical significance: if <code>p_values</code> was
provided to the <code><a href="#topic+ale">ale()</a></code> function, it will be used; otherwise,
<code>median_band_pct</code> will be used.
</p>
</li></ul>

</li>
<li><p> Various values echoed from the original call to the <code><a href="#topic+ale">ale()</a></code> function, provided
to document the key elements used to calculate the ALE data, statistics, and plots:
<code>y_col</code>, <code>x_cols</code>, <code>boot_it</code>, <code>seed</code>, <code>boot_alpha</code>, <code>boot_centre</code>, <code>relative_y</code>,
<code>y_type</code>, <code>median_band_pct</code>, <code>rug_sample_size</code>. These are either the values
provided by the user or used by default if the user did not change them.
</p>
</li>
<li> <p><code>y_summary</code>: summary statistics of y values used for the ALE calculation.
These statistics are based on the actual values of <code>y_col</code> unless if <code>y_type</code> is a
probability or other value that is constrained in the <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> range. In that
case, <code>y_summary</code> is based on the predicted values of <code>y_col</code> by applying
<code>model</code> to the <code>data</code>. <code>y_summary</code> is a named numeric vector. Most of the
elements are the percentile of the y values. E.g., the '5%' element is the
5th percentile of y values. The following elements have special meanings:
</p>

<ul>
<li><p> The first element is named either <code>p</code> or <code>q</code> and its value is always 0.
The value is not used; only the name of the element is meaningful.
<code>p</code> means that the following special <code>y_summary</code> elements are based on
the provided <code>p_values</code> object. <code>q</code> means that quantiles were calculated
based on <code>median_band_pct</code> because <code>p_values</code> was not provided.
</p>
</li>
<li> <p><code>min</code>, <code>mean</code>, <code>max</code>: the minimum, mean, and maximum y values, respectively.
Note that the median is <code style="white-space: pre;">&#8288;50%&#8288;</code>, the 50th percentile.
</p>
</li>
<li> <p><code>med_lo_2</code>, <code>med_lo</code>, <code>med_hi</code>, <code>med_hi_2</code>: <code>med_lo</code> and <code>med_hi</code> are the
inner lower and upper confidence intervals of y values with respect to
the median (<code style="white-space: pre;">&#8288;50%&#8288;</code>); <code>med_lo_2</code> and <code>med_hi_2</code> are the outer confidence
intervals. See the documentation for the <code>p_alpha</code> and <code>median_band_pct</code>
arguments to understand how these are determined.
</p>
</li></ul>

</li></ul>



<h3>Custom predict function</h3>

<p>The calculation of ALE requires modifying several values of the original
<code>data</code>. Thus, <code>ale()</code> needs direct access to a <code>predict</code> function that work on
<code>model</code>. By default, <code>ale()</code> uses a generic default <code>predict</code> function of the form
<code>predict(object, newdata, type)</code> with the default prediction type of 'response'.
If, however, the desired prediction values are not generated with that format,
the user must specify what they want. Most of the time, the only modification needed is
to change the prediction type to some other value by setting the <code>pred_type</code> argument
(e.g., to 'prob' to generated classification probabilities). But if the desired
predictions need a different function signature, then the user must create a
custom prediction function and pass it to <code>pred_fun</code>. The requirements for this
custom function are:
</p>

<ul>
<li><p> It must take three required arguments and nothing else:
</p>

<ul>
<li> <p><code>object</code>: a model
</p>
</li>
<li> <p><code>newdata</code>: a dataframe or compatible table type
</p>
</li>
<li> <p><code>type</code>: a string; it should usually be specified as <code>type = pred_type</code>
These argument names are according to the R convention for the
generic stats::predict function.
</p>
</li></ul>

</li>
<li><p> It must return a vector of numeric values as the prediction.
</p>
</li></ul>

<p>You can see an example below of a custom prediction function.
</p>
<p><strong>Note:</strong> <code>survival</code> models probably do not need a custom prediction function
but <code>y_col</code> must be set to the name of the binary event column and
<code>pred_type</code> must be set to the desired prediction type.
</p>


<h3>ALE statistics</h3>

<p>For details about the ALE-based statistics (ALED, ALER, NALED, and NALER), see
<code>vignette('ale-statistics')</code>.
</p>


<h3>Parallel processing</h3>

<p>Parallel processing using the <code>{furrr}</code> library is enabled by default. By default,
it will use all the available physical
CPU cores (minus the core being used for the current R session) with the setting
<code>parallel = parallel::detectCores(logical = FALSE) - 1</code>. Note that only
physical cores are used (not logical cores or &quot;hyperthreading&quot;) because
machine learning can only take advantage of the floating point processors on
physical cores, which are absent from logical cores. Trying to use logical
cores will not speed up processing and might actually slow it down with useless
data transfer. If you will dedicate
the entire computer to running this function (and you don't mind everything
else becoming very slow while it runs), you may use all cores by setting
<code>parallel = parallel::detectCores(logical = FALSE)</code>. To disable parallel
processing, set <code>parallel = 0</code>.
</p>


<h3>Progress bars</h3>

<p>Progress bars are implemented with the <code>{progressr}</code> package, which lets
the user fully control progress bars. <strong>To disable progress bars, set <code>silent = TRUE</code>.</strong>
The first time a function is called in
the <code>{ale}</code> package that requires progress bars, it checks if the user has
activated the necessary <code>{progressr}</code> settings. If not, the <code>{ale}</code> package
automatically enables <code>{progressr}</code> progress bars with the <code>cli</code> handler and
prints a message notifying the user.
</p>
<p>If you like the default progress bars and you want to make them permanent, then you
can <a href="https://support.posit.co/hc/en-us/articles/360047157094-Managing-R-with-Rprofile-Renviron-Rprofile-site-Renviron-site-rsession-conf-and-repos-conf">add the following lines of code to your .Rprofile configuration file</a>
and they will become your defaults for every R session; you will not see the
message again:
</p>
<div class="sourceCode R"><pre>progressr::handlers(global = TRUE)
progressr::handlers('cli')
</pre></div>
<p>For more details on formatting progress bars to your liking, see the introduction
to the <a href="https://progressr.futureverse.org/articles/progressr-intro.html"><code>{progressr}</code> package</a>.
</p>


<h3>References</h3>

<p>Okoli, Chitu. 2023.
“Statistical Inference Using Machine Learning and Classical Techniques Based
on Accumulated Local Effects (ALE).” arXiv. <a href="https://arxiv.org/abs/2310.09877">https://arxiv.org/abs/2310.09877</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
diamonds_sample &lt;- ggplot2::diamonds[sample(nrow(ggplot2::diamonds), 1000), ]

# Create a GAM model with flexible curves to predict diamond price
# Smooth all numeric variables and include all other variables
gam_diamonds &lt;- mgcv::gam(
  price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +
    cut + color + clarity,
  data = diamonds_sample
)
summary(gam_diamonds)




# Simple ALE without bootstrapping
ale_gam_diamonds &lt;- ale(
  diamonds_sample, gam_diamonds,
  parallel = 2  # CRAN limit (delete this line on your own computer)
)

# Plot the ALE data
ale_gam_diamonds$plots |&gt;
  patchwork::wrap_plots()

# Bootstrapped ALE
# This can be slow, since bootstrapping runs the algorithm boot_it times

# Create ALE with 100 bootstrap samples
ale_gam_diamonds_boot &lt;- ale(
  diamonds_sample, gam_diamonds, boot_it = 100,
  parallel = 2  # CRAN limit (delete this line on your own computer)
)

# Bootstrapped ALEs print with confidence intervals
ale_gam_diamonds_boot$plots |&gt;
  patchwork::wrap_plots()


# If the predict function you want is non-standard, you may define a
# custom predict function. It must return a single numeric vector.
custom_predict &lt;- function(object, newdata, type = pred_type) {
  predict(object, newdata, type = type, se.fit = TRUE)$fit
}

ale_gam_diamonds_custom &lt;- ale(
  diamonds_sample, gam_diamonds,
  pred_fun = custom_predict, pred_type = 'link',
  parallel = 2  # CRAN limit (delete this line on your own computer)
)

# Plot the ALE data
ale_gam_diamonds_custom$plots |&gt;
  patchwork::wrap_plots()




</code></pre>

<hr>
<h2 id='ale_ixn'>Create and return ALE interaction data, statistics, and plots</h2><span id='topic+ale_ixn'></span>

<h3>Description</h3>

<p>This is the central function that manages the creation of ALE data and plots
for two-way ALE interactions. For simple one-way ALE, see <code><a href="#topic+ale">ale()</a></code>.
See documentation there for functionality shared between both functions.
</p>
<p>For details, see the introductory vignette for this package or the details and examples below.
</p>
<p>For the plots, <code>n_y_quant</code> is the number of quantiles into which to
divide the predicted variable (y). The middle quantiles are grouped specially:
</p>

<ul>
<li><p> The middle quantile is the first confidence interval of <code>median_band_pct</code>
(<code>median_band_pct[1]</code>) around the median.
This middle quantile is special because it generally represents no meaningful
interaction.
</p>
</li>
<li><p> The quantiles above and below the middle are extended from the borders of
the middle quantile to the regular borders of the other quantiles.
</p>
</li></ul>

<p>There will always be an odd number of quantiles: the special middle quantile
plus an equal number of quantiles on each side of it. If n_y_quant is even,
then a middle quantile will be added to it. If n_y_quant is odd, then the
number specified will be used, including the middle quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ale_ixn(
  data,
  model,
  x1_cols = NULL,
  x2_cols = NULL,
  y_col = NULL,
  ...,
  parallel = parallel::detectCores(logical = FALSE) - 1,
  model_packages = as.character(NA),
  output = c("plots", "data"),
  pred_fun = function(object, newdata, type = pred_type) {
     stats::predict(object =
    object, newdata = newdata, type = type)
 },
  pred_type = "response",
  x_intervals = 100,
  relative_y = "median",
  y_type = NULL,
  median_band_pct = c(0.05, 0.5),
  rug_sample_size = 500,
  min_rug_per_interval = 1,
  ale_xs = NULL,
  n_x1_int = 20,
  n_x2_int = 20,
  n_y_quant = 10,
  compact_plots = FALSE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ale_ixn_+3A_data">data</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_model">model</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_x1_cols">x1_cols</code>, <code id="ale_ixn_+3A_x2_cols">x2_cols</code></td>
<td>
<p>character. Vectors of column names from <code>data</code> for which
two-way interaction ALE data is to be calculated. ALE data will be calculated
for each x1 column interacting with each x2 column. x1_cols can be of any standard
datatype (logical, factor, or numeric) but x2_cols can only be numeric. If
<code>ixn</code> is TRUE, then both values must be provided.</p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_y_col">y_col</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_...">...</code></td>
<td>
<p>not used. Inserted to require explicit naming of subsequent arguments.</p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_parallel">parallel</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_model_packages">model_packages</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_output">output</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_pred_fun">pred_fun</code>, <code id="ale_ixn_+3A_pred_type">pred_type</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_x_intervals">x_intervals</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_relative_y">relative_y</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_y_type">y_type</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_median_band_pct">median_band_pct</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_rug_sample_size">rug_sample_size</code>, <code id="ale_ixn_+3A_min_rug_per_interval">min_rug_per_interval</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_ale_xs">ale_xs</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_n_x1_int">n_x1_int</code>, <code id="ale_ixn_+3A_n_x2_int">n_x2_int</code></td>
<td>
<p>positive scalar integer. Number of intervals
for the x1 or x2 axes respectively for interaction plot. These values are
ignored if x1 or x2 are not numeric (i.e, if they are logical or factors).</p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_n_y_quant">n_y_quant</code></td>
<td>
<p>positive scalar integer. Number of intervals over which the range
of y values is divided for the colour bands of the interaction plot. See details.</p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_compact_plots">compact_plots</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="ale_ixn_+3A_silent">silent</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of ALE interaction data tibbles and plots.
The list has two levels of depth:
</p>

<ul>
<li><p> The first level is named by the x1 variables.
</p>
</li>
<li><p> Within each x1 variable list, the second level is named by the x2 variables.
</p>
</li>
<li><p> Within each x1-x2 list element, the data or plot is returned as requested in
the <code>output</code> argument.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(0)
diamonds_sample &lt;- ggplot2::diamonds[sample(nrow(ggplot2::diamonds), 1000), ]

# Create a GAM model with flexible curves to predict diamond price
# Smooth all numeric variables and include all other variables
gam_diamonds &lt;- mgcv::gam(
  price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +
    cut + color + clarity,
  data = diamonds_sample
)
summary(gam_diamonds)


# ALE two-way interactions
ale_ixn_gam_diamonds &lt;- ale_ixn(
  diamonds_sample, gam_diamonds,
  parallel = 2  # CRAN limit (delete this line on your own computer)
)

# Print interaction plots
ale_ixn_gam_diamonds$plots |&gt;
  # extract list of x1 ALE outputs
  purrr::walk(\(.x1) {
    # plot all x2 plots in each .x1 element
    patchwork::wrap_plots(.x1) |&gt;
      print()
  })



</code></pre>

<hr>
<h2 id='census'>Census Income</h2><span id='topic+census'></span>

<h3>Description</h3>

<p>Census data that indicates, among other details, if the respondent's income exceeds $50,000 per year. Also known as &quot;Adult&quot; dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>census
</code></pre>


<h3>Format</h3>

<p>A tibble with 32,561 rows and 15 columns:
</p>

<dl>
<dt>higher_income</dt><dd><p>TRUE if income &gt; $50,000</p>
</dd>
<dt>age</dt><dd><p>continuous</p>
</dd>
<dt>workclass</dt><dd><p>Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked</p>
</dd>
<dt>fnlwgt</dt><dd><p>continuous. &quot;A proxy for the demographic background of the people: 'People with similar demographic characteristics should have similar weights'&quot; For more details, see https://www.openml.org/search?type=data&amp;id=1590.</p>
</dd>
<dt>education</dt><dd><p>Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool</p>
</dd>
<dt>education_num</dt><dd><p>continuous</p>
</dd>
<dt>marital_status</dt><dd><p>Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse</p>
</dd>
<dt>occupation</dt><dd><p>Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces</p>
</dd>
<dt>relationship</dt><dd><p>Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried</p>
</dd>
<dt>race</dt><dd><p>White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black</p>
</dd>
<dt>sex</dt><dd><p>Female, Male</p>
</dd>
<dt>capital_gain</dt><dd><p>continuous</p>
</dd>
<dt>capital_loss</dt><dd><p>continuous</p>
</dd>
<dt>hours_per_week</dt><dd><p>continuous</p>
</dd>
<dt>native_country</dt><dd><p>United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinidad&amp;Tobago, Peru, Hong, Holland-Netherlands</p>
</dd>
</dl>

<p>This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.
</p>


<h3>Source</h3>

<p>Becker,Barry and Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository.
https://doi.org/10.24432/C5XW20.
</p>

<hr>
<h2 id='create_p_funs'>Create a p-value functions object that can be used to generate p-values</h2><span id='topic+create_p_funs'></span>

<h3>Description</h3>

<p>Calculating p-values is not trivial for ALE statistics because ALE is
non-parametric and model-agnostic. Because ALE is non-parametric (that is,
it does not assume any particular distribution of data), the <code>ale</code> package
generates p-values by calculating ALE for many random variables; this makes the
procedure somewhat slow. For this reason, they are not calculated by default;
they must be explicitly requested. Because the <code>ale</code> package is model-agnostic (that is, it
works with any kind of R model), the <code><a href="#topic+ale">ale()</a></code> function cannot always automatically
manipulate the model object to create the p-values. It can only do so for
models that follow the standard R statistical modelling conventions, which
includes almost all built-in R algorithms (like <code><a href="stats.html#topic+lm">stats::lm()</a></code> and <code><a href="stats.html#topic+glm">stats::glm()</a></code>) and many widely
used statistics packages (like <code>mgcv</code> and <code>survival</code>), but which excludes most
machine learning algorithms (like <code>tidymodels</code> and <code>caret</code>). For non-standard
algorithms, the user needs to do a little work to help the ale function
correctly manipulate its model object:
</p>

<ul>
<li><p> The full model call must be passed as a character string in the argument
'random_model_call_string', with two slight modifications as follows.
</p>
</li>
<li><p> In the formula that specifies the model, you must add a variable named
'random_variable'. This corresponds to the random variables that <code><a href="#topic+create_p_funs">create_p_funs()</a></code>
will use to estimate p-values.
</p>
</li>
<li><p> The dataset on which the model is trained must be named 'rand_data'. This
corresponds to the modified datasets that will be used to train the random
variables.
</p>
</li></ul>

<p>See the example below for how this is implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_p_funs(
  data,
  model,
  ...,
  parallel = parallel::detectCores(logical = FALSE) - 1,
  model_packages = as.character(NA),
  random_model_call_string = NULL,
  random_model_call_string_vars = character(),
  y_col = NULL,
  pred_fun = function(object, newdata, type = pred_type) {
     stats::predict(object =
    object, newdata = newdata, type = type)
 },
  pred_type = "response",
  rand_it = 1000,
  silent = FALSE,
  .testing_mode = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_p_funs_+3A_data">data</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_model">model</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_...">...</code></td>
<td>
<p>not used. Inserted to require explicit naming of subsequent arguments.</p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_parallel">parallel</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_model_packages">model_packages</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_random_model_call_string">random_model_call_string</code></td>
<td>
<p>character string. If NULL, <code>create_p_funs()</code> tries to
automatically detect and construct the call for p-values. If it cannot, the
function will fail early. In that case, a character string of the full call
for the model must be provided that includes the random variable. See details.</p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_random_model_call_string_vars">random_model_call_string_vars</code></td>
<td>
<p>See documentation for <code>model_call_string_vars</code>
in <code><a href="#topic+model_bootstrap">model_bootstrap()</a></code>; the operation is very similar.</p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_y_col">y_col</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_pred_fun">pred_fun</code>, <code id="create_p_funs_+3A_pred_type">pred_type</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code>.</p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_rand_it">rand_it</code></td>
<td>
<p>non-negative integer length 1. Number of times that the model
should be retrained with a new random variable. The default of 1000 should
give reasonably stable p-values. It can be reduced as low as 100 for faster
test runs.</p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_silent">silent</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="create_p_funs_+3A_.testing_mode">.testing_mode</code></td>
<td>
<p>logical. Internal use only.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The return value is a list of class <code style="white-space: pre;">&#8288;c('p_funs', 'ale', 'list'&#8288;</code>) with an
<code>ale_version</code> attribute whose value is the version of the <code>ale</code> package used to
create the object. See examples for an illustration of how to inspect this list.
Its elements are:
</p>

<ul>
<li> <p><code>value_to_p</code>: a list of functions named for each each available ALE statistic.
Each function signature is <code style="white-space: pre;">&#8288;function(x)&#8288;</code> where x is a numeric. The function returns
the p-value (minimum 0; maximum 1) for the respective statistic based on the random variable analysis.
For an input x that returns p, its interpretation is that p% of random variables
obtained the same or higher statistic value. For example, to get the p-value
of a NALED of 4.2, enter <code>p_funs$value_to_p(4.2)</code>. A return value of 0.03 means
that only 3% of random variables obtained a NALED greater than or equal to 4.2.
</p>
</li>
<li> <p><code>p_to_random_value</code>: a list of functions named for each each available ALE statistic.
These are the inverse functions of <code>value_to_p</code>. The signature is <code style="white-space: pre;">&#8288;function(p)&#8288;</code>
where p is a numeric from 0 to 1. The function returns the numeric value of the
random variable statistic that would yield the provided p-value.
For an input p that returns x, its interpretation is that p% of random variables
obtained the same or higher statistic value. For example, to get the random
variable ALED for the 0.05 p-value, enter <code>p_funs$p_to_random_value(0.05)</code>.
A return value of 102 means that only 5% of random variables obtained an ALED
greater than or equal to 102.
</p>
</li>
<li> <p><code>rand_stats</code>: a tibble whose rows are each of the <code>rand_it</code> iterations of the
random variable analysis and whose columns are the ALE statistics obtained for
each random variable.
</p>
</li>
<li> <p><code>residuals</code>: the actual <code>y_col</code> values from <code>data</code> minus the predicted
values from the <code>model</code> (without random variables) on the <code>data</code>.
<code>residual_distribution</code>: the closest estimated distribution for the <code>residuals</code>
as determined by <code><a href="univariateML.html#topic+MaximumLikelihoodDistribution">univariateML::rml()</a></code>. This is the distribution used to generate
all the random variables.
</p>
</li></ul>



<h3>Approach to calculating p-values</h3>

<p>The <code>ale</code> package takes a literal frequentist approach to the calculation of
p-values. That is, it literally retrains the model 1000 times, each time
modifying it by adding a distinct random variable to the model.
(The number of iterations is customizable
with the <code>rand_it</code> argument.) The ALEs and ALE statistics are calculated for
each random variable. The percentiles of the distribution of these
random-variable ALEs are then used to determine p-values for non-random variables.
Thus, p-values are interpreted as the frequency of random variable ALE statistics
that exceed the value of ALE statistic of the actual variable in question.
The specific steps are as follows:
</p>

<ul>
<li><p> The residuals of the original model trained on the training data are calculated
(residuals are the actual y target value minus the predicted values).
</p>
</li>
<li><p> The closest distribution of the residuals is detected with
<code>univariateML::model_select()</code>.
</p>
</li>
<li><p> 1000 new models are trained by generating a random variable each time with
<code>univariateML::rml()</code> and then training a new model with that random variable
added.
</p>
</li>
<li><p> The ALEs and ALE statistics are calculated for each random variable.
</p>
</li>
<li><p> For each ALE statistic, the empirical cumulative distribution function
(from <code>stats::ecdf()</code>) is used to create a function to determine p-values
according to the distribution of the random variables' ALE statistics.
</p>
</li></ul>



<h3>References</h3>

<p>Okoli, Chitu. 2023.
“Statistical Inference Using Machine Learning and Classical Techniques Based
on Accumulated Local Effects (ALE).” arXiv. <a href="https://arxiv.org/abs/2310.09877">https://arxiv.org/abs/2310.09877</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Sample 1000 rows from the ggplot2::diamonds dataset (for a simple example)
set.seed(0)
diamonds_sample &lt;- ggplot2::diamonds[sample(nrow(ggplot2::diamonds), 1000), ]

# Create a GAM model with flexible curves to predict diamond price
# Smooth all numeric variables and include all other variables
gam_diamonds &lt;- mgcv::gam(
  price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +
    cut + color + clarity,
  data = diamonds_sample
)
summary(gam_diamonds)

# Create p-value functions
pf_diamonds &lt;- create_p_funs(
  diamonds_sample,
  gam_diamonds,
  # only 100 iterations for a quick demo; but usually should remain at 1000
  rand_it = 100,
)

# Examine the structure of the returned object
str(pf_diamonds)
# In RStudio: View(pf_diamonds)

# Calculate ALEs with p-values
ale_gam_diamonds &lt;- ale(
  diamonds_sample,
  gam_diamonds,
  p_values = pf_diamonds
)

# Plot the ALE data. The horizontal bands in the plots use the p-values.
ale_gam_diamonds$plots |&gt;
  patchwork::wrap_plots()


# For non-standard models that give errors with the default settings,
# you can use 'random_model_call_string' to specify a model for the estimation
# of p-values from random variables as in this example.
# See details above for an explanation.
pf_diamonds &lt;- create_p_funs(
  diamonds_sample,
  gam_diamonds,
  random_model_call_string = 'mgcv::gam(
    price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +
        cut + color + clarity + random_variable,
    data = rand_data
  )',
  # only 100 iterations for a quick demo; but usually should remain at 1000
  rand_it = 100,
)




</code></pre>

<hr>
<h2 id='model_bootstrap'>model_bootstrap.R</h2><span id='topic+model_bootstrap'></span>

<h3>Description</h3>

<p>Execute full model bootstrapping with ALE calculation on each bootstrap run
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_bootstrap(
  data,
  model,
  ...,
  model_call_string = NULL,
  model_call_string_vars = character(),
  parallel = parallel::detectCores(logical = FALSE) - 1,
  model_packages = as.character(NA),
  boot_it = 100,
  seed = 0,
  boot_alpha = 0.05,
  boot_centre = "mean",
  output = c("ale", "model_stats", "model_coefs"),
  ale_options = list(),
  tidy_options = list(),
  glance_options = list(),
  compact_plots = FALSE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_bootstrap_+3A_data">data</code></td>
<td>
<p>dataframe. Dataset that will be bootstrapped.</p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_model">model</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_...">...</code></td>
<td>
<p>not used. Inserted to require explicit naming of subsequent arguments.</p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_model_call_string">model_call_string</code></td>
<td>
<p>character string. If NULL, <code><a href="#topic+model_bootstrap">model_bootstrap()</a></code> tries to
automatically detect and construct the call for bootstrapped datasets. If it cannot, the
function will fail early. In that case, a character string of the full call
for the model must be provided that includes <code>boot_data</code> as the data argument for the call.
See examples.</p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_model_call_string_vars">model_call_string_vars</code></td>
<td>
<p>character. Character vector of names of variables
included in <code>model_call_string</code> that are not columns in <code>data</code>.
If any such variables exist, they must be specified here or else parallel processing
will produce an error. If parallelization is disabled with <code>parallel = 0</code>,
then this is not a concern.</p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_parallel">parallel</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_model_packages">model_packages</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_boot_it">boot_it</code></td>
<td>
<p>integer from 0 to Inf. Number of bootstrap iterations.
If boot_it = 0, then the model is run as normal once on the full <code>data</code> with
no bootstrapping.</p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_seed">seed</code></td>
<td>
<p>integer. Random seed. Supply this between runs to assure identical
bootstrap samples are generated each time on the same data.</p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_boot_alpha">boot_alpha</code></td>
<td>
<p>numeric. The confidence level for the bootstrap confidence intervals is
1 - boot_alpha. For example, the default 0.05 will give a 95% confidence
interval, that is, from the 2.5% to the 97.5% percentile.</p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_boot_centre">boot_centre</code></td>
<td>
<p>See See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_output">output</code></td>
<td>
<p>character vector. Which types of bootstraps to calculate and return:
</p>

<ul>
<li><p> 'ale': Calculate and return bootstrapped ALE data and plot.
</p>
</li>
<li><p> 'model_stats': Calculate and return bootstrapped overall model statistics.
</p>
</li>
<li><p> 'model_coefs': Calculate and return bootstrapped model coefficients.
</p>
</li>
<li><p> 'boot_data': Return full data for all bootstrap iterations. This data will always be calculated
because it is needed for the bootstrap averages. By default, it is not returned
except if included in this <code>output</code> argument.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_ale_options">ale_options</code>, <code id="model_bootstrap_+3A_tidy_options">tidy_options</code>, <code id="model_bootstrap_+3A_glance_options">glance_options</code></td>
<td>
<p>list of named arguments.
Arguments to pass to the <code><a href="#topic+ale">ale()</a></code>, <code><a href="broom.html#topic+reexports">broom::tidy()</a></code>, or <code><a href="broom.html#topic+reexports">broom::glance()</a></code> functions, respectively,
beyond (or overriding) the defaults. In particular, to obtain p-values for ALE
statistics, see the details.</p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_compact_plots">compact_plots</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
<tr><td><code id="model_bootstrap_+3A_silent">silent</code></td>
<td>
<p>See documentation for <code><a href="#topic+ale">ale()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>No modelling results, with or without ALE, should be considered reliable without
being bootstrapped. For large datasets, normally the model provided to <code><a href="#topic+ale">ale()</a></code>
is the final deployment model that has been validated and evaluated on
training and testing on subsets; that is why <code><a href="#topic+ale">ale()</a></code> is calculated on the full
dataset. However, when a dataset is too small to be subdivided into training
and test sets for a standard machine learning process, then the entire model
should be bootstrapped. That is, multiple models should be trained, one on
each bootstrap sample. The reliable results are the average results of all
the bootstrap models, however many there are. For details, see the vignette
on small datasets or the details and examples below.
</p>
<p><code><a href="#topic+model_bootstrap">model_bootstrap()</a></code> automatically carries out full-model bootstrapping suitable
for small datasets. Specifically, it:
</p>

<ul>
<li><p> Creates multiple bootstrap samples (default 100; the user can specify any number);
</p>
</li>
<li><p> Creates a model on each bootstrap sample;
</p>
</li>
<li><p> Calculates model overall statistics, variable coefficients, and ALE values
for each model on each bootstrap sample;
</p>
</li>
<li><p> Calculates the mean, median, and lower and upper confidence intervals for
each of those values across all bootstrap samples.
</p>
</li></ul>

<p><strong>P-values</strong>
The <code><a href="broom.html#topic+reexports">broom::tidy()</a></code> summary statistics will provide p-values as normal, but the
situation is somewhat complicated with p-values for ALE statistics. The challenge
is that the procedure for obtaining their p-values is very slow: it involves
retraining the model 1000 times. Thus, it is not efficient to calculate p-values
on every execution of <code>model_bootstrap()</code>. Although the <code><a href="#topic+ale">ale()</a></code> function provides
an 'auto' option for creating p-values,
that option is disabled in <code>model_bootstrap()</code> because it would be far too slow:
it would involve retraining the model 1000 times the number of bootstrap iterations.
Rather, you must first create a p-values function object using the procedure
described in <code>help(create_p_funs)</code>. If the name of your p-values object is
<code>p_funs</code>, you can then request p-values each time you run <code>model_bootstrap()</code>
by passing it the argument <code>ale_options = list(p_values = p_funs)</code>.
</p>


<h3>Value</h3>

<p>list with tibbles of the following elements (depending on values requested in
the <code>output</code> argument:
</p>

<ul>
<li><p> model_stats: bootstrapped results from <code><a href="broom.html#topic+reexports">broom::glance()</a></code>
</p>
</li>
<li><p> model_coefs: bootstrapped results from <code><a href="broom.html#topic+reexports">broom::tidy()</a></code>
</p>
</li>
<li><p> ale: bootstrapped ALE results
</p>

<ul>
<li><p> data: ALE data (see <code><a href="#topic+ale">ale()</a></code> for details about the format)
</p>
</li>
<li><p> stats: ALE statistics. The same data is duplicated with different views
that might be variously useful. The column
</p>

<ul>
<li><p> by_term: statistic, estimate, conf.low, median, mean, conf.high.
(&quot;term&quot; means variable name.)
The column names are compatible with the <code>broom</code> package. The confidence intervals
are based on the <code><a href="#topic+ale">ale()</a></code> function defaults; they can be changed with the
<code>ale_options</code> argument. The estimate is the median or the mean, depending
on the <code>boot_centre</code> argument.
</p>
</li>
<li><p> by_statistic: term, estimate, conf.low, median, mean, conf.high.
</p>
</li>
<li><p> estimate: term, then one column per statistic Provided with the default
estimate. This view does not present confidence intervals.
</p>
</li></ul>

</li>
<li><p> plots: ALE plots (see <code><a href="#topic+ale">ale()</a></code> for details about the format)
</p>
</li></ul>

</li>
<li><p> boot_data: full bootstrap data (not returned by default)
</p>
</li>
<li><p> other values: the <code>boot_it</code>, <code>seed</code>, <code>boot_alpha</code>, and <code>boot_centre</code> arguments that
were originally passed are returned for reference.
</p>
</li></ul>



<h3>References</h3>

<p>Okoli, Chitu. 2023.
“Statistical Inference Using Machine Learning and Classical Techniques Based
on Accumulated Local Effects (ALE).” arXiv. <a href="https://arxiv.org/abs/2310.09877">https://arxiv.org/abs/2310.09877</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# attitude dataset
attitude

## ALE for general additive models (GAM)
## GAM is tweaked to work on the small dataset.
gam_attitude &lt;- mgcv::gam(rating ~ complaints + privileges + s(learning) +
                            raises + s(critical) + advance,
                          data = attitude)
summary(gam_attitude)


# Full model bootstrapping
# Only 4 bootstrap iterations for a rapid example; default is 100
# Increase value of boot_it for more realistic results
mb_gam &lt;- model_bootstrap(
  attitude,
  gam_attitude,
  boot_it = 4,
  parallel = 2  # CRAN limit (delete this line on your own computer)
)

# If the model is not standard, supply model_call_string with
# 'data = boot_data' in the string (not as a direct argument to [model_bootstrap()])
mb_gam &lt;- model_bootstrap(
  attitude,
  gam_attitude,
  model_call_string = 'mgcv::gam(
    rating ~ complaints + privileges + s(learning) +
      raises + s(critical) + advance,
    data = boot_data
  )',
  boot_it = 4,
  parallel = 2  # CRAN limit (delete this line on your own computer)
)

# Model statistics and coefficients
mb_gam$model_stats
mb_gam$model_coefs

# Plot ALE
mb_gam$ale$plots |&gt;
  patchwork::wrap_plots()





</code></pre>

<hr>
<h2 id='var_cars'>Multi-variable transformation of the mtcars dataset.</h2><span id='topic+var_cars'></span>

<h3>Description</h3>

<p>This is a transformation of the <code>mtcars</code> dataset from R to produce a small
dataset with each of the fundamental datatypes: logical, factor, ordered,
integer, and double. Most of the transformations are obvious, but two are
noteworthy:
</p>

<ul>
<li><p> For the unordered factor, the country of the car manufacturer is obtained
based on the row names of <code>mtcars</code>. This <code>var_cars</code> version does not have row names.
</p>
</li>
<li><p> For the ordered factor, gears 3, 4, and 5 are encoded as 'three', 'four',
and 'five', respectively. The text labels make it explicit that the variable
is ordinal, yet the number names make the order crystal clear.
</p>
</li></ul>

<p>Here is the original description of the <code>mtcars</code> dataset:
</p>
<p>The data was extracted from the 1974 <em>Motor Trend</em> US magazine, and comprises
fuel consumption and 10 aspects of automobile design and performance for 32
automobiles (1973&ndash;74 models).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_cars
</code></pre>


<h3>Format</h3>

<p>A tibble with 32 observations on 12 variables.
</p>

<dl>
<dt>mpg</dt><dd><p><code>double</code>: Miles/(US) gallon</p>
</dd>
<dt>cyl</dt><dd><p><code>integer</code>: Number of cylinders</p>
</dd>
<dt>disp</dt><dd><p><code>double</code>: Displacement (cu.in.)</p>
</dd>
<dt>hp</dt><dd><p><code>double</code>: Gross horsepower</p>
</dd>
<dt>drat</dt><dd><p><code>double</code>: Rear axle ratio</p>
</dd>
<dt>wt</dt><dd><p><code>double</code>: Weight (1000 lbs)</p>
</dd>
<dt>qsec</dt><dd><p><code>double</code>: 1/4 mile time</p>
</dd>
<dt>vs</dt><dd><p><code>logical</code>: Engine (0 = V-shaped, 1 = straight)</p>
</dd>
<dt>am</dt><dd><p><code>logical</code>: Transmission (0 = automatic, 1 = manual)</p>
</dd>
<dt>gear</dt><dd><p><code>ordered</code>: Number of forward gears</p>
</dd>
<dt>carb</dt><dd><p><code>integer</code>: Number of carburetors</p>
</dd>
<dt>country</dt><dd><p><code>factor</code>: Country of car manufacturer</p>
</dd>
</dl>



<h3>Note</h3>

<p>Henderson and Velleman (1981) comment in a footnote to Table 1: 'Hocking (original transcriber)'s
noncrucial coding of the Mazda's rotary engine as a straight six-cylinder engine and the Porsche's
flat engine as a V engine, as well as the inclusion of the diesel Mercedes 240D, have been retained
to enable direct comparisons to be made with previous analyses.'
</p>


<h3>References</h3>

<p>Henderson and Velleman (1981), Building multiple regression models interactively.
<em>Biometrics</em>, <strong>37</strong>, 391&ndash;411.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
