<!DOCTYPE html><html><head><title>Help for package statConfR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {statConfR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#fitConf'><p>Fit a static confidence model to data</p></a></li>
<li><a href='#fitConfModels'><p>Fit several static confidence models to multiple participants</p></a></li>
<li><a href='#fitMetaDprime'><p>Fits meta-d' and meta-d'/d' ratios for data from one or several subjects</p></a></li>
<li><a href='#MaskOri'><p>Data of 36 participants in a masked orientation discrimination experiment</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Models of Decision Confidence and Metacognition</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-11</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Manuel Rausch &lt;manuel.rausch@hochschule-rhein-waal.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides fitting functions and other tools for decision confidence 
    and metacognition researchers, including meta-d´/d´, often considered to be 
    the gold standard to measure metacognitive efficiency.
    Also allows to fit several static models of decision making and confidence 
    to test the assumptions underlying meta-d´/d´ and which may serve as an 
    alternative when the assumptions of meta-d´/d´ do not hold. See also Rausch 
    et al. (2023) &lt;<a href="https://doi.org/10.31234%2Fosf.io%2Fkdz34">doi:10.31234/osf.io/kdz34</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ManuelRausch/StatConfR">https://github.com/ManuelRausch/StatConfR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ManuelRausch/StatConfR">https://github.com/ManuelRausch/StatConfR</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>parallel</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-22 15:50:02 UTC</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-21 19:21:29 UTC; MRU</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Author:</td>
<td>Manuel Rausch <a href="https://orcid.org/0000-0002-5805-5544"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Sebastian Hellmann
    <a href="https://orcid.org/0000-0002-3621-6343"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
</table>
<hr>
<h2 id='fitConf'>Fit a static confidence model to data</h2><span id='topic+fitConf'></span>

<h3>Description</h3>

<p>This function fits one static model of decision confidence to empirical data.
It calls a corresponding fitting function for the selected model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitConf(data, model, nInits = 5, nRestart = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitConf_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> where each row is one trial, containing following
variables:
</p>

<ul>
<li> <p><code>condition</code> (optional; different levels of discriminability,
should be a factor with levels ordered from hardest to easiest),
</p>
</li>
<li> <p><code>rating</code> (discrete confidence judgments, should be given as factor;
otherwise will be transformed to factor with a warning),
</p>
</li>
<li> <p><code>stimulus</code> (stimulus category in a binary choice task,
should be a factor with two levels, otherwise it will be transformed to
a factor with a warning),
</p>
</li>
<li> <p><code>correct</code> (encoding whether the response was correct; should  be 0 for incorrect responses and 1 for correct responses)
</p>
</li></ul>
</td></tr>
<tr><td><code id="fitConf_+3A_model">model</code></td>
<td>
<p><code>character</code> of length 1.
Models implemented so far: 'WEV', 'SDT', 'Noisy', 'PDA', 'IG', 'ITGc' and 'ITGcm'
Alternatively, if <code>model="all"</code> (default), all implemented models will be fit.</p>
</td></tr>
<tr><td><code id="fitConf_+3A_ninits">nInits</code></td>
<td>
<p><code>integer</code>. Number of initial values used for maximum likelihood optimization.
Defaults to 5.</p>
</td></tr>
<tr><td><code id="fitConf_+3A_nrestart">nRestart</code></td>
<td>
<p><code>integer</code>. Number of times the optimization is restarted.
Defaults to 4.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fitting routine first performs a coarse grid search to find promising
starting values for the maximum likelihood optimization procedure. Then the best <code>nInits</code>
parameter sets found by the grid search are used as the initial values for separate
runs of the Nelder-Mead algorithm implemented in <code><a href="stats.html#topic+optim">optim</a></code>.
Each run is restarted <code>nRestart</code> times.
</p>


<h4>Mathematical description of models</h4>

<p>The computational models are all based on signal detection theory. It is assumed
that participants select a binary discrimination response <code class="reqn">R</code> about a stimulus <code class="reqn">S</code>.
Both <code class="reqn">S</code> and <code class="reqn">R</code> can be either -1 or 1 (although the function outputs
use A and B to refer to the two stimulus categories when it is convenient).
<code class="reqn">R</code> is considered correct if <code class="reqn">S=R</code>.
In addition, we assume that there are <code class="reqn">K</code> different levels of stimulus discriminability
in the experiment, i.e. a physical variable that makes the task easier or harder.
For each level of discriminability, the function fits a different discrimination
sensitivity parameter <code class="reqn">d_k</code>. The models assume that the stimulus
generates normally distributed sensory evidence <code class="reqn">x</code> with mean <code class="reqn">S\times d_k/2</code>
and variance of 1. The sensory evidence <code class="reqn">x</code> is compared to a decision
threshold <code class="reqn">\theta</code> to generate a discrimination response
<code class="reqn">R</code>, which is 1, if <code class="reqn">x</code> exceeds <code class="reqn">\theta</code> and -1 else.
To generate confidence, it is assumed that the confidence variable <code class="reqn">y</code> is compared to another
set of thresholds <code class="reqn">c_{D,i}, D=A, B,  i=1,...,L-1</code>, depending on the
discrimination decision <code class="reqn">D</code> to produce a <code class="reqn">L</code>-step discrete confidence response.
The number of thresholds will be inferred from the number of steps in the
<code>rating</code> column of <code>data</code>.
The parameters shared between all models are therefore:
</p>

<ul>
<li><p> sensitivity parameters <code class="reqn">d_1</code>,...,<code class="reqn">d_K</code> (<code class="reqn">K</code>: number of difficulty levels)
</p>
</li>
<li><p> decision threshold <code class="reqn">\theta</code>
</p>
</li>
<li><p> confidence threshold <code class="reqn">c_{A,1}</code>,...<code class="reqn">c_{A,L-1}</code>,<code class="reqn">c_{B,1}</code>,...
<code class="reqn">c_{B,L-1}</code> (<code class="reqn">L</code>: number of steps for confidence ratings)
</p>
</li></ul>

<p>How the confidence variable <code class="reqn">y</code> is computed varies across the different models.
The following models have been implemented so far:
</p>


<h5><strong>Signal Detection Rating Model (SDT)</strong></h5>

<p>According to the signal detection rating model (Green &amp; Swets, 1966), the same sample of sensory
evidence is used to generate response and confidence, i.e.,
<code class="reqn">y=x</code> and the confidence thresholds span from the left and
right side of the decision threshold <code class="reqn">\theta</code>.
</p>



<h5><strong>Gaussian Noise Model (Noisy)</strong></h5>

<p>According to the Gaussian noise model (Maniscalco &amp; Lau, 2016), <code class="reqn">y</code> is subject to
additive noise and assumed to be normally distributed around the decision
evidence value <code class="reqn">x</code> with some standard deviation <code class="reqn">\sigma</code>.
<code class="reqn">\sigma</code> is an additional free parameter.
</p>



<h5><strong>Weighted Evidence and Visibility model (WEV)</strong></h5>

<p>WEV assumes that the observer combines evidence about decision-relevant features
of the stimulus with the strength of evidence about choice-irrelevant features
to generate confidence (Rausch et al., 2018). Thus, the WEV model assumes that <code class="reqn">y</code> is normally
distributed with a mean of <code class="reqn">(1-w)\times x+w \times d_k\times R</code> and standard deviation <code class="reqn">\sigma</code>.
The standard deviation quantifies the amount of unsystematic variability
contributing to confidence judgments but not to the discrimination judgments.
The parameter <code class="reqn">w</code> represents the weight that is put on the choice-irrelevant
features in the confidence judgment. <code class="reqn">w</code> and <code class="reqn">\sigma</code> are fitted in
addition to the common parameters.
</p>



<h5><strong>Post-decisional accumulation model (PDA)</strong></h5>

<p>PDA represents the idea of on-going information accumulation after the
discrimination choice (Rausch et al., 2018). The parameter <code class="reqn">a</code> indicates the amount of additional
accumulation. The confidence variable is normally distributed with mean
<code class="reqn">x+S\times d_k\times a</code> and variance <code class="reqn">a</code>.
For this model the parameter <code class="reqn">a</code> is fitted in addition to the common
parameters.
</p>



<h5><strong>Independent Gaussian Model (IG)</strong></h5>

<p>According to the Independent Gaussian Model, <code class="reqn">y</code> is sampled independently
from <code class="reqn">x</code> (Rausch &amp; Zehetleitner, 2017). It is normally distributed with a mean of <code class="reqn">a\times d_k</code> and variance
of 1 (again as it would scale with <code class="reqn">a</code>). The additional parameter <code class="reqn">a</code>
represents the amount of information available for confidence judgment
relative to amount of evidence available for the discrimination decision and
can be smaller as well as greater than 1.
</p>



<h5><strong>Independent Truncated Gaussian Model - Version Fleming (ITGc)</strong></h5>

<p>According to the version of the Independent Truncated Gaussian Models consistent
with the HMetad-method (Fleming, 2017; see Rausch et al., 2023), <code class="reqn">y</code> is sampled independently
from <code class="reqn">x</code> from a truncated Gaussian distribution with a location parameter
of <code class="reqn">S\times d_k \times m/2</code> and a scale parameter of 1. The Gaussian distribution of <code class="reqn">y</code>
is truncated in a way that it is impossible to sample evidence that contradicts
the original decision: If <code class="reqn">R = -1</code>, the distribution is truncated to the
right of <code class="reqn">\theta</code>. If <code class="reqn">R = 1</code>, the distribution is truncated to the left
of <code class="reqn">\theta</code>. The additional parameter <code class="reqn">m</code> represents metacognitive efficiency,
i.e., the amount of information available for confidence judgments relative to
amount of evidence available for discrimination decisions and  can be smaller
as well as greater than 1.
</p>



<h5><strong>Independent Truncated Gaussian Model - Version Maniscalco and Lau (ITGcm)</strong></h5>

<p>According to the version of the Independent Truncated Gaussian Models consistent
with the original meta-d' method (Maniscalco &amp; Lau, 2012, see Rausch et al., 2023),
<code class="reqn">y</code> is sampled independently
from <code class="reqn">x</code> from a truncated Gaussian distribution with a location parameter
of <code class="reqn">S\times d_k \times m/2</code> and a scale parameter
of 1. If <code class="reqn">R = -1</code>, the distribution is truncated to the right of <code class="reqn">m\times\theta</code>.
If <code class="reqn">R = 1</code>, the distribution is truncated to the left of  <code class="reqn">m\times\theta</code>.
The additional parameter <code class="reqn">m</code> represents metacognitive efficiency, i.e.,
the amount of information available for confidence judgments relative to
amount of evidence available for the discrimination decision and  can be smaller
as well as greater than 1.
</p>




<h3>Value</h3>

<p>Gives data frame with one row and columns for the fitted parameters of the
selected model as well as additional information about the fit
(<code>negLogLik</code> (negative log-likelihood of the final set of parameters),
<code>k</code> (number of parameters), <code>N</code> (number of data rows), <code>BIC</code>, <code>AICc</code> and <code>AIC</code>)
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann, <a href="mailto:sebastian.hellmann@ku.de">sebastian.hellmann@ku.de</a>
</p>
<p>Manuel Rausch, <a href="mailto:manuel.rausch@hochschule-rhein-waal.de">manuel.rausch@hochschule-rhein-waal.de</a>
</p>


<h3>References</h3>

<p>Fleming, S. M. (2017). HMeta-d: Hierarchical Bayesian estimation of metacognitive efficiency from confidence ratings. Neuroscience of Consciousness, 1, 1–14. doi: 10.1093/nc/nix007
</p>
<p>Green, D. M., &amp; Swets, J. A. (1966). Signal detection theory and psychophysics. Wiley.
</p>
<p>Maniscalco, B., &amp; Lau, H. (2016). The signal processing architecture underlying subjective reports of sensory awareness. Neuroscience of Consciousness, 1, 1–17. doi: 10.1093/nc/niw002
</p>
<p>Rausch, M., Hellmann, S., &amp; Zehetleitner, M. (2018). Confidence in masked orientation judgments is informed by both evidence and visibility. Attention, Perception, and Psychophysics, 80(1), 134–154. doi: 10.3758/s13414-017-1431-5
</p>
<p>Rausch, M., Hellmann, S., &amp; Zehetleitner, M. (2023). Measures of metacognitive efficiency across cognitive models of decision confidence (Preprint). PsyArXiv. doi: 10.31234/osf.io/kdz34
</p>
<p>Rausch, M., &amp; Zehetleitner, M. (2017). Should metacognition be measured by logistic regression? Consciousness and Cognition, 49, 291–312. doi: 10.1016/j.concog.2017.02.007
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Select one subject from the masked orientation discrimination experiment
data &lt;- subset(MaskOri, participant == 1)
head(data)

# 2. Use fitting function

  # Fitting takes some time to run:
  FitFirstSbjSDT &lt;- fitConf(data, model=c("SDT"))



</code></pre>

<hr>
<h2 id='fitConfModels'>Fit several static confidence models to multiple participants</h2><span id='topic+fitConfModels'></span>

<h3>Description</h3>

<p>This function is a wrapper of the function <code><a href="#topic+fitConf">fitConf</a></code> (see
there for more information). It calls the function for every possible combination
of model in the <code>model</code> argument and participant in the <code>data</code>, respectively.
See the Details for more information about the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitConfModels(data, models = "all", nInits = 5, nRestart = 4,
  .parallel = FALSE, n.cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitConfModels_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> where each row is one trial, containing following
variables:
</p>

<ul>
<li> <p><code>condition</code> (optional; different levels of discriminability,
should be a factor with levels ordered from hardest to easiest),
</p>
</li>
<li> <p><code>rating</code> (discrete confidence judgments, should be given as factor;
otherwise will be transformed to factor with a warning),
</p>
</li>
<li> <p><code>stimulus</code> (stimulus category in a binary choice task,
should be a factor with two levels, otherwise it will be transformed to
a factor with a warning),
</p>
</li>
<li> <p><code>correct</code> (encoding whether the response was correct; should  be 0 for incorrect responses and 1 for correct responses)
</p>
</li>
<li> <p><code>participant</code> (giving the subject ID; the models given in the second argument are fitted for each
subject individually.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fitConfModels_+3A_models">models</code></td>
<td>
<p><code>character</code> vector of models to be fit for each participant.
Models implemented so far: 'WEV', 'SDT', 'Noisy', 'PDA', 'IG', 'ITGc' and 'ITGcm'
Alternatively, if <code>model="all"</code> (default), all implemented models will be fit.</p>
</td></tr>
<tr><td><code id="fitConfModels_+3A_ninits">nInits</code></td>
<td>
<p><code>integer</code>. Number of initial values used for maximum likelihood optimization.
Defaults to 5.</p>
</td></tr>
<tr><td><code id="fitConfModels_+3A_nrestart">nRestart</code></td>
<td>
<p><code>integer</code>. Number of times the optimization is restarted.
Defaults to 4.</p>
</td></tr>
<tr><td><code id="fitConfModels_+3A_.parallel">.parallel</code></td>
<td>
<p><code>logical</code>. Whether to parallelize the fitting over models and participant
(default: FALSE)</p>
</td></tr>
<tr><td><code id="fitConfModels_+3A_n.cores">n.cores</code></td>
<td>
<p><code>integer</code>. Number of cores used for parallelization. If NULL (default), the available
number of cores -1 will be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fitting routine first performs a coarse grid search to find promising
starting values for the maximum likelihood optimization procedure. Then the best <code>nInits</code>
parameter sets found by the grid search are used as the initial values for separate
runs of the Nelder-Mead algorithm implemented in <code><a href="stats.html#topic+optim">optim</a></code>.
Each run is restarted <code>nRestart</code> times.
</p>


<h4>Mathematical description of models</h4>

<p>This section contains a detailed mathematical description of all models
implemented in the package.
</p>
<p>The computational models are all based on signal detection theory. Assume that
there are <code class="reqn">k</code> different levels of difficulty manipulated in the
(and the levels are given by the <code>condition</code> column in the <code>data</code>) and that
the <code>stimulus</code> column indicated the identity of the true stimulus <code class="reqn">S</code>
being either -1 or 1. Then, for each level of difficulty , a value for the
sensitivity <code class="reqn">d_k</code> is fit. The models assume that the stimulus
generates normally distributed sensory evidence <code class="reqn">x</code> with mean <code class="reqn">Sd_k/2</code>
and variance <code class="reqn">\sigma_k</code> (see below). The sensory evidence <code class="reqn">x</code>
is compared to a decision threshold <code class="reqn">\theta</code> to generate a choice response
<code class="reqn">R</code>, which is 1, if <code class="reqn">x</code> exceeds <code class="reqn">\theta</code> and -1 else. (In the
output of the functions this will be A and B respectively.)
To generate confidence, the confidence variable <code class="reqn">y</code> is compared to another
set of thresholds <code class="reqn">c_{D,i}, D=A, B,  i=1,...,L-1</code>, depending on the
initial choice <code class="reqn">D</code> to produce a <code class="reqn">L</code>-step discrete confidence response.
The number of thresholds will be inferred by the number of steps in the
<code>rating</code> column of <code>data</code>.
The parameters common to all models are thus:
</p>

<ul>
<li><p> sensitivity parameters <code class="reqn">d_1</code>,...,<code class="reqn">d_k</code> (<code class="reqn">k</code>: number of difficulty levels)
</p>
</li>
<li><p> choice threshold <code class="reqn">\theta</code>
</p>
</li>
<li><p> confidence threshold <code class="reqn">c_{A,1}</code>,...<code class="reqn">c_{A,L-1}</code>,<code class="reqn">c_{B,1}</code>,...
<code class="reqn">c_{B,L-1}</code> (<code class="reqn">L</code>: number of steps for confidence ratings)
</p>
</li></ul>

<p>How the confidence variable <code class="reqn">y</code> is computed varies across the different models.
The following models have been implemented so far:
</p>


<h5><strong>Signal Detection Rating Model (SDT)</strong></h5>

<p>According to the signal detection rating model (Green &amp; Swets, 1966), the same sample of sensory
evidence is used to generate response and confidence, i.e.,
<code class="reqn">y=x</code> and the confidence thresholds span from the left and
right side of the decision threshold <code class="reqn">\theta</code>.
</p>



<h5><strong>Gaussian Noise Model (Noisy)</strong></h5>

<p>According to the Gaussian noise model (Maniscalco &amp; Lau, 2016), <code class="reqn">y</code> is subject to
additive noise and assumed to be normally distributed around the decision
evidence value <code class="reqn">x</code> with some standard deviation <code class="reqn">\sigma</code>.
<code class="reqn">\sigma</code> is an additional free parameter.
</p>



<h5><strong>Weighted Evidence and Visibility model (WEV)</strong></h5>

<p>WEV assumes that the observer combines evidence about decision-relevant features
of the stimulus with the strength of evidence about choice-irrelevant features
to generate confidence (Rausch et al., 2018). Thus, the WEV model assumes that <code class="reqn">y</code> is normally
distributed with a mean of <code class="reqn">(1-w)\times x+w \times d_k\times R</code> and standard deviation <code class="reqn">\sigma</code>.
The standard deviation quantifies the amount of unsystematic variability
contributing to confidence judgments but not to the discrimination judgments.
The parameter <code class="reqn">w</code> represents the weight that is put on the choice-irrelevant
features in the confidence judgment. <code class="reqn">w</code> and <code class="reqn">\sigma</code> are fitted in
addition to the common parameters.
</p>



<h5><strong>Post-decisional accumulation model (PDA)</strong></h5>

<p>PDA represents the idea of on-going information accumulation after the
discrimination choice (Rausch et al., 2018). The parameter <code class="reqn">a</code> indicates the amount of additional
accumulation. The confidence variable is normally distributed with mean
<code class="reqn">x+S\times d_k\times a</code> and variance <code class="reqn">a</code>.
For this model the parameter <code class="reqn">a</code> is fitted in addition to the common
parameters.
</p>



<h5><strong>Independent Gaussian Model (IG)</strong></h5>

<p>According to the Independent Gaussian Model, <code class="reqn">y</code> is sampled independently
from <code class="reqn">x</code> (Rausch &amp; Zehetleitner, 2017). It is normally distributed with a mean of <code class="reqn">a\times d_k</code> and variance
of 1 (again as it would scale with <code class="reqn">a</code>). The additional parameter <code class="reqn">a</code>
represents the amount of information available for confidence judgment
relative to amount of evidence available for the discrimination decision and
can be smaller as well as greater than 1.
</p>



<h5><strong>Independent Truncated Gaussian Model - Version Fleming (ITGc)</strong></h5>

<p>According to the version of the Independent Truncated Gaussian Models consistent
with the HMetad-method (Fleming, 2017; see Rausch et al., 2023), <code class="reqn">y</code> is sampled independently
from <code class="reqn">x</code> from a truncated Gaussian distribution with a location parameter
of <code class="reqn">S\times d_k \times m/2</code> and a scale parameter of 1. The Gaussian distribution of <code class="reqn">y</code>
is truncated in a way that it is impossible to sample evidence that contradicts
the original decision: If <code class="reqn">R = -1</code>, the distribution is truncated to the
right of <code class="reqn">\theta</code>. If <code class="reqn">R = 1</code>, the distribution is truncated to the left
of <code class="reqn">\theta</code>. The additional parameter <code class="reqn">m</code> represents metacognitive efficiency,
i.e., the amount of information available for confidence judgments relative to
amount of evidence available for discrimination decisions and  can be smaller
as well as greater than 1.
</p>



<h5><strong>Independent Truncated Gaussian Model - Version Maniscalco and Lau (ITGcm)</strong></h5>

<p>According to the version of the Independent Truncated Gaussian Models consistent
with the original meta-d' method (Maniscalco &amp; Lau, 2012, see Rausch et al., 2023),
<code class="reqn">y</code> is sampled independently
from <code class="reqn">x</code> from a truncated Gaussian distribution with a location parameter
of <code class="reqn">S\times d_k \times m/2</code> and a scale parameter
of 1. If <code class="reqn">R = -1</code>, the distribution is truncated to the right of <code class="reqn">m\times\theta</code>.
If <code class="reqn">R = 1</code>, the distribution is truncated to the left of  <code class="reqn">m\times\theta</code>.
The additional parameter <code class="reqn">m</code> represents metacognitive efficiency, i.e.,
the amount of information available for confidence judgments relative to
amount of evidence available for the discrimination decision and  can be smaller
as well as greater than 1.
</p>




<h3>Value</h3>

<p>Gives data frame with rows for each model-participant combination and columns for the different parameters
as fitted result as well as additional information about the fit (<code>negLogLik</code> (for final parameters),
<code>k</code> (number of parameters), <code>N</code> (number of data rows), <code>BIC</code>, <code>AICc</code> and <code>AIC</code>)
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann, <a href="mailto:sebastian.hellmann@ku.de">sebastian.hellmann@ku.de</a>
</p>
<p>Manuel Rausch, <a href="mailto:manuel.rausch@hochschule-rhein-waal.de">manuel.rausch@hochschule-rhein-waal.de</a>
</p>


<h3>References</h3>

<p>Fleming, S. M. (2017). HMeta-d: Hierarchical Bayesian estimation of metacognitive efficiency from confidence ratings. Neuroscience of Consciousness, 1, 1–14. doi: 10.1093/nc/nix007
</p>
<p>Green, D. M., &amp; Swets, J. A. (1966). Signal detection theory and psychophysics. Wiley.
</p>
<p>Maniscalco, B., &amp; Lau, H. (2016). The signal processing architecture underlying subjective reports of sensory awareness. Neuroscience of Consciousness, 1, 1–17. doi: 10.1093/nc/niw002
</p>
<p>Rausch, M., Hellmann, S., &amp; Zehetleitner, M. (2018). Confidence in masked orientation judgments is informed by both evidence and visibility. Attention, Perception, and Psychophysics, 80(1), 134–154. doi: 10.3758/s13414-017-1431-5
</p>
<p>Rausch, M., Hellmann, S., &amp; Zehetleitner, M. (2023). Measures of metacognitive efficiency across cognitive models of decision confidence. PsyArXiv. doi: 10.31234/osf.io/kdz34
</p>
<p>Rausch, M., &amp; Zehetleitner, M. (2017). Should metacognition be measured by logistic regression? Consciousness and Cognition, 49, 291–312. doi: 10.1016/j.concog.2017.02.007
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Select two subjects from the masked orientation discrimination experiment
data &lt;- subset(MaskOri, participant %in% c(1:2))
head(data)

# 2. Fit some models to each subject of the masked orientation discrimination experiment

  # Fitting several models to several subjects takes quite some time
  # If you want to fit more than just two subjects,
  # we strongly recommend setting .parallel=TRUE
  Fits &lt;- fitConfModels(data, models=c("ITGc", "SDT"), .parallel = FALSE)

</code></pre>

<hr>
<h2 id='fitMetaDprime'>Fits meta-d' and meta-d'/d' ratios for data from one or several subjects</h2><span id='topic+fitMetaDprime'></span>

<h3>Description</h3>

<p>This function computes meta-d' and meta-d'/d' for each  participant in the <code>data</code>, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitMetaDprime(data, model = "ML", nInits = 5, nRestart = 3,
  .parallel = FALSE, n.cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitMetaDprime_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> where each row is one trial, containing following
variables:
</p>

<ul>
<li> <p><code>rating</code> (discrete confidence judgments, should be given as factor;
otherwise will be transformed to factor with a warning),
</p>
</li>
<li> <p><code>stimulus</code> (stimulus category in a binary choice task,
should be a factor with two levels, otherwise it will be transformed to
a factor with a warning),
</p>
</li>
<li> <p><code>correct</code> (encoding whether the response was correct; should  be 0 for incorrect responses and 1 for correct responses)
</p>
</li>
<li> <p><code>participant</code> (giving the subject ID; the models given in the second argument are fitted for each
subject individually.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fitMetaDprime_+3A_model">model</code></td>
<td>
<p><code>character</code> of length 1. Either &quot;ML&quot; to use the original model
specification by Maniscalco and Lau (2012,  2014) or &quot;F&quot; to use the model
specification by Fleming (2017)'s HmetaD method.  Defaults to &quot;ML&quot;</p>
</td></tr>
<tr><td><code id="fitMetaDprime_+3A_ninits">nInits</code></td>
<td>
<p><code>integer</code>. Number of initial values used for maximum likelihood optimization.
Defaults to 5.</p>
</td></tr>
<tr><td><code id="fitMetaDprime_+3A_nrestart">nRestart</code></td>
<td>
<p><code>integer</code>. Number of times the optimization is restarted.
Defaults to 3.</p>
</td></tr>
<tr><td><code id="fitMetaDprime_+3A_.parallel">.parallel</code></td>
<td>
<p><code>logical</code>. Whether to parallelize the fitting over models and participant
(default: FALSE)</p>
</td></tr>
<tr><td><code id="fitMetaDprime_+3A_n.cores">n.cores</code></td>
<td>
<p><code>integer</code>. Number of cores used for parallelization. If NULL (default), the available
number of cores -1 will be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes meta-d' and meta-d'/d' either using the
hypothetical signal detection model assumed by Maniscalco and Lau (2012, 2014)
or the one assumed by Fleming (2014). The fitting routine first performs a coarse grid search to find promising
starting values for the maximum likelihood optimization procedure. Then the best <code>nInits</code>
parameter sets found by the grid search are used as the initial values for separate
runs of the Nelder-Mead algorithm implemented in <code><a href="stats.html#topic+optim">optim</a></code>.
Each run is restarted <code>nRestart</code> times. Warning: Meta-d'/d'
is only guaranteed to be unbiased from discrimination sensitivity, discrimination
bias, and confidence criteria if the data is generated according to the
independent truncated Gaussian model (see Rausch et al., 2023).
</p>


<h3>Value</h3>

<p>Gives data frame with rows for each participant and columns dprime, c, metaD, and Ratio
</p>

<ul>
<li><p> dprime is the discrimination sensitivity index d', calculated using a standard SDT formula
</p>
</li>
<li><p> c is the discrimination bias c, calculated using a standard SDT formula
</p>
</li>
<li><p> metaD is meta-d', discrimination sensitivity estimated from confidence judgments conditioned on the response
</p>
</li>
<li><p> Ratio is meta-d'/d', a quantity usually referred to as metacognitive efficiency.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Rausch, <a href="mailto:manuel.rausch@hochschule-rhein-waal.de">manuel.rausch@hochschule-rhein-waal.de</a>
</p>


<h3>References</h3>

<p>Fleming, S. M. (2017). HMeta-d: Hierarchical Bayesian estimation of metacognitive efficiency from confidence ratings. Neuroscience of Consciousness, 1, 1–14. doi: 10.1093/nc/nix007
</p>
<p>Maniscalco, B., &amp; Lau, H. (2012). A signal detection theoretic method for estimating metacognitive sensitivity from confidence ratings. Consciousness and Cognition, 21(1), 422–430.
</p>
<p>Maniscalco, B., &amp; Lau, H. C. (2014). Signal Detection Theory Analysis of Type 1 and Type 2 Data: Meta-d’, Response- Specific Meta-d’, and the Unequal Variance SDT Model. In S. M. Fleming &amp; C. D. Frith (Eds.), The Cognitive Neuroscience of Metacognition (pp. 25–66). Springer. doi: 10.1007/978-3-642-45190-4_3
</p>
<p>Rausch, M., Hellmann, S., &amp; Zehetleitner, M. (2023). Measures of metacognitive efficiency across cognitive models of decision confidence (Preprint). PsyArXiv. doi: 10.31234/osf.io/kdz34
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Select two subject from the masked orientation discrimination experiment
data &lt;- subset(MaskOri, participant %in% c(1:2))
head(data)

# 2. Fit meta-d'/d' for each subject in data
MetaDs &lt;- fitMetaDprime(data, model="F", .parallel = FALSE)

</code></pre>

<hr>
<h2 id='MaskOri'>Data of 36 participants in a masked orientation discrimination experiment</h2><span id='topic+MaskOri'></span>

<h3>Description</h3>

<p>In each trial, participants were shown a sinusoidal grating oriented either horizontally or vertically, followed by a mask after varying stimulus-onset-asynchronies.
Participants were instructed to report the orientation and their degree of confidence as accurately as possible
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MaskOri)
</code></pre>


<h3>Format</h3>

<p>A data.frame with 34,430 rows and 8 variables:
</p>

<dl>
<dt>participant</dt><dd><p>integer values as unique participant identifier</p>
</dd>
<dt>stimulus</dt><dd><p>orientation of the grating (90: vertical, 0: horizontal)</p>
</dd>
<dt>correct</dt><dd><p>0-1 column indicating whether the discrimination response was correct (1) or not (0)</p>
</dd>
<dt>rating</dt><dd><p>factor 4-point confidence scale. The four confidence categories were labelled as &quot;not at all&quot;, &quot;a little&quot;, &quot;nearly sure&quot; and &quot;sure&quot;.</p>
</dd>
<dt>diffCond</dt><dd><p>stimulus-onset-asynchrony in ms (i.e. time between stimulus and mask onset)</p>
</dd>
<dt>gender</dt><dd><p>gender of the participant: &quot;w&quot; for female; &quot;m&quot; for male participants</p>
</dd>
<dt>age</dt><dd><p>the age of participants in years</p>
</dd>
<dt>trialNo</dt><dd><p>Enumeration of trials per participant</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(MaskOri)
summary(MaskOri)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
