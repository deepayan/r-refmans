<!DOCTYPE html><html><head><title>Help for package qdap</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {qdap}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%&amp;%'><p>qdap Chaining</p></a></li>
<li><a href='#+.Network'><p>Add themes to a Network object.</p></a></li>
<li><a href='#add_incomplete'><p>Detect Incomplete Sentences; Add | Endmark</p></a></li>
<li><a href='#add_s'><p>Make Plural (or Verb to Singular) Versions of Words</p></a></li>
<li><a href='#adjacency_matrix'><p>Takes a Matrix and Generates an Adjacency Matrix</p></a></li>
<li><a href='#all_words'><p>Searches Text Column for Words</p></a></li>
<li><a href='#Animate'><p>Generic Animate Method</p></a></li>
<li><a href='#Animate.character'><p>Animate Character</p></a></li>
<li><a href='#Animate.discourse_map'><p>Discourse Map</p></a></li>
<li><a href='#Animate.formality'><p>Animate Formality</p></a></li>
<li><a href='#Animate.gantt'><p>Gantt Durations</p></a></li>
<li><a href='#Animate.gantt_plot'><p>Gantt Plot</p></a></li>
<li><a href='#Animate.lexical_classification'><p>Animate Formality</p></a></li>
<li><a href='#Animate.polarity'><p>Animate Polarity</p></a></li>
<li><a href='#as.tdm'><p>tm Package Compatibility Tools: Apply to or Convert to/from Term Document</p>
Matrix or Document Term Matrix</a></li>
<li><a href='#automated_readability_index'><p>Readability Measures</p></a></li>
<li><a href='#bag_o_words'><p>Bag of Words</p></a></li>
<li><a href='#beg2char'><p>Grab Begin/End of String to Character</p></a></li>
<li><a href='#blank2NA'><p>Replace Blanks in a dataframe</p></a></li>
<li><a href='#bracketX'><p>Bracket Parsing</p></a></li>
<li><a href='#build_qdap_vignette'><p>Replace Temporary Introduction to qdap Vignette</p></a></li>
<li><a href='#capitalizer'><p>Capitalize Select Words</p></a></li>
<li><a href='#check_spelling'><p>Check Spelling</p></a></li>
<li><a href='#check_spelling_interactive.character'><p>Check Spelling</p></a></li>
<li><a href='#check_spelling_interactive.check_spelling'><p>Check Spelling</p></a></li>
<li><a href='#check_spelling_interactive.factor'><p>Check Spelling</p></a></li>
<li><a href='#check_text'><p>Check Text For Potential Problems</p></a></li>
<li><a href='#chunker'><p>Break Text Into Ordered Word Chunks</p></a></li>
<li><a href='#clean'><p>Remove Escaped Characters</p></a></li>
<li><a href='#cm_2long'><p>A Generic to Long Function</p></a></li>
<li><a href='#cm_code.blank'><p>Blank Code Transformation</p></a></li>
<li><a href='#cm_code.combine'><p>Combine Codes</p></a></li>
<li><a href='#cm_code.exclude'><p>Exclude Codes</p></a></li>
<li><a href='#cm_code.overlap'><p>Find Co-occurrence Between Codes</p></a></li>
<li><a href='#cm_code.transform'><p>Transform Codes</p></a></li>
<li><a href='#cm_combine.dummy'><p>Find Co-occurrence Between Dummy Codes</p></a></li>
<li><a href='#cm_df.fill'><p>Range Coding</p></a></li>
<li><a href='#cm_df.temp'><p>Break Transcript Dialogue into Blank Code Matrix</p></a></li>
<li><a href='#cm_df.transcript'><p>Transcript With Word Number</p></a></li>
<li><a href='#cm_df2long'><p>Transform Codes to Start-End Durations</p></a></li>
<li><a href='#cm_distance'><p>Distance Matrix Between Codes</p></a></li>
<li><a href='#cm_dummy2long'><p>Convert cm_combine.dummy Back to Long</p></a></li>
<li><a href='#cm_long2dummy'><p>Stretch and Dummy Code cm_xxx2long</p></a></li>
<li><a href='#cm_range.temp'><p>Range Code Sheet</p></a></li>
<li><a href='#cm_range2long'><p>Transform Codes to Start-End Durations</p></a></li>
<li><a href='#cm_time.temp'><p>Time Span Code Sheet</p></a></li>
<li><a href='#cm_time2long'><p>Transform Codes to Start-End Times</p></a></li>
<li><a href='#colcomb2class'><p>Combine Columns to Class</p></a></li>
<li><a href='#colSplit'><p>Separate a Column Pasted by paste2</p></a></li>
<li><a href='#colsplit2df'><p>Wrapper for colSplit that Returns Dataframe(s)</p></a></li>
<li><a href='#comma_spacer'><p>Ensure Space After Comma</p></a></li>
<li><a href='#common'><p>Find Common Words Between Groups</p></a></li>
<li><a href='#common.list'><p>list Method for common</p></a></li>
<li><a href='#condense'><p>Condense Dataframe Columns</p></a></li>
<li><a href='#counts'><p>Generic Counts Method</p></a></li>
<li><a href='#counts.automated_readability_index'><p>Readability Measures</p></a></li>
<li><a href='#counts.character_table'><p>Term Counts</p></a></li>
<li><a href='#counts.coleman_liau'><p>Readability Measures</p></a></li>
<li><a href='#counts.end_mark_by'><p>Question Counts</p></a></li>
<li><a href='#counts.flesch_kincaid'><p>Readability Measures</p></a></li>
<li><a href='#counts.formality'><p>Formality</p></a></li>
<li><a href='#counts.fry'><p>Readability Measures</p></a></li>
<li><a href='#counts.linsear_write'><p>Readability Measures</p></a></li>
<li><a href='#counts.object_pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#counts.polarity'><p>Polarity</p></a></li>
<li><a href='#counts.pos'><p>Parts of Speech</p></a></li>
<li><a href='#counts.pos_by'><p>Parts of Speech</p></a></li>
<li><a href='#counts.pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#counts.question_type'><p>Question Counts</p></a></li>
<li><a href='#counts.SMOG'><p>Readability Measures</p></a></li>
<li><a href='#counts.subject_pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#counts.termco'><p>Term Counts</p></a></li>
<li><a href='#counts.word_length'><p>Word Length Counts</p></a></li>
<li><a href='#counts.word_position'><p>Word Position</p></a></li>
<li><a href='#counts.word_stats'><p>Word Stats</p></a></li>
<li><a href='#cumulative'><p>Cumulative Scores</p></a></li>
<li><a href='#DATA'><p>Fictitious Classroom Dialogue</p></a></li>
<li><a href='#DATA.SPLIT'><p>Fictitious Split Sentence Classroom Dialogue</p></a></li>
<li><a href='#DATA2'><p>Fictitious Repeated Measures Classroom Dialogue</p></a></li>
<li><a href='#delete'><p>Easy File Handling</p></a></li>
<li><a href='#dir_map'><p>Map Transcript Files from a Directory to a Script</p></a></li>
<li><a href='#discourse_map'><p>Discourse Mapping</p></a></li>
<li><a href='#dispersion_plot'><p>Lexical Dispersion Plot</p></a></li>
<li><a href='#Dissimilarity'><p>Dissimilarity Statistics</p></a></li>
<li><a href='#dist_tab'><p>SPSS Style Frequency Tables</p></a></li>
<li><a href='#diversity'><p>Diversity Statistics</p></a></li>
<li><a href='#duplicates'><p>Find Duplicated Words in a Text String</p></a></li>
<li><a href='#end_inc'><p>Test for Incomplete Sentences</p></a></li>
<li><a href='#end_mark'><p>Sentence End Marks</p></a></li>
<li><a href='#env.syl'><p>Syllable Lookup Environment</p></a></li>
<li><a href='#exclude'><p>Exclude Elements From a Vector</p></a></li>
<li><a href='#Filter.all_words'><p>Filter</p></a></li>
<li><a href='#formality'><p>Formality Score</p></a></li>
<li><a href='#freq_terms'><p>Find Frequent Terms</p></a></li>
<li><a href='#gantt'><p>Gantt Durations</p></a></li>
<li><a href='#gantt_plot'><p>Gantt Plot</p></a></li>
<li><a href='#gantt_rep'><p>Generate Unit Spans for Repeated Measures</p></a></li>
<li><a href='#gantt_wrap'><p>Gantt Plot</p></a></li>
<li><a href='#gradient_cloud'><p>Gradient Word Cloud</p></a></li>
<li><a href='#hamlet'><p>Hamlet (Complete &amp; Split by Sentence)</p></a></li>
<li><a href='#htruncdf'><p>Dataframe Viewing</p></a></li>
<li><a href='#imperative'><p>Intuitively Remark Sentences as Imperative</p></a></li>
<li><a href='#incomplete_replace'><p>Denote Incomplete End Marks With &quot;|&quot;</p></a></li>
<li><a href='#inspect_text'><p>Inspect Text Vectors</p></a></li>
<li><a href='#is.global'><p>Test If Environment is Global</p></a></li>
<li><a href='#key_merge'><p>Merge Demographic Information with Person/Text Transcript</p></a></li>
<li><a href='#kullback_leibler'><p>Kullback Leibler Statistic</p></a></li>
<li><a href='#left_just'><p>Text Justification</p></a></li>
<li><a href='#lexical_classification'><p>Lexical Classification Score</p></a></li>
<li><a href='#mcsv_r'><p>Read/Write Multiple csv Files at a Time</p></a></li>
<li><a href='#mraja1'><p>Romeo and Juliet: Act 1 Dialogue Merged with Demographics</p></a></li>
<li><a href='#mraja1spl'><p>Romeo and Juliet: Act 1 Dialogue Merged with Demographics and Split</p></a></li>
<li><a href='#multigsub'><p>Multiple gsub</p></a></li>
<li><a href='#multiscale'><p>Nested Standardization</p></a></li>
<li><a href='#NAer'><p>Replace Missing Values (NA)</p></a></li>
<li><a href='#name2sex'><p>Names to Gender</p></a></li>
<li><a href='#Network'><p>Generic Network Method</p></a></li>
<li><a href='#Network.formality'><p>Network Formality</p></a></li>
<li><a href='#Network.lexical_classification'><p>Network Lexical Classification</p></a></li>
<li><a href='#Network.polarity'><p>Network Polarity</p></a></li>
<li><a href='#new_project'><p>Project Template</p></a></li>
<li><a href='#ngrams'><p>Generate ngrams</p></a></li>
<li><a href='#object_pronoun_type'><p>Count Object Pronouns Per Grouping Variable</p></a></li>
<li><a href='#outlier_detect'><p>Detect Outliers in Text</p></a></li>
<li><a href='#outlier_labeler'><p>Locate Outliers in Numeric String</p></a></li>
<li><a href='#paste2'><p>Paste an Unspecified Number Of Text Columns</p></a></li>
<li><a href='#phrase_net'><p>Phrase Nets</p></a></li>
<li><a href='#plot.animated_character'><p>Plots an animated_character  Object</p></a></li>
<li><a href='#plot.animated_discourse_map'><p>Plots an animated_discourse_map  Object</p></a></li>
<li><a href='#plot.animated_formality'><p>Plots a animated_formality  Object</p></a></li>
<li><a href='#plot.animated_lexical_classification'><p>Plots an animated_lexical_classification  Object</p></a></li>
<li><a href='#plot.animated_polarity'><p>Plots an animated_polarity  Object</p></a></li>
<li><a href='#plot.automated_readability_index'><p>Plots a automated_readability_index Object</p></a></li>
<li><a href='#plot.character_table'><p>Plots a character_table Object</p></a></li>
<li><a href='#plot.cm_distance'><p>Plots a cm_distance object</p></a></li>
<li><a href='#plot.cmspans'><p>Plots a cmspans object</p></a></li>
<li><a href='#plot.coleman_liau'><p>Plots a coleman_liau Object</p></a></li>
<li><a href='#plot.combo_syllable_sum'><p>Plots a combo_syllable_sum Object</p></a></li>
<li><a href='#plot.cumulative_animated_formality'><p>Plots a cumulative_animated_formality Object</p></a></li>
<li><a href='#plot.cumulative_animated_lexical_classification'><p>Plots a cumulative_animated_lexical_classification Object</p></a></li>
<li><a href='#plot.cumulative_animated_polarity'><p>Plots a cumulative_animated_polarity Object</p></a></li>
<li><a href='#plot.cumulative_combo_syllable_sum'><p>Plots a cumulative_combo_syllable_sum Object</p></a></li>
<li><a href='#plot.cumulative_end_mark'><p>Plots a cumulative_end_mark Object</p></a></li>
<li><a href='#plot.cumulative_formality'><p>Plots a cumulative_formality Object</p></a></li>
<li><a href='#plot.cumulative_lexical_classification'><p>Plots a cumulative_lexical_classification Object</p></a></li>
<li><a href='#plot.cumulative_polarity'><p>Plots a cumulative_polarity Object</p></a></li>
<li><a href='#plot.cumulative_syllable_freq'><p>Plots a cumulative_syllable_freq Object</p></a></li>
<li><a href='#plot.discourse_map'><p>Plots a discourse_map Object</p></a></li>
<li><a href='#plot.diversity'><p>Plots a diversity object</p></a></li>
<li><a href='#plot.end_mark'><p>Plots an end_mark Object</p></a></li>
<li><a href='#plot.end_mark_by'><p>Plots a end_mark_by Object</p></a></li>
<li><a href='#plot.end_mark_by_count'><p>Plots a end_mark_by_count Object</p></a></li>
<li><a href='#plot.end_mark_by_preprocessed'><p>Plots a end_mark_by_preprocessed Object</p></a></li>
<li><a href='#plot.end_mark_by_proportion'><p>Plots a end_mark_by_proportion Object</p></a></li>
<li><a href='#plot.end_mark_by_score'><p>Plots a end_mark_by_score Object</p></a></li>
<li><a href='#plot.flesch_kincaid'><p>Plots a flesch_kincaid Object</p></a></li>
<li><a href='#plot.formality'><p>Plots a formality Object</p></a></li>
<li><a href='#plot.formality_scores'><p>Plots a formality_scores Object</p></a></li>
<li><a href='#plot.freq_terms'><p>Plots a freq_terms Object</p></a></li>
<li><a href='#plot.gantt'><p>Plots a gantt object</p></a></li>
<li><a href='#plot.kullback_leibler'><p>Plots a kullback_leibler object</p></a></li>
<li><a href='#plot.lexical'><p>Plots a lexical Object</p></a></li>
<li><a href='#plot.lexical_classification'><p>Plots a lexical_classification Object</p></a></li>
<li><a href='#plot.lexical_classification_preprocessed'><p>Plots a lexical_classification_preprocessed Object</p></a></li>
<li><a href='#plot.lexical_classification_score'><p>Plots a lexical_classification_score Object</p></a></li>
<li><a href='#plot.linsear_write'><p>Plots a linsear_write Object</p></a></li>
<li><a href='#plot.linsear_write_count'><p>Plots a linsear_write_count Object</p></a></li>
<li><a href='#plot.linsear_write_scores'><p>Plots a linsear_write_scores Object</p></a></li>
<li><a href='#plot.Network'><p>Plots a Network  Object</p></a></li>
<li><a href='#plot.object_pronoun_type'><p>Plots an object_pronoun_type Object</p></a></li>
<li><a href='#plot.polarity'><p>Plots a polarity Object</p></a></li>
<li><a href='#plot.polarity_count'><p>Plots a polarity_count Object</p></a></li>
<li><a href='#plot.polarity_score'><p>Plots a polarity_score Object</p></a></li>
<li><a href='#plot.pos'><p>Plots a pos Object</p></a></li>
<li><a href='#plot.pos_by'><p>Plots a pos_by Object</p></a></li>
<li><a href='#plot.pos_preprocessed'><p>Plots a pos_preprocessed Object</p></a></li>
<li><a href='#plot.pronoun_type'><p>Plots an pronoun_type Object</p></a></li>
<li><a href='#plot.question_type'><p>Plots a question_type Object</p></a></li>
<li><a href='#plot.question_type_preprocessed'><p>Plots a question_type_preprocessed Object</p></a></li>
<li><a href='#plot.readability_count'><p>Plots a readability_count Object</p></a></li>
<li><a href='#plot.readability_score'><p>Plots a readability_score Object</p></a></li>
<li><a href='#plot.rmgantt'><p>Plots a rmgantt object</p></a></li>
<li><a href='#plot.sent_split'><p>Plots a sent_split Object</p></a></li>
<li><a href='#plot.SMOG'><p>Plots a SMOG Object</p></a></li>
<li><a href='#plot.subject_pronoun_type'><p>Plots an subject_pronoun_type Object</p></a></li>
<li><a href='#plot.sum_cmspans'><p>Plot Summary Stats for a Summary of a cmspans Object</p></a></li>
<li><a href='#plot.sums_gantt'><p>Plots a sums_gantt object</p></a></li>
<li><a href='#plot.syllable_freq'><p>Plots a syllable_freq Object</p></a></li>
<li><a href='#plot.table_count'><p>Plots a table_count Object</p></a></li>
<li><a href='#plot.table_proportion'><p>Plots a table_proportion Object</p></a></li>
<li><a href='#plot.table_score'><p>Plots a table_score Object</p></a></li>
<li><a href='#plot.termco'><p>Plots a termco object</p></a></li>
<li><a href='#plot.type_token_ratio'><p>Plots a type_token_ratio Object</p></a></li>
<li><a href='#plot.weighted_wfm'><p>Plots a weighted_wfm object</p></a></li>
<li><a href='#plot.wfdf'><p>Plots a wfdf object</p></a></li>
<li><a href='#plot.wfm'><p>Plots a wfm object</p></a></li>
<li><a href='#plot.word_cor'><p>Plots a word_cor object</p></a></li>
<li><a href='#plot.word_length'><p>Plots a word_length Object</p></a></li>
<li><a href='#plot.word_position'><p>Plots a word_position object</p></a></li>
<li><a href='#plot.word_proximity'><p>Plots a word_proximity object</p></a></li>
<li><a href='#plot.word_stats'><p>Plots a word_stats object</p></a></li>
<li><a href='#plot.word_stats_counts'><p>Plots a word_stats_counts Object</p></a></li>
<li><a href='#polarity'><p>Polarity Score (Sentiment Analysis)</p></a></li>
<li><a href='#pos'><p>Parts of Speech Tagging</p></a></li>
<li><a href='#potential_NA'><p>Search for Potential Missing Values</p></a></li>
<li><a href='#preprocessed'><p>Generic Preprocessed Method</p></a></li>
<li><a href='#preprocessed.check_spelling_interactive'><p>Check Spelling</p></a></li>
<li><a href='#preprocessed.end_mark_by'><p>Question Counts</p></a></li>
<li><a href='#preprocessed.formality'><p>Formality</p></a></li>
<li><a href='#preprocessed.lexical_classification'><p>Lexical Classification</p></a></li>
<li><a href='#preprocessed.object_pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#preprocessed.pos'><p>Parts of Speech</p></a></li>
<li><a href='#preprocessed.pos_by'><p>Parts of Speech</p></a></li>
<li><a href='#preprocessed.pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#preprocessed.question_type'><p>Question Counts</p></a></li>
<li><a href='#preprocessed.subject_pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#preprocessed.word_position'><p>Word Position</p></a></li>
<li><a href='#pres_debate_raw2012'><p>First 2012 U.S. Presidential Debate</p></a></li>
<li><a href='#pres_debates2012'><p>2012 U.S. Presidential Debates</p></a></li>
<li><a href='#print.adjacency_matrix'><p>Prints an adjacency_matrix Object</p></a></li>
<li><a href='#print.all_words'><p>Prints an all_words Object</p></a></li>
<li><a href='#print.animated_character'><p>Prints an animated_character  Object</p></a></li>
<li><a href='#print.animated_discourse_map'><p>Prints an animated_discourse_map  Object</p></a></li>
<li><a href='#print.animated_formality'><p>Prints a animated_formality  Object</p></a></li>
<li><a href='#print.animated_lexical_classification'><p>Prints an animated_lexical_classification  Object</p></a></li>
<li><a href='#print.animated_polarity'><p>Prints an animated_polarity  Object</p></a></li>
<li><a href='#print.automated_readability_index'><p>Prints an automated_readability_index Object</p></a></li>
<li><a href='#print.boolean_qdap'><p>Prints a boolean_qdap object</p></a></li>
<li><a href='#print.character_table'><p>Prints a character_table object</p></a></li>
<li><a href='#print.check_spelling'><p>Prints a check_spelling Object</p></a></li>
<li><a href='#print.check_spelling_interactive'><p>Prints a check_spelling_interactive Object</p></a></li>
<li><a href='#print.check_text'><p>Prints a check_text Object</p></a></li>
<li><a href='#print.cm_distance'><p>Prints a cm_distance Object</p></a></li>
<li><a href='#print.coleman_liau'><p>Prints an coleman_liau Object</p></a></li>
<li><a href='#print.colsplit2df'><p>Prints a colsplit2df Object.</p></a></li>
<li><a href='#print.combo_syllable_sum'><p>Prints an combo_syllable_sum object</p></a></li>
<li><a href='#print.cumulative_animated_formality'><p>Prints a cumulative_animated_formality Object</p></a></li>
<li><a href='#print.cumulative_animated_lexical_classification'><p>Prints a cumulative_animated_lexical_classification Object</p></a></li>
<li><a href='#print.cumulative_animated_polarity'><p>Prints a cumulative_animated_polarity Object</p></a></li>
<li><a href='#print.cumulative_combo_syllable_sum'><p>Prints a cumulative_combo_syllable_sum Object</p></a></li>
<li><a href='#print.cumulative_end_mark'><p>Prints a cumulative_end_mark Object</p></a></li>
<li><a href='#print.cumulative_formality'><p>Prints a cumulative_formality Object</p></a></li>
<li><a href='#print.cumulative_lexical_classification'><p>Prints a cumulative_lexical_classification Object</p></a></li>
<li><a href='#print.cumulative_polarity'><p>Prints a cumulative_polarity Object</p></a></li>
<li><a href='#print.cumulative_syllable_freq'><p>Prints a cumulative_syllable_freqObject</p></a></li>
<li><a href='#print.discourse_map'><p>Prints a discourse_map Object</p></a></li>
<li><a href='#print.Dissimilarity'><p>Prints a Dissimilarity object</p></a></li>
<li><a href='#print.diversity'><p>Prints a diversity object</p></a></li>
<li><a href='#print.end_mark'><p>Prints an end_mark object</p></a></li>
<li><a href='#print.end_mark_by'><p>Prints an end_mark_by object</p></a></li>
<li><a href='#print.end_mark_by_preprocessed'><p>Prints a end_mark_by_preprocessed object</p></a></li>
<li><a href='#print.flesch_kincaid'><p>Prints an flesch_kincaid Object</p></a></li>
<li><a href='#print.formality'><p>Prints a formality Object</p></a></li>
<li><a href='#print.formality_scores'><p>Prints a formality_scores object</p></a></li>
<li><a href='#print.fry'><p>Prints an fry Object</p></a></li>
<li><a href='#print.inspect_text'><p>Prints an inspect_text Object</p></a></li>
<li><a href='#print.kullback_leibler'><p>Prints a kullback_leibler Object.</p></a></li>
<li><a href='#print.lexical_classification'><p>Prints an lexical_classification Object</p></a></li>
<li><a href='#print.lexical_classification_by'><p>Prints a lexical_classification Object</p></a></li>
<li><a href='#print.lexical_classification_preprocessed'><p>Prints a lexical_classification_preprocessed Object</p></a></li>
<li><a href='#print.lexical_classification_score'><p>Prints a lexical_classification_score Object</p></a></li>
<li><a href='#print.linsear_write'><p>Prints an linsear_write Object</p></a></li>
<li><a href='#print.linsear_write_count'><p>Prints a linsear_write_count Object</p></a></li>
<li><a href='#print.linsear_write_scores'><p>Prints a linsear_write_scores Object</p></a></li>
<li><a href='#print.Network'><p>Prints a Network Object</p></a></li>
<li><a href='#print.ngrams'><p>Prints an ngrams object</p></a></li>
<li><a href='#print.object_pronoun_type'><p>Prints a object_pronoun_type object</p></a></li>
<li><a href='#print.phrase_net'><p>Prints a phrase_net Object</p></a></li>
<li><a href='#print.polarity'><p>Prints an polarity Object</p></a></li>
<li><a href='#print.polarity_count'><p>Prints a polarity_count Object</p></a></li>
<li><a href='#print.polarity_score'><p>Prints a polarity_score Object</p></a></li>
<li><a href='#print.polysyllable_sum'><p>Prints an polysyllable_sum object</p></a></li>
<li><a href='#print.pos'><p>Prints a pos Object.</p></a></li>
<li><a href='#print.pos_by'><p>Prints a pos_by Object.</p></a></li>
<li><a href='#print.pos_preprocessed'><p>Prints a pos_preprocessed object</p></a></li>
<li><a href='#print.pronoun_type'><p>Prints a pronoun_type object</p></a></li>
<li><a href='#print.qdap_context'><p>Prints a qdap_context object</p></a></li>
<li><a href='#print.qdapProj'><p>Prints a qdapProj Object</p></a></li>
<li><a href='#print.question_type'><p>Prints a question_type object</p></a></li>
<li><a href='#print.question_type_preprocessed'><p>Prints a question_type_preprocessed object</p></a></li>
<li><a href='#print.readability_count'><p>Prints a readability_count Object</p></a></li>
<li><a href='#print.readability_score'><p>Prints a readability_score Object</p></a></li>
<li><a href='#print.sent_split'><p>Prints a sent_split object</p></a></li>
<li><a href='#print.SMOG'><p>Prints an SMOG Object</p></a></li>
<li><a href='#print.sub_holder'><p>Prints a sub_holder object</p></a></li>
<li><a href='#print.subject_pronoun_type'><p>Prints a subject_pronoun_type object</p></a></li>
<li><a href='#print.sum_cmspans'><p>Prints a sum_cmspans object</p></a></li>
<li><a href='#print.sums_gantt'><p>Prints a sums_gantt object</p></a></li>
<li><a href='#print.syllable_sum'><p>Prints an syllable_sum object</p></a></li>
<li><a href='#print.table_count'><p>Prints a table_count object</p></a></li>
<li><a href='#print.table_proportion'><p>Prints a table_proportion object</p></a></li>
<li><a href='#print.table_score'><p>Prints a table_score object</p></a></li>
<li><a href='#print.termco'><p>Prints a termco object.</p></a></li>
<li><a href='#print.trunc'><p>Prints a trunc object</p></a></li>
<li><a href='#print.type_token_ratio'><p>Prints a type_token_ratio Object</p></a></li>
<li><a href='#print.wfm'><p>Prints a wfm Object</p></a></li>
<li><a href='#print.wfm_summary'><p>Prints a wfm_summary Object</p></a></li>
<li><a href='#print.which_misspelled'><p>Prints a which_misspelled Object</p></a></li>
<li><a href='#print.word_associate'><p>Prints a word_associate object</p></a></li>
<li><a href='#print.word_cor'><p>Prints a word_cor object</p></a></li>
<li><a href='#print.word_length'><p>Prints a word_length object</p></a></li>
<li><a href='#print.word_list'><p>Prints a word_list Object</p></a></li>
<li><a href='#print.word_position'><p>Prints a word_position object.</p></a></li>
<li><a href='#print.word_proximity'><p>Prints a word_proximity object</p></a></li>
<li><a href='#print.word_stats'><p>Prints a word_stats object</p></a></li>
<li><a href='#print.word_stats_counts'><p>Prints a word_stats_counts object</p></a></li>
<li><a href='#pronoun_type'><p>Count Object/Subject Pronouns Per Grouping Variable</p></a></li>
<li><a href='#prop'><p>Convert Raw Numeric Matrix or Data Frame to Proportions</p></a></li>
<li><a href='#proportions'><p>Generic Proportions Method</p></a></li>
<li><a href='#proportions.character_table'><p>Term Counts</p></a></li>
<li><a href='#proportions.end_mark_by'><p>Question Counts</p></a></li>
<li><a href='#proportions.formality'><p>Formality</p></a></li>
<li><a href='#proportions.object_pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#proportions.pos'><p>Parts of Speech</p></a></li>
<li><a href='#proportions.pos_by'><p>Parts of Speech</p></a></li>
<li><a href='#proportions.pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#proportions.question_type'><p>Question Counts</p></a></li>
<li><a href='#proportions.subject_pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#proportions.termco'><p>Term Counts</p></a></li>
<li><a href='#proportions.word_length'><p>Word Length Counts</p></a></li>
<li><a href='#proportions.word_position'><p>Word Position</p></a></li>
<li><a href='#qcombine'><p>Combine Columns</p></a></li>
<li><a href='#qcv'><p>Quick Character Vector</p></a></li>
<li><a href='#qdap'><p>qdap: Quantitative Discourse Analysis Package</p></a></li>
<li><a href='#qdap_df'><p>Create qdap Specific Data Structure</p></a></li>
<li><a href='#qheat'><p>Quick Heatmap</p></a></li>
<li><a href='#qprep'><p>Quick Preparation of Text</p></a></li>
<li><a href='#qtheme'><p>Add themes to a Network object.</p></a></li>
<li><a href='#question_type'><p>Count of Question Type</p></a></li>
<li><a href='#raj'><p>Romeo and Juliet (Unchanged &amp; Complete)</p></a></li>
<li><a href='#raj.act.1'><p>Romeo and Juliet: Act 1</p></a></li>
<li><a href='#raj.act.1POS'><p>Romeo and Juliet: Act 1 Parts of Speech by Person</p>
</p>
<p>A dataset containing a list from <code>pos_by</code> using the</p>
<code>mraja1spl</code> data set (see <code>pos_by</code> for
more information).</a></li>
<li><a href='#raj.act.2'><p>Romeo and Juliet: Act 2</p></a></li>
<li><a href='#raj.act.3'><p>Romeo and Juliet: Act 3</p></a></li>
<li><a href='#raj.act.4'><p>Romeo and Juliet: Act 4</p></a></li>
<li><a href='#raj.act.5'><p>Romeo and Juliet: Act 5</p></a></li>
<li><a href='#raj.demographics'><p>Romeo and Juliet Demographics</p></a></li>
<li><a href='#rajPOS'><p>Romeo and Juliet Split in Parts of Speech</p></a></li>
<li><a href='#rajSPLIT'><p>Romeo and Juliet (Complete &amp; Split)</p></a></li>
<li><a href='#random_sent'><p>Generate Random Dialogue Data</p></a></li>
<li><a href='#rank_freq_mplot'><p>Rank Frequency Plot</p></a></li>
<li><a href='#raw.time.span'><p>Minimal Raw Time Span Data Set</p></a></li>
<li><a href='#read.transcript'><p>Read Transcripts Into R</p></a></li>
<li><a href='#replace_abbreviation'><p>Replace Abbreviations</p></a></li>
<li><a href='#replace_contraction'><p>Replace Contractions</p></a></li>
<li><a href='#replace_number'><p>Replace Numbers With Text Representation</p></a></li>
<li><a href='#replace_ordinal'><p>Replace Mixed Ordinal Numbers With Text Representation</p></a></li>
<li><a href='#replace_symbol'><p>Replace Symbols With Word Equivalents</p></a></li>
<li><a href='#replacer'><p>Replace Cells in a Matrix or Data Frame</p></a></li>
<li><a href='#rm_row'><p>Remove Rows That Contain Markers</p></a></li>
<li><a href='#rm_stopwords'><p>Remove Stop Words</p></a></li>
<li><a href='#sample.time.span'><p>Minimal Time Span Data Set</p></a></li>
<li><a href='#scores'><p>Generic Scores Method</p></a></li>
<li><a href='#scores.automated_readability_index'><p>Readability Measures</p></a></li>
<li><a href='#scores.character_table'><p>Term Counts</p></a></li>
<li><a href='#scores.coleman_liau'><p>Readability Measures</p></a></li>
<li><a href='#scores.end_mark_by'><p>Question Counts</p></a></li>
<li><a href='#scores.flesch_kincaid'><p>Readability Measures</p></a></li>
<li><a href='#scores.formality'><p>Formality</p></a></li>
<li><a href='#scores.fry'><p>Readability Measures</p></a></li>
<li><a href='#scores.lexical_classification'><p>Lexical Classification</p></a></li>
<li><a href='#scores.linsear_write'><p>Readability Measures</p></a></li>
<li><a href='#scores.object_pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#scores.polarity'><p>Polarity</p></a></li>
<li><a href='#scores.pos_by'><p>Parts of Speech</p></a></li>
<li><a href='#scores.pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#scores.question_type'><p>Question Counts</p></a></li>
<li><a href='#scores.SMOG'><p>Readability Measures</p></a></li>
<li><a href='#scores.subject_pronoun_type'><p>Question Counts</p></a></li>
<li><a href='#scores.termco'><p>Term Counts</p></a></li>
<li><a href='#scores.word_length'><p>Word Length Counts</p></a></li>
<li><a href='#scores.word_position'><p>Word Position</p></a></li>
<li><a href='#scores.word_stats'><p>Word Stats</p></a></li>
<li><a href='#scrubber'><p>Clean Imported Text</p></a></li>
<li><a href='#Search'><p>Search Columns of a Data Frame</p></a></li>
<li><a href='#sentiment_frame'><p>Power Score (Sentiment Analysis)</p></a></li>
<li><a href='#sentSplit'><p>Sentence Splitting</p></a></li>
<li><a href='#space_fill'><p>Replace Spaces</p></a></li>
<li><a href='#spaste'><p>Add Leading/Trailing Spaces</p></a></li>
<li><a href='#speakerSplit'><p>Break and Stretch if Multiple Persons per Cell</p></a></li>
<li><a href='#stemmer'><p>Stem Text</p></a></li>
<li><a href='#strip'><p>Strip Text</p></a></li>
<li><a href='#strWrap'><p>Wrap Character Strings to Format Paragraphs</p></a></li>
<li><a href='#subject_pronoun_type'><p>Count Subject Pronouns Per Grouping Variable</p></a></li>
<li><a href='#summary.cmspans'><p>Summarize a cmspans object</p></a></li>
<li><a href='#summary.wfdf'><p>Summarize a wfdf object</p></a></li>
<li><a href='#summary.wfm'><p>Summarize a wfm object</p></a></li>
<li><a href='#syllable_sum'><p>Syllabication</p></a></li>
<li><a href='#synonyms'><p>Search For Synonyms</p></a></li>
<li><a href='#termco'><p>Search For and Count Terms</p></a></li>
<li><a href='#termco_c'><p>Combine Columns from a termco Object</p></a></li>
<li><a href='#Title'><p>Add Title to Select qdap Plots</p></a></li>
<li><a href='#tot_plot'><p>Visualize Word Length by Turn of Talk</p></a></li>
<li><a href='#trans_cloud'><p>Word Clouds by Grouping Variable</p></a></li>
<li><a href='#trans_context'><p>Print Context Around Indices</p></a></li>
<li><a href='#trans_venn'><p>Venn Diagram by Grouping Variable</p></a></li>
<li><a href='#Trim'><p>Remove Leading/Trailing White Space</p></a></li>
<li><a href='#type_token_ratio'><p>Type-Token Ratio</p></a></li>
<li><a href='#unique_by'><p>Find Unique Words by Grouping Variable</p></a></li>
<li><a href='#vertex_apply'><p>Apply Parameter to List of Igraph Vertices/Edges</p></a></li>
<li><a href='#visual'><p>Generic visual Method</p></a></li>
<li><a href='#visual.discourse_map'><p>Discourse Map</p></a></li>
<li><a href='#weight'><p>Weight a qdap Object</p></a></li>
<li><a href='#wfm'><p>Word Frequency Matrix</p></a></li>
<li><a href='#word_associate'><p>Find Associated Words</p></a></li>
<li><a href='#word_cor'><p>Find Correlated Words</p></a></li>
<li><a href='#word_count'><p>Word Counts</p></a></li>
<li><a href='#word_diff_list'><p>Differences In Word Use Between Groups</p></a></li>
<li><a href='#word_length'><p>Count of Word Lengths Type</p></a></li>
<li><a href='#word_list'><p>Raw Word Lists/Frequency Counts</p></a></li>
<li><a href='#word_network_plot'><p>Word Network Plot</p></a></li>
<li><a href='#word_position'><p>Word Position</p></a></li>
<li><a href='#word_proximity'><p>Proximity Matrix Between Words</p></a></li>
<li><a href='#word_stats'><p>Descriptive Word Statistics</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bridging the Gap Between Qualitative Data and Quantitative
Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4.6</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tyler Rinker &lt;tyler.rinker@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0), qdapDictionaries (&ge; 1.0.2), qdapRegex (&ge;
0.1.2), qdapTools (&ge; 1.3.1), RColorBrewer</td>
</tr>
<tr>
<td>Imports:</td>
<td>chron, dplyr (&ge; 0.3), gender (&ge; 0.5.1), ggplot2 (&ge; 2.1.0),
grid, gridExtra, igraph, methods, NLP, openNLP (&ge; 0.2-1),
openxlsx, parallel, plotrix, RCurl, reshape2, scales,
stringdist, tidyr, tm (&ge; 0.7.6), tools, utils, venneuler,
wordcloud, XML</td>
</tr>
<tr>
<td>Suggests:</td>
<td>koRpus, knitr, lda, proxy, stringi, SnowballC, testthat</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Description:</td>
<td>Automates many of the tasks associated with quantitative discourse analysis of transcripts containing discourse
              including frequency counts of sentence types, words, sentences, turns of talk, syllables and other assorted
              analysis tasks. The package provides parsing tools for preparing transcript data. Many functions enable the user
              to aggregate data by any number of grouping variables, providing analysis and seamless integration with other R
              packages that undertake higher level analysis and visualization of text. This affords the user a more efficient
              and targeted analysis. 'qdap' is designed for transcript analysis, however, many functions are applicable to other
              areas of Text Mining/ Natural Language Processing.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://trinker.github.io/qdap/">https://trinker.github.io/qdap/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/trinker/qdap/issues">https://github.com/trinker/qdap/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-10 17:16:06 UTC; tylerrinker</td>
</tr>
<tr>
<td>Author:</td>
<td>Tyler Rinker [aut, cre],
  Bryan Goodrich [ctb],
  Dason Kurkiewicz [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-11 06:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+26amp+3B+25'>qdap Chaining</h2><span id='topic++25+26+25'></span><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p><code>%&amp;%</code> - Chain <code><a href="#topic+qdap_df">qdap_df</a></code>s to <span class="pkg">qdap</span> functions with a 
<code>text.var</code> argument.  Saves typing of an explicit <code>text.var</code> 
argument and supplying a <code><a href="base.html#topic+data.frame">data.frame</a></code>.
</p>
<p><code>%&gt;%</code> - The <span class="pkg">magrittr</span> &quot;then&quot; chain operator imported by 
<span class="pkg">dplyr</span>.  Imported for convenience.  See 
https://github.com/tidyverse/magrittr for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qdap_df.object %&amp;% qdap.fun

lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B26amp+2B3B+2B25_+3A_qdap_df.object">qdap_df.object</code></td>
<td>
<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> of the class 
<code>"qdap_df"</code>.</p>
</td></tr>
<tr><td><code id="+2B25+2B26amp+2B3B+2B25_+3A_qdap.fun">qdap.fun</code></td>
<td>
<p>A <span class="pkg">qdap</span> function with a <code>text.var</code> argument.</p>
</td></tr>
<tr><td><code id="+2B25+2B26amp+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>The value to be piped.</p>
</td></tr>
<tr><td><code id="+2B25+2B26amp+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function or expression.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Inspired by <span class="pkg">magrittr</span>'s <code><a href="dplyr.html#topic++25+3E+25">%&gt;%</a></code> functionality.
</p>


<h3>See Also</h3>

<p><code><a href="dplyr.html#topic++25+3E+25">%&gt;%</a></code>,
<code><a href="#topic+qdap_df">qdap_df</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- qdap_df(DATA, state)
dat %&amp;% trans_cloud(grouping.var=person)
dat %&amp;% trans_cloud(grouping.var=person, text.var=stemmer(DATA$state))
dat %&amp;% termco(grouping.var=person, match.list=list("fun", "computer"))

## Various examples with qdap functions (sentSplit gives class "qdap_df")
dat &lt;- sentSplit(DATA, "state")
dat %&amp;% trans_cloud(grouping.var=person)
dat %&amp;% termco(person, match.list=list("fun", "computer"))
dat %&amp;% trans_venn(person)
dat %&amp;% polarity(person)
dat %&amp;% formality(person)
dat %&amp;% automated_readability_index(person)
dat %&amp;% Dissimilarity(person)
dat %&amp;% gradient_cloud(sex)
dat %&amp;% dispersion_plot(c("fun", "computer"))
dat %&amp;% discourse_map(list(sex, adult))
dat %&amp;% gantt_plot(person)
dat %&amp;% word_list(adult)
dat %&amp;% end_mark_by(person)
dat %&amp;% end_mark()
dat %&amp;% word_stats(person)
dat %&amp;% wfm(person)
dat %&amp;% word_cor(person, "i")
dat %&amp;% sentCombine(person)
dat %&amp;% question_type(person)
dat %&amp;% word_network_plot()
dat %&amp;% character_count()
dat %&amp;% char_table(person)
dat %&amp;% phrase_net(2, .1)
dat %&amp;% boolean_search("it||!")
dat %&amp;% trans_context(person, which(end_mark(DATA.SPLIT[, "state"]) == "?"))
dat %&amp;% mgsub(c("it's", "I'm"), c("it is", "I am"))

## combine with magrittr/dplyr chaining
dat %&amp;% wfm(person) %&gt;% plot()
dat %&amp;% polarity(person) %&gt;% scores()
dat %&amp;% polarity(person) %&gt;% counts()
dat %&amp;% polarity(person) %&gt;% scores()
dat %&amp;% polarity(person) %&gt;% scores() %&gt;% plot()
dat %&amp;% polarity(person) %&gt;% scores %&gt;% plot

## Change text column in `qdap_df` (Example 1)
dat2 &lt;- sentSplit(DATA, "state", stem.col = TRUE)
class(dat2)
dat2 %&amp;% trans_cloud()
Text(dat2)
## change the `text.var` column
Text(dat2) &lt;- "stem.text"
dat2 %&amp;% trans_cloud()

## Change text column in `qdap_df` (Example 2)
(dat2$fake_dat &lt;- paste(emoticon[1:11,2], dat2$state))
Text(dat2) &lt;- "fake_dat"
(m &lt;- dat2 %&amp;% sub_holder(emoticon[,2]))
m$unhold(strip(m$output))

## End(Not run)
</code></pre>

<hr>
<h2 id='+2B.Network'>Add themes to a Network object.</h2><span id='topic++2B.Network'></span>

<h3>Description</h3>

<p>This operator allows you to add themes to a Network object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Network'
Network.obj + x
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2B.Network_+3A_network.obj">Network.obj</code></td>
<td>
<p>An object of class <code>Network</code>.</p>
</td></tr>
<tr><td><code id="+2B2B.Network_+3A_x">x</code></td>
<td>
<p>A component to add to <code>Network.obj</code></p>
</td></tr>
</table>

<hr>
<h2 id='add_incomplete'>Detect Incomplete Sentences; Add | Endmark</h2><span id='topic+add_incomplete'></span>

<h3>Description</h3>

<p>Automatically detect missing endmarks and replace with the <code>|</code> endmark 
symbol to indicate an incomplete sentence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_incomplete(text.var, endmarks = "[.?|!]+$", silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_incomplete_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="add_incomplete_+3A_endmarks">endmarks</code></td>
<td>
<p>A reguar expression to check for endmarks.</p>
</td></tr>
<tr><td><code id="add_incomplete_+3A_silent">silent</code></td>
<td>
<p>logical.  If <code>TRUE</code> messages are not printed out.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector with missing endmarks replaced with <code>|</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>add_incomplete(
    c(
        "This in a", 
        "I am funny!", 
        "An ending of sorts%", 
        "What do you want?"
    )
)
</code></pre>

<hr>
<h2 id='add_s'>Make Plural (or Verb to Singular) Versions of Words</h2><span id='topic+add_s'></span>

<h3>Description</h3>

<p>Add -s, -es, or -ies to words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_s(x, keep.original = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_s_+3A_x">x</code></td>
<td>
<p>A vector of words to make plural.</p>
</td></tr>
<tr><td><code id="add_s_+3A_keep.original">keep.original</code></td>
<td>
<p>logical.  If <code>TRUE</code> the original words are kept in 
the return vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of plural words.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(10)
add_s(sample(GradyAugmented, 10))
set.seed(10)
add_s(sample(GradyAugmented, 10), FALSE)
</code></pre>

<hr>
<h2 id='adjacency_matrix'>Takes a Matrix and Generates an Adjacency Matrix</h2><span id='topic+adjacency_matrix'></span><span id='topic+adjmat'></span>

<h3>Description</h3>

<p>Takes a matrix (wfm) or termco object and generates an adjacency matrix for 
use with the igraph package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjacency_matrix(matrix.obj)

adjmat(matrix.obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjacency_matrix_+3A_matrix.obj">matrix.obj</code></td>
<td>
<p>A matrix object, preferably, of the class &quot;termco&quot;
generated from <code><a href="#topic+termco">termco</a></code>, <code><a href="#topic+termco_d">termco_d</a></code> or 
<code><a href="#topic+termco_c">termco_c</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns list:
</p>
<table>
<tr><td><code>boolean</code></td>
<td>
<p>A Boolean matrix</p>
</td></tr>
<tr><td><code>adjacency</code></td>
<td>
<p>An adjacency matrix.  Diagonals are the total (sum) number of 
occurrences a variable had</p>
</td></tr>
<tr><td><code>shared</code></td>
<td>
<p>An adjacency matrix with no diagonal and the upper triangle 
replaced with NA</p>
</td></tr>
<tr><td><code>sum</code></td>
<td>
<p>The diagonal of the adjacency matrix; the total (sum) number of 
occurrences a variable had</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dist">dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
words &lt;- c(" you", " the", "it", "oo")
Terms &lt;- with(DATA, termco(state, list(sex, adult), words))
Terms
adjacency_matrix(Terms)

wordLIST &lt;- c(" montague", " capulet", " court", " marry")
raj.termco &lt;- with(raj.act.1, termco(dialogue, person, wordLIST))
raj.adjmat &lt;- adjmat(raj.termco)
names(raj.adjmat)  #see what's available from the adjacency_matrix object
library(igraph)
g &lt;- graph.adjacency(raj.adjmat$adjacency, weighted=TRUE, mode ="undirected")
g &lt;- simplify(g)
V(g)$label &lt;- V(g)$name
V(g)$degree &lt;- degree(g)
plot(g, layout=layout.auto(g))

## End(Not run)
</code></pre>

<hr>
<h2 id='all_words'>Searches Text Column for Words</h2><span id='topic+all_words'></span>

<h3>Description</h3>

<p>A convenience function to find words that begin with or contain a letter 
chunk and returns the frequency counts of the number of occurrences of each 
word.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>all_words(
  text.var,
  begins.with = NULL,
  contains = NULL,
  alphabetical = TRUE,
  apostrophe.remove = FALSE,
  char.keep = char2space,
  char2space = "~~",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="all_words_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="all_words_+3A_begins.with">begins.with</code></td>
<td>
<p>This argument takes a word chunk.  Default is <code>NULL</code>. 
Use this if searching for a word beginning with the word chunk.</p>
</td></tr>
<tr><td><code id="all_words_+3A_contains">contains</code></td>
<td>
<p>This argument takes a word chunk.  Default is <code>NULL</code>. 
Use this if searching for a word containing the word chunk.</p>
</td></tr>
<tr><td><code id="all_words_+3A_alphabetical">alphabetical</code></td>
<td>
<p>logical.  If <code>TRUE</code> orders rows alphabetically, if 
<code>FALSE</code> orders the rows by descending frequency.</p>
</td></tr>
<tr><td><code id="all_words_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophes from 
the text before examining.</p>
</td></tr>
<tr><td><code id="all_words_+3A_char.keep">char.keep</code></td>
<td>
<p>A character vector of symbol character (i.e., punctuation) 
that strip should keep.  The default is to strip everything except 
apostrophes.  This enables the use of special characters to be turned into 
spaces or for characters to be retained.</p>
</td></tr>
<tr><td><code id="all_words_+3A_char2space">char2space</code></td>
<td>
<p>A vector of characters to be turned into spaces.</p>
</td></tr>
<tr><td><code id="all_words_+3A_...">...</code></td>
<td>
<p>Other argument supplied to <code><a href="#topic+strip">strip</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with frequency counts of words that begin with or 
contain the provided word chunk.
</p>


<h3>Note</h3>

<p>Cannot provide both <code>begins.with</code> and <code>contains</code> arguments 
at once.  If both begins.with and contains are <code>NULL</code>.
<code><a href="#topic+all_words">all_words</a></code> returns a 
frequency count for all words.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+term_match">term_match</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x1 &lt;- all_words(raj$dialogue, begins.with="re")
head(x1, 10)
x2 &lt;- all_words(raj$dialogue, "q")
head(x2, 10)
all_words(raj$dialogue, contains="conc")
x3 &lt;- all_words(raj$dialogue)
head(x3, 10)
x4 &lt;- all_words(raj$dialogue, contains="the")
head(x4)
x5 &lt;- all_words(raj$dialogue, contains="read")
head(x5)

## Filter by nchar and stopwords
Filter(head(x3), min = 3)

## Keep spaces
all_words(space_fill(DATA$state, c("are you", "can be")))

## End(Not run)
</code></pre>

<hr>
<h2 id='Animate'>Generic Animate Method</h2><span id='topic+Animate'></span>

<h3>Description</h3>

<p>Animate select qdap objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Animate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Animate_+3A_x">x</code></td>
<td>
<p>An animatable qdap object (e.g., <code><a href="#topic+discourse_map">discourse_map</a></code>).</p>
</td></tr>
<tr><td><code id="Animate_+3A_...">...</code></td>
<td>
<p>Arguments passed to Animate method of other classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scores">scores</a></code>,
<code><a href="#topic+counts">counts</a></code>,
<code><a href="#topic+preprocessed">preprocessed</a></code>,
<code><a href="#topic+proportions">proportions</a></code>
</p>

<hr>
<h2 id='Animate.character'>Animate Character</h2><span id='topic+Animate.character'></span>

<h3>Description</h3>

<p><code>Animate.character</code> - Animate a <code><a href="base.html#topic+character">character</a></code> object.  
Typically this function is useful in conjunction with other <code>Animate</code>
objects to create complex animations with accompanying text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'character'
Animate(
  x,
  wc.time = TRUE,
  time.constant = 2,
  width = 65,
  coord = c(0, 0.5),
  just = c(0, 0.5),
  size = 5,
  color = "black",
  border.color = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Animate.character_+3A_x">x</code></td>
<td>
<p>A <code><a href="base.html#topic+character">character</a></code> object.</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_wc.time">wc.time</code></td>
<td>
<p>logical.  If <code>TRUE</code> weights duration of frame by word 
count.</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_time.constant">time.constant</code></td>
<td>
<p>A constant to divide the maximum word count by.  Time
is calculated by 'round(exp(WORD COUNT/(max(WORD COUNT)/time.constant)))'.  
Therefore a larger constant will make the difference between the large and 
small word counts greater.</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_width">width</code></td>
<td>
<p>The width to break text at if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_coord">coord</code></td>
<td>
<p>The x/y coordinate to plot the text..</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_just">just</code></td>
<td>
<p>The <code>hjust</code> and <code>vjust</code> values to use for the text.</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_size">size</code></td>
<td>
<p>The size to print the text.  Can be a vector of length 1 or equal 
to the length of <code>x</code>.</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_color">color</code></td>
<td>
<p>The color to print the text.  Can be a vector of length 1 or equal 
to the length of <code>x</code>.</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_border.color">border.color</code></td>
<td>
<p>The <code>panel.border</code> color (see<code><a href="ggplot2.html#topic+theme">theme</a></code>).</p>
</td></tr>
<tr><td><code id="Animate.character_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="ggplot2.html#topic+annotate">annotate</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>character Method for Animate
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+theme">theme</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Animate(DATA[["state"]])
Animate(DATA[["state"]], color="red")
Animate(DATA[["state"]], color=RColorBrewer::brewer.pal(11, "Set3"), size=10)
cls &lt;- DATA[["person"]] %l% data.frame(levels(DATA[["person"]]), 
    RColorBrewer::brewer.pal(5, "Set3"))
Animate(DATA[["state"]], color=cls, size=10, width=30)
cls2 &lt;- DATA[["sex"]] %l% data.frame(c("m", "f"),c("lightblue", "pink"))
Animate(DATA[["state"]], color=cls2, just=c(.5, .5), coord = c(.5, .5))

## Print method
print(Animate(DATA[["state"]], color=cls2, just=c(.5, .5), coord = c(.5, .5)), 
    pause=.25)
Animate(DATA[["state"]], color=sample(colors(), nrow(DATA)), 
    size=sample(4:13, nrow(DATA), TRUE), width=30,  just=c(.5, .5), coord = c(.5, .5))

## End(Not run)
</code></pre>

<hr>
<h2 id='Animate.discourse_map'>Discourse Map</h2><span id='topic+Animate.discourse_map'></span>

<h3>Description</h3>

<p><code>Animate.discourse_map</code> - Animate a discourse 
<code><a href="#topic+discourse_map">discourse_map</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'discourse_map'
Animate(
  x,
  edge.constant,
  sep = "_",
  current.color = "red",
  previous.color = "grey50",
  wc.time = TRUE,
  time.constant = 2,
  title = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Animate.discourse_map_+3A_x">x</code></td>
<td>
<p>The discourse_map object.</p>
</td></tr>
<tr><td><code id="Animate.discourse_map_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple edge width by.</p>
</td></tr>
<tr><td><code id="Animate.discourse_map_+3A_sep">sep</code></td>
<td>
<p>The separator character to use between grouping variables.</p>
</td></tr>
<tr><td><code id="Animate.discourse_map_+3A_current.color">current.color</code></td>
<td>
<p>The color to make the vector edge as it moves.</p>
</td></tr>
<tr><td><code id="Animate.discourse_map_+3A_previous.color">previous.color</code></td>
<td>
<p>The color to make the already plotted edges.</p>
</td></tr>
<tr><td><code id="Animate.discourse_map_+3A_wc.time">wc.time</code></td>
<td>
<p>logical.  If <code>TRUE</code> weights duration of frame by word 
count.</p>
</td></tr>
<tr><td><code id="Animate.discourse_map_+3A_time.constant">time.constant</code></td>
<td>
<p>A constant to divide the maximum word count by.  Time
is calculated by 'round(exp(WORD COUNT/(max(WORD COUNT)/time.constant)))'.  
Therefore a larger constant will make the difference between the large and 
small word counts greater.</p>
</td></tr>
<tr><td><code id="Animate.discourse_map_+3A_title">title</code></td>
<td>
<p>The title to apply to the animated image(s).</p>
</td></tr>
<tr><td><code id="Animate.discourse_map_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>discourse_map Method for Animate
</p>


<h3>Note</h3>

<p>The width of edges is based on words counts on that edge until that 
moment divided by total number of words used until that moment.  Thicker 
edges tend to thin as time passes.  The actual duration the current edge 
stays as the <code>current.color</code> is based on word counts for that particular 
flow of dialogue divided by total dialogue (words) used.
</p>

<hr>
<h2 id='Animate.formality'>Animate Formality</h2><span id='topic+Animate.formality'></span>

<h3>Description</h3>

<p><code>Animate.formality</code> - Animate a <code><a href="#topic+formality">formality</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality'
Animate(
  x,
  contextual = "yellow",
  formal = "red",
  edge.constant,
  wc.time = TRUE,
  time.constant = 2,
  title = NULL,
  digits = 3,
  current.color = "black",
  current.speaker.color = NULL,
  non.speaker.color = NA,
  missing.color = "purple",
  all.color.line = "red",
  plus.300.color = "grey40",
  under.300.color = "grey88",
  type = "network",
  width = 65,
  coord = c(0, 0.5),
  just = c(0, 0.5),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Animate.formality_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+formality">formality</a></code> object.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_contextual">contextual</code></td>
<td>
<p>The color to use for 0% formality (purely contextual).</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_formal">formal</code></td>
<td>
<p>The color to use for 100% formality (purely formal).</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple edge width by.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_wc.time">wc.time</code></td>
<td>
<p>logical.  If <code>TRUE</code> weights duration of frame by word 
count.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_time.constant">time.constant</code></td>
<td>
<p>A constant to divide the maximum word count by.  Time
is calculated by 'round(exp(WORD COUNT/(max(WORD COUNT)/time.constant)))'.  
Therefore a larger constant will make the difference between the large and 
small word counts greater.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_title">title</code></td>
<td>
<p>The title to apply to the animated image(s).</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_digits">digits</code></td>
<td>
<p>The number of digits to use in the current turn of talk 
formality.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_current.color">current.color</code></td>
<td>
<p>The color to use for the current turn of talk formality.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_current.speaker.color">current.speaker.color</code></td>
<td>
<p>The color for the current speaker.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_non.speaker.color">non.speaker.color</code></td>
<td>
<p>The color for the speakers not currently speaking.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_missing.color">missing.color</code></td>
<td>
<p>The color to use in a network plot for edges 
corresponding to missing text data.  Use <code><a href="stats.html#topic+na.omit">na.omit</a></code> before 
hand to remove the missing values all together.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_all.color.line">all.color.line</code></td>
<td>
<p>The color to use for the total discourse formality 
color line if <code>network = FALSE</code>.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_plus.300.color">plus.300.color</code></td>
<td>
<p>The bar color to use for grouping variables exceeding 
299 words per Heylighen &amp; Dewaele's (2002) minimum word recommendations.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_under.300.color">under.300.color</code></td>
<td>
<p>The bar color to use for grouping variables less 
than 300 words per Heylighen &amp; Dewaele's (2002) minimum word recommendations.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_type">type</code></td>
<td>
<p>Character string of either <code>"network"</code> (as a network 
plot), <code>"bar"</code> (as a bar plot), or <code>"text"</code> (as a simple 
colored text plot).</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_width">width</code></td>
<td>
<p>The width to break text at if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_coord">coord</code></td>
<td>
<p>The x/y coordinate to plot the text if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_just">just</code></td>
<td>
<p>The <code>hjust</code> and <code>vjust</code> values to use for the text if 
<code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.formality_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+discourse_map">discourse_map</a></code> or
<code><a href="ggplot2.html#topic+annotate">annotate</a></code> if <code>type = "text"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>formality Method for Animate
</p>


<h3>Note</h3>

<p>The width of edges is based on words counts on that edge until that 
moment divided by total number of words used until that moment.  Thicker 
edges tend to thin as time passes.  The actual duration the current edge 
stays as the <code>current.color</code> is based on word counts for that particular 
flow of dialogue divided by total dialogue (words) used.  The edge label is
the current formality for that turn of talk (an aggregation of the sub 
sentences of the current turn of talk).  The coloring of the current edge 
formality is produced at th sentence level, therefor a label may indicate a 
positive current turn of talk, while the coloring may indicate a negative 
sentences.  Coloring is based on percentage of formal parts of speech (i.e.,
noun, adjective, preposition, article).
</p>

<hr>
<h2 id='Animate.gantt'>Gantt Durations</h2><span id='topic+Animate.gantt'></span>

<h3>Description</h3>

<p><code>gantt</code> - Animate discourse from <code><a href="#topic+gantt">gantt</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gantt'
Animate(x, wc.time = TRUE, time.constant = 2, colors = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Animate.gantt_+3A_x">x</code></td>
<td>
<p>The gantt object.</p>
</td></tr>
<tr><td><code id="Animate.gantt_+3A_wc.time">wc.time</code></td>
<td>
<p>logical.  If <code>TRUE</code> weights duration of frame by word 
count.</p>
</td></tr>
<tr><td><code id="Animate.gantt_+3A_time.constant">time.constant</code></td>
<td>
<p>A constant to divide the maximum word count by.  Time
is calculated by 'round(exp(WORD COUNT/(max(WORD COUNT)/time.constant)))'.  
Therefore a larger constant will make the difference between the large and 
small word counts greater.</p>
</td></tr>
<tr><td><code id="Animate.gantt_+3A_colors">colors</code></td>
<td>
<p>An optional character vector of colors to color the Gantt bars.
Must be length 1 (repeats the same color) or equal to the levels of the 
grouping variable.</p>
</td></tr>
<tr><td><code id="Animate.gantt_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+gantt_wrap">gantt_wrap</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>gantt Method for Animate
</p>

<hr>
<h2 id='Animate.gantt_plot'>Gantt Plot</h2><span id='topic+Animate.gantt_plot'></span>

<h3>Description</h3>

<p><code>gantt_plot</code> - Animate discourse from <code><a href="#topic+gantt_wrap">gantt_wrap</a></code>,
<code><a href="#topic+gantt_plot">gantt_plot</a></code>, or any other Gantt plotting method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gantt_plot'
Animate(x, wc.time = TRUE, time.constant = 2, colors = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Animate.gantt_plot_+3A_x">x</code></td>
<td>
<p>The gantt_plot object.</p>
</td></tr>
<tr><td><code id="Animate.gantt_plot_+3A_wc.time">wc.time</code></td>
<td>
<p>logical.  If <code>TRUE</code> weights duration of frame by word 
count.</p>
</td></tr>
<tr><td><code id="Animate.gantt_plot_+3A_time.constant">time.constant</code></td>
<td>
<p>A constant to divide the maximum word count by.  Time
is calculated by 'round(exp(WORD COUNT/(max(WORD COUNT)/time.constant)))'.  
Therefore a larger constant will make the difference between the large and 
small word counts greater.</p>
</td></tr>
<tr><td><code id="Animate.gantt_plot_+3A_colors">colors</code></td>
<td>
<p>An optional character vector of colors to color the Gantt bars.
Must be length 1 (repeats the same color) or equal to the levels of the 
grouping variable.</p>
</td></tr>
<tr><td><code id="Animate.gantt_plot_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>gantt_plot Method for Animate
</p>

<hr>
<h2 id='Animate.lexical_classification'>Animate Formality</h2><span id='topic+Animate.lexical_classification'></span>

<h3>Description</h3>

<p><code>Animate.lexical_classification</code> - Animate a 
<code><a href="#topic+lexical_classification">lexical_classification</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification'
Animate(
  x,
  type = "network",
  content = "red",
  functional = "yellow",
  edge.constant,
  wc.time = TRUE,
  time.constant = 2,
  title = NULL,
  digits = 2,
  current.color = "black",
  current.speaker.color = NULL,
  non.speaker.color = NA,
  missing.color = "purple",
  all.color.line = "red",
  width = 65,
  function.words = qdapDictionaries::function.words,
  left = "&lt;&lt;",
  right = "&gt;&gt;",
  coord = c(0, 0.5),
  just = c(0, 0.5),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Animate.lexical_classification_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+lexical_classification">lexical_classification</a></code> object.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_type">type</code></td>
<td>
<p>Character string of either <code>"network"</code> (as a network 
plot), <code>"bar"</code> (as a bar plot), or <code>"text"</code> (as a simple 
colored text plot).</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_content">content</code></td>
<td>
<p>The color to use for 100% lexical_classification (purely 
content).</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_functional">functional</code></td>
<td>
<p>The color to use for 0% lexical_classification (purely 
functional).</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple edge width by.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_wc.time">wc.time</code></td>
<td>
<p>logical.  If <code>TRUE</code> weights duration of frame by word 
count.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_time.constant">time.constant</code></td>
<td>
<p>A constant to divide the maximum word count by.  Time
is calculated by 'round(exp(WORD COUNT/(max(WORD COUNT)/time.constant)))'.  
Therefore a larger constant will make the difference between the large and 
small word counts greater.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_title">title</code></td>
<td>
<p>The title to apply to the animated image(s).</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_digits">digits</code></td>
<td>
<p>The number of digits to use in the current turn of talk's
content rate.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_current.color">current.color</code></td>
<td>
<p>The color to use for the current turn of talk's 
content rate.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_current.speaker.color">current.speaker.color</code></td>
<td>
<p>The color for the current speaker.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_non.speaker.color">non.speaker.color</code></td>
<td>
<p>The color for the speakers not currently speaking.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_missing.color">missing.color</code></td>
<td>
<p>The color to use in a network plot for edges 
corresponding to missing text data.  Use <code><a href="stats.html#topic+na.omit">na.omit</a></code> before 
hand to remove the missing values all together.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_all.color.line">all.color.line</code></td>
<td>
<p>The color to use for the total average discourse 
content rate.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_width">width</code></td>
<td>
<p>The width to break text at if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_function.words">function.words</code></td>
<td>
<p>A vector of function words.  Default is 
<code><a href="qdapDictionaries.html#topic+function.words">function.words</a></code>.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_left">left</code></td>
<td>
<p>A left bound to wrap content words with if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_right">right</code></td>
<td>
<p>A right bound to wrap content words with  if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_coord">coord</code></td>
<td>
<p>The x/y coordinate to plot the test if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_just">just</code></td>
<td>
<p>The <code>hjust</code> and <code>vjust</code> values to use for the text if 
<code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.lexical_classification_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+discourse_map">discourse_map</a></code> or
<code><a href="ggplot2.html#topic+annotate">annotate</a></code> if <code>type = "text"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>lexical_classification Method for Animate
</p>


<h3>Note</h3>

<p>The width of edges is based on words counts on that edge until that 
moment divided by total number of words used until that moment.  Thicker 
edges tend to thin as time passes.  The actual duration the current edge 
stays as the <code>current.color</code> is based on word counts for that particular 
flow of dialogue divided by total dialogue (words) used.  The edge label is
the current content rate for that turn of talk (an aggregation of 
the sub sentences of the current turn of talk).  The coloring of the current 
edge content rate is produced at th sentence level, therefor a label may 
indicate a more content laden current turn of talk, while the coloring may 
indicate a functional laden average of sentences.  Coloring is based on 
percentage of conent words.
</p>

<hr>
<h2 id='Animate.polarity'>Animate Polarity</h2><span id='topic+Animate.polarity'></span>

<h3>Description</h3>

<p><code>Animate.polarity</code> - Animate a <code><a href="#topic+polarity">polarity</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity'
Animate(
  x,
  negative = "blue",
  positive = "red",
  neutral = "yellow",
  edge.constant,
  wc.time = TRUE,
  time.constant = 2,
  title = NULL,
  digits = 3,
  width = 65,
  current.color = "black",
  current.speaker.color = NULL,
  non.speaker.color = NA,
  ave.color.line = "red",
  type = "network",
  coord = c(0, 0.5),
  just = c(0, 0.5),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Animate.polarity_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+polarity">polarity</a></code> object.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_negative">negative</code></td>
<td>
<p>The color to use for negative polarity.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_positive">positive</code></td>
<td>
<p>The color to use for positive polarity.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_neutral">neutral</code></td>
<td>
<p>The color to use for neutral polarity.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple edge width by.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_wc.time">wc.time</code></td>
<td>
<p>logical.  If <code>TRUE</code> weights duration of frame by word 
count.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_time.constant">time.constant</code></td>
<td>
<p>A constant to divide the maximum word count by.  Time
is calculated by 'round(exp(WORD COUNT/(max(WORD COUNT)/time.constant)))'.  
Therefore a larger constant will make the difference between the large and 
small word counts greater.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_title">title</code></td>
<td>
<p>The title to apply to the animated image(s).</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_digits">digits</code></td>
<td>
<p>The number of digits to use in the current turn of talk 
polarity.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_width">width</code></td>
<td>
<p>The width to break text at if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_current.color">current.color</code></td>
<td>
<p>The color to use for the current turn of talk polarity.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_current.speaker.color">current.speaker.color</code></td>
<td>
<p>The color for the current speaker.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_non.speaker.color">non.speaker.color</code></td>
<td>
<p>The color for the speakers not currently speaking.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_ave.color.line">ave.color.line</code></td>
<td>
<p>The color to use for the average color line if 
<code>type = "network"</code>.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_type">type</code></td>
<td>
<p>Character string of either <code>"network"</code> (as a network 
plot), <code>"bar"</code> (as a bar plot), or <code>"text"</code> (as a simple 
colored text plot).</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_coord">coord</code></td>
<td>
<p>The x/y coordinate to plot the test if <code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_just">just</code></td>
<td>
<p>The <code>hjust</code> and <code>vjust</code> values to use for the text if 
<code>type = "text"</code>.</p>
</td></tr>
<tr><td><code id="Animate.polarity_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+discourse_map">discourse_map</a></code> or
<code><a href="ggplot2.html#topic+annotate">annotate</a></code> if <code>type = "text"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>polarity Method for Animate
</p>


<h3>Note</h3>

<p>The width of edges is based on words counts on that edge until that 
moment divided by total number of words used until that moment.  Thicker 
edges tend to thin as time passes.  The actual duration the current edge 
stays as the <code>current.color</code> is based on word counts for that particular 
flow of dialogue divided by total dialogue (words) used.  The edge label is
the current polarity for that turn of talk (an aggregation of the sub 
sentences of the current turn of talk).  The coloring of the current edge 
polarity is produced at th sentence level, therefor a label may indicate a 
positive current turn of talk, while the coloring may indicate a negative 
sentences.
</p>

<hr>
<h2 id='as.tdm'>tm Package Compatibility Tools: Apply to or Convert to/from Term Document 
Matrix or Document Term Matrix</h2><span id='topic+as.tdm'></span><span id='topic+as.TermDocumentMatrix'></span><span id='topic+as.dtm'></span><span id='topic+as.DocumentTermMatrix'></span><span id='topic+as.tdm.Corpus'></span><span id='topic+as.tdm.default'></span><span id='topic+as.tdm.character'></span><span id='topic+as.dtm.Corpus'></span><span id='topic+as.dtm.default'></span><span id='topic+as.dtm.character'></span><span id='topic+as.tdm.wfm'></span><span id='topic+as.dtm.wfm'></span><span id='topic+as.data.frame.Corpus'></span><span id='topic+as.Corpus'></span><span id='topic+as.Corpus.sent_split'></span><span id='topic+as.Corpus.default'></span><span id='topic+apply_as_tm'></span><span id='topic+apply_as_df'></span><span id='topic+as.Corpus.TermDocumentMatrix'></span><span id='topic+as.Corpus.DocumentTermMatrix'></span><span id='topic+as.Corpus.wfm'></span>

<h3>Description</h3>

<p><code>as.tdm</code> - Create term document matrices from raw text or 
<code><a href="#topic+wfm">wfm</a></code> for use with other text analysis packages.
</p>
<p><code>as.TermDocumentMatrix</code> - Create document term matrices from raw text or 
<code><a href="#topic+wfm">wfm</a></code> for use with other text analysis packages.
</p>
<p><code>as.dtm</code> - Create document term matrices from raw text or 
<code><a href="#topic+wfm">wfm</a></code> for use with other text analysis packages.
</p>
<p><code>as.DocumentTermMatrix</code> - Create document term matrices from raw text or 
<code><a href="#topic+wfm">wfm</a></code> for use with other text analysis packages.
</p>
<p><code>as.data.frame</code> - Convert a <span class="pkg">tm</span> package <code><a href="tm.html#topic+Corpus">Corpus</a></code> to 
a <span class="pkg">qdap</span> <code><a href="base.html#topic+data.frame">data.frame</a></code>.
</p>
<p><code>as.Corpus</code> - Attempts to convert its argument into a <span class="pkg">tm</span> package 
<code><a href="tm.html#topic+Corpus">Corpus</a></code>.
</p>
<p><code>apply_as_tm</code> - Apply functions intended to be used on the <span class="pkg">tm</span> 
package's <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code> to a <code><a href="#topic+wfm">wfm</a></code> 
object.
</p>
<p><code>apply_as_df</code> - Apply a <span class="pkg">tm</span> <code><a href="tm.html#topic+Corpus">Corpus</a></code> as a qdap 
dataframe.
<code>apply_as_df</code> - Apply functions intended to be used on the <span class="pkg">qdap</span> 
package's <code><a href="base.html#topic+data.frame">data.frame</a></code> + <code><a href="#topic+sentSplit">sentSplit</a></code> to 
a <span class="pkg">tm</span> <code><a href="tm.html#topic+Corpus">Corpus</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.tdm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

as.TermDocumentMatrix(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

as.dtm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

as.DocumentTermMatrix(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## S3 method for class 'Corpus'
as.tdm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## Default S3 method:
as.tdm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## S3 method for class 'character'
as.tdm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## S3 method for class 'Corpus'
as.dtm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## Default S3 method:
as.dtm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## S3 method for class 'character'
as.dtm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## S3 method for class 'wfm'
as.tdm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## S3 method for class 'wfm'
as.dtm(text.var, grouping.var = NULL, vowel.check = TRUE, ...)

## S3 method for class 'Corpus'
as.data.frame(
  x,
  row.names,
  optional,
  ...,
  doc = "doc_id",
  text = "text",
  sent.split = FALSE
)

as.Corpus(text.var, grouping.var = NULL, demographic.vars, ...)

## S3 method for class 'sent_split'
as.Corpus(text.var, grouping.var = NULL, demographic.vars, ...)

## Default S3 method:
as.Corpus(text.var, grouping.var = NULL, demographic.vars, ...)

apply_as_tm(wfm.obj, tmfun, ..., to.qdap = TRUE)

apply_as_df(
  tm.corpus,
  qdapfun,
  ...,
  stopwords = NULL,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  ignore.case = TRUE
)

## S3 method for class 'TermDocumentMatrix'
as.Corpus(text.var, ...)

## S3 method for class 'DocumentTermMatrix'
as.Corpus(text.var, ...)

## S3 method for class 'wfm'
as.Corpus(text.var, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.tdm_+3A_text.var">text.var</code></td>
<td>
<p>The text variable or a <code><a href="#topic+wfm">wfm</a></code> object.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_vowel.check">vowel.check</code></td>
<td>
<p>logical.  Should terms without vowels be remove?</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_x">x</code></td>
<td>
<p>A <code><a href="tm.html#topic+Corpus">Corpus</a></code> object.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_row.names">row.names</code></td>
<td>
<p><code>NULL</code> or a character vector giving the row names for 
the data frame. Not used in <span class="pkg">qdap</span>; for base generic consistency.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_optional">optional</code></td>
<td>
<p>logical. If <code>TRUE</code>, setting row names and converting 
column names is optional. Not used in <span class="pkg">qdap</span>; for base generic consistency.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_doc">doc</code></td>
<td>
<p>Name for <code><a href="tm.html#topic+Corpus">Corpus</a></code> documents.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_text">text</code></td>
<td>
<p>Name for <code><a href="tm.html#topic+Corpus">Corpus</a></code> text.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_sent.split">sent.split</code></td>
<td>
<p>logical.  If <code>TRUE</code> the text variable sentences will 
be split into individual rows.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_demographic.vars">demographic.vars</code></td>
<td>
<p>Additional demographic information about the grouping 
variables.  This is a data.frame, list of equal length vectors, or a single 
vector corresponding to the grouping variable/text variable.  This 
information will be mapped to the DMetaData in the <code><a href="tm.html#topic+Corpus">Corpus</a></code>.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_wfm.obj">wfm.obj</code></td>
<td>
<p>A <code><a href="#topic+wfm">wfm</a></code> object.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_tmfun">tmfun</code></td>
<td>
<p>A function applied to a <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code>
object.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_to.qdap">to.qdap</code></td>
<td>
<p>logical.  If <code>TRUE</code> should <code><a href="#topic+wfm">wfm</a></code> try to
coerce the output back to a qdap object.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_tm.corpus">tm.corpus</code></td>
<td>
<p>A <code><a href="tm.html#topic+Corpus">Corpus</a></code> object.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_qdapfun">qdapfun</code></td>
<td>
<p>A qdap function that is usually used on 
text.variable ~ grouping variable.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_stopwords">stopwords</code></td>
<td>
<p>A character vector of words to remove from the text.  qdap 
has a number of data sets that can be used as stop words including: 
<code>Top200Words</code>, <code>Top100Words</code>, <code>Top25Words</code>.  For the tm 
package's traditional English stop words use <code>tm::stopwords("english")</code>.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_min">min</code></td>
<td>
<p>Minimum word length.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_max">max</code></td>
<td>
<p>Maximum word length.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_count.apostrophe">count.apostrophe</code></td>
<td>
<p>logical.  If <code>TRUE</code> apostrophes are counted as 
characters.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> stop words will be removed 
regardless of case.</p>
</td></tr>
<tr><td><code id="as.tdm_+3A_...">...</code></td>
<td>
<p>Function dependant:
</p>

<ul>
<li> <p><b>as.tdm</b> or <b>as.dtm</b> - Other arguments passed to <code>wfm</code>
</p>
</li>
<li> <p><b>apply_as_tm</b> - Other arguments passed to functions used on a <span class="pkg">tm</span> <code>TermDocumentMatrix</code>
</p>
</li>
<li> <p><b>as.data.frame</b> - Other arguments passed to <code><a href="#topic+sentSplit">sentSplit</a></code>
</p>
</li>
<li> <p><b>as.Corpus</b> - Other arguments passed to <span class="pkg">tm</span>'s <code><a href="tm.html#topic+Corpus">Corpus</a></code>
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces output that is identical to the <code>tm</code> package's 
<code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code>, <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>,
<code><a href="tm.html#topic+Corpus">Corpus</a></code> or allows convenient interface between the qdap and 
tm packages.
</p>


<h3>Value</h3>

<p><code>as.tdm</code> - Returns a <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code>.
</p>
<p><code>as.TermDocumentMatrix</code> - Returns a 
<code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code>.
</p>
<p><code>as.dtm</code> - Returns a <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.
</p>
<p><code>as.DocumentTermMatrix</code> - Returns a 
<code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code>.
</p>
<p><code>as.data.frame</code> - Converts a <code><a href="tm.html#topic+Corpus">Corpus</a></code> and returns 
a <span class="pkg">qdap</span> oriented <code><a href="base.html#topic+data.frame">data.frame</a></code>.
</p>
<p><code>as.Corpus</code> - Converts a qdap oriented dataframe and returns 
a <code><a href="tm.html#topic+Corpus">Corpus</a></code>.
</p>
<p><code>apply_as_tm</code> - Applies a tm oriented function to a 
<code><a href="#topic+wfm">wfm</a></code> and attempts to simplify back to a 
<code><a href="#topic+wfm">wfm</a></code> or <code>weight</code> format.
</p>
<p><code>apply_as_df</code> - Returns the output typical of the applied 
<span class="pkg">qdap</span> function.
</p>


<h3>Note</h3>

<p><code>aply_as_df</code> coerces to a dataframe with columns named 'docs' and 
the other named 'text'.
</p>


<h3>See Also</h3>

<p><code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>,
<code><a href="tm.html#topic+Corpus">Corpus</a></code>,
<code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code>,
<code><a href="#topic+as.wfm">as.wfm</a></code>
</p>
<p><code><a href="#topic+Filter">Filter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
as.dtm(DATA$state, DATA$person)
as.tdm(DATA$state, DATA$person)

x &lt;- wfm(DATA$state, DATA$person)
as.tdm(x)
as.dtm(x)
library(tm)
plot(as.tdm(x))

pres &lt;- as.tdm(pres_debates2012$dialogue, pres_debates2012$person)
plot(pres, corThreshold = 0.8)
pres
(pres2 &lt;- removeSparseTerms(pres, .3))
plot(pres2, corThreshold = 0.95)

shorts &lt;- all_words(pres_debates2012)[,1][nchar(all_words(
    pres_debates2012)[,1]) &lt; 4]

SW &lt;- c(shorts, qdapDictionaries::contractions[, 1],
    qdapDictionaries::Top200Words,
    "governor", "president", "mister", "obama","romney")

DocTermMat2 &lt;- with(pres_debates2012, as.dtm(dialogue, list(person, time), stopwords = SW))
DocTermMat2 &lt;- removeSparseTerms(DocTermMat2,0.95)
(DocTermMat2 &lt;- DocTermMat2[rowSums(as.matrix(DocTermMat2))&gt; 0,])
plot(DocTermMat2)
    
## Correspondence Analysis
library(ca)

dat &lt;- pres_debates2012
dat &lt;- dat[dat$person %in% qcv(ROMNEY, OBAMA), ]

speech &lt;- stemmer(dat$dialogue)
mytable1 &lt;- with(dat, as.tdm(speech, list(person, time), stopwords = Top25Words))

fit &lt;- ca(as.matrix(mytable1))
summary(fit)
plot(fit)
plot3d.ca(fit, labels=1)


mytable2 &lt;- with(dat, as.tdm(speech, list(person, time), stopwords = Top200Words))

fit2 &lt;- ca(as.matrix(mytable2))
summary(fit2)
plot(fit2)
plot3d.ca(fit2, labels=1)

## Topic Models
# Example 1 #
library(topicmodels); library(tm)

# Generate stop words based on short words, frequent words and contractions
shorts &lt;- all_words(pres_debates2012)[,1][nchar(all_words(
    pres_debates2012)[,1]) &lt; 4]
    
SW &lt;- c(shorts, qdapDictionaries::contractions[, 1], 
    qdapDictionaries::Top200Words, 
    "governor", "president", "mister", "obama","romney")
    
DocTermMat &lt;- with(pres_debates2012, as.dtm(dialogue, person, stopwords = SW))
DocTermMat &lt;- removeSparseTerms(DocTermMat,0.999)
DocTermMat &lt;- DocTermMat[rowSums(as.matrix(DocTermMat))&gt; 0,]

lda.model &lt;- LDA(DocTermMat, 5)

(topics &lt;- posterior(lda.model, DocTermMat)$topics)
terms(lda.model,20)

# Plot the Topics Per Person
topic.dat &lt;- matrix2df(topics, "Person")
colnames(topic.dat)[-1] &lt;- paste2(t(terms(lda.model,20)), sep=", ")

library(reshape2)
mtopic &lt;- melt(topic.dat, variable="Topic", value.name="Proportion")
ggplot(mtopic, aes(weight=Proportion, x=Topic, fill=Topic)) + 
    geom_bar() + 
    coord_flip() +
    facet_grid(Person~.) +
    guides(fill=FALSE)

# Example 2 #
DocTermMat2 &lt;- with(pres_debates2012, as.dtm(dialogue, list(person, time), stopwords = SW))
DocTermMat2 &lt;- removeSparseTerms(DocTermMat2,0.95)
DocTermMat2 &lt;- DocTermMat2[rowSums(as.matrix(DocTermMat2))&gt; 0,]

lda.model2 &lt;- LDA(DocTermMat2, 6)

(topics2 &lt;- posterior(lda.model2, DocTermMat2)$topics)
terms(lda.model2,20)
qheat(topics2, high="blue", low="yellow", by.col=FALSE)

# Example 3 #
lda.model3 &lt;- LDA(DocTermMat2, 10)

(topics3 &lt;- posterior(lda.model3, DocTermMat2)$topics)
terms(lda.model3, 20)
qheat(topics3, high="blue", low="yellow", by.col=FALSE)

# Plot the Topics Per Person
topic.dat3 &lt;- matrix2df(topics3, "Person&amp;Time")
colnames(topic.dat3)[-1] &lt;- paste2(t(terms(lda.model3, 10)), sep=", ")
topic.dat3 &lt;- colsplit2df(topic.dat3)

library(reshape2)
library(scales)
mtopic3 &lt;- melt(topic.dat3, variable="Topic", value.name="Proportion")
(p1 &lt;- ggplot(mtopic3, aes(weight=Proportion, x=Topic, fill=Topic)) +
    geom_bar() +
    coord_flip() +
    facet_grid(Person~Time) +
    guides(fill=FALSE) +
    scale_y_continuous(labels = percent) +
    theme(plot.margin = unit(c(1, 0, 0.5, .5), "lines")) +
    ylab("Proportion")) 

mtopic3.b &lt;- mtopic3
mtopic3.b[, "Topic"] &lt;- factor(as.numeric(mtopic3.b[, "Topic"]), levels = 1:10)
mtopic3.b[, "Time"] &lt;- factor(gsub("time ", "", mtopic3.b[, "Time"]))

p2 &lt;- ggplot(mtopic3.b, aes(x=Time, y=Topic, fill=Proportion)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "grey70", high = "red") +
    facet_grid(Person~Time, scales = "free") +
    theme(axis.title.y = element_blank(),
        axis.text.x= element_text(colour="white"),
        axis.ticks.x= element_line(colour="white"),
        axis.ticks.y = element_blank(),
        axis.text.y= element_blank(),
        plot.margin = unit(c(1, -.5, .5, -.9), "lines")
) 

library(gridExtra)
grid.arrange(p1, p2, nrow=1, widths = grid::unit(c(.85, .15), "native")) 
    
## tm Matrices to wfm
library(tm)
data(crude)

## A Term Document Matrix Conversion
(tm_in &lt;- TermDocumentMatrix(crude, control = list(stopwords = TRUE)))
converted &lt;- as.wfm(tm_in)
head(converted)
summary(converted)

## A Document Term Matrix Conversion
(dtm_in &lt;- DocumentTermMatrix(crude, control = list(stopwords = TRUE)))
summary(as.wfm(dtm_in))

## `apply_as_tm` Examples
## Create a wfm
a &lt;- with(DATA, wfm(state, list(sex, adult)))
summary(a)

## Apply functions meant for a tm TermDocumentMatrix
out &lt;- apply_as_tm(a, tm:::removeSparseTerms, sparse=0.6)
summary(out)

apply_as_tm(a, tm:::findAssocs, "computer", .8)
apply_as_tm(a, tm:::findFreqTerms, 2, 3)
apply_as_tm(a, tm:::Zipf_plot)
apply_as_tm(a, tm:::Heaps_plot)
apply_as_tm(a, tm:::plot.TermDocumentMatrix, corThreshold = 0.4)

library(proxy)
apply_as_tm(a, tm:::weightBin)
apply_as_tm(a, tm:::weightBin, to.qdap = FALSE)
apply_as_tm(a, tm:::weightSMART)
apply_as_tm(a, tm:::weightTfIdf)

## Convert tm Corpus to Dataframe
## A tm Corpus
library(tm)
reut21578 &lt;- system.file("texts", "crude", package = "tm")
reuters &lt;- Corpus(DirSource(reut21578),
    readerControl = list(reader = readReut21578XML))

## Convert to dataframe
corp_df &lt;- as.data.frame(reuters)
htruncdf(corp_df)

z &lt;- as.Corpus(DATA$state, DATA$person, 
       demographic=DATA[, qcv(sex, adult, code)])
as.data.frame(z)

## Apply a qdap function
out &lt;- formality(corp_df$text, corp_df$docs)
plot(out)

## Convert a qdap dataframe to tm package Corpus
(x &lt;- with(DATA2, as.Corpus(state, list(person, class, day))))
library(tm)
inspect(x)
inspect_text(x)
class(x)

(y &lt;- with(pres_debates2012, as.Corpus(dialogue, list(person, time))))

## Add demographic info to DMetaData of Corpus
z &lt;- as.Corpus(DATA$state, DATA$person, 
    demographic=DATA[, qcv(sex, adult, code)])
lview(z)

lview(as.Corpus(DATA$state, DATA$person,
    demographic=DATA$sex))

lview(as.Corpus(DATA$state, DATA$person,
    demographic=list(DATA$sex, DATA$adult)))

## Apply qdap functions meant for dataframes from sentSplit to tm Corpus
library(tm)
reut21578 &lt;- system.file("texts", "crude", package = "tm")
reuters &lt;- Corpus(DirSource(reut21578),
    readerControl = list(reader = readReut21578XML))

matches &lt;- list(
    oil = qcv(oil, crude),
    money = c("economic", "money")
)

apply_as_df(reuters, word_stats)
apply_as_df(reuters, formality)
apply_as_df(reuters, word_list)
apply_as_df(reuters, polarity)
apply_as_df(reuters, Dissimilarity)
apply_as_df(reuters, diversity)
apply_as_df(reuters, pos_by)
apply_as_df(reuters, flesch_kincaid)
apply_as_df(reuters, trans_venn)
apply_as_df(reuters, gantt_plot)
apply_as_df(reuters, rank_freq_mplot)
apply_as_df(reuters, character_table)

(termco_out &lt;- apply_as_df(reuters, termco, match.list = matches))
plot(termco_out, values = TRUE, high="red")

(wordcor_out &lt;- apply_as_df(reuters, word_cor, word = unlist(matches)))
plot(wordcor_out)

(f_terms &lt;- apply_as_df(reuters, freq_terms, at.least = 3))
plot(f_terms)

apply_as_df(reuters, trans_cloud)
## To use "all" rather than "docs" as "grouping.var"...
apply_as_df(reuters, trans_cloud, grouping.var=NULL, 
    target.words=matches, cloud.colors = c("red", "blue", "grey75"))

finds &lt;- apply_as_df(reuters, freq_terms, at.least = 5,
    top = 5, stopwords = Top100Words)
apply_as_df(reuters, dispersion_plot, match.terms = finds[, 1],
    total.color = NULL)
    
## Filter for Term Document Matrix/Document Term Matrix
library(tm)
data(crude)

(tdm_in &lt;- TermDocumentMatrix(crude, control = list(stopwords = TRUE)))
Filter(tdm_in, 5)

(dtm_in &lt;- DocumentTermMatrix(crude, control = list(stopwords = TRUE)))
Filter(dtm_in, 5)

## Filter particular words based on max/min values
Filter(dtm_in, 5, 7)
Filter(dtm_in, 4, 4)
Filter(tdm_in, 3, 4)
Filter(tdm_in, 3, 4, stopwords = Top200Words)

## SPECIAL REMOVAL OF TERMS (more flexible consideration of words than wfm)
dat &lt;- data.frame(
    person = paste0("person_", 1:5),
    tweets = c("test one two", "two apples","hashtag #apple", 
        "#apple #tree", "http://microsoft.com")
)

## remove specialty items
dat[[2]] &lt;- rm_default(dat[[2]], pattern=pastex("@rm_url", "#apple\\b"))


myCorp &lt;- tm::tm_map(crude, tm::removeWords, Top200Words)
myCorp %&gt;% as.dtm() %&gt;% tm::inspect()

## End(Not run)
</code></pre>

<hr>
<h2 id='automated_readability_index'>Readability Measures</h2><span id='topic+automated_readability_index'></span><span id='topic+coleman_liau'></span><span id='topic+SMOG'></span><span id='topic+flesch_kincaid'></span><span id='topic+fry'></span><span id='topic+linsear_write'></span>

<h3>Description</h3>

<p><code>automated_readability_index</code> - Apply Automated Readability Index to 
transcript(s) by zero or more grouping variable(s).
</p>
<p><code>coleman_liau</code> - Apply Coleman Liau Index to transcript(s) by zero or 
more grouping variable(s).
</p>
<p><code>SMOG</code> - Apply SMOG Readability to transcript(s) by zero or more grouping variable(s).
</p>
<p><code>flesch_kincaid</code> - Flesch-Kincaid Readability to transcript(s) by zero or more 
grouping variable(s).
</p>
<p><code>fry</code> - Apply Fry Readability to transcript(s) by zero or more 
grouping variable(s).
</p>
<p><code>linsear_write</code> - Apply Linsear Write Readability to transcript(s) by 
zero or more grouping variable(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>automated_readability_index(
  text.var,
  grouping.var = NULL,
  rm.incomplete = FALSE,
  ...
)

coleman_liau(text.var, grouping.var = NULL, rm.incomplete = FALSE, ...)

SMOG(
  text.var,
  grouping.var = NULL,
  output = "valid",
  rm.incomplete = FALSE,
  ...
)

flesch_kincaid(text.var, grouping.var = NULL, rm.incomplete = FALSE, ...)

fry(
  text.var,
  grouping.var = NULL,
  rm.incomplete = FALSE,
  auto.label = TRUE,
  grid = FALSE,
  div.col = "grey85",
  plot = TRUE,
  ...
)

linsear_write(text.var, grouping.var = NULL, rm.incomplete = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="automated_readability_index_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="automated_readability_index_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one output for all text.  Also takes a single grouping variable or a list of 1 
or more grouping variables.</p>
</td></tr>
<tr><td><code id="automated_readability_index_+3A_rm.incomplete">rm.incomplete</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes incomplete sentences 
from the analysis.</p>
</td></tr>
<tr><td><code id="automated_readability_index_+3A_output">output</code></td>
<td>
<p>A character vector character string indicating output type. 
One of &quot;valid&quot; (default and congruent with McLaughlin's intent) or &quot;all&quot;.</p>
</td></tr>
<tr><td><code id="automated_readability_index_+3A_auto.label">auto.label</code></td>
<td>
<p>logical.  If <code>TRUE</code> labels automatically added.  If 
<code>FALSE</code> the user clicks interactively.</p>
</td></tr>
<tr><td><code id="automated_readability_index_+3A_grid">grid</code></td>
<td>
<p>logical.  If <code>TRUE</code> a micro grid is displayed, similar to 
Fry's original depiction, though this may make visualizing more difficult.</p>
</td></tr>
<tr><td><code id="automated_readability_index_+3A_div.col">div.col</code></td>
<td>
<p>The color of the grade level division lines.</p>
</td></tr>
<tr><td><code id="automated_readability_index_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> a graph is plotted corresponding to Fry's 
graphic representation.</p>
</td></tr>
<tr><td><code id="automated_readability_index_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+end_inc">end_inc</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of 2 dataframes: (1) Counts and (2) Readability.  
Counts are the raw scores used to calculate readability score and can be
accessed via <code><a href="#topic+counts">counts</a></code>.  Readability is the dataframe
with the selected readability statistic by grouping variable(s) and can be 
access via <code><a href="#topic+scores">scores</a></code>.  The <code><a href="#topic+fry">fry</a></code> function 
returns a graphic representation of the readability as the 
<code><a href="#topic+scores">scores</a></code> returns the information for graphing but not a
readability score.
</p>


<h3>Warning</h3>

<p>Many of the indices (e.g., Automated Readability Index) 
are derived from word difficulty (letters per word) and sentence difficulty 
(words per sentence).  If you have not run the sentSplit function on your 
data the results may not be accurate.
</p>


<h3>Fry</h3>

<p>The <code>fry</code> function is based on Fry's formula that randomly 
samples 3 100 word length passages.  If a group(s) in does not contain 300+ 
words they will not be included in the output.
</p>


<h3>References</h3>

<p>Coleman, M., &amp; Liau, T. L. (1975). A computer readability formula 
designed for machine scoring. Journal of Applied Psychology, Vol. 60, 
pp. 283-284.
</p>
<p>Fry, E. B. (1968). A readability formula that saves time. Journal of Reading,
11(7), 513-516, 575-578.
</p>
<p>Fry, E. B. (1969). The readability graph validated at primary levels. The Reading
Teacher, 22(6), 534-538.
</p>
<p>Flesch R. (1948). A new readability yardstick. Journal of Applied Psychology. 
Vol. 32(3), pp. 221-233. doi: 10.1037/h0057532.
</p>
<p>Gunning, T. G. (2003). Building Literacy in the Content Areas. Boston: Allyn 
&amp; Bacon.
</p>
<p>McLaughlin, G. H. (1969). SMOG Grading: A New Readability Formula. 
Journal of Reading, Vol. 12(8), pp. 639-646. 
</p>
<p>Smith, E. A. &amp; Senter, R. J. (1967) Automated readability index. 
Technical Report AMRLTR-66-220, University of Cincinnati, Cincinnati, Ohio.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
AR1 &lt;- with(rajSPLIT, automated_readability_index(dialogue, list(person, act)))
ltruncdf(AR1,, 15)
scores(AR1)
counts(AR1)
plot(AR1)
plot(counts(AR1))

AR2 &lt;- with(rajSPLIT, automated_readability_index(dialogue, list(sex, fam.aff)))
ltruncdf(AR2,, 15)
scores(AR2)
counts(AR2)
plot(AR2)
plot(counts(AR2))

AR3 &lt;- with(rajSPLIT, automated_readability_index(dialogue, person))
ltruncdf(AR3,, 15)
scores(AR3)
head(counts(AR3))
plot(AR3)
plot(counts(AR3))

CL1 &lt;- with(rajSPLIT, coleman_liau(dialogue, list(person, act)))
ltruncdf(CL1, 20)
head(counts(CL1))
plot(CL1)

CL2 &lt;- with(rajSPLIT, coleman_liau(dialogue, list(sex, fam.aff)))
ltruncdf(CL2)
plot(counts(CL2))

(SM1 &lt;- with(rajSPLIT, SMOG(dialogue, list(person, act))))
plot(counts(SM1))
plot(SM1)

(SM2 &lt;- with(rajSPLIT, SMOG(dialogue, list(sex, fam.aff))))

(FL1 &lt;- with(rajSPLIT, flesch_kincaid(dialogue, list(person, act))))
plot(scores(FL1))
plot(counts(FL1))

(FL2 &lt;-  with(rajSPLIT, flesch_kincaid(dialogue, list(sex, fam.aff))))
plot(scores(FL2))
plot(counts(FL2))

FR1 &lt;- with(rajSPLIT, fry(dialogue, list(sex, fam.aff)))
scores(FR1)
plot(scores(FR1))
counts(FR1)
plot(counts(FR1))

FR2 &lt;- with(rajSPLIT, fry(dialogue, person))
scores(FR2)
plot(scores(FR2))
counts(FR2)
plot(counts(FR2))

FR3 &lt;- with(pres_debates2012, fry(dialogue, list(time, person)))
colsplit2df(scores(FR3))
plot(scores(FR3), auto.label = FALSE)
counts(FR3)
plot(counts(FR3))

library(ggplot2)
ggplot(colsplit2df(counts(FR3)), aes(sent.per.100.wrds, 
    syllables.per.100.wrds)) +
    geom_point(aes(fill=person), shape=21, size=3) +
    facet_grid(person~time)
    
LW1 &lt;- with(rajSPLIT, linsear_write(dialogue, list(person, act)))
plot(scores(LW1))
plot(counts(LW1))

LW2 &lt;- with(rajSPLIT, linsear_write(dialogue, list(sex, fam.aff)))
plot(scores(LW2), method="lm")
plot(counts(LW2))

## End(Not run)
</code></pre>

<hr>
<h2 id='bag_o_words'>Bag of Words</h2><span id='topic+bag_o_words'></span><span id='topic+unbag'></span><span id='topic+breaker'></span><span id='topic+word_split'></span>

<h3>Description</h3>

<p><code>bag_o_words</code> - Reduces a text column to a bag of words.
</p>
<p><code>unbag</code> - Wrapper for <code>paste(collapse=" ")</code> to glue words back into 
strings.
</p>
<p><code>breaker</code> - Reduces a text column to a bag of words and qdap recognized 
end marks.
</p>
<p><code>word_split</code> - Reduces a text column to a list of vectors of bag of 
words and qdap recognized end marks (i.e., <code>".", "!", "?", "*", "-"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bag_o_words(text.var, apostrophe.remove = FALSE, ...)

unbag(text.var, na.rm = TRUE)

breaker(text.var)

word_split(text.var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bag_o_words_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="bag_o_words_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophe's from 
the output.</p>
</td></tr>
<tr><td><code id="bag_o_words_+3A_na.rm">na.rm</code></td>
<td>
<p>logical.  If <code>TRUE</code> <code>NA</code>s are removed before pasting.</p>
</td></tr>
<tr><td><code id="bag_o_words_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to strip.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of stripped words.
</p>
<p><code>unbag</code> - Returns a string.
</p>
<p><code>breaker</code> - Returns a vector of striped words and qdap 
recognized endmarks (i.e., <code>".", "!", "?", "*", "-"</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
bag_o_words("I'm going home!")
bag_o_words("I'm going home!", apostrophe.remove = TRUE)
unbag(bag_o_words("I'm going home!"))

bag_o_words(DATA$state)
by(DATA$state, DATA$person, bag_o_words)
lapply(DATA$state,  bag_o_words)

breaker(DATA$state)
by(DATA$state, DATA$person, breaker)
lapply(DATA$state,  breaker)
unbag(breaker(DATA$state))

word_split(c(NA, DATA$state))
unbag(word_split(c(NA, DATA$state)))

## End(Not run)
</code></pre>

<hr>
<h2 id='beg2char'>Grab Begin/End of String to Character</h2><span id='topic+beg2char'></span><span id='topic+char2end'></span>

<h3>Description</h3>

<p><code>beg2char</code> - Grab from beginning of string to a character(s).
</p>
<p><code>char2end</code> - Grab from character(s) to end of string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beg2char(text.var, char = " ", noc = 1, include = FALSE)

char2end(text.var, char = " ", noc = 1, include = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beg2char_+3A_text.var">text.var</code></td>
<td>
<p>A character string</p>
</td></tr>
<tr><td><code id="beg2char_+3A_char">char</code></td>
<td>
<p>The character from which to grab until/from.</p>
</td></tr>
<tr><td><code id="beg2char_+3A_noc">noc</code></td>
<td>
<p>Number of times the character appears before the grab.</p>
</td></tr>
<tr><td><code id="beg2char_+3A_include">include</code></td>
<td>
<p>logical.  If <code>TRUE</code> includes the character in the grab.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a vector of text with char on/forward removed.
</p>


<h3>Author(s)</h3>

<p>Josh O'Brien, Justin Haynes and Tyler Rinker &lt;tyler.rinker@gmail.com&gt;.
</p>


<h3>References</h3>

<p>https://stackoverflow.com/q/15909626/1000343
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("a_b_c_d", "1_2_3_4", "&lt;_?_._:")
beg2char(x, "_")
beg2char(x, "_", 2)
beg2char(x, "_", 3)
beg2char(x, "_", 4)
beg2char(x, "_", 3, include=TRUE)

char2end(x, "_")
char2end(x, "_", 2)
char2end(x, "_", 3)
char2end(x, "_", 4)
char2end(x, "_", 3, include=TRUE)

x2 &lt;- gsub("_", " ", x)
char2end(x2, " ", 2)
beg2char(x2, " ", 2)

x3 &lt;- gsub("_", "\\^", x)
char2end(x3, "^", 2)
beg2char(x3, "^", 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='blank2NA'>Replace Blanks in a dataframe</h2><span id='topic+blank2NA'></span>

<h3>Description</h3>

<p>Replaces blank (empty) cells in a dataframe.  Generally, for internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blank2NA(dataframe, missing = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blank2NA_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe with blank (empty) cells.</p>
</td></tr>
<tr><td><code id="blank2NA_+3A_missing">missing</code></td>
<td>
<p>Value to replace empty cells with.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame with blank spaces replaced.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rm_row">rm_row</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(15)
dat &lt;- data.frame(matrix(sample(c(month.abb[1:4], ""), 50, TRUE), 
    10, byrow = TRUE), stringsAsFactors = FALSE)

dat
blank2NA(dat)

## End(Not run)
</code></pre>

<hr>
<h2 id='bracketX'>Bracket Parsing</h2><span id='topic+bracketX'></span><span id='topic+bracketXtract'></span><span id='topic+genX'></span><span id='topic+genXtract'></span>

<h3>Description</h3>

<p><code>bracketX</code> - Apply bracket removal to character vectors.
</p>
<p><code>bracketXtract</code> - Apply bracket extraction to character vectors.
</p>
<p><code>genX</code> - Apply general chunk removal to character vectors.  A 
generalized version of <code>bracketX</code>.
</p>
<p><code>genXtract</code> - Apply general chunk extraction to character vectors.   A 
generalized version of <code>bracketXtract</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bracketX(
  text.var,
  bracket = "all",
  missing = NULL,
  names = FALSE,
  fix.space = TRUE,
  scrub = fix.space
)

bracketXtract(text.var, bracket = "all", with = FALSE, merge = TRUE)

genX(
  text.var,
  left,
  right,
  missing = NULL,
  names = FALSE,
  fix.space = TRUE,
  scrub = TRUE
)

genXtract(text.var, left, right, with = FALSE, merge = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bracketX_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="bracketX_+3A_bracket">bracket</code></td>
<td>
<p>The type of bracket (and encased text) to remove.  This is one 
or more of the strings <code>"curly"</code>, <code>"square"</code>, <code>"round"</code>, 
<code>"angle"</code> and <code>"all"</code>.  These strings correspond 
to: {, [, (, &lt; or all four types.</p>
</td></tr>
<tr><td><code id="bracketX_+3A_missing">missing</code></td>
<td>
<p>Value to assign to empty cells.</p>
</td></tr>
<tr><td><code id="bracketX_+3A_names">names</code></td>
<td>
<p>logical.  If <code>TRUE</code> the sentences are given as the names of 
the counts.</p>
</td></tr>
<tr><td><code id="bracketX_+3A_fix.space">fix.space</code></td>
<td>
<p>logical.  If <code>TRUE</code> extra spaces left behind from an 
extraction will be eliminated.  Additionally, non-space (e.g., 
<strong>&quot;text(no space between text and parenthesis)&quot;</strong>) is replaced with a 
single space (e.g., <strong>&quot;text (space between text and parenthesis)&quot;</strong>).</p>
</td></tr>
<tr><td><code id="bracketX_+3A_scrub">scrub</code></td>
<td>
<p>logical.  If <code>TRUE</code> <code><a href="#topic+scrubber">scrubber</a></code> will clean 
the text.</p>
</td></tr>
<tr><td><code id="bracketX_+3A_with">with</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns the brackets and the bracketed 
text.</p>
</td></tr>
<tr><td><code id="bracketX_+3A_merge">merge</code></td>
<td>
<p>logical.  If <code>TRUE</code> the results of each bracket type will 
be merged by sentence.  <code>FALSE</code> returns a named list of lists of vectors 
of bracketed text per bracket type.</p>
</td></tr>
<tr><td><code id="bracketX_+3A_left">left</code></td>
<td>
<p>A vector of character or numeric symbols as the left edge to 
extract.</p>
</td></tr>
<tr><td><code id="bracketX_+3A_right">right</code></td>
<td>
<p>A vector of character or numeric symbols as the right edge to 
extract.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>bracketX</code> -  returns a vector of text with brackets removed.
</p>
<p><code>bracketXtract</code> -  returns a list of vectors of bracketed text.
</p>
<p><code>genXtract</code> - returns a vector of text with chunks removed.
</p>
<p><code>genX</code> - returns a list of vectors of removed text.
</p>


<h3>Author(s)</h3>

<p>Martin Morgan and Tyler Rinker &lt;tyler.rinker@gmail.com&gt;.
</p>


<h3>References</h3>

<p>https://stackoverflow.com/q/8621066/1000343
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+regex">regex</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
examp &lt;- structure(list(person = structure(c(1L, 2L, 1L, 3L), 
    .Label = c("bob", "greg", "sue"), class = "factor"), text = 
    c("I love chicken [unintelligible]!", 
    "Me too! (laughter) It's so good.[interrupting]", 
    "Yep it's awesome {reading}.", "Agreed. {is so much fun}")), .Names = 
    c("person", "text"), row.names = c(NA, -4L), class = "data.frame")    

examp                                                              
bracketX(examp$text, "square")  
bracketX(examp$text, "curly") 
bracketX(examp$text, c("square", "round")) 
bracketX(examp$text)  
                                              
                                              
bracketXtract(examp$text, "square")  
bracketXtract(examp$text, "curly")  
bracketXtract(examp$text, c("square", "round")) 
bracketXtract(examp$text, c("square", "round"), merge = FALSE)  
bracketXtract(examp$text)  
bracketXtract(examp$text, with = TRUE)

paste2(bracketXtract(examp$text, "curly"), " ")

x &lt;- c("Where is the /big dog#?", 
    "I think he's @arunning@b with /little cat#.")
genXtract(x, c("/", "@a"), c("#", "@b"))

x &lt;- c("Where is the L1big dogL2?", 
    "I think he's 98running99 with L1little catL2.")
genXtract(x, c("L1", 98), c("L2", 99))

DATA$state  #notice number 1 and 10
genX(DATA$state, c("is", "we"), c("too", "on"))

## End(Not run)
</code></pre>

<hr>
<h2 id='build_qdap_vignette'>Replace Temporary Introduction to qdap Vignette</h2><span id='topic+build_qdap_vignette'></span>

<h3>Description</h3>

<p>Replaces the temporary (place holder) <em>Introduction to qdap Vignette</em> 
with the actual vignette.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_qdap_vignette(download.html = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="build_qdap_vignette_+3A_download.html">download.html</code></td>
<td>
<p>logical.  If <code>TRUE</code> the file will be downloaded 
from: <a href="http://trinker.github.io/qdap/vignettes/qdap_vignette.html">http://trinker.github.io/qdap/vignettes/qdap_vignette.html</a>.  This</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Places the (1) HTML, (2) source, &amp; (3) R code for the 
<em>Introduction to qdap Vignette</em> in the user's 
&lsquo;<span class="file">R-VERSION/library/qdap/doc</span>&rsquo;.
</p>


<h3>Note</h3>

<p>The <span class="pkg">knitr</span> built HTML approach above takes about 4 minutes.  The 
user may choose the faster approach (&lt; 30 seconds) that downloads the HTML 
file directly from the Internet (this is for the latest CRAN release of 
<span class="pkg">qdap</span>).  This choice is controlled via the <code>download.html</code> 
argument.  The function will ask for the user's permission before writing the 
documents. Once the user has run this function 
<code>browseVignettes(package = 'qdap')</code> will allow access to the new
vignette files.
</p>

<hr>
<h2 id='capitalizer'>Capitalize Select Words</h2><span id='topic+capitalizer'></span>

<h3>Description</h3>

<p>A helper function for <code><a href="#topic+word_list">word_list</a></code> that allows the user to 
supply vectors of words to be capitalized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>capitalizer(text, caps.list = NULL, I.list = TRUE, apostrophe.remove = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="capitalizer_+3A_text">text</code></td>
<td>
<p>A vector of words (generally from <code>bag_o_words</code> or 
<code>breaker</code>).</p>
</td></tr>
<tr><td><code id="capitalizer_+3A_caps.list">caps.list</code></td>
<td>
<p>A list of words to capitalize.</p>
</td></tr>
<tr><td><code id="capitalizer_+3A_i.list">I.list</code></td>
<td>
<p>logical.  If <code>TRUE</code> capitalizes I words and contractions.</p>
</td></tr>
<tr><td><code id="capitalizer_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical, asking if apostrophes have been removed.
If <code>TRUE</code> will try to insert apostrophe's back into words appropriately.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of capitalized words based on supplied 
capitalization arguments.
</p>


<h3>Note</h3>

<p>Not intended for general use.  Acts as a helper function to several 
qdap functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
capitalizer(bag_o_words("i like it but i'm not certain"), "like")
capitalizer(bag_o_words("i like it but i'm not certain"), "like", FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='check_spelling'>Check Spelling</h2><span id='topic+check_spelling'></span><span id='topic+which_misspelled'></span><span id='topic+check_spelling_interactive'></span><span id='topic+correct'></span>

<h3>Description</h3>

<p><code>check_spelling</code> - Check the spelling for an vector of strings.  The 
function use the following technique:<br />
</p>

<ul>
<li><p> Separate the words from a string into a bag of words.
</p>
</li>
<li><p> Look those words up in a dictionary to find words not recognized/found (considered possibly misspelled).
</p>
</li>
<li><p> These misses (possible misspellings) will be what is looked up for suggested replacements.
</p>
</li>
<li><p> Optionally, reduce dictionary by assuming the first letter of the misspelled word is correct (dictionary for this letter only).
</p>
</li>
<li><p> Reduce dictionary by eliminating words outside of the range of number of characters of the misspelled word.
</p>
</li>
<li><p> Use <code><a href="stringdist.html#topic+stringdist">stringdist</a></code> to find string distances between possible replacements and the misspelled term.
</p>
</li>
<li><p> Select <em>n</em> (<code>n.suggests</code>) terms from dictionary that are closest to the misspelled term.
</p>
</li></ul>

<p><code>which_misspelled</code>  - Check the spelling for a string.
</p>
<p><code>check_spelling_interactive</code> - Interactively check spelling.
</p>
<p><code>correct</code> - Access the spell corrector function from a 
<code>"check_spelling_interactive"</code> object for subsequent text character 
vector spelling corrections.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_spelling(
  text.var,
  range = 2,
  assume.first.correct = TRUE,
  method = "jw",
  dictionary = qdapDictionaries::GradyAugmented,
  parallel = TRUE,
  cores = parallel::detectCores()/2,
  n.suggests = 8
)

which_misspelled(
  x,
  suggest = FALSE,
  range = 2,
  assume.first.correct = TRUE,
  dictionary = qdapDictionaries::GradyAugmented,
  method = "jw",
  nchar.dictionary = nchar(dictionary),
  first.char.dictionary = substring(dictionary, 1, 1),
  n.suggests = 8
)

check_spelling_interactive(
  text.var,
  range = 2,
  assume.first.correct = TRUE,
  click = TRUE,
  method = "jw",
  dictionary = qdapDictionaries::GradyAugmented,
  parallel = TRUE,
  cores = parallel::detectCores()/2,
  n.suggests = 8,
  ...
)

correct(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_spelling_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_range">range</code></td>
<td>
<p>An integer of length 1 to use as a range for number of 
characters, beyond the number of characters of a word not found in the 
<code>dictionary</code>, to initially limit <code>dictionary</code> size and thus time to 
find a suggested replacement term.  This may be expanded if no suitable 
suggestion is returned.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_assume.first.correct">assume.first.correct</code></td>
<td>
<p>logical.  If <code>TRUE</code> it is assumed that the 
first letter of the misspelled word is correct.  This reduces the dictionary 
size, thus speeding up computation.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_method">method</code></td>
<td>
<p>Method for distance calculation. The default is &quot;jaccard&quot;.  It 
is assumed that smaller measures indicate closer distance.  Measures that do 
not adhere to this assumption will result in incorrect output (see 
<code><a href="stringdist.html#topic+stringdist">stringdist</a></code> for details).</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_dictionary">dictionary</code></td>
<td>
<p>A character vector of terms to search for.  To reduce 
overhead it is expected that this dictionary is lower case, unique terms.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_cores">cores</code></td>
<td>
<p>The number of cores to use if <code>parallel = TRUE</code>.  Default 
is half the number of available cores.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_n.suggests">n.suggests</code></td>
<td>
<p>The number of terms to suggest.  In the case of a tie 
(multiple terms have the same distance from misspelled word) all will be provided.  
Dictionary reduction may result in less than <code>n.suggests</code> suggested terms.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_x">x</code></td>
<td>
<p>If <code>which_misspelled</code> - A character string.  If <code>correct</code> -
An object from <code>check_spelling_interactive</code>.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_suggest">suggest</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns a 
<code><a href="base.html#topic+data.frame">data.frame</a></code> with possible suggestions for misspelled words 
(words not found in the dictionary).</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_nchar.dictionary">nchar.dictionary</code></td>
<td>
<p>A vector that corresponds in length and content to 
<code>dictionary</code> with elements that are the precalculated number of 
characters for each word in the dictionary.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_first.char.dictionary">first.char.dictionary</code></td>
<td>
<p>A vector that corresponds in length and content 
to <code>dictionary</code> with elements that are the pre-allotted first characters
of each word in the dictionary.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_click">click</code></td>
<td>
<p>logical.  If <code>TRUE</code> the interface is a point and click GUI.
If <code>FALSE</code> the interface is command line driven.</p>
</td></tr>
<tr><td><code id="check_spelling_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>check_spelling</code> - Returns a <code><a href="base.html#topic+data.frame">data.frame</a></code> with 
<code>row</code> (row number), <code>not.found</code>  <code>word.no</code> (number of 
misspelled word), <code>not.found</code> (a word not found in the dictionary), 
<code>suggestion</code> (the most likely replacement for the word), and 
<code>more.suggestions</code> (A list of vectors of up to 10 most likely replacements).
</p>
<p><code>which_misspelled</code> - Returns either a named vector (names are 
the word number) of possible misspelled words (if<code>suggestions = FALSE</code>) 
or a <code><a href="base.html#topic+data.frame">data.frame</a></code> with <code>word.no</code> (number of misspelled 
word), <code>not.found</code> (a word not found in the dictionary),
<code>suggestion</code> (the most likely replacement for the word), and 
<code>more.suggestions</code> (A list of vectors of up to 10 most likely replacements).
</p>
<p><code>check_spelling_interactive</code> - Returns a character vector with 
the corrected text, the replacement list (via an <code>attribute</code> to the 
character vector), and a function to correct the same spelling errors in 
subsequent text character vectors.
</p>
<p><code>correct</code> - Returns a function for correcting spelling errors.
</p>


<h3>Note</h3>

<p>A possible misspelled word is defined as not found in the 
<code>dictionary</code>.
</p>
<p><code>check_spelling_interactive</code> - The user may go back (undo) by 
pressing <code>"TYPE MY OWN"</code> entering either <code>"!"</code> (not) or <code>"0"</code> 
(similar to a phone system).  The second choice in the 
<code>"SELECT REPLACEMNT:"</code> will be the original word and is prefixed with 
<code>"IGNORE:"</code>.  Press this to keep the original word.
</p>


<h3>References</h3>

<p>https://stackoverflow.com/a/24454727/1000343 <br />
https://journal.r-project.org/archive/2011-2/RJournal_2011-2_Hornik+Murdoch.pdf
</p>


<h3>See Also</h3>

<p><code><a href="stringdist.html#topic+stringdist">stringdist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- "Robots are evl creatres and deserv exterimanitation."
which_misspelled(x, suggest=FALSE)
which_misspelled(x, suggest=TRUE)

check_spelling(DATA$state)

## browseURL("http://stackoverflow.com/a/24454727/1000343")
terms &lt;- c("accounts", "account", "accounting", "acounting", "acount", "acounts", "accounnt")

set.seed(10)
(fake_text &lt;- unlist(lapply(terms, function(x) {
    unbag(sample(c(x, sample(DICTIONARY[[1]], sample(1:5, 1)))))
})))

check_spelling(fake_text)

##============================##
## INTERACTIVE SPELL CHECKING ##
##============================##

## No misspellings found
check_spelling_interactive(DATA$state)

## character method approach (minimal example)
dat &lt;- DATA$state; dat[1] &lt;- "I likedd the cokie icekream"
(o &lt;- check_spelling_interactive(dat))
preprocessed(o)
fixit &lt;- attributes(o)$correct
fixit(dat)

## character method approach (larger example)
m &lt;- check_spelling_interactive(mraja1spl$dialogue[1:75])
preprocessed(m)
fixit &lt;- attributes(m)$correct
fixit(mraja1spl$dialogue[1:75])

## check_spelling method approach
out &lt;- check_spelling(mraja1spl$dialogue[1:75])
(x &lt;- check_spelling_interactive(out))
preprocessed(x)
correct(x)(mraja1spl$dialogue[1:75])
(y &lt;- check_spelling_interactive(out, click=FALSE))
preprocessed(y)

## Examine Methods (?stringdist::stringdist)
strings &lt;- c(
    "Robots are evl creatres and deserv exterimanitation kream.",
    "I gots me a biggert measrue, tommorrow"
)

meths &lt;- c("osa", "lv", "dl", "hamming", "lcs", "qgram", "cosine", "jaccard", "jw")

stats::setNames(lapply(meths, function(x) check_spelling(strings, method=x)), meths)

## End(Not run)
</code></pre>

<hr>
<h2 id='check_spelling_interactive.character'>Check Spelling</h2><span id='topic+check_spelling_interactive.character'></span>

<h3>Description</h3>

<p>View character check_spelling_interactive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'character'
check_spelling_interactive(
  text.var,
  range = 2,
  assume.first.correct = TRUE,
  click = TRUE,
  method = "jw",
  dictionary = qdapDictionaries::GradyAugmented,
  parallel = TRUE,
  cores = parallel::detectCores()/2,
  n.suggests = 8,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_spelling_interactive.character_+3A_text.var">text.var</code></td>
<td>
<p>A <code><a href="base.html#topic+character">character</a></code> object, specifically a 
text vector of character strings.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_range">range</code></td>
<td>
<p>An integer of length 1 to use as a range for number of 
characters, beyond the number of characters of a word not found in the 
<code>dictionary</code>, to initially limit <code>dictionary</code> size and thus time to 
find a suggested replacement term.  This may be expanded if no suitable 
suggestion is returned.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_assume.first.correct">assume.first.correct</code></td>
<td>
<p>logical.  If <code>TRUE</code> it is assumed that the 
first letter of the misspelled word is correct.  This reduces the dictionary 
size, thus speeding up computation.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_click">click</code></td>
<td>
<p>logical.  If <code>TRUE</code> the interface is a point and click GUI.
If <code>FALSE</code> the interface is command line driven.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_method">method</code></td>
<td>
<p>Method for distance calculation. The default is &quot;jaccard&quot;.  It 
is assumed that smaller measures indicate closer distance.  Measures that do 
not adhere to this assumption will result in incorrect output (see 
<code><a href="stringdist.html#topic+stringdist">stringdist</a></code> for details).</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_dictionary">dictionary</code></td>
<td>
<p>A character vector of terms to search for.  To reduce 
overhead it is expected that this dictionary is lower case, unique terms.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_cores">cores</code></td>
<td>
<p>The number of cores to use if <code>parallel = TRUE</code>.  Default 
is half the number of available cores.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_n.suggests">n.suggests</code></td>
<td>
<p>The number of terms to suggest.  In the case of a tie 
(multiple terms have the same distance from misspelled word) all will be provided.  
Dictionary reduction may result in less than <code>n.suggests</code> suggested terms.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.character_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>character Method for check_spelling_interactive
</p>

<hr>
<h2 id='check_spelling_interactive.check_spelling'>Check Spelling</h2><span id='topic+check_spelling_interactive.check_spelling'></span>

<h3>Description</h3>

<p>View check_spelling check_spelling_interactive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'check_spelling'
check_spelling_interactive(
  text.var,
  range = 2,
  assume.first.correct = TRUE,
  click = TRUE,
  method = "jw",
  dictionary = qdapDictionaries::GradyAugmented,
  parallel = TRUE,
  cores = parallel::detectCores()/2,
  n.suggests = 8,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_text.var">text.var</code></td>
<td>
<p>A <code><a href="#topic+check_spelling">check_spelling</a></code> object.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_range">range</code></td>
<td>
<p>An integer of length 1 to use as a range for number of 
characters, beyond the number of characters of a word not found in the 
<code>dictionary</code>, to initially limit <code>dictionary</code> size and thus time to 
find a suggested replacement term.  This may be expanded if no suitable 
suggestion is returned.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_assume.first.correct">assume.first.correct</code></td>
<td>
<p>logical.  If <code>TRUE</code> it is assumed that the 
first letter of the misspelled word is correct.  This reduces the dictionary 
size, thus speeding up computation.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_click">click</code></td>
<td>
<p>logical.  If <code>TRUE</code> the interface is a point and click GUI.
If <code>FALSE</code> the interface is command line driven.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_method">method</code></td>
<td>
<p>Method for distance calculation. The default is &quot;jaccard&quot;.  It 
is assumed that smaller measures indicate closer distance.  Measures that do 
not adhere to this assumption will result in incorrect output (see 
<code><a href="stringdist.html#topic+stringdist">stringdist</a></code> for details).</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_dictionary">dictionary</code></td>
<td>
<p>A character vector of terms to search for.  To reduce 
overhead it is expected that this dictionary is lower case, unique terms.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_cores">cores</code></td>
<td>
<p>The number of cores to use if <code>parallel = TRUE</code>.  Default 
is half the number of available cores.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_n.suggests">n.suggests</code></td>
<td>
<p>The number of terms to suggest.  In the case of a tie 
(multiple terms have the same distance from misspelled word) all will be provided.  
Dictionary reduction may result in less than <code>n.suggests</code> suggested terms.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.check_spelling_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>check_spelling Method for check_spelling_interactive
</p>

<hr>
<h2 id='check_spelling_interactive.factor'>Check Spelling</h2><span id='topic+check_spelling_interactive.factor'></span>

<h3>Description</h3>

<p>View factor check_spelling_interactive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
check_spelling_interactive(
  text.var,
  range = 2,
  assume.first.correct = TRUE,
  click = TRUE,
  method = "jw",
  dictionary = qdapDictionaries::GradyAugmented,
  parallel = TRUE,
  cores = parallel::detectCores()/2,
  n.suggests = 8,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_spelling_interactive.factor_+3A_text.var">text.var</code></td>
<td>
<p>A <code><a href="base.html#topic+factor">factor</a></code> object, specifically a text vector 
of factor strings.  Note that this method is provided for factors for 
convenience, ideally the user should supply a character vector rather than 
factor.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_range">range</code></td>
<td>
<p>An integer of length 1 to use as a range for number of 
characters, beyond the number of characters of a word not found in the 
<code>dictionary</code>, to initially limit <code>dictionary</code> size and thus time to 
find a suggested replacement term.  This may be expanded if no suitable 
suggestion is returned.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_assume.first.correct">assume.first.correct</code></td>
<td>
<p>logical.  If <code>TRUE</code> it is assumed that the 
first letter of the misspelled word is correct.  This reduces the dictionary 
size, thus speeding up computation.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_click">click</code></td>
<td>
<p>logical.  If <code>TRUE</code> the interface is a point and click GUI.
If <code>FALSE</code> the interface is command line driven.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_method">method</code></td>
<td>
<p>Method for distance calculation. The default is &quot;jaccard&quot;.  It 
is assumed that smaller measures indicate closer distance.  Measures that do 
not adhere to this assumption will result in incorrect output (see 
<code><a href="stringdist.html#topic+stringdist">stringdist</a></code> for details).</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_dictionary">dictionary</code></td>
<td>
<p>A character vector of terms to search for.  To reduce 
overhead it is expected that this dictionary is lower case, unique terms.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_cores">cores</code></td>
<td>
<p>The number of cores to use if <code>parallel = TRUE</code>.  Default 
is half the number of available cores.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_n.suggests">n.suggests</code></td>
<td>
<p>The number of terms to suggest.  In the case of a tie 
(multiple terms have the same distance from misspelled word) all will be provided.  
Dictionary reduction may result in less than <code>n.suggests</code> suggested terms.</p>
</td></tr>
<tr><td><code id="check_spelling_interactive.factor_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>factor Method for check_spelling_interactive
</p>

<hr>
<h2 id='check_text'>Check Text For Potential Problems</h2><span id='topic+check_text'></span>

<h3>Description</h3>

<p>Uncleaned text may result in errors, warnings, and incorrect results in 
subsequent analysis.  <code>check_text</code> checks text for potential problems 
and suggests possible fixes.  Potential text anomalies that are detected 
include: factors, missing ending punctuation, empty cells, double punctuation, 
non-space after comma, no alphabetic characters, non-ascii, missing value, 
and potentially misspelled words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_text(text.var, file = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_text_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="check_text_+3A_file">file</code></td>
<td>
<p>A connection, or a character string naming the file to print to.
If <code>NULL</code> prints to the console.  Note that this is assigned as an 
attribute and passed to <code>print</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with the following potential text faults reports:<br />
</p>

<ul>
<li><p>non_character- Text that is non-character.
</p>
</li>
<li><p>missing_ending_punctuation- Text with no endmark at the end of the string.
</p>
</li>
<li><p>empty- Text that contains an empty element (i.e., <code>""</code>).
</p>
</li>
<li><p>double_punctuation- Text that contains two <span class="pkg">qdap</span> punctuation marks in the same string.
</p>
</li>
<li><p>non_space_after_comma- Text that contains commas with no space after them.
</p>
</li>
<li><p>no_alpha- Text that contains string elements with no alphabetic characters.
</p>
</li>
<li><p>non_ascii- Text that contains non-ASCII characters.
</p>
</li>
<li><p>missing_value- Text that contains missing values (i.e., <code>NA</code>).
</p>
</li>
<li><p>containing_escaped- Text that contains escaped (see <code>?Quotes</code>).
</p>
</li>
<li><p>containing_digits- Text that contains digits.
</p>
</li>
<li><p>indicating_incomplete- Text that contains endmarks that are indicative of incomplete/trailing sentences (e.g., <code>...</code>).
</p>
</li>
<li><p>potentially_misspelled- Text that contains potentially misspelled words.
</p>
</li></ul>



<h3>Note</h3>

<p>The output is a list but prints as a pretty formatted output with 
potential problem elements, the accompanying text, and possible suggestions 
to fix the text.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check_spelling_interactive">check_spelling_interactive</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("i like", "i want. thet them .", "I am ! that|", "", NA, 
    "they,were there", ".", "   ", "?", "3;", "I like goud eggs!", 
    "i 4like...", "\\tgreat",  "She said \"yes\"")
check_text(x)
print(check_text(x), include.text=FALSE)

y &lt;- c("A valid sentence.", "yet another!")
check_text(y)

## End(Not run)
</code></pre>

<hr>
<h2 id='chunker'>Break Text Into Ordered Word Chunks</h2><span id='topic+chunker'></span>

<h3>Description</h3>

<p>Some visualizations and algorithms require text to be broken into chunks of 
ordered words.  <code>chunker</code> breaks text, optionally by grouping 
variables, into equal chunks.  The chunk size can be specified by giving 
number of words to be in each chunk or the number of chunks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chunker(
  text.var,
  grouping.var = NULL,
  n.words,
  n.chunks,
  as.string = TRUE,
  rm.unequal = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chunker_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="chunker_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="chunker_+3A_n.words">n.words</code></td>
<td>
<p>An integer specifying the number of words in each chunk (must 
specify n.chunks or n.words).</p>
</td></tr>
<tr><td><code id="chunker_+3A_n.chunks">n.chunks</code></td>
<td>
<p>An integer specifying the number of chunks (must specify 
n.chunks or n.words).</p>
</td></tr>
<tr><td><code id="chunker_+3A_as.string">as.string</code></td>
<td>
<p>logical.  If <code>TRUE</code> the chunks are returned as a single 
string.  If <code>FALSE</code> the chunks are returned as a vector of single words.</p>
</td></tr>
<tr><td><code id="chunker_+3A_rm.unequal">rm.unequal</code></td>
<td>
<p>logical. If <code>TRUE</code> final chunks that are unequal in 
length to the other chunks are removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of text chunks.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(DATA, chunker(state, n.chunks = 10))
with(DATA, chunker(state, n.words = 10))
with(DATA, chunker(state, n.chunks = 10, as.string=FALSE))
with(DATA, chunker(state, n.chunks = 10, rm.unequal=TRUE))
with(DATA, chunker(state, person, n.chunks = 10))
with(DATA, chunker(state, list(sex, adult), n.words = 10))
with(DATA, chunker(state, person, n.words = 10, rm.unequal=TRUE))

## Bigger data
with(hamlet, chunker(dialogue, person, n.chunks = 10))
with(hamlet, chunker(dialogue, person, n.words = 300))

## Not run: 
## with polarity hedonmetrics
dat &lt;- with(pres_debates2012[pres_debates2012$person %in% qcv(OBAMA, ROMNEY), ], 
    chunker(dialogue, list(person, time), n.words = 300))

dat2 &lt;- colsplit2df(list2df(dat, "dialogue", "person&amp;time")[, 2:1])

dat3 &lt;- split(dat2[, -2], dat2$time)
ltruncdf(dat3, 10, 50)

poldat &lt;- lapply(dat3, function(x) with(x, polarity(dialogue, person, constrain = TRUE)))


m &lt;- lapply(poldat, function(x) plot(cumulative(x)))
m &lt;- Map(function(w, x, y, z) {
        w + ggtitle(x) + xlab(y) + ylab(z)
    }, 
        m, 
        paste("Debate", 1:3), 
        list(NULL, NULL, "Duration (300 Word Segment)"), 
        list(NULL, "Cumulative Average Polarity", NULL)
)

library(gridExtra)
do.call(grid.arrange, m)

## By person
## By person
poldat2 &lt;- Map(function(x, x2){

    scores &lt;- with(counts(x), split(polarity, person))
    setNames(lapply(scores, function(y) {
        y &lt;- list(cumulative_average_polarity = y)
        attributes(y)[["constrained"]] &lt;- TRUE
        qdap:::plot.cumulative_polarity(y) + xlab(NULL) + ylab(x2)
    }), names(scores))

}, poldat, paste("Debate", 1:3))

poldat2 &lt;- lapply(poldat2, function(x) {
    x[[2]] &lt;- x[[2]] + ylab(NULL)
    x
})

poldat2[[1]] &lt;- Map(function(x, y) {
        x + ggtitle(y)
    },
        poldat2[[1]], qcv(Obama, Romney)
)

library(gridExtra)
do.call(grid.arrange, unlist(poldat2, recursive=FALSE))

## End(Not run)
</code></pre>

<hr>
<h2 id='clean'>Remove Escaped Characters</h2><span id='topic+clean'></span>

<h3>Description</h3>

<p>Preprocess data to remove escaped characters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean(text.var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of character strings with escaped characters removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- "I go \\r
    to the \\tnext line"
x
clean(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_2long'>A Generic to Long Function</h2><span id='topic+cm_2long'></span>

<h3>Description</h3>

<p>A wrapper for <code>cm_df2long</code>, <code>cm_range2long</code>, and <code>cm_time2long</code> that automatically detects the objects being read and outputs the correct form and class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_2long(..., v.name = "variable", list.var = TRUE, debug = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_2long_+3A_v.name">v.name</code></td>
<td>
<p>An optional name for the column created for the list.var 
argument.</p>
</td></tr>
<tr><td><code id="cm_2long_+3A_list.var">list.var</code></td>
<td>
<p>logical.  If <code>TRUE</code> creates a column for the data frame 
created by each time.list passed to <code>cm_t2l</code>.</p>
</td></tr>
<tr><td><code id="cm_2long_+3A_debug">debug</code></td>
<td>
<p>logical. If <code>TRUE</code> debugging mode is on.
<code><a href="#topic+cm_time2long">cm_time2long</a></code> will return possible errors in time span 
inputs.</p>
</td></tr>
<tr><td><code id="cm_2long_+3A_...">...</code></td>
<td>
<p>list object(s) in the form generated by 
<code><a href="#topic+cm_df.temp">cm_df.temp</a></code>, <code><a href="#topic+cm_range.temp">cm_range.temp</a></code>, or
<code><a href="#topic+cm_time.temp">cm_time.temp</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a long data.frame of the correct <strong>cm_XXX</strong> classes.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_time2long">cm_time2long</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## cm_range2long use: 
foo &lt;- list(
    person_greg = qcv(terms='7:11, 20:24, 30:33, 49:56'),
    person_researcher = qcv(terms='42:48'),
    person_sally = qcv(terms='25:29, 37:41'),
    person_sam = qcv(terms='1:6, 16:19, 34:36'),
    person_teacher = qcv(terms='12:15'),
    adult_0 = qcv(terms='1:11, 16:41, 49:56'),
    adult_1 = qcv(terms='12:15, 42:48'),
    AA = qcv(terms="1"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:9, 100:150")
)

foo2  &lt;- list(
    person_greg = qcv(terms='7:11, 20:24, 30:33, 49:56'),
    person_researcher = qcv(terms='42:48'),
    person_sally = qcv(terms='25:29, 37:41'),
    person_sam = qcv(terms='1:6, 16:19, 34:36'),
    person_teacher = qcv(terms='12:15'),
    adult_0 = qcv(terms='1:11, 16:41, 49:56'),
    adult_1 = qcv(terms='12:15, 42:48'),
    AA = qcv(terms="40"),
    BB = qcv(terms="50:90"),
    CC = qcv(terms="60:90, 100:120, 150"),
    DD = qcv(terms="")
)

cm_2long(foo, foo2, v.name = "time")

## cm_time2long use: 
x &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 
        9.00, 1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)
cm_2long(x)

## cm_df2long use:
codes &lt;- qcv(dc, sf, wes, pol, rejk, lk, azx, mmm)
x1 &lt;- cm_df.temp(DATA, "state", codes)
#fill it randomly
x1[, 7:14] &lt;- lapply(7:14,  function(i) sample(0:1, nrow(x1), TRUE))
out2 &lt;- cm_2long(x1)
head(out2, 15)
plot(out2)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_code.blank'>Blank Code Transformation</h2><span id='topic+cm_code.blank'></span>

<h3>Description</h3>

<p>Transform codes with any binary operator combination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_code.blank(x2long.obj, combine.code.list, rm.var = NULL, overlap = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_code.blank_+3A_x2long.obj">x2long.obj</code></td>
<td>
<p>An object from <code><a href="#topic+cm_range2long">cm_range2long</a></code>, 
<code><a href="#topic+cm_time2long">cm_time2long</a></code> or <code><a href="#topic+cm_df2long">cm_df2long</a></code>.</p>
</td></tr>
<tr><td><code id="cm_code.blank_+3A_combine.code.list">combine.code.list</code></td>
<td>
<p>A list of named character vectors of at least two 
code column names to combine.</p>
</td></tr>
<tr><td><code id="cm_code.blank_+3A_rm.var">rm.var</code></td>
<td>
<p>Name of the repeated measures column.</p>
</td></tr>
<tr><td><code id="cm_code.blank_+3A_overlap">overlap</code></td>
<td>
<p>logical, integer or character of binary operator + integer.
If <code>TRUE</code> finds the overlap.  If <code>FALSE</code> finds anywhere any of the 
codes occur.  If integer finds that exact combination of overlaps.  If 
character must be a logical vector 
c(<code>&gt;</code>, <code>&lt;</code>, <code>=&lt;</code>, <code>=&gt;</code>, <code>==</code>, <code>!=</code>) followed by 
an integer and wrapped with quotes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with transformed occurrences of supplied 
overlapping codes added.
</p>


<h3>Note</h3>

<p>For most jobs <code><a href="#topic+cm_code.transform">cm_code.transform</a></code> will work.  This
adds a bit of flexibility in exclusion and partial matching.  The code column 
must be named <code>"code"</code> and your start and end columns must be named 
<code>"start"</code> and <code>"end"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_time2long">cm_time2long</a></code>,
<code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_code.overlap">cm_code.overlap</a></code>,
<code><a href="#topic+cm_code.combine">cm_code.combine</a></code>,
<code><a href="#topic+cm_code.exclude">cm_code.exclude</a></code>,
<code><a href="#topic+cm_code.transform">cm_code.transform</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="1:10"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:3, 5:6")
)

foo2  &lt;- list(
    AA = qcv(terms="4:8"),
    BB = qcv(terms="1:4, 10:12"),
    CC = qcv(terms="1, 11, 15:20"),
    DD = qcv(terms="")
)

## Single occurrence version
(x &lt;- cm_range2long(foo))

cm_code.blank(x, combine.code.list = list(ABC=qcv(AA, BB, CC)),
    overlap = "!=1")

## Repeated measures version
(z &lt;- cm_range2long(foo, foo2, v.name="time"))

cm_code.blank(z, combine.code.list = list(ABC=qcv(AA, BB, CC)),
    rm.var = "time", overlap = "!=1")

cm_code.blank(z, combine.code.list = list(AB=qcv(AA, BB)),
    rm.var = "time", overlap = TRUE)

cm_code.blank(z, combine.code.list = list(AB=qcv(AA, BB)),
    rm.var = "time", overlap = FALSE)

cm_code.blank(z, combine.code.list = list(AB=qcv(AA, BB)),
    rm.var = "time", overlap = "&gt;1")

cm_code.blank(z, combine.code.list = list(AB=qcv(AA, BB)),
    rm.var = "time", overlap = "==2")

## Notice `overlap = "==2"` above is identical to `cm_code.overlap`
cm_code.overlap(z, overlap.code.list = list(AB=qcv(AA, BB)),
    rm.var = "time")


#WITH cm_time2long
x &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00,
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

y &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00,
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

dat &lt;- cm_time2long(x, y, v.name="time")
head(dat, 10)
out &lt;- cm_code.blank(dat, combine.code.list = list(ABC=qcv(A, B, C)),
    rm.var = "time", overlap = "!=1")

head(out)
plot(out)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_code.combine'>Combine Codes</h2><span id='topic+cm_code.combine'></span>

<h3>Description</h3>

<p>Combine all occurrences of codes into a new code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_code.combine(x2long.obj, combine.code.list, rm.var = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_code.combine_+3A_x2long.obj">x2long.obj</code></td>
<td>
<p>An object from <code><a href="#topic+cm_range2long">cm_range2long</a></code>, 
<code><a href="#topic+cm_time2long">cm_time2long</a></code> or <code><a href="#topic+cm_df2long">cm_df2long</a></code>.</p>
</td></tr>
<tr><td><code id="cm_code.combine_+3A_combine.code.list">combine.code.list</code></td>
<td>
<p>A list of named character vectors of at least two 
code column names to combine</p>
</td></tr>
<tr><td><code id="cm_code.combine_+3A_rm.var">rm.var</code></td>
<td>
<p>Name of the repeated measures column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with combined occurrences of supplied overlapping 
codes added.
</p>


<h3>Note</h3>

<p>The code column must be named <code>"code"</code> and your start and end 
columns must be named <code>"start"</code> and <code>"end"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_time2long">cm_time2long</a></code>,
<code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_code.blank">cm_code.blank</a></code>,
<code><a href="#topic+cm_code.exclude">cm_code.exclude</a></code>,
<code><a href="#topic+cm_code.overlap">cm_code.overlap</a></code>,
<code><a href="#topic+cm_code.transform">cm_code.transform</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="1:10"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:3, 5:6")
)

foo2  &lt;- list(
    AA = qcv(terms="4:8"),
    BB = qcv(terms="1:4, 10:12"),
    CC = qcv(terms="1, 11, 15:20"),
    DD = qcv(terms="")
)

(x &lt;- cm_range2long(foo))
(z &lt;- cm_range2long(foo, foo2, v.name="time"))
cm_code.combine(x, list(AB=qcv(AA, BB)))
cm_code.combine(x, list(ALL=qcv(AA, BB, CC)))
combines &lt;- list(AB=qcv(AA, BB), ABC=qcv(AA, BB, CC))
cm_code.combine(z, combines, rm.var = "time")

#WITH cm_time2long
x &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00, 
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

y &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00, 
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

dat &lt;- cm_time2long(x, y)
head(dat, 12)
cm_code.combine(dat, list(P=qcv(A, B), Q=qcv(B, C), R=qcv(A, B, C)), "variable")

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_code.exclude'>Exclude Codes</h2><span id='topic+cm_code.exclude'></span>

<h3>Description</h3>

<p>Find the occurrences of n codes excluding the nth code.  For example you have 
times/words coded for a teacher and you also have times/words coded for 
happiness.  You can find all the happiness times excluding the teacher times 
or vice versa.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_code.exclude(x2long.obj, exclude.code.list, rm.var = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_code.exclude_+3A_x2long.obj">x2long.obj</code></td>
<td>
<p>An object from <code><a href="#topic+cm_range2long">cm_range2long</a></code>, 
<code><a href="#topic+cm_time2long">cm_time2long</a></code> or <code><a href="#topic+cm_df2long">cm_df2long</a></code>.</p>
</td></tr>
<tr><td><code id="cm_code.exclude_+3A_exclude.code.list">exclude.code.list</code></td>
<td>
<p>A list of named character vectors of at least two 
code column names to compare and exclude.  The last column name is the one 
that will be excluded.</p>
</td></tr>
<tr><td><code id="cm_code.exclude_+3A_rm.var">rm.var</code></td>
<td>
<p>Name of the repeated measures column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with n codes excluding the nth code.
</p>


<h3>Note</h3>

<p>The code column must be named <code>"code"</code> and your start and end 
columns must be named <code>"start"</code> and <code>"end"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_time2long">cm_time2long</a></code>,
<code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_code.blank">cm_code.blank</a></code>,
<code><a href="#topic+cm_code.combine">cm_code.combine</a></code>,
<code><a href="#topic+cm_code.overlap">cm_code.overlap</a></code>,
<code><a href="#topic+cm_code.transform">cm_code.transform</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="1:10"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:3, 5:6")
)

foo2  &lt;- list(
    AA = qcv(terms="4:8"),
    BB = qcv(terms="1:4, 10:12"),
    CC = qcv(terms="1, 11, 15:20"),
    DD = qcv(terms="")
)


(x &lt;- cm_range2long(foo))
(z &lt;- cm_range2long(foo, foo2, v.name="time"))
cm_code.exclude(x, list(ABnoC=qcv(AA, BB, CC)))
cm_code.exclude(z, list(ABnoC=qcv(AA, BB, CC)), rm.var="time")
excludes &lt;- list(AnoB=qcv(AA, BB), ABnoC=qcv(AA, BB, CC))
(a &lt;- cm_code.exclude(z, excludes, rm.var="time"))
plot(a)

#WITH cm_time2long
x &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00, 
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

y &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00, 
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

dat &lt;- cm_time2long(x, y)
head(dat, 10)
cm_code.exclude(dat, list(P=qcv(A, B), Q=qcv(B, C), R=qcv(A, B, C)), 
    rm.var = "variable")

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_code.overlap'>Find Co-occurrence Between Codes</h2><span id='topic+cm_code.overlap'></span>

<h3>Description</h3>

<p>Combine co-occurrences of codes into a new code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_code.overlap(x2long.obj, overlap.code.list, rm.var = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_code.overlap_+3A_x2long.obj">x2long.obj</code></td>
<td>
<p>An object from <code><a href="#topic+cm_range2long">cm_range2long</a></code>, 
<code><a href="#topic+cm_time2long">cm_time2long</a></code> or <code><a href="#topic+cm_df2long">cm_df2long</a></code>.</p>
</td></tr>
<tr><td><code id="cm_code.overlap_+3A_overlap.code.list">overlap.code.list</code></td>
<td>
<p>A list of named character vectors of at least two 
code column names to aggregate co-occurrences.</p>
</td></tr>
<tr><td><code id="cm_code.overlap_+3A_rm.var">rm.var</code></td>
<td>
<p>Name of the repeated measures column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with co-occurrences of supplied overlapping codes 
added.
</p>


<h3>Note</h3>

<p>The code column must be named code and your start and end columns must 
be named <code>"start"</code> and <code>"end"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_time2long">cm_time2long</a></code>,
<code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_code.combine">cm_code.combine</a></code>,
<code><a href="#topic+cm_code.transform">cm_code.transform</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="1:10"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:3, 5:6")
)

foo2  &lt;- list(
    AA = qcv(terms="4:8"),
    BB = qcv(terms="1:4, 10:12"),
    CC = qcv(terms="1, 11, 15:20"),
    DD = qcv(terms="")
)


(x &lt;- cm_range2long(foo))
(z &lt;- cm_range2long(foo, foo2, v.name="time"))
cm_code.overlap(x, list(AB=qcv(AA, BB)))
cm_code.overlap(x, list(ALL=qcv(AA, BB, CC)))
combines &lt;- list(AB=qcv(AA, BB), ABC=qcv(AA, BB, CC))
(a &lt;- cm_code.overlap(z, combines, "time"))
plot(a)

#WITH cm_time2long
x &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00, 
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

y &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00, 
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

dat &lt;- cm_time2long(x, y)
head(dat, 10)
out &lt;- cm_code.overlap(dat, list(P=qcv(A, B), Q=qcv(B, C), R=qcv(A, B, C)), 
    rm.var="variable")
head(out, 10)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_code.transform'>Transform Codes</h2><span id='topic+cm_code.transform'></span>

<h3>Description</h3>

<p>Transform co-occurrences and/or combinations of codes into a new code(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_code.transform(
  x2long.obj,
  overlap.code.list = NULL,
  combine.code.list = NULL,
  exclude.code.list = NULL,
  rm.var = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_code.transform_+3A_x2long.obj">x2long.obj</code></td>
<td>
<p>An object from <code><a href="#topic+cm_range2long">cm_range2long</a></code>, 
<code><a href="#topic+cm_time2long">cm_time2long</a></code> or <code><a href="#topic+cm_df2long">cm_df2long</a></code>.</p>
</td></tr>
<tr><td><code id="cm_code.transform_+3A_overlap.code.list">overlap.code.list</code></td>
<td>
<p>A list of named character vectors of at least two 
code column names to aggregate co-occurrences.</p>
</td></tr>
<tr><td><code id="cm_code.transform_+3A_combine.code.list">combine.code.list</code></td>
<td>
<p>A list of named character vectors of at least two 
code column names to combine</p>
</td></tr>
<tr><td><code id="cm_code.transform_+3A_exclude.code.list">exclude.code.list</code></td>
<td>
<p>A list of named character vectors of at least two 
code column names to compare and exclude.  The last column name is the one 
that will be excluded.</p>
</td></tr>
<tr><td><code id="cm_code.transform_+3A_rm.var">rm.var</code></td>
<td>
<p>Name of the repeated measures column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with overlapping, combined occurrences, and/or 
exclusion of supplied overlapping codes added.
</p>


<h3>Note</h3>

<p>The code column must be named <code>"code"</code> and your start and end 
columns must be named <code>"start"</code> and <code>"end"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_time2long">cm_time2long</a></code>,
<code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_code.blank">cm_code.blank</a></code>,
<code><a href="#topic+cm_code.combine">cm_code.combine</a></code>,
<code><a href="#topic+cm_code.exclude">cm_code.exclude</a></code>,
<code><a href="#topic+cm_code.overlap">cm_code.overlap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="1:10"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:3, 5:6")
)

foo2  &lt;- list(
    AA = qcv(terms="4:8"),
    BB = qcv(terms="1:4, 10:12"),
    CC = qcv(terms="1, 11, 15:20"),
    DD = qcv(terms="")
)

bar1 &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "0.00:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00,
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 16.25:17.01")
)

(x &lt;- cm_range2long(foo))
(z &lt;- cm_range2long(foo, foo2, v.name="time"))
(dat &lt;- cm_time2long(bar1))

cm_code.transform(x, 
    overlap.code.list = list(ABC=qcv(AA, BB, CC)),
    combine.code.list = list(oABC=qcv(AA, BB, CC)), 
    exclude.code.list = list(ABnoC=qcv(AA, BB, CC))
)

cm_code.transform(z, 
    overlap.code.list = list(ABC=qcv(AA, BB, CC)),
    combine.code.list = list(oABC=qcv(AA, BB, CC)), 
    exclude.code.list = list(ABnoC=qcv(AA, BB, CC)), "time"
)

cm_code.transform(dat, 
    overlap.code.list = list(ABC=qcv(A, B, C)),
    combine.code.list = list(oABC=qcv(A, B, C)), 
    exclude.code.list = list(ABnoC=qcv(A, B, C))
)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_combine.dummy'>Find Co-occurrence Between Dummy Codes</h2><span id='topic+cm_combine.dummy'></span>

<h3>Description</h3>

<p>Combine code columns where they co-occur.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_combine.dummy(cm.l2d.obj, combine.code, rm.var = "time", overlap = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_combine.dummy_+3A_cm.l2d.obj">cm.l2d.obj</code></td>
<td>
<p>An object from <code><a href="#topic+cm_long2dummy">cm_long2dummy</a></code>.</p>
</td></tr>
<tr><td><code id="cm_combine.dummy_+3A_combine.code">combine.code</code></td>
<td>
<p>A list of named character vectors of at least two code 
column names to combine</p>
</td></tr>
<tr><td><code id="cm_combine.dummy_+3A_rm.var">rm.var</code></td>
<td>
<p>Name of the repeated measures column.  Default is &quot;time&quot;.</p>
</td></tr>
<tr><td><code id="cm_combine.dummy_+3A_overlap">overlap</code></td>
<td>
<p>logical, integer or character of binary operator + integer.
If <code>TRUE</code> finds the overlap.  If <code>FALSE</code> finds anywhere any of the 
codes occur.  If integer finds that exact combination of overlaps.  If 
character must be a logical vector 
c(<code>&gt;</code>, <code>&lt;</code>, <code>=&lt;</code>, <code>=&gt;</code>, <code>==</code>, <code>!=</code>) followed by 
an integer and wrapped with quotes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with co-occurrences of provided code columns.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_long2dummy">cm_long2dummy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="1:10"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:3, 5:6")
)

foo2  &lt;- list(
    AA = qcv(terms="4:8"),
    BB = qcv(terms="1:4, 10:12"),
    CC = qcv(terms="1, 11, 15:20"),
    DD = qcv(terms="")
)


(x &lt;- cm_range2long(foo))
(D1 &lt;- cm_long2dummy(x))

(z &lt;- cm_range2long(foo, foo2, v.name="time"))
(D2 &lt;- cm_long2dummy(z, "time"))
cm_combine.dummy(D1, combine.code = list(AB=qcv(AA, BB)))
cm_combine.dummy(D1, combine.code = list(AB=qcv(AA, BB)), overlap="==1")
cm_combine.dummy(D1, combine.code = list(AB=qcv(AA, BB)), overlap="!=1")
D1 &lt;- cm_combine.dummy(D1, combine.code = list(AB=qcv(AA, BB)), overlap=0)
D1 &lt;- cm_combine.dummy(D1, combine.code = list(CAB=qcv(AB, CC)), overlap=FALSE)

combines &lt;- list(AB=qcv(AA, BB), ABC=qcv(AA, BB, CC))
cm_combine.dummy(D1, combine.code = combines)
cm_combine.dummy(D2, combine.code = combines)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_df.fill'>Range Coding</h2><span id='topic+cm_df.fill'></span>

<h3>Description</h3>

<p>Allows range coding of words for efficient coding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_df.fill(
  dataframe,
  ranges,
  value = 1,
  text.var = NULL,
  code.vars = NULL,
  transform = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_df.fill_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe containing a text variable.</p>
</td></tr>
<tr><td><code id="cm_df.fill_+3A_ranges">ranges</code></td>
<td>
<p>A named list of ranges to recode.  Names correspond to code 
names in dataframe.</p>
</td></tr>
<tr><td><code id="cm_df.fill_+3A_value">value</code></td>
<td>
<p>The recode value.  Takes a vector of length one or a vector of 
length equal to the number of code columns.</p>
</td></tr>
<tr><td><code id="cm_df.fill_+3A_text.var">text.var</code></td>
<td>
<p>The name of the text variable.</p>
</td></tr>
<tr><td><code id="cm_df.fill_+3A_code.vars">code.vars</code></td>
<td>
<p>Optional vector of codes.</p>
</td></tr>
<tr><td><code id="cm_df.fill_+3A_transform">transform</code></td>
<td>
<p>logical.  If <code>TRUE</code> the words are located across the 
top of dataframe.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After ranging coding transcripts via (<code><a href="#topic+cm_df.temp">cm_df.temp</a></code>) or 
the blank code matrix via (<code><a href="#topic+cm_df.transcript">cm_df.transcript</a></code>),<code>cm_df.fill</code> 
is used to create a matrix of what codes occurred at what words (a filled code 
matrix).  A list of range codes (word number spans) is fed to 
<code>cm_df.fill</code>.  A single number indicates a single word with that coding 
scheme whereas the colon is used as a separator that indicates the range of 
words from x to y are that particular code.
</p>


<h3>Value</h3>

<p>Generates a dummy coded dataframe.
</p>


<h3>References</h3>

<p>Miles, M. B. &amp; Huberman, A. M. (1994). An expanded sourcebook: 
Qualitative   data analysis. 2nd ed. Thousand Oaks, CA: SAGE Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_df.temp">cm_df.temp</a></code>,
<code><a href="#topic+cm_df.transcript">cm_df.transcript</a></code>,
<code><a href="#topic+cm_df2long">cm_df2long</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
codes &lt;- qcv(dc, sf, wes, pol, rejk, lk, azx, mmm)
X &lt;- cm_df.temp(DATA, "state", codes)
head(X, 10)

#recommended structure
cds1 &lt;- list(
     dc=c(1:3, 5), 
     sf=c(4, 6:9, 11), 
     wes=0, 
     pol=0, 
     rejk=0,
     lk=0, 
     azx=1:30, 
     mmm=5
)

out1 &lt;- cm_df.fill(X, cds1)
head(out1)

#recommended structure
cds2 &lt;- list(
    sf=c(4, 6:9, 11), 
    dc=c(1:3, 5), 
    azx=1:30, 
    mmm=5
)
out2 &lt;- cm_df.fill(X, cds2)
head(out2)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_df.temp'>Break Transcript Dialogue into Blank Code Matrix</h2><span id='topic+cm_df.temp'></span>

<h3>Description</h3>

<p>Breaks transcript dialogue into words while retaining the demographic factors 
associate with each word.  The codes argument provides a matrix of zeros that 
can serve as a dummy coded matrix of codes per word.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_df.temp(
  dataframe,
  text.var,
  codes = NULL,
  file = NULL,
  transpose = FALSE,
  strip = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_df.temp_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe containing a text variable.</p>
</td></tr>
<tr><td><code id="cm_df.temp_+3A_text.var">text.var</code></td>
<td>
<p>The name of the text variable.</p>
</td></tr>
<tr><td><code id="cm_df.temp_+3A_codes">codes</code></td>
<td>
<p>Optional list of codes.</p>
</td></tr>
<tr><td><code id="cm_df.temp_+3A_file">file</code></td>
<td>
<p>The name of the file (csv is recommended file type).  If 
<code>NULL</code> no file is written.</p>
</td></tr>
<tr><td><code id="cm_df.temp_+3A_transpose">transpose</code></td>
<td>
<p>logical.  If <code>TRUE</code> transposes the dataframe so that 
the text is across the top.</p>
</td></tr>
<tr><td><code id="cm_df.temp_+3A_strip">strip</code></td>
<td>
<p>logical.  If <code>TRUE</code> all punctuation is removed.</p>
</td></tr>
<tr><td><code id="cm_df.temp_+3A_...">...</code></td>
<td>
<p>Other arguments passed to strip.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generates a dataframe, and optional csv file, of individual words 
while maintaining demographic information.  If a vector of codes is provided 
the outcome is a matrix of words used by codes filled with zeros.  This 
dataframe is useful for dummy coded (1-yes code exists; 0-no it does not) 
representation of data and can be used for visualizations and statistical 
analysis.
</p>


<h3>References</h3>

<p>Miles, M. B. &amp; Huberman, A. M. (1994). An expanded sourcebook: 
Qualitative data analysis. 2nd ed. Thousand Oaks, CA: SAGE Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_df.transcript">cm_df.transcript</a></code>,
<code><a href="#topic+cm_df.fill">cm_df.fill</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
codes &lt;- qcv(dc, sf, wes, pol, rejk, lk, azx, mmm)
out1 &lt;- cm_df.temp(DATA, "state", codes)
head(out1, 15)
out2 &lt;- cm_df.temp(DATA, "state", codes, transpose = TRUE)
out2[, 1:10]
out3 &lt;- cm_df.temp(raj.act.1, "dialogue", codes)
head(out3, 15)
out4 &lt;- cm_df.temp(raj.act.1, "dialogue", codes, transpose = TRUE)
out4 [, 1:8]

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_df.transcript'>Transcript With Word Number</h2><span id='topic+cm_df.transcript'></span>

<h3>Description</h3>

<p>Output a transcript with word  number/index above for easy input back into 
qdap after coding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_df.transcript(
  text.var,
  grouping.var,
  file = NULL,
  indent = 4,
  width = 70,
  space = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_df.transcript_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="cm_df.transcript_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="cm_df.transcript_+3A_file">file</code></td>
<td>
<p>A connection, or a character string naming the file to print to 
(e.g., .doc, .txt).</p>
</td></tr>
<tr><td><code id="cm_df.transcript_+3A_indent">indent</code></td>
<td>
<p>Number of spaces to indent.</p>
</td></tr>
<tr><td><code id="cm_df.transcript_+3A_width">width</code></td>
<td>
<p>Width to output the file (defaults to 70; this is generally a 
good width and indent for a .docx file).</p>
</td></tr>
<tr><td><code id="cm_df.transcript_+3A_space">space</code></td>
<td>
<p>An integer value denoting the vertical spacing between the 
<code>grouping.var</code> and the numbered text (allow more space for more coding 
room) in the output of a text file.</p>
</td></tr>
<tr><td><code id="cm_df.transcript_+3A_...">...</code></td>
<td>
<p>Other arguments passed to strip.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a transcript by grouping variable with word number above each 
word.  This makes use with <code><a href="#topic+cm_df2long">cm_df2long</a></code> transfer/usage 
easier because the researcher has coded on a transcript with the numeric word 
index already.
</p>


<h3>Note</h3>

<p>It is recommended that the researcher actually codes on the output 
from this file.  The codes can then be transferred to via a list.  If a file 
already exists <code>cm_df.transcript</code> will append to that file.
</p>


<h3>Author(s)</h3>

<p>BondedDust (stackoverflow.com), Gavin Simpson and Tyler Rinker &lt;tyler.rinker@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_df.temp">cm_df.temp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(DATA, cm_df.transcript(state, person))
with(DATA, cm_df.transcript(state, list(sex, adult)))
#use it with nested variables just to keep track of demographic info
with(DATA, cm_df.transcript(state, list(person, sex, adult)))

#use double tilde "~~" to keep word group as one word
DATA$state &lt;- mgsub("be certain", "be~~certain", DATA$state, fixed = TRUE)
with(DATA, cm_df.transcript(state, person))
DATA &lt;- qdap::DATA

##  with(mraja1spl, cm_df.transcript(dialogue, list(person)))
##  with(mraja1spl, cm_df.transcript(dialogue, list(sex, fam.aff, died)))
##  with(mraja1spl, cm_df.transcript(dialogue, list(person), file="foo.doc"))
##  delete("foo.doc")   #delete the file just created

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_df2long'>Transform Codes to Start-End Durations</h2><span id='topic+cm_df2long'></span>

<h3>Description</h3>

<p>Transforms the range coding structure(s) from <code><a href="#topic+cm_df.temp">cm_df.temp</a></code>
(in list format) into a data frame of start and end durations in long format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_df2long(
  df.temp.obj,
  v.name = "variable",
  list.var = TRUE,
  code.vars = NULL,
  no.code = NA,
  add.start.end = TRUE,
  repeat.vars = NULL,
  rev.code = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_df2long_+3A_df.temp.obj">df.temp.obj</code></td>
<td>
<p>A character vector of names of object(s) created by 
<code><a href="#topic+cm_df.temp">cm_df.temp</a></code>, a list of <code><a href="#topic+cm_df.temp">cm_df.temp</a></code> created objects 
or a data frame created by <code><a href="#topic+cm_df.temp">cm_df.temp</a></code>.</p>
</td></tr>
<tr><td><code id="cm_df2long_+3A_v.name">v.name</code></td>
<td>
<p>An optional name for the column created for the list.var 
argument.</p>
</td></tr>
<tr><td><code id="cm_df2long_+3A_list.var">list.var</code></td>
<td>
<p>logical.  If <code>TRUE</code> creates a column for the data frame 
created by each time.list.</p>
</td></tr>
<tr><td><code id="cm_df2long_+3A_code.vars">code.vars</code></td>
<td>
<p>A character vector of code variables.  If <code>NULL</code> uses 
all variables from the first column after the column named word.num.</p>
</td></tr>
<tr><td><code id="cm_df2long_+3A_no.code">no.code</code></td>
<td>
<p>The value to assign to no code; default is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="cm_df2long_+3A_add.start.end">add.start.end</code></td>
<td>
<p>logical.  If <code>TRUE</code> adds a column for start and end 
times.</p>
</td></tr>
<tr><td><code id="cm_df2long_+3A_repeat.vars">repeat.vars</code></td>
<td>
<p>A character vector of repeated/stacked variables.  If 
<code>NULL</code> uses all non code.vars variables.</p>
</td></tr>
<tr><td><code id="cm_df2long_+3A_rev.code">rev.code</code></td>
<td>
<p>logical.  If <code>TRUE</code> reverses the order of 
<code>code.vars</code> and <code>no.code</code> variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generates a data frame of start and end times for each code.
</p>


<h3>References</h3>

<p>Miles, M. B. &amp; Huberman, A. M. (1994). An expanded sourcebook: 
Qualitative   data analysis. 2nd ed. Thousand Oaks, CA: SAGE Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_time2long">cm_time2long</a></code>,
<code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_df.temp">cm_df.temp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
codes &lt;- qcv(dc, sf, wes, pol, rejk, lk, azx, mmm)
x1 &lt;- cm_df.temp(DATA, "state", codes)
head(x1)

#empty code matrix
out1 &lt;- cm_df2long(x1,  code.vars = codes)
head(out1, 15)

#fill it randomly
x1[, 7:14] &lt;- lapply(7:14,  function(i) sample(0:1, nrow(x1), TRUE))
out2 &lt;- cm_df2long(x1,  code.vars = codes)
head(out2, 15)
plot(out2)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_distance'>Distance Matrix Between Codes</h2><span id='topic+cm_distance'></span>

<h3>Description</h3>

<p>Generate distance measures to ascertain a mean distance measure between codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_distance(
  dataframe,
  pvals = c(TRUE, FALSE),
  replications = 1000,
  parallel = TRUE,
  extended.output = TRUE,
  time.var = TRUE,
  code.var = "code",
  causal = FALSE,
  start.var = "start",
  end.var = "end",
  cores = detectCores()/2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_distance_+3A_dataframe">dataframe</code></td>
<td>
<p>A data frame from the cm_x2long family 
(<code>cm_range2long</code>; <code>cm_df2long</code>; <code>cm_time2long</code>).</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_pvals">pvals</code></td>
<td>
<p>A logical vector of length 1 or 2.  If element 2 is blank 
element 1 will be recycled.  If the first element is <code>TRUE</code> pvalues 
will be calculated for the combined (main) output for all repeated measures 
from simulated resampling of the data.  If the second element is <code>TRUE</code> 
pvalues will be calculated for the individual (extended) repeated measures 
output from simulated resampling of the data.  Default is to calculate 
pvalues for the main output but not for the extended output.  This process 
involves multiple resampling of the data and is a time consuming process.  It 
may take from a few minutes to days to calculate the pvalues depending on the
number of all codes use, number of different codes and number of 
<code>replications</code>.</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_replications">replications</code></td>
<td>
<p>An integer value for the number of replications used in 
resampling the data if any <code>pvals</code> is <code>TRUE</code>.  It is recommended 
that this value be no lower than 1000. Failure to use enough replications 
may result in unreliable pvalues.</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> runs the <code>cm_distance</code> on 
multiple cores (if available).  This will generally be effective with most 
data sets, given there are repeated measures, because of the large number of 
simulations.  Default uses 1/2 of the available cores.</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_extended.output">extended.output</code></td>
<td>
<p>logical.  If <code>TRUE</code> the information on individual 
repeated measures is calculated in addition to the aggregated repeated 
measures results for the main output.</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_time.var">time.var</code></td>
<td>
<p>An optional variable to split the dataframe by (if you have 
data that is by various times this must be supplied).</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_code.var">code.var</code></td>
<td>
<p>The name of the code variable column.  Defaults to &quot;codes&quot; as 
out putted by x2long family.</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_causal">causal</code></td>
<td>
<p>logical.  If <code>TRUE</code> measures the distance between x and y 
given that x must precede y.  That is, only those <code class="reqn">y_i</code> that begin after 
the <code class="reqn">x_i</code> has begun will be considered, as it is assumed that x precedes 
y.  If <code>FALSE</code> x is not assumed to precede y.  The closest <code class="reqn">y_i</code> 
(either its beginning or end) is calculated to <code class="reqn">x_i</code> (either it's 
beginning or end).</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_start.var">start.var</code></td>
<td>
<p>The name of the start variable column.  Defaults to &quot;start&quot; 
as out putted by x2long family.</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_end.var">end.var</code></td>
<td>
<p>The name of the end variable column.  Defaults to &quot;end&quot; as out 
putted by x2long family.</p>
</td></tr>
<tr><td><code id="cm_distance_+3A_cores">cores</code></td>
<td>
<p>An integer value describing the number of cores to use if 
<code>parallel = TRUE</code>.  Default is to use half of the available cores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that row names are the first code and column names are the 
second comparison code. The values for Code A compared to Code B will not be 
the same as Code B compared to Code A. This is because, unlike a true 
distance measure, cm_distance's matrix is asymmetrical. <code>cm_distance</code> 
computes the distance by taking each span (start and end) for Code A and 
comparing it to the nearest start or end for Code B.
</p>


<h3>Value</h3>

<p>An object of the class <code>"cm_distance"</code>.  This is a list with the 
following components: 
</p>
<table>
<tr><td><code>pvals</code></td>
<td>
<p>A logical indication of whether pvalues were calculated</p>
</td></tr>
<tr><td><code>replications</code></td>
<td>
<p>Integer value of number of replications used</p>
</td></tr>
<tr><td><code>extended.output</code></td>
<td>
<p>An optional list of individual repeated measures 
information</p>
</td></tr>
<tr><td><code>main.output</code></td>
<td>
<p>A list of aggregated repeated measures information</p>
</td></tr>
<tr><td><code>adj.alpha</code></td>
<td>
<p>An adjusted alpha level (based on <code class="reqn">\alpha = .05</code>) for 
the estimated p-values using the upper end of the confidence interval around 
the p-values</p>
</td></tr>
</table>
<p>Within the lists of extended.output and list of the main.output are the 
following items: 
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>A distance matrix of average distances between codes</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>A matrix of standard deviations of distances between codes</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>A matrix of counts of distances between codes</p>
</td></tr>
<tr><td><code>stan.mean</code></td>
<td>
<p>A matrix of standardized values of distances between 
codes.  The closer a value is to zero the closer two codes relate.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>A n optional matrix of simulated pvalues associated with 
the mean distances</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>p-values are estimated and thus subject to error.  More 
replications decreases the error.  Use:
</p>
<p style="text-align: center;"><code class="reqn">p \pm \left (  1.96 \cdot \sqrt{\frac{\alpha(1-\alpha)}{n}}\right )</code>
</p>

<p>to adjust the confidence in the 
estimated p-values based on the number of replications.
</p>


<h3>References</h3>

<p>https://stats.stackexchange.com/a/22333/7482
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.cm_distance">print.cm_distance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="02:03, 05"),
    BB = qcv(terms="1:2, 3:10"),
    CC = qcv(terms="1:9, 100:150")
)

foo2  &lt;- list(
    AA = qcv(terms="40"),
    BB = qcv(terms="50:90"),
    CC = qcv(terms="60:90, 100:120, 150"),
    DD = qcv(terms="")
)

(dat &lt;- cm_2long(foo, foo2, v.name = "time"))
plot(dat)
(out &lt;- cm_distance(dat, replications=100))
names(out)
names(out$main.output)
out$main.output
out$extended.output
print(out, new.order = c(3, 2, 1))
print(out, new.order = 3:2)
#========================================
x &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 6.32:7.00, 9.00,
        10.00:11.00, 59.56"),
    B = qcv(terms = "3.01:3.02, 5.01,  19.00, 1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.32:7.00, 9.00, 17.01")
)
(dat &lt;- cm_2long(x))
plot(dat)
(a &lt;- cm_distance(dat, causal=TRUE, replications=100))

## Plotting as a network graph
datA &lt;- list(
    A = qcv(terms="02:03, 05"),
    B = qcv(terms="1:2, 3:10, 45, 60, 200:206, 250, 289:299, 330"),
    C = qcv(terms="1:9, 47, 62, 100:150, 202, 260, 292:299, 332"),
    D = qcv(terms="10:20, 30, 38:44, 138:145"),
    E = qcv(terms="10:15, 32, 36:43, 132:140"),
    F = qcv(terms="1:2, 3:9, 10:15, 32, 36:43, 45, 60, 132:140, 250, 289:299"),
    G = qcv(terms="1:2, 3:9, 10:15, 32, 36:43, 45, 60, 132:140, 250, 289:299"),
    H = qcv(terms="20, 40, 60, 150, 190, 222, 255, 277"),
    I = qcv(terms="20, 40, 60, 150, 190, 222, 255, 277")
)

datB  &lt;- list(
    A = qcv(terms="40"),
    B = qcv(terms="50:90, 110, 148, 177, 200:206, 250, 289:299"),
    C = qcv(terms="60:90, 100:120, 150, 201, 244, 292"),
    D = qcv(terms="10:20, 30, 38:44, 138:145"),
    E = qcv(terms="10:15, 32, 36:43, 132:140"),
    F = qcv(terms="10:15, 32, 36:43, 132:140, 148, 177, 200:206, 250, 289:299"),
    G = qcv(terms="10:15, 32, 36:43, 132:140, 148, 177, 200:206, 250, 289:299"),
    I = qcv(terms="20, 40, 60, 150, 190, 222, 255, 277")  
)

(datC &lt;- cm_2long(datA, datB, v.name = "time"))
plot(datC)
(out2 &lt;- cm_distance(datC, replications=1250))

plot(out2)
plot(out2, label.cex=2, label.dist=TRUE, digits=5)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_dummy2long'>Convert cm_combine.dummy Back to Long</h2><span id='topic+cm_dummy2long'></span>

<h3>Description</h3>

<p><code>cm_combine.dummy</code> back to long.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_dummy2long(cm_long2dummy_obj, rm.var = "time")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_dummy2long_+3A_cm_long2dummy_obj">cm_long2dummy_obj</code></td>
<td>
<p>An object from cm_combine.dummy</p>
</td></tr>
<tr><td><code id="cm_dummy2long_+3A_rm.var">rm.var</code></td>
<td>
<p>Name of the repeated measures column.  Default is 
<code>"time"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with co-occurrences of provided code columns.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_long2dummy">cm_long2dummy</a></code>,
<code><a href="#topic+cm_combine.dummy">cm_combine.dummy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="1:10"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:3, 5:6")
)

foo2  &lt;- list(
    AA = qcv(terms="4:8"),
    BB = qcv(terms="1:4, 10:12"),
    CC = qcv(terms="1, 11, 15:20"),
    DD = qcv(terms="")
)

(x &lt;- cm_range2long(foo))
(out1 &lt;- cm_long2dummy(x))

(z &lt;- cm_range2long(foo, foo2, v.name="time"))
out2 &lt;- cm_long2dummy(z, "time")
lapply(out2, head)
cm_combine.dummy(out1, combine.code = list(AB=qcv(AA, BB)))

combines &lt;- list(AB=qcv(AA, BB), ABC=qcv(AA, BB, CC))
A &lt;- cm_combine.dummy(out2, combine.code = combines)
head(A, 10)
B &lt;- cm_combine.dummy(out1, combine.code = combines)
head(B, 10)

cm_dummy2long(A)
cm_dummy2long(B)
plot(cm_dummy2long(A))

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_long2dummy'>Stretch and Dummy Code cm_xxx2long</h2><span id='topic+cm_long2dummy'></span>

<h3>Description</h3>

<p>Stretches and dummy codes a cm_xxx2long dataframe to allow for combining 
columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_long2dummy(
  dataframe,
  rm.var = NULL,
  code = "code",
  start = "start",
  end = "end"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_long2dummy_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe that contains the person variable.</p>
</td></tr>
<tr><td><code id="cm_long2dummy_+3A_rm.var">rm.var</code></td>
<td>
<p>An optional character argument of the name of a repeated 
measures column.</p>
</td></tr>
<tr><td><code id="cm_long2dummy_+3A_code">code</code></td>
<td>
<p>A character argument of the name of a repeated measures column.
Default is <code>"code"</code>.</p>
</td></tr>
<tr><td><code id="cm_long2dummy_+3A_start">start</code></td>
<td>
<p>A character argument of the name of a repeated measures column.
Default is <code>"start"</code>.</p>
</td></tr>
<tr><td><code id="cm_long2dummy_+3A_end">end</code></td>
<td>
<p>A character argument of the name of a repeated measures column.
Default is <code>"end"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe or a list of stretched and dummy coded 
dataframe(s).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_time2long">cm_time2long</a></code>,
<code><a href="#topic+cm_df2long">cm_df2long</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    AA = qcv(terms="1:10"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:3, 5:6")
)

foo2  &lt;- list(
    AA = qcv(terms="4:8"),
    BB = qcv(terms="1:4, 10:12"),
    CC = qcv(terms="1, 11, 15:20"),
    DD = qcv(terms="")
)

(x &lt;- cm_range2long(foo))
cm_long2dummy(x)

(z &lt;- cm_range2long(foo, foo2, v.name="time"))
out &lt;- cm_long2dummy(z, "time")
ltruncdf(out)

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_range.temp'>Range Code Sheet</h2><span id='topic+cm_range.temp'></span>

<h3>Description</h3>

<p>Generates a range coding sheet for coding words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_range.temp(codes, text.var = NULL, grouping.var = NULL, file = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_range.temp_+3A_codes">codes</code></td>
<td>
<p>Character vector of codes.</p>
</td></tr>
<tr><td><code id="cm_range.temp_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="cm_range.temp_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Also takes a single grouping 
variable or a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="cm_range.temp_+3A_file">file</code></td>
<td>
<p>A connection, or a character string naming the file to print to 
(.txt or .doc is recommended).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Miles, M. B. &amp; Huberman, A. M. (1994). An expanded sourcebook: 
Qualitative   data analysis. 2nd ed. Thousand Oaks, CA: SAGE Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_time.temp">cm_time.temp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
cm_range.temp(qcv(AA, BB, CC))
with(DATA, cm_range.temp(qcv(AA, BB, CC), state, list(person, adult)))
## cm_range.temp(qcv(AA, BB, CC), file = "foo.txt")
## delete("foo.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_range2long'>Transform Codes to Start-End Durations</h2><span id='topic+cm_range2long'></span>

<h3>Description</h3>

<p>Transforms the range coding structure(s) from cm_range.temp (in list format) 
into a data frame of start and end durations in long format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_range2long(
  ...,
  v.name = "variable",
  list.var = TRUE,
  debug = TRUE,
  object = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_range2long_+3A_v.name">v.name</code></td>
<td>
<p>An optional name for the column created for the list.var 
argument.</p>
</td></tr>
<tr><td><code id="cm_range2long_+3A_list.var">list.var</code></td>
<td>
<p>logical.  If <code>TRUE</code> creates a column for the data frame 
created by each time.list passed to <code>cm_t2l</code>.</p>
</td></tr>
<tr><td><code id="cm_range2long_+3A_debug">debug</code></td>
<td>
<p>logical. If <code>TRUE</code> debugging mode is on.
<code><a href="#topic+cm_time2long">cm_time2long</a></code> will return possible errors in time span 
inputs.</p>
</td></tr>
<tr><td><code id="cm_range2long_+3A_object">object</code></td>
<td>
<p>A list of list object(s) generated by 
<code><a href="#topic+cm_time.temp">cm_time.temp</a></code>.</p>
</td></tr>
<tr><td><code id="cm_range2long_+3A_...">...</code></td>
<td>
<p>list object(s) in the form generated by 
<code><a href="#topic+cm_time.temp">cm_time.temp</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generates a data frame of start and end spans for each code.
</p>


<h3>References</h3>

<p>Miles, M. B. &amp; Huberman, A. M. (1994). An expanded sourcebook: 
Qualitative   data analysis. 2nd ed. Thousand Oaks, CA: SAGE Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_time.temp">cm_time.temp</a></code>,
<code><a href="#topic+cm_df.transcript">cm_df.transcript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo &lt;- list(
    person_greg = qcv(terms='7:11, 20:24, 30:33, 49:56'),
    person_researcher = qcv(terms='42:48'),
    person_sally = qcv(terms='25:29, 37:41'),
    person_sam = qcv(terms='1:6, 16:19, 34:36'),
    person_teacher = qcv(terms='12:15'),
    adult_0 = qcv(terms='1:11, 16:41, 49:56'),
    adult_1 = qcv(terms='12:15, 42:48'),
    AA = qcv(terms="1"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:9, 100:150")
)

foo2  &lt;- list(
    person_greg = qcv(terms='7:11, 20:24, 30:33, 49:56'),
    person_researcher = qcv(terms='42:48'),
    person_sally = qcv(terms='25:29, 37:41'),
    person_sam = qcv(terms='1:6, 16:19, 34:36'),
    person_teacher = qcv(terms='12:15'),
    adult_0 = qcv(terms='1:11, 16:41, 49:56'),
    adult_1 = qcv(terms='12:15, 42:48'),
    AA = qcv(terms="40"),
    BB = qcv(terms="50:90"),
    CC = qcv(terms="60:90, 100:120, 150"),
    DD = qcv(terms="")
)

## General ldots Approach
(dat &lt;- cm_range2long(foo, foo2, v.name = "time"))
plot(dat)

## Specify `object` Approach
cm_range2long(object=list(foo=foo))
cm_range2long(object=list(foo=foo, foo2=foo2), v.name="time")
cm_range2long(object=list(a=foo, b=foo2), v.name="time")

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_time.temp'>Time Span Code Sheet</h2><span id='topic+cm_time.temp'></span>

<h3>Description</h3>

<p>Generates a time span coding sheet and coding format sheet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_time.temp(
  codes,
  grouping.var = NULL,
  start = ":00",
  end = NULL,
  file = NULL,
  coding = FALSE,
  print = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_time.temp_+3A_codes">codes</code></td>
<td>
<p>List of codes.</p>
</td></tr>
<tr><td><code id="cm_time.temp_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Also takes a single grouping 
variable or a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="cm_time.temp_+3A_start">start</code></td>
<td>
<p>A character string in the form of &quot;00:00&quot; indicating start time 
(default is &quot;:00&quot;).</p>
</td></tr>
<tr><td><code id="cm_time.temp_+3A_end">end</code></td>
<td>
<p>A character string in the form of &quot;00:00&quot; indicating end time.</p>
</td></tr>
<tr><td><code id="cm_time.temp_+3A_file">file</code></td>
<td>
<p>A connection, or a character string naming the file to print to 
(.txt or .doc is recommended).</p>
</td></tr>
<tr><td><code id="cm_time.temp_+3A_coding">coding</code></td>
<td>
<p>logical.  If <code>TRUE</code> a coding list is provided with the 
time span coding sheet.  <code>coding</code> is ignored if <code>end = NULL</code>.</p>
</td></tr>
<tr><td><code id="cm_time.temp_+3A_print">print</code></td>
<td>
<p>logical.  If <code>TRUE</code> the time spans are printed to the 
console.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Miles, M. B. &amp; Huberman, A. M. (1994). An expanded sourcebook: 
Qualitative   data analysis. 2nd ed. Thousand Oaks, CA: SAGE Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range.temp">cm_range.temp</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## cm_time.temp(qcv(AA, BB, CC), ":30", "7:40", file = "foo.txt")
## delete("foo.txt")
cm_time.temp(qcv(AA, BB, CC), ":30", "7:40")

x &lt;- list(
    transcript_time_span = qcv(terms="00:00 - 1:12:00"),
    A = qcv(terms="2.40:3.00, 5.01, 6.52:7.00, 9.00"),
    B = qcv(terms="2.40, 3.01:3.02, 5.01, 6.52:7.00, 9.00, 1.12.00:1.19.01"),
    C = qcv(terms="2.40:3.00, 5.01, 6.52:7.00, 9.00, 17.01")
)
cm_time2long(x)
cm_time.temp(qcv(AA, BB, CC))

## End(Not run)
</code></pre>

<hr>
<h2 id='cm_time2long'>Transform Codes to Start-End Times</h2><span id='topic+cm_time2long'></span>

<h3>Description</h3>

<p>Transforms the range coding structure(s) from <code><a href="#topic+cm_time.temp">cm_time.temp</a></code> 
(in list format) into a data frame of start and end times in long format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cm_time2long(
  ...,
  v.name = "variable",
  list.var = TRUE,
  debug = TRUE,
  object = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cm_time2long_+3A_v.name">v.name</code></td>
<td>
<p>An optional name for the column created for the list.var 
argument</p>
</td></tr>
<tr><td><code id="cm_time2long_+3A_list.var">list.var</code></td>
<td>
<p>logical.  If <code>TRUE</code> creates a column for the data frame 
created by each time.list passed to <code>cm_t2l</code>.</p>
</td></tr>
<tr><td><code id="cm_time2long_+3A_debug">debug</code></td>
<td>
<p>logical. If <code>TRUE</code> debugging mode is on.
<code><a href="#topic+cm_time2long">cm_time2long</a></code> will return possible errors in time span 
inputs.</p>
</td></tr>
<tr><td><code id="cm_time2long_+3A_object">object</code></td>
<td>
<p>A list of list object(s) generated by 
<code><a href="#topic+cm_time.temp">cm_time.temp</a></code>.</p>
</td></tr>
<tr><td><code id="cm_time2long_+3A_...">...</code></td>
<td>
<p>List object(s) in the form generated by 
<code><a href="#topic+cm_time.temp">cm_time.temp</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generates a dataframe of start and end times for each code.
</p>


<h3>References</h3>

<p>Miles, M. B. &amp; Huberman, A. M. (1994). An expanded sourcebook: 
Qualitative   data analysis. 2nd ed. Thousand Oaks, CA: SAGE Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_df2long">cm_df2long</a></code>,
<code><a href="#topic+cm_time.temp">cm_time.temp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 
        9.00, 1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)
(dat &lt;- cm_time2long(x))
plot(dat)

bar1 &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00,
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 16.25:17.01")
)

bar2 &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00, 9.00,
        1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)

## General ldots Approach
cm_time2long(bar1)
cm_time2long(bar1, bar2, v.name="time")

## Specify `object` Approach
cm_time2long(object=list(bar1=bar1))
cm_time2long(object=list(bar1=bar1, bar2=bar2), v.name="time")
cm_time2long(object=list(a=bar1, b=bar2), v.name="time")

## End(Not run)
</code></pre>

<hr>
<h2 id='colcomb2class'>Combine Columns to Class</h2><span id='topic+colcomb2class'></span>

<h3>Description</h3>

<p>Combine columns from qdap classes or a <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colcomb2class(
  dataframe,
  combined.columns,
  class = "list",
  percent = TRUE,
  digits = 2,
  elim.old = TRUE,
  zero.replace = 0,
  override = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="colcomb2class_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe or qdap class (e.g., 
<code>termco</code>, <code>question_type</code>, <code>pos_by</code>, <code>character_table</code>).</p>
</td></tr>
<tr><td><code id="colcomb2class_+3A_combined.columns">combined.columns</code></td>
<td>
<p>A list of named vectors of the colnames/indexes 
of the numeric columns to be combined (summed).  If a vector is unnamed a 
name will be assigned.</p>
</td></tr>
<tr><td><code id="colcomb2class_+3A_class">class</code></td>
<td>
<p>The class to assign to the output.</p>
</td></tr>
<tr><td><code id="colcomb2class_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="colcomb2class_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="colcomb2class_+3A_elim.old">elim.old</code></td>
<td>
<p>logical.  If <code>TRUE</code> eliminates the columns that are 
combined together by the named match.list. <code>TRUE</code> outputs the table 
proportionally (see <code><a href="#topic+prop">prop</a></code>).</p>
</td></tr>
<tr><td><code id="colcomb2class_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.</p>
</td></tr>
<tr><td><code id="colcomb2class_+3A_override">override</code></td>
<td>
<p>logical.  If <code>TRUE</code> the printing options (e.g., 
percent, digits, etc.) of the dataframe argument are overrode.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with raw counts, percents and combined raw 
and percents.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## `termco` example
ml &lt;- list(
    cat1 = c(" the ", " a ", " an "),
    cat2 = c(" I'" ),
    "good",
    the = c("the", " the ", " the", "the")
)
dat1 &lt;- with(raj.act.1,  termco(dialogue, person, ml))
colcomb2class(dat1, list(cats = c("cat1", "cat2")))

## `question_type` example
dat2 &lt;- question_type(DATA.SPLIT$state, DATA.SPLIT$person)
combs &lt;- list(
    `wh/how` = c("what", "how"), 
    oth = c("shall", "implied_do/does/did")
)
colcomb2class(dat2, combs)

## `pos_by` example
dat3 &lt;- with(DATA, pos_by(state, list(adult, sex)))
colcomb2class(dat3, qcv(DT, EX, FW))


## data.frame example
dat4 &lt;- data.frame(X=LETTERS[1:5], matrix(sample(0:5, 20, TRUE), ncol = 4))
colcomb2class(dat4, list(new = c("X1", "X4")))

## End(Not run)
</code></pre>

<hr>
<h2 id='colSplit'>Separate a Column Pasted by paste2</h2><span id='topic+colSplit'></span>

<h3>Description</h3>

<p>Separates a <code><a href="#topic+paste2">paste2</a></code> column into separate columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colSplit(column, col.sep = ".", name.sep = "&amp;")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="colSplit_+3A_column">column</code></td>
<td>
<p>The pasted vector.</p>
</td></tr>
<tr><td><code id="colSplit_+3A_col.sep">col.sep</code></td>
<td>
<p>The column separator used in <code>paste2</code>.</p>
</td></tr>
<tr><td><code id="colSplit_+3A_name.sep">name.sep</code></td>
<td>
<p>Name separator used in the column (generally for internal use 
with <code><a href="#topic+colsplit2df">colsplit2df</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe of split columns.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colsplit2df">colsplit2df</a></code>, 
<code><a href="#topic+paste2">paste2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
foo1 &lt;- paste2(CO2[, 1:3])
head(foo1, 12)
bar1 &lt;- colSplit(foo1)
head(bar1, 10)

foo2  &lt;- paste2(mtcars[, 1:3], sep="|")
head(foo2, 12)
bar2 &lt;- colSplit(foo2, col.sep = "|")
head(bar2, 10)

## End(Not run)
</code></pre>

<hr>
<h2 id='colsplit2df'>Wrapper for colSplit that Returns Dataframe(s)</h2><span id='topic+colsplit2df'></span><span id='topic+lcolsplit2df'></span>

<h3>Description</h3>

<p><code>colsplit2df</code> - Wrapper for <code><a href="#topic+colSplit">colSplit</a></code> that returns a 
dataframe.
</p>
<p><code>lcolsplit2df</code> - Wrapper for <code>colsplit2df</code> designed for qdap lists 
that returns a list dataframes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colsplit2df(
  dataframe,
  splitcols = 1,
  new.names = NULL,
  sep = ".",
  keep.orig = FALSE,
  name.sep = "&amp;",
  index.names = FALSE
)

lcolsplit2df(qdap.list, keep.orig = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="colsplit2df_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe with a column that has been pasted together.</p>
</td></tr>
<tr><td><code id="colsplit2df_+3A_splitcols">splitcols</code></td>
<td>
<p>The name/index of the column(s) that has been pasted together.</p>
</td></tr>
<tr><td><code id="colsplit2df_+3A_new.names">new.names</code></td>
<td>
<p>A character vector of new names to assign to the columns (or
list of names if multiple columns are being split).  
Default attempts to extract the original names before the paste.</p>
</td></tr>
<tr><td><code id="colsplit2df_+3A_sep">sep</code></td>
<td>
<p>The character(s) that was used in <code>paste2</code> to paste the 
columns.</p>
</td></tr>
<tr><td><code id="colsplit2df_+3A_keep.orig">keep.orig</code></td>
<td>
<p>logical.  If <code>TRUE</code> the original pasted column will be 
retained as well.</p>
</td></tr>
<tr><td><code id="colsplit2df_+3A_name.sep">name.sep</code></td>
<td>
<p>The character(s) that was used to paste the column names.</p>
</td></tr>
<tr><td><code id="colsplit2df_+3A_index.names">index.names</code></td>
<td>
<p>logical.  If <code>TRUE</code> names of columns that are duplicated
are indexed with c(&quot;name.1&quot;, &quot;name.2&quot;, ... &quot;name.n&quot;).</p>
</td></tr>
<tr><td><code id="colsplit2df_+3A_qdap.list">qdap.list</code></td>
<td>
<p>A qdap list object that contains dataframes with a leading 
<code><a href="#topic+paste2">paste2</a></code> column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>colsplit2df</code> - returns a dataframe with the <code>paste2</code> 
column split into new columns.
</p>
<p><code>lcolsplit2df</code> - returns a list of dataframes with the 
<code><a href="#topic+paste2">paste2</a></code> column split into new columns.
</p>


<h3>Warning</h3>

<p>This will strip the class of the qdap object.
</p>


<h3>Note</h3>

<p><code><a href="#topic+lcolsplit2df">lcolsplit2df</a></code> is a convenience function that is less 
flexible than <code><a href="#topic+colsplit2df">colsplit2df</a></code> but operates on multiple 
dataframes at once.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colSplit">colSplit</a></code>, 
<code><a href="#topic+colpaste2df">colpaste2df</a></code>
<code><a href="#topic+paste2">paste2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
CO2$`Plant&amp;Type&amp;Treatment` &lt;- paste2(CO2[, 1:3])
CO2 &lt;- CO2[, -c(1:3)]
head(CO2)
head(colsplit2df(CO2, 3))
head(colsplit2df(CO2, 3, qcv(A, B, C)))
head(colsplit2df(CO2, 3, qcv(A, B, C), keep.orig=TRUE))
head(colsplit2df(CO2, "Plant&amp;Type&amp;Treatment"))
CO2 &lt;- datasets::CO2

(dat &lt;- colpaste2df(head(mtcars), list(1:3), sep = "|"))
colsplit2df(dat, 12, sep = "|")

## Multiple split example
E &lt;- list(
    c(1, 2, 3, 4, 5),
    qcv(mpg, hp),
    c("disp", "am")
)

(dat2 &lt;- colpaste2df(head(mtcars), E, sep ="|"))
cols &lt;- c("mpg&amp;cyl&amp;disp&amp;hp&amp;drat", "mpg&amp;hp", "disp&amp;am")
colsplit2df(dat2, cols, sep = "|")

## lcolsplit2df example
(x &lt;- with(DATA.SPLIT, question_type(state, list(sex, adult))))
ltruncdf(x)
z &lt;- lcolsplit2df(x)
ltruncdf(z)

## End(Not run)
</code></pre>

<hr>
<h2 id='comma_spacer'>Ensure Space After Comma</h2><span id='topic+comma_spacer'></span>

<h3>Description</h3>

<p>Adds a space after a comma as strip and many other functions may consider a 
comma separated string as one word (i.e., <code>"one,two,three"</code> becomes 
<code>"onetwothree"</code>  rather than <code>"one two three"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comma_spacer(text.var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="comma_spacer_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of strings with commas that have a space after them.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("the,  dog,went", "I,like,it", "where are you", NA, "why", ",", ",f")
comma_spacer(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='common'>Find Common Words Between Groups</h2><span id='topic+common'></span>

<h3>Description</h3>

<p>Find common words between grouping variables (e.g., people).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>common(word.list, overlap = "all", equal.or = "more", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="common_+3A_word.list">word.list</code></td>
<td>
<p>A list of named character vectors.</p>
</td></tr>
<tr><td><code id="common_+3A_overlap">overlap</code></td>
<td>
<p>Minimum/exact amount of overlap.</p>
</td></tr>
<tr><td><code id="common_+3A_equal.or">equal.or</code></td>
<td>
<p>A character vector of c(<code>"equal"</code>, <code>"greater"</code>, 
<code>"more"</code>, <code>"less"</code>).</p>
</td></tr>
<tr><td><code id="common_+3A_...">...</code></td>
<td>
<p>In lieu of <code>word.list</code> the user may input n number of 
character vectors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe of all words that match the criteria set by 
<code>overlap</code> and <code>equal.or</code>.
</p>

<hr>
<h2 id='common.list'>list Method for common</h2><span id='topic+common.list'></span>

<h3>Description</h3>

<p>list Method for common
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'list'
common(word.list, overlap = "all", equal.or = "more", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="common.list_+3A_word.list">word.list</code></td>
<td>
<p>A list of names character vectors.</p>
</td></tr>
<tr><td><code id="common.list_+3A_overlap">overlap</code></td>
<td>
<p>Minimum/exact amount of overlap.</p>
</td></tr>
<tr><td><code id="common.list_+3A_equal.or">equal.or</code></td>
<td>
<p>A character vector of c(<code>"equal"</code>, <code>"greater"</code>, 
<code>"more"</code>, <code>"less"</code>).</p>
</td></tr>
<tr><td><code id="common.list_+3A_...">...</code></td>
<td>
<p>In lieu of word.list the user may input n number of character 
vectors.</p>
</td></tr>
</table>

<hr>
<h2 id='condense'>Condense Dataframe Columns</h2><span id='topic+condense'></span>

<h3>Description</h3>

<p>Condense dataframe columns that are a list of vectors to a single vector of 
strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>condense(dataframe, sep = ", ")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="condense_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe with a column(s) that are a list of vectors.</p>
</td></tr>
<tr><td><code id="condense_+3A_sep">sep</code></td>
<td>
<p>A character string to separate the terms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with condensed columns that can be wrote to 
csv/xlsx.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcsv_w">mcsv_w</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(qdap)
poldat &lt;- with(DATA.SPLIT, polarity(state, person))
write.csv(x = condense(counts(poldat)), file = "foo.csv")

## End(Not run)
</code></pre>

<hr>
<h2 id='counts'>Generic Counts Method</h2><span id='topic+counts'></span>

<h3>Description</h3>

<p>Access the count dataframes from select qdap outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts_+3A_x">x</code></td>
<td>
<p>A qdap object (list) with a count dataframe (e.g., 
<code><a href="#topic+fry">fry</a></code>).</p>
</td></tr>
<tr><td><code id="counts_+3A_...">...</code></td>
<td>
<p>Arguments passed to counts method of other classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data.frame of counts.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scores">scores</a></code>,
<code><a href="#topic+proportions">proportions</a></code>,
<code><a href="#topic+preprocessed">preprocessed</a></code>,
<code><a href="#topic+visual">visual</a></code>
</p>

<hr>
<h2 id='counts.automated_readability_index'>Readability Measures</h2><span id='topic+counts.automated_readability_index'></span>

<h3>Description</h3>

<p><code>counts.automated_readability_index</code> - View counts from <code><a href="#topic+automated_readability_index">automated_readability_index</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'automated_readability_index'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.automated_readability_index_+3A_x">x</code></td>
<td>
<p>The automated_readability_index object.</p>
</td></tr>
<tr><td><code id="counts.automated_readability_index_+3A_...">...</code></td>
<td>
<p>ignored
automated_readability_index Method for counts.</p>
</td></tr>
</table>

<hr>
<h2 id='counts.character_table'>Term Counts</h2><span id='topic+counts.character_table'></span>

<h3>Description</h3>

<p>View character_table counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'character_table'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.character_table_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+character_table">character_table</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.character_table_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>character_table Method for counts
</p>

<hr>
<h2 id='counts.coleman_liau'>Readability Measures</h2><span id='topic+counts.coleman_liau'></span>

<h3>Description</h3>

<p><code>counts.coleman_liau</code> - View counts from <code><a href="#topic+coleman_liau">coleman_liau</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coleman_liau'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.coleman_liau_+3A_x">x</code></td>
<td>
<p>The coleman_liau object.</p>
</td></tr>
<tr><td><code id="counts.coleman_liau_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>coleman_liau Method for counts.
</p>

<hr>
<h2 id='counts.end_mark_by'>Question Counts</h2><span id='topic+counts.end_mark_by'></span>

<h3>Description</h3>

<p>View end_mark_by counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.end_mark_by_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+end_mark_by">end_mark_by</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.end_mark_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>end_mark_by Method for counts
</p>

<hr>
<h2 id='counts.flesch_kincaid'>Readability Measures</h2><span id='topic+counts.flesch_kincaid'></span>

<h3>Description</h3>

<p><code>counts.flesch_kincaid</code> - View counts from <code><a href="#topic+flesch_kincaid">flesch_kincaid</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flesch_kincaid'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.flesch_kincaid_+3A_x">x</code></td>
<td>
<p>The flesch_kincaid object.</p>
</td></tr>
<tr><td><code id="counts.flesch_kincaid_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>flesch_kincaid Method for counts.
</p>

<hr>
<h2 id='counts.formality'>Formality</h2><span id='topic+counts.formality'></span>

<h3>Description</h3>

<p>View formality counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.formality_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+formality">formality</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>formality Method for counts
</p>

<hr>
<h2 id='counts.fry'>Readability Measures</h2><span id='topic+counts.fry'></span>

<h3>Description</h3>

<p><code>counts.fry</code> - View counts from <code><a href="#topic+fry">fry</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fry'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.fry_+3A_x">x</code></td>
<td>
<p>The fry object.</p>
</td></tr>
<tr><td><code id="counts.fry_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>fry Method for counts.
</p>

<hr>
<h2 id='counts.linsear_write'>Readability Measures</h2><span id='topic+counts.linsear_write'></span>

<h3>Description</h3>

<p><code>counts.linsear_write</code> - View counts from <code><a href="#topic+linsear_write">linsear_write</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'linsear_write'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.linsear_write_+3A_x">x</code></td>
<td>
<p>The linsear_write object.</p>
</td></tr>
<tr><td><code id="counts.linsear_write_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>linsear_write Method for counts.
</p>

<hr>
<h2 id='counts.object_pronoun_type'>Question Counts</h2><span id='topic+counts.object_pronoun_type'></span>

<h3>Description</h3>

<p>View object_pronoun_type counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'object_pronoun_type'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.object_pronoun_type_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+object_pronoun_type">object_pronoun_type</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.object_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>object_pronoun_type Method for counts
</p>

<hr>
<h2 id='counts.polarity'>Polarity</h2><span id='topic+counts.polarity'></span>

<h3>Description</h3>

<p><code>counts.polarity</code> - View counts from <code><a href="#topic+polarity">polarity</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.polarity_+3A_x">x</code></td>
<td>
<p>The polarity object.</p>
</td></tr>
<tr><td><code id="counts.polarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>polarity Method for counts.
</p>

<hr>
<h2 id='counts.pos'>Parts of Speech</h2><span id='topic+counts.pos'></span>

<h3>Description</h3>

<p>View pos counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.pos_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+pos">pos</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.pos_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pos Method for counts
</p>

<hr>
<h2 id='counts.pos_by'>Parts of Speech</h2><span id='topic+counts.pos_by'></span>

<h3>Description</h3>

<p>View pos_by counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos_by'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.pos_by_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+pos_by">pos_by</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.pos_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pos_by Method for counts
</p>

<hr>
<h2 id='counts.pronoun_type'>Question Counts</h2><span id='topic+counts.pronoun_type'></span>

<h3>Description</h3>

<p>View pronoun_type counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pronoun_type'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.pronoun_type_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+pronoun_type">pronoun_type</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pronoun_type Method for counts
</p>

<hr>
<h2 id='counts.question_type'>Question Counts</h2><span id='topic+counts.question_type'></span>

<h3>Description</h3>

<p>View question_type counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'question_type'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.question_type_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+question_type">question_type</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.question_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>question_type Method for counts
</p>

<hr>
<h2 id='counts.SMOG'>Readability Measures</h2><span id='topic+counts.SMOG'></span>

<h3>Description</h3>

<p><code>counts.SMOG</code> - View counts from <code><a href="#topic+SMOG">SMOG</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SMOG'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.SMOG_+3A_x">x</code></td>
<td>
<p>The SMOG object.</p>
</td></tr>
<tr><td><code id="counts.SMOG_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SMOG Method for counts.
</p>

<hr>
<h2 id='counts.subject_pronoun_type'>Question Counts</h2><span id='topic+counts.subject_pronoun_type'></span>

<h3>Description</h3>

<p>View subject_pronoun_type counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subject_pronoun_type'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.subject_pronoun_type_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+subject_pronoun_type">subject_pronoun_type</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.subject_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>subject_pronoun_type Method for counts
</p>

<hr>
<h2 id='counts.termco'>Term Counts</h2><span id='topic+counts.termco'></span>

<h3>Description</h3>

<p>View termco counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'termco'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.termco_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+termco">termco</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.termco_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>termco Method for counts
</p>

<hr>
<h2 id='counts.word_length'>Word Length Counts</h2><span id='topic+counts.word_length'></span>

<h3>Description</h3>

<p>View word_length counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_length'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.word_length_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+word_length">word_length</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.word_length_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>word_length Method for counts
</p>

<hr>
<h2 id='counts.word_position'>Word Position</h2><span id='topic+counts.word_position'></span>

<h3>Description</h3>

<p>View word_position counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_position'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.word_position_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+word_position">word_position</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.word_position_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>word_position Method for counts
</p>

<hr>
<h2 id='counts.word_stats'>Word Stats</h2><span id='topic+counts.word_stats'></span>

<h3>Description</h3>

<p>View word_stats counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_stats'
counts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counts.word_stats_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+word_stats">word_stats</a></code> object.</p>
</td></tr>
<tr><td><code id="counts.word_stats_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>word_stats Method for counts
</p>

<hr>
<h2 id='cumulative'>Cumulative Scores</h2><span id='topic+cumulative'></span><span id='topic+cumulative.end_mark'></span><span id='topic+cumulative.formality'></span><span id='topic+cumulative.pos'></span><span id='topic+cumulative.pos_by'></span><span id='topic+cumulative.animated_formality'></span><span id='topic+cumulative.lexical_classification'></span><span id='topic+cumulative.animated_lexical_classification'></span><span id='topic+cumulative.polarity'></span><span id='topic+cumulative.animated_polarity'></span><span id='topic+cumulative.syllable_freq'></span><span id='topic+cumulative.combo_syllable_sum'></span>

<h3>Description</h3>

<p><code>cumulative</code> - Generate rolling/cumulative scores for select <span class="pkg">qdap</span> 
objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cumulative(x, ...)

## S3 method for class 'end_mark'
cumulative(x, ...)

## S3 method for class 'formality'
cumulative(x, ...)

## S3 method for class 'pos'
cumulative(x, ...)

## S3 method for class 'pos_by'
cumulative(x, ...)

## S3 method for class 'animated_formality'
cumulative(x, ...)

## S3 method for class 'lexical_classification'
cumulative(x, ...)

## S3 method for class 'animated_lexical_classification'
cumulative(x, ...)

## S3 method for class 'polarity'
cumulative(x, ...)

## S3 method for class 'animated_polarity'
cumulative(x, ...)

## S3 method for class 'syllable_freq'
cumulative(x, ...)

## S3 method for class 'combo_syllable_sum'
cumulative(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cumulative_+3A_x">x</code></td>
<td>
<p>A qdap object with an accompanying <code>cumulative</code> method.</p>
</td></tr>
<tr><td><code id="cumulative_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='DATA'>Fictitious Classroom Dialogue</h2><span id='topic+DATA'></span>

<h3>Description</h3>

<p>A fictitious dataset useful for small demonstrations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DATA)
</code></pre>


<h3>Format</h3>

<p>A data frame with 11 rows and 5 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Speaker
</p>
</li>
<li><p> sex. Gender
</p>
</li>
<li><p> adult. Dummy coded adult (0-no; 1-yes)
</p>
</li>
<li><p> state. Statement (dialogue)
</p>
</li>
<li><p> code. Dialogue coding scheme  
</p>
</li></ul>


<hr>
<h2 id='DATA.SPLIT'>Fictitious Split Sentence Classroom Dialogue</h2><span id='topic+DATA.SPLIT'></span>

<h3>Description</h3>

<p>A <code><a href="#topic+sentSplit">sentSplit</a></code> version of the <code><a href="#topic+DATA">DATA</a></code> 
dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DATA.SPLIT)
</code></pre>


<h3>Format</h3>

<p>A data frame with 15 rows and 8 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Speaker
</p>
</li>
<li><p> tot. Turn of talk with sub sentences
</p>
</li>
<li><p> TOT. Turn of talk
</p>
</li>
<li><p> sex. Gender
</p>
</li>
<li><p> adult. Dummy coded adult (0-no; 1-yes)
</p>
</li>
<li><p> code. Dialogue coding scheme 
</p>
</li>
<li><p> state. Statement (dialogue)
</p>
</li>
<li><p> stem.text. A stemmed version of the text.var
</p>
</li></ul>


<hr>
<h2 id='DATA2'>Fictitious Repeated Measures Classroom Dialogue</h2><span id='topic+DATA2'></span>

<h3>Description</h3>

<p>A repeated measures version of the <code><a href="#topic+DATA">DATA</a></code> dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DATA2)
</code></pre>


<h3>Format</h3>

<p>A data frame with 74 rows and 7 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> day. Day of observation
</p>
</li>
<li><p> class. Class period/subject of observation
</p>
</li>
<li><p> person. Speaker
</p>
</li>
<li><p> sex. Gender
</p>
</li>
<li><p> adult. Dummy coded adult (0-no; 1-yes)
</p>
</li>
<li><p> state. Statement (dialogue)
</p>
</li>
<li><p> code. Dialogue coding scheme 
</p>
</li></ul>


<hr>
<h2 id='delete'>Easy File Handling</h2><span id='topic+delete'></span><span id='topic+folder'></span>

<h3>Description</h3>

<p><code>delete</code> - Deletes files and directories.
</p>
<p><code>folder</code> - Create a folder/directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delete(file = NULL)

folder(..., folder.name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delete_+3A_file">file</code></td>
<td>
<p>The name of the file in the working directory or the path to the 
file to be deleted.  If <code>NULL</code> provides a menu of files from the working 
directory.</p>
</td></tr>
<tr><td><code id="delete_+3A_folder.name">folder.name</code></td>
<td>
<p>A character vector of the name(s) of the folder to be 
created.  Default <code>NULL</code>  (if the ...  is <code>NULL</code> too) creates a 
file in the working directory with the creation date and time stamp.  Use 
this argument only if the directory names contain spaces.</p>
</td></tr>
<tr><td><code id="delete_+3A_...">...</code></td>
<td>
<p>The name(s) of the folder to be created.  If both ... and
<code>folder.name</code> are <code>NULL</code> creates a file in the working directory 
with the creation date and time stamp.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>delete</code> permanently removes a file/directory.
</p>
<p><code>folder</code> creates a folder/directory.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+unlink">unlink</a></code>, 
<code><a href="base.html#topic+file.remove">file.remove</a></code>, 
<code><a href="base.html#topic+dir.create">dir.create</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(x &lt;- folder("DELETE.ME"))
which(dir() == "DELETE.ME")
delete("DELETE.ME")
which(dir() == "DELETE.ME")

folder("the/next/big/thing", "hello world", "now/is/the/time")

folder(cat, dog)
lapply(c("cat", "dog"), delete)

## End(Not run)
</code></pre>

<hr>
<h2 id='dir_map'>Map Transcript Files from a Directory to a Script</h2><span id='topic+dir_map'></span>

<h3>Description</h3>

<p>Generate script text (and optionally output it to the clipboard and/or an 
external file) that can be used to individually read in every file in a 
directory and assign it to an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dir_map(
  loc = "DATA/TRANSCRIPTS/CLEANED_TRANSCRIPTS",
  obj.prefix = "dat",
  use.path = TRUE,
  col.names = c("person", "dialogue"),
  file = NULL,
  copy2clip = interactive()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dir_map_+3A_loc">loc</code></td>
<td>
<p>The path/location of the transcript data files.</p>
</td></tr>
<tr><td><code id="dir_map_+3A_obj.prefix">obj.prefix</code></td>
<td>
<p>A character string that will be used as the prefix (followed 
by a unique digit) as the assignment object.</p>
</td></tr>
<tr><td><code id="dir_map_+3A_use.path">use.path</code></td>
<td>
<p>logical.  If <code>TRUE</code> use the actual path to the 
<code>loc</code> argument.  If <code>FALSE</code>, the  code may be more portable in that 
the actual input to <code>loc</code> is supplied to the 
<code><a href="#topic+read.transcript">read.transcript</a></code>.</p>
</td></tr>
<tr><td><code id="dir_map_+3A_col.names">col.names</code></td>
<td>
<p>Supplies a vector of column names to the transcript columns.</p>
</td></tr>
<tr><td><code id="dir_map_+3A_file">file</code></td>
<td>
<p>A connection, or a character string naming the file to print to.</p>
</td></tr>
<tr><td><code id="dir_map_+3A_copy2clip">copy2clip</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to copy the output to the 
clipboard.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generally, the researcher will want to read in and parse every 
transcript document separately.  The task of writing the script for multiple 
transcript documents can be tedious.  This function is designed to make the 
process more efficient and less prone to errors.
</p>


<h3>Value</h3>

<p>Prints a read in script text to the console, optionally copies the 
wrapped text to the clipboard on a Mac or Windows machine and optionally 
prints to an outside file.
</p>


<h3>Note</h3>

<p><code>skip</code> is set to 0, however, it is likely that this value will 
need to be changed for each transcript.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.transcript">read.transcript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(DIR &lt;- system.file("extdata/transcripts", package = "qdap"))
dir_map(DIR)

## End(Not run)
</code></pre>

<hr>
<h2 id='discourse_map'>Discourse Mapping</h2><span id='topic+discourse_map'></span>

<h3>Description</h3>

<p>View the flow of discourse from social actors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discourse_map(
  text.var,
  grouping.var,
  edge.constant,
  sep = "_",
  condense = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discourse_map_+3A_text.var">text.var</code></td>
<td>
<p>The text variable or a  <code>"word_stats"</code> object (i.e., the 
output of a <code>word_stats</code> function).</p>
</td></tr>
<tr><td><code id="discourse_map_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Also takes a single grouping 
variable or a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="discourse_map_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple the edges by.  Defaults (if 
<code>missing</code>) to 2.5 times the number of social actors.</p>
</td></tr>
<tr><td><code id="discourse_map_+3A_sep">sep</code></td>
<td>
<p>The separator character to use between grouping variables.</p>
</td></tr>
<tr><td><code id="discourse_map_+3A_condense">condense</code></td>
<td>
<p>logical.  If <code>TRUE</code> <code>sentCombine</code> is used to 
condense text by grouping variable.</p>
</td></tr>
<tr><td><code id="discourse_map_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For an example of the video generated from the <code>Animate</code> 
output of <code>discourse_map</code> see: 
https://www.youtube.com/watch?v=7LcqFZODXNo&amp;feature=youtu.be.  An HTML
output can be viewed: 
http://trinker.github.io/qdap_examples/animation_dialogue/.
</p>


<h3>Value</h3>

<p>Returns a list:
</p>
<table>
<tr><td><code>raw</code></td>
<td>
<p>The dataframe with to and from columns (the edges) + word counts</p>
</td></tr>
<tr><td><code>edge_word_count</code></td>
<td>
<p>A dataframe of edges and word counts + proportional 
word count</p>
</td></tr>
<tr><td><code>vertex_word_count</code></td>
<td>
<p>A dataframe of vertices and word counts + 
proportional word count</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>An <span class="pkg">igraph</span> object</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
discourse_map(DATA$state, list(DATA$person, DATA$sex))
x &lt;- with(mraja1, discourse_map(dialogue, person))
x
lview(x)
library(igraph)
plot(visual(x), edge.curved=FALSE)

## Quickly add/remove a title
Title(x) &lt;- "Act 1"
x
Title(x) &lt;- NULL
x

## Augmenting the plot
library(qdapTools)
mygraph &lt;- visual(x)

plot(mygraph, edge.curved=TRUE)

V(mygraph)$sex &lt;- V(mygraph)$name %lc% raj.demographics[, 1:2]
V(mygraph)$color &lt;- ifelse(V(mygraph)$sex=="f", "pink", "lightblue")

plot(mygraph, edge.curved=TRUE)

V(mygraph)$family &lt;- V(mygraph)$name %l+% raj.demographics[, c(1, 3)]
cols &lt;- qcv(blue, red, brown, darkgreen, grey10)
V(mygraph)$label.color &lt;- lookup(V(mygraph)$family, 
    unique(V(mygraph)$family), cols)

plot(mygraph, edge.curved=TRUE)

## Community detection
x &lt;- with(mraja1, discourse_map(dialogue, person))
wc &lt;- walktrap.community(visual(x))
colors &lt;- grDevices::rainbow(max(membership(wc)))
plot(x, vertex.color=colors[membership(wc)])

## Repeated Measures (BASIC EXAMPLE)
##------------------------------

## First merge data and map to discourse per act 
## to separate networks

dat &lt;- key_merge(raj, raj.demographics)
list_dat &lt;- split(dat, dat$act)
plot_dat &lt;- lapply(list_dat, function(x) with(x, discourse_map(dialogue, person)))

opar &lt;- par()$mar
par(mfrow=c(3, 2), mar=c(0, 0, 3, 0))

lapply(seq_along(plot_dat), function(i){
    plot(plot_dat[[i]])
    graphics::mtext(paste("Act", names(plot_dat)[i]), side=3)
})


## Repeated Measures (EXTENDED EXAMPLE)
##------------------------------
fam_key &lt;- data.frame(fam=unique(raj.demographics$fam.aff),
    cols=qcv(blue, grey10, red, orange), 
    stringsAsFactors = FALSE)

par(mfrow=c(3, 2), mar=c(0, 1, 3, 1))
lapply(seq_along(plot_dat), function(i){

    THE_PLOT &lt;- visual(plot_dat[[i]])

    V(THE_PLOT)$sex &lt;- V(THE_PLOT)$name %l% raj.demographics[, 1:2]
    V(THE_PLOT)$color &lt;- ifelse(V(THE_PLOT)$sex=="f", "pink", "lightblue")
    V(THE_PLOT)$family &lt;- V(THE_PLOT)$name %lc+% raj.demographics[, c(1, 3)]
    V(THE_PLOT)$label.color &lt;- lookup(V(THE_PLOT)$family, fam_key)

    plot(THE_PLOT, edge.curved=TRUE)
    graphics::mtext(paste("Act", names(plot_dat)[i]), side=3)
})
frame()
bords &lt;- rep("black", 7)
bords[3] &lt;- "white"
legend(.29, .95, c("Female", "Male", NA, as.character(fam_key[, 1])), 
    fill=c("pink", "lightblue", NA, fam_key[, 2]), border=bords, cex=1.5) 

## Reset graphics margins
par(mar=opar)

## ANIMATION
#===========
test &lt;- discourse_map(DATA$state, list(DATA$person))

## Very quick, hard to see
Animate(test)

pdf("test.pdf")
    par(mar=c(0, 0, 1, 0))
    Animate(test, title="Test Plot")
dev.off()

## Animate it
##-----------
library(animation)
library(igraph)

loc &lt;- folder(animation_dialogue)
ans &lt;- Animate(test)

## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)

FUN &lt;- function() {
    lapply(seq_along(ans), function(i) {
        par(mar=c(0, 0, 1, 0))
        set.seed(10)
        plot.igraph(ans[[i]], edge.curved=TRUE, layout=layout.circle)
        graphics::mtext("Discourse Map", side=3)
        animation::ani.pause()
    })
}

## Detect OS
type &lt;- if(.Platform$OS.type == "windows") shell else system
saveGIF(FUN(), interval = 0.1, outdir = loc, cmd.fun = type)

saveVideo(FUN(), video.name = "discourse_map.avi", interval = 0.1, outdir = loc)

saveLatex(FUN(), autoplay = TRUE, loop = FALSE, latex.filename = "tester.tex", 
    caption = "animated dialogue", outdir = loc, ani.type = "pdf", 
    ani.dev = "pdf", ani.width = 5, ani.height = 5.5, interval = 0.1)

saveHTML(FUN(), autoplay = FALSE, loop = TRUE, verbose = FALSE, 
    outdir = file.path(loc, "new"), single.opts = 
    "'controls': ['first', 'previous', 'play', 'next', 'last', 'loop', 'speed'], 'delayMin': 0")
    
    
## More Elaborate Layout
test2 &lt;- with(mraja1, discourse_map(dialogue, person))

loc2 &lt;- folder(animation_dialogue2)
ans2 &lt;- Animate(test2)
## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)

FUN3 &lt;- function() {
    lapply(seq_along(ans2), function(i) {
        par(mar=c(0, 0, 1, 0))
        set.seed(10)
        plot.igraph(ans2[[i]], edge.curved=TRUE, layout=layout.auto)
        graphics::mtext("Discourse Map\nRomeo and Juliet: Act 1", side=3)
        animation::ani.pause()
    })
}

saveHTML(FUN3(), autoplay = FALSE, loop = FALSE, verbose = FALSE,
    outdir = file.path(loc2, "new"), single.opts =
    "'controls': ['first', 'play', 'loop', 'speed'], 'delayMin': 0")
    
saveVideo(FUN3(), video.name = "discourse_map.avi", interval = 0.2, 
    outdir = loc2)    

## End(Not run)
</code></pre>

<hr>
<h2 id='dispersion_plot'>Lexical Dispersion Plot</h2><span id='topic+dispersion_plot'></span>

<h3>Description</h3>

<p>Generate a lexical dispersion plot of terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dispersion_plot(
  text.var,
  match.terms,
  grouping.var = NULL,
  rm.vars = NULL,
  color = "blue",
  bg.color = "grey90",
  horiz.color = "grey85",
  total.color = "black",
  symbol = "|",
  title = "Lexical Dispersion Plot",
  rev.factor = TRUE,
  wrap = "'",
  xlab = "Dialogue (Words)",
  ylab = NULL,
  size = 4,
  plot = TRUE,
  char2space = "~~",
  apostrophe.remove = FALSE,
  scales = "free",
  space = "free",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dispersion_plot_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_match.terms">match.terms</code></td>
<td>
<p>A vector of quoted terms or a named list of quoted terms.
If the latter terms will be combined into a single unified theme named 
according to the list names.  Note that terms within the vectors of the list 
cannot be duplicated.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_rm.vars">rm.vars</code></td>
<td>
<p>The repeated measures variables.  Default <code>NULL</code> generates 
one facet for all text.  Also takes a single repeated measures variable or 
a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_color">color</code></td>
<td>
<p>The color of the word symbols.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_bg.color">bg.color</code></td>
<td>
<p>The background color.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_horiz.color">horiz.color</code></td>
<td>
<p>The color of the horizontal tracking stripe.  Use 
<code>horiz.color = bg.color</code> to eliminate.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_total.color">total.color</code></td>
<td>
<p>The color to use for summary 'all' group.  If <code>NULL</code>
totals are dropped.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_symbol">symbol</code></td>
<td>
<p>The word symbol.  Default is <code>"|"</code>.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_title">title</code></td>
<td>
<p>Title of the plot</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_rev.factor">rev.factor</code></td>
<td>
<p>logical.  If <code>TRUE</code> reverses the plot order of the 
factors.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_wrap">wrap</code></td>
<td>
<p>a character to wrap around the words (enables the reader to 
visualize spaces).  Default is <code>"'"</code>, use <code>""</code> to remove.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_xlab">xlab</code></td>
<td>
<p>The x label.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_ylab">ylab</code></td>
<td>
<p>The y label.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_size">size</code></td>
<td>
<p>The size of the plotting symbol.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_char2space">char2space</code></td>
<td>
<p>A vector of characters to be turned into spaces.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophes from 
the output.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_scales">scales</code></td>
<td>
<p>Should scales be fixed (<code>"fixed"</code>, the default), free 
(<code>"free"</code>), or free in one dimension (<code>"free_x"</code>, <code>"free_y"</code>)</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_space">space</code></td>
<td>
<p>If <code>"fixed"</code>, the default, all panels have the same size. 
If <code>"free_y"</code> their height will be proportional to the length of the y 
scale; if <code>"free_x"</code> their width will be proportional to the length of 
the x scale; or if <code>"free"</code> both height and width will vary.</p>
</td></tr>
<tr><td><code id="dispersion_plot_+3A_...">...</code></td>
<td>
<p>Other argument supplied to <code><a href="#topic+strip">strip</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plots a dispersion plot and invisibly returns the ggplot2 object.
</p>


<h3>Note</h3>

<p>The match.terms is character sensitive.  Spacing is an important way 
to grab specific words and requires careful thought.  Using &quot;read&quot; will find 
the words &quot;bread&quot;, &quot;read&quot; &quot;reading&quot;, and &quot;ready&quot;.  If you want to search 
for just the word &quot;read&quot; you'd supply a vector of c(&quot; read &quot;, &quot; reads&quot;, 
&quot; reading&quot;, &quot; reader&quot;).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+term_match">term_match</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
term_match(raj$dialogue, c(" love ", "love", " night ", "night"))
dispersion_plot(raj$dialogue, c(" love ", "love", " night ", "night"))
dispersion_plot(raj$dialogue, c("love", "night"), rm.vars = raj$act)
with(rajSPLIT , dispersion_plot(dialogue, c("love", "night"), 
    grouping.var = list(fam.aff, sex), rm.vars = act))

## With grouping variables
with(rajSPLIT , dispersion_plot(dialogue, c("love", "night"), 
     grouping.var = sex, rm.vars = act))

## Drop total with `total.color = NULL`
with(rajSPLIT , dispersion_plot(dialogue, c("love", "night"), 
     grouping.var = sex, rm.vars = act, total.color = NULL))

## Change color scheme
with(rajSPLIT, dispersion_plot(dialogue, c("love", "night"), 
    bg.color = "black", grouping.var = list(fam.aff, sex), 
    color = "yellow", total.color = "white", horiz.color="grey20"))
    
## Use `word_list`
## Presidential debates by all
wrds &lt;- word_list(pres_debates2012$dialogue, stopwords = Top200Words)
wrds2 &lt;- spaste(wrds[["rfswl"]][["all"]][, "WORD"])
wrds2 &lt;- c(" governor~~romney ", wrds2[-c(3, 12)])
with(pres_debates2012 , dispersion_plot(dialogue, wrds2, rm.vars = time))

## Presidential debates by person
dat &lt;- pres_debates2012
dat &lt;- dat[dat$person %in% qcv(ROMNEY, OBAMA), ]

wordlist &lt;- c(" tax", " health", " rich ", "america", " truth", 
    " money", "cost", " governnor", " president", " we ", 
    " job", " i ", " you ", " because ", " our ", " years ")

with(dat, dispersion_plot(dialogue, wordlist, total.color = NULL, 
    bg.color = "white", grouping.var = person, rm.vars = time,
    color = "black", horiz.color="grey80"))

wordlist2 &lt;- c(" i'd ", " i'll ", " i'm ", " i've ", " i ", 
    " we'd ", " we'll ", " we're ", " we've ", " we ", 
    " you'd ",  " you'll ", " you're ", " you've ", " you ", " your ",
    " he'd ", " he'll ", " he's ", " he ")

with(dat, dispersion_plot(dialogue, wordlist2, 
    bg.color = "black", grouping.var = person, rm.vars = time,
    color = "yellow", total.color = NULL, horiz.color="grey20"))
   
with(dat, dispersion_plot(dialogue, wordlist2, 
    bg.color = "black", grouping.var = person, rm.vars = time,
    color = "red", total.color = "white", horiz.color="grey20"))

## `match.terms` as a named list        
wordlist3 &lt;- list(
    I = c(" i'd ", " i'll ", " i'm ", " i've ", " i "),
    we = c(" we'd ", " we'll ", " we're ", " we've ", " we "),
    you = c(" you'd ",  " you'll ", " you're ", " you've ", " you ", " your "),
    he = c(" he'd ", " he'll ", " he's ", " he ")
)

with(dat, dispersion_plot(dialogue, wordlist3,
    bg.color = "grey60", grouping.var = person, rm.vars = time,
    color = "blue", total.color = "grey40", horiz.color="grey20"))

colsplit2df(scores(with(dat, termco(dialogue, list(time, person), wordlist3))))

## Extras:
## Reverse facets

x &lt;- with(pres_debates2012 , dispersion_plot(dialogue, wrds2, rm.vars = time))

## function to reverse ggplot2 facets
rev_facet &lt;- function(x) {
    names(x$facet)[1:2] &lt;- names(x$facet)[2:1]
    print(x)
}

rev_facet(x)

## Discourse Markers: See...
## Schiffrin, D. (2001). Discourse markers: Language, meaning, and context. 
##    In D. Schiffrin, D. Tannen, &amp; H. E. Hamilton (Eds.), The handbook of 
##    discourse analysis (pp. 54-75). Malden, MA: Blackwell Publishing.

discoure_markers &lt;- list(
    response_cries = c(" oh ", " ah ", " aha ", " ouch ", " yuk "),
    back_channels = c(" uh-huh ", " uhuh ", " yeah "), 
    summons = " hey ", 
    justification = " because "
)

(markers &lt;- with(pres_debates2012, 
    termco(dialogue, list(person, time), discoure_markers)
))
plot(markers, high="red")

with(pres_debates2012, 
    termco(dialogue, list(person, time), discoure_markers, elim.old = FALSE)
)

with(pres_debates2012, 
    dispersion_plot(dialogue, unlist(discoure_markers), person, time)
)

## End(Not run)
</code></pre>

<hr>
<h2 id='Dissimilarity'>Dissimilarity Statistics</h2><span id='topic+Dissimilarity'></span>

<h3>Description</h3>

<p>Uses the distance function to calculate dissimilarity statistics by grouping 
variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dissimilarity(
  text.var,
  grouping.var = NULL,
  method = "prop",
  diag = FALSE,
  upper = FALSE,
  p = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dissimilarity_+3A_text.var">text.var</code></td>
<td>
<p>A text variable or word frequency matrix object.</p>
</td></tr>
<tr><td><code id="Dissimilarity_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="Dissimilarity_+3A_method">method</code></td>
<td>
<p>Distance methods (see <code><a href="stats.html#topic+dist">dist</a></code> function).
If <code>"prop"</code> (the default) the result is 1 - <code>"binary"</code>.</p>
</td></tr>
<tr><td><code id="Dissimilarity_+3A_diag">diag</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns the diagonals of the matrix.  If 
<code>method = "prop"</code> diagonals will not be returned.</p>
</td></tr>
<tr><td><code id="Dissimilarity_+3A_upper">upper</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns the upper triangle of the 
matrix.</p>
</td></tr>
<tr><td><code id="Dissimilarity_+3A_p">p</code></td>
<td>
<p>The power of the Minkowski distance.</p>
</td></tr>
<tr><td><code id="Dissimilarity_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+wfm">wfm</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix of dissimilarity values (the agreement between text).
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dist">dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(DATA, Dissimilarity(state, list(sex, adult)))
with(DATA, Dissimilarity(state, person, diag = TRUE))

## Clustering: Dendrogram
(x &lt;- with(pres_debates2012, Dissimilarity(dialogue, list(person, time))))
fit &lt;- hclust(x)
plot(fit)
## draw dendrogram with red borders around the 3 clusters 
rect.hclust(fit, k=3, border=c("red", "purple", "seagreen"))

## Clustering: Dendrogram with p.values
library(pvclust)
wfm.mod &lt;- with(pres_debates2012, wfm(dialogue, list(person, time)))
fit &lt;- suppressMessages(pvclust(wfm.mod, method.hclust="ward",
    method.dist="euclidean"))
plot(fit) 
pvrect(fit, alpha=.95)

## Multidimentional Scaling
## Based on blog post from Bodong Chen
## http://bodongchen.com/blog/?p=301

## Fit it: 2-D
(diss &lt;- with(pres_debates2012, Dissimilarity(dialogue, list(person, time), 
    method = "euclidean")))
fit &lt;- cmdscale(diss, eig = TRUE, k = 2)

## Plot it 2-D
points &lt;- data.frame(x = fit$points[, 1], y = fit$points[, 2])
ggplot(points, aes(x = x, y = y)) + 
    geom_point(data = points, aes(x = x, y = y, color = rownames(points))) + 
    geom_text(data = points, aes(x = x, y = y - 0.2, label = row.names(points)))
    
## Fit it: 3-D
library(scatterplot3d)
fit &lt;- cmdscale(diss, eig = TRUE, k = 3)

points &lt;- data.frame(colSplit(names(fit$points[, 1])))
library(qdapTools)
points$colors &lt;- points$X1 %l% data.frame(levels(points$X1), 
    qcv(yellow, yellow, blue, yellow, red, yellow))
points$shape &lt;- points$X2 %l% data.frame(levels(points$X2), c(15, 17, 19))

## Plot it: 3-D
scatterplot3d(fit$points[, 1], fit$points[, 2], fit$points[, 3], 
    color = points$colors, pch = points$shape, 
    main = "Semantic Space Scaled to 3D", xlab = "x", ylab = "y", 
    zlab = "z", type = "h")

legend("bottomright", title="Person",
   qcv(Obama, Romney, Other), fill=qcv(blue, red, yellow))
legend("topleft",  paste("Time", 1:3), pch=c(15, 17, 19))

## Compare to Cosine Similarity
cos_sim &lt;- function(x, y) x %*% y / sqrt(x%*%x * y%*%y)
mat &lt;- matrix(rbinom(500, 0:1, .45), ncol=10)
v_outer(mat, cos_sim)

v_outer(with(DATA, wfm(state, person)), cos_sim)
with(DATA, Dissimilarity(state, person))

## End(Not run)
</code></pre>

<hr>
<h2 id='dist_tab'>SPSS Style Frequency Tables</h2><span id='topic+dist_tab'></span>

<h3>Description</h3>

<p>Generates a distribution table for vectors, matrices and dataframes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist_tab(dataframe, breaks = NULL, digits = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist_tab_+3A_dataframe">dataframe</code></td>
<td>
<p>A vector or data.frame object.</p>
</td></tr>
<tr><td><code id="dist_tab_+3A_breaks">breaks</code></td>
<td>
<p>Either a numeric vector of two or more cut points or a single 
number (greater than or equal to 2) giving the number of intervals into which 
x is to be cut.</p>
</td></tr>
<tr><td><code id="dist_tab_+3A_digits">digits</code></td>
<td>
<p>Integer indicating the number of decimal places (round) or 
significant digits (signif.) to be used. Negative values are allowed</p>
</td></tr>
<tr><td><code id="dist_tab_+3A_...">...</code></td>
<td>
<p>Other variables passed to cut.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of data frames (or singular data frame for a vector) of 
frequencies, cumulative frequencies, percentages and cumulative percentages 
for each interval.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cut">cut</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dist_tab(rnorm(10000), 10)
dist_tab(sample(c("red", "blue", "gray"), 100, T), right = FALSE)
dist_tab(CO2, 4)

out1 &lt;- dist_tab(mtcars[, 1:3])
ltruncdf(out1, 4)

out2 &lt;- dist_tab(mtcars[, 1:3], 4)
ltruncdf(out2, 4)

wdst &lt;- with(mraja1spl, word_stats(dialogue, list(sex, fam.aff, died)))
out3 &lt;- dist_tab(wdst$gts[1:4])
ltruncdf(out3, 4)

## End(Not run)
</code></pre>

<hr>
<h2 id='diversity'>Diversity Statistics</h2><span id='topic+diversity'></span>

<h3>Description</h3>

<p>Transcript apply diversity/richness indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diversity(text.var, grouping.var = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diversity_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="diversity_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are the formulas used to calculate the indices:
</p>
<p><b>Shannon index:</b>
</p>
<p style="text-align: center;"><code class="reqn">H_1(X)=-\sum\limits_{i=1}^R{p_i};log;p_i</code>
</p>

<p>Shannon, C. E. (1948). A mathematical theory of communication. Bell System <br />
</p>
<p><b>Simpson index:</b>
</p>
<p style="text-align: center;"><code class="reqn">D=\frac{\sum_{i=1}^R{p_i};n_i(n_i -1)}{N(N-1))}</code>
</p>

<p>Simpson, E. H. (1949). Measurement of diversity. Nature 163, p. 688 <br />
</p>
<p><b>Collision entropy:</b>
</p>
<p style="text-align: center;"><code class="reqn">H_2(X)=-log\sum_{i=1}^n{p_i}^2</code>
</p>

<p>Renyi, A. (1961). On measures of information and entropy. Proceedings of the
4th Berkeley Symposium on Mathematics, Statistics and Probability, 1960.  
pp. 547-5661. <br />
</p>
<p><b>Berger Parker index:</b>
</p>
<p style="text-align: center;"><code class="reqn">D_{BP}=\frac{N_{max}}{N}</code>
</p>

<p>Berger, W. H., &amp; Parker, F. L.(1970). Diversity of planktonic Foramenifera in 
deep sea sediments. Science 168, pp. 1345-1347. <br />
</p>
<p><b>Brillouin index:</b>
</p>
<p style="text-align: center;"><code class="reqn">H_B=\frac{ln(N!)-\sum{ln(n_1)!}}{N}</code>
</p>

<p>Magurran, A. E. (2004). Measuring biological diversity. Blackwell.
</p>


<h3>Value</h3>

<p>Returns a dataframe of various diversity related indices for Shannon, 
collision, Berger Parker and Brillouin.
</p>


<h3>References</h3>

<p>https://arxiv.org/abs/physics/0512106
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
div.mod &lt;- with(mraja1spl, diversity(dialogue, list(sex, died, fam.aff)))
colsplit2df(div.mod)
plot(div.mod, high = "red", low = "yellow")
plot(div.mod, high = "red", low = "yellow", values = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='duplicates'>Find Duplicated Words in a Text String</h2><span id='topic+duplicates'></span>

<h3>Description</h3>

<p>Find duplicated word/word chunks in a string.  Intended for internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplicates(string, threshold = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duplicates_+3A_string">string</code></td>
<td>
<p>A character string.</p>
</td></tr>
<tr><td><code id="duplicates_+3A_threshold">threshold</code></td>
<td>
<p>An integer of the minimal number of repeats.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of all duplicated words/chunks.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
duplicates(DATA$state)
duplicates(DATA$state[1])

## End(Not run)
</code></pre>

<hr>
<h2 id='end_inc'>Test for Incomplete Sentences</h2><span id='topic+end_inc'></span>

<h3>Description</h3>

<p>Test for incomplete sentences and optionally remove them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>end_inc(dataframe, text.var, warning.report = TRUE, which.mode = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="end_inc_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe that contains the person and text variable.</p>
</td></tr>
<tr><td><code id="end_inc_+3A_text.var">text.var</code></td>
<td>
<p>A character string of the text variable.</p>
</td></tr>
<tr><td><code id="end_inc_+3A_warning.report">warning.report</code></td>
<td>
<p>logical.  If <code>TRUE</code> prints a warning of regarding 
removal of incomplete sentences.</p>
</td></tr>
<tr><td><code id="end_inc_+3A_which.mode">which.mode</code></td>
<td>
<p>logical.  If <code>TRUE</code> outputs two logical vectors: 'NOT' 
(logical test of not being an incomplete sentence) and 'INC' (logical test of 
being an incomplete sentence)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generates a dataframe with incomplete sentences removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- sentSplit(DATA, "state", stem.col = FALSE)
dat$state[c(2, 5)] &lt;- paste(strip(dat$state[c(2, 5)]), "|")
end_inc(dat, "state")
end_inc(dat, "state", warning.report = FALSE)
end_inc(dat, "state", which.mode = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='end_mark'>Sentence End Marks</h2><span id='topic+end_mark'></span><span id='topic+end_mark_by'></span>

<h3>Description</h3>

<p><code>end_mark</code> - Grab the sentence end marks for a transcript.  This can be 
useful to categorize based on sentence type.
</p>
<p><code>end_mark_by</code> - Grab the sentence end marks for a transcript by grouping 
variable(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>end_mark(
  text.var,
  missing.end.mark = "_",
  missing.text = NA,
  other.endmarks = NULL
)

end_mark_by(
  text.var,
  grouping.var,
  digits = 3,
  percent = FALSE,
  zero.replace = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="end_mark_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="end_mark_+3A_missing.end.mark">missing.end.mark</code></td>
<td>
<p>A value to use for sentences with missing endmarks.</p>
</td></tr>
<tr><td><code id="end_mark_+3A_missing.text">missing.text</code></td>
<td>
<p>A value to use for sentences with missing (<code>NA</code>) 
text.</p>
</td></tr>
<tr><td><code id="end_mark_+3A_other.endmarks">other.endmarks</code></td>
<td>
<p>Other 1-2 character endmarks to search for.</p>
</td></tr>
<tr><td><code id="end_mark_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="end_mark_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="end_mark_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="end_mark_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.</p>
</td></tr>
<tr><td><code id="end_mark_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>end_mark</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector of qdap end marks for each sentence.  
End marks include:
</p>
<table>
<tr><td><code>"."</code></td>
<td>
<p>Declarative sentence.</p>
</td></tr> 
<tr><td><code>"?"</code></td>
<td>
<p>Question sentence.</p>
</td></tr> 
<tr><td><code>"!"</code></td>
<td>
<p>Exclamatory sentence.</p>
</td></tr> 
<tr><td><code>"|"</code></td>
<td>
<p>Incomplete sentence.</p>
</td></tr> 
<tr><td><code>"*."</code></td>
<td>
<p>Imperative-declarative sentence.</p>
</td></tr> 
<tr><td><code>"*?"</code></td>
<td>
<p>Imperative-question sentence (unlikely to occur)</p>
</td></tr> 
<tr><td><code>"*!"</code></td>
<td>
<p>Imperative-exclamatory sentence.</p>
</td></tr> 
<tr><td><code>"*|"</code></td>
<td>
<p>Imperative-incomplete sentence.</p>
</td></tr> 
<tr><td><code>"no.em"</code></td>
<td>
<p>No end mark.</p>
</td></tr>
<tr><td><code>"blank"</code></td>
<td>
<p>Empty cell/NA.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
end_mark(DATA.SPLIT$state)
end_mark(mraja1spl$dialogue)
table(end_mark(mraja1spl$dialogue))
plot(end_mark(mraja1spl$dialogue))
ques &lt;- mraja1spl[end_mark(mraja1spl$dialogue) == "?", ] #grab questions
htruncdf(ques)
non.ques &lt;- mraja1spl[end_mark(mraja1spl$dialogue) != "?", ] #non questions
htruncdf(non.ques, 20)
ques.per &lt;- mraja1spl[end_mark(mraja1spl$dialogue) %in% c(".", "?"), ] #grab ? and .
htruncdf(ques.per, 20)

(x_by &lt;- end_mark_by(DATA.SPLIT$state, DATA.SPLIT$person))
scores(x_by)
counts(x_by)
proportions(x_by)
preprocessed(x_by)
plot(scores(x_by))
plot(counts(x_by))
plot(proportions(x_by))
plot(preprocessed(x_by))

#================================#
## End Marks Over Time Examples ##
#================================#
##EXAMPLE 1
sentpres &lt;- lapply(with(pres_debates2012, split(dialogue, time)), function(x) {
    end_mark(x)
})

sentplots &lt;- lapply(seq_along(sentpres), function(i) {
    m &lt;- plot(cumulative(sentpres[[i]]))
    if (i != 2) m &lt;- m + ylab("")
    if (i != 3) m &lt;- m + xlab(NULL)
    m + ggtitle(paste("Debate", i))
})

library(grid)
library(gridExtra)
do.call(grid.arrange, sentplots)

##EXAMPLE 2
sentraj &lt;- lapply(with(rajSPLIT, split(dialogue, act)), function(x) {
    end_mark(x)
})
 
sentplots2 &lt;- lapply(seq_along(sentraj), function(i) {
    m &lt;- plot(cumulative(sentraj[[i]]))
    if (i != 2) m &lt;- m + ylab("")
    if (i != 3) m &lt;- m + xlab(NULL)
    act &lt;- qcv(I, II, III, IV, V)
    m + ggtitle(paste("Act", act[i]))
})

## ggplot2 function to extract legend
g_legend &lt;- function(a.gplot){ 
    tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) 
    leg &lt;- which(sapply(tmp[["grobs"]], function(x) x[["name"]]) == "guide-box") 
    legend &lt;- tmp[["grobs"]][[leg]] 
    legend
} 

## remove legends from plots
sentplots3 &lt;- lapply(sentplots2, function(x){
    x + theme(legend.position="none") + xlab(NULL) + ylab(NULL)
})

sentplots3[[6]] &lt;- g_legend(sentplots2[[1]]) 

do.call(grid.arrange, sentplots3)

## End(Not run)
</code></pre>

<hr>
<h2 id='env.syl'>Syllable Lookup Environment</h2><span id='topic+env.syl'></span>

<h3>Description</h3>

<p>A dataset containing a syllable lookup environment (see <code>DICTIONARY</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(env.syl)
</code></pre>


<h3>Format</h3>

<p>A environment with the DICTIONARY data set.
</p>


<h3>Details</h3>

<p>For internal use.
</p>


<h3>References</h3>

<p><a href="https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/nettalk/">UCI Machine Learning Repository website</a>
</p>

<hr>
<h2 id='exclude'>Exclude Elements From a Vector</h2><span id='topic+exclude'></span><span id='topic+exclude.TermDocumentMatrix'></span><span id='topic+exclude.DocumentTermMatrix'></span><span id='topic+exclude.wfm'></span><span id='topic+exclude.list'></span><span id='topic+exclude.default'></span><span id='topic++25ex+25'></span>

<h3>Description</h3>

<p><code>exclude</code> - Quickly exclude words from a word list
</p>
<p><code>%ex%</code> - Binary operator version of <code><a href="#topic+exclude">exclude</a></code> .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exclude(word.list, ...)

## S3 method for class 'TermDocumentMatrix'
exclude(word.list, ...)

## S3 method for class 'DocumentTermMatrix'
exclude(word.list, ...)

## S3 method for class 'wfm'
exclude(word.list, ...)

## S3 method for class 'list'
exclude(word.list, ...)

## Default S3 method:
exclude(word.list, ...)

word.list %ex% ...
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exclude_+3A_word.list">word.list</code></td>
<td>
<p>A list/vector of words/terms, a <code><a href="#topic+wfm">wfm</a></code>, 
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>, or <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code>
to exclude from.</p>
</td></tr>
<tr><td><code id="exclude_+3A_...">...</code></td>
<td>
<p>A vector (character/numeric) if element(s) to be excluded from 
the <code>word.list</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector with the excluded terms removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
exclude(1:10, 3, 4)
exclude(1:10, 3:4)
Top25Words
exclude(Top25Words, qcv(the, of, and))
exclude(Top25Words, "the", "of", "an")

#Using with term_match and termco 
terms &lt;- term_match(DATA$state, qcv(th), FALSE) 
exclude(terms, "truth")  
#all together
termco(DATA$state, DATA$person, exclude(term_match(DATA$state, qcv(th), 
    FALSE), "truth"))

MTCH.LST &lt;- exclude(term_match(DATA$state, qcv(th, i)), qcv(truth, stinks))
termco(DATA$state, DATA$person, MTCH.LST)

## Works with wfm
dat &lt;- wfm(DATA$state, DATA$person)
the.no &lt;- term_match(DATA$state, c("the", "no"))
exclude(dat, unlist(the.no))

## Works with tm's TermDocumentMatrix/DocumentTermMatrix
dat2 &lt;- as.dtm(DATA$state, DATA$person)
out.dtm &lt;- exclude(dat2, unlist(the.no))
tm::inspect(out.dtm)

dat3 &lt;- as.tdm(DATA$state, DATA$person)
out.tdm &lt;- exclude(dat3, unlist(the.no))
tm::inspect(out.tdm)

## End(Not run)
</code></pre>

<hr>
<h2 id='Filter.all_words'>Filter</h2><span id='topic+Filter.all_words'></span><span id='topic+Filter.TermDocumentMatrix'></span><span id='topic+Filter.DocumentTermMatrix'></span><span id='topic+Filter'></span><span id='topic+Filter.wfm'></span><span id='topic+Filter.character'></span><span id='topic+Filter.fwl'></span><span id='topic+Filter.fswl'></span><span id='topic+Filter.rfswl'></span>

<h3>Description</h3>

<p><code>Filter.all_words</code> - Filter words from a all_words 
that meet max/min word length criteria.
</p>
<p><code>Filter.TermDocumentMatrix</code> - Filter words from a TermDocumentMatrix vector that meet 
max/min word length criteria.
</p>
<p><code>Filter.DocumentTermMatrix</code> - Filter words from a DocumentTermMatrix 
that meet max/min word length criteria.
</p>
<p><code>Filter</code> - Filter words from various objects that meet max/min word 
length criteria.
</p>
<p><code>Filter.wfm</code> - Filter words from a wfm that meet max/min word length 
criteria.
</p>
<p><code>Filter.character</code> - Filter words from a character vector that meet 
max/min word length criteria.
</p>
<p><code>Filter.fwl</code> - Filter words from a fwl 
that meet max/min word length criteria.
</p>
<p><code>Filter.fswl</code> - Filter words from a fswl 
that meet max/min word length criteria.
</p>
<p><code>Filter.rfswl</code> - Filter words from a rfswl 
that meet max/min word length criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'all_words'
Filter(
  x,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  stopwords = NULL,
  ignore.case = TRUE,
  ...
)

## S3 method for class 'TermDocumentMatrix'
Filter(
  x,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  stopwords = NULL,
  ignore.case = TRUE,
  ...
)

## S3 method for class 'DocumentTermMatrix'
Filter(
  x,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  stopwords = NULL,
  ignore.case = TRUE,
  ...
)

Filter(
  x,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  stopwords = NULL,
  ignore.case = TRUE,
  ...
)

## S3 method for class 'wfm'
Filter(x, min = 1, max = Inf, count.apostrophe = TRUE, stopwords = NULL, ...)

## S3 method for class 'character'
Filter(
  x,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  stopwords = NULL,
  ignore.case = TRUE,
  ...
)

## S3 method for class 'fwl'
Filter(
  x,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  stopwords = NULL,
  ignore.case = TRUE,
  ...
)

## S3 method for class 'fswl'
Filter(
  x,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  stopwords = NULL,
  ignore.case = TRUE,
  ...
)

## S3 method for class 'rfswl'
Filter(
  x,
  min = 1,
  max = Inf,
  count.apostrophe = TRUE,
  stopwords = NULL,
  ignore.case = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Filter.all_words_+3A_x">x</code></td>
<td>
<p>A filterable object (e.g., <code><a href="#topic+wfm">wfm</a></code>,
<code><a href="base.html#topic+character">character</a></code>).</p>
</td></tr>
<tr><td><code id="Filter.all_words_+3A_min">min</code></td>
<td>
<p>Minimum word length.</p>
</td></tr>
<tr><td><code id="Filter.all_words_+3A_max">max</code></td>
<td>
<p>Maximum word length.</p>
</td></tr>
<tr><td><code id="Filter.all_words_+3A_count.apostrophe">count.apostrophe</code></td>
<td>
<p>logical.  If <code>TRUE</code> apostrophes are counted as 
characters.</p>
</td></tr>
<tr><td><code id="Filter.all_words_+3A_stopwords">stopwords</code></td>
<td>
<p>A vector of stop words to remove.</p>
</td></tr>
<tr><td><code id="Filter.all_words_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> stopwords will be removed 
regardless of case (ignored if used on a <code><a href="#topic+wfm">wfm</a></code>).</p>
</td></tr>
<tr><td><code id="Filter.all_words_+3A_...">...</code></td>
<td>
<p>Other arguments passed to specific Filter methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>all_words Method for Filter
</p>
<p>TermDocumentMatrix Method for Filter
</p>
<p>DocumentTermMatrix Method for Filter
</p>
<p>character Method for Filter
</p>
<p>fwl Method for Filter
</p>
<p>fswl Method for Filter
</p>
<p>rfswl Method for Filter
</p>


<h3>Value</h3>

<p><code>Filter.all_words</code> - Returns a matrix of the class &quot;all_words&quot;.
</p>
<p><code>Filter.TermDocumentMatrix</code> - Returns a matrix of the class &quot;TermDocumentMatrix&quot;.
</p>
<p><code>Filter.DocumentTermMatrix</code> - Returns a matrix of the class &quot;DocumentTermMatrix&quot;.
</p>
<p><code>Filter</code> - Returns a matrix of the class &quot;wfm&quot;.
</p>
<p><code>Filter.character</code> - Returns a vector of the class &quot;character&quot;.
</p>
<p><code>Filter.wfm</code> - Returns a matrix of the class &quot;wfm&quot;.
</p>
<p><code>Filter.fwl</code> - Returns a matrix of the class &quot;fwl&quot;.
</p>
<p><code>Filter.fswl</code> - Returns a matrix of the class &quot;fswl&quot;.
</p>
<p><code>Filter.rfswl</code> - Returns a matrix of the class &quot;rfswl&quot;.
</p>


<h3>Note</h3>

<p>The name and idea behind this function is inspired by the <span class="pkg">dplyr</span>
package's <code>filter</code> function and has a similar meaning in that you are 
grabbing rows (or elements) meeting a particular criteria.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Filter(with(DATA, wfm(state, list(sex, adult))), 5)
with(DATA, wfm(state, list(sex, adult)))

## Filter particular words based on max/min values in wfm
v &lt;- with(DATA, wfm(state, list(sex, adult)))
Filter(v, 5)
Filter(v, 5, count.apostrophe = FALSE)
Filter(v, 5, 7)
Filter(v, 4, 4)
Filter(v, 3, 4)
Filter(v, 3, 4, stopwords = Top25Words)

## Filter works on character strings too...
x &lt;- c("Raptors don't like robots!",  "I'd pay $500.00 to rid them.")
Filter(x, 3)
Filter(x, 4)
Filter(x, 4, count.apostrophe = FALSE)
Filter(x, 4, count.apostrophe = FALSE, stopwords="raptors")
Filter(x, 4, stopwords="raptors")
Filter(x, 4, stopwords="raptors", ignore.case = FALSE)

DATA[, "state"] &lt;- Filter(DATA[, "state"], 4)
DATA &lt;- qdap::DATA

## Filter `all_words`
head(all_words(raj$dialogue))
Filter(head(all_words(raj$dialogue)), min = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='formality'>Formality Score</h2><span id='topic+formality'></span>

<h3>Description</h3>

<p>Transcript apply formality score by grouping variable(s) and optionally plot 
the breakdown of the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formality(
  text.var,
  grouping.var = NULL,
  order.by.formality = TRUE,
  digits = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formality_+3A_text.var">text.var</code></td>
<td>
<p>The text variable (or an object from <code><a href="#topic+pos">pos</a></code>,
<code><a href="#topic+pos_by">pos_by</a></code> or <code><a href="#topic+formality">formality</a></code>.  Passing the 
later three object will greatly reduce run time.</p>
</td></tr>
<tr><td><code id="formality_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="formality_+3A_order.by.formality">order.by.formality</code></td>
<td>
<p>logical.  If <code>TRUE</code> orders the results by 
formality score.</p>
</td></tr>
<tr><td><code id="formality_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed.</p>
</td></tr>
<tr><td><code id="formality_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+pos_by">pos_by</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Heylighen &amp; Dewaele(2002)'s formality score is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">F = 50(\frac{n_{f}-n_{c}}{N} + 1)</code>
</p>

<p>Where:
</p>
<p style="text-align: center;"><code class="reqn">f = \left \{noun, \;adjective, \;preposition, \;article\right \}</code>
</p>

<p style="text-align: center;"><code class="reqn">c = \left \{pronoun, \;verb, \;adverb, \;interjection\right \}</code>
</p>

<p style="text-align: center;"><code class="reqn">N = \sum{(f \;+ \;c \;+ \;conjunctions)}</code>
</p>



<h3>Value</h3>

<p>A list containing at the following components: 
</p>
<table>
<tr><td><code>text</code></td>
<td>
<p>The text variable</p>
</td></tr> 
<tr><td><code>POStagged</code></td>
<td>
<p>Raw part of speech for every word of the text variable</p>
</td></tr> 
<tr><td><code>POSprop</code></td>
<td>
<p>Part of speech proportion for every word of the text variable</p>
</td></tr> 
<tr><td><code>POSfreq</code></td>
<td>
<p>Part of speech count for every word of the text variable</p>
</td></tr> 
<tr><td><code>pos.by.freq</code></td>
<td>
<p>The part of speech count for every word of the text 
variable by grouping variable(s)</p>
</td></tr> 
<tr><td><code>pos.by.prop</code></td>
<td>
<p>The part of speech proportion for every word of the text 
variable by grouping variable(s)</p>
</td></tr> 
<tr><td><code>form.freq.by</code></td>
<td>
<p>The nine broad part of speech categories count for every 
word of the text variable by grouping variable(s)</p>
</td></tr> 
<tr><td><code>form.prop.by</code></td>
<td>
<p>The nine broad part of speech categories proportion for 
every word of the text variable by grouping variable(s)</p>
</td></tr> 
<tr><td><code>formality</code></td>
<td>
<p>Formality scores by grouping variable(s)</p>
</td></tr> 
<tr><td><code>pos.reshaped</code></td>
<td>
<p>An expanded formality scores output (grouping, 
word.count, pos &amp; form.class) by word</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>Heylighen &amp; Dewaele (2002) state, &quot;At present, a sample would 
probably need to contain a few hundred words for the measure to be minimally 
reliable. For single sentences, the F-value should only be computed for 
purposes of illustration&quot; (p. 24).
</p>


<h3>References</h3>

<p>Heylighen, F., &amp; Dewaele, J.M. (2002). Variation in the 
contextuality of language: An empirical measure. Context in Context, Special 
issue of Foundations of Science, 7 (3), 293-340.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(DATA, formality(state, person))
(x1 &lt;- with(DATA, formality(state, list(sex, adult))))
plot(x1)
plot(x1, short.names = FALSE)

scores(x1)
counts(x1)
proportions(x1)
preprocessed(x1)

plot(scores(x1))
plot(counts(x1))
plot(proportions(x1), high="darkgreen")
plot(preprocessed(x1))

data(rajPOS) #A data set consisting of a pos list object
x2 &lt;- with(raj, formality(rajPOS, act))
plot(x2)
cumulative(x2)
x3 &lt;- with(raj, formality(rajPOS, person))
plot(x3, bar.colors="Dark2")
plot(x3, bar.colors=c("Dark2", "Set1"))
x4 &lt;- with(raj, formality(rajPOS, list(person, act)))
plot(x4, bar.colors=c("Dark2", "Set1"))

rajDEM &lt;- key_merge(raj, raj.demographics) #merge demographics with transcript.
x5 &lt;- with(rajDEM, formality(rajPOS, sex))
plot(x5, bar.colors="RdBu")
x6 &lt;- with(rajDEM, formality(rajPOS, list(fam.aff, sex)))
plot(x6, bar.colors="RdBu")
x7 &lt;- with(rajDEM, formality(rajPOS, list(died, fam.aff)))
plot(x7, bar.colors="RdBu",  point.cex=2, point.pch = 3)
x8 &lt;- with(rajDEM, formality(rajPOS, list(died, sex)))
plot(x8, bar.colors="RdBu",  point.cex=2, point.pch = "|")

names(x8)
colsplit2df(x8$formality)

#pass an object from pos or pos_by
ltruncdf(with(raj, formality(x8 , list(act, person))), 6, 4)

#=============#
## ANIMATION ##
#=============#
## EXAMPLE 1
form_ani &lt;- formality(DATA.SPLIT$state, DATA.SPLIT$person)
forma &lt;- Animate(form_ani, contextual="white", formal="blue", 
    current.color = "yellow", current.speaker.color="grey70")

bgb &lt;- vertex_apply(forma, label.color="grey80", size=20, color="grey40")
bgb &lt;- edge_apply(bgb, label.color="yellow")

print(bgb, bg="black", net.legend.color ="white", pause=1)

## EXAMPLE 2
form_ani2 &lt;- formality(raj.act.1POS, mraja1spl$person)
forma2 &lt;- Animate(form_ani2, contextual="white", formal="blue",
    current.color = "yellow", current.speaker.color="grey70")

bgb2 &lt;- vertex_apply(forma2, label.color="grey80", size=17, color="grey40")
bgb2 &lt;- edge_apply(bgb2, label.color="yellow")
print(bgb2, bg="black", pause=.75, net.legend.color = "white")

## EXAMPLE 3 (bar plot)
Animate(form_ani2, as.network=FALSE)

#=====================#
## Complex Animation ##
#=====================#
library(animation)
library(grid)
library(gridBase)
library(qdap)
library(igraph)
library(plotrix)

form_ani2 &lt;- formality(raj.act.1POS, mraja1spl$person)

## Set up the network version
form_net &lt;- Animate(form_ani2, contextual="white", formal="blue",
    current.color = "yellow", current.speaker.color="grey70")
bgb &lt;- vertex_apply(form_net, label.color="grey80", size=17, color="grey40")
bgb &lt;- edge_apply(bgb, label.color="yellow")


## Set up the bar version
form_bar &lt;- Animate(form_ani2, as.network=FALSE)

## Generate a folder
loc &lt;- folder(animation_formality)

## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)


FUN &lt;- function(follow=FALSE, theseq = seq_along(bgb)) {

    Title &lt;- "Animated Formality: Romeo and Juliet Act 1"
    Legend &lt;- c(.2, -1, 1.5, -.95)
    Legend.cex &lt;- 1

    lapply(theseq, function(i) {
        if (follow) {
            png(file=sprintf("%s/images/Rplot%s.png", loc, i),
                width=650, height=725)
        }
        ## Set up the layout
        layout(matrix(c(rep(1, 9), rep(2, 4)), 13, 1, byrow = TRUE))

        ## Plot 1
        par(mar=c(2, 0, 2, 0), bg="black")
        #par(mar=c(2, 0, 2, 0))
        set.seed(22)
        plot.igraph(bgb[[i]], edge.curved=TRUE)
        graphics::mtext(Title, side=3, col="white")
        color.legend(Legend[1], Legend[2], Legend[3], Legend[4],
              c("Contextual", "Formal"), attributes(bgb)[["legend"]],
              cex = Legend.cex, col="white")

        ## Plot2
        plot.new()
        vps &lt;- baseViewports()

        uns &lt;- unit(c(-1.3,.5,-.75,.25), "cm")
        p &lt;- form_bar[[i]] +
            theme(plot.margin = uns,
                text=element_text(color="white"),
                legend.text=element_text(color="white"),
                legend.background = element_rect(fill = "black"),
                plot.background = element_rect(fill = "black",
                    color="black"))
        print(p,vp = vpStack(vps$figure,vps$plot))
        animation::ani.pause()

        if (follow) {
            dev.off()
        }
    })

}

FUN()

## Detect OS
type &lt;- if(.Platform$OS.type == "windows") shell else system

saveHTML(FUN(, 1:20), autoplay = FALSE, loop = TRUE, verbose = FALSE,
    ani.height = 1000, ani.width=650,
    outdir = loc, single.opts =
    "'controls': ['first', 'play', 'loop', 'speed'], 'delayMin': 0")

FUN(TRUE)

#==================#
## Static Network ##
#==================#
(formdat &lt;- with(sentSplit(DATA, 4), formality(state, person)))
m &lt;- Network(formdat)
m
print(m, bg="grey97", vertex.color="grey75")

print(m, title="Formality Discourse Map", title.color="white", bg="black",
    legend.text.color="white", vertex.label.color = "grey70", 
    edge.label.color="yellow")
    
## or use themes:
dev.off()
m + qtheme()
m + theme_nightheat
dev.off()
m + theme_nightheat(title="Formality Discourse Map", 
    vertex.label.color = "grey50")
    
#===============================#
## Formality Over Time Example ##
#===============================#
formpres &lt;- lapply(with( pres_debates2012, split(dialogue, time)), function(x) {
    formality(x)
})
formplots &lt;- lapply(seq_along(formpres), function(i) {
    m &lt;- plot(cumulative(formpres[[i]]))
    if (i != 2) m &lt;- m + ylab("")
    if (i != 3) m &lt;- m + xlab(NULL)
    m + ggtitle(paste("Debate", i))
})

library(grid)
library(gridExtra)
do.call(grid.arrange, formplots)

## End(Not run)
</code></pre>

<hr>
<h2 id='freq_terms'>Find Frequent Terms</h2><span id='topic+freq_terms'></span>

<h3>Description</h3>

<p>Find the most frequently occurring terms in a text vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freq_terms(
  text.var,
  top = 20,
  at.least = 1,
  stopwords = NULL,
  extend = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freq_terms_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="freq_terms_+3A_top">top</code></td>
<td>
<p>Top number of terms to show.</p>
</td></tr>
<tr><td><code id="freq_terms_+3A_at.least">at.least</code></td>
<td>
<p>An integer indicating at least how many letters a word 
must be to be included in the output.</p>
</td></tr>
<tr><td><code id="freq_terms_+3A_stopwords">stopwords</code></td>
<td>
<p>A character vector of words to remove from the text.  qdap 
has a number of data sets that can be used as stop words including: 
<code>Top200Words</code>, <code>Top100Words</code>, <code>Top25Words</code>.  For the tm 
package's traditional English stop words use <code>tm::stopwords("english")</code>.</p>
</td></tr>
<tr><td><code id="freq_terms_+3A_extend">extend</code></td>
<td>
<p>logical.  If <code>TRUE</code> the <code>top</code> argument is extended to 
any word that has the same frequency as the <code>top</code> word.</p>
</td></tr>
<tr><td><code id="freq_terms_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+all_words">all_words</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with the top occurring words.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+word_list">word_list</a></code>,
<code><a href="#topic+all_words">all_words</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
freq_terms(DATA$state, 5)
freq_terms(DATA$state)
freq_terms(DATA$state, extend = FALSE)
freq_terms(DATA$state, at.least = 4)
(out &lt;- freq_terms(pres_debates2012$dialogue, stopwords = Top200Words))
plot(out)

## All words by sentence (row)
library(qdapTools)
x &lt;- raj$dialogue
list_df2df(setNames(lapply(x, freq_terms, top=Inf), seq_along(x)), "row")
list_df2df(setNames(lapply(x, freq_terms, top=10, stopwords = Dolch), 
    seq_along(x)), "Title")


## All words by person
FUN &lt;- function(x, n=Inf) freq_terms(paste(x, collapse=" "), top=n)
list_df2df(lapply(split(x, raj$person), FUN), "person")

## Plot it
out &lt;- lapply(split(x, raj$person), FUN, n=10)
pdf("Freq Terms by Person.pdf", width=13) 
lapply(seq_along(out), function(i) {
    ## dev.new()
    plot(out[[i]], plot=FALSE) + ggtitle(names(out)[i])
})
dev.off()

## Keep spaces
freq_terms(space_fill(DATA$state, "are you"), 500, char.keep="~~")

## End(Not run)
</code></pre>

<hr>
<h2 id='gantt'>Gantt Durations</h2><span id='topic+gantt'></span><span id='topic+plot_gantt_base'></span>

<h3>Description</h3>

<p><code>gantt</code> - Generates start and end times of supplied text selections 
(i.e., text selections are determined by any number of grouping variables).
</p>
<p><code>plot_gantt_base</code> - For internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gantt(text.var, grouping.var, units = "words", sums = FALSE, col.sep = "_")

plot_gantt_base(
  x,
  sums = NULL,
  fill.colors = NULL,
  box.color = "white",
  title = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gantt_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="gantt_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables. Also takes a single grouping 
variable or a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="gantt_+3A_units">units</code></td>
<td>
<p>The unit of measurement to analyze.  One of the strings 
<code>"character"</code>, <code>"syllable"</code>, <code>"word"</code>, or <code>"sentence"</code>.</p>
</td></tr>
<tr><td><code id="gantt_+3A_sums">sums</code></td>
<td>
<p>logical.  If <code>TRUE</code> reports and (optionally (or plots) the 
total units used by grouping variable(s).</p>
</td></tr>
<tr><td><code id="gantt_+3A_col.sep">col.sep</code></td>
<td>
<p>The character string to use to separate pasted variables in 
the merged grouping variable header/name.</p>
</td></tr>
<tr><td><code id="gantt_+3A_x">x</code></td>
<td>
<p>n object of the class &quot;gantt&quot;.</p>
</td></tr>
<tr><td><code id="gantt_+3A_fill.colors">fill.colors</code></td>
<td>
<p>The colors of the Gantt plot bars.  Either a single color 
or a length equal to the number of grouping variable(s).  If <code>NULL</code>, 
<code>rainbow</code> is used.</p>
</td></tr>
<tr><td><code id="gantt_+3A_box.color">box.color</code></td>
<td>
<p>A color to wrap the boxes with.</p>
</td></tr>
<tr><td><code id="gantt_+3A_title">title</code></td>
<td>
<p>An optional title.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame of start and end times by grouping variable(s) 
or optionally returns a list of two: (1) A data frame of the total units 
used by grouping variable(s) and (2) a data frame of start and end times 
by grouping variable(s).
</p>


<h3>Note</h3>

<p>For non-repeated measures data use <code><a href="#topic+gantt">gantt</a></code>.  For
more flexible plotting needs use <code><a href="#topic+gantt_wrap">gantt_wrap</a></code> over the 
generic plotting method.
</p>


<h3>Author(s)</h3>

<p>DigEmAll (stackoverflow.com) and Tyler Rinker &lt;tyler.rinker@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Clark, W. &amp; Gantt, H. (1922) The Gantt chart, a working 
tool of management. New York, Ronald Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gantt_rep">gantt_rep</a></code>,
<code><a href="#topic+gantt_wrap">gantt_wrap</a></code>,
<code><a href="#topic+gantt_plot">gantt_plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(a &lt;- gantt(DATA$state, DATA$person))  
plot(a)
plot(a, base = TRUE)

(b &lt;- gantt(DATA$state, DATA$person, sums = TRUE)) 
plot(b)
plot(b, base = FALSE) 

(d &lt;- gantt(DATA$state, list(DATA$sex, DATA$adult)))        
plot(d)

x &lt;- gantt(mraja1$dialogue, mraja1$person) 
plot(x, base = TRUE)
plot(x, , base = TRUE, box.color = "black") 

z &lt;- gantt(mraja1$dialogue, mraja1$sex)  
plot(z)  
                                                          
e &lt;- with(mraja1, gantt(dialogue, list(fam.aff, sex, died), 
   units = "characters", sums = TRUE))
plot(e)  
     
f &lt;- gantt(mraja1$dialogue, mraja1$person, units = "syllables",
    sums = TRUE)
plot(f, box.color = "red")
plot(f, base = FALSE)

dat &lt;- gantt(mraja1$dialogue, list(mraja1$fam.aff, mraja1$sex),
    units = "sentences", col.sep = "_")
    
    
## Animate It
##=================
ani_gannt &lt;- with(DATA.SPLIT, gantt(state, person))
Animate(ani_gannt)
Animate(plot(ani_gannt))

library(animation)
loc &lt;- folder(animation_gantt)

## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)

FUN &lt;- function() {
    out &lt;- Animate(ani_gannt)
    lapply(out, function(x) {
        print(x)
        animation::ani.pause()
    })

}

type &lt;- if(.Platform$OS.type == "windows") shell else system
saveGIF(FUN(), interval = 0.1, outdir = loc, cmd.fun = type)

## End(Not run)
</code></pre>

<hr>
<h2 id='gantt_plot'>Gantt Plot</h2><span id='topic+gantt_plot'></span>

<h3>Description</h3>

<p>A convenience function that wraps <code><a href="#topic+gantt">gantt</a></code>, 
<code><a href="#topic+gantt_rep">gantt_rep</a></code> and <code><a href="#topic+gantt_wrap">gantt_wrap</a></code> into a single 
plotting function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gantt_plot(
  text.var,
  grouping.var = NULL,
  rm.var = NULL,
  fill.var = NULL,
  xlab = "duration (in words)",
  units = "words",
  col.sep = "__",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gantt_plot_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="gantt_plot_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables. Also takes a single grouping 
variable or a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="gantt_plot_+3A_rm.var">rm.var</code></td>
<td>
<p>An optional single vector or list of 1 or 2 of repeated 
measures to facet by</p>
</td></tr>
<tr><td><code id="gantt_plot_+3A_fill.var">fill.var</code></td>
<td>
<p>An optional variable to fill the code strips by.</p>
</td></tr>
<tr><td><code id="gantt_plot_+3A_xlab">xlab</code></td>
<td>
<p>The name of the x-axis label.</p>
</td></tr>
<tr><td><code id="gantt_plot_+3A_units">units</code></td>
<td>
<p>The unit of measurement.</p>
</td></tr>
<tr><td><code id="gantt_plot_+3A_col.sep">col.sep</code></td>
<td>
<p>The column separator.</p>
</td></tr>
<tr><td><code id="gantt_plot_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+gantt_wrap">gantt_wrap</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a Gantt style visualization.  Invisibly returns the ggplot2 
list object.
</p>


<h3>Note</h3>

<p>For non-repeated measures data/plotting use <code><a href="#topic+gantt">gantt</a></code>; 
for repeated measures data output use <code><a href="#topic+gantt_rep">gantt_rep</a></code>; and for 
a flexible gantt plot that words with code matrix functions (cm) use 
<code><a href="#topic+gantt_wrap">gantt_wrap</a></code>.
</p>


<h3>References</h3>

<p>Clark, W. &amp; Gantt, H. (1922) The Gantt chart, a working 
tool of management. New York, Ronald Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gantt">gantt</a></code>, 
<code><a href="#topic+gantt_rep">gantt_rep</a></code>,
<code><a href="#topic+gantt_wrap">gantt_wrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(rajSPLIT, gantt_plot(text.var = dialogue,
    grouping.var = person, size=4))

with(rajSPLIT, gantt_plot(text.var = dialogue,
    grouping.var = list(fam.aff, sex), rm.var  = act,
    title = "Romeo and Juliet's dialogue"))

with(rajSPLIT, gantt_plot(dialogue, list(fam.aff, sex), act,
    transform=T))

rajSPLIT2 &lt;- rajSPLIT

rajSPLIT2$newb &lt;- as.factor(sample(LETTERS[1:2], nrow(rajSPLIT2),
    replace=TRUE))

z &lt;- with(rajSPLIT2, gantt_plot(dialogue, list(fam.aff, sex),
    list(act, newb), size = 4))

library(ggplot2); library(scales); library(RColorBrewer); library(grid)
z + theme(panel.spacing = unit(1, "lines")) + scale_colour_grey()
z + scale_colour_brewer(palette="Dark2")

## Fill Variable Example
dat &lt;- rajSPLIT[rajSPLIT$act == 1, ]
dat$end_mark &lt;- factor(end_mark(dat$dialogue))

with(dat, gantt_plot(text.var = dialogue, grouping.var = list(person, sex),
    fill.var=end_mark))

## Repeated Measures with Fill Example
rajSPLIT$end_mark &lt;- end_mark(rajSPLIT$dialogue)

with(rajSPLIT, gantt_plot(text.var = dialogue,
    grouping.var = list(fam.aff), rm.var  = list(act),
    fill.var=end_mark, title = "Romeo and Juliet's dialogue"))

## Repeated Measures Sentence Type Example
with(rajSPLIT, gantt_plot(text.var = dialogue,
    grouping.var = list(fam.aff, sex), rm.var  = list(end_mark, act),
    title = "Romeo and Juliet's dialogue"))

## Reset rajSPLIT
rajSPLIT &lt;- qdap::rajSPLIT

## Animate It
##=================
ani_gantt &lt;- with(mraja1, gantt_plot(dialogue, person))

library(animation)
loc &lt;- folder(animation_gantt)

## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)

FUN &lt;- function() {
    out &lt;- Animate(ani_gantt)
    lapply(out, function(x) {
        print(x)
        animation::ani.pause()
    })

}

type &lt;- if(.Platform$OS.type == "windows") shell else system
saveVideo(FUN(), video.name = "animation.avi", interval = 0.1, outdir = loc)

saveLatex(FUN(), autoplay = TRUE, loop = FALSE, latex.filename = "tester.tex", 
    caption = "animated dialogue", outdir = loc, ani.type = "pdf", 
    ani.dev = "pdf", ani.width = 5, ani.height = 5.5, interval = 0.1)


saveHTML(FUN(), autoplay = FALSE, loop = TRUE, verbose = FALSE, 
    ani.width=600, ani.height=280,
    outdir = file.path(loc, "new"), single.opts = 
    "'controls': ['first', 'play', 'loop', 'speed'], 'delayMin': 0")


## End(Not run)
</code></pre>

<hr>
<h2 id='gantt_rep'>Generate Unit Spans for Repeated Measures</h2><span id='topic+gantt_rep'></span>

<h3>Description</h3>

<p>Produces start and end times for occurrences for each repeated measure 
condition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gantt_rep(
  rm.var,
  text.var,
  grouping.var = NULL,
  units = "words",
  col.sep = "_",
  name.sep = "_"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gantt_rep_+3A_rm.var">rm.var</code></td>
<td>
<p>An optional single vector or list of 1 or 2 of repeated 
measures to facet by.</p>
</td></tr>
<tr><td><code id="gantt_rep_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="gantt_rep_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables. Also takes a single grouping 
variable or a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="gantt_rep_+3A_units">units</code></td>
<td>
<p>The unit of measurement to analyze.  One of the strings 
<code>"character"</code>, <code>"syllable"</code>, <code>"word"</code>, or <code>"sentence"</code>.</p>
</td></tr>
<tr><td><code id="gantt_rep_+3A_col.sep">col.sep</code></td>
<td>
<p>The character string to use to separate pasted variables in 
the pasted columns.</p>
</td></tr>
<tr><td><code id="gantt_rep_+3A_name.sep">name.sep</code></td>
<td>
<p>The character string to use to separate column names of the 
pasted columns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame of start and end times by repeated measure and 
grouping variable(s)
</p>


<h3>Note</h3>

<p>For non-repeated measures data use <code><a href="#topic+gantt">gantt</a></code>.  For
more flexible plotting needs use <code><a href="#topic+gantt_wrap">gantt_wrap</a></code> over the 
generic plotting method.
</p>


<h3>References</h3>

<p>Clark, W. &amp; Gantt, H. (1922) The Gantt chart, a working 
tool of management. New York, Ronald Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gantt">gantt</a></code>,
<code><a href="#topic+gantt_wrap">gantt_wrap</a></code>,
<code><a href="#topic+gantt_plot">gantt_plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- with(rajSPLIT, gantt_rep(act, dialogue, list(fam.aff, sex),
    units = "words", col.sep = "_"))
head(dat, 20)
plot(dat)

gantt_wrap(dat,  "fam.aff_sex",  facet.vars = "act",
    title = "Repeated Measures Gantt Plot",
    minor.line.freq = 25, major.line.freq = 100)

## Two facets variables
dat2 &lt;- with(DATA2, gantt_rep(list(day, class), state, person,
    units = "words", col.sep = "_"))
head(dat2, 20)
plot(dat2)

## End(Not run)
</code></pre>

<hr>
<h2 id='gantt_wrap'>Gantt Plot</h2><span id='topic+gantt_wrap'></span>

<h3>Description</h3>

<p>A ggplot2 wrapper that produces a Gantt plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gantt_wrap(
  dataframe,
  plot.var,
  facet.vars = NULL,
  fill.var = NULL,
  title = NULL,
  ylab = plot.var,
  xlab = "duration.default",
  rev.factor = TRUE,
  transform = FALSE,
  ncol = NULL,
  minor.line.freq = NULL,
  major.line.freq = NULL,
  sig.dig.line.freq = 1,
  hms.scale = NULL,
  scale = NULL,
  space = NULL,
  size = 3,
  rm.horiz.lines = FALSE,
  x.ticks = TRUE,
  y.ticks = TRUE,
  legend.position = NULL,
  bar.color = NULL,
  border.color = NULL,
  border.size = 2,
  border.width = 0.1,
  constrain = TRUE,
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gantt_wrap_+3A_dataframe">dataframe</code></td>
<td>
<p>A data frame with plotting variable(s) and a column of start 
and end times.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_plot.var">plot.var</code></td>
<td>
<p>A factor plotting variable (y axis).</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_facet.vars">facet.vars</code></td>
<td>
<p>An optional single vector or list of 1 or 2 to facet by.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_fill.var">fill.var</code></td>
<td>
<p>An optional variable to fill the code strips by.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_title">title</code></td>
<td>
<p>An optional title for the plot.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_ylab">ylab</code></td>
<td>
<p>An optional y label.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_xlab">xlab</code></td>
<td>
<p>An optional x label.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_rev.factor">rev.factor</code></td>
<td>
<p>logical.  If <code>TRUE</code> reverse the current plotting order 
so the first element in the plotting variable's levels is plotted on top.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_transform">transform</code></td>
<td>
<p>logical.  If <code>TRUE</code> the repeated facets will be 
transformed from stacked to side by side.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_ncol">ncol</code></td>
<td>
<p>if an integer value is passed to this 
<code><a href="#topic+gantt_wrap">gantt_wrap</a></code> uses <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code> 
rather than <code><a href="ggplot2.html#topic+facet_grid">facet_grid</a></code>.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_minor.line.freq">minor.line.freq</code></td>
<td>
<p>A numeric value for frequency of minor grid lines.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_major.line.freq">major.line.freq</code></td>
<td>
<p>A numeric value for frequency of major grid lines.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_sig.dig.line.freq">sig.dig.line.freq</code></td>
<td>
<p>An internal rounding factor for minor and major line 
freq.  Generally, default value of 1 suffices for larger range of x scale may 
need to be set to -2.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_hms.scale">hms.scale</code></td>
<td>
<p>logical.  If <code>TRUE</code> converts scale to h:m:s format.
Default <code>NULL</code> attempts to detect if object is a cm_time2long object</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_scale">scale</code></td>
<td>
<p>Should scales be fixed (<code>"fixed"</code>, the default), free 
(<code>"free"</code>), or free in one dimension (<code>"free_x"</code>, <code>"free_y"</code>)</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_space">space</code></td>
<td>
<p>If <code>"fixed"</code>, the default, all panels have the same size. 
If <code>"free_y"</code> their height will be proportional to the length of the y 
scale; if <code>"free_x"</code> their width will be proportional to the length of 
the x scale; or if <code>"free"</code> both height and width will vary. This 
setting has no effect unless the appropriate scales also vary.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_size">size</code></td>
<td>
<p>The width of the plot bars.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_rm.horiz.lines">rm.horiz.lines</code></td>
<td>
<p>logical.  If <code>TRUE</code> the horizontal lines will be 
removed.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_x.ticks">x.ticks</code></td>
<td>
<p>logical.  If <code>TRUE</code> the x ticks will be displayed.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_y.ticks">y.ticks</code></td>
<td>
<p>logical.  If <code>TRUE</code> the y ticks will be displayed.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_legend.position">legend.position</code></td>
<td>
<p>The position of legends. (<code>"left"</code>, 
<code>"right"</code>, <code>"bottom"</code>, <code>"top"</code>, or two-element numeric 
vector).</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_bar.color">bar.color</code></td>
<td>
<p>Optional color to constrain all bars.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_border.color">border.color</code></td>
<td>
<p>The color to plot border around Gantt bars (default is 
<code>NULL</code>).</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_border.size">border.size</code></td>
<td>
<p>An integer value for the size to plot borders around Gantt 
bars. Controls length (width also controlled if not specified).</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_border.width">border.width</code></td>
<td>
<p>Controls border width around Gantt bars.  Use a numeric 
value in addition to border size if plot borders appear disproportional.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_constrain">constrain</code></td>
<td>
<p>logical.  If <code>TRUE</code> the Gantt bars touch the edge of 
the graph.</p>
</td></tr>
<tr><td><code id="gantt_wrap_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a Gantt style visualization. Invisibly returns the ggplot2 
list object.
</p>


<h3>Note</h3>

<p>For non-repeated measures data/plotting use <code><a href="#topic+gantt">gantt</a></code>; 
for repeated measures data output use <code><a href="#topic+gantt_rep">gantt_rep</a></code>; and for 
a convenient wrapper that takes text and generates plots use 
<code><a href="#topic+gantt_plot">gantt_plot</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrie de Vries and Tyler Rinker &lt;tyler.rinker@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Clark, W. &amp; Gantt, H. (1922) The Gantt chart, a working tool of 
management. New York, Ronald Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gantt">gantt</a></code>,
<code><a href="#topic+gantt_plot">gantt_plot</a></code>,
<code><a href="#topic+gantt_rep">gantt_rep</a></code>,
<code><a href="ggplot2.html#topic+facet_grid">facet_grid</a></code>,
<code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- gantt(mraja1$dialogue, list(mraja1$fam.aff, mraja1$sex),
    units = "sentences", col.sep = "_")
htruncdf(dat)
gantt_wrap(dat, "fam.aff_sex", title = "Gantt Plot")
dat$codes &lt;- sample(LETTERS[1:3], nrow(dat), TRUE)
gantt_wrap(dat, "fam.aff_sex", fill.var = "codes",
    legend.position = "bottom")

dat2 &lt;- with(rajSPLIT, gantt_rep(act, dialogue,
    list(fam.aff, sex), units = "words", col.sep = "_"))
htruncdf(dat2)
x &lt;- gantt_wrap(dat2, "fam.aff_sex", facet.vars = "act",
    title = "Repeated Measures Gantt Plot")

library(ggplot2); library(scales); library(RColorBrewer)
x + scale_color_manual(values=rep("black",
    length(levels(dat2$fam.aff_sex))))

## End(Not run)
</code></pre>

<hr>
<h2 id='gradient_cloud'>Gradient Word Cloud</h2><span id='topic+gradient_cloud'></span>

<h3>Description</h3>

<p>Produces a gradient word cloud colored by a binary grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gradient_cloud(
  text.var,
  bigroup.var,
  rev.binary = FALSE,
  X = "red",
  Y = "blue",
  stem = FALSE,
  stopwords = NULL,
  caps = TRUE,
  caps.list = NULL,
  I.list = TRUE,
  random.order = FALSE,
  rot.per = 0,
  min.freq = 1,
  max.word.size = NULL,
  min.word.size = 0.5,
  breaks = 10,
  cloud.font = NULL,
  title = NULL,
  title.font = NULL,
  title.color = "black",
  title.padj = 0.25,
  title.location = 3,
  title.cex = NULL,
  legend.cex = 0.8,
  legend.location = c(0.025, 0.025, 0.25, 0.04),
  char2space = "~~"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gradient_cloud_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_bigroup.var">bigroup.var</code></td>
<td>
<p>A binary grouping variable.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_rev.binary">rev.binary</code></td>
<td>
<p>logical.  If <code>TRUE</code> the ordering of the binary levels of 
bigroup.var is reversed.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_x">X</code></td>
<td>
<p>The first gradient color for variable X.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_y">Y</code></td>
<td>
<p>The second gradient color for variable Y.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_stem">stem</code></td>
<td>
<p>logical.  If <code>TRUE</code> the <code>text.var</code> will be stemmed.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_stopwords">stopwords</code></td>
<td>
<p>Words to exclude from the cloud.  Words will be removed 
after determining proportional word usage.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_caps">caps</code></td>
<td>
<p>logical.  If <code>TRUE</code> selected words will be capitalized.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_caps.list">caps.list</code></td>
<td>
<p>A vector of words to capitalize (<code>caps</code> must be 
<code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_i.list">I.list</code></td>
<td>
<p>logical.  If <code>TRUE</code> capitalizes I words and contractions.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_random.order">random.order</code></td>
<td>
<p>Plot words in random order. If <code>FALSE</code>, they will be 
plotted in decreasing frequency.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_rot.per">rot.per</code></td>
<td>
<p>Proportion words with 90 degree rotation.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_min.freq">min.freq</code></td>
<td>
<p>An integer value indicating the minimum frequency a word must 
appear to be included.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_max.word.size">max.word.size</code></td>
<td>
<p>A size argument to control the minimum size of the words.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_min.word.size">min.word.size</code></td>
<td>
<p>A size argument to control the maximum size of the words.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_breaks">breaks</code></td>
<td>
<p>An integer describing the number of breaks (odd numbers will be 
rounded up).</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_cloud.font">cloud.font</code></td>
<td>
<p>The font family of the cloud text.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_title">title</code></td>
<td>
<p>A character string used as the plot title.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_title.font">title.font</code></td>
<td>
<p>The font family of the cloud title.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_title.color">title.color</code></td>
<td>
<p>A character vector of length one corresponding to the 
color of the title.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_title.padj">title.padj</code></td>
<td>
<p>Adjustment for the title. For strings parallel to the axes, 
padj = 0 means right or top alignment, and padj = 1 means left or bottom 
alignment.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_title.location">title.location</code></td>
<td>
<p>On which side of the plot (1=bottom, 2=left, 3=top, 
4=right).</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_title.cex">title.cex</code></td>
<td>
<p>Character expansion factor for the title. <code>NULL</code> and 
<code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_legend.cex">legend.cex</code></td>
<td>
<p>Character expansion factor for the legend. <code>NULL</code> and 
<code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_legend.location">legend.location</code></td>
<td>
<p>A vector of length 4 denoting the lower left (x and y 
left) and upper right (x and y right) coordinates of the rectangle of colors 
in user coordinates.</p>
</td></tr>
<tr><td><code id="gradient_cloud_+3A_char2space">char2space</code></td>
<td>
<p>A vector of characters to be turned into spaces.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Breaking is done using <code><a href="stats.html#topic+quantile">quantile</a></code>.  This will 
ensure a certain percentage of words will be colored at each bin.
</p>


<h3>Value</h3>

<p>Plots a gradient word cloud and invisibly returns the dataframe used 
to make the cloud.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trans_cloud">trans_cloud</a></code>,
<code><a href="wordcloud.html#topic+wordcloud">wordcloud</a></code>,
<code><a href="plotrix.html#topic+color.legend">color.legend</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
DATA$state &lt;- space_fill(DATA$state, c("is fun", "too fun", "you liar"))

gradient_cloud(DATA$state, DATA$sex, title="fun")
gradient_cloud(DATA$state, DATA$sex, title="fun", rev.binary = TRUE)
gradient_cloud(DATA$state, DATA$sex, title="fun", max.word.size = 5,
    min.word.size = .025)
    
with(mraja1, gradient_cloud(dialogue, died, stopwords = Top25Words, 
    rot.per = .5, title="Heatcloud", title.color="orange", title.cex=1.75))    
x &lt;- with(subset(mraja1, fam.aff %in% qcv(cap, mont)), 
    gradient_cloud(dialogue, fam.aff))
head(x) 

## 2012 U.S. Presidential Debates
invisible(lapply(split(pres_debates2012, pres_debates2012$time), function(x) {
    x &lt;- x[x$person %in% qcv(ROMNEY, OBAMA), ]
    dev.new()
    gradient_cloud(x$dialogue, x$person, 
        title = paste("Debate", char2end(x$time[1])),
        stopwords = BuckleySaltonSWL,
        X = "blue", Y = "red", 
        max.word.size = 2.2, 
        min.word.size = 0.55
    )
}))
        

## End(Not run)
</code></pre>

<hr>
<h2 id='hamlet'>Hamlet (Complete &amp; Split by Sentence)</h2><span id='topic+hamlet'></span>

<h3>Description</h3>

<p>A dataset containing the complete dialogue of Hamlet with turns of talk split 
into sentences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hamlet)
</code></pre>


<h3>Format</h3>

<p>A data frame with 2007 rows and 7 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> act. The act (akin to repeated measures) 
</p>
</li>
<li><p> tot. The turn of talk
</p>
</li>
<li><p> scene. The scene (nested within an act)
</p>
</li>
<li><p> location. Location of the scene
</p>
</li>
<li><p> person. Character in the play
</p>
</li>
<li><p> died. Logical coded death variable if yes the character dies in the 
play
</p>
</li>
<li><p> dialogue. The spoken dialogue 
</p>
</li></ul>



<h3>References</h3>

<p>http://www.gutenberg.org
</p>

<hr>
<h2 id='htruncdf'>Dataframe Viewing</h2><span id='topic+htruncdf'></span><span id='topic+truncdf'></span><span id='topic+ltruncdf'></span><span id='topic+qview'></span><span id='topic+lview'></span>

<h3>Description</h3>

<p><code>htruncdf</code> - Convenience function to view the head of a truncated 
dataframe.
</p>
<p><code>truncdf</code> - Convenience function to view a truncated dataframe.
</p>
<p><code>ltruncdf</code> - Convenience function to view the head of a list of 
truncated dataframes.
</p>
<p><code>qview</code> - Convenience function to view a summary and head of a dataframe.
</p>
<p><code>lview</code> - Convenience function to view the list (list view) of qdap 
objects that have print methods that print a single dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htruncdf(dataframe, n = 10, width = 10, ...)

truncdf(dataframe, end = 10, begin = 1)

ltruncdf(dat.list, n = 6, width = 10, ...)

qview(dataframe, ...)

lview(x, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="htruncdf_+3A_dataframe">dataframe</code></td>
<td>
<p>A data.frame object.</p>
</td></tr>
<tr><td><code id="htruncdf_+3A_n">n</code></td>
<td>
<p>Number of rows to display.</p>
</td></tr>
<tr><td><code id="htruncdf_+3A_width">width</code></td>
<td>
<p>The width of the columns to be displayed.</p>
</td></tr>
<tr><td><code id="htruncdf_+3A_end">end</code></td>
<td>
<p>The last character to be displayed (width).</p>
</td></tr>
<tr><td><code id="htruncdf_+3A_begin">begin</code></td>
<td>
<p>The first character to be displayed (width).</p>
</td></tr>
<tr><td><code id="htruncdf_+3A_dat.list">dat.list</code></td>
<td>
<p>A list of data.frame objects.</p>
</td></tr>
<tr><td><code id="htruncdf_+3A_x">x</code></td>
<td>
<p>A class qdap object that is a list which prints as a dataframe.</p>
</td></tr>
<tr><td><code id="htruncdf_+3A_print">print</code></td>
<td>
<p>logical.  If <code>TRUE</code> prints to the console.</p>
</td></tr>
<tr><td><code id="htruncdf_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+htruncdf">htruncdf</a></code> 
(<code><a href="#topic+qview">qview</a></code>; <code><a href="#topic+ltruncdf">ltruncdf</a></code>) or 
<code><a href="utils.html#topic+head">head</a></code> (<code><a href="#topic+htruncdf">htruncdf</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>htrundf</code> - returns n number of rows of a truncated dataframe.
</p>
<p><code>trundf</code> - returns a truncated dataframe.
</p>
<p><code>ltruncdf</code> - returns a list of n number of rows of a truncated 
dataframes.
</p>
<p><code>qview</code> - returns a dataframe head with summary statistics.
</p>
<p><code>lview</code> - prints a list of the qdap object and invisibly returns 
the unclassed object.
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+head">head</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
truncdf(raj[1:10, ])
truncdf(raj[1:10, ], 40)
htruncdf(raj)
htruncdf(raj, 20)
htruncdf(raj, ,20)
ltruncdf(rajPOS, width = 4)
qview(raj)
qview(CO2)
lview(question_type(DATA.SPLIT$state, DATA.SPLIT$person))
lview(rajPOS)
lview(lm(mpg~hp, data = mtcars))

## End(Not run)
</code></pre>

<hr>
<h2 id='imperative'>Intuitively Remark Sentences as Imperative</h2><span id='topic+imperative'></span>

<h3>Description</h3>

<p>Automatic imperative remarking.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imperative(
  dataframe,
  person.var,
  text.var,
  lock.incomplete = FALSE,
  additional.names = NULL,
  parallel = FALSE,
  warning = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imperative_+3A_dataframe">dataframe</code></td>
<td>
<p>A data.frame object.</p>
</td></tr>
<tr><td><code id="imperative_+3A_person.var">person.var</code></td>
<td>
<p>The person variable.</p>
</td></tr>
<tr><td><code id="imperative_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="imperative_+3A_lock.incomplete">lock.incomplete</code></td>
<td>
<p>logical.  If <code>TRUE</code> locks incomplete sentences 
(sentences ending with &quot;|&quot;) from being marked as imperative.</p>
</td></tr>
<tr><td><code id="imperative_+3A_additional.names">additional.names</code></td>
<td>
<p>Additional names that may be used in a command 
(people in the context that do not speak).</p>
</td></tr>
<tr><td><code id="imperative_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create.  With 
the <code>mraja1spl</code> data set, with an 8 core machine, 
<code><a href="#topic+imperative">imperative</a></code> had 1/3 the running time.</p>
</td></tr>
<tr><td><code id="imperative_+3A_warning">warning</code></td>
<td>
<p>logical.  If <code>TRUE</code> provides comma warnings (sentences 
that contain numerous commas that may be handled incorrectly by the 
algorithm).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with a text variable indicating imperative 
sentences.  Imperative sentences are marked with * followed by the original 
end mark.
</p>


<h3>Warning</h3>

<p>The algorithm used by <code><a href="#topic+imperative">imperative</a></code> is 
sensitive to English language dialects and types.  Commas can indicate a 
choppy sentence and may indicate a false positive.  Sentences marked with 
'AAVE' may be the use of African American Vernacular English and not an 
imperative sentence.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- data.frame(name=c("sue", rep(c("greg", "tyler", "phil", 
    "sue"), 2)), statement=c("go get it|", "I hate to read.", 
    "Stop running!", "I like it!", "You are terrible!", "Don't!", 
    "Greg, go to the red, brick office.", "Tyler go to the gym.", 
    "Alex don't run."), stringsAsFactors = FALSE)

imperative(dat, "name", "statement", , c("Alex"))
imperative(dat, "name", "statement", lock.incomplete = TRUE, c("Alex"))
imperative(dat, "name", "statement", , c("Alex"), warning=TRUE)
imperative(dat, "name", "statement", , c("Alex"), warning=TRUE,  
    parallel = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='incomplete_replace'>Denote Incomplete End Marks With &quot;|&quot;</h2><span id='topic+incomplete_replace'></span><span id='topic+incomp'></span>

<h3>Description</h3>

<p>Replaces incomplete sentence end marks (.., ..., .?, ..?, en &amp; em dash etc.)
with <code>"|"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>incomplete_replace(text.var, scan.mode = FALSE)

incomp(text.var, scan.mode = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="incomplete_replace_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="incomplete_replace_+3A_scan.mode">scan.mode</code></td>
<td>
<p>logical.  If <code>TRUE</code> only scans and reports incomplete 
sentences.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a text variable (character sting) with incomplete sentence 
marks (.., ..., .?, ..?, en &amp; em dash etc.) replaced with &quot;|&quot;.  If scan mode 
is <code>TRUE</code> returns a data frame with incomplete sentence location.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("the...",  "I.?", "you.", "threw..", "we?")
incomplete_replace(x)
incomp(x)
incomp(x, scan.mode = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='inspect_text'>Inspect Text Vectors</h2><span id='topic+inspect_text'></span><span id='topic+inspect_text.default'></span><span id='topic+inspect_text.Corpus'></span>

<h3>Description</h3>

<p><code>inspect_text</code> - Inspect a text vector with adjustable string wrapping; 
created a pretty printed named list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inspect_text(text.var, grouping.var = NULL, ...)

## Default S3 method:
inspect_text(text.var, grouping.var = NULL, ...)

## S3 method for class 'Corpus'
inspect_text(text.var, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inspect_text_+3A_text.var">text.var</code></td>
<td>
<p>The text variable or a <code><a href="#topic+wfm">wfm</a></code> object.</p>
</td></tr>
<tr><td><code id="inspect_text_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="inspect_text_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a named list (prints pretty).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(raj, inspect_text(dialogue))
with(raj, inspect_text(dialogue, person))
with(raj, inspect_text(dialogue, list(paste("Act", act), person)))

## With a tm Corpus object
library(tm)
data(crude)
inspect_text(crude)

## End(Not run)
</code></pre>

<hr>
<h2 id='is.global'>Test If Environment is Global</h2><span id='topic+is.global'></span>

<h3>Description</h3>

<p>A logical test to determine if the current environment is the global 
environment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.global(n = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.global_+3A_n">n</code></td>
<td>
<p>The number of generations to go back.  If used as a function 
argument n should be set to 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical response.
</p>


<h3>Author(s)</h3>

<p>Simon O'Hanlon and Tyler Rinker &lt;tyler.rinker@gmail.com&gt;
</p>


<h3>References</h3>

<p><a href="http://stackoverflow.com/questions/18637656/detect-if-environment-is-global-enviroment">http://stackoverflow.com/questions/18637656/detect-if-environment-is-global-enviroment</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+globalenv">globalenv</a></code>,
<code><a href="base.html#topic+parent.frame">parent.frame</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.global()
lapply(1:3, function(i) is.global())
FUN &lt;- function() is.global(); FUN()

FUN2 &lt;- function(x = is.global(2)) x
FUN2()
FUN3 &lt;- function() FUN2(); FUN3()
</code></pre>

<hr>
<h2 id='key_merge'>Merge Demographic Information with Person/Text Transcript</h2><span id='topic+key_merge'></span>

<h3>Description</h3>

<p>Wrapper function (<code><a href="base.html#topic+merge">merge</a></code>) for merging demographic 
information with a person/text transcript.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>key_merge(transcript.df, key.df, common.column = NULL, defualt.arrange = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="key_merge_+3A_transcript.df">transcript.df</code></td>
<td>
<p>The text/person transcript dataframe</p>
</td></tr>
<tr><td><code id="key_merge_+3A_key.df">key.df</code></td>
<td>
<p>The demographic dataframe.</p>
</td></tr>
<tr><td><code id="key_merge_+3A_common.column">common.column</code></td>
<td>
<p>The column(s) shared by <code>transcript.df</code> and 
<code>key.df</code>.  If <code>NULL</code> function defaults to use any columns with the 
same name.</p>
</td></tr>
<tr><td><code id="key_merge_+3A_defualt.arrange">defualt.arrange</code></td>
<td>
<p>logical.  If <code>TRUE</code> will arrange the columns with 
text to the far right.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Outputs a merged transcript dataframe with demographic information.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+merge">merge</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#First view transcript dataframe and demographics dataframe.
ltruncdf(list(raj, raj.demographics), 10, 50)
merged.raj &lt;- key_merge(raj, raj.demographics)
htruncdf(merged.raj, 10, 40)

## End(Not run)
</code></pre>

<hr>
<h2 id='kullback_leibler'>Kullback Leibler Statistic</h2><span id='topic+kullback_leibler'></span>

<h3>Description</h3>

<p>A proximity measure between two probability distributions applied to speech.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kullback_leibler(x, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kullback_leibler_+3A_x">x</code></td>
<td>
<p>A numeric vector, matrix or data frame.</p>
</td></tr>
<tr><td><code id="kullback_leibler_+3A_y">y</code></td>
<td>
<p>A second numeric vector if x is also a vector.  Default is 
<code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses Kullback &amp; Leibler's (1951) formula:
</p>
<p style="text-align: center;"><code class="reqn">D_{KL}(P||Q)=\sum_i{ln\left ( \frac{P_{i}}{Q_{i}} \right )}P_{i}</code>
</p>



<h3>Value</h3>

<p>Returns a matrix of the Kullback Leibler measure between each vector 
of probabilities.
</p>


<h3>Note</h3>

<p>The <code>kullback_leibler</code> function generally receives the output of
either <code>wfm</code> or <code>wfdf</code> functions.
</p>


<h3>References</h3>

<p>Kullback, S., &amp; Leibler, R.A. (1951). On Information and 
sufficiency. Annals of Mathematical Statistics 22 (1): 79-86. 
doi:10.1214/aoms/1177729694
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
p.df &lt;- wfdf(DATA$state, DATA$person)
p.mat &lt;- wfm(text.var = DATA$state, grouping.var = DATA$person)
kullback_leibler(p.mat)
(x &lt;- kullback_leibler(p.df))
print(x, digits = 5)
kullback_leibler(p.df$greg, p.df$sam)

## p.df2 &lt;- wfdf(raj$dialogue, raj$person)
## x &lt;- kullback_leibler(p.df2)

## End(Not run)
</code></pre>

<hr>
<h2 id='left_just'>Text Justification</h2><span id='topic+left_just'></span><span id='topic+right_just'></span>

<h3>Description</h3>

<p><code>left_just</code> - Left justifies a text/character column.
</p>
<p><code>right_just</code> - A means of undoing a left justification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>left_just(dataframe, column = NULL, keep.class = FALSE)

right_just(dataframe)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="left_just_+3A_dataframe">dataframe</code></td>
<td>
<p>A data.frame object with the text column.</p>
</td></tr>
<tr><td><code id="left_just_+3A_column">column</code></td>
<td>
<p>The column to be justified.  If <code>NULL</code> all columns are 
justified.</p>
</td></tr>
<tr><td><code id="left_just_+3A_keep.class">keep.class</code></td>
<td>
<p>logical.  If <code>TRUE</code> will attempt to keep the original 
classes of the dataframe if the justification is not altered (i.e., numeric 
will not be honored but factor may be).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with selected text column left/right justified.
</p>


<h3>Note</h3>

<p><code><a href="#topic+left_just">left_just</a></code> inserts spaces to achieve the 
justification.  This could interfere with analysis and therefore the output 
from <code><a href="#topic+left_just">left_just</a></code> should only be used for visualization 
purposes, not analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
left_just(DATA)
left_just(DATA, "state")
left_just(CO2[1:15,])
right_just(left_just(CO2[1:15,]))

## End(Not run)
</code></pre>

<hr>
<h2 id='lexical_classification'>Lexical Classification Score</h2><span id='topic+lexical_classification'></span>

<h3>Description</h3>

<p>Transcript apply lexical classification score (content to functional word 
proportion) by grouping variable(s) and optionally plot 
the breakdown of the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lexical_classification(
  text.var,
  grouping.var = NULL,
  order.by.lexical_classification = TRUE,
  function.words = qdapDictionaries::function.words,
  bracket = "all",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lexical_classification_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="lexical_classification_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="lexical_classification_+3A_order.by.lexical_classification">order.by.lexical_classification</code></td>
<td>
<p>logical.  If <code>TRUE</code> orders the 
results by #' lexical_classification score.</p>
</td></tr>
<tr><td><code id="lexical_classification_+3A_function.words">function.words</code></td>
<td>
<p>A vector of function words.  Default is 
<code><a href="qdapDictionaries.html#topic+function.words">function.words</a></code>.</p>
</td></tr>
<tr><td><code id="lexical_classification_+3A_bracket">bracket</code></td>
<td>
<p>The bracket type to remove.  Use <code>NULL</code> to not remove 
bracketed substrings.  See <code>bracket</code> argument in 
<code><a href="#topic+bracketX">bracketX</a></code> for bracket types.</p>
</td></tr>
<tr><td><code id="lexical_classification_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+bracketX">bracketX</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Content words (i.e., nouns, verbs, adjectives, and adverbs) tend to 
be the words speakers stresses in language use.  Whereas, functional words 
are the &quot;glue&quot; that holds the content together.  Speakers devote much less 
time and stress to these words (i.e., pronouns, articles, conjunctions, 
quantifiers, and prepositions).
</p>


<h3>Value</h3>

<p>A list containing at the following components: 
</p>
<table>
<tr><td><code>content</code></td>
<td>
<p>A <code>data.frame</code> of all content words used and corresponding frequencies</p>
</td></tr> 
<tr><td><code>functional</code></td>
<td>
<p>A <code>data.frame</code> of all content words used and corresponding frequencies</p>
</td></tr> 
<tr><td><code>raw</code></td>
<td>
<p>Sentence level descriptive statistics on content vs. functional word use (ave.content.rate is also nown as lexical density</p>
</td></tr> 
<tr><td><code>lexical_classification</code></td>
<td>
<p>Summarized (grouping variable level) descriptive statistics for content vs. functional word use</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chung, C. &amp; Pennebaker, J. (2007). The Psychological Functions of Function Words. In K. Fiedler (Ed.) Social Communication (pp. 343-359). New York: Psychology Press.
</p>
<p>Pulvermuller, F. (1999). Words in the brain's language. Behavioral and Brain Sciences, 22, pp. 253-279. doi:10.1017/S0140525X9900182X
</p>
<p>Segalowitz, S. J. &amp; Lane, K. (2004). Perceptual fluency and lexical access for function versus content words. Behavioral and Brain Sciences, 27, 307-308. doi:10.1017/S0140525X04310071 
</p>
<p>Bell, A., Brenier, J. M., Gregory, M., Girand, C. &amp; Jurafsky, D. (2009).  Predictability Effects on Durations of Content and Function Words in Conversational English.  Journal of Memory and Language, 60(1), 92-111. doi:10.1016/j.jml.2008.06.003
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
lexical_classification("I did not like the dog.")
lexical_classification(DATA.SPLIT$state, DATA.SPLIT$person)

(out &lt;- with(pres_debates2012, lexical_classification(dialogue, list(person, time))))
plot(out)

scores(out)

out2 &lt;- preprocessed(out)
htruncdf(out2)
plot(out2)

plot(out[["content"]])
dev.new()
plot(out[["functional"]])

## cloud of functional vs. content
## Highlight Content Words
set.seed(10)
par(mar = c(0,0,0,0))
list(
        content = out[["content"]],
        functional = out[["functional"]]
    ) %&gt;%
    list_df2df("type") %&gt;%
    dplyr::mutate(colors = ifelse(type == "functional", "gray80", "blue")) %&gt;%
    with(., wordcloud::wordcloud(
        word, 
        freq, 
        min.freq = 8, 
        random.order=FALSE,
        ordered.colors = TRUE,
        colors = colors
    )) 
mtext("2012 Presidential Debates:\nFunctional vs. Content Word Use", padj=1.25)
legend(
    .05, .12, bty = "n",
    legend = c("functional", "content"), 
    fill = c("gray80", "blue"),  
    cex = .7
)

## Highlight Functional Words
set.seed(10)
par(mar = c(0,0,0,0))
list(
        content = out[["content"]],
        functional = out[["functional"]]
    ) %&gt;%
    list_df2df("type") %&gt;%
    dplyr::mutate(colors = ifelse(type == "functional", "red", "gray80")) %&gt;%
    with(., wordcloud::wordcloud(
        word, 
        freq, 
        min.freq = 8, 
        random.order=FALSE,
        ordered.colors = TRUE,
        colors = colors
    )) 
mtext("2012 Presidential Debates:\nFunctional vs. Content Word Use", padj=1.25)
legend(
    .05, .12, bty = "n",
    legend = c("functional", "content"), 
    fill = c("red", "gray80"),  
    cex = .7
)

#=============#
## ANIMATION ##
#=============#
## EXAMPLE 1
lex_ani &lt;- lexical_classification(DATA.SPLIT$state, DATA.SPLIT$person)
lexa &lt;- Animate(lex_ani, content="white", functional="blue",
    current.color = "yellow", current.speaker.color="grey70")

bgb &lt;- vertex_apply(lexa, label.color="grey80", size=20, color="grey40")
bgb &lt;- edge_apply(bgb, label.color="yellow")

print(bgb, bg="black", net.legend.color ="white", pause=1)

## EXAMPLE 2
lex_ani2 &lt;- lexical_classification(mraja1spl$dialogue, mraja1spl$person)
lexa2 &lt;- Animate(lex_ani2, content="white", functional="blue",
    current.color = "yellow", current.speaker.color="grey70")

bgb2 &lt;- vertex_apply(lexa2, label.color="grey80", size=17, color="grey40")
bgb2 &lt;- edge_apply(bgb2, label.color="yellow")
print(bgb2, bg="black", pause=.75, net.legend.color = "white")

## EXAMPLE 3 (bar plot)
Animate(lex_ani2, type="bar")

## EXAMPLE 4 (text plot)
Animate(lex_ani2, type="text")

#======================#
## Complex Animations ##
#======================#
## EXAMPLE 1: Network + Text + Bar
 
library(animation)
library(grid)
library(gridBase)
library(qdap)
library(igraph)
library(plotrix)

lex_ani2 &lt;- lexical_classification(mraja1spl$dialogue, mraja1spl$person)

## Set up the network version
lex_net &lt;- Animate(lex_ani2, contextual="white", lexal="blue",
    current.color = "yellow", current.speaker.color="grey70")
bgb &lt;- vertex_apply(lex_net, label.color="grey80", size=17, color="grey40")
bgb &lt;- edge_apply(bgb, label.color="yellow")


## Set up the bar version
lex_bar &lt;- Animate(lex_ani2, type="bar")

## Set up the text
lex_text &lt;- Animate(lex_ani2, type="text", size = 3, width=125, color="white")

## Generate a folder
loc &lt;- folder(animation_lexical_classification)
setwd(loc)

## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)


lex_text_bar &lt;- Map(function(x, y){

    uns &lt;- unit(c(-1.6,.5,-.2,.25), "cm")

    x &lt;- x +
        theme(plot.margin = uns,
            text=element_text(color="white"),
            legend.text=element_text(color="white"),
            legend.background = element_rect(fill = "black"),
            panel.border = element_rect(color = "black"),
            panel.background = element_rect(fill = "black"),
            plot.background = element_rect(fill = "black",
                color="black"))

    uns2 &lt;- unit(c(-.5,.5,-.45,.25), "cm")

    y &lt;- y +
        theme(plot.margin = uns2,
            text=element_text(color="white"),
            legend.text=element_text(color="white"),
            legend.background = element_rect(fill = "black"),
            plot.background = element_rect(fill = "black",
                color="black"))

    gA &lt;- ggplotGrob(x)
    gB &lt;- ggplotGrob(y)
    maxWidth &lt;- grid::unit.pmax(gA$widths[2:5], gB$widths[2:5])
    gA$widths[2:5] &lt;- as.list(maxWidth)
    gB$widths[2:5] &lt;- as.list(maxWidth)
    out &lt;- arrangeGrob(gA, gB, ncol=1, heights = grid::unit(c(.3, .7), "native"))
    ## grid.draw(out)
    invisible(out)

}, lex_text, lex_bar)


FUN &lt;- function(follow=FALSE, theseq = seq_along(bgb)) {

    Title &lt;- "Animated Content Rate: Romeo and Juliet Act 1"
    Legend &lt;- c(.2, -1, 1.5, -.95)
    Legend.cex &lt;- 1

    lapply(theseq, function(i) {
        if (follow) {
            png(file=sprintf("%s/images/Rplot%s.png", loc, i),
                width=750, height=875)
        }
        ## Set up the layout
        layout(matrix(c(rep(1, 7), rep(2, 6)), 13, 1, byrow = TRUE))

        ## Plot 1
        par(mar=c(2, 0, 2, 0), bg="black")
        #par(mar=c(2, 0, 2, 0))
        set.seed(22)
        plot.igraph(bgb[[i]], edge.curved=TRUE)
        mtext(Title, side=3, col="white")
        color.legend(Legend[1], Legend[2], Legend[3], Legend[4],
              c("Functional", "Content"), attributes(bgb)[["legend"]],
              cex = Legend.cex, col="white")

        ## Plot2
        plot.new()
        vps &lt;- baseViewports()

        print(lex_text_bar[[i]], vp = vpStack(vps$figure,vps$plot))

        animation::ani.pause()

        if (follow) {
            dev.off()
        }
    })

}

FUN()

## Detect OS
type &lt;- if(.Platform$OS.type == "windows") shell else system


saveHTML(FUN(), autoplay = FALSE, loop = TRUE, verbose = FALSE,
    ani.height = 1000, ani.width=750,
    outdir = loc, single.opts =
    "'controls': ['first', 'previous', 'play', 'next', 'last', 'loop', 'speed'], 'delayMin': 0")

FUN(TRUE)

## EXAMPLE 2: Line + Text + Bar
## Generate a folder
loc2 &lt;- folder(animation_lexical_classification2)
setwd(loc2)

lex_ani2 &lt;- lexical_classification(mraja1spl$dialogue, mraja1spl$person)

## Set up the bar version
lex_bar &lt;- Animate(lex_ani2, type="bar")
cumline &lt;- cumulative(lex_bar)
lex_line &lt;- plot(cumline)
ylims &lt;- range(cumline[[1]][-c(1:100)]) + c(-.1, .1)

## Set up the text
lex_text &lt;- Animate(lex_ani2, type="text", size = 4, width = 80)


lex_line_text_bar &lt;- Map(function(x, y, z){

    mar &lt;- theme(plot.margin = unit(c(0, .5, 0, .25), "cm"))

    gA &lt;- ggplotGrob(x + mar + 
        theme(panel.background = element_rect(fill = NA, colour = NA), 
            panel.border = element_rect(fill = NA, colour = NA),
            plot.background = element_rect(fill = NA, colour = NA)))
    gB &lt;- ggplotGrob(y + mar)
    gC &lt;- ggplotGrob(z + mar + ylab("Average Content Rate") + 
        coord_cartesian(ylim = ylims) +
        ggtitle("Average Content Rate: Romeo &amp; Juliet Act 1"))

    maxWidth &lt;- grid::unit.pmax(gA$widths[2:5], gB$widths[2:5], gC$widths[2:5])
    gA$widths[2:5] &lt;- as.list(maxWidth)
    gB$widths[2:5] &lt;- as.list(maxWidth)
    gC$widths[2:5] &lt;- as.list(maxWidth)
    out &lt;- arrangeGrob(gC, gA, gB, ncol=1, heights = grid::unit(c(.38, .25, .37), "native"))
    ## grid.draw(out)
    invisible(out)

}, lex_text, lex_bar, lex_line)


FUN2 &lt;- function(follow=FALSE, theseq = seq_along(lex_line_text_bar)) {


    lapply(theseq, function(i) {
        if (follow) {
            png(file=sprintf("%s/images/Rplot%s.png", loc2, i),
                width=750, height=875)
        }
 
        print(lex_line_text_bar[[i]])
        animation::ani.pause()

        if (follow) {
            dev.off()
        }
    })

}

FUN2()

## Detect OS
type &lt;- if(.Platform$OS.type == "windows") shell else system

library(animation)
saveHTML(FUN2(), autoplay = FALSE, loop = TRUE, verbose = FALSE,
    ani.height = 1000, ani.width=750,
    outdir = loc2, single.opts =
    "'controls': ['first', 'previous', 'play', 'next', 'last', 'loop', 'speed'], 'delayMin': 0")

FUN2(TRUE)

#==================#
## Static Network ##
#==================#
(lexdat &lt;- with(sentSplit(DATA, 4), lexical_classification(state, person)))
m &lt;- Network(lexdat)
m
print(m, bg="grey97", vertex.color="grey75")

print(m, title="Lexical Content Discourse Map", title.color="white", 
    bg="black", legend.text.color="white", vertex.label.color = "grey70",
    edge.label.color="yellow")

## or use themes:
dev.off()
m + qtheme()
m + theme_nightheat
dev.off()
m + theme_nightheat(title="Lexical Content Discourse Map",
    vertex.label.color = "grey50")
    
#==================================#
## Content Rate Over Time Example ##
#==================================#
lexpres &lt;- lapply(with( pres_debates2012, split(dialogue, time)), function(x) {
    lexical_classification(x)
})
lexplots &lt;- lapply(seq_along(lexpres), function(i) {
    dat &lt;- cumulative(lexpres[[i]])
    m &lt;- plot(dat)
    if (i != 2) m &lt;- m + ylab("")  
    if (i == 2) m &lt;- m + ylab("Average Content Rate") 
    if (i != 3) m &lt;- m + xlab(NULL)
    if (i != 1) m &lt;- m + theme(plot.margin=unit(c(0, 1, 0, .5) + .1, "lines"))
    m + ggtitle(paste("Debate", i)) + 
        coord_cartesian(xlim = c(300, length(dat[[1]])),
            ylim = unlist(range(dat[[1]][-c(1:300)]) + c(-.25, .25)))
})

library(grid)
library(gridExtra)
do.call(grid.arrange, lexplots)

## End(Not run)
</code></pre>

<hr>
<h2 id='mcsv_r'>Read/Write Multiple csv Files at a Time</h2><span id='topic+mcsv_r'></span><span id='topic+mcsv_w'></span>

<h3>Description</h3>

<p><code>mcsv_r</code> - Read and assign multiple csv files at the same time.
</p>
<p><code>mcsv_w</code> - Write multiple csv files into a file at the same time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcsv_r(
  files,
  a.names = NULL,
  l.name = NULL,
  list = TRUE,
  pos = 1,
  envir = as.environment(pos)
)

mcsv_w(
  ...,
  dir = NULL,
  open = FALSE,
  sep = ", ",
  dataframes = NULL,
  pos = 1,
  envir = as.environment(pos)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcsv_r_+3A_files">files</code></td>
<td>
<p>csv file(s) to read.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_a.names">a.names</code></td>
<td>
<p>object names to assign the csv file(s) to.  If <code>NULL</code> 
assigns the name(s) of the csv files in the directory, without the file 
extension, to the objects in the global environment.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_l.name">l.name</code></td>
<td>
<p>A single character string of a name to assign to the list if 
dataframes created by the csv files being read in.  Default (<code>NULL</code>) 
uses <code>L1</code>.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_list">list</code></td>
<td>
<p>logical.  If <code>TRUE</code> then a list of dataframes is crated in 
the global environment in addition to the individual dataframes.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_pos">pos</code></td>
<td>
<p>where to do the removal. By default, uses the current environment.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_envir">envir</code></td>
<td>
<p>the environment to use.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_...">...</code></td>
<td>
<p>data.frame object(s) to write to a file or a list of data.frame 
objects.  If the objects in a list are unnamed V + digit will be assigned.  
Lists of dataframes (e.g., the output from <code><a href="#topic+termco">termco</a></code> or 
<code><a href="#topic+polarity">polarity</a></code>) can be passed as well.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_dir">dir</code></td>
<td>
<p>optional directory names.  If <code>NULL</code> a directory will be 
created in the working directory with the data and time stamp as the folder 
name.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_open">open</code></td>
<td>
<p>logical.  If <code>TRUE</code> opens the directory upon completion.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_sep">sep</code></td>
<td>
<p>A character string to separate the terms.</p>
</td></tr>
<tr><td><code id="mcsv_r_+3A_dataframes">dataframes</code></td>
<td>
<p>An optional character vector of dataframes in lieu of ... 
argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>mcsv is short for &quot;multiple csv&quot; and the suffix c(_r, _w) stands for 
&quot;read&quot; (r) or &quot;write&quot; (w).
</p>


<h3>Value</h3>

<p><code>mcsv_r</code> - reads in multiple csv files at once.
</p>
<p><code>mcsv_w</code> - creates a directory with multiple csv files.  
Silently returns the path of the directory.
</p>


<h3>Note</h3>

<p><code><a href="#topic+mcsv_r">mcsv_r</a></code> is useful for reading in multiple csv files 
from <code><a href="#topic+cm_df.temp">cm_df.temp</a></code> for interaction with 
<code><a href="#topic+cm_range2long">cm_range2long</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cm_range2long">cm_range2long</a></code>,
<code><a href="#topic+cm_df.temp">cm_df.temp</a></code>,
<code><a href="#topic+condense">condense</a></code>,
<code><a href="base.html#topic+assign">assign</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## mcsv_r EXAMPLE:
mtcarsb &lt;- mtcars[1:5, ]; CO2b &lt;- CO2[1:5, ]
(a &lt;- mcsv_w(mtcarsb, CO2b, dir="foo"))
rm("mtcarsb", "CO2b")  # gone from .GlobalEnv
(nms &lt;- dir(a))
mcsv_r(file.path(a, nms))
mtcarsb; CO2b
rm("mtcarsb", "CO2b")  # gone from .GlobalEnv
mcsv_r(file.path(a, nms), paste0("foo.dat", 1:2))
foo.dat1; foo.dat2
rm("foo.dat1", "foo.dat2")  # gone from .GlobalEnv
delete("foo")

## mcsv_w EXAMPLES:
(a &lt;- mcsv_w(mtcars, CO2, dir="foo"))
delete("foo")

## Write lists of dataframes as well
poldat &lt;- with(DATA.SPLIT, polarity(state, person))
term &lt;- c("the ", "she", " wh")
termdat &lt;- with(raj.act.1,  termco(dialogue, person, term))
mcsv_w(poldat, termdat, mtcars, CO2, dir="foo2")
delete("foo2")

## End(Not run)
</code></pre>

<hr>
<h2 id='mraja1'>Romeo and Juliet: Act 1 Dialogue Merged with Demographics</h2><span id='topic+mraja1'></span>

<h3>Description</h3>

<p>A dataset containing act 1 of Romeo and Juliet with demographic information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mraja1)
</code></pre>


<h3>Format</h3>

<p>A data frame with 235 rows and 5 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> sex. Gender
</p>
</li>
<li><p> fam.aff. Family affiliation of character
</p>
</li>
<li><p> died. Dummy coded death variable (0-no; 1-yes);  if yes the character 
dies in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='mraja1spl'>Romeo and Juliet: Act 1 Dialogue Merged with Demographics and Split</h2><span id='topic+mraja1spl'></span>

<h3>Description</h3>

<p>A dataset containing act 1 of Romeo and Juliet with demographic information 
and turns of talk split into sentences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mraja1spl)
</code></pre>


<h3>Format</h3>

<p>A data frame with 508 rows and 7 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> tot. 
</p>
</li>
<li><p> sex. Gender
</p>
</li>
<li><p> fam.aff. Family affiliation of character
</p>
</li>
<li><p> died. Dummy coded death variable (0-no; 1-yes);  if yes the character 
dies in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue 
</p>
</li>
<li><p> stem.text. 
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='multigsub'>Multiple gsub</h2><span id='topic+multigsub'></span><span id='topic+mgsub'></span><span id='topic+sub_holder'></span>

<h3>Description</h3>

<p><code>multigsub</code> - A wrapper for <code><a href="base.html#topic+gsub">gsub</a></code> that takes a vector 
of search terms and a vector or single value of replacements.
</p>
<p><code>sub_holder</code> - This function holds the place for particular character 
values, allowing the user to manipulate the vector and then revert the place
holders back to the original values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multigsub(
  pattern,
  replacement,
  text.var,
  leadspace = FALSE,
  trailspace = FALSE,
  fixed = TRUE,
  trim = TRUE,
  order.pattern = fixed,
  ...
)

mgsub(
  pattern,
  replacement,
  text.var,
  leadspace = FALSE,
  trailspace = FALSE,
  fixed = TRUE,
  trim = TRUE,
  order.pattern = fixed,
  ...
)

sub_holder(pattern, text.var, alpha.type = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multigsub_+3A_pattern">pattern</code></td>
<td>
<p>Character string to be matched in the given character vector.</p>
</td></tr>
<tr><td><code id="multigsub_+3A_replacement">replacement</code></td>
<td>
<p>Character string equal in length to pattern or of length 
one which are  a replacement for matched pattern.</p>
</td></tr>
<tr><td><code id="multigsub_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="multigsub_+3A_leadspace">leadspace</code></td>
<td>
<p>logical.  If <code>TRUE</code> inserts a leading space in the 
replacements.</p>
</td></tr>
<tr><td><code id="multigsub_+3A_trailspace">trailspace</code></td>
<td>
<p>logical.  If <code>TRUE</code> inserts a trailing space in the 
replacements.</p>
</td></tr>
<tr><td><code id="multigsub_+3A_fixed">fixed</code></td>
<td>
<p>logical. If <code>TRUE</code>, pattern is a string to be matched as is. 
Overrides all conflicting arguments.</p>
</td></tr>
<tr><td><code id="multigsub_+3A_trim">trim</code></td>
<td>
<p>logical.  If <code>TRUE</code> leading and trailing white spaces are 
removed and multiple white spaces are reduced to a single white space.</p>
</td></tr>
<tr><td><code id="multigsub_+3A_order.pattern">order.pattern</code></td>
<td>
<p>logical.  If <code>TRUE</code> and <code>fixed = TRUE</code>, the 
<code>pattern</code> string is sorted by number of characters to prevent substrings 
replacing meta strings (e.g., <code>pattern = c("the", "then")</code> resorts to 
search for &quot;then&quot; first).</p>
</td></tr>
<tr><td><code id="multigsub_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="base.html#topic+gsub">gsub</a></code>.</p>
</td></tr>
<tr><td><code id="multigsub_+3A_alpha.type">alpha.type</code></td>
<td>
<p>logical.  If <code>TRUE</code> alpha (lower case letters) are 
used for the key.  If <code>FALSE</code> numbers are used as the key.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>multigsub</code> - Returns a vector with the pattern replaced.
</p>
<p><code>sub_holder</code> - Returns a list with the following:
</p>
<table>
<tr><td><code>output</code></td>
<td>
<p>keyed place holder character vector</p>
</td></tr> 
<tr><td><code>unhold</code></td>
<td>
<p>A function used to revert back to the original values</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>unhold</code> function for <code>sub_holder</code> will only work on keys
that have not been disturbed by subsequent alterations.  The key follows the 
pattern of 'qdapplaceholder' followed by lower case letter keys followed by
'qdap'.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gsub">gsub</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## ======================
##    `mgsub` Function
## ======================

multigsub(c("it's", "I'm"), c("it is", "I am"), DATA$state)
mgsub(c("it's", "I'm"), c("it is", "I am"), DATA$state)
mgsub("[[:punct:]]", "PUNC", DATA$state, fixed = FALSE)

## ====================== 
## `sub_holder` Function
## ======================

## `alpha.type` as TRUE
(fake_dat &lt;- paste(emoticon[1:11,2], DATA$state))
(m &lt;- sub_holder(emoticon[,2], fake_dat))
m$unhold(strip(m$output))
# With Stemming
m$unhold(stemmer(strip(m$output), capitalize = FALSE))

## `alpha.type` as FALSE (numeric keys)
vowels &lt;- LETTERS[c(1, 5, 9, 15, 21)]
(m2 &lt;- sub_holder(vowels, toupper(DATA$state), alpha.type = FALSE))
m2$unhold(gsub("[^0-9]", "", m2$output))
mtabulate(strsplit(m2$unhold(gsub("[^0-9]", "", m2$output)), ""))

## End(Not run)
</code></pre>

<hr>
<h2 id='multiscale'>Nested Standardization</h2><span id='topic+multiscale'></span>

<h3>Description</h3>

<p>Standardize within a subgroup and then within a group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiscale(numeric.var, grouping.var, original_order = TRUE, digits = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiscale_+3A_numeric.var">numeric.var</code></td>
<td>
<p>A numeric variable.</p>
</td></tr>
<tr><td><code id="multiscale_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="multiscale_+3A_original_order">original_order</code></td>
<td>
<p>logical.  IF <code>TRUE</code> orders by the original order.
If <code>FALSE</code> orders by group.</p>
</td></tr>
<tr><td><code id="multiscale_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of two:
</p>
<table>
<tr><td><code>SCALED_OBSERVATIONS</code></td>
<td>
<p>A dataframe of scaled observations at level one 
and two of the nesting with possible outliers.</p>
</td></tr> 
<tr><td><code>DESCRIPTIVES_BY_GROUP</code></td>
<td>
<p>A data frame of descriptives by group.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+scale">scale</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- with(mraja1spl, word_stats(dialogue, list(person, sex, fam.aff)))
htruncdf(colsplit2df(dat$ts), ,4)
out1 &lt;- with(colsplit2df(dat$ts), multiscale(word.count, person))
ltruncdf(out1, 10)
out2 &lt;- with(colsplit2df(dat$ts), multiscale(word.count, 
    list(fam.aff, sex)))
ltruncdf(out2, 10)
out3 &lt;- with(colsplit2df(dat$ts), multiscale(word.count, 
    list(fam.aff, sex), original_order = FALSE))
ltruncdf(out3, 10)

## End(Not run)
</code></pre>

<hr>
<h2 id='NAer'>Replace Missing Values (NA)</h2><span id='topic+NAer'></span>

<h3>Description</h3>

<p>Replace missing values (<code>NA</code>) in a vector or dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NAer(x, replace = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NAer_+3A_x">x</code></td>
<td>
<p>A vector or dataframe with missing values (<code>NA</code>).</p>
</td></tr>
<tr><td><code id="NAer_+3A_replace">replace</code></td>
<td>
<p>The value to replace missing values (<code>NA</code>) with.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector or dataframe with missing values replaced.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(10)              
(x &lt;- sample(c(rep(NA, 4), 1:10), 20, rep=T))
NAer(x)

set.seed(10)
(y &lt;- data.frame(matrix(x, 5, 4))                           )
NAer(y)
NAer(y, "MISSING")  

## End(Not run)
</code></pre>

<hr>
<h2 id='name2sex'>Names to Gender</h2><span id='topic+name2sex'></span>

<h3>Description</h3>

<p>A wrapper for the <code><a href="gender.html#topic+gender">gender</a></code> function used to predict 
gender based on first name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>name2sex(names.list, USE.NAMES = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="name2sex_+3A_names.list">names.list</code></td>
<td>
<p>Character vector containing first names.</p>
</td></tr>
<tr><td><code id="name2sex_+3A_use.names">USE.NAMES</code></td>
<td>
<p>logical.  If <code>TRUE</code> names.list is used to name the 
gender vector.</p>
</td></tr>
<tr><td><code id="name2sex_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="gender.html#topic+gender">gender</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of predicted gender (M/F) based on first name.
</p>


<h3>See Also</h3>

<p><code><a href="gender.html#topic+gender">gender</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
name2sex(qcv(mary, jenn, linda, JAME, GABRIEL, OLIVA, 
    tyler, jamie, JAMES, tyrone, cheryl, drew))

## End(Not run)
</code></pre>

<hr>
<h2 id='Network'>Generic Network Method</h2><span id='topic+Network'></span>

<h3>Description</h3>

<p>Create a network plot for select qdap outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Network(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Network_+3A_x">x</code></td>
<td>
<p>A select qdap object.</p>
</td></tr>
<tr><td><code id="Network_+3A_...">...</code></td>
<td>
<p>Arguments passed to Network method of other classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a network plot.
</p>

<hr>
<h2 id='Network.formality'>Network Formality</h2><span id='topic+Network.formality'></span>

<h3>Description</h3>

<p><code>Network.formality</code> - Network a <code><a href="#topic+formality">formality</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality'
Network(
  x,
  contextual = "yellow",
  formal = "red",
  edge.constant,
  title = NULL,
  digits = 3,
  plus.300.color = "grey40",
  under.300.color = "grey88",
  missing.color = "purple",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Network.formality_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+formality">formality</a></code> object.</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_contextual">contextual</code></td>
<td>
<p>The color to use for 0% formality (purely contextual).</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_formal">formal</code></td>
<td>
<p>The color to use for 100% formality (purely formal).</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple edge width by.</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_title">title</code></td>
<td>
<p>The title to apply to the <code>Network</code>ed image(s).</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_digits">digits</code></td>
<td>
<p>The number of digits to use in the current turn of talk 
formality.</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_plus.300.color">plus.300.color</code></td>
<td>
<p>The bar color to use for grouping variables exceeding 
299 words per Heylighen &amp; Dewaele's (2002) minimum word recommendations.</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_under.300.color">under.300.color</code></td>
<td>
<p>The bar color to use for grouping variables less 
than 300 words per Heylighen &amp; Dewaele's (2002) minimum word recommendations.</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_missing.color">missing.color</code></td>
<td>
<p>The color to use in a network plot for edges 
corresponding to missing text data.  Use <code><a href="stats.html#topic+na.omit">na.omit</a></code> before 
hand to remove the missing values all together.</p>
</td></tr>
<tr><td><code id="Network.formality_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+discourse_map">discourse_map</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>formality Method for Network
</p>

<hr>
<h2 id='Network.lexical_classification'>Network Lexical Classification</h2><span id='topic+Network.lexical_classification'></span>

<h3>Description</h3>

<p><code>Network.lexical_classification</code> - Network a 
<code><a href="#topic+lexical_classification">lexical_classification</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification'
Network(
  x,
  functional = "yellow",
  content = "red",
  edge.constant,
  title = NULL,
  digits = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Network.lexical_classification_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+lexical_classification">lexical_classification</a></code> object.</p>
</td></tr>
<tr><td><code id="Network.lexical_classification_+3A_functional">functional</code></td>
<td>
<p>The color to use for 0% lexical_classification (purely 
functional).</p>
</td></tr>
<tr><td><code id="Network.lexical_classification_+3A_content">content</code></td>
<td>
<p>The color to use for 100% lexical_classification (purely 
content).</p>
</td></tr>
<tr><td><code id="Network.lexical_classification_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple edge width by.</p>
</td></tr>
<tr><td><code id="Network.lexical_classification_+3A_title">title</code></td>
<td>
<p>The title to apply to the Networked image(s).</p>
</td></tr>
<tr><td><code id="Network.lexical_classification_+3A_digits">digits</code></td>
<td>
<p>The number of digits to use in the current turn of talk 
lexical_classification.</p>
</td></tr>
<tr><td><code id="Network.lexical_classification_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+discourse_map">discourse_map</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>lexical_classification Method for Network
</p>

<hr>
<h2 id='Network.polarity'>Network Polarity</h2><span id='topic+Network.polarity'></span>

<h3>Description</h3>

<p><code>Network.polarity</code> - Network a <code><a href="#topic+polarity">polarity</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity'
Network(
  x,
  negative = "blue",
  positive = "red",
  neutral = "yellow",
  edge.constant,
  title = NULL,
  digits = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Network.polarity_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+polarity">polarity</a></code> object.</p>
</td></tr>
<tr><td><code id="Network.polarity_+3A_negative">negative</code></td>
<td>
<p>The color to use for negative polarity.</p>
</td></tr>
<tr><td><code id="Network.polarity_+3A_positive">positive</code></td>
<td>
<p>The color to use for positive polarity.</p>
</td></tr>
<tr><td><code id="Network.polarity_+3A_neutral">neutral</code></td>
<td>
<p>The color to use for neutral polarity.</p>
</td></tr>
<tr><td><code id="Network.polarity_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple edge width by.</p>
</td></tr>
<tr><td><code id="Network.polarity_+3A_title">title</code></td>
<td>
<p>The title to apply to the Networked image(s).</p>
</td></tr>
<tr><td><code id="Network.polarity_+3A_digits">digits</code></td>
<td>
<p>The number of digits to use in the current turn of talk 
polarity.</p>
</td></tr>
<tr><td><code id="Network.polarity_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+discourse_map">discourse_map</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>polarity Method for Network
</p>

<hr>
<h2 id='new_project'>Project Template</h2><span id='topic+new_project'></span>

<h3>Description</h3>

<p>Generate a project template to increase efficiency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>new_project(project = "new", path = getwd(), open = is.global(2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="new_project_+3A_project">project</code></td>
<td>
<p>A character vector of the project name.</p>
</td></tr>
<tr><td><code id="new_project_+3A_path">path</code></td>
<td>
<p>The path to where the project should be created.  Default is the 
current working directory.</p>
</td></tr>
<tr><td><code id="new_project_+3A_open">open</code></td>
<td>
<p>logical.  If <code>TRUE</code> the project will be opened in RStudio.
The default is to test if <code>new_project</code> is being used in the global 
environment, if it is then the project directory will be opened.</p>
</td></tr>
<tr><td><code id="new_project_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The project template includes these main directories and scripts:
</p>

<ul>
<li><p>CODEBOOK - A directory to store coding conventions or demographics data:
</p>

<ul>
<li><p>KEY.csv - A blank template for demographic information
</p>
</li></ul>
  

</li>
<li><p>CORRESPONDENCE - A directory to store correspondence and agreements with the client:
</p>

<ul>
<li><p>CONTACT_INFO.txt - A text file to put research team members' contact information     
</p>
</li></ul>
 

</li>
<li><p>DATA - A directory to store data:
</p>

<ul>
<li><p>CLEANED_TRANSCRIPTS - A directory to store the cleaned transcripts (If the transcripts are already cleaned you may choose to not utilize the RAW_TRANSCRIPTS directory)     
</p>
</li>
<li><p>CM_DATA - A directory to export/import scripts for cm_xxx family of functions 
</p>
</li>
<li><p>DATA_FOR_REVIEW - A directory to put data that may need to be altered or needs to be inspected more closely 
</p>
</li>
<li><p>RAW_DATA - A directory to store non-transcript data related to the project:
</p>

<ul>
<li><p>ANALYTIC_MEMOS - A directory to put audio files (or shortcuts)     
</p>
</li>
<li><p>AUDIO - A directory to put audio files (or shortcuts)     
</p>
</li>
<li><p>FIELD_NOTES - A directory to put audio files (or shortcuts)   
</p>
</li>
<li><p>PAPER_ARTIFACTS - A directory to put paper artifacts  
</p>
</li>
<li><p>PHOTOGRAPHS - A directory to put photographs  
</p>
</li>
<li><p>VIDEO - A directory to put video files (or shortcuts)  
</p>
</li></ul>
 
 
</li>
<li><p>TRANSCRIPTS - A directory to put transcription data:
</p>

<ul>
<li><p>CLEANED_TRANSCRIPTS - A directory to store the cleaned transcripts (If the transcripts are already cleaned you may choose to not utilize the RAW_TRANSCRIPTS directory)     
</p>
</li>
<li><p>RAW_TRANSCRIPTS - A directory to store the raw transcripts
</p>
</li></ul>
 
 
</li></ul>

</li>
<li><p>DOCUMENTATION - A directory to store documents related to the project
</p>
</li>
<li><p>PLOTS - A directory to store plots
</p>
</li>
<li><p>REPORTS - A directory with report and presentation related tools.
</p>
</li>
<li><p>SCRIPTS - A directory to store scripts; already contains the following:
</p>

<ul>
<li><p>01_clean_data.R - initial cleaning of raw transcripts
</p>
</li>
<li><p>02_analysis_I.R - initial analysis
</p>
</li>
<li><p>03_plots.R - plotting script
</p>
</li></ul>


</li>
<li><p>TABLES - A directory to export tables to  
</p>
</li>
<li><p>WORD_LISTS - A directory to store word lists that can be sourced and supplied to functions
</p>
</li>
<li><p>extra_functions.R - A script to store user made functions related to the project
</p>

<ul>
<li><p>email - A function to view, and optionally copy to the clipboard, emails for the client/lead researcher, analyst and/or other project members (information taking from ~/CORRESPONDENCE/CONTACT_INFO.txt file)
</p>
</li>
<li><p>todo - A function to view, and optionally copy to the clipboard, non-completed tasks from the <code>TO_DO.txt</code> file
</p>
</li></ul>


</li>
<li><p>LOG - A text file documenting project changes/needs etc.
</p>
</li>
<li><p>PROJECT_WORKFLOW_GUIDE.pdf - A pdf explaining the structure of the project template
</p>
</li>
<li><p>xxx.Rproj - A project file used by RRtudio; clicking this will open the project in RStudio. 
</p>
</li>
<li><p>TO_DO - A text file documenting project tasks
</p>
</li></ul>

<p>The template comes with a .Rproj file.  This makes operating in 
RStudio very easy.  The file can be kept on 
the desktop or a git application such as github,
bitbucket or dropbox, 
depending on what the client/research team is comfortable utilizing.
</p>


<h3>Value</h3>

<p>Creates a project template.
</p>

<hr>
<h2 id='ngrams'>Generate ngrams</h2><span id='topic+ngrams'></span>

<h3>Description</h3>

<p>Transcript apply ngrams.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ngrams(text.var, grouping.var = NULL, n = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ngrams_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="ngrams_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="ngrams_+3A_n">n</code></td>
<td>
<p>The max number of grams calculate</p>
</td></tr>
<tr><td><code id="ngrams_+3A_...">...</code></td>
<td>
<p>Further arguments passed to strip function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of:
</p>
<table>
<tr><td><code>raw</code></td>
<td>
<p>A list of pasted single vectors of the ngrams per row.</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>A list of pasted vectors of ngrams grouped by grouping.var.</p>
</td></tr>
<tr><td><code>unlist1</code></td>
<td>
<p>A list of a single vector of pasted ngrams per grouping.var in the order used.</p>
</td></tr> 
<tr><td><code>unlist2</code></td>
<td>
<p>A list of a single vector of pasted ngrams per grouping.var in alphabetical order.</p>
</td></tr>
<tr><td><code>group_n</code></td>
<td>
<p>A list of a list of vectors of ngrams per grouping.var &amp; n (not pasted).</p>
</td></tr>
<tr><td><code>all</code></td>
<td>
<p>A single vector of pasted ngrams sorted alphabetically.</p>
</td></tr>
<tr><td><code>all_n</code></td>
<td>
<p>A list of lists a single vectors of ngrams sorted alphabetically (not pasted).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ngrams(DATA$state, DATA$person, 2)
ngrams(DATA$state, DATA$person, 3)
ngrams(DATA$state, , 3)
with(mraja1, ngrams(dialogue, list(sex, fam.aff), 3))

## Alternative ngram analysis:
n_gram &lt;- function(x, n = 2, sep = " "){

    m &lt;- qdap::bag_o_words(x)
    if (length(m) &lt; n) return(character(0))
    starts &lt;- 1:(length(m) - (n - 1))
    ends &lt;- n:length(m) 
    Map(function(x, y){
            paste(m[x:y], collapse=sep)
        }, starts, ends
    )
}

dat &lt;- sentSplit(DATA, "state")

dat[["grams"]] &lt;- sapply(dat[["state"]], function(x) { 
    unbag(n_gram(x, sep = "~~"))
})

m &lt;- with(dat, as.tdm(grams, person))
rownames(m) &lt;- gsub("~~", " ", rownames(m))
as.matrix(m)
rowSums(as.matrix(m))



dat2 &lt;- sentSplit(raj, "dialogue")

dat2[["grams"]] &lt;- sapply(dat2[["dialogue"]], function(x) { 
    unbag(n_gram(x, sep = "~~"))
})

m2 &lt;- with(dat2, as.tdm(grams, person))
rownames(m2) &lt;- gsub("~~", " ", rownames(m2))
qheat(t(as.matrix(tm:::weightTfIdf(tm::removeSparseTerms(m2, .7)))), high="red")

sort(rowSums(as.matrix(m2)))

## End(Not run)
</code></pre>

<hr>
<h2 id='object_pronoun_type'>Count Object Pronouns Per Grouping Variable</h2><span id='topic+object_pronoun_type'></span>

<h3>Description</h3>

<p>Count the number of object pronouns per grouping variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>object_pronoun_type(
  text.var,
  grouping.var = NULL,
  object.pronoun.list = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="object_pronoun_type_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="object_pronoun_type_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="object_pronoun_type_+3A_object.pronoun.list">object.pronoun.list</code></td>
<td>
<p>A named list of object pronouns.  See 
<strong>Details</strong> for more.</p>
</td></tr>
<tr><td><code id="object_pronoun_type_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+termco">termco</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following object pronoun categories are the default searched terms:
</p>

<ul>
<li><p> me = c(&quot; me &quot;, &quot; my &quot;, &quot; mine &quot;)
</p>
</li>
<li><p> us = c(&quot; us &quot;, &quot; our &quot;, &quot; ours &quot;)
</p>
</li>
<li><p> you = c(&quot; you'd &quot;,  &quot; you'll &quot;, &quot; you're &quot;, &quot; you've &quot;, &quot; you &quot;, &quot; your &quot;)
</p>
</li>
<li><p> him = c(&quot; him &quot;, &quot; his &quot;)
</p>
</li>
<li><p> her = c(&quot; her &quot;, &quot; hers &quot;)
</p>
</li>
<li><p> them = c(&quot; them &quot;)
</p>
</li>
<li><p> their = c(&quot; their &quot;, &quot;theirs &quot;)
</p>
</li>
<li><p> it = c(&quot; it'd &quot;, &quot; it'll &quot;, &quot; it's &quot;, &quot; it &quot;)
</p>
</li></ul>



<h3>Value</h3>

<p>Returns a list, of class &quot;object_pronoun_type&quot;, of data frames 
regarding object pronoun word counts:
</p>
<table>
<tr><td><code>preprocessed</code></td>
<td>
<p>List of uncollapsed dataframes (raw, prop, rnp) of the class &quot;termco&quot; that contain all searchable object pronouns.</p>
</td></tr> 
<tr><td><code>raw</code></td>
<td>
<p>raw word counts by grouping variable</p>
</td></tr> 
<tr><td><code>prop</code></td>
<td>
<p>proportional word counts by grouping variable; proportional to 
each individual's object pronoun use</p>
</td></tr> 
<tr><td><code>rnp</code></td>
<td>
<p>a character combination data frame of raw and proportional object pronoun use</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+subject_pronoun_type">subject_pronoun_type</a></code>,
<code><a href="#topic+pronoun_type">pronoun_type</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- pres_debates2012
dat &lt;- dat[dat$person %in% qcv(ROMNEY, OBAMA), ]
(out &lt;- object_pronoun_type(dat$dialogue, dat$person))
plot(out)
plot(out, 2)
plot(out, 3)
plot(out, 3, ncol=2)

scores(out)
counts(out)
proportions(out)
preprocessed(out)

plot(scores(out))
plot(counts(out))
plot(proportions(out))

## End(Not run)
</code></pre>

<hr>
<h2 id='outlier_detect'>Detect Outliers in Text</h2><span id='topic+outlier_detect'></span>

<h3>Description</h3>

<p>Locate possible outliers for text variables given numeric word function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outlier_detect(
  text.var,
  grouping.var = NULL,
  FUN = word_count,
  scale.by = "grouping"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outlier_detect_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="outlier_detect_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="outlier_detect_+3A_fun">FUN</code></td>
<td>
<p>A word function with a numeric vector output (e.g., 
<code>syllable_sum</code>, <code>character_count</code> or <code>word_count</code>).</p>
</td></tr>
<tr><td><code id="outlier_detect_+3A_scale.by">scale.by</code></td>
<td>
<p>A character string indicating which dimensions to scale by. 
One of <code>"all"</code>, <code>"grouping"</code>, or <code>"both"</code>.  Default NULL scales 
by all.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with possible outliers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(DATA, outlier_detect(state))
with(DATA, outlier_detect(state, FUN = character_count))
with(DATA, outlier_detect(state, person, FUN = character_count))
with(DATA, outlier_detect(state, list(sex, adult), FUN = character_count))
with(DATA, outlier_detect(state, FUN = syllable_sum))
htruncdf(with(raj, outlier_detect(dialogue, person)), 15, 45)

## End(Not run)   
</code></pre>

<hr>
<h2 id='outlier_labeler'>Locate Outliers in Numeric String</h2><span id='topic+outlier_labeler'></span>

<h3>Description</h3>

<p>Locate and label possible outliers in a string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outlier_labeler(x, standardize = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outlier_labeler_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="outlier_labeler_+3A_standardize">standardize</code></td>
<td>
<p>logical.  If <code>TRUE</code> scales the vector first.</p>
</td></tr>
<tr><td><code id="outlier_labeler_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="base.html#topic+scale">scale</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix (one column) of possible outliers coded as 
<code>"3sd"</code>, <code>"2sd"</code> and <code>"1.5sd"</code>, corresponding to &gt;= to 3, 2, 
or 1.5 standard deviations.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+scale">scale</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
outlier_labeler(mtcars$hp)[20:32]
by(mtcars$mpg, mtcars$cyl, outlier_labeler)
tapply(mtcars$mpg, mtcars$cyl, outlier_labeler)

## End(Not run)
</code></pre>

<hr>
<h2 id='paste2'>Paste an Unspecified Number Of Text Columns</h2><span id='topic+paste2'></span><span id='topic+colpaste2df'></span>

<h3>Description</h3>

<p><code>paste2</code> - Paste unspecified columns or a list of vectors together.
</p>
<p><code>colpaste2df</code> - Wrapper for <code><a href="#topic+paste2">paste2</a></code> that returns a 
dataframe with columns pasted together.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paste2(multi.columns, sep = ".", handle.na = TRUE, trim = TRUE)

colpaste2df(
  mat,
  combined.columns,
  sep = ".",
  name.sep = "&amp;",
  keep.orig = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paste2_+3A_multi.columns">multi.columns</code></td>
<td>
<p>The multiple columns or a list of vectors to paste 
together.</p>
</td></tr>
<tr><td><code id="paste2_+3A_sep">sep</code></td>
<td>
<p>The character to be used in <code>paste2</code> to paste the columns.</p>
</td></tr>
<tr><td><code id="paste2_+3A_handle.na">handle.na</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns <code>NA</code> if any 
column/vector contains a missing value.</p>
</td></tr>
<tr><td><code id="paste2_+3A_trim">trim</code></td>
<td>
<p>logical.  If <code>TRUE</code> leading/trailing white space is removed.</p>
</td></tr>
<tr><td><code id="paste2_+3A_mat">mat</code></td>
<td>
<p>A matrix or dataframe.</p>
</td></tr>
<tr><td><code id="paste2_+3A_combined.columns">combined.columns</code></td>
<td>
<p>A list of named vectors of the colnames/indexes 
of the numeric columns to be pasted.  If a vector is unnamed a 
name will be assigned.</p>
</td></tr>
<tr><td><code id="paste2_+3A_name.sep">name.sep</code></td>
<td>
<p>The character to be used to paste the column names.</p>
</td></tr>
<tr><td><code id="paste2_+3A_keep.orig">keep.orig</code></td>
<td>
<p>logical.  If <code>TRUE</code> the original columns 
(i.e., <code>combined.columns</code>) will be retained as well.</p>
</td></tr>
<tr><td><code id="paste2_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+paste2">paste2</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>paste2</code> - Returns a vector with row-wise elements pasted together.
</p>
<p><code>colpaste2df</code> - Returns a dataframe with pasted columns.
</p>


<h3>Note</h3>

<p><code><a href="base.html#topic+paste">paste</a></code> differs from <code><a href="#topic+paste2">paste2</a></code> 
because <code>paste</code> does not allowed an unspecified number of columns to be 
pasted.  This behavior can be convenient for inside of functions when the 
number of columns being pasted is unknown.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+paste">paste</a></code>,
<code><a href="#topic+colsplit2df">colsplit2df</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## paste2 examples
v &lt;- rep(list(state.abb[1:8],  month.abb[1:8]) , 5)
n &lt;- sample(5:10, 1)
paste(v[1:n]) #odd looking return
paste2(v[1:n]) 
paste2(v[1:n], sep="|") 
paste2(mtcars[1:10,], sep="|") 
paste(mtcars[1:10,], sep="|") #odd looking return
paste2(CO2[1:10,], sep="|-|") 

## colpaste2df examples
A &lt;- list(
    a = c(1, 2, 3),
    b = qcv(mpg, hp),
    c = c("disp", "am")
)
B &lt;- list(
    c(1, 2, 3),
    new.col = qcv(mpg, hp),
    c("disp", "am")
)
E &lt;- list(
    c(1, 2, 3, 4, 5),
    qcv(mpg, hp),
    c("disp", "am")
)

colpaste2df(head(mtcars), A)
colpaste2df(head(mtcars), B)
colpaste2df(head(mtcars), E)
colpaste2df(head(mtcars), qcv(am, disp, drat), sep ="_", name.sep = "|")
colpaste2df(head(CO2), list(c(1, 2, 3, 4, 5), qcv("conc", "uptake")))

## End(Not run)
</code></pre>

<hr>
<h2 id='phrase_net'>Phrase Nets</h2><span id='topic+phrase_net'></span>

<h3>Description</h3>

<p>Create Many Eyes style phrase nets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phrase_net(
  text.var,
  freq = 4,
  r = 0.35,
  edge.constant = 6,
  vertex.constant = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="phrase_net_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="phrase_net_+3A_freq">freq</code></td>
<td>
<p>The minimum word frequency occurrence.</p>
</td></tr>
<tr><td><code id="phrase_net_+3A_r">r</code></td>
<td>
<p>The minimum correlation value</p>
</td></tr>
<tr><td><code id="phrase_net_+3A_edge.constant">edge.constant</code></td>
<td>
<p>A constant to multiple the edges by.</p>
</td></tr>
<tr><td><code id="phrase_net_+3A_vertex.constant">vertex.constant</code></td>
<td>
<p>A constant to multiple the vertex label sizes by.</p>
</td></tr>
<tr><td><code id="phrase_net_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+Filter">Filter</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an igraph object.
</p>


<h3>Note</h3>

<p>While Many Eyes
phrase nets inspired this function the two outputs are not identical.  The
<code><a href="#topic+phrase_net">phrase_net</a></code> function operates off of correlations between 
words in sentences.
</p>


<h3>References</h3>

<p>http://trinker.github.io/many-eye/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- "Questions must be at least 2 days old to be eligible for a bounty.
    There can only be 1 active bounty per question at any given time.
    Users must have at least 75 reputation to offer a bounty, and may
    only have a maximum of 3 active bounties at any given time. The
    bounty period lasts 7 days. Bounties must have a minimum duration of
    at least 1 day. After the bounty ends, there is a grace period of 24
    hours to manually award the bounty. If you do not award your bounty
    within 7 days (plus the grace period), the highest voted answer
    created after the bounty started with at least 2 upvotes will be
    awarded half the bounty amount. If there's no answer meeting that
    criteria, the bounty is not awarded to anyone. If the bounty was
    started by the question owner, and the question owner accepts an
    answer during the bounty period, and the bounty expires without an
    explicit award - we assume the bounty owner liked the answer they
    accepted and award it the full bounty amount at the time of bounty
    expiration. In any case, you will always give up the amount of
    reputation specified in the bounty, so if you start a bounty, be sure
    to follow up and award your bounty to the best answer! As an
    additional bonus, bounty awards are immune to the daily reputation
    cap and community wiki mode."

phrase_net(sent_detect(x), r=.5)
library(igraph)
plot(phrase_net(sent_detect(x), r=.5), edge.curved = FALSE)

## Declaration of Independence Example
y &lt;- readLines("http://www.constitution.org/usdeclar.txt")
y &lt;- paste(y[grep("When, in the", y):length(y)], collapse=" ")
phrase_net(sent_detect(y), r=.7)


## Multiple grouping variables
z &lt;- lapply(split(raj.act.1$dialogue, raj.act.1$person), paste, collapse = " ")
par(mfrow=c(2, 5), mai = c(.05, 0.15, 0.15, 0.15))
lapply(seq_along(z), function(i) {
    x &lt;- try(phrase_net(sent_detect(z[i]), r=.6))
    if (!inherits(x, "try-error")) {
        print(x)
        box()
        mtext(names(z)[i])
    }
}) 


lapply(seq_along(z), function(i) {
    x &lt;- try(phrase_net(sent_detect(z[i]), r=.6))
    if (!inherits(x, "try-error")) {
        dev.new()
        print(x)
        mtext(names(z)[i], padj=-1, cex=1.7, col="red")
    }
}) 

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.animated_character'>Plots an animated_character  Object</h2><span id='topic+plot.animated_character'></span>

<h3>Description</h3>

<p>Plots an animated_character  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_character'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.animated_character_+3A_x">x</code></td>
<td>
<p>The animated_character  object.</p>
</td></tr>
<tr><td><code id="plot.animated_character_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>print.animated_character</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.animated_discourse_map'>Plots an animated_discourse_map  Object</h2><span id='topic+plot.animated_discourse_map'></span>

<h3>Description</h3>

<p>Plots an animated_discourse_map  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_discourse_map'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.animated_discourse_map_+3A_x">x</code></td>
<td>
<p>The animated_discourse_map  object.</p>
</td></tr>
<tr><td><code id="plot.animated_discourse_map_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>print.animated_discourse_map </code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.animated_formality'>Plots a animated_formality  Object</h2><span id='topic+plot.animated_formality'></span>

<h3>Description</h3>

<p>Plots a animated_formality  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_formality'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.animated_formality_+3A_x">x</code></td>
<td>
<p>The animated_formality  object.</p>
</td></tr>
<tr><td><code id="plot.animated_formality_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>print.animated_formality </code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.animated_lexical_classification'>Plots an animated_lexical_classification  Object</h2><span id='topic+plot.animated_lexical_classification'></span>

<h3>Description</h3>

<p>Plots an animated_lexical_classification  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_lexical_classification'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.animated_lexical_classification_+3A_x">x</code></td>
<td>
<p>The animated_lexical_classification  object.</p>
</td></tr>
<tr><td><code id="plot.animated_lexical_classification_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>print.animated_lexical_classification </code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.animated_polarity'>Plots an animated_polarity  Object</h2><span id='topic+plot.animated_polarity'></span>

<h3>Description</h3>

<p>Plots an animated_polarity  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_polarity'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.animated_polarity_+3A_x">x</code></td>
<td>
<p>The animated_polarity  object.</p>
</td></tr>
<tr><td><code id="plot.animated_polarity_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>print.animated_polarity </code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.automated_readability_index'>Plots a automated_readability_index Object</h2><span id='topic+plot.automated_readability_index'></span>

<h3>Description</h3>

<p>Plots a automated_readability_index object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'automated_readability_index'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.automated_readability_index_+3A_x">x</code></td>
<td>
<p>The readability_score object.</p>
</td></tr>
<tr><td><code id="plot.automated_readability_index_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.character_table'>Plots a character_table Object</h2><span id='topic+plot.character_table'></span>

<h3>Description</h3>

<p>Plots a character_table  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'character_table'
plot(
  x,
  label = FALSE,
  lab.digits = 1,
  percent = NULL,
  zero.replace = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.character_table_+3A_x">x</code></td>
<td>
<p>The character_table  object</p>
</td></tr>
<tr><td><code id="plot.character_table_+3A_label">label</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cells of the heat map plot will be 
labeled with count and proportional values.</p>
</td></tr>
<tr><td><code id="plot.character_table_+3A_lab.digits">lab.digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed if <code>label</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.character_table_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.  If <code>NULL</code> uses the value from 
<code><a href="#topic+question_type">question_type</a></code>.  Only used if <code>label</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.character_table_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If <code>NULL</code> uses the 
value from <code><a href="#topic+question_type">question_type</a></code>.  Only used if <code>label</code> is 
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.character_table_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='plot.cm_distance'>Plots a cm_distance object</h2><span id='topic+plot.cm_distance'></span>

<h3>Description</h3>

<p>Plots a cm_distance object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cm_distance'
plot(
  x,
  digits = 3,
  constant = 1,
  label.dist = FALSE,
  layout = igraph::layout.fruchterman.reingold,
  label.cex = 1,
  label.cex.scale.by.n = FALSE,
  alpha = NULL,
  label.color = "black",
  use.vertex.shape = FALSE,
  arrow.size = 0.6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cm_distance_+3A_x">x</code></td>
<td>
<p>A cm_distance object.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_digits">digits</code></td>
<td>
<p>The number of digits to use if distance labels are included on 
the edges.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_constant">constant</code></td>
<td>
<p>A constant to weight the edges by.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_label.dist">label.dist</code></td>
<td>
<p>logical.  If <code>TRUE</code> distance measures are placed on 
the edges.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_layout">layout</code></td>
<td>
<p>A layout; see <code><a href="igraph.html#topic+layout">layout</a></code>.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_label.cex">label.cex</code></td>
<td>
<p>A constant to use for the label size.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_label.cex.scale.by.n">label.cex.scale.by.n</code></td>
<td>
<p>logical.  If <code>TRUE</code> the label size is scaled 
by the number of uses of the code.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_alpha">alpha</code></td>
<td>
<p>The cut off value for pvalue inclusion of edges.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_label.color">label.color</code></td>
<td>
<p>Color of the vertex labels.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_use.vertex.shape">use.vertex.shape</code></td>
<td>
<p>logical.  If <code>TRUE</code> the vertex label if plotted 
on a circle.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_arrow.size">arrow.size</code></td>
<td>
<p>The size of the arrows. Currently this is a constant, so it 
is the same for every edge.</p>
</td></tr>
<tr><td><code id="plot.cm_distance_+3A_...">...</code></td>
<td>
<p>Further arguments passed to the chosen <code>layout</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the <span class="pkg">igraph</span> object.
</p>


<h3>Note</h3>

<p>This plotting method is not particularly well developed. It is 
suggested that the user further develop the graph via direct use of the 
<span class="pkg">igraph</span> package.
</p>

<hr>
<h2 id='plot.cmspans'>Plots a cmspans object</h2><span id='topic+plot.cmspans'></span>

<h3>Description</h3>

<p>Plots a cmspans object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cmspans'
plot(x, plot.var = NULL, facet.vars = NULL, title = "Gantt Plot", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cmspans_+3A_x">x</code></td>
<td>
<p>The sums_cmspans object</p>
</td></tr>
<tr><td><code id="plot.cmspans_+3A_plot.var">plot.var</code></td>
<td>
<p>A factor plotting variable (y axis).</p>
</td></tr>
<tr><td><code id="plot.cmspans_+3A_facet.vars">facet.vars</code></td>
<td>
<p>An optional single vector or list of 1 or 2 to facet by.</p>
</td></tr>
<tr><td><code id="plot.cmspans_+3A_title">title</code></td>
<td>
<p>An optional title.</p>
</td></tr>
<tr><td><code id="plot.cmspans_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>gantt_wrap</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.coleman_liau'>Plots a coleman_liau Object</h2><span id='topic+plot.coleman_liau'></span>

<h3>Description</h3>

<p>Plots a coleman_liau object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coleman_liau'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.coleman_liau_+3A_x">x</code></td>
<td>
<p>The readability_score object.</p>
</td></tr>
<tr><td><code id="plot.coleman_liau_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.combo_syllable_sum'>Plots a combo_syllable_sum Object</h2><span id='topic+plot.combo_syllable_sum'></span>

<h3>Description</h3>

<p>Plots a combo_syllable_sum object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'combo_syllable_sum'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.combo_syllable_sum_+3A_x">x</code></td>
<td>
<p>The combo_syllable_sum object.</p>
</td></tr>
<tr><td><code id="plot.combo_syllable_sum_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_animated_formality'>Plots a cumulative_animated_formality Object</h2><span id='topic+plot.cumulative_animated_formality'></span>

<h3>Description</h3>

<p>Plots a cumulative_animated_formality object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_animated_formality'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_animated_formality_+3A_x">x</code></td>
<td>
<p>The cumulative_animated_formality object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_animated_formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_animated_lexical_classification'>Plots a cumulative_animated_lexical_classification Object</h2><span id='topic+plot.cumulative_animated_lexical_classification'></span>

<h3>Description</h3>

<p>Plots a cumulative_animated_lexical_classification object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_animated_lexical_classification'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_animated_lexical_classification_+3A_x">x</code></td>
<td>
<p>The cumulative_animated_lexical_classification object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_animated_lexical_classification_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_animated_polarity'>Plots a cumulative_animated_polarity Object</h2><span id='topic+plot.cumulative_animated_polarity'></span>

<h3>Description</h3>

<p>Plots a cumulative_animated_polarity object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_animated_polarity'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_animated_polarity_+3A_x">x</code></td>
<td>
<p>The cumulative_animated_polarity object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_animated_polarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_combo_syllable_sum'>Plots a cumulative_combo_syllable_sum Object</h2><span id='topic+plot.cumulative_combo_syllable_sum'></span>

<h3>Description</h3>

<p>Plots a cumulative_combo_syllable_sum object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_combo_syllable_sum'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_combo_syllable_sum_+3A_x">x</code></td>
<td>
<p>The cumulative_combo_syllable_sum object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_combo_syllable_sum_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_end_mark'>Plots a cumulative_end_mark Object</h2><span id='topic+plot.cumulative_end_mark'></span>

<h3>Description</h3>

<p>Plots a cumulative_end_mark object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_end_mark'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_end_mark_+3A_x">x</code></td>
<td>
<p>The cumulative_end_mark object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_end_mark_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_formality'>Plots a cumulative_formality Object</h2><span id='topic+plot.cumulative_formality'></span>

<h3>Description</h3>

<p>Plots a cumulative_formality object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_formality'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_formality_+3A_x">x</code></td>
<td>
<p>The cumulative_formality object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_lexical_classification'>Plots a cumulative_lexical_classification Object</h2><span id='topic+plot.cumulative_lexical_classification'></span>

<h3>Description</h3>

<p>Plots a cumulative_lexical_classification object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_lexical_classification'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_lexical_classification_+3A_x">x</code></td>
<td>
<p>The cumulative_lexical_classification object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_lexical_classification_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_polarity'>Plots a cumulative_polarity Object</h2><span id='topic+plot.cumulative_polarity'></span>

<h3>Description</h3>

<p>Plots a cumulative_polarity object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_polarity'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_polarity_+3A_x">x</code></td>
<td>
<p>The cumulative_polarity object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_polarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.cumulative_syllable_freq'>Plots a cumulative_syllable_freq Object</h2><span id='topic+plot.cumulative_syllable_freq'></span>

<h3>Description</h3>

<p>Plots a cumulative_syllable_freq object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_syllable_freq'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cumulative_syllable_freq_+3A_x">x</code></td>
<td>
<p>The cumulative_syllable_freq object.</p>
</td></tr>
<tr><td><code id="plot.cumulative_syllable_freq_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.discourse_map'>Plots a discourse_map Object</h2><span id='topic+plot.discourse_map'></span>

<h3>Description</h3>

<p>Plots a discourse_map object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'discourse_map'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.discourse_map_+3A_x">x</code></td>
<td>
<p>The discourse_map object.</p>
</td></tr>
<tr><td><code id="plot.discourse_map_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>print.discourse_map</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.diversity'>Plots a diversity object</h2><span id='topic+plot.diversity'></span>

<h3>Description</h3>

<p>Plots a diversity object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'diversity'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.diversity_+3A_x">x</code></td>
<td>
<p>The diversity object</p>
</td></tr>
<tr><td><code id="plot.diversity_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>qheat</code></p>
</td></tr>
</table>

<hr>
<h2 id='plot.end_mark'>Plots an end_mark Object</h2><span id='topic+plot.end_mark'></span>

<h3>Description</h3>

<p>Plots an end_mark object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.end_mark_+3A_x">x</code></td>
<td>
<p>The end_mark object.</p>
</td></tr>
<tr><td><code id="plot.end_mark_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.end_mark_by'>Plots a end_mark_by Object</h2><span id='topic+plot.end_mark_by'></span>

<h3>Description</h3>

<p>Plots a end_mark_by object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by'
plot(x, values = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.end_mark_by_+3A_x">x</code></td>
<td>
<p>The end_mark_by object.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.end_mark_by_count'>Plots a end_mark_by_count Object</h2><span id='topic+plot.end_mark_by_count'></span>

<h3>Description</h3>

<p>Plots a end_mark_by_count object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by_count'
plot(x, values = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.end_mark_by_count_+3A_x">x</code></td>
<td>
<p>The end_mark_by_count object.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_count_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_count_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+qheat">qheat</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.end_mark_by_preprocessed'>Plots a end_mark_by_preprocessed Object</h2><span id='topic+plot.end_mark_by_preprocessed'></span>

<h3>Description</h3>

<p>Plots a end_mark_by_preprocessed object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by_preprocessed'
plot(x, ncol = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.end_mark_by_preprocessed_+3A_x">x</code></td>
<td>
<p>The end_mark_by_preprocessed object.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_preprocessed_+3A_ncol">ncol</code></td>
<td>
<p>The number of columns to use for <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_preprocessed_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.end_mark_by_proportion'>Plots a end_mark_by_proportion Object</h2><span id='topic+plot.end_mark_by_proportion'></span>

<h3>Description</h3>

<p>Plots a end_mark_by_proportion object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by_proportion'
plot(x, values = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.end_mark_by_proportion_+3A_x">x</code></td>
<td>
<p>The end_mark_by_proportion object.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_proportion_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_proportion_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+qheat">qheat</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.end_mark_by_score'>Plots a end_mark_by_score Object</h2><span id='topic+plot.end_mark_by_score'></span>

<h3>Description</h3>

<p>Plots a end_mark_by_score object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by_score'
plot(x, values = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.end_mark_by_score_+3A_x">x</code></td>
<td>
<p>The end_mark_by_score object.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_score_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="plot.end_mark_by_score_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+qheat">qheat</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.flesch_kincaid'>Plots a flesch_kincaid Object</h2><span id='topic+plot.flesch_kincaid'></span>

<h3>Description</h3>

<p>Plots a flesch_kincaid object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flesch_kincaid'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.flesch_kincaid_+3A_x">x</code></td>
<td>
<p>The readability_score object.</p>
</td></tr>
<tr><td><code id="plot.flesch_kincaid_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.formality'>Plots a formality Object</h2><span id='topic+plot.formality'></span>

<h3>Description</h3>

<p>Plots a formality object including the parts of speech used to 
calculate contextual/formal speech.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality'
plot(
  x,
  point.pch = 20,
  point.cex = 0.5,
  point.colors = c("gray65", "red"),
  bar.colors = NULL,
  short.names = TRUE,
  min.wrdcnt = NULL,
  order.by.formality = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.formality_+3A_x">x</code></td>
<td>
<p>The formality object.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_point.pch">point.pch</code></td>
<td>
<p>The plotting symbol.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_point.cex">point.cex</code></td>
<td>
<p>The plotting symbol size.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_point.colors">point.colors</code></td>
<td>
<p>A vector of colors (length of two) to plot word count and 
formality score.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_bar.colors">bar.colors</code></td>
<td>
<p>A palette of colors to supply to the bars in the 
visualization.  If two palettes are provided to the two bar plots 
respectively.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_short.names">short.names</code></td>
<td>
<p>logical.  If TRUE shortens the length of legend and label 
names for more compact plot width.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_min.wrdcnt">min.wrdcnt</code></td>
<td>
<p>A minimum word count threshold that must be achieved to be 
considered in the results.  Default includes all subgroups.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_order.by.formality">order.by.formality</code></td>
<td>
<p>logical.  If <code>TRUE</code> the group formality plot 
will be ordered by average formality score, otherwise alphabetical order is 
assumed.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="plot.formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the <code>ggplot2</code> objects that form the larger 
plot.
</p>

<hr>
<h2 id='plot.formality_scores'>Plots a formality_scores Object</h2><span id='topic+plot.formality_scores'></span>

<h3>Description</h3>

<p>Plots a formality_scores object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality_scores'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.formality_scores_+3A_x">x</code></td>
<td>
<p>The formality_scores object.</p>
</td></tr>
<tr><td><code id="plot.formality_scores_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.freq_terms'>Plots a freq_terms Object</h2><span id='topic+plot.freq_terms'></span>

<h3>Description</h3>

<p>Plots a freq_terms object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'freq_terms'
plot(x, plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.freq_terms_+3A_x">x</code></td>
<td>
<p>The freq_terms object.</p>
</td></tr>
<tr><td><code id="plot.freq_terms_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="plot.freq_terms_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.gantt'>Plots a gantt object</h2><span id='topic+plot.gantt'></span>

<h3>Description</h3>

<p>Plots a gantt object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gantt'
plot(x, base = FALSE, title = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gantt_+3A_x">x</code></td>
<td>
<p>The sums_gantt object</p>
</td></tr>
<tr><td><code id="plot.gantt_+3A_base">base</code></td>
<td>
<p>logical.  If <code>TRUE</code> prints in base graphics system.
If <code>FALSE</code> prints in ggplot graphics system.</p>
</td></tr>
<tr><td><code id="plot.gantt_+3A_title">title</code></td>
<td>
<p>An optional title.</p>
</td></tr>
<tr><td><code id="plot.gantt_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>gantt_wrap</code> or 
<code>plot_gantt_base</code></p>
</td></tr>
</table>

<hr>
<h2 id='plot.kullback_leibler'>Plots a kullback_leibler object</h2><span id='topic+plot.kullback_leibler'></span>

<h3>Description</h3>

<p>Plots a kullback_leibler object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kullback_leibler'
plot(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.kullback_leibler_+3A_x">x</code></td>
<td>
<p>The kullback_leibler object</p>
</td></tr>
<tr><td><code id="plot.kullback_leibler_+3A_digits">digits</code></td>
<td>
<p>Number of decimal places to print.</p>
</td></tr>
<tr><td><code id="plot.kullback_leibler_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>qheat</code></p>
</td></tr>
</table>

<hr>
<h2 id='plot.lexical'>Plots a lexical Object</h2><span id='topic+plot.lexical'></span>

<h3>Description</h3>

<p>Plots a lexical object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical'
plot(
  x,
  min.freq = 1,
  rot.per = 0,
  random.order = FALSE,
  title = TRUE,
  title.color = "blue",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lexical_+3A_x">x</code></td>
<td>
<p>The lexical object.</p>
</td></tr>
<tr><td><code id="plot.lexical_+3A_min.freq">min.freq</code></td>
<td>
<p>Words with frequency below <code>min.freq</code> will not be plotted.</p>
</td></tr>
<tr><td><code id="plot.lexical_+3A_rot.per">rot.per</code></td>
<td>
<p>Proportion words with 90 degree rotation.</p>
</td></tr>
<tr><td><code id="plot.lexical_+3A_random.order">random.order</code></td>
<td>
<p>logical.  If codeTRUE plot words in random order. If <code>FALSE</code>, they will be plotted in decreasing frequency.</p>
</td></tr>
<tr><td><code id="plot.lexical_+3A_title">title</code></td>
<td>
<p>The title of the plot.  Use <code>NULL</code> to eliminate.</p>
</td></tr>
<tr><td><code id="plot.lexical_+3A_title.color">title.color</code></td>
<td>
<p>The color of the title.</p>
</td></tr>
<tr><td><code id="plot.lexical_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="wordcloud.html#topic+wordcloud">wordcloud</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.lexical_classification'>Plots a lexical_classification Object</h2><span id='topic+plot.lexical_classification'></span>

<h3>Description</h3>

<p>Plots a lexical_classification object as a heat map Gantt plot with lexical_classification over 
time (measured in words) and lexical_classification scores per sentence.  In the dotplot 
plot the black dots are the average lexical_classification per grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification'
plot(
  x,
  bar.size = 5,
  low = "blue",
  mid = "grey99",
  high = "red",
  ave.lexical_classification.shape = "+",
  alpha = 1/4,
  shape = 19,
  point.size = 2.5,
  jitter = 0.1,
  nrow = NULL,
  na.rm = TRUE,
  order.by.lexical_classification = TRUE,
  plot = TRUE,
  error.bars = TRUE,
  error.bar.height = 0.5,
  error.bar.size = 0.5,
  error.bar.color = "black",
  error.bar.alpha = 0.6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lexical_classification_+3A_x">x</code></td>
<td>
<p>The lexical_classification object.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_bar.size">bar.size</code></td>
<td>
<p>The size of the bars used in the Gantt plot.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_low">low</code></td>
<td>
<p>The color to be used for lower values.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_mid">mid</code></td>
<td>
<p>The color to be used for mid-range values (default is a less 
striking color).</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_ave.lexical_classification.shape">ave.lexical_classification.shape</code></td>
<td>
<p>The shape of the average lexical_classification score used in the 
dot plot.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_alpha">alpha</code></td>
<td>
<p>Transparency level of points (ranges between 0 and 1).</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_shape">shape</code></td>
<td>
<p>The shape of the points used in the dot plot.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_point.size">point.size</code></td>
<td>
<p>The size of the points used in the dot plot.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_jitter">jitter</code></td>
<td>
<p>Amount of vertical jitter to add to the points.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_nrow">nrow</code></td>
<td>
<p>The number of rows in the dotplot legend (used when the number of 
grouping variables makes the legend too wide).  If <code>NULL</code> no legend if 
plotted.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_order.by.lexical_classification">order.by.lexical_classification</code></td>
<td>
<p>logical.  If <code>TRUE</code> the group lexical_classification plot 
will be ordered by average lexical_classification score, otherwise alphabetical order is 
assumed.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_error.bars">error.bars</code></td>
<td>
<p>logical.  If <code>TRUE</code> error bars are added to the 
lexical_classification dot plot using the standard error of the mean lexical_classification score.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_error.bar.height">error.bar.height</code></td>
<td>
<p>The height of the error bar ends.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_error.bar.size">error.bar.size</code></td>
<td>
<p>The size/thickness of the error bars.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_error.bar.color">error.bar.color</code></td>
<td>
<p>The color of the error bars.  If <code>NULL</code> each 
bar will be colored by grouping variable.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_error.bar.alpha">error.bar.alpha</code></td>
<td>
<p>The alpha level of the error bars.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the <code>ggplot2</code> objects that form the larger 
plot.
</p>

<hr>
<h2 id='plot.lexical_classification_preprocessed'>Plots a lexical_classification_preprocessed Object</h2><span id='topic+plot.lexical_classification_preprocessed'></span>

<h3>Description</h3>

<p>Plots a lexical_classification_preprocessed object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification_preprocessed'
plot(x, jitter = 0.1, text.size = 3.5, alpha = 0.3, ncol = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lexical_classification_preprocessed_+3A_x">x</code></td>
<td>
<p>The lexical_classification_preprocessed object.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_preprocessed_+3A_jitter">jitter</code></td>
<td>
<p>The amount to jitter the points by in the bocplots.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_preprocessed_+3A_text.size">text.size</code></td>
<td>
<p>The text size to use for plotting the mean in the boxplots.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_preprocessed_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level to use for points.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_preprocessed_+3A_ncol">ncol</code></td>
<td>
<p>The number of columns to use for <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_preprocessed_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.lexical_classification_score'>Plots a lexical_classification_score Object</h2><span id='topic+plot.lexical_classification_score'></span>

<h3>Description</h3>

<p>Plots a lexical_classification_score object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification_score'
plot(
  x,
  error.bar.height = 0.35,
  error.bar.size = 0.5,
  error.bar.alpha = 0.3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lexical_classification_score_+3A_x">x</code></td>
<td>
<p>The lexical_classification_score object.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_score_+3A_error.bar.height">error.bar.height</code></td>
<td>
<p>The height of the error bar ends.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_score_+3A_error.bar.size">error.bar.size</code></td>
<td>
<p>The size/thickness of the error bars.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_score_+3A_error.bar.alpha">error.bar.alpha</code></td>
<td>
<p>The alpha level of the error bars.</p>
</td></tr>
<tr><td><code id="plot.lexical_classification_score_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.linsear_write'>Plots a linsear_write Object</h2><span id='topic+plot.linsear_write'></span>

<h3>Description</h3>

<p>Plots a linsear_write object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'linsear_write'
plot(x, alpha = 0.4, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.linsear_write_+3A_x">x</code></td>
<td>
<p>The readability_score object.</p>
</td></tr>
<tr><td><code id="plot.linsear_write_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level for the points and smooth fill in the 
scatterplot (length one or two; if two 1-points, 2-smooth fill).</p>
</td></tr>
<tr><td><code id="plot.linsear_write_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.linsear_write_count'>Plots a linsear_write_count Object</h2><span id='topic+plot.linsear_write_count'></span>

<h3>Description</h3>

<p>Plots a linsear_write_count object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'linsear_write_count'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.linsear_write_count_+3A_x">x</code></td>
<td>
<p>The linsear_write_count object.</p>
</td></tr>
<tr><td><code id="plot.linsear_write_count_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.linsear_write_scores'>Plots a linsear_write_scores Object</h2><span id='topic+plot.linsear_write_scores'></span>

<h3>Description</h3>

<p>Plots a linsear_write_scores object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'linsear_write_scores'
plot(x, alpha = c(0.4, 0.08), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.linsear_write_scores_+3A_x">x</code></td>
<td>
<p>The readability_score object.</p>
</td></tr>
<tr><td><code id="plot.linsear_write_scores_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level for the points and smooth fill in the 
scatterplot (length one or two; if two 1-points, 2-smooth fill).</p>
</td></tr>
<tr><td><code id="plot.linsear_write_scores_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.Network'>Plots a Network  Object</h2><span id='topic+plot.Network'></span>

<h3>Description</h3>

<p>Plots a Network  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Network'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Network_+3A_x">x</code></td>
<td>
<p>The Network  object.</p>
</td></tr>
<tr><td><code id="plot.Network_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>print.Network </code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.object_pronoun_type'>Plots an object_pronoun_type Object</h2><span id='topic+plot.object_pronoun_type'></span>

<h3>Description</h3>

<p>Plots an object_pronoun_type object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'object_pronoun_type'
plot(x, type = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.object_pronoun_type_+3A_x">x</code></td>
<td>
<p>The object_pronoun_type object.</p>
</td></tr>
<tr><td><code id="plot.object_pronoun_type_+3A_type">type</code></td>
<td>
<p>An integer of <code>1</code>, <code>2</code>, <code>3</code>) corresponding to 
1 - heat map; 2 - lexical dispersion plot; 3 - facetted bar graph.</p>
</td></tr>
<tr><td><code id="plot.object_pronoun_type_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code>, 
<code><a href="#topic+dispersion_plot">dispersion_plot</a></code>, or <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.polarity'>Plots a polarity Object</h2><span id='topic+plot.polarity'></span>

<h3>Description</h3>

<p>Plots a polarity object as a heat map Gantt plot with polarity over 
time (measured in words) and polarity scores per sentence.  In the dotplot 
plot the black dots are the average polarity per grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity'
plot(
  x,
  bar.size = 5,
  low = "blue",
  mid = "grey99",
  high = "red",
  ave.polarity.shape = "+",
  alpha = 1/4,
  shape = 19,
  point.size = 2.5,
  jitter = 0.1,
  nrow = NULL,
  na.rm = TRUE,
  order.by.polarity = TRUE,
  plot = TRUE,
  error.bars = TRUE,
  error.bar.height = 0.5,
  error.bar.size = 0.5,
  error.bar.color = "black",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.polarity_+3A_x">x</code></td>
<td>
<p>The polarity object.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_bar.size">bar.size</code></td>
<td>
<p>The size of the bars used in the Gantt plot.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_low">low</code></td>
<td>
<p>The color to be used for lower values.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_mid">mid</code></td>
<td>
<p>The color to be used for mid-range values (default is a less 
striking color).</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_ave.polarity.shape">ave.polarity.shape</code></td>
<td>
<p>The shape of the average polarity score used in the 
dot plot.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_alpha">alpha</code></td>
<td>
<p>Transparency level of points (ranges between 0 and 1).</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_shape">shape</code></td>
<td>
<p>The shape of the points used in the dot plot.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_point.size">point.size</code></td>
<td>
<p>The size of the points used in the dot plot.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_jitter">jitter</code></td>
<td>
<p>Amount of vertical jitter to add to the points.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_nrow">nrow</code></td>
<td>
<p>The number of rows in the dotplot legend (used when the number of 
grouping variables makes the legend too wide).  If <code>NULL</code> no legend if 
plotted.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_order.by.polarity">order.by.polarity</code></td>
<td>
<p>logical.  If <code>TRUE</code> the group polarity plot 
will be ordered by average polarity score, otherwise alphabetical order is 
assumed.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_error.bars">error.bars</code></td>
<td>
<p>logical.  If <code>TRUE</code> error bars are added to the 
polarity dot plot using the standard error of the mean polarity score.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_error.bar.height">error.bar.height</code></td>
<td>
<p>The height of the error bar ends.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_error.bar.size">error.bar.size</code></td>
<td>
<p>The size/thickness of the error bars.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_error.bar.color">error.bar.color</code></td>
<td>
<p>The color of the error bars.  If <code>NULL</code> each 
bar will be colored by grouping variable.</p>
</td></tr>
<tr><td><code id="plot.polarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the <code>ggplot2</code> objects that form the larger 
plot.
</p>

<hr>
<h2 id='plot.polarity_count'>Plots a polarity_count Object</h2><span id='topic+plot.polarity_count'></span>

<h3>Description</h3>

<p>Plots a polarity_count object as a heat map Gantt plot with polarity over 
time (measured in words) and polarity scores per sentence.  In the dotplot 
plot the black dots are the average polarity per grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity_count'
plot(
  x,
  bar.size = 5,
  low = "blue",
  mid = "grey99",
  high = "red",
  ave.polarity.shape = "+",
  alpha = 1/4,
  shape = 19,
  point.size = 2.5,
  jitter = 0.1,
  nrow = NULL,
  na.rm = TRUE,
  order.by.polarity = TRUE,
  plot = TRUE,
  error.bars = TRUE,
  error.bar.height = 0.5,
  error.bar.size = 0.5,
  error.bar.color = "black",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.polarity_count_+3A_x">x</code></td>
<td>
<p>The polarity_count object.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_bar.size">bar.size</code></td>
<td>
<p>The size of the bars used in the Gantt plot.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_low">low</code></td>
<td>
<p>The color to be used for lower values.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_mid">mid</code></td>
<td>
<p>The color to be used for mid-range values (default is a less 
striking color).</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_ave.polarity.shape">ave.polarity.shape</code></td>
<td>
<p>The shape of the average polarity score used in the 
dot plot.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_alpha">alpha</code></td>
<td>
<p>Transparency level of points (ranges between 0 and 1).</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_shape">shape</code></td>
<td>
<p>The shape of the points used in the dot plot.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_point.size">point.size</code></td>
<td>
<p>The size of the points used in the dot plot.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_jitter">jitter</code></td>
<td>
<p>Amount of vertical jitter to add to the points.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_nrow">nrow</code></td>
<td>
<p>The number of rows in the dotplot legend (used when the number of 
grouping variables makes the legend too wide).  If <code>NULL</code> no legend if 
plotted.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_order.by.polarity">order.by.polarity</code></td>
<td>
<p>logical.  If <code>TRUE</code> the group polarity plot 
will be ordered by average polarity score, otherwise alphabetical order is 
assumed.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_error.bars">error.bars</code></td>
<td>
<p>logical.  If <code>TRUE</code> error bars are added to the 
polarity dot plot using the standard error of the mean polarity score.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_error.bar.height">error.bar.height</code></td>
<td>
<p>The height of the error bar ends.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_error.bar.size">error.bar.size</code></td>
<td>
<p>The size/thickness of the error bars.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_error.bar.color">error.bar.color</code></td>
<td>
<p>The color of the error bars.  If <code>NULL</code> each 
bar will be colored by grouping variable.</p>
</td></tr>
<tr><td><code id="plot.polarity_count_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the <code>ggplot2</code> objects that form the larger 
plot.
</p>

<hr>
<h2 id='plot.polarity_score'>Plots a polarity_score Object</h2><span id='topic+plot.polarity_score'></span>

<h3>Description</h3>

<p>Plots a polarity_score object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity_score'
plot(
  x,
  error.bar.height = 0.35,
  error.bar.size = 0.5,
  error.bar.alpha = 0.3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.polarity_score_+3A_x">x</code></td>
<td>
<p>The polarity_score object.</p>
</td></tr>
<tr><td><code id="plot.polarity_score_+3A_error.bar.height">error.bar.height</code></td>
<td>
<p>The height of the error bar ends.</p>
</td></tr>
<tr><td><code id="plot.polarity_score_+3A_error.bar.size">error.bar.size</code></td>
<td>
<p>The size/thickness of the error bars.</p>
</td></tr>
<tr><td><code id="plot.polarity_score_+3A_error.bar.alpha">error.bar.alpha</code></td>
<td>
<p>The alpha level of the error bars.</p>
</td></tr>
<tr><td><code id="plot.polarity_score_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.pos'>Plots a pos Object</h2><span id='topic+plot.pos'></span>

<h3>Description</h3>

<p>Plots a pos object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pos_+3A_x">x</code></td>
<td>
<p>The pos object</p>
</td></tr>
<tr><td><code id="plot.pos_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.pos_by'>Plots a pos_by Object</h2><span id='topic+plot.pos_by'></span>

<h3>Description</h3>

<p>Plots a pos_by object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos_by'
plot(
  x,
  label = FALSE,
  lab.digits = 1,
  percent = NULL,
  zero.replace = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pos_by_+3A_x">x</code></td>
<td>
<p>The pos_by object</p>
</td></tr>
<tr><td><code id="plot.pos_by_+3A_label">label</code></td>
<td>
<p>logical.  If TRUE the cells of the heat map plot will be labeled 
with count and proportional values.</p>
</td></tr>
<tr><td><code id="plot.pos_by_+3A_lab.digits">lab.digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.pos_by_+3A_percent">percent</code></td>
<td>
<p>logical.  If TRUE output given as percent.  If FALSE the 
output is proportion.  If NULL uses the value from 
<code><a href="#topic+question_type">question_type</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.pos_by_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If NULL uses the value 
from <code><a href="#topic+question_type">question_type</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.pos_by_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.pos_preprocessed'>Plots a pos_preprocessed Object</h2><span id='topic+plot.pos_preprocessed'></span>

<h3>Description</h3>

<p>Plots a pos_preprocessed object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos_preprocessed'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pos_preprocessed_+3A_x">x</code></td>
<td>
<p>The pos_preprocessed object.</p>
</td></tr>
<tr><td><code id="plot.pos_preprocessed_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.pronoun_type'>Plots an pronoun_type Object</h2><span id='topic+plot.pronoun_type'></span>

<h3>Description</h3>

<p>Plots an pronoun_type object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pronoun_type'
plot(x, type = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pronoun_type_+3A_x">x</code></td>
<td>
<p>The pronoun_type object.</p>
</td></tr>
<tr><td><code id="plot.pronoun_type_+3A_type">type</code></td>
<td>
<p>An integer of <code>1</code>, <code>2</code>, <code>3</code>) corresponding to 
1 - heat map; 2 - lexical dispersion plot; 3 - facetted bar graph.</p>
</td></tr>
<tr><td><code id="plot.pronoun_type_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code>, 
<code><a href="#topic+dispersion_plot">dispersion_plot</a></code>, or <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.question_type'>Plots a question_type Object</h2><span id='topic+plot.question_type'></span>

<h3>Description</h3>

<p>Plots a question_type object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'question_type'
plot(
  x,
  label = FALSE,
  lab.digits = 1,
  percent = NULL,
  zero.replace = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.question_type_+3A_x">x</code></td>
<td>
<p>The question_type object.</p>
</td></tr>
<tr><td><code id="plot.question_type_+3A_label">label</code></td>
<td>
<p>logical.  If TRUE the cells of the heat map plot will be labeled 
with count and proportional values.</p>
</td></tr>
<tr><td><code id="plot.question_type_+3A_lab.digits">lab.digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.question_type_+3A_percent">percent</code></td>
<td>
<p>logical.  If TRUE output given as percent.  If FALSE the 
output is proportion.  If NULL uses the value from 
<code><a href="#topic+question_type">question_type</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.question_type_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If NULL uses the value 
from <code><a href="#topic+question_type">question_type</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.question_type_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.question_type_preprocessed'>Plots a question_type_preprocessed Object</h2><span id='topic+plot.question_type_preprocessed'></span>

<h3>Description</h3>

<p>Plots a question_type_preprocessed object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'question_type_preprocessed'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.question_type_preprocessed_+3A_x">x</code></td>
<td>
<p>The question_type_preprocessed object.</p>
</td></tr>
<tr><td><code id="plot.question_type_preprocessed_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+gantt_plot">gantt_plot</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.readability_count'>Plots a readability_count Object</h2><span id='topic+plot.readability_count'></span>

<h3>Description</h3>

<p>Plots a readability_count object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'readability_count'
plot(x, alpha = 0.3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.readability_count_+3A_x">x</code></td>
<td>
<p>The readability_count object.</p>
</td></tr>
<tr><td><code id="plot.readability_count_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level to use for points.</p>
</td></tr>
<tr><td><code id="plot.readability_count_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.readability_score'>Plots a readability_score Object</h2><span id='topic+plot.readability_score'></span>

<h3>Description</h3>

<p>Plots a readability_score object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'readability_score'
plot(x, alpha = 0.3, auto.label, grid, div.col, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.readability_score_+3A_x">x</code></td>
<td>
<p>The readability_score object.</p>
</td></tr>
<tr><td><code id="plot.readability_score_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level to be used for the points.</p>
</td></tr>
<tr><td><code id="plot.readability_score_+3A_auto.label">auto.label</code></td>
<td>
<p>logical.  For plotting <code><a href="#topic+fry">fry</a></code> only, if 
<code>TRUE</code> labels automatically added.  If <code>FALSE</code> the user clicks 
interactively.</p>
</td></tr>
<tr><td><code id="plot.readability_score_+3A_grid">grid</code></td>
<td>
<p>logical.  For plotting <code><a href="#topic+fry">fry</a></code> only, if 
<code>TRUE</code> a micro grid is displayed similar to Fry's original depiction, 
though this makes visualizing more difficult.</p>
</td></tr>
<tr><td><code id="plot.readability_score_+3A_div.col">div.col</code></td>
<td>
<p>For plotting <code><a href="#topic+fry">fry</a></code> only, the color of the 
grade level division lines.</p>
</td></tr>
<tr><td><code id="plot.readability_score_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.rmgantt'>Plots a rmgantt object</h2><span id='topic+plot.rmgantt'></span>

<h3>Description</h3>

<p>Plots a rmgantt object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rmgantt'
plot(x, title, transform = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rmgantt_+3A_x">x</code></td>
<td>
<p>The sums_rmgantt object</p>
</td></tr>
<tr><td><code id="plot.rmgantt_+3A_title">title</code></td>
<td>
<p>An optional title.</p>
</td></tr>
<tr><td><code id="plot.rmgantt_+3A_transform">transform</code></td>
<td>
<p>logical.  If <code>TRUE</code> and there are two repeated measures 
the faceting is reversed.</p>
</td></tr>
<tr><td><code id="plot.rmgantt_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>gantt_wrap</code></p>
</td></tr>
</table>

<hr>
<h2 id='plot.sent_split'>Plots a sent_split Object</h2><span id='topic+plot.sent_split'></span>

<h3>Description</h3>

<p>Plots a sent_split object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sent_split'
plot(x, text.var = NULL, rm.var = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sent_split_+3A_x">x</code></td>
<td>
<p>The sent_split object.</p>
</td></tr>
<tr><td><code id="plot.sent_split_+3A_text.var">text.var</code></td>
<td>
<p>The text variable (character string).</p>
</td></tr>
<tr><td><code id="plot.sent_split_+3A_rm.var">rm.var</code></td>
<td>
<p>An optional repeated measures character vector of 1 or 2 to 
facet by.  If <code>NULL</code> the <code>rm.var</code> from <code>sentSplit</code> is used.  To 
avoid this behavior use
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot.sent_split_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>tot_plot</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.SMOG'>Plots a SMOG Object</h2><span id='topic+plot.SMOG'></span>

<h3>Description</h3>

<p>Plots a SMOG object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SMOG'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SMOG_+3A_x">x</code></td>
<td>
<p>The readability_score object.</p>
</td></tr>
<tr><td><code id="plot.SMOG_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.subject_pronoun_type'>Plots an subject_pronoun_type Object</h2><span id='topic+plot.subject_pronoun_type'></span>

<h3>Description</h3>

<p>Plots an subject_pronoun_type object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subject_pronoun_type'
plot(x, type = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.subject_pronoun_type_+3A_x">x</code></td>
<td>
<p>The subject_pronoun_type object.</p>
</td></tr>
<tr><td><code id="plot.subject_pronoun_type_+3A_type">type</code></td>
<td>
<p>An integer of <code>1</code>, <code>2</code>, <code>3</code>) corresponding to 
1 - heat map; 2 - lexical dispersion plot; 3 - facetted bar graph.</p>
</td></tr>
<tr><td><code id="plot.subject_pronoun_type_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code>, 
<code><a href="#topic+dispersion_plot">dispersion_plot</a></code>, or <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.sum_cmspans'>Plot Summary Stats for a Summary of a cmspans Object</h2><span id='topic+plot.sum_cmspans'></span>

<h3>Description</h3>

<p>Plots a heat map of summary statistics for 
sum_cmspans objects (the object produced by calling <code>summary</code> on a 
cmspans object).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sum_cmspans'
plot(
  x,
  digits = 3,
  sep = ".",
  name.sep = "&amp;",
  values = TRUE,
  high = "red",
  transpose = TRUE,
  plot = TRUE,
  facet.vars = "time",
  rev.codes = !transpose,
  rev.stats = !transpose,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sum_cmspans_+3A_x">x</code></td>
<td>
<p>The sum_cmspans object (the object produced by calling 
<code>summary</code> on a cmspans object)</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_sep">sep</code></td>
<td>
<p>The character that was used in <code>paste2</code> to paste the columns.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_name.sep">name.sep</code></td>
<td>
<p>The character that was used to paste the column names.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_transpose">transpose</code></td>
<td>
<p>logical.  If <code>TRUE</code> the dataframe is rotated 90 degrees.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_facet.vars">facet.vars</code></td>
<td>
<p>A character vector of names to facet by.  Default is 
<code>"time"</code>.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_rev.codes">rev.codes</code></td>
<td>
<p>logical If <code>TRUE</code> the plotting order of the code 
groups is reversed.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_rev.stats">rev.stats</code></td>
<td>
<p>logical If <code>TRUE</code> the plotting order of the code 
descriptive statistics is reversed.</p>
</td></tr>
<tr><td><code id="plot.sum_cmspans_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+summary.cmspans">summary.cmspans</a></code>
</p>

<hr>
<h2 id='plot.sums_gantt'>Plots a sums_gantt object</h2><span id='topic+plot.sums_gantt'></span>

<h3>Description</h3>

<p>Plots a sums_gantt object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sums_gantt'
plot(x, base = TRUE, title = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sums_gantt_+3A_x">x</code></td>
<td>
<p>The sums_gantt object</p>
</td></tr>
<tr><td><code id="plot.sums_gantt_+3A_base">base</code></td>
<td>
<p>logical.  If <code>TRUE</code> prints in base graphics system.
If <code>FALSE</code> prints in ggplot graphics system.</p>
</td></tr>
<tr><td><code id="plot.sums_gantt_+3A_title">title</code></td>
<td>
<p>An optional title.</p>
</td></tr>
<tr><td><code id="plot.sums_gantt_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>gantt_wrap</code> or 
<code>plot_gantt_base</code></p>
</td></tr>
</table>

<hr>
<h2 id='plot.syllable_freq'>Plots a syllable_freq Object</h2><span id='topic+plot.syllable_freq'></span>

<h3>Description</h3>

<p>Plots a syllable_freq object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'syllable_freq'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.syllable_freq_+3A_x">x</code></td>
<td>
<p>The syllable_freq object.</p>
</td></tr>
<tr><td><code id="plot.syllable_freq_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='plot.table_count'>Plots a table_count Object</h2><span id='topic+plot.table_count'></span>

<h3>Description</h3>

<p>Plots a table_count object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'table_count'
plot(x, values = TRUE, high = "red", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.table_count_+3A_x">x</code></td>
<td>
<p>The table_count object.</p>
</td></tr>
<tr><td><code id="plot.table_count_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="plot.table_count_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.table_count_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.table_proportion'>Plots a table_proportion Object</h2><span id='topic+plot.table_proportion'></span>

<h3>Description</h3>

<p>Plots a table_proportion object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'table_proportion'
plot(x, values = TRUE, high = "red", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.table_proportion_+3A_x">x</code></td>
<td>
<p>The table_proportion object.</p>
</td></tr>
<tr><td><code id="plot.table_proportion_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="plot.table_proportion_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.table_proportion_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.table_score'>Plots a table_score Object</h2><span id='topic+plot.table_score'></span>

<h3>Description</h3>

<p>Plots a table_score object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'table_score'
plot(x, values = TRUE, high = "red", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.table_score_+3A_x">x</code></td>
<td>
<p>The table_score object.</p>
</td></tr>
<tr><td><code id="plot.table_score_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="plot.table_score_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.table_score_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.termco'>Plots a termco object</h2><span id='topic+plot.termco'></span>

<h3>Description</h3>

<p>Plots a termco object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'termco'
plot(
  x,
  label = FALSE,
  lab.digits = 1,
  percent = NULL,
  zero.replace = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.termco_+3A_x">x</code></td>
<td>
<p>The termco object.</p>
</td></tr>
<tr><td><code id="plot.termco_+3A_label">label</code></td>
<td>
<p>logical.  If TRUE the cells of the heat map plot will be labeled 
with count and proportional values.</p>
</td></tr>
<tr><td><code id="plot.termco_+3A_lab.digits">lab.digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.termco_+3A_percent">percent</code></td>
<td>
<p>logical.  If TRUE output given as percent.  If FALSE the 
output is proportion.  If NULL uses the value from 
<code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.termco_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If NULL uses the value 
from <code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.termco_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.type_token_ratio'>Plots a type_token_ratio Object</h2><span id='topic+plot.type_token_ratio'></span>

<h3>Description</h3>

<p>Plots a type_token_ratio object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'type_token_ratio'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.type_token_ratio_+3A_x">x</code></td>
<td>
<p>The type_token_ratio object.</p>
</td></tr>
<tr><td><code id="plot.type_token_ratio_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.weighted_wfm'>Plots a weighted_wfm object</h2><span id='topic+plot.weighted_wfm'></span>

<h3>Description</h3>

<p>Plots a weighted_wfm object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'weighted_wfm'
plot(
  x,
  non.zero = FALSE,
  digits = 0,
  by.column = NULL,
  high = ifelse(non.zero, "black", "blue"),
  grid = ifelse(non.zero, "black", "white"),
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.weighted_wfm_+3A_x">x</code></td>
<td>
<p>The weighted_wfm object</p>
</td></tr>
<tr><td><code id="plot.weighted_wfm_+3A_non.zero">non.zero</code></td>
<td>
<p>logical.  If <code>TRUE</code> all values converted to dummy coded 
based on x_ij &gt; 0.</p>
</td></tr>
<tr><td><code id="plot.weighted_wfm_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.weighted_wfm_+3A_by.column">by.column</code></td>
<td>
<p>logical.  If <code>TRUE</code> applies scaling to the column.  If 
<code>FALSE</code>  applies scaling by row (use <code>NULL</code> to turn off scaling).</p>
</td></tr>
<tr><td><code id="plot.weighted_wfm_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.weighted_wfm_+3A_grid">grid</code></td>
<td>
<p>The color of the grid (Use <code>NULL</code> to remove the grid).</p>
</td></tr>
<tr><td><code id="plot.weighted_wfm_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="plot.weighted_wfm_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.wfdf'>Plots a wfdf object</h2><span id='topic+plot.wfdf'></span>

<h3>Description</h3>

<p>Plots a wfdf object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wfdf'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.wfdf_+3A_x">x</code></td>
<td>
<p>The wfdf object</p>
</td></tr>
<tr><td><code id="plot.wfdf_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+plot.wfm">plot.wfm</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.wfm'>Plots a wfm object</h2><span id='topic+plot.wfm'></span>

<h3>Description</h3>

<p>Plots a wfm object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wfm'
plot(
  x,
  non.zero = FALSE,
  digits = 0,
  by.column = NULL,
  high = ifelse(non.zero, "black", "blue"),
  grid = ifelse(non.zero, "black", "white"),
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.wfm_+3A_x">x</code></td>
<td>
<p>The wfm object</p>
</td></tr>
<tr><td><code id="plot.wfm_+3A_non.zero">non.zero</code></td>
<td>
<p>logical.  If <code>TRUE</code> all values converted to dummy coded 
based on x_ij &gt; 0.</p>
</td></tr>
<tr><td><code id="plot.wfm_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.wfm_+3A_by.column">by.column</code></td>
<td>
<p>logical.  If <code>TRUE</code> applies scaling to the column.  If 
<code>FALSE</code>  applies scaling by row (use <code>NULL</code> to turn off scaling).</p>
</td></tr>
<tr><td><code id="plot.wfm_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.wfm_+3A_grid">grid</code></td>
<td>
<p>The color of the grid (Use <code>NULL</code> to remove the grid).</p>
</td></tr>
<tr><td><code id="plot.wfm_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="plot.wfm_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.word_cor'>Plots a word_cor object</h2><span id='topic+plot.word_cor'></span>

<h3>Description</h3>

<p>Plots a word_cor object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_cor'
plot(
  x,
  label = TRUE,
  lab.digits = 3,
  high = "red",
  low = "white",
  grid = NULL,
  ncol = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.word_cor_+3A_x">x</code></td>
<td>
<p>The word_cor object</p>
</td></tr>
<tr><td><code id="plot.word_cor_+3A_label">label</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cells of the heat map plot will be 
labeled with count and proportional values.</p>
</td></tr>
<tr><td><code id="plot.word_cor_+3A_lab.digits">lab.digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed if <code>label</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.word_cor_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.word_cor_+3A_low">low</code></td>
<td>
<p>The color to be used for lower values.</p>
</td></tr>
<tr><td><code id="plot.word_cor_+3A_grid">grid</code></td>
<td>
<p>The color of the grid (Use <code>NULL</code> to remove the grid).</p>
</td></tr>
<tr><td><code id="plot.word_cor_+3A_ncol">ncol</code></td>
<td>
<p>The number of columns to arrange the facets in (specifying an 
integer results in the use of <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>, specifying
<code>NULL</code> utilizes a single column with <code><a href="ggplot2.html#topic+facet_grid">facet_grid</a></code>.  
The second approach limits columns but allows the y scale's space to be free.</p>
</td></tr>
<tr><td><code id="plot.word_cor_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat if matrix and other arguments 
passed to <code><a href="ggplot2.html#topic+geom_point">geom_point</a></code> if a list.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.word_length'>Plots a word_length Object</h2><span id='topic+plot.word_length'></span>

<h3>Description</h3>

<p>Plots a word_length object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_length'
plot(
  x,
  label = FALSE,
  lab.digits = 1,
  percent = NULL,
  zero.replace = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.word_length_+3A_x">x</code></td>
<td>
<p>The word_length object.</p>
</td></tr>
<tr><td><code id="plot.word_length_+3A_label">label</code></td>
<td>
<p>logical.  If TRUE the cells of the heat map plot will be labeled 
with count and proportional values.</p>
</td></tr>
<tr><td><code id="plot.word_length_+3A_lab.digits">lab.digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.word_length_+3A_percent">percent</code></td>
<td>
<p>logical.  If TRUE output given as percent.  If FALSE the 
output is proportion.  If NULL uses the value from 
<code><a href="#topic+word_length">word_length</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.word_length_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If NULL uses the value 
from <code><a href="#topic+word_length">word_length</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="plot.word_length_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.word_position'>Plots a word_position object</h2><span id='topic+plot.word_position'></span>

<h3>Description</h3>

<p>Plots a word_position object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_position'
plot(x, qheat = TRUE, scale = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.word_position_+3A_x">x</code></td>
<td>
<p>The word_position object.</p>
</td></tr>
<tr><td><code id="plot.word_position_+3A_qheat">qheat</code></td>
<td>
<p>logical.  If <code>TRUE</code> <code><a href="#topic+qheat">qheat</a></code> is used to 
plot.  If <code>FALSE</code> <code><a href="stats.html#topic+heatmap">heatmap</a></code> is used.</p>
</td></tr>
<tr><td><code id="plot.word_position_+3A_scale">scale</code></td>
<td>
<p>logical.  If <code>TRUE</code> scales heatmap by row.  If 
<code>FALSE</code> no scaling occurs.</p>
</td></tr>
<tr><td><code id="plot.word_position_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+qheat">qheat</a></code> or 
<code><a href="stats.html#topic+heatmap">heatmap</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.word_proximity'>Plots a word_proximity object</h2><span id='topic+plot.word_proximity'></span>

<h3>Description</h3>

<p>Plots a word_proximity object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_proximity'
plot(
  x,
  label = TRUE,
  lab.digits = NULL,
  high = "red",
  low = "white",
  grid = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.word_proximity_+3A_x">x</code></td>
<td>
<p>The word_proximity object</p>
</td></tr>
<tr><td><code id="plot.word_proximity_+3A_label">label</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cells of the heat map plot will be 
labeled with count and proportional values.</p>
</td></tr>
<tr><td><code id="plot.word_proximity_+3A_lab.digits">lab.digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed if <code>label</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.word_proximity_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="plot.word_proximity_+3A_low">low</code></td>
<td>
<p>The color to be used for lower values.</p>
</td></tr>
<tr><td><code id="plot.word_proximity_+3A_grid">grid</code></td>
<td>
<p>The color of the grid (Use <code>NULL</code> to remove the grid).</p>
</td></tr>
<tr><td><code id="plot.word_proximity_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.word_stats'>Plots a word_stats object</h2><span id='topic+plot.word_stats'></span>

<h3>Description</h3>

<p>Plots a word_stats object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_stats'
plot(x, label = FALSE, lab.digits = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.word_stats_+3A_x">x</code></td>
<td>
<p>The word_stats object</p>
</td></tr>
<tr><td><code id="plot.word_stats_+3A_label">label</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cells of the heat map plot will be 
labeled with count and proportional values.</p>
</td></tr>
<tr><td><code id="plot.word_stats_+3A_lab.digits">lab.digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed if <code>label</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.word_stats_+3A_...">...</code></td>
<td>
<p>Other arguments passed to qheat.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.word_stats_counts'>Plots a word_stats_counts Object</h2><span id='topic+plot.word_stats_counts'></span>

<h3>Description</h3>

<p>Plots a word_stats_counts object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_stats_counts'
plot(x, alpha = 0.3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.word_stats_counts_+3A_x">x</code></td>
<td>
<p>The word_stats_counts object.</p>
</td></tr>
<tr><td><code id="plot.word_stats_counts_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level to use for points.</p>
</td></tr>
<tr><td><code id="plot.word_stats_counts_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='polarity'>Polarity Score (Sentiment Analysis)</h2><span id='topic+polarity'></span>

<h3>Description</h3>

<p><code>polarity</code> - Approximate the sentiment (polarity) of text by grouping 
variable(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polarity(
  text.var,
  grouping.var = NULL,
  polarity.frame = qdapDictionaries::key.pol,
  constrain = FALSE,
  negators = qdapDictionaries::negation.words,
  amplifiers = qdapDictionaries::amplification.words,
  deamplifiers = qdapDictionaries::deamplification.words,
  question.weight = 0,
  amplifier.weight = 0.8,
  n.before = 4,
  n.after = 2,
  rm.incomplete = FALSE,
  digits = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polarity_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="polarity_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="polarity_+3A_polarity.frame">polarity.frame</code></td>
<td>
<p>A dataframe or hash key of positive/negative words and 
weights.</p>
</td></tr>
<tr><td><code id="polarity_+3A_constrain">constrain</code></td>
<td>
<p>logical.  If <code>TRUE</code> polarity values are constrained to 
be between -1 and 1 using the following transformation:
</p>
<p style="text-align: center;"><code class="reqn">\left[\left( 1 - \frac{1}{exp(\delta)}\right ) \cdot 2 \right] - 1</code>
</p>
</td></tr>
<tr><td><code id="polarity_+3A_negators">negators</code></td>
<td>
<p>A character vector of terms reversing the intent of a 
positive or negative word.</p>
</td></tr>
<tr><td><code id="polarity_+3A_amplifiers">amplifiers</code></td>
<td>
<p>A character vector of terms that increase the 
intensity of a positive or negative word.</p>
</td></tr>
<tr><td><code id="polarity_+3A_deamplifiers">deamplifiers</code></td>
<td>
<p>A character vector of terms that decrease the 
intensity of a positive or negative word.</p>
</td></tr>
<tr><td><code id="polarity_+3A_question.weight">question.weight</code></td>
<td>
<p>The weighting of questions (values from 0 to 1).
Default 0 corresponds with the belief that questions (pure questions) are not 
polarized.  A weight may be applied based on the evidence that the questions 
function with polarity.</p>
</td></tr>
<tr><td><code id="polarity_+3A_amplifier.weight">amplifier.weight</code></td>
<td>
<p>The weight to apply to amplifiers/deamplifiers (values 
from 0 to 1).  This value will multiply the polarized terms by 1 + this 
value.</p>
</td></tr>
<tr><td><code id="polarity_+3A_n.before">n.before</code></td>
<td>
<p>The number of words to consider as valence shifters before 
the polarized word.</p>
</td></tr>
<tr><td><code id="polarity_+3A_n.after">n.after</code></td>
<td>
<p>The number of words to consider as valence shifters after 
the polarized word.</p>
</td></tr>
<tr><td><code id="polarity_+3A_rm.incomplete">rm.incomplete</code></td>
<td>
<p>logical.  If <code>TRUE</code> text rows ending with qdap's 
incomplete sentence end mark (<code>|</code>) will be removed from the analysis.</p>
</td></tr>
<tr><td><code id="polarity_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="polarity_+3A_...">...</code></td>
<td>
<p>Other arguments supplied to <code><a href="#topic+strip">strip</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The equation used by the algorithm to assign value to polarity of 
each sentence fist utilizes the sentiment dictionary (Hu and Liu, 2004) to 
tag polarized words.  A context cluster (<code class="reqn">x_i^{T}</code>) of words is 
pulled from around this polarized word (default 4 words before and two words 
after) to be considered as valence shifters.  The words in this context 
cluster are tagged as neutral (<code class="reqn">x_i^{0}</code>), negator 
(<code class="reqn">x_i^{N}</code>), amplifier (<code class="reqn">x_i^{a}</code>), or de-amplifier 
(<code class="reqn">x_i^{d}</code>). Neutral words hold no value 
in the equation but do affect word count (<code class="reqn">n</code>).  Each polarized word is 
then weighted <code class="reqn">w</code> based on the weights from the <code>polarity.frame</code> 
argument and then further weighted by the number and position of the valence 
shifters directly surrounding the positive or negative word.  The researcher 
may provide a weight <code class="reqn">c</code> to be utilized with amplifiers/de-amplifiers 
(default is .8; deamplifier weight is constrained to -1 lower bound).  Last, 
these context cluster (<code class="reqn">x_i^{T}</code>) are summed and divided by the 
square root of the word count (<code class="reqn">\sqrt{n}</code>) yielding an unbounded 
polarity score (<code class="reqn">\delta</code>).  Note that context clusters containing a 
comma before the polarized word will only consider words found after the 
comma.
</p>
<p style="text-align: center;"><code class="reqn">\delta=\frac{x_i^T}{\sqrt{n}}</code>
</p>

<p>Where:
</p>
<p style="text-align: center;"><code class="reqn">x_i^T=\sum{((1 + c(x_i^{A} - x_i^{D}))\cdot w(-1)^{\sum{x_i^{N}}})}</code>
</p>

<p style="text-align: center;"><code class="reqn">x_i^{A}=\sum{(w_{neg}\cdot x_i^{a})}</code>
</p>

<p style="text-align: center;"><code class="reqn">x_i^D = \max(x_i^{D'}, -1)</code>
</p>

<p style="text-align: center;"><code class="reqn">x_i^{D'}= \sum{(- w_{neg}\cdot x_i^{a} + x_i^{d})}</code>
</p>

<p style="text-align: center;"><code class="reqn">w_{neg}= \left(\sum{x_i^{N}}\right) \bmod {2}</code>
</p>



<h3>Value</h3>

<p>Returns a list of:
</p>
<table>
<tr><td><code>all</code></td>
<td>
<p>A dataframe of scores per row with:
</p>

<ul>
<li><p>  group.var - the grouping variable
</p>
</li>
<li><p>  wc - word count
</p>
</li>
<li><p>  polarity - sentence polarity score
</p>
</li>
<li><p>  pos.words - words considered positive
</p>
</li>
<li><p>  neg.words - words considered negative
</p>
</li>
<li><p>  text.var - the text variable</p>
</li></ul>

</td></tr>
<tr><td><code>group</code></td>
<td>
<p>A dataframe with the average polarity score by grouping variable:
</p>

<ul>
<li><p>  group.var - the grouping variable
</p>
</li>
<li><p>  total.sentences - Total sentences spoken.
</p>
</li>
<li><p>  total.words - Total words used.
</p>
</li>
<li><p>  ave.polarity - The sum of all polarity scores for that group divided by number of sentences spoken.
</p>
</li>
<li><p>  sd.polarity - The standard deviation of that group's sentence level polarity scores.
</p>
</li>
<li><p>  stan.mean.polarity - A standardized polarity score calculated by taking the average polarity score for a group divided by the standard deviation.</p>
</li></ul>

</td></tr>
<tr><td><code>digits</code></td>
<td>
<p>integer value od number of digits to display; mostly internal 
use</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The polarity score is dependent upon the polarity dictionary used.  
This function defaults to the word polarity dictionary used by Hu, M., &amp; 
Liu, B. (2004), however, this may not be appropriate for the context of 
children in a classroom.  The user may (is encouraged) to provide/augment the 
dictionary (see the <code>sentiment_frame</code> function).  For instance the word 
&quot;sick&quot; in a high school setting may mean that something is good, whereas 
&quot;sick&quot; used by a typical adult indicates something is not right or negative 
connotation (<strong>deixis</strong>).
</p>
<p>Also note that <code><a href="#topic+polarity">polarity</a></code> assumes you've run 
<code><a href="#topic+sentSplit">sentSplit</a></code>.
</p>


<h3>References</h3>

<p>Hu, M., &amp; Liu, B. (2004). Mining opinion features in customer 
reviews. National Conference on Artificial Intelligence. 
</p>
<p>https://www.slideshare.net/jeffreybreen/r-by-example-mining-twitter-for
</p>
<p>http://hedonometer.org/papers.html Links to papers on hedonometrics
</p>


<h3>See Also</h3>

<p><a href="https://github.com/trestletech/Sermon-Sentiment-Analysis">https://github.com/trestletech/Sermon-Sentiment-Analysis</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(DATA, polarity(state, list(sex, adult)))
(poldat &lt;- with(sentSplit(DATA, 4), polarity(state, person)))
counts(poldat)
scores(poldat)
plot(poldat)

poldat2 &lt;- with(mraja1spl, polarity(dialogue, 
    list(sex, fam.aff, died)))
colsplit2df(scores(poldat2))
plot(poldat2)
plot(scores(poldat2))
cumulative(poldat2)

poldat3 &lt;- with(rajSPLIT, polarity(dialogue, person))
poldat3[["group"]][, "OL"] &lt;- outlier_labeler(scores(poldat3)[, 
    "ave.polarity"])
poldat3[["all"]][, "OL"] &lt;- outlier_labeler(counts(poldat3)[, 
    "polarity"])
htruncdf(scores(poldat3), 10)
htruncdf(counts(poldat3), 15, 8)
plot(poldat3)
plot(poldat3, nrow=4)
qheat(scores(poldat3)[, -7], high="red", order.b="ave.polarity")

## Create researcher defined sentiment.frame
POLKEY &lt;- sentiment_frame(positive.words, negative.words)
POLKEY
c("abrasive", "abrupt", "happy") %hl% POLKEY

# Augmenting the sentiment.frame
mycorpus &lt;- c("Wow that's a raw move.", "His jokes are so corny")
counts(polarity(mycorpus))

POLKEY &lt;- sentiment_frame(c(positive.words, "raw"), c(negative.words, "corny"))
counts(polarity(mycorpus, polarity.frame=POLKEY))

## ANIMATION
#===========
(deb2 &lt;- with(subset(pres_debates2012, time=="time 2"),
    polarity(dialogue, person)))

bg_black &lt;- Animate(deb2, neutral="white", current.speaker.color="grey70")
print(bg_black, pause=.75)

bgb &lt;- vertex_apply(bg_black, label.color="grey80", size=20, color="grey40")
bgb &lt;- edge_apply(bgb, label.color="yellow")
print(bgb, bg="black", pause=.75)

## Save it
library(animation)
library(igraph)
library(plotrix)

loc &lt;- folder(animation_polarity)

## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)

FUN &lt;- function() {
    Title &lt;- "Animated Polarity: 2012 Presidential Debate 2"
    Legend &lt;- c(-1.1, -1.25, -.2, -1.2)
    Legend.cex &lt;- 1
    lapply(seq_along(bgb), function(i) {
        par(mar=c(2, 0, 1, 0), bg="black")
        set.seed(10)
        plot.igraph(bgb[[i]], edge.curved=TRUE)
        mtext(Title, side=3, col="white")
        color.legend(Legend[1], Legend[2], Legend[3], Legend[4],
              c("Negative", "Neutral", "Positive"), attributes(bgb)[["legend"]],
              cex = Legend.cex, col="white")
        animation::ani.pause()
    })
}

FUN()

## Detect OS
type &lt;- if(.Platform$OS.type == "windows") shell else system

saveHTML(FUN(), autoplay = FALSE, loop = TRUE, verbose = FALSE,
    ani.height = 500, ani.width=500,
    outdir = file.path(loc, "new"), single.opts =
    "'controls': ['first', 'play', 'loop', 'speed'], 'delayMin': 0")

## Detect OS
type &lt;- if(.Platform$OS.type == "windows") shell else system

saveHTML(FUN(), autoplay = FALSE, loop = TRUE, verbose = FALSE,
    ani.height = 1000, ani.width=650,
    outdir = loc, single.opts =
    "'controls': ['first', 'play', 'loop', 'speed'], 'delayMin': 0")
    
 ## Animated corresponding text plot
 Animate(deb2, type="text")
 
#=====================#
## Complex Animation ##
#=====================#
library(animation)
library(grid)
library(gridBase)
library(qdap)
library(qdapTools)
library(igraph)
library(plotrix)
library(gridExtra)

deb2dat &lt;- subset(pres_debates2012, time=="time 2")
deb2dat[, "person"] &lt;- factor(deb2dat[, "person"])
(deb2 &lt;- with(deb2dat, polarity(dialogue, person)))

## Set up the network version
bg_black &lt;- Animate(deb2, neutral="white", current.speaker.color="grey70")
bgb &lt;- vertex_apply(bg_black, label.color="grey80", size=30, label.size=22,
    color="grey40")
bgb &lt;- edge_apply(bgb, label.color="yellow")

## Set up the bar version
deb2_bar &lt;- Animate(deb2, as.network=FALSE)

## Generate a folder
loc2 &lt;- folder(animation_polarity2)

## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)


FUN2 &lt;- function(follow=FALSE, theseq = seq_along(bgb)) {

    Title &lt;- "Animated Polarity: 2012 Presidential Debate 2"
    Legend &lt;- c(.2, -1.075, 1.5, -1.005)
    Legend.cex &lt;- 1

    lapply(theseq, function(i) {
        if (follow) {
            png(file=sprintf("%s/images/Rplot%s.png", loc2, i), 
                width=650, height=725)
        }
        ## Set up the layout
        layout(matrix(c(rep(1, 9), rep(2, 4)), 13, 1, byrow = TRUE))

        ## Plot 1
        par(mar=c(2, 0, 2, 0), bg="black")
        #par(mar=c(2, 0, 2, 0))
        set.seed(20)
        plot.igraph(bgb[[i]], edge.curved=TRUE)
        mtext(Title, side=3, col="white")
        color.legend(Legend[1], Legend[2], Legend[3], Legend[4],
              c("Negative", "Neutral", "Positive"), attributes(bgb)[["legend"]],
              cex = Legend.cex, col="white")

        ## Plot2
        plot.new()              
        vps &lt;- baseViewports()

        uns &lt;- unit(c(-1.3,.5,-.75,.25), "cm")
        p &lt;- deb2_bar[[i]] + 
            theme(plot.margin = uns,
                text=element_text(color="white"),
                plot.background = element_rect(fill = "black", 
                    color="black")) 
        print(p,vp = vpStack(vps$figure,vps$plot))
        animation::ani.pause()

        if (follow) {
            dev.off()
        }
    })

}

FUN2()

## Detect OS
type &lt;- if(.Platform$OS.type == "windows") shell else system

saveHTML(FUN2(), autoplay = FALSE, loop = TRUE, verbose = FALSE,
    ani.height = 1000, ani.width=650,
    outdir = loc2, single.opts =
    "'controls': ['first', 'play', 'loop', 'speed'], 'delayMin': 0")

FUN2(TRUE)

#=====================#
library(animation)
library(grid)
library(gridBase)
library(qdap)
library(qdapTools)
library(igraph)
library(plotrix)
library(gplots)

deb2dat &lt;- subset(pres_debates2012, time=="time 2")
deb2dat[, "person"] &lt;- factor(deb2dat[, "person"])
(deb2 &lt;- with(deb2dat, polarity(dialogue, person)))

## Set up the network version
bg_black &lt;- Animate(deb2, neutral="white", current.speaker.color="grey70")
bgb &lt;- vertex_apply(bg_black, label.color="grey80", size=30, label.size=22,
    color="grey40")
bgb &lt;- edge_apply(bgb, label.color="yellow")

## Set up the bar version
deb2_bar &lt;- Animate(deb2, as.network=FALSE)

## Set up the line version
deb2_line &lt;- plot(cumulative(deb2_bar))

## Generate a folder
loc2b &lt;- folder(animation_polarity2)

## Set up the plotting function
oopt &lt;- animation::ani.options(interval = 0.1)

FUN2 &lt;- function(follow=FALSE, theseq = seq_along(bgb)) {

    Title &lt;- "Animated Polarity: 2012 Presidential Debate 2"
    Legend &lt;- c(.2, -1.075, 1.5, -1.005)
    Legend.cex &lt;- 1

    lapply(theseq, function(i) {
        if (follow) {
            png(file=sprintf("%s/images/Rplot%s.png", loc2b, i),
                width=650, height=725)
        }
        ## Set up the layout
        layout(matrix(c(rep(1, 9), rep(2, 4)), 13, 1, byrow = TRUE))

        ## Plot 1
        par(mar=c(2, 0, 2, 0), bg="black")
        #par(mar=c(2, 0, 2, 0))
        set.seed(20)
        plot.igraph(bgb[[i]], edge.curved=TRUE)
        mtext(Title, side=3, col="white")
        color.legend(Legend[1], Legend[2], Legend[3], Legend[4],
              c("Negative", "Neutral", "Positive"), attributes(bgb)[["legend"]],
              cex = Legend.cex, col="white")

        ## Plot2
        plot.new()
        vps &lt;- baseViewports()

        uns &lt;- unit(c(-1.3,.5,-.75,.25), "cm")
        p &lt;- deb2_bar[[i]] +
            theme(plot.margin = uns,
                text=element_text(color="white"),
                plot.background = element_rect(fill = "black",
                    color="black"))
        print(p,vp = vpStack(vps$figure,vps$plot))
        animation::ani.pause()

        if (follow) {
            dev.off()
        }
    })

}

FUN2()

## Detect OS
type &lt;- if(.Platform$OS.type == "windows") shell else system

saveHTML(FUN2(), autoplay = FALSE, loop = TRUE, verbose = FALSE,
    ani.height = 1000, ani.width=650,
    outdir = loc2b, single.opts =
    "'controls': ['first', 'play', 'loop', 'speed'], 'delayMin': 0")

FUN2(TRUE)

## Increased complexity
## --------------------

## Helper function to cbind ggplots
cbinder &lt;- function(x, y){

    uns_x &lt;- unit(c(-1.3,.15,-.75,.25), "cm")
    uns_y &lt;- unit(c(-1.3,.5,-.75,.15), "cm")

    x &lt;- x + theme(plot.margin = uns_x,
        text=element_text(color="white"),
        plot.background = element_rect(fill = "black",
        color="black")
    )

    y &lt;- y + theme(plot.margin = uns_y,
        text=element_text(color="white"),
        plot.background = element_rect(fill = "black", 
        color="black")
    )

    plots &lt;- list(x, y)
    grobs &lt;- list()
    heights &lt;- list()
    
    for (i in 1:length(plots)){
        grobs[[i]] &lt;- ggplotGrob(plots[[i]])
        heights[[i]] &lt;- grobs[[i]]$heights[2:5]
    }
    
    maxheight &lt;- do.call(grid::unit.pmax, heights)
    
    for (i in 1:length(grobs)){
         grobs[[i]]$heights[2:5] &lt;- as.list(maxheight)
    }
    
    do.call("arrangeGrob", c(grobs, ncol = 2))
}

deb2_combo &lt;- Map(cbinder, deb2_bar, deb2_line)

## Generate a folder
loc3 &lt;- folder(animation_polarity3)


FUN3 &lt;- function(follow=FALSE, theseq = seq_along(bgb)) {

    Title &lt;- "Animated Polarity: 2012 Presidential Debate 2"
    Legend &lt;- c(.2, -1.075, 1.5, -1.005)
    Legend.cex &lt;- 1

    lapply(theseq, function(i) {
        if (follow) {
            png(file=sprintf("%s/images/Rplot%s.png", loc3, i),
                width=650, height=725)
        }
        ## Set up the layout
        layout(matrix(c(rep(1, 9), rep(2, 4)), 13, 1, byrow = TRUE))

        ## Plot 1
        par(mar=c(2, 0, 2, 0), bg="black")
        #par(mar=c(2, 0, 2, 0))
        set.seed(20)
        plot.igraph(bgb[[i]], edge.curved=TRUE)
        mtext(Title, side=3, col="white")
        color.legend(Legend[1], Legend[2], Legend[3], Legend[4],
              c("Negative", "Neutral", "Positive"), attributes(bgb)[["legend"]],
              cex = Legend.cex, col="white")

        ## Plot2
        plot.new()
        vps &lt;- baseViewports()
        p &lt;- deb2_combo[[i]]
        print(p,vp = vpStack(vps$figure,vps$plot))
        animation::ani.pause()

        if (follow) {
            dev.off()
        }
    })
}

FUN3()

type &lt;- if(.Platform$OS.type == "windows") shell else system

saveHTML(FUN3(), autoplay = FALSE, loop = TRUE, verbose = FALSE,
    ani.height = 1000, ani.width=650,
    outdir = loc3, single.opts =
    "'controls': ['first', 'play', 'loop', 'speed'], 'delayMin': 0")

FUN3(TRUE)

##-----------------------------##
## Constraining between -1 &amp; 1 ##
##-----------------------------##
## The old behavior of polarity constrained the output to be between -1 and 1
## this can be replicated via the `constrain = TRUE` argument:

polarity("really hate anger")
polarity("really hate anger", constrain=TRUE)

#==================#
## Static Network ##
#==================#
(poldat &lt;- with(sentSplit(DATA, 4), polarity(state, person)))
m &lt;- Network(poldat)
m
print(m, bg="grey97", vertex.color="grey75")

print(m, title="Polarity Discourse Map", title.color="white", bg="black",
    legend.text.color="white", vertex.label.color = "grey70", 
    edge.label.color="yellow")
    
## or use themes:
dev.off()
m + qtheme()
m + theme_nightheat
dev.off()
m+ theme_nightheat(title="Polarity Discourse Map")

#===============================#
## CUMULATIVE POLARITY EXAMPLE ##
#===============================#
#        Hedonometrics          #           
#===============================#
poldat4 &lt;- with(rajSPLIT, polarity(dialogue, act, constrain = TRUE))

polcount &lt;- na.omit(counts(poldat4)$polarity)
len &lt;- length(polcount)

cummean &lt;- function(x){cumsum(x)/seq_along(x)}

cumpolarity &lt;- data.frame(cum_mean = cummean(polcount), Time=1:len)

## Calculate background rectangles
ends &lt;- cumsum(rle(counts(poldat4)$act)$lengths)
starts &lt;- c(1, head(ends + 1, -1))
rects &lt;- data.frame(xstart = starts, xend = ends + 1, 
    Act = c("I", "II", "III", "IV", "V"))

library(ggplot2)
ggplot() + theme_bw() +
    geom_rect(data = rects, aes(xmin = xstart, xmax = xend, 
        ymin = -Inf, ymax = Inf, fill = Act), alpha = 0.17) +
    geom_smooth(data = cumpolarity, aes(y=cum_mean, x = Time)) +
    geom_hline(y=mean(polcount), color="grey30", size=1, alpha=.3, linetype=2) + 
    annotate("text", x = mean(ends[1:2]), y = mean(polcount), color="grey30", 
        label = "Average Polarity", vjust = .3, size=3) +
    geom_line(data = cumpolarity, aes(y=cum_mean, x = Time), size=1) +
    ylab("Cumulative Average Polarity") + xlab("Duration") +
    scale_x_continuous(expand = c(0,0)) +
    geom_text(data=rects, aes(x=(xstart + xend)/2, y=-.04, 
        label=paste("Act", Act)), size=3) + 
    guides(fill=FALSE) +
    scale_fill_brewer(palette="Set1")

## End(Not run)
</code></pre>

<hr>
<h2 id='pos'>Parts of Speech Tagging</h2><span id='topic+pos'></span><span id='topic+pos_by'></span><span id='topic+pos_tags'></span>

<h3>Description</h3>

<p><code>pos</code> - Apply part of speech tagger to transcript(s).
</p>
<p><code>pos_by</code> - Apply part of speech tagger to transcript(s) by zero or more 
grouping variable(s).
</p>
<p><code>pos_tags</code> - Useful for interpreting the parts of speech tags created by 
pos and pos_by.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pos(
  text.var,
  parallel = FALSE,
  cores = detectCores()/2,
  progress.bar = TRUE,
  na.omit = FALSE,
  digits = 1,
  percent = TRUE,
  zero.replace = 0,
  gc.rate = 10
)

pos_by(
  text.var,
  grouping.var = NULL,
  digits = 1,
  percent = TRUE,
  zero.replace = 0,
  ...
)

pos_tags(type = "pretty")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pos_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="pos_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create.</p>
</td></tr>
<tr><td><code id="pos_+3A_cores">cores</code></td>
<td>
<p>The number of cores to use if <code>parallel = TRUE</code>.  Default 
is half the number of available cores.</p>
</td></tr>
<tr><td><code id="pos_+3A_progress.bar">progress.bar</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to provide a OS 
appropriate progress bar.  If parallel is <code>TRUE</code> this argument is 
ignored. Note that setting this argument to <code>TRUE</code> may slow down the 
function.</p>
</td></tr>
<tr><td><code id="pos_+3A_na.omit">na.omit</code></td>
<td>
<p>logical.  If <code>TRUE</code> missing values (<code>NA</code>) will be 
omitted.</p>
</td></tr>
<tr><td><code id="pos_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="pos_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="pos_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.</p>
</td></tr>
<tr><td><code id="pos_+3A_gc.rate">gc.rate</code></td>
<td>
<p>An integer value.  This is a necessary argument because of a 
problem with the garbage collection in the openNLP function that 
<code><a href="#topic+pos">pos</a></code> wraps.  Consider adjusting this argument upward if 
the error <code>java.lang.OutOfMemoryError</code> occurs.</p>
</td></tr>
<tr><td><code id="pos_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="pos_+3A_type">type</code></td>
<td>
<p>An optional character string giving the output of the pos tags.
This must be one of the strings <code>"pretty"</code> (a left justified version of 
the output optimized for viewing but not good for export),  <code>"matrix"</code> 
(a matrix version of the output), <code>"dataframe"</code>\ <code>"df"</code> (a 
dataframe version of the output), <code>"all"</code> (a list of all three of the 
previous output types).</p>
</td></tr>
<tr><td><code id="pos_+3A_...">...</code></td>
<td>
<p>Other argument supplied to <code>pos</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>pos</code> -  returns a list of 4: 
</p>
<table>
<tr><td><code>text</code></td>
<td>
<p>The original text</p>
</td></tr> 
<tr><td><code>POStagged</code></td>
<td>
<p>The original words replaced with parts of speech in context.</p>
</td></tr> 
<tr><td><code>POSprop</code></td>
<td>
<p>Dataframe of the proportion of parts of speech by row.</p>
</td></tr> 
<tr><td><code>POSfreq</code></td>
<td>
<p>Dataframe of the frequency of parts of speech by row.</p>
</td></tr> 
<tr><td><code>POSrnp</code></td>
<td>
<p>Dataframe of the frequency and proportions of parts of speech 
by row.</p>
</td></tr> 
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr>
<tr><td><code>zero.replace</code></td>
<td>
<p>The value of zero.replace used for plotting purposes.</p>
</td></tr>
</table>
<p><code>pos_by</code> -  returns a list of 6: 
</p>
<table>
<tr><td><code>text</code></td>
<td>
<p>The original text</p>
</td></tr> 
<tr><td><code>POStagged</code></td>
<td>
<p>The original words replaced with parts of speech in context.</p>
</td></tr> 
<tr><td><code>POSprop</code></td>
<td>
<p>Dataframe of the proportion of parts of speech by row.</p>
</td></tr> 
<tr><td><code>POSfreq</code></td>
<td>
<p>Dataframe of the frequency of parts of speech by row.</p>
</td></tr> 
<tr><td><code>POSrnp</code></td>
<td>
<p>Dataframe of the frequency and proportions of parts of speech 
by row.</p>
</td></tr> 
<tr><td><code>pos.by.prop</code></td>
<td>
<p>Dataframe of the proportion of parts of speech by grouping 
variable.</p>
</td></tr> 
<tr><td><code>pos.by.freq</code></td>
<td>
<p>Dataframe of the frequency of parts of speech by grouping 
variable.</p>
</td></tr> 
<tr><td><code>pos.by.rnp</code></td>
<td>
<p>Dataframe of the frequency and proportions of parts of 
speech by grouping variable.</p>
</td></tr> 
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr>
<tr><td><code>zero.replace</code></td>
<td>
<p>The value of zero.replace used for plotting purposes.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that contractions are treated as two words; for example the word 
count on <b>&quot;what's&quot;</b> is 2 for <b>&quot;what + is&quot;</b>.  This is not consistent 
with the <code><a href="#topic+word_count">word_count</a></code> treatment of contractions but makes 
sense in a part of speech framework where a phrase such as &quot;She's cool&quot; is 
treated as a pronoun, verb and adjective respectively for &quot;She + is + cool&quot;.
</p>


<h3>References</h3>

<p>http:/opennlp.apache.org
</p>


<h3>See Also</h3>

<p><code><a href="openNLP.html#topic+Maxent_POS_Tag_Annotator">Maxent_POS_Tag_Annotator</a></code>,
<code><a href="#topic+colcomb2class">colcomb2class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
posdat &lt;- pos(DATA$state)
ltruncdf(posdat, 7, 4)
## str(posdat)
names(posdat)
posdat$text           #original text

## Methods
preprocessed(posdat)  #words replaced with parts of speech
counts(posdat)        #frequency of parts of speech by row
proportions(posdat)   #proportion of parts of speech by row

## Methods Plotting
plot(preprocessed(posdat))
plot(counts(posdat))
plot(proportions(posdat))
plot(posdat)

out1 &lt;- pos(DATA$state, parallel = TRUE) # not always useful
ltruncdf(out1, 7, 4)

#use pos_tags to interpret part of speech tags used by pos &amp; pos_by
pos_tags()[1:10, ]
pos_tags("matrix")[1:10, ]
pos_tags("dataframe")[1:10, ]
pos_tags("df")[1:10, ]
ltruncdf(pos_tags("all"), 3)

posbydat &lt;- with(DATA, pos_by(state, sex))
names(posbydat)

## Methods
scores(posbydat)   
preprocessed(posbydat)
counts(posbydat)     
proportions(posbydat)   

## Methods Plotting
plot(preprocessed(posbydat))
plot(counts(posbydat))
plot(proportions(posbydat))
plot(posbydat)

ltruncdf(posbydat, 7, 4)
truncdf(posbydat$pos.by.prop, 4)

POSby &lt;- with(DATA, pos_by(state, list(adult, sex)))
plot(POSby, values = TRUE, digits = 2)
#or more quickly - reuse the output from before
out2 &lt;- with(DATA, pos_by(posbydat, list(adult, sex)))

## Definite/Indefinite Noun 
## 2 approached compared...
## The later is more efficient but less accurate

## ------------------------##
## Part off speech tagging ##
## ------------------------##
pos_after &lt;- function(text.var, words, pos){

    posses &lt;- strsplit(as.character(text.var[["POStagged"]][["POStagged"]]), "\\s+")
    namespos &lt;- lapply(posses, function(x) {
        y &lt;- unlist(strsplit(x, "/"))
        setNames(y[c(TRUE, FALSE)], y[c(FALSE, TRUE)])
    })

    lapply(namespos, function(x, thewords = words, thepos = pos){
        locs &lt;- which(x %in% thewords)
        locs &lt;- locs[!is.na(locs)]

        if (identical(unclass(locs), integer(0))) return(NA_character_)

        nounlocs &lt;- which(names(x) %in% thepos)

        unname(x[unique(sapply(locs, function(x){ 
            min(nounlocs[nounlocs - x &gt; 0])
        }))])
    })  
}

out2 &lt;- setNames(lapply(list(a=c("a", "an"), the="the"), function(x) {
    o &lt;- pos_after(rajPOS, x, c("NN", "NNS", "NNP", "NNPS"))
    m &lt;- stats::setNames(data.frame(sort(table(unlist(o))), 
        stringsAsFactors = FALSE), c("word", "freq"))
    m[m$freq&gt; 3, ]
}), c("a", "the"))


dat2 &lt;- setNames(Reduce(function(x, y) {
    merge(x, y, by = "word", all = TRUE)}, out2), c("Word", "A", "THE"))

dat2 &lt;- reshape2::melt(dat2, id="Word", variable.name="Article", value.name="freq")

dat2 &lt;- dat2[order(dat2$freq, dat2$Word), ]

ord2 &lt;- aggregate(freq ~ Word, dat2, sum)

dat2$Word &lt;- factor(dat2$Word, levels=ord2[order(ord2[[2]]), 1])
rownames(dat2) &lt;- NULL
ggplot(dat2, aes(x=freq, y=Word)) +
    geom_point()+ facet_grid(~Article) +
    ggtitle("Part Of Speech Parsing Approach")

dev.new()

## --------------------##
## Regular Expressions ##
## --------------------##

library(qdapRegex);library(ggplot2);library(reshape2)

out &lt;- setNames(lapply(c("@after_a", "@after_the"), function(x) {
    o &lt;- rm_default(stringi:::stri_trans_tolower(raj$dialogue),
        pattern = x, extract=TRUE)
    m &lt;- stats::setNames(data.frame(sort(table(unlist(o))), 
        stringsAsFactors = FALSE), c("word", "freq"))
    m[m$freq&gt; 3, ]
}), c("a", "the"))

dat &lt;- setNames(Reduce(function(x, y) {
    merge(x, y, by = "word", all = TRUE)}, out), c("Word", "A", "THE"))

dat &lt;- reshape2::melt(dat, id="Word", variable.name="Article", value.name="freq")

dat &lt;- dat[order(dat$freq, dat$Word), ]

ord &lt;- aggregate(freq ~ Word, dat, sum)

dat$Word &lt;- factor(dat$Word, levels=ord[order(ord[[2]]), 1])
rownames(dat) &lt;- NULL
ggplot(dat, aes(x=freq, y=Word)) + 
    geom_point()+ facet_grid(~Article) + 
    ggtitle("Regex Approach")

## End(Not run)
</code></pre>

<hr>
<h2 id='potential_NA'>Search for Potential Missing Values</h2><span id='topic+potential_NA'></span>

<h3>Description</h3>

<p>Search for potential missing values (i.e., sentences that are merely a 
punctuation mark) and optionally replace with missing value (<code>NA</code>).  
Useful in the initial cleaning process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>potential_NA(text.var, n = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="potential_NA_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="potential_NA_+3A_n">n</code></td>
<td>
<p>Number of characters to consider for missing (default is 3).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe of potential missing values row numbers and text.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
DATA$state[c(3, 7)] &lt;- "."
potential_NA(DATA$state, 20)
potential_NA(DATA$state)
# USE TO SELCTIVELY REPLACE CELLS WITH MISSING VALUES
DATA$state[potential_NA(DATA$state, 20)$row[-c(3)]] &lt;- NA
DATA
DATA &lt;- qdap::DATA

## End(Not run)
</code></pre>

<hr>
<h2 id='preprocessed'>Generic Preprocessed Method</h2><span id='topic+preprocessed'></span>

<h3>Description</h3>

<p>Access the preprocessed dataframes/lists from select qdap outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed_+3A_x">x</code></td>
<td>
<p>A qdap object (list) with a dataframe/list of preprocessed data 
(e.g., <code><a href="#topic+pos_by">pos_by</a></code>).</p>
</td></tr>
<tr><td><code id="preprocessed_+3A_...">...</code></td>
<td>
<p>Arguments passed to preprocessed method of other classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data.frame or list of preprocessed data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scores">scores</a></code>,
<code><a href="#topic+counts">counts</a></code>,
<code><a href="#topic+proportions">proportions</a></code>,
<code><a href="#topic+visual">visual</a></code>
</p>

<hr>
<h2 id='preprocessed.check_spelling_interactive'>Check Spelling</h2><span id='topic+preprocessed.check_spelling_interactive'></span>

<h3>Description</h3>

<p>View check_spelling_interactive preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'check_spelling_interactive'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.check_spelling_interactive_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+check_spelling_interactive">check_spelling_interactive</a></code> object.</p>
</td></tr>
<tr><td><code id="preprocessed.check_spelling_interactive_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>check_spelling_interactive Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.end_mark_by'>Question Counts</h2><span id='topic+preprocessed.end_mark_by'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+end_mark_by">end_mark_by</a></code> preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.end_mark_by_+3A_x">x</code></td>
<td>
<p>The end_mark_by object.</p>
</td></tr>
<tr><td><code id="preprocessed.end_mark_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>end_mark_by Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.formality'>Formality</h2><span id='topic+preprocessed.formality'></span>

<h3>Description</h3>

<p>View formality preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.formality_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+formality">formality</a></code> object.</p>
</td></tr>
<tr><td><code id="preprocessed.formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>formality Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.lexical_classification'>Lexical Classification</h2><span id='topic+preprocessed.lexical_classification'></span>

<h3>Description</h3>

<p><code>preprocessed.lexical_classification</code> - View preprocessed from <code><a href="#topic+lexical_classification">lexical_classification</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.lexical_classification_+3A_x">x</code></td>
<td>
<p>The lexical_classification object.</p>
</td></tr>
<tr><td><code id="preprocessed.lexical_classification_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>lexical_classification Method for preprocessed.
</p>

<hr>
<h2 id='preprocessed.object_pronoun_type'>Question Counts</h2><span id='topic+preprocessed.object_pronoun_type'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+object_pronoun_type">object_pronoun_type</a></code> preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'object_pronoun_type'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.object_pronoun_type_+3A_x">x</code></td>
<td>
<p>The object_pronoun_type object.</p>
</td></tr>
<tr><td><code id="preprocessed.object_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>object_pronoun_type Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.pos'>Parts of Speech</h2><span id='topic+preprocessed.pos'></span>

<h3>Description</h3>

<p>View pos preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.pos_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+pos">pos</a></code> object.</p>
</td></tr>
<tr><td><code id="preprocessed.pos_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pos Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.pos_by'>Parts of Speech</h2><span id='topic+preprocessed.pos_by'></span>

<h3>Description</h3>

<p>View pos_by preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos_by'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.pos_by_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+pos_by">pos_by</a></code> object.</p>
</td></tr>
<tr><td><code id="preprocessed.pos_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pos_by Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.pronoun_type'>Question Counts</h2><span id='topic+preprocessed.pronoun_type'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+pronoun_type">pronoun_type</a></code> preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pronoun_type'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.pronoun_type_+3A_x">x</code></td>
<td>
<p>The pronoun_type object.</p>
</td></tr>
<tr><td><code id="preprocessed.pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pronoun_type Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.question_type'>Question Counts</h2><span id='topic+preprocessed.question_type'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+question_type">question_type</a></code> preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'question_type'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.question_type_+3A_x">x</code></td>
<td>
<p>The question_type object.</p>
</td></tr>
<tr><td><code id="preprocessed.question_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>question_type Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.subject_pronoun_type'>Question Counts</h2><span id='topic+preprocessed.subject_pronoun_type'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+subject_pronoun_type">subject_pronoun_type</a></code> preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subject_pronoun_type'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.subject_pronoun_type_+3A_x">x</code></td>
<td>
<p>The subject_pronoun_type object.</p>
</td></tr>
<tr><td><code id="preprocessed.subject_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>subject_pronoun_type Method for preprocessed
</p>

<hr>
<h2 id='preprocessed.word_position'>Word Position</h2><span id='topic+preprocessed.word_position'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+word_position">word_position</a></code> preprocessed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_position'
preprocessed(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessed.word_position_+3A_x">x</code></td>
<td>
<p>The word_position object.</p>
</td></tr>
<tr><td><code id="preprocessed.word_position_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>word_position Method for preprocessed
</p>

<hr>
<h2 id='pres_debate_raw2012'>First 2012 U.S. Presidential Debate</h2><span id='topic+pres_debate_raw2012'></span>

<h3>Description</h3>

<p>A dataset containing the raw version of the first presidential debate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pres_debate_raw2012)
</code></pre>


<h3>Format</h3>

<p>A data frame with 94 rows and 2 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. The speaker
</p>
</li>
<li><p> dialogue. The words spoken 
</p>
</li></ul>


<hr>
<h2 id='pres_debates2012'>2012 U.S. Presidential Debates</h2><span id='topic+pres_debates2012'></span>

<h3>Description</h3>

<p>A dataset containing a cleaned version of all three presidential debates for 
the 2012 election.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pres_debates2012)
</code></pre>


<h3>Format</h3>

<p>A data frame with 2912 rows and 4 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. The speaker
</p>
</li>
<li><p> tot. Turn of talk
</p>
</li>
<li><p> dialogue. The words spoken
</p>
</li>
<li><p> time. Variable indicating which of the three debates the dialogue is from
</p>
</li></ul>


<hr>
<h2 id='print.adjacency_matrix'>Prints an adjacency_matrix Object</h2><span id='topic+print.adjacency_matrix'></span>

<h3>Description</h3>

<p>Prints an adjacency_matrix object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'adjacency_matrix'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.adjacency_matrix_+3A_x">x</code></td>
<td>
<p>The adjacency_matrix object.</p>
</td></tr>
<tr><td><code id="print.adjacency_matrix_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.all_words'>Prints an all_words Object</h2><span id='topic+print.all_words'></span>

<h3>Description</h3>

<p>Prints an all_words object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'all_words'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.all_words_+3A_x">x</code></td>
<td>
<p>The all_words object.</p>
</td></tr>
<tr><td><code id="print.all_words_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.animated_character'>Prints an animated_character  Object</h2><span id='topic+print.animated_character'></span>

<h3>Description</h3>

<p>Prints an animated_character  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_character'
print(x, pause = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.animated_character_+3A_x">x</code></td>
<td>
<p>The animated_character  object.</p>
</td></tr>
<tr><td><code id="print.animated_character_+3A_pause">pause</code></td>
<td>
<p>The length of time to pause between plots.</p>
</td></tr>
<tr><td><code id="print.animated_character_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='print.animated_discourse_map'>Prints an animated_discourse_map  Object</h2><span id='topic+print.animated_discourse_map'></span>

<h3>Description</h3>

<p>Prints an animated_discourse_map  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_discourse_map'
print(
  x,
  title = NULL,
  seed = sample(1:10000, 1),
  layout = layout.auto,
  pause = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.animated_discourse_map_+3A_x">x</code></td>
<td>
<p>The animated_discourse_map  object.</p>
</td></tr>
<tr><td><code id="print.animated_discourse_map_+3A_title">title</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="print.animated_discourse_map_+3A_seed">seed</code></td>
<td>
<p>The seed to use in plotting the graph.</p>
</td></tr>
<tr><td><code id="print.animated_discourse_map_+3A_layout">layout</code></td>
<td>
<p><span class="pkg">igraph</span> <code>layout</code> to use.</p>
</td></tr>
<tr><td><code id="print.animated_discourse_map_+3A_pause">pause</code></td>
<td>
<p>The length of time to pause between plots.</p>
</td></tr>
<tr><td><code id="print.animated_discourse_map_+3A_...">...</code></td>
<td>
<p>Other Arguments passed to <code><a href="igraph.html#topic+plot.igraph">plot.igraph</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.animated_formality'>Prints a animated_formality  Object</h2><span id='topic+print.animated_formality'></span>

<h3>Description</h3>

<p>Prints a animated_formality  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_formality'
print(
  x,
  title = NULL,
  seed = sample(1:10000, 1),
  layout = layout.auto,
  pause = 0,
  legend = c(-0.5, -1.5, 0.5, -1.45),
  legend.cex = 1,
  bg = NULL,
  net.legend.color = "black",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.animated_formality_+3A_x">x</code></td>
<td>
<p>The animated_formality  object.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_title">title</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_seed">seed</code></td>
<td>
<p>The seed to use in plotting the graph.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_layout">layout</code></td>
<td>
<p><span class="pkg">igraph</span> <code>layout</code> to use.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_pause">pause</code></td>
<td>
<p>The length of time to pause between plots.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_legend">legend</code></td>
<td>
<p>The coordinates of the legend. See 
<code><a href="plotrix.html#topic+color.legend">color.legend</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_legend.cex">legend.cex</code></td>
<td>
<p>character expansion factor. <code>NULL</code> and <code>NA</code> are 
equivalent to 1.0. See <code><a href="graphics.html#topic+mtext">mtext</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_bg">bg</code></td>
<td>
<p>The color to be used for the background of the device region. See
<code><a href="graphics.html#topic+par">par</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_net.legend.color">net.legend.color</code></td>
<td>
<p>The text legend color for the network plot.</p>
</td></tr>
<tr><td><code id="print.animated_formality_+3A_...">...</code></td>
<td>
<p>Other Arguments passed to <code><a href="igraph.html#topic+plot.igraph">plot.igraph</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.animated_lexical_classification'>Prints an animated_lexical_classification  Object</h2><span id='topic+print.animated_lexical_classification'></span>

<h3>Description</h3>

<p>Prints an animated_lexical_classification  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_lexical_classification'
print(
  x,
  title = NULL,
  seed = sample(1:10000, 1),
  layout = layout.auto,
  pause = 0,
  legend = c(-0.5, -1.5, 0.5, -1.45),
  legend.cex = 1,
  bg = NULL,
  net.legend.color = "black",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.animated_lexical_classification_+3A_x">x</code></td>
<td>
<p>The animated_lexical_classification  object.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_title">title</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_seed">seed</code></td>
<td>
<p>The seed to use in plotting the graph.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_layout">layout</code></td>
<td>
<p><span class="pkg">igraph</span> <code>layout</code> to use.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_pause">pause</code></td>
<td>
<p>The length of time to pause between plots.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_legend">legend</code></td>
<td>
<p>The coordinates of the legend. See 
<code><a href="plotrix.html#topic+color.legend">color.legend</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_legend.cex">legend.cex</code></td>
<td>
<p>character expansion factor. <code>NULL</code> and <code>NA</code> are 
equivalent to 1.0. See <code><a href="graphics.html#topic+mtext">mtext</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_bg">bg</code></td>
<td>
<p>The color to be used for the background of the device region. See
<code><a href="graphics.html#topic+par">par</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_net.legend.color">net.legend.color</code></td>
<td>
<p>The text legend color for the network plot.</p>
</td></tr>
<tr><td><code id="print.animated_lexical_classification_+3A_...">...</code></td>
<td>
<p>Other Arguments passed to <code><a href="igraph.html#topic+plot.igraph">plot.igraph</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.animated_polarity'>Prints an animated_polarity  Object</h2><span id='topic+print.animated_polarity'></span>

<h3>Description</h3>

<p>Prints an animated_polarity  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'animated_polarity'
print(
  x,
  title = NULL,
  seed = sample(1:10000, 1),
  layout = layout.auto,
  pause = 0,
  legend = c(-0.5, -1.5, 0.5, -1.45),
  legend.cex = 1,
  bg = NULL,
  net.legend.color = "black",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.animated_polarity_+3A_x">x</code></td>
<td>
<p>The animated_polarity  object.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_title">title</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_seed">seed</code></td>
<td>
<p>The seed to use in plotting the graph.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_layout">layout</code></td>
<td>
<p><span class="pkg">igraph</span> <code>layout</code> to use.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_pause">pause</code></td>
<td>
<p>The length of time to pause between plots.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_legend">legend</code></td>
<td>
<p>The coordinates of the legend. See 
<code><a href="plotrix.html#topic+color.legend">color.legend</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_legend.cex">legend.cex</code></td>
<td>
<p>character expansion factor. <code>NULL</code> and <code>NA</code> are 
equivalent to 1.0. See <code><a href="graphics.html#topic+mtext">mtext</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_bg">bg</code></td>
<td>
<p>The color to be used for the background of the device region. See
<code><a href="graphics.html#topic+par">par</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_net.legend.color">net.legend.color</code></td>
<td>
<p>The text legend color for the network plot.</p>
</td></tr>
<tr><td><code id="print.animated_polarity_+3A_...">...</code></td>
<td>
<p>Other Arguments passed to <code><a href="igraph.html#topic+plot.igraph">plot.igraph</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.automated_readability_index'>Prints an automated_readability_index Object</h2><span id='topic+print.automated_readability_index'></span>

<h3>Description</h3>

<p>Prints an automated_readability_index object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'automated_readability_index'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.automated_readability_index_+3A_x">x</code></td>
<td>
<p>The automated_readability_index object.</p>
</td></tr>
<tr><td><code id="print.automated_readability_index_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.automated_readability_index_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.boolean_qdap'>Prints a boolean_qdap object</h2><span id='topic+print.boolean_qdap'></span>

<h3>Description</h3>

<p>Prints a boolean_qdap object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'boolean_qdap'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.boolean_qdap_+3A_x">x</code></td>
<td>
<p>The boolean_qdap object</p>
</td></tr>
<tr><td><code id="print.boolean_qdap_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.character_table'>Prints a character_table object</h2><span id='topic+print.character_table'></span>

<h3>Description</h3>

<p>Prints a character_table object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'character_table'
print(x, digits = 2, percent = NULL, zero.replace = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.character_table_+3A_x">x</code></td>
<td>
<p>The character_table object</p>
</td></tr>
<tr><td><code id="print.character_table_+3A_digits">digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed.</p>
</td></tr>
<tr><td><code id="print.character_table_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.  If <code>NULL</code> uses the value from 
<code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.character_table_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If <code>NULL</code> uses the 
value from <code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is 
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.character_table_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.check_spelling'>Prints a check_spelling Object</h2><span id='topic+print.check_spelling'></span>

<h3>Description</h3>

<p>Prints a check_spelling object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'check_spelling'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.check_spelling_+3A_x">x</code></td>
<td>
<p>The check_spelling object.</p>
</td></tr>
<tr><td><code id="print.check_spelling_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.check_spelling_interactive'>Prints a check_spelling_interactive Object</h2><span id='topic+print.check_spelling_interactive'></span>

<h3>Description</h3>

<p>Prints a check_spelling_interactive object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'check_spelling_interactive'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.check_spelling_interactive_+3A_x">x</code></td>
<td>
<p>The check_spelling_interactive object.</p>
</td></tr>
<tr><td><code id="print.check_spelling_interactive_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.check_text'>Prints a check_text Object</h2><span id='topic+print.check_text'></span>

<h3>Description</h3>

<p>Prints a check_text object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'check_text'
print(x, include.text = TRUE, file = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.check_text_+3A_x">x</code></td>
<td>
<p>The check_text object.</p>
</td></tr>
<tr><td><code id="print.check_text_+3A_include.text">include.text</code></td>
<td>
<p>logical.  If <code>TRUE</code> the offending text is printed as 
well.</p>
</td></tr>
<tr><td><code id="print.check_text_+3A_file">file</code></td>
<td>
<p>A connection, or a character string naming the file to print to.
If <code>NULL</code> prints to the console.</p>
</td></tr>
<tr><td><code id="print.check_text_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cm_distance'>Prints a cm_distance Object</h2><span id='topic+print.cm_distance'></span>

<h3>Description</h3>

<p>Prints a cm_distance object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cm_distance'
print(
  x,
  mean.digits = 0,
  sd.digits = 2,
  sd.mean.digits = 3,
  pval.digits = 3,
  new.order = NULL,
  na.replace = "-",
  diag.replace = na.replace,
  print = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cm_distance_+3A_x">x</code></td>
<td>
<p>The cm_distance object.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_mean.digits">mean.digits</code></td>
<td>
<p>The number of digits to print for the mean code distances.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_sd.digits">sd.digits</code></td>
<td>
<p>The number of digits to print for the standard deviations of 
the code distances.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_sd.mean.digits">sd.mean.digits</code></td>
<td>
<p>The number of digits to print for the standardized mean 
distances.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_pval.digits">pval.digits</code></td>
<td>
<p>The number of digits to print for the p-values.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_new.order">new.order</code></td>
<td>
<p>An integer vector reordering the columns and rows of the 
output.  Omission of a column number will result in omission from the output.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_na.replace">na.replace</code></td>
<td>
<p>A character to replace <code>NA</code> values with.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_diag.replace">diag.replace</code></td>
<td>
<p>A character to replace the diagonal of the mean distance 
matrix.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_print">print</code></td>
<td>
<p>logical.  If <code>TRUE</code> prints to the console.  <code>FALSE</code> 
may be used to extract the invisibly returned output without printing to the 
console.</p>
</td></tr>
<tr><td><code id="print.cm_distance_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.coleman_liau'>Prints an coleman_liau Object</h2><span id='topic+print.coleman_liau'></span>

<h3>Description</h3>

<p>Prints an coleman_liau object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coleman_liau'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.coleman_liau_+3A_x">x</code></td>
<td>
<p>The coleman_liau object.</p>
</td></tr>
<tr><td><code id="print.coleman_liau_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.coleman_liau_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.colsplit2df'>Prints a colsplit2df Object.</h2><span id='topic+print.colsplit2df'></span>

<h3>Description</h3>

<p>Prints a colsplit2df object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'colsplit2df'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.colsplit2df_+3A_x">x</code></td>
<td>
<p>The colsplit2df object</p>
</td></tr>
<tr><td><code id="print.colsplit2df_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.combo_syllable_sum'>Prints an combo_syllable_sum object</h2><span id='topic+print.combo_syllable_sum'></span>

<h3>Description</h3>

<p>Prints an combo_syllable_sum object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'combo_syllable_sum'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.combo_syllable_sum_+3A_x">x</code></td>
<td>
<p>The combo_syllable_sum object</p>
</td></tr>
<tr><td><code id="print.combo_syllable_sum_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_animated_formality'>Prints a cumulative_animated_formality Object</h2><span id='topic+print.cumulative_animated_formality'></span>

<h3>Description</h3>

<p>Prints a cumulative_animated_formality  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_animated_formality'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_animated_formality_+3A_x">x</code></td>
<td>
<p>The cumulative_animated_formality object.</p>
</td></tr>
<tr><td><code id="print.cumulative_animated_formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_animated_lexical_classification'>Prints a cumulative_animated_lexical_classification Object</h2><span id='topic+print.cumulative_animated_lexical_classification'></span>

<h3>Description</h3>

<p>Prints a cumulative_animated_lexical_classification  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_animated_lexical_classification'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_animated_lexical_classification_+3A_x">x</code></td>
<td>
<p>The cumulative_animated_lexical_classification object.</p>
</td></tr>
<tr><td><code id="print.cumulative_animated_lexical_classification_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_animated_polarity'>Prints a cumulative_animated_polarity Object</h2><span id='topic+print.cumulative_animated_polarity'></span>

<h3>Description</h3>

<p>Prints a cumulative_animated_polarity  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_animated_polarity'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_animated_polarity_+3A_x">x</code></td>
<td>
<p>The cumulative_animated_polarity object.</p>
</td></tr>
<tr><td><code id="print.cumulative_animated_polarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_combo_syllable_sum'>Prints a cumulative_combo_syllable_sum Object</h2><span id='topic+print.cumulative_combo_syllable_sum'></span>

<h3>Description</h3>

<p>Prints a cumulative_combo_syllable_sum object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_combo_syllable_sum'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_combo_syllable_sum_+3A_x">x</code></td>
<td>
<p>The cumulative_combo_syllable_sum object.</p>
</td></tr>
<tr><td><code id="print.cumulative_combo_syllable_sum_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_end_mark'>Prints a cumulative_end_mark Object</h2><span id='topic+print.cumulative_end_mark'></span>

<h3>Description</h3>

<p>Prints a cumulative_end_mark  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_end_mark'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_end_mark_+3A_x">x</code></td>
<td>
<p>The cumulative_end_mark object.</p>
</td></tr>
<tr><td><code id="print.cumulative_end_mark_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_formality'>Prints a cumulative_formality Object</h2><span id='topic+print.cumulative_formality'></span>

<h3>Description</h3>

<p>Prints a cumulative_formality  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_formality'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_formality_+3A_x">x</code></td>
<td>
<p>The cumulative_formality object.</p>
</td></tr>
<tr><td><code id="print.cumulative_formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_lexical_classification'>Prints a cumulative_lexical_classification Object</h2><span id='topic+print.cumulative_lexical_classification'></span>

<h3>Description</h3>

<p>Prints a cumulative_lexical_classification  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_lexical_classification'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_lexical_classification_+3A_x">x</code></td>
<td>
<p>The cumulative_lexical_classification object.</p>
</td></tr>
<tr><td><code id="print.cumulative_lexical_classification_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_polarity'>Prints a cumulative_polarity Object</h2><span id='topic+print.cumulative_polarity'></span>

<h3>Description</h3>

<p>Prints a cumulative_polarity  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_polarity'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_polarity_+3A_x">x</code></td>
<td>
<p>The cumulative_polarity object.</p>
</td></tr>
<tr><td><code id="print.cumulative_polarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.cumulative_syllable_freq'>Prints a cumulative_syllable_freqObject</h2><span id='topic+print.cumulative_syllable_freq'></span>

<h3>Description</h3>

<p>Prints a cumulative_syllable_freq object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cumulative_syllable_freq'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cumulative_syllable_freq_+3A_x">x</code></td>
<td>
<p>The cumulative_syllable_freqobject.</p>
</td></tr>
<tr><td><code id="print.cumulative_syllable_freq_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.discourse_map'>Prints a discourse_map Object</h2><span id='topic+print.discourse_map'></span>

<h3>Description</h3>

<p>Prints a discourse_map object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'discourse_map'
print(x, edge.curved = TRUE, title = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.discourse_map_+3A_x">x</code></td>
<td>
<p>The discourse_map object.</p>
</td></tr>
<tr><td><code id="print.discourse_map_+3A_edge.curved">edge.curved</code></td>
<td>
<p>logical.  If <code>TRUE</code> edges are plotted with curves.</p>
</td></tr>
<tr><td><code id="print.discourse_map_+3A_title">title</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="print.discourse_map_+3A_...">...</code></td>
<td>
<p>Other Arguments passed to <code><a href="igraph.html#topic+plot.igraph">plot.igraph</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.Dissimilarity'>Prints a Dissimilarity object</h2><span id='topic+print.Dissimilarity'></span>

<h3>Description</h3>

<p>Prints a Dissimilarity object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Dissimilarity'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.Dissimilarity_+3A_x">x</code></td>
<td>
<p>The Dissimilarity object</p>
</td></tr>
<tr><td><code id="print.Dissimilarity_+3A_digits">digits</code></td>
<td>
<p>Number of decimal places to print.</p>
</td></tr>
<tr><td><code id="print.Dissimilarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.diversity'>Prints a diversity object</h2><span id='topic+print.diversity'></span>

<h3>Description</h3>

<p>Prints a diversity object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'diversity'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.diversity_+3A_x">x</code></td>
<td>
<p>The diversity object</p>
</td></tr>
<tr><td><code id="print.diversity_+3A_digits">digits</code></td>
<td>
<p>Number of decimal places to print.</p>
</td></tr>
<tr><td><code id="print.diversity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.end_mark'>Prints an end_mark object</h2><span id='topic+print.end_mark'></span>

<h3>Description</h3>

<p>Prints an end_mark object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.end_mark_+3A_x">x</code></td>
<td>
<p>The end_mark object</p>
</td></tr>
<tr><td><code id="print.end_mark_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.end_mark_by'>Prints an end_mark_by object</h2><span id='topic+print.end_mark_by'></span>

<h3>Description</h3>

<p>Prints an end_mark_by object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.end_mark_by_+3A_x">x</code></td>
<td>
<p>The end_mark_by object</p>
</td></tr>
<tr><td><code id="print.end_mark_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.end_mark_by_preprocessed'>Prints a end_mark_by_preprocessed object</h2><span id='topic+print.end_mark_by_preprocessed'></span>

<h3>Description</h3>

<p>Prints a end_mark_by_preprocessed object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by_preprocessed'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.end_mark_by_preprocessed_+3A_x">x</code></td>
<td>
<p>The end_mark_by_preprocessed object</p>
</td></tr>
<tr><td><code id="print.end_mark_by_preprocessed_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.flesch_kincaid'>Prints an flesch_kincaid Object</h2><span id='topic+print.flesch_kincaid'></span>

<h3>Description</h3>

<p>Prints an flesch_kincaid object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flesch_kincaid'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.flesch_kincaid_+3A_x">x</code></td>
<td>
<p>The flesch_kincaid object.</p>
</td></tr>
<tr><td><code id="print.flesch_kincaid_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.flesch_kincaid_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.formality'>Prints a formality Object</h2><span id='topic+print.formality'></span>

<h3>Description</h3>

<p>Prints a formality  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality'
print(x, digits, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.formality_+3A_x">x</code></td>
<td>
<p>The formality object.</p>
</td></tr>
<tr><td><code id="print.formality_+3A_digits">digits</code></td>
<td>
<p>The number of digits to print.</p>
</td></tr>
<tr><td><code id="print.formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.formality_scores'>Prints a formality_scores object</h2><span id='topic+print.formality_scores'></span>

<h3>Description</h3>

<p>Prints a formality_scores object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality_scores'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.formality_scores_+3A_x">x</code></td>
<td>
<p>The formality_scores object</p>
</td></tr>
<tr><td><code id="print.formality_scores_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.fry'>Prints an fry Object</h2><span id='topic+print.fry'></span>

<h3>Description</h3>

<p>Prints an fry object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fry'
print(x, digits = 3, auto.label, grid, div.col, plot, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.fry_+3A_x">x</code></td>
<td>
<p>The fry object.</p>
</td></tr>
<tr><td><code id="print.fry_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.fry_+3A_auto.label">auto.label</code></td>
<td>
<p>logical.  If <code>TRUE</code> labels automatically added.  If 
<code>FALSE</code> the user clicks interactively.</p>
</td></tr>
<tr><td><code id="print.fry_+3A_grid">grid</code></td>
<td>
<p>logical.  If <code>TRUE</code> a micro grid is displayed similar to 
Fry's original depiction, though this makes visualizing more difficult.</p>
</td></tr>
<tr><td><code id="print.fry_+3A_div.col">div.col</code></td>
<td>
<p>The color of the grade level division lines.</p>
</td></tr>
<tr><td><code id="print.fry_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> a graph is plotted corresponding to Fry's 
graphic representation.</p>
</td></tr>
<tr><td><code id="print.fry_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.inspect_text'>Prints an inspect_text Object</h2><span id='topic+print.inspect_text'></span>

<h3>Description</h3>

<p>Prints an inspect_text object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'inspect_text'
print(x, file = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.inspect_text_+3A_x">x</code></td>
<td>
<p>The inspect_text object.</p>
</td></tr>
<tr><td><code id="print.inspect_text_+3A_file">file</code></td>
<td>
<p>A connection, or a character string naming the file to print to. If <code>""</code>
(the default), prints to the standard output connection, the console unless redirected 
by <code><a href="base.html#topic+sink">sink</a></code>.</p>
</td></tr>
<tr><td><code id="print.inspect_text_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="base.html#topic+strwrap">strwrap</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.kullback_leibler'>Prints a kullback_leibler Object.</h2><span id='topic+print.kullback_leibler'></span>

<h3>Description</h3>

<p>Prints a kullback_leibler object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kullback_leibler'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.kullback_leibler_+3A_x">x</code></td>
<td>
<p>The kullback_leibler object</p>
</td></tr>
<tr><td><code id="print.kullback_leibler_+3A_digits">digits</code></td>
<td>
<p>Number of decimal places to print.</p>
</td></tr>
<tr><td><code id="print.kullback_leibler_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.lexical_classification'>Prints an lexical_classification Object</h2><span id='topic+print.lexical_classification'></span>

<h3>Description</h3>

<p>Prints an lexical_classification object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.lexical_classification_+3A_x">x</code></td>
<td>
<p>The lexical_classification object.</p>
</td></tr>
<tr><td><code id="print.lexical_classification_+3A_...">...</code></td>
<td>
<p>Other arguments passed to 
<code><a href="#topic+print.lexical_classification_by">print.lexical_classification_by</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.lexical_classification_by'>Prints a lexical_classification Object</h2><span id='topic+print.lexical_classification_by'></span>

<h3>Description</h3>

<p>Prints a lexical_classification_by  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification_by'
print(x, ave.digits = 1, se.digits = 2, trunc = 25, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.lexical_classification_by_+3A_x">x</code></td>
<td>
<p>The lexical_classification_by object.</p>
</td></tr>
<tr><td><code id="print.lexical_classification_by_+3A_ave.digits">ave.digits</code></td>
<td>
<p>The number of average lexical distribution proportion 
digits to print.</p>
</td></tr>
<tr><td><code id="print.lexical_classification_by_+3A_se.digits">se.digits</code></td>
<td>
<p>The number of standard error of the lexical distribution 
proportion digits to print.</p>
</td></tr>
<tr><td><code id="print.lexical_classification_by_+3A_trunc">trunc</code></td>
<td>
<p>The width to truncate content/function word lists.</p>
</td></tr>
<tr><td><code id="print.lexical_classification_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.lexical_classification_preprocessed'>Prints a lexical_classification_preprocessed Object</h2><span id='topic+print.lexical_classification_preprocessed'></span>

<h3>Description</h3>

<p>Prints a lexical_classification_preprocessed object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification_preprocessed'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.lexical_classification_preprocessed_+3A_x">x</code></td>
<td>
<p>The lexical_classification_preprocessed object.</p>
</td></tr>
<tr><td><code id="print.lexical_classification_preprocessed_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.lexical_classification_score'>Prints a lexical_classification_score Object</h2><span id='topic+print.lexical_classification_score'></span>

<h3>Description</h3>

<p>Prints a lexical_classification_score object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification_score'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.lexical_classification_score_+3A_x">x</code></td>
<td>
<p>The lexical_classification_score object.</p>
</td></tr>
<tr><td><code id="print.lexical_classification_score_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.lexical_classification_score_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.linsear_write'>Prints an linsear_write Object</h2><span id='topic+print.linsear_write'></span>

<h3>Description</h3>

<p>Prints an linsear_write object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'linsear_write'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.linsear_write_+3A_x">x</code></td>
<td>
<p>The linsear_write object.</p>
</td></tr>
<tr><td><code id="print.linsear_write_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.linsear_write_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.linsear_write_count'>Prints a linsear_write_count Object</h2><span id='topic+print.linsear_write_count'></span>

<h3>Description</h3>

<p>Prints a linsear_write_count object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'linsear_write_count'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.linsear_write_count_+3A_x">x</code></td>
<td>
<p>The linsear_write_count object.</p>
</td></tr>
<tr><td><code id="print.linsear_write_count_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed.</p>
</td></tr>
<tr><td><code id="print.linsear_write_count_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.linsear_write_scores'>Prints a linsear_write_scores Object</h2><span id='topic+print.linsear_write_scores'></span>

<h3>Description</h3>

<p>Prints a linsear_write_scores object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'linsear_write_scores'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.linsear_write_scores_+3A_x">x</code></td>
<td>
<p>The linsear_write_scores object.</p>
</td></tr>
<tr><td><code id="print.linsear_write_scores_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed.</p>
</td></tr>
<tr><td><code id="print.linsear_write_scores_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.Network'>Prints a Network Object</h2><span id='topic+print.Network'></span>

<h3>Description</h3>

<p>Prints a Network object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Network'
print(
  x,
  title = NA,
  title.color = "black",
  seed = sample(1:10000, 1),
  layout = igraph::layout.auto,
  legend = c(-0.5, -1.5, 0.5, -1.45),
  legend.cex = 1,
  bg = NULL,
  legend.text.color = "black",
  legend.gradient = NULL,
  vertex.color = "grey80",
  vertex.size = 9,
  vertex.frame.color = NA,
  vertex.label.color = "grey40",
  vertex.label.cex = 1.1,
  edge.label.color = "black",
  edge.label.cex = 0.9,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.Network_+3A_x">x</code></td>
<td>
<p>The Network object.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_title">title</code></td>
<td>
<p>The title of the plot.  <code>NULL</code> eliminates title.  <code>NA</code>
uses title attribute of the Network object.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_title.color">title.color</code></td>
<td>
<p>The color of the title.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_seed">seed</code></td>
<td>
<p>The seed to use in plotting the graph.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_layout">layout</code></td>
<td>
<p><span class="pkg">igraph</span> <code>layout</code> to use.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_legend">legend</code></td>
<td>
<p>The coordinates of the legend. See 
<code><a href="plotrix.html#topic+color.legend">color.legend</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_legend.cex">legend.cex</code></td>
<td>
<p>character expansion factor. <code>NULL</code> and <code>NA</code> are 
equivalent to 1.0. See <code><a href="graphics.html#topic+mtext">mtext</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_bg">bg</code></td>
<td>
<p>The color to be used for the background of the device region. See
<code><a href="graphics.html#topic+par">par</a></code> for more information.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_legend.text.color">legend.text.color</code></td>
<td>
<p>The legend text color.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_legend.gradient">legend.gradient</code></td>
<td>
<p>A vector of ordered colors to use for the gradient 
fills in the network edges.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_vertex.color">vertex.color</code></td>
<td>
<p>The font family to be used for vertex labels.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_vertex.size">vertex.size</code></td>
<td>
<p>The size of the vertex.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_vertex.frame.color">vertex.frame.color</code></td>
<td>
<p>The color of the vertex border.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_vertex.label.color">vertex.label.color</code></td>
<td>
<p>The color of the labels.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_vertex.label.cex">vertex.label.cex</code></td>
<td>
<p>The font size for vertex labels.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_edge.label.color">edge.label.color</code></td>
<td>
<p>The color for the edge labels.  Use <code>NA</code> to 
remove.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_edge.label.cex">edge.label.cex</code></td>
<td>
<p>The font size of the edge labels.</p>
</td></tr>
<tr><td><code id="print.Network_+3A_...">...</code></td>
<td>
<p>Other Arguments passed to <code><a href="igraph.html#topic+plot.igraph">plot.igraph</a></code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The output from <code>Network</code> is an <span class="pkg">igraph</span> object and can be
altered and plotted directly using <span class="pkg">igraph</span>.  The <span class="pkg">qdap</span> <code>print</code>
method is offered as a quick approach to styling the figure.  For more control
use <code><a href="igraph.html#topic+V">V</a></code>, <code><a href="igraph.html#topic+E">E</a></code>, and
<code>plot.igraph</code>.
</p>

<hr>
<h2 id='print.ngrams'>Prints an ngrams object</h2><span id='topic+print.ngrams'></span>

<h3>Description</h3>

<p>Prints an ngrams object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ngrams'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ngrams_+3A_x">x</code></td>
<td>
<p>The ngrams object</p>
</td></tr>
<tr><td><code id="print.ngrams_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.object_pronoun_type'>Prints a object_pronoun_type object</h2><span id='topic+print.object_pronoun_type'></span>

<h3>Description</h3>

<p>Prints a object_pronoun_type object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'object_pronoun_type'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.object_pronoun_type_+3A_x">x</code></td>
<td>
<p>The object_pronoun_type object</p>
</td></tr>
<tr><td><code id="print.object_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.phrase_net'>Prints a phrase_net Object</h2><span id='topic+print.phrase_net'></span>

<h3>Description</h3>

<p>Prints a phrase_net object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'phrase_net'
print(x, edge.curved = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.phrase_net_+3A_x">x</code></td>
<td>
<p>The phrase_net object.</p>
</td></tr>
<tr><td><code id="print.phrase_net_+3A_edge.curved">edge.curved</code></td>
<td>
<p>logical.  If <code>TRUE</code> edges are plotted with curves.</p>
</td></tr>
<tr><td><code id="print.phrase_net_+3A_...">...</code></td>
<td>
<p>Other Arguments passed to <code><a href="igraph.html#topic+plot.igraph">plot.igraph</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.polarity'>Prints an polarity Object</h2><span id='topic+print.polarity'></span>

<h3>Description</h3>

<p>Prints an polarity object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.polarity_+3A_x">x</code></td>
<td>
<p>The polarity object.</p>
</td></tr>
<tr><td><code id="print.polarity_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.polarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.polarity_count'>Prints a polarity_count Object</h2><span id='topic+print.polarity_count'></span>

<h3>Description</h3>

<p>Prints a polarity_count object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity_count'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.polarity_count_+3A_x">x</code></td>
<td>
<p>The polarity_count object.</p>
</td></tr>
<tr><td><code id="print.polarity_count_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed.</p>
</td></tr>
<tr><td><code id="print.polarity_count_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.polarity_score'>Prints a polarity_score Object</h2><span id='topic+print.polarity_score'></span>

<h3>Description</h3>

<p>Prints a polarity_score object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity_score'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.polarity_score_+3A_x">x</code></td>
<td>
<p>The polarity_score object.</p>
</td></tr>
<tr><td><code id="print.polarity_score_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.polarity_score_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.polysyllable_sum'>Prints an polysyllable_sum object</h2><span id='topic+print.polysyllable_sum'></span>

<h3>Description</h3>

<p>Prints an polysyllable_sum object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polysyllable_sum'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.polysyllable_sum_+3A_x">x</code></td>
<td>
<p>The polysyllable_sum object</p>
</td></tr>
<tr><td><code id="print.polysyllable_sum_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.pos'>Prints a pos Object.</h2><span id='topic+print.pos'></span>

<h3>Description</h3>

<p>Prints a pos object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos'
print(x, digits = 1, percent = NULL, zero.replace = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pos_+3A_x">x</code></td>
<td>
<p>The pos object</p>
</td></tr>
<tr><td><code id="print.pos_+3A_digits">digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed.</p>
</td></tr>
<tr><td><code id="print.pos_+3A_percent">percent</code></td>
<td>
<p>logical.  If TRUE output given as percent.  If FALSE the 
output is proportion.  If NULL uses the value from 
<code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="print.pos_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If NULL uses the value 
from <code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="print.pos_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.pos_by'>Prints a pos_by Object.</h2><span id='topic+print.pos_by'></span>

<h3>Description</h3>

<p>Prints a pos_by object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos_by'
print(x, digits = 1, percent = NULL, zero.replace = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pos_by_+3A_x">x</code></td>
<td>
<p>The pos_by object</p>
</td></tr>
<tr><td><code id="print.pos_by_+3A_digits">digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed.</p>
</td></tr>
<tr><td><code id="print.pos_by_+3A_percent">percent</code></td>
<td>
<p>logical.  If TRUE output given as percent.  If FALSE the 
output is proportion.  If NULL uses the value from 
<code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="print.pos_by_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If NULL uses the value 
from <code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="print.pos_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.pos_preprocessed'>Prints a pos_preprocessed object</h2><span id='topic+print.pos_preprocessed'></span>

<h3>Description</h3>

<p>Prints a pos_preprocessed object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos_preprocessed'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pos_preprocessed_+3A_x">x</code></td>
<td>
<p>The pos_preprocessed object</p>
</td></tr>
<tr><td><code id="print.pos_preprocessed_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.pronoun_type'>Prints a pronoun_type object</h2><span id='topic+print.pronoun_type'></span>

<h3>Description</h3>

<p>Prints a pronoun_type object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pronoun_type'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pronoun_type_+3A_x">x</code></td>
<td>
<p>The pronoun_type object</p>
</td></tr>
<tr><td><code id="print.pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.qdap_context'>Prints a qdap_context object</h2><span id='topic+print.qdap_context'></span>

<h3>Description</h3>

<p>Prints a qdap_context object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qdap_context'
print(
  x,
  file = NULL,
  pretty = TRUE,
  width = 70,
  sep.block = TRUE,
  double_space = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.qdap_context_+3A_x">x</code></td>
<td>
<p>The qdap_context object</p>
</td></tr>
<tr><td><code id="print.qdap_context_+3A_file">file</code></td>
<td>
<p>The name of the file (can print csv, xlsx, txt, doc and other 
text based files).  If <code>NULL</code> file prints to the console.</p>
</td></tr>
<tr><td><code id="print.qdap_context_+3A_pretty">pretty</code></td>
<td>
<p>logical.  If <code>TRUE</code> generates a prettier text version of 
the output (cannot be used with csv/xlsx file types).  If <code>FALSE</code> a
semi-structured dataframe is generated.</p>
</td></tr>
<tr><td><code id="print.qdap_context_+3A_width">width</code></td>
<td>
<p>A positive integer giving the target column for wrapping lines 
in the output.</p>
</td></tr>
<tr><td><code id="print.qdap_context_+3A_sep.block">sep.block</code></td>
<td>
<p>logical.  If <code>TRUE</code> the blocked events are separated 
with text lines.</p>
</td></tr>
<tr><td><code id="print.qdap_context_+3A_double_space">double_space</code></td>
<td>
<p>logical.  If <code>TRUE</code> and <code>pretty = TRUE</code> 
double spacing between speech chunks (speakers) is used.</p>
</td></tr>
<tr><td><code id="print.qdap_context_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.qdapProj'>Prints a qdapProj Object</h2><span id='topic+print.qdapProj'></span>

<h3>Description</h3>

<p>Prints a qdapProj object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qdapProj'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.qdapProj_+3A_x">x</code></td>
<td>
<p>The qdapProj object.</p>
</td></tr>
<tr><td><code id="print.qdapProj_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.question_type'>Prints a question_type object</h2><span id='topic+print.question_type'></span>

<h3>Description</h3>

<p>Prints a question_type object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'question_type'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.question_type_+3A_x">x</code></td>
<td>
<p>The question_type object</p>
</td></tr>
<tr><td><code id="print.question_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.question_type_preprocessed'>Prints a question_type_preprocessed object</h2><span id='topic+print.question_type_preprocessed'></span>

<h3>Description</h3>

<p>Prints a question_type_preprocessed object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'question_type_preprocessed'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.question_type_preprocessed_+3A_x">x</code></td>
<td>
<p>The question_type_preprocessed object</p>
</td></tr>
<tr><td><code id="print.question_type_preprocessed_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.readability_count'>Prints a readability_count Object</h2><span id='topic+print.readability_count'></span>

<h3>Description</h3>

<p>Prints a readability_count object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'readability_count'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.readability_count_+3A_x">x</code></td>
<td>
<p>The readability_count object.</p>
</td></tr>
<tr><td><code id="print.readability_count_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed.</p>
</td></tr>
<tr><td><code id="print.readability_count_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.readability_score'>Prints a readability_score Object</h2><span id='topic+print.readability_score'></span>

<h3>Description</h3>

<p>Prints a readability_score object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'readability_score'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.readability_score_+3A_x">x</code></td>
<td>
<p>The readability_score object.</p>
</td></tr>
<tr><td><code id="print.readability_score_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.readability_score_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.sent_split'>Prints a sent_split object</h2><span id='topic+print.sent_split'></span>

<h3>Description</h3>

<p>Prints a sent_split object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sent_split'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sent_split_+3A_x">x</code></td>
<td>
<p>The sent_split object</p>
</td></tr>
<tr><td><code id="print.sent_split_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.SMOG'>Prints an SMOG Object</h2><span id='topic+print.SMOG'></span>

<h3>Description</h3>

<p>Prints an SMOG object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SMOG'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.SMOG_+3A_x">x</code></td>
<td>
<p>The SMOG object.</p>
</td></tr>
<tr><td><code id="print.SMOG_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.SMOG_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.sub_holder'>Prints a sub_holder object</h2><span id='topic+print.sub_holder'></span>

<h3>Description</h3>

<p>Prints a sub_holder object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sub_holder'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sub_holder_+3A_x">x</code></td>
<td>
<p>The sub_holder object</p>
</td></tr>
<tr><td><code id="print.sub_holder_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.subject_pronoun_type'>Prints a subject_pronoun_type object</h2><span id='topic+print.subject_pronoun_type'></span>

<h3>Description</h3>

<p>Prints a subject_pronoun_type object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subject_pronoun_type'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.subject_pronoun_type_+3A_x">x</code></td>
<td>
<p>The subject_pronoun_type object</p>
</td></tr>
<tr><td><code id="print.subject_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.sum_cmspans'>Prints a sum_cmspans object</h2><span id='topic+print.sum_cmspans'></span>

<h3>Description</h3>

<p>Prints a sum_cmspans object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sum_cmspans'
print(x, digits = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sum_cmspans_+3A_x">x</code></td>
<td>
<p>The sum_cmspans object</p>
</td></tr>
<tr><td><code id="print.sum_cmspans_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round in the display of 
the output.</p>
</td></tr>
<tr><td><code id="print.sum_cmspans_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.sums_gantt'>Prints a sums_gantt object</h2><span id='topic+print.sums_gantt'></span>

<h3>Description</h3>

<p>Prints a sums_gantt object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sums_gantt'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sums_gantt_+3A_x">x</code></td>
<td>
<p>The sums_gantt object</p>
</td></tr>
<tr><td><code id="print.sums_gantt_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.syllable_sum'>Prints an syllable_sum object</h2><span id='topic+print.syllable_sum'></span>

<h3>Description</h3>

<p>Prints an syllable_sum object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'syllable_sum'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.syllable_sum_+3A_x">x</code></td>
<td>
<p>The syllable_sum object</p>
</td></tr>
<tr><td><code id="print.syllable_sum_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.table_count'>Prints a table_count object</h2><span id='topic+print.table_count'></span>

<h3>Description</h3>

<p>Prints a table_count object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'table_count'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.table_count_+3A_x">x</code></td>
<td>
<p>The table_count object</p>
</td></tr>
<tr><td><code id="print.table_count_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.table_proportion'>Prints a table_proportion object</h2><span id='topic+print.table_proportion'></span>

<h3>Description</h3>

<p>Prints a table_proportion object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'table_proportion'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.table_proportion_+3A_x">x</code></td>
<td>
<p>The table_proportion object</p>
</td></tr>
<tr><td><code id="print.table_proportion_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.table_score'>Prints a table_score object</h2><span id='topic+print.table_score'></span>

<h3>Description</h3>

<p>Prints a table_score object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'table_score'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.table_score_+3A_x">x</code></td>
<td>
<p>The table_score object</p>
</td></tr>
<tr><td><code id="print.table_score_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.termco'>Prints a termco object.</h2><span id='topic+print.termco'></span>

<h3>Description</h3>

<p>Prints a termco object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'termco'
print(x, digits = NULL, percent = NULL, zero.replace = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.termco_+3A_x">x</code></td>
<td>
<p>The termco object</p>
</td></tr>
<tr><td><code id="print.termco_+3A_digits">digits</code></td>
<td>
<p>Integer values specifying the number of digits to be 
printed.</p>
</td></tr>
<tr><td><code id="print.termco_+3A_percent">percent</code></td>
<td>
<p>logical.  If TRUE output given as percent.  If FALSE the 
output is proportion.  If NULL uses the value from 
<code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="print.termco_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.  If NULL uses the value 
from <code><a href="#topic+termco">termco</a></code>.  Only used if <code>label</code> is TRUE.</p>
</td></tr>
<tr><td><code id="print.termco_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.trunc'>Prints a trunc object</h2><span id='topic+print.trunc'></span>

<h3>Description</h3>

<p>Prints a trunc object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trunc'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.trunc_+3A_x">x</code></td>
<td>
<p>The trunc object</p>
</td></tr>
<tr><td><code id="print.trunc_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.type_token_ratio'>Prints a type_token_ratio Object</h2><span id='topic+print.type_token_ratio'></span>

<h3>Description</h3>

<p>Prints a type_token_ratio  object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'type_token_ratio'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.type_token_ratio_+3A_x">x</code></td>
<td>
<p>The type_token_ratio object.</p>
</td></tr>
<tr><td><code id="print.type_token_ratio_+3A_digits">digits</code></td>
<td>
<p>The number of type-token ratio digits to print.</p>
</td></tr>
<tr><td><code id="print.type_token_ratio_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.wfm'>Prints a wfm Object</h2><span id='topic+print.wfm'></span>

<h3>Description</h3>

<p>Prints a wfm object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wfm'
print(x, digits = 3, width = 10000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.wfm_+3A_x">x</code></td>
<td>
<p>The wfm object.</p>
</td></tr>
<tr><td><code id="print.wfm_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="print.wfm_+3A_width">width</code></td>
<td>
<p>The width to temporarily set for printing (default = 10000).
See <code><a href="base.html#topic+options">options</a></code> for more.</p>
</td></tr>
<tr><td><code id="print.wfm_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.wfm_summary'>Prints a wfm_summary Object</h2><span id='topic+print.wfm_summary'></span>

<h3>Description</h3>

<p>Prints a wfm_summary object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wfm_summary'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.wfm_summary_+3A_x">x</code></td>
<td>
<p>The wfm_summary object.</p>
</td></tr>
<tr><td><code id="print.wfm_summary_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.which_misspelled'>Prints a which_misspelled Object</h2><span id='topic+print.which_misspelled'></span>

<h3>Description</h3>

<p>Prints a which_misspelled object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'which_misspelled'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.which_misspelled_+3A_x">x</code></td>
<td>
<p>The which_misspelled object.</p>
</td></tr>
<tr><td><code id="print.which_misspelled_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.word_associate'>Prints a word_associate object</h2><span id='topic+print.word_associate'></span>

<h3>Description</h3>

<p>Prints a word_associate object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_associate'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.word_associate_+3A_x">x</code></td>
<td>
<p>The word_associate object</p>
</td></tr>
<tr><td><code id="print.word_associate_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.word_cor'>Prints a word_cor object</h2><span id='topic+print.word_cor'></span>

<h3>Description</h3>

<p>Prints a word_cor object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_cor'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.word_cor_+3A_x">x</code></td>
<td>
<p>The word_cor object</p>
</td></tr>
<tr><td><code id="print.word_cor_+3A_digits">digits</code></td>
<td>
<p>The number of digits to print</p>
</td></tr>
<tr><td><code id="print.word_cor_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.word_length'>Prints a word_length object</h2><span id='topic+print.word_length'></span>

<h3>Description</h3>

<p>Prints a word_length object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_length'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.word_length_+3A_x">x</code></td>
<td>
<p>The word_length object</p>
</td></tr>
<tr><td><code id="print.word_length_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.word_list'>Prints a word_list Object</h2><span id='topic+print.word_list'></span>

<h3>Description</h3>

<p>Prints a word_list object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_list'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.word_list_+3A_x">x</code></td>
<td>
<p>The word_list object</p>
</td></tr>
<tr><td><code id="print.word_list_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.word_position'>Prints a word_position object.</h2><span id='topic+print.word_position'></span>

<h3>Description</h3>

<p>Prints a word_position object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_position'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.word_position_+3A_x">x</code></td>
<td>
<p>The word_position object</p>
</td></tr>
<tr><td><code id="print.word_position_+3A_...">...</code></td>
<td>
<p>Values passed to <code>plot.word_position</code></p>
</td></tr>
</table>

<hr>
<h2 id='print.word_proximity'>Prints a word_proximity object</h2><span id='topic+print.word_proximity'></span>

<h3>Description</h3>

<p>Prints a word_proximity object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_proximity'
print(x, digits = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.word_proximity_+3A_x">x</code></td>
<td>
<p>The word_proximity object</p>
</td></tr>
<tr><td><code id="print.word_proximity_+3A_digits">digits</code></td>
<td>
<p>The number of digits to print</p>
</td></tr>
<tr><td><code id="print.word_proximity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.word_stats'>Prints a word_stats object</h2><span id='topic+print.word_stats'></span>

<h3>Description</h3>

<p>Prints a word_stats object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_stats'
print(x, digits = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.word_stats_+3A_x">x</code></td>
<td>
<p>The word_stats object</p>
</td></tr>
<tr><td><code id="print.word_stats_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round in the display of 
the output.</p>
</td></tr>
<tr><td><code id="print.word_stats_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='print.word_stats_counts'>Prints a word_stats_counts object</h2><span id='topic+print.word_stats_counts'></span>

<h3>Description</h3>

<p>Prints a word_stats_counts object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_stats_counts'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.word_stats_counts_+3A_x">x</code></td>
<td>
<p>The word_stats_counts object</p>
</td></tr>
<tr><td><code id="print.word_stats_counts_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>

<hr>
<h2 id='pronoun_type'>Count Object/Subject Pronouns Per Grouping Variable</h2><span id='topic+pronoun_type'></span>

<h3>Description</h3>

<p>Count the number of subject/object pronouns per grouping variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pronoun_type(text.var, grouping.var = NULL, pronoun.list = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pronoun_type_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="pronoun_type_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="pronoun_type_+3A_pronoun.list">pronoun.list</code></td>
<td>
<p>A named list of subject/object pronouns.  See 
<strong>Details</strong> for more.</p>
</td></tr>
<tr><td><code id="pronoun_type_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+termco">termco</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following subject/object pronoun categories are the default searched terms:
</p>

<ul>
<li><p> I = c(&quot; i'd &quot;, &quot; i'll &quot;, &quot; i'm &quot;, &quot; i've &quot;, &quot; i &quot;)
</p>
</li>
<li><p> we = c(&quot; we'd &quot;, &quot; we'll &quot;, &quot; we're &quot;, &quot; we've &quot;, &quot; we &quot;)
</p>
</li>
<li><p> you = c(&quot; you'd &quot;,  &quot; you'll &quot;, &quot; you're &quot;, &quot; you've &quot;, &quot; you &quot;, &quot; your &quot;)
</p>
</li>
<li><p> he = c(&quot; he'd &quot;, &quot; he'll &quot;, &quot; he's &quot;, &quot; he &quot;)
</p>
</li>
<li><p> she = c(&quot; she'd &quot;, &quot; she'll &quot;, &quot; she's &quot;, &quot; she &quot;)
</p>
</li>
<li><p> they = c(&quot; they'd &quot;, &quot; they'll &quot;, &quot; they're &quot;, &quot;they've &quot;, &quot; they &quot;)
</p>
</li>
<li><p> it = c(&quot; it'd &quot;, &quot; it'll &quot;, &quot; it's &quot;, &quot; it &quot;)
</p>
</li>
<li><p> me = c(&quot; me &quot;, &quot; my &quot;, &quot; mine &quot;)
</p>
</li>
<li><p> us = c(&quot; us &quot;, &quot; our &quot;, &quot; ours &quot;)
</p>
</li>
<li><p> him = c(&quot; him &quot;, &quot; his &quot;)
</p>
</li>
<li><p> her = c(&quot; her &quot;, &quot; hers &quot;)
</p>
</li>
<li><p> them = c(&quot; them &quot;)
</p>
</li>
<li><p> their = c(&quot; their &quot;, &quot;theirs &quot;)
</p>
</li></ul>



<h3>Value</h3>

<p>Returns a list, of class &quot;pronoun_type&quot;, of data frames 
regarding subject/object pronoun word counts:
</p>
<table>
<tr><td><code>preprocessed</code></td>
<td>
<p>List of uncollapsed dataframes (raw, prop, rnp) of the class &quot;termco&quot; that contain all searchable subject/object pronouns.</p>
</td></tr> 
<tr><td><code>raw</code></td>
<td>
<p>raw word counts by grouping variable</p>
</td></tr> 
<tr><td><code>prop</code></td>
<td>
<p>proportional word counts by grouping variable; proportional to 
each individual's subject/object pronoun use</p>
</td></tr> 
<tr><td><code>rnp</code></td>
<td>
<p>a character combination data frame of raw and proportional subject/object pronoun use</p>
</td></tr>
</table>


<h3>References</h3>

<p>Fairclough, N. (1989). Language and power. London: Longman. <br />
</p>
<p>Fairclough, N. (2003). Analysing discourse: Textual analysis for social 
research. Oxford and New York: Routledge.<br /> 
</p>
<p>Okamura, A. (2009). Use of personal pronouns in two types of monologic 
academic speech.  The Economic Journal of Takasaki City University of 
Economics, 52(1). 17-26. <br />
</p>
<p>Us and them: Social categorization and the process of intergroup bias. 
Perdue, C. W., Dovidio, J. F., Gurtman, M. B., &amp; Tyler, R. B. (1990). Journal 
of Personality and Social Psychology, 59(3), 475-486. 
doi: 10.1037/0022-3514.59.3.475
</p>


<h3>See Also</h3>

<p><code><a href="#topic+object_pronoun_type">object_pronoun_type</a></code>,
<code><a href="#topic+subject_pronoun_type">subject_pronoun_type</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- pres_debates2012
dat &lt;- dat[dat$person %in% qcv(ROMNEY, OBAMA), ]
(out &lt;- pronoun_type(dat$dialogue, dat$person))
plot(out)
plot(out, 2)
plot(out, 3)
plot(out, 3, ncol=2)

scores(out)
counts(out)
proportions(out)
preprocessed(out)

plot(scores(out))
plot(counts(out))
plot(proportions(out))

(out2 &lt;- pronoun_type(hamlet$dialogue, hamlet$person))
plot(out2, 3, ncol=7)

## End(Not run)
</code></pre>

<hr>
<h2 id='prop'>Convert Raw Numeric Matrix or Data Frame to Proportions</h2><span id='topic+prop'></span>

<h3>Description</h3>

<p>Convert a raw matrix or dataframe to proportions/percents.  Divides each 
element of a column by the column sum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prop(mat, digits = 2, percent = FALSE, by.column = TRUE, round = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prop_+3A_mat">mat</code></td>
<td>
<p>A numeric matrix or dataframe.</p>
</td></tr>
<tr><td><code id="prop_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round.</p>
</td></tr>
<tr><td><code id="prop_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="prop_+3A_by.column">by.column</code></td>
<td>
<p>logical.  If <code>TRUE</code> applies to the column.  If 
<code>FALSE</code> applies by row.</p>
</td></tr>
<tr><td><code id="prop_+3A_round">round</code></td>
<td>
<p>logical.  If <code>TRUE</code> rounds the returned values (controlled 
by digits).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix with proportionally scaled values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
y &lt;- wfdf(DATA$state, DATA$person, stopwords = c("your", "yours"), 
    margins = TRUE)
prop(wfm(y), 4)[1:10, ]        #as a proportion
prop(wfm(y), 4, TRUE)[1:10, ]  #as a percentage
heatmap(prop(wfm(y), 4))
wdstraj &lt;- word_stats(rajSPLIT$dialogue, rajSPLIT$person)
prop(wdstraj$gts[, -1], 5)[1:15, 1:6]

## End(Not run)
</code></pre>

<hr>
<h2 id='proportions'>Generic Proportions Method</h2><span id='topic+proportions'></span>

<h3>Description</h3>

<p>Access the proportions dataframes from select qdap outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions_+3A_x">x</code></td>
<td>
<p>A qdap object (list) with a proportions dataframe (e.g., 
<code><a href="#topic+termco">termco</a></code>).</p>
</td></tr>
<tr><td><code id="proportions_+3A_...">...</code></td>
<td>
<p>Arguments passed to proportions method of other classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data.frame of proportions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scores">scores</a></code>,
<code><a href="#topic+counts">counts</a></code>,
<code><a href="#topic+preprocessed">preprocessed</a></code>,
<code><a href="#topic+visual">visual</a></code>
</p>

<hr>
<h2 id='proportions.character_table'>Term Counts</h2><span id='topic+proportions.character_table'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+character_table">character_table</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'character_table'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.character_table_+3A_x">x</code></td>
<td>
<p>The character_table object.</p>
</td></tr>
<tr><td><code id="proportions.character_table_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>character_table Method for proportions
</p>

<hr>
<h2 id='proportions.end_mark_by'>Question Counts</h2><span id='topic+proportions.end_mark_by'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+end_mark_by">end_mark_by</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.end_mark_by_+3A_x">x</code></td>
<td>
<p>The end_mark_by object.</p>
</td></tr>
<tr><td><code id="proportions.end_mark_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>end_mark_by Method for proportions
</p>

<hr>
<h2 id='proportions.formality'>Formality</h2><span id='topic+proportions.formality'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+formality">formality</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.formality_+3A_x">x</code></td>
<td>
<p>The formality object.</p>
</td></tr>
<tr><td><code id="proportions.formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>formality Method for proportions
</p>

<hr>
<h2 id='proportions.object_pronoun_type'>Question Counts</h2><span id='topic+proportions.object_pronoun_type'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+object_pronoun_type">object_pronoun_type</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'object_pronoun_type'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.object_pronoun_type_+3A_x">x</code></td>
<td>
<p>The object_pronoun_type object.</p>
</td></tr>
<tr><td><code id="proportions.object_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>object_pronoun_type Method for proportions
</p>

<hr>
<h2 id='proportions.pos'>Parts of Speech</h2><span id='topic+proportions.pos'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+pos">pos</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.pos_+3A_x">x</code></td>
<td>
<p>The pos object.</p>
</td></tr>
<tr><td><code id="proportions.pos_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pos Method for proportions
</p>

<hr>
<h2 id='proportions.pos_by'>Parts of Speech</h2><span id='topic+proportions.pos_by'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+pos_by">pos_by</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos_by'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.pos_by_+3A_x">x</code></td>
<td>
<p>The pos_by object.</p>
</td></tr>
<tr><td><code id="proportions.pos_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pos_by Method for proportions
</p>

<hr>
<h2 id='proportions.pronoun_type'>Question Counts</h2><span id='topic+proportions.pronoun_type'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+pronoun_type">pronoun_type</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pronoun_type'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.pronoun_type_+3A_x">x</code></td>
<td>
<p>The pronoun_type object.</p>
</td></tr>
<tr><td><code id="proportions.pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pronoun_type Method for proportions
</p>

<hr>
<h2 id='proportions.question_type'>Question Counts</h2><span id='topic+proportions.question_type'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+question_type">question_type</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'question_type'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.question_type_+3A_x">x</code></td>
<td>
<p>The question_type object.</p>
</td></tr>
<tr><td><code id="proportions.question_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>question_type Method for proportions
</p>

<hr>
<h2 id='proportions.subject_pronoun_type'>Question Counts</h2><span id='topic+proportions.subject_pronoun_type'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+subject_pronoun_type">subject_pronoun_type</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subject_pronoun_type'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.subject_pronoun_type_+3A_x">x</code></td>
<td>
<p>The subject_pronoun_type object.</p>
</td></tr>
<tr><td><code id="proportions.subject_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>subject_pronoun_type Method for proportions
</p>

<hr>
<h2 id='proportions.termco'>Term Counts</h2><span id='topic+proportions.termco'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+termco">termco</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'termco'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.termco_+3A_x">x</code></td>
<td>
<p>The termco object.</p>
</td></tr>
<tr><td><code id="proportions.termco_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>termco Method for proportions
</p>

<hr>
<h2 id='proportions.word_length'>Word Length Counts</h2><span id='topic+proportions.word_length'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+word_length">word_length</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_length'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.word_length_+3A_x">x</code></td>
<td>
<p>The word_length object.</p>
</td></tr>
<tr><td><code id="proportions.word_length_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>word_length Method for proportions
</p>

<hr>
<h2 id='proportions.word_position'>Word Position</h2><span id='topic+proportions.word_position'></span>

<h3>Description</h3>

<p>View <code><a href="#topic+word_position">word_position</a></code> proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_position'
proportions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportions.word_position_+3A_x">x</code></td>
<td>
<p>The word_position object.</p>
</td></tr>
<tr><td><code id="proportions.word_position_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>word_position Method for proportions
</p>

<hr>
<h2 id='qcombine'>Combine Columns</h2><span id='topic+qcombine'></span>

<h3>Description</h3>

<p>Quickly combine columns (summed) and rename.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qcombine(mat, combined.columns, elim.old = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qcombine_+3A_mat">mat</code></td>
<td>
<p>A matrix or dataframe with numeric combine columns.</p>
</td></tr>
<tr><td><code id="qcombine_+3A_combined.columns">combined.columns</code></td>
<td>
<p>A list of named vectors of the colnames/indexes 
of the numeric columns to be combined (summed).  If a vector is unnamed a 
name will be assigned.</p>
</td></tr>
<tr><td><code id="qcombine_+3A_elim.old">elim.old</code></td>
<td>
<p>logical.  If <code>TRUE</code> eliminates the columns that are 
combined together by the named match.list. <code>TRUE</code> outputs the table 
proportionally (see <code><a href="#topic+prop">prop</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with combines columns.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+transform">transform</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- list(
    a = c(1, 2, 3),
    b = qcv(mpg, hp),
    c = c("disp", "am")
)
B &lt;- list(
    c(1, 2, 3),
    d = qcv(mpg, hp),
    c("disp", "am")
)

qcombine(head(mtcars), A)
qcombine(head(mtcars), B)
qcombine(head(mtcars), B, elim.old = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='qcv'>Quick Character Vector</h2><span id='topic+qcv'></span>

<h3>Description</h3>

<p>Create a character vector without the use of quotation marks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qcv(
  ...,
  terms = NULL,
  space.wrap = FALSE,
  trailing = FALSE,
  leading = FALSE,
  split = " ",
  rm.blank = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qcv_+3A_terms">terms</code></td>
<td>
<p>An optional argument to present the terms as one long character 
string.  This is useful if the split (separator) is not a comma (e.g., spaces 
are the term separators).</p>
</td></tr>
<tr><td><code id="qcv_+3A_space.wrap">space.wrap</code></td>
<td>
<p>logical.  If <code>TRUE</code> wraps the vector of terms with a 
leading/trailing space.</p>
</td></tr>
<tr><td><code id="qcv_+3A_trailing">trailing</code></td>
<td>
<p>logical.  If <code>TRUE</code> wraps the vector of terms with a 
trailing space.</p>
</td></tr>
<tr><td><code id="qcv_+3A_leading">leading</code></td>
<td>
<p>logical.  If <code>TRUE</code> wraps the vector of terms with a 
leading space.</p>
</td></tr>
<tr><td><code id="qcv_+3A_split">split</code></td>
<td>
<p>Character vector of length one to use for splitting (i.e., the 
separator used in the vector).  For use with the argument <code>terms</code>.</p>
</td></tr>
<tr><td><code id="qcv_+3A_rm.blank">rm.blank</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes all blank spaces from the 
vector.</p>
</td></tr>
<tr><td><code id="qcv_+3A_...">...</code></td>
<td>
<p>Character objects. Either ... or <code>terms</code> argument must 
be utilized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+c">c</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
qcv(I, like, dogs)
qcv(terms = "I, like, dogs") #default separator is " "
qcv(terms = "I, like, dogs", split = ",")
qcv(terms = "I  like dogs")
qcv(I, like, dogs, space.wrap = TRUE)
qcv(I, like, dogs, trailing = TRUE)
qcv(I, like, dogs, leading = TRUE)
exclude(Top25Words, qcv(the, of, and))
qcv(terms = "mpg cyl  disp  hp drat    wt  qsec vs am gear carb")

## End(Not run)
</code></pre>

<hr>
<h2 id='qdap'>qdap: Quantitative Discourse Analysis Package</h2><span id='topic+qdap'></span><span id='topic+package-qdap'></span>

<h3>Description</h3>

<p>This package automates many of the tasks associated with quantitative 
discourse analysis of transcripts containing discourse.  The package 
provides parsing tools for preparing transcript data, coding tools and 
analysis tools for richer understanding of the data.  Many functions 
allow the user to aggregate data by any number of grouping variables, 
providing analysis and seamless integration with other R packages which 
enable higher level analysis and visualization of text.  This empowers 
the researcher with more flexible, efficient and targeted methods and tools.
</p>

<hr>
<h2 id='qdap_df'>Create qdap Specific Data Structure</h2><span id='topic+qdap_df'></span><span id='topic+Text'></span><span id='topic+Text+3C-'></span>

<h3>Description</h3>

<p>Creating this <span class="pkg">qdap</span> specific data structure enables short hand with 
subsequent <span class="pkg">qdap</span> function calls that utilize the <code>text.var</code> 
argument.  Combined with the <code><a href="#topic++25+26+25">%&amp;%</a></code> operator, the user n
need not specify a data set or the <code>text.var</code> argument (as many 
<span class="pkg">qdap</span> functions contain a <code>text.var</code> argument).
</p>
<p>Change text.var column of a qdap_df object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qdap_df(dataframe, text.var)

Text(object)

Text(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qdap_df_+3A_dataframe">dataframe</code></td>
<td>
<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> with a text variable.
Generally, <code><a href="#topic+sentSplit">sentSplit</a></code> should be run first 
(<code><a href="#topic+sentSplit">sentSplit</a></code> actually produces a 
<code><a href="base.html#topic+data.frame">data.frame</a></code> that is of the class <code>"qdap_df"</code>).</p>
</td></tr>
<tr><td><code id="qdap_df_+3A_text.var">text.var</code></td>
<td>
<p>The name of the <code>text.var</code> column.</p>
</td></tr>
<tr><td><code id="qdap_df_+3A_object">object</code></td>
<td>
<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> of the class <code>"qdap_df"</code>.</p>
</td></tr>
<tr><td><code id="qdap_df_+3A_value">value</code></td>
<td>
<p>A character string of the updated <code>text.var</code> column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code><a href="base.html#topic+data.frame">data.frame</a></code> of the class <code>"qdap_df"</code>.
</p>


<h3>References</h3>

<p>Inspired by <span class="pkg">dplyr</span>'s <code><a href="dplyr.html#topic+tbl_df">tbl_df</a></code> structure.
</p>


<h3>See Also</h3>

<p><code><a href="#topic++25+26+25">%&amp;%</a></code>,
<code><a href="#topic+sentSplit">sentSplit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- qdap_df(DATA, state)
dat %&amp;% trans_cloud(grouping.var=person)
dat %&amp;% trans_cloud(grouping.var=person, text.var=stemmer(DATA$state))
dat %&amp;% termco(grouping.var=person, match.list=list("fun", "computer"))
class(dat)

## Change text column in `qdap_df` (Example 1)
dat2 &lt;- sentSplit(DATA, "state", stem.col = TRUE)
class(dat2)
dat2 %&amp;% trans_cloud()
Text(dat2)
## change the `text.var` column
Text(dat2) &lt;- "stem.text"
dat2 %&amp;% trans_cloud()

## Change text column in `qdap_df` (Example 2)
(dat2$fake_dat &lt;- paste(emoticon[1:11,2], dat2$state))
Text(dat2) &lt;- "fake_dat"
(m &lt;- dat2 %&amp;% sub_holder(emoticon[,2]))
m$unhold(strip(m$output))

## Various examples with qdap functions
dat &lt;- sentSplit(DATA, "state")
dat %&amp;% trans_cloud(grouping.var=person)
dat %&amp;% termco(person, match.list=list("fun", "computer"))
dat %&amp;% trans_venn(person)
dat %&amp;% polarity(person)
dat %&amp;% formality(person)
dat %&amp;% automated_readability_index(person)
dat %&amp;% Dissimilarity(person)
dat %&amp;% gradient_cloud(sex)
dat %&amp;% dispersion_plot(c("fun", "computer"))
dat %&amp;% discourse_map(list(sex, adult))
dat %&amp;% gantt_plot(person)
dat %&amp;% word_list(adult)
dat %&amp;% end_mark_by(person)
dat %&amp;% end_mark()
dat %&amp;% word_stats(person)
dat %&amp;% wfm(person)
dat %&amp;% word_cor(person, "i")
dat %&amp;% sentCombine(person)
dat %&amp;% question_type(person)
dat %&amp;% word_network_plot()
dat %&amp;% character_count()
dat %&amp;% char_table(person)
dat %&amp;% phrase_net(2, .1)
dat %&amp;% boolean_search("it||!")
dat %&amp;% trans_context(person, which(end_mark(DATA.SPLIT[, "state"]) == "?"))
dat %&amp;% mgsub(c("it's", "I'm"), c("it is", "I am"))

## combine with magrittr/dplyr chaining
dat %&amp;% wfm(person) %&gt;% plot()
dat %&amp;% polarity(person) %&gt;% scores()
dat %&amp;% polarity(person) %&gt;% counts()
dat %&amp;% polarity(person) %&gt;% scores()
dat %&amp;% polarity(person) %&gt;% scores() %&gt;% plot()
dat %&amp;% polarity(person) %&gt;% scores %&gt;% plot

## End(Not run)
</code></pre>

<hr>
<h2 id='qheat'>Quick Heatmap</h2><span id='topic+qheat'></span><span id='topic+qheat.default'></span><span id='topic+qheat.diversity'></span><span id='topic+qheat.termco'></span><span id='topic+qheat.word_stats'></span><span id='topic+qheat.character_table'></span><span id='topic+qheat.question_type'></span><span id='topic+qheat.pos_by'></span>

<h3>Description</h3>

<p>A quick heatmap function for visualizing typical qdap dataframe/matrix 
outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qheat(
  mat,
  low = "white",
  high = "darkblue",
  values = FALSE,
  digits = 1,
  text.size = 3,
  text.color = "grey40",
  xaxis.col = "black",
  yaxis.col = "black",
  order.by = NULL,
  grid = "white",
  by.column = TRUE,
  auto.size = FALSE,
  mat2 = NULL,
  plot = TRUE,
  facet.vars = NULL,
  facet.flip = FALSE,
  diag.na = FALSE,
  diag.values = "",
  ...
)

## Default S3 method:
qheat(
  mat,
  low = "white",
  high = "darkblue",
  values = FALSE,
  digits = 1,
  text.size = 3,
  text.color = "grey40",
  xaxis.col = "black",
  yaxis.col = "black",
  order.by = NULL,
  grid = "white",
  by.column = TRUE,
  auto.size = FALSE,
  mat2 = NULL,
  plot = TRUE,
  facet.vars = NULL,
  facet.flip = FALSE,
  diag.na = FALSE,
  diag.values = "",
  ...
)

## S3 method for class 'diversity'
qheat(
  mat,
  low = "white",
  high = "darkblue",
  values = FALSE,
  digits = 1,
  text.size = 3,
  text.color = "grey40",
  xaxis.col = "black",
  yaxis.col = "black",
  order.by = NULL,
  grid = "white",
  by.column = TRUE,
  auto.size = FALSE,
  mat2 = NULL,
  plot = TRUE,
  facet.vars = NULL,
  facet.flip = FALSE,
  diag.na = FALSE,
  diag.values = "",
  ...
)

## S3 method for class 'termco'
qheat(
  mat,
  low = "white",
  high = "darkblue",
  values = FALSE,
  digits = 1,
  text.size = 3,
  text.color = "grey40",
  xaxis.col = "black",
  yaxis.col = "black",
  order.by = NULL,
  grid = "white",
  by.column = TRUE,
  auto.size = FALSE,
  mat2 = NULL,
  plot = TRUE,
  facet.vars = NULL,
  facet.flip = FALSE,
  diag.na = FALSE,
  diag.values = "",
  ...
)

## S3 method for class 'word_stats'
qheat(
  mat,
  low = "white",
  high = "darkblue",
  values = FALSE,
  digits = 1,
  text.size = 3,
  text.color = "grey40",
  xaxis.col = "black",
  yaxis.col = "black",
  order.by = NULL,
  grid = "white",
  by.column = TRUE,
  auto.size = FALSE,
  mat2 = NULL,
  plot = TRUE,
  facet.vars = NULL,
  facet.flip = FALSE,
  diag.na = FALSE,
  diag.values = "",
  ...
)

## S3 method for class 'character_table'
qheat(
  mat,
  low = "white",
  high = "darkblue",
  values = FALSE,
  digits = 1,
  text.size = 3,
  text.color = "grey40",
  xaxis.col = "black",
  yaxis.col = "black",
  order.by = NULL,
  grid = "white",
  by.column = TRUE,
  auto.size = FALSE,
  mat2 = NULL,
  plot = TRUE,
  facet.vars = NULL,
  facet.flip = FALSE,
  diag.na = FALSE,
  diag.values = "",
  ...
)

## S3 method for class 'question_type'
qheat(
  mat,
  low = "white",
  high = "darkblue",
  values = FALSE,
  digits = 1,
  text.size = 3,
  text.color = "grey40",
  xaxis.col = "black",
  yaxis.col = "black",
  order.by = NULL,
  grid = "white",
  by.column = TRUE,
  auto.size = FALSE,
  mat2 = NULL,
  plot = TRUE,
  facet.vars = NULL,
  facet.flip = FALSE,
  diag.na = FALSE,
  diag.values = "",
  ...
)

## S3 method for class 'pos_by'
qheat(
  mat,
  low = "white",
  high = "darkblue",
  values = FALSE,
  digits = 1,
  text.size = 3,
  text.color = "grey40",
  xaxis.col = "black",
  yaxis.col = "black",
  order.by = NULL,
  grid = "white",
  by.column = TRUE,
  auto.size = FALSE,
  mat2 = NULL,
  plot = TRUE,
  facet.vars = NULL,
  facet.flip = FALSE,
  diag.na = FALSE,
  diag.values = "",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qheat_+3A_mat">mat</code></td>
<td>
<p>A matrix or dataframe produced by many qdap functions in 
which the first column is the grouping variable and the rest of the matrix 
is numeric.  Also accepts objects directly from <code><a href="#topic+word_stats">word_stats</a></code> 
and <code><a href="#topic+question_type">question_type</a></code>.</p>
</td></tr>
<tr><td><code id="qheat_+3A_low">low</code></td>
<td>
<p>The color to be used for lower values.</p>
</td></tr>
<tr><td><code id="qheat_+3A_high">high</code></td>
<td>
<p>The color to be used for higher values.</p>
</td></tr>
<tr><td><code id="qheat_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> the cell values will be included on 
the heatmap.</p>
</td></tr>
<tr><td><code id="qheat_+3A_digits">digits</code></td>
<td>
<p>The number of digits displayed if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="qheat_+3A_text.size">text.size</code></td>
<td>
<p>A integer size to plot the text if <code>values</code> is 
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="qheat_+3A_text.color">text.color</code></td>
<td>
<p>A character vector to plot the text if <code>values</code> 
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="qheat_+3A_xaxis.col">xaxis.col</code></td>
<td>
<p>A single character vector color choice for the high values.</p>
</td></tr>
<tr><td><code id="qheat_+3A_yaxis.col">yaxis.col</code></td>
<td>
<p>A single character vector color choice for the low values.</p>
</td></tr>
<tr><td><code id="qheat_+3A_order.by">order.by</code></td>
<td>
<p>An optional character vector of a variable name to order the 
columns by.  To reverse use a negative (<code>-</code>) before the column name.</p>
</td></tr>
<tr><td><code id="qheat_+3A_grid">grid</code></td>
<td>
<p>The color of the grid (Use <code>NULL</code> to remove the grid).</p>
</td></tr>
<tr><td><code id="qheat_+3A_by.column">by.column</code></td>
<td>
<p>logical.  If <code>TRUE</code> applies scaling to the column.  If 
<code>FALSE</code>  applies scaling by row (use <code>NULL</code> to turn off scaling).</p>
</td></tr>
<tr><td><code id="qheat_+3A_auto.size">auto.size</code></td>
<td>
<p>logical.  If <code>TRUE</code> the visual will be resized to 
create square cells.</p>
</td></tr>
<tr><td><code id="qheat_+3A_mat2">mat2</code></td>
<td>
<p>A second matrix equal in dimensions to <code>mat</code> that will be 
used for cell labels if <code>values</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="qheat_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
<tr><td><code id="qheat_+3A_facet.vars">facet.vars</code></td>
<td>
<p>A character vector of 1 or 2 column names to facet by.</p>
</td></tr>
<tr><td><code id="qheat_+3A_facet.flip">facet.flip</code></td>
<td>
<p>logical If <code>TRUE</code> the direction of the faceting 
is reversed.</p>
</td></tr>
<tr><td><code id="qheat_+3A_diag.na">diag.na</code></td>
<td>
<p>logical.  If <code>TRUE</code> and <code>mat</code> is a symmetrical 
matrix the diagonals are set to <code>NA</code>.  This is useful with correlation 
matrices because the diagonal of ones do not affect the scaling of the 
heatmap.</p>
</td></tr>
<tr><td><code id="qheat_+3A_diag.values">diag.values</code></td>
<td>
<p>The string to be used for the diagonal labels (values) 
if <code>diag.na</code> is set to <code>TRUE</code>.  Default is to not print a value.</p>
</td></tr>
<tr><td><code id="qheat_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>qheat</code> is useful for finding patterns and anomalies in large
qdap generated dataframes and matrices.
</p>


<h3>Note</h3>

<p><code><a href="#topic+qheat">qheat</a></code> is a fast way of working with data formats 
produced by qdap.  The function isn't designed to be extended beyond 
exploratory qdap usage.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- sentSplit(DATA, "state")
ws.ob &lt;- with(dat, word_stats(state, list(sex, adult), tot=tot))
qheat(ws.ob)
qheat(ws.ob) + coord_flip()
qheat(ws.ob, order.by = "sptot", 
    xaxis.col = c("red", "black", "green", "blue"))
qheat(ws.ob, order.by = "sptot")
qheat(ws.ob, order.by = "-sptot")
qheat(ws.ob, values = TRUE)
qheat(ws.ob, values = TRUE, text.color = "red")
qheat(ws.ob, "yellow", "red", grid = FALSE)
qheat(mtcars, facet.vars = "cyl")
qheat(mtcars, facet.vars = c("gear", "cyl"))
qheat(t(mtcars), by.column=FALSE)
qheat(cor(mtcars), diag.na=TRUE, diag.value="", by.column=NULL, values = TRUE)

dat1 &lt;- data.frame(G=LETTERS[1:5], matrix(rnorm(20), ncol = 4))
dat2 &lt;- data.frame(matrix(LETTERS[1:25], ncol=5))
qheat(dat1, values=TRUE)
qheat(dat1, values=TRUE, mat2=dat2)

## End(Not run)
</code></pre>

<hr>
<h2 id='qprep'>Quick Preparation of Text</h2><span id='topic+qprep'></span>

<h3>Description</h3>

<p>Wrapper for <code><a href="#topic+bracketX">bracketX</a></code>, <code><a href="#topic+replace_number">replace_number</a></code>, 
<code><a href="#topic+replace_symbol">replace_symbol</a></code>, <code><a href="#topic+replace_abbreviation">replace_abbreviation</a></code> 
and <code><a href="#topic+scrubber">scrubber</a></code> to quickly prepare text for analysis.  Care 
should be taken with this function to ensure data is properly formatted and 
complete.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qprep(
  text.var,
  rm.dash = TRUE,
  bracket = "all",
  missing = NULL,
  names = FALSE,
  abbreviation = qdapDictionaries::abbreviations,
  replace = NULL,
  ignore.case = TRUE,
  num.paste = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qprep_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="qprep_+3A_rm.dash">rm.dash</code></td>
<td>
<p>logical.  If <code>TRUE</code> dashes will be removed.</p>
</td></tr>
<tr><td><code id="qprep_+3A_bracket">bracket</code></td>
<td>
<p>The type of bracket (and encased text) to remove.  This is one 
of the strings <code>"curly"</code>, <code>"square"</code>, <code>"round"</code>, 
<code>"angle"</code> and <code>"all"</code>.  These strings correspond to: {, [, (, &lt; 
or all four types.  Also takes the argument <code>NULL</code> which turns off this 
parsing technique.</p>
</td></tr>
<tr><td><code id="qprep_+3A_missing">missing</code></td>
<td>
<p>Value to assign to empty cells.</p>
</td></tr>
<tr><td><code id="qprep_+3A_names">names</code></td>
<td>
<p>logical.  If <code>TRUE</code> the sentences are given as the names of 
the counts.</p>
</td></tr>
<tr><td><code id="qprep_+3A_abbreviation">abbreviation</code></td>
<td>
<p>A two column key of abbreviations (column 1) and long 
form replacements (column 2) or a vector of abbreviations.  Default is to use 
qdap's abbreviations data set.  Also takes the argument <code>NULL</code> which 
turns off this parsing technique.</p>
</td></tr>
<tr><td><code id="qprep_+3A_replace">replace</code></td>
<td>
<p>A vector of long form replacements if a data frame is not 
supplied to the abbreviation argument.</p>
</td></tr>
<tr><td><code id="qprep_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces without regard to 
capitalization.</p>
</td></tr>
<tr><td><code id="qprep_+3A_num.paste">num.paste</code></td>
<td>
<p>logical.  If <code>TURE</code> a the elements of larger numbers are 
separated with spaces.  If <code>FALSE</code> the elements will be joined without 
spaces.  Also takes the argument <code>NULL</code> which turns off this parsing 
technique.</p>
</td></tr>
<tr><td><code id="qprep_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+replace_symbol">replace_symbol</a></code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Care should be taken with this function to ensure data is properly 
formatted and complete.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bracketX">bracketX</a></code>,
<code><a href="#topic+replace_abbreviation">replace_abbreviation</a></code>,
<code><a href="#topic+replace_number">replace_number</a></code>,
<code><a href="#topic+replace_symbol">replace_symbol</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- "I like 60 (laughter) #d-bot and $6 @ the store w/o 8p.m."
qprep(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='qtheme'>Add themes to a Network object.</h2><span id='topic+qtheme'></span><span id='topic+theme_nightheat'></span><span id='topic+theme_badkitchen'></span><span id='topic+theme_cafe'></span><span id='topic+theme_grayscale'></span><span id='topic+theme_greyscale'></span><span id='topic+theme_norah'></span><span id='topic+theme_hipster'></span><span id='topic+theme_duskheat'></span>

<h3>Description</h3>

<p><code>qtheme</code> - This function builds generic themes to add a theme to a 
<code>Network</code> object rather than individual <code>print</code> arguments.
</p>
<p><code>theme_nightheat</code> A night heat theme.
</p>
<p><code>theme_badkitchen</code> A 70s kitchen theme.
</p>
<p><code>theme_cafe</code> A cafe theme.
</p>
<p><code>theme_grayscale</code> A grayscale theme.
</p>
<p><code>theme_norah</code> A Norah theme.
</p>
<p><code>theme_hipster</code> A hipster theme.
</p>
<p><code>theme_duskheat</code> A duskheat theme.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qtheme(
  x = "generic",
  title,
  title.color,
  layout,
  legend,
  legend.cex,
  legend.text.color,
  legend.gradient,
  bg,
  vertex.color,
  vertex.size,
  vertex.frame.color,
  vertex.label.color,
  vertex.label.cex,
  edge.label.color,
  edge.label.cex
)

theme_nightheat(
  x = pars[["x"]],
  title = pars[["title"]],
  title.color = pars[["title.color"]],
  layout = pars[["layout"]],
  legend = pars[["legend"]],
  legend.cex = pars[["legend.cex"]],
  legend.gradient = pars[["legend.gradient"]],
  bg = pars[["bg"]],
  legend.text.color = pars[["legend.text.color"]],
  vertex.color = pars[["vertex.color"]],
  vertex.size = pars[["vertex.size"]],
  vertex.frame.color = pars[["vertex.frame.color"]],
  vertex.label.color = pars[["vertex.label.color"]],
  vertex.label.cex = pars[["vertex.label.cex"]],
  edge.label.color = pars[["edge.label.color"]],
  edge.label.cex = pars[["edge.label.cex"]],
  ...
)

theme_badkitchen(
  x = pars[["x"]],
  title = pars[["title"]],
  title.color = pars[["title.color"]],
  layout = pars[["layout"]],
  legend = pars[["legend"]],
  legend.cex = pars[["legend.cex"]],
  legend.gradient = pars[["legend.gradient"]],
  bg = pars[["bg"]],
  legend.text.color = pars[["legend.text.color"]],
  vertex.color = pars[["vertex.color"]],
  vertex.size = pars[["vertex.size"]],
  vertex.frame.color = pars[["vertex.frame.color"]],
  vertex.label.color = pars[["vertex.label.color"]],
  vertex.label.cex = pars[["vertex.label.cex"]],
  edge.label.color = pars[["edge.label.color"]],
  edge.label.cex = pars[["edge.label.cex"]],
  ...
)

theme_cafe(
  x = pars[["x"]],
  title = pars[["title"]],
  title.color = pars[["title.color"]],
  layout = pars[["layout"]],
  legend = pars[["legend"]],
  legend.cex = pars[["legend.cex"]],
  legend.gradient = pars[["legend.gradient"]],
  bg = pars[["bg"]],
  legend.text.color = pars[["legend.text.color"]],
  vertex.color = pars[["vertex.color"]],
  vertex.size = pars[["vertex.size"]],
  vertex.frame.color = pars[["vertex.frame.color"]],
  vertex.label.color = pars[["vertex.label.color"]],
  vertex.label.cex = pars[["vertex.label.cex"]],
  edge.label.color = pars[["edge.label.color"]],
  edge.label.cex = pars[["edge.label.cex"]],
  ...
)

theme_grayscale(
  x = pars[["x"]],
  title = pars[["title"]],
  title.color = pars[["title.color"]],
  layout = pars[["layout"]],
  legend = pars[["legend"]],
  legend.cex = pars[["legend.cex"]],
  legend.gradient = pars[["legend.gradient"]],
  bg = pars[["bg"]],
  legend.text.color = pars[["legend.text.color"]],
  vertex.color = pars[["vertex.color"]],
  vertex.size = pars[["vertex.size"]],
  vertex.frame.color = pars[["vertex.frame.color"]],
  vertex.label.color = pars[["vertex.label.color"]],
  vertex.label.cex = pars[["vertex.label.cex"]],
  edge.label.color = pars[["edge.label.color"]],
  edge.label.cex = pars[["edge.label.cex"]],
  ...
)

theme_greyscale(
  x = pars[["x"]],
  title = pars[["title"]],
  title.color = pars[["title.color"]],
  layout = pars[["layout"]],
  legend = pars[["legend"]],
  legend.cex = pars[["legend.cex"]],
  legend.gradient = pars[["legend.gradient"]],
  bg = pars[["bg"]],
  legend.text.color = pars[["legend.text.color"]],
  vertex.color = pars[["vertex.color"]],
  vertex.size = pars[["vertex.size"]],
  vertex.frame.color = pars[["vertex.frame.color"]],
  vertex.label.color = pars[["vertex.label.color"]],
  vertex.label.cex = pars[["vertex.label.cex"]],
  edge.label.color = pars[["edge.label.color"]],
  edge.label.cex = pars[["edge.label.cex"]],
  ...
)

theme_norah(
  x = pars[["x"]],
  title = pars[["title"]],
  title.color = pars[["title.color"]],
  layout = pars[["layout"]],
  legend = pars[["legend"]],
  legend.cex = pars[["legend.cex"]],
  legend.gradient = pars[["legend.gradient"]],
  bg = pars[["bg"]],
  legend.text.color = pars[["legend.text.color"]],
  vertex.color = pars[["vertex.color"]],
  vertex.size = pars[["vertex.size"]],
  vertex.frame.color = pars[["vertex.frame.color"]],
  vertex.label.color = pars[["vertex.label.color"]],
  vertex.label.cex = pars[["vertex.label.cex"]],
  edge.label.color = pars[["edge.label.color"]],
  edge.label.cex = pars[["edge.label.cex"]],
  ...
)

theme_hipster(
  x = pars[["x"]],
  title = pars[["title"]],
  title.color = pars[["title.color"]],
  layout = pars[["layout"]],
  legend = pars[["legend"]],
  legend.cex = pars[["legend.cex"]],
  legend.gradient = pars[["legend.gradient"]],
  bg = pars[["bg"]],
  legend.text.color = pars[["legend.text.color"]],
  vertex.color = pars[["vertex.color"]],
  vertex.size = pars[["vertex.size"]],
  vertex.frame.color = pars[["vertex.frame.color"]],
  vertex.label.color = pars[["vertex.label.color"]],
  vertex.label.cex = pars[["vertex.label.cex"]],
  edge.label.color = pars[["edge.label.color"]],
  edge.label.cex = pars[["edge.label.cex"]],
  ...
)

theme_duskheat(
  x = pars[["x"]],
  title = pars[["title"]],
  title.color = pars[["title.color"]],
  layout = pars[["layout"]],
  legend = pars[["legend"]],
  legend.cex = pars[["legend.cex"]],
  legend.gradient = pars[["legend.gradient"]],
  bg = pars[["bg"]],
  legend.text.color = pars[["legend.text.color"]],
  vertex.color = pars[["vertex.color"]],
  vertex.size = pars[["vertex.size"]],
  vertex.frame.color = pars[["vertex.frame.color"]],
  vertex.label.color = pars[["vertex.label.color"]],
  vertex.label.cex = pars[["vertex.label.cex"]],
  edge.label.color = pars[["edge.label.color"]],
  edge.label.cex = pars[["edge.label.cex"]],
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qtheme_+3A_x">x</code></td>
<td>
<p>The name of the qtheme.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_title">title</code></td>
<td>
<p>The title of the plot.  <code>NULL</code> eliminates title.  <code>NA</code>
uses title attribute of the Network object.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_title.color">title.color</code></td>
<td>
<p>The color of the title.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_layout">layout</code></td>
<td>
<p><span class="pkg">igraph</span> <code>layout</code> to use.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_legend">legend</code></td>
<td>
<p>The coordinates of the legend. See 
<code><a href="plotrix.html#topic+color.legend">color.legend</a></code> for more information.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_legend.cex">legend.cex</code></td>
<td>
<p>character expansion factor. <code>NULL</code> and <code>NA</code> are 
equivalent to 1.0. See <code><a href="graphics.html#topic+mtext">mtext</a></code> for more information.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_legend.text.color">legend.text.color</code></td>
<td>
<p>The text legend text color.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_legend.gradient">legend.gradient</code></td>
<td>
<p>A vector of ordered colors to use for the gradient 
fills in the network edges.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_bg">bg</code></td>
<td>
<p>The color to be used for the background of the device region. See
<code><a href="graphics.html#topic+par">par</a></code> for more information.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_vertex.color">vertex.color</code></td>
<td>
<p>The font family to be used for vertex labels.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_vertex.size">vertex.size</code></td>
<td>
<p>The size of the vertex.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_vertex.frame.color">vertex.frame.color</code></td>
<td>
<p>The color of the vertex border.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_vertex.label.color">vertex.label.color</code></td>
<td>
<p>The color of the labels.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_vertex.label.cex">vertex.label.cex</code></td>
<td>
<p>The font size for vertex labels.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_edge.label.color">edge.label.color</code></td>
<td>
<p>The color for the edge labels.  Use <code>NA</code> to 
remove.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_edge.label.cex">edge.label.cex</code></td>
<td>
<p>The font size of the edge labels.</p>
</td></tr>
<tr><td><code id="qtheme_+3A_...">...</code></td>
<td>
<p>Additional arguments supplied to <code>qtheme</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(poldat &lt;- with(sentSplit(DATA, 4), polarity(state, person)))
m &lt;- Network(poldat)
m

m + theme_nightheat
m + theme_cafe
m + theme_grayscale
m + theme_norah
m + theme_hipster
m + theme_badkitchen
m + theme_duskheat

## make your own themes
theme_irish &lt;- qtheme(x = "irish", bg = "grey25", 
    vertex.label.color = "grey50", legend.text.color = "white",
    legend.gradient = c("darkgreen", "white", "darkorange"), 
    edge.label.color="white", vertex.size= 20)

m + theme_irish

## End(Not run)
</code></pre>

<hr>
<h2 id='question_type'>Count of Question Type</h2><span id='topic+question_type'></span>

<h3>Description</h3>

<p>Transcript apply question counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>question_type(
  text.var,
  grouping.var = NULL,
  neg.cont = FALSE,
  percent = TRUE,
  zero.replace = 0,
  digits = 2,
  contraction = qdapDictionaries::contractions,
  bracket = "all",
  amplifiers = qdapDictionaries::amplification.words,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="question_type_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="question_type_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="question_type_+3A_neg.cont">neg.cont</code></td>
<td>
<p>logical.  If <code>TRUE</code> provides separate counts for the 
negative contraction forms of the interrogative words.</p>
</td></tr>
<tr><td><code id="question_type_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="question_type_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.</p>
</td></tr>
<tr><td><code id="question_type_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="question_type_+3A_contraction">contraction</code></td>
<td>
<p>A two column key of contractions (column 1) and expanded 
form replacements (column 2) or a vector of contractions.  Default is to use 
qdapDictionaries's <code><a href="qdapDictionaries.html#topic+contractions">contractions</a></code> data set.</p>
</td></tr>
<tr><td><code id="question_type_+3A_bracket">bracket</code></td>
<td>
<p>The type of bracket (and encased text) to remove.  This is one 
or more of the strings <code>"curly"</code>, <code>"square"</code>, <code>"round"</code>, 
<code>"angle"</code> and <code>"all"</code>.  These strings correspond 
to: {, [, (, &lt; or all four types.</p>
</td></tr>
<tr><td><code id="question_type_+3A_amplifiers">amplifiers</code></td>
<td>
<p>A character vector of terms that increase the 
intensity of a positive or negative word. Default is to use 
qdapDictionaries's <code><a href="qdapDictionaries.html#topic+amplification.words">amplification.words</a></code> data 
set.</p>
</td></tr>
<tr><td><code id="question_type_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+bracketX">bracketX</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm searches for the following interrogative words (and 
optionally, their negative contraction form as well): 
</p>
<p>1) whose 2) whom 3) who 4) where 5) what 6) which 7) why 8) when 9) were* 
10) was* 11) does* 12) did* 13) do* 14) is 15) are* 16) will* 17) how 
18) should 19) could 20) would* 21) shall 22) may 23) might* 24) must* 
25) can* 26) has 27) have* 28) had* 29) ok 30) right 31) correct 
32) implied do/does/did
</p>
<p>The interrogative word that is found first (with the exception of &quot;ok&quot;, 
&quot;right&quot;/&quot;alright&quot;, and &quot;correct&quot;) in the question determines the sentence 
type. &quot;ok&quot;, &quot;right&quot;/&quot;alright&quot;, and &quot;correct&quot; sentence types are determined if 
the sentence is a question with no other interrogative words found and &quot;ok&quot;, 
&quot;right&quot;/&quot;alright&quot;, or &quot;correct&quot; is the last word of the sentence.  Those 
interrogative sentences beginning with the word &quot;you&quot;, &quot;wanna&quot;, or &quot;want&quot; are 
categorized as implying do/does/did question type, though the use of 
do/does/did is not explicit.  Those sentence beginning with &quot;you&quot; followed by 
a select interrogative word (and or their negative counter parts) above 
(marked with *) or 1-2 amplifier(s) followed by the select interrogative word
are categorized by the select word rather than an implied do/does/did 
question type.  A sentence that is marked &quot;ok&quot; over rides an implied 
do/does/did label.  Those with undetermined sentence type are labeled unknown.
</p>


<h3>Value</h3>

<p>Returns a list of:
</p>
<table>
<tr><td><code>raw</code></td>
<td>
<p>A dataframe of the questions used in the transcript and their 
type.</p>
</td></tr>
<tr><td><code>count</code></td>
<td>
<p>A dataframe of total questions (<code>tot.quest</code>) and counts of 
question types (initial interrogative word) by grouping variable(s).</p>
</td></tr>
<tr><td><code>rnp</code></td>
<td>
<p>Dataframe of the frequency and proportions of question types by 
grouping variable.</p>
</td></tr> 
<tr><td><code>inds</code></td>
<td>
<p>The indices of the original text variable that contain questions.</p>
</td></tr>
<tr><td><code>missing</code></td>
<td>
<p>The row numbers of the missing data (excluded from analysis).</p>
</td></tr>
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr>
<tr><td><code>zero.replace</code></td>
<td>
<p>The value of zero.replace used for plotting purposes.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+colcomb2class">colcomb2class</a></code>,
<code><a href="#topic+bracketX">bracketX</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Inspect the algorithm classification
x &lt;- c("Kate's got no appetite doesn't she?",
    "Wanna tell Daddy what you did today?",
    "You helped getting out a book?", "umm hum?",
    "Do you know what it is?", "What do you want?",
    "Who's there?", "Whose?", "Why do you want it?",
    "Want some?", "Where did it go?", "Was it fun?")

left_just(preprocessed(question_type(x))[, c(2, 6)])

## Transcript/dialogue examples
(x &lt;- question_type(DATA.SPLIT$state, DATA.SPLIT$person))

## methods
scores(x)
plot(scores(x))
counts(x)
plot(counts(x))
proportions(x)
plot(proportions(x))
truncdf(preprocessed(x), 15)
plot(preprocessed(x))

plot(x)
plot(x, label = TRUE)
plot(x, label = TRUE, text.color = "red")
question_type(DATA.SPLIT$state, DATA.SPLIT$person, percent = FALSE)
DATA[8, 4] &lt;- "Won't I distrust you?"
question_type(DATA.SPLIT$state, DATA.SPLIT$person)
DATA &lt;- qdap::DATA
with(DATA.SPLIT, question_type(state, list(sex, adult)))

out1 &lt;- with(mraja1spl, question_type(dialogue, person))
## out1
out2 &lt;- with(mraja1spl, question_type(dialogue, list(sex, fam.aff)))
## out2
out3 &lt;- with(mraja1spl, question_type(dialogue, list(sex, fam.aff),
   percent = FALSE))
plot(out3, label = TRUE, lab.digits = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='raj'>Romeo and Juliet (Unchanged &amp; Complete)</h2><span id='topic+raj'></span>

<h3>Description</h3>

<p>A dataset containing the original transcript from Romeo and Juliet as it was 
scraped from: http://shakespeare.mit.edu/romeo_juliet/full.html.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raj)
</code></pre>


<h3>Format</h3>

<p>A data frame with 840 rows and 3 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue 
</p>
</li>
<li><p> act. The act (akin to repeated measures)
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='raj.act.1'>Romeo and Juliet: Act 1</h2><span id='topic+raj.act.1'></span>

<h3>Description</h3>

<p>A dataset containing Romeo and Juliet: Act 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raj.act.1)
</code></pre>


<h3>Format</h3>

<p>A data frame with 235 rows and 2 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='raj.act.1POS'>Romeo and Juliet: Act 1 Parts of Speech by Person
A dataset containing a list from <code><a href="#topic+pos_by">pos_by</a></code> using the 
<code><a href="#topic+mraja1spl">mraja1spl</a></code> data set (see <code><a href="#topic+pos_by">pos_by</a></code> for 
more information).</h2><span id='topic+raj.act.1POS'></span>

<h3>Description</h3>

<p>Romeo and Juliet: Act 1 Parts of Speech by Person
</p>
<p>A dataset containing a list from <code><a href="#topic+pos_by">pos_by</a></code> using the 
<code><a href="#topic+mraja1spl">mraja1spl</a></code> data set (see <code><a href="#topic+pos_by">pos_by</a></code> for 
more information).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raj.act.1POS)
</code></pre>


<h3>Format</h3>

<p>A list with 10 elements 
http://shakespeare.mit.edu/romeo_juliet/full.html
</p>


<h3>Details</h3>

 
<dl>
<dt>text</dt><dd><p>The original text</p>
</dd> 
<dt>POStagged</dt><dd><p>The original words replaced with parts of speech in context.</p>
</dd> 
<dt>POSprop</dt><dd><p>Dataframe of the proportion of parts of speech by row.</p>
</dd> 
<dt>POSfreq</dt><dd><p>Dataframe of the frequency of parts of speech by row.</p>
</dd> 
<dt>POSrnp</dt><dd><p>Dataframe of the frequency and proportions of parts of speech by row</p>
</dd> 
<dt>percent</dt><dd><p>The value of percent used for plotting purposes.</p>
</dd> 
<dt>zero.replace</dt><dd><p>The value of zero.replace used for plotting purposes.</p>
</dd> 
<dt>pos.by.freq</dt><dd><p>Dataframe of the frequency of parts of speech by grouping variable.</p>
</dd> 
<dt>pos.by.prop</dt><dd><p>Dataframe of the proportion of parts of speech by grouping variable.</p>
</dd> 
<dt>pos.by.rnp</dt><dd><p>Dataframe of the frequency and proportions of parts of speech by grouping variable.</p>
</dd> 
</dl>


<hr>
<h2 id='raj.act.2'>Romeo and Juliet: Act 2</h2><span id='topic+raj.act.2'></span>

<h3>Description</h3>

<p>A dataset containing Romeo and Juliet: Act 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raj.act.2)
</code></pre>


<h3>Format</h3>

<p>A data frame with 205 rows and 2 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='raj.act.3'>Romeo and Juliet: Act 3</h2><span id='topic+raj.act.3'></span>

<h3>Description</h3>

<p>A dataset containing Romeo and Juliet: Act 3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raj.act.3)
</code></pre>


<h3>Format</h3>

<p>A data frame with 197 rows and 2 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='raj.act.4'>Romeo and Juliet: Act 4</h2><span id='topic+raj.act.4'></span>

<h3>Description</h3>

<p>A dataset containing Romeo and Juliet: Act 4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raj.act.4)
</code></pre>


<h3>Format</h3>

<p>A data frame with 115 rows and 2 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='raj.act.5'>Romeo and Juliet: Act 5</h2><span id='topic+raj.act.5'></span>

<h3>Description</h3>

<p>A dataset containing Romeo and Juliet: Act 5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raj.act.5)
</code></pre>


<h3>Format</h3>

<p>A data frame with 88 rows and 2 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='raj.demographics'>Romeo and Juliet Demographics</h2><span id='topic+raj.demographics'></span>

<h3>Description</h3>

<p>A dataset containing Romeo and Juliet demographic information for the 
characters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raj.demographics)
</code></pre>


<h3>Format</h3>

<p>A data frame with 34 rows and 4 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> sex. Gender
</p>
</li>
<li><p> fam.aff. Family affiliation of character
</p>
</li>
<li><p> died. Dummy coded death variable (0-no; 1-yes);  if yes the character 
dies in the play
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='rajPOS'>Romeo and Juliet Split in Parts of Speech</h2><span id='topic+rajPOS'></span>

<h3>Description</h3>

<p>A dataset containing a list from <code><a href="#topic+pos">pos</a></code> using the 
<code><a href="#topic+raj">raj</a></code> data set (see <code><a href="#topic+pos">pos</a></code> for more 
information).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rajPOS)
</code></pre>


<h3>Format</h3>

<p>A list with 4 elements
</p>


<h3>Details</h3>

 
<dl>
<dt>text</dt><dd><p>The original text</p>
</dd> 
<dt>POStagged</dt><dd><p>The original words replaced with parts of speech in context.</p>
</dd> 
<dt>POSprop</dt><dd><p>Dataframe of the proportion of parts of speech by row.</p>
</dd> 
<dt>POSfreq</dt><dd><p>Dataframe of the frequency of parts of speech by row.</p>
</dd> 
</dl>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='rajSPLIT'>Romeo and Juliet (Complete &amp; Split)</h2><span id='topic+rajSPLIT'></span>

<h3>Description</h3>

<p>A dataset containing the complete dialogue of Romeo and Juliet with turns of 
talk split into sentences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rajSPLIT)
</code></pre>


<h3>Format</h3>

<p>A data frame with 2151 rows and 8 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> person. Character in the play
</p>
</li>
<li><p> sex. Gender
</p>
</li>
<li><p> fam.aff. Family affiliation of character
</p>
</li>
<li><p> died. Dummy coded death variable (0-no; 1-yes);  if yes the character 
dies in the play
</p>
</li>
<li><p> dialogue. The spoken dialogue
</p>
</li>
<li><p> act. The act (akin to repeated measures) 
</p>
</li>
<li><p> stem.text. Text that has been stemmed
</p>
</li></ul>



<h3>References</h3>

<p>http://shakespeare.mit.edu/romeo_juliet/full.html
</p>

<hr>
<h2 id='random_sent'>Generate Random Dialogue Data</h2><span id='topic+random_sent'></span><span id='topic+random_data'></span>

<h3>Description</h3>

<p><code>random_sent</code> - Generates a random sample of sentences (sentences are 
sampled at the word level and there for are likely nonsensical).
</p>
<p><code>random_data</code> - Generate random dialogue, people, and demographic 
variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_sent(
  n = 10,
  len = 14,
  range = len - 1,
  dictionary = qdapDictionaries::Top200Words,
  endmark.fun = function() sample(c(".", "!", "|", "?"), 1, prob = c(0.85, 0.05, 0.05,
    0.05))
)

random_data(
  n = 10,
  ...,
  n.people = 10,
  ages = 7:10,
  people.names = unique(tolower(qdapDictionaries::NAMES[[1]]))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_sent_+3A_n">n</code></td>
<td>
<p>Number of sentences to create.</p>
</td></tr>
<tr><td><code id="random_sent_+3A_len">len</code></td>
<td>
<p>Average length of sentences (in words).</p>
</td></tr>
<tr><td><code id="random_sent_+3A_range">range</code></td>
<td>
<p>Range around <code>len</code> that number of words may vary.  This may 
be a recycled single integer vector or an integer vector of length 2.</p>
</td></tr>
<tr><td><code id="random_sent_+3A_dictionary">dictionary</code></td>
<td>
<p>A dictionary of words to sample from.</p>
</td></tr>
<tr><td><code id="random_sent_+3A_endmark.fun">endmark.fun</code></td>
<td>
<p>A function to create random end marks.</p>
</td></tr>
<tr><td><code id="random_sent_+3A_n.people">n.people</code></td>
<td>
<p>An integer of the number of people to include in the sample 
(number of people is sampled from; if <code>n</code> is smaller not all people may 
be included).</p>
</td></tr>
<tr><td><code id="random_sent_+3A_ages">ages</code></td>
<td>
<p>The possible ages to choose from (numeric).</p>
</td></tr>
<tr><td><code id="random_sent_+3A_people.names">people.names</code></td>
<td>
<p>A vector of names to choose from at least as large as 
<code>n.people</code>.</p>
</td></tr>
<tr><td><code id="random_sent_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>random_sent</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>random_sent</code> - Returns a random vector of sentence strings.
</p>
<p><code>random_data</code> - Returns a <code><a href="base.html#topic+data.frame">data.frame</a></code> of
people, dialogue, and demographic variables of the class <code>sent_split</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
random_sent()
random_sent(200, 10)

dict &lt;- sort(unique(bag_o_words(pres_debates2012[["dialogue"]])))
random_sent(dictionary=dict)

random_data()
random_data(ages = seq(10, 20, by = .5))
random_data(50) %&amp;% word_stats(person)
random_data(100) %&amp;% word_stats(list(race, sex))
random_data(dictionary = dict)

## End(Not run)
</code></pre>

<hr>
<h2 id='rank_freq_mplot'>Rank Frequency Plot</h2><span id='topic+rank_freq_mplot'></span><span id='topic+rank_freq_plot'></span>

<h3>Description</h3>

<p><code>rank_freq_mplot</code> - Plot a faceted word rank versus frequencies by 
grouping variable(s).
</p>
<p><code>rank_freq_plot</code> - Plot word rank versus frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rank_freq_mplot(
  text.var,
  grouping.var = NULL,
  ncol = 4,
  jitter = 0.2,
  log.freq = TRUE,
  log.rank = TRUE,
  hap.col = "red",
  dis.col = "blue",
  alpha = 1,
  shape = 1,
  title = "Rank-Frequency Plot",
  digits = 2,
  plot = TRUE
)

rank_freq_plot(
  words,
  frequencies,
  plot = TRUE,
  title.ext = NULL,
  jitter.ammount = 0.1,
  log.scale = TRUE,
  hap.col = "red",
  dis.col = "blue"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rank_freq_mplot_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_ncol">ncol</code></td>
<td>
<p>integer value indicating the number of columns in the facet wrap.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_jitter">jitter</code></td>
<td>
<p>Amount of horizontal jitter to add to the points.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_log.freq">log.freq</code></td>
<td>
<p>logical.  If <code>TRUE</code> plots the frequencies in the natural 
log scale.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_log.rank">log.rank</code></td>
<td>
<p>logical.  If <code>TRUE</code> plots the ranks in the natural log 
scale.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_hap.col">hap.col</code></td>
<td>
<p>Color of the hapax legomenon points.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_dis.col">dis.col</code></td>
<td>
<p>Color of the dis legomenon points.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_alpha">alpha</code></td>
<td>
<p>Transparency level of points (ranges between 0 and 1).</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_shape">shape</code></td>
<td>
<p>An integer specifying the symbol used to plot the points.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_title">title</code></td>
<td>
<p>Optional plot title.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> provides a rank frequency plot.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_words">words</code></td>
<td>
<p>A vector of words.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_frequencies">frequencies</code></td>
<td>
<p>A vector of frequencies corresponding to the words 
argument.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_title.ext">title.ext</code></td>
<td>
<p>The title extension that extends: &quot;Rank-Frequency Plot ...&quot;</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_jitter.ammount">jitter.ammount</code></td>
<td>
<p>Amount of horizontal jitter to add to the points.</p>
</td></tr>
<tr><td><code id="rank_freq_mplot_+3A_log.scale">log.scale</code></td>
<td>
<p>logical.  If <code>TRUE</code> plots the rank and frequency as a 
log scale.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a rank-frequency plot and a list of three dataframes:
</p>
<table>
<tr><td><code>WORD_COUNTS</code></td>
<td>
<p>The word frequencies supplied to 
<code><a href="#topic+rank_freq_plot">rank_freq_plot</a></code> or created by 
<code><a href="#topic+rank_freq_mplot">rank_freq_mplot</a></code>.</p>
</td></tr>
<tr><td><code>RANK_AND_FREQUENCY_STATS</code></td>
<td>
<p>A dataframe of rank and frequencies for the 
words used in the text.</p>
</td></tr>
<tr><td><code>LEGOMENA_STATS</code></td>
<td>
<p>A dataframe displaying the percent hapax legomena and 
percent dis legomena of the text.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>rank_freq_mplot</code> utilizes the ggplot2 package, whereas, 
<code>rank_freq_plot</code> employs base graphics.  <code>rank_freq_mplot</code> is more 
general &amp; flexible; in most cases <code>rank_freq_mplot</code> should be preferred.
</p>


<h3>References</h3>

<p>Zipf, G. K. (1949). Human behavior and the principle of least 
effort. Cambridge, Massachusetts: Addison-Wesley. p. 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#rank_freq_mplot EXAMPLES:
x1 &lt;- rank_freq_mplot(DATA$state, DATA$person, ncol = 2, jitter = 0)
ltruncdf(x1, 10)
x2 &lt;- rank_freq_mplot(mraja1spl$dialogue, mraja1spl$person, ncol = 5, 
    hap.col = "purple")
ltruncdf(x2, 10)
invisible(rank_freq_mplot(mraja1spl$dialogue, mraja1spl$person, ncol = 5, 
    log.freq = FALSE, log.rank = FALSE, jitter = .6))
invisible(rank_freq_mplot(raj$dialogue, jitter = .5, alpha = 1/15))
invisible(rank_freq_mplot(raj$dialogue, jitter = .5, shape = 19, alpha = 1/15))

#rank_freq_plot EXAMPLES:
mod &lt;- with(mraja1spl , word_list(dialogue, person, cut.n = 10, 
    cap.list=unique(mraja1spl$person)))         
x3 &lt;- rank_freq_plot(mod$fwl$Romeo$WORD, mod$fwl$Romeo$FREQ, title.ext = 'Romeo')  
ltruncdf(x3, 10)
ltruncdf(rank_freq_plot(mod$fwl$Romeo$WORD, mod$fwl$Romeo$FREQ, plot = FALSE)           , 10)
invisible(rank_freq_plot(mod$fwl$Romeo$WORD, mod$fwl$Romeo$FREQ, title.ext = 'Romeo',     
    jitter.ammount = 0.15, hap.col = "darkgreen", dis.col = "purple"))                  
invisible(rank_freq_plot(mod$fwl$Romeo$WORD, mod$fwl$Romeo$FREQ, title.ext = 'Romeo',  
    jitter.ammount = 0.5, log.scale=FALSE))  
invisible(lapply(seq_along(mod$fwl), function(i){
    dev.new()
    rank_freq_plot(mod$fwl[[i]]$WORD, mod$fwl[[i]]$FREQ, 
        title.ext = names(mod$fwl)[i], jitter.ammount = 0.5, log.scale=FALSE)
}))

## End(Not run)
</code></pre>

<hr>
<h2 id='raw.time.span'>Minimal Raw Time Span Data Set</h2><span id='topic+raw.time.span'></span>

<h3>Description</h3>

<p>A dataset containing a list of named vectors of time spans.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raw.time.span)
</code></pre>


<h3>Format</h3>

<p>A list with 3 elements
</p>

<hr>
<h2 id='read.transcript'>Read Transcripts Into R</h2><span id='topic+read.transcript'></span>

<h3>Description</h3>

<p>Read .docx, .csv or .xlsx files into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.transcript(
  file,
  col.names = NULL,
  text.var = NULL,
  merge.broke.tot = TRUE,
  header = FALSE,
  dash = "",
  ellipsis = "...",
  quote2bracket = FALSE,
  rm.empty.rows = TRUE,
  na.strings = c("999", "NA", "", " "),
  sep = NULL,
  skip = 0,
  nontext2factor = TRUE,
  text,
  comment.char = "",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.transcript_+3A_file">file</code></td>
<td>
<p>The name of the file which the data are to be read from. Each row 
of the table appears as one line of the file. If it does not contain an 
absolute path, the file name is relative to the current working directory, 
<code>getwd()</code>.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_col.names">col.names</code></td>
<td>
<p>A character vector specifying the column names of the 
transcript columns.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_text.var">text.var</code></td>
<td>
<p>A character string specifying the name of the text variable 
will ensure that variable is classed as character.  If <code>NULL</code> 
<code><a href="#topic+read.transcript">read.transcript</a></code> attempts to guess the text.variable 
(dialogue).</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_merge.broke.tot">merge.broke.tot</code></td>
<td>
<p>logical.  If <code>TRUE</code> and if the file being read in 
is .docx with broken space between a single turn of talk read.transcript 
will attempt to merge these into a single turn of talk.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_header">header</code></td>
<td>
<p>logical.  If <code>TRUE</code> the file contains the names of the 
variables as its first line.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_dash">dash</code></td>
<td>
<p>A character string to replace the en and em dashes special 
characters (default is to remove).</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_ellipsis">ellipsis</code></td>
<td>
<p>A character string to replace the ellipsis special characters 
(default is text ...).</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_quote2bracket">quote2bracket</code></td>
<td>
<p>logical. If <code>TRUE</code> replaces curly quotes with curly 
braces (default is <code>FALSE</code>).  If <code>FALSE</code> curly quotes are removed.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_rm.empty.rows">rm.empty.rows</code></td>
<td>
<p>logical.  If <code>TRUE</code> 
<code><a href="#topic+read.transcript">read.transcript</a></code>  attempts to remove empty rows.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_na.strings">na.strings</code></td>
<td>
<p>A vector of character strings which are to be interpreted 
as <code>NA</code> values.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_sep">sep</code></td>
<td>
<p>The field separator character. Values on each line of the file are 
separated by this character.  The default of <code>NULL</code> instructs 
<code><a href="#topic+read.transcript">read.transcript</a></code> to use a separator suitable for the file 
type being read in.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_skip">skip</code></td>
<td>
<p>Integer; the number of lines of the data file to skip before 
beginning to read data.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_nontext2factor">nontext2factor</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to convert any 
non-text to a factor.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_text">text</code></td>
<td>
<p>Character string: if file is not supplied and this is, then data 
are read from the value of text. Notice that a literal string can be used to 
include (small) data sets within R code.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_comment.char">comment.char</code></td>
<td>
<p>A character vector of length one containing a single 
character or an empty string. Use <code>""</code> to turn off the interpretation of 
comments altogether.</p>
</td></tr>
<tr><td><code id="read.transcript_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="utils.html#topic+read.table">read.table</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe of dialogue and people.
</p>


<h3>Warning</h3>

<p><code><a href="#topic+read.transcript">read.transcript</a></code> may contain errors if the 
file being read in is .docx.  The researcher should carefully investigate 
each transcript for errors before further parsing the data.
</p>


<h3>Note</h3>

<p>If a transcript is a .docx file read transcript expects two columns 
(generally person and dialogue) with some sort of separator (default is colon 
separator).  .doc files must be converted to .docx before reading in.
</p>


<h3>Author(s)</h3>

<p>Bryan Goodrich and Tyler Rinker &lt;tyler.rinker@gmail.com&gt;.
</p>


<h3>References</h3>

<p><a href="https://github.com/trinker/qdap/wiki/Reading-.docx-%5BMS-Word%5D-Transcripts-into-R">https://github.com/trinker/qdap/wiki/Reading-.docx-%5BMS-Word%5D-Transcripts-into-R</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dir_map">dir_map</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Note: to view the document below use the path:
system.file("extdata/transcripts/", package = "qdap")
(doc1 &lt;- system.file("extdata/transcripts/trans1.docx", package = "qdap"))
(doc2 &lt;- system.file("extdata/transcripts/trans2.docx", package = "qdap"))
(doc3 &lt;- system.file("extdata/transcripts/trans3.docx", package = "qdap"))
(doc4 &lt;- system.file("extdata/transcripts/trans4.xlsx", package = "qdap"))

dat1 &lt;- read.transcript(doc1)
truncdf(dat1, 40)
dat2 &lt;- read.transcript(doc1, col.names = c("person", "dialogue"))
truncdf(dat2, 40)
dat2b &lt;- rm_row(dat2, "person", "[C") #remove bracket row
truncdf(dat2b, 40)

## read.transcript(doc2) #throws an error (need skip)
dat3 &lt;- read.transcript(doc2, skip = 1); truncdf(dat3, 40)

## read.transcript(doc3, skip = 1) #incorrect read; wrong sep
dat4 &lt;- read.transcript(doc3, sep = "-", skip = 1); truncdf(dat4, 40)

dat5 &lt;- read.transcript(doc4); truncdf(dat5, 40) #an .xlsx file
trans &lt;- "sam: Computer is fun. Not too fun.
greg: No it's not, it's dumb.
teacher: What should we do?
sam: You liar, it stinks!"

read.transcript(text=trans)

## Read in text specify spaces as sep
## EXAMPLE 1

read.transcript(text="34    The New York Times reports a lot of words here.
12    Greenwire reports a lot of words.
31    Only three words.
 2    The Financial Times reports a lot of words.
 9    Greenwire short.
13    The New York Times reports a lot of words again.", 
    col.names=qcv(NO,    ARTICLE), sep="   ")

## EXAMPLE 2

read.transcript(text="34..    The New York Times reports a lot of words here.
12..    Greenwire reports a lot of words.
31..    Only three words.
 2..    The Financial Times reports a lot of words.
 9..    Greenwire short.
13..    The New York Times reports a lot of words again.", 
    col.names=qcv(NO,    ARTICLE), sep="\\.\\.")

## End(Not run)
</code></pre>

<hr>
<h2 id='replace_abbreviation'>Replace Abbreviations</h2><span id='topic+replace_abbreviation'></span>

<h3>Description</h3>

<p>This function replaces abbreviations with long form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_abbreviation(
  text.var,
  abbreviation = qdapDictionaries::abbreviations,
  replace = NULL,
  ignore.case = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_abbreviation_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="replace_abbreviation_+3A_abbreviation">abbreviation</code></td>
<td>
<p>A two column key of abbreviations (column 1) and long 
form replacements (column 2) or a vector of abbreviations.  Default is to use 
qdapDictionaries's <code><a href="qdapDictionaries.html#topic+abbreviations">abbreviations</a></code> data set.</p>
</td></tr>
<tr><td><code id="replace_abbreviation_+3A_replace">replace</code></td>
<td>
<p>A vector of long form replacements if a data frame is not 
supplied to the abbreviation argument.</p>
</td></tr>
<tr><td><code id="replace_abbreviation_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces without regard to 
capitalization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector with abbreviations replaced.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bracketX">bracketX</a></code>,
<code><a href="#topic+qprep">qprep</a></code>,
<code><a href="#topic+replace_contraction">replace_contraction</a></code>,
<code><a href="#topic+replace_number">replace_number</a></code>,
<code><a href="#topic+replace_symbol">replace_symbol</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("Mr. Jones is here at 7:30 p.m.",  
    "Check it out at www.github.com/trinker/qdap",
    "i.e. He's a sr. dr.; the best in 2012 A.D.",
    "the robot at t.s. is 10ft. 3in.")

replace_abbreviation(x)

#create abbreviation and replacement vectors
abv &lt;- c("in.", "ft.", "t.s.")
repl &lt;- c("inch", "feet", "talkstats")

replace_abbreviation(x, abv, repl)

(KEY &lt;- rbind(abbreviations, data.frame(abv = abv, rep = repl)))
replace_abbreviation(x, KEY)

## End(Not run)
</code></pre>

<hr>
<h2 id='replace_contraction'>Replace Contractions</h2><span id='topic+replace_contraction'></span>

<h3>Description</h3>

<p>This function replaces contractions with long form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_contraction(
  text.var,
  contraction = qdapDictionaries::contractions,
  replace = NULL,
  ignore.case = TRUE,
  sent.cap = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_contraction_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="replace_contraction_+3A_contraction">contraction</code></td>
<td>
<p>A two column key of contractions (column 1) and expanded 
form replacements (column 2) or a vector of contractions.  Default is to use 
qdapDictionaries's <code><a href="qdapDictionaries.html#topic+contractions">contractions</a></code> data set.</p>
</td></tr>
<tr><td><code id="replace_contraction_+3A_replace">replace</code></td>
<td>
<p>A vector of expanded form replacements if a data frame is not 
supplied to the contraction argument.</p>
</td></tr>
<tr><td><code id="replace_contraction_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces without regard to 
capitalization.</p>
</td></tr>
<tr><td><code id="replace_contraction_+3A_sent.cap">sent.cap</code></td>
<td>
<p>logical.  If <code>TRUE</code> capitalizes the beginning of every 
sentence.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector with contractions replaced.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bracketX">bracketX</a></code>,
<code><a href="#topic+qprep">qprep</a></code>,
<code><a href="#topic+replace_abbreviation">replace_abbreviation</a></code>,
<code><a href="#topic+replace_number">replace_number</a></code>,
<code><a href="#topic+replace_symbol">replace_symbol</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("Mr. Jones isn't going.",  
    "Check it out what's going on.",
    "He's here but didn't go.",
    "the robot at t.s. wasn't nice", 
    "he'd like it if i'd go away")

replace_contraction(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='replace_number'>Replace Numbers With Text Representation</h2><span id='topic+replace_number'></span>

<h3>Description</h3>

<p>Replaces numeric represented numbers with words (e.g., 1001 becomes one 
thousand one).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_number(text.var, num.paste = TRUE, remove = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_number_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="replace_number_+3A_num.paste">num.paste</code></td>
<td>
<p>logical.  If <code>TRUE</code> a the elements of larger numbers are 
separated with spaces.  If <code>FALSE</code> the elements will be joined without 
spaces.</p>
</td></tr>
<tr><td><code id="replace_number_+3A_remove">remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> numbers are removed from the text.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector with abbreviations replaced.
</p>


<h3>Note</h3>

<p>The user may want to use <code><a href="#topic+replace_ordinal">replace_ordinal</a></code> first to 
remove ordinal number notation.  For example <code><a href="#topic+replace_number">replace_number</a></code>
would turn &quot;21st&quot; into &quot;twenty onest&quot;, whereas <code><a href="#topic+replace_ordinal">replace_ordinal</a></code>
would generate &quot;twenty first&quot;.
</p>


<h3>References</h3>

<p>Fox, J. (2005). Programmer's niche: How do you spell that number? 
R News. Vol. 5(1), pp. 51-55.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bracketX">bracketX</a></code>,
<code><a href="#topic+qprep">qprep</a></code>,
<code><a href="#topic+replace_abbreviation">replace_abbreviation</a></code>,
<code><a href="#topic+replace_contraction">replace_contraction</a></code>,
<code><a href="#topic+replace_symbol">replace_symbol</a></code>,
<code><a href="#topic+replace_ordinal">replace_ordinal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("I like 346,457 ice cream cones.", "They are 99 percent good")
y &lt;- c("I like 346457 ice cream cones.", "They are 99 percent good")
replace_number(x)
replace_number(y)
replace_number(x, FALSE)
replace_number(x, remove=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='replace_ordinal'>Replace Mixed Ordinal Numbers With Text Representation</h2><span id='topic+replace_ordinal'></span>

<h3>Description</h3>

<p>Replaces mixed text/numeric represented ordinal numbers with words (e.g., 
&quot;1st&quot; becomes &quot;first&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_ordinal(text.var, num.paste = TRUE, remove = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_ordinal_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="replace_ordinal_+3A_num.paste">num.paste</code></td>
<td>
<p>logical.  If <code>TRUE</code> a the elements of larger numbers are 
separated with spaces.  If <code>FALSE</code> the elements will be joined without 
spaces.</p>
</td></tr>
<tr><td><code id="replace_ordinal_+3A_remove">remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> ordinal numbers are removed from the text.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Currently only implemented for ordinal values 1 through 100
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bracketX">bracketX</a></code>,
<code><a href="#topic+qprep">qprep</a></code>,
<code><a href="#topic+replace_abbreviation">replace_abbreviation</a></code>,
<code><a href="#topic+replace_contraction">replace_contraction</a></code>,
<code><a href="#topic+replace_symbol">replace_symbol</a></code>,
<code><a href="#topic+replace_number">replace_number</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c(
    "I like the 1st one not the 22nd one.", 
    "For the 100th time stop!"
)
replace_ordinal(x)
replace_ordinal(x, FALSE)
replace_ordinal(x, remove = TRUE)
"I like the 1st 1 not the 22nd 1." %&gt;% replace_ordinal %&gt;% replace_number

## End(Not run)
</code></pre>

<hr>
<h2 id='replace_symbol'>Replace Symbols With Word Equivalents</h2><span id='topic+replace_symbol'></span>

<h3>Description</h3>

<p>This function replaces symbols with word equivalents (e.g., <code>@</code> becomes 
<code>"at"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_symbol(
  text.var,
  dollar = TRUE,
  percent = TRUE,
  pound = TRUE,
  at = TRUE,
  and = TRUE,
  with = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_symbol_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="replace_symbol_+3A_dollar">dollar</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces dollar sign ($) with 
<code>"dollar"</code>.</p>
</td></tr>
<tr><td><code id="replace_symbol_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces percent sign (%) with 
<code>"percent"</code>.</p>
</td></tr>
<tr><td><code id="replace_symbol_+3A_pound">pound</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces pound sign (#) with 
<code>"number"</code>.</p>
</td></tr>
<tr><td><code id="replace_symbol_+3A_at">at</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces at sign (@) with <code>"at"</code>.</p>
</td></tr>
<tr><td><code id="replace_symbol_+3A_and">and</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces and sign (&amp;) with <code>"and"</code>.</p>
</td></tr>
<tr><td><code id="replace_symbol_+3A_with">with</code></td>
<td>
<p>logical.  If <code>TRUE</code> replaces with sign (w/) with 
<code>"with"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector with symbols replaced..
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bracketX">bracketX</a></code>,
<code><a href="#topic+qprep">qprep</a></code>,
<code><a href="#topic+replace_abbreviation">replace_abbreviation</a></code>,
<code><a href="#topic+replace_contraction">replace_contraction</a></code>,
<code><a href="#topic+replace_number">replace_number</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("I am @ Jon's &amp; Jim's w/ Marry", 
    "I owe $41 for food", 
    "two is 10% of a #")
replace_symbol(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='replacer'>Replace Cells in a Matrix or Data Frame</h2><span id='topic+replacer'></span>

<h3>Description</h3>

<p>Replace elements of a dataframe, matrix or vector with least restrictive 
class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replacer(dat, replace = 0, with = "-")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replacer_+3A_dat">dat</code></td>
<td>
<p>Data; either a dataframe, matrix or vector.</p>
</td></tr>
<tr><td><code id="replacer_+3A_replace">replace</code></td>
<td>
<p>Element to replace.</p>
</td></tr>
<tr><td><code id="replacer_+3A_with">with</code></td>
<td>
<p>Replacement element.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe, matrix or vector with the element replaced.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
replacer(mtcars[1:10, ], 0, "REP")
replacer(mtcars[1:10, ], 4, NA)
replacer(c("a", "b"), "a", "foo")
#replace missing values (NA)
dat &lt;- data.frame(matrix(sample(c(1:3, NA), 25, TRUE), ncol=5))
replacer(dat, NA, "FOO")

## End(Not run)
</code></pre>

<hr>
<h2 id='rm_row'>Remove Rows That Contain Markers</h2><span id='topic+rm_row'></span><span id='topic+rm_empty_row'></span>

<h3>Description</h3>

<p><code>rm_row</code> - Remove rows from a data set that contain a given marker/term.
</p>
<p><code>rm_empty_row</code> - Removes the empty rows of a data set that are common in 
reading in data (default method in <code><a href="#topic+read.transcript">read.transcript</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rm_row(
  dataframe,
  search.column,
  terms,
  contains = FALSE,
  ignore.case = FALSE,
  keep.rownames = FALSE,
  ...
)

rm_empty_row(dataframe)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rm_row_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe object.</p>
</td></tr>
<tr><td><code id="rm_row_+3A_search.column">search.column</code></td>
<td>
<p>Column name to search for markers/terms.</p>
</td></tr>
<tr><td><code id="rm_row_+3A_terms">terms</code></td>
<td>
<p>Terms/markers of the rows that are to be removed from the 
dataframe.  The term/marker must appear at the beginning of the string and is 
case sensitive.</p>
</td></tr>
<tr><td><code id="rm_row_+3A_contains">contains</code></td>
<td>
<p>logical.  If <code>TRUE</code> <code>rm_row</code> searches for the terms 
anywhere within the string.  If <code>FALSE</code> <code>rm_row</code> searches only the 
beginning of the string.</p>
</td></tr>
<tr><td><code id="rm_row_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> case is ignored during matching, 
if <code>FALSE</code>the pattern matching is case sensitive.</p>
</td></tr>
<tr><td><code id="rm_row_+3A_keep.rownames">keep.rownames</code></td>
<td>
<p>logical.  If <code>TRUE</code> the original, non-sequential, 
rownames will be used.</p>
</td></tr>
<tr><td><code id="rm_row_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="base.html#topic+grepl">grepl</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rm_row</code> - returns a dataframe with the termed/markered rows 
removed.
</p>
<p><code>rm_empty_row</code> - returns a dataframe with empty rows removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#rm_row EXAMPLE:
rm_row(DATA, "person", c("sam", "greg"))
rm_row(DATA, 1, c("sam", "greg"))
rm_row(DATA, "state", c("Comp"))
rm_row(DATA, "state", c("I "))
rm_row(DATA, "state", c("you"), contains = TRUE, ignore.case=TRUE)

#rm_empty_row EXAMPLE:
(dat &lt;- rbind.data.frame(DATA[, c(1, 4)], matrix(rep(" ", 4), 
   ncol =2, dimnames=list(12:13, colnames(DATA)[c(1, 4)]))))
rm_empty_row(dat)

## End(Not run)
</code></pre>

<hr>
<h2 id='rm_stopwords'>Remove Stop Words</h2><span id='topic+rm_stopwords'></span><span id='topic+rm_stop'></span><span id='topic++25sw+25'></span>

<h3>Description</h3>

<p>Removal of stop words in a variety of contexts
.
</p>
<p><code>%sw%</code> - Binary operator version of <code><a href="#topic+rm_stopwords">rm_stopwords</a></code>  that
defaults to <code>separate = FALSE</code>..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rm_stopwords(
  text.var,
  stopwords = qdapDictionaries::Top25Words,
  unlist = FALSE,
  separate = TRUE,
  strip = FALSE,
  unique = FALSE,
  char.keep = NULL,
  names = FALSE,
  ignore.case = TRUE,
  apostrophe.remove = FALSE,
  ...
)

rm_stop(
  text.var,
  stopwords = qdapDictionaries::Top25Words,
  unlist = FALSE,
  separate = TRUE,
  strip = FALSE,
  unique = FALSE,
  char.keep = NULL,
  names = FALSE,
  ignore.case = TRUE,
  apostrophe.remove = FALSE,
  ...
)

text.var %sw% stopwords
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rm_stopwords_+3A_text.var">text.var</code></td>
<td>
<p>A character string of text or a vector of character strings.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_stopwords">stopwords</code></td>
<td>
<p>A character vector of words to remove from the text.  qdap 
has a number of data sets that can be used as stop words including: 
<code>Top200Words</code>, <code>Top100Words</code>, <code>Top25Words</code>.  For the tm 
package's traditional English stop words use <code>tm::stopwords("english")</code>.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_unlist">unlist</code></td>
<td>
<p>logical.  If <code>TRUE</code> unlists into one vector.  General use 
intended for when separate is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_separate">separate</code></td>
<td>
<p>logical.  If <code>TRUE</code> separates sentences into words. If 
<code>FALSE</code> retains sentences.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_strip">strip</code></td>
<td>
<p>logical.  IF <code>TRUE</code> strips the text of all punctuation 
except apostrophes.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_unique">unique</code></td>
<td>
<p>logical.  If <code>TRUE</code> keeps only unique words (if unlist is 
<code>TRUE</code>) or sentences (if unlist is <code>FALSE</code>).  General use intended 
for when unlist is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_char.keep">char.keep</code></td>
<td>
<p>If strip is <code>TRUE</code> this argument provides a means of 
retaining supplied character(s).</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_names">names</code></td>
<td>
<p>logical.  If <code>TRUE</code> will name the elements of the vector or 
list with the original <code>text.var</code>.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> stopwords will be removed 
regardless of case.  Additionally, case will be stripped from the text.  If 
<code>FALSE</code> stop word removal is contingent upon case.  Additionally, case 
is not stripped.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophe's from 
the output.</p>
</td></tr>
<tr><td><code id="rm_stopwords_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+strip">strip</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of sentences, vector of words, or (default) a list 
of vectors of words with stop words removed.  Output depends on supplied 
arguments.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+strip">strip</a></code>, 
<code><a href="#topic+bag_o_words">bag_o_words</a></code>,
<code><a href="tm.html#topic+stopwords">stopwords</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
rm_stopwords(DATA$state)
rm_stopwords(DATA$state, tm::stopwords("english"))
rm_stopwords(DATA$state, Top200Words)
rm_stopwords(DATA$state, Top200Words, strip = TRUE)
rm_stopwords(DATA$state, Top200Words, separate = FALSE)
rm_stopwords(DATA$state, Top200Words, separate = FALSE, ignore.case = FALSE)
rm_stopwords(DATA$state, Top200Words, unlist = TRUE)
rm_stopwords(DATA$state, Top200Words, unlist = TRUE, strip=TRUE)
rm_stop(DATA$state, Top200Words, unlist = TRUE, unique = TRUE)

c("I like it alot", "I like it too") %sw% qdapDictionaries::Top25Words

## End(Not run)
</code></pre>

<hr>
<h2 id='sample.time.span'>Minimal Time Span Data Set</h2><span id='topic+sample.time.span'></span>

<h3>Description</h3>

<p>A fictitious dataset containing time spans for codes A and B.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sample.time.span)
</code></pre>


<h3>Format</h3>

<p>A data frame with 9 rows and 6 variables
</p>


<h3>Details</h3>

 
<ul>
<li><p> code. The qualitative code.
</p>
</li>
<li><p> start. The integer start time.
</p>
</li>
<li><p> end. The integer end time. 
</p>
</li>
<li><p> Start. The chron start time.
</p>
</li>
<li><p> End. The chron end time.
</p>
</li>
<li><p> variable. An arbitrary single time repeated measures variable (ignore).
</p>
</li></ul>


<hr>
<h2 id='scores'>Generic Scores Method</h2><span id='topic+scores'></span>

<h3>Description</h3>

<p>Access the scores dataframes from select qdap outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_+3A_x">x</code></td>
<td>
<p>A qdap object (list) with a dataframe of scores (e.g., 
<code><a href="#topic+fry">fry</a></code>, <code><a href="#topic+formality">formality</a></code>).</p>
</td></tr>
<tr><td><code id="scores_+3A_...">...</code></td>
<td>
<p>Arguments passed to scores method of other classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data.frame of scores.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+counts">counts</a></code>
</p>
<p><code><a href="#topic+proportions">proportions</a></code>
</p>
<p><code><a href="#topic+preprocessed">preprocessed</a></code>
</p>

<hr>
<h2 id='scores.automated_readability_index'>Readability Measures</h2><span id='topic+scores.automated_readability_index'></span>

<h3>Description</h3>

<p><code>scores.automated_readability_index</code> - View scores from <code><a href="#topic+automated_readability_index">automated_readability_index</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'automated_readability_index'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.automated_readability_index_+3A_x">x</code></td>
<td>
<p>The automated_readability_index object.</p>
</td></tr>
<tr><td><code id="scores.automated_readability_index_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>automated_readability_index Method for scores
</p>

<hr>
<h2 id='scores.character_table'>Term Counts</h2><span id='topic+scores.character_table'></span>

<h3>Description</h3>

<p>View character_table scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'character_table'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.character_table_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+character_table">character_table</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.character_table_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>character_table Method for scores
</p>

<hr>
<h2 id='scores.coleman_liau'>Readability Measures</h2><span id='topic+scores.coleman_liau'></span>

<h3>Description</h3>

<p><code>scores.coleman_liau</code> - View scores from <code><a href="#topic+coleman_liau">coleman_liau</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coleman_liau'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.coleman_liau_+3A_x">x</code></td>
<td>
<p>The coleman_liau object.</p>
</td></tr>
<tr><td><code id="scores.coleman_liau_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>coleman_liau Method for scores
</p>

<hr>
<h2 id='scores.end_mark_by'>Question Counts</h2><span id='topic+scores.end_mark_by'></span>

<h3>Description</h3>

<p>View end_mark_by scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'end_mark_by'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.end_mark_by_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+end_mark_by">end_mark_by</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.end_mark_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>end_mark_by Method for scores
</p>

<hr>
<h2 id='scores.flesch_kincaid'>Readability Measures</h2><span id='topic+scores.flesch_kincaid'></span>

<h3>Description</h3>

<p><code>scores.flesch_kincaid</code> - View scores from <code><a href="#topic+flesch_kincaid">flesch_kincaid</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'flesch_kincaid'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.flesch_kincaid_+3A_x">x</code></td>
<td>
<p>The flesch_kincaid object.</p>
</td></tr>
<tr><td><code id="scores.flesch_kincaid_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>flesch_kincaid Method for scores
</p>

<hr>
<h2 id='scores.formality'>Formality</h2><span id='topic+scores.formality'></span>

<h3>Description</h3>

<p>View formality scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formality'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.formality_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+formality">formality</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.formality_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>formality Method for scores
</p>

<hr>
<h2 id='scores.fry'>Readability Measures</h2><span id='topic+scores.fry'></span>

<h3>Description</h3>

<p><code>scores.fry</code> - View scores from <code><a href="#topic+fry">fry</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fry'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.fry_+3A_x">x</code></td>
<td>
<p>The fry object.</p>
</td></tr>
<tr><td><code id="scores.fry_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>fry Method for scores
</p>

<hr>
<h2 id='scores.lexical_classification'>Lexical Classification</h2><span id='topic+scores.lexical_classification'></span>

<h3>Description</h3>

<p><code>scores.lexical_classification</code> - View scores from <code><a href="#topic+lexical_classification">lexical_classification</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lexical_classification'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.lexical_classification_+3A_x">x</code></td>
<td>
<p>The lexical_classification object.</p>
</td></tr>
<tr><td><code id="scores.lexical_classification_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>lexical_classification Method for scores
</p>

<hr>
<h2 id='scores.linsear_write'>Readability Measures</h2><span id='topic+scores.linsear_write'></span>

<h3>Description</h3>

<p><code>scores.linsear_write</code> - View scores from <code><a href="#topic+linsear_write">linsear_write</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'linsear_write'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.linsear_write_+3A_x">x</code></td>
<td>
<p>The linsear_write object.</p>
</td></tr>
<tr><td><code id="scores.linsear_write_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>linsear_write Method for scores
</p>

<hr>
<h2 id='scores.object_pronoun_type'>Question Counts</h2><span id='topic+scores.object_pronoun_type'></span>

<h3>Description</h3>

<p>View object_pronoun_type scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'object_pronoun_type'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.object_pronoun_type_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+object_pronoun_type">object_pronoun_type</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.object_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>object_pronoun_type Method for scores
</p>

<hr>
<h2 id='scores.polarity'>Polarity</h2><span id='topic+scores.polarity'></span>

<h3>Description</h3>

<p><code>scores.polarity</code> - View scores from <code><a href="#topic+polarity">polarity</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polarity'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.polarity_+3A_x">x</code></td>
<td>
<p>The polarity object.</p>
</td></tr>
<tr><td><code id="scores.polarity_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>polarity Method for scores
</p>

<hr>
<h2 id='scores.pos_by'>Parts of Speech</h2><span id='topic+scores.pos_by'></span>

<h3>Description</h3>

<p>View pos_by scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pos_by'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.pos_by_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+pos_by">pos_by</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.pos_by_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pos_by Method for scores
</p>

<hr>
<h2 id='scores.pronoun_type'>Question Counts</h2><span id='topic+scores.pronoun_type'></span>

<h3>Description</h3>

<p>View pronoun_type scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pronoun_type'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.pronoun_type_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+pronoun_type">pronoun_type</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pronoun_type Method for scores
</p>

<hr>
<h2 id='scores.question_type'>Question Counts</h2><span id='topic+scores.question_type'></span>

<h3>Description</h3>

<p>View question_type scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'question_type'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.question_type_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+question_type">question_type</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.question_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>question_type Method for scores
</p>

<hr>
<h2 id='scores.SMOG'>Readability Measures</h2><span id='topic+scores.SMOG'></span>

<h3>Description</h3>

<p><code>scores.SMOG</code> - View scores from <code><a href="#topic+SMOG">SMOG</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SMOG'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.SMOG_+3A_x">x</code></td>
<td>
<p>The SMOG object.</p>
</td></tr>
<tr><td><code id="scores.SMOG_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SMOG Method for scores
</p>

<hr>
<h2 id='scores.subject_pronoun_type'>Question Counts</h2><span id='topic+scores.subject_pronoun_type'></span>

<h3>Description</h3>

<p>View subject_pronoun_type scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subject_pronoun_type'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.subject_pronoun_type_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+subject_pronoun_type">subject_pronoun_type</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.subject_pronoun_type_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>subject_pronoun_type Method for scores
</p>

<hr>
<h2 id='scores.termco'>Term Counts</h2><span id='topic+scores.termco'></span>

<h3>Description</h3>

<p>View termco scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'termco'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.termco_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+termco">termco</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.termco_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>termco Method for scores
</p>

<hr>
<h2 id='scores.word_length'>Word Length Counts</h2><span id='topic+scores.word_length'></span>

<h3>Description</h3>

<p>View word_length scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_length'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.word_length_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+word_length">word_length</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.word_length_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>word_length Method for scores
</p>

<hr>
<h2 id='scores.word_position'>Word Position</h2><span id='topic+scores.word_position'></span>

<h3>Description</h3>

<p>View word_position scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_position'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.word_position_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+word_position">word_position</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.word_position_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>word_position Method for scores
</p>

<hr>
<h2 id='scores.word_stats'>Word Stats</h2><span id='topic+scores.word_stats'></span>

<h3>Description</h3>

<p>View question_type scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'word_stats'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores.word_stats_+3A_x">x</code></td>
<td>
<p>The <code><a href="#topic+question_type">question_type</a></code> object.</p>
</td></tr>
<tr><td><code id="scores.word_stats_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>question_type Method for scores
</p>

<hr>
<h2 id='scrubber'>Clean Imported Text</h2><span id='topic+scrubber'></span>

<h3>Description</h3>

<p>Use to clean text variables when importing a new data set.  Removes extra
white spaces other textual anomalies that may cause errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scrubber(
  text.var,
  num2word = FALSE,
  rm.quote = TRUE,
  fix.comma = TRUE,
  fix.space = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scrubber_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="scrubber_+3A_num2word">num2word</code></td>
<td>
<p>logical If <code>TRUE</code> replaces a numbers with text 
representations.</p>
</td></tr>
<tr><td><code id="scrubber_+3A_rm.quote">rm.quote</code></td>
<td>
<p>logical If <code>TRUE</code> removes any <code>\"</code>.</p>
</td></tr>
<tr><td><code id="scrubber_+3A_fix.comma">fix.comma</code></td>
<td>
<p>logical If <code>TRUE</code> removes any spaces before a comma.</p>
</td></tr>
<tr><td><code id="scrubber_+3A_fix.space">fix.space</code></td>
<td>
<p>logical.  If <code>TRUE</code> extra spaces before endmarks are 
removed.</p>
</td></tr>
<tr><td><code id="scrubber_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+replace_number">replace_number</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a parsed character vector.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+strip">strip</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("I like 456 dogs\t  , don't you?", 'The end"')
scrubber(x)
scrubber(x, TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='Search'>Search Columns of a Data Frame</h2><span id='topic+Search'></span><span id='topic+boolean_search'></span><span id='topic++25bs+25'></span>

<h3>Description</h3>

<p><code>Search</code> - Find terms located in columns of a data frame.
</p>
<p><code>boolean_search</code> - Conducts a Boolean search for terms/strings within a 
character vector.
</p>
<p><code>%bs%</code> - Binary operator version of <code><a href="#topic+boolean_search">boolean_search</a></code> .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Search(dataframe, term, column.name = NULL, max.distance = 0.02, ...)

boolean_search(
  text.var,
  terms,
  ignore.case = TRUE,
  values = FALSE,
  exclude = NULL,
  apostrophe.remove = FALSE,
  char.keep = NULL,
  digit.remove = FALSE
)

text.var %bs% terms
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Search_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe object to search.</p>
</td></tr>
<tr><td><code id="Search_+3A_term">term</code></td>
<td>
<p>A character string to search for.</p>
</td></tr>
<tr><td><code id="Search_+3A_column.name">column.name</code></td>
<td>
<p>Optional column of the data frame to search (character 
name or integer index).</p>
</td></tr>
<tr><td><code id="Search_+3A_max.distance">max.distance</code></td>
<td>
<p>Maximum distance allowed for a match. Expressed either as 
integer, or as a fraction of the pattern length times the maximal 
transformation cost (will be replaced by the smallest integer not less than 
the corresponding fraction).</p>
</td></tr>
<tr><td><code id="Search_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="Search_+3A_terms">terms</code></td>
<td>
<p>A character string(s) to search for.  The terms are arranged in 
a single string with AND (use <code>AND</code> or <code>&amp;&amp;</code> to connect terms 
together) and OR (use <code>OR</code> or <code>||</code> to allow for searches of 
either set of terms.  Spaces may be used to control what is searched for.  
For example using <code>" I "</code> on <code>c("I'm", "I want", "in")</code> will result
in <code>FALSE TRUE FALSE</code> whereas <code>"I"</code> will match all three (if case 
is ignored).</p>
</td></tr>
<tr><td><code id="Search_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> case is ignored.</p>
</td></tr>
<tr><td><code id="Search_+3A_values">values</code></td>
<td>
<p>logical.  Should the values be returned or the index of the 
values.</p>
</td></tr>
<tr><td><code id="Search_+3A_exclude">exclude</code></td>
<td>
<p>Terms to exclude from the search.  If one of these terms is 
found in the sentence it cannot be returned.</p>
</td></tr>
<tr><td><code id="Search_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophes from 
the text before examining.</p>
</td></tr>
<tr><td><code id="Search_+3A_char.keep">char.keep</code></td>
<td>
<p>A character vector of symbol character (i.e., punctuation) 
that strip should keep.  The default is to strip everything except 
apostrophes. <code><a href="#topic+termco">termco</a></code> attempts to auto detect characters to 
keep based on the elements in <code>match.list</code>.</p>
</td></tr>
<tr><td><code id="Search_+3A_digit.remove">digit.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> strips digits from the text 
before counting. <code><a href="#topic+termco">termco</a></code> attempts to auto detect if digits 
should be retained based on the elements in <code>match.list</code>.</p>
</td></tr>
<tr><td><code id="Search_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>agrep</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The terms string is first split by the OR separators into a list.  
Next the list of vectors is split on the AND separator to produce a list of 
vectors of search terms.  Each sentence is matched against the terms.  For a 
sentence to be counted it must fit all of the terms in an AND Boolean or one 
of the conditions in an OR Boolean.
</p>


<h3>Value</h3>

<p><code>Search</code> - Returns the rows of the data frame that match the 
search term.
</p>
<p><code>boolean_search</code> - Returns the values (or indices) of a vector of strings that match
given terms.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trans_context">trans_context</a></code>
</p>
<p><code><a href="#topic+termco">termco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Dataframe search:
(SampDF &lt;- data.frame("islands"=names(islands)[1:32],mtcars, row.names=NULL))

Search(SampDF, "Cuba", "islands")
Search(SampDF, "New", "islands")
Search(SampDF, "Ho")
Search(SampDF, "Ho", max.distance = 0)
Search(SampDF, "Axel Heiberg")
Search(SampDF, 19) #too much tolerance in max.distance
Search(SampDF, 19, max.distance = 0)
Search(SampDF, 19, "qsec", max.distance = 0)

##Boolean search:
boolean_search(DATA$state, " I ORliar&amp;&amp;stinks")
boolean_search(DATA$state, " I &amp;&amp;.", values=TRUE)
boolean_search(DATA$state, " I OR.", values=TRUE)
boolean_search(DATA$state, " I &amp;&amp;.")

## Exclusion:
boolean_search(DATA$state, " I ||.", values=TRUE)
boolean_search(DATA$state, " I ||.", exclude = c("way", "truth"), values=TRUE)

## From stackoverflow: http://stackoverflow.com/q/19640562/1000343
dat &lt;- data.frame(x = c("Doggy", "Hello", "Hi Dog", "Zebra"), y = 1:4)
z &lt;- data.frame(z =c("Hello", "Dog"))

dat[boolean_search(dat$x, paste(z$z, collapse = "OR")), ]

## Binary operator version
dat[dat$x %bs% paste(z$z, collapse = "OR"), ]

## Passing to `trans_context`
inds &lt;- boolean_search(DATA.SPLIT$state, " I&amp;&amp;.|| I&amp;&amp;!", ignore.case = FALSE)
with(DATA.SPLIT, trans_context(state, person, inds=inds))

(inds2 &lt;- boolean_search(raj$dialogue, spaste(paste(negation.words, 
    collapse = " || "))))
trans_context(raj$dialogue, raj$person, inds2)

## End(Not run)
</code></pre>

<hr>
<h2 id='sentiment_frame'>Power Score (Sentiment Analysis)</h2><span id='topic+sentiment_frame'></span>

<h3>Description</h3>

<p><code>sentiment_frame</code> - Generate a sentiment lookup hash table  
for use with the <code>xxx.frame</code> argument of various sentiment functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentiment_frame(positives, negatives, pos.weights = 1, neg.weights = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentiment_frame_+3A_positives">positives</code></td>
<td>
<p>A character vector of positive words.</p>
</td></tr>
<tr><td><code id="sentiment_frame_+3A_negatives">negatives</code></td>
<td>
<p>A character vector of negative words.</p>
</td></tr>
<tr><td><code id="sentiment_frame_+3A_pos.weights">pos.weights</code></td>
<td>
<p>A vector of weights to weight each positive word by.
Length must be equal to length of <code>postives</code> or length 1 (if 1 weight 
will be recycled).</p>
</td></tr>
<tr><td><code id="sentiment_frame_+3A_neg.weights">neg.weights</code></td>
<td>
<p>A vector of weights to weight each negative word by.
Length must be equal to length of <code>negatives</code> or length 1 (if 1 weight 
will be recycled).</p>
</td></tr>
</table>

<hr>
<h2 id='sentSplit'>Sentence Splitting</h2><span id='topic+sentSplit'></span><span id='topic+sentCombine'></span><span id='topic+TOT'></span><span id='topic+sent_detect'></span><span id='topic+sent_detect_nlp'></span>

<h3>Description</h3>

<p><code>sentSplit</code> - Splits turns of talk into individual sentences (provided 
proper punctuation is used).  This procedure is usually done as part of the 
data read in and cleaning process.
</p>
<p><code>sentCombine</code> - Combines sentences by the same grouping variable together.
</p>
<p><code>TOT</code> - Convert the tot column from <code><a href="#topic+sentSplit">sentSplit</a></code> to 
turn of talk index (no sub sentence).  Generally, for internal use.
</p>
<p><code>sent_detect</code> - Detect and split sentences on endmark boundaries.
</p>
<p><code>sent_detect_nlp</code> - Detect and split sentences on endmark boundaries 
using <span class="pkg">openNLP</span> &amp; <span class="pkg">NLP</span> utilities which matches the onld version of
the <span class="pkg">openNLP</span> package's now removed <code>sentDetect</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentSplit(
  dataframe,
  text.var,
  rm.var = NULL,
  endmarks = c("?", ".", "!", "|"),
  incomplete.sub = TRUE,
  rm.bracket = TRUE,
  stem.col = FALSE,
  text.place = "right",
  verbose = is.global(2),
  ...
)

sentCombine(text.var, grouping.var = NULL, as.list = FALSE)

TOT(tot)

sent_detect(
  text.var,
  endmarks = c("?", ".", "!", "|"),
  incomplete.sub = TRUE,
  rm.bracket = TRUE,
  ...
)

sent_detect_nlp(text.var, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentSplit_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe that contains the person and text variable.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_rm.var">rm.var</code></td>
<td>
<p>An optional character vector of 1 or 2 naming the variables 
that are repeated measures (This will restart the <strong>&quot;tot&quot;</strong> column).</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_endmarks">endmarks</code></td>
<td>
<p>A character vector of endmarks to split turns of talk into 
sentences.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_incomplete.sub">incomplete.sub</code></td>
<td>
<p>logical.  If <code>TRUE</code> detects incomplete sentences 
and replaces with <code>"|"</code>.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_rm.bracket">rm.bracket</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes brackets from the text.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_stem.col">stem.col</code></td>
<td>
<p>logical.  If <code>TRUE</code> stems the text as a new column.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_text.place">text.place</code></td>
<td>
<p>A character string giving placement location of the text 
column. This must be one of the strings <code>"original"</code>, <code>"right"</code> or 
<code>"left"</code>.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_verbose">verbose</code></td>
<td>
<p>logical.  If <code>TRUE</code> select diagnostics from 
<code><a href="#topic+check_text">check_text</a></code> are reported.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_as.list">as.list</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns the output as a list. If 
<code>FALSE</code> the output is returned as a dataframe.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_tot">tot</code></td>
<td>
<p>A tot column from a <code><a href="#topic+sentSplit">sentSplit</a></code> output.</p>
</td></tr>
<tr><td><code id="sentSplit_+3A_...">...</code></td>
<td>
<p>Additional options passed to <code><a href="#topic+stem2df">stem2df</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>sentSplit</code> - returns a dataframe with turn of talk broken apart 
into sentences.  Optionally a stemmed version of the text variable may be 
returned as well.
</p>
<p><code>sentCombine</code> - returns a list of vectors with the continuous 
sentences by grouping.var pasted together. 
returned as well.
</p>
<p><code>TOT</code> - returns a numeric vector of the turns of talk without 
sentence sub indexing (e.g. 3.2 become 3).
</p>
<p><code>sent_detect</code> - returns a character vector of sentences split on
endmark.
</p>
<p><code>sent_detect</code> - returns a character vector of sentences split on
endmark.
</p>


<h3>Warning</h3>

<p><code><a href="#topic+sentSplit">sentSplit</a></code> requires the dialogue (text) 
column to be cleaned in a particular way.  The data should contain qdap
punctuation marks (<code>c("?", ".", "!", "|")</code>) at the end of each sentence.
Additionally, extraneous punctuation such as abbreviations should be removed
(see <code><a href="#topic+replace_abbreviation">replace_abbreviation</a></code>).
Trailing sentences such as <b>I thought I...</b> will be treated as 
incomplete and marked with <code>"|"</code> to denote an incomplete/trailing 
sentence.
</p>


<h3>Suggestion</h3>

<p>It is recommended that the user runs <code><a href="#topic+check_text">check_text</a></code> on the 
output of <code>sentSplit</code>'s text column.
</p>


<h3>Author(s)</h3>

<p>Dason Kurkiewicz and Tyler Rinker &lt;tyler.rinker@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bracketX">bracketX</a></code>, 
<code><a href="#topic+incomplete_replace">incomplete_replace</a></code>,
<code><a href="#topic+stem2df">stem2df</a></code> ,
<code><a href="#topic+TOT">TOT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## `sentSplit` EXAMPLE:
(out &lt;- sentSplit(DATA, "state"))
out %&amp;% check_text()  ## check output text
sentSplit(DATA, "state", stem.col = TRUE)
sentSplit(DATA, "state", text.place = "left")
sentSplit(DATA, "state", text.place = "original")
sentSplit(raj, "dialogue")[1:20, ]

## plotting
plot(out)
plot(out, grouping.var = "person")

out2 &lt;- sentSplit(DATA2, "state", rm.var = c("class", "day"))
plot(out2)
plot(out2, grouping.var = "person")
plot(out2, grouping.var = "person", rm.var = "day")
plot(out2, grouping.var = "person", rm.var = c("day", "class"))

## `sentCombine` EXAMPLE:
dat &lt;- sentSplit(DATA, "state") 
sentCombine(dat$state, dat$person)
truncdf(sentCombine(dat$state, dat$sex), 50)

## `TOT` EXAMPLE:
dat &lt;- sentSplit(DATA, "state") 
TOT(dat$tot)

## `sent_detect`
sent_detect(DATA$state)

## NLP based sentence splitting 
sent_detect_nlp(DATA$state)

## End(Not run)
</code></pre>

<hr>
<h2 id='space_fill'>Replace Spaces</h2><span id='topic+space_fill'></span>

<h3>Description</h3>

<p>Replace spaces in words groups that should be grouped together.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>space_fill(
  text.var,
  terms,
  sep = "~~",
  rm.extra = TRUE,
  ignore.case = TRUE,
  fixed = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="space_fill_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="space_fill_+3A_terms">terms</code></td>
<td>
<p>A character vector of grouped word terms to insert a new 
separating/space character.</p>
</td></tr>
<tr><td><code id="space_fill_+3A_sep">sep</code></td>
<td>
<p>A character string to separate the terms.</p>
</td></tr>
<tr><td><code id="space_fill_+3A_rm.extra">rm.extra</code></td>
<td>
<p>logical.  Should trailing, leading and &gt; 1 continuous white 
spaces be removed?</p>
</td></tr>
<tr><td><code id="space_fill_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>FALSE</code>, the pattern matching is case sensitive 
and if <code>TRUE</code>, case is ignored during matching.</p>
</td></tr>
<tr><td><code id="space_fill_+3A_fixed">fixed</code></td>
<td>
<p>logical. If <code>TRUE</code>, pattern is a string to be matched as 
is. Overrides all conflicting arguments.</p>
</td></tr>
<tr><td><code id="space_fill_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="base.html#topic+gsub">gsub</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+space_fill">space_fill</a></code> is useful for keeping grouped words 
together.  Many functions in qdap take a <code>char.keep</code> or 
<code>char2space</code> argument.  This can be used to prepare multi word phrases 
(e.g., proper nouns) as a single unit.
</p>


<h3>Value</h3>

<p>Returns a character vector with extra, trailing and/or leading spaces
removed.
</p>


<h3>Note</h3>

<p><code>link[qdap]{strip}</code> by default does not remove the double tilde 
<code>"~~"</code> character.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- c("I want to hear the Dr. Martin Luther King Jr. speech.",
    "I also want to go to the white House to see President Obama speak.")

keeps &lt;- c("Dr. Martin Luther King Jr.", "The White House", "President Obama")
space_fill(x, keeps)
strip(space_fill(x, keeps))

## End(Not run)
</code></pre>

<hr>
<h2 id='spaste'>Add Leading/Trailing Spaces</h2><span id='topic+spaste'></span>

<h3>Description</h3>

<p>Adds trailing and/or leading spaces to a vector of terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaste(terms, trailing = TRUE, leading = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spaste_+3A_terms">terms</code></td>
<td>
<p>A character vector of terms to insert trailing and/or leading 
spaces.</p>
</td></tr>
<tr><td><code id="spaste_+3A_trailing">trailing</code></td>
<td>
<p>logical.  If <code>TRUE</code> inserts a trailing space in the 
terms.</p>
</td></tr>
<tr><td><code id="spaste_+3A_leading">leading</code></td>
<td>
<p>logical.  If <code>TRUE</code> inserts a leading space in the terms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector with trailing and/or leading spaces.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spaste(Top25Words)
spaste(Top25Words, FALSE)
spaste(Top25Words, trailing = TRUE, leading = FALSE) #or
spaste(Top25Words, , FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='speakerSplit'>Break and Stretch if Multiple Persons per Cell</h2><span id='topic+speakerSplit'></span>

<h3>Description</h3>

<p>Look for cells with multiple people and create separate rows for each person.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>speakerSplit(
  dataframe,
  person.var = 1,
  sep = c("and", "&amp;", ","),
  track.reps = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="speakerSplit_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe that contains the person variable.</p>
</td></tr>
<tr><td><code id="speakerSplit_+3A_person.var">person.var</code></td>
<td>
<p>The person variable to be stretched.</p>
</td></tr>
<tr><td><code id="speakerSplit_+3A_sep">sep</code></td>
<td>
<p>The separator(s) to search for and break on.  Default is: 
c(&quot;and&quot;, &quot;&amp;&quot;, &quot;,&quot;)</p>
</td></tr>
<tr><td><code id="speakerSplit_+3A_track.reps">track.reps</code></td>
<td>
<p>logical.  If <code>TRUE</code> leaves the row names of person 
variable cells that were repeated and stretched.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an expanded dataframe with person variable stretched and 
accompanying rows repeated.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
DATA$person &lt;- as.character(DATA$person)
DATA$person[c(1, 4, 6)] &lt;- c("greg, sally, &amp; sam", 
    "greg, sally", "sam and sally")

speakerSplit(DATA)
speakerSplit(DATA, track.reps=TRUE)

DATA$person[c(1, 4, 6)] &lt;- c("greg_sally_sam", 
    "greg.sally", "sam; sally")

speakerSplit(DATA, sep = c(".", "_", ";"))

DATA &lt;- qdap::DATA  #reset DATA

## End(Not run)
</code></pre>

<hr>
<h2 id='stemmer'>Stem Text</h2><span id='topic+stemmer'></span><span id='topic+stem_words'></span><span id='topic+stem2df'></span>

<h3>Description</h3>

<p><code>stemmer</code> - Stems a vector of text strings (A wrapper for the <span class="pkg">tm</span> 
package's <code><a href="tm.html#topic+stemDocument">stemDocument</a></code>.
</p>
<p><code>stem_words</code> - Wrapper for stemmer that stems a vector of words.
</p>
<p><code>stem2df</code> - Wrapper for stemmer that stems a vector of text strings 
and returns a dataframe with the vector added..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stemmer(
  text.var,
  rm.bracket = TRUE,
  capitalize = TRUE,
  warn = TRUE,
  char.keep = "~~",
  ...
)

stem_words(...)

stem2df(dataframe, text.var, stem.name = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stemmer_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.  In <code><a href="#topic+stemmer">stemmer</a></code> this is a 
vector text string. For <code><a href="#topic+stem2df">stem2df</a></code> this is a character 
vector of length one naming the text column.</p>
</td></tr>
<tr><td><code id="stemmer_+3A_rm.bracket">rm.bracket</code></td>
<td>
<p>logical.  If <code>TRUE</code> brackets are removed from the text.</p>
</td></tr>
<tr><td><code id="stemmer_+3A_capitalize">capitalize</code></td>
<td>
<p>logical.  If <code>TRUE</code> selected terms are capitalized.</p>
</td></tr>
<tr><td><code id="stemmer_+3A_warn">warn</code></td>
<td>
<p>logical.  If <code>TRUE</code> warns about rows not ending with 
standard qdap punctuation endmarks.</p>
</td></tr>
<tr><td><code id="stemmer_+3A_char.keep">char.keep</code></td>
<td>
<p>A character vector of symbols that should be kept within 
sentences.</p>
</td></tr>
<tr><td><code id="stemmer_+3A_...">...</code></td>
<td>
<p>Various: <br />
<em><code>stemmer</code> - Other arguments passed to 
<code><a href="#topic+capitalizer">capitalizer</a></code></em> <br />
<em><code>stem_words</code> - Words or terms.</em> <br />
<em><code>stem2df</code> - Other arguments passed to 
<code><a href="#topic+stemmer">stemmer</a></code></em></p>
</td></tr>
<tr><td><code id="stemmer_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe object.</p>
</td></tr>
<tr><td><code id="stemmer_+3A_stem.name">stem.name</code></td>
<td>
<p>A character vector of length one for the stemmed column.  If 
<code>NULL</code> defaults to <code>"stem.text"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>stemmer</code> - returns a character vector with stemmed text.
</p>
<p><code>stem_words</code> - returns a vector of individually stemmed words.
</p>
<p><code>stem2df</code> - returns a dataframe with a character vector with 
stemmed text.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+capitalizer">capitalizer</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#stemmer EXAMPLE:
stemmer(DATA$state)
out1 &lt;- stemmer(raj$dialogue)
htruncdf(out1, 20, 60)

#stem_words EXAMPLE:
stem_words(doggies, jumping, swims)

#stem2df EXAMPLE:
out2 &lt;- stem2df(DATA, "state", "new")
truncdf(out2, 30)

## End(Not run)
</code></pre>

<hr>
<h2 id='strip'>Strip Text</h2><span id='topic+strip'></span><span id='topic+strip.character'></span><span id='topic+strip.factor'></span><span id='topic+strip.default'></span><span id='topic+strip.list'></span>

<h3>Description</h3>

<p>Strip text of unwanted characters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strip(
  x,
  char.keep = "~~",
  digit.remove = TRUE,
  apostrophe.remove = TRUE,
  lower.case = TRUE
)

## S3 method for class 'character'
strip(
  x,
  char.keep = "~~",
  digit.remove = TRUE,
  apostrophe.remove = TRUE,
  lower.case = TRUE
)

## S3 method for class 'factor'
strip(
  x,
  char.keep = "~~",
  digit.remove = TRUE,
  apostrophe.remove = TRUE,
  lower.case = TRUE
)

## Default S3 method:
strip(
  x,
  char.keep = "~~",
  digit.remove = TRUE,
  apostrophe.remove = TRUE,
  lower.case = TRUE
)

## S3 method for class 'list'
strip(
  x,
  char.keep = "~~",
  digit.remove = TRUE,
  apostrophe.remove = TRUE,
  lower.case = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strip_+3A_x">x</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="strip_+3A_char.keep">char.keep</code></td>
<td>
<p>A character vector of symbols (i.e., punctuation) that 
<code><a href="#topic+strip">strip</a></code> should keep.  The default is to strip every symbol 
except apostrophes and a double tilde <code>"~~"</code>.  The double tilde 
<code>"~~"</code> is included for a convenient means of keeping word groups 
together in functions that split text apart based on spaces.  To remove 
double tildes <code>"~~"</code> set <code>char.keep</code> to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="strip_+3A_digit.remove">digit.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> strips digits from the text.</p>
</td></tr>
<tr><td><code id="strip_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophes from 
the output.</p>
</td></tr>
<tr><td><code id="strip_+3A_lower.case">lower.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> forces all alpha characters to 
lower case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of text that has been stripped of unwanted characters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rm_stopwords">rm_stopwords</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
DATA$state #no strip applied
strip(DATA$state)
strip(DATA$state, apostrophe.remove=FALSE)
strip(DATA$state, char.keep = c("?", "."))

## End(Not run)
</code></pre>

<hr>
<h2 id='strWrap'>Wrap Character Strings to Format Paragraphs</h2><span id='topic+strWrap'></span>

<h3>Description</h3>

<p>A wrapper for <code><a href="base.html#topic+as.character">as.character</a></code> that writes to the Mac/Windows 
clipboard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strWrap(text = "clipboard", width = 70, copy2clip = interactive())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strWrap_+3A_text">text</code></td>
<td>
<p>character vector, or an object which can be converted to a 
character vector by <code><a href="base.html#topic+as.character">as.character</a></code>.</p>
</td></tr>
<tr><td><code id="strWrap_+3A_width">width</code></td>
<td>
<p>A positive integer giving the target column for wrapping lines 
in the output.</p>
</td></tr>
<tr><td><code id="strWrap_+3A_copy2clip">copy2clip</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to copy the output to the 
clipboard.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints a wrapped text vector to the console and copies the wrapped 
text to the clipboard on a Mac or Windows machine.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strwrap">strwrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- paste2(DATA$state, sep = " " )
strWrap(x)
strWrap(x, 10)
#should be copied to the clipboard on a Mac or Windows machine.

## End(Not run)
</code></pre>

<hr>
<h2 id='subject_pronoun_type'>Count Subject Pronouns Per Grouping Variable</h2><span id='topic+subject_pronoun_type'></span>

<h3>Description</h3>

<p>Count the number of subject pronouns per grouping variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subject_pronoun_type(
  text.var,
  grouping.var = NULL,
  subject.pronoun.list = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subject_pronoun_type_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="subject_pronoun_type_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="subject_pronoun_type_+3A_subject.pronoun.list">subject.pronoun.list</code></td>
<td>
<p>A named list of subject pronouns.  See 
<strong>Details</strong> for more.</p>
</td></tr>
<tr><td><code id="subject_pronoun_type_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+termco">termco</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following subject pronoun categories are the default searched terms:
</p>

<ul>
<li><p> I - c(&quot; i'd &quot;, &quot; i'll &quot;, &quot; i'm &quot;, &quot; i've &quot;, &quot; i &quot;)
</p>
</li>
<li><p> we - c(&quot; we'd &quot;, &quot; we'll &quot;, &quot; we're &quot;, &quot; we've &quot;, &quot; we &quot;)
</p>
</li>
<li><p> you - c(&quot; you'd &quot;,  &quot; you'll &quot;, &quot; you're &quot;, &quot; you've &quot;, &quot; you &quot;, &quot; your &quot;)
</p>
</li>
<li><p> he - c(&quot; he'd &quot;, &quot; he'll &quot;, &quot; he's &quot;, &quot; he &quot;)
</p>
</li>
<li><p> she - c(&quot; she'd &quot;, &quot; she'll &quot;, &quot; she's &quot;, &quot; she &quot;)
</p>
</li>
<li><p> it - c(&quot; it'd &quot;, &quot; it'll &quot;, &quot; it's &quot;, &quot; it &quot;)
</p>
</li>
<li><p> they - c(&quot; they'd &quot;, &quot; they'll &quot;, &quot; they're &quot;, &quot;they've &quot;, &quot; they &quot;)
</p>
</li></ul>



<h3>Value</h3>

<p>Returns a list, of class &quot;subject_pronoun_type&quot;, of data frames 
regarding subject pronoun word counts:
</p>
<table>
<tr><td><code>preprocessed</code></td>
<td>
<p>List of uncollapsed dataframes (raw, prop, rnp) of the class &quot;termco&quot; that contain all searchable subject pronouns.</p>
</td></tr> 
<tr><td><code>raw</code></td>
<td>
<p>raw word counts by grouping variable</p>
</td></tr> 
<tr><td><code>prop</code></td>
<td>
<p>proportional word counts by grouping variable; proportional to 
each individual's subject pronoun use</p>
</td></tr> 
<tr><td><code>rnp</code></td>
<td>
<p>a character combination data frame of raw and proportional subject pronoun use</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+object_pronoun_type">object_pronoun_type</a></code>,
<code><a href="#topic+pronoun_type">pronoun_type</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- pres_debates2012
dat &lt;- dat[dat$person %in% qcv(ROMNEY, OBAMA), ]
(out &lt;- subject_pronoun_type(dat$dialogue, dat$person))
plot(out)
plot(out, 2)
plot(out, 3)
plot(out, 3, ncol=2)

scores(out)
counts(out)
proportions(out)
preprocessed(out)

plot(scores(out))
plot(counts(out))
plot(proportions(out))

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.cmspans'>Summarize a cmspans object</h2><span id='topic+summary.cmspans'></span>

<h3>Description</h3>

<p>Summarize a cmspans object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cmspans'
summary(
  object,
  grouping.var = NULL,
  rm.var = NULL,
  total.span = TRUE,
  aggregate = FALSE,
  percent = TRUE,
  digits = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.cmspans_+3A_object">object</code></td>
<td>
<p>The cmspans object</p>
</td></tr>
<tr><td><code id="summary.cmspans_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables. Also takes a single grouping 
variable or a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="summary.cmspans_+3A_rm.var">rm.var</code></td>
<td>
<p>An optional single vector or list of 1 or 2 of repeated 
measures to aggregate by.</p>
</td></tr>
<tr><td><code id="summary.cmspans_+3A_total.span">total.span</code></td>
<td>
<p>logical or an option list of vectors (length 1 or 2) of the 
total duration of the event.  If <code>FALSE</code> the &quot;total&quot; column is divided 
by the sum of the total duration for all codes in that rm.var to arrive at 
&quot;total_percent&quot;.  If <code>TRUE</code> and object is from 
<code>cm_time2long</code> the difference for the time span from the 
<strong>transcript_time_span</strong> of the list used in <code>cm_time2long</code> are 
utilized to divide the &quot;total&quot; column. The user may also provide a list of 
vectors with each vector representing a single total time duration or 
provide the start and end time of the event.  The user may give input in 
numeric seconds or in character &quot;hh:mm:ss&quot; form.</p>
</td></tr>
<tr><td><code id="summary.cmspans_+3A_aggregate">aggregate</code></td>
<td>
<p>logical.  If <code>TRUE</code> the output will be aggregated 
(i.e., the output will collapse the <code>rm.var</code>).</p>
</td></tr>
<tr><td><code id="summary.cmspans_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="summary.cmspans_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="summary.cmspans_+3A_...">...</code></td>
<td>
<p>Other argument passed to <code>qheat</code> in plot (ignored in 
summary).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+plot.sum_cmspans">plot.sum_cmspans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Example 1
foo &lt;- list(
    person_greg = qcv(terms='7:11, 20:24, 30:33, 49:56'),
    person_researcher = qcv(terms='42:48'),
    person_sally = qcv(terms='25:29, 37:41'),
    person_sam = qcv(terms='1:6, 16:19, 34:36'),
    person_teacher = qcv(terms='12:15'),
    adult_0 = qcv(terms='1:11, 16:41, 49:56'),
    adult_1 = qcv(terms='12:15, 42:48'),
    AA = qcv(terms="1"),
    BB = qcv(terms="1:2, 3:10, 19"),
    CC = qcv(terms="1:9, 100:150")
)

foo2  &lt;- list(
    person_greg = qcv(terms='7:11, 20:24, 30:33, 49:56'),
    person_researcher = qcv(terms='42:48'),
    person_sally = qcv(terms='25:29, 37:41'),
    person_sam = qcv(terms='1:6, 16:19, 34:36'),
    person_teacher = qcv(terms='12:15'),
    adult_0 = qcv(terms='1:11, 16:41, 49:56'),
    adult_1 = qcv(terms='12:15, 42:48'),
    AA = qcv(terms="40"),
    BB = qcv(terms="50:90"),
    CC = qcv(terms="60:90, 100:120, 150"),
    DD = qcv(terms="")
)

v &lt;- cm_2long(foo, foo2, v.name = "time")
plot(v)
summary(v)
plot(summary(v))

## Example 2
x &lt;- list(
    transcript_time_span = qcv(00:00 - 1:12:00),
    A = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00"),
    B = qcv(terms = "2.40, 3.01:3.02, 5.01, 6.02:7.00,
        9.00, 1.12.00:1.19.01"),
    C = qcv(terms = "2.40:3.00, 5.01, 6.02:7.00, 9.00, 17.01")
)
z &lt;-cm_2long(x)

summary(z)
summary(z, total.span = FALSE)
summary(z, total.span = c(0, 3333))
summary(z, total.span = c("00:01:00", "03:02:00"))
plot(summary(z))

## suppress printing measurement units
suppressMessages(print(summary(z)))

## remove print method
as.data.frame(summary(z))

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.wfdf'>Summarize a wfdf object</h2><span id='topic+summary.wfdf'></span>

<h3>Description</h3>

<p>Summarize a wfdf object with familiar tm package look.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wfdf'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.wfdf_+3A_object">object</code></td>
<td>
<p>The wfdf object</p>
</td></tr>
<tr><td><code id="summary.wfdf_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Non-/sparse entries</strong> is the ratio of non-zeros to zero 
counts.  <strong>Sparsity</strong> is that ratio represented as a percent.  
<strong>Hapax legomenon</strong> is the number(percent) of terms that appear only 
once in the dialogue. <strong>Dis legomenon</strong> is the number(percent) of terms 
that appear exactly two times once.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- with(DATA, wfdf(state, list(sex, adult)))
summary(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.wfm'>Summarize a wfm object</h2><span id='topic+summary.wfm'></span>

<h3>Description</h3>

<p>Summarize a wfm object with familiar tm package look.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wfm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.wfm_+3A_object">object</code></td>
<td>
<p>The wfm object</p>
</td></tr>
<tr><td><code id="summary.wfm_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Non-/sparse entries</strong> is the ratio of non-zeros to zero 
counts.  <strong>Sparsity</strong> is that ratio represented as a percent.  
<strong>Hapax legomenon</strong> is the number(percent) of terms that appear only 
once in the dialogue. <strong>Dis legomenon</strong> is the number(percent) of terms 
that appear exactly two times once.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- with(DATA, wfm(state, list(sex, adult)))
summary(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='syllable_sum'>Syllabication</h2><span id='topic+syllable_sum'></span><span id='topic+syllable_count'></span><span id='topic+polysyllable_sum'></span><span id='topic+combo_syllable_sum'></span>

<h3>Description</h3>

<p><code>syllable_sum</code> - Count the number of syllables per row of text.
</p>
<p><code>syllable_count</code> - Count the number of syllables in a single text string.
</p>
<p><code>polysyllable_sum</code> - Count the number of polysyllables per row of text.
</p>
<p><code>combo_syllable_sum</code> - Count the number of both syllables and 
polysyllables per row of text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>syllable_sum(text.var, parallel = FALSE, ...)

syllable_count(
  text,
  remove.bracketed = TRUE,
  algorithm.report = FALSE,
  env = qdap::env.syl
)

polysyllable_sum(text.var, parallel = FALSE)

combo_syllable_sum(text.var, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="syllable_sum_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="syllable_sum_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create.</p>
</td></tr>
<tr><td><code id="syllable_sum_+3A_text">text</code></td>
<td>
<p>A single character vector of text.</p>
</td></tr>
<tr><td><code id="syllable_sum_+3A_remove.bracketed">remove.bracketed</code></td>
<td>
<p>logical.  If <code>TRUE</code> brackets are removed from 
the analysis.</p>
</td></tr>
<tr><td><code id="syllable_sum_+3A_algorithm.report">algorithm.report</code></td>
<td>
<p>logical.  If <code>TRUE</code> generates a report of words 
not found in the dictionary (i.e., syllables were calculated with an 
algorithm).</p>
</td></tr>
<tr><td><code id="syllable_sum_+3A_env">env</code></td>
<td>
<p>A lookup environment to lookup the number of syllables in found 
words.</p>
</td></tr>
<tr><td><code id="syllable_sum_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>syllable_count</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The worker function of all the syllable functions is 
<code><a href="#topic+syllable_count">syllable_count</a></code>, though it is not intended for direct 
use on a transcript.  This function relies on a combined dictionary lookup 
(based on the Nettalk Corpus (Sejnowski &amp; Rosenberg, 1987)) and backup 
algorithm method.
</p>


<h3>Value</h3>

<p><code>syllable_sum</code> - returns a vector of syllable counts per row.
</p>
<p><code>syllable_count</code> - returns a dataframe of syllable counts and 
algorithm/dictionary uses and, optionally, a report of words not found in the dictionary.
</p>
<p><code>polysyllable_sum</code> - returns a vector of polysyllable counts per row.
</p>
<p><code>combo_syllable_sum</code> - returns a dataframe of syllable and polysyllable 
counts per row.
</p>


<h3>References</h3>

<p>Sejnowski, T.J., and Rosenberg, C.R. (1987). &quot;Parallel networks 
that learn to pronounce English text&quot; in Complex Systems, 1, 145-168.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
syllable_count("Robots like Dason lie.")
syllable_count("Robots like Dason lie.", algorithm.report = TRUE)

syllable_sum(DATA$state)
x1 &lt;- syllable_sum(rajSPLIT$dialogue)
plot(x1)
cumulative(x1)

polysyllable_sum(DATA$state)
x2 &lt;- polysyllable_sum(rajSPLIT$dialogue)
plot(x2)
cumulative(x2)

combo_syllable_sum(DATA$state)
x3 &lt;- combo_syllable_sum(rajSPLIT$dialogue)
plot(x3) 
cumulative(x3)

## End(Not run)
</code></pre>

<hr>
<h2 id='synonyms'>Search For Synonyms</h2><span id='topic+synonyms'></span><span id='topic+syn'></span><span id='topic+synonyms_frame'></span><span id='topic+syn_frame'></span>

<h3>Description</h3>

<p><code>synonyms</code> - Search for synonyms that match term(s).
</p>
<p><code>synonyms_frame</code> - Generate a synonym lookup hash key 
for use with the <code>synonym.frame</code> argument in the <code>synonym</code> 
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>synonyms(
  terms,
  return.list = TRUE,
  multiwords = TRUE,
  report.null = TRUE,
  synonym.frame = qdapDictionaries::key.syn
)

syn(
  terms,
  return.list = TRUE,
  multiwords = TRUE,
  report.null = TRUE,
  synonym.frame = qdapDictionaries::key.syn
)

synonyms_frame(synonym.list, prior.frame)

syn_frame(synonym.list, prior.frame)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="synonyms_+3A_terms">terms</code></td>
<td>
<p>The terms to find synonyms for.</p>
</td></tr>
<tr><td><code id="synonyms_+3A_return.list">return.list</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns the output for multiple 
synonyms as a list by search term rather than a vector.</p>
</td></tr>
<tr><td><code id="synonyms_+3A_multiwords">multiwords</code></td>
<td>
<p>logical.  IF <code>TRUE</code> retains vector elements that 
contain phrases (defined as having one or more spaces) rather than a single 
word.</p>
</td></tr>
<tr><td><code id="synonyms_+3A_report.null">report.null</code></td>
<td>
<p>logical.  If <code>TRUE</code> reports the words that no match 
was found at the head of the output.</p>
</td></tr>
<tr><td><code id="synonyms_+3A_synonym.frame">synonym.frame</code></td>
<td>
<p>A dataframe or hash key of positive/negative words and weights.</p>
</td></tr>
<tr><td><code id="synonyms_+3A_synonym.list">synonym.list</code></td>
<td>
<p>A named list of lists (or vectors) of synonyms.</p>
</td></tr>
<tr><td><code id="synonyms_+3A_prior.frame">prior.frame</code></td>
<td>
<p>A prior synonyms data.frame in the format produced by 
<code>synonyms_frame</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of vectors or vector of possible words that match 
term(s).
</p>


<h3>References</h3>

<p>The synonyms dictionary (see <code><a href="qdapDictionaries.html#topic+key.syn">key.syn</a></code>) was 
generated by web scraping the Reverso (https://dictionary.reverso.net/english-synonyms/) Online Dictionary.
The word list fed to Reverso
is the unique words from the combination of <code><a href="qdapDictionaries.html#topic+DICTIONARY">DICTIONARY</a></code> 
and <code><a href="qdapDictionaries.html#topic+labMT">labMT</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
synonyms(c("the", "cat", "job", "environment", "read", "teach"))
head(syn(c("the", "cat", "job", "environment", "read", "teach"), 
    return.list = FALSE), 30)
syn(c("the", "cat", "job", "environment", "read", "teach"), multiwords = FALSE)

## User defined synonym lookup
syn_dat &lt;- list(
    like = list(c("want", "desire"), c("love", "care")),
    show = list(c("reveal"), c("movie", "opera")),
    R = c("old friend", "statistics language")
)

synonyms_frame(syn_dat)
syn(c("R", "show"), synonym.frame = syn_frame(syn_dat))

syns.hash &lt;- syn_frame(syn_dat, prior.frame = qdapDictionaries::key.syn)
syn(c("R", "show", "like", "robot"), synonym.frame = syns.hash)

## End(Not run)
</code></pre>

<hr>
<h2 id='termco'>Search For and Count Terms</h2><span id='topic+termco'></span><span id='topic+termco_d'></span><span id='topic+term_match'></span><span id='topic+termco2mat'></span>

<h3>Description</h3>

<p><code>termco</code> - Search a transcript by any number of grouping variables for 
categories (themes) of grouped root terms.  While there are other termco 
functions in the termco family (e.g., <code><a href="#topic+termco_d">termco_d</a></code>) 
<code>termco</code> is a more powerful and flexible wrapper intended for general 
use.
</p>
<p><code>termco_d</code> - Search a transcript by any number of grouping variables for 
root terms.
</p>
<p><code>term_match</code> - Search a transcript for words that exactly match term(s).
</p>
<p><code>termco2mat</code> - Convert a termco dataframe to a matrix for use with 
visualization functions (e.g., <code><a href="gplots.html#topic+heatmap.2">heatmap.2</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>termco(
  text.var,
  grouping.var = NULL,
  match.list,
  short.term = TRUE,
  ignore.case = TRUE,
  elim.old = TRUE,
  percent = TRUE,
  digits = 2,
  apostrophe.remove = FALSE,
  char.keep = NULL,
  digit.remove = NULL,
  zero.replace = 0,
  ...
)

termco_d(
  text.var,
  grouping.var = NULL,
  match.string,
  short.term = FALSE,
  ignore.case = TRUE,
  zero.replace = 0,
  percent = TRUE,
  digits = 2,
  apostrophe.remove = FALSE,
  char.keep = NULL,
  digit.remove = TRUE,
  ...
)

term_match(text.var, terms, return.list = TRUE, apostrophe.remove = FALSE)

termco2mat(
  dataframe,
  drop.wc = TRUE,
  short.term = TRUE,
  rm.zerocol = FALSE,
  no.quote = TRUE,
  transform = TRUE,
  trim.terms = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="termco_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="termco_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="termco_+3A_match.list">match.list</code></td>
<td>
<p>A list of named character vectors.</p>
</td></tr>
<tr><td><code id="termco_+3A_short.term">short.term</code></td>
<td>
<p>logical.  If <code>TRUE</code> column names are trimmed versions 
of the match list, otherwise the terms are wrapped with 'term(phrase)'</p>
</td></tr>
<tr><td><code id="termco_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical.  If <code>TRUE</code> case is ignored.</p>
</td></tr>
<tr><td><code id="termco_+3A_elim.old">elim.old</code></td>
<td>
<p>logical.  If <code>TRUE</code> eliminates the columns that are 
combined together by the named match.list.</p>
</td></tr>
<tr><td><code id="termco_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="termco_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="termco_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophes from 
the text before examining.</p>
</td></tr>
<tr><td><code id="termco_+3A_char.keep">char.keep</code></td>
<td>
<p>A character vector of symbol character (i.e., punctuation) 
that strip should keep.  The default is to strip everything except 
apostrophes. <code><a href="#topic+termco">termco</a></code> attempts to auto detect characters to 
keep based on the elements in <code>match.list</code>.</p>
</td></tr>
<tr><td><code id="termco_+3A_digit.remove">digit.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> strips digits from the text 
before counting. <code><a href="#topic+termco">termco</a></code> attempts to auto detect if digits 
should be retained based on the elements in <code>match.list</code>.</p>
</td></tr>
<tr><td><code id="termco_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.</p>
</td></tr>
<tr><td><code id="termco_+3A_match.string">match.string</code></td>
<td>
<p>A vector of terms to search for.  When using inside of 
<code>term_match</code> the term(s) must be words or partial words but do not have 
to be when using <code><a href="#topic+termco_d">termco_d</a></code> (i.e., they can be phrases, 
symbols etc.).</p>
</td></tr>
<tr><td><code id="termco_+3A_terms">terms</code></td>
<td>
<p>The terms to search for in the <code>text.var</code>.  Similar to 
<code>match.list</code> but these terms must be words or partial words rather than 
multiple words and symbols.</p>
</td></tr>
<tr><td><code id="termco_+3A_return.list">return.list</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns the output for multiple 
terms as a list by term rather than a vector.</p>
</td></tr>
<tr><td><code id="termco_+3A_dataframe">dataframe</code></td>
<td>
<p>A termco (or termco_d) dataframe or object.</p>
</td></tr>
<tr><td><code id="termco_+3A_drop.wc">drop.wc</code></td>
<td>
<p>logical.  If <code>TRUE</code> the word count column will be 
dropped.</p>
</td></tr>
<tr><td><code id="termco_+3A_rm.zerocol">rm.zerocol</code></td>
<td>
<p>logical.  If <code>TRUE</code> any column containing all zeros 
will be removed from the matrix.</p>
</td></tr>
<tr><td><code id="termco_+3A_no.quote">no.quote</code></td>
<td>
<p>logical.  If <code>TRUE</code> the matrix will be printed without 
quotes if it's character.</p>
</td></tr>
<tr><td><code id="termco_+3A_transform">transform</code></td>
<td>
<p>logical.  If <code>TRUE</code> the matrix will be transformed.</p>
</td></tr>
<tr><td><code id="termco_+3A_trim.terms">trim.terms</code></td>
<td>
<p>logical.  If <code>TRUE</code> trims the column header/names to 
ensure there is not a problem with spacing when using in other R functions.</p>
</td></tr>
<tr><td><code id="termco_+3A_...">...</code></td>
<td>
<p>Other argument supplied to <code><a href="#topic+strip">strip</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>termco</code> &amp; <code>termco_d</code> - both return a list, of class 
&quot;termco&quot;, of data frames and information regarding word counts:
</p>
<table>
<tr><td><code>raw</code></td>
<td>
<p>raw word counts by grouping variable</p>
</td></tr> 
<tr><td><code>prop</code></td>
<td>
<p>proportional word counts by grouping variable; proportional to 
each individual's word use</p>
</td></tr> 
<tr><td><code>rnp</code></td>
<td>
<p>a character combination data frame of raw and proportional</p>
</td></tr>     
<tr><td><code>zero_replace</code></td>
<td>
<p>value to replace zeros with; mostly internal use</p>
</td></tr>   
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr>
<tr><td><code>digits</code></td>
<td>
<p>integer value of number of digits to display; mostly internal 
use</p>
</td></tr>
</table>
<p><code>term_match</code> -  returns a list or vector of possible words that 
match term(s).
</p>
<p><code>termco2mat</code> - returns a matrix of term counts.
</p>


<h3>Warning</h3>

<p>Percentages are calculated as a ratio of counts of 
<code>match.list</code> elements to word counts.  Word counts do not contain 
symbols or digits.  Using symbols, digits or small segments of full words 
(e.g., &quot;to&quot;) could total more than 100%.
</p>


<h3>Note</h3>

<p>The match.list/match.string is (optionally) case and character 
sensitive.  Spacing is an important way to grab specific words and requires 
careful thought.  Using &quot;read&quot; will find the words &quot;bread&quot;, &quot;read&quot; &quot;reading&quot;, 
and &quot;ready&quot;.  If you want to search for just the word &quot;read&quot; you'd supply a 
vector of c(&quot; read &quot;, &quot; reads&quot;, &quot; reading&quot;, &quot; reader&quot;).  To search for non 
character arguments (i.e., numbers and symbols) additional arguments from 
strip must be passed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+termco_c">termco_c</a></code>,
<code><a href="#topic+colcomb2class">colcomb2class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#termco examples:

term &lt;- c("the ", "she", " wh")
(out &lt;- with(raj.act.1,  termco(dialogue, person, term)))

plot(out)
scores(out)
plot(scores(out))
counts(out)
plot(counts(out))
proportions(out)
plot(proportions(out))

# General form for match.list as themes
#
# ml &lt;- list(
#     cat1 = c(),
#     cat2 = c(),
#     catn = c()
# )

ml &lt;- list(
    cat1 = c(" the ", " a ", " an "),
    cat2 = c(" I'" ),
    "good",
    the = c("the", " the ", " the", "the")
)

(dat &lt;- with(raj.act.1,  termco(dialogue, person, ml)))
scores(dat)  #useful for presenting in tables
counts(dat)  #prop and raw counts are useful for performing calculations
proportions(dat)
datb &lt;- with(raj.act.1, termco(dialogue, person, ml,
    short.term = FALSE, elim.old=FALSE))
ltruncdf(datb, 20, 6)
    
(dat2 &lt;- data.frame(dialogue=c("@bryan is bryan good @br",
    "indeed", "@ brian"), person=qcv(A, B, A)))

ml2 &lt;- list(wrds=c("bryan", "indeed"), "@", bryan=c("bryan", "@ br", "@br"))

with(dat2, termco(dialogue, person, match.list=ml2))

with(dat2, termco(dialogue, person, match.list=ml2, percent = FALSE))

DATA$state[1] &lt;- "12 4 rgfr  r0ffrg0"
termco(DATA$state, DATA$person, '0', digit.remove=FALSE)
DATA &lt;- qdap::DATA

#Using with term_match and exclude    
exclude(term_match(DATA$state, qcv(th), FALSE), "truth")
termco(DATA$state, DATA$person, exclude(term_match(DATA$state, qcv(th), 
    FALSE), "truth"))
MTCH.LST &lt;- exclude(term_match(DATA$state, qcv(th, i)), qcv(truth, stinks))
termco(DATA$state, DATA$person, MTCH.LST)

syns &lt;- synonyms("doubt")
syns[1]
termco(DATA$state, DATA$person, unlist(syns[1]))
synonyms("doubt", FALSE)
termco(DATA$state, DATA$person, list(doubt = synonyms("doubt", FALSE)))
termco(DATA$state, DATA$person, syns)

#termco_d examples:
termco_d(DATA$state, DATA$person, c(" the", " i'"))
termco_d(DATA$state, DATA$person, c(" the", " i'"), ignore.case=FALSE)
termco_d(DATA$state, DATA$person, c(" the ", " i'"))

# termco2mat example:
MTCH.LST &lt;- exclude(term_match(DATA$state, qcv(a, i)), qcv(is, it, am, shall))
termco_obj &lt;- termco(DATA$state, DATA$person, MTCH.LST)
termco2mat(termco_obj)
plot(termco_obj)
plot(termco_obj, label = TRUE)
plot(termco_obj, label = TRUE, text.color = "red")
plot(termco_obj, label = TRUE, text.color="red", lab.digits=3)

## REVERSE TERMCO (return raw words found per variable)
df &lt;- data.frame(x=1:6,
    y = c("the fluffy little bat" , "the man was round like a ball",
        "the fluffy little bat" , "the man was round like a ball",
        "he ate the chair" , "cough, cough"),
    stringsAsFactors=FALSE)

l &lt;- list("bat" ,"man", "ball", "heavy")
z &lt;- counts(termco(df$y, qdapTools::id(df), l))[, -2]

counts2list(z[, -1], z[, 1])

## politness
politness &lt;- c("please", "excuse me", "thank you", "you welcome", 
    "you're welcome", "i'm sorry", "forgive me", "pardon me")

with(pres_debates2012, termco(dialogue, person, politness))
with(hamlet, termco(dialogue, person, politness))

## Term Use Percentage per N Words
dat &lt;- with(raj, chunker(dialogue, person, n.words = 100, rm.unequal = TRUE))
dat2 &lt;- list2df(dat, "Dialogue", "Person")
dat2[["Duration"]] &lt;- unlist(lapply(dat, id, pad=FALSE))
dat2 &lt;- qdap_df(dat2, "Dialogue")

Top5 &lt;- sapply(split(raj$dialogue, raj$person), wc, FALSE) %&gt;%
    sort(decreasing=TRUE) %&gt;% 
    list2df("wordcount", "person") %&gt;%
    `[`(1:5, 2)

propdat &lt;- dat2 %&amp;% 
    termco(list(Person, Duration), as.list(Top25Words[1:5]), percent = FALSE) %&gt;% 
    proportions %&gt;%
    colsplit2df %&gt;% 
    reshape2::melt(id=c("Person", "Duration", "word.count"), variable="Word") %&gt;%
    dplyr::filter(Person %in% Top5)

head(propdat)

ggplot(propdat, aes(y=value, x=Duration, group=Person, color=Person)) +
    geom_line(size=1.25) +
    facet_grid(Word~., scales="free_y") +
    ylab("Percent of Word Use")  +
    xlab("Per 100 Words") + 
    scale_y_continuous(labels = percent)

ggplot(propdat, aes(y=value, x=Duration, group=Word, color=Word)) +
    geom_line(size=1.25) +
    facet_grid(Person~.) +
    ylab("Percent of Word Use")  +
    xlab("Per 100 Words") + 
    scale_y_continuous(labels = percent)

ggplot(propdat, aes(y=value, x=Duration, group=Word)) +
    geom_line() +
    facet_grid(Word~Person, scales="free_y") +
    ylab("Percent of Word Use")  +
    xlab("Per 100 Words") + 
    scale_y_continuous(labels = percent) +
    ggthemes::theme_few()
    
## Discourse Markers: See...
## Schffrin, D. (2001). Discourse markers: Language, meaning, and context. 
##    In D. Schiffrin, D. Tannen, &amp; H. E. Hamilton (Eds.), The handbook of 
##    discourse analysis (pp. 54-75). Malden, MA: Blackwell Publishing.

discoure_markers &lt;- list(
    response_cries = c(" oh ", " ah ", " aha ", " ouch ", " yuk "),
    back_channels = c(" uh-huh ", " uhuh ", " yeah "), 
    summons = " hey ", 
    justification = " because "
)

(markers &lt;- with(pres_debates2012, 
    termco(dialogue, list(person, time), discoure_markers)
))
plot(markers, high="red")

with(pres_debates2012, 
    termco(dialogue, list(person, time), discoure_markers, elim.old = FALSE)
)

with(pres_debates2012, 
    dispersion_plot(dialogue, unlist(discoure_markers), person, time)
)

## End(Not run)
</code></pre>

<hr>
<h2 id='termco_c'>Combine Columns from a termco Object</h2><span id='topic+termco_c'></span>

<h3>Description</h3>

<p>Combines the columns of a termco object.  Generally intended for internal 
use but documented for completeness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>termco_c(
  termco.object,
  combined.columns,
  new.name,
  short.term = TRUE,
  zero.replace = NULL,
  elim.old = TRUE,
  percent = NULL,
  digits = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="termco_c_+3A_termco.object">termco.object</code></td>
<td>
<p>An object generated by either <code><a href="#topic+termco">termco</a></code>, 
<code><a href="#topic+termco_d">termco_d</a></code> or <code><a href="#topic+termco_c">termco_c</a></code>.</p>
</td></tr>
<tr><td><code id="termco_c_+3A_combined.columns">combined.columns</code></td>
<td>
<p>The names/indexes of the columns to be combined.</p>
</td></tr>
<tr><td><code id="termco_c_+3A_new.name">new.name</code></td>
<td>
<p>A character vector of length one to name the new combined 
column.</p>
</td></tr>
<tr><td><code id="termco_c_+3A_short.term">short.term</code></td>
<td>
<p>logical.  If <code>TRUE</code> column names are trimmed versions 
of the match list, otherwise the terms are wrapped with 'term(phrase)'</p>
</td></tr>
<tr><td><code id="termco_c_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace zeros with.</p>
</td></tr>
<tr><td><code id="termco_c_+3A_elim.old">elim.old</code></td>
<td>
<p>logical.  If <code>TRUE</code> eliminates the columns that are 
combined together by the named match.list.</p>
</td></tr>
<tr><td><code id="termco_c_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the 
output is proportion.</p>
</td></tr>
<tr><td><code id="termco_c_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a return a list, of class <code>"termco"</code>, of data frames and 
information regarding word counts:
</p>
<table>
<tr><td><code>raw</code></td>
<td>
<p>raw word counts by grouping variable</p>
</td></tr> 
<tr><td><code>prop</code></td>
<td>
<p>proportional word counts by grouping variable; proportional to 
each individual's word use</p>
</td></tr> 
<tr><td><code>rnp</code></td>
<td>
<p>a character combination data frame of raw and proportional</p>
</td></tr>     
<tr><td><code>zero_replace</code></td>
<td>
<p>value to replace zeros with; mostly internal use</p>
</td></tr>   
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr> 
<tr><td><code>digits</code></td>
<td>
<p>integer value od number of digits to display; mostly internal 
use</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+termco">termco</a></code>
</p>

<hr>
<h2 id='Title'>Add Title to Select qdap Plots</h2><span id='topic+Title'></span><span id='topic+Title+3C-'></span>

<h3>Description</h3>

<p>Add title to select qdap objects that store a plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Title(object)

Title(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Title_+3A_object">object</code></td>
<td>
<p>A select qdap object that stores a plot.</p>
</td></tr>
<tr><td><code id="Title_+3A_value">value</code></td>
<td>
<p>The value to assign to title.</p>
</td></tr>
</table>

<hr>
<h2 id='tot_plot'>Visualize Word Length by Turn of Talk</h2><span id='topic+tot_plot'></span>

<h3>Description</h3>

<p>Uses a bar graph to visualize patterns in sentence length and grouping 
variables by turn of talk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tot_plot(
  dataframe,
  text.var,
  grouping.var = NULL,
  facet.vars = NULL,
  tot = TRUE,
  transform = FALSE,
  ncol = NULL,
  ylab = NULL,
  xlab = NULL,
  bar.space = 0,
  scale = NULL,
  space = NULL,
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tot_plot_+3A_dataframe">dataframe</code></td>
<td>
<p>A dataframe that contains the text variable and optionally 
the grouping.var and tot variables.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_text.var">text.var</code></td>
<td>
<p>The text variable (character string).</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables to color by.  Default <code>NULL</code> 
colors everything in &quot;black&quot;.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_facet.vars">facet.vars</code></td>
<td>
<p>An optional single vector or list of 1 or 2 to facet by.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_tot">tot</code></td>
<td>
<p>The turn of talk variable (character string). May be <code>TRUE</code> 
(assumes &quot;tot&quot; is the variable name), <code>FALSE</code> (use row numbers), or a 
character string of the turn of talk column.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_transform">transform</code></td>
<td>
<p>logical.  If <code>TRUE</code> the repeated facets will be 
transformed from stacked to side by side.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_ncol">ncol</code></td>
<td>
<p>number of columns. 
<code><a href="#topic+gantt_wrap">gantt_wrap</a></code> uses <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code> 
rather than <code><a href="ggplot2.html#topic+facet_grid">facet_grid</a></code>.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_ylab">ylab</code></td>
<td>
<p>Optional y label.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_xlab">xlab</code></td>
<td>
<p>Optional x label.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_bar.space">bar.space</code></td>
<td>
<p>The amount space between bars (ranging between 1 and 0).</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_scale">scale</code></td>
<td>
<p>Should scales be fixed (<code>"fixed"</code>, the default), free 
(<code>"free"</code>), or free in one dimension (<code>"free_x"</code>, <code>"free_y"</code>)</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_space">space</code></td>
<td>
<p>If <code>"fixed"</code>, the default, all panels have the same size. 
If <code>"free_y"</code> their height will be proportional to the length of the y 
scale; if <code>"free_x"</code> their width will be proportional to the length of 
the x scale; or if <code>"free"</code> both height and width will vary. This 
setting has no effect unless the appropriate scales also vary.</p>
</td></tr>
<tr><td><code id="tot_plot_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> the plot will automatically plot.
The user may wish to set to <code>FALSE</code> for use in knitr, sweave, etc.
to add additional plot layers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the ggplot2 object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dataframe &lt;- sentSplit(DATA, "state")
tot_plot(dataframe, "state")
tot_plot(DATA, "state", tot=FALSE)
tot_plot(dataframe, "state", bar.space=.03)
tot_plot(dataframe, "state", "sex")
tot_plot(dataframe, "state", "person", tot = "sex")
tot_plot(mraja1, "dialogue", "fam.aff", tot=FALSE)
tot_plot(mraja1, "dialogue", "died", tot=FALSE)
tot_plot(mraja1, "dialogue", c("sex", "fam.aff"), tot=FALSE) + 
    scale_fill_hue(l=40) 
tot_plot(mraja1, "dialogue", c("sex", "fam.aff"), tot=FALSE)+ 
    scale_fill_brewer(palette="Spectral")
tot_plot(mraja1, "dialogue", c("sex", "fam.aff"), tot=FALSE)+ 
    scale_fill_brewer(palette="Set1")

## repeated measures
rajSPLIT2 &lt;- do.call(rbind, lapply(split(rajSPLIT, rajSPLIT$act), head, 25))
tot_plot(rajSPLIT2, "dialogue", "fam.aff", facet.var = "act")

## add mean and +/- 2 sd
tot_plot(mraja1, "dialogue", grouping.var = c("sex", "fam.aff"), tot=FALSE)+
    scale_fill_brewer(palette="Set1") +
    geom_hline(aes(yintercept=mean(word.count))) +
    geom_hline(aes(yintercept=mean(word.count) + (2 *sd(word.count)))) +
    geom_hline(aes(yintercept=mean(word.count) + (3 *sd(word.count)))) +
    geom_text(parse=TRUE, hjust=0, vjust=0, family="serif", size = 4, aes(x = 2, 
        y = mean(word.count) + 2, label = "bar(x)")) +
    geom_text(hjust=0, vjust=0, family="serif", size = 4, aes(x = 1, 
        y = mean(word.count) + (2 *sd(word.count)) + 2, label = "+2 sd")) +
    geom_text(hjust=0, vjust=0, family="serif", size = 4, aes(x = 1, 
        y = mean(word.count) + (3 *sd(word.count)) + 2, label = "+3 sd")) 

## End(Not run)
</code></pre>

<hr>
<h2 id='trans_cloud'>Word Clouds by Grouping Variable</h2><span id='topic+trans_cloud'></span>

<h3>Description</h3>

<p>Produces word clouds with optional theme coloring by grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trans_cloud(
  text.var = NULL,
  grouping.var = NULL,
  word.list = NULL,
  stem = FALSE,
  target.words = NULL,
  expand.target = TRUE,
  target.exclude = NULL,
  stopwords = NULL,
  min.freq = 1,
  caps = TRUE,
  caps.list = NULL,
  random.order = FALSE,
  rot.per = 0,
  cloud.colors = NULL,
  title = TRUE,
  cloud.font = NULL,
  title.font = NULL,
  title.color = "black",
  title.padj = -4.5,
  title.location = 3,
  title.cex = NULL,
  title.names = NULL,
  proportional = FALSE,
  max.word.size = NULL,
  min.word.size = 0.5,
  legend = NULL,
  legend.cex = 0.8,
  legend.location = c(-0.03, 1.03),
  char.keep = "~~",
  char2space = "~~"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trans_cloud_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_word.list">word.list</code></td>
<td>
<p>A frequency word list passed from 
<code><a href="#topic+word_list">word_list</a></code>.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_stem">stem</code></td>
<td>
<p>logical.  If <code>TRUE</code> the <code>text.var</code> will be stemmed.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_target.words">target.words</code></td>
<td>
<p>A named list of vectors of words whose length corresponds 
to <code>cloud.colors</code> (+1 length in cloud colors for non-matched terms).</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_expand.target">expand.target</code></td>
<td>
<p>logical.  If <code>TRUE</code> <code><a href="base.html#topic+agrep">agrep</a></code>
will be used to expand the <code>target.words</code>.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_target.exclude">target.exclude</code></td>
<td>
<p>A vector of words to exclude from the 
<code>target.words</code>.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_stopwords">stopwords</code></td>
<td>
<p>Words to exclude from the cloud.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_min.freq">min.freq</code></td>
<td>
<p>An integer value indicating the minimum frequency a word must 
appear to be included.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_caps">caps</code></td>
<td>
<p>logical.  If <code>TRUE</code> selected words will be capitalized.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_caps.list">caps.list</code></td>
<td>
<p>A vector of words to capitalize (<code>caps</code> must be 
<code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_random.order">random.order</code></td>
<td>
<p>Plot words in random order. If false, they will be 
plotted in decreasing frequency.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_rot.per">rot.per</code></td>
<td>
<p>Proportion words with 90 degree rotation.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_cloud.colors">cloud.colors</code></td>
<td>
<p>A vector of colors equal to the length of target words +1.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_title">title</code></td>
<td>
<p>logical.  If <code>TRUE</code> adds a title corresponding to the 
<code>grouping.var</code>.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_cloud.font">cloud.font</code></td>
<td>
<p>The font family of the cloud text.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_title.font">title.font</code></td>
<td>
<p>The font family of the cloud title.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_title.color">title.color</code></td>
<td>
<p>A character vector of length one corresponding to the 
color of the title.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_title.padj">title.padj</code></td>
<td>
<p>Adjustment for the title. For strings parallel to the axes, 
padj = 0 means right or top alignment, and padj = 1 means left or bottom 
alignment.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_title.location">title.location</code></td>
<td>
<p>On which side of the plot (1=bottom, 2=left, 3=top, 
4=right).</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_title.cex">title.cex</code></td>
<td>
<p>Character expansion factor for the title. <code>NULL</code> and 
<code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_title.names">title.names</code></td>
<td>
<p>Optional vector of title names equal in length to the 
grouping.var that will override the default use of the grouping.var names.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_proportional">proportional</code></td>
<td>
<p>logical.  If <code>TRUE</code> scales the word clouds across 
grouping.var to allow cloud to cloud comparisons.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_max.word.size">max.word.size</code></td>
<td>
<p>A size argument to control the minimum size of the words.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_min.word.size">min.word.size</code></td>
<td>
<p>A size argument to control the maximum size of the words.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_legend">legend</code></td>
<td>
<p>A character vector of names corresponding to the number of 
vectors in target.words.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_legend.cex">legend.cex</code></td>
<td>
<p>Character expansion factor for the legend. <code>NULL</code> and 
<code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_legend.location">legend.location</code></td>
<td>
<p>The x and y co-ordinates to be used to position the 
legend.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_char.keep">char.keep</code></td>
<td>
<p>A character vector of symbol character (i.e., punctuation) 
that strip should keep.  The default is to strip everything except 
apostrophes.  This enables the use of special characters to be turned into 
spaces or for characters to be retained.</p>
</td></tr>
<tr><td><code id="trans_cloud_+3A_char2space">char2space</code></td>
<td>
<p>A vector of characters to be turned into spaces.  If 
<code>char.keep</code> is <code>NULL</code>, <code>char2space</code> will activate this 
argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a series of word cloud plots with target words (themes) 
colored.
</p>


<h3>See Also</h3>

<p><code><a href="wordcloud.html#topic+wordcloud">wordcloud</a></code>,
<code><a href="#topic+gradient_cloud">gradient_cloud</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
terms &lt;- list(
    I=c("i", "i'm"),
    mal=qcv(stinks, dumb, distrust),
    articles=qcv(the, a, an),
    pronoun=qcv(we, you)
)

with(DATA, trans_cloud(state, person, target.words=terms, 
    cloud.colors=qcv(red, green, blue, black, gray65), 
    expand.target=FALSE, proportional=TRUE, legend=c(names(terms), 
    "other")))

with(DATA, trans_cloud(state, person, target.words=terms,
    stopwords=exclude(with(DATA, unique(bag_o_words(state))), 
        unique(unlist(terms))), 
    cloud.colors=qcv(red, green, blue, black, gray65), 
    expand.target=FALSE, proportional=TRUE, legend=names(terms)))
    
    
#color the negated phrases opposite:
DATA &lt;- qdap::DATA
DATA[1, 4] &lt;- "This is not good!"
DATA[8, 4] &lt;- "I don't distrust you."

DATA$state &lt;- space_fill(DATA$state, paste0(negation.words, " "), 
    rm.extra = FALSE)

txt &lt;- gsub("~~", " ", breaker(DATA$state))
rev.neg &lt;- sapply(negation.words, paste, negative.words)
rev.pos &lt;- sapply(negation.words, paste, positive.words)


tw &lt;- list(
    positive=c(positive.words, rev.neg[rev.neg %in% txt]), 
    negative=c(negative.words, rev.pos[rev.pos %in% txt])
)


with(DATA, trans_cloud(state, person,
    target.words=tw,
    cloud.colors=qcv(darkgreen, red, gray65),
    expand.target=FALSE, proportional=TRUE, legend=names(tw)))

DATA &lt;- qdap::DATA  ## Reset DATA

## End(Not run)
</code></pre>

<hr>
<h2 id='trans_context'>Print Context Around Indices</h2><span id='topic+trans_context'></span>

<h3>Description</h3>

<p>Print (or save to an external file) n text elements before and after indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trans_context(
  text.var,
  grouping.var,
  inds,
  n.before = 3,
  tot = TRUE,
  n.after = n.before,
  ord.inds = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trans_context_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="trans_context_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Also takes a single 
grouping variable or a list of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="trans_context_+3A_inds">inds</code></td>
<td>
<p>A list of integer indices to print context for.</p>
</td></tr>
<tr><td><code id="trans_context_+3A_n.before">n.before</code></td>
<td>
<p>The number of rows before the indexed occurrence.</p>
</td></tr>
<tr><td><code id="trans_context_+3A_tot">tot</code></td>
<td>
<p>logical.  If <code>TRUE</code> condenses sub-units (e.g., sentences) 
into turns of talk for that <code>grouping.var</code>.</p>
</td></tr>
<tr><td><code id="trans_context_+3A_n.after">n.after</code></td>
<td>
<p>The number of rows after the indexed occurrence.</p>
</td></tr>
<tr><td><code id="trans_context_+3A_ord.inds">ord.inds</code></td>
<td>
<p>logical.  If <code>TRUE</code> inds is ordered least to greatest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe of the class &quot;qdap_context&quot; that can be printed 
(i.e., saved) in flexible outputs.  The dataframe can be printed as a 
dataframe style or pretty text output.  The resulting file contains n rows 
before and after each index of a vector of indices.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boolean_search">boolean_search</a></code>,
<code><a href="#topic+question_type">question_type</a></code>,
<code><a href="#topic+end_mark">end_mark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(x &lt;- with(DATA, trans_context(state, person, inds=c(1, 4, 7, 11))))
print(x, pretty=FALSE)
print(x, double_space = FALSE)
print(x, file="foo.xlsx")
print(x, file="foo.csv")
print(x, file="foo.txt")
print(x, file="foo.txt", pretty = FALSE)
print(x, file="foo.doc")

## With `end_mark`
inds1 &lt;- which(end_mark(DATA.SPLIT[, "state"]) == "?")
with(DATA.SPLIT, trans_context(state, person, inds=inds1))
with(DATA.SPLIT, trans_context(state, person, n.before = 0, inds=inds1))

## With `boolean_search`
inds2 &lt;- boolean_search(DATA.SPLIT$state, " I &amp;&amp;.")
with(DATA.SPLIT, trans_context(state, person, inds=inds2))

inds3 &lt;- boolean_search(DATA$state, " I ||.")
with(DATA.SPLIT, trans_context(state, person, inds=inds3))
with(DATA.SPLIT, trans_context(state, list(person, sex), inds=inds3))
with(DATA.SPLIT, trans_context(state, list(sex, adult), inds=inds3))

inds4 &lt;- boolean_search(raj$dialogue, spaste(paste(negation.words, collapse = " || ")))
trans_context(raj$dialogue, raj$person, inds4)

### With `question_type`
(x &lt;- question_type(DATA.SPLIT$state, DATA.SPLIT$person))

## All questions
with(DATA.SPLIT, trans_context(state, person, inds=x$inds))

## Specific question types
y &lt;- x[["raw"]]
inds5 &lt;- y[y[, "q.type"] %in% qcv(what, how), "n.row"]
with(DATA.SPLIT, trans_context(state, person, inds=inds5))
with(DATA.SPLIT, trans_context(state, person, inds=inds5, tot=F))

## End(Not run)
</code></pre>

<hr>
<h2 id='trans_venn'>Venn Diagram by Grouping Variable</h2><span id='topic+trans_venn'></span>

<h3>Description</h3>

<p>Produce a Venn diagram by grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trans_venn(
  text.var,
  grouping.var,
  stopwords = NULL,
  rm.duplicates = TRUE,
  title = TRUE,
  title.font = NULL,
  title.color = "black",
  title.cex = NULL,
  title.name = NULL,
  legend = TRUE,
  legend.cex = 0.8,
  legend.location = "bottomleft",
  legend.text.col = "black",
  legend.horiz = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trans_venn_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_stopwords">stopwords</code></td>
<td>
<p>Words to exclude from the analysis.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_rm.duplicates">rm.duplicates</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes the duplicated words 
from the analysis (only single usage is considered).</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_title">title</code></td>
<td>
<p>logical.  IF <code>TRUE</code> adds a title corresponding to the 
<code>grouping.var</code>.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_title.font">title.font</code></td>
<td>
<p>The font family of the cloud title.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_title.color">title.color</code></td>
<td>
<p>A character vector of length one corresponding to the 
color of the title.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_title.cex">title.cex</code></td>
<td>
<p>Character expansion factor for the title. <code>NULL</code> and 
<code>NA</code> are equivalent to 1.0</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_title.name">title.name</code></td>
<td>
<p>A title for the plot.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_legend">legend</code></td>
<td>
<p>logical.  If <code>TRUE</code> uses the names from the 
<code>target.words</code>
list corresponding to cloud.colors.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_legend.cex">legend.cex</code></td>
<td>
<p>Character expansion factor for the legend. <code>NULL</code> and 
<code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_legend.location">legend.location</code></td>
<td>
<p>The x and y co-ordinates to be used to position the 
legend.  The location may also be specified by setting x to a 
single keyword from the list <code>"bottomright"</code>, <code>"bottom"</code>, 
<code>"bottomleft"</code>, <code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>, 
<code>"topright"</code>, <code>"right"</code> and <code>"center"</code>. This places the legend 
on the inside of the plot frame at the given location.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_legend.text.col">legend.text.col</code></td>
<td>
<p>The color used for the legend text.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_legend.horiz">legend.horiz</code></td>
<td>
<p>logical; if <code>TRUE</code>, set the legend horizontally 
rather than vertically.</p>
</td></tr>
<tr><td><code id="trans_venn_+3A_...">...</code></td>
<td>
<p>Other arguments passed to plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a Venn plot by grouping variable(s).
</p>


<h3>Warning</h3>

<p>The algorithm used to overlap the Venn circles becomes 
increasingly overburdened and less accurate with increased grouping 
variables. An alternative is to use a network plot with 
{code<a href="#topic+Dissimilarity">Dissimilarity</a> measures labeling the edges between nodes 
(grouping variables) or a heat map (<code><a href="#topic+qheat">qheat</a></code>).
</p>


<h3>See Also</h3>

<p><code><a href="venneuler.html#topic+venneuler">venneuler</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(DATA , trans_venn(state, person, legend.location = "topright"))
#the plot below will take a considerable amount of time to plot
with(raj.act.1 , trans_venn(dialogue, person, legend.location = "topleft"))

## End(Not run)
</code></pre>

<hr>
<h2 id='Trim'>Remove Leading/Trailing White Space</h2><span id='topic+Trim'></span>

<h3>Description</h3>

<p>Remove leading/trailing white space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Trim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Trim_+3A_x">x</code></td>
<td>
<p>The text variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector with the leading/trailing white spaces removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(x &lt;- c("  talkstats.com ", "   really? ", " yeah"))
Trim(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='type_token_ratio'>Type-Token Ratio</h2><span id='topic+type_token_ratio'></span>

<h3>Description</h3>

<p>Calculate type-token ratio by grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>type_token_ratio(text.var, grouping.var = NULL, n.words = 1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="type_token_ratio_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="type_token_ratio_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="type_token_ratio_+3A_n.words">n.words</code></td>
<td>
<p>An integer specifying the number of words in each chunk.</p>
</td></tr>
<tr><td><code id="type_token_ratio_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of class <code>type_text_ratio</code>.  This object 
contains a type-token ratio for the overall text and a data frame
type-token ratios per grouping vriable.
</p>


<h3>References</h3>

<p>Baker, P. (2006) Using Corpora in Discourse Analysis. London: Continuum.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(raj, type_token_ratio(dialogue, person))
plot(with(raj, type_token_ratio(dialogue, person)))
</code></pre>

<hr>
<h2 id='unique_by'>Find Unique Words by Grouping Variable</h2><span id='topic+unique_by'></span>

<h3>Description</h3>

<p>Find unique words used by grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unique_by(text.var, grouping.var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unique_by_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="unique_by_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of unique words by grouping variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- pres_debates2012[pres_debates2012$time == "time 3", ]
with(dat, unique_by(dialogue, person))
with(pres_debates2012, unique_by(dialogue, list(time, person)))

with(DATA, unique_by(state, person))

## End(Not run)
</code></pre>

<hr>
<h2 id='vertex_apply'>Apply Parameter to List of Igraph Vertices/Edges</h2><span id='topic+vertex_apply'></span><span id='topic+edge_apply'></span>

<h3>Description</h3>

<p><code>vertex_apply</code> - Uniformly apply <span class="pkg">igraph</span> vertex plotting parameters to a list of <span class="pkg">igraph</span> objects.
</p>
<p><code>edge_apply</code> - Uniformly apply <span class="pkg">igrph</span> edge plotting parameters to a list of <span class="pkg">igraph</span> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vertex_apply(x, ..., hold.ends = NULL)

edge_apply(x, ..., hold.ends = c("label.color"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vertex_apply_+3A_x">x</code></td>
<td>
<p>A list of <span class="pkg">igraph</span> objects.</p>
</td></tr>
<tr><td><code id="vertex_apply_+3A_hold.ends">hold.ends</code></td>
<td>
<p>A vector of parameters passed to ... that should not be 
altered for the first and last (ends) objects in the list.</p>
</td></tr>
<tr><td><code id="vertex_apply_+3A_...">...</code></td>
<td>
<p>Arguments passed <span class="pkg">igraph</span>'s <code><a href="igraph.html#topic+V">V</a></code> and <code><a href="igraph.html#topic+E">E</a></code>.
See https://igraph.org/redirect.html
for more.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of igraph objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- with(DATA.SPLIT, polarity(state, person))
bg_black &lt;- Animate(x, neutral="white")
print(bg_black)

bgb &lt;- vertex_apply(bg_black, label.color="grey80", size=20, color="grey40")
bgb &lt;- edge_apply(bgb, label.color="yellow")
print(bgb, bg="black", pause=.75)

## End(Not run)
</code></pre>

<hr>
<h2 id='visual'>Generic visual Method</h2><span id='topic+visual'></span>

<h3>Description</h3>

<p>Access the visual-graph-plot object from select qdap outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visual(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visual_+3A_x">x</code></td>
<td>
<p>A qdap object (list) with a visual-graph-plot object (e.g., 
<code><a href="#topic+discourse_map">discourse_map</a></code>).</p>
</td></tr>
<tr><td><code id="visual_+3A_...">...</code></td>
<td>
<p>Arguments passed to visual method of other classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scores">scores</a></code>,
<code><a href="#topic+counts">counts</a></code>,
<code><a href="#topic+preprocessed">preprocessed</a></code>,
<code><a href="#topic+proportions">proportions</a></code>
</p>

<hr>
<h2 id='visual.discourse_map'>Discourse Map</h2><span id='topic+visual.discourse_map'></span>

<h3>Description</h3>

<p><code>visual.discourse_map</code> - View visual from <code><a href="#topic+discourse_map">discourse_map</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'discourse_map'
visual(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visual.discourse_map_+3A_x">x</code></td>
<td>
<p>The discourse_map object.</p>
</td></tr>
<tr><td><code id="visual.discourse_map_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>discourse_map Method for visual
</p>

<hr>
<h2 id='weight'>Weight a qdap Object</h2><span id='topic+weight'></span>

<h3>Description</h3>

<p>Weight a word_proximity object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weight(x, type = "scale", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weight_+3A_x">x</code></td>
<td>
<p>A qdap object with a weight method.</p>
</td></tr>
<tr><td><code id="weight_+3A_type">type</code></td>
<td>
<p>A weighting type of: c(<code>"scale_log"</code>, <code>"scale"</code>, 
<code>"rev_scale"</code>, <code>"rev_scale_log"</code>, <code>"log"</code>, <code>"sqrt"</code>, 
<code>"scale_sqrt"</code>, <code>"rev_sqrt"</code>, <code>"rev_scale_sqrt"</code>).  The 
weight type section name (i.e. <code>A_B_C</code> where <code>A</code>, <code>B</code>, and
<code>C</code> are sections) determines what action will occur.  <code>log</code> will 
use <code><a href="base.html#topic+log">log</a></code>, <code>sqrt</code> will use <code><a href="base.html#topic+sqrt">sqrt</a></code>,
<code>scale</code> will standardize the values.  <code>rev</code> will multiply by -1 to 
give the inverse sign.  This enables a comparison similar to correlations 
rather than distance.</p>
</td></tr>
<tr><td><code id="weight_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a weighted list of matrices.
</p>


<h3>Note</h3>

<p>A constant of .000000000001 is added to each element when log is used 
to deal with the problem of <code>log(0)</code>.
</p>

<hr>
<h2 id='wfm'>Word Frequency Matrix</h2><span id='topic+wfm'></span><span id='topic+wfm.wfdf'></span><span id='topic+wfm.character'></span><span id='topic+wfm.factor'></span><span id='topic+wfdf'></span><span id='topic+wfm_expanded'></span><span id='topic+wfm_combine'></span><span id='topic+weight.wfm'></span><span id='topic+weight.wfdf'></span><span id='topic+as.wfm'></span><span id='topic+as.wfm.matrix'></span><span id='topic+as.wfm.default'></span><span id='topic+as.wfm.TermDocumentMatrix'></span><span id='topic+as.wfm.DocumentTermMatrix'></span><span id='topic+as.wfm.data.frame'></span><span id='topic+as.wfm.wfdf'></span><span id='topic+as.wfm.Corpus'></span><span id='topic+wfm.Corpus'></span>

<h3>Description</h3>

<p><code>wfm</code> - Generate a word frequency matrix by grouping variable(s).
</p>
<p><code>wfdf</code> - Generate a word frequency data frame by grouping variable.
</p>
<p><code>wfm_expanded</code> - Expand a word frequency matrix to have multiple rows 
for each word.
</p>
<p><code>wfm_combine</code> - Combines words (rows) of a word frequency matrix 
(<code>wfdf</code>) together.
</p>
<p><code>weight</code> - Weight a word frequency matrix for analysis where such 
weighting is sensible.
</p>
<p><code>weight.wfdf</code> - Weight a word frequency matrix for analysis where such 
weighting is sensible.
</p>
<p><code>as.wfm</code> - Attempts to coerce a matrix to a <code><a href="#topic+wfm">wfm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wfm(
  text.var = NULL,
  grouping.var = NULL,
  output = "raw",
  stopwords = NULL,
  char2space = "~~",
  ...
)

## S3 method for class 'wfdf'
wfm(
  text.var = NULL,
  grouping.var = NULL,
  output = "raw",
  stopwords = NULL,
  char2space = "~~",
  ...
)

## S3 method for class 'character'
wfm(
  text.var = NULL,
  grouping.var = NULL,
  output = "raw",
  stopwords = NULL,
  char2space = "~~",
  ...
)

## S3 method for class 'factor'
wfm(
  text.var = NULL,
  grouping.var = NULL,
  output = "raw",
  stopwords = NULL,
  char2space = "~~",
  ...
)

wfdf(
  text.var,
  grouping.var = NULL,
  stopwords = NULL,
  margins = FALSE,
  output = "raw",
  digits = 2,
  char2space = "~~",
  ...
)

wfm_expanded(text.var, grouping.var = NULL, ...)

wfm_combine(wf.obj, word.lists, matrix = TRUE)

## S3 method for class 'wfm'
weight(x, type = "prop", ...)

## S3 method for class 'wfdf'
weight(x, type = "prop", ...)

as.wfm(x, ...)

## S3 method for class 'matrix'
as.wfm(x, ...)

## Default S3 method:
as.wfm(x, ...)

## S3 method for class 'TermDocumentMatrix'
as.wfm(x, ...)

## S3 method for class 'DocumentTermMatrix'
as.wfm(x, ...)

## S3 method for class 'data.frame'
as.wfm(x, ...)

## S3 method for class 'wfdf'
as.wfm(x, ...)

## S3 method for class 'Corpus'
as.wfm(x, col = "docs", row = "text", ...)

## S3 method for class 'Corpus'
wfm(text.var, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wfm_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="wfm_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="wfm_+3A_output">output</code></td>
<td>
<p>Output type (either <code>"proportion"</code> or <code>"percent"</code>).</p>
</td></tr>
<tr><td><code id="wfm_+3A_stopwords">stopwords</code></td>
<td>
<p>A vector of stop words to remove.</p>
</td></tr>
<tr><td><code id="wfm_+3A_char2space">char2space</code></td>
<td>
<p>A vector of characters to be turned into spaces.  If 
<code>char.keep</code> is <code>NULL</code>, <code>char2space</code> will activate this 
argument.</p>
</td></tr>
<tr><td><code id="wfm_+3A_margins">margins</code></td>
<td>
<p>logical. If <code>TRUE</code> provides grouping.var and word 
variable totals.</p>
</td></tr>
<tr><td><code id="wfm_+3A_digits">digits</code></td>
<td>
<p>An integer indicating the number of decimal places (round) or 
significant digits (signif) to be used. Negative values are allowed.</p>
</td></tr>
<tr><td><code id="wfm_+3A_wf.obj">wf.obj</code></td>
<td>
<p>A <code>wfm</code> or <code>wfdf</code> object.</p>
</td></tr>
<tr><td><code id="wfm_+3A_word.lists">word.lists</code></td>
<td>
<p>A list of character vectors of words to pass to 
<code>wfm_combine</code></p>
</td></tr>
<tr><td><code id="wfm_+3A_matrix">matrix</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns the output as a 
<code><a href="#topic+wfm">wfm</a></code> rather than a <code><a href="#topic+wfdf">wfdf</a></code> object.</p>
</td></tr>
<tr><td><code id="wfm_+3A_x">x</code></td>
<td>
<p>An object with words for row names and integer values.</p>
</td></tr>
<tr><td><code id="wfm_+3A_type">type</code></td>
<td>
<p>The type of weighting to use: c(<code>"prop"</code>, <code>"max"</code>, 
<code>"scaled"</code>).  All weight by column.  <code>"prop"</code> uses a proportion
weighting and all columns sum to 1.  <code>"max"</code> weights in proportion to 
the max value; all values are integers and column sums may not be equal.
<code>"scaled"</code> uses <code><a href="base.html#topic+scale">scale</a></code> to scale with 
<code>center = FALSE</code>; output is not integer and column sums may not be 
equal.</p>
</td></tr>
<tr><td><code id="wfm_+3A_col">col</code></td>
<td>
<p>The column name (generally not used).</p>
</td></tr>
<tr><td><code id="wfm_+3A_row">row</code></td>
<td>
<p>The row name (generally not used).</p>
</td></tr>
<tr><td><code id="wfm_+3A_...">...</code></td>
<td>
<p>Other arguments supplied to <code><a href="tm.html#topic+Corpus">Corpus</a></code> or
<code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code>.  If <code>as.wfm</code> this is other 
arguments passed to <code>as.wfm</code> methods (currently ignored).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>wfm</code> - returns a word frequency of the class matrix.
</p>
<p><code>wfdf</code> - returns a word frequency of the class data.frame with 
a words column and optional margin sums.
</p>
<p><code>wfm_expanded</code> - returns a matrix similar to a word frequency 
matrix (<code>wfm</code>) but the rows are expanded to represent the maximum usages 
of the word and cells are dummy coded to indicate that number of uses.
</p>
<p><code>wfm_combine</code> - returns a word frequency matrix (<code>wfm</code>) or 
dataframe (<code>wfdf</code>) with counts for the combined word.lists merged and 
remaining terms (<code>else</code>).
</p>
<p><code>weight</code> - Returns a weighted matrix for use with other R 
packages. The output is not of the class &quot;wfm&quot;.
</p>
<p><code>as.wfm</code> - Returns a matrix of the class &quot;wfm&quot;.
</p>


<h3>Note</h3>

<p>Words can be kept as one by inserting a double tilde (<code>"~~"</code>), or 
other character strings passed to char2space, as a single word/entry. This is 
useful for keeping proper names as a single unit.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## word frequency matrix (wfm) example:
with(DATA, wfm(state, list(sex, adult)))[1:15, ]
with(DATA, wfm(state, person))[1:15, ]
Filter(with(DATA, wfm(state, list(sex, adult))), 5)
with(DATA, wfm(state, list(sex, adult)))

## Filter particular words based on max/min values in wfm
v &lt;- with(DATA, wfm(state, list(sex, adult)))
Filter(v, 5)
Filter(v, 5, count.apostrophe = FALSE)
Filter(v, 5, 7)
Filter(v, 4, 4)
Filter(v, 3, 4)
Filter(v, 3, 4, stopwords = Top25Words)

## insert double tilde ("~~") to keep phrases(i.e., first last name)
alts &lt;- c(" fun", "I ")
state2 &lt;- space_fill(DATA$state, alts, rm.extra = FALSE)
with(DATA, wfm(state2, list(sex, adult)))[1:18, ]

## word frequency dataframe (wfdf) example:
with(DATA, wfdf(state, list(sex, adult)))[1:15, ]
with(DATA, wfdf(state, person))[1:15, ]

## wfm_expanded example:
z &lt;- wfm(DATA$state, DATA$person)
wfm_expanded(z)[30:45, ] #two "you"s

## wf_combine examples:
#===================
## raw no margins (will work) 
x &lt;- wfm(DATA$state, DATA$person) 
                    
## raw with margin (will work) 
y &lt;- wfdf(DATA$state, DATA$person, margins = TRUE) 

## Proportion matrix
z2 &lt;- wfm(DATA$state, DATA$person, output="proportion")

WL1 &lt;- c(y[, 1])                                                                      
WL2 &lt;- list(c("read", "the", "a"), c("you", "your", "you're"))                       
WL3 &lt;- list(bob = c("read", "the", "a"), yous = c("you", "your", "you're"))          
WL4 &lt;- list(bob = c("read", "the", "a"), yous = c("a", "you", "your", "your're"))     
WL5 &lt;- list(yous = c("you", "your", "your're"))                                       
WL6 &lt;- list(c("you", "your", "your're"))  #no name so will be called words 1          
WL7 &lt;- c("you", "your", "your're")                             
                                                               
wfm_combine(z2, WL2) #Won't work not a raw frequency matrix     
wfm_combine(x, WL2)  #Works (raw and no margins)                     
wfm_combine(y, WL2)  #Works (raw with margins)                           
wfm_combine(y, c("you", "your", "your're"))                        
wfm_combine(y, WL1)                                                  
wfm_combine(y, WL3)                                                   
## wfm_combine(y, WL4) #Error         
wfm_combine(y, WL5)                                         
wfm_combine(y, WL6)                                              
wfm_combine(y, WL7)                                           
                                                                  
worlis &lt;- c("you", "it", "it's", "no", "not", "we")              
y &lt;- wfdf(DATA$state, list(DATA$sex, DATA$adult), margins = TRUE)  
z &lt;- wfm_combine(y, worlis)                      
                                                                 
chisq.test(z)                                                      
chisq.test(wfm(y)) 

## Dendrogram
presdeb &lt;- with(pres_debates2012, wfm(dialogue, list(person, time)))
library(sjPlot)
sjc.dend(t(presdeb), 2:4)

## Words correlated within turns of talk
## EXAMPLE 1
library(qdapTools)
x &lt;- factor(with(rajSPLIT, paste(act, pad(TOT(tot)), sep = "|")))
dat &lt;- wfm(rajSPLIT$dialogue, x)

cor(t(dat)[, c("romeo", "juliet")])
cor(t(dat)[, c("romeo", "banished")])
cor(t(dat)[, c("romeo", "juliet", "hate", "love")])
qheat(cor(t(dat)[, c("romeo", "juliet", "hate", "love")]), 
    diag.na = TRUE, values = TRUE, digits = 3, by.column = NULL)
    
dat2 &lt;- wfm(DATA$state, id(DATA))
qheat(cor(t(dat2)), low = "yellow", high = "red", 
    grid = "grey90", diag.na = TRUE, by.column = NULL)
    
## EXAMPLE 2
x2 &lt;- factor(with(pres_debates2012, paste(time, pad(TOT(tot)), sep = "|")))
dat2 &lt;- wfm(pres_debates2012$dialogue, x2)
wrds &lt;- word_list(pres_debates2012$dialogue, 
    stopwords = c("it's", "that's", Top200Words))
wrds2 &lt;- tolower(sort(wrds$rfswl[[1]][, 1]))
qheat(word_cor(t(dat2), word = wrds2, r = NULL),
    diag.na = TRUE, values = TRUE, digits = 3, by.column = NULL, 
    high="red", low="yellow", grid=NULL)
    
## EXAMPLE 3
library(gridExtra); library(ggplot2); library(grid)
dat3 &lt;- lapply(qcv(OBAMA, ROMNEY), function(x) {
    with(pres_debates2012, wfm(dialogue[person == x], x2[person == x]))
})


# Presidential debates by person
dat5 &lt;- pres_debates2012
dat5 &lt;- dat5[dat5$person %in% qcv(ROMNEY, OBAMA), ]

disp &lt;- with(dat5, dispersion_plot(dialogue, wrds2, grouping.var = person, 
    total.color = NULL, rm.vars=time))


cors &lt;- lapply(dat3, function(m) {
    word_cor(t(m), word = wrds2, r = NULL)
})

plots &lt;- lapply(cors, function(x) {
    qheat(x, diag.na = TRUE, values = TRUE, digits = 3, plot = FALSE,
    by.column = NULL, high="red", low="yellow", grid=NULL)
})

plots &lt;- lapply(1:2, function(i) {
    plots[[i]] + ggtitle(qcv(OBAMA, ROMNEY)[i]) +
    theme(axis.title.x = element_blank(),
        plot.margin = unit(rep(0, 4), "lines"))
})

grid.arrange(disp, arrangeGrob(plots[[1]], plots[[2]], ncol=1), ncol=2)

## With `word_cor`
worlis &lt;- list(
    pronouns = c("you", "it", "it's", "we", "i'm", "i"),
    negative = qcv(no, dumb, distrust, not, stinks),
    literacy = qcv(computer, talking, telling)
)
y &lt;- wfdf(DATA$state, qdapTools::id(DATA, prefix = TRUE))
z &lt;- wfm_combine(y, worlis)

word_cor(t(z), word = names(worlis), r = NULL)

## Plotting method
plot(y, TRUE)
plot(z)

## Correspondence Analysis
library(ca)

dat &lt;- pres_debates2012
dat &lt;- dat[dat$person %in% qcv(ROMNEY, OBAMA), ]

speech &lt;- stemmer(dat$dialogue)
mytable1 &lt;- with(dat, wfm(speech, list(person, time), stopwords = Top25Words))

fit &lt;- ca(mytable1)
summary(fit)
plot(fit)
plot3d.ca(fit, labels=1)


mytable2 &lt;- with(dat, wfm(speech, list(person, time), stopwords = Top200Words))

fit2 &lt;- ca(mytable2)
summary(fit2)
plot(fit2)
plot3d.ca(fit2, labels=1)

## Weight a wfm
WFM &lt;- with(DATA, wfm(state, list(sex, adult)))
plot(weight(WFM, "scaled"), TRUE)
weight(WFM, "prop")
weight(WFM, "max")
weight(WFM, "scaled")

## End(Not run)
</code></pre>

<hr>
<h2 id='word_associate'>Find Associated Words</h2><span id='topic+word_associate'></span>

<h3>Description</h3>

<p>Find words associated with a given word(s) or a phrase(s).  Results can be
output as a network graph and/or wordcloud.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_associate(
  text.var,
  grouping.var = NULL,
  match.string,
  text.unit = "sentence",
  extra.terms = NULL,
  target.exclude = NULL,
  stopwords = NULL,
  network.plot = FALSE,
  wordcloud = FALSE,
  cloud.colors = c("black", "gray55"),
  title.color = "blue",
  nw.label.cex = 0.8,
  title.padj = -4.5,
  nw.label.colors = NULL,
  nw.layout = NULL,
  nw.edge.color = "gray90",
  nw.label.proportional = TRUE,
  nw.title.padj = NULL,
  nw.title.location = NULL,
  title.font = NULL,
  title.cex = NULL,
  nw.edge.curved = TRUE,
  cloud.legend = NULL,
  cloud.legend.cex = 0.8,
  cloud.legend.location = c(-0.03, 1.03),
  nw.legend = NULL,
  nw.legend.cex = 0.8,
  nw.legend.location = c(-1.54, 1.41),
  legend.override = FALSE,
  char2space = "~~",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_associate_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_match.string">match.string</code></td>
<td>
<p>A list of vectors or vector of terms to associate in the 
text.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_text.unit">text.unit</code></td>
<td>
<p>The text unit (either <code>"sentence"</code> or <code>"tot"</code>.
This argument determines what unit to find the match string words within.  
For example if <code>"sentence"</code> is chosen the function pulls all text for 
sentences the match string terms are found in.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_extra.terms">extra.terms</code></td>
<td>
<p>Other terms to color beyond the match string.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_target.exclude">target.exclude</code></td>
<td>
<p>A vector of words to exclude from the 
<code>match.string</code>.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_stopwords">stopwords</code></td>
<td>
<p>Words to exclude from the analysis.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_network.plot">network.plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> plots a network plot of the 
words.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_wordcloud">wordcloud</code></td>
<td>
<p>logical.  If <code>TRUE</code> plots a wordcloud plot of the 
words.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_cloud.colors">cloud.colors</code></td>
<td>
<p>A vector of colors equal to the length of 
<code>match.string</code> +1.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_title.color">title.color</code></td>
<td>
<p>A character vector of length one corresponding to the 
color of the title.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.label.cex">nw.label.cex</code></td>
<td>
<p>The magnification to be used for network plot labels 
relative to the current setting of cex.  Default is .8.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_title.padj">title.padj</code></td>
<td>
<p>Adjustment for the title. For strings parallel to the axes, 
padj = 0 means right or top alignment, and padj = 1 means left or bottom 
alignment.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.label.colors">nw.label.colors</code></td>
<td>
<p>A vector of colors equal to the length of 
<code>match.string</code> +1.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.layout">nw.layout</code></td>
<td>
<p>layout types supported by igraph.  See 
<code><a href="igraph.html#topic+layout">layout</a></code>.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.edge.color">nw.edge.color</code></td>
<td>
<p>A character vector of length one corresponding to the 
color of the plot edges.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.label.proportional">nw.label.proportional</code></td>
<td>
<p>logical.  If <code>TRUE</code> scales the network 
plots across grouping.var to allow plot to plot comparisons.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.title.padj">nw.title.padj</code></td>
<td>
<p>Adjustment for the network plot title. For strings 
parallel to the axes, padj = 0 means right or top alignment, and padj = 1 
means left or bottom alignment.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.title.location">nw.title.location</code></td>
<td>
<p>On which side of the network plot (1=bottom, 2=left, 
3=top, 4=right).</p>
</td></tr>
<tr><td><code id="word_associate_+3A_title.font">title.font</code></td>
<td>
<p>The font family of the cloud title.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_title.cex">title.cex</code></td>
<td>
<p>Character expansion factor for the title. <code>NULL</code> and 
<code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.edge.curved">nw.edge.curved</code></td>
<td>
<p>logical.  If <code>TRUE</code> edges will be curved rather than 
straight paths.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_cloud.legend">cloud.legend</code></td>
<td>
<p>A character vector of names corresponding to the number of 
vectors in <code>match.string</code>.  Both <code>nw.legend</code> and <code>cloud.legend</code>
can be set separately; or one may be set and by default the other will assume 
those legend labels.  If the user does not desire this behavior use the 
<code>legend.override</code> argument.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_cloud.legend.cex">cloud.legend.cex</code></td>
<td>
<p>Character expansion factor for the  wordcloud legend. 
<code>NULL</code> and <code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_cloud.legend.location">cloud.legend.location</code></td>
<td>
<p>The x and y co-ordinates to be used to position the 
wordcloud legend.  The location may also be specified by setting x to a 
single keyword from the list <code>"bottomright"</code>, <code>"bottom"</code>, 
<code>"bottomleft"</code>, <code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>, 
<code>"topright"</code>, <code>"right"</code> and <code>"center"</code>. This places the legend on 
the inside of the plot frame at the given location.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.legend">nw.legend</code></td>
<td>
<p>A character vector of names corresponding to the number of 
vectors in <code>match.string</code>.  Both <code>nw.legend</code> and <code>cloud.legend</code>
can be set separately; or one may be set and by default the other will assume 
those legend labels.  If the user does not desire this behavior use the 
<code>legend.override</code> argument.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.legend.cex">nw.legend.cex</code></td>
<td>
<p>Character expansion factor for the  network plot legend. 
<code>NULL</code> and <code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_nw.legend.location">nw.legend.location</code></td>
<td>
<p>The x and y co-ordinates to be used to position the 
network plot legend.  The location may also be specified by setting x to a 
single keyword from the list <code>"bottomright"</code>, <code>"bottom"</code>, 
<code>"bottomleft"</code>, <code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>, 
<code>"topright"</code>, <code>"right"</code> and <code>"center"</code>. This places the legend 
on the inside of the plot frame at the given location.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_legend.override">legend.override</code></td>
<td>
<p>By default if legend labels are supplied to either 
<code>cloud.legend</code> or <code>nw.legend</code> may be set and if the other remains 
<code>NULL</code> it will assume the supplied vector to the previous legend 
argument.  If this behavior is not desired <code>legend.override</code> should be 
set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_char2space">char2space</code></td>
<td>
<p>Currently a road to nowhere.  Eventually this will allow 
the retention of characters as is allowed in <code>trans_cloud</code> already.</p>
</td></tr>
<tr><td><code id="word_associate_+3A_...">...</code></td>
<td>
<p>Other arguments supplied to <code><a href="#topic+trans_cloud">trans_cloud</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list:
</p>
<table>
<tr><td><code>word frequency matrices</code></td>
<td>
<p>Word frequency matrices for each grouping 
variable.</p>
</td></tr> 
<tr><td><code>dialogue</code></td>
<td>
<p>A list of dataframes for each word list (each vector supplied 
to <code>match.string</code>) and a final dataframe of all combined text units that 
contain any match string.</p>
</td></tr> 
<tr><td><code>match.terms</code></td>
<td>
<p>A list of vectors of word lists (each vector supplied 
to <code>match.string</code>).</p>
</td></tr> 
</table>
<p>Optionally, returns a word cloud and/or a network plot of the text unit 
containing the <code>match.string</code> terms.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trans_cloud">trans_cloud</a></code>,
<code><a href="#topic+word_network_plot">word_network_plot</a></code>,
<code><a href="wordcloud.html#topic+wordcloud">wordcloud</a></code>,
<code><a href="igraph.html#topic+graph.adjacency">graph.adjacency</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ms &lt;- c(" I ", "you")
et &lt;- c(" it", " tell", "tru")
out1 &lt;- word_associate(DATA2$state, DATA2$person, match.string = ms, 
    wordcloud = TRUE,  proportional = TRUE, 
    network.plot = TRUE,  nw.label.proportional = TRUE, extra.terms = et,  
    cloud.legend =c("A", "B", "C"),
    title.color = "blue", cloud.colors = c("red", "purple", "gray70"))

#======================================
#Note: You don't have to name the vectors in the lists but I do for clarity
ms &lt;- list(
    list1 = c(" I ", " you", "not"), 
    list2 = c(" wh")          
)

et &lt;- list(
    B = c(" the", "do", "tru"), 
    C = c(" it", " already", "we")
)

out2 &lt;- word_associate(DATA2$state, DATA2$person, match.string = ms, 
    wordcloud = TRUE,  proportional = TRUE, 
    network.plot = TRUE,  nw.label.proportional = TRUE, extra.terms = et,  
    cloud.legend =c("A", "B", "C", "D"),
    title.color = "blue", cloud.colors = c("red", "blue", "purple", "gray70"))

out3 &lt;- word_associate(DATA2$state, list(DATA2$day, DATA2$person), match.string = ms)

#======================================
m &lt;- list(
    A1 = c("you", "in"), #list 1
    A2 = c(" wh")        #list 2
)

n &lt;- list(
    B = c(" the", " on"), 
    C = c(" it", " no")
)

out4 &lt;- word_associate(DATA2$state, list(DATA2$day, DATA2$person), 
    match.string = m)
out5 &lt;- word_associate(raj.act.1$dialogue, list(raj.act.1$person), 
    match.string = m)
out6 &lt;- with(mraja1spl, word_associate(dialogue, list(fam.aff, sex), 
     match.string = m))
names(out6)
lapply(out6$dialogue, htruncdf, n = 20, w = 20)

#======================================
DATA2$state2 &lt;- space_fill(DATA2$state, c("is fun", "too fun"))

ms &lt;- list(
    list1 = c(" I ", " you", "is fun", "too fun"), 
    list2 = c(" wh")      
)

et &lt;- list(
    B = c(" the", " on"), 
    C = c(" it", " no")
)

out7 &lt;- word_associate(DATA2$state2, DATA2$person, match.string = ms, 
    wordcloud = TRUE,  proportional = TRUE, 
    network.plot = TRUE,  nw.label.proportional = TRUE, extra.terms = et,  
    cloud.legend =c("A", "B", "C", "D"),
    title.color = "blue", cloud.colors = c("red", "blue", "purple", "gray70"))
    
DATA2 &lt;- qdap::DATA2

## End(Not run)
</code></pre>

<hr>
<h2 id='word_cor'>Find Correlated Words</h2><span id='topic+word_cor'></span>

<h3>Description</h3>

<p>Find associated words within grouping variable(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_cor(
  text.var,
  grouping.var = qdapTools::id(text.var),
  word,
  r = 0.7,
  values = TRUE,
  method = "pearson",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_cor_+3A_text.var">text.var</code></td>
<td>
<p>The text variable (or frequency matrix).</p>
</td></tr>
<tr><td><code id="word_cor_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default uses each row as a group.
Also takes a single grouping variable or a list of 1 or more grouping 
variables.  Unlike other <span class="pkg">qdap</span> functions, this cannot be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_word">word</code></td>
<td>
<p>The word(s) vector to find associated words for.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_r">r</code></td>
<td>
<p>The correlation level find associated words for.  If positive this
is the minimum value, if negative this is the maximum value.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_values">values</code></td>
<td>
<p>logical.  If <code>TRUE</code> returns the named correlates (names are 
the words).  If <code>FALSE</code> only the associated words are returned.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_method">method</code></td>
<td>
<p>A character string indicating which correlation coefficient is 
to be computed (<code>"pearson"</code>, <code>"kendall"</code>, or <code>"spearman"</code>).</p>
</td></tr>
<tr><td><code id="word_cor_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+wfm">wfm</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of associated words or correlation matrix if 
<code>r = NULL</code>.
</p>


<h3>Note</h3>

<p>Note that if a word has no variablity in it's usage across grouping 
variable(s) the <code><a href="stats.html#topic+sd">sd</a></code> will result in 0, thus 
<code><a href="stats.html#topic+cor">cor</a></code> will will likely return a warning as in this 
example: <code>cor(rep(3, 10), rnorm(10))</code>.
</p>


<h3>References</h3>

<p>The plotting method for the list output was inspired by Ben 
Marwick; see https://stackoverflow.com/a/19925445/1000343 for more.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+word_proximity">word_proximity</a></code>,
<code><a href="tm.html#topic+findAssocs">findAssocs</a></code>,
<code><a href="#topic+word_associate">word_associate</a></code>,
<code><a href="#topic+wfm">wfm</a></code>,
<code><a href="stats.html#topic+cor">cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- factor(with(rajSPLIT, paste(act, pad(TOT(tot)), sep = "|")))
word_cor(rajSPLIT$dialogue, x, "romeo", .45)
word_cor(rajSPLIT$dialogue, x, "love", .5)  

## Negative correlation
word_cor(rajSPLIT$dialogue, x, "you", -.1)
with(rajSPLIT, word_cor(dialogue, list(person, act), "hate"))

words &lt;- c("hate", "i", "love", "ghost")
with(rajSPLIT, word_cor(dialogue, x, words, r = .5))
with(rajSPLIT, word_cor(dialogue, x, words, r = .4))

## Set `r = NULL` to get matrix between words
with(rajSPLIT, word_cor(dialogue, x, words, r = NULL))

## Plotting 
library(tm)
data("crude")
oil_cor1 &lt;- apply_as_df(crude, word_cor, word = "oil", r=.7)
plot(oil_cor1)

oil_cor2 &lt;- apply_as_df(crude, word_cor, word = qcv(texas, oil, money), r=.7)
plot(oil_cor2)
plot(oil_cor2, ncol=2)

oil_cor3 &lt;- apply_as_df(crude, word_cor, word = qcv(texas, oil, money), r=NULL)
plot(oil_cor3)

## Run on multiple times/person/nested
## Split and apply to data sets
## Suggested use of stemming
DATA3 &lt;- split(DATA2, DATA2$person)

## Find correlations between words per turn of talk by person
## Throws multiple warning because small data set
library(qdapTools)
lapply(DATA3, function(x) {
    word_cor(x[, "state"], qdapTools::id(x), qcv(computer, i, no, good), r = NULL)
})

## Find words correlated per turn of talk by person
## Throws multiple warning because small data set
lapply(DATA3, function(x) {
    word_cor(x[, "state"], qdapTools::id(x), qcv(computer, i, no, good))
})


## A real example
dat &lt;- pres_debates2012 
dat$TOT &lt;- factor(with(dat, paste(time, pad(TOT(tot)), sep = "|")))
dat &lt;- dat[dat$person %in% qcv(OBAMA, ROMNEY), ]
dat$person &lt;- factor(dat$person)
dat.split &lt;- with(dat, split(dat, list(person, time)))

wrds &lt;- qcv(america, debt, dollar, people, tax, health)
lapply(dat.split, function(x) {
    word_cor(x[, "dialogue"], x[, "TOT"], wrds, r=NULL)
})

## Supply a matrix (make sure to use `t` on a `wfm` matrix)
worlis &lt;- list(
    pronouns = c("you", "it", "it's", "we", "i'm", "i"),
    negative = qcv(no, dumb, distrust, not, stinks),
    literacy = qcv(computer, talking, telling)
)
y &lt;- wfdf(DATA$state, qdapTools::id(DATA, prefix = TRUE))
z &lt;- wfm_combine(y, worlis)

out &lt;- word_cor(t(z), word = c(names(worlis), "else.words"), r = NULL)
out
plot(out)

## Additional plotting/viewing
require(tm)
data("crude")

out1 &lt;- word_cor(t(as.wfm(crude)), word = "oil", r=.7)
vect2df(out1[[1]], "word", "cor")

plot(out1)
qheat(vect2df(out1[[1]], "word", "cor"), values=TRUE, high="red", 
    digits=2, order.by ="cor", plot=FALSE) + coord_flip()


out2 &lt;- word_cor(t(as.wfm(crude)), word = c("oil", "country"), r=.7)
plot(out2)

## End(Not run)
</code></pre>

<hr>
<h2 id='word_count'>Word Counts</h2><span id='topic+word_count'></span><span id='topic+wc'></span><span id='topic+character_count'></span><span id='topic+character_table'></span><span id='topic+char_table'></span>

<h3>Description</h3>

<p><code>word_count</code> - Transcript apply word counts.
</p>
<p><code>character_count</code> - Transcript apply character counts.
</p>
<p><code>character_table</code> - Computes a table of character counts by grouping .
variable(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_count(
  text.var,
  byrow = TRUE,
  missing = NA,
  digit.remove = TRUE,
  names = FALSE
)

wc(text.var, byrow = TRUE, missing = NA, digit.remove = TRUE, names = FALSE)

character_count(
  text.var,
  byrow = TRUE,
  missing = NA,
  apostrophe.remove = TRUE,
  digit.remove = TRUE,
  count.space = FALSE
)

character_table(
  text.var,
  grouping.var = NULL,
  percent = TRUE,
  prop.by.row = TRUE,
  zero.replace = 0,
  digits = 2,
  ...
)

char_table(
  text.var,
  grouping.var = NULL,
  percent = TRUE,
  prop.by.row = TRUE,
  zero.replace = 0,
  digits = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_count_+3A_text.var">text.var</code></td>
<td>
<p>The text variable</p>
</td></tr>
<tr><td><code id="word_count_+3A_byrow">byrow</code></td>
<td>
<p>logical.  If <code>TRUE</code> counts by row, if <code>FALSE</code> counts 
all words.</p>
</td></tr>
<tr><td><code id="word_count_+3A_missing">missing</code></td>
<td>
<p>Value to insert for missing values (empty cells).</p>
</td></tr>
<tr><td><code id="word_count_+3A_digit.remove">digit.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes digits before counting 
words.</p>
</td></tr>
<tr><td><code id="word_count_+3A_names">names</code></td>
<td>
<p>logical.  If <code>TRUE</code> the sentences are given as the names of 
the counts.</p>
</td></tr>
<tr><td><code id="word_count_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> apostrophes will be counted 
in the character count.</p>
</td></tr>
<tr><td><code id="word_count_+3A_count.space">count.space</code></td>
<td>
<p>logical.  If <code>TRUE</code> spaces are counted as characters.</p>
</td></tr>
<tr><td><code id="word_count_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="word_count_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="word_count_+3A_prop.by.row">prop.by.row</code></td>
<td>
<p>logical.  If <code>TRUE</code> applies proportional to the row.
If <code>FALSE</code> applies by column.</p>
</td></tr>
<tr><td><code id="word_count_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.</p>
</td></tr>
<tr><td><code id="word_count_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="word_count_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+prop">prop</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>word_count</code> - returns a word count by row or total.
</p>
<p><code>character_count</code> - returns a character count by row or total.
</p>
<p><code>character_table</code> - returns a list:
dataframe of character counts by grouping variable.
</p>
<table>
<tr><td><code>raw</code></td>
<td>
<p>Dataframe of the frequency of characters by grouping variable.</p>
</td></tr> 
<tr><td><code>prop</code></td>
<td>
<p>Dataframe of the proportion of characters by grouping variable.</p>
</td></tr> 
<tr><td><code>rnp</code></td>
<td>
<p>Dataframe of the frequency and proportions of characters by 
grouping variable.</p>
</td></tr> 
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr>
<tr><td><code>zero.replace</code></td>
<td>
<p>The value of zero.replace used for plotting purposes.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>wc is a convenient short hand for word_count.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+syllable_count">syllable_count</a></code>,
<code><a href="#topic+prop">prop</a></code>,
<code><a href="#topic+colcomb2class">colcomb2class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## WORD COUNT
word_count(DATA$state)
wc(DATA$state)
word_count(DATA$state, names = TRUE)
word_count(DATA$state, byrow=FALSE, names = TRUE)
sum(word_count(DATA$state))

sapply(split(raj$dialogue, raj$person), wc, FALSE) %&gt;%
    sort(decreasing=TRUE) %&gt;% 
    list2df("wordcount", "person") %&gt;%
    `[`(, 2:1)

## PLOT WORD COUNTS
raj2 &lt;- raj
raj2$scaled &lt;- unlist(tapply(wc(raj$dialogue), raj2$act, scale))
raj2$scaled2 &lt;- unlist(tapply(wc(raj$dialogue), raj2$act, scale, scale = FALSE))
raj2$ID &lt;- factor(unlist(tapply(raj2$act, raj2$act, seq_along)))

ggplot(raj2, aes(x = ID, y = scaled, fill =person)) +
    geom_bar(stat="identity") +
    facet_grid(act~.) + 
    ylab("Scaled") + xlab("Turn of Talk") +
    guides(fill = guide_legend(nrow = 5, byrow = TRUE)) +
    theme(legend.position="bottom") +
    ggtitle("Scaled and Centered")


ggplot(raj2, aes(x = ID, y = scaled2, fill =person)) +
    geom_bar(stat="identity") +
    facet_grid(act~.) + 
    ylab("Scaled") + xlab("Turn of Talk") +
    guides(fill = guide_legend(nrow = 5, byrow = TRUE)) +
    theme(legend.position="bottom") +
    ggtitle("Mean Difference")
  
    
raj$wc &lt;- wc(raj$dialogue)
raj$cum.wc &lt;- unlist(with(raj, tapply(wc, act, cumsum)))
raj$turn &lt;- unlist(with(raj, tapply(act, act, seq_along)))
ggplot(raj, aes(y=cum.wc, x=turn)) + 
    geom_step(direction = "hv") + 
    facet_wrap(~act)
        
## CHARACTER COUNTS
character_count(DATA$state)
character_count(DATA$state, byrow=FALSE)
sum(character_count(DATA$state))

## CHARACTER TABLE
x &lt;- character_table(DATA$state, DATA$person)
plot(x)
plot(x, label = TRUE)
plot(x, label = TRUE, text.color = "red")
plot(x, label = TRUE, lab.digits = 1, zero.replace = "PP7")

scores(x)
counts(x)
proportions(x)

plot(scores(x))
plot(counts(x))
plot(proportions(x))

## combine columns
colcomb2class(x, list(vowels = c("a", "e", "i", "o", "u")))

## char_table(DATA$state, DATA$person)
## char_table(DATA$state, DATA$person, percent = TRUE)
## character_table(DATA$state, list(DATA$sex, DATA$adult))

library(ggplot2);library(reshape2)
dat &lt;- character_table(DATA$state, list(DATA$sex, DATA$adult))
dat2 &lt;- colsplit2df(melt(counts(dat)), keep.orig = TRUE)
head(dat2, 15)

ggplot(data = dat2, aes(y = variable, x = value, colour=sex)) +
    facet_grid(adult~.) +
    geom_line(size=1, aes(group =variable), colour = "black") +
    geom_point()

ggplot(data = dat2, aes(x = variable, y = value)) +
    geom_bar(aes(fill = variable), stat = "identity") +
    facet_grid(sex ~ adult, margins = TRUE) +
    theme(legend.position="none")

## End(Not run)
</code></pre>

<hr>
<h2 id='word_diff_list'>Differences In Word Use Between Groups</h2><span id='topic+word_diff_list'></span>

<h3>Description</h3>

<p>Look at the differences in word uses between grouping variable(s).  Look at 
all possible &quot;a&quot; vs. &quot;b&quot; combinations or &quot;a&quot; vs. all others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_diff_list(
  text.var,
  grouping.var,
  vs.all = FALSE,
  vs.all.cut = 1,
  stopwords = NULL,
  alphabetical = FALSE,
  digits = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_diff_list_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="word_diff_list_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="word_diff_list_+3A_vs.all">vs.all</code></td>
<td>
<p>logical. If <code>TRUE</code> looks at each grouping variable against 
all others (&quot;a&quot; vs. all comparison).  If <code>FALSE</code> looks at each &quot;a&quot; vs. 
&quot;b&quot;, comparison (e.g., for groups &quot;a&quot;, &quot;b&quot;, and &quot;c&quot;; &quot;a&quot; vs. &quot;b&quot;, &quot;a&quot; vs. &quot;c&quot; 
and &quot;b&quot; vs. &quot;c&quot; will be considered).</p>
</td></tr>
<tr><td><code id="word_diff_list_+3A_vs.all.cut">vs.all.cut</code></td>
<td>
<p>Controls the number of other groups that may share a word 
(default is 1).</p>
</td></tr>
<tr><td><code id="word_diff_list_+3A_stopwords">stopwords</code></td>
<td>
<p>A vector of stop words to remove.</p>
</td></tr>
<tr><td><code id="word_diff_list_+3A_alphabetical">alphabetical</code></td>
<td>
<p>logical. If <code>TRUE</code> orders the word lists 
alphabetized by word.  If <code>FALSE</code> order first by frequency and then by 
word.</p>
</td></tr>
<tr><td><code id="word_diff_list_+3A_digits">digits</code></td>
<td>
<p>the number of digits to be displayed in the proportion column 
(default is 3).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list of word data frames comparing grouping variables word use 
against one another. Each dataframe contains three columns:
</p>
<table>
<tr><td><code>word</code></td>
<td>
<p>The words unique to that group</p>
</td></tr> 
<tr><td><code>freq</code></td>
<td>
<p>The number of times that group used that word</p>
</td></tr>
<tr><td><code>prop</code></td>
<td>
<p>The proportion of that group's overall word use dedicated to that 
particular word</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
out1 &lt;- with(DATA, word_diff_list(text.var = state, 
    grouping.var = list(sex, adult)))
lapply(unlist(out1, recursive = FALSE), head, n=3)

out2 &lt;- with(DATA, word_diff_list(state, person))
lapply(unlist(out2, recursive = FALSE), head, n=3)

out3 &lt;- with(DATA, word_diff_list(state, grouping.var = list(sex, adult), 
    vs.all=TRUE, vs.all.cut=2))


out4 &lt;- with(mraja1, word_diff_list(text.var = dialogue, 
    grouping.var = list(mraja1$sex, mraja1$fam.aff)))


out5 &lt;- word_diff_list(mraja1$dialogue, mraja1$person)

out6 &lt;- word_diff_list(mraja1$dialogue, mraja1$fam.aff, stopwords = Top25Words)

out7 &lt;- word_diff_list(mraja1$dialogue, mraja1$fam.aff, vs.all=TRUE, vs.all.cut=2)
lapply(out7, head, n=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='word_length'>Count of Word Lengths Type</h2><span id='topic+word_length'></span>

<h3>Description</h3>

<p>Transcript apply word length counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_length(
  text.var,
  grouping.var = NULL,
  percent = TRUE,
  zero.replace = 0,
  digits = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_length_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="word_length_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="word_length_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="word_length_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.</p>
</td></tr>
<tr><td><code id="word_length_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="word_length_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+bag_o_words">bag_o_words</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of:
</p>
<table>
<tr><td><code>count</code></td>
<td>
<p>Dataframe of word length counts by grouping variable(s).</p>
</td></tr>
<tr><td><code>prop</code></td>
<td>
<p>Dataframe of the proportions of word length counts by 
grouping variable.</p>
</td></tr> 
<tr><td><code>rnp</code></td>
<td>
<p>Dataframe of the frequency and proportions of word length counts by 
grouping variable.</p>
</td></tr> 
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr>
<tr><td><code>zero.replace</code></td>
<td>
<p>The value of zero.replace used for plotting purposes.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(x &lt;- with(DATA, word_length(state, person)))
plot(x)
scores(x)
proportions(x)
counts(x)
plot(scores(x))
plot(proportions(x))
plot(counts(x))

(x2 &lt;- word_length(DATA[["state"]]))
(x2 &lt;- word_length(DATA[["state"]], apostrophe.remove=TRUE))

## Example Visualizations with Presidential Debate Data
library(tidyr)
(x_long &lt;- proportions(x) %&gt;% 
    gather("Letter_Length", "Proportion", -c(1:2)))
ggplot(x_long, aes(x = Letter_Length, y = Proportion, color=person, group=person)) +
    geom_line(size=.8)


(x3 &lt;- with(pres_debates2012, word_length(dialogue, person)))
(x_long2 &lt;- proportions(x3) %&gt;% 
    gather("Letter_Length", "Proportion", -c(1:2)))
ggplot(x_long, aes(x = Letter_Length, weight = Proportion, fill=person, group=person)) +
    geom_bar()

ggplot(x_long, aes(x = Letter_Length, weight = Proportion, fill=person)) +
    geom_bar() + 
    facet_wrap(~person, ncol=1)
        
ggplot(x_long, aes(x = Letter_Length, weight = Proportion, fill=person)) +
    geom_bar() + 
    coord_flip() + 
    facet_wrap(~person, ncol=1)

ggplot(x_long, aes(x = person, weight = Proportion)) +
    geom_bar(fill="grey40") + 
    coord_flip() + 
    facet_grid(Letter_Length~.)

## End(Not run)
</code></pre>

<hr>
<h2 id='word_list'>Raw Word Lists/Frequency Counts</h2><span id='topic+word_list'></span>

<h3>Description</h3>

<p>Transcript Apply Raw Word Lists and Frequency Counts by grouping variable(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_list(
  text.var,
  grouping.var = NULL,
  stopwords = NULL,
  alphabetical = FALSE,
  cut.n = 20,
  cap = TRUE,
  cap.list = NULL,
  cap.I = TRUE,
  rm.bracket = TRUE,
  char.keep = NULL,
  apostrophe.remove = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_list_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="word_list_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="word_list_+3A_stopwords">stopwords</code></td>
<td>
<p>A vector of stop words to remove.</p>
</td></tr>
<tr><td><code id="word_list_+3A_alphabetical">alphabetical</code></td>
<td>
<p>If <code>TRUE</code> the output of frequency lists is ordered 
alphabetically.  If <code>FALSE</code> the list is ordered by frequency rank.</p>
</td></tr>
<tr><td><code id="word_list_+3A_cut.n">cut.n</code></td>
<td>
<p>Cut off point for reduced frequency stop word list (rfswl).</p>
</td></tr>
<tr><td><code id="word_list_+3A_cap">cap</code></td>
<td>
<p>logical. If <code>TRUE</code> capitalizes words from the cap.list.</p>
</td></tr>
<tr><td><code id="word_list_+3A_cap.list">cap.list</code></td>
<td>
<p>Vector of words to capitalize.</p>
</td></tr>
<tr><td><code id="word_list_+3A_cap.i">cap.I</code></td>
<td>
<p>logical. If <code>TRUE</code> capitalizes words containing the 
personal pronoun I.</p>
</td></tr>
<tr><td><code id="word_list_+3A_rm.bracket">rm.bracket</code></td>
<td>
<p>logical If <code>TRUE</code> all brackets and bracketed text are 
removed from analysis.</p>
</td></tr>
<tr><td><code id="word_list_+3A_char.keep">char.keep</code></td>
<td>
<p>A character vector of symbols (i.e., punctuation) that 
<code>word_list</code> should keep.  The default is to remove every symbol except 
apostrophes.</p>
</td></tr>
<tr><td><code id="word_list_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophes from 
the output.</p>
</td></tr>
<tr><td><code id="word_list_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+strip">strip</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"word_list"</code> is a list of lists of vectors 
or dataframes containing the following components: 
</p>
<table>
<tr><td><code>cwl</code></td>
<td>
<p>complete word list; raw words</p>
</td></tr>
<tr><td><code>swl</code></td>
<td>
<p>stop word list; same as rwl with stop words removed</p>
</td></tr>
<tr><td><code>fwl</code></td>
<td>
<p>frequency word list; a data frame of words and corresponding 
frequency counts</p>
</td></tr>
<tr><td><code>fswl</code></td>
<td>
<p>frequency stopword word list; same as fwl but with stop words 
removed</p>
</td></tr>
<tr><td><code>rfswl</code></td>
<td>
<p>reduced frequency stopword word list; same as fswl but truncated 
to n rows</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
word_list(raj.act.1$dialogue)

out1 &lt;- with(raj, word_list(text.var = dialogue, 
    grouping.var = list(person, act)))
names(out1)
lapply(out1$cwl, "[", 1:5)

with(DATA, word_list(state, person))
with(DATA, word_list(state, person, stopwords = Top25Words))
with(DATA, word_list(state, person, cap = FALSE, cap.list=c("do", "we")))

## End(Not run)
</code></pre>

<hr>
<h2 id='word_network_plot'>Word Network Plot</h2><span id='topic+word_network_plot'></span>

<h3>Description</h3>

<p>A network plot of words.  Shows the interconnected and supporting use of 
words between textual units containing key terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_network_plot(
  text.var,
  grouping.var = 1:length(text.var),
  target.words = NULL,
  stopwords = qdapDictionaries::Top100Words,
  label.cex = 0.8,
  label.size = 0.5,
  edge.curved = TRUE,
  vertex.shape = "circle",
  edge.color = "gray70",
  label.colors = "black",
  layout = NULL,
  title.name = NULL,
  title.padj = -4.5,
  title.location = 3,
  title.font = NULL,
  title.cex = 0.8,
  log.labels = FALSE,
  title.color = "black",
  legend = NULL,
  legend.cex = 0.8,
  legend.location = c(-1.54, 1.41),
  plot = TRUE,
  char2space = "~~",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_network_plot_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default uses the sequence along
the length of text variable (this may be the connection of sentences or turn 
of talk as the textual unit).  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_target.words">target.words</code></td>
<td>
<p>A named list of vectors of words whose length corresponds 
to <code>label.colors</code> (+1 length in cloud colors for non-matched terms).</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_stopwords">stopwords</code></td>
<td>
<p>Words to exclude from the analysis (default is Top100Words).</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_label.cex">label.cex</code></td>
<td>
<p>The magnification to be used for network plot labels 
relative to the current setting of cex.  Default is .8.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_label.size">label.size</code></td>
<td>
<p>An optional sizing constant to add to labels if log.labels 
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_edge.curved">edge.curved</code></td>
<td>
<p>logical.  If <code>TRUE</code> edges will be curved rather than 
straight paths.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_vertex.shape">vertex.shape</code></td>
<td>
<p>The shape of the vertices (see 
<code><a href="igraph.html#topic+igraph.vertex.shapes">igraph.vertex.shapes</a></code> for more).</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_edge.color">edge.color</code></td>
<td>
<p>A character vector of length one corresponding to the 
color of the plot edges.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_label.colors">label.colors</code></td>
<td>
<p>A character vector of length one corresponding to the 
color of the labels.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_layout">layout</code></td>
<td>
<p>Layout types supported by igraph.  See 
<code><a href="igraph.html#topic+layout">layout</a></code>.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_title.name">title.name</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_title.padj">title.padj</code></td>
<td>
<p>Adjustment for the network plot title. For strings 
parallel to the axes, padj = 0 means right or top alignment, and padj = 1 
means left or bottom alignment.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_title.location">title.location</code></td>
<td>
<p>On which side of the network plot (1=bottom, 2=left, 
3=top, 4=right).</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_title.font">title.font</code></td>
<td>
<p>The font family of the cloud title.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_title.cex">title.cex</code></td>
<td>
<p>Character expansion factor for the title. <code>NULL</code> and 
<code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_log.labels">log.labels</code></td>
<td>
<p>logical.  If <code>TRUE</code> uses a proportional log label for 
more readable labels.  The formula is: <code>log(SUMS)/max(log(SUMS)))</code>. 
<code>label.size</code> adds more control over the label sizes.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_title.color">title.color</code></td>
<td>
<p>A character vector of length one corresponding to the 
color of the title.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_legend">legend</code></td>
<td>
<p>A character vector of names corresponding to the number of 
vectors in <code>match.string</code>.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_legend.cex">legend.cex</code></td>
<td>
<p>Character expansion factor for the  network plot legend. 
<code>NULL</code> and <code>NA</code> are equivalent to 1.0.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_legend.location">legend.location</code></td>
<td>
<p>The x and y co-ordinates to be used to position the 
network plot legend.  The location may also be specified by setting x to a 
single keyword from the list <code>"bottomright"</code>, <code>"bottom"</code>, 
<code>"bottomleft"</code>, <code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>, 
<code>"topright"</code>, <code>"right"</code> and <code>"center"</code>. This places the legend 
on the inside of the plot frame at the given location.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>TRUE</code> plots a network plot of the words.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_char2space">char2space</code></td>
<td>
<p>A vector of characters to be turned into spaces.  If 
<code>char.keep</code> is <code>NULL</code>, <code>char2space</code> will activate this 
argument.</p>
</td></tr>
<tr><td><code id="word_network_plot_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+strip">strip</a></code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Words can be kept as one by inserting a double tilde (<code>"~~"</code>), or 
other character strings passed to char2space, as a single word/entry. This is 
useful for keeping proper names as a single unit.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+word_network_plot">word_network_plot</a></code>,
<code><a href="igraph.html#topic+graph.adjacency">graph.adjacency</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
word_network_plot(text.var=DATA$state)
word_network_plot(text.var=DATA$state, stopwords=NULL)
word_network_plot(text.var=DATA$state, DATA$person)
word_network_plot(text.var=DATA$state, DATA$person, stopwords=NULL)
word_network_plot(text.var=DATA$state, grouping.var=list(DATA$sex,
    DATA$adult))
word_network_plot(text.var=DATA$state, grouping.var=DATA$person,
    title.name = "TITLE", log.labels=TRUE)
word_network_plot(text.var=raj.act.1$dialogue, grouping.var=raj.act.1$person,
  stopwords = Top200Words)

#insert double tilde ("~~") to keep dual words (e.g., first last name)
alts &lt;- c(" fun", "I ")
state2 &lt;- mgsub(alts, gsub("\\s", "~~", alts), DATA$state)
word_network_plot(text.var=state2, grouping.var=DATA$person)

## Invisibly returns the igraph model
x &lt;- word_network_plot(text.var=DATA$state, DATA$person)
str(x)
library(igraph)
plot(x, vertex.size=0, vertex.color="white", edge.curved = TRUE)

x2 &lt;- word_network_plot(text.var=DATA$state, grouping.var=DATA$person,
    title.name = "TITLE", log.labels = TRUE, label.size = 1.2)
l &lt;- layout.drl(x2, options=list(simmer.attraction=0))
plot(x2, vertex.size=0, layout = l)

## End(Not run)
</code></pre>

<hr>
<h2 id='word_position'>Word Position</h2><span id='topic+word_position'></span>

<h3>Description</h3>

<p>Find counts of the positioning of words within a sentence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_position(
  text.var,
  match.terms,
  digits = 2,
  percent = TRUE,
  zero.replace = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_position_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="word_position_+3A_match.terms">match.terms</code></td>
<td>
<p>A character vector of quoted terms to find the positions of.</p>
</td></tr>
<tr><td><code id="word_position_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="word_position_+3A_percent">percent</code></td>
<td>
<p>logical.  If <code>TRUE</code> output given as percent.  If 
<code>FALSE</code> the output is proportion.</p>
</td></tr>
<tr><td><code id="word_position_+3A_zero.replace">zero.replace</code></td>
<td>
<p>Value to replace 0 values with.</p>
</td></tr>
<tr><td><code id="word_position_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list, of class &quot;word_position&quot;, of data frames and 
information regarding word positions:
</p>
<table>
<tr><td><code>raw</code></td>
<td>
<p>raw word position counts in long format (may be more useful for plotting)</p>
</td></tr> 
<tr><td><code>count</code></td>
<td>
<p>integer word position counts</p>
</td></tr> 
<tr><td><code>prop</code></td>
<td>
<p>proportional word position counts; proportional to 
each total word uses</p>
</td></tr> 
<tr><td><code>rnp</code></td>
<td>
<p>a character combination data frame of count and proportional</p>
</td></tr>     
<tr><td><code>zero_replace</code></td>
<td>
<p>value to replace zeros with; mostly internal use</p>
</td></tr>   
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr>
<tr><td><code>digits</code></td>
<td>
<p>integer value of number of digits to display; mostly internal 
use</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Default printing is a heatmap plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
position &lt;- with(DATA, word_position(sent_detect(state), Top25Words))
position
lview(position)
plot(position)
scores(position)
preprocessed(position)
counts(position)
proportions(position)
plot(proportions(position))

stopwords &lt;- unique(c(contractions[[1]], Top200Words))
topwords &lt;- freq_terms(pres_debates2012[["dialogue"]], top = 40, 
    at.least = 4, stopwords = stopwords)[[1]]
word_position(pres_debates2012[["dialogue"]], topwords)
plot(word_position(pres_debates2012[["dialogue"]], topwords), FALSE)
plot(word_position(pres_debates2012[["dialogue"]], topwords), TRUE, scale=FALSE)

wordlist &lt;- c("tax", "health", "rich", "america", "truth", "money", "cost", 
    "governnor", "president", "we", "job", "i", "you", "because", 
    "our", "years")

word_position(pres_debates2012[["dialogue"]], wordlist)

## BY VARIABLES
library(gridExtra)
pres_deb_by_time &lt;- with(pres_debates2012, split(dialogue, time))
out1 &lt;-lapply(pres_deb_by_time, word_position, wordlist)
do.call("grid.arrange", c(lapply(out1, plot), ncol=1))

pres_deb_by_person &lt;- with(pres_debates2012, split(dialogue, person))
out2 &lt;-lapply(pres_deb_by_person, word_position, wordlist)
plots &lt;- lapply(names(out2), function(x) plot(out2[[x]], scale=FALSE) + 
    ggtitle(x))
do.call("grid.arrange", c(plots, ncol=2))

## As a histogram
## theme taken from: http://jonlefcheck.net/2013/03/11/black-theme-for-ggplot2-2/
theme_black &lt;- function(base_size=12,base_family="") {
  theme_grey(base_size=base_size,base_family=base_family) %+replace%
    theme(
      # Specify axis options
      axis.line=element_blank(), 
      axis.text.x=element_text(size=base_size*0.8,color="grey55",
                               lineheight=0.9,vjust=1), 
      axis.text.y=element_text(size=base_size*0.8,color="grey55",
                               lineheight=0.9,hjust=1), 
      axis.ticks=element_line(color="grey55",size = 0.2), 
      axis.title.x=element_text(size=base_size,color="grey55",vjust=1), 
      axis.title.y=element_text(size=base_size,color="grey55",angle=90,
                                vjust=0.5), 
      axis.ticks.length=unit(0.3,"lines"), 
      axis.ticks.margin=unit(0.5,"lines"),
      # Specify legend options
      legend.background=element_rect(color=NA,fill="black"), 
      legend.key=element_rect(color="grey55", fill="black"), 
      legend.key.size=unit(1.2,"lines"), 
      legend.key.height=NULL, 
      legend.key.width=NULL,     
      legend.text=element_text(size=base_size*0.8,color="grey55"), 
      legend.title=element_text(size=base_size*0.8,face="bold",hjust=0,
                                color="grey55"), 
      legend.position="right", 
      legend.text.align=NULL, 
      legend.title.align=NULL, 
      legend.direction="vertical", 
      legend.box=NULL,
      # Specify panel options
      panel.background=element_rect(fill="black",color = NA), 
      panel.border=element_rect(fill=NA,color="grey55"), 
      panel.grid.major=element_blank(), 
      panel.grid.minor=element_blank(), 
      panel.spacing=unit(0.25,"lines"),  
      # Specify facetting options
      strip.background=element_rect(fill="grey30",color="grey10"), 
      strip.text.x=element_text(size=base_size*0.8,color="grey55"), 
      strip.text.y=element_text(size=base_size*0.8,color="grey55",
                                angle=-90), 
      # Specify plot options
      plot.background=element_rect(color="black",fill="black"), 
      plot.title=element_text(size=base_size*1.2,color="grey55"), 
      plot.margin=unit(c(1,1,0.5,0.5),"lines")
    )
}

out3 &lt;- list_df2df(lapply(out2[1:2], preprocessed), "Person")
out3 %&gt;% ggplot(aes(x=position)) + 
    geom_histogram(binwidth = 1, fill="white") +
    facet_grid(Person~word) +
    theme_black() + ylab("Count") + xlab("Position")

## MOVE TO THE MICRO THROUGH QUALITATIVE ANALYSIS
locs &lt;- unlist(setNames(lapply(wordlist, function(x){
     sapply(c("ROMNEY", "OBAMA"), function(y){
         which(pres_debates2012[["person"]] ==y &amp; grepl(x, pres_debates2012[["dialogue"]]))
     })
}), wordlist), recursive=FALSE)

fdl &lt;- qdap:::folder(pres_context)
Map(function(x, y){
    if (identical(integer(0), x)) return(NULL)
    z &lt;- with(pres_debates2012, trans_context(dialogue, person, inds=x, n.before=1))
    z[["text"]] &lt;- gsub(beg2char(y, "."), 
        paste0("[[", beg2char(y, "."), "]]"), z[["text"]])
    print(z, file=file.path(fdl, sprintf("%s.doc", y)))
}, locs, names(locs))

## End(Not run)
</code></pre>

<hr>
<h2 id='word_proximity'>Proximity Matrix Between Words</h2><span id='topic+word_proximity'></span><span id='topic+weight.word_proximity'></span>

<h3>Description</h3>

<p><code>word_proximity</code> - Generate proximity measures to ascertain a mean 
distance measure between word uses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_proximity(
  text.var,
  terms,
  grouping.var = NULL,
  parallel = TRUE,
  cores = parallel::detectCores()/2
)

## S3 method for class 'word_proximity'
weight(x, type = "scale", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_proximity_+3A_text.var">text.var</code></td>
<td>
<p>The text variable.</p>
</td></tr>
<tr><td><code id="word_proximity_+3A_terms">terms</code></td>
<td>
<p>A vector of quoted terms.</p>
</td></tr>
<tr><td><code id="word_proximity_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="word_proximity_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create.</p>
</td></tr>
<tr><td><code id="word_proximity_+3A_cores">cores</code></td>
<td>
<p>The number of cores to use if <code>parallel = TRUE</code>.  Default 
is half the number of available cores.</p>
</td></tr>
<tr><td><code id="word_proximity_+3A_x">x</code></td>
<td>
<p>An object to be weighted.</p>
</td></tr>
<tr><td><code id="word_proximity_+3A_type">type</code></td>
<td>
<p>A weighting type of: c(<code>"scale_log"</code>, <code>"scale"</code>, 
<code>"rev_scale"</code>, <code>"rev_scale_log"</code>, <code>"log"</code>, <code>"sqrt"</code>, 
<code>"scale_sqrt"</code>, <code>"rev_sqrt"</code>, <code>"rev_scale_sqrt"</code>).  The 
weight type section name (i.e. <code>A_B_C</code> where <code>A</code>, <code>B</code>, and
<code>C</code> are sections) determines what action will occur.  <code>log</code> will 
use <code><a href="base.html#topic+log">log</a></code>, <code>sqrt</code> will use <code><a href="base.html#topic+sqrt">sqrt</a></code>,
<code>scale</code> will standardize the values.  <code>rev</code> will multiply by -1 to 
give the inverse sign.  This enables a comparison similar to correlations 
rather than distance.</p>
</td></tr>
<tr><td><code id="word_proximity_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that row names are the first word and column names are the 
second comparison word. The values for Word A compared to Word B will not 
be the same as Word B compared to Word A. This is because, unlike a true 
distance measure, <code>word_proximity</code>'s matrix is asymmetrical. 
<code>word_proximity</code> computes the distance by taking each sentence position 
for Word A and comparing it to the nearest sentence location for Word B.
</p>


<h3>Value</h3>

<p>Returns a list of matrices of proximity measures in the unit of average 
sentences between words (defaults to scaled).
</p>


<h3>Note</h3>

<p>The match.terms is character sensitive.  Spacing is an important way 
to grab specific words and requires careful thought.  Using &quot;read&quot; will find 
the words &quot;bread&quot;, &quot;read&quot; &quot;reading&quot;, and &quot;ready&quot;.  If you want to search 
for just the word &quot;read&quot; you'd supply a vector of c(&quot; read &quot;, &quot; reads&quot;, 
&quot; reading&quot;, &quot; reader&quot;).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+word_proximity">word_proximity</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
wrds &lt;- word_list(pres_debates2012$dialogue, 
    stopwords = c("it's", "that's", Top200Words))
wrds2 &lt;- tolower(sort(wrds$rfswl[[1]][, 1]))

(x &lt;- with(pres_debates2012, word_proximity(dialogue, wrds2)))
plot(x)
plot(weight(x))
plot(weight(x, "rev_scale_log"))

(x2 &lt;- with(pres_debates2012, word_proximity(dialogue, wrds2, person)))

## The spaces around `terms` are important
(x3 &lt;- with(DATA, word_proximity(state, spaste(qcv(the, i)))))
(x4 &lt;- with(DATA, word_proximity(state, qcv(the, i))))

## End(Not run)
</code></pre>

<hr>
<h2 id='word_stats'>Descriptive Word Statistics</h2><span id='topic+word_stats'></span>

<h3>Description</h3>

<p>Transcript apply descriptive word statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_stats(
  text.var,
  grouping.var = NULL,
  tot = NULL,
  parallel = FALSE,
  rm.incomplete = FALSE,
  digit.remove = FALSE,
  apostrophe.remove = FALSE,
  digits = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_stats_+3A_text.var">text.var</code></td>
<td>
<p>The text variable or a  <code>"word_stats"</code> object (i.e., the 
output of a <code>word_stats</code> function).</p>
</td></tr>
<tr><td><code id="word_stats_+3A_grouping.var">grouping.var</code></td>
<td>
<p>The grouping variables.  Default <code>NULL</code> generates 
one word list for all text.  Also takes a single grouping variable or a list 
of 1 or more grouping variables.</p>
</td></tr>
<tr><td><code id="word_stats_+3A_tot">tot</code></td>
<td>
<p>Optional turns of talk variable that yields turn of talk measures.</p>
</td></tr>
<tr><td><code id="word_stats_+3A_parallel">parallel</code></td>
<td>
<p>logical.  If <code>TRUE</code> attempts to run the function on 
multiple cores.  Note that this may not mean a speed boost if you have one 
core or if the data set is smaller as the cluster takes time to create 
(parallel is slower until approximately 10,000 rows).  To reduce run time 
pass a <code>"word_stats"</code> object to the <code><a href="#topic+word_stats">word_stats</a></code> 
function.</p>
</td></tr>
<tr><td><code id="word_stats_+3A_rm.incomplete">rm.incomplete</code></td>
<td>
<p>logical.  If <code>TRUE</code> incomplete statements are 
removed from calculations in the output.</p>
</td></tr>
<tr><td><code id="word_stats_+3A_digit.remove">digit.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes digits from calculating 
the output.</p>
</td></tr>
<tr><td><code id="word_stats_+3A_apostrophe.remove">apostrophe.remove</code></td>
<td>
<p>logical.  If <code>TRUE</code> removes apostrophes from 
calculating the output.</p>
</td></tr>
<tr><td><code id="word_stats_+3A_digits">digits</code></td>
<td>
<p>Integer; number of decimal places to round when printing.</p>
</td></tr>
<tr><td><code id="word_stats_+3A_...">...</code></td>
<td>
<p>Any other arguments passed to <code><a href="#topic+end_inc">end_inc</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that a sentence is classified with only one endmark.  An 
imperative sentence is classified only as imperative (not as a state, quest, 
or exclm as well).  If a sentence is both imperative and incomplete the 
sentence will be counted as incomplete rather than imperative.
labeled as both imperative
</p>


<h3>Value</h3>

<p>Returns a list of three descriptive word statistics:
</p>
<table>
<tr><td><code>ts</code></td>
<td>
<p>A data frame of descriptive word statistics by row</p>
</td></tr> 
<tr><td><code>gts</code></td>
<td>
<p>A data frame of word/sentence statistics per grouping variable:
</p>

<ul>
<li><p>n.tot - number of turns of talk
</p>
</li>
<li><p>n.sent - number of sentences
</p>
</li>
<li><p>n.words - number of words
</p>
</li>
<li><p>n.char - number of characters
</p>
</li>
<li><p>n.syl - number of syllables
</p>
</li>
<li><p>n.poly - number of polysyllables
</p>
</li>
<li><p>sptot - syllables per turn of talk
</p>
</li>
<li><p>wptot - words per turn of talk
</p>
</li>
<li><p>wps - words per sentence
</p>
</li>
<li><p>cps - characters per sentence
</p>
</li>
<li><p>sps - syllables per sentence
</p>
</li>
<li><p>psps - poly-syllables per sentence
</p>
</li>
<li><p>cpw - characters per word
</p>
</li>
<li><p>spw - syllables per word
</p>
</li>
<li><p>n.state - number of statements
</p>
</li>
<li><p>n.quest - number of questions
</p>
</li>
<li><p>n.exclm - number of exclamations
</p>
</li>
<li><p>n.incom - number of incomplete statements
</p>
</li>
<li><p>p.state - proportion of statements
</p>
</li>
<li><p>p.quest - proportion of questions
</p>
</li>
<li><p>p.exclm - proportion of exclamations
</p>
</li>
<li><p>p.incom - proportion of incomplete statements
</p>
</li>
<li><p>n.hapax - number of hapax legomenon
</p>
</li>
<li><p>n.dis - number of dis legomenon
</p>
</li>
<li><p>grow.rate - proportion of hapax legomenon to words
</p>
</li>
<li><p>prop.dis - proportion of dis legomenon to words
</p>
</li></ul>

</td></tr> 
<tr><td><code>mpun</code></td>
<td>
<p>An account of sentences with an improper/missing end mark</p>
</td></tr> 
<tr><td><code>word.elem</code></td>
<td>
<p>A data frame with word element columns from gts</p>
</td></tr>
<tr><td><code>sent.elem</code></td>
<td>
<p>A data frame with sentence element columns from gts</p>
</td></tr> 
<tr><td><code>omit</code></td>
<td>
<p>Counter of omitted sentences for internal use (only included if 
some rows contained missing values)</p>
</td></tr> 
<tr><td><code>percent</code></td>
<td>
<p>The value of percent used for plotting purposes.</p>
</td></tr>
<tr><td><code>zero.replace</code></td>
<td>
<p>The value of zero.replace used for plotting purposes.</p>
</td></tr>
<tr><td><code>digits</code></td>
<td>
<p>integer value od number of digits to display; mostly internal 
use</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>It is assumed the user has run <code>sentSplit</code> on their 
data, otherwise some counts may not be accurate.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+end_inc">end_inc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
word_stats(mraja1spl$dialogue, mraja1spl$person)

(desc_wrds &lt;- with(mraja1spl, word_stats(dialogue, person, tot = tot)))

## Recycle for speed boost
with(mraja1spl, word_stats(desc_wrds, person, tot = tot)) 

scores(desc_wrds)
counts(desc_wrds)
htruncdf(counts(desc_wrds), 15, 6)
plot(scores(desc_wrds))
plot(counts(desc_wrds))

names(desc_wrds)
htruncdf(desc_wrds$ts, 15, 5)
htruncdf(desc_wrds$gts, 15, 6)
desc_wrds$mpun 
desc_wrds$word.elem
desc_wrds$sent.elem 
plot(desc_wrds)
plot(desc_wrds, label=TRUE, lab.digits = 1)

## Correlation Visualization
qheat(cor(scores(desc_wrds)[, -1]), diag.na = TRUE, by.column =NULL,
    low = "yellow", high = "red", grid = FALSE)

## Parallel (possible speed boost)
with(mraja1spl, word_stats(dialogue, list(sex, died, fam.aff))) 
with(mraja1spl, word_stats(dialogue, list(sex, died, fam.aff), 
    parallel = TRUE)) 
    
## Recycle for speed boost
word_stats(desc_wrds, mraja1spl$sex)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
