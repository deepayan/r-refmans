<!DOCTYPE html><html><head><title>Help for package mcmc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mcmc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#foo'><p>Simulated logistic regression data.</p></a></li>
<li><a href='#initseq'><p>Initial Sequence Estimators</p></a></li>
<li><a href='#logit'><p>Simulated logistic regression data.</p></a></li>
<li><a href='#metrop'><p>Metropolis Algorithm</p></a></li>
<li><a href='#morph'><p>Variable Transformation</p></a></li>
<li><a href='#morph.metrop'><p>Morphometric Metropolis Algorithm</p></a></li>
<li><a href='#olbm'><p>Overlapping Batch Means</p></a></li>
<li><a href='#temper'><p>Simulated Tempering and Umbrella Sampling</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.9-8</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-14</td>
</tr>
<tr>
<td>Title:</td>
<td>Markov Chain Monte Carlo</td>
</tr>
<tr>
<td>Author:</td>
<td>Charles J. Geyer &lt;geyer@umn.edu&gt; and Leif T. Johnson
     &lt;ltjohnson@google.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Charles J. Geyer &lt;geyer@umn.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>xtable, Iso</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Description:</td>
<td>Simulates continuous distributions of random vectors using
    Markov chain Monte Carlo (MCMC).  Users specify the distribution by an
    R function that evaluates the log unnormalized density.  Algorithms
    are random walk Metropolis algorithm (function metrop), simulated
    tempering (function temper), and morphometric random walk Metropolis
    (Johnson and Geyer, 2012, &lt;<a href="https://doi.org/10.1214%2F12-AOS1048">doi:10.1214/12-AOS1048</a>&gt;,
    function morph.metrop),
    which achieves geometric ergodicity by change of variable.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.stat.umn.edu/geyer/mcmc/">http://www.stat.umn.edu/geyer/mcmc/</a>,
<a href="https://github.com/cjgeyer/mcmc">https://github.com/cjgeyer/mcmc</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-15 05:41:20 UTC; geyer</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-16 22:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='foo'>Simulated logistic regression data.</h2><span id='topic+foo'></span>

<h3>Description</h3>

<p>Like it says
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(foo)</code></pre>


<h3>Format</h3>

<p>A data frame with variables
</p>

<dl>
<dt>x1</dt><dd><p>quantitative predictor.</p>
</dd>
<dt>x2</dt><dd><p>quantitative predictor.</p>
</dd>
<dt>x3</dt><dd><p>quantitative predictor.</p>
</dd>
<dt>y</dt><dd><p>Bernoulli response.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>library(mcmc)
data(foo)
out &lt;- glm(y ~ x1 + x2 + x3, family = binomial, data = foo)
summary(out)
</code></pre>

<hr>
<h2 id='initseq'>Initial Sequence Estimators</h2><span id='topic+initseq'></span>

<h3>Description</h3>

<p>Variance of sample mean of functional of reversible Markov chain
using methods of Geyer (1992).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initseq(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initseq_+3A_x">x</code></td>
<td>
<p>a numeric vector that is a scalar-valued functional of a reversible
Markov chain.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let
</p>
<p style="text-align: center;"><code class="reqn">\gamma_k = \textrm{cov}(X_i, X_{i + k})</code>
</p>

<p>considered as a function of the lag <code class="reqn">k</code> be
the autocovariance function of the input time series.
Define
</p>
<p style="text-align: center;"><code class="reqn">\Gamma_k = \gamma_{2 k} + \gamma_{2 k + 1}</code>
</p>

<p>the sum of consecutive pairs of autocovariances.  Then Theorem 3.1 in
Geyer (1992) says that <code class="reqn">\Gamma_k</code> considered as a function of
<code class="reqn">k</code> is strictly positive, strictly decreasing, and strictly convex,
assuming the input time series is a scalar-valued functional of a reversible Markov
chain.  All of the MCMC done by this package is reversible.
This <span class="rlang"><b>R</b></span> function estimates the &ldquo;big gamma&rdquo; function,
<code class="reqn">\Gamma_k</code> considered as a function of
<code class="reqn">k</code>, subject to three different constraints, (1) nonnegative,
(2) nonnegative and nonincreasing, and (3) nonnegative, nonincreasing,
and convex.  It also estimates the variance in the Markov chain central
limit theorem (CLT)
</p>
<p style="text-align: center;"><code class="reqn">\gamma_0 + 2 \sum_{k = 1}^\infty \gamma_k = - \gamma_0 + 2 \sum_{k = 0}^\infty \Gamma_k</code>
</p>

<p><strong>Note:</strong> The batch means provided by <code><a href="#topic+metrop">metrop</a></code> are also
scalar functionals of a reversible Markov chain.  Thus these initial sequence
estimators applied to the batch means give valid standard errors for the
mean of the match means even when the batch length is too short to provide
a valid estimate of asymptotic variance.  One does, of course, have to
multiply the asymptotic variance of the batch means by the batch length
to get the asymptotic variance for the unbatched chain.
</p>


<h3>Value</h3>

<p>a list containing the following components:
</p>
<table>
<tr><td><code>gamma0</code></td>
<td>
<p>the scalar <code class="reqn">\gamma_0</code>, the marginal variance
of <code>x</code>.</p>
</td></tr>
<tr><td><code>Gamma.pos</code></td>
<td>
<p>the vector <code class="reqn">\Gamma</code>, estimated so as to be nonnegative,
where, as always, <span class="rlang"><b>R</b></span> uses one-origin indexing so <code>Gamma.pos[1]</code> is 
<code class="reqn">\Gamma_0</code>.</p>
</td></tr>
<tr><td><code>Gamma.dec</code></td>
<td>
<p>the vector <code class="reqn">\Gamma</code>, estimated so as to be nonnegative
and nonincreasing, where, as always,
<span class="rlang"><b>R</b></span> uses one-origin indexing so <code>Gamma.dec[1]</code> is 
<code class="reqn">\Gamma_0</code>.</p>
</td></tr>
<tr><td><code>Gamma.con</code></td>
<td>
<p>the vector <code class="reqn">\Gamma</code>, estimated so as to be nonnegative
and nonincreasing and convex, where, as always,
<span class="rlang"><b>R</b></span> uses one-origin indexing so <code>Gamma.con[1]</code> is 
<code class="reqn">\Gamma_0</code>.</p>
</td></tr>
<tr><td><code>var.pos</code></td>
<td>
<p>the scalar <code>- gamma0 + 2 * sum(Gamma.pos)</code>, which is
the asymptotic variance in the Markov chain CLT.  Divide by <code>length(x)</code>
to get the approximate variance of the sample mean of <code>x</code>.</p>
</td></tr>
<tr><td><code>var.dec</code></td>
<td>
<p>the scalar <code>- gamma0 + 2 * sum(Gamma.dec)</code>, which is
the asymptotic variance in the Markov chain CLT.  Divide by <code>length(x)</code>
to get the approximate variance of the sample mean of <code>x</code>.</p>
</td></tr>
<tr><td><code>var.con</code></td>
<td>
<p>the scalar <code>- gamma0 + 2 * sum(Gamma.con)</code>, which is
the asymptotic variance in the Markov chain CLT.  Divide by <code>length(x)</code>
to get the approximate variance of the sample mean of <code>x</code>.</p>
</td></tr>
</table>


<h3>Bugs</h3>

<p>Not precisely a bug, but <code>var.pos</code>, <code>var.dec</code>, and <code>var.con</code>
can be negative.  This happens only when the chain is way too short to estimate
the variance, and even then rarely.  But it does happen.
</p>


<h3>References</h3>

<p>Geyer, C. J. (1992)
Practical Markov Chain Monte Carlo.
<em>Statistical Science</em> <b>7</b> 473&ndash;483.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+metrop">metrop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 2e4
rho &lt;- 0.99
x &lt;- arima.sim(model = list(ar = rho), n = n)
out &lt;- initseq(x)
## Not run: 
plot(seq(along = out$Gamma.pos) - 1, out$Gamma.pos,
   xlab = "k", ylab = expression(Gamma[k]), type = "l")
lines(seq(along = out$Gamma.dec) - 1, out$Gamma.dec, col = "red")
lines(seq(along = out$Gamma.con) - 1, out$Gamma.con, col = "blue")

## End(Not run)
# asymptotic 95% confidence interval for mean of x
mean(x) + c(-1, 1) * qnorm(0.975) * sqrt(out$var.con / length(x))
# estimated asymptotic variance
out$var.con
# theoretical asymptotic variance
(1 + rho) / (1 - rho) * 1 / (1 - rho^2)
# illustrating use with batch means
bm &lt;- apply(matrix(x, nrow = 5), 2, mean)
initseq(bm)$var.con * 5
</code></pre>

<hr>
<h2 id='logit'>Simulated logistic regression data.</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>Like it says
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(logit)</code></pre>


<h3>Format</h3>

<p>A data frame with variables
</p>

<dl>
<dt>x1</dt><dd><p>quantitative predictor.</p>
</dd>
<dt>x2</dt><dd><p>quantitative predictor.</p>
</dd>
<dt>x3</dt><dd><p>quantitative predictor.</p>
</dd>
<dt>x4</dt><dd><p>quantitative predictor.</p>
</dd>
<dt>y</dt><dd><p>Bernoulli response.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>library(mcmc)
data(logit)
out &lt;- glm(y ~ x1 + x2 + x3 + x4, family = binomial, data = logit)
summary(out)
</code></pre>

<hr>
<h2 id='metrop'>Metropolis Algorithm</h2><span id='topic+metrop'></span><span id='topic+metrop.function'></span><span id='topic+metrop.metropolis'></span>

<h3>Description</h3>

<p>Markov chain Monte Carlo for continuous random vector using a Metropolis
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metrop(obj, initial, nbatch, blen = 1, nspac = 1, scale = 1, outfun,
    debug = FALSE, ...)
## S3 method for class 'function'
metrop(obj, initial, nbatch, blen = 1, nspac = 1,
    scale = 1, outfun, debug = FALSE, ...)
## S3 method for class 'metropolis'
metrop(obj, initial, nbatch, blen = 1, nspac = 1,
    scale = 1, outfun, debug = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metrop_+3A_obj">obj</code></td>
<td>
<p>Either an <span class="rlang"><b>R</b></span> function or an object of class <code>"metropolis"</code>
from a previous invocation of this function.
</p>
<p>If a function, it evaluates the log unnormalized probability
density of the desired equilibrium distribution of the Markov chain.
Its first argument is the state vector of the Markov chain.  Other
arguments arbitrary and taken from the <code>...</code> arguments of this
function.
It should return <code>-Inf</code> for points of the state space having
probability zero under the desired equilibrium distribution.
See also Details and Warning.
</p>
<p>If an object of class <code>"metropolis"</code>, any missing arguments
(including the log unnormalized density function) are taken from
this object.  Also <code>initial</code> is ignored and the initial state
of the Markov chain is the final state from the run recorded in
<code>obj</code>.
</p>
</td></tr>
<tr><td><code id="metrop_+3A_initial">initial</code></td>
<td>
<p>a real vector, the initial state of the Markov chain.
Must be feasible, see Details.  Ignored if <code>obj</code> is of
class <code>"metropolis"</code>.</p>
</td></tr>
<tr><td><code id="metrop_+3A_nbatch">nbatch</code></td>
<td>
<p>the number of batches.</p>
</td></tr>
<tr><td><code id="metrop_+3A_blen">blen</code></td>
<td>
<p>the length of batches.</p>
</td></tr>
<tr><td><code id="metrop_+3A_nspac">nspac</code></td>
<td>
<p>the spacing of iterations that contribute to batches.</p>
</td></tr>
<tr><td><code id="metrop_+3A_scale">scale</code></td>
<td>
<p>controls the proposal step size.  If scalar or
vector, the proposal is <code>x + scale * z</code> where <code>x</code> is
the current state and <code>z</code> is a standard normal random vector.
If matrix, the proposal is <code>x + scale %*% z</code>.</p>
</td></tr>
<tr><td><code id="metrop_+3A_outfun">outfun</code></td>
<td>
<p>controls the output.  If a function, then the batch means
of <code>outfun(state, ...)</code> are returned.  If a numeric
or logical vector, then the batch means of <code>state[outfun]</code>
(if this makes sense).  If missing, the the batch means
of <code>state</code> are returned.</p>
</td></tr>
<tr><td><code id="metrop_+3A_debug">debug</code></td>
<td>
<p>if <code>TRUE</code> extra output useful for testing.</p>
</td></tr>
<tr><td><code id="metrop_+3A_...">...</code></td>
<td>
<p>additional arguments for <code>obj</code> or <code>outfun</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Runs a &ldquo;random-walk&rdquo; Metropolis algorithm, terminology introduced
by Tierney (1994), with multivariate normal proposal
producing a Markov chain with equilibrium distribution having a specified
unnormalized density.  Distribution must be continuous.  Support of the
distribution is the support of the density specified by argument <code>obj</code>.
The initial state must satisfy <code>obj(state, ...) &gt; -Inf</code>.
Description of a complete MCMC analysis (Bayesian logistic regression)
using this function can be found in the vignette
<code>vignette("demo", "mcmc")</code>.
</p>
<p>Suppose the function coded by the log unnormalized function (either
<code>obj</code> or <code>obj$lud</code>) is actually a log unnormalized density,
that is, if <code class="reqn">w</code> denotes that function, then <code class="reqn">e^w</code> integrates
to some value strictly between zero and infinity.  Then the <code>metrop</code>
function always simulates a reversible, Harris ergodic Markov chain having
the equilibrium distribution with this log unnormalized density.
The chain is not guaranteed to be geometrically ergodic.  In fact it cannot
be geometrically ergodic if the tails of the log unnormalized density are
sufficiently heavy.  The <code><a href="#topic+morph.metrop">morph.metrop</a></code> function deals with this
situation.
</p>


<h3>Value</h3>

<p>an object of class <code>"mcmc"</code>, subclass <code>"metropolis"</code>,
which is a list containing at least the following components:
</p>
<table>
<tr><td><code>accept</code></td>
<td>
<p>fraction of Metropolis proposals accepted.</p>
</td></tr>
<tr><td><code>batch</code></td>
<td>
<p><code>nbatch</code> by <code>p</code> matrix, the batch means, where
<code>p</code> is the dimension of the result of <code>outfun</code>
if <code>outfun</code> is a function, otherwise the dimension of
<code>state[outfun]</code> if that makes sense, and the dimension
of <code>state</code> when <code>outfun</code> is missing.</p>
</td></tr>
<tr><td><code>accept.batch</code></td>
<td>
<p>a vector of length <code>nbatch</code>, the batch means
of the acceptances.</p>
</td></tr>
<tr><td><code>initial</code></td>
<td>
<p>value of argument <code>initial</code>.</p>
</td></tr>
<tr><td><code>final</code></td>
<td>
<p>final state of Markov chain.</p>
</td></tr>
<tr><td><code>initial.seed</code></td>
<td>
<p>value of <code>.Random.seed</code> before the run.</p>
</td></tr>
<tr><td><code>final.seed</code></td>
<td>
<p>value of <code>.Random.seed</code> after the run.</p>
</td></tr>
<tr><td><code>time</code></td>
<td>
<p>running time of Markov chain from <code>system.time()</code>.</p>
</td></tr>
<tr><td><code>lud</code></td>
<td>
<p>the function used to calculate log unnormalized density,
either <code>obj</code> or <code>obj$lud</code> from a previous run.</p>
</td></tr>
<tr><td><code>nbatch</code></td>
<td>
<p>the argument <code>nbatch</code> or <code>obj$nbatch</code>.</p>
</td></tr>
<tr><td><code>blen</code></td>
<td>
<p>the argument <code>blen</code> or <code>obj$blen</code>.</p>
</td></tr>
<tr><td><code>nspac</code></td>
<td>
<p>the argument <code>nspac</code> or <code>obj$nspac</code>.</p>
</td></tr>
<tr><td><code>outfun</code></td>
<td>
<p>the argument <code>outfun</code> or <code>obj$outfun</code>.</p>
</td></tr>
</table>
<p>Description of additional output when <code>debug = TRUE</code> can be
found in the vignette <code>debug</code> (<a href="../doc/debug.pdf">../doc/debug.pdf</a>).
</p>


<h3>Warning</h3>

<p>If <code>outfun</code> is missing or not a function, then the log unnormalized
density can be defined without a ... argument and that works fine.
One can define it starting <code>ludfun &lt;- function(state)</code> and that works
or <code>ludfun &lt;- function(state, foo, bar)</code>, where <code>foo</code> and <code>bar</code>
are supplied as additional arguments to <code>metrop</code>.
</p>
<p>If <code>outfun</code> is a function, then both it and the log unnormalized
density function can be defined without ... arguments <em>if they
have exactly the same arguments list</em> and that works fine.  Otherwise it
doesn't work.  Define these functions by
</p>
<pre>
ludfun &lt;- function(state, foo)
outfun &lt;- function(state, bar)
</pre>
<p>and you get an error about unused arguments.  Instead define these functions by
</p>
<pre>
ludfun &lt;- function(state, foo, \ldots)
outfun &lt;- function(state, bar, \ldots)
</pre>
<p>and supply <code>foo</code> and <code>bar</code> as additional arguments to <code>metrop</code>,
and that works fine.
</p>
<p>In short, the log unnormalized density function and <code>outfun</code> need
to have ... in their arguments list to be safe.  Sometimes it works
when ... is left out and sometimes it doesn't.
</p>
<p>Of course, one can avoid this whole issue by always defining the log
unnormalized density function and <code>outfun</code> to have only one argument
<code>state</code> and use global variables (objects in the <span class="rlang"><b>R</b></span> global environment) to
specify any other information these functions need to use.  That too
follows the <span class="rlang"><b>R</b></span> way.  But some people consider that bad programming practice.
</p>
<p>A third option is to define either or both of these functions using a function
factory.  This is demonstrated in the vignette for this package named
<code>demo</code>, which is shown by <code>vignette("demo", "mcmc")</code>.
</p>


<h3>Philosophy of MCMC</h3>

<p>This function follows the philosophy of MCMC explained
the introductory chapter of the
<em>Handbook of Markov Chain Monte Carlo</em> (Geyer, 2011).
</p>
<p>This function automatically does batch means in order to reduce
the size of output and to enable easy calculation of Monte Carlo standard
errors (MCSE), which measure error due to the Monte Carlo sampling (not
error due to statistical sampling &mdash; MCSE gets smaller when you run the
computer longer, but statistical sampling variability only gets smaller
when you get a larger data set).  All of this is explained in the package
vignette <code>vignette("demo", "mcmc")</code> and in Section 1.10 of Geyer (2011).
</p>
<p>This function does not apparently
do &ldquo;burn-in&rdquo; because this concept does not actually help with MCMC
(Geyer, 2011, Section 1.11.4) but the re-entrant property of this
function does allow one to do &ldquo;burn-in&rdquo; if one wants.
Assuming <code>ludfun</code>, <code>start.value</code>, <code>scale</code>
have been already defined
and are, respectively, an <span class="rlang"><b>R</b></span> function coding the log unnormalized density
of the target distribution, a valid state of the Markov chain,
and a useful scale factor,
</p>
<pre>
out &lt;- metrop(ludfun, start.value, nbatch = 1, blen = 1e5, scale = scale)
out &lt;- metrop(out, nbatch = 100, blen = 1000)
</pre>
<p>throws away a run of 100 thousand iterations before doing another run of
100 thousand iterations that is actually useful for analysis, for example,
</p>
<pre>
apply(out$batch, 2, mean)
apply(out$batch, 2, sd) / sqrt(out$nbatch)
</pre>
<p>give estimates of posterior means and their MCSE assuming the batch length
(here 1000) was long enough to contain almost all of the significant
autocorrelation (see Geyer, 2011, Section 1.10, for more on MCSE).
The re-entrant property of this function (the second run starts
where the first one stops) assures that this is really &ldquo;burn-in&rdquo;.
</p>
<p>The re-entrant property allows one to do very long runs without having to
do them in one invocation of this function.
</p>
<pre>
out2 &lt;- metrop(out)
out3 &lt;- metrop(out2)
batch &lt;- rbind(out$batch, out2$batch, out3$batch)
</pre>
<p>produces a result as if the first run had been three times as long.
</p>


<h3>Tuning</h3>

<p>The <code>scale</code> argument must be adjusted so that the acceptance rate
is not too low or too high to get reasonable performance.  The rule of
thumb is that the acceptance rate should be about 25%.
But this recommendation (Gelman, et al., 1996) is justified by analysis
of a toy problem (simulating a spherical multivariate normal distribution)
for which MCMC is unnecessary.  There is no reason to believe this is optimal
for all problems (if it were optimal, a stronger theorem could be proved).
Nevertheless, it is clear that at very low acceptance rates the chain makes
little progress (because in most iterations it does not move) and that at
very high acceptance rates the chain also makes little progress (because
unless the log unnormalized density is nearly constant, very high acceptance
rates can only be achieved by very small values of <code>scale</code> so the
steps the chain takes are also very small).
</p>
<p>Even in the Gelman, et al. (1996) result, the optimal rate for spherical
multivariate normal depends on dimension.  It is 44% for <code class="reqn">d = 1</code>
and 23% for <code class="reqn">d = \infty</code>.
Geyer and Thompson (1995) have an example, admittedly for
simulated tempering (see <code><a href="#topic+temper">temper</a></code>) rather than random-walk
Metropolis, in which no acceptance rate less than 70% produces an ergodic
Markov chain.  Thus 25% is merely a rule of thumb.  We only know we don't
want too high or too low.  Probably 1% or 99% is very inefficient.
</p>


<h3>References</h3>

<p>Gelman, A., Roberts, G. O., and Gilks, W. R. (1996)
Efficient Metropolis jumping rules.
In <em>Bayesian Statistics 5: Proceedings of the Fifth Valencia
International Meeting</em>.  Edited by J. M. Bernardo,
J. O. Berger, A. P. Dawid, and A. F. M. Smith.
Oxford University Press, Oxford, pp. 599&ndash;607. 
</p>
<p>Geyer, C. J. (2011)
Introduction to MCMC.
In <em>Handbook of Markov Chain Monte Carlo</em>. Edited by S. P. Brooks,
A. E. Gelman, G. L. Jones, and X. L. Meng.
Chapman &amp; Hall/CRC, Boca Raton, FL, pp. 3&ndash;48.
</p>
<p>Geyer, C. J. and Thompson, E. A. (1995)
Annealing Markov chain Monte Carlo with applications to ancestral inference.
<em>Journal of the American Statistical Association</em> <b>90</b> 909&ndash;920.
</p>
<p>Tierney, L. (1994)
Markov chains for exploring posterior distributions (with discussion).
<em>Annals of Statistics</em> <b>22</b> 1701&ndash;1762.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+morph.metrop">morph.metrop</a></code> and <code><a href="#topic+temper">temper</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>h &lt;- function(x) if (all(x &gt;= 0) &amp;&amp; sum(x) &lt;= 1) return(1) else return(-Inf)
out &lt;- metrop(h, rep(0, 5), 1000)
out$accept
# acceptance rate too low
out &lt;- metrop(out, scale = 0.1)
out$accept
t.test(out$accept.batch)$conf.int
# acceptance rate o. k. (about 25 percent)
plot(out$batch[ , 1])
# but run length too short (few excursions from end to end of range)
out &lt;- metrop(out, nbatch = 1e4)
out$accept
plot(out$batch[ , 1])
hist(out$batch[ , 1])
acf(out$batch[ , 1], lag.max = 250)
# looks like batch length of 250 is perhaps OK
out &lt;- metrop(out, blen = 250, nbatch = 100)
apply(out$batch, 2, mean) # Monte Carlo estimates of means
apply(out$batch, 2, sd) / sqrt(out$nbatch) # Monte Carlo standard errors
t.test(out$accept.batch)$conf.int
acf(out$batch[ , 1]) # appears that blen is long enough
</code></pre>

<hr>
<h2 id='morph'>Variable Transformation</h2><span id='topic+morph'></span><span id='topic+morph.identity'></span>

<h3>Description</h3>

<p>Utility functions for variable transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>morph(b, r, p, center)
morph.identity()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="morph_+3A_b">b</code></td>
<td>
<p>Positive real number.  May be missing.</p>
</td></tr>
<tr><td><code id="morph_+3A_r">r</code></td>
<td>
<p>Non-negative real number.  May be missing.  If <code>p</code> is
specified, <code>r</code> defaults to 0.</p>
</td></tr>
<tr><td><code id="morph_+3A_p">p</code></td>
<td>
<p>Real number strictly greater than 2.  May be missing.  If
<code>r</code> is specified, <code>p</code> defaults to 3.</p>
</td></tr>
<tr><td><code id="morph_+3A_center">center</code></td>
<td>
<p>Real scalar or vector.  May be missing.  If
<code>center</code> is a vector it should be the same length of the state
of the Markov chain, <code>center</code> defaults to 0</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>morph</code> function facilitates using variable transformations
by providing functions to (using <code class="reqn">X</code> for the original random
variable with the pdf <code class="reqn">f_X</code>, and <code class="reqn">Y</code> for the transformed
random variable with the pdf <code class="reqn">f_Y</code>):
</p>

<ul>
<li><p> Calculate the log unnormalized probability density for <code class="reqn">Y</code>
induced by the transformation.
</p>
</li>
<li><p> Transform an arbitrary function of <code class="reqn">X</code> to a function of
<code class="reqn">Y</code>.
</p>
</li>
<li><p> Transform values of <code class="reqn">X</code> to values of <code class="reqn">Y</code>.
</p>
</li>
<li><p> Transform values of <code class="reqn">Y</code> to values of <code class="reqn">X</code>
(the inverse transformation).
</p>
</li></ul>

<p>for a select few transformations.
</p>
<p><code>morph.identity</code> implements the identity transformation,
<code class="reqn">Y=X</code>.
</p>
<p>The parameters <code>r</code>, <code>p</code>, <code>b</code> and <code>center</code> specify the
transformation function.  In all cases, <code>center</code> gives the center
of the transformation, which is the value <code class="reqn">c</code> in the equation
</p>
<p style="text-align: center;"><code class="reqn">Y = f(X - c).</code>
</p>
<p>  If no parameters are specified, the identity
transformation, <code class="reqn">Y=X</code>, is used.
</p>
<p>The parameters <code>r</code>, <code>p</code> and <code>b</code> specify a function
<code class="reqn">g</code>, which is a monotonically increasing bijection from the
non-negative reals to the non-negative reals.  Then
</p>
<p style="text-align: center;"><code class="reqn">f(X) = g\bigl(|X|\bigr) \frac{X}{|X|}</code>
</p>

<p>where <code class="reqn">|X|</code> represents the Euclidean norm of the vector <code class="reqn">X</code>.
The inverse function is given by
</p>
<p style="text-align: center;"><code class="reqn">f^{-1}(Y) = g^{-1}\bigl(|Y|\bigr) \frac{Y}{|Y|}.</code>
</p>

<p>The parameters <code>r</code> and <code>p</code> are used to define the function
</p>
<p style="text-align: center;"><code class="reqn">g_1(x) = x + (x-r)^p I(x &gt; r)</code>
</p>

<p>where <code class="reqn">I( \cdot )</code>  is the indicator
function.  We require that <code>r</code> is non-negative and <code>p</code> is
strictly greater than 2.  The parameter <code>b</code> is used to define the
function
</p>
<p style="text-align: center;"><code class="reqn">g_2(x) = \bigl(e^{bx} - e / 3\bigr) I(x &gt; \frac{1}{b}) + 
    \bigl(x^3 b^3 e / 6 + x b e / 2\bigr) I(x \leq
    \frac{1}{b})</code>
</p>

<p>We require that <code class="reqn">b</code> is positive.
</p>
<p>The parameters <code>r</code>, <code>p</code> and <code>b</code> specify <code class="reqn">f^{-1}</code> in
the following manner:
</p>

<ul>
<li><p>  If one or both of <code>r</code> and <code>p</code> is specified, and <code>b</code>
is not specified, then </p>
<p style="text-align: center;"><code class="reqn">f^{-1}(X) = g_1(|X|)
      \frac{X}{|X|}.</code>
</p>
<p>  If only
<code>r</code> is specified, <code>p = 3</code> is used.  If only <code>p</code> is specified,
<code>r = 0</code> is used.
</p>
</li>
<li><p> If only <code>b</code> is specified, then </p>
<p style="text-align: center;"><code class="reqn">f^{-1}(X) = g_2(|X|)
      \frac{X}{|X|}.</code>
</p>

</li>
<li><p> If one or both of <code>r</code> and <code>p</code> is specified, and <code>b</code> is
also specified, then </p>
<p style="text-align: center;"><code class="reqn">f^{-1}(X) = g_2(g_1(|X|))
      \frac{X}{|X|}.</code>
</p>

</li></ul>



<h3>Value</h3>

<p>a list containing the functions
</p>

<ul>
<li> <p><code>outfun(f)</code>, a function that operates on functions.
<code>outfun(f)</code> returns the function <code>function(state, ...)
    f(inverse(state), ...)</code>.
</p>
</li>
<li> <p><code>inverse</code>, the inverse transformation function.
</p>
</li>
<li> <p><code>transform</code>, the transformation function.
</p>
</li>
<li> <p><code>lud</code>, a function that operates on functions.  As input,
<code>lud</code> takes a function that calculates a log unnormalized
probability density, and returns a function that calculates the
log unnormalized density by transforming a random variable using the
<code>transform</code> function.  <code>lud(f) = function(state, ...)
  f(inverse(state), ...) + log.jacobian(state)</code>, where
<code>log.jacobian</code> represents the function that calculate the log
Jacobian of the transformation.  <code>log.jacobian</code> is not returned.
</p>
</li></ul>



<h3>Warning</h3>

<p>The equations for the returned <code>transform</code> function (see below)
do not have a general analytical solution when <code>p</code> is not equal
to 3.  This implementation uses numerical approximation to calculate
<code>transform</code> when <code>p</code> is not equal to 3.  If computation
speed is a factor, it is advisable to use <code>p=3</code>.  This is not a
factor when using <code><a href="#topic+morph.metrop">morph.metrop</a></code>, as <code>transform</code> is
only called once during setup, and not at all while running the Markov chain.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+morph.metrop">morph.metrop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# use an exponential transformation, centered at 100.
b1 &lt;- morph(b=1, center=100)
# original log unnormalized density is from a t distribution with 3
# degrees of freedom, centered at 100.
lud.transformed &lt;- b1$lud(function(x) dt(x - 100, df=3, log=TRUE))
d.transformed &lt;- Vectorize(function(x) exp(lud.transformed(x)))
## Not run: 
curve(d.transformed, from=-3, to=3, ylab="Induced Density")

## End(Not run)
</code></pre>

<hr>
<h2 id='morph.metrop'>Morphometric Metropolis Algorithm</h2><span id='topic+morph.metrop'></span><span id='topic+morph.metrop.function'></span><span id='topic+morph.metrop.morph.metropolis'></span>

<h3>Description</h3>

<p>Markov chain Monte Carlo for continuous random vector using a
Metropolis algorithm for an induced density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>morph.metrop(obj, initial, nbatch, blen = 1, nspac = 1, scale = 1,
  outfun, debug = FALSE, morph, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="morph.metrop_+3A_obj">obj</code></td>
<td>
<p>see <code><a href="#topic+metrop">metrop</a></code>.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_initial">initial</code></td>
<td>
<p>see <code><a href="#topic+metrop">metrop</a></code>.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_nbatch">nbatch</code></td>
<td>
<p>see <code><a href="#topic+metrop">metrop</a></code>.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_blen">blen</code></td>
<td>
<p>see <code><a href="#topic+metrop">metrop</a></code>.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_nspac">nspac</code></td>
<td>
<p>see <code><a href="#topic+metrop">metrop</a></code>.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_scale">scale</code></td>
<td>
<p>see <code><a href="#topic+metrop">metrop</a></code>.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_outfun">outfun</code></td>
<td>
<p>unlike for <code><a href="#topic+metrop">metrop</a></code> must be a function or missing;
if missing the identity function, <code>function(x) x</code>, is used.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_debug">debug</code></td>
<td>
<p>see <code><a href="#topic+metrop">metrop</a></code>.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_morph">morph</code></td>
<td>
<p>morph object used for transformations.  See <code><a href="#topic+morph">morph</a></code>.</p>
</td></tr>
<tr><td><code id="morph.metrop_+3A_...">...</code></td>
<td>
<p>see <code><a href="#topic+metrop">metrop</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>morph.metrop</code> implements morphometric methods for Markov
chains.  The caller specifies a log unnormalized probability density
and a transformation.  The transformation specified by the
<code>morph</code> parameter is used to induce a new log unnormalized
probability   density, a Metropolis algorithm is
run for the induced density.  The Markov chain is transformed back to
the original scale.  Running the Metropolis algorithm for the induced
density, instead of the original density, can result in a Markov chain
with better convergence properties.  For more details see Johnson and Geyer
(submitted).  Except for <code>morph</code>, all parameters are
passed to <code><a href="#topic+metrop">metrop</a></code>, transformed when necessary.  The
<code>scale</code> parameter is <em>not</em> transformed.
</p>
<p>If <code class="reqn">X</code> is a real vector valued continuous random variable, and
<code class="reqn">Y = f(X)</code> where <code class="reqn">f</code> is a diffeomorphism, then the pdf of
<code class="reqn">Y</code> is given by </p>
<p style="text-align: center;"><code class="reqn">f_Y(y) = f_X(f^{-1}(y)) | \nabla f^{-1}(y)
  |</code>
</p>
<p> where <code class="reqn">f_X</code> is
the pdf of <code class="reqn">X</code> and <code class="reqn">\nabla f^{-1}</code> is the Jacobian
of <code class="reqn">f^{-1}</code>.  Because <code class="reqn">f</code> is a diffeomorphism, a Markov chain
for <code class="reqn">f_Y</code> may be transformed into a Markov chain for
<code class="reqn">f_X</code>.  Furthermore, these Markov chains are isomorphic
(Johnson and Geyer, submitted) and have the same convergence rate.
The <code><a href="#topic+morph">morph</a></code> variable provides a diffeomorphism,
<code>morph.metrop</code> uses this diffeomorphism to induce the log
unnormalized density, <code class="reqn">\log f_Y</code> based on the user
supplied log unnormalized density, <code class="reqn">\log f_X</code>.
<code>morph.metrop</code> runs a Metropolis algorithm for <code class="reqn">\log f_Y</code> and transforms the resulting Markov chain into a Markov chain for
<code class="reqn">f_X</code>.  The user accessible output components are the same as
those that come from <code><a href="#topic+metrop">metrop</a></code>, see the documentation for
<code><a href="#topic+metrop">metrop</a></code> for details.
</p>
<p>Subsequent calls of <code>morph.metrop</code> may change to the
transformation by specifying a new value for <code>morph</code>.
</p>
<p>Any of the other parameters to <code>morph.metrop</code> may also be
modified in subsequent calls.  See <code><a href="#topic+metrop">metrop</a></code> for more details.
</p>
<p>The general idea is that a random-walk Metropolis sampler
(what <code><a href="#topic+metrop">metrop</a></code> does) will not be geometrically
ergodic unless the tails of the unnormalized density decrease
superexponentially fast (so the tails of the log unnormalized density
decrease faster than linearly).  It may not be geometrically ergodic
even then (see Johnson and Geyer, submitted, for the complete theory).
The transformations used by this function (provided by <code><a href="#topic+morph">morph</a></code>)
can produce geometrically ergodic chains when the tails of the log
unnormalized density are too light for <code><a href="#topic+metrop">metrop</a></code> to do so.
</p>
<p>When the tails of the unnormalized density are exponentially light but
not superexponentially light (so the tails of the log unnormalized density
are asymptotically linear, as in the case of exponential family models
when conjugate priors are used, for example logistic regression, Poisson
regression with log link, or log-linear models for categorical data), one
should use <code><a href="#topic+morph">morph</a></code> with <code>b = 0</code> (the default), which
produces a transformation of the form <code class="reqn">g_1</code> in the notation
used in the details section of the help for <code><a href="#topic+morph">morph</a></code>.
This will produce a geometrically ergodic sampler if other features of the
log unnormalized density are well behaved.  For example it will do so
for the exponential family examples mentioned above.
(See Johnson and Geyer, submitted, for the complete theory.)
</p>
<p>The transformation <code class="reqn">g_1</code> behaves like a shift transformation
on a ball of radius <code>r</code> centered at <code>center</code>, so these arguments
to <code><a href="#topic+morph">morph</a></code> should be chosen so that a sizable proportion of
the probability under the original (untransformed) unnormalized density
is contained in this ball.  This function will work when <code>r = 0</code> and
<code>center = 0</code> (the defaults) are used, but may not work as well as when
<code>r</code> and <code>center</code> are well chosen.
</p>
<p>When the tails of the unnormalized density are not exponentially light
(so the tails of the log unnormalized density decrease sublinearly, as
in the case of univariate and multivariate <code class="reqn">t</code> distributions), one
should use <code><a href="#topic+morph">morph</a></code> with <code>r &gt; 0</code> and <code>p = 3</code>, which
produces a transformation of the form <code class="reqn">g_2</code> composed
with <code class="reqn">g_1</code> in the notation
used in the details section of the help for <code><a href="#topic+morph">morph</a></code>.
This will produce a geometrically ergodic sampler if other features of the
log unnormalized density are well behaved.  For example it will do so
for the <code class="reqn">t</code> examples mentioned above.
(See Johnson and Geyer, submitted, for the complete theory.)
</p>


<h3>Value</h3>

<p>an object of class <code>mcmc</code>, subclass <code>morph.metropolis</code>.
This object is a list containing all of the elements from an object
returned by <code><a href="#topic+metrop">metrop</a></code>, plus at least the following
components:
</p>
<table>
<tr><td><code>morph</code></td>
<td>
<p>the morph object used for the transformations.</p>
</td></tr>
<tr><td><code>morph.final</code></td>
<td>
<p>the final state of the Markov chain on the
transformed scale.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Johnson, L. T. and Geyer, C. J. (submitted)
Variable Transformation to Obtain Geometric Ergodicity
in the Random-walk Metropolis Algorithm.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+metrop">metrop</a></code>, <code><a href="#topic+morph">morph</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>out &lt;- morph.metrop(function(x) dt(x, df=3, log=TRUE), 0, blen=100,
  nbatch=100, morph=morph(b=1))
# change the transformation.
out &lt;- morph.metrop(out, morph=morph(b=2))
out$accept
# accept rate is high, increase the scale.
out &lt;- morph.metrop(out, scale=4)
# close to 0.20 is about right.
out$accept
</code></pre>

<hr>
<h2 id='olbm'>Overlapping Batch Means</h2><span id='topic+olbm'></span>

<h3>Description</h3>

<p>Variance of sample mean of time series calculated using overlapping
batch means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olbm(x, batch.length, demean = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="olbm_+3A_x">x</code></td>
<td>
<p>a matrix or time series object.  Each column of <code>x</code> is
treated as a scalar time series.</p>
</td></tr>
<tr><td><code id="olbm_+3A_batch.length">batch.length</code></td>
<td>
<p>length of batches.</p>
</td></tr>
<tr><td><code id="olbm_+3A_demean">demean</code></td>
<td>
<p>when <code>demean = TRUE</code> (the default) the sample mean
is subtracted from each batch mean when estimating the variance.
Using <code>demean = FALSE</code> would essentially assume the true mean
is known to be zero, which might be useful in a toy problem where
the answer is known.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimated variance of the sample mean.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ts">ts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>h &lt;- function(x) if (all(x &gt;= 0) &amp;&amp; sum(x) &lt;= 1) return(1) else return(-Inf)
out &lt;- metrop(h, rep(0, 5), 1000)
out &lt;- metrop(out, scale = 0.1)
out &lt;- metrop(out, nbatch = 1e4)
foo &lt;- olbm(out$batch, 150)
# monte carlo estimates (true means are same by symmetry)
apply(out$batch, 2, mean)
# monte carlo standard errors (true s. d. are same by symmetry)
sqrt(diag(foo))
# check that batch length is reasonable
acf(out$batch, lag.max = 200)
</code></pre>

<hr>
<h2 id='temper'>Simulated Tempering and Umbrella Sampling</h2><span id='topic+temper'></span><span id='topic+temper.function'></span><span id='topic+temper.tempering'></span>

<h3>Description</h3>

<p>Markov chain Monte Carlo (MCMC) for continuous random vectors using
parallel or serial tempering, the latter also called umbrella
sampling and simulated tempering.
The chain simulates <code class="reqn">k</code> different distributions on the
same state space.  In parallel tempering, all the distributions are
simulated in each iteration.  In serial tempering, only one of the
distributions is simulated (a random one).  In parallel tempering,
the state is a <code class="reqn">k \times p</code> matrix, each row of which
is the state for one of the distributions.
In serial tempering the state of the Markov chain is a pair <code class="reqn">(i, x)</code>,
where <code class="reqn">i</code> is an integer between 1 and <code class="reqn">k</code> and <code class="reqn">x</code> is a vector
of length <code class="reqn">p</code>.  This pair is represented as a single real vector
<code>c(i, x)</code>.  The variable <code class="reqn">i</code> says which distribution <code class="reqn">x</code>
is a simulation for.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>temper(obj, initial, neighbors, nbatch, blen = 1, nspac = 1, scale = 1,
    outfun, debug = FALSE, parallel = FALSE, ...)
## S3 method for class 'function'
temper(obj, initial, neighbors, nbatch,
    blen = 1, nspac = 1, scale = 1,
    outfun, debug = FALSE, parallel = FALSE, ...)
## S3 method for class 'tempering'
temper(obj, initial, neighbors, nbatch,
    blen = 1, nspac = 1, scale = 1,
    outfun, debug = FALSE, parallel = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="temper_+3A_obj">obj</code></td>
<td>
<p>either an <span class="rlang"><b>R</b></span> function or an object of class <code>"tempering"</code>
from a previous run.
</p>
<p>If a function, it should evaluate the log unnormalized
density <code class="reqn">\log h(i, x)</code> of the desired equilibrium
distribution of the Markov chain for serial tempering (the same function
is used for both serial and parallel tempering, see Details below for
further explanation).
</p>
<p>If an object of class <code>"tempering"</code>,
the log unnormalized density function
is <code>obj$lud</code>, and missing arguments of <code>temper</code> are
obtained from the corresponding elements of <code>obj</code>.
</p>
<p>The first argument of the log unnormalized density function is the
is an <span class="rlang"><b>R</b></span> vector <code>c(i, x)</code>, where <code>i</code> says which distribution
<code>x</code> is supposed to be a simulation for.
Other arguments are arbitrary and taken from
the <code>...</code> arguments of <code>temper</code>.  The log unnormalized density
function should return <code>-Inf</code> in regions of the state space having
probability zero.</p>
</td></tr>
<tr><td><code id="temper_+3A_initial">initial</code></td>
<td>
<p>for serial tempering, a real vector <code>c(i, x)</code> as
described above.  For parallel tempering, a real
<code class="reqn">k \times p</code> matrix as described above.  In either case,
the initial state of the Markov chain.
Ignored if <code>obj</code> has class <code>"tempering"</code>.</p>
</td></tr>
<tr><td><code id="temper_+3A_neighbors">neighbors</code></td>
<td>
<p>a logical symmetric matrix of dimension <code>k</code>
by <code>k</code>.  Elements that are <code>TRUE</code> indicate jumps
or swaps attempted by the Markov chain.
Ignored if <code>obj</code> has class <code>"tempering"</code>.</p>
</td></tr>
<tr><td><code id="temper_+3A_nbatch">nbatch</code></td>
<td>
<p>the number of batches.</p>
</td></tr>
<tr><td><code id="temper_+3A_blen">blen</code></td>
<td>
<p>the length of batches.</p>
</td></tr>
<tr><td><code id="temper_+3A_nspac">nspac</code></td>
<td>
<p>the spacing of iterations that contribute to batches.</p>
</td></tr>
<tr><td><code id="temper_+3A_scale">scale</code></td>
<td>
<p>controls the proposal step size for real elements of the state
vector.  For serial tempering, proposing a new value for the <code class="reqn">x</code>
part of the state <code class="reqn">(i, x)</code>.  For parallel tempering, proposing
a new value for the <code class="reqn">x_i</code> part of the state
<code class="reqn">(x_1, \ldots, x_k)</code>.  In either case, the proposal
is a real vector of length <code class="reqn">p</code>.  If scalar or vector, the proposal
is <code>x + scale * z</code> where <code>x</code> is the part <code class="reqn">x</code> or
<code class="reqn">x_i</code> of the state the proposal may replace.
If matrix, the proposal is
<code>x + scale %*% z</code>.  If list, the length must be <code>k</code>,
and each element must be scalar, vector, or matrix, and operate as
described above.  The <code class="reqn">i</code>-th component of the list is used to update
<code class="reqn">x</code> when the state is <code class="reqn">(i, x)</code> or <code class="reqn">x_i</code> otherwise.</p>
</td></tr>
<tr><td><code id="temper_+3A_outfun">outfun</code></td>
<td>
<p>controls the output.  If a function, then the batch means
of <code>outfun(state, ...)</code> are returned.  The argument <code>state</code>
is like the argument <code>initial</code> of this function.  If missing, the
batch means of the real part of the state vector or matrix are returned,
and for serial tempering the batch means of a multivariate Bernoulli
indicating the current component are returned.</p>
</td></tr>
<tr><td><code id="temper_+3A_debug">debug</code></td>
<td>
<p>if <code>TRUE</code> extra output useful for testing.</p>
</td></tr>
<tr><td><code id="temper_+3A_parallel">parallel</code></td>
<td>
<p>if <code>TRUE</code> does parallel tempering, if <code>FALSE</code> does
serial tempering.
Ignored if <code>obj</code> has class <code>"tempering"</code>.</p>
</td></tr>
<tr><td><code id="temper_+3A_...">...</code></td>
<td>
<p>additional arguments for <code>obj</code> or <code>outfun</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Serial tempering simulates a mixture of distributions of a continuous random
vector.  The number of components of the mixture is <code>k</code>, and the dimension
of the random vector is <code>p</code>.  Denote the state <code class="reqn">(i, x)</code>, where <code class="reqn">i</code>
is a positive integer between 1 and <code class="reqn">k</code>, and let <code class="reqn">h(i, x)</code> denote
the unnormalized joint density of their equilibrium distribution.
The logarithm of this function is what <code>obj</code> or <code>obj$lud</code> calculates.
The mixture distribution is the marginal for <code class="reqn">x</code> derived from
the equilibrium distribution <code class="reqn">h(i, x)</code>, that is,
</p>
<p style="text-align: center;"><code class="reqn">h(x) = \sum_{i = 1}^k h(i, x)</code>
</p>

<p>Parallel tempering simulates a product of distributions of a continuous random
vector.  Denote the state <code class="reqn">(x_1, \ldots, x_k)</code>,
then the unnormalized joint density of the equilibrium distribution is
</p>
<p style="text-align: center;"><code class="reqn">h(x_1, \ldots, x_k) = \prod_{i = 1}^k h(i, x_i)</code>
</p>

<p>The update mechanism of the Markov chain combines two kinds of elementary
updates: jump/swap updates (jump for serial tempering, swap for parallel
tempering) and within-component updates.  Each iteration of the Markov chain
one of these elementary updates is done.  With probability 1/2 a jump/swap
update is done, and with probability 1/2 a with-component update is done.
</p>
<p>Within-component updates are the same for both serial and parallel tempering.
They are &ldquo;random-walk&rdquo; Metropolis updates with multivariate normal
proposal, the proposal distribution being determined by the argument
<code>scale</code>.  In serial tempering, the <code class="reqn">x</code> part of the current state
<code class="reqn">(i, x)</code> is updated preserving <code class="reqn">h(i, x)</code>.
In parallel tempering, an index <code class="reqn">i</code> is chosen at random and the part
of the state <code class="reqn">x_i</code> representing that component is updated,
again preserving <code class="reqn">h(i, x)</code>.
</p>
<p>Jump updates choose uniformly at random a neighbor of the current component:
if <code class="reqn">i</code> indexes the current component, then it chooses uniformly at random
a <code class="reqn">j</code> such that <code>neighbors[i, j] == TRUE</code>.  It then does does a
Metropolis-Hastings update for changing the current state from <code class="reqn">(i, x)</code>
to <code class="reqn">(j, x)</code>.
</p>
<p>Swap updates choose a component uniformly at random and a neighbor of that
component uniformly at random: first an index <code class="reqn">i</code> is chosen uniformly
at random between 1 and <code class="reqn">k</code>, then an index <code class="reqn">j</code> is chosen
uniformly at random such that <code>neighbors[i, j] == TRUE</code>.  It then does
does a Metropolis-Hastings update for swapping the states of the
two components: interchanging <code class="reqn">x_i</code> and <code class="reqn">x_j</code>
while preserving <code class="reqn">h(x_1, \ldots, x_k)</code>.
</p>
<p>The initial state must satisfy <code>lud(initial, ...) &gt; - Inf</code> for serial
tempering or must satisfy <code>lud(initial[i, ], ...) &gt; - Inf</code> for each
<code>i</code> for parallel tempering, where <code>lud</code> is either <code>obj</code>
or <code>obj$lud</code>.
That is, the initial state must have positive probability.
</p>


<h3>Value</h3>

<p>an object of class <code>"mcmc"</code>, subclass <code>"tempering"</code>,
which is a list containing at least the following components:
</p>
<table>
<tr><td><code>batch</code></td>
<td>
<p>the batch means of the continuous part of the state.
If <code>outfun</code> is missing, an <code>nbatch</code> by <code>k</code> by <code>p</code>
array.  Otherwise, an <code>nbatch</code> by <code>m</code> matrix, where <code>m</code>
is the length of the result of <code>outfun</code>.</p>
</td></tr>
<tr><td><code>ibatch</code></td>
<td>
<p>(returned for serial tempering only) an <code>nbatch</code>
by <code>k</code> matrix giving batch means for the multivariate Bernoulli
random vector that is all zeros except for a 1 in the <code>i</code>-th place
when the current state is <code class="reqn">(i, x)</code>.</p>
</td></tr>
<tr><td><code>acceptx</code></td>
<td>
<p>fraction of Metropolis within-component proposals accepted.
A vector of length <code>k</code> giving the acceptance rate for each component.</p>
</td></tr>
<tr><td><code>accepti</code></td>
<td>
<p>fraction of Metropolis jump/swap proposals accepted.
A <code>k</code> by <code>k</code> matrix giving the acceptance rate for each allowed
jump or swap component.  <code>NA</code> for elements such that the corresponding
elements of <code>neighbors</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code>initial</code></td>
<td>
<p>value of argument <code>initial</code>.</p>
</td></tr>
<tr><td><code>final</code></td>
<td>
<p>final state of Markov chain.</p>
</td></tr>
<tr><td><code>initial.seed</code></td>
<td>
<p>value of <code>.Random.seed</code> before the run.</p>
</td></tr>
<tr><td><code>final.seed</code></td>
<td>
<p>value of <code>.Random.seed</code> after the run.</p>
</td></tr>
<tr><td><code>time</code></td>
<td>
<p>running time of Markov chain from <code>system.time()</code>.</p>
</td></tr>
<tr><td><code>lud</code></td>
<td>
<p>the function used to calculate log unnormalized density,
either <code>obj</code> or <code>obj$lud</code> from a previous run.</p>
</td></tr>
<tr><td><code>nbatch</code></td>
<td>
<p>the argument <code>nbatch</code> or <code>obj$nbatch</code>.</p>
</td></tr>
<tr><td><code>blen</code></td>
<td>
<p>the argument <code>blen</code> or <code>obj$blen</code>.</p>
</td></tr>
<tr><td><code>nspac</code></td>
<td>
<p>the argument <code>nspac</code> or <code>obj$nspac</code>.</p>
</td></tr>
<tr><td><code>outfun</code></td>
<td>
<p>the argument <code>outfun</code> or <code>obj$outfun</code>.</p>
</td></tr>
</table>
<p>Description of additional output when <code>debug = TRUE</code> can be
found in the vignette <code>debug</code>, which is shown by
<code>vignette("debug", "mcmc")</code>.
</p>


<h3>Warning</h3>

<p>If <code>outfun</code> is missing, then the log unnormalized
density function can be defined without a ... argument and that works fine.
One can define it starting <code>ludfun &lt;- function(state)</code> and that works
or <code>ludfun &lt;- function(state, foo, bar)</code>, where <code>foo</code> and <code>bar</code>
are supplied as additional arguments to <code>temper</code> and that works too.
</p>
<p>If <code>outfun</code> is a function, then both it and the log unnormalized
density function can be defined without ... arguments <em>if they
have exactly the same arguments list</em> and that works fine.  Otherwise it
doesn't work.  Define these functions by
</p>
<pre>
ludfun &lt;- function(state, foo)
outfun &lt;- function(state, bar)
</pre>
<p>and you get an error about unused arguments.  Instead define these functions by
</p>
<pre>
ludfun &lt;- function(state, foo, \ldots)
outfun &lt;- function(state, bar, \ldots)
</pre>
<p>and supply <code>foo</code> and <code>bar</code> as additional arguments to <code>temper</code>,
and that works fine.
</p>
<p>In short, the log unnormalized density function and <code>outfun</code> need
to have ... in their arguments list to be safe.  Sometimes it works
when ... is left out and sometimes it doesn't.
</p>
<p>Of course, one can avoid this whole issue by always defining the log
unnormalized density function and <code>outfun</code> to have only one argument
<code>state</code> and use global variables (objects in the <span class="rlang"><b>R</b></span> global environment) to
specify any other information these functions need to use.  That too
follows the <span class="rlang"><b>R</b></span> way.  But some people consider that bad programming practice.
</p>
<p>A third option is to define either or both of these functions using a function
factory.  This is demonstrated in the vignette for this package named
<code>demo</code>, which is shown by <code>vignette("demo", "mcmc")</code>.
</p>


<h3>Philosophy of MCMC</h3>

<p>This function follows the philosophy of MCMC explained
the introductory chapter of the
<em>Handbook of Markov Chain Monte Carlo</em> (Geyer, 2011a)
and in the chapter of that book on tempering and related subjects
(Geyer, 2011b).
See also the section on philosophy of <code><a href="#topic+metrop">metrop</a></code>.
</p>


<h3>Tuning</h3>

<p>The <code>scale</code> argument must be adjusted so that the acceptance rate
for within-component proposals (component <code>acceptx</code> of the result
returned by this function)
is not too low or too high to get reasonable performance.
The log unnormalized density function must be chosen so that the acceptance rate
for jump/swap proposals (component <code>accepti</code> of the result
returned by this function)
is not too low or too high to get reasonable performance.
The former is a vector and the latter is a matrix, and
all these rates must be adjusted to be reasonable.
</p>
<p>The rates in in <code>accepti</code> are influenced by the number of components
of the tempering mixture distribution, by what those components are (how
far apart they are in some unspecified metric on probability distributions),
and by the chosen normalizing constants for those distributions.
</p>
<p>For examples of tuning tempering, see Geyer (2011b) and also the vignette
of this package shown by <code>vignette("bfst", "mcmc")</code>.
The help for R function <code><a href="#topic+metrop">metrop</a></code> also gives advice on tuning
its sampler, which is relevant for tuning the <code>acceptx</code> rates.
</p>
<p>See also Geyer (1991) and Geyer and Thompson (1995) for the general
theory of tuning parallel and serial tempering.
</p>


<h3>References</h3>

<p>Geyer, C. J. (1991)
Markov chain Monte Carlo maximum likelihood.
<em>Computing Science and Statistics: Proc. 23rd Symp. Interface</em>, 156&ndash;163.
<a href="http://hdl.handle.net/11299/58440">http://hdl.handle.net/11299/58440</a>.
</p>
<p>Geyer, C. J. (2011a)
Introduction to MCMC.
In <em>Handbook of Markov Chain Monte Carlo</em>. Edited by S. P. Brooks,
A. E. Gelman, G. L. Jones, and X. L. Meng.
Chapman &amp; Hall/CRC, Boca Raton, FL, pp. 3&ndash;48.
</p>
<p>Geyer, C. J. (2011b)
Importance Sampling, Simulated Tempering, and Umbrella Sampling.
In <em>Handbook of Markov Chain Monte Carlo</em>. Edited by S. P. Brooks,
A. E. Gelman, G. L. Jones, and X. L. Meng.
Chapman &amp; Hall/CRC, Boca Raton, FL, pp. 295&ndash;312.
</p>
<p>Geyer, C. J. and Thompson, E. A. (1995)
Annealing Markov chain Monte Carlo with applications to ancestral inference.
<em>Journal of the American Statistical Association</em> <b>90</b> 909&ndash;920.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- 9
witch.which &lt;- c(0.1, 0.3, 0.5, 0.7, 1.0)
ncomp &lt;- length(witch.which)

neighbors &lt;- matrix(FALSE, ncomp, ncomp)
neighbors[row(neighbors) == col(neighbors) + 1] &lt;- TRUE
neighbors[row(neighbors) == col(neighbors) - 1] &lt;- TRUE

ludfun &lt;- function(state, log.pseudo.prior = rep(0, ncomp)) {
    stopifnot(is.numeric(state))
    stopifnot(length(state) == d + 1)
    icomp &lt;- state[1]
    stopifnot(icomp == as.integer(icomp))
    stopifnot(1 &lt;= icomp &amp;&amp; icomp &lt;= ncomp)
    stopifnot(is.numeric(log.pseudo.prior))
    stopifnot(length(log.pseudo.prior) == ncomp)
    theta &lt;- state[-1]
    if (any(theta &gt; 1.0)) return(-Inf)
    bnd &lt;- witch.which[icomp]
    lpp &lt;- log.pseudo.prior[icomp]
    if (any(theta &gt; bnd)) return(lpp)
    return(- d * log(bnd) + lpp)
}

# parallel tempering
thetas &lt;- matrix(0.5, ncomp, d)
out &lt;- temper(ludfun, initial = thetas, neighbors = neighbors, nbatch = 20,
    blen = 10, nspac = 5, scale = 0.56789, parallel = TRUE, debug = TRUE)

# serial tempering
theta.initial &lt;- c(1, rep(0.5, d))
# log pseudo prior found by trial and error
qux &lt;- c(0, 9.179, 13.73, 16.71, 20.56)

out &lt;- temper(ludfun, initial = theta.initial, neighbors = neighbors,
    nbatch = 50, blen = 30, nspac = 2, scale = 0.56789,
    parallel = FALSE, debug = FALSE, log.pseudo.prior = qux)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
