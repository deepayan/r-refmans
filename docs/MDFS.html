<!DOCTYPE html><html lang="en"><head><title>Help for package MDFS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MDFS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AddContrastVariables'><p>Add contrast variables to data</p></a></li>
<li><a href='#as.data.frame.MDFS'><p>as.data.frame S3 method implementation for MDFS</p></a></li>
<li><a href='#ComputeInterestingTuples'><p>Interesting tuples</p></a></li>
<li><a href='#ComputeInterestingTuplesDiscrete'><p>Interesting tuples (discrete)</p></a></li>
<li><a href='#ComputeMaxInfoGains'><p>Max information gains</p></a></li>
<li><a href='#ComputeMaxInfoGainsDiscrete'><p>Max information gains (discrete)</p></a></li>
<li><a href='#ComputePValue'><p>Compute p-values from information gains and return MDFS</p></a></li>
<li><a href='#Discretize'><p>Discretize variable on demand</p></a></li>
<li><a href='#GenContrastVariables'><p>Generate contrast variables from data</p></a></li>
<li><a href='#GetRange'><p>Get the recommended range for multiple discretisations</p></a></li>
<li><a href='#madelon'><p>An artificial dataset called MADELON</p></a></li>
<li><a href='#MDFS'><p>Run end-to-end MDFS</p></a></li>
<li><a href='#mdfs_omp_set_num_threads'><p>Call omp_set_num_threads</p></a></li>
<li><a href='#plot.MDFS'><p>Plot MDFS details</p></a></li>
<li><a href='#RelevantVariables'><p>Find indices of relevant variables</p></a></li>
<li><a href='#RelevantVariables.MDFS'><p>Find indices of relevant variables from MDFS</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>MultiDimensional Feature Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-12-11</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.mdfs.it/">https://www.mdfs.it/</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for MultiDimensional Feature Selection (MDFS):
 calculating multidimensional information gains, scoring variables,
 finding important variables, plotting selection results.
 This package includes an optional CUDA implementation that speeds up
 information gain calculation using NVIDIA GPGPUs.
 R. Piliszek et al. (2019) &lt;<a href="https://doi.org/10.32614%2FRJ-2019-019">doi:10.32614/RJ-2019-019</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-12-11 19:31:00 UTC; radek</td>
</tr>
<tr>
<td>Author:</td>
<td>Radosław Piliszek [aut, cre],
  Krzysztof Mnich [aut],
  Paweł Tabaszewski [aut],
  Szymon Migacz [aut],
  Andrzej Sułecki [aut],
  Witold Remigiusz Rudnicki [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Radosław Piliszek &lt;radek@piliszek.it&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-12-12 08:30:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='AddContrastVariables'>Add contrast variables to data</h2><span id='topic+AddContrastVariables'></span>

<h3>Description</h3>

<p>This function is deprecated. Please use GenContrastVariables instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AddContrastVariables(data, n.contrast = max(ncol(data)/10, 30))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AddContrastVariables_+3A_data">data</code></td>
<td>
<p>data organized in matrix with separate variables in columns</p>
</td></tr>
<tr><td><code id="AddContrastVariables_+3A_n.contrast">n.contrast</code></td>
<td>
<p>number of constrast variables (defaults to max of 1/10 of variables number and 30)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following key names:
</p>

<ul>
<li> <p><code>indices</code> &ndash; vector of indices of input variables used to construct contrast variables
</p>
</li>
<li> <p><code>x</code> &ndash; data with constrast variables appended to it
</p>
</li>
<li> <p><code>mask</code> &ndash; vector of booleans making it easy to select just contrast variables
</p>
</li></ul>


<hr>
<h2 id='as.data.frame.MDFS'>as.data.frame S3 method implementation for MDFS</h2><span id='topic+as.data.frame.MDFS'></span>

<h3>Description</h3>

<p>as.data.frame S3 method implementation for MDFS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MDFS'
as.data.frame(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.data.frame.MDFS_+3A_x">x</code></td>
<td>
<p>an MDFS object</p>
</td></tr>
<tr><td><code id="as.data.frame.MDFS_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame
</p>

<hr>
<h2 id='ComputeInterestingTuples'>Interesting tuples</h2><span id='topic+ComputeInterestingTuples'></span>

<h3>Description</h3>

<p>Interesting tuples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ComputeInterestingTuples(
  data,
  decision = NULL,
  dimensions = 2,
  divisions = 1,
  discretizations = 1,
  seed = NULL,
  range = NULL,
  pc.xi = 0.25,
  ig.thr = 0,
  I.lower = NULL,
  interesting.vars = vector(mode = "integer"),
  require.all.vars = FALSE,
  return.matrix = FALSE,
  stat_mode = "MI",
  average = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ComputeInterestingTuples_+3A_data">data</code></td>
<td>
<p>input data where columns are variables and rows are observations (all numeric)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_decision">decision</code></td>
<td>
<p>decision variable as a binary sequence of length equal to number of observations</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_dimensions">dimensions</code></td>
<td>
<p>number of dimensions (a positive integer; 5 max)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions (from 1 to 15)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_discretizations">discretizations</code></td>
<td>
<p>number of discretizations</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_seed">seed</code></td>
<td>
<p>seed for PRNG used during discretizations (<code>NULL</code> for random)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_range">range</code></td>
<td>
<p>discretization range (from 0.0 to 1.0; <code>NULL</code> selects probable optimal number)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_pc.xi">pc.xi</code></td>
<td>
<p>parameter xi used to compute pseudocounts (the default is recommended not to be changed)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_ig.thr">ig.thr</code></td>
<td>
<p>IG threshold above which the tuple is interesting (0 and negative mean no filtering)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_i.lower">I.lower</code></td>
<td>
<p>IG values computed for lower dimension (1D for 2D, etc.)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_interesting.vars">interesting.vars</code></td>
<td>
<p>variables for which to check the IGs (none = all)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_require.all.vars">require.all.vars</code></td>
<td>
<p>boolean whether to require tuple to consist of only interesting.vars</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_return.matrix">return.matrix</code></td>
<td>
<p>boolean whether to return a matrix instead of a list (ignored if not using the optimised method variant)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_stat_mode">stat_mode</code></td>
<td>
<p>character, one of: &quot;MI&quot; (mutual information, the default; becomes information gain when <code>decision</code> is given), &quot;H&quot; (entropy; becomes conditional entropy when <code>decision</code> is given), &quot;VI&quot; (variation of information; becomes target information difference when <code>decision</code> is given); decides on the value computed</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuples_+3A_average">average</code></td>
<td>
<p>boolean whether to average over discretisations instead of maximising (the default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If running in 2D and no filtering is applied, this function is able to run in an
optimised fashion. It is recommended to avoid filtering in 2D if only it is
feasible.
</p>
<p>This function calculates what <code>stat_mode</code> dictates.
When <code>decision</code> is omitted, the <code>stat_mode</code> is calculated on the descriptive variables.
When <code>decision</code> is given, the <code>stat_mode</code> is calculated on the decision variable, conditional on the other variables.
Translate &quot;IG&quot; to that value in the rest of this function's description.
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> or <code><a href="base.html#topic+NULL">NULL</a></code> (following a warning) if no tuples are found.
</p>
<p>The following columns are present in the <code><a href="base.html#topic+data.frame">data.frame</a></code>:
</p>

<ul>
<li> <p><code>Var</code> &ndash; interesting variable index
</p>
</li>
<li> <p><code>Tuple.1, Tuple.2, ...</code> &ndash; corresponding tuple (up to <code>dimensions</code> columns)
</p>
</li>
<li> <p><code>IG</code> &ndash; information gain achieved by <code>var</code> in <code>Tuple.*</code>
</p>
</li></ul>

<p>Additionally attribute named <code>run.params</code> with run parameters is set on the result.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
ig.1d &lt;- ComputeMaxInfoGains(madelon$data, madelon$decision, dimensions = 1, divisions = 1,
                             range = 0, seed = 0)
ComputeInterestingTuples(madelon$data, madelon$decision, dimensions = 2, divisions = 1,
                         range = 0, seed = 0, ig.thr = 100, I.lower = ig.1d$IG)

</code></pre>

<hr>
<h2 id='ComputeInterestingTuplesDiscrete'>Interesting tuples (discrete)</h2><span id='topic+ComputeInterestingTuplesDiscrete'></span>

<h3>Description</h3>

<p>Interesting tuples (discrete)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ComputeInterestingTuplesDiscrete(
  data,
  decision = NULL,
  dimensions = 2,
  pc.xi = 0.25,
  ig.thr = 0,
  I.lower = NULL,
  interesting.vars = vector(mode = "integer"),
  require.all.vars = FALSE,
  return.matrix = FALSE,
  stat_mode = "MI"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_data">data</code></td>
<td>
<p>input data where columns are variables and rows are observations (all discrete with the same number of categories)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_decision">decision</code></td>
<td>
<p>decision variable as a binary sequence of length equal to number of observations</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_dimensions">dimensions</code></td>
<td>
<p>number of dimensions (a positive integer; 5 max)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_pc.xi">pc.xi</code></td>
<td>
<p>parameter xi used to compute pseudocounts (the default is recommended not to be changed)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_ig.thr">ig.thr</code></td>
<td>
<p>IG threshold above which the tuple is interesting (0 and negative mean no filtering)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_i.lower">I.lower</code></td>
<td>
<p>IG values computed for lower dimension (1D for 2D, etc.)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_interesting.vars">interesting.vars</code></td>
<td>
<p>variables for which to check the IGs (none = all)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_require.all.vars">require.all.vars</code></td>
<td>
<p>boolean whether to require tuple to consist of only interesting.vars</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_return.matrix">return.matrix</code></td>
<td>
<p>boolean whether to return a matrix instead of a list (ignored if not using the optimised method variant)</p>
</td></tr>
<tr><td><code id="ComputeInterestingTuplesDiscrete_+3A_stat_mode">stat_mode</code></td>
<td>
<p>character, one of: &quot;MI&quot; (mutual information, the default; becomes information gain when <code>decision</code> is given), &quot;H&quot; (entropy; becomes conditional entropy when <code>decision</code> is given), &quot;VI&quot; (variation of information; becomes target information difference when <code>decision</code> is given); decides on the value computed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If running in 2D and no filtering is applied, this function is able to run in an
optimised fashion. It is recommended to avoid filtering in 2D if only it is
feasible.
</p>
<p>This function calculates what <code>stat_mode</code> dictates.
When <code>decision</code> is omitted, the <code>stat_mode</code> is calculated on the descriptive variables.
When <code>decision</code> is given, the <code>stat_mode</code> is calculated on the decision variable, conditional on the other variables.
Translate &quot;IG&quot; to that value in the rest of this function's description.
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> or <code><a href="base.html#topic+NULL">NULL</a></code> (following a warning) if no tuples are found.
</p>
<p>The following columns are present in the <code><a href="base.html#topic+data.frame">data.frame</a></code>:
</p>

<ul>
<li> <p><code>Var</code> &ndash; interesting variable index
</p>
</li>
<li> <p><code>Tuple.1, Tuple.2, ...</code> &ndash; corresponding tuple (up to <code>dimensions</code> columns)
</p>
</li>
<li> <p><code>IG</code> &ndash; information gain achieved by <code>var</code> in <code>Tuple.*</code>
</p>
</li></ul>

<p>Additionally attribute named <code>run.params</code> with run parameters is set on the result.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
ig.1d &lt;- ComputeMaxInfoGainsDiscrete(madelon$data &gt; 500, madelon$decision, dimensions = 1)
ComputeInterestingTuplesDiscrete(madelon$data &gt; 500, madelon$decision, dimensions = 2,
                                 ig.thr = 100, I.lower = ig.1d$IG)

</code></pre>

<hr>
<h2 id='ComputeMaxInfoGains'>Max information gains</h2><span id='topic+ComputeMaxInfoGains'></span>

<h3>Description</h3>

<p>Max information gains
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ComputeMaxInfoGains(
  data,
  decision,
  contrast_data = NULL,
  dimensions = 1,
  divisions = 1,
  discretizations = 1,
  seed = NULL,
  range = NULL,
  pc.xi = 0.25,
  return.tuples = FALSE,
  interesting.vars = vector(mode = "integer"),
  require.all.vars = FALSE,
  use.CUDA = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ComputeMaxInfoGains_+3A_data">data</code></td>
<td>
<p>input data where columns are variables and rows are observations (all numeric)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_decision">decision</code></td>
<td>
<p>decision variable as a binary sequence of length equal to number of observations</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_contrast_data">contrast_data</code></td>
<td>
<p>the contrast counterpart of data, has to have the same number of observations - not supported with CUDA</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_dimensions">dimensions</code></td>
<td>
<p>number of dimensions (a positive integer; 5 max)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions (from 1 to 15; additionally limited by dimensions if using CUDA)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_discretizations">discretizations</code></td>
<td>
<p>number of discretizations</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_seed">seed</code></td>
<td>
<p>seed for PRNG used during discretizations (<code>NULL</code> for random)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_range">range</code></td>
<td>
<p>discretization range (from 0.0 to 1.0; <code>NULL</code> selects probable optimal number)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_pc.xi">pc.xi</code></td>
<td>
<p>parameter xi used to compute pseudocounts (the default is recommended not to be changed)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_return.tuples">return.tuples</code></td>
<td>
<p>whether to return tuples (and relevant discretization number) where max IG was observed (one tuple and relevant discretization number per variable) - not supported with CUDA nor in 1D</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_interesting.vars">interesting.vars</code></td>
<td>
<p>variables for which to check the IGs (none = all) - not supported with CUDA</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_require.all.vars">require.all.vars</code></td>
<td>
<p>boolean whether to require tuple to consist of only interesting.vars</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGains_+3A_use.cuda">use.CUDA</code></td>
<td>
<p>whether to use CUDA acceleration (must be compiled with CUDA)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> with the following columns:
</p>

<ul>
<li> <p><code>IG</code> &ndash; max information gain (of each variable)
</p>
</li>
<li> <p><code>Tuple.1, Tuple.2, ...</code> &ndash; corresponding tuple (up to <code>dimensions</code> columns, available only when <code>return.tuples == T</code>)
</p>
</li>
<li> <p><code>Discretization.nr</code> &ndash; corresponding discretization number (available only when <code>return.tuples == T</code>)
</p>
</li></ul>

<p>Additionally attribute named <code>run.params</code> with run parameters is set on the result.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
ComputeMaxInfoGains(madelon$data, madelon$decision, dimensions = 2, divisions = 1,
                    range = 0, seed = 0)

</code></pre>

<hr>
<h2 id='ComputeMaxInfoGainsDiscrete'>Max information gains (discrete)</h2><span id='topic+ComputeMaxInfoGainsDiscrete'></span>

<h3>Description</h3>

<p>Max information gains (discrete)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ComputeMaxInfoGainsDiscrete(
  data,
  decision,
  contrast_data = NULL,
  dimensions = 1,
  pc.xi = 0.25,
  return.tuples = FALSE,
  interesting.vars = vector(mode = "integer"),
  require.all.vars = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ComputeMaxInfoGainsDiscrete_+3A_data">data</code></td>
<td>
<p>input data where columns are variables and rows are observations (all discrete with the same number of categories)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGainsDiscrete_+3A_decision">decision</code></td>
<td>
<p>decision variable as a binary sequence of length equal to number of observations</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGainsDiscrete_+3A_contrast_data">contrast_data</code></td>
<td>
<p>the contrast counterpart of data, has to have the same number of observations</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGainsDiscrete_+3A_dimensions">dimensions</code></td>
<td>
<p>number of dimensions (a positive integer; 5 max)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGainsDiscrete_+3A_pc.xi">pc.xi</code></td>
<td>
<p>parameter xi used to compute pseudocounts (the default is recommended not to be changed)</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGainsDiscrete_+3A_return.tuples">return.tuples</code></td>
<td>
<p>whether to return tuples where max IG was observed (one tuple per variable) - not supported with CUDA nor in 1D</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGainsDiscrete_+3A_interesting.vars">interesting.vars</code></td>
<td>
<p>variables for which to check the IGs (none = all) - not supported with CUDA</p>
</td></tr>
<tr><td><code id="ComputeMaxInfoGainsDiscrete_+3A_require.all.vars">require.all.vars</code></td>
<td>
<p>boolean whether to require tuple to consist of only interesting.vars</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> with the following columns:
</p>

<ul>
<li> <p><code>IG</code> &ndash; max information gain (of each variable)
</p>
</li>
<li> <p><code>Tuple.1, Tuple.2, ...</code> &ndash; corresponding tuple (up to <code>dimensions</code> columns, available only when <code>return.tuples == T</code>)
</p>
</li>
<li> <p><code>Discretization.nr</code> &ndash; always 1 (for compatibility with the non-discrete function; available only when <code>return.tuples == T</code>)
</p>
</li></ul>

<p>Additionally attribute named <code>run.params</code> with run parameters is set on the result.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
ComputeMaxInfoGainsDiscrete(madelon$data &gt; 500, madelon$decision, dimensions = 2)

</code></pre>

<hr>
<h2 id='ComputePValue'>Compute p-values from information gains and return MDFS</h2><span id='topic+ComputePValue'></span>

<h3>Description</h3>

<p>Compute p-values from information gains and return MDFS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ComputePValue(
  IG,
  dimensions,
  divisions,
  response.divisions = 1,
  df = NULL,
  contrast.mask = NULL,
  ig.in.bits = TRUE,
  ig.doubled = FALSE,
  one.dim.mode = "exp",
  irr.vars.num = NULL,
  ign.low.ig.vars.num = NULL,
  min.irr.vars.num = NULL,
  max.ign.low.ig.vars.num = NULL,
  search.points = 8,
  level = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ComputePValue_+3A_ig">IG</code></td>
<td>
<p>max conditional information gains</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_dimensions">dimensions</code></td>
<td>
<p>number of dimensions</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_response.divisions">response.divisions</code></td>
<td>
<p>number of response divisions (i.e. categories-1)</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_df">df</code></td>
<td>
<p>vector of degrees of freedom for each variable (optional)</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_contrast.mask">contrast.mask</code></td>
<td>
<p>boolean mask on <code>IG</code> specifying which variables are contrast variables (or <code>NULL</code> if none, otherwise at least 3 variables must be marked)</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_ig.in.bits">ig.in.bits</code></td>
<td>
<p><code>TRUE</code> if input is in binary log (as opposed to natural log)</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_ig.doubled">ig.doubled</code></td>
<td>
<p><code>TRUE</code> if input is doubled (to follow the chi-squared distribution)</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_one.dim.mode">one.dim.mode</code></td>
<td>
<p><code>'exp'</code> for exponential distribution, <code>'lin'</code> for linear function of chi-squared or <code>'raw'</code> for raw chi-squared</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_irr.vars.num">irr.vars.num</code></td>
<td>
<p>if not NULL, number of irrelevant variables, specified by the user</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_ign.low.ig.vars.num">ign.low.ig.vars.num</code></td>
<td>
<p>if not NULL, number of ignored low IG variables, specified by the user</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_min.irr.vars.num">min.irr.vars.num</code></td>
<td>
<p>minimum number of irrelevant variables (<code>NULL</code> selects probable optimal number)</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_max.ign.low.ig.vars.num">max.ign.low.ig.vars.num</code></td>
<td>
<p>maximum number of ignored low IG variables (<code>NULL</code> selects probable optimal number)</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_search.points">search.points</code></td>
<td>
<p>number of points in search procedure for the optimal number of ignored variables</p>
</td></tr>
<tr><td><code id="ComputePValue_+3A_level">level</code></td>
<td>
<p>acceptable error level of goodness-of-fit one-sample Kolmogorov-Smirnov test (used only for warning)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> with class set to <code>MDFS</code>. Can be coerced back to <code>data.frame</code> using <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code>.
</p>
<p>The following columns are present:
</p>

<ul>
<li> <p><code>IG</code> &ndash; information gains (input copy)
</p>
</li>
<li> <p><code>chi.squared.p.value</code> &ndash; chi-squared p-values
</p>
</li>
<li> <p><code>p.value</code> &ndash; theoretical p-values
</p>
</li></ul>

<p>Additionally the following <code><a href="base.html#topic+attributes">attributes</a></code> are set:
</p>

<ul>
<li> <p><code>run.params</code> &ndash; run parameters
</p>
</li>
<li> <p><code>sq.dev</code> &ndash; vector of square deviations used to estimate the number of irrelevant variables
</p>
</li>
<li> <p><code>dist.param</code> &ndash; distribution parameter
</p>
</li>
<li> <p><code>err.param</code> &ndash; squared error of the distribution parameter
</p>
</li>
<li> <p><code>fit.p.value</code> &ndash; p-value of fit
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>ComputePValue(madelon$IG.2D, dimensions = 2, divisions = 1)
</code></pre>

<hr>
<h2 id='Discretize'>Discretize variable on demand</h2><span id='topic+Discretize'></span>

<h3>Description</h3>

<p>Discretize variable on demand
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Discretize(data, variable.idx, divisions, discretization.nr, seed, range)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Discretize_+3A_data">data</code></td>
<td>
<p>input data where columns are variables and rows are observations (all numeric)</p>
</td></tr>
<tr><td><code id="Discretize_+3A_variable.idx">variable.idx</code></td>
<td>
<p>variable index (as it appears in <code>data</code>)</p>
</td></tr>
<tr><td><code id="Discretize_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions</p>
</td></tr>
<tr><td><code id="Discretize_+3A_discretization.nr">discretization.nr</code></td>
<td>
<p>discretization number (positive integer)</p>
</td></tr>
<tr><td><code id="Discretize_+3A_seed">seed</code></td>
<td>
<p>seed for PRNG</p>
</td></tr>
<tr><td><code id="Discretize_+3A_range">range</code></td>
<td>
<p>discretization range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Discretized variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Discretize(madelon$data, 3, 1, 1, 0, 0.5)
</code></pre>

<hr>
<h2 id='GenContrastVariables'>Generate contrast variables from data</h2><span id='topic+GenContrastVariables'></span>

<h3>Description</h3>

<p>Generate contrast variables from data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GenContrastVariables(data, n.contrast = max(ncol(data), 30))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GenContrastVariables_+3A_data">data</code></td>
<td>
<p>data organized in matrix with separate variables in columns</p>
</td></tr>
<tr><td><code id="GenContrastVariables_+3A_n.contrast">n.contrast</code></td>
<td>
<p>number of constrast variables (defaults to max of 1/10 of variables number and 30)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following key names:
</p>

<ul>
<li> <p><code>indices</code> &ndash; vector of indices of input variables used to construct contrast variables
</p>
</li>
<li> <p><code>x</code> &ndash; data with constrast variables appended to it
</p>
</li>
<li> <p><code>mask</code> &ndash; vector of booleans making it easy to select just contrast variables
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>GenContrastVariables(madelon$data)
</code></pre>

<hr>
<h2 id='GetRange'>Get the recommended range for multiple discretisations</h2><span id='topic+GetRange'></span>

<h3>Description</h3>

<p>Get the recommended range for multiple discretisations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetRange(k = 3, n, dimensions, divisions = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetRange_+3A_k">k</code></td>
<td>
<p>the assumed minimum number of objects in a bucket (the default is the recommended value)</p>
</td></tr>
<tr><td><code id="GetRange_+3A_n">n</code></td>
<td>
<p>the total number of objects considered</p>
</td></tr>
<tr><td><code id="GetRange_+3A_dimensions">dimensions</code></td>
<td>
<p>the number of dimensions of analysis</p>
</td></tr>
<tr><td><code id="GetRange_+3A_divisions">divisions</code></td>
<td>
<p>the number of divisions of discretisations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The recommended range value (a floating point number).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>GetRange(n = 250, dimensions = 2)
</code></pre>

<hr>
<h2 id='madelon'>An artificial dataset called MADELON</h2><span id='topic+madelon'></span>

<h3>Description</h3>

<p>An artificial dataset containing data points grouped in 32 clusters placed
on the vertices of a five dimensional hypercube and randomly labeled 0/1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>madelon
</code></pre>


<h3>Format</h3>

<p>A list of two elements:
</p>

<dl>
<dt>data</dt><dd><p>2000 by 500 matrix of 2000 objects with 500 features</p>
</dd>
<dt>decision</dt><dd><p>vector of 2000 decisions (labels 0/1)</p>
</dd>
<dt>IG.2D</dt><dd><p>example 2D IG computed using <code>ComputeMaxInfoGains</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>The five dimensions constitute 5 informative features.
15 linear combinations of those features are added to form a set of 20
(redundant) informative features.
There are 480 distractor features called 'probes' having no predictive
power.
</p>
<p>Included is the original training set with label -1 changed to 0.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Madelon">https://archive.ics.uci.edu/ml/datasets/Madelon</a>
</p>

<hr>
<h2 id='MDFS'>Run end-to-end MDFS</h2><span id='topic+MDFS'></span>

<h3>Description</h3>

<p>Run end-to-end MDFS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MDFS(
  data,
  decision,
  n.contrast = max(ncol(data), 30),
  dimensions = 1,
  divisions = 1,
  discretizations = 1,
  range = NULL,
  pc.xi = 0.25,
  p.adjust.method = "holm",
  level = 0.05,
  seed = NULL,
  use.CUDA = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MDFS_+3A_data">data</code></td>
<td>
<p>input data where columns are variables and rows are observations (all numeric)</p>
</td></tr>
<tr><td><code id="MDFS_+3A_decision">decision</code></td>
<td>
<p>decision variable as a boolean vector of length equal to number of observations</p>
</td></tr>
<tr><td><code id="MDFS_+3A_n.contrast">n.contrast</code></td>
<td>
<p>number of constrast variables (defaults to max of 1/10 of variables number and 30)</p>
</td></tr>
<tr><td><code id="MDFS_+3A_dimensions">dimensions</code></td>
<td>
<p>number of dimensions (a positive integer; on CUDA limited to 2&ndash;5 range)</p>
</td></tr>
<tr><td><code id="MDFS_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions (from 1 to 15)</p>
</td></tr>
<tr><td><code id="MDFS_+3A_discretizations">discretizations</code></td>
<td>
<p>number of discretizations</p>
</td></tr>
<tr><td><code id="MDFS_+3A_range">range</code></td>
<td>
<p>discretization range (from 0.0 to 1.0; <code>NULL</code> selects probable optimal number)</p>
</td></tr>
<tr><td><code id="MDFS_+3A_pc.xi">pc.xi</code></td>
<td>
<p>parameter xi used to compute pseudocounts (the default is recommended not to be changed)</p>
</td></tr>
<tr><td><code id="MDFS_+3A_p.adjust.method">p.adjust.method</code></td>
<td>
<p>method as accepted by <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> (<code>"BY"</code> is recommended for FDR, see Details)</p>
</td></tr>
<tr><td><code id="MDFS_+3A_level">level</code></td>
<td>
<p>statistical significance level</p>
</td></tr>
<tr><td><code id="MDFS_+3A_seed">seed</code></td>
<td>
<p>seed for PRNG used during discretizations (<code>NULL</code> for random)</p>
</td></tr>
<tr><td><code id="MDFS_+3A_use.cuda">use.CUDA</code></td>
<td>
<p>whether to use CUDA acceleration (must be compiled with CUDA; NOTE: the CUDA version might provide a slightly lower sensitivity due to a lack of native support for <code>contrast_data</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In case of FDR control it is recommended to use Benjamini-Hochberg-Yekutieli p-value adjustment
method (<code>"BY"</code> in <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>) due to unknown dependencies between tests.
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list</a></code> with the following fields:
</p>

<ul>
<li> <p><code>contrast.indices</code> &ndash; indices of variables chosen to build contrast variables
</p>
</li>
<li> <p><code>contrast.variables</code> &ndash; built contrast variables
</p>
</li>
<li> <p><code>MIG.Result</code> &ndash; result of ComputeMaxInfoGains
</p>
</li>
<li> <p><code>MDFS</code> &ndash; result of ComputePValue (the MDFS object)
</p>
</li>
<li> <p><code>statistic</code> &ndash; vector of statistic's values (IGs) for corresponding variables
</p>
</li>
<li> <p><code>p.value</code> &ndash; vector of p-values for corresponding variables
</p>
</li>
<li> <p><code>adjusted.p.value</code> &ndash; vector of adjusted p-values for corresponding variables
</p>
</li>
<li> <p><code>relevant.variables</code> &ndash; vector of relevant variables indices
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
MDFS(madelon$data, madelon$decision, dimensions = 2, divisions = 1,
     range = 0, seed = 0)

</code></pre>

<hr>
<h2 id='mdfs_omp_set_num_threads'>Call omp_set_num_threads</h2><span id='topic+mdfs_omp_set_num_threads'></span>

<h3>Description</h3>

<p>Call omp_set_num_threads
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdfs_omp_set_num_threads(num_threads)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mdfs_omp_set_num_threads_+3A_num_threads">num_threads</code></td>
<td>
<p>input data where columns are variables and rows are observations (all numeric)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>

<hr>
<h2 id='plot.MDFS'>Plot MDFS details</h2><span id='topic+plot.MDFS'></span>

<h3>Description</h3>

<p>Plot MDFS details
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MDFS'
plot(x, plots = c("ig", "c", "p"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.MDFS_+3A_x">x</code></td>
<td>
<p>an MDFS object</p>
</td></tr>
<tr><td><code id="plot.MDFS_+3A_plots">plots</code></td>
<td>
<p>plots to plot (ig for max IG, c for chi-squared p-values, p for p-values)</p>
</td></tr>
<tr><td><code id="plot.MDFS_+3A_...">...</code></td>
<td>
<p>passed on to <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>

<hr>
<h2 id='RelevantVariables'>Find indices of relevant variables</h2><span id='topic+RelevantVariables'></span>

<h3>Description</h3>

<p>Find indices of relevant variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RelevantVariables(fs, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RelevantVariables_+3A_fs">fs</code></td>
<td>
<p>feature selector</p>
</td></tr>
<tr><td><code id="RelevantVariables_+3A_...">...</code></td>
<td>
<p>arguments passed to methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>indices of important variables
</p>

<hr>
<h2 id='RelevantVariables.MDFS'>Find indices of relevant variables from MDFS</h2><span id='topic+RelevantVariables.MDFS'></span>

<h3>Description</h3>

<p>Find indices of relevant variables from MDFS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MDFS'
RelevantVariables(fs, level = 0.05, p.adjust.method = "holm", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RelevantVariables.MDFS_+3A_fs">fs</code></td>
<td>
<p>an MDFS object</p>
</td></tr>
<tr><td><code id="RelevantVariables.MDFS_+3A_level">level</code></td>
<td>
<p>statistical significance level</p>
</td></tr>
<tr><td><code id="RelevantVariables.MDFS_+3A_p.adjust.method">p.adjust.method</code></td>
<td>
<p>method as accepted by <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> (<code>"BY"</code> is recommended for FDR, see Details)</p>
</td></tr>
<tr><td><code id="RelevantVariables.MDFS_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In case of FDR control it is recommended to use Benjamini-Hochberg-Yekutieli p-value adjustment
method (<code>"BY"</code> in <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>) due to unknown dependencies between tests.
</p>


<h3>Value</h3>

<p>indices of relevant variables
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
