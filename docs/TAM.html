<!DOCTYPE html><html><head><title>Help for package TAM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TAM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#anova-logLik'>
<p>Likelihood Ratio Test for Model Comparisons and Log-Likelihood Value</p></a></li>
<li><a href='#cfa.extract.itempars'>
<p>Extracting Item Parameters from a Fitted <code>cfa</code> Object in <span class="pkg">lavaan</span></p></a></li>
<li><a href='#data.cqc'>
<p>More Datasets and Examples (Similar to ConQuest Examples)</p></a></li>
<li><a href='#data.ctest'>
<p>Some C-Test Datasets</p></a></li>
<li><a href='#data.examples'>
<p>Datasets <code>data.ex</code> in <span class="pkg">TAM</span> Package</p></a></li>
<li><a href='#data.fims.Aus.Jpn.scored'>
<p>Dataset FIMS Study with Responses of Australian and Japanese Students</p></a></li>
<li><a href='#data.geiser'>
<p>Dataset from Geiser et al. (2006)</p></a></li>
<li><a href='#data.gpcm'>
<p>Dataset with Ordered Indicators</p></a></li>
<li><a href='#data.janssen'>
<p>Dataset from Janssen and Geiser (2010)</p></a></li>
<li><a href='#data.mc'>
<p>Dataset with Raw and Scored Responses from Multiple Choice Items</p></a></li>
<li><a href='#data.numeracy'>
<p>Dataset Numeracy</p></a></li>
<li><a href='#data.sim.mfr'>
<p>Simulated Multifaceted Data</p></a></li>
<li><a href='#data.sim.rasch'>
<p>Simulated Rasch data</p></a></li>
<li><a href='#data.timssAusTwn'>
<p>Dataset TIMSS 2011 of Australian and Taiwanese Students</p></a></li>
<li><a href='#DescribeBy'>
<p>S3 Method for Descriptive Statistics of Objects</p></a></li>
<li><a href='#designMatrices'>
<p>Generation of Design Matrices</p></a></li>
<li><a href='#doparse'>
<p>Parsing a String with <code>DO</code> Statements</p></a></li>
<li><a href='#IRT.cv'>
<p>Cross-Validation of a Fitted IRT Model</p></a></li>
<li><a href='#IRT.data.tam'>
<p>Extracting Item Response Dataset</p></a></li>
<li><a href='#IRT.drawPV'>
<p>Function for Drawing Plausible Values</p></a></li>
<li><a href='#IRT.expectedCounts'>
<p>Extracting Expected Counts</p></a></li>
<li><a href='#IRT.factor.scores'>
<p>Extracting Factor Scores in <span class="pkg">TAM</span></p></a></li>
<li><a href='#IRT.frequencies.tam'>
<p>Observed and Expected Frequencies for Univariate and Bivariate Distributions</p></a></li>
<li><a href='#IRT.informationCurves'>
<p>Item and Test Information Curve</p></a></li>
<li><a href='#IRT.irfprob'>
<p>Extracting Item Response Functions</p></a></li>
<li><a href='#IRT.itemfit.tam'>
<p>RMSD Item Fit Statistics for <span class="pkg">TAM</span> Objects</p></a></li>
<li><a href='#IRT.likelihood'>
<p>Extracting Individual Likelihood and Individual Posterior</p></a></li>
<li><a href='#IRT.linearCFA'>
<p>Linear Approximation of a Confirmatory Factor Analysis</p></a></li>
<li><a href='#IRT.residuals'>
<p>Residuals in an IRT Model</p></a></li>
<li><a href='#IRT.simulate'>
<p>Simulating Item Response Models</p></a></li>
<li><a href='#IRT.threshold'>
<p>Thurstonian Thresholds and Wright Map for Item Response Models</p></a></li>
<li><a href='#IRT.truescore'>
<p>Converts a <code class="reqn">\theta</code> Score into a True Score <code class="reqn">\tau ( \theta)</code></p></a></li>
<li><a href='#IRT.WrightMap'>
<p>Wright Map for Item Response Models by Using the <span class="pkg">WrightMap</span> Package</p></a></li>
<li><a href='#IRTLikelihood.cfa'>
<p>Individual Likelihood for Confirmatory Factor Analysis</p></a></li>
<li><a href='#IRTLikelihood.ctt'>
<p>Computes Individual Likelihood from Classical Test Theory Estimates</p></a></li>
<li><a href='#lavaanify.IRT'>
<p>Slight Extension of the <code>lavaan</code> Syntax, with Focus on Item Response Models</p></a></li>
<li><a href='#msq.itemfit'>
<p>Mean Squared Residual Based Item Fit Statistics (Infit, Outfit)</p></a></li>
<li><a href='#plot.tam'>
<p>Plot Function for Unidimensional Item Response Models</p></a></li>
<li><a href='#plotDevianceTAM'>
<p>Deviance Plot for <span class="pkg">TAM</span> Objects</p></a></li>
<li><a href='#predict'>
<p>Expected Values and Predicted Probabilities for Fitted <span class="pkg">TAM</span> Models</p></a></li>
<li><a href='#Scale'>
<p>S3 Method for Standardizations and Transformations of Variables</p></a></li>
<li><a href='#tam_downcode'>
<p>Downcoding an Item Response Dataset</p></a></li>
<li><a href='#tam_irf_3pl'>
<p>Item Response Function for the 3PL Model</p></a></li>
<li><a href='#tam_NA_pattern'>
<p>Missing Data Patterns</p></a></li>
<li><a href='#TAM-defunct'><p>Defunct <span class="pkg">TAM</span> Functions</p></a></li>
<li><a href='#TAM-package'>
<p>Test Analysis Modules</p></a></li>
<li><a href='#TAM-utilities'><p>Utility Functions in <span class="pkg">TAM</span></p></a></li>
<li><a href='#tam.ctt'>
<p>Classical Test Theory Based Statistics and Plots</p></a></li>
<li><a href='#tam.fa'>
<p>Bifactor Model and Exploratory Factor Analysis</p></a></li>
<li><a href='#tam.fit'>
<p>Item Infit and Outfit Statistic</p></a></li>
<li><a href='#tam.jml'>
<p>Joint Maximum Likelihood Estimation</p></a></li>
<li><a href='#tam.latreg'>
<p>Latent Regression Model</p></a></li>
<li><a href='#tam.linking'>
<p>Linking of Fitted Unidimensional Item Response Models in <span class="pkg">TAM</span></p></a></li>
<li><a href='#tam.mml'>
<p>Test Analysis Modules: Marginal Maximum Likelihood Estimation</p></a></li>
<li><a href='#tam.mml.3pl'>
<p>3PL Structured Item Response Model in <span class="pkg">TAM</span></p></a></li>
<li><a href='#tam.modelfit'>
<p>Model Fit Statistics in <span class="pkg">TAM</span></p></a></li>
<li><a href='#tam.np'>
<p>Unidimensional Non- and Semiparametric Item Response Model</p></a></li>
<li><a href='#tam.personfit'>
<p>Person Outfit and Infit Statistics</p></a></li>
<li><a href='#tam.pv'>
<p>Plausible Value Imputation</p></a></li>
<li><a href='#tam.se'>
<p>Standard Error Estimation</p></a></li>
<li><a href='#tam.threshold'>
<p>Calculation of Thurstonian Thresholds</p></a></li>
<li><a href='#tam.wle'>
<p>Weighted Likelihood Estimation and Maximum Likelihood Estimation of</p>
Person Parameters</a></li>
<li><a href='#tamaan'>
<p>Wrapper Function for <span class="pkg">TAM</span> Language</p></a></li>
<li><a href='#tamaanify'>
<p>Function for Parsing <span class="pkg">TAM</span> Input</p></a></li>
<li><a href='#tampv2datalist'>
<p>Conversion of Plausible Value Object into Datalist</p></a></li>
<li><a href='#weighted_Stats'>
<p>Descriptive Statistics for Weighted Data</p></a></li>
<li><a href='#WLErel'>
<p>Reliability Estimation in <span class="pkg">TAM</span></p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Test Analysis Modules</td>
</tr>
<tr>
<td>Version:</td>
<td>4.2-21</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-19 18:52:08</td>
</tr>
<tr>
<td>Author:</td>
<td>
    Alexander Robitzsch [aut,cre] (&lt;https://orcid.org/0000-0002-8226-3132&gt;),
    Thomas Kiefer [aut], 
    Margaret Wu [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexander Robitzsch &lt;robitzsch@ipn.uni-kiel.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Includes marginal maximum likelihood estimation and joint maximum
    likelihood estimation for unidimensional and multidimensional 
    item response models. The package functionality covers the 
    Rasch model, 2PL model, 3PL model, generalized partial credit model, 
    multi-faceted Rasch model, nominal item response model, 
    structured latent class model, mixture distribution IRT models, 
    and located latent class models. Latent regression models and 
    plausible value imputation are also supported. For details see
    Adams, Wilson and Wang, 1997 &lt;<a href="https://doi.org/10.1177%2F0146621697211001">doi:10.1177/0146621697211001</a>&gt;,
    Adams, Wilson and Wu, 1997 &lt;<a href="https://doi.org/10.3102%2F10769986022001047">doi:10.3102/10769986022001047</a>&gt;,
    Formann, 1982 &lt;<a href="https://doi.org/10.1002%2Fbimj.4710240209">doi:10.1002/bimj.4710240209</a>&gt;,
    Formann, 1992 &lt;<a href="https://doi.org/10.1080%2F01621459.1992.10475229">doi:10.1080/01621459.1992.10475229</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.1), CDM (&ge; 6.4-19)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, methods, Rcpp, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>coda, GPArotation, grDevices, lattice, lavaan, MASS,
miceadds, mvtnorm, plyr, psych, sfsmisc, splines, WrightMap</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Enhances:</td>
<td>LSAmitR</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.edmeasurementsurveys.com/TAM/Tutorials/">http://www.edmeasurementsurveys.com/TAM/Tutorials/</a>,
<a href="https://github.com/alexanderrobitzsch/TAM">https://github.com/alexanderrobitzsch/TAM</a>,
<a href="https://sites.google.com/view/alexander-robitzsch/software">https://sites.google.com/view/alexander-robitzsch/software</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-19 17:58:11 UTC; sunpn563</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-19 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='anova-logLik'>
Likelihood Ratio Test for Model Comparisons and Log-Likelihood Value
</h2><span id='topic+anova.tam'></span><span id='topic+anova.tam.mml'></span><span id='topic+anova.tam.mml.3pl'></span><span id='topic+anova.tamaan'></span><span id='topic+anova.tam.latreg'></span><span id='topic+anova.tam.np'></span><span id='topic+logLik.tam'></span><span id='topic+logLik.tam.mml'></span><span id='topic+logLik.tam.mml.3pl'></span><span id='topic+logLik.tamaan'></span><span id='topic+logLik.tam.latreg'></span><span id='topic+logLik.tam.np'></span>

<h3>Description</h3>

<p>The <code>anova</code> function compares two models estimated of class <code><a href="#topic+tam">tam</a></code>,
<code><a href="#topic+tam.mml">tam.mml</a></code> or <code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code> using a likelihood ratio test.
The <code>logLik</code> function extracts the value of the log-Likelihood.
</p>
<p>The function can be applied for values of <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.2pl">tam.mml.2pl</a></code>, <code><a href="#topic+tam.mml.mfr">tam.mml.mfr</a></code>, <code><a href="#topic+tam.fa">tam.fa</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code>, <code><a href="#topic+tam.latreg">tam.latreg</a></code> or <code><a href="#topic+tamaan">tamaan</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam'
anova(object, ...)
## S3 method for class 'tam'
logLik(object, ...)

## S3 method for class 'tam.mml'
anova(object, ...)
## S3 method for class 'tam.mml'
logLik(object, ...)

## S3 method for class 'tam.mml.3pl'
anova(object, ...)
## S3 method for class 'tam.mml.3pl'
logLik(object, ...)

## S3 method for class 'tamaan'
anova(object, ...)
## S3 method for class 'tamaan'
logLik(object, ...)

## S3 method for class 'tam.latreg'
anova(object, ...)
## S3 method for class 'tam.latreg'
logLik(object, ...)

## S3 method for class 'tam.np'
anova(object, ...)
## S3 method for class 'tam.np'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova-logLik_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam">tam</a></code>, <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code>, <code><a href="#topic+tam.latreg">tam.latreg</a></code>, <code><a href="#topic+tam.np">tam.np</a></code>,
or <code><a href="#topic+tamaan">tamaan</a></code>. Note that for <code>anova</code> two objects
(fitted models) must be provided.
</p>
</td></tr>
<tr><td><code id="anova-logLik_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the likelihood ratio test statistic and
information criteria.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Dichotomous data sim.rasch - 1PL vs. 2PL model
#############################################################################

data(data.sim.rasch)
# 1PL estimation
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
logLik(mod1)
# 2PL estimation
mod2 &lt;- TAM::tam.mml.2pl(resp=data.sim.rasch, irtmodel="2PL")
logLik(mod2)
# Model comparison
anova( mod1, mod2 )
  ##     Model   loglike Deviance Npars      AIC      BIC    Chisq df       p
  ##   1  mod1 -42077.88 84155.77    41 84278.77 84467.40 54.05078 39 0.05508
  ##   2  mod2 -42050.86 84101.72    80 84341.72 84709.79       NA NA      NA

## Not run: 
#############################################################################
# EXAMPLE 2: Dataset reading (sirt package): 1- vs. 2-dimensional model
#############################################################################

data(data.read, package="sirt")

# 1-dimensional model
mod1 &lt;- TAM::tam.mml.2pl(resp=data.read )
# 2-dimensional model
mod2 &lt;- TAM::tam.fa(resp=data.read, irtmodel="efa", nfactors=2,
             control=list(maxiter=150) )
# Model comparison
anova( mod1, mod2 )
  ##       Model   loglike Deviance Npars      AIC      BIC    Chisq df  p
  ##   1    mod1 -1954.888 3909.777    24 3957.777 4048.809 76.66491 11  0
  ##   2    mod2 -1916.556 3833.112    35 3903.112 4035.867       NA NA NA

## End(Not run)
</code></pre>

<hr>
<h2 id='cfa.extract.itempars'>
Extracting Item Parameters from a Fitted <code>cfa</code> Object in <span class="pkg">lavaan</span>
</h2><span id='topic+cfa.extract.itempars'></span>

<h3>Description</h3>

<p>This function extract item parameters from a fitted
<code><a href="lavaan.html#topic+cfa">lavaan::cfa</a></code> object in <span class="pkg">lavaan</span>. It
extract item loadings, item intercepts and the mean
and covariance matrix of latent variables in a
confirmatory factor analysis model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cfa.extract.itempars(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cfa.extract.itempars_+3A_object">object</code></td>
<td>

<p>Fitted <code>cfa</code> object
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with following entries
</p>
<table>
<tr><td><code>L</code></td>
<td>
<p>Matrix of item loadings</p>
</td></tr>
<tr><td><code>nu</code></td>
<td>
<p>Vector of item intercepts</p>
</td></tr>
<tr><td><code>psi</code></td>
<td>
<p>Residual covariance matrix</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>Covariance matrix of latent variables</p>
</td></tr>
<tr><td><code>nu</code></td>
<td>
<p>Vector of means of latent variables</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Further values</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>See <code><a href="#topic+IRTLikelihood.cfa">IRTLikelihood.cfa</a></code> for extracting the
individual likelihood from fitted confirmatory
factor analyses.
</p>
<p><code><a href="lavaan.html#topic+cfa">lavaan::cfa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: CFA data.Students
#############################################################################

library(lavaan)
library(CDM)

data(data.Students, package="CDM")
dat &lt;- data.Students

dat1 &lt;- dat[, paste0( "mj", 1:4 ) ]

#*** Model 1: Unidimensional model scale mj
lavmodel &lt;- "
   mj=~ mj1 + mj2 + mj3 + mj4
   mj ~~ mj
     "
mod1 &lt;- lavaan::cfa( lavmodel, data=dat1, std.lv=TRUE )
summary(mod1, standardized=TRUE, rsquare=TRUE )
# extract parameters
res1 &lt;- TAM::cfa.extract.itempars( mod1 )

## Not run: 
#*** Model 2: Scale mj - explicit modelling of item intercepts
lavmodel &lt;- "
   mj=~ mj1 + mj2 + mj3 + mj4
   mj ~~ mj
   mj1 ~ 1
     "
mod2 &lt;- lavaan::cfa( lavmodel, data=dat1, std.lv=TRUE )
summary(mod2, standardized=TRUE, rsquare=TRUE )
res2 &lt;- TAM::cfa.extract.itempars( mod2 )

#*** Model 3: Tau-parallel measurements scale mj
lavmodel &lt;- "
   mj=~ a*mj1 + a*mj2 + a*mj3 + a*mj4
   mj ~~ 1*mj
   mj1 ~ b*1
   mj2 ~ b*1
   mj3 ~ b*1
   mj4 ~ b*1
     "
mod3 &lt;- lavaan::cfa( lavmodel, data=dat1, std.lv=TRUE )
summary(mod3, standardized=TRUE, rsquare=TRUE )
res3 &lt;- TAM::cfa.extract.itempars( mod3 )

#*** Model 4: Two-dimensional CFA with scales mj and sc
dat2 &lt;- dat[, c(paste0("mj",1:4), paste0("sc",1:4)) ]
# lavaan model with shortage "__" operator
lavmodel &lt;- "
   mj=~ mj1__mj4
   sc=~ sc1__sc4
   mj ~~ sc
   mj ~~ 1*mj
   sc ~~ 1*sc
     "
lavmodel &lt;- TAM::lavaanify.IRT( lavmodel, data=dat2 )$lavaan.syntax
cat(lavmodel)
mod4 &lt;- lavaan::cfa( lavmodel, data=dat2, std.lv=TRUE )
summary(mod4, standardized=TRUE, rsquare=TRUE )
res4 &lt;- TAM::cfa.extract.itempars( mod4 )

## End(Not run)
</code></pre>

<hr>
<h2 id='data.cqc'>
More Datasets and Examples (Similar to ConQuest Examples)
</h2><span id='topic+data.cqc01'></span><span id='topic+data.cqc02'></span><span id='topic+data.cqc03'></span><span id='topic+data.cqc04'></span><span id='topic+data.cqc05'></span>

<h3>Description</h3>

<p>Datasets and examples similar to the ones in the ConQuest manual
(Wu, Adams, Wilson, &amp; Haldane, 2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.cqc01)
data(data.cqc02)
data(data.cqc03)
data(data.cqc04)
data(data.cqc05)
</code></pre>


<h3>Format</h3>


<ul>
<li> <p><code>data.cqc01</code> contains 512 persons on
12 dichotomous items of following format
</p>
<p><code>'data.frame':   512 obs. of  12 variables:</code> <br />
<code> $ BSMMA01: int  1 1 0 1 1 1 1 1 0 0 ...</code> <br />
<code> $ BSMMA02: int  1 0 1 1 0 1 1 1 0 0 ...</code> <br />
<code> $ BSMMA03: int  1 1 0 1 1 1 1 1 1 0 ...</code> <br />
<code> [...]</code> <br />
<code> $ BSMSA12: int  0 0 0 0 1 0 1 1 0 0 ...</code> <br />
</p>
</li>
<li> <p><code>data.cqc02</code> contains 431 persons on 8 polytomous
variables of following format
</p>
<p><code>'data.frame':   431 obs. of  8 variables:</code> <br />
<code> $ It1: int  1 1 2 0 2 1 2 2 2 1 ...</code> <br />
<code> $ It2: int  3 0 1 2 2 3 2 2 1 1 ...</code> <br />
<code> $ It3: int  1 1 1 0 1 1 0 0 1 0 ...</code> <br />
<code> [...]</code> <br />
<code> $ It8: int  3 1 0 0 3 1 3 0 3 0 ...</code> <br />
</p>
</li>
<li> <p><code>data.cqc03</code> contains 11200 observations for
5600 persons, 16 raters and 2 items (<code>crit1</code> and <code>crit2</code>)
</p>
<p><code>'data.frame':   11200 obs. of  4 variables:</code> <br />
<code> $ pid  : num  10001 10001 10002 10002 10003 ...</code> <br />
<code> $ rater: chr  "R11" "R12" "R13" "R14" ...</code> <br />
<code> $ crit1: int  2 2 2 1 3 2 2 1 1 1 ...</code> <br />
<code> $ crit2: int  3 3 2 1 2 2 2 2 2 1 ...</code> <br />
</p>
</li>
<li> <p><code>data.cqc04</code> contains 1452 observations for 363 persons,
4 raters, 4 topics and 5 items (<code>spe</code>, <code>coh</code>, <code>str</code>,
<code>gra</code>,  <code>con</code>)
</p>
<p><code>'data.frame':   1452 obs. of  8 variables:</code> <br />
<code> $ pid  : num  10010 10010 10010 10010 10016 ...</code> <br />
<code> $ rater: chr  "BE" "CO" "BE" "CO" ...</code> <br />
<code> $ topic: chr  "Spor" "Spor" "Spor" "Spor" ...</code> <br />
<code> $ spe  : int  2 0 2 1 3 3 3 3 3 2 ...</code> <br />
<code> $ coh  : int  1 1 2 0 3 3 3 3 3 3 ...</code> <br />
<code> $ str  : int  0 1 3 0 3 2 3 2 3 0 ...</code> <br />
<code> $ gra  : int  0 0 2 0 3 3 3 3 2 1 ...</code> <br />
<code> $ con  : int  0 0 0 0 3 1 2 2 3 0 ...</code> <br />
</p>
</li>
<li> <p><code>data.cqc05</code> contains 1500 persons,
3 covariates and 157 items.
</p>
<p><code>'data.frame':   1500 obs. of  160 variables:</code> <br />
<code> $ gender: int  1 0 1 0 0 0 0 1 0 1 ...</code> <br />
<code> $ level : int  0 1 1 0 0 0 1 0 1 1 ...</code> <br />
<code> $ gbyl  : int  0 0 1 0 0 0 0 0 0 1 ...</code> <br />
<code> $ A001  : num  0 0 0 1 0 1 1 1 0 1 ...</code> <br />
<code> $ A002  : num  1 1 0 1 1 1 1 1 1 0 ...</code> <br />
<code> $ A003  : num  0 0 0 0 1 1 1 0 0 1 ...</code> <br />
<code>[...]</code> <br />
</p>
</li></ul>



<h3>References</h3>

<p>Wu, M. L., Adams, R. J., Wilson, M. R. &amp; Haldane, S. (2007).
<em>ACER ConQuest Version 2.0</em>. Mulgrave.
https://shop.acer.edu.au/acer-shop/group/CON3.
</p>


<h3>See Also</h3>

<p>See the <code>sirt::R2conquest</code> function
for running ConQuest software from within <span class="rlang"><b>R</b></span>.
</p>
<p>See the <span class="pkg"><a href="WrightMap.html#topic+WrightMap">WrightMap</a></span> package for functions
connected to reading ConQuest files and creating Wright maps.
ConQuest output files can be read into <span class="rlang"><b>R</b></span> with the help of
the <code><a href="WrightMap.html#topic+CQmodel">WrightMap::CQmodel</a></code> function.
See also the <code><a href="#topic+IRT.WrightMap">IRT.WrightMap</a></code> function in <span class="pkg">TAM</span>.
</p>
<p>See also the <span class="pkg">eat</span> package (<a href="https://r-forge.r-project.org/projects/eat/">https://r-forge.r-project.org/projects/eat/</a>)
for elaborate functionality for communication of ConQuest with <span class="rlang"><b>R</b></span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

library(sirt)
library(WrightMap)
# In the following, ConQuest will also be used for estimation.
path.conquest &lt;- "C:/Conquest"             # path of the ConQuest console.exe
setwd( "p:/my_files/ConQuest_analyses" )  # working directory

#############################################################################
# EXAMPLE 01: Rasch model data.cqc01
#############################################################################

data(data.cqc01)
dat &lt;- data.cqc01

#********************************************
#*** Model 01: Estimate Rasch model
mod01 &lt;- TAM::tam.mml(dat)
summary(mod01)

#------- ConQuest

# estimate model
cmod01 &lt;- sirt::R2conquest( dat, name="mod01", path.conquest=path.conquest)
summary(cmod01)   # summary output
# read shw file with some terms
shw01a &lt;- sirt::read.show( "mod01.shw" )
cmod01$shw.itemparameter
# read person item maps
pi01a &lt;- sirt::read.pimap( "mod01.shw" )
cmod01$shw.pimap
# read plausible values (npv=10 plausible values)
pv01a &lt;- sirt::read.pv(pvfile="mod01.pv", npv=10)
cmod01$person

# read ConQuest model
res01a &lt;- WrightMap::CQmodel(p.est="mod01.wle", show="mod01.shw", p.type="WLE" )
print(res01a)
# plot item fit
WrightMap::fitgraph(res01a)
# Wright map
plot(res01a, label.items.srt=90 )

#############################################################################
# EXAMPLE 02: Partial credit model and rating scale model data.cqc02
#############################################################################

data(data.cqc02)
dat &lt;- data.cqc02

#********************************************
# Model 02a: Partial credit model in ConQuest parametrization 'item+item*step'
mod02a &lt;- TAM::tam.mml( dat, irtmodel="PCM2" )
summary(mod02a, file="mod02a")
fit02a &lt;- TAM::tam.fit(mod02a)
summary(fit02a)

#--- ConQuest
# estimate model
maxK &lt;- max( dat, na.rm=TRUE )
cmod02a &lt;- sirt::R2conquest( dat, itemcodes=0:maxK, model="item+item*step",
               name="mod02a", path.conquest=path.conquest)
summary(cmod02a)   # summary output

# read ConQuest model
res02a &lt;- WrightMap::CQmodel(p.est="mod02a.wle", show="mod02a.shw", p.type="WLE" )
print(res02a)
# Wright map
plot(res02a, label.items.srt=90 )
plot(res02a, item.table="item")

#********************************************
# Model 02b: Rating scale model
mod02b &lt;- TAM::tam.mml( dat, irtmodel="RSM" )
summary( mod02b )

#############################################################################
# EXAMPLE 03: Faceted Rasch model for rating data data.cqc03
#############################################################################

data(data.cqc03)
# select items
resp &lt;- data.cqc03[, c("crit1","crit2") ]

#********************************************
# Model 03a: 'item+step+rater'
mod03a &lt;- TAM::tam.mml.mfr( resp, facets=data.cqc03[,"rater",drop=FALSE],
            formulaA=~ item+step+rater, pid=data.cqc03$pid )
summary( mod03a )

#--- ConQuest
X &lt;- data.cqc03[,"rater",drop=FALSE]
X$rater &lt;- as.numeric(substring( X$rater, 2 )) # convert 'rater' in numeric format
maxK &lt;- max( resp, na.rm=TRUE)
cmod03a &lt;- sirt::R2conquest( resp,  X=X, regression="",  model="item+step+rater",
             name="mod03a", path.conquest=path.conquest, set.constraints="cases" )
summary(cmod03a)   # summary output

# read ConQuest model
res03a &lt;- WrightMap::CQmodel(p.est="mod03a.wle", show="mod03a.shw", p.type="WLE" )
print(res03a)
# Wright map
plot(res03a)

#********************************************
# Model 03b: 'item:step+rater'
mod03b &lt;- TAM::tam.mml.mfr( resp, facets=data.cqc03[,"rater",drop=FALSE],
            formulaA=~ item + item:step+rater, pid=data.cqc03$pid )
summary( mod03b )

#********************************************
# Model 03c: 'step+rater' for first item 'crit1'
# Restructuring the data is necessary.
# Define raters as items in the new dataset 'dat1'.
persons &lt;- unique( data.cqc03$pid )
raters &lt;- unique( data.cqc03$rater )
dat1 &lt;- matrix( NA, nrow=length(persons), ncol=length(raters) + 1 )
dat1 &lt;- as.data.frame(dat1)
colnames(dat1) &lt;- c("pid", raters )
dat1$pid &lt;- persons
for (rr in raters){
    dat1.rr &lt;- data.cqc03[ data.cqc03$rater==rr, ]
    dat1[ match(dat1.rr$pid, persons),rr] &lt;- dat1.rr$crit1
        }
  ##   &gt; head(dat1)
  ##       pid R11 R12 R13 R14 R15 R16 R17 R18 R19 R20 R21 R22 R23 R24 R25 R26
  ##   1 10001   2   2  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
  ##   2 10002  NA  NA   2   1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
  ##   3 10003  NA  NA   3   2  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
  ##   4 10004  NA  NA   2   1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
  ##   5 10005  NA  NA   1   1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
  ##   6 10006  NA  NA   1   1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
# estimate model 03c
mod03c &lt;- TAM::tam.mml( dat1[,-1], pid=dat1$pid )
summary( mod03c )

#############################################################################
# EXAMPLE 04: Faceted Rasch model for rating data data.cqc04
#############################################################################

data(data.cqc04)
resp &lt;- data.cqc04[,4:8]
facets &lt;- data.cqc04[, c("rater", "topic") ]

#********************************************
# Model 04a: 'item*step+rater+topic'
formulaA &lt;- ~ item*step + rater + topic
mod04a &lt;- TAM::tam.mml.mfr( resp, facets=facets,
            formulaA=formulaA, pid=data.cqc04$pid )
summary( mod04a )

#********************************************
# Model 04b: 'item*step+rater+topic+item*rater+item*topic'
formulaA &lt;- ~ item*step + rater + topic + item*rater + item*topic
mod04b &lt;- TAM::tam.mml.mfr( resp, facets=facets,
            formulaA=formulaA, pid=data.cqc04$pid )
summary( mod04b )

#********************************************
# Model 04c: 'item*step' with fixing rater and topic parameters to zero
formulaA &lt;- ~ item*step + rater + topic
mod04c0 &lt;- TAM::tam.mml.mfr( resp, facets=facets,
            formulaA=formulaA, pid=data.cqc04$pid, control=list(maxiter=4) )
summary( mod04c0 )
# fix rater and topic parameter to zero
xsi.est &lt;- mod04c0$xsi
xsi.fixed &lt;- cbind( seq(1,nrow(xsi.est)), xsi.est$xsi )
rownames(xsi.fixed) &lt;- rownames(xsi.est)
xsi.fixed &lt;- xsi.fixed[ c(8:13),]
xsi.fixed[,2] &lt;- 0
  ##   &gt; xsi.fixed
  ##             [,1] [,2]
  ##   raterAM      8    0
  ##   raterBE      9    0
  ##   raterCO     10    0
  ##   topicFami   11    0
  ##   topicScho   12    0
  ##   topicSpor   13    0
mod04c1 &lt;- TAM::tam.mml.mfr( resp, facets=facets,
             formulaA=formulaA, pid=data.cqc04$pid, xsi.fixed=xsi.fixed )
summary( mod04c1 )

#############################################################################
# EXAMPLE 05: Partial credit model with latent regression and
#             plausible value imputation
#############################################################################

data(data.cqc05)
resp &lt;- data.cqc05[, -c(1:3) ] # select item responses

#********************************************
# Model 05a: Partial credit model
mod05a &lt;-tam.mml(resp=resp, irtmodel="PCM2" )

#********************************************
# Model 05b: Partial credit model with latent regressors
mod05b &lt;-tam.mml(resp=resp, irtmodel="PCM2",  Y=data.cqc05[,1:3] )
# Plausible value imputation
pvmod05b &lt;- TAM::tam.pv( mod05b )

## End(Not run)
</code></pre>

<hr>
<h2 id='data.ctest'>
Some C-Test Datasets
</h2><span id='topic+data.ctest'></span><span id='topic+data.ctest1'></span><span id='topic+data.ctest2'></span>

<h3>Description</h3>

<p>Some C-Test datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.ctest1)
data(data.ctest2)
</code></pre>


<h3>Format</h3>


<ul>
<li><p> The dataset <code>data.ctest1</code> contains item responses of C-tests
at two time points. The format is
</p>
<p><code>'data.frame':   1675 obs. of  42 variables:</code> <br />
<code> $ idstud : num  100101 100102 100103 100104 100105 ...</code> <br />
<code> $ idclass: num  1001 1001 1001 1001 1001 ...</code> <br />
<code> $ A01T1  : int  0 1 0 1 1 NA 1 0 1 1 ...</code> <br />
<code> $ A02T1  : int  0 1 0 1 0 NA 0 1 1 0 ...</code> <br />
<code> $ A03T1  : int  0 1 1 1 0 NA 0 1 1 1 ...</code> <br />
<code> $ A04T1  : int  1 0 0 0 0 NA 0 0 0 0 ...</code> <br />
<code> $ A05T1  : int  0 0 0 1 1 NA 0 0 1 1 ...</code> <br />
<code> $ B01T1  : int  1 1 0 1 1 NA 0 0 1 0 ...</code> <br />
<code> $ B02T1  : int  0 0 0 1 0 NA 0 0 1 1 ...</code> <br />
<code> [...]</code> <br />
<code> $ C02T2  : int  0 1 1 1 1 0 1 0 1 1 ...</code> <br />
<code> $ C03T2  : int  1 1 0 1 0 0 0 0 1 0 ...</code> <br />
<code> $ C04T2  : int  0 0 1 0 0 0 0 1 0 0 ...</code> <br />
<code> $ C05T2  : int  0 1 0 0 1 0 1 0 0 1 ...</code> <br />
<code> $ D01T2  : int  0 1 1 1 0 1 1 1 1 1 ...</code> <br />
<code> $ D02T2  : int  0 1 1 1 1 1 0 1 1 1 ...</code> <br />
<code> $ D03T2  : int  1 0 0 0 1 0 0 0 0 0 ...</code> <br />
<code> $ D04T2  : int  1 0 1 1 1 0 1 0 1 1 ...</code> <br />
<code> $ D05T2  : int  1 0 1 1 1 1 1 1 1 1 ...</code> <br />
</p>
</li>
<li><p> The dataset <code>data.ctest2</code> contains two datasets
(<code>$data1</code> containing item responses, <code>$data2</code>
containing sum scores of each C-test) and
a data frame <code>$ITEM</code> with item informations.
</p>
<p><code>List of 3</code> <br />
<code> $ data1:'data.frame':  933 obs. of  102 variables:</code> <br />
<code>  ..$ idstud: num [1:933] 10001 10002 10003 10004 10005 ...</code> <br />
<code>  ..$ female: num [1:933] 1 1 0 0 0 0 1 1 0 1 ...</code> <br />
<code>  ..$ A101  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ A102  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ A103  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ A104  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ A105  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ A106  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ E115  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ E116  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ E117  : int [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  .. [list output truncated]</code> <br />
<code> $ data2:'data.frame':  933 obs. of  7 variables:</code> <br />
<code>  ..$ idstud: num [1:933] 10001 10002 10003 10004 10005 ...</code> <br />
<code>  ..$ female: num [1:933] 1 1 0 0 0 0 1 1 0 1 ...</code> <br />
<code>  ..$ A     : num [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ B     : num [1:933] 16 14 15 13 17 11 11 18 19 13 ...</code> <br />
<code>  ..$ C     : num [1:933] 17 15 17 14 17 13 9 15 17 12 ...</code> <br />
<code>  ..$ D     : num [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code>  ..$ E     : num [1:933] NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ ITEM :'data.frame':  100 obs. of  3 variables:</code> <br />
<code>  ..$ item   : chr [1:100] "A101" "A102" "A103" "A104" ...</code> <br />
<code>  ..$ ctest  : chr [1:100] "A" "A" "A" "A" ...</code> <br />
<code>  ..$ testlet: int [1:100] 1 1 2 2 2 3 3 3 NA 4 ...</code> <br />
</p>
</li></ul>


<hr>
<h2 id='data.examples'>
Datasets <code>data.ex</code> in <span class="pkg">TAM</span> Package
</h2><span id='topic+data.ex08'></span><span id='topic+data.ex10'></span><span id='topic+data.ex11'></span><span id='topic+data.ex12'></span><span id='topic+data.ex14'></span><span id='topic+data.ex15'></span><span id='topic+data.exJ03'></span><span id='topic+data.ex16'></span><span id='topic+data.ex17'></span>

<h3>Description</h3>

<p>Datasets included in the <span class="pkg">TAM</span> package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.ex08)
data(data.ex10)
data(data.ex11)
data(data.ex12)
data(data.ex14)
data(data.ex15)
data(data.exJ03)
</code></pre>


<h3>Format</h3>



<ul>
<li><p> Data <code>data.ex08</code> for Example 8 in <code><a href="#topic+tam.mml">tam.mml</a></code>
has the following format:
</p>
<p><code>List of 2</code> <br />
<code> $ facets:'data.frame': 1000 obs. of  1 variable:</code> <br />
<code>  ..$ female: int [1:1000] 1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ resp  : num [1:1000, 1:10] 1 1 1 0 1 0 1 1 0 1 ...</code> <br />
<code>  ..- attr(*, "dimnames")=List of 2</code> <br />
<code>  .. ..$ : NULL</code> <br />
<code>  .. ..$ : chr [1:10] "I0001" "I0002" "I0003" "I0004" ...</code> <br />
</p>
</li>
<li><p> Data <code>data.ex10</code> for Example 10 in <code><a href="#topic+tam.mml">tam.mml</a></code>
has the following format:
</p>
<p><code>'data.frame':   675 obs. of  7 variables:</code> <br />
<code> $ pid  : int  1 1 1 2 2 3 3 4 4 5 ...</code> <br />
<code> $ rater: int  1 2 3 2 3 1 2 1 3 1 ...</code> <br />
<code> $ I0001: num  0 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ I0002: num  1 1 1 1 1 0 1 1 1 1 ...</code> <br />
<code> $ I0003: num  1 1 1 1 0 0 0 1 0 1 ...</code> <br />
<code> $ I0004: num  0 1 0 0 1 0 1 0 1 0 ...</code> <br />
<code> $ I0005: num  0 0 1 1 1 0 0 1 0 1 ...</code> <br />
</p>

</li>
<li><p> Data <code>data.ex11</code> for Example 11 in <code><a href="#topic+tam.mml">tam.mml</a></code>
has the following format:
</p>
<p><code>'data.frame':   3400 obs. of  13 variables:</code> <br />
<code> $ booklet: chr  "B1" "B1" "B3" "B2" ...</code> <br />
<code> $ M133   : int  1 1 NA 1 NA 1 NA 1 0 1 ...</code> <br />
<code> $ M176   : int  1 0 1 NA 0 0 0 NA NA NA ...</code> <br />
<code> $ M202   : int  NA NA NA 0 NA NA NA 0 0 0 ...</code> <br />
<code> $ M212   : int  NA NA 1 0 0 NA 0 1 0 0 ...</code> <br />
<code> $ M214   : int  1 0 1 1 0 0 0 0 1 0 ...</code> <br />
<code> $ M259   : int  NA NA 1 1 1 NA 1 1 1 1 ...</code> <br />
<code> $ M303   : int  NA NA 1 1 1 NA 1 1 1 0 ...</code> <br />
<code> $ M353   : int  NA NA NA 1 NA NA NA 1 1 9 ...</code> <br />
<code> $ M355   : int  NA NA NA 1 NA NA NA 1 1 0 ...</code> <br />
<code> $ M444   : int  0 0 0 NA 0 0 0 NA NA NA ...</code> <br />
<code> $ M446   : int  1 0 0 1 0 1 1 1 0 0 ...</code> <br />
<code> $ M449   : int  NA NA NA 1 NA NA NA 1 1 1 ...</code>
</p>
<p>Missing responses by design are coded as <code>NA</code>, omitted
responses are coded as <code>9</code>. <br />
</p>

</li>
<li><p> Data <code>data.ex12</code> for Example 12 in <code><a href="#topic+tam.mml">tam.mml</a></code>
has the following format:
</p>
<p><code> num [1:100, 1:10] 1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> - attr(*, "dimnames")=List of 2</code> <br />
<code>  ..$ : NULL</code> <br />
<code>  ..$ : chr [1:10] "I0001" "I0002" "I0003" "I0004" ...</code> <br />
</p>

</li>
<li><p> Data <code>data.ex14</code> for Example 14 in <code><a href="#topic+tam.mml">tam.mml</a></code>
has the following format:
</p>
<p><code>'data.frame':   1110 obs. of  11 variables:</code> <br />
<code> $ pid  : num  1001 1001 1001 1001 1001 ...</code> <br />
<code> $ X1   : num  1 1 1 1 1 1 0 0 0 0 ...</code> <br />
<code> $ X2   : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ rater: int  4 4 4 4 4 4 4 4 4 4 ...</code> <br />
<code> $ crit1: int  0 0 2 1 1 2 0 0 0 0 ...</code> <br />
<code> $ crit2: int  0 0 0 0 0 0 0 0 0 0 ...</code> <br />
<code> $ crit3: int  0 1 1 0 0 1 0 0 1 0 ...</code> <br />
<code> $ crit4: int  0 0 0 1 0 0 0 0 0 0 ...</code> <br />
<code> $ crit5: int  0 0 0 0 1 1 0 0 0 0 ...</code> <br />
<code> $ crit6: int  0 0 0 0 1 0 0 0 0 0 ...</code> <br />
<code> $ crit7: int  1 0 2 0 0 0 0 0 0 0 ...</code> <br />
</p>

</li>
<li><p> Data <code>data.ex15</code> for Example 15 in <code><a href="#topic+tam.mml">tam.mml</a></code>
has the following format:
</p>
<p><code>'data.frame':   2155 obs. of  182 variables:</code> <br />
<code> $ pid    : num  10001 10002 10003 10004 10005 ...</code> <br />
<code> $ group  : num  1 1 0 0 1 0 1 0 1 1 ...</code> <br />
<code> $ Item001: num  0 NA NA 0 NA NA NA 0 0 NA ...</code> <br />
<code> $ Item002: num  1 NA NA 1 NA NA NA NA 1 NA ...</code> <br />
<code> $ Item003: num  NA NA NA NA 1 NA NA NA NA 1 ...</code> <br />
<code> $ Item004: num  NA NA 0 NA NA NA NA NA NA NA ...</code> <br />
<code> $ Item005: num  NA NA 1 NA NA NA NA NA NA NA ...</code> <br />
<code>[...]</code>
</p>
<p>This dataset shows an atypical convergence behavior. Look at Example 15
to fix convergence problems using arguments <code>increment.factor</code> and
<code>fac.oldxsi</code>. <br />
</p>

</li>
<li><p> Data <code>data.exJ03</code> for Example 4 in <code><a href="#topic+tam.jml">tam.jml</a></code>
has the following format:
</p>
<p><code>List of 2</code> <br />
<code> $ resp:'data.frame':   40 obs. of  20 variables:</code> <br />
<code>  ..$ I104: int [1:40] 4 5 6 5 3 4 3 5 4 6 ...</code> <br />
<code>  ..$ I118: int [1:40] 6 4 6 5 3 2 5 3 5 4 ...</code> <br />
<code>[...]</code>
<code>  ..$ I326: int [1:40] 6 1 5 1 4 2 4 1 6 1 ...</code> <br />
<code>  ..$ I338: int [1:40] 6 2 6 1 6 2 4 1 6 1 ...</code> <br />
<code> $ X   :'data.frame':   40 obs. of  4 variables:</code> <br />
<code>  ..$ rater : int [1:40] 40 40 96 96 123 123 157 157 164 164 ...</code> <br />
<code>  ..$ gender: int [1:40] 2 2 1 1 1 1 2 2 2 2 ...</code> <br />
<code>  ..$ region: num [1:40] 1 1 1 1 2 2 1 1 1 1 ...</code> <br />
<code>  ..$ leader: int [1:40] 1 2 1 2 1 2 1 2 1 2 ...</code>
</p>
<p>It is a rating dataset (a subset of a dataset provided by Matt Barney). <br />
</p>

</li>
<li><p> Data <code>data.ex16</code> contains dichotomous item response data from
three studies corresponding to three grades.
</p>
<p><code>'data.frame':   3235 obs. of  25 variables:</code> <br />
<code> $ idstud: num  1e+05 1e+05 1e+05 1e+05 1e+05 ...</code> <br />
<code> $ grade : num  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ A1    : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ B1    : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ C1    : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ D1    : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ E1    : int  0 0 1 0 1 1 1 0 1 1 ...</code> <br />
<code> $ E2    : int  1 1 1 1 1 1 1 0 1 1 ...</code> <br />
<code> $ E3    : int  1 1 1 1 1 1 1 0 1 1 ...</code> <br />
<code> $ F1    : int  1 0 1 1 0 0 1 0 1 1 ...</code> <br />
<code> $ G1    : int  0 1 1 1 1 0 1 0 1 1 ...</code> <br />
<code> $ G2    : int  1 1 1 1 1 0 0 0 1 1 ...</code> <br />
<code> $ G3    : int  1 0 1 1 1 0 0 0 1 1 ...</code> <br />
<code> $ H1    : int  1 0 1 1 1 0 0 0 1 1 ...</code> <br />
<code> $ H2    : int  1 0 1 1 1 0 0 0 1 1 ...</code> <br />
<code> $ I1    : int  1 0 1 0 1 0 0 0 1 1 ...</code> <br />
<code> $ I2    : int  1 0 1 0 1 0 0 0 1 1 ...</code> <br />
<code> $ J1    : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ K1    : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ L1    : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ L2    : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ L3    : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ M1    : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ M2    : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ M3    : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
</p>

</li>
<li><p> Data <code>data.ex17</code> contains polytomous item response data from
three studies corresponding to three grades.
</p>
<p><code>'data.frame':   3235 obs. of  15 variables:</code> <br />
<code> $ idstud: num  1e+05 1e+05 1e+05 1e+05 1e+05 ...</code> <br />
<code> $ grade : num  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ A     : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ B     : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ C     : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ D     : int  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ E     : num  2 2 3 2 3 3 3 0 3 3 ...</code> <br />
<code> $ F     : int  1 0 1 1 0 0 1 0 1 1 ...</code> <br />
<code> $ G     : num  2 2 3 3 3 0 1 0 3 3 ...</code> <br />
<code> $ H     : num  2 0 2 2 2 0 0 0 2 2 ...</code> <br />
<code> $ I     : num  2 0 2 0 2 0 0 0 2 2 ...</code> <br />
<code> $ J     : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ K     : int  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ L     : num  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
<code> $ M     : num  NA NA NA NA NA NA NA NA NA NA ...</code> <br />
</p>
</li></ul>
 


<h3>See Also</h3>

<p>These examples are used in the <code><a href="#topic+tam.mml">tam.mml</a></code> Examples.
</p>

<hr>
<h2 id='data.fims.Aus.Jpn.scored'>
Dataset FIMS Study with Responses of Australian and Japanese Students
</h2><span id='topic+data.fims.Aus.Jpn.raw'></span><span id='topic+data.fims.Aus.Jpn.scored'></span>

<h3>Description</h3>

<p>Dataset FIMS study with raw responses (<code>data.fims.Aus.Jpn.raw</code>) or
scored responses (<code>data.fims.Aus.Jpn.scored</code>) of Australian and
Japanese Students.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.fims.Aus.Jpn.raw)
data(data.fims.Aus.Jpn.scored)
</code></pre>


<h3>Format</h3>

<p>A data frame with 6371 observations on the following 16 variables.
</p>

<dl>
<dt><code>SEX</code></dt><dd><p>Gender: 1 &ndash; male, 2 &ndash; female</p>
</dd>
<dt><code>M1PTI1</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI2</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI3</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI6</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI7</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI11</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI12</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI14</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI17</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI18</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI19</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI21</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI22</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>M1PTI23</code></dt><dd><p>A Mathematics item</p>
</dd>
<dt><code>country</code></dt><dd><p>Country: 1 &ndash; Australia, 2 &ndash; Japan</p>
</dd>
</dl>



<h3>See Also</h3>

<p><a href="http://www.edmeasurementsurveys.com/TAM/Tutorials/7DIF.htm">http://www.edmeasurementsurveys.com/TAM/Tutorials/7DIF.htm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(data.fims.Aus.Jpn.scored)
#*****
# Model 1: Differential Item Functioning Gender for Australian students

# extract Australian students
scored &lt;- data.fims.Aus.Jpn.scored[ data.fims.Aus.Jpn.scored$country==1, ]

# select items
items &lt;- grep("M1", colnames(data.fims.Aus.Jpn.scored), value=TRUE)
##   &gt; items
##    [1] "M1PTI1"  "M1PTI2"  "M1PTI3"  "M1PTI6"  "M1PTI7"  "M1PTI11" "M1PTI12"
##    [8] "M1PTI14" "M1PTI17" "M1PTI18" "M1PTI19" "M1PTI21" "M1PTI22" "M1PTI23"

# Run partial credit model
mod1 &lt;- TAM::tam.mml(scored[,items])

# extract values of the gender variable into a variable called "gender".
gender &lt;- scored[,"SEX"]
# computes the test score for each student by calculating the row sum
# of each student's scored responses.
raw_score &lt;- rowSums(scored[,items] )

# compute the mean test score for each gender group: 1=male, and 2=female
stats::aggregate(raw_score,by=list(gender),FUN=mean)
# The mean test score is 6.12 for group 1 (males) and 6.27 for group 2 (females).
# That is, the two groups performed similarly, with girls having a slightly
# higher mean test score. The step of computing raw test scores is not necessary
# for the IRT analyses. But it's always a good practice to explore the data
# a little before delving into more complex analyses.

# Facets analysis
# To conduct a DIF analysis, we set up the variable "gender" as a facet and
# re-run the IRT analysis.
formulaA &lt;- ~item+gender+item*gender    # define facets analysis
facets &lt;- as.data.frame(gender)         # data frame with student covariates
# facets model for studying differential item functioning
mod2 &lt;- TAM::tam.mml.mfr( resp=scored[,items], facets=facets, formulaA=formulaA )
summary(mod2)

## End(Not run)
</code></pre>

<hr>
<h2 id='data.geiser'>
Dataset from Geiser et al. (2006)
</h2><span id='topic+data.geiser'></span>

<h3>Description</h3>

<p>This is a subsample of the dataset used in Geiser et al. (2006) and
Geiser and Eid (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.geiser)
</code></pre>


<h3>Format</h3>

<p>A data frame with 519 observations on the following 24 variables
</p>
<p><code>'data.frame':   519 obs. of  24 variables:</code> <br />
<code> $ mrt1 : num  0 0 0 0 0 0 0 0 0 0 ...</code> <br />
<code> $ mrt2 : num  0 0 0 0 0 0 0 0 0 0 ...</code> <br />
<code> $ mrt3 : num  0 0 0 0 0 0 0 0 1 0 ...</code> <br />
<code> $ mrt4 : num  0 0 0 0 0 1 0 0 0 0 ...</code> <br />
<code>[...]</code> <br />
<code> $ mrt23: num  0 0 0 0 0 0 0 1 0 0 ...</code> <br />
<code> $ mrt24: num  0 0 0 0 0 0 0 0 0 0 ...</code> <br />
</p>


<h3>References</h3>

<p>Geiser, C., &amp; Eid, M. (2010). Item-Response-Theorie.
In C. Wolf &amp; H. Best (Hrsg.). <em>Handbuch der sozialwissenschaftlichen
Datenanalyse</em> (S. 311-332). VS Verlag fuer Sozialwissenschaften.
</p>
<p>Geiser, C., Lehmann, W., &amp; Eid, M. (2006). Separating rotators from
nonrotators in the mental rotations test: A multigroup latent class analysis.
<em>Multivariate Behavioral Research, 41</em>(3), 261-293.
<a href="https://doi.org/10.1207/s15327906mbr4103_2">doi:10.1207/s15327906mbr4103_2</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Latent trait and latent class models (Geiser et al., 2006, MBR)
#############################################################################

data(data.geiser)
dat &lt;- data.geiser

#**********************************************
# Model 1: Rasch model
tammodel &lt;- "
  LAVAAN MODEL:
    F=~ 1*mrt1__mrt12
    F ~~ F
  ITEM TYPE:
    ALL(Rasch)
    "
mod1 &lt;- TAM::tamaan( tammodel, dat)
summary(mod1)

#**********************************************
# Model 2: 2PL model
tammodel &lt;- "
  LAVAAN MODEL:
    F=~ mrt1__mrt12
    F ~~ 1*F
    "
mod2 &lt;- TAM::tamaan( tammodel, dat)
summary(mod2)

# model comparison Rasch vs. 2PL
anova(mod1,mod2)

#*********************************************************************
#*** Model 3: Latent class analysis with four classes

tammodel &lt;- "
ANALYSIS:
  TYPE=LCA;
  NCLASSES(4);   # 4 classes
  NSTARTS(10,20); # 10 random starts with 20 iterations
LAVAAN MODEL:
  F=~ mrt1__mrt12
    "
mod3 &lt;- TAM::tamaan( tammodel, resp=dat  )
summary(mod3)

# extract item response functions
imod2 &lt;- IRT.irfprob(mod3)[,2,]
# plot class specific probabilities
matplot( imod2, type="o", pch=1:4, xlab="Item", ylab="Probability" )
legend( 10,1, paste0("Class",1:4), lty=1:4, col=1:4, pch=1:4 )

#*********************************************************************
#*** Model 4: Latent class analysis with five classes

tammodel &lt;- "
ANALYSIS:
  TYPE=LCA;
  NCLASSES(5);
  NSTARTS(10,20);
LAVAAN MODEL:
  F=~ mrt1__mrt12
    "
mod4 &lt;- TAM::tamaan( tammodel, resp=dat )
summary(mod4)

# compare different models
AIC(mod1); AIC(mod2); AIC(mod3); AIC(mod4)
BIC(mod1); BIC(mod2); BIC(mod3); BIC(mod4)
# more condensed form
IRT.compareModels(mod1, mod2, mod3, mod4)

#############################################################################
# EXAMPLE 2: Rasch model and mixture Rasch model (Geiser &amp; Eid, 2010)
#############################################################################

data(data.geiser)
dat &lt;- data.geiser

#*********************************************************************
#*** Model 1: Rasch model
tammodel &lt;- "
LAVAAN MODEL:
  F=~ mrt1__mrt6
  F ~~ F
ITEM TYPE:
  ALL(Rasch);
    "
mod1 &lt;- TAM::tamaan( tammodel, resp=dat  )
summary(mod1)

#*********************************************************************
#*** Model 2: Mixed Rasch model with two classes
tammodel &lt;- "
ANALYSIS:
  TYPE=MIXTURE ;
  NCLASSES(2);
  NSTARTS(20,25);
LAVAAN MODEL:
  F=~ mrt1__mrt6
  F ~~ F
ITEM TYPE:
  ALL(Rasch);
    "
mod2 &lt;- TAM::tamaan( tammodel, resp=dat  )
summary(mod2)

# plot item parameters
ipars &lt;- mod2$itempartable_MIXTURE[ 1:6, ]
plot( 1:6, ipars[,3], type="o", ylim=c(-3,2), pch=16,
        xlab="Item", ylab="Item difficulty")
lines( 1:6, ipars[,4], type="l", col=2, lty=2)
points( 1:6, ipars[,4],  col=2, pch=2)

# extract individual posterior distribution
post2 &lt;- IRT.posterior(mod2)
str(post2)
# num [1:519, 1:30] 0.000105 0.000105 0.000105 0.000105 0.000105 ...
# - attr(*, "theta")=num [1:30, 1:30] 1 0 0 0 0 0 0 0 0 0 ...
# - attr(*, "prob.theta")=num [1:30, 1] 1.21e-05 2.20e-04 2.29e-03 1.37e-02 4.68e-02 ...
# - attr(*, "G")=num 1

# There are 2 classes and 15 theta grid points for each class
# The loadings of the theta grid on items are as follows
mod2$E[1,2,,"mrt1_F_load_Cl1"]
mod2$E[1,2,,"mrt1_F_load_Cl2"]

# compute individual posterior probability for class 1 (first 15 columns)
round( rowSums( post2[, 1:15] ), 3 )
# columns 16 to 30 refer to class 2

#*********************************************************************
#*** Model 3: Mixed Rasch model with three classes
tammodel &lt;- "
ANALYSIS:
  TYPE=MIXTURE ;
  NCLASSES(3);
  NSTARTS(20,25);
LAVAAN MODEL:
  F=~ mrt1__mrt6
  F ~~ F
ITEM TYPE:
  ALL(Rasch);
    "
mod3 &lt;- TAM::tamaan( tammodel, resp=dat  )
summary(mod3)

# plot item parameters
ipars &lt;- mod3$itempartable_MIXTURE[ 1:6, ]
plot( 1:6, ipars[,3], type="o", ylim=c(-3.7,2), pch=16,
        xlab="Item", ylab="Item difficulty")
lines( 1:6, ipars[,4], type="l", col=2, lty=2)
points( 1:6, ipars[,4],  col=2, pch=2)
lines( 1:6, ipars[,5], type="l", col=3, lty=3)
points( 1:6, ipars[,5],  col=3, pch=17)

# model comparison
IRT.compareModels( mod1, mod2, mod3 )

## End(Not run)
</code></pre>

<hr>
<h2 id='data.gpcm'>
Dataset with Ordered Indicators
</h2><span id='topic+data.gpcm'></span>

<h3>Description</h3>

<p>Dataset with ordered values of 3 indicators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.gpcm)</code></pre>


<h3>Format</h3>

<p>A data frame with 392 observations on the following 3 items.
</p>

<dl>
<dt><code>Comfort</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Work</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Benefit</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>The dataset is copied from the <span class="pkg">ltm</span> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data.gpcm)
summary(data.gpcm)
</code></pre>

<hr>
<h2 id='data.janssen'>
Dataset from Janssen and Geiser (2010)
</h2><span id='topic+data.janssen'></span><span id='topic+data.janssen2'></span>

<h3>Description</h3>

<p>Dataset used in Janssen and Geiser (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.janssen)
data(data.janssen2)
</code></pre>


<h3>Format</h3>


<ul>
<li> <p><code>data.janssen</code> is a data frame with 346 observations on the 8
items of the following format
</p>
<p><code>'data.frame':   346 obs. of  8 variables:</code> <br />
<code> $ PIS1 : num  1 1 1 0 0 1 1 1 0 1 ...</code> <br />
<code> $ PIS3 : num  0 1 1 1 1 1 0 1 1 1 ...</code> <br />
<code> $ PIS4 : num  1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code> $ PIS5 : num  0 1 1 0 1 1 1 1 1 0 ...</code> <br />
<code> $ SCR6 : num  1 1 1 1 1 1 1 1 1 0 ...</code> <br />
<code> $ SCR9 : num  1 1 1 1 0 0 0 1 0 0 ...</code> <br />
<code> $ SCR10: num  0 0 0 0 0 0 0 0 0 0 ...</code> <br />
<code> $ SCR17: num  0 0 0 0 0 1 0 0 0 0 ...</code> <br />
</p>
</li>
<li> <p><code>data.janssen2</code> contains 20 IST items:
</p>
<p><code>'data.frame':   346 obs. of  20 variables:</code> <br />
<code> $ IST01 : num  1 1 1 0 0 1 1 1 0 1 ...</code> <br />
<code> $ IST02 : num  1 0 1 0 1 1 1 1 0 1 ...</code> <br />
<code> $ IST03 : num  0 1 1 1 1 1 0 1 1 1 ...</code> <br />
<code>[...]</code> <br />
<code> $ IST020: num  0 0 0 1 1 0 0 0 0 0 ...</code> <br />
</p>
</li></ul>



<h3>References</h3>

<p>Janssen, A. B., &amp; Geiser, C. (2010). On the relationship between solution
strategies in two mental rotation tasks.
<em>Learning and Individual Differences, 20</em>(5), 473-478.
<a href="https://doi.org/10.1016/j.lindif.2010.03.002">doi:10.1016/j.lindif.2010.03.002</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: CCT data, Janssen and Geiser (2010, LID)
#            Latent class analysis based on data.janssen
#############################################################################

data(data.janssen)
dat &lt;- data.janssen
colnames(dat)
  ##   [1] "PIS1"  "PIS3"  "PIS4"  "PIS5"  "SCR6"  "SCR9"  "SCR10" "SCR17"

#*********************************************************************
#*** Model 1: Latent class analysis with two classes

tammodel &lt;- "
ANALYSIS:
  TYPE=LCA;
  NCLASSES(2);
  NSTARTS(10,20);
LAVAAN MODEL:
  # missing item numbers (e.g. PIS2) are ignored in the model
  F=~ PIS1__PIS5 + SCR6__SCR17
    "
mod3 &lt;- TAM::tamaan( tammodel, resp=dat  )
summary(mod3)

# extract item response functions
imod2 &lt;- IRT.irfprob(mod3)[,2,]
# plot class specific probabilities
ncl &lt;- 2
matplot( imod2, type="o", pch=1:ncl, xlab="Item", ylab="Probability" )
legend( 1, .3, paste0("Class",1:ncl), lty=1:ncl, col=1:ncl, pch=1:ncl )

#*********************************************************************
#*** Model 2: Latent class analysis with three classes

tammodel &lt;- "
ANALYSIS:
  TYPE=LCA;
  NCLASSES(3);
  NSTARTS(10,20);
LAVAAN MODEL:
  F=~ PIS1__PIS5 + SCR6__SCR17
    "
mod3 &lt;- TAM::tamaan( tammodel, resp=dat  )
summary(mod3)

# extract item response functions
imod2 &lt;- IRT.irfprob(mod3)[,2,]
# plot class specific probabilities
ncl &lt;- 3
matplot( imod2, type="o", pch=1:ncl, xlab="Item", ylab="Probability" )
legend( 1, .3, paste0("Class",1:ncl), lty=1:ncl, col=1:ncl, pch=1:ncl )

# compare models
AIC(mod1); AIC(mod2)

## End(Not run)
</code></pre>

<hr>
<h2 id='data.mc'>
Dataset with Raw and Scored Responses from Multiple Choice Items
</h2><span id='topic+data.mc'></span>

<h3>Description</h3>

<p>Dataset of responses from multiple choice items, containing 143 students
on 30 items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.mc)
</code></pre>


<h3>Format</h3>

<p>The dataset is a list with two elements. The entry <code>raw</code>
contains unscored (raw) item responses and the entry <code>scored</code>
contains the scored (recoded) item responses. The format is:
</p>
<p><code>List of 2</code> <br />
<code> $ raw   : chr [1:143, 1:30] "A" "A" "A" "A" ...</code> <br />
<code>  ..- attr(*, "dimnames")=List of 2</code> <br />
<code>  .. ..$ : NULL</code> <br />
<code>  .. ..$ : chr [1:30] "I01" "I02" "I03" "I04" ...</code> <br />
<code> $ scored:'data.frame':</code> <br />
<code>  ..$ I01: num [1:143] 1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code>  ..$ I02: num [1:143] 1 1 1 0 1 1 1 1 1 1 ...</code> <br />
<code>  ..$ I03: num [1:143] 1 1 1 1 1 1 1 1 1 1 ...</code> <br />
<code>  [...]</code> <br />
<code>  ..$ I29: num [1:143] NA 0 1 0 1 0 0 0 0 0 ...</code> <br />
<code>  ..$ I30: num [1:143] NA NA 1 1 1 1 0 1 1 0 ...</code> <br />
</p>

<hr>
<h2 id='data.numeracy'>
Dataset Numeracy
</h2><span id='topic+data.numeracy'></span>

<h3>Description</h3>

<p>Dataset numeracy with unscored (<code>raw</code>) and scored (<code>scored</code>)
item responses of 876 persons and 15 items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.numeracy)
</code></pre>


<h3>Format</h3>

<p>The format is a list a two entries:
</p>
<p><code>List of 2</code> <br />
<code> $ raw   :'data.frame':</code> <br />
<code>  ..$ I1 : int [1:876] 1 0 1 0 0 0 0 0 1 1 ...</code> <br />
<code>  ..$ I2 : int [1:876] 0 1 0 0 1 1 1 1 1 0 ...</code> <br />
<code>  ..$ I3 : int [1:876] 4 4 1 3 4 4 4 4 4 4 ...</code> <br />
<code>  ..$ I4 : int [1:876] 4 1 2 2 1 1 1 1 1 1 ...</code> <br />
<code>  [...] </code> <br />
<code>  ..$ I15: int [1:876] 1 1 1 1 0 1 1 1 1 1 ...</code> <br />
<code> $ scored:'data.frame':</code> <br />
<code>  ..$ I1 : int [1:876] 1 0 1 0 0 0 0 0 1 1 ...</code> <br />
<code>  ..$ I2 : int [1:876] 0 1 0 0 1 1 1 1 1 0 ...</code> <br />
<code>  ..$ I3 : int [1:876] 1 1 0 0 1 1 1 1 1 1 ...</code> <br />
<code>  ..$ I4 : int [1:876] 0 1 0 0 1 1 1 1 1 1 ...</code> <br />
<code>  [...] </code> <br />
<code>  ..$ I15: int [1:876] 1 1 1 1 0 1 1 1 1 1 ...</code> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######################################################################
# (1) Scored numeracy data
######################################################################

data(data.numeracy)
dat &lt;- data.numeracy$scored

#Run IRT analysis: Rasch model
mod1 &lt;- TAM::tam.mml(dat)

#Item difficulties
mod1$xsi
ItemDiff &lt;- mod1$xsi$xsi
ItemDiff

#Ability estimate - Weighted Likelihood Estimate
Abil &lt;- TAM::tam.wle(mod1)
Abil
PersonAbility &lt;- Abil$theta
PersonAbility

#Descriptive statistics of item and person parameters
hist(ItemDiff)
hist(PersonAbility)
mean(ItemDiff)
mean(PersonAbility)
stats::sd(ItemDiff)
stats::sd(PersonAbility)

## Not run: 
#Extension
#plot histograms of ability and item parameters in the same graph
oldpar &lt;- par(no.readonly=TRUE)          # save writable default graphic settings
windows(width=4.45, height=4.45, pointsize=12)
layout(matrix(c(1,1,2),3,byrow=TRUE))
layout.show(2)
hist(PersonAbility,xlim=c(-3,3),breaks=20)
hist(ItemDiff,xlim=c(-3,3),breaks=20)

par( oldpar )  # restore default graphic settings
hist(PersonAbility,xlim=c(-3,3),breaks=20)

######################################################################
# (2) Raw numeracy data
######################################################################

raw_resp &lt;- data.numeracy$raw

#score responses
key &lt;- c(1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1)
scored &lt;- sapply( seq(1,length(key)),
            FUN=function(ii){ 1*(raw_resp[,ii]==key[ii]) } )

#run IRT analysis
mod1 &lt;- TAM::tam.mml(scored)

#Ability estimate - Weighted Likelihood Estimate
Abil &lt;- TAM::tam.wle(mod1)

#CTT statistics
ctt1 &lt;- TAM::tam.ctt(raw_resp, Abil$theta)
write.csv(ctt1,"D1_ctt1.csv")       # write statistics into a file
        # use maybe write.csv2 if ';' should be the column separator

#Fit statistics
Fit &lt;- TAM::tam.fit(mod1)
Fit

# plot expected response curves
plot( mod1, ask=TRUE )

## End(Not run)
</code></pre>

<hr>
<h2 id='data.sim.mfr'>
Simulated Multifaceted Data
</h2><span id='topic+data.sim.mfr'></span><span id='topic+data.sim.facets'></span>

<h3>Description</h3>

<p>Simulated data from multiple facets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> data(data.sim.mfr)
 data(data.sim.facets)
</code></pre>


<h3>Format</h3>

<p>The format of <code>data.sim.mfr</code> is: <br />
<code> num [1:100, 1:5] 3 2 1 1 0 1 0 1 0 0 ...</code> <br />
<code> - attr(*, "dimnames")=List of 2</code> <br />
<code>  ..$ : chr [1:100] "V1" "V1.1" "V1.2" "V1.3" ...</code> <br />
<code>  ..$ : NULL</code>
</p>
<p>The format of <code>data.sim.facets</code> is: <br />
<code>'data.frame':   100 obs. of  3 variables:</code> <br />
<code> $ rater : num  1 2 3 4 5 1 2 3 4 5 ...</code> <br />
<code> $ topic : num  3 1 3 1 3 2 3 2 2 1 ...</code> <br />
<code> $ female: num  2 2 1 2 1 1 2 1 2 1 ...</code> <br />
</p>


<h3>Source</h3>

<p>Simulated
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######
# sim multi faceted Rasch model
data(data.sim.mfr)
data(data.sim.facets)

  # 1: A-matrix test_rater
  test_1_items &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~rater,
            facets=data.sim.facets, constraint="items" )
  test_1_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~rater,
            facets=data.sim.facets, constraint="cases" )

  # 2: test_item+rater
  test_2_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+rater,
            facets=data.sim.facets, constraint="cases" )

  # 3: test_item+rater+topic+ratertopic
  test_3_items &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+rater*topic,
            facets=data.sim.facets, constraint="items" )
  # conquest uses a different way of ordering the rows
  # these are the first few rows of the conquest design matrix
  # test_3_items$A[grep("item1([[:print:]])*topic1", rownames(test_3_items)),]

  # 4: test_item+step
  test_4_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+step,
            facets=data.sim.facets, constraint="cases" )

  # 5: test_item+item:step
  test_5_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+item:step,
            facets=data.sim.facets, constraint="cases" )
  test_5_cases$A[, grep("item1", colnames(test_5_cases)) ]

  # 5+x: more
  #=&gt; 6: is this even well defined in the conquest-design output
  #          (see test_item+topicstep_cases.cqc / .des)
  #        regardless of the meaning of such a formula;
  #        currently .A.matrix throws a warning
  # test_6_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+topic:step,
  #                 facets=data.sim.facets, constraint="cases" )
  test_7_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+topic+topic:step,
            facets=data.sim.facets, constraint="cases" )

## Not run: 
  #=&gt; 8: same as with 6
  test_8_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+rater+item:rater:step,
            facets=data.sim.facets, constraint="cases" )
## [1] "Can't proceed the estimation: Lower-order term is missing."
  test_9_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+step+rater+item:step+item:rater,
            facets=data.sim.facets, constraint="cases" )
  test_10_cases &lt;- TAM::.A.matrix( data.sim.mfr, formulaA=~item+female+item:female,
            facets=data.sim.facets, constraint="cases" )

  ### All Design matrices
  test_1_cases &lt;- TAM::designMatrices.mfr( data.sim.mfr, formulaA=~rater,
            facets=data.sim.facets, constraint="cases" )
  test_4_cases &lt;- TAM::designMatrices.mfr( data.sim.mfr, formulaA=~item+item:step,
            facets=data.sim.facets, constraint="cases" )

  ### TAM
  test_4_cases &lt;- TAM::tam.mml.mfr( data.sim.mfr, formulaA=~item+item:step )
  test_tam &lt;- TAM::tam.mml( data.sim.mfr )

  test_1_cases &lt;- TAM::tam.mml.mfr( data.sim.mfr, formulaA=~rater,
            facets=data.sim.facets, constraint="cases" )
  test_2_cases &lt;- TAM::tam.mml.mfr( data.sim.mfr, formulaA=~item+rater,
            facets=data.sim.facets, constraint="cases" )
## End(Not run)
</code></pre>

<hr>
<h2 id='data.sim.rasch'>
Simulated Rasch data
</h2><span id='topic+data.sim.rasch'></span><span id='topic+data.sim.rasch.pweights'></span><span id='topic+data.sim.rasch.missing'></span>

<h3>Description</h3>

<p>Simulated Rasch data under unidimensional trait distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'> data(data.sim.rasch)
 data(data.sim.rasch.pweights)
 data(data.sim.rasch.missing)
</code></pre>


<h3>Format</h3>

<p>The format is: <br /> <br />
<code>num [1:2000, 1:40] 1 0 1 1 1 1 1 1 1 1 ...</code><br />
<code> - attr(*, "dimnames")=List of 2</code> <br />
<code>  ..$ : NULL</code> <br />
<code>  ..$ : chr [1:40] "I1" "I2" "I3" "I4" ...</code> <br />
</p>


<h3>Details</h3>

<p><code>N &lt;- 2000     </code> <br />
<code> # simulate predictors</code> <br />
<code> Y &lt;- cbind( stats::rnorm( N, sd=1.5), stats::rnorm(N, sd=.3 ) )</code> <br />
<code> theta &lt;- stats::rnorm( N ) + .4 * Y[,1] + .2 * Y[,2]  # latent regression model</code> <br />
<code> # simulate item responses with missing data</code> <br />
<code> I &lt;- 40</code> <br />
<code> resp[ theta &lt; 0, c(1,seq(I/2+1, I)) ] &lt;- NA</code> <br />
<code> # define person weights</code> <br />
<code> pweights &lt;- c(  rep(3,N/2), rep( 1, N/2 ) )</code> <br />
</p>


<h3>Source</h3>

<p>Simulated data (see Details)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(data.sim.rasch)
N &lt;- 2000
Y &lt;- cbind( stats::rnorm( N, sd=1.5), stats::rnorm(N, sd=.3 ) )

# Loading Matrix
# B &lt;- array( 0, dim=c( I, 2, 1 )  )
# B[1:(nrow(B)), 2, 1] &lt;- 1
B &lt;- TAM::designMatrices(resp=data.sim.rasch)[["B"]]

# estimate Rasch model
mod1_1 &lt;- TAM::tam.mml(resp=data.sim.rasch, Y=Y)

# standard errors
res1 &lt;- TAM::tam.se(mod1_1)

# Compute fit statistics
tam.fit(mod1_1)

# plausible value imputation
# PV imputation has to be adpated for multidimensional case!
pv1 &lt;- TAM::tam.pv( mod1_1, nplausible=7, # 7 plausible values
               samp.regr=TRUE       # sampling of regression coefficients
              )

# item parameter constraints
xsi.fixed &lt;- matrix( c( 1, -2,5, -.22,10, 2 ), nrow=3, ncol=2, byrow=TRUE)
xsi.fixed
mod1_4 &lt;- TAM::tam.mml( resp=data.sim.rasch, xsi.fixed=xsi.fixed )

# missing value handling
data(data.sim.rasch.missing)
mod1_2 &lt;- TAM::tam.mml(data.sim.rasch.missing, Y=Y)

# handling of sample (person) weights
data(data.sim.rasch.pweights)
N &lt;- 1000
pweights &lt;- c(  rep(3,N/2), rep( 1, N/2 ) )
mod1_3 &lt;- TAM::tam.mml( data.sim.rasch.pweights, control=list(conv=.001),
               pweights=pweights )
  
## End(Not run)
</code></pre>

<hr>
<h2 id='data.timssAusTwn'>
Dataset TIMSS 2011 of Australian and Taiwanese Students
</h2><span id='topic+data.timssAusTwn'></span><span id='topic+data.timssAusTwn.scored'></span>

<h3>Description</h3>

<p>Mathematics items of TIMSS 2011 of 1773 Australian and
Taiwanese students. The dataset <code>data.timssAusTwn</code> contains raw
responses while <code>data.timssAusTwn.scored</code> contains scored item
responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.timssAusTwn)
data(data.timssAusTwn.scored)
</code></pre>


<h3>Format</h3>

<p>A data frame with 1773 observations on the following 14 variables.
</p>

<dl>
<dt><code>M032166</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032721</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032757</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032760A</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032760B</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032760C</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032761</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032692</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032626</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032595</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>M032673</code></dt><dd><p>a mathematics item</p>
</dd>
<dt><code>IDCNTRY</code></dt><dd><p>Country identifier</p>
</dd>
<dt><code>ITSEX</code></dt><dd><p>Gender</p>
</dd>
<dt><code>IDBOOK</code></dt><dd><p>Booklet identifier</p>
</dd>
</dl>



<h3>See Also</h3>

<p><a href="http://www.edmeasurementsurveys.com/TAM/Tutorials/5PartialCredit.htm">http://www.edmeasurementsurveys.com/TAM/Tutorials/5PartialCredit.htm</a>
</p>
<p><a href="http://www.edmeasurementsurveys.com/TAM/Tutorials/6Population.htm">http://www.edmeasurementsurveys.com/TAM/Tutorials/6Population.htm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data.timssAusTwn)
raw_resp &lt;- data.timssAusTwn

#Recode data
resp &lt;- raw_resp[,1:11]
      #Column 12 is country code. Column 13 is gender code. Column 14 is Book ID.
all.na &lt;- rowMeans( is.na(resp) )==1
        #Find records where all responses are missing.
resp &lt;- resp[!all.na,]              #Delete records with all missing responses
resp[resp==20 | resp==21] &lt;- 2      #TIMSS double-digit coding: "20" or "21" is a score of 2
resp[resp==10 | resp==11] &lt;- 1      #TIMSS double-digit coding: "10" or "11" is a score of 1
resp[resp==70 | resp==79] &lt;- 0      #TIMSS double-digit coding: "70" or "79" is a score of 0
resp[resp==99] &lt;- 0                 #"99" is omitted responses. Score it as wrong here.
resp[resp==96 | resp==6] &lt;- NA      #"96" and "6" are not-reached items. Treat these as missing.

#Score multiple-choice items        #"resp" contains raw responses for MC items.
Scored &lt;- resp
Scored[,9] &lt;- (resp[,9]==4)*1       #Key for item 9 is D.
Scored[,c(1,2)] &lt;- (resp[,c(1,2)]==2)*1  #Key for items 1 and 2 is B.
Scored[,c(10,11)] &lt;- (resp[,c(10,11)]==3)*1  #Key for items 10 and 11 is C.

#Run IRT analysis for partial credit model (MML estimation)
mod1 &lt;- TAM::tam.mml(Scored)

#Item parameters
mod1$xsi

#Thurstonian thresholds
tthresh &lt;- TAM::tam.threshold(mod1)
tthresh

## Not run: 
#Plot Thurstonian thresholds
windows (width=8, height=7)
par(ps=9)
dotchart(t(tthresh), pch=19)
# plot expected response curves
plot( mod1, ask=TRUE)

#Re-run IRT analysis in JML
mod1.2 &lt;- TAM::tam.jml(Scored)
stats::var(mod1.2$WLE)

#Re-run the model with "not-reached" coded as incorrect.
Scored2 &lt;- Scored
Scored2[is.na(Scored2)] &lt;- 0

#Prepare anchor parameter values
nparam &lt;- length(mod1$xsi$xsi)
xsi &lt;- mod1$xsi$xsi
anchor &lt;- matrix(c(seq(1,nparam),xsi), ncol=2)

#Run IRT with item parameters anchored on mod1 values
mod2 &lt;- TAM::tam.mml(Scored2, xsi.fixed=anchor)

#WLE ability estimates
ability &lt;- TAM::tam.wle(mod2)
ability

#CTT statistics
ctt &lt;- TAM::tam.ctt(resp, ability$theta)
write.csv(ctt,"TIMSS_CTT.csv")

#plot histograms of ability and item parameters in the same graph
windows(width=4.45, height=4.45, pointsize=12)
layout(matrix(c(1,1,2),3,byrow=TRUE))
layout.show(2)
hist(ability$theta,xlim=c(-3,3),breaks=20)
hist(tthresh,xlim=c(-3,3),breaks=20)

#Extension
#Score equivalence table
dummy &lt;- matrix(0,nrow=16,ncol=11)
dummy[lower.tri(dummy)] &lt;- 1
dummy[12:16,c(3,4,7,8)][lower.tri(dummy[12:16,c(3,4,7,8)])]&lt;-2

mod3 &lt;- TAM::tam.mml(dummy, xsi.fixed=anchor)
wle3 &lt;- TAM::tam.wle(mod3)

## End(Not run)
</code></pre>

<hr>
<h2 id='DescribeBy'>
S3 Method for Descriptive Statistics of Objects
</h2><span id='topic+DescribeBy'></span>

<h3>Description</h3>

<p>S3 method for descriptive statistics of objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DescribeBy(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DescribeBy_+3A_object">object</code></td>
<td>

<p>An object
</p>
</td></tr>
<tr><td><code id="DescribeBy_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="psych.html#topic+describe">psych::describe</a></code>
</p>

<hr>
<h2 id='designMatrices'>
Generation of Design Matrices
</h2><span id='topic+designMatrices'></span><span id='topic+print.designMatrices'></span><span id='topic+designMatrices.mfr'></span><span id='topic+designMatrices.mfr2'></span><span id='topic+.A.matrix'></span><span id='topic+rownames.design'></span><span id='topic+.A.PCM2'></span><span id='topic+.A.PCM3'></span>

<h3>Description</h3>

<p>Generate design matrices, and display them at console.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>designMatrices(modeltype=c("PCM", "RSM"), maxKi=NULL, resp=resp,
    ndim=1, A=NULL, B=NULL, Q=NULL, R=NULL, constraint="cases",...)

## S3 method for class 'designMatrices'
print(x, ...)

designMatrices.mfr(resp, formulaA=~ item + item:step, facets=NULL,
    constraint=c("cases", "items"), ndim=1, Q=NULL, A=NULL, B=NULL,
    progress=FALSE)
designMatrices.mfr2(resp, formulaA=~ item + item:step, facets=NULL,
    constraint=c("cases", "items"), ndim=1, Q=NULL, A=NULL, B=NULL,
    progress=FALSE)

.A.matrix(resp, formulaA=~ item + item*step, facets=NULL,
    constraint=c("cases", "items"), progress=FALSE, maxKi=NULL)
rownames.design(X)

.A.PCM2( resp, Kitem=NULL, constraint="cases", Q=NULL)
   # generates ConQuest parametrization of partial credit model

.A.PCM3( resp, Kitem=NULL ) # parametrization for A matrix in the dispersion model
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="designMatrices_+3A_modeltype">modeltype</code></td>
<td>

<p>Type of item response model. Until now, the
partial credit model (<code>PCM</code>; <code>'item+item*step'</code>) and
the rating scale model (<code>RSM</code>; <code>'item+step'</code>) is implemented.
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_maxki">maxKi</code></td>
<td>

<p>A vector containing the maximum score per item
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_resp">resp</code></td>
<td>

<p>Data frame of item responses
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_ndim">ndim</code></td>
<td>

<p>Number of dimensions
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_a">A</code></td>
<td>

<p>The design matrix for linking item category parameters
to generalized item parameters <code class="reqn">\xi</code>.
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_b">B</code></td>
<td>

<p>The scoring matrix of item categories on <code class="reqn">\theta</code>
dimensions.
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_q">Q</code></td>
<td>

<p>A loading matrix of items on dimensions
with number of rows equal the number
of items and the number of columns equals the
number of dimensions in the item response model.
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_r">R</code></td>
<td>

<p>This argument is not used
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_x">x</code></td>
<td>

<p>Object generated by <code>designMatrices</code>. This argument is used in
<code>print.designMatrices</code> and <code>rownames.design</code>.
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_x">X</code></td>
<td>

<p>Object generated by <code>designMatrices</code>. This argument is used in
<code>print.designMatrices</code> and <code>rownames.design</code>.
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_formulaa">formulaA</code></td>
<td>

<p>An <span class="rlang"><b>R</b></span> formula object for generating the <code>A</code> design matrix.
Variables in <code>formulaA</code> have to be included in <code>facets</code>.
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_facets">facets</code></td>
<td>

<p>A data frame with observed facets. The number of rows must be equal
to the number of rows in <code>resp</code>.
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_constraint">constraint</code></td>
<td>

<p>Constraint in estimation: <code>cases</code> assumes zero means
of trait distributions and <code>items</code> a sum constraint of
zero of item parameters
</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_kitem">Kitem</code></td>
<td>
<p>Maximum number of categories per item</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_progress">progress</code></td>
<td>
<p>Display progress for creation of design matrices</p>
</td></tr>
<tr><td><code id="designMatrices_+3A_...">...</code></td>
<td>

<p>Further arguments
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>.A.PCM2</code> generates the Conquest parametrization
of the partial credit model.
</p>
<p>The function <code>.A.PCM3</code> generates the parametrization for the <code class="reqn">A</code>
design matrix in the dispersion model for ordered data (Andrich, 1982).
</p>


<h3>Note</h3>

<p>The function <code>designMatrices.mfr2</code> handles multi-faceted design for
items with differing number of response options.
</p>


<h3>References</h3>

<p>Andrich, D. (1982). An extension of the Rasch model for ratings providing
both location and dispersion parameters. <em>Psychometrika, 47</em>(1),
105-113. <a href="https://doi.org/10.1007/BF02293856">doi:10.1007/BF02293856</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+data.sim.mfr">data.sim.mfr</a></code> for some examples for creating design matrices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################
# different parametrizations for ordered data
data( data.gpcm )
resp &lt;- data.gpcm

# parametrization for partial credit model
A1 &lt;- TAM::designMatrices( resp=resp )$A
# item difficulty and threshold parametrization
A2 &lt;- TAM::.A.PCM2( resp )
# dispersion model of Andrich (1982)
A3 &lt;- TAM::.A.PCM3( resp )
# rating scale model
A4 &lt;- TAM::designMatrices( resp=resp, modeltype="RSM" )$A
</code></pre>

<hr>
<h2 id='doparse'>
Parsing a String with <code>DO</code> Statements
</h2><span id='topic+doparse'></span>

<h3>Description</h3>

<p>This function parses a string and expands this string in case of <code>DO</code>
statements which are shortcuts for writing loops. The statement
<code>DO(n,m,k)</code> increments an index from <code>n</code> to <code>m</code> in steps
of <code>k</code>. The index in the string <code>model</code> must be defined
as <code>%</code>. For a nested loop within a loop,
the <code>DO2</code> statement can be used using <code>%1</code> and <code>%2</code>
as indices. See Examples for hints on the specification. The loop in <code>DO2</code>
must not be explicitly crossed, e.g. in applications for specifying
covariances or correlations. The formal syntax for <br />
<code> for (ii in 1:(K-1)){  for (jj in (ii+1):K) { ... } }</code> <br />
can be written as <code>DO2(1,K-1,1,%1,K,1
)</code>. See Example 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doparse(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="doparse_+3A_model">model</code></td>
<td>

<p>A string with <code>DO</code> or <code>DO2</code> statements.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Parsed string in which <code>DO</code> statements are expanded.
</p>


<h3>See Also</h3>

<p>This function is also used in <code><a href="#topic+lavaanify.IRT">lavaanify.IRT</a></code> and
<code><a href="#topic+tamaanify">tamaanify</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: doparse example
#############################################################################

# define model
model &lt;- "
 # items I1,...,I10 load on G
 DO(1,10,1)
   G=~ lamg% * I%
 DOEND
 I2 | 0.75*t1
 v10 &gt; 0 ;
 # The first index loops from 1 to 3 and the second index loops from 1 to 2
 DO2(1,3,1,  1,2,1)
   F%2=~ a%2%1 * A%2%1 ;
 DOEND
 # Loop from 1 to 9 with steps of 2
 DO(1,9,2)
   HA1=~ I%
   I% | beta% * t1
 DOEND
 "

# process string
out &lt;- TAM::doparse(model)
cat(out)
  ##    # items I1,...,I10 load on G
  ##       G=~ lamg1 * I1
  ##       G=~ lamg2 * I2
  ##       G=~ lamg3 * I3
  ##       G=~ lamg4 * I4
  ##       G=~ lamg5 * I5
  ##       G=~ lamg6 * I6
  ##       G=~ lamg7 * I7
  ##       G=~ lamg8 * I8
  ##       G=~ lamg9 * I9
  ##       G=~ lamg10 * I10
  ##     I2 | 0.75*t1
  ##     v10 &gt; 0
  ##       F1=~ a11 * A11
  ##       F2=~ a21 * A21
  ##       F1=~ a12 * A12
  ##       F2=~ a22 * A22
  ##       F1=~ a13 * A13
  ##       F2=~ a23 * A23
  ##       HA1=~ I1
  ##       HA1=~ I3
  ##       HA1=~ I5
  ##       HA1=~ I7
  ##       HA1=~ I9
  ##       I1 | beta1 * t1
  ##       I3 | beta3 * t1
  ##       I5 | beta5 * t1
  ##       I7 | beta7 * t1
  ##       I9 | beta9 * t1

#############################################################################
# EXAMPLE 2: doparse with nested loop example
#############################################################################

# define model
model &lt;- "
 DO(1,4,1)
   G=~ lamg% * I%
 DOEND
 # specify some correlated residuals
 DO2(1,3,1,%1,4,1)
   I%1 ~~ I%2
 DOEND
 "
# process string
out &lt;- TAM::doparse(model)
cat(out)
  ##       G=~ lamg1 * I1
  ##       G=~ lamg2 * I2
  ##       G=~ lamg3 * I3
  ##       G=~ lamg4 * I4
  ##     # specify some correlated residuals
  ##       I1 ~~ I2
  ##       I1 ~~ I3
  ##       I1 ~~ I4
  ##       I2 ~~ I3
  ##       I2 ~~ I4
  ##       I3 ~~ I4
</code></pre>

<hr>
<h2 id='IRT.cv'>
Cross-Validation of a Fitted IRT Model
</h2><span id='topic+IRT.cv'></span>

<h3>Description</h3>

<p>This S3 method performs a cross-validation of a fitted item response model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT.cv(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.cv_+3A_object">object</code></td>
<td>

<p>Object</p>
</td></tr>
<tr><td><code id="IRT.cv_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value: the cross-validated deviance value
</p>

<hr>
<h2 id='IRT.data.tam'>
Extracting Item Response Dataset
</h2><span id='topic+IRT.data.tam.mml'></span><span id='topic+IRT.data.tam.mml.3pl'></span><span id='topic+IRT.data.tamaan'></span>

<h3>Description</h3>

<p>Extracts the used data set for models
fitted in <span class="pkg">TAM</span>. See <code><a href="CDM.html#topic+IRT.data">CDM::IRT.data</a></code>
for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam.mml'
IRT.data(object, ...)

## S3 method for class 'tam.mml.3pl'
IRT.data(object, ...)

## S3 method for class 'tamaan'
IRT.data(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.data.tam_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam">tam</a></code>, <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code> or <code><a href="#topic+tamaan">tamaan</a></code>.
</p>
</td></tr>
<tr><td><code id="IRT.data.tam_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataset with item responses
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Dichotomous data data.sim.rasch
#############################################################################

data(data.sim.rasch)
dat &lt;- data.sim.rasch

# estimate model
mod1 &lt;- TAM::tam.mml(dat)
# extract dataset (and weights and group if available)
dmod1 &lt;- IRT.data(mod1)
str(dmod1)

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.drawPV'>
Function for Drawing Plausible Values
</h2><span id='topic+IRT.drawPV'></span>

<h3>Description</h3>

<p>This function draws plausible values of a continuous latent variable
based on a fitted object for which the
<code><a href="CDM.html#topic+IRT.posterior">CDM::IRT.posterior</a></code> method
is defined.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT.drawPV(object,NPV=5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.drawPV_+3A_object">object</code></td>
<td>

<p>Object for which the method <code><a href="CDM.html#topic+IRT.posterior">CDM::IRT.posterior</a></code>
does exist.</p>
</td></tr>
<tr><td><code id="IRT.drawPV_+3A_npv">NPV</code></td>
<td>
<p>Number of plausible values to be drawn.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with plausible values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Plausible value imputation for Rasch model in sirt
#############################################################################

library(sirt)
data(data.read, package="sirt")
dat &lt;- data.read

# fit Rasch model
mod &lt;- rasch.mml2(dat)
# draw 10 plausible values
pv1 &lt;- TAM::IRT.drawPV(mod, NPV=10)

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.expectedCounts'>
Extracting Expected Counts
</h2><span id='topic+IRT.expectedCounts.tam'></span><span id='topic+IRT.expectedCounts.tam.mml'></span><span id='topic+IRT.expectedCounts.tam.mml.3pl'></span><span id='topic+IRT.expectedCounts.tamaan'></span><span id='topic+IRT.expectedCounts.tam.np'></span>

<h3>Description</h3>

<p>Extracts expected counts for models
fitted in <span class="pkg">TAM</span>. See <code><a href="CDM.html#topic+IRT.expectedCounts">CDM::IRT.expectedCounts</a></code>
for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam'
IRT.expectedCounts(object, ...)

## S3 method for class 'tam.mml'
IRT.expectedCounts(object, ...)

## S3 method for class 'tam.mml.3pl'
IRT.expectedCounts(object, ...)

## S3 method for class 'tamaan'
IRT.expectedCounts(object, ...)

## S3 method for class 'tam.np'
IRT.expectedCounts(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.expectedCounts_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam">tam</a></code>, <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code>, <code><a href="#topic+tam.np">tam.np</a></code> or <code><a href="#topic+tamaan">tamaan</a></code>.
</p>
</td></tr>
<tr><td><code id="IRT.expectedCounts_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See <code><a href="CDM.html#topic+IRT.expectedCounts">CDM::IRT.expectedCounts</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Dichotomous data data.sim.rasch - extract expected counts
#############################################################################

data(data.sim.rasch)
# 1PL estimation
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
# extract expected counts
IRT.expectedCounts(mod1)

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.factor.scores'>
Extracting Factor Scores in <span class="pkg">TAM</span>
</h2><span id='topic+IRT.factor.scores.tam'></span><span id='topic+IRT.factor.scores.tam.mml'></span><span id='topic+IRT.factor.scores.tam.mml.3pl'></span><span id='topic+IRT.factor.scores.tamaan'></span>

<h3>Description</h3>

<p>Extracts factor scores for models
fitted in <span class="pkg">TAM</span>. See <code><a href="CDM.html#topic+IRT.factor.scores">CDM::IRT.factor.scores</a></code>
for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam'
IRT.factor.scores(object, type="EAP", ...)

## S3 method for class 'tam.mml'
IRT.factor.scores(object, type="EAP", ...)

## S3 method for class 'tam.mml.3pl'
IRT.factor.scores(object, type="EAP", ...)

## S3 method for class 'tamaan'
IRT.factor.scores(object, type="EAP", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.factor.scores_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam">tam</a></code>, <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code> or <code><a href="#topic+tamaan">tamaan</a></code>.
</p>
</td></tr>
<tr><td><code id="IRT.factor.scores_+3A_type">type</code></td>
<td>
<p>Type of factor score to be used. <code>type="EAP"</code> can be used
for all classes in <span class="pkg">TAM</span> while <code>type="WLE"</code> and
<code>type="MLE"</code> can only be used for objects of class
<code><a href="#topic+tam.mml">tam.mml</a></code>. Further arguments to the
used function <code><a href="#topic+tam.wle">tam.wle</a></code> can be specified
with <code>...</code>.
</p>
</td></tr>
<tr><td><code id="IRT.factor.scores_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See <code><a href="CDM.html#topic+IRT.factor.scores">CDM::IRT.factor.scores</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: data.sim.rasch - Different factor scores in Rasch model
#############################################################################

data(data.sim.rasch)
# 1PL estimation
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
# EAP
pmod1 &lt;- IRT.factor.scores( mod1 )
# WLE
pmod1 &lt;- IRT.factor.scores( mod1, type="WLE" )
# MLE
pmod1 &lt;- IRT.factor.scores( mod1, type="MLE" )

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.frequencies.tam'>
Observed and Expected Frequencies for Univariate and Bivariate Distributions
</h2><span id='topic+IRT.frequencies.tam.mml'></span><span id='topic+IRT.frequencies.tam.mml.3pl'></span><span id='topic+IRT.frequencies.tamaan'></span>

<h3>Description</h3>

<p>Computes observed and expected frequencies for univariate and bivariate distributions
for models fitted in <span class="pkg">TAM</span>. See <code><a href="CDM.html#topic+IRT.frequencies">CDM::IRT.frequencies</a></code>
for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam.mml'
IRT.frequencies(object, ...)

## S3 method for class 'tam.mml.3pl'
IRT.frequencies(object, ...)

## S3 method for class 'tamaan'
IRT.frequencies(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.frequencies.tam_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam">tam</a></code>, <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code> or <code><a href="#topic+tamaan">tamaan</a></code>.
</p>
</td></tr>
<tr><td><code id="IRT.frequencies.tam_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See <code><a href="CDM.html#topic+IRT.frequencies">CDM::IRT.frequencies</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="CDM.html#topic+IRT.frequencies">CDM::IRT.frequencies</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Dichotomous data data.sim.rasch
#############################################################################

data(data.sim.rasch)
dat &lt;- data.sim.rasch

# estimate model
mod1 &lt;- TAM::tam.mml(dat)
# compute observed and expected frequencies
fmod1 &lt;- IRT.frequencies(mod1)
str(fmod1)

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.informationCurves'>
Item and Test Information Curve
</h2><span id='topic+IRT.informationCurves'></span><span id='topic+IRT.informationCurves.tam.mml'></span><span id='topic+IRT.informationCurves.tam.mml.2pl'></span><span id='topic+IRT.informationCurves.tam.mml.3pl'></span><span id='topic+IRT.informationCurves.tam.mml.mfr'></span><span id='topic+plot.IRT.informationCurves'></span>

<h3>Description</h3>

<p>An S3 method which computes item and test information curves, see Muraki (1993).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT.informationCurves(object, ...)

## S3 method for class 'tam.mml'
IRT.informationCurves( object, h=.0001, iIndex=NULL,
          theta=NULL, ... )

## S3 method for class 'tam.mml.2pl'
IRT.informationCurves( object, h=.0001, iIndex=NULL,
          theta=NULL, ... )

## S3 method for class 'tam.mml.mfr'
IRT.informationCurves( object, h=.0001, iIndex=NULL,
          theta=NULL, ... )

## S3 method for class 'tam.mml.3pl'
IRT.informationCurves( object, h=.0001, iIndex=NULL,
          theta=NULL, ... )

## S3 method for class 'IRT.informationCurves'
plot(x, curve_type="test", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.informationCurves_+3A_object">object</code></td>
<td>

<p>Object of class <code>tam.mml</code>, <code>tam.mml.2pl</code>, <code>tam.mml.mfr</code>
or <code>tam.mml.3pl</code>.
</p>
</td></tr>
<tr><td><code id="IRT.informationCurves_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
<tr><td><code id="IRT.informationCurves_+3A_h">h</code></td>
<td>
<p>Numerical differentiation parameter</p>
</td></tr>
<tr><td><code id="IRT.informationCurves_+3A_iindex">iIndex</code></td>
<td>
<p>Indices of items for which test information should be computed.
The default is to use all items.</p>
</td></tr>
<tr><td><code id="IRT.informationCurves_+3A_theta">theta</code></td>
<td>
<p>Optional vector of <code class="reqn">\theta</code> for which information curves
should be computed.</p>
</td></tr>
<tr><td><code id="IRT.informationCurves_+3A_curve_type">curve_type</code></td>
<td>
<p>Type of information to be plotted. It can be <code>"test"</code>
for the test information curve and <code>"se"</code> for the
standard error curve.</p>
</td></tr>
<tr><td><code id="IRT.informationCurves_+3A_x">x</code></td>
<td>

<p>Object of class <code>tam.mml</code>, <code>tam.mml.2pl</code>, <code>tam.mml.mfr</code>
or <code>tam.mml.3pl</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with following entries
</p>
<table>
<tr><td><code>se_curve</code></td>
<td>
<p>Standard error curves</p>
</td></tr>
<tr><td><code>test_info_curve</code></td>
<td>
<p>Test information curve</p>
</td></tr>
<tr><td><code>info_curves_item</code></td>
<td>
<p>Item information curves</p>
</td></tr>
<tr><td><code>info_curves_categories</code></td>
<td>
<p>Item-category information curves</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Used <code class="reqn">\theta</code> grid</p>
</td></tr>
</table>


<h3>References</h3>

<p>Muraki, E. (1993). Information functions of the generalized partial credit
model. <em>Applied Psychological Measurement, 17</em>(4), 351-363.
<a href="https://doi.org/10.1177/014662169301700403">doi:10.1177/014662169301700403</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Dichotomous data | data.read
#############################################################################

data(data.read, package="sirt")
dat &lt;- data.read

# fit 2PL model
mod1 &lt;- TAM::tam.mml.2pl( dat )
summary(mod1)

# compute information curves at grid seq(-5,5,length=100)
imod1 &lt;- TAM::IRT.informationCurves( mod1, theta=seq(-5,5,len=100)  )
str(imod1)
# plot test information
plot( imod1 )
# plot standard error curve
plot( imod1, curve_type="se", xlim=c(-3,2) )
# cutomized plot
plot( imod1, curve_type="se", xlim=c(-3,2), ylim=c(0,2), lwd=2, lty=3)

#############################################################################
# EXAMPLE 2: Mixed dichotomous and polytomous data
#############################################################################

data(data.timssAusTwn.scored, package="TAM")
dat &lt;- data.timssAusTwn.scored
# select item response data
items &lt;- grep( "M0", colnames(dat), value=TRUE )
resp &lt;- dat[, items ]

#*** Model 1: Partial credit model
mod1 &lt;- TAM::tam.mml( resp )
summary(mod1)
# information curves
imod1 &lt;- TAM::IRT.informationCurves( mod1, theta=seq(-3,3,len=20)  )

#*** Model 2: Generalized partial credit model
mod2 &lt;- TAM::tam.mml.2pl( resp, irtmodel="GPCM")
summary(mod2)
imod2 &lt;- TAM::IRT.informationCurves( mod2 )

#*** Model 3: Mixed 3PL and generalized partial credit model
psych::describe(resp)
maxK &lt;- apply( resp, 2, max, na.rm=TRUE )
I &lt;- ncol(resp)
# specify guessing parameters, including a prior distribution
est.guess &lt;- 1:I
est.guess[ maxK &gt; 1 ] &lt;- 0
guess &lt;- .2*(est.guess &gt;0)
guess.prior &lt;- matrix( 0, nrow=I, ncol=2 )
guess.prior[ est.guess  &gt; 0, 1] &lt;- 5
guess.prior[ est.guess  &gt; 0, 2] &lt;- 17

# fit model
mod3 &lt;- TAM::tam.mml.3pl( resp, gammaslope.des="2PL", est.guess=est.guess, guess=guess,
           guess.prior=guess.prior,
           control=list( maxiter=100, Msteps=10, fac.oldxsi=0.1,
                        nodes=seq(-8,8,len=41) ),  est.variance=FALSE )
summary(mod3)

# information curves
imod3 &lt;- TAM::IRT.informationCurves( mod3 )
imod3

#*** estimate model in mirt package
library(mirt)
itemtype &lt;- rep("gpcm", I)
itemtype[ maxK==1] &lt;- "3PL"
mod3b &lt;- mirt::mirt(resp, 1, itemtype=itemtype, verbose=TRUE )
print(mod3b)

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.irfprob'>
Extracting Item Response Functions
</h2><span id='topic+IRT.irfprob.tam'></span><span id='topic+IRT.irfprob.tam.mml'></span><span id='topic+IRT.irfprob.tam.mml.3pl'></span><span id='topic+IRT.irfprob.tamaan'></span><span id='topic+IRT.irfprob.tam.np'></span>

<h3>Description</h3>

<p>Extracts item response functions for models
fitted in <span class="pkg">TAM</span>. See <code><a href="CDM.html#topic+IRT.irfprob">CDM::IRT.irfprob</a></code>
for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam'
IRT.irfprob(object, ...)

## S3 method for class 'tam.mml'
IRT.irfprob(object, ...)

## S3 method for class 'tam.mml.3pl'
IRT.irfprob(object, ...)

## S3 method for class 'tamaan'
IRT.irfprob(object, ...)

## S3 method for class 'tam.np'
IRT.irfprob(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.irfprob_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam">tam</a></code>, <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code>, <code><a href="#topic+tam.np">tam.np</a></code> or <code><a href="#topic+tamaan">tamaan</a></code>.
</p>
</td></tr>
<tr><td><code id="IRT.irfprob_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See <code><a href="CDM.html#topic+IRT.irfprob">CDM::IRT.irfprob</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Dichotomous data data.sim.rasch - item response functions
#############################################################################

data(data.sim.rasch)
# 1PL estimation
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
IRT.irfprob(mod1)
</code></pre>

<hr>
<h2 id='IRT.itemfit.tam'>
RMSD Item Fit Statistics for <span class="pkg">TAM</span> Objects
</h2><span id='topic+IRT.itemfit.tam.mml'></span><span id='topic+IRT.itemfit.tam.mml.2pl'></span><span id='topic+IRT.itemfit.tam.mml.mfr'></span><span id='topic+IRT.itemfit.tam.mml.3pl'></span>

<h3>Description</h3>

<p>Computes the RMSD item fit statistic (formerly labeled as RMSEA;
Yamamoto, Khorramdel, &amp; von Davier, 2013) for fitted objects in the
<span class="pkg">TAM</span> package, see
<code><a href="CDM.html#topic+IRT.itemfit">CDM::IRT.itemfit</a></code> and
<code><a href="CDM.html#topic+IRT.RMSD">CDM::IRT.RMSD</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam.mml'
IRT.itemfit(object, method="RMSD", ...)

## S3 method for class 'tam.mml.2pl'
IRT.itemfit(object, method="RMSD", ...)

## S3 method for class 'tam.mml.mfr'
IRT.itemfit(object, method="RMSD", ...)

## S3 method for class 'tam.mml.3pl'
IRT.itemfit(object, method="RMSD", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.itemfit.tam_+3A_object">object</code></td>
<td>

<p>Object of class <code>tam.mml</code>, <code>tam.mml.2pl</code>, <code>tam.mml.mfr</code>
or <code>tam.mml.3pl</code>.
</p>
</td></tr>
<tr><td><code id="IRT.itemfit.tam_+3A_method">method</code></td>
<td>
<p>Requested method for item fit calculation. Currently,
only the RMSD fit statistic (formerly labeled as the RMSEA statistic,
see <code><a href="CDM.html#topic+IRT.RMSD">CDM::IRT.RMSD</a></code>)
can be used.
</p>
</td></tr>
<tr><td><code id="IRT.itemfit.tam_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yamamoto, K., Khorramdel, L., &amp; von Davier, M. (2013). Scaling PIAAC cognitive data.
In OECD (Eds.). <em>Technical Report of the Survey of Adults Skills (PIAAC)</em> (Ch. 17).
Paris: OECD.
</p>


<h3>See Also</h3>

<p><code><a href="CDM.html#topic+IRT.itemfit">CDM::IRT.itemfit</a></code>,
<code><a href="CDM.html#topic+IRT.RMSD">CDM::IRT.RMSD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: RMSD item fit statistic data.read
#############################################################################

library(sirt)
data(data.read,package="sirt")
dat &lt;- data.read

#*** fit 1PL model
mod1 &lt;- TAM::tam.mml( dat )
summary(mod1)

#*** fit 2PL model
mod2 &lt;- TAM::tam.mml.2pl( dat )
summary(mod2)

#*** assess RMSEA item fit
fmod1 &lt;- IRT.itemfit(mod1)
fmod2 &lt;- IRT.itemfit(mod2)
# summary of fit statistics
summary( fmod1 )
summary( fmod2 )

#############################################################################
# EXAMPLE 2: Simulated 2PL data and fit of 1PL model
#############################################################################

set.seed(987)
N &lt;- 1000    # 1000 persons
I &lt;- 10      # 10 items
# define item difficulties and item slopes
b &lt;- seq(-2,2,len=I)
a &lt;- rep(1,I)
a[c(3,8)] &lt;- c( 1.7, .4 )
# simulate 2PL data
dat &lt;- sirt::sim.raschtype( theta=rnorm(N), b=b, fixed.a=a)

# fit 1PL model
mod &lt;- TAM::tam.mml( dat )

# RMSEA item fit
fmod &lt;- IRT.itemfit(mod)
round( fmod, 3 )

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.likelihood'>
Extracting Individual Likelihood and Individual Posterior
</h2><span id='topic+IRT.likelihood.tam'></span><span id='topic+IRT.likelihood.tam.mml'></span><span id='topic+IRT.likelihood.tam.mml.3pl'></span><span id='topic+IRT.likelihood.tamaan'></span><span id='topic+IRT.likelihood.tam.latreg'></span><span id='topic+IRT.likelihood.tam.np'></span><span id='topic+IRT.posterior.tam'></span><span id='topic+IRT.posterior.tam.mml'></span><span id='topic+IRT.posterior.tam.mml.3pl'></span><span id='topic+IRT.posterior.tamaan'></span><span id='topic+IRT.posterior.tam.latreg'></span><span id='topic+IRT.posterior.tam.np'></span>

<h3>Description</h3>

<p>Extracts individual likelihood and posterior for models
fitted in <span class="pkg">TAM</span>. See <code><a href="CDM.html#topic+IRT.likelihood">CDM::IRT.likelihood</a></code>
for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam'
IRT.likelihood(object, ...)
## S3 method for class 'tam'
IRT.posterior(object, ...)

## S3 method for class 'tam.mml'
IRT.likelihood(object, ...)
## S3 method for class 'tam.mml'
IRT.posterior(object, ...)

## S3 method for class 'tam.mml.3pl'
IRT.likelihood(object, ...)
## S3 method for class 'tam.mml.3pl'
IRT.posterior(object, ...)

## S3 method for class 'tamaan'
IRT.likelihood(object, ...)
## S3 method for class 'tamaan'
IRT.posterior(object, ...)

## S3 method for class 'tam.latreg'
IRT.likelihood(object, ...)
## S3 method for class 'tam.latreg'
IRT.posterior(object, ...)

## S3 method for class 'tam.np'
IRT.likelihood(object, ...)
## S3 method for class 'tam.np'
IRT.posterior(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.likelihood_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam">tam</a></code>, <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code>, <code><a href="#topic+tamaan">tamaan</a></code>, <code><a href="#topic+tam.np">tam.np</a></code>
or <code><a href="#topic+tam.latreg">tam.latreg</a></code>.
</p>
</td></tr>
<tr><td><code id="IRT.likelihood_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See <code><a href="CDM.html#topic+IRT.likelihood">CDM::IRT.likelihood</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Dichotomous data data.sim.rasch - extracting likelihood/posterior
#############################################################################

data(data.sim.rasch)
# 1PL estimation
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
lmod1 &lt;- IRT.likelihood(mod1)
str(lmod1)
pmod1 &lt;- IRT.posterior(mod1)
str(pmod1)
</code></pre>

<hr>
<h2 id='IRT.linearCFA'>
Linear Approximation of a Confirmatory Factor Analysis
</h2><span id='topic+IRT.linearCFA'></span><span id='topic+summary.IRT.linearCFA'></span>

<h3>Description</h3>

<p>This function approximates a fitted item response model by a linear
confirmatory factor analysis. I.e., given item response functions, the
expectation <code class="reqn">E(X_i | \theta_1, \ldots, \theta_D)</code> is
linearly approximated by <code class="reqn">a_{i1} \theta _1 + \ldots + a_{iD} \theta_D</code>.
See Vermunt and Magidson (2005) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT.linearCFA( object, group=1)

## S3 method for class 'IRT.linearCFA'
summary(object,  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.linearCFA_+3A_object">object</code></td>
<td>

<p>Fitted item response model for which the <code>IRT.expectedCounts</code>
method is defined.
</p>
</td></tr>
<tr><td><code id="IRT.linearCFA_+3A_group">group</code></td>
<td>
<p>Group identifier which defines the selected group.</p>
</td></tr>
<tr><td><code id="IRT.linearCFA_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with following entries
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>Data frame with factor loadings. <code>Mlat</code> and
<code>SDlat</code> denote the model-implied item mean and standard deviation.
The values <code>ResidVar</code> and <code>h2</code> denote residual variances
and item communality.
</p>
</td></tr>
<tr><td><code>stand.loadings</code></td>
<td>
<p>Data frame with standardized factor loadings.</p>
</td></tr>
<tr><td><code>M.trait</code></td>
<td>
<p>Mean of factors</p>
</td></tr>
<tr><td><code>SD.trait</code></td>
<td>
<p>Standard deviations of factors</p>
</td></tr>
</table>


<h3>References</h3>

<p>Vermunt, J. K., &amp; Magidson, J. (2005). Factor Analysis with categorical
indicators: A comparison between traditional and latent class approaches.
In A. Van der Ark, M.A. Croon &amp; K. Sijtsma (Eds.),
<em>New Developments in Categorical Data Analysis for the Social and
Behavioral Sciences</em> (pp. 41-62). Mahwah: Erlbaum
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+tam.fa">tam.fa</a></code> for confirmatory factor analysis in <span class="pkg">TAM</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(lavaan)

#############################################################################
# EXAMPLE 1: Two-dimensional confirmatory factor analysis data.Students
#############################################################################

data(data.Students, package="CDM")
# select variables
vars &lt;- scan(nlines=1, what="character")
    sc1 sc2 sc3 sc4 mj1 mj2 mj3 mj4
dat &lt;- data.Students[, vars]

# define Q-matrix
Q &lt;- matrix( 0, nrow=8, ncol=2 )
Q[1:4,1] &lt;- Q[5:8,2] &lt;- 1

#*** Model 1: Two-dimensional 2PL model
mod1 &lt;- TAM::tam.mml.2pl( dat, Q=Q, control=list( nodes=seq(-4,4,len=12) ) )
summary(mod1)

# linear approximation CFA
cfa1 &lt;- TAM::IRT.linearCFA(mod1)
summary(cfa1)

# linear CFA in lavaan package
lavmodel &lt;- "
    sc=~ sc1+sc2+sc3+sc4
    mj=~ mj1+mj2+mj3+mj4
    sc1 ~ 1
    sc ~~ mj
    "
mod1b &lt;- lavaan::sem( lavmodel, data=dat, missing="fiml", std.lv=TRUE)
summary(mod1b, standardized=TRUE, fit.measures=TRUE )

#############################################################################
# EXAMPLE 2: Unidimensional confirmatory factor analysis data.Students
#############################################################################

data(data.Students, package="CDM")
# select variables
vars &lt;- scan(nlines=1, what="character")
    sc1 sc2 sc3 sc4
dat &lt;- data.Students[, vars]

#*** Model 1: 2PL model
mod1 &lt;- TAM::tam.mml.2pl( dat )
summary(mod1)

# linear approximation CFA
cfa1 &lt;- TAM::IRT.linearCFA(mod1)
summary(cfa1)

# linear CFA
lavmodel &lt;- "
    sc=~ sc1+sc2+sc3+sc4
    "
mod1b &lt;- lavaan::sem( lavmodel, data=dat, missing="fiml", std.lv=TRUE)
summary(mod1b, standardized=TRUE, fit.measures=TRUE )

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.residuals'>
Residuals in an IRT Model
</h2><span id='topic+IRT.residuals'></span><span id='topic+IRT.residuals.tam.jml'></span><span id='topic+IRT.residuals.tam.mml'></span><span id='topic+IRT.residuals.tam.mml.2pl'></span><span id='topic+IRT.residuals.tam.mml.mfr'></span><span id='topic+residuals.tam.jml'></span><span id='topic+residuals.tam.mml'></span><span id='topic+residuals.tam.mml.2pl'></span><span id='topic+residuals.tam.mml.mfr'></span>

<h3>Description</h3>

<p>Defines an S3 method for the computation of observed residual values.
The computation of residuals is based on weighted likelihood estimates as
person parameters, see <code><a href="#topic+tam.wle">tam.wle</a></code>.
<code>IRT.residuals</code> can only be applied for unidimensional IRT models.
The methods <code>IRT.residuals</code> and <code>residuals</code> are equivalent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT.residuals(object, ...)

## S3 method for class 'tam.mml'
IRT.residuals(object, ...)
## S3 method for class 'tam.mml'
residuals(object, ...)

## S3 method for class 'tam.mml.2pl'
IRT.residuals(object, ...)
## S3 method for class 'tam.mml.2pl'
residuals(object, ...)

## S3 method for class 'tam.mml.mfr'
IRT.residuals(object, ...)
## S3 method for class 'tam.mml.mfr'
residuals(object, ...)

## S3 method for class 'tam.jml'
IRT.residuals(object, ...)
## S3 method for class 'tam.jml'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.residuals_+3A_object">object</code></td>
<td>

<p>Object of class <code>tam.mml</code>, <code>tam.mml.2pl</code> or <code>tam.mml.mfr</code>.
</p>
</td></tr>
<tr><td><code id="IRT.residuals_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with following entries
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>Residuals</p>
</td></tr>
<tr><td><code>stand_residuals</code></td>
<td>
<p>Standardized residuals</p>
</td></tr>
<tr><td><code>X_exp</code></td>
<td>
<p>Expected value of the item response <code class="reqn">X_{pi}</code></p>
</td></tr>
<tr><td><code>X_var</code></td>
<td>
<p>Variance of the item response <code class="reqn">X_{pi}</code></p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Used person parameter estimate</p>
</td></tr>
<tr><td><code>probs</code></td>
<td>
<p>Expected item response probabilities</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Residuals can be used to inspect local dependencies in the item
response data, for example using principle component analysis or
factor analysis (see Example 1).
</p>


<h3>See Also</h3>

<p>See also the <code>eRm::residuals</code> (<b>eRm</b>) or
<code><a href="mirt.html#topic+residuals-method">residuals</a></code> (<b>mirt</b>)
functions.
</p>
<p>See also <code><a href="#topic+predict.tam.mml">predict.tam.mml</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Residuals data.read
#############################################################################

library(sirt)
data(data.read, package="sirt")
dat &lt;- data.read

# for Rasch model
mod &lt;- TAM::tam.mml( dat )
# extract residuals
res &lt;- TAM::IRT.residuals( mod )
str(res)

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.simulate'>
Simulating Item Response Models
</h2><span id='topic+IRT.simulate'></span><span id='topic+IRT.simulate.tam.mml'></span><span id='topic+IRT.simulate.tam.mml.2pl'></span><span id='topic+IRT.simulate.tam.mml.3pl'></span><span id='topic+IRT.simulate.tam.mml.mfr'></span>

<h3>Description</h3>

<p>Defines an S3 method for simulation of item response models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT.simulate(object, ...)

## S3 method for class 'tam.mml'
IRT.simulate(object, iIndex=NULL, theta=NULL, nobs=NULL, ...)

## S3 method for class 'tam.mml.2pl'
IRT.simulate(object, iIndex=NULL, theta=NULL, nobs=NULL, ...)

## S3 method for class 'tam.mml.mfr'
IRT.simulate(object, iIndex=NULL, theta=NULL, nobs=NULL, ...)

## S3 method for class 'tam.mml.3pl'
IRT.simulate(object, iIndex=NULL, theta=NULL, nobs=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.simulate_+3A_object">object</code></td>
<td>

<p>An object of class <code>tam.mml</code>, <code>tam.mml.2pl</code>, <code>tam.mml.mfr</code> or
<code>tam.mml.3pl</code>.
</p>
</td></tr>
<tr><td><code id="IRT.simulate_+3A_iindex">iIndex</code></td>
<td>
<p>Optional vector of item indices</p>
</td></tr>
<tr><td><code id="IRT.simulate_+3A_theta">theta</code></td>
<td>
<p>Optional matrix of <code>theta</code> values</p>
</td></tr>
<tr><td><code id="IRT.simulate_+3A_nobs">nobs</code></td>
<td>
<p>Optional numeric containing the number of observations to be simulated.</p>
</td></tr>
<tr><td><code id="IRT.simulate_+3A_...">...</code></td>
<td>

<p>Further objects to be passed
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame with simulated item responses
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Simulating Rasch model
#############################################################################

data(data.sim.rasch)

#** (1) estimate model
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch )

#** (2) simulate data
sim.dat &lt;- TAM::IRT.simulate(mod1)

## Not run: 
#** (3) use a subset of items with the argument iIndex
set.seed(976)
iIndex &lt;- sort(sample(ncol(data.sim.rasch), 15))  # randomly select 15 items
sim.dat &lt;- TAM::IRT.simulate(mod1, iIndex=iIndex)
mod.sim.dat &lt;- TAM::tam.mml(sim.dat)

#** (4) specify number of persons in addition
sim.dat &lt;- TAM::IRT.simulate(mod1, nobs=1500, iIndex=iIndex)

# Rasch - constraint="items" ----
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch,  constraint="items",
                control=list( xsi.start0=1, fac.oldxsi=.5) )

# provide abilities
theta0 &lt;- matrix( rnorm(1500, mean=0.5, sd=sqrt(mod1$variance)), ncol=1 )
# simulate data
data &lt;- TAM::IRT.simulate(mod1, theta=theta0 )
# estimate model based on simulated data
xsi.fixed &lt;- cbind(1:nrow(mod1$item), mod1$item$xsi.item)
mod2 &lt;- TAM::tam.mml(data, xsi.fixed=xsi.fixed )
summary(mod2)

#############################################################################
# EXAMPLE 2: Simulating 2PL model
#############################################################################

data(data.sim.rasch)
# estimate 2PL
mod2 &lt;- TAM::tam.mml.2pl(resp=data.sim.rasch, irtmodel="2PL")
# simulate 2PL
sim.dat &lt;- TAM::IRT.simulate(mod2)
mod.sim.dat &lt;- TAM::tam.mml.2pl(resp=sim.dat, irtmodel="2PL")

#############################################################################
# EXAMPLE 3: Simulate multiple group model
#############################################################################

# Multi-Group ----
set.seed(6778)
N &lt;- 3000
theta &lt;- c( stats::rnorm(N/2,mean=0,sd=1.5), stats::rnorm(N/2,mean=.5,sd=1)  )
I &lt;- 20
p1 &lt;- stats::plogis( outer( theta, seq( -2, 2, len=I ), "-" ) )
resp &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
colnames(resp) &lt;- paste("I", 1:I, sep="")
group &lt;- rep(1:2, each=N/2 )
mod3 &lt;- TAM::tam.mml(resp, group=group)

# simulate data
sim.dat.g1 &lt;- TAM::IRT.simulate(mod3,
                   theta=matrix( stats::rnorm(N/2, mean=0, sd=1.5), ncol=1) )
sim.dat.g2 &lt;- TAM::IRT.simulate(mod3,
                   theta=matrix( stats::rnorm(N/2, mean=.5, sd=1), ncol=1) )
sim.dat &lt;- rbind( sim.dat.g1, sim.dat.g2)
# estimate model
mod3s &lt;- TAM::tam.mml( sim.dat, group=group)

#############################################################################
# EXAMPLE 4: Multidimensional model and latent regression
#############################################################################

set.seed(6778)
N &lt;- 2000
Y &lt;- cbind( stats::rnorm(N), stats::rnorm(N))
theta &lt;- mvtnorm::rmvnorm(N, mean=c(0,0), sigma=matrix(c(1,.5,.5,1), 2, 2))
theta[,1] &lt;- theta[,1] + .4 * Y[,1] + .2 * Y[,2]  # latent regression model
theta[,2] &lt;- theta[,2] + .8 * Y[,1] + .5 * Y[,2]  # latent regression model
I &lt;- 20
p1 &lt;- stats::plogis(outer(theta[, 1], seq(-2, 2, len=I), "-"))
resp1 &lt;- 1 * (p1 &gt; matrix(stats::runif(N * I), nrow=N, ncol=I))
p1 &lt;- stats::plogis(outer(theta[, 2], seq(-2, 2, len=I ), "-" ))
resp2 &lt;- 1 * (p1 &gt; matrix(stats::runif(N * I), nrow=N, ncol=I))
resp &lt;- cbind(resp1, resp2)
colnames(resp) &lt;- paste("I", 1 : (2 * I), sep="")

# (2) define loading Matrix
Q &lt;- array(0, dim=c(2 * I, 2))
Q[cbind(1:(2*I), c(rep(1, I), rep(2, I)))] &lt;- 1
Q

# (3) estimate models
mod4 &lt;- TAM::tam.mml(resp=resp, Q=Q, Y=Y, control=list(  maxiter=15))

# simulate new item responses
theta &lt;- mvtnorm::rmvnorm(N, mean=c(0,0), sigma=matrix(c(1,.5,.5,1), 2, 2))
theta[,1] &lt;- theta[,1] + .4 * Y[,1] + .2 * Y[,2]  # latent regression model
theta[,2] &lt;- theta[,2] + .8 * Y[,1] + .5 * Y[,2]  # latent regression model

sim.dat &lt;- TAM::IRT.simulate(mod4, theta=theta)
mod.sim.dat &lt;- TAM::tam.mml(resp=sim.dat, Q=Q, Y=Y, control=list( maxiter=15))

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.threshold'>
Thurstonian Thresholds and Wright Map for Item Response Models
</h2><span id='topic+IRT.threshold'></span><span id='topic+IRT.WrightMap'></span><span id='topic+IRT.WrightMap.IRT.threshold'></span><span id='topic+print.IRT.threshold'></span>

<h3>Description</h3>

<p>The function <code>IRT.threshold</code> computes Thurstonian thresholds
for item response models. It is only based on fitted models
for which the <code><a href="CDM.html#topic+IRT.irfprob">IRT.irfprob</a></code> does exist.
</p>
<p>The function <code>IRT.WrightMap</code> creates a Wright map and works as a wrapper to the
<code><a href="WrightMap.html#topic+wrightMap">WrightMap::wrightMap</a></code> function in
the <span class="pkg">WrightMap</span> package. Wright maps operate
on objects of class <code><a href="#topic+IRT.threshold">IRT.threshold</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT.threshold(object, prob.lvl=.5, type="category")

## S3 method for class 'IRT.threshold'
print(x, ...)

IRT.WrightMap(object, ...)

## S3 method for class 'IRT.threshold'
IRT.WrightMap(object, label.items=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.threshold_+3A_object">object</code></td>
<td>

<p>Object of fitted models for which <code><a href="CDM.html#topic+IRT.irfprob">IRT.irfprob</a></code> exists.
</p>
</td></tr>
<tr><td><code id="IRT.threshold_+3A_prob.lvl">prob.lvl</code></td>
<td>
<p>Requested probability level of thresholds.</p>
</td></tr>
<tr><td><code id="IRT.threshold_+3A_type">type</code></td>
<td>
<p>Type of thresholds to be calculated. The default is
category-wise calculation. If only one threshold per item should
be calculated, then choose <code>type="item"</code>. If an item possesses
a maximum score of <code class="reqn">K_i</code>, then a threshold is defined as a
value which produces an expected value of <code class="reqn">K_i /2</code>
(see Ali, Chang &amp; Anderson, 2015).</p>
</td></tr>
<tr><td><code id="IRT.threshold_+3A_x">x</code></td>
<td>
<p>Object of class <code>IRT.threshold</code></p>
</td></tr>
<tr><td><code id="IRT.threshold_+3A_label.items">label.items</code></td>
<td>
<p>Vector of item labels</p>
</td></tr>
<tr><td><code id="IRT.threshold_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Function <code>IRT.threshold</code>:<br />
Matrix with Thurstonian thresholds
</p>
<p>Function <code>IRT.WrightMap</code>: <br />
A Wright map generated by the <span class="pkg">WrightMap</span> package.
</p>


<h3>Author(s)</h3>

<p>The <code>IRT.WrightMap</code> function is based on the
<code><a href="WrightMap.html#topic+wrightMap">WrightMap::wrightMap</a></code> function
in the <span class="pkg"><a href="WrightMap.html#topic+WrightMap">WrightMap</a></span> package.
</p>


<h3>References</h3>

<p>Ali, U. S., Chang, H.-H., &amp; Anderson, C. J. (2015). <em>Location indices for ordinal
polytomous items based on item response theory</em> (Research
Report No. RR-15-20). Princeton, NJ: Educational Testing Service.
<a href="https://doi.org/10.1002/ets2.12065">doi:10.1002/ets2.12065</a>
</p>


<h3>See Also</h3>

<p>See the <code><a href="WrightMap.html#topic+wrightMap">WrightMap::wrightMap</a></code> function in
the <span class="pkg">WrightMap</span> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Fitted unidimensional model with gdm
#############################################################################

data(data.Students)
dat &lt;- data.Students

# select part of the dataset
resp &lt;- dat[, paste0("sc",1:4) ]
resp[ paste(resp[,1])==3,1] &lt;-  2
psych::describe(resp)

# Model 1: Partial credit model in gdm
theta.k &lt;- seq( -5, 5, len=21 )   # discretized ability
mod1 &lt;- CDM::gdm( dat=resp, irtmodel="1PL", theta.k=theta.k, skillspace="normal",
              centered.latent=TRUE)

# compute thresholds
thresh1 &lt;- TAM::IRT.threshold(mod1)
print(thresh1)
IRT.WrightMap(thresh1)

#############################################################################
# EXAMPLE 2: Fitted mutidimensional model with gdm
#############################################################################

data( data.fraction2 )
dat &lt;- data.fraction2$data
Qmatrix &lt;- data.fraction2$q.matrix3

# Model 1: 3-dimensional Rasch Model (normal distribution)
theta.k &lt;- seq( -4, 4, len=11 )   # discretized ability
mod1 &lt;- CDM::gdm( dat, irtmodel="1PL", theta.k=theta.k, Qmatrix=Qmatrix,
              centered.latent=TRUE, maxiter=10 )
summary(mod1)

# compute thresholds
thresh1 &lt;- TAM::IRT.threshold(mod1)
print(thresh1)

#############################################################################
# EXAMPLE 3: Item-wise thresholds
#############################################################################

data(data.timssAusTwn.scored)
dat &lt;- data.timssAusTwn.scored
dat &lt;- dat[, grep("M03", colnames(dat) ) ]
summary(dat)

# fit partial credit model
mod &lt;- TAM::tam.mml( dat )
# compute thresholds with tam.threshold function
t1mod &lt;- TAM::tam.threshold( mod )
t1mod
# compute thresholds with IRT.threshold function
t2mod &lt;- TAM::IRT.threshold( mod )
t2mod
# compute item-wise thresholds
t3mod &lt;- TAM::IRT.threshold( mod, type="item")
t3mod

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.truescore'>
Converts a <code class="reqn">\theta</code> Score into a True Score <code class="reqn">\tau ( \theta)</code>
</h2><span id='topic+IRT.truescore'></span>

<h3>Description</h3>

<p>Converts a <code class="reqn">\theta</code> score into an unweighted true score
<code class="reqn">\tau ( \theta)=\sum_i \sum_h h P_i ( \theta ) </code>.
In addition, a weighted true score
<code class="reqn">\tau ( \theta)=\sum_i \sum_h q_{ih} P_i ( \theta ) </code>
can also be computed by specifying item-category weights
<code class="reqn">q_{ih}</code> in the matrix <code>Q</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT.truescore(object, iIndex=NULL, theta=NULL, Q=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.truescore_+3A_object">object</code></td>
<td>

<p>Object for which the
<code><a href="CDM.html#topic+IRT.irfprob">CDM::IRT.irfprob</a></code> S3 method is defined
</p>
</td></tr>
<tr><td><code id="IRT.truescore_+3A_iindex">iIndex</code></td>
<td>

<p>Optional vector with item indices
</p>
</td></tr>
<tr><td><code id="IRT.truescore_+3A_theta">theta</code></td>
<td>

<p>Optional vector with <code class="reqn">\theta</code> values
</p>
</td></tr>
<tr><td><code id="IRT.truescore_+3A_q">Q</code></td>
<td>
<p>Optional weighting matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame containing <code class="reqn">\theta</code> values and corresponding
true scores <code class="reqn">\tau( \theta ) </code>.
</p>


<h3>See Also</h3>

<p>See also <code>sirt::truescore.irt</code>
for a conversion function for generalized partial credit models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: True score conversion for a test with polytomous items
#############################################################################

data(data.Students, package="CDM")
dat &lt;- data.Students[, paste0("mj",1:4) ]

# fit partial credit model
mod1 &lt;- TAM::tam.mml( dat,control=list(maxiter=20) )
summary(mod1)

# true score conversion
tmod1 &lt;- TAM::IRT.truescore( mod1 )
round( tmod1, 4 )
# true score conversion with user-defined theta grid
tmod1b &lt;- TAM::IRT.truescore( mod1, theta=seq( -8,8, len=33 ) )
# plot results
plot( tmod1$theta, tmod1$truescore, type="l",
            xlab=expression(theta), ylab=expression(tau( theta ) ) )
points( tmod1b$theta, tmod1b$truescore, pch=16, col="brown" )

## Not run: 
#############################################################################
# EXAMPLE 2: True scores with different category weightings
#############################################################################

data(data.timssAusTwn.scored)
dat &lt;- data.timssAusTwn.scored
# extract item response data
dat &lt;- dat[, grep("M03", colnames(dat) ) ]
# select items with do have maximum score of 2 (polytomous items)
ind &lt;- which( apply( dat,  2, max, na.rm=TRUE )==2 )
I &lt;- ncol(dat)
# define Q-matrix with scoring variant
Q &lt;- matrix( 1, nrow=I, ncol=1 )
Q[ ind, 1 ] &lt;- .5    # score of 0.5 for polyomous items

# estimate model
mod1 &lt;- TAM::tam.mml( dat, Q=Q, irtmodel="PCM2", control=list( nodes=seq(-10,10,len=61) ) )
summary(mod1)

# true score with scoring (0,1,2) which is the default of the function
tmod1 &lt;- TAM::IRT.truescore(mod1)
# true score with user specified weighting matrix
Q &lt;- mod1$B[,,1]
tmod2 &lt;- TAM::IRT.truescore(mod1, Q=Q)

## End(Not run)
</code></pre>

<hr>
<h2 id='IRT.WrightMap'>
Wright Map for Item Response Models by Using the <span class="pkg">WrightMap</span> Package
</h2><span id='topic+IRT.WrightMap.tam.mml'></span><span id='topic+IRT.WrightMap.tamaan'></span>

<h3>Description</h3>

<p>This function creates a Wright map and works as a wrapper to the
<code><a href="WrightMap.html#topic+wrightMap">wrightMap</a></code> function in
the <span class="pkg">WrightMap</span> package. The arguments <code>thetas</code> and
<code>thresholds</code> are automatically generated from fitted
objects in <span class="pkg">TAM</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam.mml'
IRT.WrightMap(object, prob.lvl=.5, type="PV", ...)

## S3 method for class 'tamaan'
IRT.WrightMap(object, prob.lvl=.5, type="PV", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRT.WrightMap_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam.mml">tam.mml</a></code> or class <code><a href="#topic+tamaan">tamaan</a></code>
</p>
</td></tr>
<tr><td><code id="IRT.WrightMap_+3A_prob.lvl">prob.lvl</code></td>
<td>
<p>Requested probability level of thresholds.</p>
</td></tr>
<tr><td><code id="IRT.WrightMap_+3A_type">type</code></td>
<td>
<p>Type of person parameter estimate. <code>"PV"</code> (plausible values),
<code>"WLE"</code> (weighted likelihood estimates) and
<code>"Pop"</code> (population trait distribution) can be specified.</p>
</td></tr>
<tr><td><code id="IRT.WrightMap_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed in the
<code><a href="WrightMap.html#topic+wrightMap">wrightMap</a></code> (<span class="pkg">WrightMap</span>) function.
See Examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Wright map is only created for models with an assumed normal distribution.
Hence, not for all models of the <code><a href="#topic+tamaan">tamaan</a></code> functions
Wright maps are created.
</p>


<h3>Value</h3>

<p>A Wright map generated by the <span class="pkg">WrightMap</span> package.
</p>


<h3>Author(s)</h3>

<p>The <code>IRT.WrightMap</code> function is based on the
<code><a href="WrightMap.html#topic+wrightMap">WrightMap::wrightMap</a></code> function
in the <span class="pkg"><a href="WrightMap.html#topic+WrightMap">WrightMap</a></span> package.
</p>


<h3>See Also</h3>

<p>See the <code><a href="WrightMap.html#topic+wrightMap">WrightMap::wrightMap</a></code> function in
the <span class="pkg">WrightMap</span> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(WrightMap)

#############################################################################
# EXAMPLE 1: Unidimensional models dichotomous data
#############################################################################

data(data.sim.rasch)
str(data.sim.rasch)
dat &lt;- data.sim.rasch

# fit Rasch model
mod1 &lt;- TAM::tam.mml(resp=dat)
# Wright map
IRT.WrightMap( mod1 )
# some customized plots
IRT.WrightMap( mod1, show.thr.lab=FALSE, label.items=c(1:40), label.items.rows=3)

IRT.WrightMap( mod1,  show.thr.sym=FALSE, thr.lab.text=paste0("I",1:ncol(dat)),
     label.items="", label.items.ticks=FALSE)

#--- direct specification with wrightMap function
theta &lt;- TAM::tam.wle(mod1)$theta
thr &lt;- TAM::tam.threshold(mod1)

# default wrightMap plots
WrightMap::wrightMap( theta, thr, label.items.srt=90)
WrightMap::wrightMap( theta, t(thr), label.items=c("items") )

# stack all items below each other
thr.lab.text &lt;- matrix( "", 1, ncol(dat) )
thr.lab.text[1,] &lt;- colnames(dat)
WrightMap::wrightMap( theta, t(thr), label.items=c("items"),
       thr.lab.text=thr.lab.text, show.thr.sym=FALSE )

#############################################################################
# EXAMPLE 2: Unidimensional model polytomous data
#############################################################################

data( data.Students, package="CDM")
dat &lt;- data.Students

# fit generalized partial credit model using the tamaan function
tammodel &lt;- "
LAVAAN MODEL:
  SC=~ sc1__sc4
  SC ~~ 1*SC
    "
mod1 &lt;- TAM::tamaan( tammodel, dat )
# create item level colors
library(RColorBrewer)
ncat &lt;- 3               # number of category parameters
I &lt;- ncol(mod1$resp)    # number of items
itemlevelcolors &lt;- matrix(rep( RColorBrewer::brewer.pal(ncat, "Set1"), I),
        byrow=TRUE, ncol=ncat)
# Wright map
IRT.WrightMap(mod1, prob.lvl=.625, thr.sym.col.fg=itemlevelcolors,
     thr.sym.col.bg=itemlevelcolors, label.items=colnames( mod1$resp) )

#############################################################################
# EXAMPLE 3: Multidimensional item response model
#############################################################################

data( data.read, package="sirt")
dat &lt;- data.read

# fit three-dimensional Rasch model
Q &lt;- matrix( 0, nrow=12, ncol=3 )
Q[1:4,1] &lt;- Q[5:8,2] &lt;- Q[9:12,3] &lt;- 1
mod1 &lt;- TAM::tam.mml( dat, Q=Q, control=list(maxiter=20, snodes=1000)  )
summary(mod1)
# define matrix with colors for thresholds
c1 &lt;- matrix( c( rep(1,4), rep(2,4), rep(4,4)), ncol=1 )
# create Wright map using WLE
IRT.WrightMap( mod1, prob.lvl=.65, type="WLE", thr.lab.col=c1, thr.sym.col.fg=c1,
        thr.sym.col.bg=c1, label.items=colnames(dat) )
# Wright map using PV (the default)
IRT.WrightMap( mod1, prob.lvl=.65, type="PV" )
# Wright map using population distribution
IRT.WrightMap( mod1, prob.lvl=.65, type="Pop" )

#############################################################################
# EXAMPLE 4: Wright map for a multi-faceted Rasch model
#############################################################################

# This example is copied from
# http://wrightmap.org/post/107431190622/wrightmap-multifaceted-models

library(WrightMap)
data(data.ex10)
dat &lt;- data.ex10

#--- fit multi-faceted Rasch model
facets &lt;- dat[, "rater", drop=FALSE]  # define facet (rater)
pid &lt;- dat$pid  # define person identifier (a person occurs multiple times)
resp &lt;- dat[, -c(1:2)]  # item response data
formulaA &lt;- ~item * rater  # formula
mod &lt;- TAM::tam.mml.mfr(resp=resp, facets=facets, formulaA=formulaA, pid=dat$pid)

# person parameters
persons.mod &lt;- TAM::tam.wle(mod)
theta &lt;- persons.mod$theta
# thresholds
thr &lt;- TAM::tam.threshold(mod)
item.labs &lt;- c("I0001", "I0002", "I0003", "I0004", "I0005")
rater.labs &lt;- c("rater1", "rater2", "rater3")

#--- Plot 1: Item specific
thr1 &lt;- matrix(thr, nrow=5, byrow=TRUE)
WrightMap::wrightMap(theta, thr1, label.items=item.labs,
   thr.lab.text=rep(rater.labs, each=5))

#--- Plot 2: Rater specific
thr2 &lt;- matrix(thr, nrow=3)
WrightMap::wrightMap(theta, thr2, label.items=rater.labs,
   thr.lab.text=rep(item.labs,  each=3), axis.items="Raters")

#--- Plot 3a: item, rater and item*rater parameters
pars &lt;- mod$xsi.facets$xsi
facet &lt;- mod$xsi.facets$facet

item.par &lt;- pars[facet=="item"]
rater.par &lt;- pars[facet=="rater"]
item_rat &lt;- pars[facet=="item:rater"]

len &lt;- length(item_rat)
item.long &lt;- c(item.par, rep(NA, len - length(item.par)))
rater.long &lt;- c(rater.par, rep(NA, len - length(rater.par)))
ir.labs &lt;- mod$xsi.facets$parameter[facet=="item:rater"]

WrightMap::wrightMap(theta, rbind(item.long, rater.long, item_rat),
    label.items=c("Items",  "Raters", "Item*Raters"),
    thr.lab.text=rbind(item.labs, rater.labs, ir.labs), axis.items="")

#--- Plot 3b: item, rater and item*rater (separated by raters) parameters

# parameters item*rater
ir_rater &lt;- matrix(item_rat, nrow=3, byrow=TRUE)
# define matrix of thresholds
thr &lt;- rbind(item.par, c(rater.par, NA, NA), ir_rater)
# matrix with threshold labels
thr.lab.text &lt;- rbind(item.labs, rater.labs,
           matrix(item.labs, nrow=3, ncol=5, byrow=TRUE))

WrightMap::wrightMap(theta, thresholds=thr,
      label.items=c("Items", "Raters", "Item*Raters (R1)",
                           "Item*Raters (R2)", "Item*Raters (R3)"),
      axis.items="", thr.lab.text=thr.lab.text )

#--- Plot 3c: item, rater and item*rater (separated by items) parameters

# thresholds
ir_item &lt;- matrix(item_rat, nrow=5)
thr &lt;- rbind(item.par, c(rater.par, NA, NA), cbind(ir_item, NA, NA))
# labels
label.items &lt;- c("Items", "Raters", "Item*Raters\n (I1)", "Item*Raters \n(I2)",
     "Item*Raters \n(I3)", "Item*Raters \n (I4)", "Item*Raters \n(I5)")
thr.lab.text &lt;- rbind(item.labs,
          matrix(c(rater.labs, NA, NA), nrow=6, ncol=5, byrow=TRUE))

WrightMap::wrightMap(theta, thr,  label.items=label.items,
      axis.items="", thr.lab.text=thr.lab.text  )

## End(Not run)
</code></pre>

<hr>
<h2 id='IRTLikelihood.cfa'>
Individual Likelihood for Confirmatory Factor Analysis
</h2><span id='topic+IRTLikelihood.cfa'></span>

<h3>Description</h3>

<p>This function computes the individual likelihood evaluated
at a <code>theta</code> grid for confirmatory factor analysis
under the normality assumption of residuals. Either
the item parameters (item loadings <code>L</code>, item
intercepts <code>nu</code> and residual covariances <code>psi</code>)
or a fitted <code>cfa</code> object from the <span class="pkg">lavaan</span>
package can be provided. The individual likelihood
can be used for drawing plausible values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRTLikelihood.cfa(data, cfaobj=NULL, theta=NULL, L=NULL, nu=NULL,
    psi=NULL, snodes=NULL, snodes.adj=2, version=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRTLikelihood.cfa_+3A_data">data</code></td>
<td>

<p>Dataset with item responses
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.cfa_+3A_cfaobj">cfaobj</code></td>
<td>

<p>Fitted <code><a href="lavaan.html#topic+cfa">lavaan::cfa</a></code> (<span class="pkg">lavaan</span>) object
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.cfa_+3A_theta">theta</code></td>
<td>

<p>Optional matrix containing the <code>theta</code> values
used for evaluating the individual likelihood
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.cfa_+3A_l">L</code></td>
<td>

<p>Matrix of item loadings (if <code>cfaobj</code> is not provided)
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.cfa_+3A_nu">nu</code></td>
<td>

<p>Vector of item intercepts (if <code>cfaobj</code> is not provided)
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.cfa_+3A_psi">psi</code></td>
<td>

<p>Matrix with residual covariances
(if <code>cfaobj</code> is not provided)
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.cfa_+3A_snodes">snodes</code></td>
<td>

<p>Number of <code>theta</code> values used for the approximation
of the distribution of latent variables.
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.cfa_+3A_snodes.adj">snodes.adj</code></td>
<td>

<p>Adjustment factor for quasi monte carlo nodes for
more than two latent variables.
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.cfa_+3A_version">version</code></td>
<td>
<p>Function version. <code>version=1</code> is based on a
<span class="pkg">Rcpp</span> implementation while <code>version=0</code> is
a pure <span class="rlang"><b>R</b></span> implementation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Individual likelihood evaluated at <code>theta</code>
</p>


<h3>See Also</h3>

<p><code><a href="CDM.html#topic+IRT.likelihood">CDM::IRT.likelihood</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Two-dimensional CFA data.Students
#############################################################################

library(lavaan)
library(CDM)

data(data.Students, package="CDM")
dat &lt;- data.Students

dat2 &lt;- dat[, c(paste0("mj",1:4), paste0("sc",1:4)) ]
# lavaan model with DO operator
lavmodel &lt;- "
DO(1,4,1)
   mj=~ mj%
   sc=~ sc%
DOEND
   mj ~~ sc
   mj ~~ 1*mj
   sc ~~ 1*sc
     "
lavmodel &lt;- TAM::lavaanify.IRT( lavmodel, data=dat2 )$lavaan.syntax
cat(lavmodel)

mod4 &lt;- lavaan::cfa( lavmodel, data=dat2, std.lv=TRUE )
summary(mod4, standardized=TRUE, rsquare=TRUE )
# extract item parameters
res4 &lt;- TAM::cfa.extract.itempars( mod4 )
# create theta grid
theta0 &lt;- seq( -6, 6, len=15)
theta &lt;- expand.grid( theta0, theta0 )
L &lt;- res4$L
nu &lt;- res4$nu
psi &lt;- res4$psi
data &lt;- dat2
# evaluate likelihood using item parameters
like2 &lt;- TAM::IRTLikelihood.cfa( data=dat2, theta=theta, L=L, nu=nu, psi=psi )
# The likelihood can also be obtained by direct evaluation
# of the fitted cfa object "mod4"
like4 &lt;- TAM::IRTLikelihood.cfa( data=dat2, cfaobj=mod4 )
attr( like4, "theta")
# the theta grid is automatically created if theta is not
# supplied as an argument

## End(Not run)
</code></pre>

<hr>
<h2 id='IRTLikelihood.ctt'>
Computes Individual Likelihood from Classical Test Theory Estimates
</h2><span id='topic+IRTLikelihood.ctt'></span>

<h3>Description</h3>

<p>Computes individual likelihood from classical test theory estimates
under a unidimensional normal distribution of measurement errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRTLikelihood.ctt(y, errvar, theta=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRTLikelihood.ctt_+3A_y">y</code></td>
<td>

<p>Vector of observed scores
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.ctt_+3A_errvar">errvar</code></td>
<td>

<p>Vector of error variances
</p>
</td></tr>
<tr><td><code id="IRTLikelihood.ctt_+3A_theta">theta</code></td>
<td>

<p>Optional vector for <code class="reqn">\theta</code> grid.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>IRT.likelihood</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Individual likelihood and latent regression in CTT
#############################################################################

set.seed(75)

#--- simulate data
N &lt;- 2000
x1 &lt;- stats::rnorm(N)
x2 &lt;- .7 * x1 + stats::runif(N)
# simulate true score
theta &lt;- 1.2 + .6*x1 + .3 *x2 + stats::rnorm(N, sd=sqrt(.50) )
var(theta)
# simulate measurement error variances
errvar &lt;- stats::runif( N, min=.6, max=.9 )
# simulate observed scores
y &lt;- theta + stats::rnorm( N, sd=sqrt( errvar) )

#--- create likelihood object
like1 &lt;- TAM::IRTLikelihood.ctt( y=y, errvar=errvar, theta=NULL )

#--- estimate latent regression
X &lt;- data.frame(x1,x2)
mod1 &lt;- TAM::tam.latreg( like=like1, Y=X )

## Not run: 
#--- draw plausible values
pv1 &lt;- TAM::tam.pv( mod1, normal.approx=TRUE )

#--- create datalist
datlist1 &lt;- TAM::tampv2datalist( pv1, pvnames="thetaPV", Y=X )

#--- statistical inference on plausible values using mitools package
library(mitools)
datlist1a &lt;- mitools::imputationList(datlist1)

# fit linear regression and apply Rubin formulas
mod2 &lt;- with( datlist1a, stats::lm( thetaPV ~ x1 + x2 ) )
summary( mitools::MIcombine(mod2) )

## End(Not run)
</code></pre>

<hr>
<h2 id='lavaanify.IRT'>
Slight Extension of the <code>lavaan</code> Syntax, with Focus on Item Response Models
</h2><span id='topic+lavaanify.IRT'></span>

<h3>Description</h3>

<p>This functions slightly extends the <code>lavaan</code>
syntax implemented in the <span class="pkg">lavaan</span> package
(see <code><a href="lavaan.html#topic+lavaanify">lavaan::lavaanify</a></code>).
</p>
<p>Guessing and slipping parameters can be specified
by using the operators <code>?=g1</code> and <code>?=s1</code>,
respectively.
</p>
<p>The operator <code>__</code> can be used for a convenient
specification for groups of items. For example, <code>I1__I5</code> refers
to items <code>I1,...,I5</code>. The operator <code>__</code> can also be used for
item labels (see Example 2).
</p>
<p>Nonlinear terms can also be specified for loadings (<code>=~</code>) and
regressions (<code>~</code>) (see Example 3).
</p>
<p>It is also possible to construct the syntax using a loop by making use
of the <code>DO</code> statement, see <code><a href="#topic+doparse">doparse</a></code> for specification.
</p>
<p>The operators <code>MEASERR1</code> and <code>MEASERR0</code> can be used for
model specification for variables which contains known measurement
error (see Example 6). While <code>MEASERR1</code> can be used for endogenous
variables, <code>MEASERR0</code> provides the specification for exogeneous variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lavaanify.IRT(lavmodel, items=NULL, data=NULL, include.residuals=TRUE,
    doparse=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lavaanify.IRT_+3A_lavmodel">lavmodel</code></td>
<td>

<p>A model in <code>lavaan</code> syntax plus the additional
operators <code>?=g1</code>, <code>?=s1</code>, <code>__</code> and nonlinear terms.
</p>
</td></tr>
<tr><td><code id="lavaanify.IRT_+3A_items">items</code></td>
<td>
<p>Optional vector of item names</p>
</td></tr>
<tr><td><code id="lavaanify.IRT_+3A_data">data</code></td>
<td>
<p>Optional data frame with item responses</p>
</td></tr>
<tr><td><code id="lavaanify.IRT_+3A_include.residuals">include.residuals</code></td>
<td>
<p>Optional logical indicating whether
residual variances should be processed such that they
are freely estimated.</p>
</td></tr>
<tr><td><code id="lavaanify.IRT_+3A_doparse">doparse</code></td>
<td>
<p>Optional logical indicating whether <code>lavmodel</code>
should be parsed for <code>DO</code> statements.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with following entries
</p>
<table>
<tr><td><code>lavpartable</code></td>
<td>
<p>A <code>lavaan</code> parameter table</p>
</td></tr>
<tr><td><code>lavaan.syntax</code></td>
<td>
<p>Processed syntax for <span class="pkg">lavaan</span> package</p>
</td></tr>
<tr><td><code>nonlin_factors</code></td>
<td>
<p>Data frame with renamed and original nonlinear
factor specifications</p>
</td></tr>
<tr><td><code>nonlin_syntable</code></td>
<td>
<p>Data frame with original and modified
syntax if nonlinear factors are used.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="lavaan.html#topic+lavaanify">lavaan::lavaanify</a></code>
</p>
<p>See <code>sirt::tam2mirt</code> for
converting objects of class <code>tam</code> into <code>mirt</code>
objects.
</p>
<p>See <code>sirt::lavaan2mirt</code>
for estimating models in the <b>mirt</b> package using <code>lavaan</code> syntax.
</p>
<p>See <code><a href="#topic+doparse">doparse</a></code> for the <code>DO</code> and <code>DO2</code> statements.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lavaan)

#############################################################################
# EXAMPLE 1: lavaan syntax with guessing and slipping parameters
#############################################################################

# define model in lavaan
lavmodel &lt;- "
    F=~ A1+c*A2+A3+A4
    # define slipping parameters for A1 and A2
    A1 + A2 ?=s1
    # joint guessing parameter for A1 and A2
    A1+A2 ?=c1*g1
    A3 | 0.75*t1
    # fix guessing parameter to .25 and
    # slipping parameter to .01 for item A3
    A3 ?=.25*g1+.01*s1
    A4 ?=c2*g1
    A1 | a*t1
    A2 | b*t1
      "

# process lavaan syntax
lavpartable &lt;- TAM::lavaanify.IRT(lavmodel)$lavpartable
  ##     id lhs op rhs user group free ustart exo label eq.id unco
  ##  1   1   F=~  A1    1     1    1     NA   0           0    1
  ##  2   2   F=~  A2    1     1    2     NA   0     c     0    2
  ##  3   3   F=~  A3    1     1    3     NA   0           0    3
  ##  4   4   F=~  A4    1     1    4     NA   0           0    4
  ##  5   5  A3  |  t1    1     1    0   0.75   0           0    0
  ##  6   6  A1  |  t1    1     1    5     NA   0     a     0    5
  ##  7   7  A2  |  t1    1     1    6     NA   0     b     0    6
  ##  8   8  A1 ?=s1    1     1    7     NA   0           0    7
  ##  9   9  A2 ?=s1    1     1    8     NA   0           0    8
  ##  10 10  A1 ?=g1    1     1    9     NA   0    c1     1    9
  ##  11 11  A2 ?=g1    1     1    9     NA   0    c1     1   10
  ##  12 12  A3 ?=g1    1     1    0   0.25   0           0    0
  ##  13 13  A3 ?=s1    1     1    0   0.01   0           0    0
  ##  14 14  A4 ?=g1    1     1   10     NA   0    c2     0   11

## Not run: 
#############################################################################
# EXAMPLE 2: Usage of "__" and "?=" operators
#############################################################################

library(sirt)
data(data.read, package="sirt")
dat &lt;- data.read
items &lt;- colnames(dat)

lavmodel &lt;- "
   F1=~ A1+A2+ A3+lam4*A4
   # equal item loadings for items B1 to B4
   F2=~ lam5*B1__B4
   # different labelled item loadings of items C1 to C4
   F3=~ lam9__lam12*C1__C4
   # item intercepts
   B1__B2 | -0.5*t1
   B3__C1 | int6*t1
   # guessing parameters
   C1__C3 ?=g1
   C4 + B1__B3 ?=0.2*g1
   # slipping parameters
   A1__B1 + B3__C2 ?=slip1*s1
   # residual variances
   B1__B3 ~~ errB*B1__B3
   A2__A4 ~~ erra1__erra3*A2__A4
    "
lav2 &lt;- TAM::lavaanify.IRT( lavmodel, data=dat)
lav2$lavpartable
cat( lav2$lavaan.syntax )

#** simplified example
lavmodel &lt;- "
   F1=~ A1+lam4*A2+A3+lam4*A4
   F2=~ lam5__lam8*B1__B4
   F1 ~~ F2
   F1 ~~ 1*F1
   F2 ~~ 1*F2
    "
lav3 &lt;- TAM::lavaanify.IRT( lavmodel, data=dat)
lav3$lavpartable
cat( lav3$lavaan.syntax )

#############################################################################
# EXAMPLE 3: Nonlinear terms
#############################################################################

#*** define items
items &lt;- paste0("I",1:12)

#*** define lavaan model
lavmodel &lt;- "
   F1=~ I1__I5
   F2=~ I6__I9
   F3=~ I10__I12
   # I3, I4 and I7 load on interaction of F1 and F2
   I(F1*F2)=~ a*I3+a*I4
   I(F1*F2)=~ I7
   # I3 and I5 load on squared factor F1
   I(F1^2)=~ I3 + I5
   # I1 regression on B spline version of factor F1
   I( bs(F1,4) )=~ I1
   F2 ~ F1 + b*I(F1^2) + I(F1&gt;0)
   F3 ~ F1 + F2 + 1.4*I(F1*F2) + b*I(F1^2) + I(F2^2 )
   # F3 ~ F2 + I(F2^2)      # this line is ignored in the lavaan model
   F1 ~~ 1*F1
    "

#*** process lavaan syntax
lav3 &lt;- TAM::lavaanify.IRT( lavmodel, items=items)

#*** inspect results
lav3$lavpartable
cat( lav3$lavaan.syntax )
lav3$nonlin_syntable
lav3$nonlin_factors

#############################################################################
# EXAMPLE 4: Using lavaanify.IRT for estimation with lavaan
#############################################################################

data(data.big5, package="sirt")
# extract first 10 openness items
items &lt;- which( substring( colnames(data.big5), 1, 1 )=="O"  )[1:10]
dat &lt;- as.data.frame( data.big5[, items ] )
  ##   &gt; colnames(dat)
  ##    [1] "O3"  "O8"  "O13" "O18" "O23" "O28" "O33" "O38" "O43" "O48"
apply(dat,2,var)  # variances

#*** Model 1: Confirmatory factor analysis with one factor
lavmodel &lt;- "
   O=~ O3__O48   # convenient syntax for defining the factor for all items
   O ~~ 1*O
   "
# process lavaan syntax
res &lt;- TAM::lavaanify.IRT( lavmodel, data=dat )
# estimate lavaan model
mod1 &lt;- lavaan::lavaan( model=res$lavaan.syntax, data=dat)
summary(mod1, standardized=TRUE, fit.measures=TRUE, rsquare=TRUE )

## End(Not run)

#############################################################################
# EXAMPLE 5: lavaanify.IRT with do statements
#############################################################################

lavmodel &lt;- "
  DO(1,6,1)
    F=~ I%
  DOEND
  DO(1,5,2)
    A=~ I%
  DOEND
  DO(2,6,2)
    B=~ I%
  DOEND
  F ~~ 1*F
  A ~~ 1*A
  B ~~ 1*B
  F ~~ 0*A
  F ~~ 0*B
  A ~~ 0*B
   "
res &lt;- TAM::lavaanify.IRT( lavmodel, items=paste("I",1:6) )
cat(res$lavaan.syntax)

#############################################################################
# EXAMPLE 6: Single indicator models with measurement error (MEASERR operator)
#############################################################################

# define lavaan model
lavmodel &lt;- "
  ytrue ~ xtrue + z
  # exogeneous variable error-prone y with error variance .20
  MEASERR1(ytrue,y,.20)
  # exogeneous variable error-prone x with error variance .35
  MEASERR0(xtrue,x,.35)
  ytrue ~~ ytrue
    "
# observed items
items &lt;- c("y","x","z")
# lavaanify
res &lt;- TAM::lavaanify.IRT( lavmodel, items )
cat(res$lavaan.syntax)
  ##   &gt; cat(res$lavaan.syntax)
  ##   ytrue~xtrue
  ##   ytrue~z
  ##   ytrue=~1*y
  ##   y~~0.2*y
  ##   xtrue=~1*x
  ##   x~~0.35*x
  ##   xtrue~~xtrue
  ##   ytrue~~ytrue
  ##   z~~z
</code></pre>

<hr>
<h2 id='msq.itemfit'>
Mean Squared Residual Based Item Fit Statistics (Infit, Outfit)
</h2><span id='topic+msq.itemfit'></span><span id='topic+summary.msq.itemfit'></span><span id='topic+msq.itemfitWLE'></span><span id='topic+summary.msq.itemfitWLE'></span>

<h3>Description</h3>

<p>The function <code>msq.itemfit</code> computes computed the outfit and infit statistic
for items or item groups. Contrary to <code><a href="#topic+tam.fit">tam.fit</a></code>, the function
<code>msq.itemfit</code> is not based on simulation from individual posterior distributions
but rather on evaluating the individual posterior.
</p>
<p>The function <code>msq.itemfit</code> also computes the outfit and infit statistics
but these are based on weighted likelihood estimates obtained from
<code><a href="#topic+tam.wle">tam.wle</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msq.itemfit( object, fitindices=NULL)

## S3 method for class 'msq.itemfit'
summary(object, file=NULL, ... )

msq.itemfitWLE( tamobj, fitindices=NULL, ... )

## S3 method for class 'msq.itemfitWLE'
summary(object, file=NULL, ... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msq.itemfit_+3A_object">object</code></td>
<td>

<p>Object for which the classes <code>IRT.data</code>,
<code>IRT.posterior</code> and <code>predict</code> are defined.</p>
</td></tr>
<tr><td><code id="msq.itemfit_+3A_fitindices">fitindices</code></td>
<td>
<p>Vector with parameter labels defining the item groups for
which the fit should be evaluated.</p>
</td></tr>
<tr><td><code id="msq.itemfit_+3A_tamobj">tamobj</code></td>
<td>
<p>Object of class <code>tam.mml</code>, <code>tam.mml.2pl</code>
or <code>tam.mml.mfr</code>.
</p>
</td></tr>
<tr><td><code id="msq.itemfit_+3A_file">file</code></td>
<td>
<p>Optional name of a file to which the summary should be written</p>
</td></tr>
<tr><td><code id="msq.itemfit_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with following entries
</p>
<table>
<tr><td><code>itemfit</code></td>
<td>
<p>Data frame with outfit and infit statistics.</p>
</td></tr>
<tr><td><code>summary_itemfit</code></td>
<td>
<p>Summary statistics of outfit
and infit</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>See also <code><a href="#topic+tam.fit">tam.fit</a></code> for simulation based assessment of item fit.
</p>
<p>See also <code>eRm::itemfit</code> or <code>mirt::itemfit</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#############################################################################
# EXAMPLE 1: Simulated data Rasch model
#############################################################################

#*** simulate data
library(sirt)
set.seed(9875)
N &lt;- 2000
I &lt;- 20
b &lt;- sample( seq( -2, 2, length=I ) )
a &lt;- rep( 1, I )
# create some misfitting items
a[c(1,3)] &lt;- c(.5, 1.5 )
# simulate data
dat &lt;- sirt::sim.raschtype( rnorm(N), b=b, fixed.a=a )
#*** estimate Rasch model
mod1 &lt;- TAM::tam.mml(resp=dat)
# compute WLEs
wmod1 &lt;- TAM::tam.wle(mod1)$theta

#--- item fit from "msq.itemfit" function
fit1 &lt;- TAM::msq.itemfit(mod1)
summary( fit1 )

#--- item fit using simulation in "tam.fit"
fit0 &lt;- TAM::tam.fit( mod1 )
summary(fit0)

#--- item fit based on WLEs
fit2a &lt;- TAM::msq.itemfitWLE( mod1 )
summary(fit2a)

#++ fit assessment in mirt package
library(mirt)
mod1b &lt;- mirt::mirt( dat, model=1, itemtype="Rasch", verbose=TRUE )
print(mod1b)
sirt::mirt.wrapper.coef(mod1b)
fmod1b &lt;- mirt::itemfit(mod1b, Theta=as.matrix(wmod1,ncol=1),
                 Zh=TRUE, X2=FALSE, S_X2=FALSE )
cbind( fit2a$fit_data, fmod1b )

#++ fit assessment in eRm package
library(eRm)
mod1c &lt;- eRm::RM( dat )
summary(mod1c)
eRm::plotPImap(mod1c)    # person-item map
pmod1c &lt;- eRm::person.parameter(mod1c)
fmod1c &lt;- eRm::itemfit(pmod1c)
print(fmod1c)
plot(fmod1c)

#--- define some item groups for fit assessment

# bases on evaluating the posterior
fitindices &lt;- rep( paste0("IG",c(1,2)), each=10)
fit2 &lt;- TAM::msq.itemfit( mod1, fitindices )
summary(fit2)

# using WLEs
fit2b &lt;- TAM::msq.itemfitWLE( mod1, fitindices )
summary(fit2b)

#############################################################################
# EXAMPLE 2: data.read | fit statistics assessed for testlets
#############################################################################

library(sirt)
data(data.read,package="sirt")
dat &lt;- data.read

# fit Rasch model
mod &lt;- TAM::tam.mml( dat )

#***** item fit for each item
# based on posterior
res1 &lt;- TAM::msq.itemfit( mod  )
summary(res1)
# based on WLEs
res2 &lt;- TAM::msq.itemfitWLE( mod  )
summary(res2)

#***** item fit for item groups
# define item groups
fitindices &lt;- substring( colnames(dat), 1, 1 )
# based on posterior
res1 &lt;- TAM::msq.itemfit( mod, fitindices )
summary(res1)
# based on WLEs
res2 &lt;- TAM::msq.itemfitWLE( mod, fitindices )
summary(res2)

#############################################################################
# EXAMPLE 3: Fit statistics for rater models
#############################################################################

library(sirt)
data(data.ratings2, package="sirt")
dat &lt;- data.ratings2

# fit rater model "~ item*step + rater"
mod &lt;- TAM::tam.mml.mfr( resp=dat[, paste0( "k",1:5) ],
            facets=dat[, "rater", drop=FALSE],
            pid=dat$pid, formulaA=~ item*step + rater )

# fit for parameter with "tam.fit" function
fmod1a &lt;- TAM::tam.fit( mod )
fmod1b &lt;- TAM::msq.itemfit( mod )
summary(fmod1a)
summary(fmod1b)

# define item groups using pseudo items from object "mod"
pseudo_items &lt;- colnames(mod$resp)
pss &lt;- strsplit( pseudo_items, split="-" )
item_parm &lt;- unlist( lapply( pss, FUN=function(ll){ ll[1] } ) )
rater_parm &lt;- unlist( lapply( pss, FUN=function(ll){ ll[2] } ) )

# fit for items with "msq.itemfit" functions
res2a &lt;- TAM::msq.itemfit( mod, item_parm )
res2b &lt;- TAM::msq.itemfitWLE( mod, item_parm )
summary(res2a)
summary(res2b)

# fit for raters
res3a &lt;- TAM::msq.itemfit( mod, rater_parm )
res3b &lt;- TAM::msq.itemfitWLE( mod, rater_parm )
summary(res3a)
summary(res3b)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.tam'>
Plot Function for Unidimensional Item Response Models
</h2><span id='topic+plot.tam'></span><span id='topic+plot.tam.mml'></span><span id='topic+plot.tam.jml'></span>

<h3>Description</h3>

<p>S3 plot method for objects of class <code>tam</code>, <code>tam.mml</code>
or <code>tam.mml</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam'
plot(x, items=1:x$nitems, type="expected", low=-3, high=3, ngroups=6,
                   groups_by_item=FALSE, wle=NULL, export=TRUE, export.type="png",
                   export.args=list(), observed=TRUE, overlay=FALSE,
                   ask=FALSE, package="lattice", fix.devices=TRUE, nnodes=100, ...)

## S3 method for class 'tam.mml'
plot(x, items=1:x$nitems, type="expected", low=-3, high=3, ngroups=6,
                       groups_by_item=FALSE, wle=NULL, export=TRUE, export.type="png",
                       export.args=list(), observed=TRUE, overlay=FALSE,
                       ask=FALSE,  package="lattice",  fix.devices=TRUE, nnodes=100, ...)

## S3 method for class 'tam.jml'
plot(x, items=1:x$nitems, type="expected", low=-3, high=3, ngroups=6,
                       groups_by_item=FALSE, wle=NULL, export=TRUE, export.type="png",
                       export.args=list(), observed=TRUE, overlay=FALSE,
                       ask=FALSE,  package="lattice", fix.devices=TRUE, nnodes=100, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.tam_+3A_x">x</code></td>
<td>

<p>Object of class <code>tam</code>, <code>tam.mml</code>
or <code>tam.mml</code>.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_items">items</code></td>
<td>

<p>An index vector giving the items to be visualized.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_type">type</code></td>
<td>
<p>Plot type. <code>type="expected"</code> plot the expected item
response curves while <code>type="items"</code> plots the response
curves of all item categories.</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_low">low</code></td>
<td>

<p>Lowest <code class="reqn">\theta</code> value to be displayed
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_high">high</code></td>
<td>

<p>Highest <code class="reqn">\theta</code> value to be displayed
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_ngroups">ngroups</code></td>
<td>

<p>Number of score groups to be displayed. The default are
six groups.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_groups_by_item">groups_by_item</code></td>
<td>
<p>Logical indicating whether grouping of persons
should be conducted item-wise. The groupings will differ from item to item
in case of missing item responses.</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_wle">wle</code></td>
<td>

<p>Use WLE estimate for displaying observed scores.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_export">export</code></td>
<td>

<p>A logical which indicates whether all graphics should be separately
exported in files of type <code>export.type</code> in a subdirectory <code>'Plots'</code>
of the working directory.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_export.type">export.type</code></td>
<td>

<p>A string which indicates the type of the graphics export. For currently
supported file types, see
<code><a href="grDevices.html#topic+dev.new">grDevices::dev.new</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_export.args">export.args</code></td>
<td>

<p>A list of arguments that are passed to the export method can be specified.
See the respective export device method for supported usage.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_observed">observed</code></td>
<td>

<p>A logical which indicates whether observed response curve should
be displayed
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_overlay">overlay</code></td>
<td>

<p>A logical indicating whether expected score functions should overlay.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_ask">ask</code></td>
<td>

<p>A logical which asks for changing the graphic from item to item.
The default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_package">package</code></td>
<td>
<p>Used <span class="rlang"><b>R</b></span> package for plot. Can be <code>"lattice"</code> or
<code>"graphics"</code>.</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_fix.devices">fix.devices</code></td>
<td>
<p>Optional logical indicating whether old graphics devices should
be saved.</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_nnodes">nnodes</code></td>
<td>
<p>Number of <code class="reqn">\theta</code> points at which item response functions
are evaluated</p>
</td></tr>
<tr><td><code id="plot.tam_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This plot method does not work for multidimensional item response
models.
</p>


<h3>Value</h3>

<p>A plot and list of computed values for <code>plot</code> (if saved as an object)
</p>


<h3>Author(s)</h3>

<p>Margaret Wu, Thomas Kiefer, Alexander Robitzsch, Michal Modzelewski
</p>


<h3>See Also</h3>

<p>See <code><a href="CDM.html#topic+IRT.irfprobPlot">CDM::IRT.irfprobPlot</a></code>
for a general plot method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Dichotomous data data.sim.rasch
#############################################################################

data(data.sim.rasch)
mod &lt;- TAM::tam.mml(data.sim.rasch)
# expected response curves
plot(mod, items=1:5, export=FALSE)
# export computed values
out &lt;- plot(mod, items=1:5, export=FALSE)
# item response curves
plot(mod, items=1:5, type="items", export=FALSE)
# plot with graphics package
plot(mod, items=1:5, type="items", export=FALSE, ask=TRUE, package="graphics")

#############################################################################
# EXAMPLE 2: Polytomous data
#############################################################################

data(data.Students, package="CDM")
dat &lt;- data.Students[, c("sc3","sc4", "mj1", "mj2" )]
dat &lt;- na.omit(dat)
dat[ dat[,1]==3, 1 ] &lt;- 2   # modify data
dat[ 1:20, 2 ] &lt;- 4

# estimate model
mod1 &lt;- TAM::tam.mml( dat )
# plot item response curves and expected response curves
plot(mod1, type="items", export=FALSE)
plot(mod1, type="expected", export=FALSE )

## End(Not run)
</code></pre>

<hr>
<h2 id='plotDevianceTAM'>
Deviance Plot for <span class="pkg">TAM</span> Objects
</h2><span id='topic+plotDevianceTAM'></span>

<h3>Description</h3>

<p>Plots the deviance change in every iteration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDevianceTAM(tam.obj, omitUntil=1, reverse=TRUE, change=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDevianceTAM_+3A_tam.obj">tam.obj</code></td>
<td>

<p>Object of class <code>tam.mml</code>, <code>tam.mml.2pl</code> or <code>tam.mml.mfr</code>.
</p>
</td></tr>
<tr><td><code id="plotDevianceTAM_+3A_omituntil">omitUntil</code></td>
<td>

<p>An optional value indicating number of iterations to be omitted for
plotting.
</p>
</td></tr>
<tr><td><code id="plotDevianceTAM_+3A_reverse">reverse</code></td>
<td>

<p>A logical indicating whether the deviance change should be
multiplied by minus 1. The default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="plotDevianceTAM_+3A_change">change</code></td>
<td>
<p>An optional logical indicating whether deviance change
or the deviance should be plotted.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Hecht, Sebastian Weirich, Alexander Robitzsch
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: deviance plot dichotomous data
#############################################################################
data(data.sim.rasch)

# 2PL model
mod1 &lt;- TAM::tam.mml.2pl(resp=data.sim.rasch )
# plot deviance change
plotDevianceTAM( mod1 )
# plot deviance
plotDevianceTAM( mod1, change=FALSE)
</code></pre>

<hr>
<h2 id='predict'>
Expected Values and Predicted Probabilities for Fitted <span class="pkg">TAM</span> Models
</h2><span id='topic+predict.tam.mml'></span><span id='topic+predict.tam.mml.3pl'></span><span id='topic+predict.tamaan'></span>

<h3>Description</h3>

<p>Extracts predicted values from the posterior distribution for models
fitted in <span class="pkg">TAM</span>.
</p>
<p>See <code><a href="CDM.html#topic+predict">CDM::predict</a></code>
for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tam.mml'
predict(object, ...)

## S3 method for class 'tam.mml.3pl'
predict(object, ...)

## S3 method for class 'tamaan'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_object">object</code></td>
<td>

<p>Object of class <code><a href="#topic+tam">tam</a></code>, <code><a href="#topic+tam.mml">tam.mml</a></code>,
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code> or <code><a href="#topic+tamaan">tamaan</a></code>.
</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with entries for predicted values (expectations and probabilities)
for each person and each item.
</p>
<p>See <code><a href="CDM.html#topic+predict">predict</a></code> (<span class="pkg">CDM</span>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Dichotomous data sim.rasch - predict method
#############################################################################

data(data.sim.rasch)
# 1PL estimation
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
# predict method
prmod1 &lt;- IRT.predict(mod1, data.sim.rasch)
str(prmod1)
</code></pre>

<hr>
<h2 id='Scale'>
S3 Method for Standardizations and Transformations of Variables
</h2><span id='topic+Scale'></span>

<h3>Description</h3>

<p>S3 method for standardizations and transformations of variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Scale(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Scale_+3A_object">object</code></td>
<td>

<p>An object
</p>
</td></tr>
<tr><td><code id="Scale_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+scale">base::scale</a></code>
</p>

<hr>
<h2 id='tam_downcode'>
Downcoding an Item Response Dataset
</h2><span id='topic+tam_downcode'></span>

<h3>Description</h3>

<p>Recodes item categories in a data frame such that each item has values
<code class="reqn">0,1,\ldots,K_i</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam_downcode(dat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam_downcode_+3A_dat">dat</code></td>
<td>

<p>Data frame containing item responses
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with following entries
</p>
<table>
<tr><td><code>dat</code></td>
<td>
<p>Recoded dataset</p>
</td></tr>
<tr><td><code>rec</code></td>
<td>
<p>Recoding table</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Downcoding in a toy example
#############################################################################

#-- simulate some toy data
set.seed(989)
# values to be sampled
vals &lt;- c(NA, 0:6)
# number of persons and items
N &lt;- 10; I &lt;- 5
dat &lt;- as.data.frame(matrix(NA, nrow=N, ncol=I))
colnames(dat) &lt;- paste0("I",1:I)
for (ii in 1L:I){
    dat[,ii] &lt;- sample(vals, size=N, replace=TRUE)
}

#-- apply downcoding
res &lt;- TAM::tam_downcode(dat)
dat &lt;- res$dat   # extract downcoded dataset
rec &lt;- res$rec   # extract recoded table
</code></pre>

<hr>
<h2 id='tam_irf_3pl'>
Item Response Function for the 3PL Model
</h2><span id='topic+tam_irf_3pl'></span>

<h3>Description</h3>

<p>Computes the item response function for the 3PL model in the <span class="pkg">TAM</span>
package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam_irf_3pl(theta, AXsi, B, guess=NULL, subtract_max=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam_irf_3pl_+3A_theta">theta</code></td>
<td>

<p>Matrix or vector of <code class="reqn">\bold{\theta}</code> values
</p>
</td></tr>
<tr><td><code id="tam_irf_3pl_+3A_axsi">AXsi</code></td>
<td>
<p>Matrix of item-category parameters</p>
</td></tr>
<tr><td><code id="tam_irf_3pl_+3A_b">B</code></td>
<td>
<p>Array containing item-category loadings</p>
</td></tr>
<tr><td><code id="tam_irf_3pl_+3A_guess">guess</code></td>
<td>
<p>Optional parameter of guessing parameters</p>
</td></tr>
<tr><td><code id="tam_irf_3pl_+3A_subtract_max">subtract_max</code></td>
<td>
<p>Logical indicating whether numerical underflow in
probabilities should be explicitly avoided</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Array containing item response probabilities arranged by the dimensions
theta points <code class="reqn">\times</code> items <code class="reqn">\times</code> categories
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: 2PL example
#############################################################################

library(sirt)
data(data.read, package="sirt")
dat &lt;- data.read

#* estimate 2PL model
mod &lt;- TAM::tam.mml.2pl( resp=dat )
#* define theta vector
theta &lt;- seq(-3,3, len=41)
#* compute item response probabilities
probs &lt;- TAM::tam_irf_3pl( theta=theta, AXsi=mod$AXsi, B=mod$B )
str(probs)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam_NA_pattern'>
Missing Data Patterns
</h2><span id='topic+tam_NA_pattern'></span><span id='topic+tam_01_pattern'></span>

<h3>Description</h3>

<p>Determines patterns of missing values or pattern of dichotomous item
responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam_NA_pattern(x)

tam_01_pattern(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam_NA_pattern_+3A_x">x</code></td>
<td>
<p>Matrix or data frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing pattern identifiers and indices
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Missing data patterns
#############################################################################

data(data.sim.rasch.missing, package="TAM")
dat &lt;- data.sim.rasch.missing

res &lt;- TAM::tam_NA_pattern(dat)
str(res)

## Not run: 
#############################################################################
# EXAMPLE 2: Item response patterns
#############################################################################

data(data.read, package="sirt")
dat &lt;- data.read

res &lt;- TAM::tam_01_pattern(dat)
str(res)

## End(Not run)
</code></pre>

<hr>
<h2 id='TAM-defunct'>Defunct <span class="pkg">TAM</span> Functions</h2><span id='topic+TAM-defunct'></span><span id='topic+tam.jml2'></span>

<h3>Description</h3>

<p>These functions have been removed or replaced in the <span class="pkg">tam.jml2</span>
package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.jml2(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TAM-defunct_+3A_...">...</code></td>
<td>
<p>Arguments to be passed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>tam.jml2</code> is included as the default in
<code><a href="#topic+tam.jml">tam.jml</a></code>.
</p>

<hr>
<h2 id='TAM-package'>
Test Analysis Modules
</h2><span id='topic+TAM-package'></span><span id='topic+TAM'></span>

<h3>Description</h3>


<p>    Includes marginal maximum likelihood estimation and joint maximum
    likelihood estimation for unidimensional and multidimensional 
    item response models. The package functionality covers the 
    Rasch model, 2PL model, 3PL model, generalized partial credit model, 
    multi-faceted Rasch model, nominal item response model, 
    structured latent class model, mixture distribution IRT models, 
    and located latent class models. Latent regression models and 
    plausible value imputation are also supported. For details see
    Adams, Wilson and Wang, 1997 &lt;doi:10.1177/0146621697211001&gt;,
    Adams, Wilson and Wu, 1997 &lt;doi:10.3102/10769986022001047&gt;,
    Formann, 1982 &lt;doi:10.1002/bimj.4710240209&gt;,
    Formann, 1992 &lt;doi:10.1080/01621459.1992.10475229&gt;.
</p>


<h3>Details</h3>

<p>See <a href="http://www.edmeasurementsurveys.com/TAM/Tutorials/">http://www.edmeasurementsurveys.com/TAM/Tutorials/</a> for
tutorials of the <span class="pkg">TAM</span> package.
</p>


<h3>Author(s)</h3>


<p>    Alexander Robitzsch [aut,cre] (&lt;https://orcid.org/0000-0002-8226-3132&gt;),
    Thomas Kiefer [aut], 
    Margaret Wu [aut]
</p>
<p>Maintainer: Alexander Robitzsch &lt;robitzsch@ipn.uni-kiel.de&gt;
</p>


<h3>References</h3>

<p>Adams, R. J., Wilson, M., &amp; Wang, W. C. (1997). The multidimensional random coefficients
multinomial logit model. <em>Applied Psychological Measurement, 21</em>(1), 1-23.
<a href="https://doi.org/10.1177/0146621697211001">doi:10.1177/0146621697211001</a>
</p>
<p>Adams, R. J., Wilson, M., &amp; Wu, M. (1997).
Multilevel item response models: An approach to errors in
variables regression. <em>Journal of Educational and Behavioral
Statistics, 22</em>(1), 47-76. <a href="https://doi.org/10.3102/10769986022001047">doi:10.3102/10769986022001047</a>
</p>
<p>Adams, R. J., &amp; Wu, M. L. (2007). The mixed-coefficients multinomial logit model.
A generalized form of the Rasch model. In M. von Davier &amp; C. H. Carstensen (Eds.):
<em>Multivariate and mixture distribution Rasch models: Extensions and applications</em>
(pp. 55-76). New York: Springer.
<a href="https://doi.org/10.1007/978-0-387-49839-3_4">doi:10.1007/978-0-387-49839-3_4</a>
</p>
<p>Formann, A. K. (1982). Linear logistic latent class analysis.
<em>Biometrical Journal, 24</em>(2), 171-190.
<a href="https://doi.org/10.1002/bimj.4710240209">doi:10.1002/bimj.4710240209</a>
</p>
<p>Formann, A. K. (1992). Linear logistic latent class analysis for polytomous data.
<em>Journal of the American Statistical Association, 87</em>(418), 476-486.
<a href="https://doi.org/10.1080/01621459.1992.10475229">doi:10.1080/01621459.1992.10475229</a>
</p>

<hr>
<h2 id='TAM-utilities'>Utility Functions in <span class="pkg">TAM</span></h2><span id='topic+TAM-utilities'></span><span id='topic+tam_packageinfo'></span><span id='topic+tam_rsessinfo'></span><span id='topic+tam_print_call'></span><span id='topic+tam_args_CALL_search'></span><span id='topic+tam_matrix2'></span><span id='topic+tam_outer'></span><span id='topic+tam_normalize_matrix_rows'></span><span id='topic+tam_trim_increment'></span><span id='topic+tam_difference_quotient'></span><span id='topic+tam_assign_list_elements'></span><span id='topic+tam_aggregate'></span><span id='topic+tam_interval_index'></span><span id='topic+tam_rowCumsums'></span><span id='topic+tam_normalize_vector'></span><span id='topic+tam_remove_missings'></span><span id='topic+tam_AXsi_compute'></span><span id='topic+tam_AXsi_fit'></span><span id='topic+require_namespace_msg'></span><span id='topic+tam_dmvnorm'></span><span id='topic+add.lead'></span><span id='topic+tam_bayesian_bootstrap'></span><span id='topic+tam_cov_wt'></span><span id='topic+tam_cor_wt'></span><span id='topic+tam_round_data_frame'></span><span id='topic+tam_round_data_frame_print'></span><span id='topic+tam_osink'></span><span id='topic+tam_csink'></span><span id='topic+tam_ginv'></span><span id='topic+tam_ginv_scaled'></span><span id='topic+tam_max_abs'></span><span id='topic+tam_max_abs_list'></span><span id='topic+IRT.RISE'></span><span id='topic+tam_model_implied_means'></span>

<h3>Description</h3>

<p>Utility functions in <span class="pkg">TAM</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## RISE item fit statistic of two models
IRT.RISE( mod_p, mod_np, use_probs=TRUE )
## model-implied means
tam_model_implied_means(mod)

## information about used package version
tam_packageinfo(pack)
## call statement in a string format
tam_print_call(CALL)
## information about R session
tam_rsessinfo()
## grep list of arguments for a specific variable
tam_args_CALL_search(args_CALL, variable, default_value)
## requireNamespace with message of needed installation
require_namespace_msg(pkg)
## add leading zeroes
add.lead(x, width=max(nchar(x)))
## round some columns in a data frame
tam_round_data_frame(obji, from=1, to=ncol(obji), digits=3, rownames_null=FALSE)
## round some columns in a data frame and print this data frame
tam_round_data_frame_print(obji, from=1, to=ncol(obji), digits=3, rownames_null=FALSE)
## copy of CDM::osink
tam_osink(file, suffix=".Rout")
## copy of CDM::csink
tam_csink(file)

## base::matrix function with argument value byrow=TRUE
tam_matrix2(x, nrow=NULL, ncol=NULL)
## more efficient base::outer functions for operations "*", "+" and "-"
tam_outer(x, y, op="*")
## row normalization of a matrix
tam_normalize_matrix_rows(x)
## row normalization of a vector
tam_normalize_vector(x)
## aggregate function for mean and sum based on base::rowsum
tam_aggregate(x, group, mean=FALSE, na.rm=TRUE)
## column index when a value in a matrix is exceeded (used in TAM::tam.pv)
tam_interval_index(matr, rn)
## cumulative sum of row entries in a matrix
tam_rowCumsums(matr)
## extension of mvtnorm::dmvnorm to matrix entries of mean
tam_dmvnorm(x, mean, sigma, log=FALSE )
## Bayesian bootstrap in TAM (used in tam.pv.mcmc)
tam_bayesian_bootstrap(N, sample_integers=FALSE, do_boot=TRUE)
## weighted covariance matrix
tam_cov_wt(x, wt=NULL, method="ML")
## weighted correlation matrix
tam_cor_wt(x, wt=NULL, method="ML")
## generalized inverse
tam_ginv(x, eps=.05)
## generalized inverse with scaled matrix using MASS::ginv
tam_ginv_scaled(x, use_MASS=TRUE)

## remove items or persons with complete missing entries
tam_remove_missings( dat, items, elim_items=TRUE, elim_persons=TRUE )
## compute AXsi given A and xsi
tam_AXsi_compute(A, xsi)
## fit xsi given A and AXsi
tam_AXsi_fit(A, AXsi)

## maximum absolute difference between objects
tam_max_abs( list1, list2, label )
tam_max_abs_list( list1, list2)

## trimming increments in iterations
tam_trim_increment(increment, max.increment, trim_increment="cut",
     trim_incr_factor=2, eps=1E-10, avoid_na=FALSE)
## numerical differentiation by central difference
tam_difference_quotient(d0, d0p, d0m, h)
## assign elements of a list in an environment
tam_assign_list_elements(x, envir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TAM-utilities_+3A_mod_p">mod_p</code></td>
<td>
<p>Fitted model</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_mod_np">mod_np</code></td>
<td>
<p>Fitted model</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_mod">mod</code></td>
<td>
<p>Fitted model</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_use_probs">use_probs</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_pack">pack</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> package</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_call">CALL</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> call</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_args_call">args_CALL</code></td>
<td>
<p>Arguments obtained from <code>as.list( sys.call() )</code></p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_variable">variable</code></td>
<td>
<p>Name of a variable</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_default_value">default_value</code></td>
<td>
<p>Default value of a variable</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_pkg">pkg</code></td>
<td>
<p>String</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_x">x</code></td>
<td>
<p>Vector or matrix or list</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_width">width</code></td>
<td>
<p>Number of zeroes before decimal</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_obji">obji</code></td>
<td>
<p>Data frame or vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_from">from</code></td>
<td>
<p>Integer</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_to">to</code></td>
<td>
<p>Integer</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_digits">digits</code></td>
<td>
<p>Integer</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_rownames_null">rownames_null</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_file">file</code></td>
<td>
<p>File name</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_suffix">suffix</code></td>
<td>
<p>Suffix for file name of summary output</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_nrow">nrow</code></td>
<td>
<p>Number of rows</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_ncol">ncol</code></td>
<td>
<p>Number of columns</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_y">y</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_op">op</code></td>
<td>
<p>An operation <code>"*"</code>, <code>"+"</code> or <code>"-"</code></p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_group">group</code></td>
<td>
<p>Vector of grouping identifiers</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_mean">mean</code></td>
<td>
<p>Logical indicating whether mean should be calculated or the sum or
vector or matrix</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical indicating whether missing values should be removed</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_matr">matr</code></td>
<td>
<p>Matrix</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_sigma">sigma</code></td>
<td>
<p>Matrix</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_log">log</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_n">N</code></td>
<td>
<p>Integer</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_sample_integers">sample_integers</code></td>
<td>
<p>Logical indicating whether weights for complete cases
should be sampled in bootstrap</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_do_boot">do_boot</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_wt">wt</code></td>
<td>
<p>Optional vector containing weights</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_method">method</code></td>
<td>
<p>Method, see <code><a href="stats.html#topic+cov.wt">stats::cov.wt</a></code> </p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_rn">rn</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_dat">dat</code></td>
<td>
<p>Data frame</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_items">items</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_elim_items">elim_items</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_elim_persons">elim_persons</code></td>
<td>
<p>Logical</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_a">A</code></td>
<td>
<p>Array</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_xsi">xsi</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_axsi">AXsi</code></td>
<td>
<p>Matrix</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_increment">increment</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_max.increment">max.increment</code></td>
<td>
<p>Numeric</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_trim_increment">trim_increment</code></td>
<td>
<p>One of the methods <code>"half"</code> or <code>"cut"</code></p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_trim_incr_factor">trim_incr_factor</code></td>
<td>
<p>Factor of trimming in method <code>"half"</code></p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_eps">eps</code></td>
<td>
<p>Small number preventing from division by zero</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_use_mass">use_MASS</code></td>
<td>
<p>Logical indicating whether <span class="pkg">MASS</span> package should be used.</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_avoid_na">avoid_na</code></td>
<td>
<p>Logical indicating whether missing values should be set to zero.</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_d0">d0</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_d0p">d0p</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_d0m">d0m</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_h">h</code></td>
<td>
<p>Vector</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_envir">envir</code></td>
<td>
<p>Environment variable</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_list1">list1</code></td>
<td>
<p>List</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_list2">list2</code></td>
<td>
<p>List</p>
</td></tr>
<tr><td><code id="TAM-utilities_+3A_label">label</code></td>
<td>
<p>Element of a list</p>
</td></tr>
</table>

<hr>
<h2 id='tam.ctt'>
Classical Test Theory Based Statistics and Plots
</h2><span id='topic+tam.ctt'></span><span id='topic+tam.ctt2'></span><span id='topic+tam.ctt3'></span><span id='topic+plotctt'></span><span id='topic+tam.cb'></span>

<h3>Description</h3>

<p>The functions computes some item statistics based on classical test
theory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.ctt(resp, wlescore=NULL, pvscores=NULL, group=NULL, progress=TRUE)
tam.ctt2(resp, wlescore=NULL, group=NULL, allocate=30, progress=TRUE)
tam.ctt3(resp, wlescore=NULL, group=NULL, allocate=30, progress=TRUE, max_ncat=30,
          pweights=NULL)

tam.cb( dat, wlescore=NULL, group=NULL, max_ncat=30, progress=TRUE,
             pweights=NULL, digits_freq=5)

plotctt( resp, theta, Ncuts=NULL, ask=FALSE, col.list=NULL,
       package="lattice", ... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.ctt_+3A_resp">resp</code></td>
<td>

<p>A data frame with unscored or scored item responses
</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_wlescore">wlescore</code></td>
<td>

<p>A vector with person parameter estimates, e.g. weighted likelihood
estimates obtained from <code>tam.wle</code>. If <code>wlescore=NULL</code> is
chosen in <code>tam.ctt2</code>, then only a frequency table of all items
is produced.
</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_pvscores">pvscores</code></td>
<td>

<p>A matrix with plausible values, e.g. obtained from <code>tam.pv</code>
</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_group">group</code></td>
<td>
<p>Vector of group identifiers if descriptive statistics shall
be groupwise calculated</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_progress">progress</code></td>
<td>

<p>An optional logical indicating whether computation progress
should be displayed.
</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_allocate">allocate</code></td>
<td>
<p>Average number of categories per item. This argument is just
used for matrix size allocations. If an error is produced, use
a sufficiently higher number.
</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_max_ncat">max_ncat</code></td>
<td>
<p>Maximum number of categories of variables for which
frequency tables should be computed</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_pweights">pweights</code></td>
<td>
<p>Optional vector of person weights</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_dat">dat</code></td>
<td>
<p>Data frame</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_digits_freq">digits_freq</code></td>
<td>
<p>Number of digits for rounding in frequency table</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_theta">theta</code></td>
<td>
<p>A score to be conditioned</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_ncuts">Ncuts</code></td>
<td>
<p>Number of break points for <code>theta</code></p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_ask">ask</code></td>
<td>

<p>A logical which asks for changing the graphic from item to item.
The default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_col.list">col.list</code></td>
<td>
<p>Optional vector of colors for plotting</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_package">package</code></td>
<td>
<p>Package used for plotting. Can be <code>"lattice"</code>
or <code>"graphics"</code>.</p>
</td></tr>
<tr><td><code id="tam.ctt_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions <code>tam.ctt2</code> and <code>tam.ctt3</code> use <span class="pkg">Rcpp</span> code
and are slightly faster.
However, only <code>tam.ctt</code> allows the input of <code>wlescore</code> and
<code>pvscores</code>.
</p>


<h3>Value</h3>

<p>A data frame with following columns:
</p>
<table>
<tr><td><code>index</code></td>
<td>
<p>Index variable in this data frame</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>Group identifier</p>
</td></tr>
<tr><td><code>itemno</code></td>
<td>
<p>Item number</p>
</td></tr>
<tr><td><code>item</code></td>
<td>
<p>Item</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>Number of students responding to this item</p>
</td></tr>
<tr><td><code>Categ</code></td>
<td>
<p>Category label</p>
</td></tr>
<tr><td><code>AbsFreq</code></td>
<td>
<p>Absolute frequency of category</p>
</td></tr>
<tr><td><code>RelFreq</code></td>
<td>
<p>Relative frequency of category</p>
</td></tr>
<tr><td><code>rpb.WLE</code></td>
<td>
<p>Point biserial correlation of an item category and the WLE</p>
</td></tr>
<tr><td><code>M.WLE</code></td>
<td>
<p>Mean of the WLE of students in this item category</p>
</td></tr>
<tr><td><code>SD.WLE</code></td>
<td>
<p>Standard deviation of the WLE of students in this item category</p>
</td></tr>
<tr><td><code>rpb.PV</code></td>
<td>
<p>Point biserial correlation of an item category and the PV</p>
</td></tr>
<tr><td><code>M.PV</code></td>
<td>
<p>Mean of the PV of students in this item category</p>
</td></tr>
<tr><td><code>SD.PV</code></td>
<td>
<p>Standard deviation of the PV of students in this item category</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For dichotomously scored data, <code>rpb.WLE</code> is the ordinary point biserial
correlation of an item and a test score (here the WLE).
</p>


<h3>See Also</h3>

<p><a href="http://www.edmeasurementsurveys.com/TAM/Tutorials/4CTT.htm">http://www.edmeasurementsurveys.com/TAM/Tutorials/4CTT.htm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Multiple choice data data.mc
#############################################################################

data(data.mc)
# estimate Rasch model for scored data.mc data
mod &lt;- TAM::tam.mml( resp=data.mc$scored )
# estimate WLE
w1 &lt;- TAM::tam.wle( mod )
# estimate plausible values
set.seed(789)
p1 &lt;- TAM::tam.pv( mod, ntheta=500, normal.approx=TRUE )$pv

# CTT results for raw data
stat1 &lt;- TAM::tam.ctt( resp=data.mc$raw, wlescore=w1$theta, pvscores=p1[,-1] )
stat1a &lt;- TAM::tam.ctt2( resp=data.mc$raw, wlescore=w1$theta )  # faster
stat1b &lt;- TAM::tam.ctt2( resp=data.mc$raw )  # only frequencies
stat1c &lt;- TAM::tam.ctt3( resp=data.mc$raw, wlescore=w1$theta )  # faster

# plot empirical item response curves
plotctt( resp=data.mc$raw, theta=w1$theta, Ncuts=5, ask=TRUE)
# use graphics for plot
plotctt( resp=data.mc$raw, theta=w1$theta, Ncuts=5, ask=TRUE, package="graphics")
# change colors
col.list &lt;- c( "darkred",  "darkslateblue", "springgreen4", "darkorange",
                "hotpink4", "navy" )
plotctt( resp=data.mc$raw, theta=w1$theta, Ncuts=5, ask=TRUE,
        package="graphics", col.list=col.list )

# CTT results for scored data
stat2 &lt;- TAM::tam.ctt( resp=data.mc$scored, wlescore=w1$theta, pvscores=p1[,-1] )

# descriptive statistics for different groups
# define group identifier
group &lt;- c( rep(1,70), rep(2,73) )
stat3 &lt;- TAM::tam.ctt( resp=data.mc$raw, wlescore=w1$theta, pvscores=p1[,-1], group=group)
stat3a &lt;- TAM::tam.ctt2( resp=data.mc$raw, wlescore=w1$theta,  group=group)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.fa'>
Bifactor Model and Exploratory Factor Analysis
</h2><span id='topic+tam.fa'></span>

<h3>Description</h3>

<p>Estimates the bifactor model and exploratory factor analysis with
marginal maximum likelihood estimation.
</p>
<p>This function is simply a wrapper to <code><a href="#topic+tam.mml">tam.mml</a></code> or
<code><a href="#topic+tam.mml.2pl">tam.mml.2pl</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.fa(resp, irtmodel, dims=NULL, nfactors=NULL, pid=NULL,
    pweights=NULL, verbose=TRUE, control=list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.fa_+3A_resp">resp</code></td>
<td>

<p>Data frame with polytomous item responses <code class="reqn">k=0,...,K</code>.
Missing responses must be declared as <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="tam.fa_+3A_irtmodel">irtmodel</code></td>
<td>

<p>A string which defines the IRT model to be estimated. Options
are <code>"efa"</code> (exploratory factor analysis), <code>"bifactor1"</code> (Rasch
testlet model in case of dichotomous data; Wang &amp; Wilson, 2005;
for polytomous data it assumes item slopes of 1) and <code>"bifactor2"</code>
(bifactor model).
See Details for more information.
</p>
</td></tr>
<tr><td><code id="tam.fa_+3A_dims">dims</code></td>
<td>

<p>A numeric or string vector which only applies in case of
<code>irtmodel="bifactor1"</code> or <code>irtmodel="bifactor2"</code>.
Different entries in the vector indicate different dimensions of items
which should load on the nested factor. If items should only load
on the general factor, then an <code>NA</code> must be specified.
</p>
</td></tr>
<tr><td><code id="tam.fa_+3A_nfactors">nfactors</code></td>
<td>

<p>A numerical value which indicates the number of factors in
exploratory factor analysis.
</p>
</td></tr>
<tr><td><code id="tam.fa_+3A_pid">pid</code></td>
<td>

<p>An optional vector of person identifiers
</p>
</td></tr>
<tr><td><code id="tam.fa_+3A_pweights">pweights</code></td>
<td>

<p>An optional vector of person weights
</p>
</td></tr>
<tr><td><code id="tam.fa_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether output should
be printed during iterations. This argument replaces <code>control$progress</code>.
</p>
</td></tr>
<tr><td><code id="tam.fa_+3A_control">control</code></td>
<td>

<p>See <code><a href="#topic+tam.mml">tam.mml</a></code> for more details. Note that the default is
Quasi Monte Carlo integration with 1500 nodes (<code>snodes=1500</code>,
<code>QMC=TRUE</code>).
</p>
</td></tr>
<tr><td><code id="tam.fa_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed. These arguments are used in
<code><a href="#topic+tam.mml">tam.mml</a></code> and <code><a href="#topic+tam.mml.2pl">tam.mml.2pl</a></code>. For example,
<code>beta.inits</code> or <code>xsi.inits</code> can be supplied.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exploratory factor analysis (<code>irtmodel="efa"</code>
is estimated using an echelon form of the loading matrix and uncorrelated factors.
The obtained standardized loading matrix is rotated using oblimin rotation.
In addition, a Schmid-Leimann transformation (see Revelle &amp; Zinbarg, 2009)
is employed.
</p>
<p>The bifactor model (<code>irtmodel="bifactor2"</code>; Reise 2012)
for dichotomous responses is defined as
</p>
<p style="text-align: center;"><code class="reqn">logit P(X_{pi}=1 | \theta_{pg}, u_{p1}, \ldots, u_{pD} )=
    a_{i0} \theta_{pg} + a_{i1} u_{pd(i) } </code>
</p>

<p>Items load on the general factor <code class="reqn">\theta_{pg}</code> and a specific (nested)
factor <code class="reqn">u_{pd(i) }</code>. All factors are assumed to be uncorrelated.
</p>
<p>In the Rasch testlet model (<code>irtmodel="bifactor1"</code>),
all item slopes are set to 1 and variances are
estimated.
</p>
<p>For polytomous data, the generalized partial credit model is used. The loading
structure is defined in the same way as for dichotomous data.
</p>


<h3>Value</h3>

<p>The same list entries as in <code><a href="#topic+tam.mml">tam.mml</a></code> but in addition the
following statistics are included:
</p>
<table>
<tr><td><code>B.stand</code></td>
<td>
<p>Standardized factor loadings of the bifactor model or the
exploratory factor analysis.</p>
</td></tr>
<tr><td><code>B.SL</code></td>
<td>
<p> In case of exploratory factor analysis (<code>irtmodel="efa"</code>),
loadings form the Schmid-Leimann solution of the <span class="pkg">psych</span> package.</p>
</td></tr>
<tr><td><code>efa.oblimin</code></td>
<td>
<p>Output from oblimin rotation in exploratory
factor analysis which is produced by the <span class="pkg">GPArotation</span> package</p>
</td></tr>
<tr><td><code>meas</code></td>
<td>
<p>Vector of dimensionality and reliability statistics.
Included are the ECV measure (explained common variation;
Reise, Moore &amp; Haviland, 2010; Reise, 2012),
<code class="reqn">\omega_t</code> (Omega Total), <code class="reqn">\omega_a</code> (Omega asymptotic)
and <code class="reqn">\omega_h</code> (Omega hierarchical) (Revelle &amp; Zinbarg, 2009).
The reliability of the sum score based on
the bifactor model for dichotomous item responses is also
included (Green &amp; Yang, 2009).
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Green, S. B., &amp; Yang, Y. (2009). Reliability of summed item
scores using structural equation modeling: An alternative to
coefficient alpha. <em>Psychometrika, 74</em>, 155-167.
<a href="https://doi.org/10.1007/s11336-008-9099-3">doi:10.1007/s11336-008-9099-3</a>
</p>
<p>Reise, S. P. (2012). The rediscovery of bifactor measurement models.
<em>Multivariate Behavioral Research, 47</em>(5), 667-696.
<a href="https://doi.org/10.1080/00273171.2012.715555">doi:10.1080/00273171.2012.715555</a>
</p>
<p>Reise, S. P., Moore, T. M., &amp; Haviland, M. G.  (2010).
Bifactor models and rotations: Exploring the extent to which
multidimensional data yield univocal scale scores.
<em>Journal of Personality Assessment, 92</em>(6), 544-559.
<a href="https://doi.org/10.1080/00223891.2010.496477">doi:10.1080/00223891.2010.496477</a>
</p>
<p>Revelle, W., &amp; Zinbarg, R. E. (2009).
Coefficients alpha, beta, omega and the glb: Comments on Sijtsma.
<em>Psychometrika, 74</em>(1), 145-154.
<a href="https://doi.org/10.1007/s11336-008-9102-z">doi:10.1007/s11336-008-9102-z</a>
</p>
<p>Wang, W.-C., &amp; Wilson, M. (2005). The Rasch testlet model.
<em>Applied Psychological Measurement, 29</em>(2), 126-149.
<a href="https://doi.org/10.1177/0146621604271053">doi:10.1177/0146621604271053</a>
</p>


<h3>See Also</h3>

<p>For more details see <code><a href="#topic+tam.mml">tam.mml</a></code> because <code>tam.fa</code> is just
a wrapper for <code><a href="#topic+tam.mml.2pl">tam.mml.2pl</a></code> and <code><a href="#topic+tam.mml">tam.mml</a></code>.
</p>
<p><code><a href="#topic+logLik.tam">logLik.tam</a></code>, <code><a href="#topic+anova.tam">anova.tam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Dataset reading from sirt package
#############################################################################

data(data.read,package="sirt")
resp &lt;- data.read

#***
# Model 1a: Exploratory factor analysis with 2 factors
mod1a &lt;- TAM::tam.fa( resp=resp, irtmodel="efa", nfactors=2  )
summary(mod1a)
# varimax rotation
stats::varimax(mod1a$B.stand)
# promax rotation
stats::promax(mod1a$B.stand)
# more rotations are included in the GPArotation package
library(GPArotation)
# geomin rotation oblique
GPArotation::geominQ( mod1a$B.stand )
# quartimin rotation
GPArotation::quartimin( mod1a$B.stand )

#***
# Model 1b: Rasch testlet model with 3 testlets
dims &lt;- substring( colnames(resp),1,1 )     # define dimensions
mod1b &lt;- TAM::tam.fa( resp=resp, irtmodel="bifactor1", dims=dims )
summary(mod1b)

#***
# Model 1c: Bifactor model
mod1c &lt;- TAM::tam.fa( resp=resp, irtmodel="bifactor2", dims=dims )
summary(mod1c)

#***
# Model 1d: reestimate Model 1c but assume that items 3 and 5 do not load on
#           specific factors
dims1 &lt;- dims
dims1[c(3,5)] &lt;- NA
mod1d &lt;- TAM::tam.fa( resp=resp, irtmodel="bifactor2", dims=dims1 )
summary(mod1d)

#############################################################################
# EXAMPLE 2: Polytomous data
#############################################################################

data(data.timssAusTwn.scored, package="TAM")
dat &lt;- data.timssAusTwn.scored
resp &lt;- dat[, grep("M0", colnames(dat))]

#***
# Model 1a: Rasch testlet model with 2 testlets
dims &lt;- c( rep(1,5), rep(2,6))
mod1a &lt;- TAM::tam.fa( resp=resp, irtmodel="bifactor1", dims=dims )
summary(mod1a)

#***
# Model 1b: Bifactor model
mod1b &lt;- TAM::tam.fa( resp=resp, irtmodel="bifactor2", dims=dims )
summary(mod1b)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.fit'>
Item Infit and Outfit Statistic
</h2><span id='topic+tam.fit'></span><span id='topic+tam.mml.fit'></span><span id='topic+tam.jml.fit'></span><span id='topic+summary.tam.fit'></span>

<h3>Description</h3>

<p>The item infit and outfit statistic are calculated for
objects of classes <code>tam</code>, <code>tam.mml</code> and
<code>tam.jml</code>,  respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.fit(tamobj, ...)

tam.mml.fit(tamobj, FitMatrix=NULL, Nsimul=NULL,progress=TRUE,
   useRcpp=TRUE, seed=NA, fit.facets=TRUE)

tam.jml.fit(tamobj, trim_val=10)

## S3 method for class 'tam.fit'
summary(object, file=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.fit_+3A_tamobj">tamobj</code></td>
<td>

<p>An object of class <code>tam</code>, <code>tam.mml</code> or <code>tam.jml</code>
</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_fitmatrix">FitMatrix</code></td>
<td>

<p>A fit matrix <code class="reqn">F</code> for a specific hypothesis of fit of the linear function
<code class="reqn">F \xi </code> (see Simulated Example 3 and Adams &amp; Wu 2007).
</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_nsimul">Nsimul</code></td>
<td>
<p>Number of simulations used for fit calculation.
The default is 100 (less than 400 students), 40 (less than 1000 students),
15 (less than 3000 students) and 5 (more than 3000 students)</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_progress">progress</code></td>
<td>

<p>An optional logical indicating whether computation progress should
be displayed at console.
</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_usercpp">useRcpp</code></td>
<td>
<p>Optional logical indicating whether <span class="pkg">Rcpp</span>
or pure <span class="rlang"><b>R</b></span> code should be used for fit calculation.
The latter is consistent with <span class="pkg">TAM</span> (&lt;=1.1).</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_seed">seed</code></td>
<td>
<p>Fixed simulation seed.</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_fit.facets">fit.facets</code></td>
<td>
<p>An optional logical indicating whether
fit for all facet parameters should be computed.</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_trim_val">trim_val</code></td>
<td>
<p>Optional trimming value. Squared standardized reaisuals
larger than <code>trim_val</code> are set to <code>trim_val</code>.</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_object">object</code></td>
<td>
<p>Object of class <code>tam.fit</code></p>
</td></tr>
<tr><td><code id="tam.fit_+3A_file">file</code></td>
<td>
<p>Optional file name for summary output</p>
</td></tr>
<tr><td><code id="tam.fit_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>In case of <code>tam.mml.fit</code> a data frame as entry <code>itemfit</code>
with four columns:
</p>
<table>
<tr><td><code>Outfit</code></td>
<td>
<p>Item outfit statistic</p>
</td></tr>
<tr><td><code>Outfit_t</code></td>
<td>
<p>The <code class="reqn">t</code> value for the outfit statistic</p>
</td></tr>
<tr><td><code>Outfit_p</code></td>
<td>
<p>Significance <code class="reqn">p</code> value for outfit statistic</p>
</td></tr>
<tr><td><code>Outfit_pholm</code></td>
<td>
<p>Significance <code class="reqn">p</code> value for outfit statistic,
adjusted for multiple testing according to the Holm procedure</p>
</td></tr>
<tr><td><code>Infit</code></td>
<td>
<p>Item infit statistic</p>
</td></tr>
<tr><td><code>Infit_t</code></td>
<td>
<p>The <code class="reqn">t</code> value for the infit statistic</p>
</td></tr>
<tr><td><code>Infit_p</code></td>
<td>
<p>Significance <code class="reqn">p</code> value for infit statistic</p>
</td></tr>
<tr><td><code>Infit_pholm</code></td>
<td>
<p>Significance <code class="reqn">p</code> value for infit statistic,
adjusted for multiple testing according to the Holm procedure</p>
</td></tr>
</table>


<h3>References</h3>

<p>Adams, R. J., &amp; Wu, M. L. (2007). The mixed-coefficients multinomial logit model.
A generalized form of the Rasch model. In M. von Davier &amp; C. H. Carstensen (Eds.),
<em>Multivariate and mixture distribution Rasch models: Extensions and applications</em>
(pp. 55-76). New York: Springer.
<a href="https://doi.org/10.1007/978-0-387-49839-3_4">doi:10.1007/978-0-387-49839-3_4</a>
</p>


<h3>See Also</h3>

<p>Fit statistics can be also calculated by the function <code><a href="#topic+msq.itemfit">msq.itemfit</a></code>
which avoids simulations and directly evaluates individual
posterior distributions.
</p>
<p>See <code><a href="#topic+tam.jml.fit">tam.jml.fit</a></code> for calculating item fit and person fit statistics
for models fitted with JML.
</p>
<p>See <code><a href="#topic+tam.personfit">tam.personfit</a></code> for computing person fit statistics.
</p>
<p>Item fit and person fit based on estimated person parameters can also be
calculated using the <code>sirt::pcm.fit</code> function
in the <b>sirt</b> package (see Example 1 and Example 2).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Dichotomous data data.sim.rasch
#############################################################################

data(data.sim.rasch)
# estimate Rasch model
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
# item fit
fit1 &lt;- TAM::tam.fit( mod1 )
summary(fit1)
  ##   &gt; summary(fit1)
  ##      parameter Outfit Outfit_t Outfit_p Infit Infit_t Infit_p
  ##   1         I1  0.966   -0.409    0.171 0.996  -0.087   0.233
  ##   2         I2  1.044    0.599    0.137 1.029   0.798   0.106
  ##   3         I3  1.022    0.330    0.185 1.012   0.366   0.179
  ##   4         I4  1.047    0.720    0.118 1.054   1.650   0.025

## Not run: 

#--------
# infit and oufit based on estimated WLEs
library(sirt)

# estimate WLE
wle &lt;- TAM::tam.wle(mod1)
# extract item parameters
b1 &lt;- - mod1$AXsi[, -1 ]
# assess item fit and person fit
fit1a &lt;- sirt::pcm.fit(b=b1, theta=wle$theta, data.sim.rasch )
fit1a$item       # item fit statistic
fit1a$person     # person fit statistic

#############################################################################
# EXAMPLE 2: Partial credit model data.gpcm
#############################################################################

data( data.gpcm )
dat &lt;- data.gpcm

# estimate partial credit model in ConQuest parametrization 'item+item*step'
mod2 &lt;- TAM::tam.mml( resp=dat, irtmodel="PCM2" )
summary(mod2)
# estimate item fit
fit2 &lt;- TAM::tam.fit(mod2)
summary(fit2)

#=&gt; The first three rows of the data frame correspond to the fit statistics
#     of first three items Comfort, Work and Benefit.

#--------
# infit and oufit based on estimated WLEs
# compute WLEs
wle &lt;- TAM::tam.wle(mod2)
# extract item parameters
b1 &lt;- - mod2$AXsi[, -1 ]
# assess fit
fit1a &lt;- sirt::pcm.fit(b=b1, theta=wle$theta, dat)
fit1a$item

#############################################################################
# EXAMPLE 3: Fit statistic testing for local independence
#############################################################################

# generate data with local dependence and User-defined fit statistics
set.seed(4888)
I &lt;- 40        # 40 items
N &lt;- 1000       # 1000 persons

delta &lt;- seq(-2,2, len=I)
theta &lt;- stats::rnorm(N, 0, 1)
# simulate data
prob &lt;- stats::plogis(outer(theta, delta, "-"))
rand &lt;- matrix( stats::runif(N*I), nrow=N, ncol=I)
resp &lt;- 1*(rand &lt; prob)
colnames(resp) &lt;- paste("I", 1:I, sep="")

#induce some local dependence
for (item in c(10, 20, 30)){
 #  20
 #are made equal to the previous item
  row &lt;- round( stats::runif(0.2*N)*N + 0.5)
  resp[row, item+1] &lt;- resp[row, item]
}

#run TAM
mod1 &lt;- TAM::tam.mml(resp)

#User-defined fit design matrix
F &lt;- array(0, dim=c(dim(mod1$A)[1], dim(mod1$A)[2], 6))
F[,,1] &lt;- mod1$A[,,10] + mod1$A[,,11]
F[,,2] &lt;- mod1$A[,,12] + mod1$A[,,13]
F[,,3] &lt;- mod1$A[,,20] + mod1$A[,,21]
F[,,4] &lt;- mod1$A[,,22] + mod1$A[,,23]
F[,,5] &lt;- mod1$A[,,30] + mod1$A[,,31]
F[,,6] &lt;- mod1$A[,,32] + mod1$A[,,33]
fit &lt;- TAM::tam.fit(mod1, FitMatrix=F)
summary(fit)

#############################################################################
# EXAMPLE 4: Fit statistic testing for items with differing slopes
#############################################################################

#*** simulate data
library(sirt)
set.seed(9875)
N &lt;- 2000
I &lt;- 20
b &lt;- sample( seq( -2, 2, length=I ) )
a &lt;- rep( 1, I )
# create some misfitting items
a[c(1,3)] &lt;- c(.5, 1.5 )
# simulate data
dat &lt;- sirt::sim.raschtype( rnorm(N), b=b, fixed.a=a )
#*** estimate Rasch model
mod1 &lt;- TAM::tam.mml(resp=dat)
#*** assess item fit by infit and outfit statistic
fit1 &lt;- TAM::tam.fit( mod1 )$itemfit
round( cbind( "b"=mod1$item$AXsi_.Cat1, fit1$itemfit[,-1] )[1:7,], 3 )

#*** compute item fit statistic in mirt package
library(mirt)
library(sirt)
mod1c &lt;- mirt::mirt( dat, model=1, itemtype="Rasch", verbose=TRUE)
print(mod1c)                      # model summary
sirt::mirt.wrapper.coef(mod1c)    # estimated parameters
fit1c &lt;- mirt::itemfit(mod1c, method="EAP")    # model fit in mirt package
# compare results of TAM and mirt
dfr &lt;- cbind( "TAM"=fit1, "mirt"=fit1c[,-c(1:2)] )

# S-X2 item fit statistic (see also the output from mirt)
library(CDM)
sx2mod1 &lt;- CDM::itemfit.sx2( mod1 )
summary(sx2mod1)

# compare results of CDM and mirt
sx2comp &lt;-  cbind( sx2mod1$itemfit.stat[, c("S-X2", "p") ],
                    dfr[, c("mirt.S_X2", "mirt.p.S_X2") ] )
round(sx2comp, 3 )

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.jml'>
Joint Maximum Likelihood Estimation
</h2><span id='topic+tam.jml'></span><span id='topic+summary.tam.jml'></span><span id='topic+logLik.tam.jml'></span>

<h3>Description</h3>

<p>This function estimate unidimensional
item response models with joint maximum likelihood (JML,
see e.g. Linacre, 1994).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.jml(resp, group=NULL, adj=.3, disattenuate=FALSE, bias=TRUE,
    xsi.fixed=NULL, xsi.inits=NULL, theta.fixed=NULL, A=NULL, B=NULL, Q=NULL,
    ndim=1, pweights=NULL, constraint="cases", verbose=TRUE, control=list(), version=3)

## S3 method for class 'tam.jml'
summary(object, file=NULL, ...)

## S3 method for class 'tam.jml'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.jml_+3A_resp">resp</code></td>
<td>

<p>A matrix of item responses. Missing responses must be declared
as <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_group">group</code></td>
<td>

<p>An optional vector of group identifier
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_disattenuate">disattenuate</code></td>
<td>

<p>An optional logical indicating whether the person parameters
should be disattenuated due to unreliability?
The disattenuation is conducted by applying the Kelley formula.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_adj">adj</code></td>
<td>
<p>Adjustment constant which is subtracted or added to extreme
scores (score of zero or maximum score). The default is a value of 0.3</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_bias">bias</code></td>
<td>

<p>A logical which indicates if JML bias should be reduced
by multiplying item parameters by the adjustment factor
of <code class="reqn">(I-1)/I</code>
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_xsi.fixed">xsi.fixed</code></td>
<td>

<p>An optional matrix with two columns for fixing some of the
basis parameters <code class="reqn">\xi</code> of item intercepts.
1st column: Index of <code class="reqn">\xi</code> parameter, 2nd column:
Fixed value of <code class="reqn">\xi</code> parameter
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_xsi.inits">xsi.inits</code></td>
<td>

<p>An optional vector of initial <code class="reqn">\xi</code> parameters. Note that
all parameters must be specified and the vector is not of the
same format as <code>xsi.fixed</code>.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_theta.fixed">theta.fixed</code></td>
<td>
<p>Matrix for fixed person parameters <code class="reqn">\theta</code>. The first
column includes the index whereas the second column includes
the fixed value. This argument can only be applied for <code>version=1</code>.</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_a">A</code></td>
<td>

<p>A design array <code class="reqn">A</code> for item category intercepts.
For item <code class="reqn">i</code> and category <code class="reqn">k</code>, the threshold is
specified as <code class="reqn"> \sum _j a_{ikj}   \xi_j</code>.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_b">B</code></td>
<td>

<p>A design array for scoring item category responses.
Entries in <code class="reqn">B</code> represent item loadings on
abilities <code class="reqn">\theta</code>.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_q">Q</code></td>
<td>

<p>A Q-matrix which defines loadings of items on dimensions.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_ndim">ndim</code></td>
<td>

<p>Number of dimensions in the model. The default is 1.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_pweights">pweights</code></td>
<td>

<p>An optional vector of person weights.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_constraint">constraint</code></td>
<td>
<p>Type of constraint for means. Either <code>"cases"</code>
(set mean of person parameters to zero)
or <code>"items"</code> (set mean of item parameters to zero).
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether output should
be printed during iterations. This argument replaces <code>control$progress</code>.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_control">control</code></td>
<td>

<p>A list of control arguments. See <code><a href="#topic+tam.mml">tam.mml</a></code>
for more details.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_version">version</code></td>
<td>
<p>Version function which should be used. <code>version=2</code>
is the former <code>tam.jml2</code> function in <span class="pkg">TAM</span> (&lt;2.0).
The default <code>version=3</code> allows efficient handling in case of missing
data.
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_object">object</code></td>
<td>

<p>Object of class <code>tam.jml</code> (only for <code>summary.tam</code>
function)
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_file">file</code></td>
<td>

<p>A file name in which the summary output will be written
(only for <code>summary.tam.jml</code> function)
</p>
</td></tr>
<tr><td><code id="tam.jml_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with following entries
</p>
<table>
<tr><td><code>item1</code></td>
<td>
<p>Data frame with item parameters</p>
</td></tr>
<tr><td><code>xsi</code></td>
<td>
<p>Vector of item parameters <code class="reqn">\xi</code></p>
</td></tr>
<tr><td><code>errorP</code></td>
<td>
<p>Standard error of item parameters <code class="reqn">\xi</code></p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>MLE in final step</p>
</td></tr>
<tr><td><code>errorWLE</code></td>
<td>
<p>Standard error of WLE</p>
</td></tr>
<tr><td><code>WLE</code></td>
<td>
<p>WLE in last iteration</p>
</td></tr>
<tr><td><code>WLEreliability</code></td>
<td>
<p>WLE reliability</p>
</td></tr>
<tr><td><code>PersonScores</code></td>
<td>
<p>Scores for each person (sufficient statistic)</p>
</td></tr>
<tr><td><code>ItemScore</code></td>
<td>
<p>Sufficient statistic for each item parameter</p>
</td></tr>
<tr><td><code>PersonMax</code></td>
<td>
<p>Maximum person score</p>
</td></tr>
<tr><td><code>ItemMax</code></td>
<td>
<p>Maximum item score</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>Deviance</p>
</td></tr>
<tr><td><code>deviance.history</code></td>
<td>
<p>Deviance history in iterations</p>
</td></tr>
<tr><td><code>resp</code></td>
<td>
<p>Original data frame</p>
</td></tr>
<tr><td><code>resp.ind</code></td>
<td>
<p>Response indicator matrix</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>Vector of group identifiers (if provided as an argument)</p>
</td></tr>
<tr><td><code>pweights</code></td>
<td>
<p>Vector of person weights</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Design matrix <code class="reqn">A</code> of item intercepts</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>Loading (or scoring) matrix <code class="reqn">B</code></p>
</td></tr>
<tr><td><code>nitems</code></td>
<td>
<p>Number of items</p>
</td></tr>
<tr><td><code>maxK</code></td>
<td>
<p>Maximum number of categories</p>
</td></tr>
<tr><td><code>nstud</code></td>
<td>
<p>Number of persons in <code>resp</code></p>
</td></tr>
<tr><td><code>resp.ind.list</code></td>
<td>
<p>Like <code>resp.ind</code>, only in the format of a list</p>
</td></tr>
<tr><td><code>xsi.fixed</code></td>
<td>
<p>Fixed <code class="reqn">\xi</code> item parameters</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>Control list</p>
</td></tr>
<tr><td><code>item</code></td>
<td>
<p>Extended data frame of item parameters</p>
</td></tr>
<tr><td><code>theta_summary</code></td>
<td>
<p>Summary of person parameters</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
</td></tr>
</table>


<h3>Note</h3>

<p>This joint maximum likelihood estimation procedure should be
compatible with Winsteps and Facets software, see also
<em>http://www.rasch.org/software.htm</em>.
</p>


<h3>References</h3>

<p>Linacre, J. M. (1994). <em>Many-Facet Rasch Measurement</em>.
Chicago: MESA Press.
</p>


<h3>See Also</h3>

<p>For estimating the same class of models with marginal
maximum likelihood estimation see <code><a href="#topic+tam.mml">tam.mml</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Dichotomous data
#############################################################################
data(data.sim.rasch)
resp &lt;- data.sim.rasch[1:700, seq( 1, 40, len=10)  ]  # subsample
# estimate the Rasch model with JML (function 'tam.jml')
mod1a &lt;- TAM::tam.jml(resp=resp)
summary(mod1a)
itemfit &lt;- TAM::tam.fit(mod1a)$fit.item

# compare results with Rasch model estimated by MML
mod1b &lt;- TAM::tam.mml(resp=resp )

# constrain item difficulties to zero
mod1c &lt;- TAM::tam.jml(resp=resp, constraint="items")

# plot estimated parameters
plot( mod1a$xsi, mod1b$xsi$xsi, pch=16,
    xlab=expression( paste( xi[i], " (JML)" )),
    ylab=expression( paste( xi[i], " (MML)" )),
    main="Item Parameter Estimate Comparison")
lines( c(-5,5), c(-5,5), col="gray" )

# Now, the adjustment pf .05 instead of the default .3 is used.
mod1d &lt;- TAM::tam.jml(resp=resp, adj=.05)
# compare item parameters
round( rbind( mod1a$xsi, mod1d$xsi ), 3 )
  ##          [,1]   [,2]   [,3]   [,4]   [,5]  [,6]  [,7]  [,8]  [,9] [,10]
  ##   [1,] -2.076 -1.743 -1.217 -0.733 -0.338 0.147 0.593 1.158 1.570 2.091
  ##   [2,] -2.105 -1.766 -1.233 -0.746 -0.349 0.139 0.587 1.156 1.574 2.108

# person parameters for persons with a score 0, 5 and 10
pers1 &lt;- data.frame( "score_adj0.3"=mod1a$PersonScore, "theta_adj0.3"=mod1a$theta,
           "score_adj0.05"=mod1d$PersonScore, "theta_adj0.05"=mod1d$theta  )
round( pers1[ c(698, 683, 608), ],3  )
  ##       score_adj0.3 theta_adj0.3 score_adj0.05 theta_adj0.05
  ##   698          0.3       -4.404          0.05        -6.283
  ##   683          5.0       -0.070          5.00        -0.081
  ##   608          9.7        4.315          9.95         6.179

## Not run: 
#*** item fit and person fit statistics
fmod1a &lt;- TAM::tam.jml.fit(mod1a)
head(fmod1a$fit.item)
head(fmod1a$fit.person)

#*** Models in which some item parameters are fixed
xsi.fixed &lt;- cbind( c(1,3,9,10), c(-2, -1.2, 1.6, 2 ) )
mod1e &lt;- TAM::tam.jml( resp=resp, xsi.fixed=xsi.fixed )
summary(mod1e)

#*** Model in which also some person parameters theta are fixed
# fix theta parameters of persons 2, 3, 4 and 33 to values -2.9, ...
theta.fixed &lt;- cbind( c(2,3,4,33), c( -2.9, 4, -2.9, -2.9 ) )
mod1g &lt;- TAM::tam.jml( resp=resp, xsi.fixed=xsi.fixed, theta.fixed=theta.fixed )
# look at estimated results
ind.person &lt;- c( 1:5, 30:33 )
cbind( mod1g$WLE, mod1g$errorWLE )[ind.person,]

#############################################################################
# EXAMPLE 2: Partial credit model
#############################################################################

data(data.gpcm, package="TAM")
dat &lt;- data.gpcm

# JML estimation
mod2 &lt;- TAM::tam.jml(resp=dat)
mod2$xsi     # extract item parameters
summary(mod2)
TAM::tam.fit(mod2)    # item and person infit/outfit statistic

#* estimate rating scale model
A &lt;- TAM::designMatrices(resp=dat, modeltype="RSM")$A
#* estimate model with design matrix A
mod3 &lt;- TAM::tam.jml(dat, A=A)
summary(mod3)

#############################################################################
# EXAMPLE 3: Facet model estimation using joint maximum likelihood
#            data.ex10; see also Example 10 in ?tam.mml
#############################################################################

data(data.ex10)
dat &lt;- data.ex10
  ## &gt; head(dat)
  ##  pid rater I0001 I0002 I0003 I0004 I0005
  ##    1     1     0     1     1     0     0
  ##    1     2     1     1     1     1     0
  ##    1     3     1     1     1     0     1
  ##    2     2     1     1     1     0     1
  ##    2     3     1     1     0     1     1

facets &lt;- dat[, "rater", drop=FALSE ] # define facet (rater)
pid &lt;- dat$pid      # define person identifier (a person occurs multiple times)
resp &lt;- dat[, -c(1:2) ]        # item response data
formulaA &lt;- ~ item * rater      # formula

# use MML function only to restructure data and input obtained design matrices
# and processed response data to tam.jml (-&gt; therefore use only 2 iterations)
mod3a &lt;- TAM::tam.mml.mfr( resp=resp, facets=facets, formulaA=formulaA,
             pid=dat$pid,  control=list(maxiter=2) )

# use modified response data mod3a$resp and design matrix mod3a$A
resp1 &lt;- mod3a$resp
# JML
mod3b &lt;- TAM::tam.jml( resp=resp1, A=mod3a$A, control=list(maxiter=200) )

#############################################################################
# EXAMPLE 4: Multi faceted model with some anchored item and person parameters
#############################################################################

data(data.exJ03)
resp &lt;- data.exJ03$resp
X &lt;- data.exJ03$X

#*** (0) preprocess data with TAM::tam.mml.mfr
mod0 &lt;- TAM::tam.mml.mfr( resp=resp, facets=X, pid=X$rater,
                formulaA=~ leader + item + step,
                control=list(maxiter=2) )
summary(mod0)

#*** (1) estimation with tam.jml (no parameter fixings)

# extract processed data and design matrix from tam.mml.mfr
resp1 &lt;- mod0$resp
A1 &lt;- mod0$A
# estimate model with tam.jml
mod1 &lt;- TAM::tam.jml( resp=resp1, A=A1, control=list( Msteps=4, maxiter=100 ) )
summary(mod1)

#*** (2) fix some parameters (persons and items)

# look at indices in mod1$xsi
mod1$xsi
# fix step parameters
xsi.index1 &lt;- cbind( 21:25, c( -2.44, 0.01, -0.15, 0.01,  1.55 ) )
# fix some item parameters of items 1,2,3,6 and 13
xsi.index2 &lt;- cbind( c(1,2,3,6,13), c(-2,-1,-1,-1.32, -1 ) )
xsi.index &lt;- rbind( xsi.index1, xsi.index2 )
# fix some theta parameters of persons 1, 15 and 20
theta.fixed &lt;- cbind(  c(1,15,20), c(0.4, 1, 0 ) )
# estimate model, theta.fixed only works for version=1
mod2 &lt;- TAM::tam.jml( resp=resp1, A=A1, xsi.fixed=xsi.fixed, theta.fixed=theta.fixed,
            control=list( Msteps=4, maxiter=100) )
summary(mod2)
cbind( mod2$WLE, mod2$errorWLE )

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.latreg'>
Latent Regression Model
</h2><span id='topic+tam.latreg'></span><span id='topic+summary.tam.latreg'></span><span id='topic+print.tam.latreg'></span>

<h3>Description</h3>

<p>This function fits a latent regression model <code class="reqn">\bold{\theta}=\bold{Y}
\bold{\beta} + \bold{\varepsilon}</code>.
Only the individual likelihood evaluated at a
<code class="reqn">\bold{\theta}</code> grid is needed as the input. Like in
<code><a href="#topic+tam.mml">tam.mml</a></code> a multivariate normal distribution is posed
on the residual distribution. Plausible values can be drawn by subsequent
application of <code><a href="#topic+tam.pv">tam.pv</a></code> (see Example 1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.latreg(like, theta=NULL, Y=NULL, group=NULL, formulaY=NULL, dataY=NULL,
   beta.fixed=FALSE, beta.inits=NULL, variance.fixed=NULL,
   variance.inits=NULL, est.variance=TRUE, pweights=NULL, pid=NULL,
   userfct.variance=NULL, variance.Npars=NULL, verbose=TRUE, control=list())

## S3 method for class 'tam.latreg'
summary(object,file=NULL,...)

## S3 method for class 'tam.latreg'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.latreg_+3A_like">like</code></td>
<td>

<p>Individual likelihood. This can be typically extracted from fitted
item response models by making use of <code>IRT.likelihood</code>.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_theta">theta</code></td>
<td>

<p>Used <code class="reqn">\bold{\theta}</code> grid in the fitted IRT model. If <code>like</code>
is generated by the <code>IRT.likelihood</code> function, then <code>theta</code>
is automatically extracted as an attribute.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_y">Y</code></td>
<td>

<p>A matrix of covariates in latent regression. Note that the
intercept is automatically included as the first predictor.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_group">group</code></td>
<td>

<p>An optional vector of group identifiers
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_formulay">formulaY</code></td>
<td>

<p>An <span class="rlang"><b>R</b></span> formula for latent regression. Transformations of predictors
in <code class="reqn">Y</code> (included in <code>dataY</code>) can be easily specified,
e. g. <code>female*race</code> or <code>I(age^2)</code>.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_datay">dataY</code></td>
<td>

<p>An optional data frame with possible covariates <code class="reqn">Y</code> in latent regression.
This data frame will be used if an <span class="rlang"><b>R</b></span> formula in <code>formulaY</code>
is specified.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_beta.fixed">beta.fixed</code></td>
<td>

<p>A matrix with three columns for fixing regression coefficients.
1st column: Index of <code class="reqn">Y</code> value, 2nd column: dimension,
3rd column: fixed <code class="reqn">\beta</code> value. <br />
If no constraints should be imposed on <code class="reqn">\beta</code>, then
set <code>beta.fixed=FALSE</code> (see Example 2, Model <code>2_4</code>)
which is the default.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_beta.inits">beta.inits</code></td>
<td>

<p>A matrix (same format as in <code>beta.fixed</code>)
with initial <code class="reqn">\beta</code> values
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_variance.fixed">variance.fixed</code></td>
<td>

<p>An optional matrix with three columns for fixing
entries in covariance matrix:
1st column: dimension 1, 2nd column: dimension 2,
3rd column: fixed value
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_variance.inits">variance.inits</code></td>
<td>

<p>Initial covariance matrix in estimation. All matrix entries have to be
specified and this matrix is NOT in the same format like
<code>variance.inits</code>.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_est.variance">est.variance</code></td>
<td>

<p>Should the covariance matrix be estimated? This argument
applies to estimated item slopes in <code>tam.mml.2pl</code>.
The default is <code>FALSE</code> which means that latent
variables (in the first group) are standardized in 2PL estimation.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_pweights">pweights</code></td>
<td>

<p>An optional vector of person weights
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_pid">pid</code></td>
<td>

<p>An optional vector of person identifiers
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_userfct.variance">userfct.variance</code></td>
<td>
<p>Optional user customized function for variance specification
(See Simulated Example 17).</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_variance.npars">variance.Npars</code></td>
<td>
<p>Number of estimated parameters of variance matrix
if a <code>userfct.variance</code> is provided.</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_verbose">verbose</code></td>
<td>

<p>Optional logical indicating whether iteration should be displayed.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_control">control</code></td>
<td>

<p>List of control parameters, see <code><a href="#topic+tam.mml">tam.mml</a></code> fro details.
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_object">object</code></td>
<td>

<p>Object of class <code>tam.latreg</code>
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_file">file</code></td>
<td>

<p>A file name in which the summary output will be written
</p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_x">x</code></td>
<td>
<p>Object of class <code>tam.latreg</code></p>
</td></tr>
<tr><td><code id="tam.latreg_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Subset of values of <code><a href="#topic+tam.mml">tam.mml</a></code>. In addition,
means (<code>M_post</code>) and standard deviations (<code>SD_post</code>) are computed.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+tam.pv">tam.pv</a></code> for plausible value imputation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Unidimensional latent regression model with fitted IRT model in
#            the sirt package
#############################################################################

library(sirt)
data(data.pisaRead, package="sirt")
dat &lt;- data.pisaRead$data

items &lt;- grep("R4", colnames(dat), value=TRUE )    # select test items from data
# define testlets
testlets &lt;- substring( items, 1, 4 )
itemcluster &lt;- match( testlets, unique(testlets) )
# fit Rasch copula model (only few iterations)
mod &lt;- sirt::rasch.copula2( dat[,items], itemcluster=itemcluster, mmliter=5)
# extract individual likelihood
like1 &lt;- IRT.likelihood( mod )
# fit latent regression model in TAM
Y &lt;- dat[, c("migra", "hisei", "female") ]
mod2 &lt;- TAM::tam.latreg( like1, theta=attr(like1, "theta"), Y=Y, pid=dat$idstud )
summary(mod2)
# plausible value imputation
pv2 &lt;- TAM::tam.pv( mod2 )
# create list of imputed datasets
Y &lt;- dat[, c("idstud", "idschool", "female", "hisei", "migra") ]
pvnames &lt;- c("PVREAD")
datlist &lt;- TAM::tampv2datalist( pv2, pvnames=pvnames, Y=Y, Y.pid="idstud")

#--- fit some models
library(mice)
library(miceadds)
# convert data list into a mice object
mids1 &lt;- miceadds::datalist2mids( datlist )
# perform an ANOVA
mod3a &lt;- with( mids1, stats::lm(PVREAD ~ hisei*migra) )
summary( pool( mod3a ))
mod3b &lt;- miceadds::mi.anova( mids1, "PVREAD ~ hisei*migra" )

#############################################################################
# EXAMPLE 2: data.pisaRead - fitted IRT model in mirt package
#############################################################################

library(sirt)
library(mirt)

data(data.pisaRead, package="sirt")
dat &lt;- data.pisaRead$data

# define dataset with item responses
items &lt;- grep("R4", colnames(dat), value=TRUE )
resp &lt;- dat[,items]
# define dataset with covariates
X &lt;- dat[, c("female","hisei","migra") ]

# fit 2PL model in mirt
mod &lt;- mirt::mirt( resp, 1, itemtype="2PL", verbose=TRUE)
print(mod)
# extract coefficients
sirt::mirt.wrapper.coef(mod)

# extract likelihood
like &lt;- IRT.likelihood(mod)
str(like)

# fit latent regression model in TAM
mod2 &lt;- TAM::tam.latreg( like, Y=X, pid=dat$idstud )
summary(mod2)
# plausible value imputation
pv2 &lt;- TAM::tam.pv( mod2, samp.regr=TRUE, nplausible=5 )
# create list of imputed datasets
X &lt;- dat[, c("idstud", "idschool", "female", "hisei", "migra") ]
pvnames &lt;- c("PVREAD")
datlist &lt;- TAM::tampv2datalist( pv2, pvnames=pvnames, Y=X, Y.pid="idstud")
str(datlist)

# regression using semTools package
library(semTools)
lavmodel &lt;- "
   PVREAD ~ hisei + female
           "
mod1a &lt;- semTools::sem.mi( lavmodel, datlist)
summary(mod1a, standardized=TRUE, rsquare=TRUE)

#############################################################################
# EXAMPLE 3: data.Students - fitted confirmatory factor analysis in lavaan
#############################################################################

library(CDM)
library(sirt)
library(lavaan)

data(data.Students, package="CDM")
dat &lt;- data.Students
vars &lt;- scan(what="character", nlines=1)
   urban female sc1 sc2 sc3 sc4 mj1 mj2 mj3 mj4
dat &lt;- dat[, vars]
dat &lt;- na.omit(dat)

# fit confirmatory factor analysis in lavaan
lavmodel &lt;- "
   SC=~ sc1__sc4
   SC ~~ 1*SC
   MJ=~ mj1__mj4
   MJ ~~ 1*MJ
   SC ~~ MJ
        "
# process lavaan syntax
res &lt;- TAM::lavaanify.IRT( lavmodel, dat )
# fit lavaan CFA model
mod1 &lt;- lavaan::cfa( res$lavaan.syntax, dat, std.lv=TRUE)
summary(mod1, standardized=TRUE, fit.measures=TRUE )
# extract likelihood
like1 &lt;- TAM::IRTLikelihood.cfa( dat, mod1 )
str(like1)
# fit latent regression model in TAM
X &lt;- dat[, c("urban","female") ]
mod2 &lt;- TAM::tam.latreg( like1, Y=X  )
summary(mod2)
# plausible value imputation
pv2 &lt;- TAM::tam.pv( mod2, samp.regr=TRUE, normal.approx=TRUE )
# create list of imputed datasets
Y &lt;- dat[, c("urban", "female" ) ]
pvnames &lt;- c("PVSC", "PVMJ")
datlist &lt;- TAM::tampv2datalist( pv2, pvnames=pvnames, Y=Y )
str(datlist)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.linking'>
Linking of Fitted Unidimensional Item Response Models in <span class="pkg">TAM</span>
</h2><span id='topic+tam.linking'></span><span id='topic+summary.tam.linking'></span><span id='topic+tam_linking_2studies'></span><span id='topic+summary.tam_linking_2studies'></span><span id='topic+print.tam.linking'></span><span id='topic+print.tam_linking_2studies'></span>

<h3>Description</h3>

<p>Performs linking of fitted unidimensional item response models in <span class="pkg">TAM</span>
according to the Stocking-Lord and the Haebara method (Kolen &amp; Brennan, 2014;
Gonzales &amp; Wiberg, 2017).
Several studies can either be linked by a chain of linkings of two studies
(<code>method="chain"</code>) or a joint linking approach (<code>method="joint"</code>)
comprising all pairwise linkings.
</p>
<p>The linking of two studies is implemented in the <code>tam_linking_2studies</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.linking(tamobj_list, type="Hae", method="joint", pow_rob_hae=1, eps_rob_hae=1e-4,
   theta=NULL, wgt=NULL, wgt_sd=2, fix.slope=FALSE, elim_items=NULL,
   par_init=NULL, verbose=TRUE)

## S3 method for class 'tam.linking'
summary(object, file=NULL, ...)

## S3 method for class 'tam.linking'
print(x, ...)

tam_linking_2studies( B1, AXsi1, guess1, B2, AXsi2, guess2, theta, wgt, type,
    M1=0, SD1=1, M2=0, SD2=1, fix.slope=FALSE, pow_rob_hae=1)

## S3 method for class 'tam_linking_2studies'
summary(object, file=NULL, ...)

## S3 method for class 'tam_linking_2studies'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.linking_+3A_tamobj_list">tamobj_list</code></td>
<td>

<p>List of fitted objects in <span class="pkg">TAM</span>
</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_type">type</code></td>
<td>

<p>Type of linking method: <code>"SL"</code> (Stocking-Lord), <code>"Hae"</code> (Haebara) or
<code>"RobHae"</code> (robust Haebara). See Details for more information.
The default is the Haebara linking method.
</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_method">method</code></td>
<td>
<p>Chain linking (<code>"chain"</code>) or joint linking (<code>"joint"</code>)</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_pow_rob_hae">pow_rob_hae</code></td>
<td>
<p>Power for robust Heabara linking</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_eps_rob_hae">eps_rob_hae</code></td>
<td>
<p>Value <code class="reqn">\varepsilon</code> for numerical approximation of
loss function <code class="reqn">|x|^p</code> in robust Haebara linking</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_theta">theta</code></td>
<td>

<p>Grid of <code class="reqn">\theta</code> points. The default is <code>seq(-6,6,len=101)</code>.
</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_wgt">wgt</code></td>
<td>

<p>Weights defined for the <code>theta</code> grid. The default is <br />
<code>tam_normalize_vector( stats::dnorm( theta, sd=2 ))</code>.
</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_wgt_sd">wgt_sd</code></td>
<td>
<p>Standard deviation for <code class="reqn">\theta</code> grid used for
linking function</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_fix.slope">fix.slope</code></td>
<td>

<p>Logical indicating whether the slope transformation constant is fixed to 1.
</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_elim_items">elim_items</code></td>
<td>
<p>List of vectors refering to items which should be removed
from linking (see Model 'lmod2' in Example 1)
</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_par_init">par_init</code></td>
<td>
<p>Optional vector with initial parameter values</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_verbose">verbose</code></td>
<td>

<p>Logical indicating progress of linking computation
</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_object">object</code></td>
<td>
<p>Object of class <code>tam.linking</code> or <code>tam_linking_2studies</code>.</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_x">x</code></td>
<td>
<p>Object of class <code>tam.linking</code> or <code>tam_linking_2studies</code>.</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_file">file</code></td>
<td>
<p>A file name in which the summary output will be written</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_b1">B1</code></td>
<td>
<p>Array <code class="reqn">B</code> for first study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_axsi1">AXsi1</code></td>
<td>
<p>Matrix <code class="reqn">A \xi</code> for first study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_guess1">guess1</code></td>
<td>
<p>Guessing parameter for first study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_b2">B2</code></td>
<td>
<p>Array <code class="reqn">B</code> for second study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_axsi2">AXsi2</code></td>
<td>
<p>Matrix <code class="reqn">A \xi</code> for second study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_guess2">guess2</code></td>
<td>
<p>Guessing parameter for second study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_m1">M1</code></td>
<td>
<p>Mean of first study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_sd1">SD1</code></td>
<td>
<p>Standard deviation of first study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_m2">M2</code></td>
<td>
<p>Mean of second study</p>
</td></tr>
<tr><td><code id="tam.linking_+3A_sd2">SD2</code></td>
<td>
<p>Standard deviation of second study</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Haebara linking is defined by minimizing the loss function
</p>
<p style="text-align: center;"><code class="reqn">\sum_i \sum_k \int \left ( P_{ik} ( \theta ) - P_{ik}^\ast ( \theta ) \right )^2  </code>
</p>

<p>A robustification of Haebara linking minimizes the loss function
</p>
<p style="text-align: center;"><code class="reqn">\sum_i \sum_k \int \left ( P_{ik} ( \theta ) - P_{ik}^\ast ( \theta ) \right )^p  </code>
</p>

<p>with a power <code class="reqn">p</code> (defined in <code>pow_rob_hae</code>) smaller than 2. He, Cui and
Osterlind (2015) consider <code class="reqn">p=1</code>.
</p>


<h3>Value</h3>

<p>List containing entries
</p>
<table>
<tr><td><code>parameters_list</code></td>
<td>
<p>List containing transformed item parameters</p>
</td></tr>
<tr><td><code>linking_list</code></td>
<td>
<p>List containing results of each linking in the
linking chain</p>
</td></tr>
<tr><td><code>M_SD</code></td>
<td>
<p>Mean and standard deviation for each study after linking</p>
</td></tr>
<tr><td><code>trafo_items</code></td>
<td>
<p>Transformation constants for item parameters</p>
</td></tr>
<tr><td><code>trafo_persons</code></td>
<td>
<p>Transformation constants for person parameters</p>
</td></tr>
</table>


<h3>References</h3>

<p>Battauz, M. (2015). <span class="pkg">equateIRT</span>: An <span class="rlang"><b>R</b></span> package for IRT test equating.
<em>Journal of Statistical Software, 68</em>(7), 1-22.
<a href="https://doi.org/10.18637/jss.v068.i07">doi:10.18637/jss.v068.i07</a>
</p>
<p>Gonzalez, J., &amp; Wiberg, M. (2017).
<em>Applying test equating methods: Using <span class="rlang"><b>R</b></span></em>. New York, Springer.
<a href="https://doi.org/10.1007/978-3-319-51824-4">doi:10.1007/978-3-319-51824-4</a>
</p>
<p>He, Y., Cui, Z., &amp; Osterlind, S. J. (2015). New robust scale transformation methods in the
presence of outlying common items.
<em>Applied Psychological Measurement, 39</em>(8), 613-626.
<a href="https://doi.org/10.1177/0146621615587003">doi:10.1177/0146621615587003</a>
</p>
<p>Kolen, M. J., &amp; Brennan, R. L. (2014). <em>Test equating, scaling, and linking:
Methods and practices</em>. New York, Springer.
<a href="https://doi.org/10.1007/978-1-4939-0317-7">doi:10.1007/978-1-4939-0317-7</a>
</p>
<p>Weeks, J. P. (2010). <span class="pkg">plink</span>: An <span class="rlang"><b>R</b></span> package for linking mixed-format tests
using IRT-based methods. <em>Journal of Statistical Software, 35</em>(12), 1-33.
<a href="https://doi.org/10.18637/jss.v035.i12">doi:10.18637/jss.v035.i12</a>
</p>


<h3>See Also</h3>

<p>Linking or equating of item response models can be also conducted with <span class="pkg">plink</span>
(Weeks, 2010), <span class="pkg">equate</span>, <span class="pkg">equateIRT</span> (Battauz, 2015), <span class="pkg">equateMultiple</span>,
<span class="pkg">kequate</span> and <span class="pkg">irteQ</span> packages.
</p>
<p>See also the <code>sirt::linking.haberman</code>,
<code>sirt::invariance.alignment</code> and <code>sirt::linking.haebara</code> functions
in the <b>sirt</b> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Linking dichotomous data with the 2PL model
#############################################################################

data(data.ex16)
dat &lt;- data.ex16
items &lt;- colnames(dat)[-c(1,2)]

# fit grade 1
rdat1 &lt;- TAM::tam_remove_missings( dat[ dat$grade==1, ], items=items )
mod1 &lt;- TAM::tam.mml.2pl( resp=rdat1$resp[, rdat1$items], pid=rdat1$dat$idstud )
summary(mod1)

# fit grade 2
rdat2 &lt;- TAM::tam_remove_missings( dat[ dat$grade==2, ], items=items )
mod2 &lt;- TAM::tam.mml.2pl( resp=rdat2$resp[, rdat2$items], pid=rdat2$dat$idstud )
summary(mod2)

# fit grade 3
rdat3 &lt;- TAM::tam_remove_missings( dat[ dat$grade==3, ], items=items )
mod3 &lt;- TAM::tam.mml.2pl( resp=rdat3$resp[, rdat3$items], pid=rdat3$dat$idstud )
summary(mod3)

# define list of fitted models
tamobj_list &lt;- list( mod1, mod2, mod3 )

#-- link item response models
lmod &lt;- TAM::tam.linking( tamobj_list)
summary(lmod)

# estimate WLEs based on transformed item parameters
parm_list &lt;- lmod$parameters_list

# WLE grade 1
arglist &lt;- list( resp=mod1$resp, B=parm_list[[1]]$B, AXsi=parm_list[[1]]$AXsi )
wle1 &lt;- TAM::tam.mml.wle(tamobj=arglist)

# WLE grade 2
arglist &lt;- list( resp=mod2$resp, B=parm_list[[2]]$B, AXsi=parm_list[[2]]$AXsi )
wle2 &lt;- TAM::tam.mml.wle(tamobj=arglist)

# WLE grade 3
arglist &lt;- list( resp=mod3$resp, B=parm_list[[3]]$B, AXsi=parm_list[[3]]$AXsi )
wle3 &lt;- TAM::tam.mml.wle(tamobj=arglist)

# compare result with chain linking
lmod1b &lt;- TAM::tam.linking(tamobj_list)
summary(lmod1b)

#-- linking with some eliminated items

# remove three items from first group and two items from third group
elim_items &lt;- list( c("A1", "E2","F1"), NULL,  c("F1","F2") )
lmod2 &lt;- TAM::tam.linking(tamobj_list, elim_items=elim_items)
summary(lmod2)

#-- Robust Haebara linking with p=1
lmod3a &lt;- TAM::tam.linking(tamobj_list, type="RobHae", pow_rob_hae=1)
summary(lmod3a)

#-- Robust Haeabara linking with initial parameters and prespecified epsilon value
par_init &lt;- lmod3a$par
lmod3b &lt;- TAM::tam.linking(tamobj_list, type="RobHae", pow_rob_hae=.1,
                eps_rob_hae=1e-3, par_init=par_init)
summary(lmod3b)

#############################################################################
# EXAMPLE 2: Linking polytomous data with the partial credit model
#############################################################################

data(data.ex17)
dat &lt;- data.ex17

items &lt;- colnames(dat)[-c(1,2)]

# fit grade 1
rdat1 &lt;- TAM::tam_remove_missings( dat[ dat$grade==1, ], items=items )
mod1 &lt;- TAM::tam.mml.2pl( resp=rdat1$resp[, rdat1$items], pid=rdat1$dat$idstud )
summary(mod1)

# fit grade 2
rdat2 &lt;- TAM::tam_remove_missings( dat[ dat$grade==2, ], items=items )
mod2 &lt;- TAM::tam.mml.2pl( resp=rdat2$resp[, rdat2$items], pid=rdat2$dat$idstud )
summary(mod2)

# fit grade 3
rdat3 &lt;- TAM::tam_remove_missings( dat[ dat$grade==3, ], items=items )
mod3 &lt;- TAM::tam.mml.2pl( resp=rdat3$resp[, rdat3$items], pid=rdat3$dat$idstud )
summary(mod3)

# list of fitted TAM models
tamobj_list &lt;- list( mod1, mod2, mod3 )

#-- linking: fix slope because partial credit model is fitted
lmod &lt;- TAM::tam.linking( tamobj_list, fix.slope=TRUE)
summary(lmod)

# WLEs can be estimated in the same way as in Example 1.

#############################################################################
# EXAMPLE 3: Linking dichotomous data with the multiple group 2PL models
#############################################################################

data(data.ex16)
dat &lt;- data.ex16
items &lt;- colnames(dat)[-c(1,2)]

# fit grade 1
rdat1 &lt;- TAM::tam_remove_missings( dat[ dat$grade==1, ], items=items )
# create some grouping variable
group &lt;- ( seq( 1, nrow( rdat1$dat ) ) %% 3 ) + 1
mod1 &lt;- TAM::tam.mml.2pl( resp=rdat1$resp[, rdat1$items], pid=rdat1$dat$idstud, group=group)
summary(mod1)

# fit grade 2
rdat2 &lt;- TAM::tam_remove_missings( dat[ dat$grade==2, ], items=items )
group &lt;- 1*(rdat2$dat$dat$idstud &gt; 500)
mod2 &lt;- TAM::tam.mml.2pl( resp=rdat2$resp[, rdat2$items], pid=rdat2$dat$dat$idstud, group=group)
summary(mod2)

# fit grade 3
rdat3 &lt;- TAM::tam_remove_missings( dat[ dat$grade==3, ], items=items )
mod3 &lt;- TAM::tam.mml.2pl( resp=rdat3$resp[, rdat3$items], pid=rdat3$dat$idstud )
summary(mod3)

# define list of fitted models
tamobj_list &lt;- list( mod1, mod2, mod3 )

#-- link item response models
lmod &lt;- TAM::tam.linking( tamobj_list)

#############################################################################
# EXAMPLE 4: Linking simulated dichotomous data with two groups
#############################################################################

library(sirt)

#*** simulate data
N &lt;- 3000  # number of persons
I &lt;- 30    # number of items
b &lt;- seq(-2,2, length=I)
# data for group 1
dat1 &lt;- sirt::sim.raschtype( rnorm(N, mean=0, sd=1), b=b )
# data for group 2
dat2 &lt;- sirt::sim.raschtype( rnorm(N, mean=1, sd=.6), b=b )

# fit group 1
mod1 &lt;- TAM::tam.mml.2pl( resp=dat1 )
summary(mod1)

# fit group 2
mod2 &lt;- TAM::tam.mml.2pl( resp=dat2 )
summary(mod2)

# define list of fitted models
tamobj_list &lt;- list( mod1, mod2 )

#-- link item response models
lmod &lt;- TAM::tam.linking( tamobj_list)
summary(lmod)

# estimate WLEs based on transformed item parameters
parm_list &lt;- lmod$parameters_list

# WLE grade 1
arglist &lt;- list( resp=mod1$resp, B=parm_list[[1]]$B, AXsi=parm_list[[1]]$AXsi )
wle1 &lt;- TAM::tam.mml.wle(tamobj=arglist)

# WLE grade 2
arglist &lt;- list( resp=mod2$resp, B=parm_list[[2]]$B, AXsi=parm_list[[2]]$AXsi )
wle2 &lt;- TAM::tam.mml.wle(tamobj=arglist)
summary(wle1)
summary(wle2)

# estimation with linked and fixed item parameters for group 2
B &lt;- parm_list[[2]]$B
xsi.fixed &lt;- cbind( 1:I, -parm_list[[2]]$AXsi[,2] )
mod2f &lt;- TAM::tam.mml( resp=dat2, B=B, xsi.fixed=xsi.fixed )
summary(mod2f)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.mml'>
Test Analysis Modules: Marginal Maximum Likelihood Estimation
</h2><span id='topic+tam'></span><span id='topic+tam.mml'></span><span id='topic+tam.mml.2pl'></span><span id='topic+tam.mml.mfr'></span><span id='topic+summary.tam'></span><span id='topic+summary.tam.mml'></span><span id='topic+print.tam'></span><span id='topic+print.tam.mml'></span><span id='topic+prior_list_include'></span>

<h3>Description</h3>

<p>Modules for psychometric test analysis demonstrated
with the help of artificial example data.
The package includes MML and JML estimation of
uni- and multidimensional IRT (Rasch,  2PL, Generalized Partial
Credit, Rating Scale, Multi Facets, Nominal Item Response)
models, fit statistic computation, standard error estimation, as
well as plausible value imputation and weighted likelihood
estimation of ability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam(resp, irtmodel="1PL", formulaA=NULL, ...)

tam.mml(resp, Y=NULL, group=NULL, irtmodel="1PL", formulaY=NULL,
    dataY=NULL, ndim=1,  pid=NULL, xsi.fixed=NULL, xsi.inits=NULL,
    beta.fixed=NULL, beta.inits=NULL, variance.fixed=NULL,
    variance.inits=NULL, est.variance=TRUE, constraint="cases", A=NULL,
    B=NULL, B.fixed=NULL,  Q=NULL,  est.slopegroups=NULL, E=NULL,
    pweights=NULL, userfct.variance=NULL,
    variance.Npars=NULL, item.elim=TRUE, verbose=TRUE, control=list() )

tam.mml.2pl(resp, Y=NULL, group=NULL, irtmodel="2PL", formulaY=NULL,
    dataY=NULL, ndim=1, pid=NULL, xsi.fixed=NULL, xsi.inits=NULL,
    beta.fixed=NULL, beta.inits=NULL, variance.fixed=NULL,
    variance.inits=NULL, est.variance=FALSE, A=NULL, B=NULL,
    B.fixed=NULL, Q=NULL, est.slopegroups=NULL, E=NULL, gamma.init=NULL,
    pweights=NULL, userfct.variance=NULL, variance.Npars=NULL,
    item.elim=TRUE, verbose=TRUE, control=list() )

tam.mml.mfr(resp, Y=NULL, group=NULL, irtmodel="1PL", formulaY=NULL,
    dataY=NULL, ndim=1, pid=NULL, xsi.fixed=NULL, xsi.setnull=NULL,
    xsi.inits=NULL, beta.fixed=NULL, beta.inits=NULL, variance.fixed=NULL,
    variance.inits=NULL, est.variance=TRUE, formulaA=~item+item:step,
    constraint="cases", A=NULL, B=NULL,  B.fixed=NULL, Q=NULL,
    facets=NULL, est.slopegroups=NULL, E=NULL,
    pweights=NULL, verbose=TRUE, control=list(), delete.red.items=TRUE )

## S3 method for class 'tam'
summary(object, file=NULL, ...)

## S3 method for class 'tam.mml'
summary(object, file=NULL, ...)

## S3 method for class 'tam'
print(x, ...)

## S3 method for class 'tam.mml'
print(x, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.mml_+3A_resp">resp</code></td>
<td>

<p>Data frame with polytomous item responses <code class="reqn">k=0,...,K</code>.
Missing responses must be declared as <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_y">Y</code></td>
<td>

<p>A matrix of covariates in latent regression. Note that the
intercept is automatically included as the first predictor.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_group">group</code></td>
<td>

<p>An optional vector of group identifiers
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_irtmodel">irtmodel</code></td>
<td>

<p>For fixed item slopes (in <code>tam.mml</code>)
options include <code>PCM</code> (partial credit model), <code>PCM2</code>
(partial credit model with ConQuest parametrization
<code>'item+item*step'</code> and <code>RSM</code> (rating scale model;
the ConQuest parametrization <code>'item+step'</code>). <br />
For estimated item slopes (only available in <code>tam.mml.2pl</code>)
options are <code>2PL</code> (all slopes of item categories
are estimated; Nominal Item Response Model),
<code>GPCM</code> (generalized partial credit
model in which every item gets one and only slope
parameter per dimension) and <code>2PL.groups</code> or <code>GPCM.groups</code>
(subsets of items get same item slope estimates)
and a design matrix <code>E</code> on item slopes in the
generalized partial credit model (<code>GPCM.design</code>,
see Examples).
Note that item slopes can not be estimated with faceted
designs using the function <code>tam.mml.mfr</code>. However,
it is easy to use pre-specified design matrices and apply
some restrictions to <code>tam.mml.2pl</code> (see Example 14, Model 3).
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_formulay">formulaY</code></td>
<td>

<p>An <span class="rlang"><b>R</b></span> formula for latent regression. Transformations of predictors
in <code class="reqn">Y</code> (included in <code>dataY</code>) can be easily specified,
e. g. <code>female*race</code> or <code>I(age^2)</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_datay">dataY</code></td>
<td>

<p>An optional data frame with possible covariates <code class="reqn">Y</code> in latent regression.
This data frame is used if an <span class="rlang"><b>R</b></span> formula in <code>formulaY</code>
is specified.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_ndim">ndim</code></td>
<td>

<p>Number of dimensions (is not needed to determined by the user)
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_pid">pid</code></td>
<td>

<p>An optional vector of person identifiers
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_xsi.fixed">xsi.fixed</code></td>
<td>

<p>A matrix with two columns for fixing <code class="reqn">\xi</code> parameters.
1st column: index of <code class="reqn">\xi</code> parameter, 2nd column: fixed value
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_xsi.setnull">xsi.setnull</code></td>
<td>
<p>A vector of strings indicating which <code class="reqn">\xi</code>
elements should be set to zero which do have entries in
<code>xsi.setnull</code> in their labels (see Example 10a).</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_xsi.inits">xsi.inits</code></td>
<td>

<p>A matrix with two columns (in the same way defined as in
<code>xsi.fixed</code> with initial value for <code class="reqn">\xi</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_beta.fixed">beta.fixed</code></td>
<td>

<p>A matrix with three columns for fixing regression coefficients.
1st column: Index of <code class="reqn">Y</code> value, 2nd column: dimension,
3rd column: fixed <code class="reqn">\beta</code> value. <br />
If no constraints should be imposed on <code class="reqn">\beta</code>, then
set <code>beta.fixed=FALSE</code> (see Example 2, Model <code>2_4</code>).
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_beta.inits">beta.inits</code></td>
<td>

<p>A matrix (same format as in <code>beta.fixed</code>)
with initial <code class="reqn">\beta</code> values
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_variance.fixed">variance.fixed</code></td>
<td>

<p>An optional matrix with three columns for fixing
entries in covariance matrix:
1st column: dimension 1, 2nd column: dimension 2,
3rd column: fixed value
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_variance.inits">variance.inits</code></td>
<td>

<p>Initial covariance matrix in estimation. All matrix entries have to be
specified and this matrix is NOT in the same format like
<code>variance.fixed</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_est.variance">est.variance</code></td>
<td>

<p>Should the covariance matrix be estimated? This argument
applies to estimated item slopes in <code>tam.mml.2pl</code>.
The default is <code>FALSE</code> which means that latent
variables (in the first group) are standardized in 2PL estimation.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_constraint">constraint</code></td>
<td>
<p>Set sum constraint for parameter identification
for <code>items</code> or <code>cases</code> (applies to
<code>tam.mml</code> and <code>tam.mml.mfr</code>)
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_a">A</code></td>
<td>

<p>An optional array of dimension <code class="reqn"> I \times (K+1) \times N_\xi</code>.
Only <code class="reqn">\xi</code> parameters are estimated, entries in <code class="reqn">A</code>
only correspond to the design.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_b">B</code></td>
<td>

<p>An optional array of dimension <code class="reqn"> I \times (K+1) \times D</code>.
In case of <code>tam.mml.2pl</code> entries of the <code class="reqn">B</code> matrix can be
estimated.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_b.fixed">B.fixed</code></td>
<td>

<p>An optional matrix with four columns for fixing <code class="reqn">B</code> matrix entries in 2PL estimation.
1st column: item index, 2nd column: category, 3rd column: dimension,
4th column: fixed value.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_q">Q</code></td>
<td>

<p>An optional <code class="reqn">I \times D</code> matrix (the Q-matrix) which specifies the
loading structure of items on dimensions.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_est.slopegroups">est.slopegroups</code></td>
<td>

<p>A vector of integers of length <code class="reqn">I</code> for estimating item slope
parameters of item groups. This function only applies to
the generalized partial credit model <br /> (<code>irtmodel="2PL.groups"</code>).
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_e">E</code></td>
<td>

<p>An optional design matrix for estimating item slopes
in the generalized partial credit model (<code>irtmodel="GPCM.design"</code>)
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_gamma.init">gamma.init</code></td>
<td>
<p>Optional initial <code class="reqn">gamma</code> parameter vector
(<code>irtmodel="GPCM.design"</code>).
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_pweights">pweights</code></td>
<td>

<p>An optional vector of person weights
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_formulaa">formulaA</code></td>
<td>
<p>Design formula (only applies to <code>tam.mml.mfr</code>).
See Example 8. It is also to possible to set all effects
of a facet to zero, e.g. <code>item*step + 0*rater</code> (see Example 10a).</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_facets">facets</code></td>
<td>
<p>A data frame with facet entries (only applies to
<code>tam.mml.mfr</code>)
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_userfct.variance">userfct.variance</code></td>
<td>
<p>Optional user customized function for variance specification
(See Simulated Example 17).</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_variance.npars">variance.Npars</code></td>
<td>
<p>Number of estimated parameters of variance matrix
if a <code>userfct.variance</code> is provided.</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_item.elim">item.elim</code></td>
<td>
<p>Optional logical indicating whether an item with has
only zero entries should be removed from the analysis. The default
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether output should
be printed during iterations. This argument replaces <code>control$progress</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_control">control</code></td>
<td>

<p>A list of control arguments for the algorithm: <br /><br />
<code> list( nodes=seq(-6,6,len=21), snodes=0, QMC=TRUE,</code><br />
<code>        convD=.001,conv=.0001, convM=.0001, Msteps=4,   </code><br />
<code>        maxiter=1000, max.increment=1, </code><br />
<code>        min.variance=.001, progress=TRUE, ridge=0,    </code><br />
<code>        seed=NULL, xsi.start0=0, increment.factor=1,  </code><br />
<code>        fac.oldxsi=0, acceleration="none", dev_crit="absolute",  </code><br />
<code>        trim_increment="half" )  </code><br />
</p>
<p><code>nodes</code>: the discretized <code class="reqn">\theta</code> nodes for numerical integration
</p>
<p><code>snodes</code>: number of simulated <code class="reqn">\theta</code> nodes for stochastic integration.
If <code>snodes=0</code>, numerical integration is used.
</p>
<p><code>QMC</code>: A logical indicating whether quasi Monte Carlo integration
(Gonzales at al., 2006; Pan &amp; Thompson, 2007) should be used. The default is <code>TRUE</code>.
Quasi Monte Carlo integration is a nonstochastic integration approach
but prevents the very demanding numeric integration using Gaussian quadrature.
In case of <code>QMC=FALSE</code>, &quot;ordinary&quot; stochastic integration is used
(see the section <em>Integration</em> in Details).
</p>
<p><code>convD</code>: Convergence criterion for deviance
</p>
<p><code>conv</code>: Convergence criterion for item parameters and regression
coefficients
</p>
<p><code>convM</code>: Convergence criterion for item parameters within each
M step
</p>
<p><code>Msteps</code>: Number of M steps for item parameter estimation.
A high value of M steps could be helpful in cases of non-convergence.
In <code>tam.mml</code>, <code>tam.mml.2pl</code> and <code>tam.mml.mfr</code>, the default is
set to 4, in <code>tam.mml.3pl</code> it is set to 10.
</p>
<p><code>maxiter</code>: Maximum number of iterations
</p>
<p><code>max.increment</code>: Maximum increment for item parameter change for
every iteration
</p>
<p><code>min.variance</code>: Minimum variance to be estimated during iterations.
</p>
<p><code>progress</code>: A logical indicating whether computation progress should
be displayed at <span class="rlang"><b>R</b></span> console
</p>
<p><code>ridge</code>: A numeric value or a vector of ridge parameter(s)
for the latent regression which is added to the covariance matrix
<code class="reqn">Y'Y</code> of predictors in the diagonal.
</p>
<p><code>seed</code>: An optional integer defining the simulation seed
(important for reproducible results for stochastic integration)
</p>
<p><code>xsi.start0</code>: A numeric value. The value of 0 indicates that for all
parameters starting values are provided. A value of 1 means that all
starting values are set to zero and a value of 2 means that only
starting values of item parameters (but not facet parameters)
are used.
</p>
<p><code>increment.factor</code>: A value (larger than one)
which defines the extent of the decrease of the maximum
increment of item parameters in every iteration. The maximum increment
in iteration <code>iter</code> is defined as
<code>max.increment*increment.factor^(-iter)</code>
where <code>max.increment=1</code>. Using a value larger than 1 helps
to reach convergence in some non-converging analyses (see Example 12).
</p>
<p><code>fac.oldxsi</code>: An optional numeric value <code class="reqn">f</code> between 0 and 1 which
defines the weight of parameter values in previous iteration. If <code class="reqn">\xi_t</code>
denotes a parameter update in iteration <code class="reqn">t</code>, <code class="reqn">\xi_{t-1}</code> is the
parameter value of iteration <code class="reqn">t-1</code>, then the modified parameter value
is defined as <code class="reqn"> \xi_t^*=(1-f) \cdot \xi_t + f \cdot \xi_{t-1}</code>.
Especially in cases where the deviance increases, setting the parameter
larger than 0 (maybe .4 or .5) is helpful in stabilizing the algorithm
(see Example 15).
</p>
<p><code>acceleration</code>: String indicating whether convergence acceleration of
the EM algorithm should be employed. Options are <code>"none"</code> (no acceleration,
the default), the monotone overrelaxation method of <code>"Yu"</code> (Yu, 2012) and
<code>"Ramsay"</code> for the Ramsay (1975) acceleration method.
</p>
<p><code>dev_crit</code>: Criterion for convergence in deviance. <code>dev_crit="absolute"</code>
refers to absolute differences in successive deviance values, while
<code>dev_crit="relative"</code> refers to relative differences.
</p>
<p><code>trim_increment</code>: Type of method for trimming parameter increments in
algorithm. Possible types are <code>"half"</code> or &quot;<code>"cut"</code>.
<br />
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_delete.red.items">delete.red.items</code></td>
<td>
<p>An optional logical indicating whether redundant
generalized items (with no observations) should be eliminated.
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_object">object</code></td>
<td>

<p>Object of class <code>tam</code> or <code>tam.mml</code> (only for <code>summary.tam</code>
functions)
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_file">file</code></td>
<td>

<p>A file name in which the summary output should be written
(only for <code>summary.tam</code> functions)
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
<tr><td><code id="tam.mml_+3A_x">x</code></td>
<td>
<p>Object of class <code>tam</code> or <code>tam.mml</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The multidimensional item response model in <span class="pkg">TAM</span> is
described in Adams, Wilson and Wu (1997) or Adams and Wu (2007).
</p>
<p>The data frame <code>resp</code> contains item responses of <code class="reqn">N</code> persons (in rows)
at <code class="reqn">I</code> items (in columns), each item having at most
<code class="reqn">K</code> categories <code class="reqn">k=0,...,K</code>.
The item response model has <code class="reqn">D</code> dimensions of the <code class="reqn">\theta</code> ability
vector and can be written as
</p>
<p style="text-align: center;"><code class="reqn">
        P( X_{pi}=k | \theta_p )  \propto exp( b_{ik} \theta_p + a_{ik} \xi )
        </code>
</p>

<p>The symbol <code class="reqn">\propto </code> means that response probabilities are normalized such
that <code class="reqn"> \sum _k P( X_{pi}=k | \theta_p )=1 </code>.
</p>
<p>Item category thresholds for item <code class="reqn">i</code> in category <code class="reqn">k</code>
are written as a linear combination
<code class="reqn">a_i \xi</code> where the vector <code class="reqn">\xi</code> of length <code class="reqn">N_\xi</code>
contains generalized item parameters and
<code class="reqn">A=( a_{ik} )_{ik}=( a_i )_{i} </code> is
a three-dimensional design array (specified in <code>A</code>).
</p>
<p>The scoring vector <code class="reqn">b_{ik}</code> contains the fixed (in <code>tam.mml</code>)
or estimated (in <code>tam.mml.2pl</code>) scores of item <code class="reqn">i</code> in category <code class="reqn">k</code>
on dimension <code class="reqn">d</code>.
</p>
<p>For <code>tam.mml.2pl</code> and <code>irtmodel="GPCM.design"</code>, item slopes <code class="reqn">a_i</code>
can be written as a linear combination <code class="reqn">a_i=( E \gamma)_i </code>
of basis item slopes which is an analogue
of the LLTM for item slopes (see Example 7; Embretson, 1999).
</p>
<p>The latent regression model regresses the latent trait <code class="reqn">\theta_p</code>
on covariates <code class="reqn">Y</code> which results in
</p>
<p style="text-align: center;"><code class="reqn">
    \theta_p=Y \beta + \epsilon_p, \epsilon_p \sim N_D ( 0, \Sigma )
</code>
</p>

<p>Where <code class="reqn">\beta</code> is a <code class="reqn">N_Y</code> times <code class="reqn">D</code> matrix of regression
coefficients for <code class="reqn">N_Y</code> covariates in <code class="reqn">Y</code>.
</p>
<p>The multiple group model for groups
<code class="reqn">g=1,...,G</code> is implemented for unidimensional and multidimensional item
response models. In this case, variance heterogeneity is allowed
</p>
<p style="text-align: center;"><code class="reqn">
    \theta_p=Y \beta + \epsilon_p, \epsilon_p \sim N ( 0, \sigma_g^2 )
</code>
</p>

<p><b>Integration</b>: Uni- and multidimensional integrals are approximated by
posing a uni- or multivariate normality assumption. The default is Gaussian
quadrature with nodes defined in <code>control$nodes</code>. For <code class="reqn">D</code>-dimensional
IRT models, the <code class="reqn">D</code>-dimensional cube consisting of the vector
<code>control$nodes</code> in all dimensions is used. If the user specifies
<code>control$snodes</code> with a value larger than zero, then Quasi-Monte Carlo
integration (Pan &amp; Thomas, 2007; Gonzales et al., 2006) with <code>control$snodes</code> is used
(because <code>control$QMC=TRUE</code> is set by default). If
<code>control$QMC=FALSE</code> is specified, then stochastic (Monte Carlo) integration
is employed with <code>control$snodes</code> stochastic nodes.
</p>


<h3>Value</h3>

<p>A list with following entries:
</p>
<table>
<tr><td><code>xsi</code></td>
<td>
<p>Vector of <code class="reqn">\xi</code> parameter estimates and their
corresponding standard errors</p>
</td></tr>
<tr><td><code>xsi.facets</code></td>
<td>
<p>Data frame of <code class="reqn">\xi</code> parameters and corresponding
constraints for multifacet models</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Matrix of <code class="reqn">\beta</code> regression coefficient estimates</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>Covariance matrix. In case of multiple groups,
it is a vector indicating heteroscedastic variances</p>
</td></tr>
<tr><td><code>item</code></td>
<td>
<p>Data frame with item parameters. The column <code>xsi.item</code>
denotes the item difficulty of polytomous items in the parametrization
<code>irtmodel="PCM2"</code>.</p>
</td></tr>
<tr><td><code>item_irt</code></td>
<td>
<p>IRT parameterization of item parameters</p>
</td></tr>
<tr><td><code>person</code></td>
<td>
<p>Matrix with person parameter estimates.
<code>EAP</code> is the mean of the posterior distribution and <code>SD.EAP</code>
the corresponding standard deviation
</p>
</td></tr>
<tr><td><code>pid</code></td>
<td>
<p>Vector of person identifiers</p>
</td></tr>
<tr><td><code>EAP.rel</code></td>
<td>
<p>EAP reliability</p>
</td></tr>
<tr><td><code>post</code></td>
<td>
<p>Posterior distribution for item response pattern</p>
</td></tr>
<tr><td><code>rprobs</code></td>
<td>
<p>A three-dimensional array with estimated response probabilities
(dimensions are items <code class="reqn">\times</code> categories <code class="reqn">\times</code>
theta length)</p>
</td></tr>
<tr><td><code>itemweight</code></td>
<td>
<p>Matrix of item weights</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Theta grid</p>
</td></tr>
<tr><td><code>n.ik</code></td>
<td>
<p>Array of expected counts: theta class <code class="reqn">\times</code>
item <code class="reqn">\times</code> category <code class="reqn">\times</code> group</p>
</td></tr>
<tr><td><code>pi.k</code></td>
<td>
<p>Marginal trait distribution at grid <code>theta</code></p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>Matrix of covariates</p>
</td></tr>
<tr><td><code>resp</code></td>
<td>
<p>Original data frame</p>
</td></tr>
<tr><td><code>resp.ind</code></td>
<td>
<p>Response indicator matrix</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>Group identifier</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>Number of groups</p>
</td></tr>
<tr><td><code>formulaY</code></td>
<td>
<p>Formula for latent regression</p>
</td></tr>
<tr><td><code>dataY</code></td>
<td>
<p>Data frame for latent regression</p>
</td></tr>
<tr><td><code>pweights</code></td>
<td>
<p>Person weights</p>
</td></tr>
<tr><td><code>time</code></td>
<td>
<p>Computation time</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Design matrix <code class="reqn">A</code> for <code class="reqn">\xi</code> parameters</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>Fixed or estimated loading matrix</p>
</td></tr>
<tr><td><code>se.B</code></td>
<td>
<p>Standard errors of <code class="reqn">B</code> parameters</p>
</td></tr>
<tr><td><code>nitems</code></td>
<td>
<p>Number of items</p>
</td></tr>
<tr><td><code>maxK</code></td>
<td>
<p>Maximum number of categories</p>
</td></tr>
<tr><td><code>AXsi</code></td>
<td>
<p>Estimated item intercepts <code class="reqn"> a_{ik} \xi</code></p>
</td></tr>
<tr><td><code>AXsi_</code></td>
<td>
<p>Estimated item intercepts -<code class="reqn"> a_{ik} \xi</code>.
Note that in <code>summary.tam</code>, the parameters <code>AXsi_</code>
are displayed.
</p>
</td></tr>
<tr><td><code>se.AXsi</code></td>
<td>
<p>Standard errors of <code class="reqn">a_{ik} \xi</code> parameters</p>
</td></tr>
<tr><td><code>nstud</code></td>
<td>
<p>Number of persons</p>
</td></tr>
<tr><td><code>resp.ind.list</code></td>
<td>
<p>List of response indicator vectors</p>
</td></tr>
<tr><td><code>hwt</code></td>
<td>
<p>Individual posterior distribution</p>
</td></tr>
<tr><td><code>like</code></td>
<td>
<p>Individual likelihood</p>
</td></tr>
<tr><td><code>ndim</code></td>
<td>
<p>Number of dimensions</p>
</td></tr>
<tr><td><code>xsi.fixed</code></td>
<td>
<p>Fixed <code class="reqn">\xi</code> parameters</p>
</td></tr>
<tr><td><code>xsi.fixed.estimated</code></td>
<td>
<p>Matrix of estimated <code class="reqn">\xi</code> parameters
in form of <code>xsi.fixed</code> which can
be used for parameter fixing in subsequent estimations.</p>
</td></tr>
<tr><td><code>B.fixed</code></td>
<td>
<p>Fixed loading parameters (only applies to <code>tam.mml.2pl</code>)</p>
</td></tr>
<tr><td><code>B.fixed.estimated</code></td>
<td>
<p>Matrix of estimated <code class="reqn">B</code> parameters
in the same format as <code>B.fixed</code>.</p>
</td></tr>
<tr><td><code>est.slopegroups</code></td>
<td>
<p>An index vector of item groups of common slope
parameters (only applies to <code>tam.mml.2pl</code>)</p>
</td></tr>
<tr><td><code>E</code></td>
<td>
<p>Design matrix for estimated item slopes in the generalized partial
credit model (only applies to <code>tam.mml.2pl</code> in case of
<code>irtmodel="GPCM.design"</code>)</p>
</td></tr>
<tr><td><code>basispar</code></td>
<td>
<p>Vector of <code class="reqn">\gamma</code> parameters of the linear combination
<code class="reqn">a_i=( E \gamma)_i </code> for item slopes (only applies to
<code>tam.mml.2pl</code> in case of <code>irtmodel='GPCM.design'</code>)</p>
</td></tr>
<tr><td><code>formulaA</code></td>
<td>
<p>Design formula (only applies to <code>tam.mml.mfr</code>)</p>
</td></tr>
<tr><td><code>facets</code></td>
<td>
<p>Data frame with facet entries (only applies to
<code>tam.mml.mfr</code>)
</p>
</td></tr>
<tr><td><code>variance.fixed</code></td>
<td>
<p>Fixed covariance matrix</p>
</td></tr>
<tr><td><code>nnodes</code></td>
<td>
<p>Number of theta nodes</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>Final deviance</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>Vector with information criteria</p>
</td></tr>
<tr><td><code>deviance.history</code></td>
<td>
<p>Deviance history in iterations</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>List of control arguments</p>
</td></tr>
<tr><td><code>latreg_stand</code></td>
<td>
<p>List containing standardized regression coefficients</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Further values</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For more than three dimensions, quasi-Monte Carlo or stochastic integration
is recommended because otherwise problems in memory allocation and large
computation time will result. Choose in <code>control</code> a suitable value of
the number of quasi Monte Carlo or stochastic nodes <code>snodes</code>
(say, larger than 1000). See Pan and Thompson (2007) or Gonzales et al. (2006)
for more details.
</p>
<p>In faceted models (<code>tam.mml.mfr</code>), parameters which cannot be estimated
are fixed to <code>99</code>.
</p>
<p>Several choices can be made if your model does not converge. First, the number
of iterations within a M step can be increased (<code>Msteps=10</code>).
Second, the absolute value of increments can be forced with increasing
iterations (set a value higher than 1 to <code>max.increment</code>, maybe 1.05).
Third, change in estimated parameters can be stabilized by <code>fac.oldxsi</code> for
which a value of 0 (the default) and a value of 1 can be chosen. We recommend
values between .5 and .8 if your model does not converge.
</p>


<h3>References</h3>

<p>Adams, R. J., Wilson, M., &amp; Wu, M. (1997).
Multilevel item response models: An approach to errors in
variables regression. <em>Journal of Educational and Behavioral
Statistics, 22</em>, 47-76.
<a href="https://doi.org/10.3102/10769986022001047">doi:10.3102/10769986022001047</a>
</p>
<p>Adams, R. J., &amp; Wu, M. L. (2007). The mixed-coefficients multinomial logit model.
A generalized form of the Rasch model. In M. von Davier &amp; C. H. Carstensen (Eds.),
<em>Multivariate and mixture distribution Rasch models: Extensions and applications</em>
(pp. 55-76). New York: Springer.
<a href="https://doi.org/10.1007/978-0-387-49839-3_4">doi:10.1007/978-0-387-49839-3_4</a>
</p>
<p>Embretson, S. E. (1999). Generating items during testing:
Psychometric issues and models. <em>Psychometrika, 64</em>, 407-433.
<a href="https://doi.org/10.1007/BF02294564">doi:10.1007/BF02294564</a>
</p>
<p>Gonzalez, J., Tuerlinckx, F., De Boeck, P., &amp; Cools, R. (2006).
Numerical integration in logistic-normal models.
<em>Computational Statistics &amp; Data Analysis, 51</em>, 1535-1548.
<a href="https://doi.org/10.1016/j.csda.2006.05.003">doi:10.1016/j.csda.2006.05.003</a>
</p>
<p>Pan, J., &amp; Thompson, R. (2007). Quasi-Monte Carlo estimation in
generalized linear mixed models. <em>Computational Statistics &amp;
Data Analysis, 51</em>, 5765-5775.
<a href="https://doi.org/10.1016/j.csda.2006.10.003">doi:10.1016/j.csda.2006.10.003</a>
</p>
<p>Ramsay, J. O. (1975). Solving implicit equations in psychometric data analysis.
<em>Psychometrika, 40</em>(3), 337-360.
<a href="https://doi.org/10.1007/BF02291762">doi:10.1007/BF02291762</a>
</p>
<p>Yu, Y. (2012). Monotonically overrelaxed EM algorithms.
<em>Journal of Computational and Graphical Statistics, 21</em>(2), 518-537.
<a href="https://doi.org/10.1080/10618600.2012.672115">doi:10.1080/10618600.2012.672115</a>
</p>
<p>Wu, M. L., Adams, R. J., Wilson, M. R. &amp; Haldane, S. (2007).
<em>ACER ConQuest Version 2.0</em>. Mulgrave.
https://shop.acer.edu.au/acer-shop/group/CON3.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+data.cqc01">data.cqc01</a></code> for more examples which is are similar to the ones
in the ConQuest manual (Wu, Adams, Wilson &amp; Haldane, 2007).
</p>
<p>See <code><a href="#topic+tam.jml">tam.jml</a></code> for joint maximum likelihood estimation.
</p>
<p>Standard errors are estimated by a rather crude (but quick) approximation.
Use <code><a href="#topic+tam.se">tam.se</a></code> for improved standard errors.
</p>
<p>For model comparisons see <code><a href="#topic+anova.tam">anova.tam</a></code>.
</p>
<p>See <code>sirt::tam2mirt</code> for converting
<code>tam</code> objects into objects of class
<code>mirt::mirt</code> in the <b>mirt</b> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: dichotomous data
# data.sim.rasch: 2000 persons, 40 items
#############################################################################
data(data.sim.rasch)

#************************************************************
# Model 1: Rasch model (MML estimation)
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
# extract item parameters
mod1$item    # item difficulties

## Not run: 
# WLE estimation
wle1 &lt;- TAM::tam.wle( mod1 )
# item fit
fit1 &lt;- TAM::tam.fit(mod1)
# plausible value imputation
pv1 &lt;- TAM::tam.pv(mod1, normal.approx=TRUE, ntheta=300)
# standard errors
se1 &lt;- TAM::tam.se( mod1 )
# summary
summary(mod1)

#-- specification with tamaan
tammodel &lt;- "
 LAVAAN MODEL:
   F=~ I1__I40;
   F ~~ F
 ITEM TYPE:
   ALL(Rasch)
   "
mod1t &lt;- TAM::tamaan( tammodel, data.sim.rasch)
summary(mod1t)

#************************************************************
# Model 1a: Rasch model with fixed item difficulties from 'mod1'
xsi0 &lt;- mod1$xsi$xsi
xsi.fixed &lt;- cbind( 1:(length(xsi0)), xsi0 )
        # define vector with fixed item difficulties
mod1a &lt;- TAM::tam.mml( resp=data.sim.rasch, xsi.fixed=xsi.fixed )
summary(mod1a)

# Usage of the output value mod1$xsi.fixed.estimated has the right format
# as the input of xsi.fixed
mod1aa &lt;- TAM::tam.mml( resp=data.sim.rasch, xsi.fixed=mod1$xsi.fixed.estimated )
summary(mod1b)

#************************************************************
# Model 1b: Rasch model with initial xsi parameters for items 2 (item difficulty b=-1.8),
# item 4 (b=-1.6) and item 40 (b=2)
xsi.inits &lt;- cbind( c(2,4,40), c(-1.8,-1.6,2))
mod1b &lt;- TAM::tam.mml( resp=data.sim.rasch, xsi.inits=xsi.inits )

#-- tamaan specification
tammodel &lt;- "
 LAVAAN MODEL:
   F=~ I1__I40
   F ~~ F
   # Fix item difficulties. Note that item intercepts instead of difficulties
   # must be specified.
   I2 | 1.8*t1
   I4 | 1.6*t1
 ITEM TYPE:
   ALL(Rasch)
   "
mod1bt &lt;- TAM::tamaan( tammodel, data.sim.rasch)
summary(mod1bt)

#************************************************************
# Model 1c: 1PL estimation with sum constraint on item difficulties
dat &lt;- data.sim.rasch
# modify A design matrix to include the sum constraint
des &lt;- TAM::designMatrices(resp=dat)
A1 &lt;- des$A[,, - ncol(dat) ]
A1[ ncol(dat),2, ] &lt;- 1
A1[,2,]
# estimate model
mod1c &lt;- TAM::tam.mml( resp=dat, A=A1, beta.fixed=FALSE,
           control=list(fac.oldxsi=.1) )
summary(mod1c)

#************************************************************
# Model 1d: estimate constraint='items' using tam.mml.mfr
formulaA=~ 0 + item
mod1d &lt;- TAM::tam.mml.mfr( resp=dat, formulaA=formulaA,
                     control=list(fac.oldxsi=.1), constraint="items")
summary(mod1d)

#************************************************************
# Model 1e: This sum constraint can also be obtained by using the argument
# constraint="items" in tam.mml
mod1e &lt;- TAM::tam.mml( resp=data.sim.rasch, constraint="items" )
summary(mod1e)

#************************************************************
# Model 1d2: estimate constraint='items' using tam.mml.mfr
# long format response data
resp.long &lt;- c(dat)

# pid and item facet specifications are necessary
#     Note, that we recommend the facet labels to be sortable in the same order that the
#     results are desired.
#     compare to: facets &lt;- data.frame( "item"=rep(colnames(dat), each=nrow(dat)) )
pid &lt;- rep(1:nrow(dat), ncol(dat))
itemnames &lt;- paste0("I", sprintf(paste('%0', max(nchar(1:ncol(dat))), 'i', sep='' ),
                    c(1:ncol(dat)) ) )
facets   &lt;- data.frame( "item_"=rep(itemnames, each=nrow(dat)) )
formulaA=~ 0 + item_

mod1d2 &lt;- TAM::tam.mml.mfr( resp=resp.long, formulaA=formulaA, control=list(fac.oldxsi=.1),
                       constraint="items", facets=facets, pid=pid)
stopifnot( all(mod1d$xsi.facets$xsi==mod1d2$xsi.facets$xsi) )

## End(Not run)


#************************************************************
# Model 2: 2PL model
mod2 &lt;- TAM::tam.mml.2pl(resp=data.sim.rasch,irtmodel="2PL")

# extract item parameters
mod2$xsi    # item difficulties
mod2$B      # item slopes

#--- tamaan specification
tammodel &lt;- "
 LAVAAN MODEL:
   F=~ I1__I40
   F ~~ 1*F
   # item type of 2PL is the default for dichotomous data
   "
# estimate model
mod2t &lt;- TAM::tamaan( tammodel, data.sim.rasch)
summary(mod2t)

## Not run: 
#************************************************************
# Model 2a: 2PL with fixed item difficulties and slopes from 'mod2'
xsi0 &lt;- mod2$xsi$xsi
xsi.fixed &lt;- cbind( 1:(length(xsi0)), xsi0 )
        # define vector with fixed item difficulties
mod2a &lt;- TAM::tam.mml( resp=data.sim.rasch, xsi.fixed=xsi.fixed,
                 B=mod2$B # fix slopes
            )
summary(mod2a)
mod2a$B     # inspect used slope matrix

#************************************************************
# Model 3: constrained 2PL estimation
# estimate item parameters in different slope groups
# items 1-10, 21-30 group 1
# items 11-20 group 2 and items 31-40 group 3
est.slope &lt;- rep(1,40)
est.slope[ 11:20 ] &lt;- 2
est.slope[ 31:40 ] &lt;- 3
mod3 &lt;- TAM::tam.mml.2pl( resp=data.sim.rasch, irtmodel="2PL.groups",
               est.slopegroups=est.slope )
mod3$B
summary(mod3)

#--- tamaan specification (A)
tammodel &lt;- "
 LAVAAN MODEL:
   F=~ lam1*I1__I10 + lam2*I11__I20 + lam1*I21__I30 + lam3*I31__I40;
   F ~~ 1*F
   "
# estimate model
mod3tA &lt;- TAM::tamaan( tammodel, data.sim.rasch)
summary(mod3tA)

#--- tamaan specification (alternative B)
tammodel &lt;- "
 LAVAAN MODEL:
   F=~ a1__a40*I1__I40;
   F ~~ 1*F
 MODEL CONSTRAINT:
   a1__a10==lam1
   a11__a20==lam2
   a21__a30==lam1
   a31__a40==lam3
   "
mod3tB &lt;- TAM::tamaan( tammodel, data.sim.rasch)
summary(mod3tB)

#--- tamaan specification (alternative C using DO operator)
tammodel &lt;- "
 LAVAAN MODEL:
 DO(1,10,1)
   F=~ lam1*I%
 DOEND
 DO(11,20,1)
   F=~ lam2*I%
 DOEND
 DO(21,30,1)
   F=~ lam1*I%
 DOEND
 DO(31,40,1)
   F=~ lam3*I%
 DOEND
   F ~~ 1*F
   "
# estimate model
mod3tC &lt;- TAM::tamaan( tammodel, data.sim.rasch)
summary(mod3tC)

#############################################################################
# EXAMPLE 2: Unidimensional calibration with latent regressors
#############################################################################

# (1) simulate data
set.seed(6778)     # set simulation seed
N &lt;- 2000          # number of persons
# latent regressors Y
Y &lt;- cbind( stats::rnorm( N, sd=1.5), stats::rnorm(N, sd=.3 ) )
# simulate theta
theta &lt;- stats::rnorm( N ) + .4 * Y[,1] + .2 * Y[,2]  # latent regression model
# number of items
I &lt;- 40
p1 &lt;- stats::plogis( outer( theta, seq( -2, 2, len=I ), "-" ) )
# simulate response matrix
resp &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
colnames(resp) &lt;- paste("I", 1:I, sep="")

# (2) estimate model
mod2_1 &lt;- TAM::tam.mml(resp=resp, Y=Y)
summary(mod2_1)

# (3) setting initial values for beta coefficients
#   beta_2=.20, beta_3=.35 for dimension 1
beta.inits &lt;- cbind( c(2,3), 1, c(.2, .35 ) )
mod2_2 &lt;- TAM::tam.mml(resp=resp, Y=Y, beta.inits=beta.inits)

# (4) fix intercept to zero and third coefficient to .3
beta.fixed &lt;- cbind( c(1,3), 1, c(0, .3 ) )
mod2_3 &lt;- TAM::tam.mml(resp=resp, Y=Y, beta.fixed=beta.fixed )

# (5) same model but with R regression formula for Y
dataY &lt;- data.frame(Y)
colnames(dataY) &lt;- c("Y1","Y2")
mod2_4 &lt;- TAM::tam.mml(resp=resp, dataY=dataY, formulaY=~ Y1+Y2 )
summary(mod2_4)

# (6) model with interaction of regressors
mod2_5 &lt;- TAM::tam.mml(resp=resp, dataY=dataY, formulaY=~ Y1*Y2 )
summary(mod2_5)

# (7) no constraint on regressors (removing constraint from intercept)
mod2_6 &lt;- TAM::tam.mml(resp=resp, Y=Y, beta.fixed=FALSE )

#############################################################################
# EXAMPLE 3: Multiple group estimation
#############################################################################

# (1) simulate data
set.seed(6778)
N &lt;- 3000
theta &lt;- c( stats::rnorm(N/2,mean=0,sd=1.5), stats::rnorm(N/2,mean=.5,sd=1)  )
I &lt;- 20
p1 &lt;- stats::plogis( outer( theta, seq( -2, 2, len=I ), "-" ) )
resp &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
colnames(resp) &lt;- paste("I", 1:I, sep="")
group &lt;- rep(1:2, each=N/2 )

# (2) estimate model
mod3_1 &lt;- TAM::tam.mml( resp,  group=group )
summary(mod3_1)

#############################################################################
# EXAMPLE 4: Multidimensional estimation
# with two dimensional theta's - simulate some bivariate data,
# and regressors
# 40 items: first 20 items load on dimension 1,
#           second 20 items load on dimension 2
#############################################################################

# (1) simulate some data
set.seed(6778)
library(mvtnorm)
N &lt;- 1000
Y &lt;- cbind( stats::rnorm( N ), stats::rnorm(N) )
theta &lt;- mvtnorm::rmvnorm( N,mean=c(0,0), sigma=matrix( c(1,.5,.5,1), 2, 2 ))
theta[,1] &lt;- theta[,1] + .4 * Y[,1] + .2 * Y[,2]  # latent regression model
theta[,2] &lt;- theta[,2] + .8 * Y[,1] + .5 * Y[,2]  # latent regression model
I &lt;- 20
p1 &lt;- stats::plogis( outer( theta[,1], seq( -2, 2, len=I ), "-" ) )
resp1 &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
p1 &lt;- stats::plogis( outer( theta[,2], seq( -2, 2, len=I ), "-" ) )
resp2 &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
resp &lt;- cbind(resp1,resp2)
colnames(resp) &lt;- paste("I", 1:(2*I), sep="")

# (2) define loading Matrix
Q &lt;- array( 0, dim=c( 2*I, 2 ))
Q[cbind(1:(2*I), c( rep(1,I), rep(2,I) ))] &lt;- 1

# (3) estimate models

#************************************************************
# Model 4.1: Rasch model: without regressors
mod4_1 &lt;- TAM::tam.mml( resp=resp, Q=Q )

#--- tamaan specification
tammodel &lt;- "
  LAVAAN MODEL:
    F1=~ 1*I1__I20
    F2=~ 1*I21__I40
    # Alternatively to the factor 1 one can use the item type Rasch
    F1 ~~ F1
    F2 ~~ F2
    F1 ~~ F2
    "
mod4_1t &lt;- TAM::tamaan( tammodel, resp, control=list(maxiter=100))
summary(mod4_1t)

#************************************************************
# Model 4.1b: estimate model with sum constraint of items for each dimension
mod4_1b &lt;- TAM::tam.mml( resp=resp, Q=Q,constraint="items")

#************************************************************
# Model 4.2: Rasch model: set covariance between dimensions to zero
variance_fixed &lt;- cbind( 1, 2, 0 )
mod4_2 &lt;- TAM::tam.mml( resp=resp, Q=Q, variance.fixed=variance_fixed )
summary(mod4_2)

#--- tamaan specification
tammodel &lt;- "
  LAVAAN MODEL:
    F1=~ I1__I20
    F2=~ I21__I40
    F1 ~~ F1
    F2 ~~ F2
    F1 ~~ 0*F2
  ITEM TYPE:
    ALL(Rasch)
    "
mod4_2t &lt;- TAM::tamaan( tammodel, resp)
summary(mod4_2t)

#************************************************************
# Model 4.3: 2PL model
mod4_3 &lt;- TAM::tam.mml.2pl( resp=resp, Q=Q, irtmodel="2PL" )

#--- tamaan specification
tammodel &lt;- "
  LAVAAN MODEL:
    F1=~ I1__I20
    F2=~ I21__I40
    F1 ~~ F1
    F2 ~~ F2
    F1 ~~ F2
    "
mod4_3t &lt;- TAM::tamaan( tammodel, resp )
summary(mod4_3t)

#************************************************************
# Model 4.4: Rasch model with 2000 quasi monte carlo nodes
# -&gt; nodes are useful for more than 3 or 4 dimensions
mod4_4 &lt;- TAM::tam.mml( resp=resp, Q=Q, control=list(snodes=2000) )

#************************************************************
# Model 4.5: Rasch model with 2000 stochastic nodes
mod4_5 &lt;- TAM::tam.mml( resp=resp, Q=Q,control=list(snodes=2000,QMC=FALSE))

#************************************************************
# Model 4.6: estimate two dimensional Rasch model with regressors
mod4_6 &lt;- TAM::tam.mml( resp=resp, Y=Y, Q=Q )

#--- tamaan specification
tammodel &lt;- "
  LAVAAN MODEL:
    F1=~ I1__I20
    F2=~ I21__I40
    F1 ~~ F1
    F2 ~~ F2
    F1 ~~ F2
  ITEM TYPE:
    ALL(Rasch)
    "
mod4_6t &lt;- TAM::tamaan( tammodel, resp, Y=Y )
summary(mod4_6t)

#############################################################################
# EXAMPLE 5: 2-dimensional estimation with within item dimensionality
#############################################################################
library(mvtnorm)
# (1) simulate data
set.seed(4762)
N &lt;- 2000 # 2000 persons
Y &lt;- stats::rnorm( N )
theta &lt;- mvtnorm::rmvnorm( N,mean=c(0,0), sigma=matrix( c(1,.5,.5,1), 2, 2 ))
I &lt;- 10
# 10 items load on the first dimension
p1 &lt;- stats::plogis( outer( theta[,1], seq( -2, 2, len=I ), "-" ) )
resp1 &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
# 10 items load on the second dimension
p1 &lt;- stats::plogis( outer( theta[,2], seq( -2, 2, len=I ), "-" ) )
resp2 &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
# 20 items load on both dimensions
p1 &lt;- stats::plogis( outer( 0.5*theta[,1] + 1.5*theta[,2], seq(-2,2,len=2*I ), "-" ))
resp3 &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*2*I ), nrow=N, ncol=2*I ) )
#Combine the two sets of items into one response matrix
resp &lt;- cbind(resp1, resp2, resp3 )
colnames(resp) &lt;- paste("I", 1:(4*I), sep="")

# (2) define loading matrix
Q &lt;- cbind(c(rep(1,10),rep(0,10),rep(1,20)), c(rep(0,10),rep(1,10),rep(1,20)))

# (3) model: within item dimensionality and 2PL estimation
mod5 &lt;- TAM::tam.mml.2pl(resp, Q=Q, irtmodel="2PL" )
summary(mod5)

# item difficulties
mod5$item
# item loadings
mod5$B

#--- tamaan specification
tammodel &lt;- "
  LAVAAN MODEL:
    F1=~ I1__I10 + I21__I40
    F2=~ I11__I20 + I21__I40
    F1 ~~ 1*F1
    F1 ~~ F2
    F2 ~~ 1*F2
    "
mod5t &lt;- TAM::tamaan( tammodel, resp,  control=list(maxiter=10))
summary(mod5t)

#############################################################################
# EXAMPLE 6: ordered data - Generalized partial credit model
#############################################################################
data(data.gpcm, package="TAM")

#************************************************************
# Ex6.1: Nominal response model (irtmodel="2PL")
mod6_1 &lt;- TAM::tam.mml.2pl( resp=data.gpcm, irtmodel="2PL", control=list(maxiter=200) )
mod6_1$item # item intercepts
mod6_1$B    # for every category a separate slope parameter is estimated

# reestimate the model with fixed item parameters
mod6_1a &lt;- TAM::tam.mml.2pl( resp=data.gpcm, irtmodel="2PL",
       xsi.fixed=mod6_1$xsi.fixed.estimated,  B.fixed=mod6_1$B.fixed.estimated,
       est.variance=TRUE )

# estimate the model with initial item parameters from mod6_1
mod6_1b &lt;- TAM::tam.mml.2pl( resp=data.gpcm, irtmodel="2PL",
       xsi.inits=mod6_1$xsi.fixed.estimated,  B=mod6_1$B )

#************************************************************
# Ex6.2: Generalized partial credit model
mod6_2 &lt;- TAM::tam.mml.2pl( resp=data.gpcm, irtmodel="GPCM", control=list(maxiter=200))
mod6_2$B[,2,]    # joint slope parameter for all categories

#************************************************************
# Ex6.3: some fixed entries of slope matrix B
# B: nitems x maxK x ndim
#   ( number of items x maximum number of categories x number of dimensions)
# set two constraints
B.fixed &lt;- matrix( 0, 2, 4 )
# set second item, score of 2 (category 3), at first dimension to 2.3
B.fixed[1,] &lt;- c(2,3,1,2.3)
# set third item, score of 1 (category 2), at first dimension to 1.4
B.fixed[2,] &lt;- c(3,2,1,1.4)

# estimate item parameter with variance fixed (by default)
mod6_3 &lt;- TAM::tam.mml.2pl( resp=data.gpcm, irtmodel="2PL", B.fixed=B.fixed,
                 control=list( maxiter=200) )
mod6_3$B

#************************************************************
# Ex 6.4: estimate the same model, but estimate variance
mod6_4 &lt;- TAM::tam.mml.2pl( resp=data.gpcm, irtmodel="2PL", B.fixed=B.fixed,
               est.variance=TRUE, control=list( maxiter=350) )
mod6_4$B

#************************************************************
# Ex 6.5: partial credit model
mod6_5 &lt;- TAM::tam.mml( resp=data.gpcm,control=list( maxiter=200) )
mod6_5$B

#************************************************************
# Ex 6.6: partial credit model: Conquest parametrization 'item+item*step'
mod6_6 &lt;- TAM::tam.mml( resp=data.gpcm, irtmodel="PCM2" )
summary(mod6_6)

# estimate mod6_6 applying the sum constraint of item difficulties
# modify design matrix of xsi paramters
A1 &lt;- TAM::.A.PCM2(resp=data.gpcm )
A1[3,2:4,"Comfort"] &lt;- 1:3
A1[3,2:4,"Work"] &lt;- 1:3
A1 &lt;- A1[,, -3] # remove Benefit xsi item parameter
# estimate model
mod6_6b &lt;- TAM::tam.mml( resp=data.gpcm, A=A1, beta.fixed=FALSE )
summary(mod6_6b)

# estimate model with argument constraint="items"
mod6_6c &lt;- TAM::tam.mml( resp=data.gpcm, irtmodel="PCM2", constraint="items")

# estimate mod6_6 using tam.mml.mfr
mod6_6d &lt;- TAM::tam.mml.mfr( resp=data.gpcm, formulaA=~ 0 + item + item:step,
    control=list(fac.oldxsi=.1), constraint="items" )
summary(mod6_6d)

#************************************************************
# Ex 6.7: Rating scale model: Conquest parametrization 'item+step'
mod6_7 &lt;- TAM::tam.mml( resp=data.gpcm, irtmodel="RSM" )
summary(mod6_7)

#************************************************************
# Ex 6.8: sum constraint on item difficulties
#         partial credit model: ConQuest parametrization 'item+item*step'
#         polytomous scored TIMMS data
#         compare to Example 16
#

data(data.timssAusTwn.scored)
dat &lt;- data.timssAusTwn.scored[,1:11]

## &gt; tail(sort(names(dat)),1) # constrained item
## [1] "M032761"

# modify design matrix of xsi paramters
A1 &lt;- TAM::.A.PCM2( resp=dat )
# constrained item loads on every other main item parameter
# with opposing margin it had been loaded on its own main item parameter
A1["M032761",,setdiff(colnames(dat), "M032761")] &lt;- -A1["M032761",,"M032761"]
# remove main item parameter for constrained item
A1 &lt;- A1[,, setdiff(dimnames(A1)[[3]],"M032761")]

# estimate model
mod6_8a &lt;- TAM::tam.mml( resp=dat, A=A1, beta.fixed=FALSE )
summary(mod6_8a)
# extract fixed item parameter for item M032761
## - sum(mod6_8a$xsi[setdiff(colnames(dat), "M032761"),"xsi"])

# estimate mod6_8a using tam.mml.mfr
## fixed a bug in 'tam.mml.mfr' for differing number of categories
## per item -&gt; now a xsi vector with parameter fixings to values
## of 99 is used
mod6_8b &lt;- TAM::tam.mml.mfr( resp=dat, formulaA=~ 0 + item + item:step,
                        control=list(fac.oldxsi=.1), constraint="items" )
summary(mod6_8b)

#************************************************************
# Ex 6.9: sum constraint on item difficulties for irtmodel="PCM"

data(data.timssAusTwn.scored)
dat &lt;- data.timssAusTwn.scored[,2:11]
dat[ dat==9 ] &lt;- NA

# obtain the design matrix for the PCM parametrization and
# the number of categories for each item
maxKi &lt;- apply(dat, 2, max, na.rm=TRUE)
des &lt;- TAM::designMatrices(resp=dat)
A1 &lt;- des$A

# define the constrained item category and remove the respective parameter
(par &lt;- unlist( strsplit(dimnames(A1)[[3]][dim(A1)[3]], split="_") ))
A1 &lt;- A1[,,-dim(A1)[3]]

# the item category loads on every other item category parameter with
# opposing margin, balancing the number of categories for each item
item.id &lt;- which(colnames(dat)==par[1])
cat.id &lt;- maxKi[par[1]]+1
loading &lt;- 1/rep(maxKi, maxKi)
loading &lt;- loading [-which(names(loading)==par[1])[1]]
A1[item.id, cat.id, ] &lt;- loading
A1[item.id,,]

# estimate model
mod6_9 &lt;- TAM::tam.mml( resp=dat, A=A1, beta.fixed=FALSE )
summary(mod6_9)

## extract fixed item category parameter
# calculate mean for each item
ind.item.cat.pars &lt;- sapply(colnames(dat), grep, rownames(mod6_8$xsi))
item.means &lt;- lapply(ind.item.cat.pars, function(ii) mean(mod6_8$xsi$xsi[ii]))

# these sum up to the negative of the fixed parameter
fix.par &lt;- -sum( unlist(item.means), na.rm=TRUE)

#************************************************************
# Ex 6.10: Generalized partial credit model with equality constraints
#          on item discriminations

data(data.gpcm)
dat &lt;- data.gpcm

# Ex 6.10a: set all slopes of three items equal to each other
E &lt;- matrix( 1, nrow=3, ncol=1 )
mod6_10a &lt;- TAM::tam.mml.2pl( dat, irtmodel="GPCM.design", E=E  )
summary(mod6_10a)
mod6_10a$B[,,]

# Ex 6.10b: equal slope for first and third item
E &lt;- matrix( 0, nrow=3, ncol=2 )
E[c(1,3),1] &lt;- 1
E[ 2, 2 ] &lt;- 1
mod6_10b &lt;- TAM::tam.mml.2pl( dat, irtmodel="GPCM.design", E=E  )
summary(mod6_10b)
mod6_10b$B[,,]

#############################################################################
# EXAMPLE 7: design matrix for slopes for the generalized partial credit model
#############################################################################

# (1) simulate data from a model with a (item slope) design matrix E
set.seed(789)
I &lt;- 42
b &lt;- seq( -2, 2, len=I)
# create design matrix for loadings
E &lt;- matrix( 0, I, 5 )
E[ seq(1,I,3), 1 ] &lt;- 1
E[ seq(2,I,3), 2 ] &lt;- 1
E[ seq(3,I,3), 3 ] &lt;- 1
ind &lt;- seq( 1, I, 2 ) ; E[ ind, 4 ] &lt;- rep( c( .3, -.2 ), I )[ 1:length(ind) ]
ind &lt;- seq( 2, I, 4 ) ; E[ ind, 5 ] &lt;- rep( .15, I )[ 1:length(ind) ]
E

# true basis slope parameters
lambda &lt;- c( 1, 1.2, 0.8, 1, 1.1 )
# calculate item slopes
a &lt;- E %*% lambda

# simulate
N &lt;- 4000
theta &lt;- stats::rnorm( N )
aM &lt;- outer( rep(1,N), a[,1] )
bM &lt;- outer( rep(1,N), b )
pM &lt;- stats::plogis( aM * ( matrix( theta, nrow=N, ncol=I  ) - bM ) )
dat &lt;- 1 * ( pM &gt; stats::runif( N*I ) )
colnames(dat) &lt;- paste("I", 1:I, sep="")

# estimate model
mod7 &lt;- TAM::tam.mml.2pl( resp=dat, irtmodel="GPCM.design", E=E )
mod7$B

# recalculate estimated basis parameters
stats::lm( mod7$B[,2,1] ~ 0+ as.matrix(E ) )
  ##   Call:
  ##   lm(formula=mod7$B[, 2, 1] ~ 0 + as.matrix(E))
  ##   Coefficients:
  ##   as.matrix(E)1  as.matrix(E)2  as.matrix(E)3  as.matrix(E)4  as.matrix(E)5
  ##          0.9904         1.1896         0.7817         0.9601         1.2132

#############################################################################
# EXAMPLE 8: Differential item functioning                                  #
#  A first example of a Multifaceted Rasch Model                            #
#  Facet is only female; 10 items are studied                               #
#############################################################################
data(data.ex08)

formulaA &lt;- ~ item+female+item*female
# this formula is in R equivalent to 'item*female'
resp &lt;- data.ex08[["resp"]]
facets &lt;- as.data.frame( data.ex08[["facets"]] )

#***
# Model 8a: investigate gender DIF on all items
mod8a &lt;- TAM::tam.mml.mfr( resp=resp, facets=facets, formulaA=formulaA )
summary(mod8a)

#***
# Model 8a 2: specification with long format response data
resp.long &lt;- c( data.ex08[["resp"]] )
pid &lt;- rep( 1:nrow(data.ex08[["resp"]]), ncol(data.ex08[["resp"]]) )

itemnames &lt;- rep(colnames(data.ex08[["resp"]]), each=nrow(data.ex08[["resp"]]))
facets.long &lt;- cbind( data.frame( "item"=itemnames ),
                 data.ex08[["facets"]][pid,,drop=F] )

mod8a_2 &lt;- TAM::tam.mml.mfr( resp=resp.long, facets=facets.long,
                      formulaA=formulaA, pid=pid)
stopifnot( all(mod8a$xsi.facets$xsi==mod8a_2$xsi.facets$xsi) )

#***
# Model 8b: Differential bundle functioning (DBF)
#   - investigate differential item functioning in item groups

# modify pre-specified design matrix to define 'appropriate' DBF effects
formulaA &lt;- ~ item*female
des &lt;- TAM::designMatrices.mfr( resp=resp, facets=facets, formulaA=formulaA)
A1 &lt;- des$A$A.3d
# item group A: items 1-5
# item group B: items 6-8
# item group C: items 9-10
A1 &lt;- A1[,,1:13]
dimnames(A1)[[3]][ c(12,13) ] &lt;- c("A:female1", "B:female1")
# item group A
A1[,2,12] &lt;- 0
A1[c(1,5,7,9,11),2,12] &lt;- -1
A1[c(1,5,7,9,11)+1,2,12] &lt;- 1
# item group B
A1[,2,13] &lt;- 0
A1[c(13,15,17),2,13] &lt;- -1
A1[c(13,15,17)+1,2,13] &lt;- 1
# item group C (define effect(A)+effect(B)+effect(C)=0)
A1[c(19,3),2,c(12,13)] &lt;- 1
A1[c(19,3)+1,2,c(12,13)] &lt;- -1
#   A1[,2,]   # look at modified design matrix
# estimate model
mod8b &lt;- TAM::tam.mml( resp=des$gresp$gresp.noStep, A=A1 )
summary(mod8b)

#############################################################################
# EXAMPLE 9: Multifaceted Rasch Model
#############################################################################

data(data.sim.mfr)
data(data.sim.facets)

# two way interaction item and rater
formulaA &lt;- ~item+item:step + item*rater
mod9a &lt;- TAM::tam.mml.mfr( resp=data.sim.mfr, facets=data.sim.facets, formulaA=formulaA)
mod9a$xsi.facets
summary(mod9a)

# three way interaction item, female and rater
formulaA &lt;- ~item+item:step + female*rater + female*item*step
mod9b &lt;- TAM::tam.mml.mfr( resp=data.sim.mfr, facets=data.sim.facets, formulaA=formulaA)
summary(mod9b)

#############################################################################
# EXAMPLE 10: Model with raters.
#   Persons are arranged in multiple rows which is indicated
#   by multiple person identifiers.
#############################################################################
data(data.ex10)
dat &lt;- data.ex10
head(dat)
  ##     pid rater I0001 I0002 I0003 I0004 I0005
  ## 1     1     1     0     1     1     0     0
  ## 451   1     2     1     1     1     1     0
  ## 901   1     3     1     1     1     0     1
  ## 452   2     2     1     1     1     0     1
  ## 902   2     3     1     1     0     1     1

facets &lt;- dat[, "rater", drop=FALSE ] # define facet (rater)
pid &lt;- dat$pid      # define person identifier (a person occurs multiple times)
resp &lt;- dat[, -c(1:2) ]        # item response data
formulaA &lt;- ~ item * rater      # formula

mod10 &lt;- TAM::tam.mml.mfr( resp=resp, facets=facets, formulaA=formulaA, pid=dat$pid )
summary(mod10)

# estimate person parameter with WLE
wmod10 &lt;- TAM::tam.wle( mod10 )

#--- Example 10a
# compare model containing only item
formulaA &lt;- ~ item + rater      # pseudo formula for item
xsi.setnull &lt;- "rater"          # set all rater effects to zero
mod10a &lt;- TAM::tam.mml.mfr( resp=resp, facets=facets, formulaA=formulaA,
            xsi.setnull=xsi.setnull, pid=dat$pid, beta.fixed=cbind(1,1,0))
summary(mod10a)

# A shorter way for specifying this example is
formulaA &lt;- ~ item + 0*rater        # set all rater effects to zero
mod10a1 &lt;- TAM::tam.mml.mfr( resp=resp, facets=facets, formulaA=formulaA, pid=dat$pid )
summary(mod10a1)

# tam.mml.mfr also appropriately extends the facets data frame with pseudo facets
# if necessary
formulaA &lt;- ~ item     # omitting the rater term
mod10a2 &lt;- TAM::tam.mml.mfr( resp=resp, facets=facets, formulaA=formulaA, pid=dat$pid )
  ##   Item Parameters Xsi
  ##              xsi se.xsi
  ##   I0001   -1.931  0.111
  ##   I0002   -1.023  0.095
  ##   I0003   -0.089  0.089
  ##   I0004    1.015  0.094
  ##   I0005    1.918  0.110
  ##   psfPF11  0.000  0.000
  ##   psfPF12  0.000  0.000

#***
# Model 10_2: specification with long format response data
resp.long &lt;- c(unlist( dat[, -c(1:2) ] ))

pid &lt;- rep( dat$pid, ncol(dat[, -c(1:2) ]) )
itemnames &lt;- rep(colnames(dat[, -c(1:2) ]), each=nrow(dat[, -c(1:2) ]))

# quick note: the 'trick' to use pid as the row index of the facet  (cf., used in Ex 8a_2)
# is not working here, since pid already occures multiple times in the original response data
facets &lt;- cbind( data.frame("item"=itemnames),
                 dat[ rep(1:nrow(dat), ncol(dat[,-c(1:2)])), "rater",drop=F]
)

mod10_2 &lt;- TAM::tam.mml.mfr( resp=resp.long, facets=facets, formulaA=formulaA, pid=pid)

stopifnot( all(mod10$xsi.facets$xsi==mod10_2$xsi.facets$xsi) )

#############################################################################
# EXAMPLE 11: Dichotomous data with missing and omitted responses
#############################################################################
data(data.ex11) ; dat &lt;- data.ex11

#***
# Model 11a: Calibration (item parameter estimating) in which omitted
#            responses (code 9) are set to missing
dat1 &lt;- dat[,-1]
dat1[ dat1==9 ] &lt;- NA
# estimate Rasch model
mod11a &lt;- TAM::tam.mml( resp=dat1 )
summary(mod11a)
# compute person parameters
wmod11a &lt;- TAM::tam.wle( mod11a )

#***
# Model 11b: Scaling persons (WLE estimation) setting omitted
#            responses as incorrect and using fixed
#            item parameters form Model 11a

# set matrix with fixed item difficulties as the input
xsi1 &lt;- mod11a$xsi    # xsi output from Model 11a
xsi.fixed &lt;- cbind( seq(1,nrow(xsi1) ), xsi1$xsi )
# recode 9 to 0
dat2 &lt;- dat[,-1]
dat2[ dat2==9 ] &lt;- 0
# run Rasch model with fixed item difficulties
mod11b &lt;- TAM::tam.mml( resp=dat2, xsi.fixed=xsi.fixed )
summary(mod11b)
# WLE estimation
wmod11b &lt;- TAM::tam.wle( mod11b )

#############################################################################
# EXAMPLE 12: Avoiding nonconvergence using the argument increment.factor
#############################################################################
data(data.ex12)
dat &lt;- data.ex12

# non-convergence without increment.factor
mod1 &lt;- TAM::tam.mml.2pl( resp=data.ex12, control=list( maxiter=1000) )

# avoiding non-convergence with increment.factor=1.02
mod2 &lt;- TAM::tam.mml.2pl( resp=data.ex12,
            control=list( maxiter=1000, increment.factor=1.02) )
summary(mod1)
summary(mod2)

#############################################################################
# EXAMPLE 13: Longitudinal data 'data.long' from sirt package
#############################################################################
library(sirt)
data(data.long, package="sirt")
dat &lt;- data.long
  ##   &gt; colnames(dat)
  ##    [1] "idstud" "I1T1"   "I2T1"   "I3T1"   "I4T1"   "I5T1"   "I6T1"
  ##    [8] "I3T2"   "I4T2"   "I5T2"   "I6T2"   "I7T2"   "I8T2"

## item 1 to 6 administered at T1 and items 3 to 8 at T2
## items 3 to 6 are anchor items

#***
# Model 13a: 2-dimensional Rasch model assuming invariant item difficulties

# define matrix loadings
Q &lt;- matrix(0,12,2)
colnames(Q) &lt;- c("T1","T2")
Q[1:6,1] &lt;- 1       # items at T1
Q[7:12,2] &lt;- 1      # items at T2

# assume equal item difficulty of I3T1 and I3T2, I4T1 and I4T2, ...
# create draft design matrix and modify it
A &lt;- TAM::designMatrices(resp=data.long[,-1])$A
dimnames(A)[[1]] &lt;- colnames(data.long)[-1]
  ##   &gt; str(A)
  ##    num [1:12, 1:2, 1:12] 0 0 0 0 0 0 0 0 0 0 ...
  ##    - attr(*, "dimnames")=List of 3
  ##     ..$ : chr [1:12] "Item01" "Item02" "Item03" "Item04" ...
  ##     ..$ : chr [1:2] "Category0" "Category1"
  ##     ..$ : chr [1:12] "I1T1" "I2T1" "I3T1" "I4T1" ...
A1 &lt;- A[,, c(1:6, 11:12 ) ]
dimnames(A1)[[3]] &lt;- substring( dimnames(A1)[[3]],1,2)
A1[7,2,3] &lt;- -1     # difficulty(I3T1)=difficulty(I3T2)
A1[8,2,4] &lt;- -1     # I4T1=I4T2
A1[9,2,5] &lt;- A1[10,2,6] &lt;- -1
  ##   &gt; A1[,2,]
  ##        I1 I2 I3 I4 I5 I6 I7 I8
  ##   I1T1 -1  0  0  0  0  0  0  0
  ##   I2T1  0 -1  0  0  0  0  0  0
  ##   I3T1  0  0 -1  0  0  0  0  0
  ##   I4T1  0  0  0 -1  0  0  0  0
  ##   I5T1  0  0  0  0 -1  0  0  0
  ##   I6T1  0  0  0  0  0 -1  0  0
  ##   I3T2  0  0 -1  0  0  0  0  0
  ##   I4T2  0  0  0 -1  0  0  0  0
  ##   I5T2  0  0  0  0 -1  0  0  0
  ##   I6T2  0  0  0  0  0 -1  0  0
  ##   I7T2  0  0  0  0  0  0 -1  0
  ##   I8T2  0  0  0  0  0  0  0 -1

# estimate model
# set intercept of second dimension (T2) to zero
beta.fixed &lt;- cbind( 1, 2, 0 )
mod13a &lt;- TAM::tam.mml( resp=data.long[,-1], Q=Q, A=A1, beta.fixed=beta.fixed)
summary(mod13a)

#--- tamaan specification
tammodel &lt;- "
  LAVAAN MODEL:
    T1=~ 1*I1T1__I6T1
    T2=~ 1*I3T2__I8T2
    T1 ~~ T1
    T2 ~~ T2
    T1 ~~ T2
    # constraint on item difficulties
    I3T1 + I3T2 | b3*t1
    I4T1 + I4T2 | b4*t1
    I5T1 + I5T2 | b5*t1
    I6T1 + I6T2 | b6*t1
    "
# The constraint on item difficulties can be more efficiently written as
  ##       DO(3,6,1)
  ##         I%T1 + I%T2 | b%*t1
  ##       DOEND
# estimate model
mod13at &lt;- TAM::tamaan( tammodel, resp=data.long,  beta.fixed=beta.fixed )
summary(mod13at)

#***
# Model 13b: invariant item difficulties with zero mean item difficulty
#           of anchor items

A &lt;- TAM::designMatrices(resp=data.long[,-1])$A
dimnames(A)[[1]] &lt;- colnames(data.long)[-1]
A1 &lt;- A[,, c(1:5, 11:12 ) ]
dimnames(A1)[[3]] &lt;- substring( dimnames(A1)[[3]],1,2)
A1[7,2,3] &lt;- -1     # difficulty(I3T1)=difficulty(I3T2)
A1[8,2,4] &lt;- -1     # I4T1=I4T2
A1[9,2,5] &lt;- -1
A1[6,2,3] &lt;- A1[6,2,4] &lt;- A1[6,2,5] &lt;- 1     # I6T1=-(I3T1+I4T1+I5T1)
A1[10,2,3] &lt;- A1[10,2,4] &lt;- A1[10,2,5] &lt;- 1  # I6T2=-(I3T2+I4T2+I5T2)
A1[,2,]
  ##      I1 I2 I3 I4 I5 I7 I8
  ## I1T1 -1  0  0  0  0  0  0
  ## I2T1  0 -1  0  0  0  0  0
  ## I3T1  0  0 -1  0  0  0  0
  ## I4T1  0  0  0 -1  0  0  0
  ## I5T1  0  0  0  0 -1  0  0
  ## I6T1  0  0  1  1  1  0  0
  ## I3T2  0  0 -1  0  0  0  0
  ## I4T2  0  0  0 -1  0  0  0
  ## I5T2  0  0  0  0 -1  0  0
  ## I6T2  0  0  1  1  1  0  0
  ## I7T2  0  0  0  0  0 -1  0
  ## I8T2  0  0  0  0  0  0 -1

mod13b &lt;- TAM::tam.mml( resp=data.long[,-1], Q=Q, A=A1, beta.fixed=FALSE)
summary(mod13b)

#***
# Model 13c: longitudinal polytomous data
#

# modifiy Items I1T1, I4T1, I4T2 in order to be trichotomous (codes: 0,1,2)
set.seed(42)
dat &lt;- data.long
dat[(1:50),2] &lt;- sample(c(0,1,2), 50, replace=TRUE)
dat[(1:50),5] &lt;- sample(c(0,1,2), 50, replace=TRUE)
dat[(1:50),9] &lt;- sample(c(0,1,2), 50, replace=TRUE)
  ##   &gt; colnames(dat)
  ##    [1] "idstud" "I1T1"   "I2T1"   "I3T1"   "I4T1"   "I5T1"   "I6T1"
  ##    [8] "I3T2"   "I4T2"   "I5T2"   "I6T2"   "I7T2"   "I8T2"

## item 1 to 6 administered at T1, items 3 to 8 at T2
## items 3 to 6 are anchor items

# (1) define matrix loadings
Q &lt;- matrix(0,12,2)
colnames(Q) &lt;- c("T1","T2")
Q[1:6,1] &lt;- 1       # items at T1
Q[7:12,2] &lt;- 1      # items at T2

# (2) assume equal item difficulty of anchor items
#     create draft design matrix and modify it
A &lt;- TAM::designMatrices(resp=dat[,-1])$A
dimnames(A)[[1]] &lt;- colnames(dat)[-1]
  ## &gt; str(A)
  ## num [1:12, 1:3, 1:15] 0 0 0 0 0 0 0 0 0 0 ...
  ## - attr(*, "dimnames")=List of 3
  ## ..$ : chr [1:12] "I1T1" "I2T1" "I3T1" "I4T1" ...
  ## ..$ : chr [1:3] "Category0" "Category1" "Category2"
  ## ..$ : chr [1:15] "I1T1_Cat1" "I1T1_Cat2" "I2T1_Cat1" "I3T1_Cat1" ...

# define matrix A
# Items 1 to 3 administered at T1, Items 3 to 6 are anchor items
# Item 7 to 8 administered at T2
# Item I1T1, I4T1, I4T2 are trichotomous (codes: 0,1,2)
A1 &lt;- A[,, c(1:8, 14:15) ]
dimnames(A1)[[3]] &lt;- gsub("T1|T2", "",  dimnames(A1)[[3]])

# Modifications are shortened compared to Model 13 a, but are still valid
A1[7,,] &lt;- A1[3,,]  # item 7, i.e. I3T2, loads on same parameters as
                    # item 3, I3T1
A1[8,,] &lt;- A1[4,,]  # same for item 8 and item 4
A1[9,,] &lt;- A1[5,,]  # same for item 9 and item 5
A1[10,,] &lt;- A1[6,,] # same for item 10 and item 6
  ## &gt; A1[8,,]
  ##           I1_Cat1 I1_Cat2 I2_Cat1 I3_Cat1 I4_Cat1 I4_Cat2 I5_Cat1 ...
  ## Category0       0       0       0       0       0       0       0
  ## Category1       0       0       0       0      -1       0       0
  ## Category2       0       0       0       0      -1      -1       0

# (3) estimate model
#     set intercept of second dimension (T2) to zero
beta.fixed &lt;- cbind( 1, 2, 0 )
mod13c &lt;- TAM::tam.mml( resp=dat[,-1], Q=Q, A=A1, beta.fixed=beta.fixed,
                   irtmodel="PCM")
summary(mod13c)
wle.mod13c &lt;- TAM::tam.wle(mod13c) # WLEs of dimension T1 and T2

#############################################################################
# EXAMPLE 14: Facet model with latent regression
#############################################################################
data( data.ex14 )
dat &lt;- data.ex14

#***
# Model 14a: facet model
resp &lt;- dat[, paste0("crit",1:7,sep="") ]    # item data
facets &lt;- data.frame( "rater"=dat$rater )     # define facets
formulaA &lt;- ~item+item*step + rater
mod14a &lt;- TAM::tam.mml.mfr( resp, facets=facets, formulaA=formulaA, pid=dat$pid )
summary(mod14a)

#***
# Model 14b: facet model with latent regression
#   Note that dataY must correspond to rows in resp and facets which means
#   that there must be the same rows in Y for a person with multiple rows
#   in resp
dataY &lt;- dat[, c("X1","X2") ]        # latent regressors
formulaY &lt;- ~ X1+X2            # latent regression formula
mod14b &lt;- TAM::tam.mml.mfr( resp, facets=facets, formulaA=formulaA,
            dataY=dataY, formulaY=formulaY, pid=dat$pid)
summary(mod14b)

#***
# Model 14c: Multi-facet model with item slope estimation
# use design matrix and modified response data from Model 1
# item-specific slopes

resp1 &lt;- mod14a$resp      # extract response data with generalized items
A &lt;- mod14a$A             # extract design matrix for item intercepts
colnames(resp1)

# define design matrix for slopes
E &lt;- matrix( 0, nrow=ncol(resp1), ncol=7 )
colnames(E) &lt;- paste0("crit",1:7)
rownames(E) &lt;- colnames(resp1)
E[ cbind( 1:(7*7), rep(1:7,each=7) ) ] &lt;- 1

mod14c &lt;- TAM::tam.mml.2pl( resp=resp1, A=A, irtmodel="GPCM.design", E=E,
        control=list(maxiter=100) )
summary(mod14c)

#############################################################################
# EXAMPLE 15: Coping with nonconvergent models
#############################################################################

data(data.ex15)
data &lt;- data.ex15
# facet model 'group*item' is of interest

#***
# Model 15a:
mod15a &lt;- TAM::tam.mml.mfr(resp=data[,-c(1:2)],facets=data[,"group",drop=FALSE],
    formulaA=~ item + group*item, pid=data$pid )
# See output:
  ##
  ##   Iteration 47     2013-09-10 16:51:39
  ##   E Step
  ##   M Step Intercepts   |----
  ##     Deviance=75510.2868 | Deviance change: -595.0609
  ##   !!! Deviance increases!                                        !!!!
  ##   !!! Choose maybe fac.oldxsi &gt; 0 and/or increment.factor &gt; 1    !!!!
  ##     Maximum intercept parameter change: 0.925045
  ##     Maximum regression parameter change: 0
  ##     Variance:  0.9796  | Maximum change: 0.009226

#***
# Model 15b: Follow the suggestions of changing the default of fac.oldxsi and
#            increment.factor
mod15b &lt;- TAM::tam.mml.mfr(resp=data[,-c(1:2)],facets=data[,"group",drop=FALSE],
            formulaA=~ group*item, pid=data$pid,
            control=list( increment.factor=1.03, fac.oldxsi=.4 ) )

#***
# Model 15c: Alternatively, just choose more iterations in M-step by "Msteps=10"
mod15c &lt;- TAM::tam.mml.mfr(resp=data[,-c(1:2)],facets=data[,"group",drop=FALSE],
    formulaA=~ item + group*item, pid=data$pid,
    control=list(maxiter=250, Msteps=10))

#############################################################################
# EXAMPLE 16: Differential item function for polytomous items and
#             differing number of response options per item
#############################################################################

data(data.timssAusTwn.scored)
dat &lt;- data.timssAusTwn.scored
# extract item response data
resp &lt;- dat[, sort(grep("M", colnames(data.timssAusTwn.scored), value=TRUE)) ]
# some descriptives
psych::describe(resp)
# define facets: 'cnt' is group identifier
facets &lt;- data.frame( "cnt"=dat$IDCNTRY)
# create design matrices
des2 &lt;- TAM::designMatrices.mfr2( resp=resp, facets=facets,
                   formulaA=~item*step + item*cnt)
# restructured data set: pseudoitem=item x country
resp2 &lt;- des2$gresp$gresp.noStep
# A design matrix
A &lt;- des2$A$A.3d
    # redundant xsi parameters must be eliminated from design matrix
xsi.elim &lt;- des2$xsi.elim
A &lt;- A[,, - xsi.elim[,2] ]
# extract loading matrix B
B &lt;- des2$B$B.3d
# estimate model
mod1 &lt;- TAM::tam.mml( resp=resp2, A=A, B=B, control=list(maxiter=100) )
summary(mod1)
# The sum of all DIF parameters is set to zero. The DIF parameter for the last
# item is therefore obtained
xsi1 &lt;- mod1$xsi
difxsi &lt;- xsi1[ intersect( grep("cnt",rownames(xsi1)),
              grep("M03",rownames(xsi1))), ]   - colSums(difxsi)
    # this is the DIF effect of the remaining item

#############################################################################
# EXAMPLE 17: Several multidimensional and subdimension models
#############################################################################

library(mirt)
#*** (1) simulate data in mirt package
set.seed(9897)
# simulate data according to the four-dimensional Rasch model
# variances
variances &lt;- c( 1.45, 1.74, .86, 1.48  )
# correlations
corrs &lt;- matrix( 1, 4, 4 )
dd1 &lt;- 1 ; dd2 &lt;- 2 ; corrs[dd1,dd2] &lt;- corrs[dd2,dd1] &lt;- .88
dd1 &lt;- 1 ; dd2 &lt;- 3 ; corrs[dd1,dd2] &lt;- corrs[dd2,dd1] &lt;- .85
dd1 &lt;- 1 ; dd2 &lt;- 4 ; corrs[dd1,dd2] &lt;- corrs[dd2,dd1] &lt;- .87
dd1 &lt;- 2 ; dd2 &lt;- 3 ; corrs[dd1,dd2] &lt;- corrs[dd2,dd1] &lt;- .84
dd1 &lt;- 2 ; dd2 &lt;- 4 ; corrs[dd1,dd2] &lt;- corrs[dd2,dd1] &lt;- .90
dd1 &lt;- 3 ; dd2 &lt;- 4 ; corrs[dd1,dd2] &lt;- corrs[dd2,dd1] &lt;- .90
# covariance matrix
covar &lt;- outer( sqrt( variances), sqrt(variances) )*corrs
# item thresholds and item discriminations
d &lt;- matrix( stats::runif(40, -2, 2 ), ncol=1 )
a &lt;- matrix(NA, nrow=40,ncol=4)
a[1:10,1] &lt;- a[11:20,2] &lt;- a[21:30,3] &lt;- a[31:40,4] &lt;- 1
# simulate data
dat &lt;- mirt::simdata(a=a, d=d, N=1000, itemtype="dich", sigma=covar )
# define Q-matrix for testlet and subdimension models estimated below
Q &lt;- matrix( 0, nrow=40, ncol=5 )
colnames(Q) &lt;- c("g", paste0( "subd", 1:4) )
Q[,1] &lt;- 1
Q[1:10,2] &lt;- Q[11:20,3] &lt;- Q[21:30,4] &lt;- Q[31:40,5] &lt;- 1

# define maximum number of iterations and number of quasi monte carlo nodes
# maxit &lt;- 5  ; snodes &lt;- 300    # this specification is only for speed reasons
maxit &lt;- 200 ; snodes &lt;- 1500

#*****************
# Model 1: Rasch testlet model
#*****************

# define a user function for restricting the variance according to the
# Rasch testlet model
variance.fct1 &lt;- function( variance ){
            ndim &lt;- ncol(variance)
            variance.new &lt;- matrix( 0, ndim, ndim )
            diag(variance.new) &lt;- diag(variance)
            variance &lt;- variance.new
            return(variance)
                    }
variance.Npars &lt;- 5    # number of estimated parameters in variance matrix
# estimation using tam.mml
mod1 &lt;- TAM::tam.mml( dat, Q=Q, userfct.variance=variance.fct1,
             variance.Npars=variance.Npars, control=list(maxiter=maxit, QMC=TRUE,
                          snodes=snodes))
summary(mod1)

#*****************
# Model 2: Testlet model with correlated testlet effects
#*****************

# specify a testlet model with general factor g and testlet effects
# u_1,u_2,u_3 and u_4. Assume that Cov(g,u_t)=0 for all t=1,2,3,4.
# Additionally, assume that \sum_t,t' Cov( u_t, u_t')=0, i.e.
# the sum of all testlet covariances is equal to zero
#=&gt; testlet effects are uncorrelated on average.

# set Cov(g,u_t)=0 and sum of all testlet covariances equals to zero
variance.fct2 &lt;- function( variance ){
            ndim &lt;- ncol(variance)
            variance.new &lt;- matrix( 0, ndim, ndim )
            diag(variance.new) &lt;- diag(variance)
            variance.new[1,2:ndim] &lt;- variance.new[2:ndim,1] &lt;- 0
            # calculate average covariance between testlets
            v1 &lt;- variance[ -1, -1] - variance.new[-1,-1]
            M1 &lt;- sum(v1) / ( ( ndim-1)^2 - ( ndim - 1))
            v1 &lt;- v1 - M1
            variance.new[ -1, -1 ] &lt;- v1
            diag(variance.new) &lt;- diag(variance)
            variance &lt;- variance.new
            return(variance)
                    }
variance.Npars &lt;- 1 + 4 + (4*3)/2 - 1
# estimate model in TAM
mod2 &lt;- TAM::tam.mml( dat, Q=Q, userfct.variance=variance.fct2,
                variance.Npars=variance.Npars,
                control=list(maxiter=maxit, QMC=TRUE, snodes=snodes) )
summary(mod2)

#*****************
# Model 3: Testlet model with correlated testlet effects (different identification)
#*****************

# Testlet model like in Model 2. But now the constraint is
# \sum _t,t' Cov(u_t, u_t') + \sum_t Var(u_t)=0, i.e.
# the sum of all testlet covariances and variances is equal to zero.
variance.fct3 &lt;- function( variance ){
            ndim &lt;- ncol(variance)
            variance.new &lt;- matrix( 0, ndim, ndim )
            diag(variance.new) &lt;- diag(variance)
            variance.new[1,2:ndim] &lt;- variance.new[2:ndim,1] &lt;- 0
            # calculate average covariance and variance between testlets
            v1 &lt;- variance[ -1, -1]
            M1 &lt;- mean(v1)
            v1 &lt;- v1 - M1
            variance.new[ -1, -1 ] &lt;- v1
            # ensure positive definiteness of covariance matrix
            eps &lt;- 10^(-2)
            diag(variance.new) &lt;- diag( variance.new) + eps
            variance.new &lt;- psych::cor.smooth( variance.new )  # smoothing in psych
            variance &lt;- variance.new
            return(variance)
                    }
variance.Npars &lt;- 1 + 4 + (4*3)/2 - 1
# estimate model in TAM
mod3 &lt;- TAM::tam.mml( dat, Q=Q, userfct.variance=variance.fct3,
                variance.Npars=variance.Npars,
                control=list(maxiter=maxit, QMC=TRUE, snodes=snodes) )
summary(mod3)

#*****************
# Model 4: Rasch subdimension model
#*****************

# The Rasch subdimension model is specified according to Brandt (2008).
# The fourth testlet effect is defined as u4=- (u1+u2+u3)
# specify an alternative Q-matrix with 4 dimensions
Q2 &lt;- Q[,-5]
Q2[31:40,2:4] &lt;- -1

# set Cov(g,u1)=Cov(g,u2)=Cov(g,u3)=0
variance.fixed &lt;- rbind( c(1,2,0), c(1,3,0), c(1,4,0) )
# estimate model in TAM
mod4 &lt;- TAM::tam.mml( dat, Q=Q2,variance.fixed=variance.fixed,
                control=list(maxiter=maxit, QMC=TRUE, snodes=snodes) )
summary(mod4)

#*****************
# Model 5: Higher-order model
#*****************

# A four-dimensional model with a higher-order factor is specified.
# F_t=a_t g + eps_g
Q3 &lt;- Q[,-1]
# define fitting function using the lavaan package and ULS estimation
N0 &lt;- nrow(dat)         # sample size of dataset
library(lavaan)        # requires lavaan package for fitting covariance
variance.fct5 &lt;- function( variance ){
    ndim &lt;- ncol(variance)
    rownames(variance) &lt;- colnames(variance) &lt;- paste0("F",1:ndim)
    lavmodel &lt;- paste0(
        "FHO=~", paste0( paste0( "F", 1:ndim ), collapse="+" ) )
    lavres &lt;- lavaan::cfa( model=lavmodel, sample.cov=variance, estimator="ULS",
                       std.lv=TRUE, sample.nobs=N0)
    variance.new &lt;- fitted(lavres)$cov
    variance &lt;- variance.new
    # print coefficients
    cat( paste0( "\n **** Higher order loadings: ",
            paste0( paste0( round( coef(lavres)[ 1:ndim ], 3 )), collapse=" ")
                        ), "\n")
    return(variance)
                    }
variance.Npars &lt;- 4+4
# estimate model in TAM
mod5 &lt;- TAM::tam.mml( dat, Q=Q3, userfct.variance=variance.fct5,
                variance.Npars=variance.Npars,
                control=list(maxiter=maxit, QMC=TRUE, snodes=snodes) )
summary(mod5)

#*****************
# Model 6: Generalized Rasch subdimension model (Brandt, 2012)
#*****************

Q2 &lt;- Q[,-5]
Q2[31:40,2:4] &lt;- -1
# fixed covariances
variance.fixed2 &lt;- rbind( c(1,2,0), c(1,3,0), c(1,4,0)  )
# design matrix for item loading parameters
#      items x category x dimension x xsi parameter
E &lt;- array( 0, dim=c( 40, 2, 4, 4 ) )
E[ 1:10, 2, c(1,2), 1 ] &lt;- 1
E[ 11:20, 2, c(1,3), 2 ] &lt;- 1
E[ 21:30, 2, c(1,4), 3 ] &lt;- 1
E[ 31:40, 2, 1, 4 ] &lt;- 1
E[ 31:40, 2, 2:4, 4 ] &lt;- -1

# constraint on slope parameters, see Brandt (2012)
gammaconstr &lt;- function( gammaslope ){
        K &lt;- length( gammaslope)
        g1 &lt;- sum( gammaslope^2  )
        gammaslope.new &lt;- sqrt(K) / sqrt(g1) * gammaslope
        return(gammaslope.new)
                    }
# estimate model
mod6 &lt;- TAM::tam.mml.3pl( dat, E=E, Q=Q2, variance.fixed=variance.fixed2,
           skillspace="normal", userfct.gammaslope=gammaconstr, gammaslope.constr.Npars=1,
           control=list(maxiter=maxit, QMC=TRUE, snodes=snodes ) )
summary(mod6)

#############################################################################
# EXAMPLE 18: Partial credit model with dimension-specific sum constraints
#             on item difficulties
#############################################################################

data(data.Students, package="CDM")
dat &lt;- data.Students[, c( paste0("sc",1:4), paste0("mj",1:4) ) ]
# specify dimensions in Q-matrix
Q &lt;- matrix( 0,  nrow=8, ncol=2 )
Q[1:4,1] &lt;- Q[5:8,2] &lt;- 1
# partial credit model with some constraint on item parameters
mod1 &lt;- TAM::tam.mml( dat, Q=Q, irtmodel="PCM2", constraint="items")
summary(mod1)

#############################################################################
# EXAMPLE 19: Partial credit scoring: 0.5 points for partial credit items
#             and 1 point for dichotomous items
#############################################################################

data(data.timssAusTwn.scored)
dat &lt;- data.timssAusTwn.scored
# extrcat item response data
dat &lt;- dat[, grep("M03", colnames(dat) ) ]

# select items with do have maximum score of 2 (polytomous items)
ind &lt;- which( apply( dat,  2, max, na.rm=TRUE )==2 )
I &lt;- ncol(dat)
# define Q-matrix with scoring variant
Q &lt;- matrix( 1, nrow=I, ncol=1 )
Q[ ind, 1 ] &lt;- .5    # score of 0.5 for polyomous items

# estimate model
mod1 &lt;- TAM::tam.mml( dat, Q=Q, irtmodel="PCM2", control=list(nodes=seq(-10,10,len=21)))
summary(mod1)

#############################################################################
# EXAMPLE 20: Specification of loading matrix in multidimensional model
#############################################################################

data(data.gpcm)
psych::describe(data.gpcm)
resp &lt;- data.gpcm

# define three dimensions and different loadings of item categories
# on these dimensions in B loading matrix
I &lt;- 3  # 3 items
D &lt;- 3  # 3 dimensions
# define loading matrix B
# 4 categories for each item (0,1,2,3)
B &lt;- array( 0, dim=c(I,4,D) )
for (ii in 1:I){
    B[ ii, 1:4, 1 ] &lt;- 0:3
    B[ ii, 1,2 ] &lt;- 1
    B[ ii, 4,3 ] &lt;- 1
            }
dimnames(B)[[1]] &lt;- colnames(resp)
B[1,,]
  ##   &gt; B[1,,]
  ##        [,1] [,2] [,3]
  ##   [1,]    0    1    0
  ##   [2,]    1    0    0
  ##   [3,]    2    0    0
  ##   [4,]    3    0    1
#-- test run
mod1 &lt;- TAM::tam.mml( resp, B=B, control=list( snodes=1000, maxiter=5)  )
summary(mod1)

# Same model with TAM::tam.mml.3pl instead

dim4 &lt;- sum(apply(B, c(1, 3), function(x) any(!(x==0))))
E1 &lt;- array(0, dim=c(dim(B), dim4))

kkk &lt;- 0
for (iii in seq_len(dim(E1)[1])) {
    for (jjj in seq_len(dim(E1)[3])) {
        if (any(B[iii,, jjj] !=0)) {
            kkk &lt;- kkk + 1
            E1[iii,, jjj, kkk] &lt;- B[iii,, jjj]
        }
    }
}
if (kkk !=dim4) stop("Something went wrong in the loop, because 'kkk !=dim4'.")

mod2 &lt;- TAM::tam.mml.3pl(resp, E=E1, est.some.slopes=FALSE, control=list(maxiter=50))
summary(mod2)

cor(mod1$person$EAP.Dim3, mod2$person$EAP.Dim3)
cor(mod1$person$EAP.Dim2, mod2$person$EAP.Dim2)
cor(mod1$person$EAP.Dim1, mod2$person$EAP.Dim1)
cor(mod1$xsi$xsi, mod2$xsi$xsi)

#############################################################################
# EXAMPLE 21: Acceleration of EM algorithm | dichotomous data
#############################################################################

N &lt;- 1000      # number of persons
I &lt;- 100       # number of items
set.seed(987)
# simulate data according to the Rasch model
dat &lt;- sirt::sim.raschtype( stats::rnorm(N), b=seq(-2,2,len=I)  )
# estimate models
mod1n &lt;- TAM::tam.mml( resp=dat, control=list( acceleration="none") )  # no acceler.
mod1y &lt;- TAM::tam.mml( resp=dat, control=list( acceleration="Yu") )  # Yu acceler.
mod1r &lt;- TAM::tam.mml( resp=dat, control=list( acceleration="Ramsay") )  # Ramsay acceler.
# compare number of iterations
mod1n$iter ; mod1y$iter ; mod1r$iter
# log-likelihood values
logLik(mod1n); logLik(mod1y) ; logLik(mod1r)

#############################################################################
# EXAMPLE 22: Acceleration of EM algorithm | polytomous data
#############################################################################

data(data.gpcm)
dat &lt;- data.gpcm

# no acceleration
mod1n &lt;- TAM::tam.mml.2pl( resp=dat, irtmodel="GPCM",
                control=list( conv=1E-4, acceleration="none") )
# Yu acceleration
mod1y &lt;- TAM::tam.mml.2pl( resp=dat, irtmodel="GPCM",
                control=list( conv=1E-4, acceleration="Yu") )
# Ramsay acceleration
mod1r &lt;- TAM::tam.mml.2pl( resp=dat, irtmodel="GPCM",
                control=list( conv=1E-4, acceleration="Ramsay") )
# number of iterations
mod1n$iter ; mod1y$iter ; mod1r$iter

#############################################################################
# EXAMPLE 23: Multidimensional polytomous Rasch model in which
#             dimensions are defined by categories
#############################################################################

data(data.Students, package="CDM")
dat &lt;- data.Students[, grep( "act", colnames(data.Students) ) ]

# define multidimensional model in which categories of item define dimensions

# * Category 0 -&gt; loading of one on Dimension 0
# * Category 1 -&gt; no loadings
# * Category 2 -&gt; loading of one on Dimension 2

# extract default design matrices
res &lt;- TAM::designMatrices( resp=dat )
A &lt;- res$A
B0 &lt;- 0*res$B
# create design matrix B
B &lt;- array( 0, dim=c( dim(B0)[c(1,2) ], 2  ) )
dimnames(B)[[1]] &lt;- dimnames(B0)[[1]]
dimnames(B)[[2]] &lt;- dimnames(B0)[[2]]
dimnames(B)[[3]] &lt;- c( "Dim0", "Dim2" )
B[,1,1]  &lt;- 1
B[,3,2]  &lt;- 1

# estimate multdimensional Rasch model
mod1 &lt;- TAM::tam.mml( resp=dat, A=A, B=B, control=list( maxiter=100) )
summary(mod1)

# alternative definition of B
# * Category 1: negative loading on Dimension 1 and Dimension 2
B &lt;- array( 0, dim=c( dim(B0)[c(1,2) ], 2  ) )
dimnames(B)[[1]] &lt;- dimnames(B0)[[1]]
dimnames(B)[[2]] &lt;- dimnames(B0)[[2]]
dimnames(B)[[3]] &lt;- c( "Dim0", "Dim2" )
B[,1, 1]  &lt;- 1
B[,3, 2]  &lt;- 1
B[,2, c(1,2)]  &lt;- -1

# estimate model
mod2 &lt;- TAM::tam.mml( resp=dat, A=A, B=B, control=list( maxiter=100) )
summary(mod2)

#############################################################################
# EXAMPLE 24: Sum constraint on item-category parameters in partial credit model
#############################################################################

data(data.gpcm,package="TAM")
dat &lt;- data.gpcm

# check number of categories
c1 &lt;- TAM::tam.ctt3(dat)

#--- fit with PCM
mod1 &lt;- TAM::tam.mml( dat )
summary(mod1, file="mod1")

#--- fit with constraint on sum of categories
#** redefine design matrix
A1 &lt;- 0*mod1$A
A1 &lt;- A1[,, - dim(A1)[[3]]]
str(A1)
NP &lt;- dim(A1)[[3]]
# define item category parameters
A1[1,2,1] &lt;- A1[1,3,2] &lt;- A1[1,4,3] &lt;- -1
A1[2,2,4] &lt;- A1[2,3,5] &lt;- A1[2,4,6] &lt;- -1
A1[3,2,7] &lt;- A1[3,3,8] &lt;- -1
A1[3,4,1:8] &lt;- 1
# check definition
A1[1,,]
A1[2,,]
A1[3,,]

#** estimate model
mod2 &lt;- TAM::tam.mml( dat, A=A1, beta.fixed=FALSE)
summary(mod2, file="mod2")

#--- compare model fit
IRT.compareModels(mod1, mod2 )  # -&gt; equivalent model fit

#############################################################################
# EXAMPLE 25: Different GPCM parametrizations in IRT packages
#############################################################################

library(TAM)
library(mirt)
library(ltm)

data(data.gpcm, package="TAM")
dat &lt;- data.gpcm

#*** TAM
mod1 &lt;- TAM::tam.mml.2pl(dat, irtmodel="GPCM")
#*** mirt
mod2 &lt;- mirt::mirt(dat, 1, itemtype="gpcm", verbose=TRUE)
#*** ltm
mod3 &lt;- ltm::gpcm( dat, control=list(verbose=TRUE) )
mod3b &lt;- ltm::gpcm( dat, control=list(verbose=TRUE), IRT.param=FALSE)

#-- comparison log likelihood
logLik(mod1)
logLik(mod2)
logLik(mod3)
logLik(mod3b)

#*** intercept parametrization (like in TAM)

# TAM
mod1$B[,2,1]   # slope
mod1$AXsi      # intercepts
# mirt
coef(mod2)
# ltm
coef(mod3b, IRT.param=FALSE)[, c(4,1:3)]

#*** IRT parametrization

# TAM
mod1$AXsi / mod1$B[,2,1]
# mirt
coef(mod2, IRTpars=TRUE)
# ltm
coef(mod3)[, c(4,1:3)]

#############################################################################
# EXAMPLE 26: Differential item functioning in multdimensional models
#############################################################################

data(data.ex08, package="TAM")
formulaA &lt;- ~ item+female+item*female
resp &lt;- data.ex08[["resp"]]
facets &lt;- as.data.frame(data.ex08[["facets"]])

#***  Model 8a: investigate gender DIF in undimensional model
mod8a &lt;- TAM::tam.mml.mfr(resp=resp, facets=facets, formulaA=formulaA)
summary(mod8a)

#*** multidimensional 2PL Model
I &lt;- 10
Q &lt;- array(0, dim=c(I, 3))
Q[cbind(1:I, c(rep(1, 3), rep(2, 3), rep(3, 4)))] &lt;- 1
rownames(Q) &lt;- colnames(resp)
mod3dim2pl &lt;- TAM::tam.mml.2pl(resp=resp, Q=Q, irtmodel="2PL",
                          control=list(snodes=2000))

#*** Combine both approaches
thisRows &lt;- gsub("-.*", "", colnames(mod8a$resp)) #select item names

#*** uniform DIF (note irtmodel="2PL.groups" &amp; est.slopegroups)
mod3dim2pl_udiff &lt;- TAM::tam.mml.2pl(resp=mod8a$resp, A=mod8a$A, Q=Q[thisRows, ],
                               irtmodel="2PL.groups",
                               est.slopegroups=as.numeric(as.factor(thisRows)),
                               control=list(snodes=2000))

#*** non-uniform DIF (?); different slope parameters for each item administered to each group
mod3dim2pl_nudiff &lt;- TAM::tam.mml.2pl(resp=mod8a$resp, A=mod8a$A, Q=Q[thisRows, ],
                                irtmodel="2PL", control=list(snodes=2000))

#*** check results
print(mod8a$xsi)
print(mod3dim2pl_udiff$xsi)
summary(mod3dim2pl_nudiff)

#*** within item dimensionality (one item loads on two dimensions)
Q2 &lt;- Q
Q2[4,1] &lt;- 1

# uniform DIF (note irtmodel="2PL.groups" &amp; est.slopegroups)
mod3dim2pl_udiff2 &lt;- TAM::tam.mml.2pl(resp=mod8a$resp, A=mod8a$A, Q=Q2[thisRows, ],
                                irtmodel="2PL.groups",
                                est.slopegroups=as.numeric(as.factor(thisRows)),
                                control=list(snodes=2000))
print(mod8a$xsi)
print(mod3dim2pl_udiff2$xsi)
print(mod3dim2pl_udiff2$xsi)

#############################################################################
# EXAMPLE 27: IRT parameterization for generalized partial credit model (GPCM) in TAM
#############################################################################

#--- read item parameters
pars &lt;- as.numeric(miceadds::scan.vec(
"0.19029 1.25309 0.51737 -1.77046 0.94803
  0.19407 1.22680 0.34986 -1.57666 1.29726
  -0.00888 1.07093 0.31662 -1.38755 1.14809
  -0.33810 1.08205 0.48490 -1.56696 0.79547
  -0.18866 0.99587 0.37880 -1.37468 0.81114" ))
pars &lt;- matrix( pars, nrow=5, byrow=TRUE)
beta &lt;- pars[,1]
alpha &lt;- pars[,5]
tau &lt;- pars[,2:4]

#--- data simulation function for GPCM
sim_gpcm_irt_param &lt;- function(alpha, beta, tau, N, mu=0, sigma=1)
{
    theta &lt;- stats::rnorm(N, mean=mu, sd=sigma)
    I &lt;- length(beta)
    K &lt;- ncol(tau)
    dat &lt;- matrix(0, nrow=N, ncol=I)
    colnames(dat) &lt;- paste0("I",1:I)
    for (ii in 1:I){
        probs &lt;- matrix(0, nrow=N, ncol=K+1)
        for (kk in 1:K){
            probs[,kk+1] &lt;- probs[,kk] + alpha[ii]*( theta - beta[ii] - tau[ii,kk] )
        }
        probs &lt;- exp(probs)
        probs &lt;- probs/rowSums(probs)
        rn &lt;- stats::runif(N)
        cumprobs &lt;- t(apply(probs,1,cumsum))
        for (kk in 1:K){
            dat[,ii] &lt;- dat[,ii] + ( rn &gt; cumprobs[,kk] )
        }
    }
    return(dat)
}

#-- simulate data
N &lt;- 20000     # number of persons
set.seed(98)
dat1 &lt;- sim_gpcm_irt_param(alpha=alpha, beta=beta, tau=tau, N=N, mu=0, sigma=1)
head(dat1)

#* generate design matrix for IRT parameterization
A1 &lt;- TAM::.A.PCM2( resp=dat1)

#- estimate GPCM model
mod1 &lt;- TAM::tam.mml.2pl( resp=dat1, irtmodel="GPCM", A=A1)
summary(mod1)

# compare true and estimated slope estimates (alpha)
cbind( alpha, mod1$B[,2,] )

# compare true and estimated item difficulties (beta)
cbind( beta, mod1$xsi$xsi[1:5] / mod1$B[,2,1] )

# compare true and estimated tau parameters
cbind( tau[,-3], matrix( mod1$xsi$xsi[-c(1:5)], nrow=5, byrow=TRUE ) / mod1$B[,2,1] )

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.mml.3pl'>
3PL Structured Item Response Model in <span class="pkg">TAM</span>
</h2><span id='topic+tam.mml.3pl'></span><span id='topic+summary.tam.mml.3pl'></span><span id='topic+print.tam.mml.3pl'></span>

<h3>Description</h3>

<p>This estimates a 3PL model with design matrices for item slopes and
item intercepts. Discrete distributions of the latent variables are
allowed which can be log-linearly smoothed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.mml.3pl(resp, Y=NULL, group=NULL, formulaY=NULL, dataY=NULL, ndim=1,
  pid=NULL, xsi.fixed=NULL, xsi.inits=NULL, xsi.prior=NULL,
  beta.fixed=NULL, beta.inits=NULL, variance.fixed=NULL, variance.inits=NULL,
  est.variance=TRUE, A=NULL, notA=FALSE, Q=NULL, Q.fixed=NULL, E=NULL,
  gammaslope.des="2PL", gammaslope=NULL, gammaslope.fixed=NULL,
  est.some.slopes=TRUE, gammaslope.max=9.99, gammaslope.constr.V=NULL,
  gammaslope.constr.c=NULL, gammaslope.center.index=NULL,  gammaslope.center.value=NULL,
  gammaslope.prior=NULL, userfct.gammaslope=NULL, gammaslope.constr.Npars=0,
  est.guess=NULL, guess=rep(0, ncol(resp)),
  guess.prior=NULL, max.guess=0.5, skillspace="normal", theta.k=NULL,
  delta.designmatrix=NULL, delta.fixed=NULL, delta.inits=NULL, pweights=NULL,
  item.elim=TRUE, verbose=TRUE, control=list(), Edes=NULL )

## S3 method for class 'tam.mml.3pl'
summary(object,file=NULL,...)

## S3 method for class 'tam.mml.3pl'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.mml.3pl_+3A_resp">resp</code></td>
<td>

<p>Data frame with polytomous item responses <code class="reqn">k=0,...,K</code>.
Missing responses must be declared as <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_y">Y</code></td>
<td>

<p>A matrix of covariates in latent regression. Note that the
intercept is automatically included as the first predictor.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_group">group</code></td>
<td>

<p>An optional vector of group identifiers
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_formulay">formulaY</code></td>
<td>

<p>An <span class="rlang"><b>R</b></span> formula for latent regression. Transformations of predictors
in <code class="reqn">Y</code> (included in <code>dataY</code>) can be easily specified,
e. g. <code>female*race</code> or <code>I(age^2)</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_datay">dataY</code></td>
<td>

<p>An optional data frame with possible covariates <code class="reqn">Y</code> in latent regression.
This data frame will be used if an <span class="rlang"><b>R</b></span> formula in <code>formulaY</code>
is specified.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_ndim">ndim</code></td>
<td>

<p>Number of dimensions (is not needed to determined by the user)
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_pid">pid</code></td>
<td>

<p>An optional vector of person identifiers
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_xsi.fixed">xsi.fixed</code></td>
<td>

<p>A matrix with two columns for fixing <code class="reqn">\xi</code> parameters.
1st column: index of <code class="reqn">\xi</code> parameter, 2nd column: fixed value
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_xsi.inits">xsi.inits</code></td>
<td>

<p>A matrix with two columns (in the same way defined as in
<code>xsi.fixed</code> with initial value for <code class="reqn">\xi</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_xsi.prior">xsi.prior</code></td>
<td>

<p>Item-specific prior distribution for <code class="reqn">\xi</code> parameters. It is
assumed that <code class="reqn">\xi_k \sim N( \mu_k, \sigma_k^2 )</code>. The first column
in <code>xsi.prior</code> is <code class="reqn">\mu_k</code>, the second is <code class="reqn">\sigma_k</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_beta.fixed">beta.fixed</code></td>
<td>

<p>A matrix with three columns for fixing regression coefficients.
1st column: Index of <code class="reqn">Y</code> value, 2nd column: dimension,
3rd column: fixed <code class="reqn">\beta</code> value. <br />
If no constraints should be imposed on <code class="reqn">\beta</code>, then
set <code>beta.fixed=FALSE</code> (see Example 2, Model <code>2_4</code>).
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_beta.inits">beta.inits</code></td>
<td>

<p>A matrix (same format as in <code>beta.fixed</code>)
with initial <code class="reqn">\beta</code> values
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_variance.fixed">variance.fixed</code></td>
<td>

<p>An optional matrix. In case of a single group it is a matrix with three columns for fixing
entries in covariance matrix:
1st column: dimension 1, 2nd column: dimension 2,
3rd column: fixed value of covariance/variance.
In case of multiple groups, it is a matrix with four columns
1st column: group index (from <code class="reqn">1,\ldots,G</code>, 2nd column: dimension 1,
3rd column: dimension 2, 4th column: fixed value of covariance
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_variance.inits">variance.inits</code></td>
<td>

<p>Initial covariance matrix in estimation. All matrix entries have to be
specified and this matrix is NOT in the same format like
<code>variance.fixed</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_est.variance">est.variance</code></td>
<td>

<p>Should the covariance matrix be estimated? This argument
applies to estimated item slopes in <code>tam.mml.2pl</code>.
The default is <code>FALSE</code> which means that latent
variables (in the first group) are standardized in 2PL estimation.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_a">A</code></td>
<td>

<p>An optional array of dimension <code class="reqn"> I \times (K+1) \times N_\xi</code>.
Only <code class="reqn">\xi</code> parameters are estimated, entries in <code class="reqn">A</code>
only correspond to the design.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_nota">notA</code></td>
<td>
<p>An optional logical indicating whether all entries in
the <code class="reqn">A</code> matrix are set to zero and no item intercept
<code class="reqn">\xi</code> should be estimated.</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_q">Q</code></td>
<td>

<p>An optional <code class="reqn">I \times D</code> matrix (the Q-matrix) which specifies the
loading structure of items on dimensions.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_q.fixed">Q.fixed</code></td>
<td>
<p>Optional <code class="reqn">I \times D</code> matrix of the same dimensions
like <code>Q</code>. Non <code>NA</code> entries contain values at which
item loadings should be fixed to.</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_e">E</code></td>
<td>

<p>Optional design array for item slopes <code class="reqn">\gamma</code>. It is a four
dimensional array of size <code class="reqn">I \times (K+1) \times D \times N_\gamma</code>
containing items, categories, dimensions, <code class="reqn">\gamma</code> parameter.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.des">gammaslope.des</code></td>
<td>

<p>Optional string indicating type of item slope parameter to be estimated.
<code>gammaslope.des="2PL"</code> estimates a slope parameter for an item,
<code>gammaslope.des="2PLcat"</code> for an item and a
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope">gammaslope</code></td>
<td>

<p>Initial or fixed vector of <code class="reqn">\gamma</code> parameters
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.fixed">gammaslope.fixed</code></td>
<td>

<p>An optional matrix containing fixed values in the <code class="reqn">\gamma</code> vector.
First column: parameter index; second colunmn: fixed value.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_est.some.slopes">est.some.slopes</code></td>
<td>

<p>An optional logical indicating whether some item slopes should be estimated.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.max">gammaslope.max</code></td>
<td>
<p>Value for absolute entries in <code class="reqn">\gamma</code> vector</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.constr.v">gammaslope.constr.V</code></td>
<td>

<p>An optional constraint matrix <code class="reqn">V</code> for item slope parameters <code class="reqn">\gamma</code>
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.constr.c">gammaslope.constr.c</code></td>
<td>

<p>An optional constraint vector <code class="reqn">c</code> for item slope parameters <code class="reqn">\gamma</code>
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.center.index">gammaslope.center.index</code></td>
<td>

<p>Indices of <code>gammaslope</code> parameters which should be fixed to
sum specified in <code>gammaslope.center.value</code> (see Example 7).
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.center.value">gammaslope.center.value</code></td>
<td>
<p>Specified values of sum of
subset of <code>gammaslope</code> parameters.</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.prior">gammaslope.prior</code></td>
<td>

<p>Item-specific prior distribution for <code class="reqn">\gamma</code> parameters. It is
assumed that <code class="reqn">\gamma_k \sim N( \mu_k, \sigma_k^2 )</code>. The first column
in <code>gammaslope.prior</code> is <code class="reqn">\mu_k</code>, the second is <code class="reqn">\sigma_k</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_userfct.gammaslope">userfct.gammaslope</code></td>
<td>
<p>A user specified function for
constraints or transformations of the <code class="reqn">\gamma</code> parameters
within the algorithm. See Example 17 in <code><a href="#topic+tam.mml">tam.mml</a></code>.</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_gammaslope.constr.npars">gammaslope.constr.Npars</code></td>
<td>
<p>Number of constrained
<code class="reqn">\gamma</code> parameters in <code>userfct.gammaslope</code>
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_est.guess">est.guess</code></td>
<td>

<p>An optional vector of integers indicating for which items a guessing
parameter should be estimated. Same integers correspond to same estimated
guessing parameters. A value of 0 denotes an item for which no guessing
parameter is estimated.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_guess">guess</code></td>
<td>

<p>Fixed or initial guessing parameters
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_guess.prior">guess.prior</code></td>
<td>

<p>Item-specific prior distribution for guessing parameters <code class="reqn">c_i</code>. It is
assumed that <code class="reqn">c_i \sim Beta(a_i, b_i)</code>. The first column
in <code>gammaslope.prior</code> is <code class="reqn">a_i</code>, the second is <code class="reqn">b_i</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_max.guess">max.guess</code></td>
<td>
<p>Upper bound for guessing parameters</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_skillspace">skillspace</code></td>
<td>

<p>Skill space: normal distribution (<code>"normal"</code>) or discrete
distribution (<code>"discrete"</code>).
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_theta.k">theta.k</code></td>
<td>

<p>A matrix of the <code class="reqn">\bold{\theta}</code> skill space in case of a discrete
distribution (<code>skillspace="discrete"</code>).
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_delta.designmatrix">delta.designmatrix</code></td>
<td>

<p>A design matrix of the log-linear model for the skill space in case of a discrete
distribution (<code>skillspace="discrete"</code>).
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_delta.fixed">delta.fixed</code></td>
<td>

<p>Fixed <code class="reqn">\delta</code> values of the log-linear skill space.
<code>delta.fixed</code> must be a matrix with three columns. First column:
<code class="reqn">\delta</code> parameter index, Second column: Group index,
Third column: Fixed <code class="reqn">\delta</code> parameter value.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_delta.inits">delta.inits</code></td>
<td>
<p>Optional initial matrix of <code class="reqn">\delta</code>
parameters.</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_pweights">pweights</code></td>
<td>

<p>Optional vector of person weights.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_item.elim">item.elim</code></td>
<td>
<p>Optional logical indicating whether an item with has
only zero entries should be removed from the analysis. The default
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether output should
be printed during iterations. This argument replaces <code>control$progress</code>.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_control">control</code></td>
<td>

<p>See <code><a href="#topic+tam.mml">tam.mml</a></code> for more details.
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_edes">Edes</code></td>
<td>
<p>Compact form of design matrix. This argument is only
defined for convenience for models with random starting
values to avoid recalculations.</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_object">object</code></td>
<td>

<p>Object of class <code>tam.mml.3pl</code>
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_file">file</code></td>
<td>

<p>A file name in which the summary output will be written
</p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_x">x</code></td>
<td>
<p>Object of class <code>tam.mml.3pl</code></p>
</td></tr>
<tr><td><code id="tam.mml.3pl_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The item response model for item <code class="reqn">i</code> and category <code class="reqn">h</code> and no guessing
parameters can be written as
</p>
<p style="text-align: center;"><code class="reqn"> P( X_{i}=h | \bold{\theta} ) \propto \exp( \sum_d b_{ihd} \theta_d +
 \sum_k a_{ih} \xi_k ) </code>
</p>

<p>For item slopes, a linear decomposition is allowed
</p>
<p style="text-align: center;"><code class="reqn"> b_{ihd}=\sum_k   e_{ihdk} \gamma_k </code>
</p>

<p>In case of a guessing parameter, the item response function is
</p>
<p style="text-align: center;"><code class="reqn"> P( X_{i}=h | \bold{\theta} )=c_i + ( 1 - c_i ) \cdot
    ( 1 + \exp( - \sum_d b_{ihd} \theta_d - \sum_k a_{ih} \xi_k ) )^{-1}
        </code>
</p>

<p>For possibilities of definitions of the design matrix <code class="reqn">E=(e_{ihdk})</code>
see Formann (2007), for the strongly related linear logistic latent
class model see Formann (1992). Linear constraints on <code class="reqn">\gamma</code>
can be specified by equations <code class="reqn">V \gamma=c</code> and using the arguments
<code>gammaslope.constr.V</code> and <code>gammaslope.constr.c</code>.
</p>
<p>Like in <code><a href="#topic+tam.mml">tam.mml</a></code>, a multivariate linear regression
</p>
<p style="text-align: center;"><code class="reqn"> \bold{\theta}=Y \beta + \bold{\epsilon}</code>
</p>

<p>assuming a multivariate normal distribution on the residuals <code class="reqn">\bold{\epsilon}</code>
can be specified (<code>skillspace="normal"</code>).
</p>
<p>Alternatively, a log-linear distribution of the skill classes <code class="reqn">P(\theta)</code>
(<code>skillspace="discrete"</code>)
is performed </p>
<p style="text-align: center;"><code class="reqn">\log P(\theta )=D_{ \delta } \delta </code>
</p>
<p> See Xu and
von Davier (2008). The design matrix <code class="reqn">D_{\delta}</code> can be specified in
<code>delta.designmatrix</code>. The theta grid <code class="reqn">\bold{\theta}</code> of the skill space
can be defined in <code>theta.k</code>.
</p>


<h3>Value</h3>

<p>The same output as in <code><a href="#topic+tam.mml">tam.mml</a></code> and additional entries
</p>
<table>
<tr><td><code>delta</code></td>
<td>
<p>Parameter vector <code class="reqn">\delta</code></p>
</td></tr>
<tr><td><code>gammaslope</code></td>
<td>
<p>Estimated <code class="reqn">\gamma</code> item slope parameters</p>
</td></tr>
<tr><td><code>se.gammaslope</code></td>
<td>
<p>Standard errors <code class="reqn">\gamma</code> item slope parameters</p>
</td></tr>
<tr><td><code>E</code></td>
<td>
<p>Used design matrix <code class="reqn">E</code></p>
</td></tr>
<tr><td><code>Edes</code></td>
<td>
<p>Used design matrix <code class="reqn">E</code> in compact form</p>
</td></tr>
<tr><td><code>guess</code></td>
<td>
<p>Estimated <code class="reqn">c</code> guessing parameters</p>
</td></tr>
<tr><td><code>se.guess</code></td>
<td>
<p>Standard errors <code class="reqn">c</code> guessing parameters</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The implementation of the model builds on pieces work of Anton Formann.
See <a href="http://www.antonformann.at/">http://www.antonformann.at/</a> for more information.
</p>


<h3>References</h3>

<p>Formann, A. K. (1992). Linear logistic latent class analysis for polytomous data.
<em>Journal of the American Statistical Association, 87</em>, 476-486.
<a href="https://doi.org/10.2307/2290280">doi:10.2307/2290280</a>
</p>
<p>Formann, A. K. (2007). (Almost) Equivalence between conditional and mixture maximum
likelihood estimates for some models of the Rasch type. In M. von Davier &amp; C. H. Carstensen
(Eds.), <em>Multivariate and mixture distribution Rasch models</em> (pp. 177-189).
New York: Springer.
<a href="https://doi.org/10.1007/978-0-387-49839-3_11">doi:10.1007/978-0-387-49839-3_11</a>
</p>
<p>Xu, X., &amp; von Davier, M. (2008). <em>Fitting the structured general diagnostic
model to NAEP data</em>. ETS Research Report ETS RR-08-27. Princeton, ETS.
<a href="https://doi.org/10.1002/j.2333-8504.2008.tb02113.x">doi:10.1002/j.2333-8504.2008.tb02113.x</a>
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+tam.mml">tam.mml</a></code>.
</p>
<p>See the <code><a href="CDM.html#topic+slca">CDM::slca</a></code> function in the <span class="pkg">CDM</span> package
for a similar method.
</p>
<p><code><a href="#topic+logLik.tam">logLik.tam</a></code>, <code><a href="#topic+anova.tam">anova.tam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Dichotomous data | data.sim.rasch
#############################################################################

data(data.sim.rasch)
dat &lt;- data.sim.rasch
# some control arguments
ctl.list &lt;- list(maxiter=100) # increase the number of iterations in applications!

#*** Model 1: Rasch model, normal trait distribution
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, skillspace="normal", est.some.slopes=FALSE,
              control=ctl.list)
summary(mod1)

#*** Model 2: Rasch model, discrete trait distribution
#  choose theta grid
theta.k &lt;- seq( -3, 3, len=7 )    # discrete theta grid distribution
# define symmetric trait distribution
delta.designmatrix &lt;- matrix( 0, nrow=7, ncol=4 )
delta.designmatrix[4,1] &lt;- 1
delta.designmatrix[c(3,5),2] &lt;- 1
delta.designmatrix[c(2,6),3] &lt;- 1
delta.designmatrix[c(1,7),4] &lt;- 1
mod2 &lt;- TAM::tam.mml.3pl(resp=dat, skillspace="discrete", est.some.slopes=FALSE,
           theta.k=theta.k, delta.designmatrix=delta.designmatrix, control=ctl.list)
summary(mod2)

#*** Model 3: 2PL model
mod3 &lt;- TAM::tam.mml.3pl(resp=dat, skillspace="normal", gammaslope.des="2PL",
       control=ctl.list, est.variance=FALSE )
summary(mod3)

#*** Model 4: 3PL model
# estimate guessing parameters for items 3,7,9 and 12
I &lt;- ncol(dat)
est.guess &lt;- rep(0, I )
# set parameters 9 and 12 equal -&gt; same integers
est.guess[ c(3,7,9,12) ] &lt;- c( 1, 3, 2, 2 )
# starting values guessing parameter
guess &lt;- .2*(est.guess &gt; 0)
# estimate model
mod4 &lt;- TAM::tam.mml.3pl(resp=dat, skillspace="normal", gammaslope.des="2PL",
        control=ctl.list, est.guess=est.guess, guess=guess, est.variance=FALSE)
summary(mod4)

#--- specification in tamaan
tammodel &lt;- "
LAVAAN MODEL:
  F1=~ I1__I40
  F1 ~~ 1*F1
  I3 + I7 ?=g1
  I9 + I12 ?=g912 * g1
    "
mod4a &lt;- TAM::tamaan( tammodel, resp=dat, control=list(maxiter=20))
summary(mod4a)

#*** Model 5: 3PL model, add some prior Beta distribution
guess.prior &lt;- matrix( 0, nrow=I, ncol=2 )
guess.prior[ est.guess  &gt; 0, 1] &lt;- 5
guess.prior[ est.guess  &gt; 0, 2] &lt;- 17
mod5 &lt;- TAM::tam.mml.3pl(resp=dat, skillspace="normal", gammaslope.des="2PL",
        control=ctl.list, est.guess=est.guess, guess=guess, guess.prior=guess.prior)
summary(mod5)

#--- specification in tamaan
tammodel &lt;- "
LAVAAN MODEL:
  F1=~ I1__I40
  F1 ~~ 1*F1
  I3 + I7 ?=g1
  I9 + I12 ?=g912 * g1
MODEL PRIOR:
  g912 ~ Beta(5,17)
  I3_guess ~ Beta(5,17)
  I7_guess ~ Beta(5,17)
    "
mod5a &lt;- TAM::tamaan( tammodel, resp=dat, control=list(maxiter=20))

#*** Model 6: 2PL model with design matrix for item slopes
I &lt;- 40         # number of items
D &lt;- 1       # dimensions
maxK &lt;- 2    # maximum number of categories
Ngam &lt;- 13   # number of different slope parameters
E &lt;- array( 0, dim=c(I,maxK,D,Ngam) )
# joint slope parameters for items 1 to 10, 11 to 20, 21 to 30
E[ 1:10, 2, 1, 2 ] &lt;- 1
E[ 11:20, 2, 1, 1 ] &lt;- 1
E[ 21:30, 2, 1, 3 ] &lt;- 1
for (ii in 31:40){   E[ii,2,1,ii - 27 ] &lt;- 1 }
# estimate model
mod6 &lt;- TAM::tam.mml.3pl(resp=dat, control=ctl.list,   E=E, est.variance=FALSE  )
summary(mod6)

#*** Model 6b: Truncated normal prior distribution for slope parameters
gammaslope.prior &lt;- matrix( 0, nrow=Ngam, ncol=4 )
gammaslope.prior[,1] &lt;- 2  # mean
gammaslope.prior[,2] &lt;- 10  # standard deviation
gammaslope.prior[,3] &lt;- -Inf # lower bound
gammaslope.prior[ 4:13,3] &lt;- 1.2
gammaslope.prior[,4] &lt;- Inf  # upper bound
# estimate model
mod6b &lt;- TAM::tam.mml.3pl(resp=dat, E=E, est.variance=FALSE,
                gammaslope.prior=gammaslope.prior, control=ctl.list )
summary(mod6b)

#*** Model 7: 2PL model with design matrix of slopes and slope constraints
Ngam &lt;- dim(E)[4]   # number of gamma parameters
# define two constraint equations
gammaslope.constr.V &lt;- matrix( 0, nrow=Ngam, ncol=2 )
gammaslope.constr.c &lt;- rep(0,2)
# set sum of first two xlambda entries to 1.8
gammaslope.constr.V[1:2,1] &lt;- 1
gammaslope.constr.c[1] &lt;- 1.8
# set sum of entries 4, 5 and 6 to 3
gammaslope.constr.V[4:6,2] &lt;- 1
gammaslope.constr.c[2] &lt;- 3
mod7 &lt;- TAM::tam.mml.3pl(resp=dat, control=ctl.list,  E=E,  est.variance=FALSE,
   gammaslope.constr.V=gammaslope.constr.V, gammaslope.constr.c=gammaslope.constr.c)
summary(mod7)

#**** Model 8: Located latent class Rasch model with estimated three skill points

# three classes of theta's are estimated
TP &lt;- 3
theta.k &lt;- diag(TP)
# because item difficulties are unrestricted, we define the sum of the estimated
# theta points equal to zero
Ngam &lt;- TP  # estimate three gamma loading parameters which are discrete theta points
E &lt;- array( 0, dim=c(I,2,TP,Ngam) )
E[,2,1,1] &lt;- E[,2,2,2] &lt;- E[,2,3,3] &lt;- 1
gammaslope.constr.V &lt;- matrix( 1, nrow=3, ncol=1 )
gammaslope.constr.c &lt;- c(0)
# initial gamma values
gammaslope &lt;- c( -2, 0, 2 )
# estimate model
mod8 &lt;- TAM::tam.mml.3pl(resp=dat, control=ctl.list,  E=E,  skillspace="discrete",
     theta.k=theta.k, gammaslope=gammaslope, gammaslope.constr.V=gammaslope.constr.V,
     gammaslope.constr.c=gammaslope.constr.c )
summary(mod8)

#*** Model 9: Multidimensional multiple group model
N &lt;- nrow(dat)
I &lt;- ncol(dat)
group &lt;- c( rep(1,N/4), rep(2,N/4), rep(3,N/2) )
Q &lt;- matrix(0,nrow=I,ncol=2)
Q[ 1:(I/2), 1] &lt;- Q[ seq(I/2+1,I), 2] &lt;- 1
# estimate model
mod9 &lt;- TAM::tam.mml.3pl(resp=dat, skillspace="normal", est.some.slopes=FALSE,
               group=group, Q=Q)
summary(mod9)

#############################################################################
# EXAMPLE 2: Polytomous data
#############################################################################

data( data.mg, package="CDM")
dat &lt;- data.mg[1:1000, paste0("I",1:11)]

#*******************************************************
#*** Model 1: 1-dimensional 1PL estimation, normal skill distribution
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, skillspace="normal",
           gammaslope.des="2PL", est.some.slopes=FALSE,  est.variance=TRUE  )
summary(mod1)

#*******************************************************
#*** Model 2: 1-dimensional 2PL estimation, discrete skill distribution
# define skill space
theta.k &lt;- matrix( seq(-5,5,len=21) )
# allow skew skill distribution
delta.designmatrix &lt;- cbind( 1, theta.k, theta.k^2, theta.k^3 )
# fix 13th xsi item parameter to zero
xsi.fixed &lt;- cbind( 13, 0 )
# fix 10th slope paremeter to one
gammaslope.fixed &lt;- cbind( 10, 1 )
# estimate model
mod2 &lt;- TAM::tam.mml.3pl(resp=dat, skillspace="discrete", theta.k=theta.k,
          delta.designmatrix=delta.designmatrix, gammaslope.des="2PL", xsi.fixed=xsi.fixed,
          gammaslope.fixed=gammaslope.fixed)
summary(mod2)

#*******************************************************
#*** Model 3: 2-dimensional 2PL estimation, normal skill distribution

# define loading matrix
Q &lt;- matrix(0,11,2)
Q[1:6,1] &lt;- 1   # items 1 to 6 load on dimension 1
Q[7:11,2] &lt;- 1  # items 7 to 11 load on dimension 2
# estimate model
mod3 &lt;- TAM::tam.mml.3pl(resp=dat, gammaslope.des="2PL", Q=Q )
summary(mod3)

#############################################################################
# EXAMPLE 3: Dichotomous data with guessing
#############################################################################

#*** simulate data
set.seed(9765)
N &lt;- 4000   # number of persons
I &lt;- 20     # number of items
b &lt;- seq( -1.5, 1.5, len=I )
guess &lt;- rep(0, I )
guess.items &lt;- c(6,11,16)
guess[ guess.items ] &lt;- .33
library(sirt)
dat &lt;- sirt::sim.raschtype( stats::rnorm(N), b=b, fixed.c=guess )

#*******************************************************
#*** Model 1: Difficulty + guessing model, i.e. fix slopes to 1
est.guess &lt;- rep(0,I)
est.guess[ guess.items ] &lt;- seq(1, length(guess.items) )
# define prior distribution
guess.prior &lt;- matrix( cbind( 5, 17 ), I, 2, byrow=TRUE )
guess.prior[ ! est.guess, ] &lt;- 0
# estimate model
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, guess=guess, est.guess=est.guess,
           guess.prior=guess.prior, control=ctl.list,est.variance=TRUE,
           est.some.slopes=FALSE )
summary(mod1)

#*******************************************************
#*** Model 2: estimate a joint guessing parameter
est.guess &lt;- rep(0,I)
est.guess[ guess.items ] &lt;- 1
# estimate model
mod2 &lt;- TAM::tam.mml.3pl(resp=dat, guess=guess, est.guess=est.guess,
            guess.prior=guess.prior, control=ctl.list,est.variance=TRUE,
            est.some.slopes=FALSE )
summary(mod2)

#############################################################################
# EXAMPLE 4: Latent class model with two classes
#      See slca Simulated Example 2 in the CDM package
#############################################################################

#*******************************************************
#*** simulate data
set.seed(9876)
I &lt;- 7  # number of items
# simulate response probabilities
a1 &lt;- round( stats::runif(I,0, .4 ),4)
a2 &lt;- round( stats::runif(I, .6, 1 ),4)
N &lt;- 1000   # sample size
# simulate data in two classes of proportions .3 and .7
N1 &lt;- round(.3*N)
dat1 &lt;- 1 * ( matrix(a1,N1,I,byrow=TRUE) &gt; matrix( stats::runif( N1 * I), N1, I ) )
N2 &lt;- round(.7*N)
dat2 &lt;- 1 * ( matrix(a2,N2,I,byrow=TRUE) &gt; matrix( stats::runif( N2 * I), N2, I ) )
dat &lt;- rbind( dat1, dat2 )
colnames(dat) &lt;- paste0("I", 1:I)

#*******************************************************
# estimation using tam.mml.3pl function

# define design matrices
TP &lt;- 2     # two classes
theta.k &lt;- diag(TP)     # there are theta dimensions -&gt; two classes
# The idea is that latent classes refer to two different "dimensions".
# Items load on latent class indicators 1 and 2, see below.
E &lt;- array(0, dim=c(I,2,2,2*I) )
items &lt;- colnames(dat)
dimnames(E)[[4]] &lt;- c(paste0( colnames(dat), "Class", 1),
          paste0( colnames(dat), "Class", 2) )
# items, categories, classes, parameters
# probabilities for correct solution
for (ii in 1:I){
    E[ ii, 2, 1, ii ] &lt;- 1    # probabilities class 1
    E[ ii, 2, 2, ii+I ] &lt;- 1  # probabilities class 2
                    }

# estimation command
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, E=E, control=list(maxit=20), skillspace="discrete",
          theta.k=theta.k, notA=TRUE)
summary(mod1)
# compare simulated and estimated data
cbind( mod1$rprobs[,2,1], a2 )  # Simulated class 2
cbind( mod1$rprobs[,2,2], a1 )  # Simulated class 1

#*******************************************************
#** specification with tamaan
tammodel &lt;- "
ANALYSIS:
  TYPE=LCA;
  NCLASSES(2);   # 2 classes
  NSTARTS(5,20); # 5 random starts with 20 iterations
LAVAAN MODEL:
  F=~ I1__I7
    "
mod1b &lt;- TAM::tamaan( tammodel, resp=dat )
summary(mod1b)
# compare with mod1
logLik(mod1)
logLik(mod1b)

#############################################################################
# EXAMPLE 5: Located latent class model, Rasch model
#      See slca Simulated Example 4 in the CDM package
#############################################################################

#*** simulate data
set.seed(487)
I &lt;- 15  # I items
b1 &lt;- seq( -2, 2, len=I)      # item difficulties
N &lt;- 2000    # number of persons
# simulate 4 theta classes
theta0 &lt;- c( -2.5, -1, 0.3, 1.3 )  # skill classes
probs0 &lt;- c( .1, .4, .2, .3 )      # skill class probabilities
TP &lt;- length(theta0)
theta &lt;- theta0[ rep(1:TP, round(probs0*N)  ) ]
library(sirt)
dat &lt;- sirt::sim.raschtype( theta, b1 )
colnames(dat) &lt;- paste0("I",1:I)

#*******************************************************
#*** Model 1: Located latent class model with 4 classes
maxK &lt;- 2
Ngam &lt;- TP
E &lt;- array( 0, dim=c(I, maxK, TP,  Ngam ) )
dimnames(E)[[1]] &lt;- colnames(dat)
dimnames(E)[[2]] &lt;- paste0("Cat", 1:(maxK) )
dimnames(E)[[3]] &lt;- paste0("Class", 1:TP)
dimnames(E)[[4]] &lt;- paste0("theta", 1:TP)
# theta design
for (tt in 1:TP){   E[1:I, 2, tt,  tt] &lt;- 1       }
theta.k &lt;- diag(TP)
# set eighth item difficulty to zero
xsi.fixed &lt;- cbind( 8, 0 )
# initial gamma parameter
gammaslope &lt;- seq( -1.5, 1.5, len=TP)
# estimate model
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, E=E, xsi.fixed=xsi.fixed,
           control=list(maxiter=100), skillspace="discrete",
           theta.k=theta.k, gammaslope=gammaslope)
summary(mod1)
# compare estimated and simulated theta class locations
cbind( mod1$gammaslope, theta0 )
# compare estimated and simulated latent class proportions
cbind( mod1$pi.k, probs0 )

#----- specification using tamaan
tammodel &lt;- "
ANALYSIS:
  TYPE=LOCLCA;
  NCLASSES(4)
LAVAAN MODEL:
  F=~ I1__I15
  I8 | 0*t1
    "
mod1b &lt;- TAM::tamaan( tammodel, resp=dat )
summary(mod1b)

#############################################################################
# EXAMPLE 6: DINA model with two skills
#      See slca Simulated Example 5 in the CDM package
#############################################################################

#*** simulate data
set.seed(487)
N &lt;- 3000   # number of persons
# define Q-matrix
I &lt;- 9  # 9 items
NS &lt;- 2 # 2 skills
TP &lt;- 4 # number of skill classes
Q &lt;- scan(nlines=3, text=
  "1 0   1 0   1 0
   0 1   0 1   0 1
   1 1   1 1   1 1",
   )
Q &lt;- matrix(Q, I, ncol=NS, byrow=TRUE)
# define skill distribution
alpha0 &lt;- matrix( c(0,0,1,0,0,1,1,1), nrow=4,ncol=2,byrow=TRUE)
prob0 &lt;- c( .2, .4, .1, .3 )
alpha &lt;- alpha0[ rep( 1:TP, prob0*N),]
# define guessing and slipping parameters
guess &lt;- round( stats::runif(I, 0, .4 ), 2 )
slip &lt;- round( stats::runif(I, 0, .3 ), 2 )
# simulate data according to the DINA model
dat &lt;- CDM::sim.din( q.matrix=Q, alpha=alpha, slip=slip, guess=guess )$dat

#*** Model 1: Estimate DINA model
# define E matrix which contains the anti-slipping parameters
maxK &lt;- 2
Ngam &lt;- I
E &lt;- array( 0, dim=c(I, maxK, TP,  Ngam ) )
dimnames(E)[[1]] &lt;- colnames(dat)
dimnames(E)[[2]] &lt;- paste0("Cat", 1:(maxK) )
dimnames(E)[[3]] &lt;- c("S00","S10","S01","S11")
dimnames(E)[[4]] &lt;- paste0( "antislip", 1:I )
# define anti-slipping parameters in E
for (ii in 1:I){
        # define latent responses
        latresp &lt;- 1*( alpha0 %*% Q[ii,]==sum(Q[ii,]) )[,1]
        # model slipping parameters
        E[ii, 2, latresp==1, ii ] &lt;- 1
                 }
# skill space definition
theta.k &lt;- diag(TP)
gammaslope &lt;- rep( qlogis( .8 ), I )

# estimate model
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, E=E, control=list(maxiter=100), skillspace="discrete",
          theta.k=theta.k, gammaslope=gammaslope)
summary(mod1)
# compare estimated and simulated latent class proportions
cbind( mod1$pi.k, probs0 )
# compare estimated and simulated guessing parameters
cbind( mod1$rprobs[,2,1], guess )
# compare estimated and simulated slipping parameters
cbind( 1 - mod1$rprobs[,2,4], slip )

#############################################################################
# EXAMPLE 7: Mixed Rasch model with two classes
#      See slca Simulated Example 3 in the CDM package
#############################################################################

#*** simulate data
set.seed(987)
library(sirt)
# simulate two latent classes of Rasch populations
I &lt;- 15  # 6 items
b1 &lt;- seq( -1.5, 1.5, len=I)      # difficulties latent class 1
b2 &lt;- b1    # difficulties latent class 2
b2[ c(4,7, 9, 11, 12, 13) ] &lt;- c(1, -.5, -.5, .33, .33, -.66 )
b2 &lt;- b2 - mean(b2)
N &lt;- 3000    # number of persons
wgt &lt;- .25       # class probability for class 1
# class 1
dat1 &lt;- sirt::sim.raschtype( stats::rnorm( wgt*N ), - b1 )
# class 2
dat2 &lt;- sirt::sim.raschtype( stats::rnorm( (1-wgt)*N, mean=1, sd=1.7), - b2 )
dat &lt;- rbind( dat1, dat2 )

# The idea is that each grid point class x theta is defined as new
# dimension. If we approximate the trait distribution by 7 theta points
# and are interested in estimating 2 latent classes, then we need
# 7*2=14 dimensions.

#*** Model 1: Rasch model
# theta grid
theta.k1 &lt;- seq( -5, 5, len=7 )
TT &lt;- length(theta.k1)
#-- define theta design matrix
theta.k &lt;- diag(TT)
#-- delta designmatrix
delta.designmatrix &lt;- matrix( 0, TT, ncol=3 )
delta.designmatrix[, 1] &lt;- 1
delta.designmatrix[, 2:3] &lt;- cbind( theta.k1, theta.k1^2 )

#-- define loading matrix E
E &lt;- array( 0, dim=c(I,2,TT,I + 1) )  # last parameter is constant 1
for (ii in 1:I){
    E[ ii, 2, 1:TT, ii ] &lt;- -1   # '-b' in '1*theta - b'
    E[ ii, 2, 1:TT, I+1] &lt;- theta.k1  # '1*theta' in '1*theta - b'
                }
# initial gammaslope parameters
par1 &lt;- stats::qlogis( colMeans( dat ) )
gammaslope &lt;- c( par1, 1 )
# sum constraint of zero on item difficulties
gammaslope.constr.V &lt;- matrix( 0, I+1, 1 )
gammaslope.constr.V[ 1:I, 1] &lt;- 1  # Class 1
gammaslope.constr.c &lt;- c(0)
# fixed gammaslope parameter
gammaslope.fixed &lt;- cbind( I+1, 1 )
# estimate model
mod1 &lt;- TAM::tam.mml.3pl(resp=dat1, E=E, skillspace="discrete",
           theta.k=theta.k, delta.designmatrix=delta.designmatrix,
           gammaslope=gammaslope, gammaslope.constr.V=gammaslope.constr.V,
           gammaslope.constr.c=gammaslope.constr.c, gammaslope.fixed=gammaslope.fixed,
           notA=TRUE, est.variance=FALSE)
summary(mod1)

#*** Model 2: Mixed Rasch model with two latent classes
# theta grid
theta.k1 &lt;- seq( -4, 4, len=7 )
TT &lt;- length(theta.k1)
#-- define theta design matrix
theta.k &lt;- diag(2*TT)   # 2*7=14 classes
#-- delta designmatrix
delta.designmatrix &lt;- matrix( 0, 2*TT, ncol=6 )
# Class 1
delta.designmatrix[1:TT, 1] &lt;- 1
delta.designmatrix[1:TT, 2:3] &lt;- cbind( theta.k1, theta.k1^2 )
# Class 2
delta.designmatrix[TT+1:TT, 4] &lt;- 1
delta.designmatrix[TT+1:TT, 5:6] &lt;- cbind( theta.k1, theta.k1^2 )

#-- define loading matrix E
E &lt;- array( 0, dim=c(I,2,2*TT,2*I + 1) )  # last parameter is constant 1
dimnames(E)[[1]] &lt;- colnames(dat)
dimnames(E)[[2]] &lt;- c("Cat0","Cat1")
dimnames(E)[[3]] &lt;- c( paste0("Class1_theta", 1:TT), paste0("Class2_theta", 1:TT) )
dimnames(E)[[4]] &lt;- c( paste0("b_Class1_", colnames(dat)),
       paste0("b_Class2_", colnames(dat)), "One")
for (ii in 1:I){
  # Class 1 item parameters
    E[ ii, 2, 1:TT, ii ] &lt;- -1   # '-b' in '1*theta - b'
    E[ ii, 2, 1:TT, 2*I+1] &lt;- theta.k1  # '1*theta' in '1*theta - b'
  # Class 2 item parameters
    E[ ii, 2, TT + 1:TT, I + ii ] &lt;- -1
    E[ ii, 2, TT + 1:TT, 2*I+1] &lt;- theta.k1
                }
# initial gammaslope parameters
par1 &lt;- qlogis( colMeans( dat ) )
gammaslope &lt;- c( par1, par1 + stats::runif(I, -2,2 ), 1 )
# sum constraint of zero on item difficulties within a class
gammaslope.center.index &lt;- c( rep( 1, I ), rep(2,I), 0 )
gammaslope.center.value &lt;- c(0,0)

# estimate model
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, E=E, skillspace="discrete",
            theta.k=theta.k, delta.designmatrix=delta.designmatrix,
            gammaslope=gammaslope, gammaslope.center.index=gammaslope.center.index,
            gammaslope.center.value=gammaslope.center.value, gammaslope.fixed=gammaslope.fixed,
            notA=TRUE)
summary(mod1)
# latent class proportions
stats::aggregate( mod1$pi.k, list( rep(1:2, each=TT)), sum )
# compare simulated and estimated item parameters
cbind( b1, b2, - mod1$gammaslope[1:I], - mod1$gammaslope[I + 1:I ] )

#--- specification in tamaan
tammodel &lt;- "
ANALYSIS:
  TYPE=MIXTURE;
  NCLASSES(2)
  NSTARTS(5,30)
LAVAAN MODEL:
  F=~ I0001__I0015
ITEM TYPE:
  ALL(Rasch);
    "
mod1b &lt;- TAM::tamaan( tammodel, resp=dat )
summary(mod1b)

#############################################################################
# EXAMPLE 8: 2PL mixture distribution model
#############################################################################

#*** simulate data
set.seed(9187)
library(sirt)
# simulate two latent classes of Rasch populations
I &lt;- 20
b1 &lt;- seq( -1.5, 1.5, len=I)      # difficulties latent class 1
b2 &lt;- b1    # difficulties latent class 2
b2[ c(4,7, 9, 11, 12, 13, 16, 18) ] &lt;- c(1, -.5, -.5, .33, .33, -.66, -1, .3)
# b2 &lt;- scale( b2, scale=FALSE)
b2 &lt;- b2 - mean(b2)
N &lt;- 4000       # number of persons
wgt &lt;- .75       # class probability for class 1
# item slopes
a1 &lt;- rep( 1, I )  # first class
a2 &lt;- rep( c(.5,1.5), I/2 )

# class 1
dat1 &lt;- sirt::sim.raschtype( stats::rnorm( wgt*N ), - b1, fixed.a=a1)
# class 2
dat2 &lt;- sirt::sim.raschtype( stats::rnorm( (1-wgt)*N, mean=1, sd=1.4), - b2, fixed.a=a2)
dat &lt;- rbind( dat1, dat2 )

#*** Model 1: Mixed 2PL model with two latent classes

theta.k1 &lt;- seq( -4, 4, len=7 )
TT &lt;- length(theta.k1)
#-- define theta design matrix
theta.k &lt;- diag(2*TT)   # 2*7=14 classes
#-- delta designmatrix
delta.designmatrix &lt;- matrix( 0, 2*TT, ncol=6 )
# Class 1
delta.designmatrix[1:TT, 1] &lt;- 1
delta.designmatrix[1:TT, 2:3] &lt;- cbind( theta.k1, theta.k1^2 )
# Class 2
delta.designmatrix[TT+1:TT, 4] &lt;- 1
delta.designmatrix[TT+1:TT, 5:6] &lt;- cbind( theta.k1, theta.k1^2 )

#-- define loading matrix E
E &lt;- array( 0, dim=c(I,2,2*TT,4*I ) )
dimnames(E)[[1]] &lt;- colnames(dat)
dimnames(E)[[2]] &lt;- c("Cat0","Cat1")
dimnames(E)[[3]] &lt;- c( paste0("Class1_theta", 1:TT), paste0("Class2_theta", 1:TT) )
dimnames(E)[[4]] &lt;- c( paste0("b_Class1_", colnames(dat)),
                       paste0("a_Class1_", colnames(dat)),
                       paste0("b_Class2_", colnames(dat)),
                       paste0("a_Class2_", colnames(dat)) )

for (ii in 1:I){
  # Class 1 item parameters
    E[ ii, 2, 1:TT, ii ] &lt;- -1           # '-b' in 'a*theta - b'
    E[ ii, 2, 1:TT, I + ii] &lt;- theta.k1  # 'a*theta' in 'a*theta - b'
  # Class 2 item parameters
    E[ ii, 2, TT + 1:TT, 2*I + ii ] &lt;- -1
    E[ ii, 2, TT + 1:TT, 3*I + ii ] &lt;- theta.k1
}

# initial gammaslope parameters
par1 &lt;- scale( - stats::qlogis( colMeans( dat ) ), scale=FALSE )
gammaslope &lt;- c( par1, rep(1,I),  scale( par1 + runif(I, - 1.4, 1.4 ),
        scale=FALSE), stats::runif( I,.6,1.4) )

# constraint matrix
gammaslope.constr.V &lt;- matrix( 0, 4*I, 4 )
# sum of item intercepts equals zero
gammaslope.constr.V[ 1:I, 1] &lt;- 1        # Class 1 (b)
gammaslope.constr.V[ 2*I + 1:I, 2] &lt;- 1  # Class 2 (b)
# sum of item slopes equals number of items -&gt; mean slope of 1
gammaslope.constr.V[ I + 1:I, 3] &lt;- 1    # Class 1 (a)
gammaslope.constr.V[ 3*I + 1:I, 4] &lt;- 1  # Class 2 (a)
gammaslope.constr.c &lt;- c(0,0,I,I)

# estimate model
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, E=E, control=list(maxiter=80), skillspace="discrete",
      theta.k=theta.k, delta.designmatrix=delta.designmatrix,
      gammaslope=gammaslope, gammaslope.constr.V=gammaslope.constr.V,
      gammaslope.constr.c=gammaslope.constr.c,  gammaslope.fixed=gammaslope.fixed,
      notA=TRUE)

# estimated item parameters
mod1$gammaslope
# summary
summary(mod1)
# latent class proportions
round( stats::aggregate( mod1$pi.k, list( rep(1:2, each=TT)), sum ), 3 )
# compare simulated and estimated item intercepts
int &lt;- cbind( b1*a1, b2 * a2, - mod1$gammaslope[1:I], - mod1$gammaslope[2*I + 1:I ] )
round( int, 3 )
# simulated and estimated item slopes
slo &lt;- cbind( a1, a2,  mod1$gammaslope[I+1:I], mod1$gammaslope[3*I + 1:I ] )
round(slo,3)

#--- specification in tamaan
tammodel &lt;- "
ANALYSIS:
  TYPE=MIXTURE;
  NCLASSES(2)
  NSTARTS(10,25)
LAVAAN MODEL:
  F=~ I0001__I0020
    "
mod1t &lt;- TAM::tamaan( tammodel, resp=dat )
summary(mod1t)

#############################################################################
# EXAMPLE 9: Toy example: Exact representation of an item by a factor
#############################################################################

data(data.gpcm)
dat &lt;- data.gpcm[,1,drop=FALSE ]   # choose first item
# some descriptives
( t1 &lt;- table(dat) )

# The idea is that we define an IRT model with one latent variable
# which extactly corresponds to the manifest item.

I &lt;- 1    # 1 item
K &lt;- 4    # 4 categories
TP &lt;- 4   # 4 discrete theta points

# define skill space
theta.k &lt;- diag(TP)
# define loading matrix E
E &lt;- array( -99, dim=c(I,K,TP,1 ) )
for (vv in 1:K){
    E[ 1, vv, vv, 1 ] &lt;- 9
                }
# estimate model
mod1 &lt;- TAM::tam.mml.3pl(resp=dat, E=E, skillspace="discrete",
         theta.k=theta.k,  notA=TRUE)
summary(mod1)
# -&gt; the latent distribution corresponds to the manifest distribution, because ...
round( mod1$pi.k, 3 )
round( t1 / sum(t1), 3 )

#############################################################################
# EXAMPLE 10: Some fixed item loadings
#############################################################################

data(data.Students,package="CDM")
dat &lt;- data.Students
# select variables
vars &lt;- scan( nlines=1, what="character")
    act1 act2 act3 act4 act5 sc1 sc2 sc3 sc4
dat &lt;- data.Students[, vars  ]

# define loading matrix: two-dimensional model
Q &lt;- matrix( 0, nrow=9, ncol=2 )
Q[1:5,1] &lt;- 1
Q[6:9,2] &lt;- 1
# define some fixed item loadings
Q.fixed &lt;- NA*Q
Q.fixed[ c(1,4), 1] &lt;- .5
Q.fixed[ 6:7, 2 ] &lt;- 1

# estimate model
mod3 &lt;- TAM::tam.mml.3pl( resp=dat, gammaslope.des="2PL", Q=Q, Q.fixed=Q.fixed,
            control=list( maxiter=10, nodes=seq(-4,4,len=10) )  )
summary(mod3)

#############################################################################
# EXAMPLE 11: Mixed response formats - Multiple choice and partial credit items
#############################################################################

data(data.timssAusTwn.scored)
dat &lt;- data.timssAusTwn.scored

# select columns with item responses
dat &lt;- dat[, grep("M0", colnames(dat) ) ]
I &lt;- ncol(dat)   # number of items

# The idea is to start with partial credit modelling
# and then to include the guessing parameters

#*** Model 0: Partial Credit Model
mod0 &lt;- TAM::tam.mml(dat)
summary(mod0)

#*** Model 1 and Model 2: include guessing parameters

# multiple choice items
guess_items &lt;- which( apply( dat, 2, max, na.rm=TRUE )==1 )
# define guessing parameters
guess0 &lt;- rep(0,I)
guess0[ guess_items ] &lt;- .25  # set guessing probability to .25

# define which guessing parameters should be estimated
est.guess1 &lt;- rep(0,I)  # all parameters are fixed
est.guess2 &lt;- 1 * ( guess0==.25 )  # joint guessing parameter

# use design matrix from partial credit model
A0 &lt;- mod0$A

#--- Model 1: fixed guessing parameters of .25 and item slopes of 1
mod1 &lt;- TAM::tam.mml.3pl( dat, guess=guess0, est.guess=est.guess1,
            A=A0, est.some.slopes=FALSE, control=list(maxiter=50) )
summary(mod1)

#--- Model 2: estimate joint guessing parameters and item slopes of 1
mod2 &lt;- TAM::tam.mml.3pl( dat, guess=guess0, est.guess=est.guess2,
            A=A0, est.some.slopes=FALSE, control=list(maxiter=50) )
summary(mod2)

# model comparison
IRT.compareModels(mod0,mod1,mod2)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.modelfit'>
Model Fit Statistics in <span class="pkg">TAM</span>
</h2><span id='topic+tam.modelfit'></span><span id='topic+summary.tam.modelfit'></span><span id='topic+IRT.modelfit.tam.mml'></span><span id='topic+IRT.modelfit.tam.mml.3pl'></span><span id='topic+IRT.modelfit.tamaan'></span><span id='topic+summary.IRT.modelfit.tam.mml'></span><span id='topic+summary.IRT.modelfit.tam.mml.3pl'></span><span id='topic+summary.IRT.modelfit.tamaan'></span><span id='topic+tam.modelfit.IRT'></span><span id='topic+tam.modelfit.args'></span><span id='topic+tam.Q3'></span><span id='topic+summary.tam.Q3'></span>

<h3>Description</h3>

<p>The function <code>tam.modelfit</code> computes several model fit statistics.
It includes the Q3 statistic (Yen, 1984) and an
adjusted variant of it (see Details). Effect sizes of model fit
(<code>MADaQ3</code>, <code class="reqn">MADRESIDCOV</code>,
<code class="reqn">SRMR</code>) are also available.
</p>
<p>The function <code>IRT.modelfit</code> is a wrapper to <code>tam.modelfit</code>,
but allows convenient model comparisons by using the
<code><a href="CDM.html#topic+IRT.compareModels">CDM::IRT.compareModels</a></code> function.
</p>
<p>The <code>tam.modelfit</code> function can also be used for fitted
models outside the <span class="pkg">TAM</span> package by applying
<code>tam.modelfit.IRT</code> or <code>tam.modelfit.args</code>.
</p>
<p>The function <code>tam.Q3</code> computes the <code class="reqn">Q_3</code> statistic based on
weighted likelihood estimates (see <code><a href="#topic+tam.wle">tam.wle</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.modelfit(tamobj, progress=TRUE)

## S3 method for class 'tam.modelfit'
summary(object,...)

## S3 method for class 'tam.mml'
IRT.modelfit(object, ...)
## S3 method for class 'tam.mml.3pl'
IRT.modelfit(object, ...)
## S3 method for class 'tamaan'
IRT.modelfit(object, ...)

## S3 method for class 'IRT.modelfit.tam.mml'
summary(object, ...)
## S3 method for class 'IRT.modelfit.tam.mml.3pl'
summary(object, ...)
## S3 method for class 'IRT.modelfit.tamaan'
summary(object, ...)

tam.modelfit.IRT( object, progress=TRUE )

tam.modelfit.args( resp, probs, theta, post, progress=TRUE )

tam.Q3(tamobj, ... )

## S3 method for class 'tam.Q3'
summary(object,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.modelfit_+3A_tamobj">tamobj</code></td>
<td>

<p>Object of class <code>tam</code>
</p>
</td></tr>
<tr><td><code id="tam.modelfit_+3A_progress">progress</code></td>
<td>

<p>An optional logical indicating whether progress should
be displayed
</p>
</td></tr>
<tr><td><code id="tam.modelfit_+3A_object">object</code></td>
<td>
<p>Object of class <code>tam.modelfit</code> (for <code>summary</code>)
or objects for which <code>IRT.data</code>, <code>IRT.irfprob</code>
and <code>IRT.posterior</code> have been defined (for <code>tam.modelfit.IRT</code>).</p>
</td></tr>
<tr><td><code id="tam.modelfit_+3A_resp">resp</code></td>
<td>
<p>Dataset with item responses</p>
</td></tr>
<tr><td><code id="tam.modelfit_+3A_probs">probs</code></td>
<td>
<p>Array with item response functions evaluated at <code>theta</code></p>
</td></tr>
<tr><td><code id="tam.modelfit_+3A_theta">theta</code></td>
<td>
<p>Matrix with used <code class="reqn">\bold{\theta}</code> grid</p>
</td></tr>
<tr><td><code id="tam.modelfit_+3A_post">post</code></td>
<td>
<p>Individual posterior distribution</p>
</td></tr>
<tr><td><code id="tam.modelfit_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each item <code class="reqn">i</code> and each person <code class="reqn">n</code>, residuals
<code class="reqn">e_{ni}=X_{ni}-E(X_{ni})</code> are computed. The expected
value <code class="reqn">E(X_{ni})</code> is obtained by integrating the individual
posterior distribution.
</p>
<p>The Q3 statistic of item pairs <code class="reqn">i</code> and <code class="reqn">j</code> is defined as the
correlation <code class="reqn">Q3_{ij}=Cor( e_{ni}, e_{nj} )</code>. The residuals in
<code>tam.modelfit</code> are
calculated by integrating values of the individual posterior distribution.
Residuals in <code>tam.Q3</code> are calculated by using weighted likelihood
estimates (WLEs) from <code><a href="#topic+tam.wle">tam.wle</a></code>.
</p>
<p>It is known that under local independence, the expected value of <code class="reqn">Q_3</code>
is slightly smaller than zero. Therefore,
an adjusted Q3 statistic (<code>aQ3</code>; <code class="reqn">aQ3_{ij}</code>)
is computed by subtracting the average of all Q3 statistics from
Q3. To control for multiple testing,
a p value adjustment by the method of
Holm (<code>p.holm</code>) is employed (see Chen, de la Torre &amp; Zhang, 2013).
</p>
<p>An effect size of model fit (<code>MADaQ3</code>) is defined as
the average of absolute values of <code class="reqn">aQ3</code> statistics. An equivalent
statistic based on the <code class="reqn">Q_3</code> statistic is similar to the
standardized generalized dimensionality discrepancy measure (SGDDM; Levy,
Xu, Yel &amp; Svetina, 2015).
</p>
<p>The SRMSR (standardized root mean square root of squared residuals,
Maydeu-Olivaras, 2013) is based on comparing residual correlations
of item pairs
</p>
<p style="text-align: center;"><code class="reqn"> SRMSR=\sqrt{ \frac{1}{ J(J-1)/2 } \sum_{i &lt; j}
    ( r_{ij} - \hat{r}_{ij} )^2 } </code>
</p>

<p>Additionally, the SRMR is computed as
</p>
<p style="text-align: center;"><code class="reqn"> SRMR=\frac{1}{ J(J-1)/2 } \sum_{i &lt; j}
     | r_{ij} - \hat{r}_{ij} | </code>
</p>

<p>The <code class="reqn">MADRESIDCOV</code> statistic (McDonald &amp; Mok, 1995) is based on comparing
residual covariances of item pairs
</p>
<p style="text-align: center;"><code class="reqn"> MADRESIDCOV=\frac{1}{ J(J-1)/2 } \sum_{i &lt; j}
    | c_{ij} - \hat{c}_{ij} |  </code>
</p>

<p>This statistic is just multiplied by 100 in the output of this function.
</p>


<h3>Value</h3>

<p>A list with following entries
</p>
<table>
<tr><td><code>stat.MADaQ3</code></td>
<td>
<p>Global fit statistic <code>MADaQ3</code> and
global model test with <code>p</code> value obtained
by Holm adjustment</p>
</td></tr>
<tr><td><code>chi2.stat</code></td>
<td>
<p>Data frame with chi square tests of conditional independence
for every item pair (Chen &amp; Thissen, 1997)</p>
</td></tr>
<tr><td><code>fitstat</code></td>
<td>
<p>Model fit statistics <code class="reqn">100 \cdot MADRESIDCOV</code>,
<code class="reqn">SRMR</code> and <code class="reqn">SRMSR</code></p>
</td></tr>
<tr><td><code>modelfit.test</code></td>
<td>
<p>Test statistic of global fit based on multiple
testing correction of <code class="reqn">\chi^2</code> statistics
</p>
</td></tr>
<tr><td><code>stat.itempair</code></td>
<td>
<p>Q3 and adjusted Q3 statistic for all item pairs</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>Residuals</p>
</td></tr>
<tr><td><code>Q3.matr</code></td>
<td>
<p>Matrix of <code class="reqn">Q_3</code> statistics</p>
</td></tr>
<tr><td><code>aQ3.matr</code></td>
<td>
<p>Matrix of adjusted <code class="reqn">Q_3</code> statistics</p>
</td></tr>
<tr><td><code>Q3_summary</code></td>
<td>
<p>Summary of <code class="reqn">Q_3</code> statistics</p>
</td></tr>
<tr><td><code>N_itempair</code></td>
<td>
<p>Sample size for each item pair</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chen, J., de la Torre, J., &amp; Zhang, Z. (2013).
Relative and absolute fit evaluation in cognitive diagnosis modeling.
<em>Journal of Educational Measurement, 50</em>, 123-140.
<a href="https://doi.org/10.1111/j.1745-3984.2012.00185.x">doi:10.1111/j.1745-3984.2012.00185.x</a>
</p>
<p>Chen, W., &amp; Thissen, D. (1997). Local dependence indexes for item pairs
using item response theory. <em>Journal of Educational and Behavioral Statistics,
22</em>, 265-289.
</p>
<p>Levy, R., Xu, Y., Yel, N., &amp; Svetina, D. (2015). A standardized
generalized dimensionality discrepancy measure and a standardized model-based
covariance for dimensionality assessment for multidimensional models.
<em>Journal of Educational Measurement, 52</em>(2), 144&ndash;158.
<a href="https://doi.org/10.1111/jedm.12070">doi:10.1111/jedm.12070</a>
</p>
<p>Maydeu-Olivares, A. (2013). Goodness-of-fit assessment of item response
theory models (with discussion).
<em>Measurement: Interdisciplinary Research and Perspectives,
11</em>, 71-137.
<a href="https://doi.org/10.1080/15366367.2013.831680">doi:10.1080/15366367.2013.831680</a>
</p>
<p>McDonald, R. P., &amp; Mok, M. M.-C. (1995). Goodness of fit in item response models.
<em>Multivariate Behavioral Research, 30</em>, 23-40.
<a href="https://doi.org/10.1207/s15327906mbr3001_2">doi:10.1207/s15327906mbr3001_2</a>
</p>
<p>Yen, W. M. (1984). Effects of local item dependence on the fit and equating
performance of the three-parameter logistic model.
<em>Applied Psychological Measurement, 8</em>, 125-145.
<a href="https://doi.org/10.1177/014662168400800201">doi:10.1177/014662168400800201</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: data.cqc01
#############################################################################

data(data.cqc01)
dat &lt;- data.cqc01

#*****************************************************
#*** Model 1: Rasch model
mod1 &lt;- TAM::tam.mml( dat )
# assess model fit
res1 &lt;- TAM::tam.modelfit( tamobj=mod1 )
summary(res1)
# display item pairs with five largest adjusted Q3 statistics
res1$stat.itempair[1:5,c("item1","item2","aQ3","p","p.holm")]

## Not run: 
# IRT.modelfit
fmod1 &lt;- IRT.modelfit(mod1)
summary(fmod1)

#*****************************************************
#*** Model 2: 2PL model
mod2 &lt;- TAM::tam.mml.2pl( dat )
# IRT.modelfit
fmod2 &lt;- IRT.modelfit(mod2)
summary(fmod2)

# model comparison
IRT.compareModels(fmod1, fmod2 )

#############################################################################
# SIMULATED EXAMPLE 2: Rasch model
#############################################################################

set.seed(8766)
N &lt;- 1000    # number of persons
I &lt;- 20      # number of items
# simulate responses
library(sirt)
dat &lt;- sirt::sim.raschtype( stats::rnorm(N), b=seq(-1.5,1.5,len=I) )
#*** estimation
mod1 &lt;- TAM::tam.mml( dat )
summary(dat)
#*** model fit
res1 &lt;- TAM::tam.modelfit( tamobj=mod1)
summary(res1)

#############################################################################
# EXAMPLE 3: Model fit data.gpcm | Partial credit model
#############################################################################

data(data.gpcm)
dat &lt;- data.gpcm

# estimate partial credit model
mod1 &lt;- TAM::tam.mml( dat)
summary(mod1)

# assess model fit
tmod1 &lt;- TAM::tam.modelfit( mod1 )
summary(tmod1)

#############################################################################
# EXAMPLE 4: data.read | Comparison Q3 statistic
#############################################################################

library(sirt)
data(data.read, package="sirt")
dat &lt;- data.read

#**** Model 1: 1PL model
mod1 &lt;- TAM::tam.mml( dat )
summary(mod1)

#**** Model 2: 2PL model
mod2 &lt;- TAM::tam.mml.2pl( dat )
summary(mod2)

#**** assess model fits
# Q3 based on posterior
fmod1 &lt;- TAM::tam.modelfit(mod1)
fmod2 &lt;- TAM::tam.modelfit(mod2)
# Q3 based on WLEs
q3_mod1 &lt;- TAM::tam.Q3(mod1)
q3_mod2 &lt;- TAM::tam.Q3(mod2)
summary(fmod1)
summary(fmod2)
summary(q3_mod1)
summary(q3_mod2)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.np'>
Unidimensional Non- and Semiparametric Item Response Model
</h2><span id='topic+tam.np'></span><span id='topic+summary.tam.np'></span><span id='topic+IRT.cv.tam.np'></span>

<h3>Description</h3>

<p>Conducts non- and semiparametric estimation of a unidimensional item response model
for a single group allowing polytomous item responses (Rossi, Wang &amp; Ramsay, 2002).
</p>
<p>For dichotomous data, the function also allows group lasso penalty
(<code>penalty_type="lasso"</code>; Breheny &amp; Huang, 2015; Yang &amp; Zhou, 2015) and a ridge penalty
(<code>penalty_type="ridge"</code>; Rossi et al., 2002)
which is applied to the nonlinear part of the basis expansion. This approach
automatically detects deviations from a 2PL or a 1PL model (see Examples 2 and 3).
See Details for model specification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.np( dat, probs_init=NULL, pweights=NULL, lambda=NULL, control=list(),
    model="2PL", n_basis=0, basis_type="hermite", penalty_type="lasso",
    pars_init=NULL, orthonormalize=TRUE)

## S3 method for class 'tam.np'
summary(object, file=NULL, ...)

## S3 method for class 'tam.np'
IRT.cv(object, kfold=10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.np_+3A_dat">dat</code></td>
<td>

<p>Matrix of integer item responses (starting from zero)
</p>
</td></tr>
<tr><td><code id="tam.np_+3A_probs_init">probs_init</code></td>
<td>
<p>Array containing initial probabilities</p>
</td></tr>
<tr><td><code id="tam.np_+3A_pweights">pweights</code></td>
<td>

<p>Optional vector of person weights
</p>
</td></tr>
<tr><td><code id="tam.np_+3A_lambda">lambda</code></td>
<td>
<p>Numeric or vector of regularization parameter</p>
</td></tr>
<tr><td><code id="tam.np_+3A_control">control</code></td>
<td>

<p>List of control arguments, see <code><a href="#topic+tam.mml">tam.mml</a></code>.
</p>
</td></tr>
<tr><td><code id="tam.np_+3A_model">model</code></td>
<td>
<p>Specified target model. Can be <code>"2PL"</code> or <code>"1PL"</code>.</p>
</td></tr>
<tr><td><code id="tam.np_+3A_n_basis">n_basis</code></td>
<td>
<p>Number of basis functions</p>
</td></tr>
<tr><td><code id="tam.np_+3A_basis_type">basis_type</code></td>
<td>
<p>Type of basis function: <code>"bspline"</code> for B-splines
or <code>"hermite"</code> for Gauss-Hermite polynomials
</p>
</td></tr>
<tr><td><code id="tam.np_+3A_penalty_type">penalty_type</code></td>
<td>
<p>Lasso type penalty (<code>"lasso"</code>) or ridge
penalty (<code>"ridge"</code>)
</p>
</td></tr>
<tr><td><code id="tam.np_+3A_pars_init">pars_init</code></td>
<td>
<p>Optional matrix of initial item parameters</p>
</td></tr>
<tr><td><code id="tam.np_+3A_orthonormalize">orthonormalize</code></td>
<td>
<p>Logical indicating whether basis functions should
be orthonormalized</p>
</td></tr>
<tr><td><code id="tam.np_+3A_object">object</code></td>
<td>
<p>Object of class <code>tam.np</code></p>
</td></tr>
<tr><td><code id="tam.np_+3A_file">file</code></td>
<td>
<p>Optional file name for summary output</p>
</td></tr>
<tr><td><code id="tam.np_+3A_kfold">kfold</code></td>
<td>
<p>Number of folds in <code class="reqn">k</code>-fold cross-validation</p>
</td></tr>
<tr><td><code id="tam.np_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basis expansion approach is applied for the logit transformation of item
response functions for dichotomous data. In more detail, it this assumed that
</p>
<p style="text-align: center;"><code class="reqn">P(X_i=1|\theta)=\psi( H_0(\theta) + H_1(\theta)</code>
</p>

<p>where <code class="reqn">H_0</code> is the target function type and <code class="reqn">H_1</code> is the semiparametric
part which parameterizes model deviations. For the 2PL model (<code>model="2PL"</code>)
it is <code class="reqn">H_0(\theta)=d_i + a_i \theta </code> and for the 1PL model
(<code>model="1PL"</code>) we set <code class="reqn">H_1(\theta)=d_i + 1 \cdot \theta </code>.
The model discrepancy is specified as a basis expansion approach
</p>
<p style="text-align: center;"><code class="reqn">H_1 ( \theta )=\sum_{h=1}^p \beta_{ih} f_h( \theta)</code>
</p>
<p> where <code class="reqn">f_h</code> are
basis functions (possibly orthonormalized) and <code class="reqn">\beta_{ih}</code> are
item parameters which should be estimated. Penalty functions are posed on the
<code class="reqn">\beta_{ih}</code> coefficients. For the group lasso penalty, we specify the
penalty <code class="reqn">J_{i,L1}=N \lambda \sqrt{p} \sqrt{ \sum_{h=1}^p \beta_{ih}^2 }</code> while for
the ridge penalty it is <code class="reqn">J_{i,L2}=N \lambda \sum_{h=1}^p \beta_{ih}^2 </code>
(<code class="reqn">N</code> denoting the sample size).
</p>


<h3>Value</h3>

<p>List containing several entries
</p>
<table>
<tr><td><code>rprobs</code></td>
<td>
<p>Item response probabilities</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Used nodes for approximation of <code class="reqn">\theta</code> distribution</p>
</td></tr>
<tr><td><code>n.ik</code></td>
<td>
<p>Expected counts</p>
</td></tr>
<tr><td><code>like</code></td>
<td>
<p>Individual likelihood</p>
</td></tr>
<tr><td><code>hwt</code></td>
<td>
<p>Individual posterior</p>
</td></tr>
<tr><td><code>item</code></td>
<td>
<p>Summary item parameter table</p>
</td></tr>
<tr><td><code>pars</code></td>
<td>
<p>Estimated parameters</p>
</td></tr>
<tr><td><code>regularized</code></td>
<td>
<p>Logical indicating which items are regularized</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>List containing </p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Further values</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P., &amp; Huang, J. (2015). Group descent algorithms for nonconvex penalized linear
and logistic regression models with grouped predictors.
<em>Statistics and Computing, 25</em>(2), 173-187.
<a href="https://doi.org/10.1007/s11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>
</p>
<p>Rossi, N., Wang, X., &amp; Ramsay, J. O. (2002). Nonparametric item response function
estimates with the EM algorithm.
<em>Journal of Educational and Behavioral Statistics, 27</em>(3), 291-317.
<a href="https://doi.org/10.3102/10769986027003291">doi:10.3102/10769986027003291</a>
</p>
<p>Yang, Y., &amp; Zou, H. (2015). A fast unified algorithm for solving group-lasso penalized
learning problems. <em>Statistics and Computing, 25</em>(6), 1129-1141.
<a href="https://doi.org/10.1007/s11222-014-9498-5">doi:10.1007/s11222-014-9498-5</a>
</p>


<h3>See Also</h3>

<p>Nonparametric item response models can also be estimated with the
<code>mirt::itemGAM</code> function in the <b>mirt</b> package and the
<code>KernSmoothIRT::ksIRT</code> in the <b>KernSmoothIRT</b> package.
</p>
<p>See <code><a href="#topic+tam.mml">tam.mml</a></code> and <code><a href="#topic+tam.mml.2pl">tam.mml.2pl</a></code> for parametric item response
models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Nonparametric estimation polytomous data
#############################################################################

data(data.cqc02, package="TAM")
dat &lt;- data.cqc02

#** nonparametric estimation
mod &lt;- TAM::tam.np(dat)

#** extractor functions for objects of class 'tam.np'
lmod &lt;- IRT.likelihood(mod)
pmod &lt;- IRT.posterior(mod)
rmod &lt;- IRT.irfprob(mod)
emod &lt;- IRT.expectedCounts(mod)

#############################################################################
# EXAMPLE 2: Semiparametric estimation and detection of item misfit
#############################################################################

#- simulate data with two misfitting items
set.seed(998)
I &lt;- 10
N &lt;- 1000
a &lt;- stats::rnorm(I, mean=1, sd=.3)
b &lt;- stats::rnorm(I, mean=0, sd=1)
dat &lt;- matrix(NA, nrow=N, ncol=I)
colnames(dat) &lt;- paste0("I",1:I)
theta &lt;- stats::rnorm(N)
for (ii in 1:I){
    dat[,ii] &lt;- 1*(stats::runif(N) &lt; stats::plogis( a[ii]*(theta-b[ii] ) ))
}

#* first misfitting item with lower and upper asymptote
ii &lt;- 1
l &lt;- .3
u &lt;- 1
b[ii] &lt;- 1.5
dat[,ii] &lt;- 1*(stats::runif(N) &lt; l + (u-l)*stats::plogis( a[ii]*(theta-b[ii] ) ))

#* second misfitting item with non-monotonic item response function
ii &lt;- 3
dat[,ii] &lt;- (stats::runif(N) &lt; stats::plogis( theta-b[ii]+.6*theta^2))

#- 2PL model
mod0 &lt;- TAM::tam.mml.2pl(dat)

#- lasso penalty with lambda of .05
mod1 &lt;- TAM::tam.np(dat, n_basis=4, lambda=.05)

#- lambda value of .03 using starting value of previous model
mod2 &lt;- TAM::tam.np(dat, n_basis=4, lambda=.03, pars_init=mod1$pars)
cmod2 &lt;- TAM::IRT.cv(mod2)  # cross-validated deviance

#- lambda=.015
mod3 &lt;- TAM::tam.np(dat, n_basis=4, lambda=.015, pars_init=mod2$pars)
cmod3 &lt;- TAM::IRT.cv(mod3)

#- lambda=.007
mod4 &lt;- TAM::tam.np(dat, n_basis=4, lambda=.007, pars_init=mod3$pars)

#- lambda=.001
mod5 &lt;- TAM::tam.np(dat, n_basis=4, lambda=.001, pars_init=mod4$pars)

#- final estimation using solution of mod3
eps &lt;- .0001
lambda_final &lt;- eps+(1-eps)*mod3$regularized   # lambda parameter for final estimate
mod3b &lt;- TAM::tam.np(dat, n_basis=4, lambda=lambda_final, pars_init=mod3$pars)
summary(mod1)
summary(mod2)
summary(mod3)
summary(mod3b)
summary(mod4)

# compare models with respect to information criteria
IRT.compareModels(mod0, mod1, mod2, mod3, mod3b, mod4, mod5)

#-- compute item fit statistics RISE
# regularized solution
TAM::IRT.RISE(mod_p=mod1, mod_np=mod3)
# regularized solution, final estimation
TAM::IRT.RISE(mod_p=mod1, mod_np=mod3b, use_probs=TRUE)
TAM::IRT.RISE(mod_p=mod1, mod_np=mod3b, use_probs=FALSE)
# use TAM::IRT.RISE() function for computing the RMSD statistic
TAM::IRT.RISE(mod_p=mod1, mod_np=mod1, use_probs=FALSE)

#############################################################################
# EXAMPLE 3: Mixed 1PL/2PL model
#############################################################################

#* simulate data with 2 2PL items and 8 1PL items
set.seed(9877)
N &lt;- 2000
I &lt;- 10
b &lt;- seq(-1,1,len=I)
a &lt;- rep(1,I)
a[c(3,8)] &lt;- c(.5, 2)
theta &lt;- stats::rnorm(N, sd=1)
dat &lt;- sirt::sim.raschtype(theta, b=b, fixed.a=a)

#- 1PL model
mod1 &lt;- TAM::tam.mml(dat)
#- 2PL model
mod2 &lt;- TAM::tam.mml.2pl(dat)
#- 2PL model with penalty on slopes
mod3 &lt;- TAM::tam.np(dat, lambda=.04, model="1PL", n_basis=0)
summary(mod3)
#- final mixed 1PL/2PL model
lambda &lt;- 1*mod3$regularized
mod4 &lt;- TAM::tam.np(dat, lambda=lambda, model="1PL", n_basis=0)
summary(mod4)

IRT.compareModels(mod1, mod2, mod3, mod4)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.personfit'>
Person Outfit and Infit Statistics
</h2><span id='topic+tam.personfit'></span>

<h3>Description</h3>

<p>Computes person outfit and infit statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.personfit(tamobj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.personfit_+3A_tamobj">tamobj</code></td>
<td>

<p>Fitted object in <span class="pkg">TAM</span>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame containing person outfit and infit statistics
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+tam.fit">tam.fit</a></code> and <code><a href="#topic+msq.itemfit">msq.itemfit</a></code> for item fit
statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Person fit dichotomous data
#############################################################################

data(data.sim.rasch, package="TAM")
resp &lt;- data.sim.rasch

#*** estimate Rasch model
mod1 &lt;- TAM::tam.mml(resp=resp)
summary(mod1)

#*** compute person fit statistics
fmod1 &lt;- TAM::tam.personfit(mod1)
head(fmod1)
</code></pre>

<hr>
<h2 id='tam.pv'>
Plausible Value Imputation
</h2><span id='topic+tam.pv'></span><span id='topic+tam.pv.mcmc'></span><span id='topic+summary.tam.pv.mcmc'></span><span id='topic+plot.tam.pv.mcmc'></span>

<h3>Description</h3>

<p>Plausible value imputation for objects of the classes <code>tam</code> and <code>tam.mml</code>
(Adams &amp; Wu, 2007). For converting generated plausible values into
a list of multiply imputed datasets see <code><a href="#topic+tampv2datalist">tampv2datalist</a></code>
and the Examples 2 and 3 of this function.
</p>
<p>The function <code>tam.pv.mcmc</code> employs fully Bayesian estimation for drawing
plausible values and is recommended in cases when the latent regression model
is unreliably estimated (multidimensional model with stochastic nodes).
The parameters of the latent regression (regression coefficients and
residual covariance matrices) are drawn by Bayesian bootstrap (Rubin, 1981).
Either case probabilities (i.e., non-integer weights for cases in resampling;
argument <code>sample_integers=FALSE</code>) or ordinary
bootstrap (i.e., sampling cases with replacement; argument <code>sample_integers=TRUE</code>)
can be used for the Bootstrap step by obtaining posterior draws of regression parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.pv(tamobj, nplausible=10, ntheta=2000, normal.approx=FALSE,
    samp.regr=FALSE, theta.model=FALSE, np.adj=8, na.grid=5, verbose=TRUE)

tam.pv.mcmc( tamobj, Y=NULL, group=NULL, beta_groups=TRUE, nplausible=10, level=.95,
    n.iter=1000, n.burnin=500, adj_MH=.5, adj_change_MH=.05, refresh_MH=50,
    accrate_bound_MH=c(.45, .55), sample_integers=FALSE, theta_init=NULL,
    print_iter=20, verbose=TRUE, calc_ic=TRUE)

## S3 method for class 'tam.pv.mcmc'
summary(object, file=NULL, ...)

## S3 method for class 'tam.pv.mcmc'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.pv_+3A_tamobj">tamobj</code></td>
<td>

<p>Object of class <code>tam</code> or <code>tam.mml</code>. For <code>tam.pv.mcmc</code>, it must not
be an object of this class but rather a list with (at least the)
entries <code>AXsi</code>, <code>B</code>, <code>resp</code>.
</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_nplausible">nplausible</code></td>
<td>

<p>Number of plausible values to be drawn
</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_ntheta">ntheta</code></td>
<td>

<p>Number of ability nodes for plausible value imputation. Note
that in this function ability nodes are simulated for the
whole sample, not for every person (contrary to the software ConQuest).
</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_normal.approx">normal.approx</code></td>
<td>

<p>An optional logical indicating whether the individual posterior distributions
should be approximated by a normal distribution?
The default is <code>FALSE</code>. In the case <code>normal.approx=TRUE</code>
(normal distribution approximation), the number of ability nodes
<code>ntheta</code> can be substantially smaller than 2000, say 200 or 500.
The normal approximation is implemented for unidimensional and
multidimensional models.
</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_samp.regr">samp.regr</code></td>
<td>

<p>An optional logical indicating whether regression coefficients
should be fixed in the plausible value imputation or
also sampled from their posterior distribution?
The default is <code>FALSE</code>. Sampled regression coefficients are
obtained by nonparametric bootstrap.
</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_theta.model">theta.model</code></td>
<td>
<p>Logical indicating whether the theta grid from the
<code>tamobj</code> object should be used for plausible value
imputation. In case of <code>normal.approx=TRUE</code>, this should
be sufficient in many applications.
</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_np.adj">np.adj</code></td>
<td>

<p>This parameter defines the &quot;spread&quot; of the random theta values
for drawing plausible values when <code>normal.approx=FALSE</code>.
If <code class="reqn">s_{EAP}</code> denotes the standard deviation of the posterior
distribution of theta (in the one-dimensional case), then theta
is simulated from a normal distribution with standard deviation
<code>np.adj</code> times <code class="reqn">s_{EAP}</code>.
</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_na.grid">na.grid</code></td>
<td>
<p>Range of the grid in normal approximation. Default is from
-5 to 5.</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_y">Y</code></td>
<td>
<p>Optional matrix of regressors</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_group">group</code></td>
<td>
<p>Optional vector of group identifiers</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_beta_groups">beta_groups</code></td>
<td>
<p>Logical indicating whether group specific beta coefficients
shall be estimated.</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_level">level</code></td>
<td>
<p>Confidence level</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_n.iter">n.iter</code></td>
<td>
<p>Number of iterations</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_n.burnin">n.burnin</code></td>
<td>
<p>Number of burnin-iterations</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_adj_mh">adj_MH</code></td>
<td>
<p>Adjustment factor for Metropolis-Hastings (MH) steps which controls
the variance of the proposal distribution for <code class="reqn">\theta</code>. Can be also
a vector of length equal to the number of persons.</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_adj_change_mh">adj_change_MH</code></td>
<td>
<p>Allowed change for MH adjustment factor after refreshing</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_refresh_mh">refresh_MH</code></td>
<td>
<p>Number of iterations after which the variance of the proposal
distribution should be updated</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_accrate_bound_mh">accrate_bound_MH</code></td>
<td>
<p>Bounds for target acceptance rates of sampled <code class="reqn">\theta</code>
values.</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_sample_integers">sample_integers</code></td>
<td>
<p>Logical indicating whether weights for complete cases
should be sampled in bootstrap</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_theta_init">theta_init</code></td>
<td>
<p>Optional matrix with initial <code class="reqn">\bold{\theta}</code> values</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_print_iter">print_iter</code></td>
<td>
<p>Print iteration progress every <code>print_iter</code>th iteration</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether iteration progress should be displayed.</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_calc_ic">calc_ic</code></td>
<td>
<p>Logical indicating whether information criteria should be computed.</p>
</td></tr>
<tr><td><code id="tam.pv_+3A_object">object</code></td>
<td>
<p>Object of class <code>tam.pv.mcmc</code></p>
</td></tr>
<tr><td><code id="tam.pv_+3A_x">x</code></td>
<td>
<p>Object of class <code>tam.pv.mcmc</code></p>
</td></tr>
<tr><td><code id="tam.pv_+3A_file">file</code></td>
<td>
<p>A file name in which the summary output will be written</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of <code>tam.pv</code> is a list with following entries:
</p>
<table>
<tr><td><code>pv</code></td>
<td>

<p>A data frame containing a person identifier (<code>pid</code>)
and plausible values denoted by <code>PVxx.Dimyy</code> which
is the <code>xx</code>th plausible value of
dimension <code>yy</code>.
</p>
</td></tr>
<tr><td><code>hwt</code></td>
<td>
<p>Individual posterior distribution evaluated at
the ability grid <code>theta</code>
</p>
</td></tr>
<tr><td><code>hwt1</code></td>
<td>
<p>Cumulated individual posterior distribution</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Simulated ability nodes</p>
</td></tr>
</table>
<p>The value of <code>tam.pv.mcmc</code> is a list containing entries
</p>
<table>
<tr><td><code>pv</code></td>
<td>
<p>Data frame containing plausible values</p>
</td></tr>
<tr><td><code>parameter_samples</code></td>
<td>
<p>Sampled regression parameters</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>Information criteria</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Estimate of regression parameters <code class="reqn">\bold{\beta}</code></p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>Estimate of residual variance matrix <code class="reqn">\bold{\Sigma}</code></p>
</td></tr>
<tr><td><code>correlation</code></td>
<td>
<p>Estimate of residual correlation matrix corresponding to
<code>variance</code></p>
</td></tr>
<tr><td><code>theta_acceptance_MH</code></td>
<td>
<p>Acceptance rates and acceptance MH factors for each
individual</p>
</td></tr>
<tr><td><code>theta_last</code></td>
<td>
<p>Last sampled <code class="reqn">\bold{\theta}</code> value</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Further values</p>
</td></tr>
</table>


<h3>References</h3>

<p>Adams, R. J., &amp; Wu, M. L. (2007). The mixed-coefficients multinomial logit model.
A generalized form of the Rasch model. In M. von Davier &amp; C. H. Carstensen (Eds.):
<em>Multivariate and mixture distribution Rasch models: Extensions and applications</em>
(pp. 55-76). New York: Springer.
<a href="https://doi.org/10.1007/978-0-387-49839-3_4">doi:10.1007/978-0-387-49839-3_4</a>
</p>
<p>Rubin, D. B. (1981). The Bayesian bootstrap. <em>The Annals of Statistics, 9</em>(1),
130-134.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+tam.latreg">tam.latreg</a></code> for further examples of
fitting latent regression models and drawing plausible values
from models which provides an individual likelihood as an input.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Dichotomous unidimensional data sim.rasch
#############################################################################

data(data.sim.rasch)
resp &lt;- data.sim.rasch[ 1:500, 1:15 ]  # select subsample of students and items

# estimate Rasch model
mod &lt;- TAM::tam.mml(resp)

# draw 5 plausible values without a normality
# assumption of the posterior and 2000 ability nodes
pv1a &lt;- TAM::tam.pv( mod, nplausible=5, ntheta=2000 )

# draw 5 plausible values with a normality
# assumption of the posterior and 500 ability nodes
pv1b &lt;- TAM::tam.pv( mod, nplausible=5, ntheta=500, normal.approx=TRUE )

# distribution of first plausible value from imputation pv1
hist(pv1a$pv$PV1.Dim1 )
# boxplot of all plausible values from imputation pv2
boxplot(pv1b$pv[, 2:6 ] )

## Not run: 
# draw plausible values with tam.pv.mcmc function
Y &lt;- matrix(1, nrow=500, ncol=1)
pv2 &lt;- TAM::tam.pv.mcmc( tamobj=mod, Y=Y, nplausible=5 )
str(pv2)

# summary output
summary(pv2)
# assessing convergence with traceplots
plot(pv2, ask=TRUE)

# use starting values for theta and MH factors which fulfill acceptance rates
# from previously fitted model
pv3 &lt;- TAM::tam.pv.mcmc( tamobj=mod, Y=Y, nplausible=5, theta_init=pv2$theta_last,
            adj_MH=pv2$theta_acceptance_MH$adj_MH )

#############################################################################
# EXAMPLE 2: Unidimensional plausible value imputation with
#            background variables; dataset data.pisaRead from sirt package
#############################################################################

data(data.pisaRead, package="sirt")
dat &lt;- data.pisaRead$data
  ##   &gt; colnames(dat)
  ##    [1] "idstud"   "idschool" "female"   "hisei"    "migra"    "R432Q01"
  ##    [7] "R432Q05"  "R432Q06"  "R456Q01"  "R456Q02"  "R456Q06"  "R460Q01"
  ##   [13] "R460Q05"  "R460Q06"  "R466Q02"  "R466Q03"  "R466Q06"

## Note that reading items have variable names starting with R4

# estimate 2PL model without covariates
items &lt;- grep("R4", colnames(dat) )    # select test items from data
mod2a &lt;- TAM::tam.mml.2pl( resp=dat[,items] )
summary(mod2a)

# fix item parameters for plausible value imputation
   # fix item intercepts by defining xsi.fixed
xsi0 &lt;- mod2a$xsi$xsi
xsi.fixed &lt;- cbind( seq(1,length(xsi0)), xsi0 )
   # fix item slopes using mod2$B
# matrix of latent regressors female, hisei and migra
Y &lt;- dat[, c("female", "hisei", "migra") ]
mod2b &lt;- TAM::tam.mml( resp=dat[,items], B=mod2a$B, xsi.fixed=xsi.fixed, Y=Y,
            pid=dat$idstud)

# plausible value imputation with normality assumption
# and ignoring uncertainty about regression coefficients
#    -&gt; the default is samp.regr=FALSE
pv2c &lt;- TAM::tam.pv( mod2b, nplausible=10, ntheta=500, normal.approx=TRUE )
# sampling of regression coefficients
pv2d &lt;- TAM::tam.pv( mod2b, nplausible=10, ntheta=500, samp.regr=TRUE)
# sampling of regression coefficients, normal approximation using the
# theta grid from the model
pv2e &lt;- TAM::tam.pv( mod2b, samp.regr=TRUE, theta.model=TRUE, normal.approx=TRUE)

#--- create list of multiply imputed datasets with plausible values
# define dataset with covariates to be matched
Y &lt;- dat[, c("idstud", "idschool", "female", "hisei", "migra") ]

# define plausible value names
pvnames &lt;- c("PVREAD")
# create list of imputed datasets
datlist1 &lt;- TAM::tampv2datalist( pv2e, pvnames=pvnames, Y=Y, Y.pid="idstud")
str(datlist1)

# create a matrix of covariates with different set of students than in pv2e
Y1 &lt;- Y[ seq( 1, 600, 2 ), ]
# create list of multiply imputed datasets
datlist2 &lt;- TAM::tampv2datalist( pv2e, pvnames=c("PVREAD"), Y=Y1, Y.pid="idstud")

#--- fit some models in lavaan and semTools
library(lavaan)
library(semTools)

#*** Model 1: Linear regression
lavmodel &lt;- "
   PVREAD ~ migra + hisei
   PVREAD ~~ PVREAD
        "
mod1 &lt;- semTools::lavaan.mi( lavmodel, data=datlist1, m=0)
summary(mod1, standardized=TRUE, rsquare=TRUE)

# apply lavaan for third imputed dataset
mod1a &lt;- lavaan::lavaan( lavmodel, data=datlist1[[3]] )
summary(mod1a, standardized=TRUE, rsquare=TRUE)

# compare with mod1 by looping over all datasets
mod1b &lt;- lapply( datlist1, FUN=function(dat0){
    mod1a &lt;- lavaan( lavmodel, data=dat0 )
    coef( mod1a)
        } )
mod1b
mod1b &lt;- matrix( unlist( mod1b ), ncol=length( coef(mod1)), byrow=TRUE )
mod1b
round( colMeans(mod1b), 3 )
coef(mod1)   # -&gt; results coincide

#*** Model 2: Path model
lavmodel &lt;- "
   PVREAD ~ migra + hisei
   hisei ~ migra
   PVREAD ~~ PVREAD
   hisei ~~ hisei
        "
mod2 &lt;- semTools::lavaan.mi( lavmodel, data=datlist1 )
summary(mod2, standardized=TRUE, rsquare=TRUE)
# fit statistics
inspect( mod2, what="fit")

#--- using mitools package
library(mitools)
# convert datalist into an object of class imputationList
datlist1a &lt;- mitools::imputationList( datlist1 )
# fit linear regression
mod1c &lt;- with( datlist1a, stats::lm( PVREAD ~ migra + hisei ) )
summary( mitools::MIcombine(mod1c) )

#--- using mice package
library(mice)
library(miceadds)
# convert datalist into a mids object
mids1 &lt;- miceadds::datalist2mids( datlist1 )
# fit linear regression
mod1c &lt;- with( mids1, stats::lm( PVREAD ~ migra + hisei ) )
summary( mice::pool(mod1c) )

#############################################################################
# EXAMPLE 3: Multidimensional plausible value imputation
#############################################################################

# (1) simulate some data
set.seed(6778)
library(mvtnorm)
N &lt;- 1000
Y &lt;- cbind( stats::rnorm(N), stats::rnorm(N) )
theta &lt;- mvtnorm::rmvnorm( N, mean=c(0,0), sigma=matrix( c(1,.5,.5,1), 2, 2 ))
theta[,1] &lt;- theta[,1] + .4 * Y[,1] + .2 * Y[,2]  # latent regression model
theta[,2] &lt;- theta[,2] + .8 * Y[,1] + .5 * Y[,2]  # latent regression model
I &lt;- 20
p1 &lt;- stats::plogis( outer( theta[,1], seq( -2, 2, len=I ), "-" ) )
resp1 &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
p1 &lt;- stats::plogis( outer( theta[,2], seq( -2, 2, len=I ), "-" ) )
resp2 &lt;- 1 * ( p1 &gt; matrix( stats::runif( N*I ), nrow=N, ncol=I ) )
resp &lt;- cbind(resp1,resp2)
colnames(resp) &lt;- paste("I", 1:(2*I), sep="")

# (2) define loading Matrix
Q &lt;- array( 0, dim=c( 2*I, 2 ))
Q[cbind(1:(2*I), c( rep(1,I), rep(2,I) ))] &lt;- 1

# (3) fit latent regression model
mod &lt;- TAM::tam.mml( resp=resp, Y=Y, Q=Q )

# (4) draw plausible values
pv1 &lt;- TAM::tam.pv( mod, theta.model=TRUE )

# (5) convert plausible values to list of imputed datasets
Y1 &lt;- data.frame(Y)
colnames(Y1) &lt;- paste0("Y",1:2)
pvnames &lt;- c("PVFA","PVFB")
# create list of imputed datasets
datlist1 &lt;- TAM::tampv2datalist( pv1, pvnames=pvnames, Y=Y1 )
str(datlist1)

# (6) apply statistical models
library(semTools)
# define linear regression
lavmodel &lt;- "
   PVFA ~ Y1 + Y2
   PVFA ~~ PVFA
        "
mod1 &lt;- semTools::lavaan.mi( lavmodel, data=datlist1 )
summary(mod1, standardized=TRUE, rsquare=TRUE)

# (7) draw plausible values with tam.pv.mcmc function
Y1 &lt;- cbind( 1, Y )
pv2 &lt;- TAM::tam.pv.mcmc( tamobj=mod, Y=Y1, n.iter=1000, n.burnin=200 )

# (8) group-specific plausible values
set.seed(908)
# create artificial grouping variable
group &lt;- sample( 1:3, N, replace=TRUE )
pv3 &lt;- TAM::tam.pv.mcmc( tamobj, Y=Y1, n.iter=1000, n.burnin=200, group=group )

# (9) plausible values with no fitted object in TAM

# fit IRT model without covariates
mod4a &lt;- TAM::tam.mml( resp=resp, Q=Q )
# define input for tam.pv.mcmc
tamobj1 &lt;- list( AXsi=mod4a$AXsi, B=mod4a$B, resp=mod4a$resp )
pmod4 &lt;- TAM::tam.pv.mcmc( tamobj1, Y=Y1 )

#############################################################################
# EXAMPLE 4: Plausible value imputation with measurement errors in covariates
#############################################################################

library(sirt)
set.seed(7756)
N &lt;- 2000    # number of persons
I &lt;- 10     # number of items

# simulate covariates
X &lt;- mvrnorm( N, mu=c(0,0), Sigma=matrix( c(1,.5,.5,1),2,2 ) )
colnames(X) &lt;- paste0("X",1:2)
# second covariate with measurement error with variance var.err
var.err &lt;- .3
X.err &lt;- X
X.err[,2] &lt;-X[,2] + rnorm(N, sd=sqrt(var.err) )
# simulate theta
theta &lt;- .5*X[,1] + .4*X[,2] + rnorm( N, sd=.5 )
# simulate item responses
itemdiff &lt;- seq( -2, 2, length=I)  # item difficulties
dat &lt;- sirt::sim.raschtype( theta, b=itemdiff )

#***********************
#*** Model 0: Regression model with true variables
mod0 &lt;- stats::lm( theta ~ X )
summary(mod0)

#***********************
#*** Model 1: latent regression model with true covariates X
xsi.fixed &lt;- cbind( 1:I, itemdiff )
mod1 &lt;- TAM::tam.mml( dat, xsi.fixed=xsi.fixed, Y=X)
summary(mod1)

# draw plausible values
res1a &lt;- TAM::tam.pv( mod1, normal.approx=TRUE, ntheta=200, samp.regr=TRUE)
# create list of multiply imputed datasets
library(miceadds)
datlist1a &lt;- TAM::tampv2datalist( res1a, Y=X )
imp1a &lt;- miceadds::datalist2mids( datlist1a )

# fit linear model
# linear regression with measurement errors in X
lavmodel &lt;- "
   PV.Dim1 ~ X1 + X2true
   X2true=~ 1*X2
   X2 ~~ 0.3*X2  #=var.err
   PV.Dim1 ~~ PV.Dim1
   X2true ~~ X2true
        "
mod1a &lt;- semTools::lavaan.mi( lavmodel, datlist1a)
summary(mod1a, standardized=TRUE, rsquare=TRUE)

#***********************
#*** Model 2: latent regression model with error-prone covariates X.err
mod2 &lt;- TAM::tam.mml( dat, xsi.fixed=xsi.fixed, Y=X.err)
summary(mod2)

#***********************
#*** Model 3: Adjustment of covariates

cov.X.err &lt;- cov( X.err )
# matrix of variance of measurement errors
measerr &lt;- diag( c(0,var.err) )
# true covariance matrix
cov.X &lt;- cov.X.err - measerr
# mean of X.err
mu &lt;- colMeans(X.err)
muM &lt;- matrix( mu, nrow=nrow(X.err), ncol=ncol(X.err), byrow=TRUE)
# reliability matrix
W &lt;- solve( cov.X.err ) %*% cov.X
ident &lt;- diag(2)
# adjusted scores of X
X.adj &lt;- ( X.err - muM ) %*% W   + muM %*% ( ident - W )

# fit latent regression model
mod3 &lt;- TAM::tam.mml( dat, xsi.fixed=xsi.fixed, Y=X.adj)
summary(mod3)

# draw plausible values
res3a &lt;- TAM::tam.pv( mod3, normal.approx=TRUE, ntheta=200, samp.regr=TRUE)

# create list of multiply imputed datasets
library(semTools)

#*** PV dataset 1
# datalist with error-prone covariates
datlist3a &lt;- TAM::tampv2datalist( res3a, Y=X.err )
# datalist with adjusted covariates
datlist3b &lt;- TAM::tampv2datalist( res3a, Y=X.adj )

# linear regression with measurement errors in X
lavmodel &lt;- "
   PV.Dim1 ~ X1 + X2true
   X2true=~ 1*X2
   X2 ~~ 0.3*X2  #=var.err
   PV.Dim1 ~~ PV.Dim1
   X2true ~~ X2true
        "
mod3a &lt;- semTools::lavaan.mi( lavmodel, datlist3a)
summary(mod3a, standardized=TRUE, rsquare=TRUE)

lavmodel &lt;- "
   PV.Dim1 ~ X1 + X2
   PV.Dim1 ~~ PV.Dim1
        "
mod3b &lt;- semTools::lavaan.mi( lavmodel, datlist3b)
summary(mod3b, standardized=TRUE, rsquare=TRUE)
#=&gt; mod3b leads to the correct estimate.

#*********************************************
# plausible value imputation for abilities and error-prone
# covariates using the mice package

library(mice)
library(miceadds)

# creating the likelihood for plausible value for abilities
mod11 &lt;- TAM::tam.mml( dat, xsi.fixed=xsi.fixed )
likePV &lt;- IRT.likelihood(mod11)
# creating the likelihood for error-prone covariate X2
lavmodel &lt;- "
  X2true=~ 1*X2
  X2 ~~ 0.3*X2
    "
mod12 &lt;- lavaan::cfa( lavmodel, data=as.data.frame(X.err) )
summary(mod12)
likeX2 &lt;- TAM::IRTLikelihood.cfa( data=X.err, cfaobj=mod12)
str(likeX2)

#-- create data input for mice package
data &lt;- data.frame( "PVA"=NA, "X1"=X[,1], "X2"=NA  )
vars &lt;- colnames(data)
V &lt;- length(vars)
predictorMatrix &lt;- 1 - diag(V)
rownames(predictorMatrix) &lt;- colnames(predictorMatrix) &lt;- vars
imputationMethod &lt;- rep("norm", V )
names(imputationMethod) &lt;- vars
imputationMethod[c("PVA","X2")] &lt;- "plausible.values"

#-- create argument lists for plausible value imputation
# likelihood and theta grid of plausible value derived from IRT model
like &lt;- list( "PVA"=likePV, "X2"=likeX2 )
theta &lt;- list( "PVA"=attr(likePV,"theta"), "X2"=attr(likeX2, "theta") )
#-- initial imputations
data.init &lt;- data
data.init$PVA &lt;- mod11$person$EAP
data.init$X2 &lt;- X.err[,"X2"]

#-- imputation using the mice and miceadds package
imp1 &lt;- mice::mice( as.matrix(data), predictorMatrix=predictorMatrix, m=4, maxit=6,
             method=imputationMethod,  allow.na=TRUE,
             theta=theta, like=like, data.init=data.init )
summary(imp1)

# compute linear regression
mod4a &lt;- with( imp1, stats::lm( PVA ~ X1 + X2 ) )
summary( mice::pool(mod4a) )

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.se'>
Standard Error Estimation
</h2><span id='topic+tam.se'></span><span id='topic+tam_mml_se_quick'></span><span id='topic+tam_latreg_se_quick'></span>

<h3>Description</h3>

<p>Standard error computation for objects of the classes <code>tam</code>
and <code>tam.mml</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.se(tamobj, item_pars=TRUE, ...)

tam_mml_se_quick(tamobj, numdiff.parm=0.001, item_pars=TRUE )

tam_latreg_se_quick(tamobj, numdiff.parm=0.001 )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.se_+3A_tamobj">tamobj</code></td>
<td>

<p>An object generated by <code>tam.mml</code>
</p>
</td></tr>
<tr><td><code id="tam.se_+3A_item_pars">item_pars</code></td>
<td>
<p>Logical indicating whether standard errors should also
be computed for item parameters</p>
</td></tr>
<tr><td><code id="tam.se_+3A_numdiff.parm">numdiff.parm</code></td>
<td>
<p>Step width parameter for numerical
differentiation
</p>
</td></tr>
<tr><td><code id="tam.se_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Covariances between parameters estimates are ignored in this standard
error calculation. The standard error is obtained by numerical
differentiation.
</p>


<h3>Value</h3>

<p>A list with following entries:
</p>
<table>
<tr><td><code>xsi</code></td>
<td>

<p>Data frame with <code class="reqn">\xi</code> parameters (<code>est</code>)
and their corresponding standard errors (<code>se</code>)
</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>

<p>Data frame with <code class="reqn">\beta</code> regression parameters and
their standard error estimates
</p>
</td></tr>
<tr><td><code>B</code></td>
<td>

<p>Data frame with loading  parameters and their
corresponding standard errors
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Standard error estimation for variances and covariances is not yet
implemented.
Standard error estimation for loading parameters in case of
<code>irtmodel='GPCM.design'</code> is highly experimental.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: 1PL model, data.sim.rasch
#############################################################################

data(data.sim.rasch)
# estimate Rasch model
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch[1:500,1:10])
# standard error estimation
se1 &lt;- TAM::tam.se( mod1 )
# proportion of standard errors estimated by 'tam.se' and 'tam.mml'
prop1 &lt;- se1$xsi$se / mod1$xsi$se
##   &gt; summary( prop1 )
##      Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##     1.030   1.034   1.035   1.036   1.039   1.042
##=&gt; standard errors estimated by tam.se are a bit larger

## Not run: 
#############################################################################
# EXAMPLE 2: Standard errors differential item functioning
#############################################################################
data(data.ex08)

formulaA &lt;- ~ item*female
resp &lt;- data.ex08[["resp"]]
facets &lt;- as.data.frame( data.ex08[["facets"]] )
# investigate DIF
mod &lt;- TAM::tam.mml.mfr( resp=resp, facets=facets, formulaA=formulaA )
summary(mod)
# estimate standard errors
semod &lt;- TAM::tam.se(mod)
prop1 &lt;- semod$xsi$se / mod$xsi$se
summary(prop1)
# plot differences in standard errors
plot( mod$xsi$se, semod$xsi$se, pch=16, xlim=c(0,.15), ylim=c(0,.15),
    xlab="Standard error 'tam.mml'", ylab="Standard error 'tam.se'" )
lines( c(-6,6), c(-6,6), col="gray")

round( cbind( mod$xsi, semod$xsi[,-1] ), 3 )
  ##                    xsi se.xsi   N    est    se
  ##   I0001         -1.956  0.092 500 -1.956 0.095
  ##   I0002         -1.669  0.085 500 -1.669 0.088
  ##   [...]
  ##   I0010          2.515  0.108 500  2.515 0.110
  ##   female1       -0.091  0.025 500 -0.091 0.041
  ##   I0001:female1 -0.051  0.070 500 -0.051 0.071
  ##   I0002:female1  0.085  0.067 500  0.085 0.068
  ##   [...]
  ##   I0009:female1 -0.019  0.068 500 -0.019 0.068
  ##
#=&gt; The largest discrepancy in standard errors is observed for the
#    main female effect (.041 in 'tam.se' instead of .025 in 'tam.mml')

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.threshold'>
Calculation of Thurstonian Thresholds
</h2><span id='topic+tam.threshold'></span>

<h3>Description</h3>

<p>This function estimates Thurstonian thresholds for item category
parameters of (generalized) partial credit models (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.threshold(tamobj, prob.lvl=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.threshold_+3A_tamobj">tamobj</code></td>
<td>

<p>Object of class <code>tam</code>
</p>
</td></tr>
<tr><td><code id="tam.threshold_+3A_prob.lvl">prob.lvl</code></td>
<td>

<p>A numeric specifying the probability level of the threshold.
The default is <code>prob.lvl=0.5</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function only works appropriately for unidimensional models
or between item multidimensional models.
</p>


<h3>Value</h3>

<p>A data frame with Thurstonian thresholds. Rows correspond to items and
columns to item steps.
</p>


<h3>See Also</h3>

<p>See the <span class="pkg">WrightMap</span> package and Example 3 for creating Wright maps
with fitted models in <span class="pkg">TAM</span>, see
<code><a href="WrightMap.html#topic+wrightMap">wrightMap</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: ordered data - Partial credit model
#############################################################################
data( data.gpcm )

# Model 1: partial credit model
mod1 &lt;- TAM::tam.mml( resp=data.gpcm,control=list( maxiter=200) )
summary(mod1)
  ##   Item Parameters -A*Xsi
  ##        item   N     M AXsi_.Cat1 AXsi_.Cat2 AXsi_.Cat3 B.Cat1.Dim1 B.Cat2.Dim1 B.Cat3.Dim1
  ##   1 Comfort 392 0.880     -1.302      1.154      3.881           1           2           3
  ##   2    Work 392 1.278     -1.706     -0.847      0.833           1           2           3
  ##   3 Benefit 392 1.163     -1.233     -0.404      1.806           1           2           3

# Calculation of Thurstonian thresholds
TAM::tam.threshold(mod1)
  ##                Cat1      Cat2     Cat3
  ##   Comfort -1.325226 2.0717468 3.139801
  ##   Work    -1.777679 0.6459045 1.971222
  ##   Benefit -1.343536 0.7491760 2.403168

## Not run: 
#############################################################################
# EXAMPLE 2: Multidimensional model data.math
#############################################################################

library(sirt)
data(data.math, package="sirt")
dat &lt;- data.math$data
# select items
items1 &lt;- grep("M[A-D]", colnames(dat), value=TRUE)
items2 &lt;- grep("M[H-I]", colnames(dat), value=TRUE)
# select dataset
dat &lt;- dat[ c(items1,items2)]
# create Q-matrix
Q &lt;- matrix( 0, nrow=ncol(dat), ncol=2 )
Q[ seq(1,length(items1) ), 1 ] &lt;- 1
Q[ length(items1) + seq(1,length(items2) ), 2 ] &lt;- 1

# fit two-dimensional model
mod1 &lt;- TAM::tam.mml( dat, Q=Q )
# compute thresholds (specify a probability level of .625)
tmod1 &lt;- TAM::tam.threshold( mod1, prob.lvl=.625 )

#############################################################################
# EXAMPLE 3: Creating Wright maps with the WrightMap package
#############################################################################

library(WrightMap)
# For conducting Wright maps in combination with TAM, see
# http://wrightmap.org/post/100850738072/using-wrightmap-with-the-tam-package
data(sim.rasch)
dat &lt;- sim.rasch

# estimate Rasch model in TAM
mod1 &lt;- TAM::tam.mml(dat)
summary(mod1)

#--- A: creating a Wright map with WLEs

# compute WLE
wlemod1 &lt;- TAM::tam.wle(mod1)$theta
# extract thresholds
tmod1 &lt;- TAM::tam.threshold(mod1)
# create Wright map
WrightMap::wrightMap( thetas=wlemod1, thresholds=tmod1, label.items.srt=-90)

#--- B: creating a Wright Map with population distribution

# extract ability distribution and replicate observations
uni.proficiency &lt;- rep( mod1$theta[,1], round( mod1$pi.k * mod1$ic$n) )
# draw WrightMap
WrightMap::wrightMap( thetas=uni.proficiency, thresholds=tmod1, label.items.rows=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='tam.wle'>
Weighted Likelihood Estimation and Maximum Likelihood Estimation of
Person Parameters
</h2><span id='topic+tam.wle'></span><span id='topic+tam.mml.wle'></span><span id='topic+tam.mml.wle2'></span><span id='topic+tam_jml_wle'></span><span id='topic+print.tam.wle'></span><span id='topic+summary.tam.wle'></span>

<h3>Description</h3>

<p>Compute the weighted likelihood estimator (Warm, 1989)
for objects of classes <code>tam</code>, <code>tam.mml</code> and <code>tam.jml</code>,
respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tam.wle(tamobj, ...)

tam.mml.wle( tamobj, score.resp=NULL, WLE=TRUE, adj=.3, Msteps=20,
       convM=.0001, progress=TRUE,    output.prob=FALSE )

tam.mml.wle2(tamobj, score.resp=NULL, WLE=TRUE, adj=0.3, Msteps=20, convM=1e-04,
        progress=TRUE, output.prob=FALSE, pid=NULL, theta_init=NULL )

tam_jml_wle(tamobj, resp, resp.ind, A, B, nstud, nitems, maxK, convM,
    PersonScores, theta, xsi, Msteps, WLE=FALSE, theta.fixed=NULL, progress=FALSE,
    output.prob=TRUE, damp=0, version=2)

## S3 method for class 'tam.wle'
summary(object, file=NULL, digits=3, ...)

## S3 method for class 'tam.wle'
print(x, digits=3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tam.wle_+3A_tamobj">tamobj</code></td>
<td>

<p>An object generated by <code>tam.mml</code> or <code>tam.jml</code>. The object can also
be a list containing (at least the) inputs <code>AXsi</code>, <code>B</code> and
<code>resp</code> and therefore allows WLE estimation without fitting models
in <span class="pkg">TAM</span>.
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_score.resp">score.resp</code></td>
<td>
<p>An optional data frame for which WLEs or MLEs
should be calculated. In case of the default <code>NULL</code>,
<code>resp</code> from <code>tamobj</code> (i.e. <code>tamobj$resp</code>) is chosen.
Note that items in <code>score.resp</code> must be the same (and in the
same order) as in <code>tamobj$resp</code>.
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_wle">WLE</code></td>
<td>

<p>A logical indicating whether the weighted likelihood estimate
(WLE, <code>WLE=TRUE</code>) or the maximum likelihood estimate (MLE, <code>WLE=FALSE</code>)
should be used.
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_adj">adj</code></td>
<td>

<p>Adjustment in MLE estimation for extreme scores (i.e. all or none
items were correctly solved). This argument is not used if
<code>WLE=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_msteps">Msteps</code></td>
<td>

<p>Maximum number of iterations
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_convm">convM</code></td>
<td>

<p>Convergence criterion
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_progress">progress</code></td>
<td>
<p>Logical indicating whether progress should be displayed.</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_output.prob">output.prob</code></td>
<td>
<p>Logical indicating whether evaluated probabilities should
be included in the list of outputs.</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_pid">pid</code></td>
<td>
<p>Optional vector of person identifiers</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_theta_init">theta_init</code></td>
<td>
<p>Initial theta values</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_resp">resp</code></td>
<td>
<p>Data frame with item responses (only for <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_resp.ind">resp.ind</code></td>
<td>
<p>Data frame with response indicators (only for <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_a">A</code></td>
<td>
<p>Design matrix <code class="reqn">A</code> (applies only to <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_b">B</code></td>
<td>
<p>Design matrix <code class="reqn">B</code> (applies only to <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_nstud">nstud</code></td>
<td>
<p>Number of persons (applies only to <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_nitems">nitems</code></td>
<td>
<p>Number of items (applies only to <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_maxk">maxK</code></td>
<td>
<p>Maximum item score (applies only to <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_personscores">PersonScores</code></td>
<td>
<p>A vector containing the sufficient statistics for the
person parameters (applies only to <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_theta">theta</code></td>
<td>
<p>Initial <code class="reqn">\theta</code> estimate (applies only to <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_xsi">xsi</code></td>
<td>
<p>Parameter vector <code class="reqn">\xi</code> (applies only to <code>tam.jml.WLE</code>)
</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_theta.fixed">theta.fixed</code></td>
<td>
<p>Matrix for fixed person parameters <code class="reqn">\theta</code>. The first
column includes the index whereas the second column includes
the fixed value.</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_damp">damp</code></td>
<td>
<p>Numeric value between 0 and 1 indicating amount of dampening
increments in <code class="reqn">\theta</code> estimates during iterations</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_version">version</code></td>
<td>
<p>Integer with possible values 2 or 3. In case of missing item responses,
<code>version=3</code> will typically be more efficient.</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_object">object</code></td>
<td>
<p>Object of class <code>tam.wle</code></p>
</td></tr>
<tr><td><code id="tam.wle_+3A_x">x</code></td>
<td>
<p>Object of class <code>tam.wle</code></p>
</td></tr>
<tr><td><code id="tam.wle_+3A_file">file</code></td>
<td>
<p>Optional file name in which the object summary should be written.</p>
</td></tr>
<tr><td><code id="tam.wle_+3A_digits">digits</code></td>
<td>
<p>Number of digits for rounding</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>tam.wle.mml</code> and <code>tam.wle.mml2</code>, it is a data frame with following
columns:
</p>
<table>
<tr><td><code>pid</code></td>
<td>
<p>Person identifier</p>
</td></tr>
<tr><td><code>PersonScores</code></td>
<td>
<p>Score of each person</p>
</td></tr>
<tr><td><code>PersonMax</code></td>
<td>
<p>Maximum score of each person</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Weighted likelihood estimate (WLE) or MLE</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>Standard error of the WLE or MLE</p>
</td></tr>
<tr><td><code>WLE.rel</code></td>
<td>
<p>WLE reliability (same value for all persons)</p>
</td></tr> </table>
<p><br />
</p>
<p>For <code>tam.jml.WLE</code>, it is a list with following entries:
</p>
<table>
<tr><td><code>theta</code></td>
<td>
<p>Weighted likelihood estimate (WLE) or MLE</p>
</td></tr>
<tr><td><code>errorWLE</code></td>
<td>
<p>Standard error of the WLE or MLE</p>
</td></tr>
<tr><td><code>meanChangeWLE</code></td>
<td>
<p>Mean change between updated and previous ability
estimates from last iteration</p>
</td></tr>
</table>


<h3>References</h3>

<p>Penfield, R. D., &amp; Bergeron, J. M. (2005). Applying a weighted maximum
likelihood latent trait estimator to the generalized partial credit model.
<em>Applied Psychological Measurement, 29</em>, 218-233.
</p>
<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item
response theory. <em>Psychometrika, 54</em>, 427-450.
<a href="https://doi.org/10.1007/BF02294627">doi:10.1007/BF02294627</a>
</p>


<h3>See Also</h3>

<p>See the <code>PP::PP_gpcm</code> function
in the <span class="pkg">PP</span> package for more person
parameter estimators for the partial credit model (Penfield &amp; Bergeron, 2005).
</p>
<p>See the S3 method <code><a href="#topic+IRT.factor.scores.tam">IRT.factor.scores.tam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: 1PL model, data.sim.rasch
#############################################################################

data(data.sim.rasch)
# estimate Rasch model
mod1 &lt;- TAM::tam.mml(resp=data.sim.rasch)
# WLE estimation
wle1 &lt;- TAM::tam.wle( mod1 )
  ## WLE Reliability=0.894

print(wle1)
summary(wle1)

# scoring for a different dataset containing same items (first 10 persons in sim.rasch)
wle2 &lt;- TAM::tam.wle( mod1, score.resp=data.sim.rasch[1:10,])

#--- WLE estimation without using a TAM object

#* create an input list
input &lt;- list( resp=data.sim.rasch, AXsi=mod1$AXsi, B=mod1$B )
#* estimation
wle2b &lt;- TAM::tam.mml.wle2( input )

## Not run: 
#############################################################################
# EXAMPLE 2: 3-dimensional Rasch model | data.read from sirt package
#############################################################################

data(data.read, package="sirt")
# define Q-matrix
Q &lt;- matrix(0,12,3)
Q[ cbind( 1:12, rep(1:3,each=4) ) ] &lt;- 1
# redefine data: create some missings for first three cases
resp &lt;- data.read
resp[1:2, 5:12] &lt;- NA
resp[3,1:4] &lt;- NA
  ##   &gt; head(resp)
  ##      A1 A2 A3 A4 B1 B2 B3 B4 C1 C2 C3 C4
  ##   2   1  1  1  1 NA NA NA NA NA NA NA NA
  ##   22  1  1  0  0 NA NA NA NA NA NA NA NA
  ##   23 NA NA NA NA  1  0  1  1  1  1  1  1
  ##   41  1  1  1  1  1  1  1  1  1  1  1  1
  ##   43  1  0  0  1  0  0  1  1  1  0  1  0
  ##   63  1  1  0  0  1  0  1  1  1  1  1  1

# estimate 3-dimensional Rasch model
mod &lt;- TAM::tam.mml( resp=resp, Q=Q, control=list(snodes=1000,maxiter=50) )
summary(mod)

# WLE estimates
wmod &lt;- TAM::tam.wle(mod, Msteps=3)
summary(wmod)
  ##   head(round(wmod,2))
  ##      pid N.items PersonScores.Dim01 PersonScores.Dim02 PersonScores.Dim03
  ##   2    1       4                3.7                0.3                0.3
  ##   22   2       4                2.0                0.3                0.3
  ##   23   3       8                0.3                3.0                3.7
  ##   41   4      12                3.7                3.7                3.7
  ##   43   5      12                2.0                2.0                2.0
  ##   63   6      12                2.0                3.0                3.7
  ##      PersonMax.Dim01 PersonMax.Dim02 PersonMax.Dim03 theta.Dim01 theta.Dim02
  ##   2              4.0             0.6             0.6        1.06          NA
  ##   22             4.0             0.6             0.6       -0.96          NA
  ##   23             0.6             4.0             4.0          NA       -0.07
  ##   41             4.0             4.0             4.0        1.06        0.82
  ##   43             4.0             4.0             4.0       -0.96       -1.11
  ##   63             4.0             4.0             4.0       -0.96       -0.07
  ##      theta.Dim03 error.Dim01 error.Dim02 error.Dim03 WLE.rel.Dim01
  ##   2           NA        1.50          NA          NA          -0.1
  ##   22          NA        1.11          NA          NA          -0.1
  ##   23        0.25          NA        1.17        1.92          -0.1
  ##   41        0.25        1.50        1.48        1.92          -0.1
  ##   43       -1.93        1.11        1.10        1.14          -0.1

# (1) Note that estimated WLE reliabilities are not trustworthy in this example.
# (2) If cases do not possess any observations on dimensions, then WLEs
#     and their corresponding standard errors are set to NA.

#############################################################################
# EXAMPLE 3: Partial credit model | Comparison WLEs with PP package
#############################################################################

library(PP)
data(data.gpcm)
dat &lt;- data.gpcm
I &lt;- ncol(dat)

#****************************************
#*** Model 1: Partial Credit Model

# estimation in TAM
mod1 &lt;- TAM::tam.mml( dat )
summary(mod1)

#-- WLE estimation in TAM
tamw1 &lt;- TAM::tam.wle( mod1 )

#-- WLE estimation with PP package
# convert AXsi parameters into thres parameters for PP
AXsi0 &lt;- - mod1$AXsi[,-1]
b &lt;- AXsi0
K &lt;- ncol(AXsi0)
for (cc in 2:K){
    b[,cc] &lt;- AXsi0[,cc] - AXsi0[,cc-1]
}
# WLE estimation in PP
ppw1 &lt;- PP::PP_gpcm( respm=as.matrix(dat),  thres=t(b), slopes=rep(1,I) )

#-- compare results
dfr &lt;- cbind( tamw1[, c("theta","error") ], ppw1$resPP)
head( round(dfr,3))
  ##      theta error resPP.estimate resPP.SE nsteps
  ##   1 -1.006 0.973         -1.006    0.973      8
  ##   2 -0.122 0.904         -0.122    0.904      8
  ##   3  0.640 0.836          0.640    0.836      8
  ##   4  0.640 0.836          0.640    0.836      8
  ##   5  0.640 0.836          0.640    0.836      8
  ##   6 -1.941 1.106         -1.941    1.106      8
plot( dfr$resPP.estimate, dfr$theta, pch=16, xlab="PP", ylab="TAM")
lines( c(-10,10), c(-10,10) )

#****************************************
#*** Model 2: Generalized partial Credit Model

# estimation in TAM
mod2 &lt;- TAM::tam.mml.2pl( dat, irtmodel="GPCM" )
summary(mod2)

#-- WLE estimation in TAM
tamw2 &lt;- TAM::tam.wle( mod2 )

#-- WLE estimation in PP
# convert AXsi parameters into thres and slopes parameters for PP
AXsi0 &lt;- - mod2$AXsi[,-1]
slopes &lt;- mod2$B[,2,1]
K &lt;- ncol(AXsi0)
slopesM &lt;- matrix( slopes, I, ncol=K )
AXsi0 &lt;- AXsi0 / slopesM
b &lt;- AXsi0
for (cc in 2:K){
    b[,cc] &lt;- AXsi0[,cc] - AXsi0[,cc-1]
}
# estimation in PP
ppw2 &lt;- PP::PP_gpcm( respm=as.matrix(dat),  thres=t(b), slopes=slopes )

#-- compare results
dfr &lt;- cbind( tamw2[, c("theta","error") ], ppw2$resPP)
head( round(dfr,3))
  ##      theta error resPP.estimate resPP.SE nsteps
  ##   1 -0.476 0.971         -0.476    0.971     13
  ##   2 -0.090 0.973         -0.090    0.973     13
  ##   3  0.311 0.960          0.311    0.960     13
  ##   4  0.311 0.960          0.311    0.960     13
  ##   5  1.749 0.813          1.749    0.813     13
  ##   6 -1.513 1.032         -1.513    1.032     13

## End(Not run)
</code></pre>

<hr>
<h2 id='tamaan'>
Wrapper Function for <span class="pkg">TAM</span> Language
</h2><span id='topic+tamaan'></span><span id='topic+summary.tamaan'></span><span id='topic+print.tamaan'></span>

<h3>Description</h3>

<p>This function is a convenience wrapper function for
several item response models in <span class="pkg">TAM</span>. Using the
<code><a href="#topic+tamaanify">tamaanify</a></code> framework, multidimensional item response models,
latent class models, located and ordered latent class models
and mixture item response models can be estimated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tamaan(tammodel, resp, tam.method=NULL, control=list(), doparse=TRUE, ...)

## S3 method for class 'tamaan'
summary(object,file=NULL,...)

## S3 method for class 'tamaan'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tamaan_+3A_tammodel">tammodel</code></td>
<td>

<p>String for specification in <span class="pkg">TAM</span>, see also <code><a href="#topic+tamaanify">tamaanify</a></code>.
</p>
</td></tr>
<tr><td><code id="tamaan_+3A_resp">resp</code></td>
<td>

<p>Dataset with item responses
</p>
</td></tr>
<tr><td><code id="tamaan_+3A_tam.method">tam.method</code></td>
<td>

<p>One of the <span class="pkg">TAM</span> methods <code>tam.mml</code>, <code>tam.mml.2pl</code>
or <code>tam.mml.3pl</code>.
</p>
</td></tr>
<tr><td><code id="tamaan_+3A_control">control</code></td>
<td>

<p>List with control arguments. See <code><a href="#topic+tam.mml">tam.mml</a></code>.
</p>
</td></tr>
<tr><td><code id="tamaan_+3A_doparse">doparse</code></td>
<td>
<p>Optional logical indicating whether <code>lavmodel</code>
should be parsed for <code>DO</code> statements, see <code><a href="#topic+doparse">doparse</a></code>.
</p>
</td></tr>
<tr><td><code id="tamaan_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed to
<code>tam.mml</code>, <code>tam.mml.2pl</code>
or <code>tam.mml.3pl</code>.
</p>
</td></tr>
<tr><td><code id="tamaan_+3A_object">object</code></td>
<td>

<p>Object of class <code>tamaan</code>
</p>
</td></tr>
<tr><td><code id="tamaan_+3A_file">file</code></td>
<td>

<p>A file name in which the summary output will be written
</p>
</td></tr>
<tr><td><code id="tamaan_+3A_x">x</code></td>
<td>
<p>Object of class <code>tamaan</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Values generated by <code>tam.mml</code>, <code>tam.mml.2pl</code>
or <code>tam.mml.3pl</code>. In addition, the list also contains the (optional) entries
</p>
<table>
<tr><td><code>tamaanify</code></td>
<td>
<p>Output produced by <code><a href="#topic+tamaanify">tamaanify</a></code></p>
</td></tr>
<tr><td><code>lcaprobs</code></td>
<td>
<p>Matrix with probabilities for latent class models</p>
</td></tr>
<tr><td><code>locs</code></td>
<td>
<p>Matrix with cluster locations (for <code>TYPE="LOCLCA"</code>)
</p>
</td></tr>
<tr><td><code>probs_MIXTURE</code></td>
<td>
<p>Class probabilities (for <code>TYPE="MIXTURE"</code>)</p>
</td></tr>
<tr><td><code>moments_MIXTURE</code></td>
<td>
<p>Distribution parameters (for <code>TYPE="MIXTURE"</code>)</p>
</td></tr>
<tr><td><code>itempartable_MIXTURE</code></td>
<td>
<p>Item parameters (for <code>TYPE="MIXTURE"</code>)</p>
</td></tr>
<tr><td><code>ind_classprobs</code></td>
<td>
<p>Individual posterior probabilities for
latent classes (for <code>TYPE="MIXTURE"</code>)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>See <code><a href="#topic+tamaanify">tamaanify</a></code> for more details about model specification
using <code>tammodel</code>.
</p>
<p>See <code><a href="#topic+tam.mml">tam.mml</a></code> or <code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code>
for more examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#############################################################################
# EXAMPLE 1: Examples dichotomous data data.read
#############################################################################

library(sirt)
data(data.read,package="sirt")
dat &lt;- data.read

#*********************************************************************
#*** Model 1: Rasch model

tammodel &lt;- "
LAVAAN MODEL:
  F1=~ A1__C4
  F1 ~~ F1
ITEM TYPE:
  ALL(Rasch);
    "
# estimate model
mod1 &lt;- TAM::tamaan( tammodel, resp=dat)
summary(mod1)

#*********************************************************************
#*** Model 2: 2PL model with some selected items

tammodel &lt;- "
LAVAAN MODEL:
  F1=~ A1__B1 + B3 + C1__C3
  F1 ~~ F1
    "
mod2 &lt;- TAM::tamaan( tammodel, resp=dat)
summary(mod2)

#*********************************************************************
#*** Model 3: Multidimensional IRT model

tammodel &lt;- "
LAVAAN MODEL:
  G=~ A1__C4
  F1=~ A1__B4
  F2=~ C1__C4
  F1 ~~ F2
  # specify fixed entries in covariance matrix
  F1 ~~ 1*F1
  F2 ~~ 1*F2
  G  ~~ 0*F1
  G  ~~ 0.3*F2
  G  ~~ 0.7*G
    "
mod3 &lt;- TAM::tamaan( tammodel, resp=dat, control=list(maxiter=30))
summary(mod3)

#*********************************************************************
#*** Model 4: Some linear constraints for item slopes and intercepts

tammodel &lt;- "
LAVAAN MODEL:
  F=~ lam1__lam10*A1__C2
  F=~ 0.78*C3
  F ~~ F
  A1 | a1*t1
  A2 | a2*t1
  A3 | a3*t1
  A4 | a4*t1
  B1 | b1*t1
  B2 | b2*t1
  B3 | b3*t1
  C1 | t1
MODEL CONSTRAINT:
  # defined parameters
  # only linear combinations are permitted
  b2==1.3*b1 + (-0.6)*b3
  a1==q1
  a2==q2 + t
  a3==q1 + 2*t
  a4==q2 + 3*t
  # linear constraints for loadings
  lam2==1.1*lam1
  lam3==0.9*lam1 + (-.1)*lam0
  lam8==lam0
  lam9==lam0
    "
mod4 &lt;- TAM::tamaan( tammodel, resp=dat, control=list(maxiter=5) )
summary(mod4)

#*********************************************************************
#*** Model 5: Latent class analysis with three classes

tammodel &lt;- "
ANALYSIS:
  TYPE=LCA;
  NCLASSES(3);   # 3 classes
  NSTARTS(5,20); # 5 random starts with 20 iterations
LAVAAN MODEL:
  F=~ A1__C4
    "
mod5 &lt;- TAM::tamaan( tammodel, resp=dat, control=list(maxiter=100)  )
summary(mod5)

#*********************************************************************
#*** Model 6: Ordered latent class analysis with three classes

tammodel &lt;- "
ANALYSIS:
  TYPE=OLCA;
  NCLASSES(3);    # 3 classes
  NSTARTS(20,40); # 20 random starts with 40 iterations
LAVAAN MODEL:
  F=~ A1__C4
    "
mod6 &lt;- TAM::tamaan( tammodel, dat )
summary(mod6)

#*********************************************************************
#*** Model 7: Unidimensional located latent class model with three classes

tammodel &lt;- "
ANALYSIS:
  TYPE=LOCLCA;
  NCLASSES(3)
  NSTARTS(10,40)
LAVAAN MODEL:
  F=~ A1__C4
  B2 | 0*t1
    "
mod7 &lt;- TAM::tamaan( tammodel, resp=dat)
summary(mod7)

#*********************************************************************
#*** Model 8: Two-dimensional located latent class analysis with some
#             priors and equality constraints among thresholds

tammodel &lt;- "
ANALYSIS:
  TYPE=LOCLCA;
  NCLASSES(4);
  NSTARTS(10,20);
LAVAAN MODEL:
  AB=~ A1__B4
  C=~ C1__C4
  A1 | a1diff*t1
  B2 | 0*t1
  C2 | 0*t1
  B1 | a1diff*t1
MODEL PRIOR:
  # prior distributions for cluster locations
  DO2(1,4,1,1,2,1)
    Cl%1_Dim%2 ~ N(0,2);
  DOEND
    "
# estimate model
mod8 &lt;- TAM::tamaan( tammodel, resp=dat )
summary(mod8)

#*********************************************************************
#*** Model 9: Two-dimensional model with constraints on parameters

tammodel &lt;- "
LAVAAN MODEL:
  FA=~ A1+b*A2+A3+d*A4
  FB=~ B1+b*B2+B3+d*B4
  FA ~~ 1*FA
  FA ~~ FB
  FB ~~ 1*FB
  A1 | c*t1
  B1 | c*t1
  A2 | .7*t1
    "
# estimate model
mod9 &lt;- TAM::tamaan( tammodel, resp=dat, control=list(maxiter=30) )
summary(mod9)

#############################################################################
# EXAMPLE 2: Examples polytomous data | data.Students
#############################################################################

library(CDM)
data( data.Students, package="CDM")
dat &lt;- data.Students[,3:13]
  ##   &gt; colnames(dat)
  ##    [1] "act1" "act2" "act3" "act4" "act5" "sc1"  "sc2"  "sc3"  "sc4"  "mj1"  "mj2"

#*********************************************************************
#*** Model 1: Two-dimensional generalized partial credit model

tammodel &lt;- "
LAVAAN MODEL:
  FA=~ act1__act5
  FS=~ sc1__sc4
  FA ~~ 1*FA
  FS ~~ 1*FS
  FA ~~ FS
    "
# estimate model
mod1 &lt;- TAM::tamaan( tammodel, dat, control=list(maxiter=10)  )
summary(mod1)

#*********************************************************************
#*** Model 2: Two-dimensional model, some constraints

tammodel &lt;- "
LAVAAN MODEL:
  FA=~ a1__a4*act1__act4 + 0.89*act5
  FS=~ 1*sc1 + sc2__sc4
  FA ~~ FA
  FS ~~ FS
  FA ~~ FS
  # some equality constraints
  act1 + act3 | a13_t1 * t1
  act1 + act3 | a13_t2 * t2
    "
# only create design matrices with tamaanify
mod2 &lt;- TAM::tamaanify( tammodel, dat  )
mod2$lavpartable
# estimate model (only few iterations as a test)
mod2 &lt;- TAM::tamaan( tammodel, dat, control=list(maxiter=10)  )
summary(mod2)

#*********************************************************************
#*** Model 3: Two-dimensional model, some more linear constraints

tammodel &lt;- "
LAVAAN MODEL:
  FA=~ a1__a5*act1__act5
  FS=~ b1__b4*sc1__sc4
  FA ~~ 1*FA
  FA ~~ FS
  FS ~~ 1*FS
  act1 + act3 | a13_t1 * t1
  act1 + act3 | a13_t2 * t2
MODEL CONSTRAINT:
  a1==q0
  a2==q0
  a3==q0    + q1
  a4==q2
  a5==q2 + q1
    "
# estimate
mod3 &lt;- TAM::tamaan( tammodel, dat, control=list(maxiter=300 )  )
summary(mod3)

#*********************************************************************
#*** Model 4: Latent class analysis with three latent classes

tammodel &lt;- "
ANALYSIS:
  TYPE=LCA;
  NCLASSES(3);    # 3 classes
  NSTARTS(10,30); # 10 random starts with 30 iterations
LAVAAN MODEL:
  F=~ act1__act5
    "
# estimate model
mod4 &lt;- TAM::tamaan( tammodel, resp=dat)
summary(mod4)

#*********************************************************************
#*** Model 5: Partial credit model with "PCM2" parametrization

# select data
dat1 &lt;- dat[, paste0("act",1:5) ]
# specify tamaan model
tammodel &lt;- "
  LAVAAN MODEL:
    F=~ act1__act5
    F ~~ F
    # use DO statement as shortages
    DO(1,5,1)
      act% | b%_1 * t1
      act% | b%_2 * t2
    DOEND
  MODEL CONSTRAINT:
    DO(1,5,1)
      b%_1==delta% + tau%_1
      b%_2==2*delta%
    DOEND
  ITEM TYPE:
    ALL(PCM)
  "
# estimate model
mod5 &lt;- TAM::tamaan( tammodel, dat1 )
summary(mod5)
# compare with PCM2 parametrization in tam.mml
mod5b &lt;- TAM::tam.mml( dat1, irtmodel="PCM2" )
summary(mod5b)

#*********************************************************************
#*** Model 6: Rating scale model

# select data
dat1 &lt;- dat[, paste0("sc",1:4) ]
psych::describe(dat1)

# specify tamaan model
tammodel &lt;- "
  LAVAAN MODEL:
    F=~ sc1__sc4
    F ~~ F
    # use DO statement as shortages
    DO(1,4,1)
      sc% | b%_1 * t1
      sc% | b%_2 * t2
      sc% | b%_3 * t3
    DOEND
  MODEL CONSTRAINT:
    DO(1,4,1)
      b%_1==delta% + step1
      b%_2==2*delta% + step1 + step2
      b%_3==3*delta%
    DOEND
  ITEM TYPE:
    ALL(PCM)
  "
# estimate model
mod6 &lt;- TAM::tamaan( tammodel, dat1 )
summary(mod6)
# compare with RSM in tam.mml
mod6b &lt;- TAM::tam.mml( dat1, irtmodel="RSM" )
summary(mod6b)

#*********************************************************************
#*** Model 7: Partial credit model with Fourier basis for
#             item intercepts (Thissen, Cai &amp; Bock, 2010)
# see ?tamaanify manual

# define tamaan model
tammodel &lt;- "
LAVAAN MODEL:
   mj=~ mj1__mj4
   mj ~~ 1*mj
ITEM TYPE:
  mj1(PCM,2)
  mj2(PCM,3)
  mj3(PCM)
  mj4(PCM,1)
   "
# estimate model
mod7 &lt;- TAM::tamaan( tammodel, dat )
summary(mod7)
# -&gt; This function can also be applied for the generalized partial credit
#    model (GPCM).

#############################################################################
# EXAMPLE 3: Rasch model and mixture Rasch model (Geiser &amp; Eid, 2010)
#############################################################################

data(data.geiser, package="TAM")
dat &lt;- data.geiser

#*********************************************************************
#*** Model 1: Rasch model
tammodel &lt;- "
LAVAAN MODEL:
  F=~ mrt1__mrt6
  F ~~ F
ITEM TYPE:
  ALL(Rasch);
    "
mod1 &lt;- TAM::tamaan( tammodel, resp=dat  )
summary(mod1)

#*********************************************************************
#*** Model 2: Mixed Rasch model with two classes
tammodel &lt;- "
ANALYSIS:
  TYPE=MIXTURE ;
  NCLASSES(2);
  NSTARTS(20,25);
LAVAAN MODEL:
  F=~ mrt1__mrt6
  F ~~ F
ITEM TYPE:
  ALL(Rasch);
    "
mod2 &lt;- TAM::tamaan( tammodel, resp=dat  )
summary(mod2)

# plot item parameters
ipars &lt;- mod2$itempartable_MIXTURE[ 1:6, ]
plot( 1:6, ipars[,3], type="o", ylim=c(-3,2), pch=16,
        xlab="Item", ylab="Item difficulty")
lines( 1:6, ipars[,4], type="l", col=2, lty=2)
points( 1:6, ipars[,4],  col=2, pch=2)

# extract individual posterior distribution
post2 &lt;- IRT.posterior(mod2)
str(post2)
# num [1:519, 1:30] 0.000105 0.000105 0.000105 0.000105 0.000105 ...
# - attr(*, "theta")=num [1:30, 1:30] 1 0 0 0 0 0 0 0 0 0 ...
# - attr(*, "prob.theta")=num [1:30, 1] 1.21e-05 2.20e-04 2.29e-03 1.37e-02 4.68e-02 ...
# - attr(*, "G")=num 1

# There are 2 classes and 15 theta grid points for each class
# The loadings of the theta grid on items are as follows
mod2$E[1,2,,"mrt1_F_load_Cl1"]
mod2$E[1,2,,"mrt1_F_load_Cl2"]

# compute individual posterior probability for class 1 (first 15 columns)
round( rowSums( post2[, 1:15] ), 3 )
# columns 16 to 30 refer to class 2


## End(Not run)
</code></pre>

<hr>
<h2 id='tamaanify'>
Function for Parsing <span class="pkg">TAM</span> Input
</h2><span id='topic+tamaanify'></span>

<h3>Description</h3>

<p>This function parses a so called <code>tammodel</code> which is a
string used for model estimation in <span class="pkg">TAM</span>.
The function is based on the <span class="pkg">lavaan</span> syntax and operates
at the extension <code><a href="#topic+lavaanify.IRT">lavaanify.IRT</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tamaanify(tammodel, resp, tam.method=NULL, doparse=TRUE )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tamaanify_+3A_tammodel">tammodel</code></td>
<td>

<p>String for model definition following the rules described in Details and
in Examples.
</p>
</td></tr>
<tr><td><code id="tamaanify_+3A_resp">resp</code></td>
<td>

<p>Item response dataset
</p>
</td></tr>
<tr><td><code id="tamaanify_+3A_tam.method">tam.method</code></td>
<td>

<p>One of the <span class="pkg">TAM</span> methods <code>tam.mml</code>, <code>tam.mml.2pl</code>
or <code>tam.mml.3pl</code>.
</p>
</td></tr>
<tr><td><code id="tamaanify_+3A_doparse">doparse</code></td>
<td>
<p>Optional logical indicating whether <code>lavmodel</code>
should be parsed for <code>DO</code> statements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model syntax <code>tammodel</code> consists of several sections.
Some of them are optional. <br />
</p>
<p><code>ANALYSIS:</code> <br />
Possible model types are unidimensional and multidimensional
item response models (<code>TYPE="TRAIT"</code>), latent class models
(<code>"LCA"</code>), located latent class models (<code>"LOCLCA"</code>;
e.g. Formann, 1989; Bartolucci, 2007),
ordered latent class models (<code>"OLCA"</code>; only works for
dichotomous item responses; e.g. Hoijtink, 1997; Shojima, 2007) and
mixture distribution models (<code>"MIXTURE"</code>; e.g. von Davier, 2007). <br />
</p>
<p><code>LAVAAN MODEL:</code> <br />
For specification of the syntax, see <code><a href="#topic+lavaanify.IRT">lavaanify.IRT</a></code>. <br />
</p>
<p><code>MODEL CONSTRAINT:</code> <br />
Linear constraints can be specified by using conventional
specification in <span class="rlang"><b>R</b></span> syntax. All terms must be combined
with the <code>+</code> operator. Equality constraints are
set by using the <code>==</code> operator as in <span class="pkg">lavaan</span>. <br />
</p>
<p><code>ITEM TYPE:</code> <br />
The following item types can be defined: Rasch model (<code>Rasch</code>),
the 2PL model (<code>2PL</code>), partial credit model (<code>PCM</code>)
and the generalized partial credit model (<code>GPCM</code>).
</p>
<p>The item intercepts can also be smoothed for the <code>PCM</code>
and the <code>GPCM</code> by using a Fourier basis proposed by
Thissen, Cai and Bock (2010). For an item with a maximum
of score of <code class="reqn">K</code>, a smoothed partial credit model
is requested by <code>PCM(kk)</code> where <code>kk</code> is an
integer between 1 and <code class="reqn">K</code>. With <code>kk</code>=1, only a linear
function is used. The subsequent integers correspond to
Fourier functions with decreasing periods.
See Example 2, Model 7 of the <code><a href="#topic+tamaan">tamaan</a></code>
function. <br />
</p>
<p><code>PRIOR:</code> <br />
Possible prior distributions: Normal distribution <code>N(mu,sd)</code>,
truncated normal distribution <code>TN(mu,sd,low,upp)</code> and
Beta distribution <code>Beta(a,b)</code>.
Parameter labels and prior specification must be separated
by <code>~</code>.<br />
</p>


<h3>Value</h3>

<p>A list with following (optional) entries
which are used as input in one of the <span class="pkg">TAM</span> functions
<code><a href="#topic+tam.mml">tam.mml</a></code>, <code><a href="#topic+tam.mml.2pl">tam.mml.2pl</a></code> or
<code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code>:
</p>
<table>
<tr><td><code>tammodel</code></td>
<td>
<p>Model input for <span class="pkg">TAM</span></p>
</td></tr>
<tr><td><code>tammodel.dfr</code></td>
<td>
<p>Processed <code>tammodel</code> input</p>
</td></tr>
<tr><td><code>ANALYSIS</code></td>
<td>
<p>Syntax specified in <code>ANALYSIS</code></p>
</td></tr>
<tr><td><code>ANALYSIS.list</code></td>
<td>
<p>Parsed specifications in <code>ANALYSIS</code></p>
</td></tr>
<tr><td><code>LAVAANMODEL</code></td>
<td>
<p>Syntax specified in <code>LAVAAN MODEL</code></p>
</td></tr>
<tr><td><code>lavpartable</code></td>
<td>
<p>Parameter table processed by the
syntax in <code>LAVAAN MODEL</code></p>
</td></tr>
<tr><td><code>items</code></td>
<td>
<p>Informations about items: Number of categories,
specified item response function</p>
</td></tr>
<tr><td><code>maxcat</code></td>
<td>
<p>Maximum number of categories</p>
</td></tr>
<tr><td><code>ITEMTYPE</code></td>
<td>
<p>Syntax specified in <code>ITEM TYPE</code></p>
</td></tr>
<tr><td><code>MODELCONSTRAINT</code></td>
<td>
<p>Syntax specified in <code>MODEL CONSTRAINT</code></p>
</td></tr>
<tr><td><code>MODELCONSTRAINT.dfr</code></td>
<td>
<p>Processed syntax in <code>MODEL CONSTRAINT</code></p>
</td></tr>
<tr><td><code>modelconstraint.thresh</code></td>
<td>
<p>Processed data frame for model constraint of thresholds</p>
</td></tr>
<tr><td><code>modelconstraint.loading</code></td>
<td>
<p>Processed data frame for loadings</p>
</td></tr>
<tr><td><code>resp</code></td>
<td>
<p>Data set for usage</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Used <span class="pkg">TAM</span> function</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Design matrix A</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>Design matrix for loadings</p>
</td></tr>
<tr><td><code>Q.fixed</code></td>
<td>
<p>Fixed values in <code class="reqn">Q</code> matrix</p>
</td></tr>
<tr><td><code>B.fixed</code></td>
<td>
<p>Matrix with fixed item loadings
(used for <code>tam.mml.2pl</code>)</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>Processed design matrix for loadings when there
are model constraints for loadings</p>
</td></tr>
<tr><td><code>variance.fixed</code></td>
<td>
<p>Matrix for specification of fixed values
in covariance matrix</p>
</td></tr>
<tr><td><code>est.variance</code></td>
<td>
<p>Logical indicating whether variance should
be estimated (<code><a href="#topic+tam.mml.2pl">tam.mml.2pl</a></code>)
</p>
</td></tr>
<tr><td><code>theta.k</code></td>
<td>
<p>Theta design matrix</p>
</td></tr>
<tr><td><code>E</code></td>
<td>
<p>Design matrix E</p>
</td></tr>
<tr><td><code>notA</code></td>
<td>
<p>Logical indicating whether <code class="reqn">A</code> matrix is defined</p>
</td></tr>
<tr><td><code>gammaslope.fixed</code></td>
<td>
<p>Fixed <code>gammaslope</code> parameters</p>
</td></tr>
<tr><td><code>gammaslope.prior</code></td>
<td>
<p>Prior distributions for <code>gammaslope</code> parameters</p>
</td></tr>
<tr><td><code>xsi.fixed</code></td>
<td>
<p>Fixed <code class="reqn">\xi</code> parameter</p>
</td></tr>
<tr><td><code>xsi.prior</code></td>
<td>
<p>Prior distributions for <code class="reqn">\xi</code> parameters</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bartolucci, F. (2007). A class of multidimensional IRT models for testing
unidimensionality and clustering items.
<em>Psychometrika, 72</em>, 141-157.
<a href="https://doi.org/10.1007/s11336-005-1376-9">doi:10.1007/s11336-005-1376-9</a>
</p>
<p>Formann, A. K. (1989). Constrained latent class models: Some further
applications. <em>British Journal of Mathematical and Statistical
Psychology, 42</em>, 37-54.
<a href="https://doi.org/10.1111/j.2044-8317.1989.tb01113.x">doi:10.1111/j.2044-8317.1989.tb01113.x</a>
</p>
<p>Hojtink, H., &amp; Molenaar, I. W. (1997). A multidimensional item response model:
Constrained latent class analysis using the Gibbs sampler and posterior
predictive checks. <em>Psychometrika, 62</em>(2), 171-189.
<a href="https://doi.org/10.1007/BF02295273">doi:10.1007/BF02295273</a>
</p>
<p>Thissen, D., Cai, L., &amp; Bock, R. D. (2010).
The nominal categories item response model.
In M. L. Nering &amp; Ostini, R. (Eds.).
<em>Handbook of Polytomous Item Response Models</em>
(pp. 43-75). New York: Routledge.
</p>
<p>Shojima, K. (2007). <em>Latent rank theory: Estimation of item reference
profile by marginal maximum likelihood method with EM algorithm</em>.
DNC Research Note 07-12.
</p>
<p>von Davier, M. (2007). <em>Mixture distribution diagnostic models</em>.
ETS Research Report ETS RR-07-32. Princeton, ETS.
<a href="https://doi.org/10.1002/j.2333-8504.2007.tb02074.x">doi:10.1002/j.2333-8504.2007.tb02074.x</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+tamaan">tamaan</a></code> for more examples. Other examples
are included in <code><a href="#topic+tam.mml">tam.mml</a></code> and <code><a href="#topic+tam.mml.3pl">tam.mml.3pl</a></code>.
</p>
<p><code><a href="#topic+lavaanify.IRT">lavaanify.IRT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#############################################################################
# EXAMPLE 1: Examples dichotomous data data.read
#############################################################################

library(sirt)
data(data.read,package="sirt")
dat &lt;- data.read

#*********************************************************************
#*** Model 1: 2PL estimation with some fixed parameters and
#             equality constraints
tammodel &lt;- "
LAVAAN MODEL:
  F2=~ C1__C2 + 1.3*C3 + C4
  F1=~ A1__B1
  # fixed loading of 1.4 for item B2
  F1=~ 1.4*B2
  F1=~ B3
  F1 ~~ F1
  F2 ~~ F2
  F1 ~~ F2
  B1 | 1.23*t1 ; A3 | 0.679*t1
  A2 | a*t1 ; C2 | a*t1 ; C4 | a*t1
  C3 | x1*t1 ; C1 | x1*t1
ITEM TYPE:
  A1__A3 (Rasch) ;
  A4 (2PL) ;
  B1__C4 (Rasch) ;
    "
# process model
out &lt;- TAM::tamaanify( tammodel, resp=dat)
# inspect some output
out$method          # used TAM function
out$lavpartable     # lavaan parameter table

#*********************************************************************
#*** Model 2: Latent class analysis with three classes
tammodel &lt;- "
ANALYSIS:
  TYPE=LCA;
  NCLASSES(3);   # 3 classes
  NSTARTS(5,20); # 5 random starts with 20 iterations
LAVAAN MODEL:
  F=~ A1__C4
    "
# process syntax
out &lt;- TAM::tamaanify( tammodel, resp=dat)
str(out$E)     # E design matrix for estimation with tam.mml.3pl function

#*********************************************************************
#*** Model 3: Linear constraints for item intercepts and item loadings
tammodel &lt;- "
LAVAAN MODEL:
  F=~ lam1__lam10*A1__C2
  F ~~ F
  A1 | a1*t1
  A2 | a2*t1
  A3 | a3*t1
  A4 | a4*t1
  B1 | b1*t1
  B2 | b2*t1
  B3 | b3*t1
  C1 | t1
MODEL CONSTRAINT:
  # defined parameters
  # only linear combinations are permitted
  b2==1.3*b1 + (-0.6)*b3
  a1==q1
  a2==q2 + t
  a3==q1 + 2*t
  a4==q2 + 3*t
  # linear constraints for loadings
  lam2==1.1*lam1
  lam3==0.9*lam1 + (-.1)*lam0
  lam8==lam0
  lam9==lam0
    "
# parse syntax
mod1 &lt;- TAM::tamaanify( tammodel, resp=dat)
mod1$A          # design matrix A for intercepts
mod1$L[,1,]     # design matrix L for loadings

## End(Not run)

#############################################################################
# EXAMPLE 2: Examples polytomous data data.Students
#############################################################################

library(CDM)
data( data.Students, package="CDM")
dat &lt;- data.Students[,3:13]

#*********************************************************************
#*** Model 1: Two-dimensional generalized partial credit model
tammodel &lt;- "
LAVAAN MODEL:
  FA=~ act1__act5
  FS=~ sc1__sc4
  FA ~~ 1*FA
  FS ~~ 1*FS
  FA ~~ FS
  act1__act3 | t1
  sc2 | t2
    "
out &lt;- TAM::tamaanify( tammodel, resp=dat)
out$A    # design matrix for item intercepts
out$Q    # loading matrix for items

#*********************************************************************
#*** Model 2: Linear constraints

# In the following syntax, linear equations for multiple constraints
# are arranged over multiple lines.
tammodel &lt;- "
  LAVAAN MODEL:
    F=~ a1__a5*act1__act5
    F ~~ F
  MODEL CONSTRAINT:
      a1==delta +
                tau1
      a2==delta
      a3==delta + z1
      a4==1.1*delta +
              2*tau1
                + (-0.2)*z1
  "
# tamaanify model
res &lt;- TAM::tamaanify( tammodel, dat )
res$MODELCONSTRAINT.dfr
res$modelconstraint.loading
</code></pre>

<hr>
<h2 id='tampv2datalist'>
Conversion of Plausible Value Object into Datalist
</h2><span id='topic+tampv2datalist'></span>

<h3>Description</h3>

<p>Converts a <code><a href="#topic+tam.pv">tam.pv</a></code> object and a matrix of covariates
into a list of multiply imputed datasets. This list can be conveniently
analyzed by <span class="rlang"><b>R</b></span> packages such as <span class="pkg">semTools</span>, <span class="pkg">Zelig</span>, <span class="pkg">mice</span>
or <span class="pkg">BIFIEsurvey</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tampv2datalist(tam.pv.object, pvnames=NULL, Y=NULL, Y.pid="pid",
      as_mids=FALSE, stringsAsFactors=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tampv2datalist_+3A_tam.pv.object">tam.pv.object</code></td>
<td>

<p>Generated <code><a href="#topic+tam.pv">tam.pv</a></code> object
</p>
</td></tr>
<tr><td><code id="tampv2datalist_+3A_pvnames">pvnames</code></td>
<td>

<p>Variable names of generated plausible values
</p>
</td></tr>
<tr><td><code id="tampv2datalist_+3A_y">Y</code></td>
<td>

<p>Matrix with covariates
</p>
</td></tr>
<tr><td><code id="tampv2datalist_+3A_y.pid">Y.pid</code></td>
<td>

<p>Person identifier in <code>Y</code> matrix. It is not required that a person
identifier is provided. In this case, the merge of the datasets will
be conducted as for <code>rbind</code>.
</p>
</td></tr>
<tr><td><code id="tampv2datalist_+3A_as_mids">as_mids</code></td>
<td>
<p>Logical indicating whether the datalist
should be converted into an object of class <code>mids</code> for
analysis in the <span class="pkg">mice</span> package. This functionality uses the
the function <code><a href="miceadds.html#topic+datalist2mids">miceadds::datalist2mids</a></code>.
</p>
</td></tr>
<tr><td><code id="tampv2datalist_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>Logical indicating whether strings in the data frame
should be converted into factors</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of multiply imputed datasets or an <code>mids</code> object
</p>


<h3>See Also</h3>

<p>For examples see <code><a href="#topic+tam.pv">tam.pv</a></code>.
</p>

<hr>
<h2 id='weighted_Stats'>
Descriptive Statistics for Weighted Data
</h2><span id='topic+weighted_Stats'></span><span id='topic+weighted_var'></span><span id='topic+weighted_sd'></span><span id='topic+weighted_mean'></span><span id='topic+weighted_skewness'></span><span id='topic+weighted_kurtosis'></span><span id='topic+weighted_quantile'></span><span id='topic+weighted_table'></span>

<h3>Description</h3>

<p>Some descriptive statistics for weighted data: variance,
standard deviation, means, skewness, excess kurtosis, quantiles and
frequency tables. Missing values are automatically removed from
the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted_mean(x, w=rep(1, length(x)), select=NULL  )

weighted_var(x, w=rep(1, length(x)), method="unbiased", select=NULL )

weighted_sd(x, w=rep(1, length(x)), method="unbiased", select=NULL )

weighted_skewness( x, w=rep(1,length(x)), select=NULL  )

weighted_kurtosis( x, w=rep(1,length(x)), select=NULL  )

weighted_quantile( x, w=rep(1,length(x)), probs=seq(0,1,.25), type=NULL, select=NULL )

weighted_table( x, w=NULL, props=FALSE )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted_Stats_+3A_x">x</code></td>
<td>

<p>A numeric vector. For <code>weighted_table</code>, a matrix with
two columns can be used as input for cross-tabulation.
</p>
</td></tr>
<tr><td><code id="weighted_Stats_+3A_w">w</code></td>
<td>

<p>Optional vector of sample weights
</p>
</td></tr>
<tr><td><code id="weighted_Stats_+3A_select">select</code></td>
<td>
<p>Vector referring to selected cases</p>
</td></tr>
<tr><td><code id="weighted_Stats_+3A_method">method</code></td>
<td>

<p>Computation method (can be <code>"unbiased"</code> or <code>"ML"</code>)), see
<code><a href="stats.html#topic+cov.wt">stats::cov.wt</a></code>
</p>
</td></tr>
<tr><td><code id="weighted_Stats_+3A_probs">probs</code></td>
<td>
<p>Vector with probabilities</p>
</td></tr>
<tr><td><code id="weighted_Stats_+3A_type">type</code></td>
<td>
<p>Quantile type. For unweighted data, quantile types 6 and
7 can be used (see
<code><a href="stats.html#topic+quantile">stats::quantile</a></code>).
For weighted data, the quantile type <code>"i/n"</code>
is used (see <code>Hmisc::wtd.quantile</code>)).
</p>
</td></tr>
<tr><td><code id="weighted_Stats_+3A_props">props</code></td>
<td>
<p>Logical indicating whether relative or absolute
frequencies should be calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value
</p>


<h3>See Also</h3>

<p>See <code><a href="stats.html#topic+weighted.mean">stats::weighted.mean</a></code> for
computing a weighted mean.
</p>
<p>See <code><a href="stats.html#topic+var">stats::var</a></code> for computing
unweighted variances.
</p>
<p>See <code><a href="stats.html#topic+quantile">stats::quantile</a></code> and
<code>Hmisc::wtd.quantile</code>) for quantiles.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Toy example for weighted_var function
#############################################################################

set.seed(9897)
# simulate data
N &lt;- 10
x &lt;- stats::rnorm(N)
w &lt;- stats::runif(N)

#---- variance

# use weighted_var
weighted_var( x=x, w=w )
# use cov.wt
stats::cov.wt( data.frame(x=x), w=w )$cov[1,1]
## Not run: 
# use wtd.var from Hmisc package
Hmisc::wtd.var(x=x, weights=w, normwt=TRUE, method="unbiased")

#---- standard deviation
weighted_sd( x=x, w=w )

#---- mean
weighted_mean( x=x, w=w )
stats::weighted.mean( x=x, w=w )

#---- weighted quantiles for unweighted data
pvec &lt;- c(.23, .53, .78, .99 )  # choose probabilities
type &lt;- 7

# quantiles for unweighted data
weighted_quantile( x, probs=pvec, type=type)
quantile( x, probs=pvec, type=type)
Hmisc::wtd.quantile(x,probs=pvec, type=type)

# quantiles for weighted data
pvec &lt;- c(.23, .53, .78, .99 )  # probabilities
weighted_quantile( x, w=w, probs=pvec)
Hmisc::wtd.quantile(x, weights=w, probs=pvec)

#--- weighted skewness and kurtosis
weighted_skewness(x=x, w=w)
weighted_kurtosis(x=x, w=w)

#############################################################################
# EXAMPLE 2: Descriptive statistics normally distributed data
#############################################################################

# simulate some normally distributed data
set.seed(7768)
x &lt;- stats::rnorm( 10000, mean=1.7, sd=1.2)
# some statistics
weighted_mean(x=x)
weighted_sd(x=x)
weighted_skewness(x=x)
weighted_kurtosis(x=x)

#############################################################################
# EXAMPLE 3: Frequency tables
#############################################################################

#*****
# simulate data for weighted frequency tables
y &lt;- scan()
   1 0  1 1   1 2   1 3    1 4
   2 0  2 1   2 2   2 3    2 4

y &lt;- matrix( y, ncol=2, byrow=TRUE)
# define probabilities
set.seed(976)
pr &lt;- stats::runif(10)
pr &lt;- pr / sum(pr)
# sample data
N &lt;- 300
x &lt;- y[ sample( 1:10, size=300, prob=pr, replace=TRUE ), ]
w &lt;- stats::runif( N, 0.5, 1.5 )

# frequency table unweighted data
weighted_table(x[,2] )
table( x[,2] )

# weighted data and proportions
weighted_table(x[,2], w=w, props=TRUE)

#*** contingency table
table( x[,1], x[,2] )
weighted_table( x )
# table using weights
weighted_table( x, w=w )

## End(Not run)
</code></pre>

<hr>
<h2 id='WLErel'>
Reliability Estimation in <span class="pkg">TAM</span>
</h2><span id='topic+WLErel'></span><span id='topic+EAPrel'></span>

<h3>Description</h3>

<p>Functions for computing reliability estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WLErel(theta, error, w=rep(1, length(theta)), select=NULL)

EAPrel(theta, error, w=rep(1, length(theta)), select=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WLErel_+3A_theta">theta</code></td>
<td>

<p>Vector with theta estimates
</p>
</td></tr>
<tr><td><code id="WLErel_+3A_error">error</code></td>
<td>

<p>Vector with standard errors of theta estimates
</p>
</td></tr>
<tr><td><code id="WLErel_+3A_w">w</code></td>
<td>

<p>Optional vector of person weights
</p>
</td></tr>
<tr><td><code id="WLErel_+3A_select">select</code></td>
<td>
<p>Optional vector for selecting cases</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reliability formulas follow Adams (2005). Let <code class="reqn">v</code> denote
the variance of <code>theta</code> estimates and let <code class="reqn">s</code> denote
the average of the squared <code>error</code>. Then, the WLE reliability is
defined as <code class="reqn">1-s/v=(v-s)/v</code> while the EAP reliability is defined as
<code class="reqn">1 - s/(s+v)=v/(s+v)</code>.
</p>


<h3>Value</h3>

<p>Numeric value
</p>


<h3>References</h3>

<p>Adams, R. J. (2005). Reliability as a measurement design effect.
<em>Studies in Educational Evaluation, 31</em>(2), 162-172.
<a href="https://doi.org/10.1016/j.stueduc.2005.05.008">doi:10.1016/j.stueduc.2005.05.008</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Toy example for reliability functions
#############################################################################

set.seed(9897)
N &lt;- 100
# simulate theta and error SDs
x &lt;- stats::rnorm(N,sd=2)
error &lt;- stats::runif(N, .7, 1.3)
# compute WLE reliability
WLErel(x,error)
# compute EAP reliaility
EAPrel(x,error)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
