<!DOCTYPE html><html><head><title>Help for package c2c</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {c2c}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calculate_clustering_metrics'><p>Calculate clustering metrics for a confusion matrix</p></a></li>
<li><a href='#class_entropy'><p>Calculate cluster entropy per class</p></a></li>
<li><a href='#class_purity'><p>Calculate cluster purity per class</p></a></li>
<li><a href='#get_conf_mat'><p>Generate a confusion matrix from two classifications/clustering solutions.</p></a></li>
<li><a href='#get_hard'><p>Decompose soft (fuzzy, probabilistic) membership to hard binary matrix</p></a></li>
<li><a href='#labels_to_matrix'><p>Make a vector of class labels into a hard binary matrix</p></a></li>
<li><a href='#overall_entropy'><p>Calculate overall cluster entropy</p></a></li>
<li><a href='#overall_purity'><p>Calculate overall cluster purity</p></a></li>
<li><a href='#percentage_agreement'><p>Calculate overall percentage agreement</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Compare Two Classifications or Clustering Solutions of Varying
Structure</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mitchell Lyons &lt;mitchell.lyons@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Compare two classifications or clustering solutions that may or may
    not have the same number of classes, and that might have hard or soft
    (fuzzy, probabilistic) membership. Calculate various metrics to assess how
    the clusters compare to each other. The calculations are simple, but provide
    a handy tool for users unfamiliar with matrix multiplication. This package
    is not geared towards traditional accuracy assessment for classification/
    mapping applications - the motivating use case is for comparing a
    probabilistic clustering solution to a set of reference or existing class
    labels that could have any number of classes (that is, without having to
    degrade the probabilistic clustering to hard classes).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mitchest/c2c/">https://github.com/mitchest/c2c/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mitchest/c2c/issues">https://github.com/mitchest/c2c/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown, e1071</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-07-23 02:57:48 UTC; mitchell</td>
</tr>
<tr>
<td>Author:</td>
<td>Mitchell Lyons [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-07-23 17:50:40 UTC</td>
</tr>
</table>
<hr>
<h2 id='calculate_clustering_metrics'>Calculate clustering metrics for a confusion matrix</h2><span id='topic+calculate_clustering_metrics'></span>

<h3>Description</h3>

<p>Calculate a range of clustering metrics on a confusion confusion matrix, usually from <code><a href="#topic+get_conf_mat">get_conf_mat</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate_clustering_metrics(conf_mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate_clustering_metrics_+3A_conf_mat">conf_mat</code></td>
<td>
<p>a confusion matrix, as produced by <code><a href="#topic+get_conf_mat">get_conf_mat</a></code>, or otherwise a confusion matrix of the same form.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Entropy calculated via <code><a href="#topic+overall_entropy">overall_entropy</a></code> and <code><a href="#topic+class_entropy">class_entropy</a></code>, purity calculated via <code><a href="#topic+overall_purity">overall_purity</a></code> and <code><a href="#topic+class_purity">class_purity</a></code>, percentage agreement calculated via <code><a href="#topic+percentage_agreement">percentage_agreement</a></code> (only for confusion matrices of equal dimensions and matching class order)
</p>


<h3>Value</h3>

<p>A list containing the metrics that can be calculated, see details.
</p>


<h3>Author(s)</h3>

<p>Mitchell Lyons
</p>


<h3>References</h3>

<p>Lyons, Foster and Keith (2017). Simultaneous vegetation classification and mapping at large spatial scales. <em>Journal of Biogeography</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_conf_mat">get_conf_mat</a></code>, <code><a href="#topic+labels_to_matrix">labels_to_matrix</a></code>, <code><a href="#topic+get_hard">get_hard</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># meaningless data, but you get the idea

# compare two soft classifications
my_soft_mat1 &lt;- matrix(runif(50,0,1), nrow = 10, ncol = 5)
my_soft_mat2 &lt;- matrix(runif(30,0,1), nrow = 10, ncol = 3)
# make the confusion matrix and calculate stats
conf_mat &lt;- get_conf_mat(my_soft_mat1, my_soft_mat2)
conf_mat; calculate_clustering_metrics(conf_mat)

# compare a soft classificaiton to a vector of hard labels
my_labels &lt;- rep(c("a","b","c"), length.out = 10)
# utilising labels_to_matrix(my_labels)
conf_mat &lt;- get_conf_mat(my_soft_mat1, my_labels)
conf_mat; calculate_clustering_metrics(conf_mat)

# make one of the soft matrices hard
# utilising get_hard(my_soft_mat2)
conf_mat &lt;- get_conf_mat(my_soft_mat1, my_soft_mat2, make.B.hard = TRUE)
conf_mat; calculate_clustering_metrics(conf_mat)

# two classifications with same number of classes, enables percentage agreement
conf_mat &lt;- get_conf_mat(my_soft_mat1, my_soft_mat1)
conf_mat; calculate_clustering_metrics(conf_mat)

</code></pre>

<hr>
<h2 id='class_entropy'>Calculate cluster entropy per class</h2><span id='topic+class_entropy'></span>

<h3>Description</h3>

<p>Used to calculate cluster entropy from a confusion matrix, for each class (i.e. each row and column of the confusion matrix).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>class_entropy(conf_mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="class_entropy_+3A_conf_mat">conf_mat</code></td>
<td>
<p>A confusion matrix from <code><a href="#topic+get_conf_mat">get_conf_mat</a></code> or otherwise (ideally a matrix, although data frames will probably work)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Metrics per class are useful when you are comparing two classifications with different numbers of classes, when an overall measure might not be useful or sensible. Entropy as defined in Manning (2008).
</p>


<h3>Value</h3>

<p>A data frame with two columns, the first corresponding to the confusion matrix rows, the second corresponding to the confusion matrix columns.
</p>


<h3>References</h3>

<p>Manning, C. D., Raghavan, P., &amp; Schütze, H. (2008) Introduction to information retrieval (Vol. 1, No. 1). Cambridge: Cambridge university press.
</p>

<hr>
<h2 id='class_purity'>Calculate cluster purity per class</h2><span id='topic+class_purity'></span>

<h3>Description</h3>

<p>Used to calculate cluster purity from a confusion matrix, for each class (i.e. each row and column of the confusion matrix).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>class_purity(conf_mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="class_purity_+3A_conf_mat">conf_mat</code></td>
<td>
<p>A confusion matrix from <code><a href="#topic+get_conf_mat">get_conf_mat</a></code> or otherwise (ideally a matrix, although data frames will probably work)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Metrics per class are useful when you are comparing two classifications with different numbers of classes, when an overall measure might not be useful or sensible. Purity as defined in Manning (2008).
</p>


<h3>Value</h3>

<p>A data frame with two columns, the first corresponding to the confusion matrix rows, the second corresponding to the confusion matrix columns.
</p>


<h3>References</h3>

<p>Manning, C. D., Raghavan, P., &amp; Schütze, H. (2008) Introduction to information retrieval (Vol. 1, No. 1). Cambridge: Cambridge university press.
</p>

<hr>
<h2 id='get_conf_mat'>Generate a confusion matrix from two classifications/clustering solutions.</h2><span id='topic+get_conf_mat'></span>

<h3>Description</h3>

<p><code>get_conf_mat</code> takes two classifications or clustering solutions and creates a confusion matrix representing the number of shared sites between them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_conf_mat(A, B, make.A.hard = F, make.B.hard = F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_conf_mat_+3A_a">A</code></td>
<td>
<p>A matrix or data.frame (or something that can be coerced to a matrix) of class membership or a vector of class labels (character or factor).</p>
</td></tr>
<tr><td><code id="get_conf_mat_+3A_b">B</code></td>
<td>
<p>A matrix or data.frame (or something that can be coerced to a matrix) or class membership or a vector of class labels (character or factor).</p>
</td></tr>
<tr><td><code id="get_conf_mat_+3A_make.a.hard">make.A.hard</code></td>
<td>
<p>logical (defaults to FALSE). If TRUE, and if A= is a matrix of soft membership, it will be degraded to a hard binary matrix, taking the highest value, breaking ties at random</p>
</td></tr>
<tr><td><code id="get_conf_mat_+3A_make.b.hard">make.B.hard</code></td>
<td>
<p>logical (defaults to FALSE). If TRUE, and if B= is a matrix of soft membership, it will be degraded to a hard binary matrix, taking the highest value, breaking ties at random</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes inputs A and B (converting labels to matrices if required) and combines them via (<code class="reqn">A^TB</code>). Soft classifications will necessarily be matrices. Hard classifications can be given as a binary matrix of membership or a vector of labels. For matrix inputs, rows should represent individual sites, observations, cases etc., and columns should represent classes. For class label inputs, the vector should be ordered similarly by site, observation, case etc; they will be converted to a binary matrix (see <code><a href="#topic+labels_to_matrix">labels_to_matrix</a></code>). Classes from matrix A are represented by rows of the output, and classes from matrix B are represented by the columns. Class names inherited from <code>names()</code> or <code>colnames()</code> - if at least one of the inputs has names, interpretation will be much easier. Ties in membership probability are broken at random - if you don't want this to happen, suggest you break the tie manually before proceeding.
</p>


<h3>Value</h3>

<p>A confusion matrix
</p>


<h3>Author(s)</h3>

<p>Mitchell Lyons
</p>


<h3>References</h3>

<p>Lyons, Foster and Keith (2017). Simultaneous vegetation classification and mapping at large spatial scales. <em>Journal of Biogeography</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calculate_clustering_metrics">calculate_clustering_metrics</a></code>, <code><a href="#topic+labels_to_matrix">labels_to_matrix</a></code>, <code><a href="#topic+get_hard">get_hard</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># meaningless data, but you get the idea

# compare two soft classifications
my_soft_mat1 &lt;- matrix(runif(50,0,1), nrow = 10, ncol = 5)
my_soft_mat2 &lt;- matrix(runif(30,0,1), nrow = 10, ncol = 3)
# make the confusion matrix and calculate stats
conf_mat &lt;- get_conf_mat(my_soft_mat1, my_soft_mat2)
conf_mat; calculate_clustering_metrics(conf_mat)

# compare a soft classification to a vector of hard labels
my_labels &lt;- rep(c("a","b","c"), length.out = 10)
# utilising labels_to_matrix(my_labels)
conf_mat &lt;- get_conf_mat(my_soft_mat1, my_labels)
conf_mat; calculate_clustering_metrics(conf_mat)

# make one of the soft matrices hard
# utilising get_hard(my_soft_mat2)
conf_mat &lt;- get_conf_mat(my_soft_mat1, my_soft_mat2, make.B.hard = TRUE)
conf_mat; calculate_clustering_metrics(conf_mat)

# two classifications with same number of classes, enables percentage agreement
conf_mat &lt;- get_conf_mat(my_soft_mat1, my_soft_mat1)
conf_mat; calculate_clustering_metrics(conf_mat)

</code></pre>

<hr>
<h2 id='get_hard'>Decompose soft (fuzzy, probabilistic) membership to hard binary matrix</h2><span id='topic+get_hard'></span>

<h3>Description</h3>

<p>Used in <code><a href="#topic+get_conf_mat">get_conf_mat</a></code> but might be useful separately
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_hard(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_hard_+3A_x">x</code></td>
<td>
<p>A matrix or data frame (or something coercible to a matrix) containing memberships - rows are sites (observations, cases etc.) columns are classes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Binary matrix of class membership. Class names inherited from <code>names()</code> or <code>colnames()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my_mat &lt;- matrix(runif(20,0,1), nrow = 4)
get_hard(my_mat)

</code></pre>

<hr>
<h2 id='labels_to_matrix'>Make a vector of class labels into a hard binary matrix</h2><span id='topic+labels_to_matrix'></span>

<h3>Description</h3>

<p>Used in <code><a href="#topic+get_conf_mat">get_conf_mat</a></code> but might be useful separately
</p>


<h3>Usage</h3>

<pre><code class='language-R'>labels_to_matrix(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="labels_to_matrix_+3A_x">x</code></td>
<td>
<p>Character or factor vector of class labels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Binary matrix of class membership.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my_labels &lt;- rep(c("a","b","c","d"), 5)
labels_to_matrix(my_labels)

</code></pre>

<hr>
<h2 id='overall_entropy'>Calculate overall cluster entropy</h2><span id='topic+overall_entropy'></span>

<h3>Description</h3>

<p>Used to calculate overall cluster entropy from a confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overall_entropy(conf_mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="overall_entropy_+3A_conf_mat">conf_mat</code></td>
<td>
<p>A confusion matrix from <code><a href="#topic+get_conf_mat">get_conf_mat</a></code> or otherwise (ideally a matrix, although data frames will probably work)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A scaler, cluster entropy as defined in Manning (2008)
</p>


<h3>References</h3>

<p>Manning, C. D., Raghavan, P., &amp; Schütze, H. (2008) Introduction to information retrieval (Vol. 1, No. 1). Cambridge: Cambridge university press.
</p>

<hr>
<h2 id='overall_purity'>Calculate overall cluster purity</h2><span id='topic+overall_purity'></span>

<h3>Description</h3>

<p>Used to calculate overall cluster purity from a confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overall_purity(conf_mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="overall_purity_+3A_conf_mat">conf_mat</code></td>
<td>
<p>A confusion matrix from <code><a href="#topic+get_conf_mat">get_conf_mat</a></code> or otherwise (ideally a matrix, although data frames will probably work)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A scaler, cluster purity as defined in Manning (2008)
</p>


<h3>References</h3>

<p>Manning, C. D., Raghavan, P., &amp; Schütze, H. (2008) Introduction to information retrieval (Vol. 1, No. 1). Cambridge: Cambridge university press.
</p>

<hr>
<h2 id='percentage_agreement'>Calculate overall percentage agreement</h2><span id='topic+percentage_agreement'></span>

<h3>Description</h3>

<p>Used to calculate overall percentage agreement for a confusion matrix - the confusion matrix must have equal dimensions and the diagonal must represent 'matching' class pairs (percentage agreement does not make sense otherwise)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentage_agreement(conf_mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="percentage_agreement_+3A_conf_mat">conf_mat</code></td>
<td>
<p>A confusion matrix from <code><a href="#topic+get_conf_mat">get_conf_mat</a></code> or otherwise (ideally a matrix, although data frames will probably work)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A scaler, percentage agreement (sometime referred to as overall accuracy)
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
