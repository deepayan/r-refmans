<!DOCTYPE html><html lang="en-US"><head><title>Help for package effectsize</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {effectsize}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#effectsize-package'><p>effectsize: Indices of Effect Size</p></a></li>
<li><a href='#chisq_to_phi'><p>Convert <code class="reqn">\chi^2</code> to <code class="reqn">\phi</code> and Other Correlation-like Effect Sizes</p></a></li>
<li><a href='#cohens_d'><p>Cohen's <em>d</em> and Other Standardized Differences</p></a></li>
<li><a href='#cohens_g'><p>Effect Size for Paired Contingency Tables</p></a></li>
<li><a href='#d_to_r'><p>Convert Between <em>d</em>, <em>r</em>, and Odds Ratio</p></a></li>
<li><a href='#diff_to_cles'><p>Convert Standardized Differences to Common Language Effect Sizes</p></a></li>
<li><a href='#effectsize_API'><p><code>effectsize</code> API</p></a></li>
<li><a href='#effectsize_CIs'><p>Confidence (Compatibility) Intervals</p></a></li>
<li><a href='#effectsize_deprecated'><p>Deprecated / Defunct Functions</p></a></li>
<li><a href='#effectsize_options'><p><code>effectsize</code> options</p></a></li>
<li><a href='#effectsize.BFBayesFactor'><p>Effect Sizes</p></a></li>
<li><a href='#equivalence_test.effectsize_table'><p>Test Effect Size for Practical Equivalence to the Null</p></a></li>
<li><a href='#eta_squared'><p><code class="reqn">\eta^2</code> and Other Effect Size for ANOVA</p></a></li>
<li><a href='#eta2_to_f2'><p>Convert Between ANOVA Effect Sizes</p></a></li>
<li><a href='#F_to_eta2'><p>Convert <em>F</em> and <em>t</em> Statistics to <strong>partial</strong>-<code class="reqn">\eta^2</code> and Other ANOVA Effect Sizes</p></a></li>
<li><a href='#food_class'><p>Classification of Foods</p></a></li>
<li><a href='#format_standardize'><p>Format a Standardized Vector</p></a></li>
<li><a href='#hardlyworking'><p>Workers' Salary and Other Information</p></a></li>
<li><a href='#interpret'><p>Generic Function for Interpretation</p></a></li>
<li><a href='#interpret_bf'><p>Interpret Bayes Factor (BF)</p></a></li>
<li><a href='#interpret_cohens_d'><p>Interpret Standardized Differences</p></a></li>
<li><a href='#interpret_cohens_g'><p>Interpret Cohen's <em>g</em></p></a></li>
<li><a href='#interpret_direction'><p>Interpret Direction</p></a></li>
<li><a href='#interpret_ess'><p>Interpret Bayesian Diagnostic Indices</p></a></li>
<li><a href='#interpret_gfi'><p>Interpret of CFA / SEM Indices of Goodness of Fit</p></a></li>
<li><a href='#interpret_icc'><p>Interpret Intraclass Correlation Coefficient (ICC)</p></a></li>
<li><a href='#interpret_kendalls_w'><p>Interpret Kendall's Coefficient of Concordance <em>W</em></p></a></li>
<li><a href='#interpret_oddsratio'><p>Interpret Odds Ratio</p></a></li>
<li><a href='#interpret_omega_squared'><p>Interpret ANOVA Effect Sizes</p></a></li>
<li><a href='#interpret_p'><p>Interpret <em>p</em>-Values</p></a></li>
<li><a href='#interpret_pd'><p>Interpret Probability of Direction (pd)</p></a></li>
<li><a href='#interpret_r'><p>Interpret Correlation Coefficient</p></a></li>
<li><a href='#interpret_r2'><p>Interpret Coefficient of Determination (<code class="reqn">R^2</code>)</p></a></li>
<li><a href='#interpret_rope'><p>Interpret Bayesian Posterior Percentage in ROPE.</p></a></li>
<li><a href='#interpret_vif'><p>Interpret the Variance Inflation Factor (VIF)</p></a></li>
<li><a href='#is_effectsize_name'><p>Checks for a Valid Effect Size Name</p></a></li>
<li><a href='#mahalanobis_d'><p>Mahalanobis' <em>D</em> (a multivariate Cohen's <em>d</em>)</p></a></li>
<li><a href='#means_ratio'><p>Ratio of Means</p></a></li>
<li><a href='#Music_preferences'><p>Music Preference by College Major</p></a></li>
<li><a href='#Music_preferences2'><p>Music Preference by College Major</p></a></li>
<li><a href='#odds_to_probs'><p>Convert Between Odds and Probabilities</p></a></li>
<li><a href='#oddsratio'><p>Odds Ratios, Risk Ratios and Other Effect Sizes for 2-by-2 Contingency Tables</p></a></li>
<li><a href='#oddsratio_to_riskratio'><p>Convert Between Odds Ratios, Risk Ratios and Other Metrics of Change in Probabilities</p></a></li>
<li><a href='#p_superiority'><p>Cohen's <em>U</em>s and Other Common Language Effect Sizes (CLES)</p></a></li>
<li><a href='#phi'><p><code class="reqn">\phi</code> and Other Contingency Tables Correlations</p></a></li>
<li><a href='#plot.effectsize_table'><p>Methods for <code>{effectsize}</code> Tables</p></a></li>
<li><a href='#r2_semipartial'><p>Semi-Partial (Part) Correlation Squared (<code class="reqn">\Delta R^2</code>)</p></a></li>
<li><a href='#rank_biserial'><p>Dominance Effect Sizes for Rank Based Differences</p></a></li>
<li><a href='#rank_epsilon_squared'><p>Effect Size for Rank Based ANOVA</p></a></li>
<li><a href='#RCT_table'><p>Fictional Results from a Workers' Randomized Control Trial</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#repeated_measures_d'><p>Standardized Mean Differences for Repeated Measures</p></a></li>
<li><a href='#rouder2016'><p>Jeff Rouder's Example Dataset for Repeated Measures</p></a></li>
<li><a href='#rules'><p>Create an Interpretation Grid</p></a></li>
<li><a href='#screening_test'><p>Results from 2 Screening Tests</p></a></li>
<li><a href='#sd_pooled'><p>Pooled Indices of (Co)Deviation</p></a></li>
<li><a href='#Smoking_FASD'><p>Frequency of FASD for Smoking Mothers</p></a></li>
<li><a href='#t_to_d'><p>Convert <em>t</em>, <em>z</em>, and <em>F</em> to Cohen's <em>d</em> or <strong>partial</strong>-<em>r</em></p></a></li>
<li><a href='#w_to_fei'><p>Convert Between Effect Sizes for Contingency Tables Correlations</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Indices of Effect Size</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mattan S. Ben-Shachar &lt;mattansb@msbstats.info&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provide utilities to work with indices of effect size for a wide 
    variety of models and hypothesis tests (see list of supported models using 
    the function 'insight::supported_models()'), allowing computation of and 
    conversion between indices such as Cohen's d, r, odds, etc.
    References: Ben-Shachar et al. (2020) &lt;<a href="https://doi.org/10.21105%2Fjoss.02815">doi:10.21105/joss.02815</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://easystats.github.io/effectsize/">https://easystats.github.io/effectsize/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/easystats/effectsize/issues/">https://github.com/easystats/effectsize/issues/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bayestestR (&ge; 0.15.0), insight (&ge; 1.0.0), parameters (&ge;
0.24.0), performance (&ge; 0.12.4), datawizard (&ge; 0.13.0),
stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>correlation (&ge; 0.8.4), see (&ge; 0.8.0), afex, BayesFactor,
boot, brms, car, emmeans, gt, knitr, lavaan, lme4, lmerTest,
mgcv, parsnip, pwr, rmarkdown, rms, rstanarm, rstantools,
testthat (&ge; 3.1.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>true</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>rstudio/bslib, r-lib/pkgdown,
easystats/easystatstemplate</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-12-10 06:14:11 UTC; user</td>
</tr>
<tr>
<td>Author:</td>
<td>Mattan S. Ben-Shachar
    <a href="https://orcid.org/0000-0002-4287-4801"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Dominique Makowski
    <a href="https://orcid.org/0000-0001-5375-9967"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Daniel LÃ¼decke <a href="https://orcid.org/0000-0002-8895-3206"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Indrajeet Patil <a href="https://orcid.org/0000-0003-1995-6531"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Brenton M. Wiernik
    <a href="https://orcid.org/0000-0001-9560-6336"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  RÃ©mi ThÃ©riault <a href="https://orcid.org/0000-0003-4315-6788"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Ken Kelley [ctb],
  David Stanley [ctb],
  Aaron Caldwell <a href="https://orcid.org/0000-0002-4541-6283"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Jessica Burnett <a href="https://orcid.org/0000-0002-0896-5099"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [rev],
  Johannes Karreth <a href="https://orcid.org/0000-0003-4586-7153"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [rev],
  Philip Waggoner <a href="https://orcid.org/0000-0002-7825-7573"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-12-10 07:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='effectsize-package'>effectsize: Indices of Effect Size</h2><span id='topic+effectsize-package'></span>

<h3>Description</h3>

<p>In both theoretical and applied research, it is often of interest to assess
the strength of an observed association. This is typically done to allow the
judgment of the magnitude of an effect, especially when units of measurement
are not meaningful. Though some indices of effect size, such as the
correlation coefficient (itself a standardized covariance coefficient) are
readily available, other measures are often harder to obtain.
</p>
<p><strong>effectsize</strong> fills this important gap, providing utilities for easily
estimating a wide variety of standardized effect sizes (i.e., effect sizes
that are not tied to the units of measurement of the variables of interest)
and their confidence intervals (CIs), from a variety of statistical models
and hypothesis tests, such as <code><a href="#topic+cohens_d">cohens_d()</a></code>, <code><a href="#topic+phi">phi()</a></code>, <code><a href="#topic+eta_squared">eta_squared()</a></code>, and
many more.
</p>
<p>See <a href="https://easystats.github.io/effectsize/articles/effectsize.html"><code>vignette("effectsize", package = "effectsize")</code></a>
for more details, or <a href="https://easystats.github.io/effectsize/articles/"><code>vignette(package = "effectsize")</code></a>
for a full list of vignettes.
</p>
<p>References: Ben-Shachar et al. (2020) <a href="https://doi.org/10.21105/joss.02815">doi:10.21105/joss.02815</a>.
</p>


<h3>Details</h3>

<p><code>effectsize</code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Mattan S. Ben-Shachar <a href="mailto:mattansb@msbstats.info">mattansb@msbstats.info</a> (<a href="https://orcid.org/0000-0002-4287-4801">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Dominique Makowski <a href="mailto:dom.makowski@gmail.com">dom.makowski@gmail.com</a> (<a href="https://orcid.org/0000-0001-5375-9967">ORCID</a>)
</p>
</li>
<li><p> Daniel LÃ¼decke <a href="mailto:d.luedecke@uke.de">d.luedecke@uke.de</a> (<a href="https://orcid.org/0000-0002-8895-3206">ORCID</a>)
</p>
</li>
<li><p> Indrajeet Patil <a href="mailto:patilindrajeet.science@gmail.com">patilindrajeet.science@gmail.com</a> (<a href="https://orcid.org/0000-0003-1995-6531">ORCID</a>)
</p>
</li>
<li><p> Brenton M. Wiernik <a href="mailto:brenton@wiernik.org">brenton@wiernik.org</a> (<a href="https://orcid.org/0000-0001-9560-6336">ORCID</a>)
</p>
</li>
<li><p> RÃ©mi ThÃ©riault <a href="mailto:remi.theriault@mail.mcgill.ca">remi.theriault@mail.mcgill.ca</a> (<a href="https://orcid.org/0000-0003-4315-6788">ORCID</a>)
</p>
</li>
<li><p> Philip Waggoner <a href="mailto:philip.waggoner@gmail.com">philip.waggoner@gmail.com</a> (<a href="https://orcid.org/0000-0002-7825-7573">ORCID</a>) [contributor]
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Ken Kelley [contributor]
</p>
</li>
<li><p> David Stanley [contributor]
</p>
</li>
<li><p> Aaron Caldwell <a href="mailto:arcaldwell49@gmail.com">arcaldwell49@gmail.com</a> (<a href="https://orcid.org/0000-0002-4541-6283">ORCID</a>) [contributor]
</p>
</li>
<li><p> Jessica Burnett <a href="mailto:jburnett@usgs.gov">jburnett@usgs.gov</a> (<a href="https://orcid.org/0000-0002-0896-5099">ORCID</a>) [reviewer]
</p>
</li>
<li><p> Johannes Karreth <a href="mailto:jkarreth@ursinus.edu">jkarreth@ursinus.edu</a> (<a href="https://orcid.org/0000-0003-4586-7153">ORCID</a>) [reviewer]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://easystats.github.io/effectsize/">https://easystats.github.io/effectsize/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/easystats/effectsize/issues/">https://github.com/easystats/effectsize/issues/</a>
</p>
</li></ul>


<hr>
<h2 id='chisq_to_phi'>Convert <code class="reqn">\chi^2</code> to <code class="reqn">\phi</code> and Other Correlation-like Effect Sizes</h2><span id='topic+chisq_to_phi'></span><span id='topic+chisq_to_cohens_w'></span><span id='topic+chisq_to_cramers_v'></span><span id='topic+chisq_to_tschuprows_t'></span><span id='topic+chisq_to_fei'></span><span id='topic+chisq_to_pearsons_c'></span><span id='topic+phi_to_chisq'></span>

<h3>Description</h3>

<p>Convert between <code class="reqn">\chi^2</code> (chi-square), <code class="reqn">\phi</code> (phi), Cramer's
<code class="reqn">V</code>, Tschuprow's <code class="reqn">T</code>, Cohen's <code class="reqn">w</code>,
×¤ (Fei) and Pearson's <code class="reqn">C</code> for contingency
tables or goodness of fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisq_to_phi(
  chisq,
  n,
  nrow = 2,
  ncol = 2,
  adjust = TRUE,
  ci = 0.95,
  alternative = "greater",
  ...
)

chisq_to_cohens_w(
  chisq,
  n,
  nrow,
  ncol,
  p,
  ci = 0.95,
  alternative = "greater",
  ...
)

chisq_to_cramers_v(
  chisq,
  n,
  nrow,
  ncol,
  adjust = TRUE,
  ci = 0.95,
  alternative = "greater",
  ...
)

chisq_to_tschuprows_t(
  chisq,
  n,
  nrow,
  ncol,
  adjust = TRUE,
  ci = 0.95,
  alternative = "greater",
  ...
)

chisq_to_fei(chisq, n, nrow, ncol, p, ci = 0.95, alternative = "greater", ...)

chisq_to_pearsons_c(
  chisq,
  n,
  nrow,
  ncol,
  ci = 0.95,
  alternative = "greater",
  ...
)

phi_to_chisq(phi, n, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chisq_to_phi_+3A_chisq">chisq</code></td>
<td>
<p>The <code class="reqn">\chi^2</code> (chi-square) statistic.</p>
</td></tr>
<tr><td><code id="chisq_to_phi_+3A_n">n</code></td>
<td>
<p>Total sample size.</p>
</td></tr>
<tr><td><code id="chisq_to_phi_+3A_nrow">nrow</code>, <code id="chisq_to_phi_+3A_ncol">ncol</code></td>
<td>
<p>The number of rows/columns in the contingency table.</p>
</td></tr>
<tr><td><code id="chisq_to_phi_+3A_adjust">adjust</code></td>
<td>
<p>Should the effect size be corrected for small-sample bias?
Defaults to <code>TRUE</code>; Advisable for small samples and large tables.</p>
</td></tr>
<tr><td><code id="chisq_to_phi_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="chisq_to_phi_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"greater"</code> (default) or <code>"less"</code>
(one-sided CI), or <code>"two.sided"</code> (two-sided CI). Partial matching is
allowed (e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in
<a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="chisq_to_phi_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="chisq_to_phi_+3A_p">p</code></td>
<td>
<p>Vector of expected values. See <code><a href="stats.html#topic+chisq.test">stats::chisq.test()</a></code>.</p>
</td></tr>
<tr><td><code id="chisq_to_phi_+3A_phi">phi</code></td>
<td>
<p>The <code class="reqn">\phi</code> (phi) statistic.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions use the following formulas:
</p>
<p style="text-align: center;"><code class="reqn">\phi = w = \sqrt{\chi^2 / n}</code>
</p>


<p style="text-align: center;"><code class="reqn">\textrm{Cramer's } V = \phi / \sqrt{\min(\textit{nrow}, \textit{ncol}) - 1}</code>
</p>



<p style="text-align: center;"><code class="reqn">\textrm{Tschuprow's } T = \phi / \sqrt[4]{(\textit{nrow} - 1) \times (\textit{ncol} - 1)}</code>
</p>



<p style="text-align: center;"><code class="reqn">×¤ = \phi / \sqrt{[1 / \min(p_E)] - 1}</code>
</p>


<p>Where <code class="reqn">p_E</code> are the expected probabilities.
</p>
<p style="text-align: center;"><code class="reqn">\textrm{Pearson's } C = \sqrt{\chi^2 / (\chi^2 + n)}</code>
</p>

<p>For versions adjusted for small-sample bias of <code class="reqn">\phi</code>, <code class="reqn">V</code>, and <code class="reqn">T</code>,
see <a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V#Bias_correction">Bergsma, 2013</a>.
</p>


<h3>Value</h3>

<p>A data frame with the effect size(s), and confidence interval(s). See
<code><a href="#topic+cramers_v">cramers_v()</a></code>.
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="#topic+effectsize_CIs">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Cumming, G., &amp; Finch, S. (2001). A primer on the understanding, use, and
calculation of confidence intervals that are based on central and noncentral
distributions. Educational and Psychological Measurement, 61(4), 532-574.
</p>
</li>
<li><p> Ben-Shachar, M.S., Patil, I., ThÃ©riault, R., Wiernik, B.M., LÃ¼decke, D.
(2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the
ChiâSquared Statistic. Mathematics, 11, 1982. <a href="https://doi.org/10.3390/math11091982">doi:10.3390/math11091982</a>
</p>
</li>
<li><p> Bergsma, W. (2013). A bias-correction for Cramer's V and Tschuprow's T.
Journal of the Korean Statistical Society, 42(3), 323-328.
</p>
</li>
<li><p> Johnston, J. E., Berry, K. J., &amp; Mielke Jr, P. W. (2006). Measures of
effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
Perceptual and motor skills, 103(2), 412-414.
</p>
</li>
<li><p> Rosenberg, M. S. (2010). A generalized formula for converting chi-square
tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+phi">phi()</a></code> for more details.
</p>
<p>Other effect size from test statistic: 
<code><a href="#topic+F_to_eta2">F_to_eta2</a>()</code>,
<code><a href="#topic+t_to_d">t_to_d</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Music_preferences")

# chisq.test(Music_preferences)
#&gt;
#&gt; 	Pearson's Chi-squared test
#&gt;
#&gt; data:  Music_preferences
#&gt; X-squared = 95.508, df = 6, p-value &lt; 2.2e-16
#&gt;

chisq_to_cohens_w(95.508,
  n = sum(Music_preferences),
  nrow = nrow(Music_preferences),
  ncol = ncol(Music_preferences)
)




data("Smoking_FASD")

# chisq.test(Smoking_FASD, p = c(0.015, 0.010, 0.975))
#&gt;
#&gt; 	Chi-squared test for given probabilities
#&gt;
#&gt; data:  Smoking_FASD
#&gt; X-squared = 7.8521, df = 2, p-value = 0.01972

chisq_to_fei(
  7.8521,
  n = sum(Smoking_FASD),
  nrow = 1,
  ncol = 3,
  p = c(0.015, 0.010, 0.975)
)

</code></pre>

<hr>
<h2 id='cohens_d'>Cohen's <em>d</em> and Other Standardized Differences</h2><span id='topic+cohens_d'></span><span id='topic+hedges_g'></span><span id='topic+glass_delta'></span>

<h3>Description</h3>

<p>Compute effect size indices for standardized differences: Cohen's <em>d</em>,
Hedges' <em>g</em> and Glassâs <em>delta</em> (<code class="reqn">\Delta</code>). (This function returns the
<strong>population</strong> estimate.) Pair with any reported <code><a href="stats.html#topic+t.test">stats::t.test()</a></code>.
<br /><br />
Both Cohen's <em>d</em> and Hedges' <em>g</em> are the estimated the standardized
difference between the means of two populations. Hedges' <em>g</em> provides a
correction for small-sample bias (using the exact method) to Cohen's <em>d</em>. For
sample sizes &gt; 20, the results for both statistics are roughly equivalent.
Glassâs <em>delta</em> is appropriate when the standard deviations are significantly
different between the populations, as it uses only the <em>second</em> group's
standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cohens_d(
  x,
  y = NULL,
  data = NULL,
  pooled_sd = TRUE,
  mu = 0,
  paired = FALSE,
  adjust = FALSE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)

hedges_g(
  x,
  y = NULL,
  data = NULL,
  pooled_sd = TRUE,
  mu = 0,
  paired = FALSE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)

glass_delta(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  adjust = TRUE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cohens_d_+3A_x">x</code>, <code id="cohens_d_+3A_y">y</code></td>
<td>
<p>A numeric vector, or a character name of one in <code>data</code>.
Any missing values (<code>NA</code>s) are dropped from the resulting vector.
<code>x</code> can also be a formula (see <code><a href="stats.html#topic+t.test">stats::t.test()</a></code>), in which case <code>y</code> is
ignored.</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables.</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_pooled_sd">pooled_sd</code></td>
<td>
<p>If <code>TRUE</code> (default), a <code><a href="#topic+sd_pooled">sd_pooled()</a></code> is used (assuming equal
variance). Else the mean SD from both groups is used instead.</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_mu">mu</code></td>
<td>
<p>a number indicating the true value of the mean (or
difference in means if you are performing a two sample test).</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_paired">paired</code></td>
<td>
<p>If <code>TRUE</code>, the values of <code>x</code> and <code>y</code> are considered as paired.
This produces an effect size that is equivalent to the one-sample effect
size on <code>x - y</code>. See also <code><a href="#topic+repeated_measures_d">repeated_measures_d()</a></code> for more options.</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_adjust">adjust</code></td>
<td>
<p>Should the effect size be adjusted for small-sample bias using
Hedges' method? Note that <code>hedges_g()</code> is an alias for
<code>cohens_d(adjust = TRUE)</code>.</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="cohens_d_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. When <code>x</code> is a formula,
these can be <code>subset</code> and <code>na.action</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Set <code>pooled_sd = FALSE</code> for effect sizes that are to accompany a Welch's
<em>t</em>-test (Delacre et al, 2021).
</p>


<h3>Value</h3>

<p>A data frame with the effect size ( <code>Cohens_d</code>, <code>Hedges_g</code>,
<code>Glass_delta</code>) and their CIs (<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="#topic+effectsize_CIs">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>Note</h3>

<p>The indices here give the population estimated standardized difference.
Some statistical packages give the sample estimate instead (without
applying Bessel's correction).
</p>


<h3>References</h3>


<ul>
<li><p> Algina, J., Keselman, H. J., &amp; Penfield, R. D. (2006). Confidence intervals
for an effect size when variances are not equal. Journal of Modern Applied
Statistical Methods, 5(1), 2.
</p>
</li>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral
sciences (2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Delacre, M., Lakens, D., Ley, C., Liu, L., &amp; Leys, C. (2021, May 7). Why
Hedgesâ g*s based on the non-pooled standard deviation should be reported
with Welch's t-test. <a href="https://doi.org/10.31234/osf.io/tu6mp">doi:10.31234/osf.io/tu6mp</a>
</p>
</li>
<li><p> Hedges, L. V. &amp; Olkin, I. (1985). Statistical methods for
meta-analysis. Orlando, FL: Academic Press.
</p>
</li>
<li><p> Hunter, J. E., &amp; Schmidt, F. L. (2004). Methods of meta-analysis:
Correcting error and bias in research findings. Sage.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rm_d">rm_d()</a></code>, <code><a href="#topic+sd_pooled">sd_pooled()</a></code>, <code><a href="#topic+t_to_d">t_to_d()</a></code>, <code><a href="#topic+r_to_d">r_to_d()</a></code>
</p>
<p>Other standardized differences: 
<code><a href="#topic+mahalanobis_d">mahalanobis_d</a>()</code>,
<code><a href="#topic+means_ratio">means_ratio</a>()</code>,
<code><a href="#topic+p_superiority">p_superiority</a>()</code>,
<code><a href="#topic+rank_biserial">rank_biserial</a>()</code>,
<code><a href="#topic+repeated_measures_d">repeated_measures_d</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mtcars)
mtcars$am &lt;- factor(mtcars$am)

# Two Independent Samples ----------

(d &lt;- cohens_d(mpg ~ am, data = mtcars))
# Same as:
# cohens_d("mpg", "am", data = mtcars)
# cohens_d(mtcars$mpg[mtcars$am=="0"], mtcars$mpg[mtcars$am=="1"])

# More options:
cohens_d(mpg ~ am, data = mtcars, pooled_sd = FALSE)
cohens_d(mpg ~ am, data = mtcars, mu = -5)
cohens_d(mpg ~ am, data = mtcars, alternative = "less")
hedges_g(mpg ~ am, data = mtcars)
glass_delta(mpg ~ am, data = mtcars)


# One Sample ----------

cohens_d(wt ~ 1, data = mtcars)

# same as:
# cohens_d("wt", data = mtcars)
# cohens_d(mtcars$wt)

# More options:
cohens_d(wt ~ 1, data = mtcars, mu = 3)
hedges_g(wt ~ 1, data = mtcars, mu = 3)


# Paired Samples ----------

data(sleep)

cohens_d(Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep)

# same as:
# cohens_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], paired = TRUE)
# cohens_d(sleep$extra[sleep$group == 1] - sleep$extra[sleep$group == 2])
# rm_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], method = "z", adjust = FALSE)

# More options:
cohens_d(Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, mu = -1, verbose = FALSE)
hedges_g(Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, verbose = FALSE)


# Interpretation -----------------------
interpret_cohens_d(-1.48, rules = "cohen1988")
interpret_hedges_g(-1.48, rules = "sawilowsky2009")
interpret_glass_delta(-1.48, rules = "gignac2016")
# Or:
interpret(d, rules = "sawilowsky2009")

# Common Language Effect Sizes
d_to_u3(1.48)
# Or:
print(d, append_CLES = TRUE)


</code></pre>

<hr>
<h2 id='cohens_g'>Effect Size for Paired Contingency Tables</h2><span id='topic+cohens_g'></span>

<h3>Description</h3>

<p>Cohen's <em>g</em> is an effect size of asymmetry (or marginal heterogeneity) for
dependent (paired) contingency tables ranging between 0 (perfect symmetry)
and 0.5 (perfect asymmetry) (see <code><a href="stats.html#topic+mcnemar.test">stats::mcnemar.test()</a></code>). (Note this is not
<em>not</em> a measure of (dis)agreement between the pairs, but of (a)symmetry.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cohens_g(x, y = NULL, ci = 0.95, alternative = "two.sided", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cohens_g_+3A_x">x</code></td>
<td>
<p>a numeric vector or matrix. <code>x</code> and <code>y</code> can also
both be factors.</p>
</td></tr>
<tr><td><code id="cohens_g_+3A_y">y</code></td>
<td>
<p>a numeric vector; ignored if <code>x</code> is a matrix.  If
<code>x</code> is a factor, <code>y</code> should be a factor of the same length.</p>
</td></tr>
<tr><td><code id="cohens_g_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="cohens_g_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="cohens_g_+3A_...">...</code></td>
<td>
<p>Ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the effect size (<code>Cohens_g</code>, <code>Risk_ratio</code>
(possibly with the prefix <code>log_</code>), <code>Cohens_h</code>) and its CIs (<code>CI_low</code> and
<code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Confidence intervals are based on the proportion (<code class="reqn">P = g + 0.5</code>)
confidence intervals returned by <code><a href="stats.html#topic+prop.test">stats::prop.test()</a></code> (minus 0.5), which give
a good close approximation.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other effect sizes for contingency table: 
<code><a href="#topic+oddsratio">oddsratio</a>()</code>,
<code><a href="#topic+phi">phi</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("screening_test")

phi(screening_test$Diagnosis, screening_test$Test1)

phi(screening_test$Diagnosis, screening_test$Test2)

# Both tests seem comparable - but are the tests actually different?

(tests &lt;- table(Test1 = screening_test$Test1, Test2 = screening_test$Test2))

mcnemar.test(tests)

cohens_g(tests)

# Test 2 gives a negative result more than test 1!

</code></pre>

<hr>
<h2 id='d_to_r'>Convert Between <em>d</em>, <em>r</em>, and Odds Ratio</h2><span id='topic+d_to_r'></span><span id='topic+r_to_d'></span><span id='topic+oddsratio_to_d'></span><span id='topic+logoddsratio_to_d'></span><span id='topic+d_to_oddsratio'></span><span id='topic+d_to_logoddsratio'></span><span id='topic+oddsratio_to_r'></span><span id='topic+logoddsratio_to_r'></span><span id='topic+r_to_oddsratio'></span><span id='topic+r_to_logoddsratio'></span>

<h3>Description</h3>

<p>Enables a conversion between different indices of effect size, such as
standardized difference (Cohen's d), (point-biserial) correlation r or (log) odds ratios.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d_to_r(d, n1, n2, ...)

r_to_d(r, n1, n2, ...)

oddsratio_to_d(OR, p0, log = FALSE, ...)

logoddsratio_to_d(logOR, p0, log = TRUE, ...)

d_to_oddsratio(d, log = FALSE, ...)

d_to_logoddsratio(d, log = TRUE, ...)

oddsratio_to_r(OR, p0, n1, n2, log = FALSE, ...)

logoddsratio_to_r(logOR, p0, n1, n2, log = TRUE, ...)

r_to_oddsratio(r, n1, n2, log = FALSE, ...)

r_to_logoddsratio(r, n1, n2, log = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="d_to_r_+3A_d">d</code>, <code id="d_to_r_+3A_r">r</code>, <code id="d_to_r_+3A_or">OR</code>, <code id="d_to_r_+3A_logor">logOR</code></td>
<td>
<p>Standardized difference value (Cohen's d), correlation
coefficient (r), Odds ratio, or logged Odds ratio.</p>
</td></tr>
<tr><td><code id="d_to_r_+3A_n1">n1</code>, <code id="d_to_r_+3A_n2">n2</code></td>
<td>
<p>Group sample sizes. If either is missing, groups are assumed to be of equal size.</p>
</td></tr>
<tr><td><code id="d_to_r_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="d_to_r_+3A_p0">p0</code></td>
<td>
<p>Baseline risk. If not specified, the <em>d</em> to <em>OR</em> conversion uses am approximation (see details).</p>
</td></tr>
<tr><td><code id="d_to_r_+3A_log">log</code></td>
<td>
<p>Take in or output the log of the ratio (such as in logistic models),
e.g. when the desired input or output are log odds ratios instead odds ratios.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conversions between <em>d</em> and <em>OR</em> is done through these formulae:
</p>

<ul>
<li> <p><code class="reqn">d = \frac{\log(OR)\times\sqrt{3}}{\pi}</code>
</p>
</li>
<li> <p><code class="reqn">log(OR) = d * \frac{\pi}{\sqrt(3)}</code>
</p>
</li></ul>

<p>Converting between <em>d</em> and <em>r</em> is done through these formulae:
</p>

<ul>
<li> <p><code class="reqn">d = \frac{\sqrt{h} * r}{\sqrt{1 - r^2}}</code>
</p>
</li>
<li> <p><code class="reqn">r = \frac{d}{\sqrt{d^2 + h}}</code>
</p>
</li></ul>

<p>Where <code class="reqn">h = \frac{n_1 + n_2 - 2}{n_1} + \frac{n_1 + n_2 - 2}{n_2}</code>.
When groups are of equal size, <em>h</em> reduces to approximately 4. The resulting
<em>r</em> is also called the binomial effect size display (BESD; Rosenthal et al.,
1982).
</p>


<h3>Value</h3>

<p>Converted index.
</p>


<h3>References</h3>


<ul>
<li><p> Borenstein, M., Hedges, L. V., Higgins, J. P. T., &amp; Rothstein, H. R.
(2009). Converting among effect sizes. Introduction to meta-analysis, 45-49.
</p>
</li>
<li><p> Jacobs, P., &amp; Viechtbauer, W. (2017). Estimation of the biserial
correlation and its sampling variance for use in meta-analysis. Research
synthesis methods, 8(2), 161-180. <a href="https://doi.org/10.1002/jrsm.1218">doi:10.1002/jrsm.1218</a>
</p>
</li>
<li><p> Rosenthal, R., &amp; Rubin, D. B. (1982). A simple, general purpose display of
magnitude of experimental effect. Journal of educational psychology, 74(2), 166.
</p>
</li>
<li><p> SÃ¡nchez-Meca, J., MarÃ­n-MartÃ­nez, F., &amp; ChacÃ³n-Moscoso, S. (2003).
Effect-size indices for dichotomized outcomes in meta-analysis. Psychological
methods, 8(4), 448.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cohens_d">cohens_d()</a></code>
</p>
<p>Other convert between effect sizes: 
<code><a href="#topic+diff_to_cles">diff_to_cles</a></code>,
<code><a href="#topic+eta2_to_f2">eta2_to_f2</a>()</code>,
<code><a href="#topic+odds_to_probs">odds_to_probs</a>()</code>,
<code><a href="#topic+oddsratio_to_riskratio">oddsratio_to_riskratio</a>()</code>,
<code><a href="#topic+w_to_fei">w_to_fei</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r_to_d(0.5)
d_to_oddsratio(1.154701)
oddsratio_to_r(8.120534)

d_to_r(1)
r_to_oddsratio(0.4472136, log = TRUE)
oddsratio_to_d(1.813799, log = TRUE)

</code></pre>

<hr>
<h2 id='diff_to_cles'>Convert Standardized Differences to Common Language Effect Sizes</h2><span id='topic+diff_to_cles'></span><span id='topic+d_to_p_superiority'></span><span id='topic+d_to_cles'></span><span id='topic+rb_to_cles'></span><span id='topic+rb_to_p_superiority'></span><span id='topic+rb_to_vda'></span><span id='topic+d_to_u2'></span><span id='topic+d_to_u1'></span><span id='topic+d_to_u3'></span><span id='topic+d_to_overlap'></span><span id='topic+rb_to_wmw_odds'></span>

<h3>Description</h3>

<p>Convert Standardized Differences to Common Language Effect Sizes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d_to_p_superiority(d)

rb_to_p_superiority(rb)

rb_to_vda(rb)

d_to_u2(d)

d_to_u1(d)

d_to_u3(d)

d_to_overlap(d)

rb_to_wmw_odds(rb)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="diff_to_cles_+3A_d">d</code>, <code id="diff_to_cles_+3A_rb">rb</code></td>
<td>
<p>A numeric vector of Cohen's d / rank-biserial correlation <em>or</em>
the output from <code><a href="#topic+cohens_d">cohens_d()</a></code> / <code><a href="#topic+rank_biserial">rank_biserial()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function use the following formulae for Cohen's <em>d</em>:
</p>
<p style="text-align: center;"><code class="reqn">Pr(superiority) = \Phi(d/\sqrt{2})</code>
</p>

<p><br />
</p>
<p style="text-align: center;"><code class="reqn">\textrm{Cohen's } U_3 = \Phi(d)</code>
</p>

<p><br />
</p>
<p style="text-align: center;"><code class="reqn">\textrm{Cohen's } U_2 = \Phi(|d|/2)</code>
</p>

<p><br />
</p>
<p style="text-align: center;"><code class="reqn">\textrm{Cohen's } U_1 = (2\times U_2 - 1)/U_2</code>
</p>

<p><br />
</p>
<p style="text-align: center;"><code class="reqn">Overlap = 2 \times \Phi(-|d|/2)</code>
</p>

<p><br />
And the following for the rank-biserial correlation:
</p>
<p style="text-align: center;"><code class="reqn">Pr(superiority) = (r_{rb} + 1)/2</code>
</p>

<p><br />
<code class="reqn">WMW_{Odds} = Pr(superiority) / (1 - Pr(superiority))</code>
</p>


<h3>Value</h3>

<p>A list of <code style="white-space: pre;">&#8288;Cohen's U3&#8288;</code>, <code>Overlap</code>, <code>Pr(superiority)</code>, a
numeric vector of <code>Pr(superiority)</code>, or a data frame, depending
on the input.
</p>


<h3>Note</h3>

<p>For <em>d</em>, these calculations assume that the populations have equal variance
and are normally distributed.
</p>
<p>Vargha and Delaney's <em>A</em> is an alias for the non-parametric <em>probability of
superiority</em>.
</p>


<h3>References</h3>


<ul>
<li><p> Cohen, J. (1977). Statistical power analysis for the behavioral sciences.
New York: Routledge.
</p>
</li>
<li><p> Reiser, B., &amp; Faraggi, D. (1999). Confidence intervals for the overlapping
coefficient: the normal equal variance case. Journal of the Royal Statistical
Society, 48(3), 413-418.
</p>
</li>
<li><p> Ruscio, J. (2008). A probability-based measure of effect size: robustness
to base rates and other factors. Psychological methods, 13(1), 19â30.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cohens_u3">cohens_u3()</a></code> for descriptions of the effect sizes (also,
<code><a href="#topic+cohens_d">cohens_d()</a></code>, <code><a href="#topic+rank_biserial">rank_biserial()</a></code>).
</p>
<p>Other convert between effect sizes: 
<code><a href="#topic+d_to_r">d_to_r</a>()</code>,
<code><a href="#topic+eta2_to_f2">eta2_to_f2</a>()</code>,
<code><a href="#topic+odds_to_probs">odds_to_probs</a>()</code>,
<code><a href="#topic+oddsratio_to_riskratio">oddsratio_to_riskratio</a>()</code>,
<code><a href="#topic+w_to_fei">w_to_fei</a>()</code>
</p>

<hr>
<h2 id='effectsize_API'><code>effectsize</code> API</h2><span id='topic+effectsize_API'></span><span id='topic+.es_aov_simple'></span><span id='topic+.es_aov_strata'></span><span id='topic+.es_aov_table'></span>

<h3>Description</h3>

<p>Read the <a href="https://easystats.github.io/effectsize/articles/effectsize_API.html"><em>Support functions for model extensions</em></a> vignette.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.es_aov_simple(
  aov_table,
  type = c("eta", "omega", "epsilon"),
  partial = TRUE,
  generalized = FALSE,
  include_intercept = FALSE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE
)

.es_aov_strata(
  aov_table,
  DV_names,
  type = c("eta", "omega", "epsilon"),
  partial = TRUE,
  generalized = FALSE,
  include_intercept = FALSE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE
)

.es_aov_table(
  aov_table,
  type = c("eta", "omega", "epsilon"),
  partial = TRUE,
  generalized = FALSE,
  include_intercept = FALSE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="effectsize_API_+3A_aov_table">aov_table</code></td>
<td>
<p>Input data frame</p>
</td></tr>
<tr><td><code id="effectsize_API_+3A_type">type</code></td>
<td>
<p>Which effect size to compute?</p>
</td></tr>
<tr><td><code id="effectsize_API_+3A_partial">partial</code>, <code id="effectsize_API_+3A_generalized">generalized</code>, <code id="effectsize_API_+3A_ci">ci</code>, <code id="effectsize_API_+3A_alternative">alternative</code>, <code id="effectsize_API_+3A_verbose">verbose</code></td>
<td>
<p>See <code><a href="#topic+eta_squared">eta_squared()</a></code>.</p>
</td></tr>
<tr><td><code id="effectsize_API_+3A_include_intercept">include_intercept</code></td>
<td>
<p>Should the intercept (<code>(Intercept)</code>) be included?</p>
</td></tr>
<tr><td><code id="effectsize_API_+3A_dv_names">DV_names</code></td>
<td>
<p>A character vector with the names of all the predictors,
including the grouping variable (e.g., <code>"Subject"</code>).</p>
</td></tr>
</table>

<hr>
<h2 id='effectsize_CIs'>Confidence (Compatibility) Intervals</h2><span id='topic+effectsize_CIs'></span>

<h3>Description</h3>

<p>More information regarding Confidence (Compatibiity) Intervals and how
they are computed in <em>effectsize</em>.
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="#topic+effectsize_CIs">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Bootstrapped CIs</h3>

<p>Some effect sizes are directionless&ndash;they do have a minimum value that would
be interpreted as &quot;no effect&quot;, but they cannot cross it. For example, a null
value of <a href="#topic+kendalls_w">Kendall's W</a> is 0, indicating no difference between
groups, but it can never have a negative value. Same goes for
<a href="#topic+cohens_u2">U2</a> and <a href="#topic+p_overlap">Overlap</a>: the null value of <code class="reqn">U_2</code> is
0.5, but it can never be smaller than 0.5; am <em>Overlap</em> of 1 means &quot;full
overlap&quot; (no difference), but it cannot be larger than 1.
<br /><br />
When bootstrapping CIs for such effect sizes, the bounds of the CIs will
never cross (and often will never cover) the null. Therefore, these CIs
should not be used for statistical inference.
</p>


<h3>One-Sided CIs</h3>

<p>Typically, CIs are constructed as two-tailed intervals, with an equal
proportion of the cumulative probability distribution above and below the
interval. CIs can also be constructed as <em>one-sided</em> intervals,
giving only a lower bound or upper bound. This is analogous to computing a
1-tailed <em>p</em> value or conducting a 1-tailed hypothesis test.
<br /><br />
Significance tests conducted using CIs (whether a value is inside the interval)
and using <em>p</em> values (whether p &lt; alpha for that value) are only guaranteed
to agree when both are constructed using the same number of sides/tails.
<br /><br />
Most effect sizes are not bounded by zero (e.g., <em>r</em>, <em>d</em>, <em>g</em>), and as such
are generally tested using 2-tailed tests and 2-sided CIs.
<br /><br />
Some effect sizes are strictly positive&ndash;they do have a minimum value, of 0.
For example, <code class="reqn">R^2</code>, <code class="reqn">\eta^2</code>, <code class="reqn">sr^2</code>, and other variance-accounted-for effect
sizes, as well as Cramer's <em>V</em> and multiple <em>R</em>, range from 0 to 1. These
typically involve <em>F</em>- or <code class="reqn">\chi^2</code>-statistics and are generally tested
using <em>1-tailed</em> tests which test whether the estimated effect size is
<em>larger</em> than the hypothesized null value (e.g., 0). In order for a CI to
yield the same significance decision it must then by a <em>1-sided</em> CI,
estimating only a lower bound. This is the default CI computed by
<em>effectsize</em> for these effect sizes, where <code>alternative = "greater"</code> is set.
<br /><br />
This lower bound interval indicates the smallest effect size that is not
significantly different from the observed effect size. That is, it is the
minimum effect size compatible with the observed data, background model
assumptions, and <code class="reqn">\alpha</code> level. This type of interval does not indicate
a maximum effect size value; anything up to the maximum possible value of the
effect size (e.g., 1) is in the interval.
<br /><br />
One-sided CIs can also be used to test against a maximum effect size value
(e.g., is <code class="reqn">R^2</code> significantly smaller than a perfect correlation of 1.0?)
by setting <code>alternative = "less"</code>. This estimates a CI with only an
<em>upper</em> bound; anything from the minimum possible value of the effect size
(e.g., 0) up to this upper bound is in the interval.
<br /><br />
We can also obtain a 2-sided interval by setting <code>alternative = "two.sided"</code>.
These intervals can be interpreted in the same way as other 2-sided
intervals, such as those for <em>r</em>, <em>d</em>, or <em>g</em>.
<br /><br />
An alternative approach to aligning significance tests using CIs and 1-tailed
<em>p</em> values that can often be found in the literature is to construct a
2-sided CI at a lower confidence level (e.g., 100(1-2<code class="reqn">\alpha</code>)% = 100 -
2*5% = 90%. This estimates the lower bound and upper bound for the above
1-sided intervals simultaneously. These intervals are commonly reported when
conducting <strong>equivalence tests</strong>. For example, a 90% 2-sided interval gives
the bounds for an equivalence test with <code class="reqn">\alpha</code> = .05. However, be aware
that this interval does not give 95% coverage for the underlying effect size
parameter value. For that, construct a 95% 2-sided CI.
</p>
<div class="sourceCode r"><pre>data("hardlyworking")
fit &lt;- lm(salary ~ n_comps, data = hardlyworking)
eta_squared(fit) # default, ci = 0.95, alternative = "greater"
#&gt; For one-way between subjects designs, partial eta squared is equivalent
#&gt;   to eta squared. Returning eta squared.
#&gt; # Effect Size for ANOVA
#&gt; 
#&gt; Parameter | Eta2 |       95% CI
#&gt; -------------------------------
#&gt; n_comps   | 0.19 | [0.14, 1.00]
#&gt; 
#&gt; - One-sided CIs: upper bound fixed at [1.00].
eta_squared(fit, alternative = "less") # Test is eta is smaller than some value
#&gt; For one-way between subjects designs, partial eta squared is equivalent
#&gt;   to eta squared. Returning eta squared.
#&gt; # Effect Size for ANOVA
#&gt; 
#&gt; Parameter | Eta2 |       95% CI
#&gt; -------------------------------
#&gt; n_comps   | 0.19 | [0.00, 0.24]
#&gt; 
#&gt; - One-sided CIs: lower bound fixed at [0.00].
eta_squared(fit, alternative = "two.sided") # 2-sided bounds for alpha = .05
#&gt; For one-way between subjects designs, partial eta squared is equivalent
#&gt;   to eta squared. Returning eta squared.
#&gt; # Effect Size for ANOVA
#&gt; 
#&gt; Parameter | Eta2 |       95% CI
#&gt; -------------------------------
#&gt; n_comps   | 0.19 | [0.14, 0.25]
eta_squared(fit, ci = 0.9, alternative = "two.sided") # both 1-sided bounds for alpha = .05
#&gt; For one-way between subjects designs, partial eta squared is equivalent
#&gt;   to eta squared. Returning eta squared.
#&gt; # Effect Size for ANOVA
#&gt; 
#&gt; Parameter | Eta2 |       90% CI
#&gt; -------------------------------
#&gt; n_comps   | 0.19 | [0.14, 0.24]
</pre></div>


<h3>CI Does Not Contain the Estimate</h3>

<p>For very large sample sizes or effect sizes, the width of the CI can be
smaller than the tolerance of the optimizer, resulting in CIs of width 0.
This can also result in the estimated CIs excluding the point estimate.
</p>
<p>In these cases, consider an alternative method for computing CIs, such as the
bootstrap.
</p>


<h3>References</h3>

<p>Bauer, P., &amp; Kieser, M. (1996).
A unifying approach for confidence intervals and testing of equivalence and difference.
<em>Biometrika, 83</em>(4), 934-â937.
<a href="https://doi.org/10.1093/biomet/83.4.934">doi:10.1093/biomet/83.4.934</a>
</p>
<p>Rafi, Z., &amp; Greenland, S. (2020).
Semantic and cognitive tools to aid statistical science: Replace confidence and significance by compatibility and surprise.
<em>BMC Medical Research Methodology, 20</em>(1), Article 244.
<a href="https://doi.org/10.1186/s12874-020-01105-9">doi:10.1186/s12874-020-01105-9</a>
</p>
<p>Schweder, T., &amp; Hjort, N. L. (2016).
<em>Confidence, likelihood, probability: Statistical inference with confidence distributions.</em>
Cambridge University Press.
<a href="https://doi.org/10.1017/CBO9781139046671">doi:10.1017/CBO9781139046671</a>
</p>
<p>Steiger, J. H. (2004).
Beyond the <em>F</em> test: Effect size confidence intervals and tests of close fit in the analysis of variance and contrast analysis.
<em>Psychological Methods, 9</em>(2), 164&ndash;182.
<a href="https://doi.org/10.1037/1082-989x.9.2.164">doi:10.1037/1082-989x.9.2.164</a>
</p>
<p>Xie, M., &amp; Singh, K. (2013).
Confidence distribution, the frequentist distribution estimator of a parameter: A review.
<em>International Statistical Review, 81</em>(1), 3â-39.
<a href="https://doi.org/10.1111/insr.12000">doi:10.1111/insr.12000</a>
</p>

<hr>
<h2 id='effectsize_deprecated'>Deprecated / Defunct Functions</h2><span id='topic+effectsize_deprecated'></span><span id='topic+convert_odds_to_probs'></span><span id='topic+convert_probs_to_odds'></span><span id='topic+convert_d_to_r'></span><span id='topic+convert_r_to_d'></span><span id='topic+convert_oddsratio_to_d'></span><span id='topic+convert_d_to_oddsratio'></span><span id='topic+convert_oddsratio_to_r'></span><span id='topic+convert_r_to_oddsratio'></span>

<h3>Description</h3>

<p>Deprecated / Defunct Functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_odds_to_probs(...)

convert_probs_to_odds(...)

convert_d_to_r(...)

convert_r_to_d(...)

convert_oddsratio_to_d(...)

convert_d_to_oddsratio(...)

convert_oddsratio_to_r(...)

convert_r_to_oddsratio(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="effectsize_deprecated_+3A_...">...</code></td>
<td>
<p>Arguments to the deprecated function.</p>
</td></tr>
</table>

<hr>
<h2 id='effectsize_options'><code>effectsize</code> options</h2><span id='topic+effectsize_options'></span>

<h3>Description</h3>

<p>Currently, the following global options are supported:
</p>

<ul>
<li> <p><code>es.use_symbols</code> <a href="base.html#topic+logical">logical</a>: Should proper symbols be printed (<code>TRUE</code>) instead of transliterated effect size names (<code>FALSE</code>; default).
</p>
</li></ul>


<hr>
<h2 id='effectsize.BFBayesFactor'>Effect Sizes</h2><span id='topic+effectsize.BFBayesFactor'></span><span id='topic+effectsize'></span><span id='topic+effectsize.aov'></span><span id='topic+effectsize.htest'></span>

<h3>Description</h3>

<p>This function tries to return the best effect-size measure for the provided
input model. See details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BFBayesFactor'
effectsize(model, type = NULL, ci = 0.95, test = NULL, verbose = TRUE, ...)

effectsize(model, ...)

## S3 method for class 'aov'
effectsize(model, type = NULL, ...)

## S3 method for class 'htest'
effectsize(model, type = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="effectsize.BFBayesFactor_+3A_model">model</code></td>
<td>
<p>An object of class <code>htest</code>, or a statistical model. See details.</p>
</td></tr>
<tr><td><code id="effectsize.BFBayesFactor_+3A_type">type</code></td>
<td>
<p>The effect size of interest. See details.</p>
</td></tr>
<tr><td><code id="effectsize.BFBayesFactor_+3A_ci">ci</code></td>
<td>
<p>Value or vector of probability of the CI (between 0 and 1)
to be estimated. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="effectsize.BFBayesFactor_+3A_test">test</code></td>
<td>
<p>The indices of effect existence to compute. Character (vector) or
list with one or more of these options: <code>"p_direction"</code> (or <code>"pd"</code>),
<code>"rope"</code>, <code>"p_map"</code>, <code>"equivalence_test"</code> (or <code>"equitest"</code>),
<code>"bayesfactor"</code> (or <code>"bf"</code>) or <code>"all"</code> to compute all tests. For each
&quot;test&quot;, the corresponding <span class="pkg">bayestestR</span> function is called (e.g.
<code><a href="bayestestR.html#topic+rope">rope()</a></code> or <code><a href="bayestestR.html#topic+p_direction">p_direction()</a></code>) and its results included in the summary
output.</p>
</td></tr>
<tr><td><code id="effectsize.BFBayesFactor_+3A_verbose">verbose</code></td>
<td>
<p>Toggle off warnings.</p>
</td></tr>
<tr><td><code id="effectsize.BFBayesFactor_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. See details.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> For an object of class <code>htest</code>, data is extracted via <code><a href="insight.html#topic+get_data">insight::get_data()</a></code>, and passed to the relevant function according to:
</p>

<ul>
<li><p> A <strong>t-test</strong> depending on <code>type</code>: <code>"cohens_d"</code> (default), <code>"hedges_g"</code>, or one of <code>"p_superiority"</code>, <code>"u1"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>

<ul>
<li><p> For a <strong>Paired t-test</strong>: depending on <code>type</code>: <code>"rm_rm"</code>, <code>"rm_av"</code>, <code>"rm_b"</code>, <code>"rm_d"</code>, <code>"rm_z"</code>.
</p>
</li></ul>

</li>
<li><p> A <strong>Chi-squared tests of independence</strong> or <strong>Fisher's Exact Test</strong>, depending on <code>type</code>: <code>"cramers_v"</code> (default), <code>"tschuprows_t"</code>, <code>"phi"</code>, <code>"cohens_w"</code>, <code>"pearsons_c"</code>, <code>"cohens_h"</code>, <code>"oddsratio"</code>, <code>"riskratio"</code>, <code>"arr"</code>, or <code>"nnt"</code>.
</p>
</li>
<li><p> A <strong>Chi-squared tests of goodness-of-fit</strong>, depending on <code>type</code>: <code>"fei"</code> (default) <code>"cohens_w"</code>, <code>"pearsons_c"</code>
</p>
</li>
<li><p> A <strong>One-way ANOVA test</strong>, depending on <code>type</code>: <code>"eta"</code> (default), <code>"omega"</code> or <code>"epsilon"</code> -squared, <code>"f"</code>, or <code>"f2"</code>.
</p>
</li>
<li><p> A <strong>McNemar test</strong> returns <em>Cohen's g</em>.
</p>
</li>
<li><p> A <strong>Wilcoxon test</strong> depending on <code>type</code>: returns &quot;<code>rank_biserial</code>&quot; correlation (default) or one of <code>"p_superiority"</code>, <code>"vda"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>
</li>
<li><p> A <strong>Kruskal-Wallis test</strong> depending on <code>type</code>: <code>"epsilon"</code> (default) or <code>"eta"</code>.
</p>
</li>
<li><p> A <strong>Friedman test</strong> returns <em>Kendall's W</em>.
(Where applicable, <code>ci</code> and <code>alternative</code> are taken from the <code>htest</code> if not otherwise provided.)
</p>
</li></ul>

</li>
<li><p> For an object of class <code>BFBayesFactor</code>, using <code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code>,
</p>

<ul>
<li><p> A <strong>t-test</strong> depending on <code>type</code>: <code>"cohens_d"</code> (default) or one of <code>"p_superiority"</code>, <code>"u1"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>
</li>
<li><p> A <strong>correlation test</strong> returns <em>r</em>.
</p>
</li>
<li><p> A <strong>contingency table test</strong>, depending on <code>type</code>: <code>"cramers_v"</code> (default), <code>"phi"</code>, <code>"tschuprows_t"</code>, <code>"cohens_w"</code>, <code>"pearsons_c"</code>, <code>"cohens_h"</code>, <code>"oddsratio"</code>, or <code>"riskratio"</code>, <code>"arr"</code>, or <code>"nnt"</code>.
</p>
</li>
<li><p> A <strong>proportion test</strong> returns <em>p</em>.
</p>
</li></ul>

</li>
<li><p> Objects of class <code>anova</code>, <code>aov</code>, <code>aovlist</code> or <code>afex_aov</code>, depending on <code>type</code>: <code>"eta"</code> (default), <code>"omega"</code> or <code>"epsilon"</code> -squared, <code>"f"</code>, or <code>"f2"</code>.
</p>
</li>
<li><p> Other objects are passed to <code><a href="parameters.html#topic+standardize_parameters">parameters::standardize_parameters()</a></code>.
</p>
</li></ul>

<p><strong>For statistical models it is recommended to directly use the listed
functions, for the full range of options they provide.</strong>
</p>


<h3>Value</h3>

<p>A data frame with the effect size (depending on input) and and its
CIs (<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>See Also</h3>

<p><code>vignette(package = "effectsize")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Hypothesis Testing
## ------------------
data("Music_preferences")
Xsq &lt;- chisq.test(Music_preferences)
effectsize(Xsq)
effectsize(Xsq, type = "cohens_w")

Tt &lt;- t.test(1:10, y = c(7:20), alternative = "less")
effectsize(Tt)

Tt &lt;- t.test(
  x = c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30),
  y = c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29),
  paired = TRUE
)
effectsize(Tt, type = "rm_b")

Aov &lt;- oneway.test(extra ~ group, data = sleep, var.equal = TRUE)
effectsize(Aov)
effectsize(Aov, type = "omega")

Wt &lt;- wilcox.test(1:10, 7:20, mu = -3, alternative = "less", exact = FALSE)
effectsize(Wt)
effectsize(Wt, type = "u2")

## Models and Anova Tables
## -----------------------
fit &lt;- lm(mpg ~ factor(cyl) * wt + hp, data = mtcars)
effectsize(fit, method = "basic")

anova_table &lt;- anova(fit)
effectsize(anova_table)
effectsize(anova_table, type = "epsilon")


## Bayesian Hypothesis Testing
## ---------------------------
bf_prop &lt;- BayesFactor::proportionBF(3, 7, p = 0.3)
effectsize(bf_prop)

bf_corr &lt;- BayesFactor::correlationBF(attitude$rating, attitude$complaints)
effectsize(bf_corr)

data(RCT_table)
bf_xtab &lt;- BayesFactor::contingencyTableBF(RCT_table, sampleType = "poisson", fixedMargin = "cols")
effectsize(bf_xtab)
effectsize(bf_xtab, type = "oddsratio")
effectsize(bf_xtab, type = "arr")

bf_ttest &lt;- BayesFactor::ttestBF(sleep$extra[sleep$group == 1],
  sleep$extra[sleep$group == 2],
  paired = TRUE, mu = -1
)
effectsize(bf_ttest)

</code></pre>

<hr>
<h2 id='equivalence_test.effectsize_table'>Test Effect Size for Practical Equivalence to the Null</h2><span id='topic+equivalence_test.effectsize_table'></span>

<h3>Description</h3>

<p>Perform a <strong>Test for Practical Equivalence</strong> for indices of
effect size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'effectsize_table'
equivalence_test(
  x,
  range = "default",
  rule = c("classic", "cet", "bayes"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="equivalence_test.effectsize_table_+3A_x">x</code></td>
<td>
<p>An effect size table, such as returned by <code><a href="#topic+cohens_d">cohens_d()</a></code>,
<code><a href="#topic+eta_squared">eta_squared()</a></code>, <code><a href="#topic+F_to_r">F_to_r()</a></code>, etc.</p>
</td></tr>
<tr><td><code id="equivalence_test.effectsize_table_+3A_range">range</code></td>
<td>
<p>The range of practical equivalence of an effect. For one-sides
CIs, a single value can be proved for the lower / upper bound to test
against (but see more details below). For two-sided CIs, a single value is
duplicated to <code>c(-range, range)</code>. If <code>"default"</code>, will be set to <code style="white-space: pre;">&#8288;[-.1, .1]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="equivalence_test.effectsize_table_+3A_rule">rule</code></td>
<td>
<p>How should acceptance and rejection be decided? See details.</p>
</td></tr>
<tr><td><code id="equivalence_test.effectsize_table_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The CIs used in the equivalence test are the ones in the provided effect size
table. For results equivalent (ha!) to those that can be obtained using the
TOST approach (e.g., Lakens, 2017), appropriate CIs should be extracted using
the function used to make the effect size table (<code>cohens_d</code>, <code>eta_squared</code>,
<code>F_to_r</code>, etc), with <code>alternative = "two.sided"</code>. See examples.
</p>


<h4>The Different Rules</h4>


<ul>
<li> <p><code>"classic"</code> - <strong>the classic method</strong>:
</p>

<ul>
<li><p> If the CI is completely within the ROPE - <em>Accept H0</em>
</p>
</li>
<li><p> Else, if the CI does not contain 0 - <em>Reject H0</em>
</p>
</li>
<li><p> Else - <em>Undecided</em>
</p>
</li></ul>

</li>
<li> <p><code>"cet"</code> - <strong>conditional equivalence testing</strong>:
</p>

<ul>
<li><p> If the CI does not contain 0 - <em>Reject H0</em>
</p>
</li>
<li><p> Else, If the CI is completely within the ROPE - <em>Accept H0</em>
</p>
</li>
<li><p> Else - <em>Undecided</em>
</p>
</li></ul>

</li>
<li> <p><code>"bayes"</code> - <strong>The Bayesian approach</strong>, as put forth by Kruschke:
</p>

<ul>
<li><p> If the CI does is completely outside the ROPE - <em>Reject H0</em>
</p>
</li>
<li><p> Else, If the CI is completely within the ROPE - <em>Accept H0</em>
</p>
</li>
<li><p> Else - <em>Undecided</em>
</p>
</li></ul>

</li></ul>




<h3>Value</h3>

<p>A data frame with the results of the equivalence test.
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Campbell, H., &amp; Gustafson, P. (2018). Conditional equivalence testing: An
alternative remedy for publication bias. PLOS ONE, 13(4), e0195145.
<a href="https://doi.org/10.1371/journal.pone.0195145">doi:10.1371/journal.pone.0195145</a>
</p>
</li>
<li><p> Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with R,
JAGS, and Stan. Academic Press
</p>
</li>
<li><p> Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian
estimation. Advances in Methods and Practices in Psychological Science, 1(2),
270-280. <a href="https://doi.org/10.1177/2515245918771304">doi:10.1177/2515245918771304</a>
</p>
</li>
<li><p> Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests,
Correlations, and Meta-Analyses. Social Psychological and Personality
Science, 8(4), 355â362. <a href="https://doi.org/10.1177/1948550617697177">doi:10.1177/1948550617697177</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>For more details, see <code><a href="bayestestR.html#topic+equivalence_test">bayestestR::equivalence_test()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("hardlyworking")
model &lt;- aov(salary ~ age + factor(n_comps) * cut(seniority, 3), data = hardlyworking)
es &lt;- eta_squared(model, ci = 0.9, alternative = "two.sided")
equivalence_test(es, range = c(0, 0.15)) # TOST

data("RCT_table")
OR &lt;- oddsratio(RCT_table, alternative = "greater")
equivalence_test(OR, range = c(0, 1))

ds &lt;- t_to_d(
  t = c(0.45, -0.65, 7, -2.2, 2.25),
  df_error = c(675, 525, 2000, 900, 1875),
  ci = 0.9, alternative = "two.sided" # TOST
)
# Can also plot
if (require(see)) plot(equivalence_test(ds, range = 0.2))
if (require(see)) plot(equivalence_test(ds, range = 0.2, rule = "cet"))
if (require(see)) plot(equivalence_test(ds, range = 0.2, rule = "bayes"))


</code></pre>

<hr>
<h2 id='eta_squared'><code class="reqn">\eta^2</code> and Other Effect Size for ANOVA</h2><span id='topic+eta_squared'></span><span id='topic+omega_squared'></span><span id='topic+epsilon_squared'></span><span id='topic+cohens_f'></span><span id='topic+cohens_f_squared'></span><span id='topic+eta_squared_posterior'></span>

<h3>Description</h3>

<p>Functions to compute effect size measures for ANOVAs, such as Eta-
(<code class="reqn">\eta</code>), Omega- (<code class="reqn">\omega</code>) and Epsilon- (<code class="reqn">\epsilon</code>) squared,
and Cohen's f (or their partialled versions) for ANOVA tables. These indices
represent an estimate of how much variance in the response variables is
accounted for by the explanatory variable(s).
<br /><br />
When passing models, effect sizes are computed using the sums of squares
obtained from <code>anova(model)</code> which might not always be appropriate. See
details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eta_squared(
  model,
  partial = TRUE,
  generalized = FALSE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

omega_squared(
  model,
  partial = TRUE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

epsilon_squared(
  model,
  partial = TRUE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

cohens_f(
  model,
  partial = TRUE,
  generalized = FALSE,
  squared = FALSE,
  method = c("eta", "omega", "epsilon"),
  model2 = NULL,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

cohens_f_squared(
  model,
  partial = TRUE,
  generalized = FALSE,
  squared = TRUE,
  method = c("eta", "omega", "epsilon"),
  model2 = NULL,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

eta_squared_posterior(
  model,
  partial = TRUE,
  generalized = FALSE,
  ss_function = stats::anova,
  draws = 500,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eta_squared_+3A_model">model</code></td>
<td>
<p>An ANOVA table (or an ANOVA-like table, e.g., outputs from
<code>parameters::model_parameters</code>), or a statistical model for which such a
table can be extracted. See details.</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_partial">partial</code></td>
<td>
<p>If <code>TRUE</code>, return partial indices.</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_generalized">generalized</code></td>
<td>
<p>A character vector of observed (non-manipulated) variables
to be used in the estimation of a generalized Eta Squared. Can also be
<code>TRUE</code>, in which case generalized Eta Squared is estimated assuming <em>none</em>
of the variables are observed (all are manipulated). (For <code>afex_aov</code>
models, when <code>TRUE</code>, the observed variables are extracted automatically
from the fitted model, if they were provided during fitting.</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"greater"</code> (default) or <code>"less"</code>
(one-sided CI), or <code>"two.sided"</code> (two-sided CI). Partial matching is
allowed (e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in
<a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.
</p>

<ul>
<li><p> Can be <code>include_intercept = TRUE</code> to include the effect size for the intercept (when it is included in the ANOVA table).
</p>
</li>
<li><p> For Bayesian models, arguments passed to <code>ss_function</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="eta_squared_+3A_squared">squared</code></td>
<td>
<p>Return Cohen's <em>f</em> or Cohen's <em>f</em>-squared?</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_method">method</code></td>
<td>
<p>What effect size should be used as the basis for Cohen's <em>f</em>?</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_model2">model2</code></td>
<td>
<p>Optional second model for Cohen's f (/squared). If specified,
returns the effect size for R-squared-change between the two models.</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_ss_function">ss_function</code></td>
<td>
<p>For Bayesian models, the function used to extract
sum-of-squares. Uses <code><a href="stats.html#topic+anova">anova()</a></code> by default, but can also be <code>car::Anova()</code>
for simple linear models.</p>
</td></tr>
<tr><td><code id="eta_squared_+3A_draws">draws</code></td>
<td>
<p>For Bayesian models, an integer indicating the number of draws
from the posterior predictive distribution to return. Larger numbers take
longer to run, but provide estimates that are more stable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>aov</code> (or <code>lm</code>), <code>aovlist</code> and <code>afex_aov</code> models, and for <code>anova</code> objects
that provide Sums-of-Squares, the effect sizes are computed directly using
Sums-of-Squares. (For <code>maov</code> (or <code>mlm</code>) models, effect sizes are computed for
each response separately.)
<br /><br />
For other ANOVA tables and models (converted to ANOVA-like tables via
<code>anova()</code> methods), effect sizes are approximated via test statistic
conversion of the omnibus <em>F</em> statistic provided by the (see <code><a href="#topic+F_to_eta2">F_to_eta2()</a></code>
for more details.)
</p>


<h4>Type of Sums of Squares</h4>

<p>When <code>model</code> is a statistical model, the sums of squares (or <em>F</em> statistics)
used for the computation of the effect sizes are based on those returned by
<code>anova(model)</code>. Different models have different default output type. For
example, for <code>aov</code> and <code>aovlist</code> these are <em>type-1</em> sums of squares, but for
<code>lmerMod</code> (and <code>lmerModLmerTest</code>) these are <em>type-3</em> sums of squares. Make
sure these are the sums of squares you are interested in. You might want to
convert your model to an ANOVA(-like) table yourself and then pass the result
to <code>eta_squared()</code>. See examples below for use of <code>car::Anova()</code> and the
<code>afex</code> package.
<br /><br />
For type 3 sum of squares, it is generally recommended to fit models with
<em>orthogonal factor weights</em> (e.g., <code>contr.sum</code>) and <em>centered covariates</em>,
for sensible results. See examples and the <code>afex</code> package.
</p>



<h4>Un-Biased Estimate of Eta</h4>

<p>Both <em><strong>Omega</strong></em> and <em><strong>Epsilon</strong></em> are unbiased estimators of the
population's <em><strong>Eta</strong></em>, which is especially important is small samples. But
which to choose?
<br /><br />
Though Omega is the more popular choice (Albers and Lakens, 2018), Epsilon is
analogous to adjusted R2 (Allen, 2017, p. 382), and has been found to be less
biased (Carroll &amp; Nordholm, 1975).
</p>



<h4>Cohen's f</h4>

<p>Cohen's f can take on values between zero, when the population means are all
equal, and an indefinitely large number as standard deviation of means
increases relative to the average standard deviation within each group.
<br /><br />
When comparing two models in a sequential regression analysis, Cohen's f for
R-square change is the ratio between the increase in R-square
and the percent of unexplained variance.
<br /><br />
Cohen has suggested that the values of 0.10, 0.25, and 0.40 represent small,
medium, and large effect sizes, respectively.
</p>



<h4>Eta Squared from Posterior Predictive Distribution</h4>

<p>For Bayesian models (fit with <code>brms</code> or <code>rstanarm</code>),
<code>eta_squared_posterior()</code> simulates data from the posterior predictive
distribution (ppd) and for each simulation the Eta Squared is computed for
the model's fixed effects. This means that the returned values are the
population level effect size as implied by the posterior model (and not the
effect size in the sample data). See <code><a href="rstantools.html#topic+posterior_predict">rstantools::posterior_predict()</a></code> for
more info.
</p>



<h3>Value</h3>

<p>A data frame with the effect size(s) between 0-1 (<code>Eta2</code>, <code>Epsilon2</code>,
<code>Omega2</code>, <code>Cohens_f</code> or <code>Cohens_f2</code>, possibly with the <code>partial</code> or
<code>generalized</code> suffix), and their CIs (<code>CI_low</code> and <code>CI_high</code>).
<br /><br />
For <code>eta_squared_posterior()</code>, a data frame containing the ppd of the Eta
squared for each fixed effect, which can then be passed to
<code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code> for summary stats.
</p>
<p>A data frame containing the effect size values and their confidence
intervals.
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="#topic+effectsize_CIs">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Albers, C., and Lakens, D. (2018). When power analyses based on pilot data
are biased: Inaccurate effect size estimators and follow-up bias. Journal of
experimental social psychology, 74, 187-195.
</p>
</li>
<li><p> Allen, R. (2017). Statistics and Experimental Design for Psychologists: A
Model Comparison Approach. World Scientific Publishing Company.
</p>
</li>
<li><p> Carroll, R. M., &amp; Nordholm, L. A. (1975). Sampling Characteristics of
Kelley's epsilon and Hays' omega. Educational and Psychological Measurement,
35(3), 541-554.
</p>
</li>
<li><p> Kelley, T. (1935) An unbiased correlation ratio measure. Proceedings of the
National Academy of Sciences. 21(9). 554-559.
</p>
</li>
<li><p> Olejnik, S., &amp; Algina, J. (2003). Generalized eta and omega squared
statistics: measures of effect size for some common research designs.
Psychological methods, 8(4), 434.
</p>
</li>
<li><p> Steiger, J. H. (2004). Beyond the F test: Effect size confidence intervals
and tests of close fit in the analysis of variance and contrast analysis.
Psychological Methods, 9, 164-182.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+F_to_eta2">F_to_eta2()</a></code>
</p>
<p>Other effect sizes for ANOVAs: 
<code><a href="#topic+rank_epsilon_squared">rank_epsilon_squared</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mtcars)
mtcars$am_f &lt;- factor(mtcars$am)
mtcars$cyl_f &lt;- factor(mtcars$cyl)

model &lt;- aov(mpg ~ am_f * cyl_f, data = mtcars)

(eta2 &lt;- eta_squared(model))

# More types:
eta_squared(model, partial = FALSE)
eta_squared(model, generalized = "cyl_f")
omega_squared(model)
epsilon_squared(model)
cohens_f(model)

model0 &lt;- aov(mpg ~ am_f + cyl_f, data = mtcars) # no interaction
cohens_f_squared(model0, model2 = model)

## Interpretation of effect sizes
## ------------------------------

interpret_omega_squared(0.10, rules = "field2013")
interpret_eta_squared(0.10, rules = "cohen1992")
interpret_epsilon_squared(0.10, rules = "cohen1992")

interpret(eta2, rules = "cohen1992")


plot(eta2) # Requires the {see} package


# Recommended: Type-2 or -3 effect sizes + effects coding
# -------------------------------------------------------
contrasts(mtcars$am_f) &lt;- contr.sum
contrasts(mtcars$cyl_f) &lt;- contr.sum

model &lt;- aov(mpg ~ am_f * cyl_f, data = mtcars)
model_anova &lt;- car::Anova(model, type = 3)

epsilon_squared(model_anova)


# afex takes care of both type-3 effects and effects coding:
data(obk.long, package = "afex")
model &lt;- afex::aov_car(value ~ gender + Error(id / (phase * hour)),
  data = obk.long, observed = "gender"
)

omega_squared(model)
eta_squared(model, generalized = TRUE) # observed vars are pulled from the afex model.


## Approx. effect sizes for mixed models
## -------------------------------------
model &lt;- lme4::lmer(mpg ~ am_f * cyl_f + (1 | vs), data = mtcars)
omega_squared(model)


## Bayesian Models (PPD)
## ---------------------
fit_bayes &lt;- rstanarm::stan_glm(
  mpg ~ factor(cyl) * wt + qsec,
  data = mtcars, family = gaussian(),
  refresh = 0
)

es &lt;- eta_squared_posterior(fit_bayes,
  verbose = FALSE,
  ss_function = car::Anova, type = 3
)
bayestestR::describe_posterior(es, test = NULL)


# compare to:
fit_freq &lt;- lm(mpg ~ factor(cyl) * wt + qsec,
  data = mtcars
)
aov_table &lt;- car::Anova(fit_freq, type = 3)
eta_squared(aov_table)

</code></pre>

<hr>
<h2 id='eta2_to_f2'>Convert Between ANOVA Effect Sizes</h2><span id='topic+eta2_to_f2'></span><span id='topic+eta2_to_f'></span><span id='topic+f2_to_eta2'></span><span id='topic+f_to_eta2'></span>

<h3>Description</h3>

<p>Convert Between ANOVA Effect Sizes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eta2_to_f2(es)

eta2_to_f(es)

f2_to_eta2(f2)

f_to_eta2(f)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eta2_to_f2_+3A_es">es</code></td>
<td>
<p>Any measure of variance explained such as Eta-, Epsilon-, Omega-,
or R-Squared, partial or otherwise. See details.</p>
</td></tr>
<tr><td><code id="eta2_to_f2_+3A_f">f</code>, <code id="eta2_to_f2_+3A_f2">f2</code></td>
<td>
<p>Cohen's <em>f</em> or <em>f</em>-squared.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Any measure of variance explained can be converted to a corresponding Cohen's
<em>f</em> via:
<br /><br />
</p>
<p style="text-align: center;"><code class="reqn">f^2 = \frac{\eta^2}{1 - \eta^2}</code>
</p>

<p><br /><br />
</p>
<p style="text-align: center;"><code class="reqn">\eta^2 = \frac{f^2}{1 + f^2}</code>
</p>

<p><br /><br />
If a partial Eta-Squared is used, the resulting Cohen's <em>f</em> is a
partial-Cohen's <em>f</em>; If a less biased estimate of variance explained is used
(such as Epsilon- or Omega-Squared), the resulting Cohen's <em>f</em> is likewise a
less biased estimate of Cohen's <em>f</em>.
</p>


<h3>References</h3>


<ul>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences
(2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Steiger, J. H. (2004). Beyond the F test: Effect size confidence intervals
and tests of close fit in the analysis of variance and contrast analysis.
Psychological Methods, 9, 164-182.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+eta_squared">eta_squared()</a></code> for more details.
</p>
<p>Other convert between effect sizes: 
<code><a href="#topic+d_to_r">d_to_r</a>()</code>,
<code><a href="#topic+diff_to_cles">diff_to_cles</a></code>,
<code><a href="#topic+odds_to_probs">odds_to_probs</a>()</code>,
<code><a href="#topic+oddsratio_to_riskratio">oddsratio_to_riskratio</a>()</code>,
<code><a href="#topic+w_to_fei">w_to_fei</a>()</code>
</p>

<hr>
<h2 id='F_to_eta2'>Convert <em>F</em> and <em>t</em> Statistics to <strong>partial</strong>-<code class="reqn">\eta^2</code> and Other ANOVA Effect Sizes</h2><span id='topic+F_to_eta2'></span><span id='topic+t_to_eta2'></span><span id='topic+F_to_epsilon2'></span><span id='topic+t_to_epsilon2'></span><span id='topic+F_to_eta2_adj'></span><span id='topic+t_to_eta2_adj'></span><span id='topic+F_to_omega2'></span><span id='topic+t_to_omega2'></span><span id='topic+F_to_f'></span><span id='topic+t_to_f'></span><span id='topic+F_to_f2'></span><span id='topic+t_to_f2'></span>

<h3>Description</h3>

<p>These functions are convenience functions to convert F and t test statistics
to <strong>partial</strong> Eta- (<code class="reqn">\eta</code>), Omega- (<code class="reqn">\omega</code>) Epsilon-
(<code class="reqn">\epsilon</code>) squared (an alias for the adjusted Eta squared) and Cohen's
f. These are useful in cases where the various Sum of Squares and Mean
Squares are not easily available or their computation is not straightforward
(e.g., in liner mixed models, contrasts, etc.). For test statistics derived
from <code>lm</code> and <code>aov</code> models, these functions give exact results. For all other
cases, they return close approximations.
<br />
See <a href="https://easystats.github.io/effectsize/articles/from_test_statistics.html">Effect Size from Test Statistics vignette.</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>F_to_eta2(f, df, df_error, ci = 0.95, alternative = "greater", ...)

t_to_eta2(t, df_error, ci = 0.95, alternative = "greater", ...)

F_to_epsilon2(f, df, df_error, ci = 0.95, alternative = "greater", ...)

t_to_epsilon2(t, df_error, ci = 0.95, alternative = "greater", ...)

F_to_eta2_adj(f, df, df_error, ci = 0.95, alternative = "greater", ...)

t_to_eta2_adj(t, df_error, ci = 0.95, alternative = "greater", ...)

F_to_omega2(f, df, df_error, ci = 0.95, alternative = "greater", ...)

t_to_omega2(t, df_error, ci = 0.95, alternative = "greater", ...)

F_to_f(
  f,
  df,
  df_error,
  squared = FALSE,
  ci = 0.95,
  alternative = "greater",
  ...
)

t_to_f(t, df_error, squared = FALSE, ci = 0.95, alternative = "greater", ...)

F_to_f2(
  f,
  df,
  df_error,
  squared = TRUE,
  ci = 0.95,
  alternative = "greater",
  ...
)

t_to_f2(t, df_error, squared = TRUE, ci = 0.95, alternative = "greater", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="F_to_eta2_+3A_df">df</code>, <code id="F_to_eta2_+3A_df_error">df_error</code></td>
<td>
<p>Degrees of freedom of numerator or of the error estimate
(i.e., the residuals).</p>
</td></tr>
<tr><td><code id="F_to_eta2_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="F_to_eta2_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"greater"</code> (default) or <code>"less"</code>
(one-sided CI), or <code>"two.sided"</code> (two-sided CI). Partial matching is
allowed (e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in
<a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="F_to_eta2_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="F_to_eta2_+3A_t">t</code>, <code id="F_to_eta2_+3A_f">f</code></td>
<td>
<p>The t or the F statistics.</p>
</td></tr>
<tr><td><code id="F_to_eta2_+3A_squared">squared</code></td>
<td>
<p>Return Cohen's <em>f</em> or Cohen's <em>f</em>-squared?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions use the following formulae:
<br />
</p>
<p style="text-align: center;"><code class="reqn">\eta_p^2 = \frac{F \times df_{num}}{F \times df_{num} + df_{den}}</code>
</p>

<p><br />
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den}}</code>
</p>

<p><br />
</p>
<p style="text-align: center;"><code class="reqn">\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}</code>
</p>

<p><br />
</p>
<p style="text-align: center;"><code class="reqn">f_p = \sqrt{\frac{\eta_p^2}{1-\eta_p^2}}</code>
</p>

<p><br /><br />
For <em>t</em>, the conversion is based on the equality of <code class="reqn">t^2 = F</code> when <code class="reqn">df_{num}=1</code>.
</p>


<h4>Choosing an Un-Biased Estimate</h4>

<p>Both Omega and Epsilon are unbiased estimators of the population Eta. But
which to choose? Though Omega is the more popular choice, it should be noted
that:
</p>

<ol>
<li><p> The formula given above for Omega is only an approximation for complex
designs.
</p>
</li>
<li><p> Epsilon has been found to be less biased (Carroll &amp; Nordholm, 1975).
</p>
</li></ol>




<h3>Value</h3>

<p>A data frame with the effect size(s) between 0-1 (<code>Eta2_partial</code>,
<code>Epsilon2_partial</code>, <code>Omega2_partial</code>, <code>Cohens_f_partial</code> or
<code>Cohens_f2_partial</code>), and their CIs (<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="#topic+effectsize_CIs">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>Note</h3>

<p>Adjusted (partial) Eta-squared is an alias for (partial) Epsilon-squared.
</p>


<h3>References</h3>


<ul>
<li><p> Albers, C., &amp; Lakens, D. (2018). When power analyses based on pilot data
are biased: Inaccurate effect size estimators and follow-up bias. Journal of
experimental social psychology, 74, 187-195. <a href="https://doi.org/10.31234/osf.io/b7z4q">doi:10.31234/osf.io/b7z4q</a>
</p>
</li>
<li><p> Carroll, R. M., &amp; Nordholm, L. A. (1975). Sampling Characteristics of
Kelley's epsilon and Hays' omega. Educational and Psychological Measurement,
35(3), 541-554.
</p>
</li>
<li><p> Cumming, G., &amp; Finch, S. (2001). A primer on the understanding, use, and
calculation of confidence intervals that are based on central and noncentral
distributions. Educational and Psychological Measurement, 61(4), 532-574.
</p>
</li>
<li><p> Friedman, H. (1982). Simplified determinations of statistical power,
magnitude of effect and research sample sizes. Educational and Psychological
Measurement, 42(2), 521-526. <a href="https://doi.org/10.1177/001316448204200214">doi:10.1177/001316448204200214</a>
</p>
</li>
<li><p> Mordkoff, J. T. (2019). A Simple Method for Removing Bias From a Popular
Measure of Standardized Effect Size: Adjusted Partial Eta Squared. Advances
in Methods and Practices in Psychological Science, 2(3), 228-232.
<a href="https://doi.org/10.1177/2515245919855053">doi:10.1177/2515245919855053</a>
</p>
</li>
<li><p> Morey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., &amp; Wagenmakers, E. J.
(2016). The fallacy of placing confidence in confidence intervals.
Psychonomic bulletin &amp; review, 23(1), 103-123.
</p>
</li>
<li><p> Steiger, J. H. (2004). Beyond the F test: Effect size confidence intervals
and tests of close fit in the analysis of variance and contrast analysis.
Psychological Methods, 9, 164-182.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+eta_squared">eta_squared()</a></code> for more details.
</p>
<p>Other effect size from test statistic: 
<code><a href="#topic+chisq_to_phi">chisq_to_phi</a>()</code>,
<code><a href="#topic+t_to_d">t_to_d</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod &lt;- aov(mpg ~ factor(cyl) * factor(am), mtcars)
anova(mod)
(etas &lt;- F_to_eta2(
  f = c(44.85, 3.99, 1.38),
  df = c(2, 1, 2),
  df_error = 26
))

if (require(see)) plot(etas)

# Compare to:
eta_squared(mod)


fit &lt;- lmerTest::lmer(extra ~ group + (1 | ID), sleep)
# anova(fit)
# #&gt; Type III Analysis of Variance Table with Satterthwaite's method
# #&gt;       Sum Sq Mean Sq NumDF DenDF F value   Pr(&gt;F)
# #&gt; group 12.482  12.482     1     9  16.501 0.002833 **
# #&gt; ---
# #&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

F_to_eta2(16.501, 1, 9)
F_to_omega2(16.501, 1, 9)
F_to_epsilon2(16.501, 1, 9)
F_to_f(16.501, 1, 9)


## Use with emmeans based contrasts
## --------------------------------
warp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)

jt &lt;- emmeans::joint_tests(warp.lm, by = "wool")
F_to_eta2(jt$F.ratio, jt$df1, jt$df2)

</code></pre>

<hr>
<h2 id='food_class'>Classification of Foods</h2><span id='topic+food_class'></span>

<h3>Description</h3>

<p>Fictional data.
</p>


<h3>Format</h3>

<p>A 2-by-3 table.
</p>
<div class="sourceCode r"><pre>data("food_class")
food_class
#&gt;           Soy Milk Meat
#&gt; Vegan      47    0    0
#&gt; Not-Vegan   0   12   21
</pre></div>


<h3>See Also</h3>

<p>Other effect size datasets: 
<code><a href="#topic+Music_preferences">Music_preferences</a></code>,
<code><a href="#topic+Music_preferences2">Music_preferences2</a></code>,
<code><a href="#topic+RCT_table">RCT_table</a></code>,
<code><a href="#topic+Smoking_FASD">Smoking_FASD</a></code>,
<code><a href="#topic+hardlyworking">hardlyworking</a></code>,
<code><a href="#topic+rouder2016">rouder2016</a></code>,
<code><a href="#topic+screening_test">screening_test</a></code>
</p>

<hr>
<h2 id='format_standardize'>Format a Standardized Vector</h2><span id='topic+format_standardize'></span>

<h3>Description</h3>

<p>Transform a standardized vector into character, e.g., <code>c("-1 SD", "Mean", "+1 SD")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_standardize(
  x,
  reference = x,
  robust = FALSE,
  digits = 1,
  protect_integers = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="format_standardize_+3A_x">x</code></td>
<td>
<p>A standardized numeric vector.</p>
</td></tr>
<tr><td><code id="format_standardize_+3A_reference">reference</code></td>
<td>
<p>The reference vector from which to compute the mean and SD.</p>
</td></tr>
<tr><td><code id="format_standardize_+3A_robust">robust</code></td>
<td>
<p>Logical, if <code>TRUE</code>, centering is done by subtracting the
median from the variables and dividing it by the median absolute deviation
(MAD). If <code>FALSE</code>, variables are standardized by subtracting the
mean and dividing it by the standard deviation (SD).</p>
</td></tr>
<tr><td><code id="format_standardize_+3A_digits">digits</code></td>
<td>
<p>Number of digits for rounding or significant figures. May also
be <code>"signif"</code> to return significant figures or <code>"scientific"</code>
to return scientific notation. Control the number of digits by adding the
value as suffix, e.g. <code>digits = "scientific4"</code> to have scientific
notation with 4 decimal places, or <code>digits = "signif5"</code> for 5
significant figures (see also <code><a href="base.html#topic+signif">signif()</a></code>).</p>
</td></tr>
<tr><td><code id="format_standardize_+3A_protect_integers">protect_integers</code></td>
<td>
<p>Should integers be kept as integers (i.e., without
decimals)?</p>
</td></tr>
<tr><td><code id="format_standardize_+3A_...">...</code></td>
<td>
<p>Other arguments to pass to <code><a href="insight.html#topic+format_value">insight::format_value()</a></code> such as <code>digits</code>, etc.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>format_standardize(c(-1, 0, 1))
format_standardize(c(-1, 0, 1, 2), reference = rnorm(1000))
format_standardize(c(-1, 0, 1, 2), reference = rnorm(1000), robust = TRUE)

format_standardize(standardize(mtcars$wt), digits = 1)
format_standardize(standardize(mtcars$wt, robust = TRUE), digits = 1)
</code></pre>

<hr>
<h2 id='hardlyworking'>Workers' Salary and Other Information</h2><span id='topic+hardlyworking'></span>

<h3>Description</h3>

<p>A sample (simulated) dataset, used in tests and some examples.
</p>


<h3>Format</h3>

<p>A data frame with 500 rows and 5 variables:
</p>

<dl>
<dt>salary</dt><dd><p>Salary, in Shmekels</p>
</dd>
<dt>xtra_hours</dt><dd><p>Number of overtime hours (on average, per week)</p>
</dd>
<dt>n_comps</dt><dd><p>Number of compliments given to the boss (observed over the last week)</p>
</dd>
<dt>age</dt><dd><p>Age in years</p>
</dd>
<dt>seniority</dt><dd><p>How many years with the company</p>
</dd>
<dt>is_senior</dt><dd><p>Has this person been working here for more than 4 years?</p>
</dd>
</dl>

<div class="sourceCode r"><pre>data("hardlyworking")
head(hardlyworking, n = 5)
#&gt;     salary xtra_hours n_comps age seniority is_senior
#&gt; 1 19744.65       4.16       1  32         3     FALSE
#&gt; 2 11301.95       1.62       0  34         3     FALSE
#&gt; 3 20635.62       1.19       3  33         5      TRUE
#&gt; 4 23047.16       7.19       1  35         3     FALSE
#&gt; 5 27342.15      11.26       0  33         4     FALSE
</pre></div>


<h3>See Also</h3>

<p>Other effect size datasets: 
<code><a href="#topic+Music_preferences">Music_preferences</a></code>,
<code><a href="#topic+Music_preferences2">Music_preferences2</a></code>,
<code><a href="#topic+RCT_table">RCT_table</a></code>,
<code><a href="#topic+Smoking_FASD">Smoking_FASD</a></code>,
<code><a href="#topic+food_class">food_class</a></code>,
<code><a href="#topic+rouder2016">rouder2016</a></code>,
<code><a href="#topic+screening_test">screening_test</a></code>
</p>

<hr>
<h2 id='interpret'>Generic Function for Interpretation</h2><span id='topic+interpret'></span><span id='topic+interpret.numeric'></span><span id='topic+interpret.effectsize_table'></span>

<h3>Description</h3>

<p>Interpret a value based on a set of rules. See <code><a href="#topic+rules">rules()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret(x, ...)

## S3 method for class 'numeric'
interpret(x, rules, name = attr(rules, "rule_name"), transform = NULL, ...)

## S3 method for class 'effectsize_table'
interpret(x, rules, transform = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_+3A_x">x</code></td>
<td>
<p>Vector of value break points (edges defining categories), or a data
frame of class <code>effectsize_table</code>.</p>
</td></tr>
<tr><td><code id="interpret_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="interpret_+3A_rules">rules</code></td>
<td>
<p>Set of <code><a href="#topic+rules">rules()</a></code>. When <code>x</code> is a data frame, can be a name of an
established set of rules.</p>
</td></tr>
<tr><td><code id="interpret_+3A_name">name</code></td>
<td>
<p>Name of the set of rules (will be printed).</p>
</td></tr>
<tr><td><code id="interpret_+3A_transform">transform</code></td>
<td>
<p>a function (or name of a function) to apply to <code>x</code> before
interpreting. See examples.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li><p> For numeric input: A character vector of interpretations.
</p>
</li>
<li><p> For data frames: the <code>x</code> input with an additional <code>Interpretation</code> column.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rules">rules()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rules_grid &lt;- rules(c(0.01, 0.05), c("very significant", "significant", "not significant"))
interpret(0.001, rules_grid)
interpret(0.021, rules_grid)
interpret(0.08, rules_grid)
interpret(c(0.01, 0.005, 0.08), rules_grid)

interpret(c(0.35, 0.15), c("small" = 0.2, "large" = 0.4), name = "Cohen's Rules")
interpret(c(0.35, 0.15), rules(c(0.2, 0.4), c("small", "medium", "large")))

bigness &lt;- rules(c(1, 10), c("small", "medium", "big"))
interpret(abs(-5), bigness)
interpret(-5, bigness, transform = abs)

# ----------
d &lt;- cohens_d(mpg ~ am, data = mtcars)
interpret(d, rules = "cohen1988")

d &lt;- glass_delta(mpg ~ am, data = mtcars)
interpret(d, rules = "gignac2016")

interpret(d, rules = rules(1, c("tiny", "yeah okay")))

m &lt;- lm(formula = wt ~ am * cyl, data = mtcars)
eta2 &lt;- eta_squared(m)
interpret(eta2, rules = "field2013")

X &lt;- chisq.test(mtcars$am, mtcars$cyl == 8)
interpret(oddsratio(X), rules = "cohen1988")
interpret(cramers_v(X), rules = "lovakov2021")
</code></pre>

<hr>
<h2 id='interpret_bf'>Interpret Bayes Factor (BF)</h2><span id='topic+interpret_bf'></span>

<h3>Description</h3>

<p>Interpret Bayes Factor (BF)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_bf(
  bf,
  rules = "jeffreys1961",
  log = FALSE,
  include_value = FALSE,
  protect_ratio = TRUE,
  exact = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_bf_+3A_bf">bf</code></td>
<td>
<p>Value or vector of Bayes factor (BF) values.</p>
</td></tr>
<tr><td><code id="interpret_bf_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"jeffreys1961"</code> (default), <code>"raftery1995"</code> or custom set
of <code><a href="#topic+rules">rules()</a></code> (for the <em>absolute magnitude</em> of evidence).</p>
</td></tr>
<tr><td><code id="interpret_bf_+3A_log">log</code></td>
<td>
<p>Is the <code>bf</code> value <code>log(bf)</code>?</p>
</td></tr>
<tr><td><code id="interpret_bf_+3A_include_value">include_value</code></td>
<td>
<p>Include the value in the output.</p>
</td></tr>
<tr><td><code id="interpret_bf_+3A_protect_ratio">protect_ratio</code></td>
<td>
<p>Should values smaller than 1 be represented as ratios?</p>
</td></tr>
<tr><td><code id="interpret_bf_+3A_exact">exact</code></td>
<td>
<p>Should very large or very small values be reported with a
scientific format (e.g., 4.24e5), or as truncated values (as &quot;&gt; 1000&quot; and
&quot;&lt; 1/1000&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Argument names can be partially matched.
</p>


<h3>Rules</h3>

<p>Rules apply to BF as ratios, so BF of 10 is as extreme as a BF of 0.1 (1/10).
</p>

<ul>
<li><p> Jeffreys (1961) (<code>"jeffreys1961"</code>; default)
</p>

<ul>
<li> <p><strong>BF = 1</strong> - No evidence
</p>
</li>
<li> <p><strong>1 &lt; BF &lt;= 3</strong> - Anecdotal
</p>
</li>
<li> <p><strong>3 &lt; BF &lt;= 10</strong> - Moderate
</p>
</li>
<li> <p><strong>10 &lt; BF &lt;= 30</strong> - Strong
</p>
</li>
<li> <p><strong>30 &lt; BF &lt;= 100</strong> - Very strong
</p>
</li>
<li> <p><strong>BF &gt; 100</strong> - Extreme.
</p>
</li></ul>

</li>
<li><p> Raftery (1995) (<code>"raftery1995"</code>)
</p>

<ul>
<li> <p><strong>BF = 1</strong> - No evidence
</p>
</li>
<li> <p><strong>1 &lt; BF &lt;= 3</strong> - Weak
</p>
</li>
<li> <p><strong>3 &lt; BF &lt;= 20</strong> - Positive
</p>
</li>
<li> <p><strong>20 &lt; BF &lt;= 150</strong> - Strong
</p>
</li>
<li> <p><strong>BF &gt; 150</strong> - Very strong
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p> Jeffreys, H. (1961), Theory of Probability, 3rd ed., Oxford University
Press, Oxford.
</p>
</li>
<li><p> Raftery, A. E. (1995). Bayesian model selection in social research.
Sociological methodology, 25, 111-164.
</p>
</li>
<li><p> Jarosz, A. F., &amp; Wiley, J. (2014). What are the odds? A practical guide to
computing and reporting Bayes factors. The Journal of Problem Solving, 7(1), 2.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_bf(1)
interpret_bf(c(5, 2, 0.01))

</code></pre>

<hr>
<h2 id='interpret_cohens_d'>Interpret Standardized Differences</h2><span id='topic+interpret_cohens_d'></span><span id='topic+interpret_hedges_g'></span><span id='topic+interpret_glass_delta'></span>

<h3>Description</h3>

<p>Interpretation of standardized differences using different sets of rules of
thumb.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_cohens_d(d, rules = "cohen1988", ...)

interpret_hedges_g(g, rules = "cohen1988")

interpret_glass_delta(delta, rules = "cohen1988")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_cohens_d_+3A_d">d</code>, <code id="interpret_cohens_d_+3A_g">g</code>, <code id="interpret_cohens_d_+3A_delta">delta</code></td>
<td>
<p>Value or vector of effect size values.</p>
</td></tr>
<tr><td><code id="interpret_cohens_d_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"cohen1988"</code> (default), <code>"gignac2016"</code>,
<code>"sawilowsky2009"</code>, <code>"lovakov2021"</code> or a custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_cohens_d_+3A_...">...</code></td>
<td>
<p>Not directly used.</p>
</td></tr>
</table>


<h3>Rules</h3>

<p>Rules apply to equally to positive and negative <em>d</em> (i.e., they are given as
absolute values).
</p>

<ul>
<li><p> Cohen (1988) (<code>"cohen1988"</code>; default)
</p>

<ul>
<li> <p><strong>d &lt; 0.2</strong> - Very small
</p>
</li>
<li> <p><strong>0.2 &lt;= d &lt; 0.5</strong> - Small
</p>
</li>
<li> <p><strong>0.5 &lt;= d &lt; 0.8</strong> - Medium
</p>
</li>
<li> <p><strong>d &gt;= 0.8</strong> - Large
</p>
</li></ul>

</li>
<li><p> Sawilowsky (2009) (<code>"sawilowsky2009"</code>)
</p>

<ul>
<li> <p><strong>d &lt; 0.1</strong> - Tiny
</p>
</li>
<li> <p><strong>0.1 &lt;= d &lt; 0.2</strong> - Very small
</p>
</li>
<li> <p><strong>0.2 &lt;= d &lt; 0.5</strong> - Small
</p>
</li>
<li> <p><strong>0.5 &lt;= d &lt; 0.8</strong> - Medium
</p>
</li>
<li> <p><strong>0.8 &lt;= d &lt; 1.2</strong> - Large
</p>
</li>
<li> <p><strong>1.2 &lt;= d &lt; 2</strong> - Very large
</p>
</li>
<li> <p><strong>d &gt;= 2</strong> - Huge
</p>
</li></ul>

</li>
<li><p> Lovakov &amp; Agadullina (2021) (<code>"lovakov2021"</code>)
</p>

<ul>
<li> <p><strong>d &lt; 0.15</strong> - Very small
</p>
</li>
<li> <p><strong>0.15 &lt;= d &lt; 0.36</strong> - Small
</p>
</li>
<li> <p><strong>0.36 &lt;= d &lt; 0.65</strong> - Medium
</p>
</li>
<li> <p><strong>d &gt;= 0.65</strong> - Large
</p>
</li></ul>

</li>
<li><p> Gignac &amp; Szodorai (2016) (<code>"gignac2016"</code>, based on the <code><a href="#topic+d_to_r">d_to_r()</a></code> conversion, see <code><a href="#topic+interpret_r">interpret_r()</a></code>)
</p>

<ul>
<li> <p><strong>d &lt; 0.2</strong> - Very small
</p>
</li>
<li> <p><strong>0.2 &lt;= d &lt; 0.41</strong> - Small
</p>
</li>
<li> <p><strong>0.41 &lt;= d &lt; 0.63</strong> - Moderate
</p>
</li>
<li> <p><strong>d &gt;= 0.63</strong> - Large
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p> Lovakov, A., &amp; Agadullina, E. R. (2021). Empirically Derived Guidelines for
Effect Size Interpretation in Social Psychology. European Journal of Social
Psychology.
</p>
</li>
<li><p> Gignac, G. E., &amp; Szodorai, E. T. (2016). Effect size guidelines for
individual differences researchers. Personality and individual differences,
102, 74-78.
</p>
</li>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences
(2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Sawilowsky, S. S. (2009). New effect size rules of thumb.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_cohens_d(.02)
interpret_cohens_d(c(.5, .02))
interpret_cohens_d(.3, rules = "lovakov2021")
</code></pre>

<hr>
<h2 id='interpret_cohens_g'>Interpret Cohen's <em>g</em></h2><span id='topic+interpret_cohens_g'></span>

<h3>Description</h3>

<p>Interpret Cohen's <em>g</em>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_cohens_g(g, rules = "cohen1988", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_cohens_g_+3A_g">g</code></td>
<td>
<p>Value or vector of effect size values.</p>
</td></tr>
<tr><td><code id="interpret_cohens_g_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"cohen1988"</code> (default) or a custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_cohens_g_+3A_...">...</code></td>
<td>
<p>Not directly used.</p>
</td></tr>
</table>


<h3>Rules</h3>

<p>Rules apply to equally to positive and negative <em>g</em> (i.e., they are given as
absolute values).
</p>

<ul>
<li><p> Cohen (1988) (<code>"cohen1988"</code>; default)
</p>

<ul>
<li> <p><strong>d &lt; 0.05</strong> - Very small
</p>
</li>
<li> <p><strong>0.05 &lt;= d &lt; 0.15</strong> - Small
</p>
</li>
<li> <p><strong>0.15 &lt;= d &lt; 0.25</strong> - Medium
</p>
</li>
<li> <p><strong>d &gt;= 0.25</strong> - Large
</p>
</li></ul>

</li></ul>



<h3>Note</h3>

<p>&quot;<em>Since <strong>g</strong> is so transparently clear a unit, it is expected that
workers in any given substantive area of the behavioral sciences will very
frequently be able to set relevant [effect size] values without the
proposed conventions, or set up conventions of their own which are suited
to their area of inquiry.</em>&quot; - Cohen, 1988, page 147.
</p>


<h3>References</h3>


<ul>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences
(2nd Ed.). New York: Routledge.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_cohens_g(.02)
interpret_cohens_g(c(.3, .15))

</code></pre>

<hr>
<h2 id='interpret_direction'>Interpret Direction</h2><span id='topic+interpret_direction'></span>

<h3>Description</h3>

<p>Interpret Direction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_direction(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_direction_+3A_x">x</code></td>
<td>
<p>Numeric value.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>interpret_direction(.02)
interpret_direction(c(.5, -.02))
interpret_direction(0)

</code></pre>

<hr>
<h2 id='interpret_ess'>Interpret Bayesian Diagnostic Indices</h2><span id='topic+interpret_ess'></span><span id='topic+interpret_rhat'></span>

<h3>Description</h3>

<p>Interpretation of Bayesian diagnostic indices, such as Effective Sample Size (ESS) and Rhat.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_ess(ess, rules = "burkner2017")

interpret_rhat(rhat, rules = "vehtari2019")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_ess_+3A_ess">ess</code></td>
<td>
<p>Value or vector of Effective Sample Size (ESS) values.</p>
</td></tr>
<tr><td><code id="interpret_ess_+3A_rules">rules</code></td>
<td>
<p>A character string (see <em>Rules</em>) or a custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_ess_+3A_rhat">rhat</code></td>
<td>
<p>Value or vector of Rhat values.</p>
</td></tr>
</table>


<h3>Rules</h3>



<h4>ESS</h4>


<ul>
<li><p> BÃ¼rkner, P. C. (2017) (<code>"burkner2017"</code>; default)
</p>

<ul>
<li> <p><strong>ESS &lt; 1000</strong> - Insufficient
</p>
</li>
<li> <p><strong>ESS &gt;= 1000</strong> - Sufficient
</p>
</li></ul>

</li></ul>




<h4>Rhat</h4>


<ul>
<li><p> Vehtari et al. (2019) (<code>"vehtari2019"</code>; default)
</p>

<ul>
<li> <p><strong>Rhat &lt; 1.01</strong> - Converged
</p>
</li>
<li> <p><strong>Rhat &gt;= 1.01</strong> - Failed
</p>
</li></ul>

</li>
<li><p> Gelman &amp; Rubin (1992) (<code>"gelman1992"</code>)
</p>

<ul>
<li> <p><strong>Rhat &lt; 1.1</strong> - Converged
</p>
</li>
<li> <p><strong>Rhat &gt;= 1.1</strong> - Failed
</p>
</li></ul>

</li></ul>




<h3>References</h3>


<ul>
<li><p> BÃ¼rkner, P. C. (2017). brms: An R package for Bayesian multilevel models
using Stan. Journal of Statistical Software, 80(1), 1-28.
</p>
</li>
<li><p> Gelman, A., &amp; Rubin, D. B. (1992). Inference from iterative simulation
using multiple sequences. Statistical science, 7(4), 457-472.
</p>
</li>
<li><p> Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; BÃ¼rkner, P. C.
(2019). Rank-normalization, folding, and localization: An improved Rhat for
assessing convergence of MCMC. arXiv preprint arXiv:1903.08008.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_ess(1001)
interpret_ess(c(852, 1200))

interpret_rhat(1.00)
interpret_rhat(c(1.5, 0.9))
</code></pre>

<hr>
<h2 id='interpret_gfi'>Interpret of CFA / SEM Indices of Goodness of Fit</h2><span id='topic+interpret_gfi'></span><span id='topic+interpret_agfi'></span><span id='topic+interpret_nfi'></span><span id='topic+interpret_nnfi'></span><span id='topic+interpret_cfi'></span><span id='topic+interpret_rfi'></span><span id='topic+interpret_ifi'></span><span id='topic+interpret_pnfi'></span><span id='topic+interpret_rmsea'></span><span id='topic+interpret_srmr'></span><span id='topic+interpret.lavaan'></span><span id='topic+interpret.performance_lavaan'></span>

<h3>Description</h3>

<p>Interpretation of indices of fit found in confirmatory analysis or structural
equation modelling, such as RMSEA, CFI, NFI, IFI, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_gfi(x, rules = "byrne1994")

interpret_agfi(x, rules = "byrne1994")

interpret_nfi(x, rules = "byrne1994")

interpret_nnfi(x, rules = "byrne1994")

interpret_cfi(x, rules = "byrne1994")

interpret_rfi(x, rules = "default")

interpret_ifi(x, rules = "default")

interpret_pnfi(x, rules = "default")

interpret_rmsea(x, rules = "byrne1994")

interpret_srmr(x, rules = "byrne1994")

## S3 method for class 'lavaan'
interpret(x, ...)

## S3 method for class 'performance_lavaan'
interpret(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_gfi_+3A_x">x</code></td>
<td>
<p>vector of values, or an object of class <code>lavaan</code>.</p>
</td></tr>
<tr><td><code id="interpret_gfi_+3A_rules">rules</code></td>
<td>
<p>Can be the name of a set of rules (see below) or custom set of
<code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_gfi_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Indices of fit</h4>


<ul>
<li> <p><strong>Chisq</strong>: The model Chi-squared assesses overall fit and the discrepancy
between the sample and fitted covariance matrices. Its p-value should be &gt;
.05 (i.e., the hypothesis of a perfect fit cannot be rejected). However, it
is quite sensitive to sample size.
</p>
</li>
<li> <p><strong>GFI/AGFI</strong>: The (Adjusted) Goodness of Fit is the proportion of variance
accounted for by the estimated population covariance. Analogous to R2. The
GFI and the AGFI should be &gt; .95 and &gt; .90, respectively (Byrne, 1994;
<code>"byrne1994"</code>).
</p>
</li>
<li> <p><strong>NFI/NNFI/TLI</strong>: The (Non) Normed Fit Index. An NFI of 0.95, indicates the
model of interest improves the fit by 95\
NNFI (also called the Tucker Lewis index; TLI) is preferable for smaller
samples. They should be &gt; .90 (Byrne, 1994; <code>"byrne1994"</code>) or &gt; .95
(Schumacker &amp; Lomax, 2004; <code>"schumacker2004"</code>).
</p>
</li>
<li> <p><strong>CFI</strong>: The Comparative Fit Index is a revised form of NFI. Not very
sensitive to sample size (Fan, Thompson, &amp; Wang, 1999). Compares the fit of a
target model to the fit of an independent, or null, model. It should be &gt; .96
(Hu &amp; Bentler, 1999; <code>"hu&amp;bentler1999"</code>) or .90 (Byrne, 1994; <code>"byrne1994"</code>).
</p>
</li>
<li> <p><strong>RFI</strong>: the Relative Fit Index, also known as RHO1, is not guaranteed to
vary from 0 to 1. However, RFI close to 1 indicates a good fit.
</p>
</li>
<li> <p><strong>IFI</strong>: the Incremental Fit Index (IFI) adjusts the Normed Fit Index (NFI)
for sample size and degrees of freedom (Bollen's, 1989). Over 0.90 is a good
fit, but the index can exceed 1.
</p>
</li>
<li> <p><strong>PNFI</strong>: the Parsimony-Adjusted Measures Index. There is no commonly
agreed-upon cutoff value for an acceptable model for this index. Should be &gt;
0.50.
</p>
</li>
<li> <p><strong>RMSEA</strong>: The Root Mean Square Error of Approximation is a
parsimony-adjusted index. Values closer to 0 represent a good fit. It should
be &lt; .08 (Awang, 2012; <code>"awang2012"</code>) or &lt; .05 (Byrne, 1994; <code>"byrne1994"</code>).
The p-value printed with it tests the hypothesis that RMSEA is less than or
equal to .05 (a cutoff sometimes used for good fit), and thus should be not
significant.
</p>
</li>
<li> <p><strong>RMR/SRMR</strong>: the (Standardized) Root Mean Square Residual represents the
square-root of the difference between the residuals of the sample covariance
matrix and the hypothesized model. As the RMR can be sometimes hard to
interpret, better to use SRMR. Should be &lt; .08 (Byrne, 1994; <code>"byrne1994"</code>).
</p>
</li></ul>

<p>See the documentation for <code><a href="lavaan.html#topic+fitmeasures">fitmeasures()</a></code>.
</p>



<h4>What to report</h4>

<p>For structural equation models (SEM), Kline (2015) suggests that at a minimum
the following indices should be reported: The model <strong>chi-square</strong>, the
<strong>RMSEA</strong>, the <strong>CFI</strong> and the <strong>SRMR</strong>.
</p>



<h3>Note</h3>

<p>When possible, it is recommended to report dynamic cutoffs of fit
indices. See https://dynamicfit.app/cfa/.
</p>


<h3>References</h3>


<ul>
<li><p> Awang, Z. (2012). A handbook on SEM. Structural equation modeling.
</p>
</li>
<li><p> Byrne, B. M. (1994). Structural equation modeling with EQS and EQS/Windows.
Thousand Oaks, CA: Sage Publications.
</p>
</li>
<li><p> Fan, X., B. Thompson, and L. Wang (1999). Effects of sample size,
estimation method, and model specification on structural equation modeling
fit indexes. Structural Equation Modeling, 6, 56-83.
</p>
</li>
<li><p> Hu, L. T., &amp; Bentler, P. M. (1999). Cutoff criteria for fit indexes in
covariance structure analysis: Conventional criteria versus new
alternatives. Structural equation modeling: a multidisciplinary journal,
6(1), 1-55.
</p>
</li>
<li><p> Kline, R. B. (2015). Principles and practice of structural equation
modeling. Guilford publications.
</p>
</li>
<li><p> Schumacker, R. E., and Lomax, R. G. (2004). A beginner's guide to
structural equation modeling, Second edition. Mahwah, NJ: Lawrence Erlbaum
Associates.
</p>
</li>
<li><p> Tucker, L. R., and Lewis, C. (1973). The reliability coefficient for
maximum likelihood factor analysis. Psychometrika, 38, 1-10.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_gfi(c(.5, .99))
interpret_agfi(c(.5, .99))
interpret_nfi(c(.5, .99))
interpret_nnfi(c(.5, .99))
interpret_cfi(c(.5, .99))
interpret_rmsea(c(.07, .04))
interpret_srmr(c(.5, .99))
interpret_rfi(c(.5, .99))
interpret_ifi(c(.5, .99))
interpret_pnfi(c(.5, .99))


# Structural Equation Models (SEM)
structure &lt;- " ind60 =~ x1 + x2 + x3
               dem60 =~ y1 + y2 + y3
               dem60 ~ ind60 "

model &lt;- lavaan::sem(structure, data = lavaan::PoliticalDemocracy)

interpret(model)

</code></pre>

<hr>
<h2 id='interpret_icc'>Interpret Intraclass Correlation Coefficient (ICC)</h2><span id='topic+interpret_icc'></span>

<h3>Description</h3>

<p>The value of an ICC lies between 0 to 1, with 0 indicating no reliability among raters and 1 indicating perfect reliability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_icc(icc, rules = "koo2016", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_icc_+3A_icc">icc</code></td>
<td>
<p>Value or vector of Intraclass Correlation Coefficient (ICC) values.</p>
</td></tr>
<tr><td><code id="interpret_icc_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"koo2016"</code> (default) or custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_icc_+3A_...">...</code></td>
<td>
<p>Not used for now.</p>
</td></tr>
</table>


<h3>Rules</h3>


<ul>
<li><p> Koo (2016) (<code>"koo2016"</code>; default)
</p>

<ul>
<li> <p><strong>ICC &lt; 0.50</strong> - Poor reliability
</p>
</li>
<li> <p><strong>0.5 &lt;= ICC &lt; 0.75</strong> - Moderate reliability
</p>
</li>
<li> <p><strong>0.75 &lt;= ICC &lt; 0.9</strong> - Good reliability
</p>
</li>
<li><p> **ICC &gt;= 0.9 ** - Excellent reliability
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p> Koo, T. K., and Li, M. Y. (2016). A guideline of selecting and reporting intraclass correlation coefficients for reliability research. Journal of chiropractic medicine, 15(2), 155-163.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_icc(0.6)
interpret_icc(c(0.4, 0.8))
</code></pre>

<hr>
<h2 id='interpret_kendalls_w'>Interpret Kendall's Coefficient of Concordance <em>W</em></h2><span id='topic+interpret_kendalls_w'></span>

<h3>Description</h3>

<p>Interpret Kendall's Coefficient of Concordance <em>W</em>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_kendalls_w(w, rules = "landis1977")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_kendalls_w_+3A_w">w</code></td>
<td>
<p>Value or vector of Kendall's coefficient of concordance.</p>
</td></tr>
<tr><td><code id="interpret_kendalls_w_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"landis1977"</code> (default) or a custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
</table>


<h3>Rules</h3>


<ul>
<li><p> Landis &amp; Koch (1977) (<code>"landis1977"</code>; default)
</p>

<ul>
<li> <p><strong>0.00 &lt;= w &lt; 0.20</strong> - Slight agreement
</p>
</li>
<li> <p><strong>0.20 &lt;= w &lt; 0.40</strong> - Fair agreement
</p>
</li>
<li> <p><strong>0.40 &lt;= w &lt; 0.60</strong> - Moderate agreement
</p>
</li>
<li> <p><strong>0.60 &lt;= w &lt; 0.80</strong> - Substantial agreement
</p>
</li>
<li> <p><strong>w &gt;= 0.80</strong>        - Almost perfect agreement
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p> Landis, J. R., &amp; Koch G. G. (1977). The measurement of observer agreement
for categorical data. Biometrics, 33:159-74.
</p>
</li></ul>


<hr>
<h2 id='interpret_oddsratio'>Interpret Odds Ratio</h2><span id='topic+interpret_oddsratio'></span>

<h3>Description</h3>

<p>Interpret Odds Ratio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_oddsratio(OR, rules = "cohen1988", p0 = NULL, log = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_oddsratio_+3A_or">OR</code></td>
<td>
<p>Value or vector of (log) odds ratio values.</p>
</td></tr>
<tr><td><code id="interpret_oddsratio_+3A_rules">rules</code></td>
<td>
<p>If <code>"cohen1988"</code> (default), <code>OR</code> is transformed to a
standardized difference (via <code><a href="#topic+oddsratio_to_d">oddsratio_to_d()</a></code>) and interpreted according
to Cohen's rules (see <code><a href="#topic+interpret_cohens_d">interpret_cohens_d()</a></code>; see Chen et al., 2010). If a
custom set of <code><a href="#topic+rules">rules()</a></code> is used, OR is interpreted as is.</p>
</td></tr>
<tr><td><code id="interpret_oddsratio_+3A_p0">p0</code></td>
<td>
<p>Baseline risk. If not specified, the <em>d</em> to <em>OR</em> conversion uses am approximation (see details).</p>
</td></tr>
<tr><td><code id="interpret_oddsratio_+3A_log">log</code></td>
<td>
<p>Are the provided values log odds ratio.</p>
</td></tr>
<tr><td><code id="interpret_oddsratio_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Rules</h3>

<p>Rules apply to OR as ratios, so OR of 10 is as extreme as a OR of 0.1 (1/10).
</p>

<ul>
<li><p> Cohen (1988) (<code>"cohen1988"</code>, based on the <code><a href="#topic+oddsratio_to_d">oddsratio_to_d()</a></code> conversion, see <code><a href="#topic+interpret_cohens_d">interpret_cohens_d()</a></code>)
</p>

<ul>
<li> <p><strong>OR &lt; 1.44</strong> - Very small
</p>
</li>
<li> <p><strong>1.44 &lt;= OR &lt; 2.48</strong> - Small
</p>
</li>
<li> <p><strong>2.48 &lt;= OR &lt; 4.27</strong> - Medium
</p>
</li>
<li> <p><strong>OR &gt;= 4.27</strong> - Large
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences
(2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Chen, H., Cohen, P., &amp; Chen, S. (2010). How big is a big odds ratio?
Interpreting the magnitudes of odds ratios in epidemiological studies.
Communications in Statistics-Simulation and Computation, 39(4), 860-864.
</p>
</li>
<li><p> SÃ¡nchez-Meca, J., MarÃ­n-MartÃ­nez, F., &amp; ChacÃ³n-Moscoso, S. (2003).
Effect-size indices for dichotomized outcomes in meta-analysis. Psychological
methods, 8(4), 448.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_oddsratio(1)
interpret_oddsratio(c(5, 2))

</code></pre>

<hr>
<h2 id='interpret_omega_squared'>Interpret ANOVA Effect Sizes</h2><span id='topic+interpret_omega_squared'></span><span id='topic+interpret_eta_squared'></span><span id='topic+interpret_epsilon_squared'></span><span id='topic+interpret_r2_semipartial'></span>

<h3>Description</h3>

<p>Interpret ANOVA Effect Sizes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_omega_squared(es, rules = "field2013", ...)

interpret_eta_squared(es, rules = "field2013", ...)

interpret_epsilon_squared(es, rules = "field2013", ...)

interpret_r2_semipartial(es, rules = "field2013", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_omega_squared_+3A_es">es</code></td>
<td>
<p>Value or vector of (partial) eta / omega / epsilon squared or semipartial r squared values.</p>
</td></tr>
<tr><td><code id="interpret_omega_squared_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"field2013"</code> (default), <code>"cohen1992"</code> or custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_omega_squared_+3A_...">...</code></td>
<td>
<p>Not used for now.</p>
</td></tr>
</table>


<h3>Rules</h3>


<ul>
<li><p> Field (2013) (<code>"field2013"</code>; default)
</p>

<ul>
<li> <p><strong>ES &lt; 0.01</strong> - Very small
</p>
</li>
<li> <p><strong>0.01 &lt;= ES &lt; 0.06</strong> - Small
</p>
</li>
<li> <p><strong>0.06 &lt;= ES &lt; 0.14</strong> - Medium
</p>
</li>
<li><p> **ES &gt;= 0.14 ** - Large
</p>
</li></ul>

</li>
<li><p> Cohen (1992) (<code>"cohen1992"</code>) applicable to one-way anova, or to <em>partial</em>
eta / omega / epsilon squared in multi-way anova.
</p>

<ul>
<li> <p><strong>ES &lt; 0.02</strong> - Very small
</p>
</li>
<li> <p><strong>0.02 &lt;= ES &lt; 0.13</strong> - Small
</p>
</li>
<li> <p><strong>0.13 &lt;= ES &lt; 0.26</strong> - Medium
</p>
</li>
<li> <p><strong>ES &gt;= 0.26</strong> - Large
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p> Field, A (2013) Discovering statistics using IBM SPSS Statistics. Fourth
Edition. Sage:London.
</p>
</li>
<li><p> Cohen, J. (1992). A power primer. Psychological bulletin, 112(1), 155.
</p>
</li></ul>



<h3>See Also</h3>

<p>https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>interpret_eta_squared(.02)
interpret_eta_squared(c(.5, .02), rules = "cohen1992")
</code></pre>

<hr>
<h2 id='interpret_p'>Interpret <em>p</em>-Values</h2><span id='topic+interpret_p'></span>

<h3>Description</h3>

<p>Interpret <em>p</em>-Values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_p(p, rules = "default")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_p_+3A_p">p</code></td>
<td>
<p>Value or vector of p-values.</p>
</td></tr>
<tr><td><code id="interpret_p_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"default"</code>, <code>"rss"</code> (for <em>Redefine statistical
significance</em> rules) or custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
</table>


<h3>Rules</h3>


<ul>
<li><p> Default
</p>

<ul>
<li> <p><strong>p &gt;= 0.05</strong> - Not significant
</p>
</li>
<li> <p><strong>p &lt; 0.05</strong> - Significant
</p>
</li></ul>

</li>
<li><p> Benjamin et al. (2018) (<code>"rss"</code>)
</p>

<ul>
<li> <p><strong>p &gt;= 0.05</strong> - Not significant
</p>
</li>
<li> <p><strong>0.005 &lt;= p &lt; 0.05</strong> - Suggestive
</p>
</li>
<li> <p><strong>p &lt; 0.005</strong> - Significant
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p> Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E. J., Berk, R., ... &amp; Cesarini, D. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6-10.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_p(c(.5, .02, 0.001))
interpret_p(c(.5, .02, 0.001), rules = "rss")

stars &lt;- rules(c(0.001, 0.01, 0.05, 0.1), c("***", "**", "*", "+", ""),
  right = FALSE, name = "stars"
)
interpret_p(c(.5, .02, 0.001), rules = stars)

</code></pre>

<hr>
<h2 id='interpret_pd'>Interpret Probability of Direction (pd)</h2><span id='topic+interpret_pd'></span>

<h3>Description</h3>

<p>Interpret Probability of Direction (pd)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_pd(pd, rules = "default", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_pd_+3A_pd">pd</code></td>
<td>
<p>Value or vector of probabilities of direction.</p>
</td></tr>
<tr><td><code id="interpret_pd_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"default"</code>, <code>"makowski2019"</code> or a custom set of
<code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_pd_+3A_...">...</code></td>
<td>
<p>Not directly used.</p>
</td></tr>
</table>


<h3>Rules</h3>


<ul>
<li><p> Default (i.e., equivalent to p-values)
</p>

<ul>
<li> <p><strong>pd &lt;= 0.975</strong> - not significant
</p>
</li>
<li> <p><strong>pd &gt; 0.975</strong> - significant
</p>
</li></ul>

</li>
<li><p> Makowski et al. (2019) (<code>"makowski2019"</code>)
</p>

<ul>
<li> <p><strong>pd &lt;= 0.95</strong> - uncertain
</p>
</li>
<li> <p><strong>pd &gt; 0.95</strong> - possibly existing
</p>
</li>
<li> <p><strong>pd &gt; 0.97</strong> - likely existing
</p>
</li>
<li> <p><strong>pd &gt; 0.99</strong> - probably existing
</p>
</li>
<li> <p><strong>pd &gt; 0.999</strong> - certainly existing
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p> Makowski, D., Ben-Shachar, M. S., Chen, S. H., and LÃ¼decke, D. (2019). Indices of effect existence and significance in the Bayesian framework. Frontiers in psychology, 10, 2767.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_pd(.98)
interpret_pd(c(.96, .99), rules = "makowski2019")
</code></pre>

<hr>
<h2 id='interpret_r'>Interpret Correlation Coefficient</h2><span id='topic+interpret_r'></span><span id='topic+interpret_phi'></span><span id='topic+interpret_cramers_v'></span><span id='topic+interpret_rank_biserial'></span><span id='topic+interpret_fei'></span>

<h3>Description</h3>

<p>Interpret Correlation Coefficient
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_r(r, rules = "funder2019", ...)

interpret_phi(r, rules = "funder2019", ...)

interpret_cramers_v(r, rules = "funder2019", ...)

interpret_rank_biserial(r, rules = "funder2019", ...)

interpret_fei(r, rules = "funder2019", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_r_+3A_r">r</code></td>
<td>
<p>Value or vector of correlation coefficient.</p>
</td></tr>
<tr><td><code id="interpret_r_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"funder2019"</code> (default), <code>"gignac2016"</code>, <code>"cohen1988"</code>,
<code>"evans1996"</code>, <code>"lovakov2021"</code> or a custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_r_+3A_...">...</code></td>
<td>
<p>Not directly used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since Cohen's <em>w</em> does not have a fixed upper bound, for all by the most
simple of cases (2-by-2 or 1-by-2 tables), interpreting Cohen's <em>w</em> as a
correlation coefficient is inappropriate (Ben-Shachar, et al., 2024; Cohen,
1988, p. 222). Please us <code><a href="#topic+cramers_v">cramers_v()</a></code> of the like instead.
</p>


<h3>Rules</h3>

<p>Rules apply to positive and negative <em>r</em> alike.
</p>

<ul>
<li><p> Funder &amp; Ozer (2019) (<code>"funder2019"</code>; default)
</p>

<ul>
<li> <p><strong>r &lt; 0.05</strong> - Tiny
</p>
</li>
<li> <p><strong>0.05 &lt;= r &lt; 0.1</strong> - Very small
</p>
</li>
<li> <p><strong>0.1 &lt;= r &lt; 0.2</strong> - Small
</p>
</li>
<li> <p><strong>0.2 &lt;= r &lt; 0.3</strong> - Medium
</p>
</li>
<li> <p><strong>0.3 &lt;= r &lt; 0.4</strong> - Large
</p>
</li>
<li> <p><strong>r &gt;= 0.4</strong> - Very large
</p>
</li></ul>

</li>
<li><p> Gignac &amp; Szodorai (2016) (<code>"gignac2016"</code>)
</p>

<ul>
<li> <p><strong>r &lt; 0.1</strong> - Very small
</p>
</li>
<li> <p><strong>0.1 &lt;= r &lt; 0.2</strong> - Small
</p>
</li>
<li> <p><strong>0.2 &lt;= r &lt; 0.3</strong> - Moderate
</p>
</li>
<li> <p><strong>r &gt;= 0.3</strong> - Large
</p>
</li></ul>

</li>
<li><p> Cohen (1988) (<code>"cohen1988"</code>)
</p>

<ul>
<li> <p><strong>r &lt; 0.1</strong> - Very small
</p>
</li>
<li> <p><strong>0.1 &lt;= r &lt; 0.3</strong> - Small
</p>
</li>
<li> <p><strong>0.3 &lt;= r &lt; 0.5</strong> - Moderate
</p>
</li>
<li> <p><strong>r &gt;= 0.5</strong> - Large
</p>
</li></ul>

</li>
<li><p> Lovakov &amp; Agadullina (2021) (<code>"lovakov2021"</code>)
</p>

<ul>
<li> <p><strong>r &lt; 0.12</strong> - Very small
</p>
</li>
<li> <p><strong>0.12 &lt;= r &lt; 0.24</strong> - Small
</p>
</li>
<li> <p><strong>0.24 &lt;= r &lt; 0.41</strong> - Moderate
</p>
</li>
<li> <p><strong>r &gt;= 0.41</strong> - Large
</p>
</li></ul>

</li>
<li><p> Evans (1996) (<code>"evans1996"</code>)
</p>

<ul>
<li> <p><strong>r &lt; 0.2</strong> - Very weak
</p>
</li>
<li> <p><strong>0.2 &lt;= r &lt; 0.4</strong> - Weak
</p>
</li>
<li> <p><strong>0.4 &lt;= r &lt; 0.6</strong> - Moderate
</p>
</li>
<li> <p><strong>0.6 &lt;= r &lt; 0.8</strong> - Strong
</p>
</li>
<li> <p><strong>r &gt;= 0.8</strong> - Very strong
</p>
</li></ul>

</li></ul>



<h3>Note</h3>

<p>As <code class="reqn">\phi</code> can be larger than 1 - it is recommended to compute
and interpret Cramer's <em>V</em> instead.
</p>


<h3>References</h3>


<ul>
<li><p> Lovakov, A., &amp; Agadullina, E. R. (2021). Empirically Derived Guidelines for
Effect Size Interpretation in Social Psychology. European Journal of Social
Psychology.
</p>
</li>
<li><p> Funder, D. C., &amp; Ozer, D. J. (2019). Evaluating effect size in
psychological research: sense and nonsense. Advances in Methods and Practices
in Psychological Science.
</p>
</li>
<li><p> Gignac, G. E., &amp; Szodorai, E. T. (2016). Effect size guidelines for
individual differences researchers. Personality and individual differences,
102, 74-78.
</p>
</li>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences
(2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Evans, J. D. (1996). Straightforward statistics for the behavioral
sciences. Thomson Brooks/Cole Publishing Co.
</p>
</li>
<li><p> Ben-Shachar, M.S., Patil, I., ThÃ©riault, R., Wiernik, B.M., LÃ¼decke, D.
(2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the
ChiâSquared Statistic. Mathematics, 11, 1982. <a href="https://doi.org/10.3390/math11091982">doi:10.3390/math11091982</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Page 88 of APA's 6th Edition.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>interpret_r(.015)
interpret_r(c(.5, -.02))
interpret_r(.3, rules = "lovakov2021")
</code></pre>

<hr>
<h2 id='interpret_r2'>Interpret Coefficient of Determination (<code class="reqn">R^2</code>)</h2><span id='topic+interpret_r2'></span>

<h3>Description</h3>

<p>Interpret Coefficient of Determination (<code class="reqn">R^2</code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_r2(r2, rules = "cohen1988")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_r2_+3A_r2">r2</code></td>
<td>
<p>Value or vector of <code class="reqn">R^2</code> values.</p>
</td></tr>
<tr><td><code id="interpret_r2_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"cohen1988"</code> (default), <code>"falk1992"</code>, <code>"chin1998"</code>,
<code>"hair2011"</code>, or custom set of <code><a href="#topic+rules">rules()</a></code>].</p>
</td></tr>
</table>


<h3>Rules</h3>



<h4>For Linear Regression</h4>


<ul>
<li><p> Cohen (1988) (<code>"cohen1988"</code>; default)
</p>

<ul>
<li> <p><strong>R2 &lt; 0.02</strong> - Very weak
</p>
</li>
<li> <p><strong>0.02 &lt;= R2 &lt; 0.13</strong> - Weak
</p>
</li>
<li> <p><strong>0.13 &lt;= R2 &lt; 0.26</strong> - Moderate
</p>
</li>
<li> <p><strong>R2 &gt;= 0.26</strong> - Substantial
</p>
</li></ul>

</li>
<li><p> Falk &amp; Miller (1992) (<code>"falk1992"</code>)
</p>

<ul>
<li> <p><strong>R2 &lt; 0.1</strong> - Negligible
</p>
</li>
<li> <p><strong>R2 &gt;= 0.1</strong> - Adequate
</p>
</li></ul>

</li></ul>




<h4>For PLS / SEM R-Squared of <em>latent</em> variables</h4>


<ul>
<li><p> Chin, W. W. (1998) (<code>"chin1998"</code>)
</p>

<ul>
<li> <p><strong>R2 &lt; 0.19</strong> - Very weak
</p>
</li>
<li> <p><strong>0.19 &lt;= R2 &lt; 0.33</strong> - Weak
</p>
</li>
<li> <p><strong>0.33 &lt;= R2 &lt; 0.67</strong> - Moderate
</p>
</li>
<li> <p><strong>R2 &gt;= 0.67</strong> - Substantial
</p>
</li></ul>

</li>
<li><p> Hair et al. (2011) (<code>"hair2011"</code>)
</p>

<ul>
<li> <p><strong>R2 &lt; 0.25</strong> - Very weak
</p>
</li>
<li> <p><strong>0.25 &lt;= R2 &lt; 0.50</strong> - Weak
</p>
</li>
<li> <p><strong>0.50 &lt;= R2 &lt; 0.75</strong> - Moderate
</p>
</li>
<li> <p><strong>R2 &gt;= 0.75</strong> - Substantial
</p>
</li></ul>

</li></ul>




<h3>References</h3>


<ul>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences
(2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Falk, R. F., &amp; Miller, N. B. (1992). A primer for soft modeling. University
of Akron Press.
</p>
</li>
<li><p> Chin, W. W. (1998). The partial least squares approach to structural
equation modeling. Modern methods for business research, 295(2), 295-336.
</p>
</li>
<li><p> Hair, J. F., Ringle, C. M., &amp; Sarstedt, M. (2011). PLS-SEM: Indeed a silver
bullet. Journal of Marketing theory and Practice, 19(2), 139-152.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>interpret_r2(.02)
interpret_r2(c(.5, .02))
</code></pre>

<hr>
<h2 id='interpret_rope'>Interpret Bayesian Posterior Percentage in ROPE.</h2><span id='topic+interpret_rope'></span>

<h3>Description</h3>

<p>Interpretation of
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_rope(rope, rules = "default", ci = 0.9)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_rope_+3A_rope">rope</code></td>
<td>
<p>Value or vector of percentages in ROPE.</p>
</td></tr>
<tr><td><code id="interpret_rope_+3A_rules">rules</code></td>
<td>
<p>A character string (see details) or a custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
<tr><td><code id="interpret_rope_+3A_ci">ci</code></td>
<td>
<p>The Credible Interval (CI) probability, corresponding to the
proportion of HDI, that was used. Can be <code>1</code> in the case of &quot;full ROPE&quot;.</p>
</td></tr>
</table>


<h3>Rules</h3>


<ul>
<li><p> Default
</p>

<ul>
<li><p> For CI &lt; 1
</p>

<ul>
<li> <p><strong>Rope = 0</strong> - Significant
</p>
</li>
<li> <p><strong>0 &lt; Rope &lt; 1</strong> - Undecided
</p>
</li>
<li> <p><strong>Rope = 1</strong> - Negligible
</p>
</li></ul>

</li>
<li><p> For CI = 1
</p>

<ul>
<li> <p><strong>Rope &lt; 0.01</strong> - Significant
</p>
</li>
<li> <p><strong>0.01 &lt; Rope &lt; 0.025</strong> - Probably significant
</p>
</li>
<li> <p><strong>0.025 &lt; Rope &lt; 0.975</strong> - Undecided
</p>
</li>
<li> <p><strong>0.975 &lt; Rope &lt; 0.99</strong> - Probably negligible
</p>
</li>
<li> <p><strong>Rope &gt; 0.99</strong> - Negligible
</p>
</li></ul>

</li></ul>

</li></ul>



<h3>References</h3>

<p><a href="https://easystats.github.io/bayestestR/articles/guidelines.html">BayestestR's reporting guidelines</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>interpret_rope(0, ci = 0.9)
interpret_rope(c(0.005, 0.99), ci = 1)
</code></pre>

<hr>
<h2 id='interpret_vif'>Interpret the Variance Inflation Factor (VIF)</h2><span id='topic+interpret_vif'></span>

<h3>Description</h3>

<p>Interpret VIF index of multicollinearity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_vif(vif, rules = "default")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpret_vif_+3A_vif">vif</code></td>
<td>
<p>Value or vector of VIFs.</p>
</td></tr>
<tr><td><code id="interpret_vif_+3A_rules">rules</code></td>
<td>
<p>Can be <code>"default"</code> or a custom set of <code><a href="#topic+rules">rules()</a></code>.</p>
</td></tr>
</table>


<h3>Rules</h3>


<ul>
<li><p> Default
</p>

<ul>
<li> <p><strong>VIF &lt; 5</strong> - Low
</p>
</li>
<li> <p><strong>5 &lt;= VIF &lt; 10</strong> - Moderate
</p>
</li>
<li> <p><strong>VIF &gt;= 10</strong> - High
</p>
</li></ul>

</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
interpret_vif(c(1.4, 30.4))

</code></pre>

<hr>
<h2 id='is_effectsize_name'>Checks for a Valid Effect Size Name</h2><span id='topic+is_effectsize_name'></span><span id='topic+get_effectsize_name'></span><span id='topic+get_effectsize_label'></span>

<h3>Description</h3>

<p>For use by other functions and packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_effectsize_name(x, ignore_case = TRUE)

get_effectsize_name(x, ignore_case = TRUE)

get_effectsize_label(
  x,
  ignore_case = TRUE,
  use_symbols = getOption("es.use_symbols", FALSE)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_effectsize_name_+3A_x">x</code></td>
<td>
<p>A character, or a vector.</p>
</td></tr>
<tr><td><code id="is_effectsize_name_+3A_ignore_case">ignore_case</code></td>
<td>
<p>Should case of input be ignored?</p>
</td></tr>
<tr><td><code id="is_effectsize_name_+3A_use_symbols">use_symbols</code></td>
<td>
<p>Should proper symbols be printed (<code>TRUE</code>) instead of
transliterated effect size names (<code>FALSE</code>). See <a href="#topic+effectsize_options">effectsize_options</a>.</p>
</td></tr>
</table>

<hr>
<h2 id='mahalanobis_d'>Mahalanobis' <em>D</em> (a multivariate Cohen's <em>d</em>)</h2><span id='topic+mahalanobis_d'></span>

<h3>Description</h3>

<p>Compute effect size indices for standardized difference between two normal
multivariate distributions or between one multivariate distribution and a
defined point. This is the standardized effect size for Hotelling's <code class="reqn">T^2</code>
test (e.g., <code>DescTools::HotellingsT2Test()</code>). <em>D</em> is computed as:
<br /><br />
</p>
<p style="text-align: center;"><code class="reqn">D = \sqrt{(\bar{X}_1-\bar{X}_2-\mu)^T \Sigma_p^{-1} (\bar{X}_1-\bar{X}_2-\mu)}</code>
</p>

<p><br /><br />
Where <code class="reqn">\bar{X}_i</code> are the column means, <code class="reqn">\Sigma_p</code> is the <em>pooled</em>
covariance matrix, and <code class="reqn">\mu</code> is a vector of the null differences for each
variable. When there is only one variate, this formula reduces to Cohen's
<em>d</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mahalanobis_d(
  x,
  y = NULL,
  data = NULL,
  pooled_cov = TRUE,
  mu = 0,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mahalanobis_d_+3A_x">x</code>, <code id="mahalanobis_d_+3A_y">y</code></td>
<td>
<p>A data frame or matrix. Any incomplete observations (with <code>NA</code>
values) are dropped. <code>x</code> can also be a formula (see details) in which case
<code>y</code> is ignored.</p>
</td></tr>
<tr><td><code id="mahalanobis_d_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables.</p>
</td></tr>
<tr><td><code id="mahalanobis_d_+3A_pooled_cov">pooled_cov</code></td>
<td>
<p>Should equal covariance be assumed? Currently only
<code>pooled_cov = TRUE</code> is supported.</p>
</td></tr>
<tr><td><code id="mahalanobis_d_+3A_mu">mu</code></td>
<td>
<p>A named list/vector of the true difference in means for each
variable. Can also be a vector of length 1, which will be recycled.</p>
</td></tr>
<tr><td><code id="mahalanobis_d_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="mahalanobis_d_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="mahalanobis_d_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="mahalanobis_d_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To specify a <code>x</code> as a formula:
</p>

<ul>
<li><p> Two sample case: <code>DV1 + DV2 ~ group</code> or <code>cbind(DV1, DV2) ~ group</code>
</p>
</li>
<li><p> One sample case: <code>DV1 + DV2 ~ 1</code> or <code>cbind(DV1, DV2) ~ 1</code>
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame with the <code>Mahalanobis_D</code> and potentially its CI
(<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="#topic+effectsize_CIs">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Del Giudice, M. (2017). Heterogeneity coefficients for Mahalanobis' D as a multivariate effect size. Multivariate Behavioral Research, 52(2), 216-221.
</p>
</li>
<li><p> Mahalanobis, P. C. (1936). On the generalized distance in statistics. National Institute of Science of India.
</p>
</li>
<li><p> Reiser, B. (2001). Confidence intervals for the Mahalanobis distance. Communications in Statistics-Simulation and Computation, 30(1), 37-45.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="stats.html#topic+mahalanobis">stats::mahalanobis()</a></code>, <code><a href="#topic+cov_pooled">cov_pooled()</a></code>
</p>
<p>Other standardized differences: 
<code><a href="#topic+cohens_d">cohens_d</a>()</code>,
<code><a href="#topic+means_ratio">means_ratio</a>()</code>,
<code><a href="#topic+p_superiority">p_superiority</a>()</code>,
<code><a href="#topic+rank_biserial">rank_biserial</a>()</code>,
<code><a href="#topic+repeated_measures_d">repeated_measures_d</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Two samples --------------
mtcars_am0 &lt;- subset(mtcars, am == 0,
  select = c(mpg, hp, cyl)
)
mtcars_am1 &lt;- subset(mtcars, am == 1,
  select = c(mpg, hp, cyl)
)

mahalanobis_d(mtcars_am0, mtcars_am1)

# Or
mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars)

mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars, alternative = "two.sided")

# Different mu:
mahalanobis_d(mpg + hp + cyl ~ am,
  data = mtcars,
  mu = c(mpg = -4, hp = 15, cyl = 0)
)


# D is a multivariate d, so when only 1 variate is provided:
mahalanobis_d(hp ~ am, data = mtcars)

cohens_d(hp ~ am, data = mtcars)


# One sample ---------------------------
mahalanobis_d(mtcars[, c("mpg", "hp", "cyl")])

# Or
mahalanobis_d(mpg + hp + cyl ~ 1,
  data = mtcars,
  mu = c(mpg = 15, hp = 5, cyl = 3)
)

</code></pre>

<hr>
<h2 id='means_ratio'>Ratio of Means</h2><span id='topic+means_ratio'></span>

<h3>Description</h3>

<p>Computes the ratio of two means (also known as the &quot;response ratio&quot;; RR) of
<strong>variables on a ratio scale</strong> (with an absolute 0). Pair with any reported
<code><a href="stats.html#topic+t.test">stats::t.test()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>means_ratio(
  x,
  y = NULL,
  data = NULL,
  paired = FALSE,
  adjust = TRUE,
  log = FALSE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="means_ratio_+3A_x">x</code>, <code id="means_ratio_+3A_y">y</code></td>
<td>
<p>A numeric vector, or a character name of one in <code>data</code>.
Any missing values (<code>NA</code>s) are dropped from the resulting vector.
<code>x</code> can also be a formula (see <code><a href="stats.html#topic+t.test">stats::t.test()</a></code>), in which case <code>y</code> is
ignored.</p>
</td></tr>
<tr><td><code id="means_ratio_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables.</p>
</td></tr>
<tr><td><code id="means_ratio_+3A_paired">paired</code></td>
<td>
<p>If <code>TRUE</code>, the values of <code>x</code> and <code>y</code> are considered as paired.
The correlation between these variables will affect the CIs.</p>
</td></tr>
<tr><td><code id="means_ratio_+3A_adjust">adjust</code></td>
<td>
<p>Should the effect size be adjusted for small-sample bias?
Defaults to <code>TRUE</code>; Advisable for small samples.</p>
</td></tr>
<tr><td><code id="means_ratio_+3A_log">log</code></td>
<td>
<p>Should the log-ratio be returned? Defaults to <code>FALSE</code>.
Normally distributed and useful for meta-analysis.</p>
</td></tr>
<tr><td><code id="means_ratio_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="means_ratio_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="means_ratio_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="means_ratio_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. When <code>x</code> is a formula,
these can be <code>subset</code> and <code>na.action</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Means Ratio ranges from 0 to <code class="reqn">\infty</code>, with values smaller than 1
indicating that the second mean is larger than the first, values larger than
1 indicating that the second mean is smaller than the first, and values of 1
indicating that the means are equal.
</p>


<h3>Value</h3>

<p>A data frame with the effect size (<code>Means_ratio</code> or
<code>Means_ratio_adjusted</code>) and their CIs (<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Confidence intervals are estimated as described by Lajeunesse (2011 &amp; 2015)
using the log-ratio standard error assuming a normal distribution. By this
method, the log is taken of the ratio of means, which makes this outcome
measure symmetric around 0 and yields a corresponding sampling distribution
that is closer to normality.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>Note</h3>

<p>The small-sample bias corrected response ratio reported from this
function is derived from Lajeunesse (2015).
</p>


<h3>References</h3>

<p>Lajeunesse, M. J. (2011). On the meta-analysis of response ratios for studies
with correlated and multi-group designs. Ecology, 92(11), 2049-2055.
<a href="https://doi.org/10.1890/11-0423.1">doi:10.1890/11-0423.1</a>
</p>
<p>Lajeunesse, M. J. (2015). Bias and correction for the log response ratio in
ecological meta-analysis. Ecology, 96(8), 2056-2063. <a href="https://doi.org/10.1890/14-2402.1">doi:10.1890/14-2402.1</a>
</p>
<p>Hedges, L. V., Gurevitch, J., &amp; Curtis, P. S. (1999). The meta-analysis of
response ratios in experimental ecology. Ecology, 80(4), 1150â1156.
<a href="https://doi.org/10.1890/0012-9658%281999%29080%5B1150%3ATMAORR%5D2.0.CO%3B2">doi:10.1890/0012-9658(1999)080[1150:TMAORR]2.0.CO;2</a>
</p>


<h3>See Also</h3>

<p>Other standardized differences: 
<code><a href="#topic+cohens_d">cohens_d</a>()</code>,
<code><a href="#topic+mahalanobis_d">mahalanobis_d</a>()</code>,
<code><a href="#topic+p_superiority">p_superiority</a>()</code>,
<code><a href="#topic+rank_biserial">rank_biserial</a>()</code>,
<code><a href="#topic+repeated_measures_d">repeated_measures_d</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
y &lt;- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
means_ratio(x, y)
means_ratio(x, y, adjust = FALSE)

means_ratio(x, y, log = TRUE)


# The ratio is scale invariant, making it a standardized effect size
means_ratio(3 * x, 3 * y)

</code></pre>

<hr>
<h2 id='Music_preferences'>Music Preference by College Major</h2><span id='topic+Music_preferences'></span>

<h3>Description</h3>

<p>Fictional data.
</p>


<h3>Format</h3>

<p>A 4-by-3 table, with a <em>column</em> for each major and a <em>row</em> for each type of music.
</p>
<div class="sourceCode r"><pre>data("Music_preferences")
Music_preferences
#&gt;       Pop Rock Jazz Classic
#&gt; Psych 150  100  165     130
#&gt; Econ   50   65   35      10
#&gt; Law     2   55   40      25
</pre></div>


<h3>See Also</h3>

<p>Other effect size datasets: 
<code><a href="#topic+Music_preferences2">Music_preferences2</a></code>,
<code><a href="#topic+RCT_table">RCT_table</a></code>,
<code><a href="#topic+Smoking_FASD">Smoking_FASD</a></code>,
<code><a href="#topic+food_class">food_class</a></code>,
<code><a href="#topic+hardlyworking">hardlyworking</a></code>,
<code><a href="#topic+rouder2016">rouder2016</a></code>,
<code><a href="#topic+screening_test">screening_test</a></code>
</p>

<hr>
<h2 id='Music_preferences2'>Music Preference by College Major</h2><span id='topic+Music_preferences2'></span>

<h3>Description</h3>

<p>Fictional data, with more extreme preferences than <a href="#topic+Music_preferences">Music_preferences</a>
</p>


<h3>Format</h3>

<p>A 4-by-3 table, with a <em>column</em> for each major and a <em>row</em> for each type of music.
</p>
<div class="sourceCode r"><pre>data("Music_preferences2")
Music_preferences2
#&gt;       Pop Rock Jazz Classic
#&gt; Psych 151  130   12       7
#&gt; Econ   77    6  111       4
#&gt; Law     0    4    2     165
</pre></div>


<h3>See Also</h3>

<p>Other effect size datasets: 
<code><a href="#topic+Music_preferences">Music_preferences</a></code>,
<code><a href="#topic+RCT_table">RCT_table</a></code>,
<code><a href="#topic+Smoking_FASD">Smoking_FASD</a></code>,
<code><a href="#topic+food_class">food_class</a></code>,
<code><a href="#topic+hardlyworking">hardlyworking</a></code>,
<code><a href="#topic+rouder2016">rouder2016</a></code>,
<code><a href="#topic+screening_test">screening_test</a></code>
</p>

<hr>
<h2 id='odds_to_probs'>Convert Between Odds and Probabilities</h2><span id='topic+odds_to_probs'></span><span id='topic+odds_to_probs.data.frame'></span><span id='topic+probs_to_odds'></span><span id='topic+probs_to_odds.data.frame'></span>

<h3>Description</h3>

<p>Convert Between Odds and Probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>odds_to_probs(odds, log = FALSE, ...)

## S3 method for class 'data.frame'
odds_to_probs(odds, log = FALSE, select = NULL, exclude = NULL, ...)

probs_to_odds(probs, log = FALSE, ...)

## S3 method for class 'data.frame'
probs_to_odds(probs, log = FALSE, select = NULL, exclude = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="odds_to_probs_+3A_odds">odds</code></td>
<td>
<p>The <em>Odds</em> (or <code>log(odds)</code> when <code>log = TRUE</code>) to convert.</p>
</td></tr>
<tr><td><code id="odds_to_probs_+3A_log">log</code></td>
<td>
<p>Take in or output log odds (such as in logistic models).</p>
</td></tr>
<tr><td><code id="odds_to_probs_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="odds_to_probs_+3A_select">select</code></td>
<td>
<p>When a data frame is passed, character or list of of column
names to be transformed.</p>
</td></tr>
<tr><td><code id="odds_to_probs_+3A_exclude">exclude</code></td>
<td>
<p>When a data frame is passed, character or list of column names
to be excluded from transformation.</p>
</td></tr>
<tr><td><code id="odds_to_probs_+3A_probs">probs</code></td>
<td>
<p>Probability values to convert.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Converted index.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Logistic">stats::plogis()</a></code>
</p>
<p>Other convert between effect sizes: 
<code><a href="#topic+d_to_r">d_to_r</a>()</code>,
<code><a href="#topic+diff_to_cles">diff_to_cles</a></code>,
<code><a href="#topic+eta2_to_f2">eta2_to_f2</a>()</code>,
<code><a href="#topic+oddsratio_to_riskratio">oddsratio_to_riskratio</a>()</code>,
<code><a href="#topic+w_to_fei">w_to_fei</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>odds_to_probs(3)
odds_to_probs(1.09, log = TRUE)

probs_to_odds(0.95)
probs_to_odds(0.95, log = TRUE)
</code></pre>

<hr>
<h2 id='oddsratio'>Odds Ratios, Risk Ratios and Other Effect Sizes for 2-by-2 Contingency Tables</h2><span id='topic+oddsratio'></span><span id='topic+riskratio'></span><span id='topic+cohens_h'></span><span id='topic+arr'></span><span id='topic+nnt'></span>

<h3>Description</h3>

<p>Compute Odds Ratios, Risk Ratios, Cohen's <em>h</em>, Absolute Risk Reduction or
Number Needed to Treat. Report with any <code><a href="stats.html#topic+chisq.test">stats::chisq.test()</a></code> or
<code><a href="stats.html#topic+fisher.test">stats::fisher.test()</a></code>.
<br /><br />
Note that these are computed with each <strong>column</strong> representing the different
groups, and the <em>first</em> column representing the treatment group and the
<em>second</em> column baseline (or control). Effects are given as <code>treatment / control</code>. If you wish you use rows as groups you must pass a transposed
table, or switch the <code>x</code> and <code>y</code> arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oddsratio(x, y = NULL, ci = 0.95, alternative = "two.sided", log = FALSE, ...)

riskratio(x, y = NULL, ci = 0.95, alternative = "two.sided", log = FALSE, ...)

cohens_h(x, y = NULL, ci = 0.95, alternative = "two.sided", ...)

arr(x, y = NULL, ci = 0.95, alternative = "two.sided", ...)

nnt(x, y = NULL, ci = 0.95, alternative = "two.sided", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="oddsratio_+3A_x">x</code></td>
<td>
<p>a numeric vector or matrix. <code>x</code> and <code>y</code> can also
both be factors.</p>
</td></tr>
<tr><td><code id="oddsratio_+3A_y">y</code></td>
<td>
<p>a numeric vector; ignored if <code>x</code> is a matrix.  If
<code>x</code> is a factor, <code>y</code> should be a factor of the same length.</p>
</td></tr>
<tr><td><code id="oddsratio_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="oddsratio_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="oddsratio_+3A_log">log</code></td>
<td>
<p>Take in or output the log of the ratio (such as in logistic models),
e.g. when the desired input or output are log odds ratios instead odds ratios.</p>
</td></tr>
<tr><td><code id="oddsratio_+3A_...">...</code></td>
<td>
<p>Ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the effect size (<code>Odds_ratio</code>, <code>Risk_ratio</code>
(possibly with the prefix <code>log_</code>), <code>Cohens_h</code>, <code>ARR</code>, <code>NNT</code>) and its CIs
(<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Confidence intervals are estimated using the standard normal parametric
method (see Katz et al., 1978; Szumilas, 2010).
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Katz, D. J. S. M., Baptista, J., Azen, S. P., &amp; Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
</p>
</li>
<li><p> Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other effect sizes for contingency table: 
<code><a href="#topic+cohens_g">cohens_g</a>()</code>,
<code><a href="#topic+phi">phi</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("RCT_table")
RCT_table # note groups are COLUMNS

oddsratio(RCT_table)
oddsratio(RCT_table, alternative = "greater")

riskratio(RCT_table)

cohens_h(RCT_table)

arr(RCT_table)

nnt(RCT_table)

</code></pre>

<hr>
<h2 id='oddsratio_to_riskratio'>Convert Between Odds Ratios, Risk Ratios and Other Metrics of Change in Probabilities</h2><span id='topic+oddsratio_to_riskratio'></span><span id='topic+oddsratio_to_arr'></span><span id='topic+oddsratio_to_nnt'></span><span id='topic+logoddsratio_to_riskratio'></span><span id='topic+logoddsratio_to_arr'></span><span id='topic+logoddsratio_to_nnt'></span><span id='topic+riskratio_to_oddsratio'></span><span id='topic+riskratio_to_arr'></span><span id='topic+riskratio_to_logoddsratio'></span><span id='topic+riskratio_to_nnt'></span><span id='topic+arr_to_riskratio'></span><span id='topic+arr_to_oddsratio'></span><span id='topic+arr_to_logoddsratio'></span><span id='topic+arr_to_nnt'></span><span id='topic+nnt_to_oddsratio'></span><span id='topic+nnt_to_logoddsratio'></span><span id='topic+nnt_to_riskratio'></span><span id='topic+nnt_to_arr'></span>

<h3>Description</h3>

<p>Convert Between Odds Ratios, Risk Ratios and Other Metrics of Change in Probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oddsratio_to_riskratio(OR, p0, log = FALSE, verbose = TRUE, ...)

oddsratio_to_arr(OR, p0, log = FALSE, verbose = TRUE, ...)

oddsratio_to_nnt(OR, p0, log = FALSE, verbose = TRUE, ...)

logoddsratio_to_riskratio(logOR, p0, log = TRUE, verbose = TRUE, ...)

logoddsratio_to_arr(logOR, p0, log = TRUE, verbose = TRUE, ...)

logoddsratio_to_nnt(logOR, p0, log = TRUE, verbose = TRUE, ...)

riskratio_to_oddsratio(RR, p0, log = FALSE, verbose = TRUE, ...)

riskratio_to_arr(RR, p0, verbose = TRUE, ...)

riskratio_to_logoddsratio(RR, p0, log = TRUE, verbose = TRUE, ...)

riskratio_to_nnt(RR, p0, verbose = TRUE, ...)

arr_to_riskratio(ARR, p0, verbose = TRUE, ...)

arr_to_oddsratio(ARR, p0, log = FALSE, verbose = TRUE, ...)

arr_to_logoddsratio(ARR, p0, log = TRUE, verbose = TRUE, ...)

arr_to_nnt(ARR, ...)

nnt_to_oddsratio(NNT, p0, log = FALSE, verbose = TRUE, ...)

nnt_to_logoddsratio(NNT, p0, log = TRUE, verbose = TRUE, ...)

nnt_to_riskratio(NNT, p0, verbose = TRUE, ...)

nnt_to_arr(NNT, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="oddsratio_to_riskratio_+3A_or">OR</code>, <code id="oddsratio_to_riskratio_+3A_logor">logOR</code>, <code id="oddsratio_to_riskratio_+3A_rr">RR</code>, <code id="oddsratio_to_riskratio_+3A_arr">ARR</code>, <code id="oddsratio_to_riskratio_+3A_nnt">NNT</code></td>
<td>
<p>Odds-ratio of <code>odds(p1)/odds(p0)</code>, log-Odds-ratio
of <code>log(odds(p1)/odds(p0))</code>, Risk ratio of <code>p1/p0</code>, Absolute Risk Reduction
of <code>p1 - p0</code>, or Number-needed-to-treat of <code>1/(p1 - p0)</code>. <code>OR</code> and <code>logOR</code>
can also be a logistic regression model.</p>
</td></tr>
<tr><td><code id="oddsratio_to_riskratio_+3A_p0">p0</code></td>
<td>
<p>Baseline risk</p>
</td></tr>
<tr><td><code id="oddsratio_to_riskratio_+3A_log">log</code></td>
<td>
<p>If:
</p>

<ul>
<li> <p><code>TRUE</code>:
</p>

<ul>
<li><p> In <code style="white-space: pre;">&#8288;oddsratio_to_*()&#8288;</code>, <code>OR</code> input is treated as <code>log(OR)</code>.
</p>
</li>
<li><p> In <code style="white-space: pre;">&#8288;*_to_oddsratio()&#8288;</code>, returned value is <code>log(OR)</code>.
</p>
</li></ul>

</li>
<li> <p><code>FALSE</code>:
</p>

<ul>
<li><p> In <code style="white-space: pre;">&#8288;logoddsratio_to_*()&#8288;</code>, <code>logOR</code> input is treated as <code>OR</code>.
</p>
</li>
<li><p> In <code style="white-space: pre;">&#8288;*_to_logoddsratio()&#8288;</code>, returned value is <code>OR</code>.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="oddsratio_to_riskratio_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="oddsratio_to_riskratio_+3A_...">...</code></td>
<td>
<p>Arguments passed to and from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Converted index, or if <code>OR</code>/<code>logOR</code> is a logistic regression model, a
parameter table with the converted indices.
</p>


<h3>References</h3>

<p>Grant, R. L. (2014). Converting an odds ratio to a range of plausible
relative risks for better communication of research findings. Bmj, 348,
f7450.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+oddsratio">oddsratio()</a></code>, <code><a href="#topic+riskratio">riskratio()</a></code>, <code><a href="#topic+arr">arr()</a></code>, and <code><a href="#topic+nnt">nnt()</a></code>.
</p>
<p>Other convert between effect sizes: 
<code><a href="#topic+d_to_r">d_to_r</a>()</code>,
<code><a href="#topic+diff_to_cles">diff_to_cles</a></code>,
<code><a href="#topic+eta2_to_f2">eta2_to_f2</a>()</code>,
<code><a href="#topic+odds_to_probs">odds_to_probs</a>()</code>,
<code><a href="#topic+w_to_fei">w_to_fei</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p0 &lt;- 0.4
p1 &lt;- 0.7

(OR &lt;- probs_to_odds(p1) / probs_to_odds(p0))
(RR &lt;- p1 / p0)
(ARR &lt;- p1 - p0)
(NNT &lt;- arr_to_nnt(ARR))

riskratio_to_oddsratio(RR, p0 = p0)
oddsratio_to_riskratio(OR, p0 = p0)
riskratio_to_arr(RR, p0 = p0)
arr_to_oddsratio(nnt_to_arr(NNT), p0 = p0)

m &lt;- glm(am ~ factor(cyl),
  data = mtcars,
  family = binomial()
)
oddsratio_to_riskratio(m, verbose = FALSE) # RR is relative to the intercept if p0 not provided

</code></pre>

<hr>
<h2 id='p_superiority'>Cohen's <em>U</em>s and Other Common Language Effect Sizes (CLES)</h2><span id='topic+p_superiority'></span><span id='topic+cles'></span><span id='topic+cohens_u1'></span><span id='topic+cohens_u2'></span><span id='topic+cohens_u3'></span><span id='topic+p_overlap'></span><span id='topic+vd_a'></span><span id='topic+wmw_odds'></span>

<h3>Description</h3>

<p>Cohen's <code class="reqn">U_1</code>, <code class="reqn">U_2</code>, and <code class="reqn">U_3</code>, probability of superiority,
proportion of overlap, Wilcoxon-Mann-Whitney odds, and Vargha and Delaney's
<em>A</em> are CLESs. These are effect sizes that represent differences between two
(independent) distributions in probabilistic terms (See details). Pair with
any reported <code><a href="stats.html#topic+t.test">stats::t.test()</a></code> or <code><a href="stats.html#topic+wilcox.test">stats::wilcox.test()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p_superiority(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  paired = FALSE,
  parametric = TRUE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)

cohens_u1(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  parametric = TRUE,
  ci = 0.95,
  alternative = "two.sided",
  iterations = 200,
  verbose = TRUE,
  ...
)

cohens_u2(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  parametric = TRUE,
  ci = 0.95,
  alternative = "two.sided",
  iterations = 200,
  verbose = TRUE,
  ...
)

cohens_u3(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  parametric = TRUE,
  ci = 0.95,
  alternative = "two.sided",
  iterations = 200,
  verbose = TRUE,
  ...
)

p_overlap(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  parametric = TRUE,
  ci = 0.95,
  alternative = "two.sided",
  iterations = 200,
  verbose = TRUE,
  ...
)

vd_a(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)

wmw_odds(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  paired = FALSE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="p_superiority_+3A_x">x</code>, <code id="p_superiority_+3A_y">y</code></td>
<td>
<p>A numeric vector, or a character name of one in <code>data</code>.
Any missing values (<code>NA</code>s) are dropped from the resulting vector.
<code>x</code> can also be a formula (see <code><a href="stats.html#topic+t.test">stats::t.test()</a></code>), in which case <code>y</code> is
ignored.</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables.</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_mu">mu</code></td>
<td>
<p>a number indicating the true value of the mean (or
difference in means if you are performing a two sample test).</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_paired">paired</code></td>
<td>
<p>If <code>TRUE</code>, the values of <code>x</code> and <code>y</code> are considered as paired.
This produces an effect size that is equivalent to the one-sample effect
size on <code>x - y</code>.</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_parametric">parametric</code></td>
<td>
<p>Use parametric estimation (see <code><a href="#topic+cohens_d">cohens_d()</a></code>) or
non-parametric estimation (see <code><a href="#topic+rank_biserial">rank_biserial()</a></code>). See details.</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. When <code>x</code> is a formula,
these can be <code>subset</code> and <code>na.action</code>.</p>
</td></tr>
<tr><td><code id="p_superiority_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates for computing confidence
intervals. Only applies when <code>ci</code> is not <code>NULL</code> and <code>parametric = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These measures of effect size present group differences in probabilistic
terms:
</p>

<ul>
<li> <p><strong>Probability of superiority</strong> is the probability that, when sampling an
observation from each of the groups at random, that the observation from
the second group will be larger than the sample from the first group. For
the one-sample (or paired) case, it is the probability that the sample (or
difference) is larger than <em>mu</em>. (Vargha and Delaney's <em>A</em> is an alias for
the non-parametric <em>probability of superiority</em>.)
</p>
</li>
<li> <p><strong>Cohen's <code class="reqn">U_1</code></strong> is the proportion of the total of both distributions
that does not overlap.
</p>
</li>
<li> <p><strong>Cohen's <code class="reqn">U_2</code></strong> is the proportion of one of the groups that exceeds
<em>the same proportion</em> in the other group.
</p>
</li>
<li> <p><strong>Cohen's <code class="reqn">U_3</code></strong> is the proportion of the second group that is smaller
than the median of the first group.
</p>
</li>
<li> <p><strong>Overlap</strong> (OVL) is the proportional overlap between the distributions.
(When <code>parametric = FALSE</code>, <code><a href="bayestestR.html#topic+overlap">bayestestR::overlap()</a></code> is used.)
</p>
</li></ul>

<p>Wilcoxon-Mann-Whitney odds are the <em>odds</em> of
non-parametric superiority (via <code><a href="#topic+probs_to_odds">probs_to_odds()</a></code>), that is the odds that,
when sampling an observation from each of the groups at random, that the
observation from the second group will be larger than the sample from the
first group.
</p>
<p>Where <code class="reqn">U_1</code>, <code class="reqn">U_2</code>, and <em>Overlap</em> are agnostic to the direction of
the difference between the groups, <code class="reqn">U_3</code> and probability of superiority
are not.
</p>
<p>The parametric version of these effects assumes normality of both populations
and homoscedasticity. If those are not met, the non parametric versions
should be used.
</p>


<h3>Value</h3>

<p>A data frame containing the common language effect sizes (and
optionally their CIs).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>For parametric CLES, the CIs are transformed CIs for Cohen's <em>d</em> (see
<code><a href="#topic+d_to_u3">d_to_u3()</a></code>). For non-parametric (<code>parametric = FALSE</code>) CLES, the CI of
<em>Pr(superiority)</em> is a transformed CI of the rank-biserial correlation
(<code><a href="#topic+rb_to_p_superiority">rb_to_p_superiority()</a></code>), while for all others, confidence intervals are
estimated using the bootstrap method (using the <code>{boot}</code> package).
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Bootstrapped CIs</h3>

<p>Some effect sizes are directionless&ndash;they do have a minimum value that would
be interpreted as &quot;no effect&quot;, but they cannot cross it. For example, a null
value of <a href="#topic+kendalls_w">Kendall's W</a> is 0, indicating no difference between
groups, but it can never have a negative value. Same goes for
<a href="#topic+cohens_u2">U2</a> and <a href="#topic+p_overlap">Overlap</a>: the null value of <code class="reqn">U_2</code> is
0.5, but it can never be smaller than 0.5; am <em>Overlap</em> of 1 means &quot;full
overlap&quot; (no difference), but it cannot be larger than 1.
<br /><br />
When bootstrapping CIs for such effect sizes, the bounds of the CIs will
never cross (and often will never cover) the null. Therefore, these CIs
should not be used for statistical inference.
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>Note</h3>

<p>If <code>mu</code> is not 0, the effect size represents the difference between the
first <em>shifted sample</em> (by <code>mu</code>) and the second sample.
</p>


<h3>References</h3>


<ul>
<li><p> Cohen, J. (1977). Statistical power analysis for the behavioral sciences.
New York: Routledge.
</p>
</li>
<li><p> Reiser, B., &amp; Faraggi, D. (1999). Confidence intervals for the overlapping
coefficient: the normal equal variance case. Journal of the Royal Statistical
Society, 48(3), 413-418.
</p>
</li>
<li><p> Ruscio, J. (2008). A probability-based measure of effect size: robustness
to base rates and other factors. Psychological methods, 13(1), 19â30.
</p>
</li>
<li><p> Vargha, A., &amp; Delaney, H. D. (2000). A critique and improvement of the CL
common language effect size statistics of McGraw and Wong. Journal of
Educational and Behavioral Statistics, 25(2), 101-132.
</p>
</li>
<li><p> OâBrien, R. G., &amp; Castelloe, J. (2006, March). Exploiting the link between
the Wilcoxon-Mann-Whitney test and a simple odds statistic.
In Proceedings of the Thirty-first Annual SAS Users Group International
Conference (pp. 209-31). Cary, NC: SAS Institute.
</p>
</li>
<li><p> Agresti, A. (1980). Generalized odds ratios for ordinal data.
Biometrics, 59-67.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+sd_pooled">sd_pooled()</a></code>
</p>
<p>Other standardized differences: 
<code><a href="#topic+cohens_d">cohens_d</a>()</code>,
<code><a href="#topic+mahalanobis_d">mahalanobis_d</a>()</code>,
<code><a href="#topic+means_ratio">means_ratio</a>()</code>,
<code><a href="#topic+rank_biserial">rank_biserial</a>()</code>,
<code><a href="#topic+repeated_measures_d">repeated_measures_d</a>()</code>
</p>
<p>Other rank-based effect sizes: 
<code><a href="#topic+rank_biserial">rank_biserial</a>()</code>,
<code><a href="#topic+rank_epsilon_squared">rank_epsilon_squared</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cohens_u2(mpg ~ am, data = mtcars)

p_superiority(mpg ~ am, data = mtcars, parametric = FALSE)

wmw_odds(mpg ~ am, data = mtcars)

x &lt;- c(1.83, 0.5, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.3)
y &lt;- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)

p_overlap(x, y)
p_overlap(y, x) # direction of effect does not matter

cohens_u3(x, y)
cohens_u3(y, x) # direction of effect does matter

</code></pre>

<hr>
<h2 id='phi'><code class="reqn">\phi</code> and Other Contingency Tables Correlations</h2><span id='topic+phi'></span><span id='topic+cramers_v'></span><span id='topic+tschuprows_t'></span><span id='topic+cohens_w'></span><span id='topic+fei'></span><span id='topic+pearsons_c'></span>

<h3>Description</h3>

<p>Compute phi (<code class="reqn">\phi</code>), Cramer's <em>V</em>, Tschuprow's <em>T</em>, Cohen's <em>w</em>,
×¤ (Fei), Pearson's contingency coefficient for
contingency tables or goodness-of-fit. Pair with any reported
<code><a href="stats.html#topic+chisq.test">stats::chisq.test()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phi(x, y = NULL, adjust = TRUE, ci = 0.95, alternative = "greater", ...)

cramers_v(x, y = NULL, adjust = TRUE, ci = 0.95, alternative = "greater", ...)

tschuprows_t(
  x,
  y = NULL,
  adjust = TRUE,
  ci = 0.95,
  alternative = "greater",
  ...
)

cohens_w(
  x,
  y = NULL,
  p = rep(1, length(x)),
  ci = 0.95,
  alternative = "greater",
  ...
)

fei(x, p = rep(1, length(x)), ci = 0.95, alternative = "greater", ...)

pearsons_c(
  x,
  y = NULL,
  p = rep(1, length(x)),
  ci = 0.95,
  alternative = "greater",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phi_+3A_x">x</code></td>
<td>
<p>a numeric vector or matrix. <code>x</code> and <code>y</code> can also
both be factors.</p>
</td></tr>
<tr><td><code id="phi_+3A_y">y</code></td>
<td>
<p>a numeric vector; ignored if <code>x</code> is a matrix.  If
<code>x</code> is a factor, <code>y</code> should be a factor of the same length.</p>
</td></tr>
<tr><td><code id="phi_+3A_adjust">adjust</code></td>
<td>
<p>Should the effect size be corrected for small-sample bias?
Defaults to <code>TRUE</code>; Advisable for small samples and large tables.</p>
</td></tr>
<tr><td><code id="phi_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="phi_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"greater"</code> (default) or <code>"less"</code>
(one-sided CI), or <code>"two.sided"</code> (two-sided CI). Partial matching is
allowed (e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in
<a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="phi_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="phi_+3A_p">p</code></td>
<td>
<p>a vector of probabilities of the same length as <code>x</code>.
An error is given if any entry of <code>p</code> is negative.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>phi (<code class="reqn">\phi</code>), Cramer's <em>V</em>, Tschuprow's <em>T</em>, Cohen's <em>w</em>, and Pearson's
<em>C</em> are effect sizes for tests of independence in 2D contingency tables. For
2-by-2 tables, phi, Cramer's <em>V</em>, Tschuprow's <em>T</em>, and Cohen's <em>w</em> are
identical, and are equal to the simple correlation between two dichotomous
variables, ranging between  0 (no dependence) and 1 (perfect dependence).
<br /><br />
For larger tables, Cramer's <em>V</em>, Tschuprow's <em>T</em> or Pearson's <em>C</em> should be
used, as they are bounded between 0-1. (Cohen's <em>w</em> can also be used, but
since it is not bounded at 1 (can be larger) its interpretation is more
difficult.) For square table, Cramer's <em>V</em> and Tschuprow's <em>T</em> give the same
results, but for non-square tables Tschuprow's <em>T</em> is more conservative:
while <em>V</em> will be 1 if either columns are fully dependent on rows (for each
column, there is only one non-0 cell) <em>or</em> rows are fully dependent on
columns, <em>T</em> will only be 1 if both are true.
<br /> <br />
For goodness-of-fit in 1D tables Cohen's <em>W</em>, ×¤ (Fei)
or Pearson's <em>C</em> can be used. Cohen's <em>w</em> has no upper bound (can be
arbitrarily large, depending on the expected distribution). <em>Fei</em> is an
adjusted Cohen's <em>w</em>, accounting for the expected distribution, making it
bounded between 0-1 (Ben-Shachar et al, 2023). Pearson's <em>C</em> is also bounded
between 0-1.
<br /> <br />
To summarize, for correlation-like effect sizes, we recommend:
</p>

<ul>
<li><p> For a 2x2 table, use <code>phi()</code>
</p>
</li>
<li><p> For larger tables, use <code>cramers_v()</code>
</p>
</li>
<li><p> For goodness-of-fit, use <code>fei()</code>
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame with the effect size (<code>Cramers_v</code>, <code>phi</code> (possibly with
the suffix <code style="white-space: pre;">&#8288;_adjusted&#8288;</code>), <code>Cohens_w</code>, <code>Fei</code>) and its CIs (<code>CI_low</code> and
<code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="#topic+effectsize_CIs">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Ben-Shachar, M.S., Patil, I., ThÃ©riault, R., Wiernik, B.M., LÃ¼decke, D.
(2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the
ChiâSquared Statistic. Mathematics, 11, 1982. <a href="https://doi.org/10.3390/math11091982">doi:10.3390/math11091982</a>
</p>
</li>
<li><p> Johnston, J. E., Berry, K. J., &amp; Mielke Jr, P. W. (2006). Measures of
effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
Perceptual and motor skills, 103(2), 412-414.
</p>
</li>
<li><p> Rosenberg, M. S. (2010). A generalized formula for converting chi-square
tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+chisq_to_phi">chisq_to_phi()</a></code> for details regarding estimation and CIs.
</p>
<p>Other effect sizes for contingency table: 
<code><a href="#topic+cohens_g">cohens_g</a>()</code>,
<code><a href="#topic+oddsratio">oddsratio</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 2-by-2 tables
## -------------
data("RCT_table")
RCT_table # note groups are COLUMNS

phi(RCT_table)
pearsons_c(RCT_table)



## Larger tables
## -------------
data("Music_preferences")
Music_preferences

cramers_v(Music_preferences)

cohens_w(Music_preferences)

pearsons_c(Music_preferences)



## Goodness of fit
## ---------------
data("Smoking_FASD")
Smoking_FASD

fei(Smoking_FASD)

cohens_w(Smoking_FASD)

pearsons_c(Smoking_FASD)

# Use custom expected values:
fei(Smoking_FASD, p = c(0.015, 0.010, 0.975))

cohens_w(Smoking_FASD, p = c(0.015, 0.010, 0.975))

pearsons_c(Smoking_FASD, p = c(0.015, 0.010, 0.975))

</code></pre>

<hr>
<h2 id='plot.effectsize_table'>Methods for <code>{effectsize}</code> Tables</h2><span id='topic+plot.effectsize_table'></span><span id='topic+print.effectsize_table'></span><span id='topic+print_md.effectsize_table'></span><span id='topic+print_html.effectsize_table'></span><span id='topic+format.effectsize_table'></span><span id='topic+print.effectsize_difference'></span>

<h3>Description</h3>

<p>Printing, formatting and plotting methods for <code>effectsize</code> tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'effectsize_table'
plot(x, ...)

## S3 method for class 'effectsize_table'
print(x, digits = 2, use_symbols = getOption("es.use_symbols", FALSE), ...)

## S3 method for class 'effectsize_table'
print_md(x, digits = 2, use_symbols = getOption("es.use_symbols", FALSE), ...)

## S3 method for class 'effectsize_table'
print_html(
  x,
  digits = 2,
  use_symbols = getOption("es.use_symbols", FALSE),
  ...
)

## S3 method for class 'effectsize_table'
format(
  x,
  digits = 2,
  output = c("text", "markdown", "html"),
  use_symbols = getOption("es.use_symbols", FALSE),
  ...
)

## S3 method for class 'effectsize_difference'
print(x, digits = 2, append_CLES = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.effectsize_table_+3A_x">x</code></td>
<td>
<p>Object to print.</p>
</td></tr>
<tr><td><code id="plot.effectsize_table_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other functions.</p>
</td></tr>
<tr><td><code id="plot.effectsize_table_+3A_digits">digits</code></td>
<td>
<p>Number of digits for rounding or significant figures. May also
be <code>"signif"</code> to return significant figures or <code>"scientific"</code>
to return scientific notation. Control the number of digits by adding the
value as suffix, e.g. <code>digits = "scientific4"</code> to have scientific
notation with 4 decimal places, or <code>digits = "signif5"</code> for 5
significant figures (see also <code><a href="base.html#topic+signif">signif()</a></code>).</p>
</td></tr>
<tr><td><code id="plot.effectsize_table_+3A_use_symbols">use_symbols</code></td>
<td>
<p>Should proper symbols be printed (<code>TRUE</code>) instead of
transliterated effect size names (<code>FALSE</code>). See <a href="#topic+effectsize_options">effectsize_options</a>.</p>
</td></tr>
<tr><td><code id="plot.effectsize_table_+3A_output">output</code></td>
<td>
<p>Which output is the formatting intended for? Affects how title
and footers are formatted.</p>
</td></tr>
<tr><td><code id="plot.effectsize_table_+3A_append_cles">append_CLES</code></td>
<td>
<p>Which Common Language Effect Sizes should be printed as
well? Only applicable to Cohen's <em>d</em>, Hedges' <em>g</em> for independent samples
of equal variance (pooled sd) or for the rank-biserial correlation for
independent samples (See <a href="#topic+d_to_cles">d_to_cles</a>).</p>
</td></tr>
</table>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>See Also</h3>

<p><code><a href="insight.html#topic+display">insight::display()</a></code>
</p>

<hr>
<h2 id='r2_semipartial'>Semi-Partial (Part) Correlation Squared (<code class="reqn">\Delta R^2</code>)</h2><span id='topic+r2_semipartial'></span><span id='topic+r2_delta'></span><span id='topic+r2_part'></span>

<h3>Description</h3>

<p>Compute the semi-partial (part) correlation squared (also known as
<code class="reqn">\Delta R^2</code>). Currently, only <code>lm()</code> models are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r2_semipartial(
  model,
  type = c("terms", "parameters"),
  ci = 0.95,
  alternative = "greater",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r2_semipartial_+3A_model">model</code></td>
<td>
<p>An <code>lm</code> model.</p>
</td></tr>
<tr><td><code id="r2_semipartial_+3A_type">type</code></td>
<td>
<p>Type, either <code>"terms"</code>, or <code>"parameters"</code>.</p>
</td></tr>
<tr><td><code id="r2_semipartial_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="r2_semipartial_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"greater"</code> (default) or <code>"less"</code>
(one-sided CI), or <code>"two.sided"</code> (two-sided CI). Partial matching is
allowed (e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in
<a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="r2_semipartial_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is similar to the last column of the &quot;Conditional Dominance Statistics&quot;
section of the <code><a href="parameters.html#topic+dominance_analysis">parameters::dominance_analysis()</a></code> output. For each term, the
model is refit <em>without</em> the columns on the <a href="stats.html#topic+model.matrix">model matrix</a> that correspond to that term. The <code class="reqn">R^2</code> of
this <em>sub</em>-model is then subtracted from the <code class="reqn">R^2</code> of the <em>full</em> model to
yield the <code class="reqn">\Delta R^2</code>. (For <code>type = "parameters"</code>, this is done for each
column in the model matrix.)
</p>
<p><strong>Note</strong> that this is unlike <code><a href="parameters.html#topic+dominance_analysis">parameters::dominance_analysis()</a></code>, where term
deletion is done via the formula interface, and therefore may lead to
different results.
</p>
<p>For other, non-<code>lm()</code> models, as well as more verbose information and
options, please see the documentation for <code><a href="parameters.html#topic+dominance_analysis">parameters::dominance_analysis()</a></code>.
</p>


<h3>Value</h3>

<p>A data frame with the effect size.
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Confidence intervals are based on the normal approximation as provided by Alf
and Graf (1999). An adjustment to the lower bound of the CI is used, to
improve the coverage properties of the CIs, according to Algina et al (2008):
If the <em>F</em> test associated with the <code class="reqn">sr^2</code> is significant (at <code>1-ci</code>
level), but the lower bound of the CI is 0, it is set to a small value
(arbitrarily to a 10th of the estimated <code class="reqn">sr^2</code>); if the <em>F</em> test is not
significant, the lower bound is set to 0. (Additionally, lower and upper
bound are &quot;fixed&quot; so that they cannot be smaller than 0 or larger than 1.)
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Alf Jr, E. F., &amp; Graf, R. G. (1999). Asymptotic confidence limits for the
difference between two squared multiple correlations: A simplified approach.
<em>Psychological Methods, 4</em>(1), 70-75. <a href="https://doi.org/10.1037/1082-989X.4.1.70">doi:10.1037/1082-989X.4.1.70</a>
</p>
</li>
<li><p> Algina, J., Keselman, H. J., &amp; Penfield, R. D. (2008). Confidence intervals
for the squared multiple semipartial correlation coefficient. <em>Journal of
Modern Applied Statistical Methods, 7</em>(1), 2-10. <a href="https://doi.org/10.22237/jmasm/1209614460">doi:10.22237/jmasm/1209614460</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+eta_squared">eta_squared()</a></code>, <code><a href="#topic+cohens_f">cohens_f()</a></code> for comparing two models,
<code><a href="parameters.html#topic+dominance_analysis">parameters::dominance_analysis()</a></code> and
<code><a href="parameters.html#topic+standardize_parameters">parameters::standardize_parameters()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hardlyworking")

m &lt;- lm(salary ~ factor(n_comps) + xtra_hours * seniority, data = hardlyworking)

r2_semipartial(m)

r2_semipartial(m, type = "parameters")



# Compare to `eta_squared()`
# --------------------------
npk.aov &lt;- lm(yield ~ N + P + K, npk)

# When predictors are orthogonal,
# eta_squared(partial = FALSE) gives the same effect size:
performance::check_collinearity(npk.aov)

eta_squared(npk.aov, partial = FALSE)

r2_semipartial(npk.aov)


# Compare to `dominance_analysis()`
# ---------------------------------
m_full &lt;- lm(salary ~ ., data = hardlyworking)

r2_semipartial(m_full)

# Compare to last column of "Conditional Dominance Statistics":
parameters::dominance_analysis(m_full)

</code></pre>

<hr>
<h2 id='rank_biserial'>Dominance Effect Sizes for Rank Based Differences</h2><span id='topic+rank_biserial'></span><span id='topic+cliffs_delta'></span>

<h3>Description</h3>

<p>Compute the rank-biserial correlation (<code class="reqn">r_{rb}</code>) and Cliff's <em>delta</em>
(<code class="reqn">\delta</code>) effect sizes for non-parametric
(rank sum) differences. These effect sizes of dominance are closely related
to the <a href="#topic+cohens_u3">Common Language Effect Sizes</a>. Pair with any reported
<code><a href="stats.html#topic+wilcox.test">stats::wilcox.test()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rank_biserial(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  paired = FALSE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)

cliffs_delta(
  x,
  y = NULL,
  data = NULL,
  mu = 0,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rank_biserial_+3A_x">x</code>, <code id="rank_biserial_+3A_y">y</code></td>
<td>
<p>A numeric or ordered vector, or a character name of one in <code>data</code>.
Any missing values (<code>NA</code>s) are dropped from the resulting vector. <code>x</code> can
also be a formula (see <code><a href="stats.html#topic+wilcox.test">stats::wilcox.test()</a></code>), in which case <code>y</code> is
ignored.</p>
</td></tr>
<tr><td><code id="rank_biserial_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables.</p>
</td></tr>
<tr><td><code id="rank_biserial_+3A_mu">mu</code></td>
<td>
<p>a number indicating the value around which (a-)symmetry (for
one-sample or paired samples) or shift (for independent samples) is to be
estimated. See <a href="stats.html#topic+wilcox.test">stats::wilcox.test</a>.</p>
</td></tr>
<tr><td><code id="rank_biserial_+3A_paired">paired</code></td>
<td>
<p>If <code>TRUE</code>, the values of <code>x</code> and <code>y</code> are considered as paired.
This produces an effect size that is equivalent to the one-sample effect
size on <code>x - y</code>.</p>
</td></tr>
<tr><td><code id="rank_biserial_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="rank_biserial_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="rank_biserial_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="rank_biserial_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. When <code>x</code> is a formula,
these can be <code>subset</code> and <code>na.action</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rank-biserial correlation is appropriate for non-parametric tests of
differences - both for the one sample or paired samples case, that would
normally be tested with Wilcoxon's Signed Rank Test (giving the
<strong>matched-pairs</strong> rank-biserial correlation) and for two independent samples
case, that would normally be tested with Mann-Whitney's <em>U</em> Test (giving
<strong>Glass'</strong> rank-biserial correlation). See <a href="stats.html#topic+wilcox.test">stats::wilcox.test</a>. In both
cases, the correlation represents the difference between the proportion of
favorable and unfavorable pairs / signed ranks (Kerby, 2014). Values range
from <code>-1</code> complete dominance of the second sample (<em>all</em> values of the second
sample are larger than <em>all</em> the values of the first sample) to <code>+1</code> complete
dominance of the fist sample (<em>all</em> values of the second sample are smaller
than <em>all</em> the values of the first sample).
<br /><br />
Cliff's <em>delta</em> is an alias to the rank-biserial correlation in the two sample case.
</p>


<h3>Value</h3>

<p>A data frame with the effect size <code>r_rank_biserial</code> and its CI
(<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Ties</h3>

<p>When tied values occur, they are each given the average of the ranks that
would have been given had no ties occurred. This results in an effect size of
reduced magnitude. A correction has been applied for Kendall's <em>W</em>.
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Confidence intervals for the rank-biserial correlation (and Cliff's <em>delta</em>)
are estimated using the normal approximation (via Fisher's transformation).
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Cureton, E. E. (1956). Rank-biserial correlation. Psychometrika, 21(3),
287-290.
</p>
</li>
<li><p> Glass, G. V. (1965). A ranking variable analogue of biserial correlation:
Implications for short-cut item analysis. Journal of Educational Measurement,
2(1), 91-95.
</p>
</li>
<li><p> Kerby, D. S. (2014). The simple difference formula: An approach to teaching
nonparametric correlation. Comprehensive Psychology, 3, 11-IT.
</p>
</li>
<li><p> King, B. M., &amp; Minium, E. W. (2008). Statistical reasoning in the
behavioral sciences. John Wiley &amp; Sons Inc.
</p>
</li>
<li><p> Cliff, N. (1993). Dominance statistics: Ordinal analyses to answer ordinal
questions. Psychological bulletin, 114(3), 494.
</p>
</li>
<li><p> Tomczak, M., &amp; Tomczak, E. (2014). The need to report effect size estimates
revisited. An overview of some recommended measures of effect size.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other standardized differences: 
<code><a href="#topic+cohens_d">cohens_d</a>()</code>,
<code><a href="#topic+mahalanobis_d">mahalanobis_d</a>()</code>,
<code><a href="#topic+means_ratio">means_ratio</a>()</code>,
<code><a href="#topic+p_superiority">p_superiority</a>()</code>,
<code><a href="#topic+repeated_measures_d">repeated_measures_d</a>()</code>
</p>
<p>Other rank-based effect sizes: 
<code><a href="#topic+p_superiority">p_superiority</a>()</code>,
<code><a href="#topic+rank_epsilon_squared">rank_epsilon_squared</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mtcars)
mtcars$am &lt;- factor(mtcars$am)
mtcars$cyl &lt;- factor(mtcars$cyl)

# Two Independent Samples ----------
(rb &lt;- rank_biserial(mpg ~ am, data = mtcars))
# Same as:
# rank_biserial("mpg", "am", data = mtcars)
# rank_biserial(mtcars$mpg[mtcars$am=="0"], mtcars$mpg[mtcars$am=="1"])
# cliffs_delta(mpg ~ am, data = mtcars)

# More options:
rank_biserial(mpg ~ am, data = mtcars, mu = -5)
print(rb, append_CLES = TRUE)


# One Sample ----------
# from help("wilcox.test")
x &lt;- c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
y &lt;- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
depression &lt;- data.frame(first = x, second = y, change = y - x)

rank_biserial(change ~ 1, data = depression)

# same as:
# rank_biserial("change", data = depression)
# rank_biserial(mtcars$wt)

# More options:
rank_biserial(change ~ 1, data = depression, mu = -0.5)


# Paired Samples ----------
(rb &lt;- rank_biserial(Pair(first, second) ~ 1, data = depression))

# same as:
# rank_biserial(depression$first, depression$second, paired = TRUE)

interpret_rank_biserial(0.78)
interpret(rb, rules = "funder2019")


</code></pre>

<hr>
<h2 id='rank_epsilon_squared'>Effect Size for Rank Based ANOVA</h2><span id='topic+rank_epsilon_squared'></span><span id='topic+rank_eta_squared'></span><span id='topic+kendalls_w'></span>

<h3>Description</h3>

<p>Compute rank epsilon squared (<code class="reqn">E^2_R</code>) or rank eta squared
(<code class="reqn">\eta^2_H</code>) (to accompany <code><a href="stats.html#topic+kruskal.test">stats::kruskal.test()</a></code>), and Kendall's <em>W</em>
(to accompany <code><a href="stats.html#topic+friedman.test">stats::friedman.test()</a></code>) effect sizes for non-parametric (rank
sum) one-way ANOVAs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rank_epsilon_squared(
  x,
  groups,
  data = NULL,
  ci = 0.95,
  alternative = "greater",
  iterations = 200,
  verbose = TRUE,
  ...
)

rank_eta_squared(
  x,
  groups,
  data = NULL,
  ci = 0.95,
  alternative = "greater",
  iterations = 200,
  verbose = TRUE,
  ...
)

kendalls_w(
  x,
  groups,
  blocks,
  data = NULL,
  blocks_on_rows = TRUE,
  ci = 0.95,
  alternative = "greater",
  iterations = 200,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rank_epsilon_squared_+3A_x">x</code></td>
<td>
<p>Can be one of:
</p>

<ul>
<li><p> A numeric or ordered vector, or a character name of one in <code>data</code>.
</p>
</li>
<li><p> A list of vectors (for <code>rank_eta/epsilon_squared()</code>).
</p>
</li>
<li><p> A matrix of <code style="white-space: pre;">&#8288;blocks x groups&#8288;</code> (for <code>kendalls_w()</code>) (or <code style="white-space: pre;">&#8288;groups x blocks&#8288;</code>
if <code>blocks_on_rows = FALSE</code>). See details for the <code>blocks</code> and <code>groups</code>
terminology used here.
</p>
</li>
<li><p> A formula in the form of:
</p>

<ul>
<li> <p><code>DV ~ groups</code> for <code>rank_eta/epsilon_squared()</code>.
</p>
</li>
<li> <p><code>DV ~ groups | blocks</code> for <code>kendalls_w()</code> (See details for the
<code>blocks</code> and <code>groups</code> terminology used here).
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="rank_epsilon_squared_+3A_groups">groups</code>, <code id="rank_epsilon_squared_+3A_blocks">blocks</code></td>
<td>
<p>A factor vector giving the group / block for the
corresponding elements of <code>x</code>, or a character name of one in <code>data</code>.
Ignored if <code>x</code> is not a vector.</p>
</td></tr>
<tr><td><code id="rank_epsilon_squared_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables.</p>
</td></tr>
<tr><td><code id="rank_epsilon_squared_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="rank_epsilon_squared_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="rank_epsilon_squared_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates for computing confidence
intervals. Only applies when <code>ci</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="rank_epsilon_squared_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="rank_epsilon_squared_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. When <code>x</code> is a formula,
these can be <code>subset</code> and <code>na.action</code>.</p>
</td></tr>
<tr><td><code id="rank_epsilon_squared_+3A_blocks_on_rows">blocks_on_rows</code></td>
<td>
<p>Are blocks on rows (<code>TRUE</code>) or columns (<code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rank epsilon squared and rank eta squared are appropriate for
non-parametric tests of differences between 2 or more samples (a rank based
ANOVA). See <a href="stats.html#topic+kruskal.test">stats::kruskal.test</a>. Values range from 0 to 1, with larger
values indicating larger differences between groups.
<br /><br />
Kendall's <em>W</em> is appropriate for non-parametric tests of differences between
2 or more dependent samples (a rank based rmANOVA), where each <code>group</code> (e.g.,
experimental condition) was measured for each <code>block</code> (e.g., subject). This
measure is also common as a measure of reliability of the rankings of the
<code>groups</code> between raters (<code>blocks</code>). See <a href="stats.html#topic+friedman.test">stats::friedman.test</a>. Values range
from 0 to 1, with larger values indicating larger differences between groups
/ higher agreement between raters.
</p>


<h3>Value</h3>

<p>A data frame with the effect size and its CI.
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Confidence intervals for <code class="reqn">E^2_R</code>, <code class="reqn">\eta^2_H</code>, and Kendall's <em>W</em> are
estimated using the bootstrap method (using the <code>{boot}</code> package).
</p>


<h3>Ties</h3>

<p>When tied values occur, they are each given the average of the ranks that
would have been given had no ties occurred. This results in an effect size of
reduced magnitude. A correction has been applied for Kendall's <em>W</em>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Bootstrapped CIs</h3>

<p>Some effect sizes are directionless&ndash;they do have a minimum value that would
be interpreted as &quot;no effect&quot;, but they cannot cross it. For example, a null
value of <a href="#topic+kendalls_w">Kendall's W</a> is 0, indicating no difference between
groups, but it can never have a negative value. Same goes for
<a href="#topic+cohens_u2">U2</a> and <a href="#topic+p_overlap">Overlap</a>: the null value of <code class="reqn">U_2</code> is
0.5, but it can never be smaller than 0.5; am <em>Overlap</em> of 1 means &quot;full
overlap&quot; (no difference), but it cannot be larger than 1.
<br /><br />
When bootstrapping CIs for such effect sizes, the bounds of the CIs will
never cross (and often will never cover) the null. Therefore, these CIs
should not be used for statistical inference.
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
</p>
</li>
<li><p> Tomczak, M., &amp; Tomczak, E. (2014). The need to report effect size estimates
revisited. An overview of some recommended measures of effect size. Trends in
sport sciences, 1(21), 19-25.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other rank-based effect sizes: 
<code><a href="#topic+p_superiority">p_superiority</a>()</code>,
<code><a href="#topic+rank_biserial">rank_biserial</a>()</code>
</p>
<p>Other effect sizes for ANOVAs: 
<code><a href="#topic+eta_squared">eta_squared</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Rank Eta/Epsilon Squared
# ========================

rank_eta_squared(mpg ~ cyl, data = mtcars)

rank_epsilon_squared(mpg ~ cyl, data = mtcars)



# Kendall's W
# ===========
dat &lt;- data.frame(
  cond = c("A", "B", "A", "B", "A", "B"),
  ID = c("L", "L", "M", "M", "H", "H"),
  y = c(44.56, 28.22, 24, 28.78, 24.56, 18.78)
)
(W &lt;- kendalls_w(y ~ cond | ID, data = dat, verbose = FALSE))

interpret_kendalls_w(0.11)
interpret(W, rules = "landis1977")


</code></pre>

<hr>
<h2 id='RCT_table'>Fictional Results from a Workers' Randomized Control Trial</h2><span id='topic+RCT_table'></span>

<h3>Description</h3>

<p>Fictional Results from a Workers' Randomized Control Trial
</p>


<h3>Format</h3>

<p>A 2-by-2 table, with a <em>column</em> for each group and a <em>row</em> for the diagnosis.
</p>
<div class="sourceCode r"><pre>data("RCT_table")
RCT_table
#&gt;            Group
#&gt; Diagnosis   Treatment Control
#&gt;   Sick             71      30
#&gt;   Recovered        50     100
</pre></div>


<h3>See Also</h3>

<p>Other effect size datasets: 
<code><a href="#topic+Music_preferences">Music_preferences</a></code>,
<code><a href="#topic+Music_preferences2">Music_preferences2</a></code>,
<code><a href="#topic+Smoking_FASD">Smoking_FASD</a></code>,
<code><a href="#topic+food_class">food_class</a></code>,
<code><a href="#topic+hardlyworking">hardlyworking</a></code>,
<code><a href="#topic+rouder2016">rouder2016</a></code>,
<code><a href="#topic+screening_test">screening_test</a></code>
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+equivalence_test'></span><span id='topic+standardize'></span><span id='topic+standardise'></span><span id='topic+standardize_parameters'></span><span id='topic+standardize_posteriors'></span><span id='topic+standardize_info'></span><span id='topic+display'></span><span id='topic+print_html'></span><span id='topic+print_md'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>bayestestR</dt><dd><p><code><a href="bayestestR.html#topic+equivalence_test">equivalence_test</a></code></p>
</dd>
<dt>datawizard</dt><dd><p><code><a href="datawizard.html#topic+standardize">standardise</a></code>, <code><a href="datawizard.html#topic+standardize">standardize</a></code></p>
</dd>
<dt>insight</dt><dd><p><code><a href="insight.html#topic+display">display</a></code>, <code><a href="insight.html#topic+display">print_html</a></code>, <code><a href="insight.html#topic+display">print_md</a></code></p>
</dd>
<dt>parameters</dt><dd><p><code><a href="parameters.html#topic+standardize_info">standardize_info</a></code>, <code><a href="parameters.html#topic+standardize_parameters">standardize_parameters</a></code>, <code><a href="parameters.html#topic+standardize_parameters">standardize_posteriors</a></code></p>
</dd>
</dl>

<hr>
<h2 id='repeated_measures_d'>Standardized Mean Differences for Repeated Measures</h2><span id='topic+repeated_measures_d'></span><span id='topic+rm_d'></span>

<h3>Description</h3>

<p>Compute effect size indices for standardized mean differences in repeated
measures data. Pair with any reported <code>stats::t.test(paired = TRUE)</code>.
<br /><br />
In a repeated-measures design, the same subjects are measured in multiple
conditions or time points. Unlike the case of independent groups, there are
multiple sources of variation that can be used to standardized the
differences between the means of the conditions / times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repeated_measures_d(
  x,
  y,
  data = NULL,
  mu = 0,
  method = c("rm", "av", "z", "b", "d", "r"),
  adjust = TRUE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)

rm_d(
  x,
  y,
  data = NULL,
  mu = 0,
  method = c("rm", "av", "z", "b", "d", "r"),
  adjust = TRUE,
  ci = 0.95,
  alternative = "two.sided",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="repeated_measures_d_+3A_x">x</code>, <code id="repeated_measures_d_+3A_y">y</code></td>
<td>
<p>Paired numeric vectors, or names of ones in <code>data</code>. <code>x</code> can also
be a formula:
</p>

<ul>
<li> <p><code>Pair(x,y) ~ 1</code> for wide data.
</p>
</li>
<li> <p><code>y ~ condition | id</code> for long data, possibly with repetitions.
</p>
</li></ul>
</td></tr>
<tr><td><code id="repeated_measures_d_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables.</p>
</td></tr>
<tr><td><code id="repeated_measures_d_+3A_mu">mu</code></td>
<td>
<p>a number indicating the true value of the mean (or
difference in means if you are performing a two sample test).</p>
</td></tr>
<tr><td><code id="repeated_measures_d_+3A_method">method</code></td>
<td>
<p>Method of repeated measures standardized differences. See
details.</p>
</td></tr>
<tr><td><code id="repeated_measures_d_+3A_adjust">adjust</code></td>
<td>
<p>Apply Hedges' small-sample bias correction? See <code><a href="#topic+hedges_g">hedges_g()</a></code>.</p>
</td></tr>
<tr><td><code id="repeated_measures_d_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="repeated_measures_d_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="repeated_measures_d_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="repeated_measures_d_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. When <code>x</code> is a formula,
these can be <code>subset</code> and <code>na.action</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the effect size and their CIs (<code>CI_low</code> and
<code>CI_high</code>).
</p>


<h3>Standardized Mean Differences for Repeated Measures</h3>

<p>Unlike <a href="#topic+cohens_d">Cohen's d</a> for independent groups, where standardization
naturally is done by the (pooled) population standard deviation (cf. Glassâs
<code class="reqn">\Delta</code>), when measured across two conditions are dependent, there are
many more options for what error term to standardize by. Additionally, some
options allow for data to be replicated (many measurements per condition per
individual), others require a single observation per condition per individual
(aka, paired data; so replications are aggregated).
</p>
<p>(It should be noted that all of these have awful and confusing notations.)
</p>
<p>Standardize by...
</p>

<ul>
<li> <p><strong>Difference Score Variance: <code class="reqn">d_{z}</code></strong> (<em>Requires paired data</em>) - This
is akin to computing difference scores for each individual and then
computing a one-sample Cohen's <em>d</em> (Cohen, 1988, pp. 48; see examples).
</p>
</li>
<li> <p><strong>Within-Subject Variance: <code class="reqn">d_{rm}</code></strong> (<em>Requires paired data</em>) - Cohen
suggested adjusting <code class="reqn">d_{z}</code> to estimate the &quot;standard&quot; between-subjects
<em>d</em> by a factor of <code class="reqn">\sqrt{2(1-r)}</code>, where <em>r</em> is the Pearson correlation
between the paired measures (Cohen, 1988, pp. 48).
</p>
</li>
<li> <p><strong>Control Variance: <code class="reqn">d_{b}</code> (aka Becker's <em>d</em>)</strong> (<em>Requires paired
data</em>) - Standardized by the variance of the control condition (or in a pre-
post-treatment setting, the pre-treatment condition). This is akin to Glass'
<em>delta</em> (<code><a href="#topic+glass_delta">glass_delta()</a></code>) (Becker, 1988). Note that this is taken here as the
<em>second</em> condition (<code>y</code>).
</p>
</li>
<li> <p><strong>Average Variance: <code class="reqn">d_{av}</code></strong> (<em>Requires paired data</em>) - Instead of
standardizing by the variance in the of the control (or pre) condition,
Cumming suggests standardizing by the average variance of the two paired
conditions (Cumming, 2013, pp. 291).
</p>
</li>
<li> <p><strong>All Variance: Just <code class="reqn">d</code></strong> - This is the same as computing a standard
independent-groups Cohen's <em>d</em> (Cohen, 1988). Note that CIs <em>do</em> account for
the dependence, and so are typically more narrow (see examples).
</p>
</li>
<li> <p><strong>Residual Variance: <code class="reqn">d_{r}</code></strong> (<em>Requires data with replications</em>) -
Divide by the pooled variance after all individual differences have been
partialled out (i.e., the residual/level-1 variance in an ANOVA or MLM
setting). In between-subjects designs where each subject contributes a single
response, this is equivalent to classical Cohenâs d. Priors in the
<code>BayesFactor</code> package are defined on this scale (Rouder et al., 2012).
<br /><br />
Note that for paired data, when the two conditions have equal variance,
<code class="reqn">d_{rm}</code>, <code class="reqn">d_{av}</code>, <code class="reqn">d_{b}</code> are equal to <code class="reqn">d</code>.
</p>
</li></ul>



<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Confidence intervals are estimated using the standard normal parametric
method (see Algina &amp; Keselman, 2003; Becker, 1988; Cooper et al., 2009;
Hedges &amp; Olkin, 1985; Pustejovsky et al., 2014).
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>Note</h3>

<p><code>rm_d()</code> is an alias for <code>repeated_measures_d()</code>.
</p>


<h3>References</h3>


<ul>
<li><p> Algina, J., &amp; Keselman, H. J. (2003). Approximate confidence intervals for
effect sizes. Educational and Psychological Measurement, 63(4), 537-553.
</p>
</li>
<li><p> Becker, B. J. (1988). Synthesizing standardized meanâchange measures.
British Journal of Mathematical and Statistical Psychology, 41(2), 257-278.
</p>
</li>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral
sciences (2nd Ed.). New York: Routledge.
</p>
</li>
<li><p> Cooper, H., Hedges, L., &amp; Valentine, J. (2009). Handbook of research
synthesis and meta-analysis. Russell Sage Foundation, New York.
</p>
</li>
<li><p> Cumming, G. (2013). Understanding the new statistics: Effect sizes,
confidence intervals, and meta-analysis. Routledge.
</p>
</li>
<li><p> Hedges, L. V. &amp; Olkin, I. (1985). Statistical methods for
meta-analysis. Orlando, FL: Academic Press.
</p>
</li>
<li><p> Pustejovsky, J. E., Hedges, L. V., &amp; Shadish, W. R. (2014).
Design-comparable effect sizes in multiple baseline designs: A general
modeling framework. Journal of Educational and Behavioral Statistics, 39(5),
368-393.
</p>
</li>
<li><p> Rouder, J. N., Morey, R. D., Speckman, P. L., &amp; Province, J. M. (2012).
Default Bayes factors for ANOVA designs. Journal of mathematical psychology,
56(5), 356-374.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cohens_d">cohens_d()</a></code>, and <code>lmeInfo::g_mlm()</code> and <code>emmeans::effsize()</code> for
more flexible methods.
</p>
<p>Other standardized differences: 
<code><a href="#topic+cohens_d">cohens_d</a>()</code>,
<code><a href="#topic+mahalanobis_d">mahalanobis_d</a>()</code>,
<code><a href="#topic+means_ratio">means_ratio</a>()</code>,
<code><a href="#topic+p_superiority">p_superiority</a>()</code>,
<code><a href="#topic+rank_biserial">rank_biserial</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Paired data -------

data("sleep")
sleep2 &lt;- reshape(sleep,
  direction = "wide",
  idvar = "ID", timevar = "group"
)

repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2)

# Same as:
# repeated_measures_d(sleep$extra[sleep$group==1],
#                     sleep$extra[sleep$group==2])
# repeated_measures_d(extra ~ group | ID, data = sleep)


# More options:
repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2, mu = -1)
repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2, alternative = "less")

# Other methods
repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2, method = "av")
repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2, method = "b")
repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2, method = "d")
repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2, method = "z", adjust = FALSE)

# d_z is the same as Cohen's d for one sample (of individual difference):
cohens_d(extra.1 - extra.2 ~ 1, data = sleep2)



# Repetition data -----------

data("rouder2016")

# For rm, ad, z, b, data is aggregated
repeated_measures_d(rt ~ cond | id, data = rouder2016)

# same as:
rouder2016_wide &lt;- tapply(rouder2016[["rt"]], rouder2016[1:2], mean)
repeated_measures_d(rouder2016_wide[, 1], rouder2016_wide[, 2])

# For r or d, data is not aggragated:
repeated_measures_d(rt ~ cond | id, data = rouder2016, method = "r")
repeated_measures_d(rt ~ cond | id, data = rouder2016, method = "d", adjust = FALSE)

# d is the same as Cohen's d for two independent groups:
cohens_d(rt ~ cond, data = rouder2016, ci = NULL)

</code></pre>

<hr>
<h2 id='rouder2016'>Jeff Rouder's Example Dataset for Repeated Measures</h2><span id='topic+rouder2016'></span>

<h3>Description</h3>

<p>A dataset &quot;with 25 people each observing 50 trials in 2 conditions&quot;,
published as <code>effectSizePuzzler.txt</code> by Jeff Rouder on March 24, 2016
(<em>http://jeffrouder.blogspot.com/2016/03/the-effect-size-puzzler.html</em>).
<br /><br />
The data is used in examples and tests of <code><a href="#topic+rm_d">rm_d()</a></code>.
</p>


<h3>Format</h3>

<p>A data frame with 2500 rows and 3 variables:
</p>

<dl>
<dt>id</dt><dd><p>participant: 1...25</p>
</dd>
<dt>cond</dt><dd><p>condition: 1,2</p>
</dd>
<dt>rt</dt><dd><p>response time in seconds</p>
</dd>
</dl>

<div class="sourceCode r"><pre>data("rouder2016")
head(rouder2016, n = 5)
#&gt;   id cond    rt
#&gt; 1  1    1 0.560
#&gt; 2  1    1 0.930
#&gt; 3  1    1 0.795
#&gt; 4  1    1 0.615
#&gt; 5  1    1 1.028
</pre></div>


<h3>See Also</h3>

<p>Other effect size datasets: 
<code><a href="#topic+Music_preferences">Music_preferences</a></code>,
<code><a href="#topic+Music_preferences2">Music_preferences2</a></code>,
<code><a href="#topic+RCT_table">RCT_table</a></code>,
<code><a href="#topic+Smoking_FASD">Smoking_FASD</a></code>,
<code><a href="#topic+food_class">food_class</a></code>,
<code><a href="#topic+hardlyworking">hardlyworking</a></code>,
<code><a href="#topic+screening_test">screening_test</a></code>
</p>

<hr>
<h2 id='rules'>Create an Interpretation Grid</h2><span id='topic+rules'></span><span id='topic+is.rules'></span>

<h3>Description</h3>

<p>Create a container for interpretation rules of thumb. Usually used in conjunction with <a href="#topic+interpret">interpret</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rules(values, labels = NULL, name = NULL, right = TRUE)

is.rules(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rules_+3A_values">values</code></td>
<td>
<p>Vector of reference values (edges defining categories or
critical values).</p>
</td></tr>
<tr><td><code id="rules_+3A_labels">labels</code></td>
<td>
<p>Labels associated with each category. If <code>NULL</code>, will try to
infer it from <code>values</code> (if it is a named vector or a list), otherwise, will
return the breakpoints.</p>
</td></tr>
<tr><td><code id="rules_+3A_name">name</code></td>
<td>
<p>Name of the set of rules (will be printed).</p>
</td></tr>
<tr><td><code id="rules_+3A_right">right</code></td>
<td>
<p>logical, for threshold-type rules, indicating if the thresholds
themselves should be included in the interval to the right (lower values)
or in the interval to the left (higher values).</p>
</td></tr>
<tr><td><code id="rules_+3A_x">x</code></td>
<td>
<p>An arbitrary R object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+interpret">interpret()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rules(c(0.05), c("significant", "not significant"), right = FALSE)
rules(c(0.2, 0.5, 0.8), c("small", "medium", "large"))
rules(c("small" = 0.2, "medium" = 0.5), name = "Cohen's Rules")
</code></pre>

<hr>
<h2 id='screening_test'>Results from 2 Screening Tests</h2><span id='topic+screening_test'></span>

<h3>Description</h3>

<p>A sample (simulated) dataset, used in tests and some examples.
</p>


<h3>Format</h3>

<p>A data frame with 1600 rows and 3 variables:
</p>

<dl>
<dt>Diagnosis</dt><dd><p>Ground truth</p>
</dd>
<dt>Test1</dt><dd><p>Results given by the 1st test</p>
</dd>
<dt>Test2</dt><dd><p>Results given by the 2nd test</p>
</dd>
</dl>

<div class="sourceCode r"><pre>data("screening_test")
head(screening_test, n = 5)
#&gt;   Diagnosis Test1 Test2
#&gt; 1       Neg "Neg" "Neg"
#&gt; 2       Neg "Neg" "Neg"
#&gt; 3       Neg "Neg" "Neg"
#&gt; 4       Neg "Neg" "Neg"
#&gt; 5       Neg "Neg" "Neg"
</pre></div>


<h3>See Also</h3>

<p>Other effect size datasets: 
<code><a href="#topic+Music_preferences">Music_preferences</a></code>,
<code><a href="#topic+Music_preferences2">Music_preferences2</a></code>,
<code><a href="#topic+RCT_table">RCT_table</a></code>,
<code><a href="#topic+Smoking_FASD">Smoking_FASD</a></code>,
<code><a href="#topic+food_class">food_class</a></code>,
<code><a href="#topic+hardlyworking">hardlyworking</a></code>,
<code><a href="#topic+rouder2016">rouder2016</a></code>
</p>

<hr>
<h2 id='sd_pooled'>Pooled Indices of (Co)Deviation</h2><span id='topic+sd_pooled'></span><span id='topic+mad_pooled'></span><span id='topic+cov_pooled'></span>

<h3>Description</h3>

<p>The Pooled Standard Deviation is a weighted average of standard deviations
for two or more groups, <em>assumed to have equal variance</em>. It represents the
common deviation among the groups, around each of their respective means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sd_pooled(x, y = NULL, data = NULL, verbose = TRUE, ...)

mad_pooled(x, y = NULL, data = NULL, constant = 1.4826, verbose = TRUE, ...)

cov_pooled(x, y = NULL, data = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sd_pooled_+3A_x">x</code>, <code id="sd_pooled_+3A_y">y</code></td>
<td>
<p>A numeric vector, or a character name of one in <code>data</code>.
Any missing values (<code>NA</code>s) are dropped from the resulting vector.
<code>x</code> can also be a formula (see <code><a href="stats.html#topic+t.test">stats::t.test()</a></code>), in which case <code>y</code> is
ignored.</p>
</td></tr>
<tr><td><code id="sd_pooled_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables.</p>
</td></tr>
<tr><td><code id="sd_pooled_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="sd_pooled_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. When <code>x</code> is a formula,
these can be <code>subset</code> and <code>na.action</code>.</p>
</td></tr>
<tr><td><code id="sd_pooled_+3A_constant">constant</code></td>
<td>
<p>scale factor.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard version is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{\frac{\sum (x_i - \bar{x})^2}{n_1 + n_2 - 2}}</code>
</p>

<p>The robust version is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">1.4826 \times Median(|\left\{x - Median_x,\,y - Median_y\right\}|)</code>
</p>



<h3>Value</h3>

<p>Numeric, the pooled standard deviation. For <code>cov_pooled()</code> a matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cohens_d">cohens_d()</a></code>, <code><a href="#topic+mahalanobis_d">mahalanobis_d()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sd_pooled(mpg ~ am, data = mtcars)
mad_pooled(mtcars$mpg, factor(mtcars$am))

cov_pooled(mpg + hp + cyl ~ am, data = mtcars)

</code></pre>

<hr>
<h2 id='Smoking_FASD'>Frequency of FASD for Smoking Mothers</h2><span id='topic+Smoking_FASD'></span>

<h3>Description</h3>

<p>Fictional data.
</p>


<h3>Format</h3>

<p>A 1-by-3 table, with a <em>column</em> for each diagnosis.
</p>
<div class="sourceCode r"><pre>data("Smoking_FASD")
Smoking_FASD
#&gt;  FAS PFAS   TD 
#&gt;   17   11  640
</pre></div>


<h3>See Also</h3>

<p>Other effect size datasets: 
<code><a href="#topic+Music_preferences">Music_preferences</a></code>,
<code><a href="#topic+Music_preferences2">Music_preferences2</a></code>,
<code><a href="#topic+RCT_table">RCT_table</a></code>,
<code><a href="#topic+food_class">food_class</a></code>,
<code><a href="#topic+hardlyworking">hardlyworking</a></code>,
<code><a href="#topic+rouder2016">rouder2016</a></code>,
<code><a href="#topic+screening_test">screening_test</a></code>
</p>

<hr>
<h2 id='t_to_d'>Convert <em>t</em>, <em>z</em>, and <em>F</em> to Cohen's <em>d</em> or <strong>partial</strong>-<em>r</em></h2><span id='topic+t_to_d'></span><span id='topic+z_to_d'></span><span id='topic+F_to_d'></span><span id='topic+t_to_r'></span><span id='topic+z_to_r'></span><span id='topic+F_to_r'></span>

<h3>Description</h3>

<p>These functions are convenience functions to convert t, z and F test
statistics to Cohen's d and <strong>partial</strong> r. These are useful in cases where
the data required to compute these are not easily available or their
computation is not straightforward (e.g., in liner mixed models, contrasts,
etc.).
<br />
See <a href="https://easystats.github.io/effectsize/articles/from_test_statistics.html">Effect Size from Test Statistics vignette.</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_to_d(t, df_error, paired = FALSE, ci = 0.95, alternative = "two.sided", ...)

z_to_d(z, n, paired = FALSE, ci = 0.95, alternative = "two.sided", ...)

F_to_d(
  f,
  df,
  df_error,
  paired = FALSE,
  ci = 0.95,
  alternative = "two.sided",
  ...
)

t_to_r(t, df_error, ci = 0.95, alternative = "two.sided", ...)

z_to_r(z, n, ci = 0.95, alternative = "two.sided", ...)

F_to_r(f, df, df_error, ci = 0.95, alternative = "two.sided", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="t_to_d_+3A_t">t</code>, <code id="t_to_d_+3A_f">f</code>, <code id="t_to_d_+3A_z">z</code></td>
<td>
<p>The t, the F or the z statistics.</p>
</td></tr>
<tr><td><code id="t_to_d_+3A_paired">paired</code></td>
<td>
<p>Should the estimate account for the t-value being testing the
difference between dependent means?</p>
</td></tr>
<tr><td><code id="t_to_d_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="t_to_d_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in <a href="#topic+effectsize_CIs">effectsize_CIs</a>.</p>
</td></tr>
<tr><td><code id="t_to_d_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="t_to_d_+3A_n">n</code></td>
<td>
<p>The number of observations (the sample size).</p>
</td></tr>
<tr><td><code id="t_to_d_+3A_df">df</code>, <code id="t_to_d_+3A_df_error">df_error</code></td>
<td>
<p>Degrees of freedom of numerator or of the error estimate
(i.e., the residuals).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions use the following formulae to approximate <em>r</em> and <em>d</em>:
<br /><br />
</p>
<p style="text-align: center;"><code class="reqn">r_{partial} = t / \sqrt{t^2 + df_{error}}</code>
</p>

<p><br /><br />
</p>
<p style="text-align: center;"><code class="reqn">r_{partial} = z / \sqrt{z^2 + N}</code>
</p>

<p><br /><br />
</p>
<p style="text-align: center;"><code class="reqn">d = 2 * t / \sqrt{df_{error}}</code>
</p>

<p><br /><br />
</p>
<p style="text-align: center;"><code class="reqn">d_z = t / \sqrt{df_{error}}</code>
</p>

<p><br /><br />
</p>
<p style="text-align: center;"><code class="reqn">d = 2 * z / \sqrt{N}</code>
</p>

<p>The resulting <code>d</code> effect size is an <em>approximation</em> to Cohen's <em>d</em>, and
assumes two equal group sizes. When possible, it is advised to directly
estimate Cohen's <em>d</em>, with <code><a href="#topic+cohens_d">cohens_d()</a></code>, <code>emmeans::eff_size()</code>, or similar
functions.
</p>


<h3>Value</h3>

<p>A data frame with the effect size(s)(<code>r</code> or <code>d</code>), and their CIs
(<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="#topic+effectsize_CIs">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Friedman, H. (1982). Simplified determinations of statistical power,
magnitude of effect and research sample sizes. Educational and Psychological
Measurement, 42(2), 521-526. <a href="https://doi.org/10.1177/001316448204200214">doi:10.1177/001316448204200214</a>
</p>
</li>
<li><p> Wolf, F. M. (1986). Meta-analysis: Quantitative methods for research
synthesis (Vol. 59). Sage.
</p>
</li>
<li><p> Rosenthal, R. (1994) Parametric measures of effect size. In H. Cooper and
L.V. Hedges (Eds.). The handbook of research synthesis. New York: Russell
Sage Foundation.
</p>
</li>
<li><p> Steiger, J. H. (2004). Beyond the F test: Effect size confidence intervals
and tests of close fit in the analysis of variance and contrast analysis.
Psychological Methods, 9, 164-182.
</p>
</li>
<li><p> Cumming, G., &amp; Finch, S. (2001). A primer on the understanding, use, and
calculation of confidence intervals that are based on central and noncentral
distributions. Educational and Psychological Measurement, 61(4), 532-574.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cohens_d">cohens_d()</a></code>
</p>
<p>Other effect size from test statistic: 
<code><a href="#topic+F_to_eta2">F_to_eta2</a>()</code>,
<code><a href="#topic+chisq_to_phi">chisq_to_phi</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## t Tests
res &lt;- t.test(1:10, y = c(7:20), var.equal = TRUE)
t_to_d(t = res$statistic, res$parameter)
t_to_r(t = res$statistic, res$parameter)
t_to_r(t = res$statistic, res$parameter, alternative = "less")

res &lt;- with(sleep, t.test(extra[group == 1], extra[group == 2], paired = TRUE))
t_to_d(t = res$statistic, res$parameter, paired = TRUE)
t_to_r(t = res$statistic, res$parameter)
t_to_r(t = res$statistic, res$parameter, alternative = "greater")


## Linear Regression
model &lt;- lm(rating ~ complaints + critical, data = attitude)
(param_tab &lt;- parameters::model_parameters(model))

(rs &lt;- t_to_r(param_tab$t[2:3], param_tab$df_error[2:3]))

# How does this compare to actual partial correlations?
correlation::correlation(attitude,
  select = "rating",
  select2 = c("complaints", "critical"),
  partial = TRUE
)

</code></pre>

<hr>
<h2 id='w_to_fei'>Convert Between Effect Sizes for Contingency Tables Correlations</h2><span id='topic+w_to_fei'></span><span id='topic+w_to_v'></span><span id='topic+w_to_t'></span><span id='topic+w_to_c'></span><span id='topic+fei_to_w'></span><span id='topic+v_to_w'></span><span id='topic+t_to_w'></span><span id='topic+c_to_w'></span><span id='topic+v_to_t'></span><span id='topic+t_to_v'></span>

<h3>Description</h3>

<p>Enables a conversion between different indices of effect size, such as
Cohen's <em>w</em> to ×¤ (Fei), and Cramer's <em>V</em> to
Tschuprow's <em>T</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_to_fei(w, p)

w_to_v(w, nrow, ncol)

w_to_t(w, nrow, ncol)

w_to_c(w)

fei_to_w(fei, p)

v_to_w(v, nrow, ncol)

t_to_w(t, nrow, ncol)

c_to_w(c)

v_to_t(v, nrow, ncol)

t_to_v(t, nrow, ncol)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="w_to_fei_+3A_w">w</code>, <code id="w_to_fei_+3A_c">c</code>, <code id="w_to_fei_+3A_v">v</code>, <code id="w_to_fei_+3A_t">t</code>, <code id="w_to_fei_+3A_fei">fei</code></td>
<td>
<p>Effect size to be converted</p>
</td></tr>
<tr><td><code id="w_to_fei_+3A_p">p</code></td>
<td>
<p>Vector of expected values. See <code><a href="stats.html#topic+chisq.test">stats::chisq.test()</a></code>.</p>
</td></tr>
<tr><td><code id="w_to_fei_+3A_nrow">nrow</code>, <code id="w_to_fei_+3A_ncol">ncol</code></td>
<td>
<p>The number of rows/columns in the contingency table.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Ben-Shachar, M.S., Patil, I., ThÃ©riault, R., Wiernik, B.M., LÃ¼decke, D.
(2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the
ChiâSquared Statistic. Mathematics, 11, 1982. <a href="https://doi.org/10.3390/math11091982">doi:10.3390/math11091982</a>
</p>
</li>
<li><p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cramers_v">cramers_v()</a></code> <code><a href="#topic+chisq_to_fei">chisq_to_fei()</a></code>
</p>
<p>Other convert between effect sizes: 
<code><a href="#topic+d_to_r">d_to_r</a>()</code>,
<code><a href="#topic+diff_to_cles">diff_to_cles</a></code>,
<code><a href="#topic+eta2_to_f2">eta2_to_f2</a>()</code>,
<code><a href="#topic+odds_to_probs">odds_to_probs</a>()</code>,
<code><a href="#topic+oddsratio_to_riskratio">oddsratio_to_riskratio</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(effectsize)

## 2D tables
## ---------
data("Music_preferences2")
Music_preferences2

cramers_v(Music_preferences2, adjust = FALSE)

v_to_t(0.80, 3, 4)

tschuprows_t(Music_preferences2)



## Goodness of fit
## ---------------
data("Smoking_FASD")
Smoking_FASD

cohens_w(Smoking_FASD, p = c(0.015, 0.010, 0.975))

w_to_fei(0.11, p = c(0.015, 0.010, 0.975))

fei(Smoking_FASD, p = c(0.015, 0.010, 0.975))


## Power analysis
## --------------
# See https://osf.io/cg64s/

p0 &lt;- c(0.35, 0.65)
Fei &lt;- 0.3

pwr::pwr.chisq.test(
  w = fei_to_w(Fei, p = p0),
  df = length(p0) - 1,
  sig.level = 0.01,
  power = 0.85
)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
