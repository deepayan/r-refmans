<!DOCTYPE html><html lang="en"><head><title>Help for package lolR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lolR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lol.classify.nearestCentroid'><p>Nearest Centroid Classifier Training</p></a></li>
<li><a href='#lol.classify.rand'><p>Random Classifier Utility</p></a></li>
<li><a href='#lol.classify.randomChance'><p>Randomly Chance Classifier Training</p></a></li>
<li><a href='#lol.classify.randomGuess'><p>Randomly Guessing Classifier Training</p></a></li>
<li><a href='#lol.embed'><p>Embedding</p></a></li>
<li><a href='#lol.project.bayes_optimal'><p>Bayes Optimal</p></a></li>
<li><a href='#lol.project.dp'><p>Data  Piling</p></a></li>
<li><a href='#lol.project.lol'><p>Linear Optimal Low-Rank Projection (LOL)</p></a></li>
<li><a href='#lol.project.lrcca'><p>Low-rank Canonical Correlation Analysis (LR-CCA)</p></a></li>
<li><a href='#lol.project.lrlda'><p>Low-Rank Linear Discriminant Analysis (LRLDA)</p></a></li>
<li><a href='#lol.project.pca'><p>Principal Component Analysis (PCA)</p></a></li>
<li><a href='#lol.project.pls'><p>Partial Least-Squares (PLS)</p></a></li>
<li><a href='#lol.project.rp'><p>Random Projections (RP)</p></a></li>
<li><a href='#lol.sims.cigar'><p>Stacked Cigar</p></a></li>
<li><a href='#lol.sims.cross'><p>Cross</p></a></li>
<li><a href='#lol.sims.fat_tails'><p>Fat Tails Simulation</p></a></li>
<li><a href='#lol.sims.mean_diff'><p>Mean Difference Simulation</p></a></li>
<li><a href='#lol.sims.qdtoep'><p>Quadratic Discriminant Toeplitz Simulation</p></a></li>
<li><a href='#lol.sims.random_rotate'><p>Random Rotation</p></a></li>
<li><a href='#lol.sims.rev_rtrunk'><p>Reverse Random Trunk</p></a></li>
<li><a href='#lol.sims.rotation'><p>Sample Random Rotation</p></a></li>
<li><a href='#lol.sims.rtrunk'><p>Random Trunk</p></a></li>
<li><a href='#lol.sims.sim_gmm'><p>GMM Simulate</p></a></li>
<li><a href='#lol.sims.toep'><p>Toeplitz Simulation</p></a></li>
<li><a href='#lol.sims.xor2'><p>Xor Problem</p></a></li>
<li><a href='#lol.utils.decomp'><p>A utility to use irlba when necessary</p></a></li>
<li><a href='#lol.utils.deltas'><p>A function that performs a utility computation of information about the differences of the classes.</p></a></li>
<li><a href='#lol.utils.info'><p>A function that performs basic utilities about the data.</p></a></li>
<li><a href='#lol.utils.ohe'><p>A function for one-hot encoding categorical respose vectors.</p></a></li>
<li><a href='#lol.xval.eval'><p>Embedding Cross Validation</p></a></li>
<li><a href='#lol.xval.optimal_dimselect'><p>Optimal Cross-Validated Number of Embedding Dimensions</p></a></li>
<li><a href='#lol.xval.split'><p>Cross-Validation Data Splitter</p></a></li>
<li><a href='#predict.nearestCentroid'><p>Nearest Centroid Classifier Prediction</p></a></li>
<li><a href='#predict.randomChance'><p>Randomly Chance Classifier Prediction</p></a></li>
<li><a href='#predict.randomGuess'><p>Randomly Guessing Classifier Prediction</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Linear Optimal Low-Rank Projection</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-06-20</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Eric Bridgeford &lt;ericwb95@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Supervised learning techniques designed for the situation when the dimensionality exceeds the sample size have a tendency to overfit as the dimensionality of the data increases. To remedy this High dimensionality; low sample size (HDLSS) situation, we attempt to learn a lower-dimensional representation of the data before learning a classifier. That is, we project the data to a situation where the dimensionality is more manageable, and then are able to better apply standard classification or clustering techniques since we will have fewer dimensions to overfit. A number of previous works have focused on how to strategically reduce dimensionality in the unsupervised case, yet in the supervised HDLSS regime, few works have attempted to devise dimensionality reduction techniques that leverage the labels associated with the data. In this package and the associated manuscript Vogelstein et al. (2017) &lt;<a href="https://doi.org/10.48550/arXiv.1709.01233">doi:10.48550/arXiv.1709.01233</a>&gt;, we provide several methods for feature extraction, some utilizing labels and some not, along with easily extensible utilities to simplify cross-validative efforts to identify the best feature extraction method. Additionally, we include a series of adaptable benchmark simulations to serve as a standard for future investigative efforts into supervised HDLSS. Finally, we produce a comprehensive comparison of the included algorithms across a range of benchmark simulations and real data applications.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/neurodata/lol">https://github.com/neurodata/lol</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, abind, MASS, irlba, pls, robust, robustbase</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, parallel, randomForest, latex2exp,
testthat, covr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-06-25 18:56:31 UTC; eric</td>
</tr>
<tr>
<td>Author:</td>
<td>Eric Bridgeford [aut, cre],
  Minh Tang [ctb],
  Jason Yim [ctb],
  Joshua Vogelstein [ths]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-06-26 22:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='lol.classify.nearestCentroid'>Nearest Centroid Classifier Training</h2><span id='topic+lol.classify.nearestCentroid'></span>

<h3>Description</h3>

<p>A function that trains a classifier based on the nearest centroid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.classify.nearestCentroid(X, Y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.classify.nearestCentroid_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.classify.nearestCentroid_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the <code>n</code> samples.</p>
</td></tr>
<tr><td><code id="lol.classify.nearestCentroid_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>nearestCentroid</code>, with the following attributes:
</p>
<table role = "presentation">
<tr><td><code>centroids</code></td>
<td>
<p><code>[K, d]</code> the centroids of each class with <code>K</code>  classes in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> the ylabels for each of the <code>K</code> unique classes, ordered.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("centroid", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.classify.nearestCentroid(X, Y)
</code></pre>

<hr>
<h2 id='lol.classify.rand'>Random Classifier Utility</h2><span id='topic+lol.classify.rand'></span>

<h3>Description</h3>

<p>A function for random classifiers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.classify.rand(X, Y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.classify.rand_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.classify.rand_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the <code>n</code> samples.</p>
</td></tr>
<tr><td><code id="lol.classify.rand_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A structure, with the following attributes:
</p>
<table role = "presentation">
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> the ylabels for each of the <code>K</code> unique classes, ordered.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>

<hr>
<h2 id='lol.classify.randomChance'>Randomly Chance Classifier Training</h2><span id='topic+lol.classify.randomChance'></span>

<h3>Description</h3>

<p>A function that predicts the maximally present class in the dataset. Functionality consistent
with the standard R prediction interface so that one can compute the &quot;chance&quot; accuracy
with minimal modification of other classification scripts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.classify.randomChance(X, Y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.classify.randomChance_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.classify.randomChance_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the <code>n</code> samples.</p>
</td></tr>
<tr><td><code id="lol.classify.randomChance_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>randomGuess</code>, with the following attributes:
</p>
<table role = "presentation">
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> the ylabels for each of the <code>K</code> unique classes, ordered.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.classify.randomChance(X, Y)
</code></pre>

<hr>
<h2 id='lol.classify.randomGuess'>Randomly Guessing Classifier Training</h2><span id='topic+lol.classify.randomGuess'></span>

<h3>Description</h3>

<p>A function that predicts by randomly guessing based on the pmf of the class priors. Functionality consistent
with the standard R prediction interface so that one can compute the &quot;guess&quot; accuracy
with minimal modification of other classification scripts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.classify.randomGuess(X, Y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.classify.randomGuess_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.classify.randomGuess_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the <code>n</code> samples.</p>
</td></tr>
<tr><td><code id="lol.classify.randomGuess_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>randomGuess</code>, with the following attributes:
</p>
<table role = "presentation">
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> the ylabels for each of the <code>K</code> unique classes, ordered.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.classify.randomGuess(X, Y)
</code></pre>

<hr>
<h2 id='lol.embed'>Embedding</h2><span id='topic+lol.embed'></span>

<h3>Description</h3>

<p>A function that embeds points in high dimensions to a lower dimensionality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.embed(X, A, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.embed_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.embed_+3A_a">A</code></td>
<td>
<p><code>[d, r]</code> the embedding matrix from <code>d</code> to <code>r</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.embed_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an array <code>[n, r]</code> the original <code>n</code> points embedded into <code>r</code> dimensions.
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.project.lol(X=X, Y=Y, r=5)  # use lol to project into 5 dimensions
Xr &lt;- lol.embed(X, model$A)
</code></pre>

<hr>
<h2 id='lol.project.bayes_optimal'>Bayes Optimal</h2><span id='topic+lol.project.bayes_optimal'></span>

<h3>Description</h3>

<p>A function for recovering the Bayes Optimal Projection, which optimizes Bayes classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.project.bayes_optimal(X, Y, mus, Sigmas, priors, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.project.bayes_optimal_+3A_x">X</code></td>
<td>
<p><code>[n, p]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.bayes_optimal_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the samples with <code>K</code> unique labels.</p>
</td></tr>
<tr><td><code id="lol.project.bayes_optimal_+3A_mus">mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.bayes_optimal_+3A_sigmas">Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.bayes_optimal_+3A_priors">priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code id="lol.project.bayes_optimal_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>embedding</code> containing the following:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p><code>[d, K]</code> the projection matrix from <code>d</code> to <code>K</code> dimensions.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>the eigen values associated with the eigendecomposition.</p>
</td></tr>
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> unique, ordered class labels.</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p><code>[K, d]</code> centroid matrix of the <code>K</code> unique, ordered classes in native <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> prior probabilities for the unique, ordered classes.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p><code>[n, K]</code> the <code>n</code> data points in reduced dimensionality <code>K</code>.</p>
</td></tr>
<tr><td><code>cr</code></td>
<td>
<p><code>[K, K]</code> the <code>K</code> centroids in reduced dimensionality <code>K</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
# obtain bayes-optimal projection of the data
model &lt;- lol.project.bayes_optimal(X=X, Y=Y, mus=data$mus,
                                   S=data$Sigmas, priors=data$priors)
</code></pre>

<hr>
<h2 id='lol.project.dp'>Data  Piling</h2><span id='topic+lol.project.dp'></span>

<h3>Description</h3>

<p>A function for implementing the Maximal Data Piling (MDP) Algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.project.dp(X, Y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.project.dp_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.dp_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the samples with <code>K</code> unique labels.</p>
</td></tr>
<tr><td><code id="lol.project.dp_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p><code>[d, r]</code> the projection matrix from <code>d</code> to <code>r</code> dimensions.</p>
</td></tr>
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> unique, ordered class labels.</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p><code>[K, d]</code> centroid matrix of the <code>K</code> unique, ordered classes in native <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> prior probabilities for the unique, ordered classes.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p><code>[n, r]</code> the <code>n</code> data points in reduced dimensionality <code>r</code>.</p>
</td></tr>
<tr><td><code>cr</code></td>
<td>
<p><code>[K, r]</code> the <code>K</code> centroids in reduced dimensionality <code>r</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("dp", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Minh Tang and Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.project.dp(X=X, Y=Y)  # use mdp to project into maximal data piling
</code></pre>

<hr>
<h2 id='lol.project.lol'>Linear Optimal Low-Rank Projection (LOL)</h2><span id='topic+lol.project.lol'></span>

<h3>Description</h3>

<p>A function for implementing the Linear Optimal Low-Rank Projection (LOL) Algorithm. This algorithm allows users to find an optimal
projection from 'd' to 'r' dimensions, where 'r &lt;&lt; d', by combining information from the first and second moments in thet data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.project.lol(
  X,
  Y,
  r,
  second.moment.xfm = FALSE,
  second.moment.xfm.opts = list(),
  first.moment = "delta",
  second.moment = "linear",
  orthogonalize = FALSE,
  robust = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.project.lol_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the samples with <code>K</code> unique labels.</p>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_r">r</code></td>
<td>
<p>the rank of the projection. Note that <code>r &gt;= K</code>, and <code>r &lt; d</code>.</p>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_second.moment.xfm">second.moment.xfm</code></td>
<td>
<p>whether to use extraneous options in estimation of the second moment component. The transforms specified should be a numbered list of transforms you wish to apply, and will be applied in accordance with <code>second.moment</code>.</p>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_second.moment.xfm.opts">second.moment.xfm.opts</code></td>
<td>
<p>optional arguments to pass to the <code>second.moment.xfm</code> option specified. Should be a numbered list of lists, where <code>second.moment.xfm.opts[[i]]</code> corresponds to the optional arguments for <code>second.moment.xfm[[i]]</code>.
Defaults to the default options for each transform scheme.</p>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_first.moment">first.moment</code></td>
<td>
<p>the function to capture the first moment. Defaults to <code>'delta'</code>.
</p>

<ul>
<li><p><code>'delta'</code> capture the first moment with the hyperplane separating the per-class means.
</p>
</li>
<li><p><code>FALSE</code> do not capture the first moment.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_second.moment">second.moment</code></td>
<td>
<p>the function to capture the second moment. Defaults to <code>'linear'</code>.
</p>

<ul>
<li><p><code>'linear'</code> performs PCA on the class-conditional data to capture the second moment, retaining the vectors with the top singular values.   Transform options for <code>second.moment.xfm</code> and arguments in <code>second.moment.opts</code> should be in accordance with the trailing arguments for <a href="#topic+lol.project.lrlda">lol.project.lrlda</a>.
</p>
</li>
<li><p><code>'quadratic'</code> performs PCA on the data for each class separately to capture the second moment, retaining the vectors with the top singular values from each class's PCA. Transform options for <code>second.moment.xfm</code> and arguments in <code>second.moment.opts</code> should be in accordance with the trailing arguments for <a href="#topic+lol.project.pca">lol.project.pca</a>.
</p>
</li>
<li><p><code>'pls'</code> performs PLS on the data to capture the second moment, retaining the vectors that maximize the correlation between the different classes. Transform options for <code>second.moment.xfm</code> and arguments in <code>second.moment.opts</code> should be in accordance with the trailing arguments for <a href="#topic+lol.project.pls">lol.project.pls</a>.
</p>
</li>
<li><p><code>FALSE</code> do not capture the second moment.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_orthogonalize">orthogonalize</code></td>
<td>
<p>whether to orthogonalize the projection matrix. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_robust">robust</code></td>
<td>
<p>whether to perform PCA on a robust estimate of the covariance matrix or not. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.project.lol_+3A_...">...</code></td>
<td>
<p>trailing args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p><code>[d, r]</code> the projection matrix from <code>d</code> to <code>r</code> dimensions.</p>
</td></tr>
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> unique, ordered class labels.</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p><code>[K, d]</code> centroid matrix of the <code>K</code> unique, ordered classes in native <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> prior probabilities for the unique, ordered classes.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p><code>[n, r]</code> the <code>n</code> data points in reduced dimensionality <code>r</code>.</p>
</td></tr>
<tr><td><code>cr</code></td>
<td>
<p><code>[K, r]</code> the <code>K</code> centroids in reduced dimensionality <code>r</code>.</p>
</td></tr>
<tr><td><code>second.moment</code></td>
<td>
<p>the method used to estimate the second moment.</p>
</td></tr>
<tr><td><code>first.moment</code></td>
<td>
<p>the method used to estimate the first moment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("lol", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>References</h3>

<p>Joshua T. Vogelstein, et al. &quot;Supervised Dimensionality Reduction for Big Data&quot; arXiv (2020).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.project.lol(X=X, Y=Y, r=5)  # use lol to project into 5 dimensions

# use lol to project into 5 dimensions, and produce an orthogonal basis for the projection matrix
model &lt;- lol.project.lol(X=X, Y=Y, r=5, orthogonalize=TRUE)

# use LRQDA to estimate the second moment by performing PCA on each class
model &lt;- lol.project.lol(X=X, Y=Y, r=5, second.moment='quadratic')


# use PLS to estimate the second moment
model &lt;- lol.project.lol(X=X, Y=Y, r=5, second.moment='pls')

# use LRLDA to estimate the second moment, and apply a unit transformation
# (according to scale function) with no centering
model &lt;- lol.project.lol(X=X, Y=Y, r=5, second.moment='linear', second.moment.xfm='unit',
                         second.moment.xfm.opts=list(center=FALSE))
</code></pre>

<hr>
<h2 id='lol.project.lrcca'>Low-rank Canonical Correlation Analysis (LR-CCA)</h2><span id='topic+lol.project.lrcca'></span>

<h3>Description</h3>

<p>A function for implementing the Low-rank Canonical Correlation Analysis (LR-CCA) Algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.project.lrcca(X, Y, r, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.project.lrcca_+3A_x">X</code></td>
<td>
<p>[n, d] the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.lrcca_+3A_y">Y</code></td>
<td>
<p>[n] the labels of the samples with <code>K</code> unique labels.</p>
</td></tr>
<tr><td><code id="lol.project.lrcca_+3A_r">r</code></td>
<td>
<p>the rank of the projection.</p>
</td></tr>
<tr><td><code id="lol.project.lrcca_+3A_...">...</code></td>
<td>
<p>trailing args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p><code>[d, r]</code> the projection matrix from <code>d</code> to <code>r</code> dimensions.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>the eigen values associated with the eigendecomposition.</p>
</td></tr>
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> unique, ordered class labels.</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p><code>[K, d]</code> centroid matrix of the <code>K</code> unique, ordered classes in native <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> prior probabilities for the unique, ordered classes.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p><code>[n, r]</code> the <code>n</code> data points in reduced dimensionality <code>r</code>.</p>
</td></tr>
<tr><td><code>cr</code></td>
<td>
<p><code>[K, r]</code> the <code>K</code> centroids in reduced dimensionality <code>r</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("lrcca", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford and Minh Tang
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.project.lrcca(X=X, Y=Y, r=5)  # use lrcca to project into 5 dimensions
</code></pre>

<hr>
<h2 id='lol.project.lrlda'>Low-Rank Linear Discriminant Analysis (LRLDA)</h2><span id='topic+lol.project.lrlda'></span>

<h3>Description</h3>

<p>A function that performs LRLDA on the class-centered data. Same as class-conditional PCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.project.lrlda(X, Y, r, xfm = FALSE, xfm.opts = list(), robust = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.project.lrlda_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.lrlda_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the samples with <code>K</code> unique labels.</p>
</td></tr>
<tr><td><code id="lol.project.lrlda_+3A_r">r</code></td>
<td>
<p>the rank of the projection.</p>
</td></tr>
<tr><td><code id="lol.project.lrlda_+3A_xfm">xfm</code></td>
<td>
<p>whether to transform the variables before taking the SVD.
</p>

<ul>
<li><p>FALSEapply no transform to the variables.
</p>
</li>
<li><p>'unit'unit transform the variables, defaulting to centering and scaling to mean 0, variance 1. See <code><a href="base.html#topic+scale">scale</a></code> for details and optional args.
</p>
</li>
<li><p>'log'log-transform the variables, for use-cases such as having high variance in larger values. Defaults to natural logarithm. See <code><a href="base.html#topic+Log">log</a></code> for details and optional args.
</p>
</li>
<li><p>'rank'rank-transform the variables. Defalts to breaking ties with the average rank of the tied values. See <code><a href="base.html#topic+rank">rank</a></code> for details and optional args.
</p>
</li>
<li><p>c(opt1, opt2, etc.)apply the transform specified in opt1, followed by opt2, etc.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.project.lrlda_+3A_xfm.opts">xfm.opts</code></td>
<td>
<p>optional arguments to pass to the <code>xfm</code> option specified. Should be a numbered list of lists, where <code>xfm.opts[[i]]</code> corresponds to the optional arguments for <code>xfm[i]</code>. Defaults to the default options for each transform scheme.</p>
</td></tr>
<tr><td><code id="lol.project.lrlda_+3A_robust">robust</code></td>
<td>
<p>whether to use a robust estimate of the covariance matrix when taking PCA. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.project.lrlda_+3A_...">...</code></td>
<td>
<p>trailing args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p><code>[d, r]</code> the projection matrix from <code>d</code> to <code>r</code> dimensions.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>the eigen values associated with the eigendecomposition.</p>
</td></tr>
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> unique, ordered class labels.</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p><code>[K, d]</code> centroid matrix of the <code>K</code> unique, ordered classes in native <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> prior probabilities for the unique, ordered classes.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p><code>[n, r]</code> the <code>n</code> data points in reduced dimensionality <code>r</code>.</p>
</td></tr>
<tr><td><code>cr</code></td>
<td>
<p><code>[K, r]</code> the <code>K</code> centroids in reduced dimensionality <code>r</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("lrlda", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.project.lrlda(X=X, Y=Y, r=2)  # use lrlda to project into 2 dimensions
</code></pre>

<hr>
<h2 id='lol.project.pca'>Principal Component Analysis (PCA)</h2><span id='topic+lol.project.pca'></span>

<h3>Description</h3>

<p>A function that performs PCA on data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.project.pca(X, r, xfm = FALSE, xfm.opts = list(), robust = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.project.pca_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.pca_+3A_r">r</code></td>
<td>
<p>the rank of the projection.</p>
</td></tr>
<tr><td><code id="lol.project.pca_+3A_xfm">xfm</code></td>
<td>
<p>whether to transform the variables before taking the SVD.
</p>

<ul>
<li><p>FALSEapply no transform to the variables.
</p>
</li>
<li><p>'unit'unit transform the variables, defaulting to centering and scaling to mean 0, variance 1. See <code><a href="base.html#topic+scale">scale</a></code> for details and optional arguments to be passed with <code>xfm.opts</code>.
</p>
</li>
<li><p>'log'log-transform the variables, for use-cases such as having high variance in larger values. Defaults to natural logarithm. See <code><a href="base.html#topic+Log">log</a></code> for details and optional arguments to be passed with <code>xfm.opts</code>.
</p>
</li>
<li><p>'rank'rank-transform the variables. Defalts to breaking ties with the average rank of the tied values. See <code><a href="base.html#topic+rank">rank</a></code> for details and optional arguments to be passed with <code>xfm.opts</code>.
</p>
</li>
<li><p>c(opt1, opt2, etc.)apply the transform specified in opt1, followed by opt2, etc.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.project.pca_+3A_xfm.opts">xfm.opts</code></td>
<td>
<p>optional arguments to pass to the <code>xfm</code> option specified. Should be a numbered list of lists, where <code>xfm.opts[[i]]</code> corresponds to the optional arguments for <code>xfm[i]</code>. Defaults to the default options for each transform scheme.</p>
</td></tr>
<tr><td><code id="lol.project.pca_+3A_robust">robust</code></td>
<td>
<p>whether to perform PCA on a robust estimate of the covariance matrix or not. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.project.pca_+3A_...">...</code></td>
<td>
<p>trailing args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p><code>[d, r]</code> the projection matrix from <code>d</code> to <code>r</code> dimensions.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>the eigen values associated with the eigendecomposition.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p><code>[n, r]</code> the <code>n</code> data points in reduced dimensionality <code>r</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("pca", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.project.pca(X=X, r=2)  # use pca to project into 2 dimensions
</code></pre>

<hr>
<h2 id='lol.project.pls'>Partial Least-Squares (PLS)</h2><span id='topic+lol.project.pls'></span>

<h3>Description</h3>

<p>A function for implementing the Partial Least-Squares (PLS) Algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.project.pls(X, Y, r, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.project.pls_+3A_x">X</code></td>
<td>
<p>[n, d] the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.pls_+3A_y">Y</code></td>
<td>
<p>[n] the labels of the samples with <code>K</code> unique labels.</p>
</td></tr>
<tr><td><code id="lol.project.pls_+3A_r">r</code></td>
<td>
<p>the rank of the projection.</p>
</td></tr>
<tr><td><code id="lol.project.pls_+3A_...">...</code></td>
<td>
<p>trailing args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p><code>[d, r]</code> the projection matrix from <code>d</code> to <code>r</code> dimensions.</p>
</td></tr>
<tr><td><code>ylabs</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> unique, ordered class labels.</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p><code>[K, d]</code> centroid matrix of the <code>K</code> unique, ordered classes in native <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> vector containing the <code>K</code> prior probabilities for the unique, ordered classes.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p><code>[n, r]</code> the <code>n</code> data points in reduced dimensionality <code>r</code>.</p>
</td></tr>
<tr><td><code>cr</code></td>
<td>
<p><code>[K, r]</code> the <code>K</code> centroids in reduced dimensionality <code>r</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("pls", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.project.pls(X=X, Y=Y, r=5)  # use pls to project into 5 dimensions
</code></pre>

<hr>
<h2 id='lol.project.rp'>Random Projections (RP)</h2><span id='topic+lol.project.rp'></span>

<h3>Description</h3>

<p>A function for implementing gaussian random projections (rp).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.project.rp(X, r, scale = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.project.rp_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.project.rp_+3A_r">r</code></td>
<td>
<p>the rank of the projection. Note that <code>r &gt;= K</code>, and <code>r &lt; d</code>.</p>
</td></tr>
<tr><td><code id="lol.project.rp_+3A_scale">scale</code></td>
<td>
<p>whether to scale the random projection by the sqrt(1/d). Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="lol.project.rp_+3A_...">...</code></td>
<td>
<p>trailing args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p><code>[d, r]</code> the projection matrix from <code>d</code> to <code>r</code> dimensions.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p><code>[n, r]</code> the <code>n</code> data points in reduced dimensionality <code>r</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("rp", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.project.rp(X=X, r=5)  # use lol to project into 5 dimensions
</code></pre>

<hr>
<h2 id='lol.sims.cigar'>Stacked Cigar</h2><span id='topic+lol.sims.cigar'></span>

<h3>Description</h3>

<p>A simulation for the stacked cigar experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.cigar(n, d, rotate = FALSE, priors = NULL, a = 0.15, b = 4)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.cigar_+3A_n">n</code></td>
<td>
<p>the number of samples of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.cigar_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.cigar_+3A_rotate">rotate</code></td>
<td>
<p>whether to apply a random rotation to the mean and covariance. With random rotataion matrix <code>Q</code>, <code>mu = Q*mu</code>, and <code>S = Q*S*Q</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.cigar_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.cigar_+3A_a">a</code></td>
<td>
<p>scalar for all of the mu1 but 2nd dimension. Defaults to <code>0.15</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.cigar_+3A_b">b</code></td>
<td>
<p>scalar for 2nd dimension value of mu2 and the 2nd variance term of S. Defaults to <code>4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.cigar(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
</code></pre>

<hr>
<h2 id='lol.sims.cross'>Cross</h2><span id='topic+lol.sims.cross'></span>

<h3>Description</h3>

<p>A simulation for the cross experiment, in which the two classes have orthogonal covariant dimensions and the same means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.cross(n, d, rotate = FALSE, priors = NULL, a = 1, b = 0.25, K = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.cross_+3A_n">n</code></td>
<td>
<p>the number of samples of simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.cross_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.cross_+3A_rotate">rotate</code></td>
<td>
<p>With random rotataion matrix <code>Q</code>, <code>mu = Q*mu</code>, and <code>S = Q*S*Q</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.cross_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.cross_+3A_a">a</code></td>
<td>
<p>scalar for the magnitude of the variance that is high within the particular class. Defaults to <code>1</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.cross_+3A_b">b</code></td>
<td>
<p>scalar for the magnitude of the varaince that is not high within the particular class. Defaults to <code>2</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.cross_+3A_k">K</code></td>
<td>
<p>the number of classes. Defaults to <code>2</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.cross(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y

</code></pre>

<hr>
<h2 id='lol.sims.fat_tails'>Fat Tails Simulation</h2><span id='topic+lol.sims.fat_tails'></span>

<h3>Description</h3>

<p>A function for simulating from 2 classes with differing means each with 2 sub-clusters, where one sub-cluster has a narrow tail and the other sub-cluster has a fat tail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.fat_tails(
  n,
  d,
  rotate = FALSE,
  f = 15,
  s0 = 10,
  rho = 0.2,
  t = 0.8,
  priors = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.fat_tails_+3A_n">n</code></td>
<td>
<p>the number of samples of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.fat_tails_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.fat_tails_+3A_rotate">rotate</code></td>
<td>
<p>whether to apply a random rotation to the mean and covariance. With random rotataion matrix <code>Q</code>, <code>mu = Q*mu</code>, and <code>S = Q*S*Q</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.fat_tails_+3A_f">f</code></td>
<td>
<p>the fatness scaling of the tail. S2 = f*S1, where S1_ij = rho if i != j, and 1 if i == j. Defaults to <code>15</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.fat_tails_+3A_s0">s0</code></td>
<td>
<p>the number of dimensions with a difference in the means. s0 should be &lt; d. Defaults to <code>10</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.fat_tails_+3A_rho">rho</code></td>
<td>
<p>the scaling of the off-diagonal covariance terms, should be &lt; 1. Defaults to <code>0.2</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.fat_tails_+3A_t">t</code></td>
<td>
<p>the fraction of each class from the narrower-tailed distribution. Defaults to <code>0.8</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.fat_tails_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.fat_tails(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
</code></pre>

<hr>
<h2 id='lol.sims.mean_diff'>Mean Difference Simulation</h2><span id='topic+lol.sims.mean_diff'></span>

<h3>Description</h3>

<p>A function for simulating data in which a difference in the means is present only in a subset of dimensions, and equal covariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.mean_diff(
  n,
  d,
  rotate = FALSE,
  priors = NULL,
  K = 2,
  md = 1,
  subset = c(1),
  offdiag = 0,
  s = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.mean_diff_+3A_n">n</code></td>
<td>
<p>the number of samples of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.mean_diff_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.mean_diff_+3A_rotate">rotate</code></td>
<td>
<p>whether to apply a random rotation to the mean and covariance. With random rotataion matrix <code>Q</code>, <code>mu = Q*mu</code>, and <code>S = Q*S*Q</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.mean_diff_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.mean_diff_+3A_k">K</code></td>
<td>
<p>the number of classes. Defaults to <code>2</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.mean_diff_+3A_md">md</code></td>
<td>
<p>the magnitude of the difference in the means in the specified subset of dimensions. Ddefaults to <code>1</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.mean_diff_+3A_subset">subset</code></td>
<td>
<p>the dimensions to have a difference in the means. Defaults to only the first dimension. <code>max(subset) &lt; d</code>. Defaults to <code>c(1)</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.mean_diff_+3A_offdiag">offdiag</code></td>
<td>
<p>the off-diagonal elements of the covariance matrix. Should be &lt; 1. <code>S_{ij} = offdiag</code> if <code>i != j</code>, or 1 if <code>i == j</code>. Defaults to <code>0</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.mean_diff_+3A_s">s</code></td>
<td>
<p>the scaling parameter of the covariance matrix. S_ij = scaling*1 if i == j, or scaling*offdiag if i != j. Defaults to <code>1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.mean_diff(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
</code></pre>

<hr>
<h2 id='lol.sims.qdtoep'>Quadratic Discriminant Toeplitz Simulation</h2><span id='topic+lol.sims.qdtoep'></span>

<h3>Description</h3>

<p>A function for simulating data generalizing the Toeplitz setting, where each class has a different covariance matrix. This results in a Quadratic Discriminant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.qdtoep(
  n,
  d,
  rotate = FALSE,
  priors = NULL,
  D1 = 10,
  b = 0.4,
  rho = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.qdtoep_+3A_n">n</code></td>
<td>
<p>the number of samples of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.qdtoep_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.qdtoep_+3A_rotate">rotate</code></td>
<td>
<p>whether to apply a random rotation to the mean and covariance. With random rotataion matrix <code>Q</code>, <code>mu = Q*mu</code>, and <code>S = Q*S*Q</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.qdtoep_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.qdtoep_+3A_d1">D1</code></td>
<td>
<p>the dimensionality for the non-equal covariance terms. Defaults to <code>10</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.qdtoep_+3A_b">b</code></td>
<td>
<p>a scaling parameter for the means. Defaults to <code>0.4</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.qdtoep_+3A_rho">rho</code></td>
<td>
<p>the scaling of the covariance terms, should be &lt; 1. Defaults to <code>0.5</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.qdtoep(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
</code></pre>

<hr>
<h2 id='lol.sims.random_rotate'>Random Rotation</h2><span id='topic+lol.sims.random_rotate'></span>

<h3>Description</h3>

<p>A helper function for applying a random rotation to gaussian parameter set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.random_rotate(mus, Sigmas, Q = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.random_rotate_+3A_mus">mus</code></td>
<td>
<p>means per class.</p>
</td></tr>
<tr><td><code id="lol.sims.random_rotate_+3A_sigmas">Sigmas</code></td>
<td>
<p>covariances per class.</p>
</td></tr>
<tr><td><code id="lol.sims.random_rotate_+3A_q">Q</code></td>
<td>
<p>rotation to use, if any</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>

<hr>
<h2 id='lol.sims.rev_rtrunk'>Reverse Random Trunk</h2><span id='topic+lol.sims.rev_rtrunk'></span>

<h3>Description</h3>

<p>A simulation for the reversed random trunk experiment, in which the maximal covariant directions are the same as the directions with the maximal mean difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.rev_rtrunk(
  n,
  d,
  robust = FALSE,
  rotate = FALSE,
  priors = NULL,
  b = 4,
  K = 2,
  maxvar = b^3,
  maxvar.outlier = maxvar^3
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.rev_rtrunk_+3A_n">n</code></td>
<td>
<p>the number of samples of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.rev_rtrunk_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.rev_rtrunk_+3A_robust">robust</code></td>
<td>
<p>the number of outlier points to add, where outliers have opposite covariance of inliers. Defaults to <code>FALSE</code>, which will not add any outliers.</p>
</td></tr>
<tr><td><code id="lol.sims.rev_rtrunk_+3A_rotate">rotate</code></td>
<td>
<p>whether to apply a random rotation to the mean and covariance. With random rotataion matrix <code>Q</code>, <code>mu = Q*mu</code>, and <code>S = Q*S*Q</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rev_rtrunk_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rev_rtrunk_+3A_b">b</code></td>
<td>
<p>scalar for mu scaling. Default to <code>4</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rev_rtrunk_+3A_k">K</code></td>
<td>
<p>number of classes, should be &lt;4. Defaults to <code>2</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rev_rtrunk_+3A_maxvar">maxvar</code></td>
<td>
<p>the maximum covariance between the two classes. Defaults to <code>100</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rev_rtrunk_+3A_maxvar.outlier">maxvar.outlier</code></td>
<td>
<p>the maximum covariance for the outlier points. Defaults to <code>maxvar*5</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
<tr><td><code>robust</code></td>
<td>
<p>If robust is not false, a list containing <code>inlier</code> a boolean array indicating which points are inliers, <code>s.outlier</code> the covariance structure of outliers, and <code>mu.outlier</code> the means of the outliers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
</code></pre>

<hr>
<h2 id='lol.sims.rotation'>Sample Random Rotation</h2><span id='topic+lol.sims.rotation'></span>

<h3>Description</h3>

<p>A helper function for estimating a random rotation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.rotation(d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.rotation_+3A_d">d</code></td>
<td>
<p>dimensions to generate a rotation matrix for.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the rotation matrix
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>

<hr>
<h2 id='lol.sims.rtrunk'>Random Trunk</h2><span id='topic+lol.sims.rtrunk'></span>

<h3>Description</h3>

<p>A simulation for the random trunk experiment, in which the maximal covariant dimensions are the reverse of the maximal mean differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.rtrunk(
  n,
  d,
  rotate = FALSE,
  priors = NULL,
  b = 4,
  K = 2,
  maxvar = 100
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.rtrunk_+3A_n">n</code></td>
<td>
<p>the number of samples of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.rtrunk_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.rtrunk_+3A_rotate">rotate</code></td>
<td>
<p>whether to apply a random rotation to the mean and covariance. With random rotataion matrix <code>Q</code>, <code>mu = Q*mu</code>, and <code>S = Q*S*Q</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rtrunk_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rtrunk_+3A_b">b</code></td>
<td>
<p>scalar for mu scaling. Default to <code>4</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rtrunk_+3A_k">K</code></td>
<td>
<p>number of classes, should be &lt;4. Defaults to <code>2</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.rtrunk_+3A_maxvar">maxvar</code></td>
<td>
<p>the maximum covariance between the two classes. Defaults to <code>100</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
<tr><td><code>robust</code></td>
<td>
<p>If robust is not false, a list containing <code>inlier</code> a boolean array indicating which points are inliers, <code>s.outlier</code> the covariance structure of outliers, and <code>mu.outlier</code> the means of the outliers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
</code></pre>

<hr>
<h2 id='lol.sims.sim_gmm'>GMM Simulate</h2><span id='topic+lol.sims.sim_gmm'></span>

<h3>Description</h3>

<p>A helper function for simulating from Gaussian Mixture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.sim_gmm(mus, Sigmas, n, priors)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.sim_gmm_+3A_mus">mus</code></td>
<td>
<p><code>[d, K]</code> the mus for each class.</p>
</td></tr>
<tr><td><code id="lol.sims.sim_gmm_+3A_sigmas">Sigmas</code></td>
<td>
<p><code>[d,d,K]</code> the Sigmas for each class.</p>
</td></tr>
<tr><td><code id="lol.sims.sim_gmm_+3A_n">n</code></td>
<td>
<p>the number of examples.</p>
</td></tr>
<tr><td><code id="lol.sims.sim_gmm_+3A_priors">priors</code></td>
<td>
<p><code>K</code> the priors for each class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the simulated data.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the labels for each data point.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each class.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>

<hr>
<h2 id='lol.sims.toep'>Toeplitz Simulation</h2><span id='topic+lol.sims.toep'></span>

<h3>Description</h3>

<p>A function for simulating data in which the covariance is a non-symmetric toeplitz matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.toep(n, d, rotate = FALSE, priors = NULL, D1 = 10, b = 0.4, rho = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.toep_+3A_n">n</code></td>
<td>
<p>the number of samples of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.toep_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.toep_+3A_rotate">rotate</code></td>
<td>
<p>whether to apply a random rotation to the mean and covariance. With random rotataion matrix <code>Q</code>, <code>mu = Q*mu</code>, and <code>S = Q*S*Q</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.toep_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.toep_+3A_d1">D1</code></td>
<td>
<p>the dimensionality for the non-equal covariance terms. Defaults to <code>10</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.toep_+3A_b">b</code></td>
<td>
<p>a scaling parameter for the means. Defaults to <code>0.4</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.toep_+3A_rho">rho</code></td>
<td>
<p>the scaling of the covariance terms, should be &lt; 1. Defaults to <code>0.5</code>/</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.toep(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
</code></pre>

<hr>
<h2 id='lol.sims.xor2'>Xor Problem</h2><span id='topic+lol.sims.xor2'></span>

<h3>Description</h3>

<p>A function to simulate from the 2-class xor problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.sims.xor2(n, d, priors = NULL, fall = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.sims.xor2_+3A_n">n</code></td>
<td>
<p>the number of samples of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.xor2_+3A_d">d</code></td>
<td>
<p>the dimensionality of the simulated data.</p>
</td></tr>
<tr><td><code id="lol.sims.xor2_+3A_priors">priors</code></td>
<td>
<p>the priors for each class. If <code>NULL</code>, class priors are all equal. If not null, should be <code>|priors| = K</code>, a length <code>K</code> vector for <code>K</code> classes. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lol.sims.xor2_+3A_fall">fall</code></td>
<td>
<p>the falloff for the covariance structuring. Sigma declines by ndim/fall across the variance terms. Defaults to <code>100</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>simulation</code> with the following:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p><code>[n, d]</code> the <code>n</code> data points in <code>d</code> dimensions as a matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p><code>[n]</code> the <code>n</code> labels as an array.</p>
</td></tr>
<tr><td><code>mus</code></td>
<td>
<p><code>[d, K]</code> the <code>K</code> class means in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>Sigmas</code></td>
<td>
<p><code>[d, d, K]</code> the <code>K</code> class covariance matrices in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p><code>[K]</code> the priors for each of the <code>K</code> classes.</p>
</td></tr>
<tr><td><code>simtype</code></td>
<td>
<p>The name of the simulation.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Any extraneous parameters the simulation was created with.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("sims", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.xor2(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
</code></pre>

<hr>
<h2 id='lol.utils.decomp'>A utility to use irlba when necessary</h2><span id='topic+lol.utils.decomp'></span>

<h3>Description</h3>

<p>A utility to use irlba when necessary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.utils.decomp(
  X,
  xfm = FALSE,
  xfm.opts = list(),
  ncomp = 0,
  t = 0.05,
  robust = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.utils.decomp_+3A_x">X</code></td>
<td>
<p>the data to compute the svd of.</p>
</td></tr>
<tr><td><code id="lol.utils.decomp_+3A_xfm">xfm</code></td>
<td>
<p>whether to transform the variables before taking the SVD.
</p>

<ul>
<li><p>FALSEapply no transform to the variables.
</p>
</li>
<li><p>'unit'unit transform the variables, defaulting to centering and scaling to mean 0, variance 1. See <code><a href="base.html#topic+scale">scale</a></code> for details and optional args.
</p>
</li>
<li><p>'log'log-transform the variables, for use-cases such as having high variance in larger values. Defaults to natural logarithm. See <code><a href="base.html#topic+Log">log</a></code> for details and optional args.
</p>
</li>
<li><p>'rank'rank-transform the variables. Defalts to breaking ties with the average rank of the tied values. See <code><a href="base.html#topic+rank">rank</a></code> for details and optional args.
</p>
</li>
<li><p>c(opt1, opt2, etc.)apply the transform specified in opt1, followed by opt2, etc.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.utils.decomp_+3A_xfm.opts">xfm.opts</code></td>
<td>
<p>optional arguments to pass to the <code>xfm</code> option specified. Should be a numbered list of lists, where <code>xfm.opts[[i]]</code> corresponds to the optional arguments for <code>xfm[i]</code>. Defaults to the default options for each transform scheme.</p>
</td></tr>
<tr><td><code id="lol.utils.decomp_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of left singular vectors to retain.</p>
</td></tr>
<tr><td><code id="lol.utils.decomp_+3A_t">t</code></td>
<td>
<p>the threshold of percent of singular vals/vecs to use irlba.</p>
</td></tr>
<tr><td><code id="lol.utils.decomp_+3A_robust">robust</code></td>
<td>
<p>whether to use a robust estimate of the covariance matrix when taking PCA. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the svd of X.
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>

<hr>
<h2 id='lol.utils.deltas'>A function that performs a utility computation of information about the differences of the classes.</h2><span id='topic+lol.utils.deltas'></span>

<h3>Description</h3>

<p>A function that performs a utility computation of information about the differences of the classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.utils.deltas(centroids, priors, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.utils.deltas_+3A_centroids">centroids</code></td>
<td>
<p><code>[d, K]</code> centroid matrix of the unique, ordered classes.</p>
</td></tr>
<tr><td><code id="lol.utils.deltas_+3A_priors">priors</code></td>
<td>
<p><code>[K]</code> vector containing prior probability for the unique, ordered classes.</p>
</td></tr>
<tr><td><code id="lol.utils.deltas_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>deltas <code>[d, K]</code> the K difference vectors.
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>

<hr>
<h2 id='lol.utils.info'>A function that performs basic utilities about the data.</h2><span id='topic+lol.utils.info'></span>

<h3>Description</h3>

<p>A function that performs basic utilities about the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.utils.info(X, Y, robust = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.utils.info_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with n samples in d dimensions.</p>
</td></tr>
<tr><td><code id="lol.utils.info_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the samples.</p>
</td></tr>
<tr><td><code id="lol.utils.info_+3A_robust">robust</code></td>
<td>
<p>whether to perform PCA on a robust estimate of the covariance matrix or not. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lol.utils.info_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>n</code> the number of samples.
</p>
<p><code>d</code> the number of dimensions.
</p>
<p>ylabs <code>[K]</code> vector containing the unique, ordered class labels.
</p>
<p>priors <code>[K]</code> vector containing prior probability for the unique, ordered classes.
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>

<hr>
<h2 id='lol.utils.ohe'>A function for one-hot encoding categorical respose vectors.</h2><span id='topic+lol.utils.ohe'></span>

<h3>Description</h3>

<p>A function for one-hot encoding categorical respose vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.utils.ohe(Y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.utils.ohe_+3A_y">Y</code></td>
<td>
<p>[n] a vector of the categorical resposes, with <code>K</code> unique categories.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following:
</p>
<table role = "presentation">
<tr><td><code>Yh</code></td>
<td>
<p>[n, K] the one-hot encoded Y respose variable.</p>
</td></tr>
<tr><td><code>ylabs</code></td>
<td>
<p>[K] a vector of the y names corresponding to each response column.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>

<hr>
<h2 id='lol.xval.eval'>Embedding Cross Validation</h2><span id='topic+lol.xval.eval'></span>

<h3>Description</h3>

<p>A function for performing leave-one-out cross-validation for a given embedding model. This function produces fold-wise
cross-validated misclassification rates for standard embedding techniques. Users can optionally specify custom embedding techniques
with proper configuration of <code>alg.*</code> parameters and hyperparameters. Optional classifiers implementing the S3 <code>predict</code> function can be used
for classification, with hyperparameters to classifiers for determining misclassification rate specified in <code>classifier.*</code> parameters and hyperparameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.xval.eval(
  X,
  Y,
  r,
  alg,
  sets = NULL,
  alg.dimname = "r",
  alg.opts = list(),
  alg.embedding = "A",
  classifier = lda,
  classifier.opts = list(),
  classifier.return = "class",
  k = "loo",
  rank.low = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.xval.eval_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the samples with <code>K</code> unique labels.</p>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_r">r</code></td>
<td>
<p>the number of embedding dimensions desired, where <code>r &lt;= d</code>.</p>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_alg">alg</code></td>
<td>
<p>the algorithm to use for embedding. Should be a function that accepts inputs <code>X</code>, <code>Y</code>, and has a parameter for <code>alg.dimname</code> if <code>alg</code> is supervised, or just <code>X</code> and <code>alg.dimname</code> if <code>alg</code> is unsupervised.This algorithm should return a list containing a matrix that embeds from d to r &lt;= d dimensions.</p>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_sets">sets</code></td>
<td>
<p>a user-defined cross-validation set. Defaults to <code>NULL</code>.
</p>

<ul>
<li><p><code>is.null(sets)</code> randomly partition the inputs <code>X</code> and <code>Y</code> into training and testing sets.
</p>
</li>
<li><p><code>!is.null(sets)</code> use a user-defined partitioning of the inputs <code>X</code> and <code>Y</code> into training and testing sets. Should be in the format of the outputs from <code><a href="#topic+lol.xval.split">lol.xval.split</a></code>. That is, a <code>list</code> with each element containing <code>X.train</code>, an <code>[n-k][d]</code> subset of data to test on, <code>Y.train</code>, an <code>[n-k]</code> subset of class labels for <code>X.train</code>; <code>X.test</code>, an <code>[n-k][d]</code> subset of data to test the model on, <code>Y.train</code>, an <code>[k]</code> subset of class labels for <code>X.test</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_alg.dimname">alg.dimname</code></td>
<td>
<p>the name of the parameter accepted by <code>alg</code> for indicating the embedding dimensionality desired. Defaults to <code>r</code>.</p>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_alg.opts">alg.opts</code></td>
<td>
<p>the hyper-parameter options you want to pass into your algorithm, as a keyworded list. Defaults to <code>list()</code>, or no hyper-parameters.</p>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_alg.embedding">alg.embedding</code></td>
<td>
<p>the attribute returned by <code>alg</code> containing the embedding matrix. Defaults to assuming that <code>alg</code> returns an embgedding matrix as <code>"A"</code>.
</p>

<ul>
<li> <p><code>!is.nan(alg.embedding)</code> Assumes that <code>alg</code> will return a list containing an attribute, <code>alg.embedding</code>, a <code>[d, r]</code> matrix that embeds <code>[n, d]</code> data from <code>[d]</code> to <code>[r &lt; d]</code> dimensions.
</p>
</li>
<li> <p><code>is.nan(alg.embedding)</code> Assumes that <code>alg</code> returns a <code>[d, r]</code> matrix that embeds <code>[n, d]</code> data from <code>[d]</code> to <code>[r &lt; d]</code> dimensions.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_classifier">classifier</code></td>
<td>
<p>the classifier to use for assessing performance. The classifier should accept <code>X</code>, a <code>[n, d]</code> array as the first input, and <code>Y</code>, a <code>[n]</code> array of labels, as the first 2 arguments. The class should implement a predict function, <code>predict.classifier</code>, that is compatible with the <code>stats::predict</code> <code>S3</code> method. Defaults to <code>MASS::lda</code>.</p>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_classifier.opts">classifier.opts</code></td>
<td>
<p>any extraneous options to be passed to the classifier function, as a list. Defaults to an empty list.</p>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_classifier.return">classifier.return</code></td>
<td>
<p>if the return type is a list, <code>class</code> encodes the attribute containing the prediction labels from <code>stats::predict</code>. Defaults to the return type of <code>MASS::lda</code>, <code>class</code>.
</p>

<ul>
<li><p><code>!is.nan(classifier.return)</code> Assumes that <code>predict.classifier</code> will return a list containing an attribute, <code>classifier.return</code>, that encodes the predicted labels.
</p>
</li>
<li><p><code>is.nan(classifier.return)</code> Assumes that <code>predict.classifer</code> returns a <code>[n]</code> vector/array containing the prediction labels for <code>[n, d]</code> inputs.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_k">k</code></td>
<td>
<p>the cross-validated method to perform. Defaults to <code>'loo'</code>. If <code>sets</code> is provided, this option is ignored. See <code><a href="#topic+lol.xval.split">lol.xval.split</a></code> for details.
</p>

<ul>
<li><p><code>'loo'</code> Leave-one-out cross validation
</p>
</li>
<li><p><code>isinteger(k)</code>  perform <code>k</code>-fold cross-validation with <code>k</code> as the number of folds.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_rank.low">rank.low</code></td>
<td>
<p>whether to force the training set to low-rank. Defaults to <code>FALSE</code>. If <code>sets</code> is provided, this option is ignored. See <code><a href="#topic+lol.xval.split">lol.xval.split</a></code> for details.
</p>

<ul>
<li><p>if <code>rank.low == FALSE</code>, uses default cross-validation method with standard <code>k</code>-fold validation. Training sets are <code>k-1</code> folds, and testing sets are <code>1</code> fold, where the fold held-out for testing is rotated to ensure no dependence of potential downstream inference in the cross-validated misclassification rates.
</p>
</li>
<li><p>if ]coderank.low == TRUE, users cross-validation method with <code>ntrain = min((k-1)/k*n, d)</code> sample training sets, where <code>d</code>  is the number of dimensions in <code>X</code>. This ensures that the training data is always low-rank, <code>ntrain &lt; d + 1</code>. Note that the resulting training sets may have <code>ntrain &lt; (k-1)/k*n</code>, but the resulting testing sets will always be properly rotated <code>ntest = n/k</code> to ensure no dependencies in fold-wise testing.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.eval_+3A_...">...</code></td>
<td>
<p>trailing args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table role = "presentation">
<tr><td><code>lhat</code></td>
<td>
<p>the mean cross-validated error.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The model returned by <code>alg</code> computed on all of the data.</p>
</td></tr>
<tr><td><code>classifier</code></td>
<td>
<p>The classifier trained on all of the embedded data.</p>
</td></tr>
<tr><td><code>lhats</code></td>
<td>
<p>the cross-validated error for each of the <code>k</code>-folds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("xval", package = "lolR")</code>
</p>
<p>For  extending cross-validation techniques shown here to arbitrary embedding algorithms, see the vignette:
<code>vignette("extend_embedding", package = "lolR")</code>
</p>
<p>For  extending cross-validation techniques shown here to arbitrary classification algorithms, see the vignette:
<code>vignette("extend_classification", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'># train model and analyze with loo validation using lda classifier
library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
r=5  # embed into r=5 dimensions
# run cross-validation with the nearestCentroid method and
# leave-one-out cross-validation, which returns only
# prediction labels so we specify classifier.return as NaN
xval.fit &lt;- lol.xval.eval(X, Y, r, lol.project.lol,
                          classifier=lol.classify.nearestCentroid,
                          classifier.return=NaN, k='loo')

# train model and analyze with 5-fold validation using lda classifier
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
xval.fit &lt;- lol.xval.eval(X, Y, r, lol.project.lol, k=5)

# pass in existing cross-validation sets
sets &lt;- lol.xval.split(X, Y, k=2)
xval.fit &lt;- lol.xval.eval(X, Y, r, lol.project.lol, sets=sets)
</code></pre>

<hr>
<h2 id='lol.xval.optimal_dimselect'>Optimal Cross-Validated Number of Embedding Dimensions</h2><span id='topic+lol.xval.optimal_dimselect'></span>

<h3>Description</h3>

<p>A function for performing leave-one-out cross-validation for a given embedding model, that allows users to determine the optimal number of embedding dimensions for
their algorithm-of-choice. This function produces fold-wise cross-validated misclassification rates for standard embedding techniques across a specified selection of
embedding dimensions. Optimal embedding dimension is selected as the dimension with the lowest average misclassification rate across all folds.
Users can optionally specify custom embedding techniques with proper configuration of <code>alg.*</code> parameters and hyperparameters.
Optional classifiers implementing the S3 <code>predict</code> function can be used for classification, with hyperparameters to classifiers for
determining misclassification rate specified in <code>classifier.*</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.xval.optimal_dimselect(
  X,
  Y,
  rs,
  alg,
  sets = NULL,
  alg.dimname = "r",
  alg.opts = list(),
  alg.embedding = "A",
  alg.structured = TRUE,
  classifier = lda,
  classifier.opts = list(),
  classifier.return = "class",
  k = "loo",
  rank.low = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.xval.optimal_dimselect_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the samples with <code>K</code> unique labels. Defaults to <code>NaN</code>.#' @param alg.opts any extraneous options to be passed to the classifier function, as a list. Defaults to an empty list. For example, this could be the embedding dimensionality to investigate.</p>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_rs">rs</code></td>
<td>
<p><code>[r.n]</code> the embedding dimensions to investigate over, where <code>max(rs) &lt;= d</code>.</p>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_alg">alg</code></td>
<td>
<p>the algorithm to use for embedding. Should be a function that accepts inputs <code>X</code> and <code>Y</code> and embedding dimension <code>r</code> if <code>alg</code> is supervised, or just <code>X</code> and embedding dimension <code>r</code> if <code>alg</code> is unsupervised.This algorithm should return a list containing a matrix that embeds from d to r &lt; d dimensions.</p>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_sets">sets</code></td>
<td>
<p>a user-defined cross-validation set. Defaults to <code>NULL</code>.
</p>

<ul>
<li><p><code>is.null(sets)</code> randomly partition the inputs <code>X</code> and <code>Y</code> into training and testing sets.
</p>
</li>
<li><p><code>!is.null(sets)</code> use a user-defined partitioning of the inputs <code>X</code> and <code>Y</code> into training and testing sets. Should be in the format of the outputs from <code><a href="#topic+lol.xval.split">lol.xval.split</a></code>. That is, a <code>list</code> with each element containing <code>X.train</code>, an <code>[n-k][d]</code> subset of data to test on, <code>Y.train</code>, an <code>[n-k]</code> subset of class labels for <code>X.train</code>; <code>X.test</code>, an <code>[n-k][d]</code> subset of data to test the model on, <code>Y.train</code>, an <code>[k]</code> subset of class labels for <code>X.test</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_alg.dimname">alg.dimname</code></td>
<td>
<p>the name of the parameter accepted by <code>alg</code> for indicating the embedding dimensionality desired. Defaults to <code>r</code>.</p>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_alg.opts">alg.opts</code></td>
<td>
<p>the hyper-parameter options to pass to your algorithm as a keyworded list. Defaults to <code>list()</code>, or no hyper-parameters. This should not include the number of embedding dimensions, <code>r</code>, which are passed separately in the <code>rs</code> vector.</p>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_alg.embedding">alg.embedding</code></td>
<td>
<p>the attribute returned by <code>alg</code> containing the embedding matrix. Defaults to assuming that <code>alg</code> returns an embgedding matrix as <code>"A"</code>.
</p>

<ul>
<li> <p><code>!is.nan(alg.embedding)</code> Assumes that <code>alg</code> will return a list containing an attribute, <code>alg.embedding</code>, a <code>[d, r]</code> matrix that embeds <code>[n, d]</code> data from <code>[d]</code> to <code>[r &lt; d]</code> dimensions.
</p>
</li>
<li> <p><code>is.nan(alg.embedding)</code> Assumes that <code>alg</code> returns a <code>[d, r]</code> matrix that embeds <code>[n, d]</code> data from <code>[d]</code> to <code>[r &lt; d]</code> dimensions.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_alg.structured">alg.structured</code></td>
<td>
<p>a boolean to indicate whether the embedding matrix is structured. Provides performance increase by not having to compute the embedding matrix <code>xv</code> times if unnecessary. Defaults to <code>TRUE</code>.
</p>

<ul>
<li> <p><code>TRUE</code> assumes that if <code>Ar: R^d -&gt; R^r</code> embeds from <code>d</code> to <code>r</code> dimensions and <code>Aq: R^d -&gt; R^q</code> from <code>d</code> to <code>q &gt; r</code> dimensions, that <code>Aq[, 1:r] == Ar</code>,
</p>
</li>
<li> <p><code>TRUE</code> assumes that if <code>Ar: R^d -&gt; R^r</code> embeds from <code>d</code> to <code>r</code> dimensions and <code>Aq: R^d -&gt; R^q</code> from <code>d</code> to <code>q &gt; r</code> dimensions, that <code>Aq[, 1:r] != Ar</code>,
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_classifier">classifier</code></td>
<td>
<p>the classifier to use for assessing performance. The classifier should accept <code>X</code>, a <code>[n, d]</code> array as the first input, and <code>Y</code>, a <code>[n]</code> array of labels, as the first 2 arguments. The class should implement a predict function, <code>predict.classifier</code>, that is compatible with the <code>stats::predict</code> <code>S3</code> method. Defaults to <code>MASS::lda</code>.</p>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_classifier.opts">classifier.opts</code></td>
<td>
<p>any extraneous options to be passed to the classifier function, as a list. Defaults to an empty list.</p>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_classifier.return">classifier.return</code></td>
<td>
<p>if the return type is a list, <code>class</code> encodes the attribute containing the prediction labels from <code>stats::predict</code>. Defaults to the return type of <code>MASS::lda</code>, <code>class</code>.
</p>

<ul>
<li><p><code>!is.nan(classifier.return)</code> Assumes that <code>predict.classifier</code> will return a list containing an attribute, <code>classifier.return</code>, that encodes the predicted labels.
</p>
</li>
<li><p><code>is.nan(classifier.return)</code> Assumes that <code>predict.classifer</code> returns a <code>[n]</code> vector/array containing the prediction labels for <code>[n, d]</code> inputs.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_k">k</code></td>
<td>
<p>the cross-validated method to perform. Defaults to <code>'loo'</code>. If <code>sets</code> is provided, this option is ignored. See <code><a href="#topic+lol.xval.split">lol.xval.split</a></code> for details.
</p>

<ul>
<li><p><code>'loo'</code> Leave-one-out cross validation
</p>
</li>
<li><p><code>isinteger(k)</code>  perform <code>k</code>-fold cross-validation with <code>k</code> as the number of folds.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_rank.low">rank.low</code></td>
<td>
<p>whether to force the training set to low-rank. Defaults to <code>FALSE</code>. If <code>sets</code> is provided, this option is ignored. See <code><a href="#topic+lol.xval.split">lol.xval.split</a></code> for details.
</p>

<ul>
<li><p>if <code>rank.low == FALSE</code>, uses default cross-validation method with standard <code>k</code>-fold validation. Training sets are <code>k-1</code> folds, and testing sets are <code>1</code> fold, where the fold held-out for testing is rotated to ensure no dependence of potential downstream inference in the cross-validated misclassification rates.
</p>
</li>
<li><p>if ]coderank.low == TRUE, users cross-validation method with <code>ntrain = min((k-1)/k*n, d)</code> sample training sets, where <code>d</code>  is the number of dimensions in <code>X</code>. This ensures that the training data is always low-rank, <code>ntrain &lt; d + 1</code>. Note that the resulting training sets may have <code>ntrain &lt; (k-1)/k*n</code>, but the resulting testing sets will always be properly rotated <code>ntest = n/k</code> to ensure no dependencies in fold-wise testing.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.optimal_dimselect_+3A_...">...</code></td>
<td>
<p>trailing args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table role = "presentation">
<tr><td><code>folds.data</code></td>
<td>
<p>the results, as a data-frame, of the per-fold classification accuracy.</p>
</td></tr>
<tr><td><code>foldmeans.data</code></td>
<td>
<p>the results, as a data-frame, of the average classification accuracy for each <code>r</code>.</p>
</td></tr>
<tr><td><code>optimal.lhat</code></td>
<td>
<p>the classification error of the optimal <code>r</code></p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code>optimal.r</code></td>
<td>
<p>the optimal number of embedding dimensions from <code>rs</code></p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code>model</code></td>
<td>
<p>the model trained on all of the data at the optimal number of embedding dimensions.</p>
</td></tr>
<tr><td><code>classifier</code></td>
<td>
<p>the classifier trained on all of the data at the optimal number of embedding dimensions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("xval", package = "lolR")</code>
</p>
<p>For  extending cross-validation techniques shown here to arbitrary embedding algorithms, see the vignette:
<code>vignette("extend_embedding", package = "lolR")</code>
</p>
<p>For  extending cross-validation techniques shown here to arbitrary classification algorithms, see the vignette:
<code>vignette("extend_classification", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'># train model and analyze with loo validation using lda classifier
library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
# run cross-validation with the nearestCentroid method and
# leave-one-out cross-validation, which returns only
# prediction labels so we specify classifier.return as NaN
xval.fit &lt;- lol.xval.optimal_dimselect(X, Y, rs=c(5, 10, 15), lol.project.lol,
                          classifier=lol.classify.nearestCentroid,
                          classifier.return=NaN, k='loo')

# train model and analyze with 5-fold validation using lda classifier
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
xval.fit &lt;- lol.xval.optimal_dimselect(X, Y, rs=c(5, 10, 15), lol.project.lol, k=5)

# pass in existing cross-validation sets
sets &lt;- lol.xval.split(X, Y, k=2)
xval.fit &lt;- lol.xval.optimal_dimselect(X, Y, rs=c(5, 10, 15), lol.project.lol, sets=sets)
</code></pre>

<hr>
<h2 id='lol.xval.split'>Cross-Validation Data Splitter</h2><span id='topic+lol.xval.split'></span>

<h3>Description</h3>

<p>A function to split a dataset into training and testing sets for cross validation. The procedure for cross-validation
is to split the data into k-folds. The k-folds are then rotated individually to form a single held-out testing set the model will be validated on,
and the remaining (k-1) folds are used for training the developed model. Note that this cross-validation function includes functionality to be used for
low-rank cross-validation. In that case, instead of using the full (k-1) folds for training, we subset <code>min((k-1)/k*n, d)</code> samples to ensure that
the resulting training sets  are all low-rank. We still rotate properly over the held-out fold to ensure that the resulting testing sets
do not have any shared examples, which would add a complicated  dependence structure to inference we attempt to infer on the testing sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lol.xval.split(X, Y, k = "loo", rank.low = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lol.xval.split_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="lol.xval.split_+3A_y">Y</code></td>
<td>
<p><code>[n]</code> the labels of the samples with <code>K</code> unique labels.</p>
</td></tr>
<tr><td><code id="lol.xval.split_+3A_k">k</code></td>
<td>
<p>the cross-validated method to perform. Defaults to <code>'loo'</code>.
</p>

<ul>
<li><p>if <code>k == round(k)</code>, performed k-fold cross-validation.
</p>
</li>
<li><p>if <code>k == 'loo'</code>, performs leave-one-out cross-validation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.split_+3A_rank.low">rank.low</code></td>
<td>
<p>whether to force the training set to low-rank. Defaults to <code>FALSE</code>.
</p>

<ul>
<li><p>if <code>rank == FALSE</code>, uses default cross-validation method with standard <code>k</code>-fold validation. Training sets are <code>k-1</code> folds, and testing sets are <code>1</code> fold, where the fold held-out for testing is rotated to ensure no dependence of potential downstream inference in the cross-validated misclassification rates.
</p>
</li>
<li><p>if <code>rank == TRUE</code>, users cross-validation method with <code>ntrain = min((k-1)/k*n, d)</code> sample training sets, where <code>d</code>  is the number of dimensions in <code>X</code>. This ensures that the training data is always low-rank, <code>ntrain &lt; d + 1</code>. Note that the resulting training sets may have <code>ntrain &lt; (k-1)/k*n</code>, but the resulting testing sets will always be properly rotated <code>ntest = n/k</code> to ensure no dependencies in fold-wise testing.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lol.xval.split_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sets the cross-validation sets as an object of class <code>"XV"</code> containing the following:
</p>
<table role = "presentation">
<tr><td><code>train</code></td>
<td>
<p>length <code>[ntrain]</code> vector indicating the indices of the training examples.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p> length <code>[ntest]</code> vector indicating the indices of the testing examples.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'># prepare data for 10-fold validation
library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
sets.xval.10fold &lt;- lol.xval.split(X, Y, k=10)

# prepare data for loo validation
sets.xval.loo &lt;- lol.xval.split(X, Y, k='loo')

</code></pre>

<hr>
<h2 id='predict.nearestCentroid'>Nearest Centroid Classifier Prediction</h2><span id='topic+predict.nearestCentroid'></span>

<h3>Description</h3>

<p>A function that predicts the class of points based on the nearest centroid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nearestCentroid'
predict(object, X, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.nearestCentroid_+3A_object">object</code></td>
<td>
<p>An object of class <code>nearestCentroid</code>, with the following attributes:
</p>

<ul>
<li><p>centroids<code>[K, d]</code> the centroids of each class with <code>K</code> classes in <code>d</code> dimensions.
</p>
</li>
<li><p>ylabs<code>[K]</code> the ylabels for each of the <code>K</code> unique classes, ordered.
</p>
</li>
<li><p>priors<code>[K]</code> the priors for each of the <code>K</code> classes.
</p>
</li></ul>
</td></tr>
<tr><td><code id="predict.nearestCentroid_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data to classify with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="predict.nearestCentroid_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Yhat <code>[n]</code> the predicted class of each of the <code>n</code> data point in <code>X</code>.
</p>


<h3>Details</h3>

<p>For more details see the help vignette:
<code>vignette("centroid", package = "lolR")</code>
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.classify.nearestCentroid(X, Y)
Yh &lt;- predict(model, X)
</code></pre>

<hr>
<h2 id='predict.randomChance'>Randomly Chance Classifier Prediction</h2><span id='topic+predict.randomChance'></span>

<h3>Description</h3>

<p>A function that predicts the maximally present class in the dataset. Functionality consistent
with the standard R prediction interface so that one can compute the &quot;chance&quot; accuracy
with minimal modification of other classification scripts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'randomChance'
predict(object, X, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.randomChance_+3A_object">object</code></td>
<td>
<p>An object of class <code>randomChance</code>, with the following attributes:
</p>

<ul>
<li><p>ylabs<code>[K]</code> the ylabels for each of the <code>K</code> unique classes, ordered.
</p>
</li>
<li><p>priors<code>[K]</code> the priors for each of the <code>K</code> classes.
</p>
</li></ul>
</td></tr>
<tr><td><code id="predict.randomChance_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data to classify with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="predict.randomChance_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Yhat <code>[n]</code> the predicted class of each of the <code>n</code> data point in <code>X</code>.
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.classify.randomChance(X, Y)
Yh &lt;- predict(model, X)
</code></pre>

<hr>
<h2 id='predict.randomGuess'>Randomly Guessing Classifier Prediction</h2><span id='topic+predict.randomGuess'></span>

<h3>Description</h3>

<p>A function that predicts by randomly guessing based on the pmf of the class priors. Functionality consistent
with the standard R prediction interface so that one can compute the &quot;guess&quot; accuracy
with minimal modification of other classification scripts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'randomGuess'
predict(object, X, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.randomGuess_+3A_object">object</code></td>
<td>
<p>An object of class <code>randomGuess</code>, with the following attributes:
</p>

<ul>
<li><p>ylabs<code>[K]</code> the ylabels for each of the <code>K</code> unique classes, ordered.
</p>
</li>
<li><p>priors<code>[K]</code> the priors for each of the <code>K</code> classes.
</p>
</li></ul>
</td></tr>
<tr><td><code id="predict.randomGuess_+3A_x">X</code></td>
<td>
<p><code>[n, d]</code> the data to classify with <code>n</code> samples in <code>d</code> dimensions.</p>
</td></tr>
<tr><td><code id="predict.randomGuess_+3A_...">...</code></td>
<td>
<p>optional args.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Yhat <code>[n]</code> the predicted class of each of the <code>n</code> data point in <code>X</code>.
</p>


<h3>Author(s)</h3>

<p>Eric Bridgeford
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lolR)
data &lt;- lol.sims.rtrunk(n=200, d=30)  # 200 examples of 30 dimensions
X &lt;- data$X; Y &lt;- data$Y
model &lt;- lol.classify.randomGuess(X, Y)
Yh &lt;- predict(model, X)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
