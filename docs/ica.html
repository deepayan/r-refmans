<!DOCTYPE html><html><head><title>Help for package ica</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ica}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#acy'>
<p>Amari-Cichocki-Yang Error</p></a></li>
<li><a href='#ica'>
<p>ICA via FastICA, Infomax, or JADE</p></a></li>
<li><a href='#ica-internal'><p>Internal Functions for ica Package</p></a></li>
<li><a href='#icafast'>
<p>ICA via FastICA Algorithm</p></a></li>
<li><a href='#icaimax'>
<p>ICA via Infomax Algorithm</p></a></li>
<li><a href='#icajade'>
<p>ICA via JADE Algorithm</p></a></li>
<li><a href='#icaplot'>
<p>Plot Densities of Source Signal Distributions</p></a></li>
<li><a href='#icasamp'>
<p>Sample from Various Source Signal Distributions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Independent Component Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-07-08</td>
</tr>
<tr>
<td>Author:</td>
<td>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Independent Component Analysis (ICA) using various algorithms: FastICA, Information-Maximization (Infomax), and Joint Approximate Diagonalization of Eigenmatrices (JADE).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-08 16:45:10 UTC; nate</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-08 17:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='acy'>
Amari-Cichocki-Yang Error
</h2><span id='topic+acy'></span>

<h3>Description</h3>

<p>The Amari-Cichocki-Yang (ACY) error is an asymmetric measure of dissimilarity between two nonsingular matrices <code>X</code> and <code>Y</code>. The ACY error: (a) is invariant to permutation and rescaling of the columns of <code>X</code> and <code>Y</code>, (b) ranges between 0 and <code>n-1</code>, and (c) equals 0 if and only if <code>X</code> and <code>Y</code> are identical up to column permutations and rescalings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acy(X,Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acy_+3A_x">X</code></td>
<td>

<p>Nonsingular matrix of dimension <code class="reqn">n \times n</code> (test matrix).
</p>
</td></tr>
<tr><td><code id="acy_+3A_y">Y</code></td>
<td>

<p>Nonsingular matrix of dimension <code class="reqn">n \times n</code> (target matrix).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ACY error is defined as </p>
<p style="text-align: center;"><code class="reqn">\frac{1}{2n}\sum_{i=1}^{n}\left(\frac{\sum_{j=1}^{n}|a_{ij}|}{\max_{j}|a_{ij}|}-1\right) + \frac{1}{2n}\sum_{j=1}^{n}\left(\frac{\sum_{i=1}^{n}|a_{ij}|}{\max_{i}|a_{ij}|}-1\right)  </code>
</p>

<p>where <code class="reqn">a_{ij} = (\mathbf{Y}^{-1}\mathbf{X})_{ij}</code>. 
</p>


<h3>Value</h3>

<p>Returns a scalar (the ACY error).
</p>


<h3>Warnings </h3>

<p>If <code>Y</code> is singular, function will produce an error.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Amari, S., Cichocki, A., &amp; Yang, H.H. (1996). A new learning algorithm for blind signal separation. In D. S. Touretzky, M. C. Mozer, and M. E. Hasselmo (Eds.), <em>Advances in Neural Information Processing Systems, 8</em>. Cambridge, MA: MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE   ##########

set.seed(1)
X &lt;- matrix(runif(16),4,4)
Y &lt;- matrix(runif(16),4,4)
Z &lt;- X[,c(3,1,2,4)]%*%diag(1:4)
acy(X,Y)
acy(X,Z)

</code></pre>

<hr>
<h2 id='ica'>
ICA via FastICA, Infomax, or JADE
</h2><span id='topic+ica'></span>

<h3>Description</h3>

<p>Computes ICA decomposition using Hyvarinen's (1999) FastICA algorithm, Bell and Sejnowski's (1995) Information-Maximization (Infomax) algorithm, or Cardoso and Souloumiac's (1993, 1996) Joint Approximate Diagonalization of Eigenmatrices (JADE) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ica(X, nc, method = c("fast", "imax", "jade"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ica_+3A_x">X</code></td>
<td>

<p>Data matrix with <code>n</code> rows (samples) and <code>p</code> columns (variables).
</p>
</td></tr>
<tr><td><code id="ica_+3A_nc">nc</code></td>
<td>

<p>Number of components to extract.  
</p>
</td></tr>
<tr><td><code id="ica_+3A_method">method</code></td>
<td>

<p>Method for decomposition.  
</p>
</td></tr>
<tr><td><code id="ica_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to other ICA functions (see Details).  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>ICA Model</b>
The ICA model can be written as <code>X = tcrossprod(S, M) + E</code>, where <code>S</code> contains the source signals, <code>M</code> is the mixing matrix, and <code>E</code> contains the noise signals. Columns of <code>X</code> are assumed to have zero mean. The goal is to find the unmixing matrix <code>W</code> such that columns of <code>S = tcrossprod(X, W)</code> are independent as possible.
</p>
<p><b>Whitening</b>
Without loss of generality, we can write <code>M = P %*% R</code> where <code>P</code> is a tall matrix and <code>R</code> is an orthogonal rotation matrix. Letting <code>Q</code> denote the pseudoinverse of <code>P</code>, we can whiten the data using <code>Y = tcrossprod(X, Q)</code>. The goal is to find the orthongal rotation matrix <code>R</code> such that the source signal estimates <code>S = Y %*% R</code> are as independent as possible. Note that <code>W = crossprod(R, Q)</code>.
</p>
<p><b>Method</b>
This is a wrapper function for the functions <code><a href="#topic+icafast">icafast</a></code>, <code><a href="#topic+icaimax">icaimax</a></code>, or <code><a href="#topic+icajade">icajade</a></code>. See the corresponding function for details on the method, as well as the available arguments (handled by the <code>...</code> argument).
</p>


<h3>Value</h3>

<table>
<tr><td><code>S</code></td>
<td>
<p>Matrix of source signal estimates (<code>S = Y %*% R</code>).</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Estimated mixing matrix.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Estimated unmixing matrix (<code>W = crossprod(R, Q)</code>).</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>Whitened data matrix.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>Whitening matrix.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Orthogonal rotation matrix.</p>
</td></tr>
<tr><td><code>vafs</code></td>
<td>
<p>Variance-accounted-for by each component.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of algorithm iterations.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Logical indicating if algorithm converged.</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Other arguments (if <code>method = "fast"</code> or <code>method = "imax"</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Bell, A.J. &amp; Sejnowski, T.J. (1995). An information-maximization approach to blind separation and blind deconvolution. <em>Neural Computation, 7</em>(6), 1129-1159. <a href="https://doi.org/10.1162/neco.1995.7.6.1129">doi:10.1162/neco.1995.7.6.1129</a>
</p>
<p>Cardoso, J.F., &amp; Souloumiac, A. (1993). Blind beamforming for non-Gaussian signals. <em>IEE Proceedings-F, 140</em>(6), 362-370. <a href="https://doi.org/10.1049/ip-f-2.1993.0054">doi:10.1049/ip-f-2.1993.0054</a>
</p>
<p>Cardoso, J.F., &amp; Souloumiac, A. (1996). Jacobi angles for simultaneous diagonalization. <em>SIAM Journal on Matrix Analysis and Applications, 17</em>(1), 161-164. <a href="https://doi.org/10.1137/S0895479893259546">doi:10.1137/S0895479893259546</a>
</p>
<p>Helwig, N.E. &amp; Hong, S. (2013). A critique of Tensor Probabilistic Independent Component Analysis: Implications and recommendations for multi-subject fMRI data analysis. <em>Journal of Neuroscience Methods, 213</em>(2), 263-273. <a href="https://doi.org/10.1016/j.jneumeth.2012.12.009">doi:10.1016/j.jneumeth.2012.12.009</a>
</p>
<p>Hyvarinen, A. (1999). Fast and robust fixed-point algorithms for independent component analysis. <em>IEEE Transactions on Neural Networks, 10</em>(3), 626-634. <a href="https://doi.org/10.1109/72.761722">doi:10.1109/72.761722</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+icafast">icafast</a></code> for ICA via FastICA
</p>
<p><code><a href="#topic+icaimax">icaimax</a></code> for ICA via Infomax
</p>
<p><code><a href="#topic+icajade">icajade</a></code> for ICA via JADE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE 1   ##########

# generate noiseless data (p == r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(4), nrow = 2, ncol = 2)
Xmat &lt;- tcrossprod(Amat, Bmat)

# ICA via different algorithms
imod.fast &lt;- ica(Xmat, nc = 2)
imod.imax &lt;- ica(Xmat, nc = 2, method = "imax")
imod.jade &lt;- ica(Xmat, nc = 2, method = "jade")

# compare mixing matrix recovery
acy(Bmat, imod.fast$M)
acy(Bmat, imod.imax$M)
acy(Bmat, imod.jade$M)

# compare source signal recovery
cor(Amat, imod.fast$S)
cor(Amat, imod.imax$S)
cor(Amat, imod.jade$S)


##########   EXAMPLE 2   ##########

# generate noiseless data (p != r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(200), nrow = 100, ncol = 2)
Xmat &lt;- tcrossprod(Amat, Bmat)

# ICA via different algorithms
imod.fast &lt;- ica(Xmat, nc = 2)
imod.imax &lt;- ica(Xmat, nc = 2, method = "imax")
imod.jade &lt;- ica(Xmat, nc = 2, method = "jade")

# compare source signal recovery
cor(Amat, imod.fast$S)
cor(Amat, imod.imax$S)
cor(Amat, imod.jade$S)


##########   EXAMPLE 3   ##########

# generate noisy data (p != r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(200), 100, 2)
Emat &lt;- matrix(rnorm(10^5), nrow = 1000, ncol = 100)
Xmat &lt;- tcrossprod(Amat,Bmat) + Emat

# ICA via different algorithms
imod.fast &lt;- ica(Xmat, nc = 2)
imod.imax &lt;- ica(Xmat, nc = 2, method = "imax")
imod.jade &lt;- ica(Xmat, nc = 2, method = "jade")

# compare source signal recovery
cor(Amat, imod.fast$S)
cor(Amat, imod.imax$S)
cor(Amat, imod.jade$S)

</code></pre>

<hr>
<h2 id='ica-internal'>Internal Functions for ica Package</h2><span id='topic+sdiag'></span><span id='topic+print.icafast'></span><span id='topic+print.icaimax'></span><span id='topic+print.icajade'></span>

<h3>Description</h3>

<p>Internal functions for ica package.
</p>


<h3>Details</h3>

<p>These functions are not to be called by the user.
</p>

<hr>
<h2 id='icafast'>
ICA via FastICA Algorithm
</h2><span id='topic+icafast'></span>

<h3>Description</h3>

<p>Computes ICA decomposition using Hyvarinen's (1999) FastICA algorithm with various options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icafast(X, nc, center = TRUE, maxit = 100, tol = 1e-6, Rmat = diag(nc), 
        alg = "par", fun = "logcosh", alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icafast_+3A_x">X</code></td>
<td>

<p>Data matrix with <code>n</code> rows (samples) and <code>p</code> columns (variables).
</p>
</td></tr>
<tr><td><code id="icafast_+3A_nc">nc</code></td>
<td>

<p>Number of components to extract.
</p>
</td></tr>
<tr><td><code id="icafast_+3A_center">center</code></td>
<td>

<p>If <code>TRUE</code>, columns of <code>X</code> are mean-centered before ICA decomposition.
</p>
</td></tr>
<tr><td><code id="icafast_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of algorithm iterations to allow.
</p>
</td></tr>
<tr><td><code id="icafast_+3A_tol">tol</code></td>
<td>

<p>Convergence tolerance.
</p>
</td></tr>
<tr><td><code id="icafast_+3A_rmat">Rmat</code></td>
<td>

<p>Initial estimate of the <code>nc</code>-by-<code>nc</code> orthogonal rotation matrix.
</p>
</td></tr>
<tr><td><code id="icafast_+3A_alg">alg</code></td>
<td>

<p>Algorithm to use: <code>alg="par"</code> to estimate all <code>nc</code> components in parallel (default) or <code>alg="def"</code> for deflation estimation (i.e., projection pursuit).
</p>
</td></tr>
<tr><td><code id="icafast_+3A_fun">fun</code></td>
<td>

<p>Contrast function to use for negentropy approximation: <code>fun="logcosh"</code> for log of hyperbolic cosine, <code>fun="exp"</code> for Gaussian kernel, and <code>fun="kur"</code> for kurtosis.  
</p>
</td></tr>
<tr><td><code id="icafast_+3A_alpha">alpha</code></td>
<td>

<p>Tuning parameter for &quot;logcosh&quot; contrast function (1 &lt;= <code>alpha</code> &lt;= 2).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>ICA Model</b>
The ICA model can be written as <code>X = tcrossprod(S, M) + E</code>, where <code>S</code> contains the source signals, <code>M</code> is the mixing matrix, and <code>E</code> contains the noise signals. Columns of <code>X</code> are assumed to have zero mean. The goal is to find the unmixing matrix <code>W</code> such that columns of <code>S = tcrossprod(X, W)</code> are independent as possible.
</p>
<p><b>Whitening</b>
Without loss of generality, we can write <code>M = P %*% R</code> where <code>P</code> is a tall matrix and <code>R</code> is an orthogonal rotation matrix. Letting <code>Q</code> denote the pseudoinverse of <code>P</code>, we can whiten the data using <code>Y = tcrossprod(X, Q)</code>. The goal is to find the orthongal rotation matrix <code>R</code> such that the source signal estimates <code>S = Y %*% R</code> are as independent as possible. Note that <code>W = crossprod(R, Q)</code>.
</p>
<p><b>FastICA</b>
The FastICA algorithm finds the orthogonal rotation matrix <code>R</code> that (approximately) maximizes the negentropy of the estimated source signals. Negentropy is approximated using </p>
<p style="text-align: center;"><code class="reqn">J(s) = [ E(G(s)) - E(G(z)) ]^2</code>
</p>
<p> where <em>E</em> denotes the expectation, <em>G</em> is the contrast function, and <em>z</em> is a standard normal variable. See Hyvarinen (1999) or Helwig and Hong (2013) for specifics of fixed-point algorithm.
</p>


<h3>Value</h3>

<table>
<tr><td><code>S</code></td>
<td>
<p>Matrix of source signal estimates (<code>S = Y %*% R</code>).</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Estimated mixing matrix.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Estimated unmixing matrix (<code>W = crossprod(R, Q)</code>).</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>Whitened data matrix.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>Whitening matrix.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Orthogonal rotation matrix.</p>
</td></tr>
<tr><td><code>vafs</code></td>
<td>
<p>Variance-accounted-for by each component.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of algorithm iterations.</p>
</td></tr>
<tr><td><code>alg</code></td>
<td>
<p>Algorithm used (same as input).</p>
</td></tr>
<tr><td><code>fun</code></td>
<td>
<p>Contrast function (same as input).</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Tuning parameter (same as input).</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Logical indicating if algorithm converged.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N.E. &amp; Hong, S. (2013). A critique of Tensor Probabilistic Independent Component Analysis: Implications and recommendations for multi-subject fMRI data analysis. <em>Journal of Neuroscience Methods, 213</em>(2), 263-273. <a href="https://doi.org/10.1016/j.jneumeth.2012.12.009">doi:10.1016/j.jneumeth.2012.12.009</a>
</p>
<p>Hyvarinen, A. (1999). Fast and robust fixed-point algorithms for independent component analysis. <em>IEEE Transactions on Neural Networks, 10</em>(3), 626-634. <a href="https://doi.org/10.1109/72.761722">doi:10.1109/72.761722</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+icaimax">icaimax</a></code> for ICA via Infomax
</p>
<p><code><a href="#topic+icajade">icajade</a></code> for ICA via JADE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE 1   ##########

# generate noiseless data (p == r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(4), nrow = 2, ncol = 2)
Xmat &lt;- tcrossprod(Amat, Bmat)

# ICA via FastICA with 2 components
imod &lt;- icafast(Xmat, nc = 2)
acy(Bmat, imod$M)
cor(Amat, imod$S)



##########   EXAMPLE 2   ##########

# generate noiseless data (p != r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(200), nrow = 100, ncol = 2)
Xmat &lt;- tcrossprod(Amat, Bmat)

# ICA via FastICA with 2 components
imod &lt;- icafast(Xmat, nc = 2)
cor(Amat, imod$S)



##########   EXAMPLE 3   ##########

# generate noisy data (p != r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(200), 100, 2)
Emat &lt;- matrix(rnorm(10^5), nrow = 1000, ncol = 100)
Xmat &lt;- tcrossprod(Amat,Bmat) + Emat

# ICA via FastICA with 2 components
imod &lt;- icafast(Xmat, nc = 2)
cor(Amat, imod$S)

</code></pre>

<hr>
<h2 id='icaimax'>
ICA via Infomax Algorithm
</h2><span id='topic+icaimax'></span>

<h3>Description</h3>

<p>Computes ICA decomposition using Bell and Sejnowski's (1995) Information-Maximization (Infomax) approach with various options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icaimax(X, nc, center = TRUE, maxit = 100, tol = 1e-6, Rmat = diag(nc), 
        alg = "newton", fun = "tanh", signs = rep(1, nc), signswitch = TRUE, 
        rate = 1, rateanneal = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icaimax_+3A_x">X</code></td>
<td>

<p>Data matrix with <code>n</code> rows (samples) and <code>p</code> columns (variables).
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_nc">nc</code></td>
<td>

<p>Number of components to extract.
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_center">center</code></td>
<td>

<p>If <code>TRUE</code>, columns of <code>X</code> are mean-centered before ICA decomposition.
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of algorithm iterations to allow.
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_tol">tol</code></td>
<td>

<p>Convergence tolerance.
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_rmat">Rmat</code></td>
<td>

<p>Initial estimate of the <code>nc</code>-by-<code>nc</code> orthogonal rotation matrix.
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_alg">alg</code></td>
<td>

<p>Algorithm to use: <code>alg="newton"</code> for Newton iteration, and <code>alg="gradient"</code> for gradient descent.
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_fun">fun</code></td>
<td>

<p>Nonlinear (squashing) function to use for algorithm: <code>fun="tanh"</code> for hyperbolic tangent, <code>fun="log"</code> for logistic, and <code>fun="ext"</code> for extended Infomax.  
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_signs">signs</code></td>
<td>

<p>Vector of length <code>nc</code> such that <code>signs[j] = 1</code> if j-th component is super-Gaussian and <code>signs[j] = -1</code> if j-th component is sub-Gaussian. Only used if <code>fun="ext"</code>. Ignored if <code>signswitch=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_signswitch">signswitch</code></td>
<td>

<p>If <code>TRUE</code>, the <code>signs</code> vector is automatically determined from the data; otherwise a confirmatory ICA decomposition is calculated using input <code>signs</code> vector. Only used if <code>fun="ext"</code>.
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_rate">rate</code></td>
<td>

<p>Learing rate for gradient descent algorithm. Ignored if <code>alg="newton"</code>.  
</p>
</td></tr>
<tr><td><code id="icaimax_+3A_rateanneal">rateanneal</code></td>
<td>

<p>Annealing angle and proportion for gradient descent learing rate (see Details). Ignored if <code>alg="newton"</code>.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>ICA Model</b>
The ICA model can be written as <code>X = tcrossprod(S, M) + E</code>, where <code>S</code> contains the source signals, <code>M</code> is the mixing matrix, and <code>E</code> contains the noise signals. Columns of <code>X</code> are assumed to have zero mean. The goal is to find the unmixing matrix <code>W</code> such that columns of <code>S = tcrossprod(X, W)</code> are independent as possible.
</p>
<p><b>Whitening</b>
Without loss of generality, we can write <code>M = P %*% R</code> where <code>P</code> is a tall matrix and <code>R</code> is an orthogonal rotation matrix. Letting <code>Q</code> denote the pseudoinverse of <code>P</code>, we can whiten the data using <code>Y = tcrossprod(X, Q)</code>. The goal is to find the orthongal rotation matrix <code>R</code> such that the source signal estimates <code>S = Y %*% R</code> are as independent as possible. Note that <code>W = crossprod(R, Q)</code>.
</p>
<p><b>Infomax</b>
The Infomax approach finds the orthogonal rotation matrix <code>R</code> that (approximately) maximizes the joint entropy of a nonlinear function of the estimated source signals. See Bell and Sejnowski (1995) and Helwig and Hong (2013) for specifics of algorithms.
</p>


<h3>Value</h3>

<table>
<tr><td><code>S</code></td>
<td>
<p>Matrix of source signal estimates (<code>S = Y %*% R</code>).</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Estimated mixing matrix.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Estimated unmixing matrix (<code>W = crossprod(R, Q)</code>).</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>Whitened data matrix.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>Whitening matrix.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Orthogonal rotation matrix.</p>
</td></tr>
<tr><td><code>vafs</code></td>
<td>
<p>Variance-accounted-for by each component.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of algorithm iterations.</p>
</td></tr>
<tr><td><code>alg</code></td>
<td>
<p>Algorithm used (same as input).</p>
</td></tr>
<tr><td><code>fun</code></td>
<td>
<p>Contrast function (same as input).</p>
</td></tr>
<tr><td><code>signs</code></td>
<td>
<p>Component signs (same as input).</p>
</td></tr>
<tr><td><code>rate</code></td>
<td>
<p>Learning rate (same as input).</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Logical indicating if algorithm converged.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Bell, A.J. &amp; Sejnowski, T.J. (1995). An information-maximization approach to blind separation and blind deconvolution. <em>Neural Computation, 7</em>(6), 1129-1159. <a href="https://doi.org/10.1162/neco.1995.7.6.1129">doi:10.1162/neco.1995.7.6.1129</a>
</p>
<p>Helwig, N.E. &amp; Hong, S. (2013). A critique of Tensor Probabilistic Independent Component Analysis: Implications and recommendations for multi-subject fMRI data analysis. <em>Journal of Neuroscience Methods, 213</em>(2), 263-273. <a href="https://doi.org/10.1016/j.jneumeth.2012.12.009">doi:10.1016/j.jneumeth.2012.12.009</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+icafast">icafast</a></code> for FastICA
</p>
<p><code><a href="#topic+icajade">icajade</a></code> for ICA via JADE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE 1   ##########

# generate noiseless data (p == r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(4), nrow = 2, ncol = 2)
Xmat &lt;- tcrossprod(Amat, Bmat)

# ICA via Infomax with 2 components
imod &lt;- icaimax(Xmat, nc = 2)
acy(Bmat, imod$M)
cor(Amat, imod$S)



##########   EXAMPLE 2   ##########

# generate noiseless data (p != r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(200), nrow = 100, ncol = 2)
Xmat &lt;- tcrossprod(Amat, Bmat)

# ICA via Infomax with 2 components
imod &lt;- icaimax(Xmat, nc = 2)
cor(Amat, imod$S)



##########   EXAMPLE 3   ##########

# generate noisy data (p != r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(200), 100, 2)
Emat &lt;- matrix(rnorm(10^5), nrow = 1000, ncol = 100)
Xmat &lt;- tcrossprod(Amat,Bmat) + Emat

# ICA via Infomax with 2 components
imod &lt;- icaimax(Xmat, nc = 2)
cor(Amat, imod$S)

</code></pre>

<hr>
<h2 id='icajade'>
ICA via JADE Algorithm
</h2><span id='topic+icajade'></span>

<h3>Description</h3>

<p>Computes ICA decomposition using Cardoso and Souloumiac's (1993, 1996) Joint Approximate Diagonalization of Eigenmatrices (JADE) approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icajade(X, nc, center = TRUE, maxit = 100, tol = 1e-6, Rmat = diag(nc))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icajade_+3A_x">X</code></td>
<td>

<p>Data matrix with <code>n</code> rows (samples) and <code>p</code> columns (variables).
</p>
</td></tr>
<tr><td><code id="icajade_+3A_nc">nc</code></td>
<td>

<p>Number of components to extract.
</p>
</td></tr>
<tr><td><code id="icajade_+3A_center">center</code></td>
<td>

<p>If <code>TRUE</code>, columns of <code>X</code> are mean-centered before ICA decomposition.
</p>
</td></tr>
<tr><td><code id="icajade_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of algorithm iterations to allow.
</p>
</td></tr>
<tr><td><code id="icajade_+3A_tol">tol</code></td>
<td>

<p>Convergence tolerance.
</p>
</td></tr>
<tr><td><code id="icajade_+3A_rmat">Rmat</code></td>
<td>

<p>Initial estimate of the <code>nc</code>-by-<code>nc</code> orthogonal rotation matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>ICA Model</b>
The ICA model can be written as <code>X = tcrossprod(S, M) + E</code>, where <code>S</code> contains the source signals, <code>M</code> is the mixing matrix, and <code>E</code> contains the noise signals. Columns of <code>X</code> are assumed to have zero mean. The goal is to find the unmixing matrix <code>W</code> such that columns of <code>S = tcrossprod(X, W)</code> are independent as possible.
</p>
<p><b>Whitening</b>
Without loss of generality, we can write <code>M = P %*% R</code> where <code>P</code> is a tall matrix and <code>R</code> is an orthogonal rotation matrix. Letting <code>Q</code> denote the pseudoinverse of <code>P</code>, we can whiten the data using <code>Y = tcrossprod(X, Q)</code>. The goal is to find the orthongal rotation matrix <code>R</code> such that the source signal estimates <code>S = Y %*% R</code> are as independent as possible. Note that <code>W = crossprod(R, Q)</code>.
</p>
<p><b>JADE</b>
The JADE approach finds the orthogonal rotation matrix <code>R</code> that (approximately) diagonalizes the cumulant array of the source signals. See Cardoso and Souloumiac (1993,1996) and Helwig and Hong (2013) for specifics of the JADE algorithm.
</p>


<h3>Value</h3>

<table>
<tr><td><code>S</code></td>
<td>
<p>Matrix of source signal estimates (<code>S = Y %*% R</code>).</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Estimated mixing matrix.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Estimated unmixing matrix (<code>W = crossprod(R, Q)</code>).</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>Whitened data matrix.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>Whitening matrix.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Orthogonal rotation matrix.</p>
</td></tr>
<tr><td><code>vafs</code></td>
<td>
<p>Variance-accounted-for by each component.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of algorithm iterations.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Logical indicating if algorithm converged.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Cardoso, J.F., &amp; Souloumiac, A. (1993). Blind beamforming for non-Gaussian signals. <em>IEE Proceedings-F, 140</em>(6), 362-370. <a href="https://doi.org/10.1049/ip-f-2.1993.0054">doi:10.1049/ip-f-2.1993.0054</a>
</p>
<p>Cardoso, J.F., &amp; Souloumiac, A. (1996). Jacobi angles for simultaneous diagonalization. <em>SIAM Journal on Matrix Analysis and Applications, 17</em>(1), 161-164. <a href="https://doi.org/10.1137/S0895479893259546">doi:10.1137/S0895479893259546</a>
</p>
<p>Helwig, N.E. &amp; Hong, S. (2013). A critique of Tensor Probabilistic Independent Component Analysis: Implications and recommendations for multi-subject fMRI data analysis. <em>Journal of Neuroscience Methods, 213</em>(2), 263-273. <a href="https://doi.org/10.1016/j.jneumeth.2012.12.009">doi:10.1016/j.jneumeth.2012.12.009</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+icafast">icafast</a></code> for FastICA
</p>
<p><code><a href="#topic+icaimax">icaimax</a></code> for ICA via Infomax
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE 1   ##########

# generate noiseless data (p == r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(4), nrow = 2, ncol = 2)
Xmat &lt;- tcrossprod(Amat, Bmat)

# ICA via JADE with 2 components
imod &lt;- icajade(Xmat, nc = 2)
acy(Bmat, imod$M)
cor(Amat, imod$S)



##########   EXAMPLE 2   ##########

# generate noiseless data (p != r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(200), nrow = 100, ncol = 2)
Xmat &lt;- tcrossprod(Amat, Bmat)

# ICA via JADE with 2 components
imod &lt;- icajade(Xmat, nc = 2)
cor(Amat, imod$S)



##########   EXAMPLE 3   ##########

# generate noisy data (p != r)
set.seed(123)
nobs &lt;- 1000
Amat &lt;- cbind(icasamp("a", "rnd", nobs), icasamp("b", "rnd", nobs))
Bmat &lt;- matrix(2 * runif(200), 100, 2)
Emat &lt;- matrix(rnorm(10^5), nrow = 1000, ncol = 100)
Xmat &lt;- tcrossprod(Amat,Bmat) + Emat

# ICA via JADE with 2 components
imod &lt;- icajade(Xmat, nc = 2)
cor(Amat, imod$S)

</code></pre>

<hr>
<h2 id='icaplot'>
Plot Densities of Source Signal Distributions
</h2><span id='topic+icaplot'></span>

<h3>Description</h3>

<p>Plot density (pdf) and kurtosis for the 18 source signal distributions used in Bach and Jordan (2002); see <code><a href="#topic+icasamp">icasamp</a></code> for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icaplot(xseq = seq(-2,2,length.out=500),
        xlab = "", ylab = "", lty = 1, 
        lwd = 1, col = "black", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icaplot_+3A_xseq">xseq</code></td>
<td>

<p>Sequence of ordered data values for plotting density.
</p>
</td></tr>
<tr><td><code id="icaplot_+3A_xlab">xlab</code></td>
<td>

<p>X-axis label for plot (default is no label).
</p>
</td></tr>
<tr><td><code id="icaplot_+3A_ylab">ylab</code></td>
<td>

<p>Y-axis label for plot (default is no label).
</p>
</td></tr>
<tr><td><code id="icaplot_+3A_lty">lty</code></td>
<td>

<p>Line type for each density (scalar or vector of length 18).
</p>
</td></tr>
<tr><td><code id="icaplot_+3A_lwd">lwd</code></td>
<td>

<p>Line width for each density (scalar or vector of length 18).
</p>
</td></tr>
<tr><td><code id="icaplot_+3A_col">col</code></td>
<td>

<p>Line color for each density (scalar or vector of length 18).
</p>
</td></tr>
<tr><td><code id="icaplot_+3A_...">...</code></td>
<td>

<p>Optional inputs for <code>plot</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Produces a plot with <code>NULL</code> return value.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Bach, F.R. (2002). <em>kernel-ica</em>. MATLAB toolbox (ver 1.2) http://www.di.ens.fr/~fbach/kernel-ica/.
</p>
<p>Bach, F.R. &amp; Jordan, M.I. (2002). Kernel independent component analysis. <em>Journal of Machine Learning Research, 3</em>, 1-48.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
##########   EXAMPLE   ##########

quartz(height=9,width=7)
par(mar=c(3,3,3,3))
icaplot()

## End(Not run)

</code></pre>

<hr>
<h2 id='icasamp'>
Sample from Various Source Signal Distributions
</h2><span id='topic+icasamp'></span>

<h3>Description</h3>

<p>Sample observations from the 18 source signal distributions used in Bach and Jordan (2002). Can also return density values and kurtosis for each distribution. Use <code><a href="#topic+icaplot">icaplot</a></code> to plot distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icasamp(dname, query = c("rnd","pdf","kur"),
        nsamp = NULL, data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icasamp_+3A_dname">dname</code></td>
<td>

<p>Distribution name: letter &quot;a&quot; through &quot;r&quot; (see Bach &amp; Jordan, 2002).
</p>
</td></tr>
<tr><td><code id="icasamp_+3A_query">query</code></td>
<td>

<p>What to return: <code>query="rnd"</code> for random sample, <code>query="pdf"</code> for density values, and <code>query="kur"</code> for kurtosis.
</p>
</td></tr>
<tr><td><code id="icasamp_+3A_nsamp">nsamp</code></td>
<td>

<p>Number of observations to sample. Only used if <code>query="rnd"</code>.
</p>
</td></tr>
<tr><td><code id="icasamp_+3A_data">data</code></td>
<td>

<p>Data values for density evaluation. Only used if <code>query="pdf"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inspired by <code>usr_distrib.m</code> from Bach's (2002) <code>kernel-ica</code> MATLAB toolbox.
</p>


<h3>Value</h3>

<p>If <code>query="rnd"</code>, returns random sample of size <code>nsamp</code>.
</p>
<p>If <code>query="pdf"</code>, returns density for input <code>data</code>.
</p>
<p>If <code>query="kur"</code>, returns kurtosis of distribution.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Bach, F.R. (2002). <em>kernel-ica</em>. MATLAB toolbox (ver 1.2) http://www.di.ens.fr/~fbach/kernel-ica/.
</p>
<p>Bach, F.R. &amp; Jordan, M.I. (2002). Kernel independent component analysis. <em>Journal of Machine Learning Research, 3</em>, 1-48.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE   ##########

# sample 1000 observations from distribution "f"
set.seed(123)
mysamp &lt;- icasamp("f","rnd",nsamp=1000)
xr &lt;- range(mysamp)
hist(mysamp,freq=FALSE,ylim=c(0,.8),breaks=sqrt(1000))

# evaluate density of distribution "f"
xseq &lt;- seq(-5,5,length.out=1000)
mypdf &lt;- icasamp("f","pdf",data=xseq)
lines(xseq,mypdf)

# evaluate kurtosis of distribution "f"
icasamp("f","kur")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
