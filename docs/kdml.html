<!DOCTYPE html><html lang="en"><head><title>Help for package kdml</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kdml}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#kdml'><p>Kernel Metric Learning for Mixed-type Data</p></a></li>
<li><a href='#confactord'>
<p>Mixed-type Data Generation with True Membership Labels</p></a></li>
<li><a href='#dkps'>
<p>Distance using Kernel Product Similarity (DKPS) for Mixed-type Data</p></a></li>
<li><a href='#dkss'>
<p>Distance using Kernel Summation Similarity (DKSS) for Mixed-type Data</p></a></li>
<li><a href='#kss'>
<p>Kernel Summation Similarity Function (KSS) for Mixed-type Data</p></a></li>
<li><a href='#mscv.dkps'>
<p>Maximum-similarity Cross-validated (MSCV) bandwidth selection method for the</p>
Distance using Kernel Product Similarities (DKPS)</a></li>
<li><a href='#mscv.dkss'>
<p>Maximum-similarity Cross-validated (MSCV) bandwidth selection method for the</p>
distance using kernel summation similarity (DKSS)</a></li>
<li><a href='#spectral.clust'>
<p>Spectral Clustering using Similarity or Distance Matrices</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Kernel Distance Metric Learning for Mixed-Type Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>John R. J. Thompson &lt;john.thompson@ubc.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Distance metrics for mixed-type data consisting of continuous, nominal, and ordinal variables. This methodology uses additive and product kernels to calculate similarity functions and metrics, and selects variables relevant to the underlying distance through bandwidth selection via maximum similarity cross-validation. These methods can be used in any distance-based algorithm, such as distance-based clustering. For further details, we refer the reader to Ghashti and Thompson (2024) &lt;<a href="https://doi.org/10.1007%2Fs00357-024-09493-z">doi:10.1007/s00357-024-09493-z</a>&gt; for dkps() methodology, and Ghashti (2024) &lt;<a href="https://doi.org/10.14288%2F1.0443975">doi:10.14288/1.0443975</a>&gt; for dkss() methodology.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), np</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, markdown</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-21 00:09:41 UTC; Mango</td>
</tr>
<tr>
<td>Author:</td>
<td>John R. J. Thompson
    <a href="https://orcid.org/0000-0002-6303-449X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Jesse S. Ghashti <a href="https://orcid.org/0009-0001-6645-1766"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-21 00:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='kdml'>Kernel Metric Learning for Mixed-type Data</h2><span id='topic+kdml'></span><span id='topic+kdml-package'></span>

<h3>Description</h3>

<p>This package contains nonparametric kernel methods for calculating pairwise 
distances between mixed-type observations. These methods can be used in any 
distance based algorithm, with emphasis placed on usage in clustering or 
classification applications. Descriptions of the implementation of these methods
can be found in Ghashti (2024) and Ghashti and Thompson (2024).
</p>


<h3>Details</h3>

<p>This package contains two functions for pairwise distance calculations of 
mixed-type data based on two different methods. Kernel methods also require 
variable-specific bandwidths, with two additional functions for the bandwidth 
specification methods. Additionally, this package contains a function methods 
for mixed-type data generation.
</p>


<h3>Author(s)</h3>

<p>John R.J. Thompson &lt;john.thompson@ubc.ca&gt;, Jesse S. Ghashti 
&lt;jesse.ghashti@ubc.ca&gt;
</p>
<p>Maintainer: John R.J. Thompson &lt;john.thompson@ubc.ca&gt;
</p>
<p>We would like to acknowledge funding support from the University of British 
Columbia Aspire Fund (UBC:www.ok.ubc.ca/). We also acknowledge support from 
the Natural Sciences and Engineering Research Council of Canada (NSERC). 
</p>


<h3>References</h3>

<p>Ghashti, J.S. (2024), &ldquo;Similarity Maximization and Shrinkage Approach 
in Kernel Metric Learning for Clustering Mixed-type Data (T)&rdquo;, University 
of British Columbia. &lt;https://dx.doi.org/10.14288/1.044397&gt;
</p>
<p>Ghashti, J.S. and J.R.J Thompson (2024), &ldquo;Mixed-type Distance 
Shrinkage and Selection for Clustering via Kernel Metric Learning&rdquo;. 
Journal of Classification, Accepted. 
</p>

<hr>
<h2 id='confactord'>
Mixed-type Data Generation with True Membership Labels
</h2><span id='topic+confactord'></span>

<h3>Description</h3>

<p>This function generates a mixed-type data frame with a combination of continuous
(<code>numeric</code>), nominal (<code>factor</code>), and  ordinal (<code>ordered</code>) 
variables with prespecified cluster overlap for each variable type. 
<code>confactord</code> allows the user to specify the number of each 
variable type, the amount of variables per variable type that have cluster 
overlap, the amount of cluster overlap for each variable type, the number of 
levels for the nominal and ordinal variables, and proportion of observations 
per class membership. Within and across-type variables are generated 
independently from one another. Currently, only two classes are may be generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confactord(n = 200, 
            popProb = c(0.5,0.5), 
            numMixVar = c(1,1,1), 
            numMixVarOl = c(1,1,1),  
            olVarType = c(0.1,0.1,0.1), 
            catLevels = c(2,4))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confactord_+3A_n">n</code></td>
<td>

<p>integer number of observations to be generated. Defaults to <code>n = 200</code>
</p>
</td></tr>
<tr><td><code id="confactord_+3A_popprob">popProb</code></td>
<td>

<p>numeric vector of length two specifying the proportion of observations 
allocated to each class membership, which must sum to one. Defaults to 
<code>popProb = c(0.5, 0.5)</code>.
</p>
</td></tr>
<tr><td><code id="confactord_+3A_nummixvar">numMixVar</code></td>
<td>

<p>numeric vector of integers of length three specifying (in order) the total 
number of continuous (numeric), nominal (factor), and ordinal (ordered) 
variables to be generated. If a specific variable type is not required, 
set the appropriate vector indice to zero. Defaults to 
<code>numMixVar = c(1,1,1)</code>.
</p>
</td></tr>
<tr><td><code id="confactord_+3A_nummixvarol">numMixVarOl</code></td>
<td>

<p>numeric vector of integers of length three specifying (in order) the total 
number of continuous (numeric), nominal (factor), and ordinal (ordered) 
variables that will have class membership overlap. If all variables are to
be well-separated by class membership, set all indices to zero. No indice 
of this vector may be greater than the corresponding indice in 
<code>numMixVar</code>. Defaults to <code>numMixVarOl = c(1,1,1)</code>.
</p>
</td></tr>
<tr><td><code id="confactord_+3A_olvartype">olVarType</code></td>
<td>

<p>numeric vector of length three specifying (in order) the percentage of class 
membership overlap to be applied to the continuous (numeric), nominal 
(factor), and ordinal (ordered) No argument required if 
<code>numMixVarOl = c(0,0,0)</code>. Permissible class membership overlap per 
variable type is between 0.01 and 0.99. Defaults to ten percent overlap per
variable type, <code>olVarType = c(0.1,0.1,0.1)</code>.
</p>
</td></tr>
<tr><td><code id="confactord_+3A_catlevels">catLevels</code></td>
<td>

<p>numeric vector of length two specifying (in order) the number of levels 
(integer values) for each of the nominal (factor) and ordinal (ordered) 
variable types. Defaults to <code>catLevels = c(2,4)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Continuous variables are generated independently from normal distributions, 
with means determined by true class membership. If overlap is specified, 
additional variance is introduced to simulate cluster overlap. Nominal 
variables are generated using Dirichlet distributions representing different 
population proportions. Ordinal variables are initially simulated as 
continuous variables and then discretized into ordered categories based on 
quantile distributions, similar to a latent class model where ordinal 
categories are inferred based on underlying continuous distributions and 
adjusted for cluster overlap parameters.
</p>


<h3>Value</h3>

<p><code>confactord</code> returns a <code>list</code> object, with the
following components:
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> of mixed variable types based on user-
specified parameters</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>a numeric vector of integers specifying the true class memberships 
for the returned <code>data</code> data frame</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John R. J. Thompson <a href="mailto:john.thompson@ubc.ca">john.thompson@ubc.ca</a>, Jesse S. Ghashti
<a href="mailto:jesse.ghashti@ubc.ca">jesse.ghashti@ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mscv.dkss">mscv.dkss</a></code>, <code><a href="#topic+mscv.dkps">mscv.dkps</a></code>, <code><a href="#topic+dkss">dkss</a></code>, 
<code><a href="#topic+dkps">dkps</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># EXAMPLE1: Default implementation generates the following
# 200 observations split into two clusters of equal size (100 observations each) 
# Three variables-- one of each numeric, factor, and ordered
# Each variable has ten percent cluster overlap
# Nominal variable is binary
# Ordinal variable has four levels

df1 &lt;- confactord()


# EXAMPLE2: 
# 500 observations; 100 observations in cluster one and 400 in cluster two 
# Three continuous variables, two nominal, one ordinal
# Only one continuous variable has cluster overlap
# All nominal and ordinal variables have cluster overlap
# Cluster overlap for continuous variable is twenty percent
# Cluster overlap for nominal variables are thirty percent
# Cluster overlap for ordinal variable is fourty percent
# Nominal variable has three levels, while ordinal has 5

df2 &lt;- confactord(n = 500, 
                    popProb = c(0.2,0.8), 
                    numMixVar = c(3,2,1), 
                    numMixVarOl = c(1,2,1),  
                    olVarType = c(0.2,0.3,0.4), 
                    catLevels = c(3,5))
</code></pre>

<hr>
<h2 id='dkps'>
Distance using Kernel Product Similarity (DKPS) for Mixed-type Data
</h2><span id='topic+dkps'></span>

<h3>Description</h3>

<p>This function calculates the pairwise distances between mixed-type observations 
consisting of numeric (continuous), factor (nominal), and ordered factor 
(ordinal) variables using the method described in Ghashti, J. S. and Thompson, 
J. R. J (2023). This kernel metric learning methodology learns the bandwidths 
associated with each kernel function for each variable type and returns a 
distance matrix that can be utilized in any distance-based clustering algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dkps(df, bw = "mscv", cFUN = "c_gaussian", uFUN = "u_aitken", 
      oFUN = "o_wangvanryzin", stan = TRUE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dkps_+3A_df">df</code></td>
<td>

<p>a <code class="reqn">p</code>-variate data frame for which the pairwise distances between 
observations will be calculated. The data types may be continuous, nominal 
(unordered factors), ordinal (ordered factors), or any combination thereof. 
Columns of <code>df</code> should be of appropriate variable type prior to running 
the function.
</p>
</td></tr>
<tr><td><code id="dkps_+3A_bw">bw</code></td>
<td>

<p>a bandwidth specification method. This can be set as a vector of <code class="reqn">p</code>-many
bandwidths, with each element <code class="reqn">i</code> corresponding to the bandwidth for 
column <code class="reqn">i</code> in <code>df</code>. Alternatively, one of two character strings may 
be inputted for bandwidth selection methods. <code>mscv</code> specifies maximum-
similarity cross-validation, and <code>np</code> specifies likelihood-cross 
validation which is calculated via <code><a href="np.html#topic+npudensbw">npudensbw</a></code> in package 
<code><a href="np.html#topic+np">np</a></code>. Defaults to <code>mscv</code>. See details.
</p>
</td></tr>
<tr><td><code id="dkps_+3A_cfun">cFUN</code></td>
<td>

<p>character string specifying the continuous kernel function. Options include 
<code>c_gaussian</code>, <code>c_epanechnikov</code>, <code>c_uniform</code>, <code>c_triangle</code>,
<code>c_biweight</code>, <code>c_triweight</code>, <code>c_tricube</code>, <code>c_cosine</code>, 
<code>c_logistic</code>, <code>c_sigmoid</code>, and <code>c_silverman</code>. Note that if 
using <code>np</code> for <code>bw</code> selection above, continuous kernel types are 
restricted to either <code>c_gaussian</code>, <code>c_epanechnikov</code>, or <code>c_uniform</code>. 
Defaults to <code>c_gaussian</code>. See details.
</p>
</td></tr>
<tr><td><code id="dkps_+3A_ufun">uFUN</code></td>
<td>

<p>character string specifying the nominal kernel function for unordered 
factors. Options include <code>u_aitken</code> and <code>u_aitchisonaitken</code>. 
Defaults to <code>u_aitken</code>. See details.
</p>
</td></tr>
<tr><td><code id="dkps_+3A_ofun">oFUN</code></td>
<td>

<p>character string specifying the ordinal kernel function for ordered factors. 
Options include <code>o_aitken</code>, <code>o_aitchisonaitken</code>, <code>o_habbema</code>, 
<code>o_wangvanryzin</code>, and <code>o_liracine</code>. Note that if using <code>np</code> 
for <code>bw</code> selection above, ordinal kernel types are restricted to either 
<code>o_wangvanryzin</code> or <code>o_liracine</code>. Defaults to <code>o_wangvanryzin</code>.
See details.
</p>
</td></tr>
<tr><td><code id="dkps_+3A_stan">stan</code></td>
<td>

<p>a logical value which specifies whether to scale the resulting distance 
matrix between 0 and 1 using min-max normalization. If set to <code>FALSE</code>, 
there is no normalization. Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="dkps_+3A_verbose">verbose</code></td>
<td>

<p>a logical value which specifies whether to print procedural steps to the 
console. If set to <code>FALSE</code>, no output is printed to the console. 
Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dkps</code> implements the distance using kernel product similarity (DKPS) as 
described by Ghashti and Thompson (2023). This approach uses product kernels 
for continuous variables, and summation kernels for nominal and ordinal data,
which are then summed over all variable types to return the pairwise distance 
between mixed-type data. 
</p>
<p>Each kernel requires a bandwidth specification, which can either be a user 
defined numeric vector of length <code class="reqn">p</code> from alternative methodologies for 
bandwidth selection, or through two bandwidth specification methods. The 
<code>mscv</code> bandwidth selection routine is based on the maximum-similarity 
cross-validation routine by Ghashti and Thompson (2023), invoked by the 
function <code><a href="#topic+mscv.dkps">mscv.dkps</a></code>. The <code>np</code> bandwidth selection routine 
follows maximum-likelihood cross-validation techniques described by Li and 
Racine (2007) and Li and Racine (2003) for kernel density estimation of 
mixed-type data. Bandwidths will differ for each variable.
</p>
<p>Data contained in the data frame <code>df</code> may constitute any combinations of 
continuous, nominal, or ordinal data, which is to be specified in the data 
frame <code>df</code> using <code><a href="base.html#topic+factor">factor</a></code> for nominal data, and <code><a href="base.html#topic+ordered">ordered</a></code> 
for ordinal data. Data can be entered in an arbitrary order and data types 
will be detected automatically. User-inputted vectors of bandwidths <code>bw</code> 
must be defined in the same order as the variables in the data frame <code>df</code>, 
as to ensure they sorted accordingly by the routine.
</p>
<p>The are many kernels which can be specified by the user. The majority of the 
continuous kernel functions may be found in Cameron and Trivedi (2005), Härdle
et al. (2004) or Silverman (1986). Nominal kernels use a variation on 
Aitchison and Aitken's (1976) kernel, while ordinal kernels use a variation 
of the Wang and van Ryzin (1981) kernel. Both nominal and ordinal kernel 
functions can be found in Li and Racine (2007), Li and Racine (2003), Ouyan et
al. (2006), and Titterington and Bowman (1985).
</p>


<h3>Value</h3>

<p><code>dkps</code> returns a <code>list</code> object, with the
following components:
</p>
<table role = "presentation">
<tr><td><code>distances</code></td>
<td>

<p>an <code class="reqn">n \times n</code> numeric matrix containing pairwise distances between 
observations
</p>
</td></tr>
<tr><td><code>bandwidths</code></td>
<td>

<p>a <code class="reqn">p</code>-variate vector of bandwidth values returned based on the <code>bw</code> 
bandwidth specification method, sorted by variable type
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John R. J. Thompson <a href="mailto:john.thompson@ubc.ca">john.thompson@ubc.ca</a>, Jesse S. Ghashti
<a href="mailto:jesse.ghashti@ubc.ca">jesse.ghashti@ubc.ca</a>
</p>


<h3>References</h3>

<p>Aitchison, J. and  C.G.G. Aitken (1976), &ldquo;Multivariate binary 
discrimination by the kernel method&rdquo;, Biometrika, 63, 413-420.
</p>
<p>Cameron, A. and P. Trivedi (2005), &ldquo;Microeconometrics: Methods and 
Applications&rdquo;, Cambridge University Press.
</p>
<p>Ghashti, J.S. and J.R.J Thompson (2023), &ldquo;Mixed-type Distance Shrinkage 
and Selection for Clustering via Kernel Metric Learning&rdquo;, arXiv preprint 
arXiv:2306.01890.
</p>
<p>Härdle, W., and M. Müller and S. Sperlich and A. Werwatz (2004), 
&ldquo;Nonparametric and Semiparametric Models&rdquo;, (Vol. 1). Berlin: Springer.
</p>
<p>Li, Q. and J.S. Racine (2007), &ldquo;Nonparametric Econometrics: Theory
and Practice&rdquo;, Princeton University Press.
</p>
<p>Li, Q. and J.S. Racine (2003), &ldquo;Nonparametric estimation of
distributions with categorical and continuous data&rdquo;, Journal
of Multivariate Analysis, 86, 266-292.
</p>
<p>Ouyang, D. and Q. Li and J.S. Racine (2006), &ldquo;Cross-validation
and the estimation of probability distributions with categorical
data&rdquo;, Journal of Nonparametric Statistics, 18, 69-100.
</p>
<p>Silverman, B.W. (1986), &ldquo;Density Estimation&rdquo;, London: Chapman and
Hall.
</p>
<p>Titterington, D.M. and A.W. Bowman (1985), &ldquo;A comparative study of 
smoothing procedures for ordered categorical data&rdquo;, Journal of Statistical 
Computation and Simulation, 21(3-4), 291-312.
</p>
<p>Wang, M.C. and J. van Ryzin (1981), &ldquo;A class of smooth estimators
for discrete distributions&rdquo;,  Biometrika, 68, 301-309.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mscv.dkps">mscv.dkps</a></code>, <code><a href="#topic+dkss">dkss</a></code>, <code><a href="#topic+mscv.dkss">mscv.dkss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example data frame with mixed numeric, nominal, and ordinal data.
levels = c("Low", "Medium", "High")
df &lt;- data.frame(
  x1 = runif(100, 0, 100),
  x2 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x3 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x4 = rnorm(100, 10, 3),
  x5 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels),
  x6 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels))

# minimal implementation requires just the data frame, and will automatically be
# defaulted to the mscv bandwidth specification technique and default kernel 
# function
d1 &lt;- dkps(df = df)
# d$bandwidths to see the mscv obtained bandwidths
# d$distances to see the distance matrix


# try using the np package, which has few continuous and ordinal kernels to 
# choose from. Recommended using default kernel functions
d2 &lt;- dkps(df = df, bw = "np")


# precomputed bandwidth example
# note that continuous variables requires bandwidths &gt; 0
# ordinal variables requires bandwidths in [0,1]
# for nominal variables, u_aitken requires bandwidths in [0,1] 
# and u_aitchisonaitken in [0,(c-1)/c]
# where c is the number of unique values in the i-th column of df.
# any bandwidths outside this range will result in a warning message
bw_vec &lt;- c(1.0, 0.5, 0.5, 5.0, 0.3, 0.3) 
d3 &lt;- dkps(df = df, bw = bw_vec)


# user-specific kernel functions example
d5 &lt;- dkps(df = df, bw = "mscv", cFUN = "c_epanechnikov", uFUN = "u_aitken", 
      oFUN = "o_habbema")

</code></pre>

<hr>
<h2 id='dkss'>
Distance using Kernel Summation Similarity (DKSS) for Mixed-type Data
</h2><span id='topic+dkss'></span>

<h3>Description</h3>

<p>This function calculates the pairwise distances between mixed-type observations 
consisting of continuous (<code>numeric</code>), nominal (<code>factor</code>), and ordinal 
(<code>ordered</code>) variables using the method described in Ghashti (2024). 
This kernel metric learning methodology calculates a kernel sum similarity 
function, with a variety of options for kernel functions associated with each 
variable type and returns a distance matrix that can be used in any distance-
based algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dkss(df, bw = "mscv", cFUN = "c_gaussian", uFUN = "u_aitken", 
    oFUN = "o_wangvanryzin", stan = TRUE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dkss_+3A_df">df</code></td>
<td>

<p>a <code class="reqn">p</code>-variate data frame for which the pairwise distances between 
observations will be calculated. The data types may be continuous 
(<code>numeric</code>), nominal (<code>factor</code>), and ordinal (<code>ordered</code>), 
or any combination thereof. Columns of <code>df</code> should be of appropriate 
variable type prior to running the function.
</p>
</td></tr>
<tr><td><code id="dkss_+3A_bw">bw</code></td>
<td>

<p>numeric bandwidth vector of length <code class="reqn">p</code>, with each element <code class="reqn">i</code> 
corresponding to the bandwidth for column <code class="reqn">i</code> in <code>df</code>. 
Alternatively, one of two character strings may be inputted for bandwidth 
selection methods. <code>mscv</code> specifies maximum-similarity cross-validation,
and <code>np</code> specifies likelihood-cross validation which is calculated using 
<code><a href="np.html#topic+npudensbw">npudensbw</a></code> in package <code><a href="np.html#topic+np">np</a></code>. Defaults to 
<code>mscv</code>. See details.
</p>
</td></tr>
<tr><td><code id="dkss_+3A_cfun">cFUN</code></td>
<td>

<p>character value specifying the continuous kernel function. Options include 
<code>c_gaussian</code>, <code>c_epanechnikov</code>, <code>c_uniform</code>, 
<code>c_triangle</code>, <code>c_biweight</code>, <code>c_triweight</code>, <code>c_tricube</code>, 
<code>c_cosine</code>, <code>c_logistic</code>, <code>c_sigmoid</code>, and <code>c_silverman</code>. 
Note that if using <code>np</code> for <code>bw</code> selection above, continuous kernel 
types are restricted to either <code>c_gaussian</code>, <code>c_epanechnikov</code>, or
<code>c_uniform</code>. Defaults to <code>c_gaussian</code>. See details.
</p>
</td></tr>
<tr><td><code id="dkss_+3A_ufun">uFUN</code></td>
<td>

<p>character value specifying the nominal kernel function for unordered 
factors. Options include <code>u_aitken</code> and <code>u_aitchisonaitken</code>. 
Defaults to <code>u_aitken</code>. See details.
</p>
</td></tr>
<tr><td><code id="dkss_+3A_ofun">oFUN</code></td>
<td>

<p>character value specifying the ordinal kernel function for ordered factors.
Options include <code>o_aitken</code>, <code>o_aitchisonaitken</code>, <code>o_habbema</code>, 
<code>o_wangvanryzin</code>, and <code>o_liracine</code>. Note that if using <code>np</code> 
for <code>bw</code> selection above, ordinal kernel types are restricted to either
<code>o_wangvanryzin</code> or <code>o_liracine</code>. Defaults to <code>o_wangvanryzin</code>. 
See details.
</p>
</td></tr>
<tr><td><code id="dkss_+3A_stan">stan</code></td>
<td>

<p>a logical value which specifies whether to scale the resulting distance 
matrix between 0 and 1 using min-max normalization. If set to <code>FALSE</code>, 
distances are unscaled. Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="dkss_+3A_verbose">verbose</code></td>
<td>

<p>a logical value which specifies whether to print procedural steps to the 
console. If set to <code>FALSE</code>, no output is printed to the console. 
Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dkss</code> implements the distance using summation similarity distance (DKSS)
as described by Ghashti (2024). This approach uses summation kernels for 
continuous, nominal and ordinal data, which are then summed over all variable 
types to return the pairwise distance between mixed-type data. 
</p>
<p>There are several kernels to select from. The continuous kernel functions may 
be found in Cameron and Trivedi (2005), Härdle et al. (2004) or Silverman 
(1986). Nominal kernels use a variation on Aitchison and Aitken's (1976) 
kernel, while ordinal kernels use a variation of the Wang and van Ryzin (1981)
kernel. Both nominal and ordinal kernel functions can be found in Li and 
Racine (2007), Li and Racine (2003), Ouyan et al. (2006), and Titterington and
Bowman (1985).
</p>
<p>Each kernel requires a bandwidth specification, which can either be a user 
defined numeric vector of length <code class="reqn">p</code> from alternative methodologies for 
bandwidth selection, or through two bandwidth selection methods can be 
specified. The <code>mscv</code> bandwidth selection is based on maximum similarity 
cross-validation by Ghashti and Thompson (2024), invoked by the function 
<code><a href="#topic+mscv.dkss">mscv.dkss</a></code>. The <code>np</code> bandwidth selection follows the maximum
likelihood cross-validation method described by Li and Racine (2007) and Li 
and Racine (2003) for kernel density estimation of mixed-type data. 
</p>
<p>Data contained in the data frame <code>df</code> may constitute any combinations of 
continuous, nominal, or ordinal data, which is to be specified in the data 
frame <code>df</code> using <code><a href="base.html#topic+factor">factor</a></code> for nominal data, and 
<code><a href="base.html#topic+ordered">ordered</a></code> for ordinal data. Data types can be in any order and 
will be detected automatically. User-inputted vectors of
bandwidths <code>bw</code> must be specified in the same order as the variables in 
the data frame <code>df</code>, as to ensure they sorted accordingly by the routine.
</p>


<h3>Value</h3>

<p><code>dkss</code> returns a <code>list</code> object, with the
following components:
</p>
<table role = "presentation">
<tr><td><code>distances</code></td>
<td>

<p>an <code class="reqn">n \times n</code> numeric matrix containing pairwise distances between 
observations
</p>
</td></tr>
<tr><td><code>bandwidths</code></td>
<td>

<p>a <code class="reqn">p</code>-variate vector of bandwidth values returned based on the <code>bw</code> 
bandwidth specification method, sorted by variable type
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John R. J. Thompson <a href="mailto:john.thompson@ubc.ca">john.thompson@ubc.ca</a>, Jesse S. Ghashti
<a href="mailto:jesse.ghashti@ubc.ca">jesse.ghashti@ubc.ca</a>
</p>


<h3>References</h3>

<p>Aitchison, J. and  C.G.G. Aitken (1976), &ldquo;Multivariate binary 
discrimination by the kernel method&rdquo;, Biometrika, 63, 413-420.
</p>
<p>Cameron, A. and P. Trivedi (2005), &ldquo;Microeconometrics: Methods and 
Applications&rdquo;, Cambridge University Press.
</p>
<p>Ghashti, J.S. (2024), &ldquo;Similarity Maximization and Shrinkage Approach 
in Kernel Metric Learning for Clustering Mixed-type Data (T)&rdquo;, University of 
British Columbia.
</p>
<p>Härdle, W., and M. Müller and S. Sperlich and A. Werwatz (2004), 
&ldquo;Nonparametric and Semiparametric Models&rdquo;, (Vol. 1). Berlin: Springer.
</p>
<p>Li, Q. and J.S. Racine (2007), &ldquo;Nonparametric Econometrics: Theory
and Practice&rdquo;, Princeton University Press.
</p>
<p>Li, Q. and J.S. Racine (2003), &ldquo;Nonparametric estimation of
distributions with categorical and continuous data&rdquo;, Journal
of Multivariate Analysis, 86, 266-292.
</p>
<p>Ouyang, D. and Q. Li and J.S. Racine (2006), &ldquo;Cross-validation
and the estimation of probability distributions with categorical
data&rdquo;, Journal of Nonparametric Statistics, 18, 69-100.
</p>
<p>Silverman, B.W. (1986), &ldquo;Density Estimation&rdquo;, London: Chapman and
Hall.
</p>
<p>Titterington, D.M. and A.W. Bowman (1985), &ldquo;A comparative study of 
smoothing procedures for ordered categorical data&rdquo;, Journal of Statistical 
</p>
<p>Computation and Simulation, 21(3-4), 291-312.
</p>
<p>Wang, M.C. and J. van Ryzin (1981), &ldquo;A class of smooth estimators
for discrete distributions&rdquo;,  Biometrika, 68, 301-309.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mscv.dkps">mscv.dkps</a></code>, <code><a href="#topic+dkps">dkps</a></code>, <code><a href="#topic+mscv.dkss">mscv.dkss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example data frame with mixed numeric, nominal, and ordinal data.
levels = c("Low", "Medium", "High")
df &lt;- data.frame(
  x1 = runif(100, 0, 100),
  x2 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x3 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x4 = rnorm(100, 10, 3),
  x5 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels),
  x6 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels))

# minimal implementation requires just the data frame, and will automatically be
# defaulted to the mscv bandwidth specification technique and default kernel 
# function
d1 &lt;- dkss(df = df)
# d$bandwidths to see the mscv obtained bandwidths
# d$distances to see the distance matrix


# try using the np package, which has few continuous and ordinal kernels 
# to choose from. Recommended using default kernel functions
d2 &lt;- dkss(df = df, bw = "np")


# precomputed bandwidth example
# note that continuous variables requires bandwidths &gt; 0
# ordinal variables requires bandwidths in [0,1]
# for nominal variables, u_aitken requires bandwidths in [0,1] 
# and u_aitchisonaitken in [0,(c-1)/c]
# where c is the number of unique values in the i-th column of df.
# any bandwidths outside this range will result in a warning message
bw_vec &lt;- c(1.0, 0.5, 0.5, 5.0, 0.3, 0.3) 
d3 &lt;- dkss(df = df, bw = bw_vec)


# user-specific kernel functions example
d5 &lt;- dkss(df = df, bw = "mscv", cFUN = "c_epanechnikov", uFUN = "u_aitken", 
      oFUN = "o_habbema")

</code></pre>

<hr>
<h2 id='kss'>
Kernel Summation Similarity Function (KSS) for Mixed-type Data
</h2><span id='topic+kss'></span>

<h3>Description</h3>

<p>This function calculates the pairwise similarities between mixed-type 
observations  consisting of continuous (<code>numeric</code>), nominal 
(<code>factor</code>), and ordinal (<code>ordered</code>) variables using the method 
described in Ghashti (2024). This kernel similarity learning methodology 
calculates a kernel sum similarity function, with a variety of options for 
kernel functions associated with each variable type and returns a distance 
matrix that can be used in any distance-based algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kss(df, bw = "np", npmethod = NULL, cFUN = "c_gaussian", 
    uFUN = "u_aitken", oFUN = "o_wangvanryzin", nstart = NULL, 
    stan = TRUE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kss_+3A_df">df</code></td>
<td>

<p>a <code class="reqn">p</code>-variate data frame for which the pairwise similarities between 
observations will be calculated. The data types may be continuous 
(<code>numeric</code>), nominal (<code>factor</code>), and ordinal (<code>ordered</code>), 
or any combination thereof. Columns of <code>df</code> should be of appropriate 
variable type prior to running the function.
</p>
</td></tr>
<tr><td><code id="kss_+3A_bw">bw</code></td>
<td>

<p>numeric bandwidth vector of length <code class="reqn">p</code>, with each element <code class="reqn">i</code> 
corresponding to the bandwidth for column <code class="reqn">i</code> in <code>df</code>. 
Alternatively, a character strings may be inputted for bandwidth 
selection methods. <code>np</code> specifies this techniques which calculate 
bandwidths using <code><a href="np.html#topic+npudensbw">npudensbw</a></code> in package <code><a href="np.html#topic+np">np</a></code>. 
Defaults to <code>np</code> with <code>npmethod</code> set to <code>cv.ml</code> for maximum 
likelihood cross-validation. See details.
</p>
</td></tr>
<tr><td><code id="kss_+3A_npmethod">npmethod</code></td>
<td>

<p>character value specifying the <code>np</code> bandwidth selection to be used for 
calculating bandwidths. Options include <code>cv.ml</code> for maximum likelihood 
cross-validation, <code>cv.ls</code> for least squares cross-validation, and 
<code>normal-reference</code> for normal reference. If left as <code>NULL</code>, defaults 
to <code>cv.ml</code>.
</p>
</td></tr>
<tr><td><code id="kss_+3A_cfun">cFUN</code></td>
<td>

<p>character value specifying the continuous kernel function. Options include 
<code>c_gaussian</code>, <code>c_epanechnikov</code>, <code>c_uniform</code>, 
<code>c_triangle</code>, <code>c_biweight</code>, <code>c_triweight</code>, <code>c_tricube</code>, 
<code>c_cosine</code>, <code>c_logistic</code>, <code>c_sigmoid</code>, and <code>c_silverman</code>. 
Note that if using <code>np</code> for <code>bw</code> selection above, continuous kernel 
types are restricted to either <code>c_gaussian</code>, <code>c_epanechnikov</code>, or
<code>c_uniform</code>. Defaults to <code>c_gaussian</code>. See details.
</p>
</td></tr>
<tr><td><code id="kss_+3A_ufun">uFUN</code></td>
<td>

<p>character value specifying the nominal kernel function for unordered 
factors. Options include <code>u_aitken</code> and <code>u_aitchisonaitken</code>. 
Defaults to <code>u_aitken</code>. See details.
</p>
</td></tr>
<tr><td><code id="kss_+3A_ofun">oFUN</code></td>
<td>

<p>character value specifying the ordinal kernel function for ordered factors.
Options include <code>o_aitken</code>, <code>o_aitchisonaitken</code>, <code>o_habbema</code>, 
<code>o_wangvanryzin</code>, and <code>o_liracine</code>. Note that if using <code>np</code> 
for <code>bw</code> selection above, ordinal kernel types are restricted to either
<code>o_wangvanryzin</code> or <code>o_liracine</code>. Defaults to <code>o_wangvanryzin</code>. 
See details.
</p>
</td></tr>
<tr><td><code id="kss_+3A_nstart">nstart</code></td>
<td>

<p>integer value specifying the number of random starts for the <code>kmeans</code> 
algorithm. Defaults to <code>10</code>.
</p>
</td></tr>
<tr><td><code id="kss_+3A_stan">stan</code></td>
<td>

<p>a logical value which specifies whether to scale the resulting distance 
matrix between 0 and 1 using min-max normalization. If set to <code>FALSE</code>, 
distances are unscaled. Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="kss_+3A_verbose">verbose</code></td>
<td>

<p>a logical value which specifies whether to print procedural steps to the 
console. If set to <code>FALSE</code>, no output is printed to the console. 
Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>kss</code> implements the kernel summation similarity function (KSS)
as described by Ghashti (2024). This approach uses summation kernels for 
continuous, nominal and ordinal data, which are then summed over all variable 
types to return the pairwise similarities between mixed-type data. 
</p>
<p>There are several kernels to select from. The continuous kernel functions may 
be found in Cameron and Trivedi (2005), Härdle et al. (2004) or Silverman 
(1986). Nominal kernels use a variation on Aitchison and Aitken's (1976) 
kernel, while ordinal kernels use a variation of the Wang and van Ryzin (1981)
kernel. Both nominal and ordinal kernel functions can be found in Li and 
Racine (2007), Li and Racine (2003), Ouyan et al. (2006), and Titterington and
Bowman (1985).
</p>
<p>Each kernel requires a bandwidth specification, which can either be a user 
defined numeric vector of length <code class="reqn">p</code> from alternative methodologies for 
bandwidth selection, or through one bandwidth selection method can be 
specified. The <code>np</code> bandwidth selection methods follow three techniques 
(<code>cv.ml</code>, <code>cv.ls</code> and <code>normal-reference</code>) described by Li and 
Racine (2007) and Li and Racine (2003) for kernel density estimation of 
mixed-type data. 
</p>
<p>Data contained in the data frame <code>df</code> may constitute any combinations of 
continuous, nominal, or ordinal data, which is to be specified in the data 
frame <code>df</code> using <code><a href="base.html#topic+factor">factor</a></code> for nominal data, and 
<code><a href="base.html#topic+ordered">ordered</a></code> for ordinal data. Data types can be in any order and 
will be detected automatically. User-inputted vectors of
bandwidths <code>bw</code> must be specified in the same order as the variables in 
the data frame <code>df</code>, as to ensure they sorted accordingly by the routine.
</p>


<h3>Value</h3>

<p><code>kss</code> returns a <code>list</code> object, with the
following components:
</p>
<table role = "presentation">
<tr><td><code>similarities</code></td>
<td>

<p>an <code class="reqn">n \times n</code> numeric matrix containing pairwise similarities between 
observations
</p>
</td></tr>
<tr><td><code>bandwidths</code></td>
<td>

<p>a <code class="reqn">p</code>-variate vector of bandwidth values returned based on the <code>bw</code> 
bandwidth specification method, sorted by variable type
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John R. J. Thompson <a href="mailto:john.thompson@ubc.ca">john.thompson@ubc.ca</a>, Jesse S. Ghashti
<a href="mailto:jesse.ghashti@ubc.ca">jesse.ghashti@ubc.ca</a>
</p>


<h3>References</h3>

<p>Aitchison, J. and  C.G.G. Aitken (1976), &ldquo;Multivariate binary 
discrimination by the kernel method&rdquo;, Biometrika, 63, 413-420.
</p>
<p>Cameron, A. and P. Trivedi (2005), &ldquo;Microeconometrics: Methods and 
Applications&rdquo;, Cambridge University Press.
</p>
<p>Ghashti, J.S. (2024), &ldquo;Similarity Maximization and Shrinkage Approach 
in Kernel Metric Learning for Clustering Mixed-type Data (T)&rdquo;, University of 
British Columbia.
</p>
<p>Härdle, W., and M. Müller and S. Sperlich and A. Werwatz (2004), 
&ldquo;Nonparametric and Semiparametric Models&rdquo;, (Vol. 1). Berlin: Springer.
</p>
<p>Li, Q. and J.S. Racine (2007), &ldquo;Nonparametric Econometrics: Theory
and Practice&rdquo;, Princeton University Press.
</p>
<p>Li, Q. and J.S. Racine (2003), &ldquo;Nonparametric estimation of
distributions with categorical and continuous data&rdquo;, Journal
of Multivariate Analysis, 86, 266-292.
</p>
<p>Ouyang, D. and Q. Li and J.S. Racine (2006), &ldquo;Cross-validation
and the estimation of probability distributions with categorical
data&rdquo;, Journal of Nonparametric Statistics, 18, 69-100.
</p>
<p>Silverman, B.W. (1986), &ldquo;Density Estimation&rdquo;, London: Chapman and
Hall.
</p>
<p>Titterington, D.M. and A.W. Bowman (1985), &ldquo;A comparative study of 
smoothing procedures for ordered categorical data&rdquo;, Journal of Statistical 
Computation and Simulation, 21(3-4), 291-312.
</p>
<p>Wang, M.C. and J. van Ryzin (1981), &ldquo;A class of smooth estimators
for discrete distributions&rdquo;,  Biometrika, 68, 301-309.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mscv.dkps">mscv.dkps</a></code>, <code><a href="#topic+dkps">dkps</a></code>, <code><a href="#topic+mscv.dkss">mscv.dkss</a></code>, <code><a href="#topic+dkss">dkss</a></code>, <code>link{spectral.clust}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example data frame with mixed numeric, nominal, and ordinal data.
levels = c("Low", "Medium", "High")
df &lt;- data.frame(
  x1 = runif(100, 0, 100),
  x2 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x3 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x4 = rnorm(100, 10, 3),
  x5 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels),
  x6 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels))

# minimal implementation requires just the data frame, and will automatically be
# defaulted to the mscv bandwidth specification technique and default kernel 
# function
s1 &lt;- kss(df = df)
# s$bandwidths to see the mscv obtained bandwidths
# s$similarities to see the similarity matrix


# try using the np package, which has few continuous and ordinal kernels 
# to choose from. Recommended using default kernel functions
s2 &lt;- kss(df = df, bw = "np") #defaults to npmethod "cv.ml"


# precomputed bandwidth example
# note that continuous variables requires bandwidths &gt; 0
# ordinal variables requires bandwidths in [0,1]
# for nominal variables, u_aitken requires bandwidths in [0,1] 
# and u_aitchisonaitken in [0,(c-1)/c]
# where c is the number of unique values in the i-th column of df.
# any bandwidths outside this range will result in a warning message
bw_vec &lt;- c(1.0, 0.5, 0.5, 5.0, 0.3, 0.3) 
s3 &lt;- kss(df = df, bw = bw_vec)


# user-specific kernel functions example with "cv.ls" from np.
s4 &lt;- kss(df = df, bw = "np", npmethod = "cv.ls", cFUN = "c_epanechnikov", 
    uFUN = "u_aitken", oFUN = "o_wangvanryzin")

</code></pre>

<hr>
<h2 id='mscv.dkps'>
Maximum-similarity Cross-validated (MSCV) bandwidth selection method for the 
Distance using Kernel Product Similarities (DKPS)
</h2><span id='topic+mscv.dkps'></span>

<h3>Description</h3>

<p>This function calculates maximum-similarity cross-validated bandwidths for the 
distance using kernel summation similarity. This implementation uses the method 
described in Ghashti and Thompson (2023) for mixed-type data that includes any 
of numeric (continuous), factor (nominal), and ordered factor (ordinal) 
variables. <code>mscv.dkps</code> calculates the bandwidths associated with each 
kernel function for variable types and returns a numeric vector of bandwidths 
that can be used with the <code>dkps</code> pairwise distance calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mscv.dkps(df, nstart = NULL, ckernel = "c_gaussian", ukernel = "u_aitken",
          okernel = "o_wangvanryzin", verbose = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mscv.dkps_+3A_df">df</code></td>
<td>

<p>a <code class="reqn">p</code>-variate data frame. The data types may be continuous (<code><a href="base.html#topic+numeric">numeric</a></code>), 
nominal (<code><a href="base.html#topic+factor">factor</a></code>), ordinal (<code><a href="base.html#topic+ordered">ordered</a></code>), or any 
combination thereof. Columns of <code>df</code> should be set to the appropriate 
data type class.
</p>
</td></tr>
<tr><td><code id="mscv.dkps_+3A_nstart">nstart</code></td>
<td>

<p>integer number of restarts for the process of finding extrema of the mscv 
function from random initial bandwidth parameters (starting points). If the 
default of <code>NULL</code> is used, then the number of restarts will be 
<code class="reqn">min(3,\text{ncol(df)})</code>.
</p>
</td></tr>
<tr><td><code id="mscv.dkps_+3A_ckernel">ckernel</code></td>
<td>

<p>character string specifying the continuous kernel function. Options include 
<code>c_gaussian</code>, <code>c_epanechnikov</code>, <code>c_uniform</code>, <code>c_triangle</code>, 
<code>c_biweight</code>, <code>c_triweight</code>, <code>c_tricube</code>, <code>c_cosine</code>, 
<code>c_logistic</code>, <code>c_sigmoid</code>, and <code>c_silverman</code>. Note that if 
using <code>np</code> for <code>bw</code> selection above, continuous kernel types are 
restricted to either <code>c_gaussian</code>, <code>c_epanechnikov</code>, or 
<code>c_uniform</code>. Defaults to <code>c_gaussian</code>. See details.
</p>
</td></tr>
<tr><td><code id="mscv.dkps_+3A_ukernel">ukernel</code></td>
<td>

<p>character string specifying the nominal kernel function for unordered factors. 
Options include <code>u_aitken</code> and <code>u_aitchisonaitken</code>. Defaults to 
<code>u_aitken</code>. See details.
</p>
</td></tr>
<tr><td><code id="mscv.dkps_+3A_okernel">okernel</code></td>
<td>

<p>character string specifying the ordinal kernel function for ordered factors. 
Options include <code>o_aitken</code>, <code>o_aitchisonaitken</code>, <code>o_habbema</code>, 
<code>o_wangvanryzin</code>, and <code>o_liracine</code>. Note that if using <code>np</code> 
for <code>bw</code> selection above, ordinal kernel types are restricted to either 
<code>o_wangvanryzin</code> or <code>o_liracine</code>. Defaults to <code>o_wangvanryzin</code>.
See details.
</p>
</td></tr>
<tr><td><code id="mscv.dkps_+3A_verbose">verbose</code></td>
<td>

<p>a logical value which specifies whether to output the <code class="reqn">i</code>-th iteration of
the total number of <code>nstarts</code>, and output if the optimization procedure 
converges. Defaults to <code>TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mscv.dkps</code> implements the maximum-similarity cross-validation (MSCV) 
technique for bandwidth selection pertaining to the <code><a href="#topic+dkps">dkps</a></code> function,
as described by Ghashti and Thompson (2023). This approach uses product kernels 
for continuous variables, and summation kernels for nominal and ordinal data,
which are then summed over all variable types to return the pairwise distance 
between mixed-type data. 
</p>
<p>The maximization procedure for bandwidth selection is based on the objective
<code class="reqn">\text{arg}\max_{\boldsymbol{\lambda}}\left\{\frac{1}{n}\sum_{i=1}^n\log\left(\frac{1}{(n-1)}\sum_{\substack{j=1 \\ j \ne i}}^n\psi_{\boldsymbol{\lambda}}(\textbf{x}_i,\textbf{x}_j)\right)\right\},</code>
where
</p>
<p><code class="reqn">\psi(\textbf{x}_i, \textbf{x}_j \ | \boldsymbol{\lambda}) = \prod_{k=1}^{p_c}\frac{1}{\lambda_k^c}K(x_{i,k}^c, x_{j,k}^c, \lambda_k^c) + \sum_{k=1}^{p_u}L(x_{i,k}^u,x_{j,k}^u,\lambda_k^u) + \sum_{k=1}^{p_o}\ell(x_{i,k}^o,x_{j,k}^o,\lambda_k^o).</code>
</p>
<p><code class="reqn">K(\cdot)</code>, <code class="reqn">L(\cdot)</code>, and <code class="reqn">\ell(\cdot)</code> are the continuous, 
nominal, and ordinal kernel functions, repectively, with <code class="reqn">\lambda_k</code>'s 
representing kernel specifical bandwiths for the <code class="reqn">k</code>-th variable, and 
<code class="reqn">p_c</code>, <code class="reqn">p_u</code>, <code class="reqn">p_o</code> the number of continuous, nominal, and ordinal
variables in the data frame <code>df</code>. The resulting <code>bw</code> vector returned
is the bandwidths that yield the highest objective function value. 
</p>
<p>Data contained in the data frame <code>df</code> may constitute any combinations of 
continuous, nominal, or ordinal data, which is to be specified in the data 
frame <code>df</code> using <code><a href="base.html#topic+numeric">numeric</a></code> for continuous data, <code><a href="base.html#topic+factor">factor</a></code>
for nominal data, and <code><a href="base.html#topic+ordered">ordered</a></code> for ordinal data. Data can be 
entered in an arbitrary order and data types will be detected automatically. 
User-inputted vectors of bandwidths <code>bw</code> must be defined in the same 
order as the variables in the data frame <code>df</code>, as to ensure they sorted 
accordingly by the routine.
</p>
<p>The are many kernels which can be specified by the user. Continuous kernel 
functions may be found in Cameron and Trivedi (2005), Härdle et al. (2004) or 
Silverman (1986). Nominal kernels use a variation on Aitchison and Aitken's 
(1976) kernel. Ordinal kernels use a variation of the Wang and van Ryzin 
(1981) kernel. All nominal and ordinal kernel functions can be found in Li and
Racine (2007), Li and Racine (2003), Ouyan et al. (2006), and Titterington and
Bowman (1985).
</p>


<h3>Value</h3>

<p><code>mscv.dkps</code> returns a <code>list</code> object, with the
following components:
</p>
<table role = "presentation">
<tr><td><code>bw</code></td>
<td>
<p>a <code class="reqn">p</code>-variate vector of bandwidth values, intended to be used for 
the <code><a href="#topic+dkps">dkps</a></code> pairwise distance calculation </p>
</td></tr>
<tr><td><code>fn_value</code></td>
<td>
<p>a numeric value of the MSCV objective function, obtained using 
the <code><a href="stats.html#topic+optim">optim</a></code> function for constrained multivariate optimization</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John R. J. Thompson <a href="mailto:john.thompson@ubc.ca">john.thompson@ubc.ca</a>, Jesse S. Ghashti
<a href="mailto:jesse.ghashti@ubc.ca">jesse.ghashti@ubc.ca</a>
</p>


<h3>References</h3>

<p>Aitchison, J. and  C.G.G. Aitken (1976), &ldquo;Multivariate binary 
discrimination by the kernel method&rdquo;, Biometrika, 63, 413-420.
</p>
<p>Cameron, A. and P. Trivedi (2005), &ldquo;Microeconometrics: Methods and 
Applications&rdquo;, Cambridge University Press.
</p>
<p>Ghashti, J.S. and J.R.J Thompson (2023), &ldquo;Mixed-type Distance Shrinkage
and Selection for Clustering via Kernel Metric Learning. Journal of 
Classification, Accepted.&rdquo;
</p>
<p>Härdle, W., and M. Müller and S. Sperlich and A. Werwatz (2004), 
&ldquo;Nonparametric and Semiparametric Models&rdquo;, (Vol. 1). Berlin: Springer.
</p>
<p>Li, Q. and J.S. Racine (2007), &ldquo;Nonparametric Econometrics: Theory
and Practice&rdquo;, Princeton University Press.
</p>
<p>Li, Q. and J.S. Racine (2003), &ldquo;Nonparametric estimation of
distributions with categorical and continuous data&rdquo;, Journal
of Multivariate Analysis, 86, 266-292.
</p>
<p>Ouyang, D. and Q. Li and J.S. Racine (2006), &ldquo;Cross-validation
and the estimation of probability distributions with categorical
data&rdquo;, Journal of Nonparametric Statistics, 18, 69-100.
</p>
<p>Silverman, B.W. (1986), &ldquo;Density Estimation&rdquo;, London: Chapman and
Hall.
</p>
<p>Titterington, D.M. and A.W. Bowman (1985), &ldquo;A comparative study of 
smoothing procedures for ordered categorical data&rdquo;, Journal of Statistical 
Computation and Simulation, 21(3-4), 291-312.
</p>
<p>Wang, M.C. and J. van Ryzin (1981), &ldquo;A class of smooth estimators
for discrete distributions&rdquo;,  Biometrika, 68, 301-309.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mscv.dkss">mscv.dkss</a></code>, <code><a href="#topic+dkss">dkss</a></code>, <code><a href="#topic+dkps">dkps</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example data frame with mixed numeric, nominal, and ordinal data.
levels = c("Low", "Medium", "High")
df &lt;- data.frame(
  x1 = runif(100, 0, 100),
  x2 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x3 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x4 = rnorm(100, 10, 3),
  x5 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels),
  x6 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels))

# minimal implementation requires just the data frame, with defaults
bw &lt;- mscv.dkps(df = df)

# specify number of starts and kernel functions
bw2 &lt;- mscv.dkps(df = df, nstart = 5, ckernel = "c_triangle",
                  ukernel = "u_aitken", okernel = "o_liracine")

</code></pre>

<hr>
<h2 id='mscv.dkss'>
Maximum-similarity Cross-validated (MSCV) bandwidth selection method for the 
distance using kernel summation similarity (DKSS)
</h2><span id='topic+mscv.dkss'></span>

<h3>Description</h3>

<p>This function calculates maximum-similarity cross-validated bandwidths for the 
distance using kernel summation similarity. This implementation uses the method 
described in Ghashti (2024) for mixed-type data that includes any of numeric 
(continuous), factor (nominal), and ordered factor (ordinal) variables. 
<code>mscv.dkss</code> calculates the bandwidths associated with each kernel function 
for variable types and returns a numeric vector of bandwidths that can be used 
with the <code>dkss</code> pairwise distance calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mscv.dkss(df, nstart = NULL, ckernel = "c_gaussian", ukernel = "u_aitken", 
          okernel = "o_wangvanryzin", verbose = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mscv.dkss_+3A_df">df</code></td>
<td>

<p>a <code class="reqn">p</code>-variate data frame. The data types may be continuous 
(<code><a href="base.html#topic+numeric">numeric</a></code>), nominal (<code><a href="base.html#topic+factor">factor</a></code>), ordinal 
(<code><a href="base.html#topic+ordered">ordered</a></code>), or any combination thereof. Columns of <code>df</code> 
should be set to the appropriate data type class.
</p>
</td></tr>
<tr><td><code id="mscv.dkss_+3A_nstart">nstart</code></td>
<td>

<p>integer number of restarts for the process of finding extrema of the mscv 
function from random initial bandwidth parameters (starting points). If the 
default of <code>NULL</code> is used, then the number of restarts will be 
<code class="reqn">min(3,\text{ncol(df)})</code>.
</p>
</td></tr>
<tr><td><code id="mscv.dkss_+3A_ckernel">ckernel</code></td>
<td>

<p>character string specifying the continuous kernel function. Options include 
<code>c_gaussian</code>, <code>c_epanechnikov</code>, <code>c_uniform</code>, <code>c_triangle</code>, 
<code>c_biweight</code>, <code>c_triweight</code>, <code>c_tricube</code>, <code>c_cosine</code>, 
<code>c_logistic</code>, <code>c_sigmoid</code>, and <code>c_silverman</code>. Note that if 
using <code>np</code> for <code>bw</code> selection above, continuous kernel types are 
restricted to either <code>c_gaussian</code>, <code>c_epanechnikov</code>, or 
<code>c_uniform</code>. Defaults to <code>c_gaussian</code>. See details.
</p>
</td></tr>
<tr><td><code id="mscv.dkss_+3A_ukernel">ukernel</code></td>
<td>

<p>character string specifying the nominal kernel function for unordered factors.
Options include <code>u_aitken</code> and <code>u_aitchisonaitken</code>. Defaults to 
<code>u_aitken</code>. See details.
</p>
</td></tr>
<tr><td><code id="mscv.dkss_+3A_okernel">okernel</code></td>
<td>

<p>character string specifying the ordinal kernel function for ordered factors. 
Options include <code>o_aitken</code>, <code>o_aitchisonaitken</code>, <code>o_habbema</code>, 
<code>o_wangvanryzin</code>, and <code>o_liracine</code>. Note that if using <code>np</code> 
for <code>bw</code> selection above, ordinal kernel types are restricted to either 
<code>o_wangvanryzin</code> or <code>o_liracine</code>. Defaults to <code>o_wangvanryzin</code>. 
See details.
</p>
</td></tr>
<tr><td><code id="mscv.dkss_+3A_verbose">verbose</code></td>
<td>

<p>a logical value which specifies whether to output the <code class="reqn">i</code>-th iteration of
the total number of <code>nstarts</code>, and output if the optimization procedure 
converges. Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mscv.dkss</code> implements the maximum-similarity cross-validation (MSCV) 
bandwidth selection technique for the <code><a href="#topic+dkss">dkss</a></code> function, described 
by Ghashti (2024). This approach uses summation kernels for continuous, 
nominal and ordinal data, which are then summed over all variable types to 
return the pairwise distance between mixed-type data. 
</p>
<p>The maximization procedure for bandwidth selection is based on the objective
<code class="reqn">\text{arg}\max_{\boldsymbol{\lambda}}\left\{\frac{1}{n}\sum_{i=1}^n\log\left(\frac{1}{(n-1)}\sum_{\substack{j=1 \\ j \ne i}}^ns_{\text{KSS}_{\boldsymbol{\lambda}}}(\textbf{x}_i,\textbf{x}_j)\right)\right\},</code>
where
</p>
<p><code class="reqn">s_{\text{KSS}}(\textbf{x}_i, \textbf{x}_j \ | \boldsymbol{\lambda}) = \sum_{k=1}^{p_c}K(x_{i,k}^c, x_{j,k}^c, \lambda_k^c) + \sum_{k=1}^{p_u}L(x_{i,k}^u,x_{j,k}^u,\lambda_k^u) + \sum_{k=1}^{p_o}\ell(x_{i,k}^o,x_{j,k}^o,\lambda_k^o).</code>
</p>
<p><code class="reqn">K(\cdot)</code>, <code class="reqn">L(\cdot)</code>, and <code class="reqn">\ell(\cdot)</code> are the continuous, 
nominal, and ordinal kernel functions, repectively, with <code class="reqn">\lambda_k</code>'s 
representing kernel specifical bandwiths for the <code class="reqn">k</code>-th variable, and 
<code class="reqn">p_c</code>, <code class="reqn">p_u</code>, <code class="reqn">p_o</code> the number of continuous, nominal, and ordinal
variables in the data frame <code>df</code>. The <code>bw</code> vector returned is the
bandwidths that yield the highest objective function value. 
</p>
<p>Data contained in the data frame <code>df</code> may constitute any combinations of
continuous, nominal, or ordinal data, which is to be specified in the data 
frame <code>df</code> using <code><a href="base.html#topic+numeric">numeric</a></code> for continuous data, 
<code><a href="base.html#topic+factor">factor</a></code> for nominal data, and <code><a href="base.html#topic+ordered">ordered</a></code> for ordinal 
data. Data can be entered in an arbitrary order and data types will be 
detected automatically. User-inputted vectors of bandwidths <code>bw</code> must be 
defined in the same order as the variables in the data frame <code>df</code>, as to 
ensure they sorted accordingly by the routine.
</p>
<p>The are many kernels which can be specified by the user. Continuous kernel 
functions may be found in Cameron and Trivedi (2005), Härdle et al. (2004) or 
Silverman (1986). Nominal kernels use a variation of Aitchison and Aitken's 
(1976) kernel. Ordinal kernels use a variation of the Wang and van Ryzin 
(1981) kernel. All nominal and ordinal kernel functions can be found in Li and
Racine (2007), Li and Racine (2003), Ouyan et al. (2006), and Titterington and
Bowman (1985).
</p>


<h3>Value</h3>

<p><code>mscv.dkss</code> returns a <code>list</code> object, with the
following components:
</p>
<table role = "presentation">
<tr><td><code>bw</code></td>
<td>
<p>a <code class="reqn">p</code>-variate vector of bandwidth values, intended to be used for
the <code><a href="#topic+dkss">dkss</a></code> pairwise distance calculation </p>
</td></tr>
<tr><td><code>fn_value</code></td>
<td>
<p>a numeric value of the MSCV objective function, obtained using 
the <code><a href="stats.html#topic+optim">optim</a></code> function for constrained multivariate optimization</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John R. J. Thompson <a href="mailto:john.thompson@ubc.ca">john.thompson@ubc.ca</a>, Jesse S. Ghashti
<a href="mailto:jesse.ghashti@ubc.ca">jesse.ghashti@ubc.ca</a>
</p>


<h3>References</h3>

<p>Aitchison, J. and  C.G.G. Aitken (1976), &ldquo;Multivariate binary 
discrimination by the kernel method&rdquo;, Biometrika, 63, 413-420.
</p>
<p>Cameron, A. and P. Trivedi (2005), &ldquo;Microeconometrics: Methods and 
Applications&rdquo;, Cambridge University Press.
</p>
<p>Ghashti, J.S. (2024), &ldquo;Similarity Maximization and Shrinkage Approach 
in Kernel Metric Learning for Clustering Mixed-type Data&rdquo;, University of 
British Columbia.
</p>
<p>Härdle, W., and M. Müller and S. Sperlich and A. Werwatz (2004), 
&ldquo;Nonparametric and Semiparametric Models&rdquo;, (Vol. 1). Berlin: Springer.
</p>
<p>Li, Q. and J.S. Racine (2007), &ldquo;Nonparametric Econometrics: Theory
and Practice&rdquo;, Princeton University Press.
</p>
<p>Li, Q. and J.S. Racine (2003), &ldquo;Nonparametric estimation of
distributions with categorical and continuous data&rdquo;, Journal
of Multivariate Analysis, 86, 266-292.
</p>
<p>Ouyang, D. and Q. Li and J.S. Racine (2006), &ldquo;Cross-validation
and the estimation of probability distributions with categorical
data&rdquo;, Journal of Nonparametric Statistics, 18, 69-100.
</p>
<p>Silverman, B.W. (1986), &ldquo;Density Estimation&rdquo;, London: Chapman and
Hall.
</p>
<p>Titterington, D.M. and A.W. Bowman (1985), &ldquo;A comparative study of 
smoothing procedures for ordered categorical data&rdquo;, Journal of Statistical 
Computation and Simulation, 21(3-4), 291-312.
</p>
<p>Wang, M.C. and J. van Ryzin (1981), &ldquo;A class of smooth estimators
for discrete distributions&rdquo;,  Biometrika, 68, 301-309.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mscv.dkps">mscv.dkps</a></code>, <code><a href="#topic+dkss">dkss</a></code>, <code><a href="#topic+dkps">dkps</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example data frame with mixed numeric, nominal, and ordinal data.
levels = c("Low", "Medium", "High")
df &lt;- data.frame(
  x1 = runif(100, 0, 100),
  x2 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x3 = factor(sample(c("A", "B", "C"), 100, TRUE)),
  x4 = rnorm(100, 10, 3),
  x5 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels),
  x6 = ordered(sample(c("Low", "Medium", "High"), 100, TRUE), levels = levels))

# minimal implementation requires just the data frame, with defaults
bw &lt;- mscv.dkss(df = df)

# specify number of starts and kernel functions
bw2 &lt;- mscv.dkss(df = df, nstart = 5, ckernel = "c_triangle", 
                ukernel = "u_aitken", okernel = "o_liracine")

</code></pre>

<hr>
<h2 id='spectral.clust'>
Spectral Clustering using Similarity or Distance Matrices
</h2><span id='topic+spectral.clust'></span>

<h3>Description</h3>

<p>This function calculates performs spectral clustering with the k-means step 
using precomputed similarity or distance matrices, and returns a vector of 
cluster assignments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectral.clust(S, k, nstart = 10, iter.max = 1000, 
              is.sim = NULL, neighbours = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spectral.clust_+3A_s">S</code></td>
<td>

<p>a <code class="reqn">n \times n</code> numeric matrix representing either pairwise similarities
or distances between observations. The matrix can be a similarity matrix or 
a distance matrix, as indicated by the <code>is.sim</code> argument.
</p>
</td></tr>
<tr><td><code id="spectral.clust_+3A_k">k</code></td>
<td>

<p>integer value specifying the number of clusters to form. This is passed to 
the <code>kmeans</code> algorithm.
</p>
</td></tr>
<tr><td><code id="spectral.clust_+3A_nstart">nstart</code></td>
<td>

<p>integer value specifying the number of random starts for the bandwidth 
estimation. Defaults to 3 or the number of variables, whichever is larger.
</p>
</td></tr>
<tr><td><code id="spectral.clust_+3A_iter.max">iter.max</code></td>
<td>

<p>integer value specifying the maximum number of iterations for the 
<code>kmeans</code> algorithm. Defaults to <code>1000</code>.
</p>
</td></tr>
<tr><td><code id="spectral.clust_+3A_is.sim">is.sim</code></td>
<td>

<p>logical value indicating whether the input matrix <code>S</code> is a similarity 
matrix. If set to <code>TRUE</code>, <code>S</code> is treated as a similarity matrix. 
If set to <code>FALSE</code>, <code>S</code> is treated as a distance matrix. Must be 
specified.
</p>
</td></tr>
<tr><td><code id="spectral.clust_+3A_neighbours">neighbours</code></td>
<td>

<p>integer value specifying the number of nearest neighbours to consider when 
constructing the graph Laplacian. This helps in determining the structure 
of the graph from the similarity or distance matrix. Defaults to <code>10</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>spectral.clust</code> implements spectral clustering on pairwise similarity or
distance matrices, following the method described by Ng et al. (2001). The 
function first constructs an adjacency matrix from the input similarity or 
distance matrix <code>S</code> using the <code>neighbours</code> parameter to define the 
nearest connections. If <code>S</code> is a similarity matrix (<code>is.sim = TRUE</code>),
the function retains the largest values corresponding to the <code>neighbours</code>
nearest observations. If <code>S</code> is a distance matrix (<code>is.sim = FALSE</code>), 
it retains the smallest values for the nearest observations. The adjacency 
matrix is symmetrized and used to compute the unnormalized Laplacian matrix. 
The eigenvectors corresponding to the smallest eigenvalues of the Laplacian 
are extracted and clustered using the <code>kmeans</code> algorithm. The number of 
clusters, <code>k</code>, and parameters such as the number of random starts 
(<code>nstart</code>) and maximum iterations (<code>iter.max</code>) for the <code>kmeans</code>
step are user-specified. 
</p>


<h3>Value</h3>

<p><code>spectral.clust</code> returns a <code>list</code> object with the following components:
</p>
<table role = "presentation">
<tr><td><code>clusters</code></td>
<td>

<p>an <code class="reqn">n</code>-variate integer vector indicating the cluster assignment for each 
observation, as determined by the <code>kmeans</code> algorithm.
</p>
</td></tr>
<tr><td><code>S</code></td>
<td>

<p>the original <code class="reqn">n \times n</code> numeric matrix used as input, representing 
either pairwise similarities or distances between observations, depending 
on the <code>is.sim</code> argument.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John R. J. Thompson <a href="mailto:john.thompson@ubc.ca">john.thompson@ubc.ca</a>, Jesse S. Ghashti
<a href="mailto:jesse.ghashti@ubc.ca">jesse.ghashti@ubc.ca</a>
</p>


<h3>References</h3>

<p>Ng, A., Jordan, M., &amp; Weiss, Y. (2001). On spectral clustering: Analysis and 
an algorithm. &ldquo;Advances in Neural Information processing systems&rdquo;, 14.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mscv.dkps">mscv.dkps</a></code>, <code><a href="#topic+dkps">dkps</a></code>, <code><a href="#topic+mscv.dkss">mscv.dkss</a></code>, 
<code><a href="#topic+dkss">dkss</a></code>, <code>link{kss}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the Iris dataset
dat &lt;- iris[,-5]

# calculate pairwise similarities using maximum likelihood cross validation
S &lt;- kss(dat, bw = "np", npmethod = "cv.ml", cFUN = "c_gaussian", verbose = TRUE)

# cluster points using spectral clustering and compare to true class labels
cl &lt;- spectral.clust(S$similarities, 3, is.sim = TRUE)
table(cl$clusters, iris[,5])

# try a different number of neighbours
cl2 &lt;- spectral.clust(S$similarities, 3, is.sim = TRUE, neighbours = 4)
table(cl2$clusters, iris[,5])
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
