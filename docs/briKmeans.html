<!DOCTYPE html><html><head><title>Help for package briKmeans</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {briKmeans}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#brik'><p> Computation of Initial Seeds and Kmeans Results</p></a></li>
<li><a href='#elbowRule'><p> Selection of Appropriate DF Parameter Based on an Elbow Rule for the Distortion</p></a></li>
<li><a href='#fabrik'><p> Computation of Initial Seeds for Kmeans and Clustering of Functional Data</p></a></li>
<li><a href='#fdebrik'><p> Computation of Initial Seeds for Kmeans with a Functional Extension of Brik</p></a></li>
<li><a href='#kma'><p>Clustering and alignment of functional data</p></a></li>
<li><a href='#kma.similarity'><p>Similarity/dissimilarity index between two functions</p></a></li>
<li><a href='#plotKmeansClustering'><p> Kmeans Clustering Plot</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-07-20</td>
</tr>
<tr>
<td>Title:</td>
<td>Package for Brik, Fabrik and Fdebrik Algorithms to Initialise
Kmeans</td>
</tr>
<tr>
<td>Author:</td>
<td>Javier Albert Smet &lt;javas@kth.se&gt; and
        Aurora Torrente &lt;etorrent@est-econ.uc3m.es&gt;.
        Alice Parodi, Mirco Patriarca, Laura Sangalli, Piercesare Secchi, 
        Simone Vantini and Valeria Vitelli, as contributors.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Aurora Torrente &lt;etorrent@est-econ.uc3m.es&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0), boot, cluster, depthTools, splines, splines2,
stats</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the BRIk, FABRIk and FDEBRIk algorithms 
        to initialise k-means. These methods are intended for the 
        clustering of multivariate and functional data, respectively.
        They make use of the Modified Band Depth and bootstrap to 
        identify appropriate initial seeds for k-means, which are 
        proven to be better options than many techniques in the 
        literature. Torrente and Romo (2021) &lt;<a href="https://doi.org/10.1007%2Fs00357-020-09372-3">doi:10.1007/s00357-020-09372-3</a>&gt;
        It makes use of the functions kma and kma.similarity, from the 
        archived package fdakma, by Alice Parodi et al.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-20 23:46:42 UTC; mtl</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-21 08:40:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='brik'> Computation of Initial Seeds and Kmeans Results </h2><span id='topic+brik'></span>

<h3>Description</h3>

 
<p><code>brik</code> computes appropriate seeds &ndash;based on bootstrap and the MBD depth&ndash; to initialise k-means, which is then run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brik(x, k, method="Ward", nstart=1, B=10, J = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brik_+3A_x">x</code></td>
<td>
<p> a data matrix containing <code>N</code> observations (individuals) by rows and <code>d</code> variables (features) by columns </p>
</td></tr>
<tr><td><code id="brik_+3A_k">k</code></td>
<td>
<p> number of clusters </p>
</td></tr> 
<tr><td><code id="brik_+3A_method">method</code></td>
<td>
<p> clustering algorithm used to cluster the cluster centres from the bootstrapped replicates; <code>Ward</code>, by default. Currently, only <code>pam</code> and randomly initialised <code>kmeans</code> are implemented </p>
</td></tr>
<tr><td><code id="brik_+3A_nstart">nstart</code></td>
<td>
<p> number of random initialisations when using the <code>kmeans</code> method to cluster the cluster centres </p>
</td></tr>
<tr><td><code id="brik_+3A_b">B</code></td>
<td>
<p> number of bootstrap replicates to be generated </p>
</td></tr>
<tr><td><code id="brik_+3A_j">J</code></td>
<td>
<p> number of observations used to build the bands for the MBD computation. Currently, only the value J=2 can be used </p>
</td></tr>
<tr><td><code id="brik_+3A_...">...</code></td>
<td>
<p> additional arguments to be passed to the <code>kmeans</code> function for the final clustering; at this stage <code>nstart</code> is set to 1, as the initial seeds are fixed </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The brik algorithm is a simple, computationally feasible method, which provides k-means with a set of initial seeds to cluster datasets of arbitrary dimensions. It consists of two stages: first, a set of cluster centers is obtained by applying k-means to bootstrap replications of the original data to be, next, clustered; the deepest point in each assembled cluster is returned as initial seeds for k-means. </p>


<h3>Value</h3>

<table>
<tr><td><code>seeds</code></td>
<td>
<p> a matrix of size <code>k x d</code> containing the initial seeds obtained with the BRIk algorithm </p>
</td></tr>
<tr><td><code>km</code></td>
<td>
<p> an object of class <code>kmeans</code> corresponding to the run of kmeans on <code>x</code> with starting points <code>seeds</code> </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Javier Albert Smet <a href="mailto:javas@kth.se">javas@kth.se</a> and 
Aurora Torrente <a href="mailto:etorrent@est-econ.uc3m.es">etorrent@est-econ.uc3m.es</a></p>


<h3>References</h3>

<p>Torrente, A. and Romo, J. (2020). Initializing k-means Clustering by Bootstrap and Data Depth. <em>J Classif</em> (2020). https://doi.org/10.1007/s00357-020-09372-3.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## brik algorithm 
    ## simulated data
    set.seed(0)
    g1 &lt;- matrix(rnorm(200,0,3), 25, 8) ; g1[,1]&lt;-g1[,1]+4;
    g2 &lt;- matrix(rnorm(200,0,3), 25, 8) ; g2[,1]&lt;-g2[,1]+4; g2[,3]&lt;-g2[,3]-4
    g3 &lt;- matrix(rnorm(200,0,3), 25, 8) ; g3[,1]&lt;-g3[,1]+4; g3[,3]&lt;-g3[,3]+4

    x &lt;- rbind(g1,g2,g3)
    labels &lt;-c(rep(1,25),rep(2,25),rep(3,25))

    C1 &lt;- kmeans(x,3)
    C2 &lt;- brik(x,3,B=25)
  
    table(C1$cluster, labels)
    table(C2$km$cluster, labels)    

</code></pre>

<hr>
<h2 id='elbowRule'> Selection of Appropriate DF Parameter Based on an Elbow Rule for the Distortion </h2><span id='topic+elbowRule'></span>

<h3>Description</h3>

 
<p><code>elbowRule</code> runs the FABRIk algorithm for different degrees of freedom (DF) and suggests the best of such values as the one where the minimum distortion is obtained. An optional visualization of the computed values allows the choice of alternative suitable DF values based on an elbow-like rule.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elbowRule(x, k, method="Ward", nstart=1, B = 10, J = 2, x.coord = NULL, OSF = 1, 
    vect = NULL, intercept = TRUE, degPolyn = 3, degFr = 4:20, knots = NULL, 
    plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="elbowRule_+3A_x">x</code></td>
<td>
<p> a data matrix containing <code>N</code> observations (individuals) by rows and <code>d</code> variables (features) by columns </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_k">k</code></td>
<td>
<p> number of clusters </p>
</td></tr> 
<tr><td><code id="elbowRule_+3A_method">method</code></td>
<td>
<p> clustering algorithm used to cluster the cluster centres from the bootstrapped replicates; <code>Ward</code>, by default. Currently, only <code>pam</code> and randomly initialised <code>kmeans</code> are implemented </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_nstart">nstart</code></td>
<td>
<p> number of random initialisations when using the <code>kmeans</code> method to cluster the cluster centres </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_b">B</code></td>
<td>
<p> number of bootstrap replicates to be generated </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_j">J</code></td>
<td>
<p> number of observations used to build the bands for the MBD computation. Currently, only the value J=2 can be used </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_x.coord">x.coord</code></td>
<td>
<p> initial x coordinates (time points) where the functional data is observed; if not provided, it is assumed to be <code>1:d</code> </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_osf">OSF</code></td>
<td>
<p> oversampling factor for the smoothed data; an OSF of m means that the number of (equally spaced) time points observed in the approximated function is m times the number of original number of features, <code>d</code> </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_vect">vect</code></td>
<td>
<p> optional collection of x coordinates (time points) where to assess the smoothed data; if provided, it ignores the OSF </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_intercept">intercept</code></td>
<td>
<p> if <code>TRUE</code>, an intercept is included in the basis; default is <code>FALSE</code> </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_degpolyn">degPolyn</code></td>
<td>
<p> degree of the piecewise polynomial; 3 by default (cubic splines) </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_degfr">degFr</code></td>
<td>
<p> a vector containing tentative values of the degrees of freedom, to be tested </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_knots">knots</code></td>
<td>
<p> the internal breakpoints that define the spline </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_plot">plot</code></td>
<td>
<p> a Boolean parameter; it allows plotting the distortion against the degrees of freedom. Set to <code>FALSE</code> by default </p>
</td></tr>
<tr><td><code id="elbowRule_+3A_...">...</code></td>
<td>
<p> additional arguments to be passed to the <code>kmeans</code> function for the final clustering; at this stage <code>nstart</code> is set to 1, as the initial seeds are fixed </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The function implements a simple elbow-like rule that allows selecting an appropriate value for the DF parameter among the tested ones. It computes the distortion obtained for each of these values and returns the one yielding to the smallest distortion. By setting the parameter <code>plot</code> to <code>TRUE</code> the distortion is plotted against the degrees of freedom and elbows or minima can be visually detected. </p>


<h3>Value</h3>

<table>
<tr><td><code>df</code></td>
<td>
<p> the original vector of DF values to be tested </p>
</td></tr>
<tr><td><code>tot.withinss</code></td>
<td>
<p> a vector containing the distortion obtained for each tested DF value </p>
</td></tr>
<tr><td><code>optimal</code></td>
<td>
<p> DF value producing the smallest distortion among the tested <code>df</code> </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Javier Albert Smet <a href="mailto:javas@kth.se">javas@kth.se</a> and 
Aurora Torrente <a href="mailto:etorrent@est-econ.uc3m.es">etorrent@est-econ.uc3m.es</a></p>


<h3>References</h3>

 
<p>Torrente, A. and Romo, J. (2020). Initializing Kmeans Clustering by Bootstrap and Data Depth. <em>J Classif</em> (2020). https://doi.org/10.1007/s00357-020-09372-3.
Albert-Smet, J., Torrente, A. and Romo J. (2021). Modified Band Depth Based Initialization of Kmeans for Functional Data Clustering. Submitted to Computational Statistics and Data Analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## simulated data
    set.seed(1)
    x.coord = seq(0,1,0.01)
    x &lt;- matrix(ncol = length(x.coord), nrow = 80)
    labels &lt;- matrix(ncol = 100, nrow = 1)
  
    centers &lt;-  matrix(ncol = length(x.coord), nrow = 4)
    centers[1, ] &lt;- abs(x.coord)-0.5
    centers[2, ] &lt;- (abs(x.coord-0.5))^2 - 0.8
    centers[3, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7
    centers[4, ] &lt;- 0.75*sin(8*pi*abs(x.coord))
  
    for(i in 1:4){
        for(j in 1:20){
            labels[20*(i-1) + j] &lt;- i  
            if(i == 1){x[20*(i-1) + j, ] &lt;- abs(x.coord)-0.5 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 2){x[20*(i-1) + j, ] &lt;- (abs(x.coord-0.5))^2 - 0.8 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 3){x[20*(i-1) + j, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 4){x[20*(i-1) + j, ] &lt;- 0.75*sin(8*pi*abs(x.coord)) + 
                rnorm(length(x.coord),0,1.5)}
            }
        }

    # ER &lt;- elbowRule(x, 4, B=25, degFr = 5:12, plot=FALSE)
    ER &lt;- elbowRule(x, 4, B=25, degFr = 5:12, plot=TRUE)
  
</code></pre>

<hr>
<h2 id='fabrik'> Computation of Initial Seeds for Kmeans and Clustering of Functional Data </h2><span id='topic+fabrik'></span>

<h3>Description</h3>

 
<p><code>fabrik</code> fits splines to the multivariate dataset and runs the BRIk algorithm on the smoothed data. For functional data, this is just a straight forward application of BRIk to the k-means algorithm; for multivariate data, the result corresponds to an alternative clustering method where the objective function is not necessarily minimised, but better allocations are obtained in general.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fabrik(x, k, method="Ward", nstart=1, B = 10, J = 2, x.coord = NULL, OSF = 1, 
    vect = NULL, intercept = TRUE, degPolyn = 3, degFr = 5, knots = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fabrik_+3A_x">x</code></td>
<td>
<p> a data matrix containing <code>N</code> observations (individuals) by rows and <code>d</code> variables (features) by columns </p>
</td></tr>
<tr><td><code id="fabrik_+3A_k">k</code></td>
<td>
<p> number of clusters </p>
</td></tr> 
<tr><td><code id="fabrik_+3A_method">method</code></td>
<td>
<p> clustering algorithm used to cluster the cluster centres from the bootstrapped replicates; <code>Ward</code>, by default. Currently, only <code>pam</code> and randomly initialised <code>kmeans</code> are implemented </p>
</td></tr>
<tr><td><code id="fabrik_+3A_nstart">nstart</code></td>
<td>
<p> number of random initialisations when using the <code>kmeans</code> method to cluster the cluster centres </p>
</td></tr>
<tr><td><code id="fabrik_+3A_b">B</code></td>
<td>
<p> number of bootstrap replicates to be generated </p>
</td></tr>
<tr><td><code id="fabrik_+3A_j">J</code></td>
<td>
<p> number of observations used to build the bands for the MBD computation. Currently, only the value J=2 can be used </p>
</td></tr>
<tr><td><code id="fabrik_+3A_x.coord">x.coord</code></td>
<td>
<p> initial x coordinates (time points) where the functional data is observed; if not provided, it is assumed to be <code>1:d</code> </p>
</td></tr>
<tr><td><code id="fabrik_+3A_osf">OSF</code></td>
<td>
<p> oversampling factor for the smoothed data; an OSF of m means that the number of (equally spaced) time points observed in the approximated function is m times the number of original number of features, <code>d</code> </p>
</td></tr>
<tr><td><code id="fabrik_+3A_vect">vect</code></td>
<td>
<p> optional collection of x coordinates (time points) where to assess the smoothed data; if provided, it ignores the OSF </p>
</td></tr>
<tr><td><code id="fabrik_+3A_intercept">intercept</code></td>
<td>
<p> if <code>TRUE</code>, an intercept is included in the basis; default is <code>FALSE</code> </p>
</td></tr>
<tr><td><code id="fabrik_+3A_degpolyn">degPolyn</code></td>
<td>
<p> degree of the piecewise polynomial; 3 by default (cubic splines) </p>
</td></tr>
<tr><td><code id="fabrik_+3A_degfr">degFr</code></td>
<td>
<p> degrees of freedom, as in the <code>bs</code> function </p>
</td></tr>
<tr><td><code id="fabrik_+3A_knots">knots</code></td>
<td>
<p> the internal breakpoints that define the spline </p>
</td></tr>
<tr><td><code id="fabrik_+3A_...">...</code></td>
<td>
<p> additional arguments to be passed to the <code>kmeans</code> function for the final clustering; at this stage <code>nstart</code> is set to 1, as the initial seeds are fixed </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The FABRIk algorithm extends the BRIk algorithm to the case of longitudinal functional data by adding a step that includes B-splines fitting and evaluation of the curve at specific x coordinates. Thus, it allows handling issues such as noisy or missing data. It identifies smoothed initial seeds that are used as starting points of kmeans on the smoothed data. The resulting clustering does not optimise the distortion (sum of squared distances of each data point to its nearest centre) in the original data space but it provides in general a better allocation of datapoints to real groups. </p>


<h3>Value</h3>

<table>
<tr><td><code>seeds</code></td>
<td>
<p> a matrix of size <code>k x D</code>, where <code>D</code> is either <code>m x d</code> or the length of <code>vect</code> . It contains the initial smoothed seeds obtained with the BRIk algorithm </p>
</td></tr>
<tr><td><code>km</code></td>
<td>
<p> an object of class <code>kmeans</code> corresponding to the run of kmeans on the smoothed data, with starting points <code>seeds</code> </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Javier Albert Smet <a href="mailto:javas@kth.se">javas@kth.se</a> and 
Aurora Torrente <a href="mailto:etorrent@est-econ.uc3m.es">etorrent@est-econ.uc3m.es</a></p>


<h3>References</h3>

 
<p>Torrente, A. and Romo, J. (2020). Initializing Kmeans Clustering by Bootstrap and Data Depth. <em>J Classif</em> (2020). https://doi.org/10.1007/s00357-020-09372-3.
Albert-Smet, J., Torrente, A. and Romo J. (2021). Modified Band Depth Based Initialization of Kmeans for Functional Data Clustering. Submitted to Computational Statistics and Data Analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## fabrik algorithm 
    ## simulated data
    set.seed(1)
    x.coord = seq(0,1,0.01)
    x &lt;- matrix(ncol = length(x.coord), nrow = 100)
    labels &lt;- matrix(ncol = 100, nrow = 1)
  
    centers &lt;-  matrix(ncol = length(x.coord), nrow = 4)
    centers[1, ] &lt;- abs(x.coord)-0.5
    centers[2, ] &lt;- (abs(x.coord-0.5))^2 - 0.8
    centers[3, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7
    centers[4, ] &lt;- 0.75*sin(8*pi*abs(x.coord))
  
    for(i in 1:4){
        for(j in 1:25){
            labels[25*(i-1) + j] &lt;- i  
            if(i == 1){x[25*(i-1) + j, ] &lt;- abs(x.coord)-0.5 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 2){x[25*(i-1) + j, ] &lt;- (abs(x.coord-0.5))^2 - 0.8 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 3){x[25*(i-1) + j, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 4){x[25*(i-1) + j, ] &lt;- 0.75*sin(8*pi*abs(x.coord)) + 
                rnorm(length(x.coord),0,1.5)}
            }
        }

    C1 &lt;- kmeans(x,4)
    C2 &lt;- fabrik(x,4,B=25)
  
    table(C1$cluster, labels)
    table(C2$km$cluster, labels)    
</code></pre>

<hr>
<h2 id='fdebrik'> Computation of Initial Seeds for Kmeans with a Functional Extension of Brik </h2><span id='topic+fdebrik'></span>

<h3>Description</h3>

 
<p><code>fdebrik</code> first fits splines to the multivariate dataset; then it identifies functional centers that form tighter groups, by means of the kma algorithm; finally, it converts these into a multivariate data set in a selected dimension, clusters them and finds the deepest point of each cluster to be used as initial seeds. The multivariate objective function is not necessarily minimised, but better allocations are obtained in general.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdebrik(x, k, method="Ward", nstart=1, B = 10, J = 2, x.coord = NULL,
    functionalDist="d0.pearson", OSF = 1, vect = NULL, intercept = TRUE, 
    degPolyn = 3, degFr = 5, knots = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fdebrik_+3A_x">x</code></td>
<td>
<p> a data matrix containing <code>N</code> observations (individuals) by rows and <code>d</code> variables (features) by columns </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_k">k</code></td>
<td>
<p> number of clusters </p>
</td></tr> 
<tr><td><code id="fdebrik_+3A_method">method</code></td>
<td>
<p> clustering algorithm used to cluster the cluster centres from the bootstrapped replicates; <code>Ward</code>, by default. Currently, only <code>pam</code> and randomly initialised <code>kmeans</code> with <code>nstart</code> initializations are implemented </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_nstart">nstart</code></td>
<td>
<p> number of random initialisations when using the <code>kmeans</code> method to cluster the cluster centres </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_b">B</code></td>
<td>
<p> number of bootstrap replicates to be generated </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_j">J</code></td>
<td>
<p> number of observations used to build the bands for the MBD computation. Currently, only the value J=2 can be used </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_x.coord">x.coord</code></td>
<td>
<p> initial x coordinates (time points) where the functional data is observed; if not provided, it is assumed to be <code>1:d</code> </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_functionaldist">functionalDist</code></td>
<td>
<p> similarity measure between functions to be used. Currently, only the cosine of the angles between functions (<code>"d0.pearson"</code>) and between their derivatives (<code>"d1.pearson"</code>) can be used </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_osf">OSF</code></td>
<td>
<p> oversampling factor for the smoothed data; an OSF of m means that the number of (equally spaced) time points observed in the approximated function is m times the number of original number of features, <code>d</code> </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_vect">vect</code></td>
<td>
<p> optional collection of x coordinates (time points) where to assess the smoothed data; if provided, it ignores the OSF </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_intercept">intercept</code></td>
<td>
<p> if <code>TRUE</code>, an intercept is included in the basis; default is <code>FALSE</code> </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_degpolyn">degPolyn</code></td>
<td>
<p> degree of the piecewise polynomial; 3 by default (cubic splines) </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_degfr">degFr</code></td>
<td>
<p> degrees of freedom, as in the <code>bs</code> function </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_knots">knots</code></td>
<td>
<p> the internal breakpoints that define the spline </p>
</td></tr>
<tr><td><code id="fdebrik_+3A_...">...</code></td>
<td>
<p> additional arguments to be passed to the <code>kmeans</code> function for the final clustering; at this stage <code>nstart</code> is set to 1, as the initial seeds are fixed </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The FDEBRIk algorithm extends the BRIk algorithm to the case of longitudinal functional data by adding a B-spline fitting step, a collection of functional centers by means of the kma algorithm and the evaluation of these at specific x coordinates. Thus, it allows handling issues such as noisy or missing data. It identifies smoothed initial seeds that are used as starting points of kmeans on the smoothed data. The resulting clustering does not optimise the distortion (sum of squared distances of each data point to its nearest centre) in the original data space but it provides in general a better allocation of datapoints to real groups. </p>


<h3>Value</h3>

<table>
<tr><td><code>seeds</code></td>
<td>
<p> a matrix of size <code>k x D</code>, where <code>D</code> is either <code>m x d</code> or the length of <code>vect</code> . It contains the initial smoothed seeds obtained with the FDEBRIk algorithm </p>
</td></tr>
<tr><td><code>km</code></td>
<td>
<p> an object of class <code>kmeans</code> corresponding to the run of kmeans on the smoothed data, with starting points <code>seeds</code> </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Javier Albert Smet <a href="mailto:javas@kth.se">javas@kth.se</a> and 
Aurora Torrente <a href="mailto:etorrent@est-econ.uc3m.es">etorrent@est-econ.uc3m.es</a></p>


<h3>References</h3>

 
<p>Torrente, A. and Romo, J. Initializing Kmeans Clustering by Bootstrap and Data Depth. <em>J Classif</em> (2021) 38(2):232-256. DOI: 10.1007/s00357-020-09372-3
Albert-Smet, J., Torrente, A. and Romo, J. Modified Band Depth Based Initialization of Kmeans for Functional Data Clustering. Submitted to <em>Adv. Data Anal. Classif.</em> (2022).
Sangalli, L.M., Secchi, P., Vantini, V.S. and Vitelli, V. K-mean alignment for
curve clustering. <em>Comput. Stat. Data Anal.</em> (2010) 54(5):1219-1233. DOI:10.1016/j.csda.2009.12.008
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## fdebrik algorithm 
    ## Not run: 
    ## simulated data
    set.seed(1)
    x.coord = seq(0,1,0.05)
    x &lt;- matrix(ncol = length(x.coord), nrow = 40)
    labels &lt;- matrix(ncol = 100, nrow = 1)
  
    centers &lt;-  matrix(ncol = length(x.coord), nrow = 4)
    centers[1, ] &lt;- abs(x.coord)-0.5
    centers[2, ] &lt;- (abs(x.coord-0.5))^2 - 0.8
    centers[3, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7
    centers[4, ] &lt;- 0.75*sin(8*pi*abs(x.coord))
  
    for(i in 1:4){
        for(j in 1:10){
            labels[10*(i-1) + j] &lt;- i  
            if(i == 1){x[10*(i-1) + j, ] &lt;- abs(x.coord)-0.5 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 2){x[10*(i-1) + j, ] &lt;- (abs(x.coord-0.5))^2 - 0.8 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 3){x[10*(i-1) + j, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 4){x[10*(i-1) + j, ] &lt;- 0.75*sin(8*pi*abs(x.coord)) + 
                rnorm(length(x.coord),0,1.5)}
            }
        }

    C1 &lt;- kmeans(x,4)
    C2 &lt;- fdebrik(x,4,B=5)
  
    table(C1$cluster, labels)
    table(C2$km$cluster, labels)
    
## End(Not run)
</code></pre>

<hr>
<h2 id='kma'>Clustering and alignment of functional data</h2><span id='topic+kma'></span>

<h3>Description</h3>

<p>kma jointly performs clustering and alignment of a functional dataset (multidimensional or unidimensional functions). </p>


<h3>Usage</h3>

<pre><code class='language-R'>kma(x, y0 = NULL, y1 = NULL, n.clust = 1, warping.method = "affine",
similarity.method = "d1.pearson", center.method = "k-means", seeds = NULL,
optim.method = "L-BFGS-B", span = 0.15, t.max = 0.1, m.max = 0.1, n.out = NULL,
tol = 0.01, fence = TRUE, iter.max = 100, show.iter = 0, nstart=2, return.all=FALSE,
check.total.similarity=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kma_+3A_x">x</code></td>
<td>
<p>matrix <em>n.func</em> X <em>grid.size</em> or vector <em>grid.size</em>: 
the abscissa values where each function is evaluated. <em>n.func</em>: number of functions in the dataset. <em>grid.size</em>: maximal number of abscissa values where each function is evaluated. The abscissa points may be unevenly spaced and they may differ from function to function. <code>x</code> can also be a vector of length <em>grid.size</em>. In this case, <code>x</code> will be used as abscissa grid for all functions.</p>
</td></tr>
<tr><td><code id="kma_+3A_y0">y0</code></td>
<td>
<p>matrix <em>n.func</em> X <em>grid.size</em> or array <em>n.func</em> X <em>grid.size</em> X <em>d</em>: evaluations of the set of original functions on the abscissa grid <code>x</code>. <em>n.func</em>: number of functions in the dataset. <em>grid.size</em>: maximal number of abscissa values where each function is evaluated. <em>d</em>: (only if the sample is multidimensional) number of function components, i.e. each function is a <em>d</em>-dimensional curve. Default value of <code>y0</code> is <code>NULL</code>. The parameter <code>y0</code> must be provided if the chosen <code>similarity.method</code> concerns original functions.</p>
</td></tr>
<tr><td><code id="kma_+3A_y1">y1</code></td>
<td>
<p>matrix <em>n.func</em> X <em>grid.size</em> or array <em>n.func</em> X <em>grid.size</em> X <em>d</em>: evaluations of the set of original functions first derivatives on the abscissa grid <code>x</code>. Default value of <code>y1</code> is <code>NULL</code>. The parameter <code>y1</code> must be provided if the chosen <code>similarity.method</code> concerns original function first derivatives.</p>
</td></tr>
<tr><td><code id="kma_+3A_n.clust">n.clust</code></td>
<td>
<p>scalar: required number of clusters. Default value is <code>1</code>. Note that if <code>n.clust=1</code> kma performs only alignment without clustering.</p>
</td></tr>
<tr><td><code id="kma_+3A_warping.method">warping.method</code></td>
<td>
<p>character: type of alignment required. If <code>warping.method='NOalignment'</code> kma performs only k-mean clustering (without alignment). If <code>warping.method='affine'</code> kma performs alignment (and possibly clustering) of functions using linear affine transformation as warping functions, i.e., <em>x.final = dilation*x + shift</em>. If <code>warping.method='shift'</code> kma allows only shift, i.e., <em>x.final = x + shift</em>. If <code>warping.method='dilation'</code> kma allows only dilation, i.e., <em>x.final = dilation*x</em>. Default value is <code>'affine'</code>.</p>
</td></tr>
<tr><td><code id="kma_+3A_similarity.method">similarity.method</code></td>
<td>
<p>character: required similarity measure. Possible choices are: <code>'d0.pearson'</code>, <code>'d1.pearson'</code>, <code>'d0.L2'</code>, <code>'d1.L2'</code>, <code>'d0.L2.centered'</code>, <code>'d1.L2.centered'</code>. Default value is <code>'d1.pearson'</code>. See <a href="#topic+kma.similarity">kma.similarity</a> for details.</p>
</td></tr>
<tr><td><code id="kma_+3A_center.method">center.method</code></td>
<td>
<p>character: type of clustering method to be used. Possible choices are: <code>'k-means'</code> and <code>'k-medoids'</code>. Default value is <code>'k-means'</code>.</p>
</td></tr>
<tr><td><code id="kma_+3A_seeds">seeds</code></td>
<td>
<p>vector <em>max(n.clust)</em> or matrix <em>nstart</em> X <em>n.clust</em>: indexes of the functions to be used as initial centers. If it is a matrix, each row contains the indexes of the initial centers of one of the <code>nstart</code> initializations. In the case where not all the values of <code>seeds</code> are provided, those not provided are randomly chosen among the <code>n.func</code> original functions. If <code>seeds=NULL</code> all the centers are randomly chosen. Default value of <code>seeds</code> is <code>NULL</code></p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="kma_+3A_optim.method">optim.method</code></td>
<td>
<p>character: optimization method chosen to find the best warping functions at each iteration. Possible choices are: <code>'L-BFGS-B'</code> and <code>'SANN'</code>. See <a href="stats.html#topic+optim">optim</a> function for details. Default method is <code>'L-BFGS-B'</code>.
</p>
</td></tr>
<tr><td><code id="kma_+3A_span">span</code></td>
<td>
<p>scalar: the span to be used for the <a href="stats.html#topic+loess">loess</a> procedure in the center estimation step when <code>center.method='k-means'</code>. Default value is 0.15. If <code>center.method='k-medoids'</code> value of <code>span</code> is ignored.</p>
</td></tr>
<tr><td><code id="kma_+3A_t.max">t.max</code></td>
<td>
<p>scalar: <code>t.max</code> controls the maximal allowed shift, at each iteration, in the alignment procedure with respect to the range of curve domains. <code>t.max</code> must be such that <em>0&lt;t.max&lt;1</em> (e.g., <code>t.max=0.1</code> means that shift is bounded, at each iteration, between <em>-0.1*range(x)</em> and <em>+0.1*range(x)</em>). Default value is <code>0.1</code>. If <code>warping.method='dilation'</code> value of <code>t.max</code> is ignored.</p>
</td></tr>
<tr><td><code id="kma_+3A_m.max">m.max</code></td>
<td>
<p>scalar: <code>m.max</code> controls the maximal allowed dilation, at each iteration, in the alignment procedure. <code>m.max</code> must be such that <em>0&lt;m.max&lt;1</em> (e.g., <code>m.max=0.1</code> means that dilation is bounded, at each iteration, between <em>1-0.1</em> and <em>1+0.1</em> ). Default value is <code>0.1</code>. If <code>warping.method='shift'</code> value of <code>m.max</code> is ignored.</p>
</td></tr>
<tr><td><code id="kma_+3A_n.out">n.out</code></td>
<td>
<p>scalar: the desired length of the abscissa for computation of the similarity indexes and the centers. Default value is <code>round(1.1*grid.size)</code>.</p>
</td></tr>
<tr><td><code id="kma_+3A_tol">tol</code></td>
<td>
<p>scalar: the algorithm stops when the increment of similarity of each function with respect to the corrispondent center is lower than <code>tol</code>. Default value is <code>0.01</code>.</p>
</td></tr>
<tr><td><code id="kma_+3A_fence">fence</code></td>
<td>
<p>boolean: if <code>fence=TRUE</code> a control is activated at the end of each iteration. The aim of the control is to avoid shift/dilation outlighers with respect to their computed distributions. If <code>fence=TRUE</code> the running time can increase considerably. Default value of <code>fence</code> is TRUE.</p>
</td></tr>
<tr><td><code id="kma_+3A_iter.max">iter.max</code></td>
<td>
<p>scalar: maximum number of iterations in the k-mean alignment cycle. Default value is <code>100</code>.</p>
</td></tr>
<tr><td><code id="kma_+3A_show.iter">show.iter</code></td>
<td>
<p>boolean: if <code>show.iter=TRUE</code> kma shows the current iteration of the algorithm. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="kma_+3A_nstart">nstart</code></td>
<td>
<p>scalar: number of initializations with different seeds. Default value is <code>2</code>. This parameter is used only if <code>center.method</code> is <code>'k-medoids'</code>. When <code>center.method = 'k-means'</code> one initialization is performed.</p>
</td></tr>
<tr><td><code id="kma_+3A_return.all">return.all</code></td>
<td>
<p>boolean: if <code>return.all=TRUE</code> the results of all the <code>nstart</code> initializations are returned; the output is a list of length <code>nstart</code>. If <code>return.all=FALSE</code> only the best result is provided (the one with higher mean similarity if <code>similarity.method</code> is <code>'d0.pearson'</code> or<code>'d1.pearson'</code>, or the one with lower distance if <code>similarity.method</code> is <code>'d0.L2'</code>, <code>'d1.L2'</code>, <code>'d0.L2.centered'</code> or <code>'d1.L2.centered'</code>). Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="kma_+3A_check.total.similarity">check.total.similarity</code></td>
<td>
<p>boolean: if <code>check.total.similarity=TRUE</code> at each iteration the algorithm checks if there is a decrease of the total similarity and stops. In the affermative case the result obtained in the penultimate iteration is returned. Default value is <code>FALSE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function output is a list containing the following elements:
</p>
<table>
<tr><td><code>iterations</code></td>
<td>
<p>scalar: total number of iterations performed by kma function.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>as input.</p>
</td></tr>
<tr><td><code>y0</code></td>
<td>
<p>as input.</p>
</td></tr>
<tr><td><code>y1</code></td>
<td>
<p>as input.</p>
</td></tr>
<tr><td><code>n.clust</code></td>
<td>
<p>as input.</p>
</td></tr>
<tr><td><code>warping.method</code></td>
<td>
<p>as input.</p>
</td></tr>
<tr><td><code>similarity.method</code></td>
<td>
<p>as input.</p>
</td></tr>
<tr><td><code>center.method</code></td>
<td>
<p>as input.</p>
</td></tr>
<tr><td><code>x.center.orig</code></td>
<td>
<p>vector <em>n.out</em>: abscissa of the original center.</p>
</td></tr>
<tr><td><code>y0.center.orig</code></td>
<td>
<p>matrix <em>1</em> X <em>n.out</em>: the unique row contains the evaluations of the original function center. If <code>warping.method='k-means'</code> there are two scenarios: if <code>similarity.method='d0.pearson'</code> or <code>'d0.L2'</code> or <code>d0.L2.centered</code> the original function center is computed via <a href="stats.html#topic+loess">loess</a> procedure applied to original data; if <code>similarity.method='d1.pearson'</code> or <code>'d1.L2'</code> or <code>d1.L2.centered</code> it is computed by integration of first derivatives center <code>y1.center.orig</code> (the integration constant is computed minimizing the sum of the weighed L2 distances between the center and the original functions). If <code>warping.method='k-medoids'</code> the original function center is the medoid of original functions.</p>
</td></tr>
<tr><td><code>y1.center.orig</code></td>
<td>
<p>matrix <em>1</em> X <em>n.out</em>: the unique row contains the evaluations of the original function first derivatives center. If <code>warping.method='k-means'</code> the original center is computed via <a href="stats.html#topic+loess">loess</a> procedure applied to original function first derivatives. If <code>warping.method='k-medoids'</code> the original center is the medoid of original functions.</p>
</td></tr>
<tr><td><code>similarity.orig</code></td>
<td>
<p>vector: original similarities between the original functions and the original center.</p>
</td></tr>
<tr><td><code>x.final</code></td>
<td>
<p>matrix <em>n.func</em> X <em>grid.size</em>: aligned abscissas.</p>
</td></tr>
<tr><td><code>n.clust.final</code></td>
<td>
<p>scalar: final number of clusters. Note that, when <code>center.method='k.means'</code>, the parameter <code>n.clust.final</code> may differ from initial number of clusters (i.e., from <code>n.clust</code>) if some clusters are found to be empty. In this case a warning message is issued.</p>
</td></tr>
<tr><td><code>x.centers.final</code></td>
<td>
<p>vector <em>n.out</em>: abscissas of the final function centers and/or of the final function first derivatives centers.</p>
</td></tr>
<tr><td><code>y0.centers.final</code></td>
<td>
<p>matrix <em>n.clust.final</em> X <em>n.out</em>: rows contain the evaluations of the final functions centers. <code>y0.centers.final</code> is <code>NULL</code> if <code>y0</code> is not given as input.</p>
</td></tr>
<tr><td><code>y1.centers.final</code></td>
<td>
<p>matrix <em>n.clust.final</em> X <em>n.out</em>: rows contains the evaluations of the final derivatives centers. <code>y1.centers.final</code> is <code>NULL</code> if the chosen similarity measure does not concern function first derivatives.</p>
</td></tr>
<tr><td><code>labels</code></td>
<td>
<p>vector: cluster assignments.</p>
</td></tr>
<tr><td><code>similarity.final</code></td>
<td>
<p>vector: similarities between each function and the center of the cluster the function is assigned to.</p>
</td></tr>
<tr><td><code>dilation.list</code></td>
<td>
<p>list: dilations obtained at each iteration of kma function.</p>
</td></tr>
<tr><td><code>shift.list</code></td>
<td>
<p>list: shifts obtained at each iteration of kma function.</p>
</td></tr>
<tr><td><code>dilation</code></td>
<td>
<p>vector: dilation applied to the original abscissas <code>x</code> to obtain the aligned abscissas <code>x.final</code>.</p>
</td></tr>
<tr><td><code>shift</code></td>
<td>
<p>vector: shift applied to the original abscissas <code>x</code> to obtain the aligned abscissas <code>x.final</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alice Parodi, Mirco Patriarca, Laura Sangalli, Piercesare Secchi, Simone Vantini, Valeria Vitelli.
</p>


<h3>References</h3>

<p>Sangalli, L.M., Secchi, P., Vantini, S., Vitelli, V., 2010. <em>&quot;K-mean alignment for curve clustering&quot;</em>. Computational Statistics and Data Analysis, 54, 1219-1233.
</p>
<p>Sangalli, L.M., Secchi, P., Vantini, S., 2014. <em>&quot;Analysis of AneuRisk65 data: K-mean Alignment&quot;</em>. Electronic Journal of Statistics, Special Section on &quot;Statistics of Time Warpings and Phase Variations&quot;, Vol. 8, No. 2, 1891-1904.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kma.similarity">kma.similarity</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## simulated data
    set.seed(1)
    x.coord = seq(0,1,0.01)
    x &lt;- matrix(ncol = length(x.coord), nrow = 100)
    labels &lt;- matrix(ncol = 100, nrow = 1)
  
    centers &lt;-  matrix(ncol = length(x.coord), nrow = 4)
    centers[1, ] &lt;- abs(x.coord)-0.5
    centers[2, ] &lt;- (abs(x.coord-0.5))^2 - 0.8
    centers[3, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7
    centers[4, ] &lt;- 0.75*sin(8*pi*abs(x.coord))
  
    for(i in 1:4){
        for(j in 1:25){
            labels[25*(i-1) + j] &lt;- i  
            if(i == 1){x[25*(i-1) + j, ] &lt;- abs(x.coord)-0.5 + 
                rnorm(length(x.coord),0,0.1)}
            if(i == 2){x[25*(i-1) + j, ] &lt;- (abs(x.coord-0.5))^2 - 0.8 + 
                rnorm(length(x.coord),0,0.1)}
            if(i == 3){x[25*(i-1) + j, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7 + 
                rnorm(length(x.coord),0,0.1)}
            if(i == 4){x[25*(i-1) + j, ] &lt;- 0.75*sin(8*pi*abs(x.coord)) + 
                rnorm(length(x.coord),0,0.1)}
            }
        }
    C &lt;- kma(x.coord, x, n.clust = 4, 
            warping.method = "NOalignment", similarity.method = "d0.pearson")
    table(C$labels, labels)

</code></pre>

<hr>
<h2 id='kma.similarity'>Similarity/dissimilarity index between two functions</h2><span id='topic+kma.similarity'></span>

<h3>Description</h3>

<p>kma.similarity computes a similarity/dissimilarity measure between two functions <code class="reqn">f</code> and <code class="reqn">g</code>. Users can choose among different types of measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kma.similarity(x.f = NULL, y0.f = NULL, y1.f = NULL,
x.g = NULL, y0.g = NULL, y1.g = NULL, similarity.method, unif.grid = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kma.similarity_+3A_x.f">x.f</code></td>
<td>
<p>vector <em>length.f</em>: abscissa grid where function <code class="reqn">f</code>  and his first derivatives <code class="reqn">f'</code> is evaluated. <em>length.f</em>: numbrt of abscissa values where <code class="reqn">f</code> is evaluated. <code>x.f</code> must always be provided.</p>
</td></tr>
<tr><td><code id="kma.similarity_+3A_y0.f">y0.f</code></td>
<td>
<p>vector <em>length.f</em> or matrix <em>length.f</em> X <em>d</em>: evaluations of function <code class="reqn">f</code> on the abscissa grid <code>x.f</code>. <em>length.f</em>: number of abscissa values where <code class="reqn">f</code> is evaluated. <em>d</em> (only if <code class="reqn">f</code> and <code class="reqn">g</code> are multidimensional) number of function's components, i.e. <code class="reqn">f</code> is <code class="reqn">d</code>-dimensional curve.  Default value of <code>y0.f</code> is <code>NULL</code>. The vector<code>y0.f</code> must be provided if the chosen <code>similarity.method</code> concerns original functions.</p>
</td></tr>
<tr><td><code id="kma.similarity_+3A_y1.f">y1.f</code></td>
<td>
<p>vector <em>length.f</em> or matrix <em>length.f</em> X <em>d</em>: evaluations of <code class="reqn">f</code> first derivative, i.e., <code class="reqn">f'</code>, on the abscissa grid <code>x.f</code>. Default value of <code>y1.f</code> is <code>NULL</code>. The vector <code>y1.f</code> must be provided if the chosen <code>similarity.method</code> concerns function first derivatives.</p>
</td></tr>
<tr><td><code id="kma.similarity_+3A_x.g">x.g</code></td>
<td>
<p>vector <em>length.g</em>: abscissa grid where function <code class="reqn">g</code>  and his first derivatives <code class="reqn">g'</code> is evaluated. <em>length.g</em>: numbrt of abscissa values where <code class="reqn">g</code> is evaluated. <code>x.g</code> must always be provided.</p>
</td></tr>
<tr><td><code id="kma.similarity_+3A_y0.g">y0.g</code></td>
<td>
<p>vector  <em>length.g</em> or matrix <em>length.g</em> X <em>d</em>: evaluations of function <code class="reqn">g</code> on the abscissa grid <code>x.g</code>.  <em>length.g</em>: number of abscissa values where <code class="reqn">g</code> is evaluated. <em>d</em> (only if <code class="reqn">f</code> and <code class="reqn">g</code> are multidimensional) number of function's components, i.e. <code class="reqn">g</code> is <code class="reqn">d</code>-dimensional curve. Default value of <code>y0.g</code> is <code>NULL</code>. The vector <code>y0.g</code> must be provided if the chosen <code>similarity.method</code> concerns original functions.</p>
</td></tr>
<tr><td><code id="kma.similarity_+3A_y1.g">y1.g</code></td>
<td>
<p>vector <em>length.g</em> or matrix <em>length.g</em> X <em>d</em>: evaluations of <code class="reqn">g</code> first derivative, i.e., <code class="reqn">g'</code>, on the abscissa grid <code>x.g</code>. Default value is of <code>y1.g</code> <code>NULL</code>. The vector <code>y1.g</code> must be provided if the chosen <code>similarity.method</code> concerns function first derivatives.</p>
</td></tr>
<tr><td><code id="kma.similarity_+3A_similarity.method">similarity.method</code></td>
<td>
<p>character: similarity/dissimilarity between <code class="reqn">f</code> and <code class="reqn">g</code>. Possible choices are: <code>'d0.pearson'</code>, <code>'d1.pearson'</code>, <code>'d0.L2'</code>, <code>'d1.L2'</code>,
<code>'d0.L2.centered'</code>, <code>'d1.L2.centered'</code>. Default value is <code>'d1.pearson'</code>. See details.</p>
</td></tr>
<tr><td><code id="kma.similarity_+3A_unif.grid">unif.grid</code></td>
<td>
<p>boolean: if equal to <code>TRUE</code> the similarity measure is computed over an uniform grid built in the intersection domain of the two functions, that is an additional discretization is performed. If equal to <code>FALSE</code> the additional discretization is not performed, so the functions are supposed to be already defined on the same abscissa grid and the grid is supposed to be fine enough to well compute similarity.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We report the list of the currently available similarities/dissimilarities. Note that all norms and inner products are computed over <code class="reqn">D</code>, that is the intersection of the domains of <code class="reqn">f</code> and <code class="reqn">g</code>. <code class="reqn">\overline{f}</code> and <code class="reqn">\overline{g}</code> denote the mean value, respectively, of functions <code class="reqn">f</code> and <code class="reqn">g</code>.
</p>
<p>1. <code>'d0.pearson'</code>: this similarity measure is the cosine of the angle between the two functions <code class="reqn">f</code> and <code class="reqn">g</code>.
</p>
<p style="text-align: center;"><code class="reqn">
\frac{&lt;f,g&gt;_{L^2}}{\|{f}\|_{L^2} \|{g}\|_{L^2}}</code>
</p>

<p>2. <code>'d1.pearson'</code>: this similarity measure is the cosine of the angle between the two function derivatives <code class="reqn">f'</code> and <code class="reqn">g'</code>.
</p>
<p style="text-align: center;"><code class="reqn">
\frac{&lt;f',g'&gt;_{L^2}}{\|{f'}\|_{L^2} \|{g'}\|_{L^2}}</code>
</p>

<p>3. <code>'d0.L2'</code>: this dissimilarity measure is the L2 distance of the two functions <code class="reqn">f</code> and <code class="reqn">g</code> normalized by the length of the common domain <code class="reqn">D</code>.
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\|{f-g}\|_{L^2}}{|D|}</code>
</p>

<p>4. <code>'d1.L2'</code>: this dissimilarity measure is the L2 distance of the two function first derivatives <code class="reqn">f'</code> and <code class="reqn">g'</code> normalized by the length of the common domain <code class="reqn">D</code>.
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\|{f'-g'}\|_{L^2}}{|D|}</code>
</p>

<p>5. <code>'d0.L2.centered'</code>: this dissimilarity measure is the L2 distance of <code class="reqn">f-\overline{f}</code> and <code class="reqn">g-\overline{g}</code> normalized by the length of the common domain <code class="reqn">D</code>.
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\|{(f-\overline{f})-(g-\overline{g})}\|_{L^2}}{|D|}</code>
</p>

<p>6. <code>'d1.L2.centered'</code>: this dissimilarity measure is the L2 distance of <code class="reqn">f'-\overline{f'}</code> and <code class="reqn">g'-\overline{g'}</code> normalized by the length of the common domain <code class="reqn">D</code>.
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\|{(f'-\overline{f'})-(g'-\overline{g'})}\|_{L^2}}{|D|}</code>
</p>

<p>For multidimensional functions, if <code>similarity.method='d0.pearson'</code> or <code>'d1.pearson'</code> the similarity/dissimilarity measure is computed via the average of the indexes in all directions.
</p>
<p>The coherence properties specified in Sangalli et al. (2010) implies that if <code>similarity.method</code> is set to <code>'d0.L2'</code>, <code>'d1.L2'</code>, <code>'d0.L2.centered'</code> or <code>'d1.L2.centered'</code>, value of <code>warping.method</code> must be <code>'shift'</code> or <code>'NOalignment'</code>. If <code>similarity.method</code> is set to <code>'d0.pearson'</code> or <code>'d1.pearson'</code> all values for <code>warping.method</code> are allowed.
</p>


<h3>Value</h3>

<p>scalar: similarity/dissimilarity measure between the two functions <code class="reqn">f</code> and <code class="reqn">g</code> computed via the similarity/dissimilarity measure specified.
</p>


<h3>Author(s)</h3>

<p>Alice Parodi, Mirco Patriarca, Laura Sangalli, Piercesare Secchi, Simone Vantini, Valeria Vitelli.
</p>


<h3>References</h3>

<p>Sangalli, L.M., Secchi, P., Vantini, S., Vitelli, V., 2010. <em>&quot;K-mean alignment for curve clustering&quot;</em>. Computational Statistics and Data Analysis, 54, 1219-1233.
</p>
<p>Sangalli, L.M., Secchi, P., Vantini, S., 2014. <em>&quot;Analysis of AneuRisk65 data: K-mean Alignment&quot;</em>. Electronic Journal of Statistics, Special Section on &quot;Statistics of Time Warpings and Phase Variations&quot;, Vol. 8, No. 2, 1891-1904.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kma">kma</a></code>
</p>

<hr>
<h2 id='plotKmeansClustering'> Kmeans Clustering Plot </h2><span id='topic+plotKmeansClustering'></span>

<h3>Description</h3>

 
<p><code>plotKmeansClustering</code> represents, in different subpanels, each of the clusters obtained after running k-means. The corresponding centroid is highlighted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotKmeansClustering(x, kmeansObj, col=c(8,2), lty=c(2,1), x.coord = NULL, 
    no.ticks = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotKmeansClustering_+3A_x">x</code></td>
<td>
<p> a data matrix containing <code>N</code> observations (individuals) by rows and <code>d</code> variables (features) by columns </p>
</td></tr>
<tr><td><code id="plotKmeansClustering_+3A_kmeansobj">kmeansObj</code></td>
<td>
<p> an object of class <code>kmeans</code>, containing the cluster labels output by kmeans </p>
</td></tr> 
<tr><td><code id="plotKmeansClustering_+3A_col">col</code></td>
<td>
<p> a vector containing colors for the elements in <code>x</code> and for the centroid. The last one is used for the centroid, whereas the previous ones are recycled </p>
</td></tr>
<tr><td><code id="plotKmeansClustering_+3A_lty">lty</code></td>
<td>
<p> a vector containing the line type for the elements in <code>x</code> and for the centroid. The last one is used for the centroid, whereas the previous ones are recycled </p>
</td></tr>
<tr><td><code id="plotKmeansClustering_+3A_x.coord">x.coord</code></td>
<td>
<p> initial x coordinates (time points) where the functional data is observed; if not provided, it is assumed to be <code>1:d</code> </p>
</td></tr>
<tr><td><code id="plotKmeansClustering_+3A_no.ticks">no.ticks</code></td>
<td>
<p> number of ticks to be displayed in the X axis </p>
</td></tr>
<tr><td><code id="plotKmeansClustering_+3A_...">...</code></td>
<td>
<p> additional arguments to be passed to the <code>plot</code> function </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The function creates a suitable grid where to plot the different clusters independently. In the i-th cell of the grid, the data points corresponding to the i-th cluster are represented in parallel coordinates and the final centroid is highlighted. </p>


<h3>Value</h3>

<p> the function returns invisibly a list with the following components:
</p>
<table>
<tr><td><code>clusters</code></td>
<td>
<p> a list containing one cluster per component; observations are given by rows </p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p> a list with the centroid of each cluster </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Javier Albert Smet <a href="mailto:javas@kth.se">javas@kth.se</a> and 
Aurora Torrente <a href="mailto:etorrent@est-econ.uc3m.es">etorrent@est-econ.uc3m.es</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## simulated data
    set.seed(1)
    x.coord = seq(0,1,0.01)
    x &lt;- matrix(ncol = length(x.coord), nrow = 100)
    labels &lt;- matrix(ncol = 100, nrow = 1)
  
    centers &lt;-  matrix(ncol = length(x.coord), nrow = 4)
    centers[1, ] &lt;- abs(x.coord)-0.5
    centers[2, ] &lt;- (abs(x.coord-0.5))^2 - 0.8
    centers[3, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7
    centers[4, ] &lt;- 0.75*sin(8*pi*abs(x.coord))
  
    for(i in 1:4){
        for(j in 1:25){
            labels[25*(i-1) + j] &lt;- i  
            if(i == 1){x[25*(i-1) + j, ] &lt;- abs(x.coord)-0.5 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 2){x[25*(i-1) + j, ] &lt;- (abs(x.coord-0.5))^2 - 0.8 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 3){x[25*(i-1) + j, ] &lt;- -(abs(x.coord-0.5))^2 + 0.7 + 
                rnorm(length(x.coord),0,1.5)}
            if(i == 4){x[25*(i-1) + j, ] &lt;- 0.75*sin(8*pi*abs(x.coord)) + 
                rnorm(length(x.coord),0,1.5)}
            }
        }

    plotKmeansClustering(x, kmeans(x,4))
    plotKmeansClustering(x, brik(x,4)$km)
    plotKmeansClustering(x, fabrik(x,4)$km)
    plotKmeansClustering(x, fabrik(x,4,degFr=10)$km)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
