<!DOCTYPE html><html><head><title>Help for package SurvDisc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SurvDisc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AsympDiscSurv'><p>Asymptotic Estimate of Mean and Variance of Log-hazard Ratio for Discrete Time Survival</p></a></li>
<li><a href='#LongToSurv'><p>Longitudinal To Survival Function</p></a></li>
<li><a href='#PrenticeGloeckler.test'><p>Regression for Grouped Survival Data Function</p></a></li>
<li><a href='#print.PrenticeGloeckler.test'><p>Print Regression for Grouped Survival Data Function Object</p></a></li>
<li><a href='#print.SSDS'><p>Print Sample Size Discrete Survival Object</p></a></li>
<li><a href='#rowMSD'><p>Mean and Standard Deviation estimates for each row in a matrix</p></a></li>
<li><a href='#SampleSizeDiscSurv'><p>Sample Size for Discrete Time Survival</p></a></li>
<li><a href='#simexlme'><p>SIMEX algorithm for linear mixed effects models</p></a></li>
<li><a href='#simGFRdata'><p>Data Set Containing Simulated Longitudinal eGFR</p></a></li>
<li><a href='#TKVsurv'><p>Data Set Containing Fitted Model Estimates and Covariances</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Discrete Time Survival and Longitudinal Data Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 2.10.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cubature, mvtnorm, MASS, nlme, simex, survival</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>John Lawrence &lt;john.lawrence@fda.hhs.gov&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Various functions for discrete time survival analysis and longitudinal analysis. SIMEX method for correcting for bias for errors-in-variables
  in a mixed effects model. Asymptotic mean and variance of different proportional hazards test statistics using different ties methods given two
  survival curves and censoring distributions. Score test and Wald test for regression analysis of grouped survival data. Calculation of survival
  curves for events defined by the response variable in a mixed effects model crossing a threshold with or without confirmation.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-05-04 20:10:14 UTC; LAWRENCEJ</td>
</tr>
<tr>
<td>Author:</td>
<td>John Lawrence [aut, cre],
  Jianjin Xu [ctb],
  Sue Jane Wang [ctb],
  Jim Hung [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-05-04 20:25:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='AsympDiscSurv'>Asymptotic Estimate of Mean and Variance of Log-hazard Ratio for Discrete Time Survival</h2><span id='topic+AsympDiscSurv'></span>

<h3>Description</h3>

<p>calculates the expected estimated log-hazard ratio and the estimated variance for large sample sizes when there are two groups with possibly non-proportional hazards and possible unequal randomization and censoring distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AsympDiscSurv(h0,h1,p0,p1,method=c("efron","breslow","PrenticeGloeckler"),tol=1E-12)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AsympDiscSurv_+3A_h0">h0</code></td>
<td>
<p>vector of hazard rates in the control group</p>
</td></tr>
<tr><td><code id="AsympDiscSurv_+3A_h1">h1</code></td>
<td>
<p>vector of hazard rates in the treatment group</p>
</td></tr>
<tr><td><code id="AsympDiscSurv_+3A_p0">p0</code></td>
<td>
<p>vector of probabilities of being in the risk set and in the control group. See <code>Details</code> section below.</p>
</td></tr>
<tr><td><code id="AsympDiscSurv_+3A_p1">p1</code></td>
<td>
<p>vector of probabilities of being in the risk set and in the treatment group. See <code>Details</code> section below.</p>
</td></tr>
<tr><td><code id="AsympDiscSurv_+3A_method">method</code></td>
<td>
<p>method for handling ties.</p>
</td></tr>
<tr><td><code id="AsympDiscSurv_+3A_tol">tol</code></td>
<td>
<p>a positive scalar giving the tolerance at which the maximum absolute value of the gradient is considered close enough to 0 to stop the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This calculates the asymptotic mean of the coefficient estimated by a proportional hazards regression model between two groups.
</p>
<p>If there are <code>r</code> intervals, the vectors need only be of length r-1 since all subjects reaching the final interval will be assumed to have an event at some time in the last interval.
</p>
<p><code>p0</code> and <code>p1</code> are not the survival curves because they also include information about the allocation ratio between groups and the censoring distribution. The j^th element of <code>p0</code> is the probability of being assigned to the control group and being at risk at time <code>time[j]</code>. <code>p0+p1</code> is always less than or equal to 1 and should be close to 1 at the first time point and decreasing with time.  Note that subjects censored at <code>time[j]</code> are not in the risk set, only subjects who have an event at this time or later or who are censored later. This definition of censoring time is the definition used in the reference and may be different than used in other places. Add 1 to all censored times if desired to force censoring to conform with the more standard ways. With equal allocation and no censoring, then <code>p0[1]=p1[1]=0.5</code>.
</p>


<h3>Value</h3>

<p>A list which contains:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the estimated coefficient (log-hazard ratio)</p>
</td></tr>
<tr><td><code>varn</code></td>
<td>
<p>the asymptotic variance multiplied by n where n is the total sample size combined in both groups</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Lawrence,<a href="mailto:john.lawrence@fda.hhs.gov">john.lawrence@fda.hhs.gov</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+LongToSurv">LongToSurv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
nsim=1
n=250
k=50
trt=c(rep(0,n),rep(1,n))
betaef=rep(0,nsim)
varef=betaef
betapg=betaef
varpg=betaef
m1=3.05
for (i in 1:nsim){
  x=rexp(2*n,1)
  x[(n+1):(2*n)]=x[(n+1):(2*n)]/2
  x=ceiling(x*(k-1)/m1)
  x=pmin(x,k)
  cens=rbinom(2*n,1,0.9)
  pg1=PrenticeGloeckler.test(x,cens,trt,k)
  betapg[i]=pg1$coefficient
  varpg[i]=(pg1$coefficient/pg1$wald.test)^2
  efron=survival::coxph(survival::Surv(x,cens)~trt,ties="efron")
  betaef[i]=efron$coef
  varef[i]=efron$var}

h0=0.9*(exp(-c(0:(k-2))*m1/(k-1))-exp(-c(1:(k-1))*m1/(k-1)))
h0=h0/(h0+exp(-c(1:(k-1))*m1/(k-1)))
p0=exp(-c(0:(k-1))*m1/(k-1))
p0=(p0[1:(k-1)]*0.9+p0[2:k]*0.1)/2
h1=0.9*(exp(-c(0:(k-2))*2*m1/(k-1))-exp(-c(1:(k-1))*2*m1/(k-1)))
h1=h1/(h1+exp(-c(1:(k-1))*2*m1/(k-1)))
p1=exp(-2*c(0:(k-1))*m1/(k-1))
p1=(p1[1:(k-1)]*0.9+p1[2:k]*0.1)/2

fa=AsympDiscSurv(h0=h0, h1=h1,p0=p0,p1=p1)
c(fa$estimate,fa$var/(2*n))
c(mean(betaef),var(betaef),mean(varef))

</code></pre>

<hr>
<h2 id='LongToSurv'>Longitudinal To Survival Function</h2><span id='topic+LongToSurv'></span>

<h3>Description</h3>

<p>This function calculates the survival curve for events where the events are defined by some function of a variable measured longitudinally. The events can be defined with or without confirmation (see arguments and details).  The survival curve is integrated over a distribution of covariates. The term &quot;covariates&quot; is used loosely here and includes all terms in the mixed effects longitudinal model including random effects and error terms. This distribution is assumed to be truncated multivariate normal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LongToSurv(M,V,L,U,time,p0f,p1f=NULL,method=c("simulation","asymptotic"),
  conf.type=c("scheduled","unscheduled","none"),nsim=100000)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LongToSurv_+3A_m">M</code></td>
<td>
<p>Mean vector for the parent multivariate normal distribution of the covariates.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_v">V</code></td>
<td>
<p>Covariance matrix for the parent multivariate normal distribution of the covariates.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_l">L</code></td>
<td>
<p>vector of lower limits for the covariates.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_u">U</code></td>
<td>
<p>vector of upper limits for the covariates.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_time">time</code></td>
<td>
<p>vector of time points.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_p0f">p0f</code></td>
<td>
<p>multi-valued function that calculates the probability of crossing the threshold at each sceduled visit time point in the control group. If <code>method="unscheduled"</code>, the probability of crossing the threshold at both the scheduled and subsequent unscheduled visit; even the last visit is assumed to allow an unscheduled confirmation visit.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_p1f">p1f</code></td>
<td>
<p>Optional multi-valued function that calculates the probability of crossing the threshold in the treatment group.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_method">method</code></td>
<td>
<p>Method used; either <code>"simulation"</code> or <code>"analytic"</code>. Defaults to <code>"simulation"</code>.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_conf.type">conf.type</code></td>
<td>
<p>type of confirmation. &quot;none&quot; meaing a single value crossing the threshold is an event, &quot;scheduled&quot; meaning two consecutive scheduled measurements crossing the threshold, or &quot;unscheduled&quot; meaning that after a qualifying event at a scheduled visit, a subsequent measurement is taken at an unscheduled visit to potentially confirm the event.</p>
</td></tr>
<tr><td><code id="LongToSurv_+3A_nsim">nsim</code></td>
<td>
<p>Approximate number of simulated covariate values used. Used only if method = <code>"simulation"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete survival function is found given a distribution of covariates and a longitudinal model. The event is defined by the response variable crossing a threshold value either once (confirmation = &quot;none&quot;) or twice in successive time points.  The distribution of the covariates is assumed to be truncated multivariate normal. If method is <code>"simulation"</code>, then /codensim/accept.rate values of the covariates are simulated first. The truncation conditions are tested and approximately <code>nsim</code> of these covariates will be accepted. The survival curve is found and averaged over the covariate values in the sample. If the method is <code>"analytic"</code>, then the survival curve function is integrated analytically (using the <code>adaptIntegrate</code> function from the <code>cubature</code> package).
</p>


<h3>Value</h3>

<p>A list consisting of:
</p>
<table>
<tr><td><code>times</code></td>
<td>
<p>numeric vector of time points</p>
</td></tr>
<tr><td><code>S0</code></td>
<td>
<p>numeric vector of survival beyond time t in the control group</p>
</td></tr>
<tr><td><code>S0err</code></td>
<td>
<p>numeric vector of the estimated standard error (or estimated absolute error for analytic method) of S0</p>
</td></tr>
<tr><td><code>S1</code></td>
<td>
<p>numeric vector of survival beyond time t in the test group.</p>
</td></tr>
<tr><td><code>S1err</code></td>
<td>
<p>numeric vector of the estimated standard error (or estimated absolute error for analytic method) of S1</p>
</td></tr>
<tr><td><code>accept.rate</code></td>
<td>
<p>estimate probability that a covariate vector from the parent multivariate normal disitrbution will lie between the truncation limits L and U.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Lawrence</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu.AGE = 38.582
mu.lbtkv = 6.9276
mu.base.leGFR = 4.2237
var.AGE = 220.73
var.lbtkv = 0.46848
var.base.leGFR=0.19770
cov.AGE.lbtkv = 3.4075
cov.AGE.leGFR = -4.5065
cov.lbtkv.leGFR = -0.16303
sig.intercept=0.03975
sig.time=0.04505
sig.cor=0.008
res.sd=0.11470307/sqrt(2)

M=c(mu.AGE,mu.lbtkv,mu.base.leGFR,0,0,0)
V=diag(c(var.AGE,var.lbtkv,var.base.leGFR+res.sd^2,res.sd^2,sig.intercept^2,sig.time^2))
V[1,2] = V[2,1] = cov.AGE.lbtkv
V[1,3] = V[3,1] = cov.AGE.leGFR
V[2,3] = V[3,2] = cov.lbtkv.leGFR
V[3,4] = V[4,3] = V[4,4]
V[5,6] = V[6,5] = sig.cor*sig.intercept*sig.time
L=c(18,6.9,3.9,-Inf,-Inf,-Inf)
U=c(40,8,5,Inf,Inf,Inf)
time=c(1:12)/4

p0f=function(x,t) {
  fixed.time=-0.337166
  fixed.age=0.0008176
  fixed.lbtkv=-0.02409
  fixed.leGFR0=0.09591
  trt.acute=-0.047759
  trt.chronic=0.0191574
  res.sd=0.11470307/sqrt(2)
  pnorm((log(0.7)-as.vector(x[5]+outer(x[6]+fixed.age*x[1]+fixed.lbtkv*x[2]+
  fixed.leGFR0*(x[3]-x[4])+fixed.time,t)-x[4]))/res.sd)
}

p1f=function(x,t) {
  fixed.time=-0.337166
  fixed.age=0.0008176
  fixed.lbtkv=-0.02409
  fixed.leGFR0=0.09591
  trt.acute=-0.047759
  trt.chronic=0.0191574
  res.sd=0.11470307/sqrt(2)
  pnorm((log(0.7)-as.vector(x[5]+trt.acute+outer(x[6]+fixed.age*x[1]+fixed.lbtkv*x[2]+
  fixed.leGFR0*(x[3]-x[4])+fixed.time+trt.chronic,t)-x[4]))/res.sd)
}

LTS1=LongToSurv(M,V,L,U,time,p0f,p1f,nsim=100) #nsim much larger than 100 is recommended
LTS1
#LTS2=LongToSurv(M,V,L,U,time,p0f,p1f,method="analytic")
#LTS2
</code></pre>

<hr>
<h2 id='PrenticeGloeckler.test'>Regression for Grouped Survival Data Function</h2><span id='topic+PrenticeGloeckler.test'></span>

<h3>Description</h3>

<p>This function calculates the estimated hazard ratio for grouped survival data described in the reference below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrenticeGloeckler.test(time,event,grp,r)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrenticeGloeckler.test_+3A_time">time</code></td>
<td>
<p>vector of times to event or censoring. The times are assumed to be integers from 1, 2, .., r corresponding to the discrete time points or the continuous time intervals A1, ..., Ar</p>
</td></tr>
<tr><td><code id="PrenticeGloeckler.test_+3A_event">event</code></td>
<td>
<p>vector of binary status indicator variables (0 = censored at the start of the interval, 1 = event during the interval)</p>
</td></tr>
<tr><td><code id="PrenticeGloeckler.test_+3A_grp">grp</code></td>
<td>
<p>vector of binary group indicators (0 or 1)</p>
</td></tr>
<tr><td><code id="PrenticeGloeckler.test_+3A_r">r</code></td>
<td>
<p>number of time points or intervals</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The hazard functions and hazard ratio are estimated for grouped survival data.
</p>


<h3>Value</h3>

<p>A list consisting of:
</p>
<table>
<tr><td><code>coefficient</code></td>
<td>
<p>The estimated coefficient (log hazard ratio) found by maximizing the likelihood.</p>
</td></tr>
<tr><td><code>indx</code></td>
<td>
<p>vector of time points where the hazard functions are estimated. The subset of <code>1,...,r-1</code> with at least one event.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>numeric vector with the same length as <code>indx</code> representing the log(-log(hazard rate)) in the control group for time points in the vector <code>indx</code></p>
</td></tr>
<tr><td><code>grad1</code></td>
<td>
<p>gradient evaluated at <code>(gamma[indx],ceofficient)</code></p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>number of time points or time intervals</p>
</td></tr>
<tr><td><code>hess1</code></td>
<td>
<p>hessian matrix evaluated at the maximum likelihood estimate.</p>
</td></tr>
<tr><td><code>ll0</code></td>
<td>
<p>log-likelihood evaluated at ceofficient=0. includes attributes <code>"gradient"</code> and <code>"hessian"</code></p>
</td></tr>
<tr><td><code>ll1</code></td>
<td>
<p>log-likelihood at maximum likeohood estimate.  includes attributes <code>"gradient"</code> and <code>"hessian"</code></p>
</td></tr>
<tr><td><code>score.test</code></td>
<td>
<p>value of the score test statistic for testing coefficient=0 (see reference).</p>
</td></tr>
<tr><td><code>lr.test</code></td>
<td>
<p>value of the likelihood ratio test statistic, 2*(ll0-ll1)</p>
</td></tr>
<tr><td><code>wald.test</code></td>
<td>
<p>value of the Wald test statistic; the estimated coefficient divided by the square root of the estimated variance.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Lawrence</p>


<h3>References</h3>

<p>Prentice, R. L. and Gloeckler, L.A. (1978). Regression analysis of grouped survival data with application to breast cancer data. <em>Biometrics</em>, 57 &ndash; 67
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
nsim=1
n=250
tn=2*n
k=0.1*tn
betaef=rep(0,nsim)
betapg=rep(0,nsim)
cens=rep(1,2*n)
trt=c(rep(0,n),rep(1,n))

for (i in 1:nsim) {
  x=rexp(tn,1)
  x[(n+1):tn]=x[(n+1):tn]/2
  m1=max(x[(n+1):tn])
  x=ceiling(x*(k-1)/m1)
  x[(n+1):tn]=pmin(x[(n+1):tn],k-1)
  x[1:n]=pmin(x[1:n],k)
  pg1=PrenticeGloeckler.test(x,cens,trt,k)
  betapg[i]=pg1$coefficient
  betaef[i]=survival::coxph(survival::Surv(x,cens)~trt,ties="efron")$coef}
mean(betaef)
mean(betapg)
</code></pre>

<hr>
<h2 id='print.PrenticeGloeckler.test'>Print Regression for Grouped Survival Data Function Object</h2><span id='topic+print.PrenticeGloeckler.test'></span>

<h3>Description</h3>

<p>Print coefficient returned by PrenticeGloeckler function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PrenticeGloeckler.test'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.PrenticeGloeckler.test_+3A_x">x</code></td>
<td>
<p>object of class PrenticeGloeckler.test returned by call to PrenticeGloeckler function.</p>
</td></tr>
<tr><td><code id="print.PrenticeGloeckler.test_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the coefficient, the estimated log-hazard ratio.
</p>


<h3>Author(s)</h3>

<p>John Lawrence</p>


<h3>See Also</h3>

<p><code><a href="#topic+PrenticeGloeckler.test">PrenticeGloeckler.test</a></code></p>

<hr>
<h2 id='print.SSDS'>Print Sample Size Discrete Survival Object</h2><span id='topic+print.SSDS'></span>

<h3>Description</h3>

<p>Print coefficient returned by SampleSizeDiscSurv function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SSDS'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.SSDS_+3A_x">x</code></td>
<td>
<p>object of class SSDS returned by call to  SampleSizeDiscSurv function.</p>
</td></tr>
<tr><td><code id="print.SSDS_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints a few sentences describing the results of the call to the SampleSizeDiscSurv function.
</p>


<h3>Author(s)</h3>

<p>John Lawrence</p>


<h3>See Also</h3>

<p><code><a href="#topic+SampleSizeDiscSurv">SampleSizeDiscSurv</a></code></p>

<hr>
<h2 id='rowMSD'>Mean and Standard Deviation estimates for each row in a matrix</h2><span id='topic+rowMSD'></span>

<h3>Description</h3>

<p>Calculates the sample mean and standard deviation for each row in a matrix. The mean vector is calculated first. The elements of the matrix are then centered by the mean vector before the sample standard deviation is calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowMSD(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rowMSD_+3A_x">x</code></td>
<td>
<p>numeric matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consisting of:
</p>
<table>
<tr><td><code>rm</code></td>
<td>
<p>vector of row means</p>
</td></tr>
<tr><td><code>rsd</code></td>
<td>
<p>vector of row standard deviations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Lawrence</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(1000),nrow=10)
rowMSD(x)
</code></pre>

<hr>
<h2 id='SampleSizeDiscSurv'>Sample Size for Discrete Time Survival</h2><span id='topic+SampleSizeDiscSurv'></span>

<h3>Description</h3>

<p>Calculates the sample size needed to achieve any given power for any specifed type 1 error rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SampleSizeDiscSurv(power=0.9,alpha=0.025,alternative=c("less","greater"),beta0=0,
  h0,h1,p0,p1,ties.method=c("efron","breslow","PrenticeGloeckler"),
  method=c("asymptotic","simulation"),tol,AMV=NULL,nsim=10000,Nvec=NULL,
  test=c("Wald","Score"))
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SampleSizeDiscSurv_+3A_power">power</code></td>
<td>
<p>scalar value of the desired power. Default value is 0.9.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_alpha">alpha</code></td>
<td>
<p>scalar value of the one-sided type 1 error rate. Default value is 0.025.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_alternative">alternative</code></td>
<td>
<p>character specifying the type of alternative</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_beta0">beta0</code></td>
<td>
<p>scalar value of the log-hazard ratio on the boundary of the null hypothesis. Default is 0.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_h0">h0</code></td>
<td>
<p>vector of length r-1 containing the postulated hazard rates in the control group for the times 1, ..., r-1 or corresponding time intervals. Assumed to be r intervals with the last interval being infinite.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_h1">h1</code></td>
<td>
<p>vector of postulated hazard rates in the treatment group</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_p0">p0</code></td>
<td>
<p>vector of probabilities of being in the risk set and in the control group. See <code>Details</code> section below.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_p1">p1</code></td>
<td>
<p>vector of probabilities of being in the risk set and in the treatment group. See <code>Details</code> section below.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_ties.method">ties.method</code></td>
<td>
<p>method for handling ties.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_method">method</code></td>
<td>
<p>character specifiying the asymptotic or simalution based method for determining the sample size.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_tol">tol</code></td>
<td>
<p>a positive scalar giving the tolerance at which the maximum absolute value of the gradient is considered close enough to 0 to stop the algorithm used if <code>method="asymptotic"</code>.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_amv">AMV</code></td>
<td>
<p>AsympDiscSurv object from a previous call to the AsympDiscSurv function.</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_nsim">nsim</code></td>
<td>
<p>number of simulations used per <code>N</code> value in the <code>Nvec</code> vector. Used only if <code>method="simulation"</code></p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_nvec">Nvec</code></td>
<td>
<p>vector of sample sizes used in simulation based method. If none specifed, default is to use two N values close to the estimate from the asymptotic method (see details below).</p>
</td></tr>
<tr><td><code id="SampleSizeDiscSurv_+3A_test">test</code></td>
<td>
<p>character specifying the type of test statistics used. Used only for simulation based method because asymptotically, the tests are equivalent.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method="asymptotic"</code>, then the mean of the test statistic (wald or score, which are equivalent asymptotically) for a sample size divided by sqrt(N) converges to a constant. This constant is found from the parameters in the result of the call to AsympDiscSurv. If the AsympDiscSurv object has already been found, it can be passed to this function in the arguments. If not, then this function calls AsympDiscSurv to find those paraemters.
</p>
<p>If <code>method="simulation"</code>, then the mean of the test statistic is found for each sample size in the <code>Nvec</code> vector. The mean and variance of the test statistic for each <code>N</code> is found. Then, a linear regression is used to find the sample size that will provide the correct power. Each test statistic is asumed to have a mean that depends on sqrt(N) and the same variance. Theoretically, the variance should be close to 1, but the variance is estimated from the simulated values (not assumed equal to 1). The normality assumption is usually satisfied if the number of events is sufficiently large.
</p>
<p>Neither the simulation nor the asymptotic method is reliable if the expected number of events is small (say, less than 20). The asymptotic method is faster. However, the simulation method has several advantages. First, the asymptotic variance found by the AsympDiscSurv function can differ from the true variance by a few percent even for moderately large sample sizes. The simulation based method estimates the true variance by simulation. Second, for moderatley large sample sizes, the score test can be different from the Wald test. Third, asymptotically the mean of the test statistic is approximately constant times sqrt(N), i.e. a linear function of sqrt(N) with no intercept. But, for small N, the relationship may not be so simple. The simulation method models the relationship for values of N close to the target value without making this strong assumption. The simulation method still assumes that the test statistic is normally distributed, so may be inaccurate for very small sample sizes or rare events.
</p>
<p>Iy is assumed there are <code>r</code> time intervals, the vectors defining the hazard and at-risk rates have length <code>r-1</code> since all subjects reaching the final interval must have an event at some time in the last interval.
</p>
<p><code>p0</code> and <code>p1</code> are not the survival curves because they also include information about the allocation ratio between groups and the censoring distribution. The j^th element of <code>p0</code> is the probability of being assigned to the control group and being at risk at time <code>time[j]</code>. <code>p0+p1</code> is always less than or equal to 1 and should be close to 1 at the first time point and decreasing with time.  Note that subjects censored at <code>time[j]</code> are not in the risk set, only subjects who have an event at this time or later or who are censored later. This definition of censoring time is the definition used in the reference and may be different than used in other places. Add 1 to all censored times if desired to force censoring to conform with the more standard ways. With equal allocation and no censoring, then <code>p0[1]=p1[1]=0.5</code>.
</p>


<h3>Value</h3>

<p>An object of class SSDS, which is a list containing:
</p>
<table>
<tr><td><code>N</code></td>
<td>
<p>sample size that should provide the correct power</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>character specifying the type of alternative</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p>scalar value of the log-hazard ratio on the boundary of the null hypothesis. Default is 0.</p>
</td></tr>
<tr><td><code>ties.method</code></td>
<td>
<p>method for handling ties.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>character specifiying the asymptotic or simalution based method for determining the sample size.</p>
</td></tr>
<tr><td><code>AMV</code></td>
<td>
<p>AsympDiscSurv object</p>
</td></tr>
<tr><td><code>EZobj</code></td>
<td>
<p>required expected value of the test statistic</p>
</td></tr>
<tr><td><code>Nvec</code></td>
<td>
<p>vector of sample sizes used in the simulation</p>
</td></tr>
<tr><td><code>EZvec</code></td>
<td>
<p>vector of mean values of the test statistic for each value of N</p>
</td></tr>
<tr><td><code>VZvec</code></td>
<td>
<p>vector of sample variances for each value of N</p>
</td></tr>
<tr><td><code>int.est</code></td>
<td>
<p>estimate of the intercept in the linear relationship between sqrt(N) and expected value of the test statistic.</p>
</td></tr>
<tr><td><code>slope.est</code></td>
<td>
<p>estimate of the slope in the linear relationship between sqrt(N) and expected value of the test statistic.</p>
</td></tr>
<tr><td><code>nsim</code></td>
<td>
<p>number of simulations used per <code>N</code> value in the <code>Nvec</code> vector. Used only if <code>method="simulation"</code></p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>character specifying the type of test statistics used. Used only for simulation based method because asymptotically,
the tests are equivalent.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Lawrence,<a href="mailto:john.lawrence@fda.hhs.gov">john.lawrence@fda.hhs.gov</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+LongToSurv">LongToSurv</a></code>,<code><a href="#topic+AsympDiscSurv">AsympDiscSurv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
k=50
m1=3.05

h0=0.9*(exp(-c(0:(k-2))*m1/(k-1))-exp(-c(1:(k-1))*m1/(k-1)))
h0=h0/(h0+exp(-c(1:(k-1))*m1/(k-1)))
p0=exp(-c(0:(k-1))*m1/(k-1))
p0=(p0[1:(k-1)]*0.9+p0[2:k]*0.1)/2
h1=0.9*(exp(-c(0:(k-2))*2*m1/(k-1))-exp(-c(1:(k-1))*2*m1/(k-1)))
h1=h1/(h1+exp(-c(1:(k-1))*2*m1/(k-1)))
p1=exp(-2*c(0:(k-1))*m1/(k-1))
p1=(p1[1:(k-1)]*0.9+p1[2:k]*0.1)/2

fa=AsympDiscSurv(h0=h0,h1=h1,p0=p0,p1=p1)

(SSDS1=SampleSizeDiscSurv(power=0.9,alpha=0.025,alternative="greater",beta0=0,h0,h1,
  p0,p1,ties.method="efron",method="asymptotic",AMV=fa,Nvec=NULL,test="Wald"))

</code></pre>

<hr>
<h2 id='simexlme'>SIMEX algorithm for linear mixed effects models</h2><span id='topic+simexlme'></span>

<h3>Description</h3>

<p>Implementation of the SIMEX algorithm for measurement error models according
to Cook and Stefanski.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simexlme(model, model.model, SIMEXvariable, respvar, grpvar, corform, measurement.error,
  measurement.error.resp, lambda = c(0.5, 1, 1.5, 2), B = 100,
  fitting.method = "quadratic", jackknife.estimation = "quadratic")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simexlme_+3A_model">model</code></td>
<td>
<p>naive model</p>
</td></tr>
<tr><td><code id="simexlme_+3A_model.model">model.model</code></td>
<td>
<p>dataframe containing all variables in the model</p>
</td></tr>
<tr><td><code id="simexlme_+3A_simexvariable">SIMEXvariable</code></td>
<td>
<p>character name of the variable with measurement error. Assumed to be the baseline measurement.</p>
</td></tr>
<tr><td><code id="simexlme_+3A_respvar">respvar</code></td>
<td>
<p>character name of the response variable. The response is assumed to represent a change from baseline.</p>
</td></tr>
<tr><td><code id="simexlme_+3A_grpvar">grpvar</code></td>
<td>
<p>character name of the grouping variable for the random effects in the model.</p>
</td></tr>
<tr><td><code id="simexlme_+3A_corform">corform</code></td>
<td>
<p>formula for the correlation of residual errors within groups. see example</p>
</td></tr>
<tr><td><code id="simexlme_+3A_measurement.error">measurement.error</code></td>
<td>
<p>The known standard deviation of measurement errors for <code>SIMEXvariable</code>.</p>
</td></tr>
<tr><td><code id="simexlme_+3A_measurement.error.resp">measurement.error.resp</code></td>
<td>
<p>The known stadard deviaiton for <code>respvar</code></p>
</td></tr>
<tr><td><code id="simexlme_+3A_lambda">lambda</code></td>
<td>
<p>vector of lambdas for which the simulation step should be done</p>
</td></tr>
<tr><td><code id="simexlme_+3A_b">B</code></td>
<td>
<p>number of iterations for each lambda</p>
</td></tr>
<tr><td><code id="simexlme_+3A_fitting.method">fitting.method</code></td>
<td>
<p>fitting method for extrapolation. Only <code>linear</code> or <code>quadratic</code> are recommended.</p>
</td></tr>
<tr><td><code id="simexlme_+3A_jackknife.estimation">jackknife.estimation</code></td>
<td>
<p>specifying the extrapolation method for jackknife variance estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See documentation for <code><a href="simex.html#topic+mcsimex">mcsimex</a></code> function. This function for lme models was adapted from that function, which is designed to handle linear and generalized linear models, but not lme models. In this function, the measurement error variable must be the baseline value of some measurement and the response is the change from baseline in the same measurement. There is assumed to be one value of this baseline measurement per level of the grouping variable in the mixed effect model. The correlation between the measurement errors for two response values within a subject is assumed to be equal to be equal to the variance of baseline divided by the sum of the variance of baseline and variance of post-baseline errors. For example, for a study measuring the effect of some weight loss treatment, the grouping variable could be subject, the baseline weight is the covariate with measurement error and the response is change from baseline in weight.</p>


<h3>Value</h3>

<p>An object of class 'simex' which contains:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the corrected coefficients of the SIMEX model</p>
</td></tr>
<tr><td><code>SIMEX.estimates</code></td>
<td>
<p>the estimates for every lambda</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the naive model</p>
</td></tr>
<tr><td><code>measurement.error</code></td>
<td>
<p>the known error standard deviations for <code>SIMEXvariable</code></p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>the number of iterations</p>
</td></tr>
<tr><td><code>extrapolation</code></td>
<td>
<p>the model object of the extrapolation step</p>
</td></tr>
<tr><td><code>fitting.method</code></td>
<td>
<p>the fitting method used in the extrapolation step</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals of the main model</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted values of the main model</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>variance.jackknife</code></td>
<td>
<p>the jackknife variance estimate</p>
</td></tr>
<tr><td><code>extrapolation.variance</code></td>
<td>
<p>the model object of the variance extrapolation</p>
</td></tr>
<tr><td><code>variance.jackknife.lambda</code></td>
<td>
<p>the data set for the extrapolation</p>
</td></tr>
<tr><td><code>variance.asymptotic</code></td>
<td>
<p>the asymptotic variance estimates</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>the estimates for every B and lambda</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Lawrence,<a href="mailto:john.lawrence@fda.hhs.gov">john.lawrence@fda.hhs.gov</a>, Jianjin Xu, Wolfgang Lederer, Heidi Seibold</p>


<h3>References</h3>

<p>Cook, J.R. and Stefanski, L.A. (1994) Simulation-extrapolation estimation in
parametric measurement error models. <em>Journal of American Statistical
Association</em>, <b>89</b>, 1314 &ndash; 1328
</p>


<h3>See Also</h3>

<p><code><a href="simex.html#topic+simex">simex</a></code>,<code><a href="nlme.html#topic+lme">lme</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
data("simGFRdata")
simGFR=simGFR[is.element(simGFR$time,c(1:12)/4) &amp; is.element(simGFR$PID,c(1:80)*100),]

fm2=nlme::lme.formula(fixed = cfb ~ time + x1:time + trt + trt:time + trt:x1:time + 0,
                data = simGFR, random = ~time | PID,
                correlation = nlme::corCompSymm(0.5,form = ~time | PID, fixed = TRUE),
                control=nlme::lmeControl(returnObject=TRUE))

(s1 = simexlme(model=fm2, model.model=simGFR[,c("cfb","PID","time","x1","trt")],
                SIMEXvariable="x1",respvar="cfb",grpvar="PID",corform="~time | PID",
                measurement.error=res.sd,measurement.error.resp=res.sd,
                lambda = c(0.5,2),B = 2, fitting.method = "linear",
                jackknife.estimation = FALSE))

plot(s1)

#values of fixed effects used to simulate data
c(fixed.time,fixed.trt,fixed.leGFR,fixed.trttime,fixed.leGFRtrt)

#naive estimates
fm2$coefficients$fixed

#SIMEX corrected estimates
s1$coefficients
</code></pre>

<hr>
<h2 id='simGFRdata'>Data Set Containing Simulated Longitudinal eGFR</h2><span id='topic+simGFRdata'></span><span id='topic+simGFR'></span><span id='topic+fix.beta'></span><span id='topic+fixed.leGFR'></span><span id='topic+fixed.leGFRtrt'></span><span id='topic+fixed.time'></span><span id='topic+fixed.trt'></span><span id='topic+fixed.trttime'></span><span id='topic+mu.base.leGFR'></span><span id='topic+var.base.leGFR'></span><span id='topic+res.sd'></span><span id='topic+sig.intercept'></span><span id='topic+sig.time'></span><span id='topic+sig.cor'></span>

<h3>Description</h3>

<p>A data set containing simulated values of log-eGFR measured longitudinally over time as a function of baseline eGFR.
The data were simulated from a mixed effects model with the following form (using the lme model structure syntax; see format section below
for definition of variables):
</p>
<p>cfb ~ time + x1:time + trt + trt:time + trt:x1:time + 0
</p>
<p>and these coefficients:
</p>
<p>time         trt     time:x1    time:trt time:x1:trt
-0.6447911  -0.0478315   0.1333391   0.2186963  -0.0458998
</p>
<p>In addition, each subject has a random slope and intercept. The baseline eGFR were simulated from a log-Normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(simGFRdata)</code></pre>


<h3>Format</h3>

<p>Fixed effect coefficients used to simulate the data:
fix.beta
fixed.leGFR
fixed.leGFRtrt
fixed.time
fixed.trt
fixed.trttime
</p>
<p>mu.base.leGFR: mean of baseline log-eGFR
var.base.leGFR: variance of baseline log-eGFR
</p>
<p>res.sd: residual error standard deviation. note this is for a single log-eGFR, so the standard deviation for the change from baseline is sqrt(2)*res.sd and the residual error for cfb within a patient have correlation 0.5.
</p>
<p>Variance components of random effects distribution:
sig.intercept: standard deviaiton of random intercept
sig.time: standrd deviation of random slope
sig.cor: correlation
</p>
<p>A data frame named simGFR that consists of fourteen columns and 28800 rows. The variables are:
PID: patient ID
trt: the treatment group indicator
x1: measured value of baseline log-eGFR
time: time from baseline measured in years
alphai: subject's random intercept
betai: subject's random slope
alpha: subject's intercept including fixed and random effects
beta: subject's slope including fixed and random effects
cfb0: the measurement error for the baseline log-eGFR
x: the unobserved &quot;true&quot; baseline log-eGFR
cfb: the change from baseline in measured log-eGFR
</p>

<hr>
<h2 id='TKVsurv'>Data Set Containing Fitted Model Estimates and Covariances</h2><span id='topic+TKVsurv'></span>

<h3>Description</h3>

<p>A data set containing the estimates fromthe fitted Cox proportional hazards model from a dataset of patients with Autosomal Dominant Polycystic Kideny Disease. See references for further details. The model has 6 parameters describing how the hazard changes for different levels of the 3 covariates. In addition, there are 3 strata correspoding to the different imaging modalities: CT, MRI, US.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(TKVsurv)</code></pre>


<h3>Format</h3>

<p>A list with the following components
covariates: names of covariates
mean: sample mean of covariates
stand.dev.: standard deviation of covariates
labels: labels for coefficients and rows and columns of covariance matrix sigma
beta: estimated coefficients in the proportional hazards model
sigma: estimated covariance martix for beta
CT.time: time points where Survival curve changes for CT strata
CT.lcumhaz: estimated log-cumulative hazard in CT strata with coefficients = 0
CT.sig17: estimated 7 elements to fill the last row (and last column) of the covariance matrix
MRI.time: time points where Survival curve changes for MRI strata
MRI.lcumhaz: estimated log-cumulative hazard in MRI strata with coefficients = 0
MRI.sig17: estimated 7 elements to fill the last row (and last column) of the covariance matrix
US.time: time points where Survival curve changes for US strata
US.lcumhaz: estimated log-cumulative hazard in US strata with coefficients = 0
US.sig17: estimated 7 elements to fill the last row (and last column) of the covariance matrix
</p>


<h3>Author(s)</h3>

<p>John Lawrence, Jianjin Xu, Jim Hung, Sue Jane Wang</p>


<h3>References</h3>

<p>http://www.fda.gov/downloads/Drugs/DevelopmentApprovalProcess/DrugDevelopmentToolsQualificationProgram/UCM458523.pdf
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
