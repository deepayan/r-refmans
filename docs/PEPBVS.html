<!DOCTYPE html><html><head><title>Help for package PEPBVS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PEPBVS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#PEPBVS-package'><p>Bayesian variable selection using power-expected-posterior prior</p></a></li>
<li><a href='#full_enumeration_pep'><p>Bayesian variable selection through exhaustive search</p></a></li>
<li><a href='#image.pep'><p>Heatmap for top models</p></a></li>
<li><a href='#mc3_pep'><p>Bayesian variable selection with MC3 algorithm</p></a></li>
<li><a href='#plot.pep'><p>Plots for object of class pep</p></a></li>
<li><a href='#predict.pep'><p>Prediction under PEP approach</p></a></li>
<li><a href='#print.pep'><p>Printing object of class pep</p></a></li>
<li><a href='#UScrime_data'><p>US Crime Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Variable Selection using Power-Expected-Posterior Prior</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-14</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Konstantina Charmpi &lt;xarmpi.kon@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs Bayesian variable selection under normal linear
          models for the data with the model parameters following as prior either 
          the power-expected-posterior (PEP) or the intrinsic (a special case of the former)
          (Fouskakis and Ntzoufras (2022) &lt;<a href="https://doi.org/10.1214%2F21-BA1288">doi:10.1214/21-BA1288</a>&gt;,
          Fouskakis and Ntzoufras (2020) &lt;<a href="https://doi.org/10.3390%2Feconometrics8020017">doi:10.3390/econometrics8020017</a>&gt;).          
          The prior distribution on model space is the uniform on model space
          or the uniform on model dimension (a special case of the beta-binomial prior). 
          The selection can be done either with full enumeration of all 
          possible models or using the Markov Chain Monte Carlo Model Composition (MC3) 
          algorithm (Madigan and York (1995) &lt;<a href="https://doi.org/10.2307%2F1403615">doi:10.2307/1403615</a>&gt;). 
          Complementary functions for making predictions, as well as plotting and 
          printing the results are also provided.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, Rcpp (&ge; 1.0.9)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppGSL</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU GSL</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-15 15:09:54 UTC; k.charbi</td>
</tr>
<tr>
<td>Author:</td>
<td>Konstantina Charmpi [aut, cre],
  Dimitris Fouskakis [aut],
  Ioannis Ntzoufras [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-19 16:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='PEPBVS-package'>Bayesian variable selection using power-expected-posterior prior</h2><span id='topic+PEPBVS-package'></span>

<h3>Description</h3>

<p>Performs Bayesian variable selection under normal linear
models for the data with the model parameters following as prior either
the PEP or the intrinsic (a special case of the former). 
The prior distribution on model space is the 
uniform on model space or the uniform on model dimension (a special case 
of the beta-binomial prior). Posterior model probabilities and marginal
likelihoods can be derived in closed-form expressions under this setup. 
The selection can be done either with full enumeration of all possible 
models (for small–to–moderate model spaces) or using the MC3 algorithm 
(for large model spaces). Complementary functions for making predictions, 
as well as plotting and printing the results are also available.
</p>


<h3>References</h3>

<p>Fouskakis, D. and Ntzoufras, I. (2022) Power-Expected-Posterior 
Priors as Mixtures of g-Priors in Normal Linear Models. 
Bayesian Analysis, 17(4): 1073-1099. <a href="https://doi.org/10.1214/21-BA1288">doi:10.1214/21-BA1288</a>
</p>
<p>Fouskakis, D. and Ntzoufras, I. (2020) Bayesian Model Averaging Using 
Power-Expected-Posterior Priors. 
Econometrics, 8(2): 17. <a href="https://doi.org/10.3390/econometrics8020017">doi:10.3390/econometrics8020017</a>
</p>

<hr>
<h2 id='full_enumeration_pep'>Bayesian variable selection through exhaustive search</h2><span id='topic+full_enumeration_pep'></span>

<h3>Description</h3>

<p>Given a response vector and an input data matrix, performs Bayesian variable 
selection using full enumeration of the model space. Normal linear 
models are assumed for the data with the prior distribution on the model 
parameters (beta coefficients and error variance) being the PEP or the intrinsic. 
The prior distribution on the model space can be the uniform on the model 
space or the uniform on the model dimension (special case of the beta-binomial prior).
The model space consists of all possible models including an intercept term.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>full_enumeration_pep(
  x,
  y,
  intrinsic = FALSE,
  reference.prior = TRUE,
  beta.binom = TRUE,
  ml_constant.term = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="full_enumeration_pep_+3A_x">x</code></td>
<td>
<p>A matrix of numeric (of size nxp), input data matrix. 
This matrix contains the values of the p explanatory variables 
without an intercept column of 1's.</p>
</td></tr>
<tr><td><code id="full_enumeration_pep_+3A_y">y</code></td>
<td>
<p>A vector of numeric (of length n), response vector.</p>
</td></tr>
<tr><td><code id="full_enumeration_pep_+3A_intrinsic">intrinsic</code></td>
<td>
<p>Boolean, indicating whether the PEP 
(<code>FALSE</code>) or the intrinsic - which   
is a special case of it - (<code>TRUE</code>) should be used as prior on the  
regression parameters. Default value=<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="full_enumeration_pep_+3A_reference.prior">reference.prior</code></td>
<td>
<p>Boolean, indicating whether the reference prior
(<code>TRUE</code>) or the dependence Jeffreys prior (<code>FALSE</code>) is used as 
baseline. Default value=<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="full_enumeration_pep_+3A_beta.binom">beta.binom</code></td>
<td>
<p>Boolean, indicating whether the beta-binomial 
distribution (<code>TRUE</code>) or the uniform distribution (<code>FALSE</code>)    
should be used as prior on the model space. Default value=<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="full_enumeration_pep_+3A_ml_constant.term">ml_constant.term</code></td>
<td>
<p>Boolean, indicating whether the constant
(marginal likelihood of the null/intercept-only model) should be
included in computing the marginal likelihood of a model (<code>TRUE</code>)  
or not (<code>FALSE</code>). Default value=<code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works when p&lt;=n-2 where p is the number of explanatory variables
and n is the sample size.
</p>
<p>It is suggested to use this function (i.e. enumeration of the model space) 
when p is up to 20.
</p>
<p>The reference model is the null model (i.e. intercept-only model).
</p>
<p>The case of missing data (i.e. presence of <code>NA</code>'s either in the  
input data matrix or the response vector) is not currently supported.
</p>
<p>All models considered (i.e. model space) include an intercept term.
</p>
<p>If p&gt;1, the input data matrix needs to be of full rank.
</p>
<p>The reference prior as baseline corresponds to hyperparameter values
d0=0 and d1=0, while the dependence Jeffreys prior corresponds to 
model-dependent-based values for the hyperparameters d0 and d1,
see Fouskakis and Ntzoufras (2022) for more details.
</p>
<p>For computing the marginal likelihood of a model, Equation 16 of 
Fouskakis and Ntzoufras (2022) is used.
</p>
<p>When <code>ml_constant.term=FALSE</code> then the log marginal likelihood of a
model in the output is shifted by -logC1
(logC1: log marginal likelihood of the null model).
</p>
<p>When the prior on the model space is beta-binomial 
(i.e. <code>beta.binom=TRUE</code>), the following special case is used: uniform 
prior on model dimension.
</p>


<h3>Value</h3>

<p><code>full_enumeration_pep</code> returns an object of class <code>pep</code>, 
i.e. a list with the following elements:
</p>
<table>
<tr><td><code>models</code></td>
<td>
<p>A matrix containing information about the models examined. 
In particular, in row i after representing the model i with variable inclusion 
indicators, its marginal likelihood (in log scale), the R2, its dimension  
(including the intercept), the corresponding Bayes factor, 
posterior odds and its posterior probability are contained. The models
are sorted in decreasing order of the posterior probability. For the 
Bayes factor and the posterior odds, the comparison is done to the model 
with the largest posterior probability.</p>
</td></tr>
<tr><td><code>inc.probs</code></td>
<td>
<p>A named vector with the posterior inclusion probabilities of the 
explanatory variables.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The input data matrix (of size nxp).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response vector (of length n).</p>
</td></tr>
<tr><td><code>intrinsic</code></td>
<td>
<p>Whether the prior on the model parameters was PEP or intrinsic.</p>
</td></tr>
<tr><td><code>reference.prior</code></td>
<td>
<p>Whether the baseline prior was the reference prior
or the dependence Jeffreys prior.</p>
</td></tr>
<tr><td><code>beta.binom</code></td>
<td>
<p>Whether the prior on the model space was beta-binomial or
uniform.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Fouskakis, D. and Ntzoufras, I. (2022) Power-Expected-Posterior 
Priors as Mixtures of g-Priors in Normal Linear Models. 
Bayesian Analysis, 17(4): 1073-1099. <a href="https://doi.org/10.1214/21-BA1288">doi:10.1214/21-BA1288</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mc3_pep">mc3_pep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(UScrime_data)
y &lt;- UScrime_data[,"y"]
X &lt;- UScrime_data[,-15]
res &lt;- full_enumeration_pep(X,y)
resu &lt;- full_enumeration_pep(X,y,beta.binom=FALSE)
resi &lt;- full_enumeration_pep(X,y,intrinsic=TRUE)
resiu &lt;- full_enumeration_pep(X,y,intrinsic=TRUE,beta.binom=FALSE)
resj &lt;- full_enumeration_pep(X,y,reference.prior=FALSE)

</code></pre>

<hr>
<h2 id='image.pep'>Heatmap for top models</h2><span id='topic+image.pep'></span>

<h3>Description</h3>

<p>Generates a heatmap where the rows correspond to the (top) models
and the columns to the input/explanatory variables. The value depicted
in cell (i,j) corresponds to the posterior inclusion probability of variable i if this
is included in model j and 0 otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pep'
image(x, n.models = 20, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="image.pep_+3A_x">x</code></td>
<td>
<p>An object of class pep (e.g. output of <code>full_enumeration_pep</code> 
or <code>mc3_pep</code>).</p>
</td></tr>
<tr><td><code id="image.pep_+3A_n.models">n.models</code></td>
<td>
<p>Positive integer, number of models to be shown on the 
heatmap. Default value=20.</p>
</td></tr>
<tr><td><code id="image.pep_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to <code>heatmap</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of models to be displayed on the heatmap is computed as the minimum
between the number asked by the user and the number of models present in
the object <code>x</code>.
</p>
<p>The color code is as follows: the darker the blue in the figure, the 
higher the posterior inclusion probability is, while white means that the 
variable is not included in the model.
</p>
<p>In the special case of no explanatory variables, no heatmap is produced
and a message is printed.
</p>


<h3>Value</h3>

<p>No return value, used for generating a heatmap.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.pep">plot.pep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(UScrime_data)
y &lt;- UScrime_data[,"y"]
X &lt;- UScrime_data[,-15]
set.seed(123)
resu &lt;- mc3_pep(X,y,beta.binom=FALSE,itermc3=5000)
image(resu)
image(resu,n.models=10)

</code></pre>

<hr>
<h2 id='mc3_pep'>Bayesian variable selection with MC3 algorithm</h2><span id='topic+mc3_pep'></span>

<h3>Description</h3>

<p>Given a response vector and an input data matrix, performs Bayesian variable 
selection using the MC3 algorithm. Normal linear models are assumed for 
the data with the prior distribution on the model parameters 
(beta coefficients and error variance) being the PEP or the intrinsic. The prior 
distribution on the model space can be the uniform on the model 
space or the uniform on the model dimension (special case of the beta-binomial prior).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mc3_pep(
  x,
  y,
  intrinsic = FALSE,
  reference.prior = TRUE,
  beta.binom = TRUE,
  ml_constant.term = FALSE,
  burnin = 1000,
  itermc3 = 11000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mc3_pep_+3A_x">x</code></td>
<td>
<p>A matrix of numeric (of size nxp), input data matrix.
This matrix contains the values of the p explanatory variables 
without an intercept column of 1's.</p>
</td></tr>
<tr><td><code id="mc3_pep_+3A_y">y</code></td>
<td>
<p>A vector of numeric (of length n), response vector.</p>
</td></tr>
<tr><td><code id="mc3_pep_+3A_intrinsic">intrinsic</code></td>
<td>
<p>Boolean, indicating whether the PEP 
(<code>FALSE</code>) or the intrinsic - which   
is a special case of it - (<code>TRUE</code>) should be used as prior on the  
regression parameters. Default value=<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mc3_pep_+3A_reference.prior">reference.prior</code></td>
<td>
<p>Boolean, indicating whether the reference prior
(<code>TRUE</code>) or the dependence Jeffreys prior (<code>FALSE</code>) is used as 
baseline. Default value=<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="mc3_pep_+3A_beta.binom">beta.binom</code></td>
<td>
<p>Boolean, indicating whether the beta-binomial 
distribution (<code>TRUE</code>) or the uniform distribution (<code>FALSE</code>)    
should be used as prior on the model space. Default value=<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="mc3_pep_+3A_ml_constant.term">ml_constant.term</code></td>
<td>
<p>Boolean, indicating whether the constant
(marginal likelihood of the null/intercept-only model) should be
included in computing the marginal likelihood of a model (<code>TRUE</code>)  
or not (<code>FALSE</code>). Default value=<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mc3_pep_+3A_burnin">burnin</code></td>
<td>
<p>Non-negative integer, the burnin period for the MC3 algorithm.
Default value=1000.</p>
</td></tr>
<tr><td><code id="mc3_pep_+3A_itermc3">itermc3</code></td>
<td>
<p>Positive integer (larger than <code>burnin</code>),
the (total) number of iterations for the MC3 algorithm. Default value=11000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works when p&lt;=n-2 where p is the number of explanatory variables
and n is the sample size.
</p>
<p>It is suggested to use this function (i.e. MC3 algorithm) when p is 
larger than 20.
</p>
<p>The reference model is the null model (i.e. intercept-only model).
</p>
<p>The case of missing data (i.e. presence of <code>NA</code>'s either in the  
input matrix or the response vector) is not currently supported.
</p>
<p>The intercept term is included in all models.
</p>
<p>If p&gt;1, the input matrix needs to be of full rank.
</p>
<p>The reference prior as baseline corresponds to hyperparameter values
d0=0 and d1=0, while the dependence Jeffreys prior corresponds to 
model-dependent-based values for the hyperparameters d0 and d1,
see Fouskakis and Ntzoufras (2022) for more details.
</p>
<p>The MC3 algorithm was first introduced by Madigan and York (1995)
while its current implementation is described in the Appendix 
of Fouskakis and Ntzoufras (2022).
</p>
<p>When <code>ml_constant.term=FALSE</code> then the log marginal likelihood of a
model in the output is shifted by -logC1
(logC1: marginal likelihood of the null model).
</p>
<p>When the prior on the model space is beta-binomial 
(i.e. <code>beta.binom=TRUE</code>), the following special case is used: uniform 
prior on model size.
</p>


<h3>Value</h3>

<p><code>mc3_pep</code> returns an object of class <code>pep</code>, 
as this is described in detail in <code><a href="#topic+full_enumeration_pep">full_enumeration_pep</a></code>. The
difference is that here the number of rows of the first list element
is not 2^p but the number of unique models &lsquo;visited&rsquo; by the 
MC3 algorithm. Further, the posterior probability of a model corresponds to
the estimated posterior probability as this is computed by the relative
Monte Carlo frequency of the &lsquo;visited&rsquo; models by the MC3 algorithm.
</p>


<h3>References</h3>

<p>Fouskakis, D. and Ntzoufras, I. (2022) Power-Expected-Posterior 
Priors as Mixtures of g-Priors in Normal Linear Models. 
Bayesian Analysis, 17(4): 1073-1099. <a href="https://doi.org/10.1214/21-BA1288">doi:10.1214/21-BA1288</a>
</p>
<p>Madigan, D. and York, J. (1995) Bayesian Graphical Models for Discrete Data.
International Statistical Review, 63(2): 215–232. <a href="https://doi.org/10.2307/1403615">doi:10.2307/1403615</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+full_enumeration_pep">full_enumeration_pep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(UScrime_data)
y &lt;- UScrime_data[,"y"]
X &lt;- UScrime_data[,-15]
set.seed(123)
res &lt;- mc3_pep(X,y,itermc3=3000)
resu &lt;- mc3_pep(X,y,beta.binom=FALSE,itermc3=3000)
resj &lt;- mc3_pep(X,y,reference.prior=FALSE,burnin=500,itermc3=2200)

</code></pre>

<hr>
<h2 id='plot.pep'>Plots for object of class pep</h2><span id='topic+plot.pep'></span>

<h3>Description</h3>

<p>Generates four plots related to an object of class pep. In particular,
the first one is a plot of the residuals against fitted values under 
Bayesian model averaging. The second plots the cumulative posterior 
probability of the top models (those with cumulative posterior probability 
larger than 0.99). The third plot depicts the marginal likelihood 
(in log scale) of a model against its dimension while 
the fourth plot shows the posterior inclusion probabilities
of the explanatory variables (with those exceeding 0.5 marked in red).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pep'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pep_+3A_x">x</code></td>
<td>
<p>An object of class pep (e.g. output of <code>full_enumeration_pep</code> 
or <code>mc3_pep</code>).</p>
</td></tr>
<tr><td><code id="plot.pep_+3A_...">...</code></td>
<td>
<p>Additional graphical parameters to be passed to plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let k be the number of models with cumulative posterior probability up 
to 0.99. Then, the second plot depicts the cumulative posterior probability 
of the top (k+1) models.
</p>
<p>In the special case of no explanatory variables, the fourth plot with the
posterior inclusion probabilities is not generated.
</p>


<h3>Value</h3>

<p>No return value, used for generating a figure.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+image.pep">image.pep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(UScrime_data)
y &lt;- UScrime_data[,"y"]
X &lt;- UScrime_data[,-15]
res &lt;- full_enumeration_pep(X,y)
plot(res)

</code></pre>

<hr>
<h2 id='predict.pep'>Prediction under PEP approach</h2><span id='topic+predict.pep'></span>

<h3>Description</h3>

<p>Computes predicted or fitted values under the PEP approach. Predictions
can be based on Bayesian model averaging, maximum a posteriori model or
median probability model. For the Bayesian model averaging, a subset of the 
top models (either based on explicit number or on their cumulative probability) 
can be used for prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pep'
predict(
  object,
  xnew,
  estimator = "BMA",
  n.models = NULL,
  cumul.prob = 0.99,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.pep_+3A_object">object</code></td>
<td>
<p>An object of class pep (e.g. output of <code>full_enumeration_pep</code> 
or <code>mc3_pep</code>).</p>
</td></tr>
<tr><td><code id="predict.pep_+3A_xnew">xnew</code></td>
<td>
<p>A matrix of numeric (with p columns), the new data to be used for prediction.
This matrix contains the values of the explanatory variables 
without an intercept column of 1's, i.e. the number of its columns
coincides with the number of columns of <code>object$x</code>.
If omitted, fitted values are computed.</p>
</td></tr>
<tr><td><code id="predict.pep_+3A_estimator">estimator</code></td>
<td>
<p>A character, the type of prediction. One of 
&quot;BMA&quot; (Bayesian model averaging, default), 
&quot;MAP&quot; (maximum a posteriori model) or &quot;MPM&quot; (median probability model).</p>
</td></tr>
<tr><td><code id="predict.pep_+3A_n.models">n.models</code></td>
<td>
<p>Positive integer, the number of (top) models that
prediction is based on or <code>NULL</code>. Relevant for <code>estimator="BMA"</code>.
Default value=<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="predict.pep_+3A_cumul.prob">cumul.prob</code></td>
<td>
<p>Numeric between 0 and 1, cumulative probability of
top models to be used for prediction. Relevant for <code>estimator="BMA"</code>. 
Default value=0.99.</p>
</td></tr>
<tr><td><code id="predict.pep_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed, currently none.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>xnew</code> is missing or <code>xnew</code>=<code>object$x</code> then fitted 
values are computed (and returned).
</p>
<p>For prediction, Equation 9 of Fouskakis and Ntzoufras (2020) is used.
</p>
<p>The case of missing data (i.e. presence of NA’s) in the new data matrix is
not currently supported.
</p>
<p>Let k be the number of models with cumulative posterior probability up 
to the given value of <code>cumul.prob</code>. Then, for Bayesian model averaging 
the prediction is based on the top (k+1) models if they exist, otherwise
on the top k models.
</p>
<p>When both <code>n.models</code> and <code>cumul.prob</code> are provided - once 
specifying the number of models for the given cumulative probability as 
described above - the minimum between the two numbers is used for prediction.
</p>


<h3>Value</h3>

<p><code>predict</code> returns a vector with the predicted (or fitted)
values for the different observations.
</p>


<h3>References</h3>

<p>Fouskakis, D. and Ntzoufras, I. (2022) Power-Expected-Posterior 
Priors as Mixtures of g-Priors in Normal Linear Models. 
Bayesian Analysis, 17(4): 1073-1099. <a href="https://doi.org/10.1214/21-BA1288">doi:10.1214/21-BA1288</a>
</p>
<p>Fouskakis, D. and Ntzoufras, I. (2020) Bayesian Model Averaging Using 
Power-Expected-Posterior Priors. 
Econometrics, 8(2): 17. <a href="https://doi.org/10.3390/econometrics8020017">doi:10.3390/econometrics8020017</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(UScrime_data)
y &lt;- UScrime_data[,"y"]
X &lt;- UScrime_data[,-15]
set.seed(123)
res &lt;- mc3_pep(X[1:45,],y[1:45],intrinsic=TRUE,itermc3=4000)
resf &lt;- predict(res)
resf2 &lt;- predict(res,estimator="MPM")
resp &lt;- predict(res,xnew=X[46:47,])
</code></pre>

<hr>
<h2 id='print.pep'>Printing object of class pep</h2><span id='topic+print.pep'></span>

<h3>Description</h3>

<p>For each of the top models (shown in columns), the following information is
printed: the model representation using variable inclusion indicators, 
its marginal likelihood (in log scale), the R2, the model dimension, the Bayes 
factor, posterior odds and posterior probability. An additional 
column with the posterior inclusion probabilities of the explanatory variables is 
also printed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pep'
print(
  x,
  n.models = 5,
  actual.PO = FALSE,
  digits = max(3L, getOption("digits") - 3L),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pep_+3A_x">x</code></td>
<td>
<p>An object of class pep (e.g. output of <code>full_enumeration_pep</code> 
or <code>mc3_pep</code>).</p>
</td></tr>
<tr><td><code id="print.pep_+3A_n.models">n.models</code></td>
<td>
<p>Positive integer, the number of top models for which information 
is provided. Default value=5.</p>
</td></tr>
<tr><td><code id="print.pep_+3A_actual.po">actual.PO</code></td>
<td>
<p>Boolean, relevant for the MC3 algorithm. If <code>TRUE</code>
then apart from the estimated posterior odds, the actual posterior
odds of the top models (i.e. ratios based on the marginal likelihood 
times prior probability) are also printed - which could be used as a 
convergence indicator of the algorithm. Default value=<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="print.pep_+3A_digits">digits</code></td>
<td>
<p>Positive integer, the number of digits for printing numbers. 
Default value=<code>max(3L, getOption("digits") - 3L)</code>.</p>
</td></tr>
<tr><td><code id="print.pep_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to 
<code>print.default</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of models for which information is provided, is computed as the minimum
between the number asked by the user and the number of models present in
the object <code>x</code>.
</p>


<h3>Value</h3>

<p>No return value, used for printing the results on the R console.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(UScrime_data)
y &lt;- UScrime_data[,"y"]
X &lt;- UScrime_data[,-15]
res &lt;- full_enumeration_pep(X,y)
print(res)

</code></pre>

<hr>
<h2 id='UScrime_data'>US Crime Data</h2><span id='topic+UScrime_data'></span>

<h3>Description</h3>

<p>The dataset has been borrowed from the MASS R package and describes 
the effect of punishment regimes on crime rates. One explanatory
variable (indicator variable for a Southern state) was removed since it was binary.
</p>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>M</code></dt><dd><p>percentage of males aged 14&ndash;24.</p>
</dd>
<dt><code>Ed</code></dt><dd><p>mean years of schooling.</p>
</dd>
<dt><code>Po1</code></dt><dd><p>police expenditure in 1960.</p>
</dd>
<dt><code>Po2</code></dt><dd><p>police expenditure in 1959.</p>
</dd>
<dt><code>LF</code></dt><dd><p>labour force participation rate.</p>
</dd>
<dt><code>M.F</code></dt><dd><p>number of males per 1000 females.</p>
</dd>
<dt><code>Pop</code></dt><dd><p>state population.</p>
</dd>
<dt><code>NW</code></dt><dd><p>number of non-whites per 1000 people.</p>
</dd>
<dt><code>U1</code></dt><dd><p>unemployment rate of urban males 14&ndash;24.</p>
</dd>
<dt><code>U2</code></dt><dd><p>unemployment rate of urban males 35&ndash;39.</p>
</dd>
<dt><code>GDP</code></dt><dd><p>gross domestic product per head.</p>
</dd>
<dt><code>Ineq</code></dt><dd><p>income inequality.</p>
</dd>
<dt><code>Prob</code></dt><dd><p>probability of imprisonment.</p>
</dd>
<dt><code>Time</code></dt><dd><p>average time served in state prisons.</p>
</dd>
<dt><code>y</code></dt><dd><p>rate of crimes in a particular category per head of population.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data from the R package MASS
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
