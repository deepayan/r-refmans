<!DOCTYPE html><html lang="en-US"><head><title>Help for package solrium</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {solrium}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#solrium-package'><p>General purpose R interface to Solr.</p></a></li>
<li><a href='#add'><p>Add documents from R objects</p></a></li>
<li><a href='#collapse_pivot_names'><p>Collapse Pivot Field and Value Columns</p></a></li>
<li><a href='#collection_addreplica'><p>Add a replica</p></a></li>
<li><a href='#collection_addreplicaprop'><p>Add a replica property</p></a></li>
<li><a href='#collection_addrole'><p>Add a role to a node</p></a></li>
<li><a href='#collection_balanceshardunique'><p>Balance a property</p></a></li>
<li><a href='#collection_clusterprop'><p>Add, edit, delete a cluster-wide property</p></a></li>
<li><a href='#collection_clusterstatus'><p>Get cluster status</p></a></li>
<li><a href='#collection_create'><p>Add a collection</p></a></li>
<li><a href='#collection_createalias'><p>Create an alias for a collection</p></a></li>
<li><a href='#collection_createshard'><p>Create a shard</p></a></li>
<li><a href='#collection_delete'><p>Add a collection</p></a></li>
<li><a href='#collection_deletealias'><p>Delete a collection alias</p></a></li>
<li><a href='#collection_deletereplica'><p>Delete a replica</p></a></li>
<li><a href='#collection_deletereplicaprop'><p>Delete a replica property</p></a></li>
<li><a href='#collection_deleteshard'><p>Delete a shard</p></a></li>
<li><a href='#collection_exists'><p>Check if a collection exists</p></a></li>
<li><a href='#collection_list'><p>List collections</p></a></li>
<li><a href='#collection_migrate'><p>Migrate documents to another collection</p></a></li>
<li><a href='#collection_overseerstatus'><p>Get overseer status</p></a></li>
<li><a href='#collection_rebalanceleaders'><p>Rebalance leaders</p></a></li>
<li><a href='#collection_reload'><p>Reload a collection</p></a></li>
<li><a href='#collection_removerole'><p>Remove a role from a node</p></a></li>
<li><a href='#collection_requeststatus'><p>Get request status</p></a></li>
<li><a href='#collection_splitshard'><p>Create a shard</p></a></li>
<li><a href='#collections'><p>List collections or cores</p></a></li>
<li><a href='#commit'><p>Commit</p></a></li>
<li><a href='#config_get'><p>Get Solr configuration details</p></a></li>
<li><a href='#config_overlay'><p>Get Solr configuration overlay</p></a></li>
<li><a href='#config_params'><p>Set Solr configuration params</p></a></li>
<li><a href='#config_set'><p>Set Solr configuration details</p></a></li>
<li><a href='#core_create'><p>Create a core</p></a></li>
<li><a href='#core_exists'><p>Check if a core exists</p></a></li>
<li><a href='#core_mergeindexes'><p>Merge indexes (cores)</p></a></li>
<li><a href='#core_reload'><p>Reload a core</p></a></li>
<li><a href='#core_rename'><p>Rename a core</p></a></li>
<li><a href='#core_requeststatus'><p>Request status of asynchronous CoreAdmin API call</p></a></li>
<li><a href='#core_split'><p>Split a core</p></a></li>
<li><a href='#core_status'><p>Get core status</p></a></li>
<li><a href='#core_swap'><p>Swap a core</p></a></li>
<li><a href='#core_unload'><p>Unload (delete) a core</p></a></li>
<li><a href='#delete'><p>Delete documents by ID or query</p></a></li>
<li><a href='#is.sr_facet'><p>Test for sr_facet class</p></a></li>
<li><a href='#makemultiargs'><p>Function to make make multiple args of the same name from a</p>
single input with length &gt; 1</a></li>
<li><a href='#ping'><p>Ping a Solr instance</p></a></li>
<li><a href='#pivot_flatten_tabular'><p>Flatten facet.pivot responses</p></a></li>
<li><a href='#schema'><p>Get the schema for a collection or core</p></a></li>
<li><a href='#solr_all'><p>All purpose search</p></a></li>
<li><a href='#solr_facet'><p>Faceted search</p></a></li>
<li><a href='#solr_get'><p>Real time get</p></a></li>
<li><a href='#solr_group'><p>Grouped search</p></a></li>
<li><a href='#solr_highlight'><p>Highlighting search</p></a></li>
<li><a href='#solr_json_request'><p>Solr json request</p></a></li>
<li><a href='#solr_mlt'><p>&quot;more like this&quot; search</p></a></li>
<li><a href='#solr_optimize'><p>Optimize</p></a></li>
<li><a href='#solr_parse'><p>Parse raw data from solr_search, solr_facet, or solr_highlight.</p></a></li>
<li><a href='#solr_search'><p>Solr search</p></a></li>
<li><a href='#solr_stats'><p>Solr stats</p></a></li>
<li><a href='#SolrClient'><p>Solr connection client</p></a></li>
<li><a href='#update_atomic_json'><p>Atomic updates with JSON data</p></a></li>
<li><a href='#update_atomic_xml'><p>Atomic updates with XML data</p></a></li>
<li><a href='#update_csv'><p>Update documents with CSV data</p></a></li>
<li><a href='#update_json'><p>Update documents with JSON data</p></a></li>
<li><a href='#update_xml'><p>Update documents with XML data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>General Purpose R Interface to 'Solr'</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a set of functions for querying and parsing data
    from 'Solr' (<a href="https://solr.apache.org/">https://solr.apache.org/</a>) 'endpoints' (local and
    remote), including search, 'faceting', 'highlighting', 'stats', and
    'more like this'. In addition, some functionality is included for
    creating, deleting, and updating documents in a 'Solr' 'database'.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ropensci/solrium">https://github.com/ropensci/solrium</a> (devel),
<a href="https://docs.ropensci.org/solrium/">https://docs.ropensci.org/solrium/</a> (user manual)</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ropensci/solrium/issues">https://github.com/ropensci/solrium/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, dplyr (&ge; 0.5.0), plyr (&ge; 1.8.4), crul (&ge; 0.4.0),
xml2 (&ge; 1.0.0), jsonlite (&ge; 1.0), tibble (&ge; 1.4.2), R6</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>X-schema.org-applicationCategory:</td>
<td>Databases</td>
</tr>
<tr>
<td>X-schema.org-keywords:</td>
<td>database, search, JSON, XML, API, web</td>
</tr>
<tr>
<td>X-schema.org-isPartOf:</td>
<td>https://ropensci.org</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-18 21:19:53 UTC; sckott</td>
</tr>
<tr>
<td>Author:</td>
<td>Scott Chamberlain <a href="https://orcid.org/0000-0003-1444-9135"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  rOpenSci [fnd] (https://ropensci.org/)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Scott Chamberlain &lt;myrmecocystus@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-19 04:40:13 UTC</td>
</tr>
</table>
<hr>
<h2 id='solrium-package'>General purpose R interface to Solr.</h2><span id='topic+solrium-package'></span><span id='topic+solrium'></span>

<h3>Description</h3>

<p>This package has support for all the search endpoints, as well as a suite
of functions for managing a Solr database, including adding and deleting
documents.
</p>


<h3>Important search functions</h3>


<ul>
<li> <p><code><a href="#topic+solr_search">solr_search()</a></code> - General search, only returns documents
</p>
</li>
<li> <p><code><a href="#topic+solr_all">solr_all()</a></code> - General search, including all non-documents
in addition to documents: facets, highlights, groups, mlt, stats.
</p>
</li>
<li> <p><code><a href="#topic+solr_facet">solr_facet()</a></code> - Faceting only (w/o general search)
</p>
</li>
<li> <p><code><a href="#topic+solr_highlight">solr_highlight()</a></code> - Highlighting only (w/o general search)
</p>
</li>
<li> <p><code><a href="#topic+solr_mlt">solr_mlt()</a></code> - More like this (w/o general search)
</p>
</li>
<li> <p><code><a href="#topic+solr_group">solr_group()</a></code> - Group search (w/o general search)
</p>
</li>
<li> <p><code><a href="#topic+solr_stats">solr_stats()</a></code> - Stats search (w/o general search)
</p>
</li></ul>



<h3>Important Solr management functions</h3>


<ul>
<li> <p><code><a href="#topic+update_json">update_json()</a></code> - Add or delete documents using json in a file
</p>
</li>
<li> <p><code><a href="#topic+add">add()</a></code> - Add documents via an R list or data.frame
</p>
</li>
<li> <p><code><a href="#topic+delete_by_id">delete_by_id()</a></code> - Delete documents by ID
</p>
</li>
<li> <p><code><a href="#topic+delete_by_query">delete_by_query()</a></code> - Delete documents by query
</p>
</li></ul>



<h3>Vignettes</h3>

<p>See the vignettes for help <code>browseVignettes(package = "solrium")</code>
</p>


<h3>Performance</h3>

<p><code>v0.2</code> and above of this package will have <code>wt=csv</code> as the default.
This  should give significant performance improvement over the previous
default of <code>wt=json</code>, which pulled down json, parsed to an R list,
then to a data.frame. With <code>wt=csv</code>, we pull down csv, and read that
in directly to a data.frame.
</p>
<p>The http library we use, <span class="pkg">crul</span>, sets gzip compression header by
default. As long as compression is used server side, you're good to go on
compression, which should be a good peformance boost. See
https://wiki.apache.org/solr/SolrPerformanceFactors#Query_Response_Compression
for notes on how to enable compression.
</p>
<p>There are other notes about Solr performance at
https://wiki.apache.org/solr/SolrPerformanceFactors that can be
used server side/in your Solr config, but aren't things to tune here in
this R client.
</p>
<p>Let us know if there's any further performance improvements we can make.
</p>


<h3>Author(s)</h3>

<p>Scott Chamberlain <a href="mailto:myrmecocystus@gmail.com">myrmecocystus@gmail.com</a>
</p>

<hr>
<h2 id='add'>Add documents from R objects</h2><span id='topic+add'></span>

<h3>Description</h3>

<p>Add documents from R objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add(
  x,
  conn,
  name,
  commit = TRUE,
  commit_within = NULL,
  overwrite = TRUE,
  boost = NULL,
  wt = "json",
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_+3A_x">x</code></td>
<td>
<p>Documents, either as rows in a data.frame, or a list.</p>
</td></tr>
<tr><td><code id="add_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="add_+3A_name">name</code></td>
<td>
<p>(character) A collection or core name. Required.</p>
</td></tr>
<tr><td><code id="add_+3A_commit">commit</code></td>
<td>
<p>(logical) If <code>TRUE</code>, documents immediately searchable.
Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="add_+3A_commit_within">commit_within</code></td>
<td>
<p>(numeric) Milliseconds to commit the change, the
document will be added within that time. Default: NULL</p>
</td></tr>
<tr><td><code id="add_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical) Overwrite documents with matching keys.
Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="add_+3A_boost">boost</code></td>
<td>
<p>(numeric) Boost factor. Default: NULL</p>
</td></tr>
<tr><td><code id="add_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to
parse</p>
</td></tr>
<tr><td><code id="add_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="add_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Works for Collections as well as Cores (in SolrCloud and Standalone
modes, respectively)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+update_json">update_json</a></code>, <code><a href="#topic+update_xml">update_xml</a></code>,
<code><a href="#topic+update_csv">update_csv</a></code> for adding documents from files
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create the boooks collection
if (!collection_exists(conn, "books")) {
  collection_create(conn, name = "books", numShards = 1)
}

# Documents in a list
ss &lt;- list(list(id = 1, price = 100), list(id = 2, price = 500))
add(ss, conn, name = "books")
conn$get(c(1, 2), "books")

# Documents in a data.frame
## Simple example
df &lt;- data.frame(id = c(67, 68), price = c(1000, 500000000))
add(df, conn, "books")
df &lt;- data.frame(id = c(77, 78), price = c(1, 2.40))
add(df, conn, "books")

## More complex example, get file from package examples
# start Solr in Schemaless mode first: bin/solr start -e schemaless
file &lt;- system.file("examples", "books.csv", package = "solrium")
x &lt;- read.csv(file, stringsAsFactors = FALSE)
class(x)
head(x)
if (!collection_exists(conn, "mybooks")) {
  collection_create(conn, name = "mybooks", numShards = 2)
}
add(x, conn, "mybooks")

# Use modifiers
add(x, conn, "mybooks", commit_within = 5000)

# Get back XML instead of a list
ss &lt;- list(list(id = 1, price = 100), list(id = 2, price = 500))
# parsed XML
add(ss, conn, name = "books", wt = "xml")
# raw XML
add(ss, conn, name = "books", wt = "xml", raw = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='collapse_pivot_names'>Collapse Pivot Field and Value Columns</h2><span id='topic+collapse_pivot_names'></span>

<h3>Description</h3>

<p>Convert a table consisting of columns in sets of 3
into 2 columns assuming that the first column of every set of 3
(field) is duplicated throughout all rows and should be removed.
This type of structure is usually returned by facet.pivot responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collapse_pivot_names(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collapse_pivot_names_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> with every 2 columns
representing a field and value and the final representing
a count</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code>
</p>

<hr>
<h2 id='collection_addreplica'>Add a replica</h2><span id='topic+collection_addreplica'></span>

<h3>Description</h3>

<p>Add a replica to a shard in a collection. The node name can be
specified if the replica is to be created in a specific node
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_addreplica(
  conn,
  name,
  shard = NULL,
  route = NULL,
  node = NULL,
  instanceDir = NULL,
  dataDir = NULL,
  async = NULL,
  raw = FALSE,
  callopts = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_addreplica_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_shard">shard</code></td>
<td>
<p>(character) The name of the shard to which replica is to be added.
If <code>shard</code> is not given, then <code>route</code> must be.</p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_route">route</code></td>
<td>
<p>(character) If the exact shard name is not known, users may pass
the <code>route</code> value and the system would identify the name of the shard.
Ignored if the <code>shard</code> param is also given</p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_node">node</code></td>
<td>
<p>(character) The name of the node where the replica should be created</p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_instancedir">instanceDir</code></td>
<td>
<p>(character) The instanceDir for the core that will be created</p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_datadir">dataDir</code></td>
<td>
<p>(character)    The directory in which the core should be created</p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be processed
asynchronously</p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="collection_addreplica_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for details on
supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("foobar")) {
  conn$collection_create(name = "foobar", numShards = 2)
  # OR bin/solr create -c foobar
}

# status
conn$collection_clusterstatus()$cluster$collections$foobar

# add replica
if (!conn$collection_exists("foobar")) {
  conn$collection_addreplica(name = "foobar", shard = "shard1")
}

# status again
conn$collection_clusterstatus()$cluster$collections$foobar
conn$collection_clusterstatus()$cluster$collections$foobar$shards
conn$collection_clusterstatus()$cluster$collections$foobar$shards$shard1

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_addreplicaprop'>Add a replica property</h2><span id='topic+collection_addreplicaprop'></span>

<h3>Description</h3>

<p>Assign an arbitrary property to a particular replica and give it
the value specified. If the property already exists, it will be overwritten
with the new value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_addreplicaprop(
  conn,
  name,
  shard,
  replica,
  property,
  property.value,
  shardUnique = FALSE,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_addreplicaprop_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_addreplicaprop_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_addreplicaprop_+3A_shard">shard</code></td>
<td>
<p>(character) Required. The name of the shard the replica
belongs to</p>
</td></tr>
<tr><td><code id="collection_addreplicaprop_+3A_replica">replica</code></td>
<td>
<p>(character) Required. The replica, e.g. core_node1.</p>
</td></tr>
<tr><td><code id="collection_addreplicaprop_+3A_property">property</code></td>
<td>
<p>(character) Required. The property to add. Note: this will
have the literal 'property.' prepended to distinguish it from
system-maintained properties. So these two forms are equivalent:
<code>property=special</code> and <code>property=property.special</code></p>
</td></tr>
<tr><td><code id="collection_addreplicaprop_+3A_property.value">property.value</code></td>
<td>
<p>(character) Required. The value to assign to
the property</p>
</td></tr>
<tr><td><code id="collection_addreplicaprop_+3A_shardunique">shardUnique</code></td>
<td>
<p>(logical) If <code>TRUE</code>, then setting this property in one
replica will (1) remove the property from all other replicas in that shard
Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="collection_addreplicaprop_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_addreplicaprop_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("addrep")) {
  conn$collection_create(name = "addrep", numShards = 1)
  # OR bin/solr create -c addrep
}

# status
conn$collection_clusterstatus()$cluster$collections$addrep$shards

# add the value world to the property hello
conn$collection_addreplicaprop(name = "addrep", shard = "shard1",
  replica = "core_node1", property = "hello", property.value = "world")

# check status
conn$collection_clusterstatus()$cluster$collections$addrep$shards
conn$collection_clusterstatus()$cluster$collections$addrep$shards$shard1$replicas$core_node1

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_addrole'>Add a role to a node</h2><span id='topic+collection_addrole'></span>

<h3>Description</h3>

<p>Assign a role to a given node in the cluster. The only supported role
as of 4.7 is 'overseer' . Use this API to dedicate a particular node as Overseer.
Invoke it multiple times to add more nodes. This is useful in large clusters where
an Overseer is likely to get overloaded . If available, one among the list of
nodes which are assigned the 'overseer' role would become the overseer. The
system would assign the role to any other node if none of the designated nodes
are up and running
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_addrole(conn, role = "overseer", node, raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_addrole_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_addrole_+3A_role">role</code></td>
<td>
<p>(character) Required. The name of the role. The only supported role
as of now is overseer (set as default).</p>
</td></tr>
<tr><td><code id="collection_addrole_+3A_node">node</code></td>
<td>
<p>(character) Required. The name of the node. It is possible to assign a
role even before that node is started.</p>
</td></tr>
<tr><td><code id="collection_addrole_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_addrole_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# get list of nodes
nodes &lt;- conn$collection_clusterstatus()$cluster$live_nodes
collection_addrole(conn, node = nodes[1])

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_balanceshardunique'>Balance a property</h2><span id='topic+collection_balanceshardunique'></span>

<h3>Description</h3>

<p>Insures that a particular property is distributed evenly
amongst the physical nodes that make up a collection. If the property
already exists on a replica, every effort is made to leave it there. If the
property is not on any replica on a shard one is chosen and the property
is added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_balanceshardunique(
  conn,
  name,
  property,
  onlyactivenodes = TRUE,
  shardUnique = NULL,
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_balanceshardunique_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_balanceshardunique_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_balanceshardunique_+3A_property">property</code></td>
<td>
<p>(character) Required. The property to balance. The literal
&quot;property.&quot; is prepended to this property if not specified explicitly.</p>
</td></tr>
<tr><td><code id="collection_balanceshardunique_+3A_onlyactivenodes">onlyactivenodes</code></td>
<td>
<p>(logical) Normally, the property is instantiated
on active nodes only. If <code>FALSE</code>, then inactive nodes are also included
for distribution. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="collection_balanceshardunique_+3A_shardunique">shardUnique</code></td>
<td>
<p>(logical) Something of a safety valve. There is one
pre-defined property (preferredLeader) that defaults this value to <code>TRUE</code>.
For all other properties that are balanced, this must be set to <code>TRUE</code> or
an error message is returned</p>
</td></tr>
<tr><td><code id="collection_balanceshardunique_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_balanceshardunique_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("addrep")) {
  conn$collection_create(name = "mycollection")
  # OR: bin/solr create -c mycollection
}

# balance preferredLeader property
conn$collection_balanceshardunique("mycollection", property = "preferredLeader")

# examine cluster status
conn$collection_clusterstatus()$cluster$collections$mycollection

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_clusterprop'>Add, edit, delete a cluster-wide property</h2><span id='topic+collection_clusterprop'></span>

<h3>Description</h3>

<p>Important: whether add, edit, or delete is used is determined
by the value passed to the <code>val</code> parameter. If the property name is
new, it will be added. If the property name exists, and the value is
different, it will be edited. If the property name exists, and the value
is <code>NULL</code> or empty the property is deleted (unset).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_clusterprop(conn, name, val, raw = FALSE, callopts = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_clusterprop_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_clusterprop_+3A_name">name</code></td>
<td>
<p>(character) Name of the core or collection</p>
</td></tr>
<tr><td><code id="collection_clusterprop_+3A_val">val</code></td>
<td>
<p>(character) Required. The value of the property. If the value is
empty or null, the property is unset.</p>
</td></tr>
<tr><td><code id="collection_clusterprop_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="collection_clusterprop_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# add the value https to the property urlScheme
collection_clusterprop(conn, name = "urlScheme", val = "https")

# status again
collection_clusterstatus(conn)$cluster$properties

# delete the property urlScheme by setting val to NULL or a 0 length string
collection_clusterprop(conn, name = "urlScheme", val = "")

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_clusterstatus'>Get cluster status</h2><span id='topic+collection_clusterstatus'></span>

<h3>Description</h3>

<p>Fetch the cluster status including collections, shards,
replicas, configuration name as well as collection aliases and cluster
properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_clusterstatus(conn, name = NULL, shard = NULL, raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_clusterstatus_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_clusterstatus_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_clusterstatus_+3A_shard">shard</code></td>
<td>
<p>(character) The shard(s) for which information is requested.
Multiple shard names can be specified as a character vector.</p>
</td></tr>
<tr><td><code id="collection_clusterstatus_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_clusterstatus_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())
conn$collection_clusterstatus()
res &lt;- conn$collection_clusterstatus()
res$responseHeader
res$cluster
res$cluster$collections
res$cluster$collections$gettingstarted
res$cluster$live_nodes

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_create'>Add a collection</h2><span id='topic+collection_create'></span>

<h3>Description</h3>

<p>Add a collection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_create(
  conn,
  name,
  numShards = 1,
  maxShardsPerNode = 1,
  createNodeSet = NULL,
  collection.configName = NULL,
  replicationFactor = 1,
  router.name = NULL,
  shards = NULL,
  createNodeSet.shuffle = TRUE,
  router.field = NULL,
  autoAddReplicas = FALSE,
  async = NULL,
  raw = FALSE,
  callopts = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_create_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_create_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_create_+3A_numshards">numShards</code></td>
<td>
<p>(integer) The number of shards to be created as part of the
collection. This is a required parameter when using the 'compositeId' router.</p>
</td></tr>
<tr><td><code id="collection_create_+3A_maxshardspernode">maxShardsPerNode</code></td>
<td>
<p>(integer) When creating collections, the shards and/or replicas
are spread across all available (i.e., live) nodes, and two replicas of the same shard
will never be on the same node. If a node is not live when the CREATE operation is called,
it will not get any parts of the new collection, which could lead to too many replicas
being created on a single live node. Defining maxShardsPerNode sets a limit on the number
of replicas CREATE will spread to each node. If the entire collection can not be fit into
the live nodes, no collection will be created at all. Default: 1</p>
</td></tr>
<tr><td><code id="collection_create_+3A_createnodeset">createNodeSet</code></td>
<td>
<p>(logical) Allows defining the nodes to spread the new collection
across. If not provided, the CREATE operation will create shard-replica spread across all
live Solr nodes. The format is a comma-separated list of node_names, such as
localhost:8983_solr, localhost:8984_solr, localhost:8985_solr. Default: <code>NULL</code></p>
</td></tr>
<tr><td><code id="collection_create_+3A_collection.configname">collection.configName</code></td>
<td>
<p>(character) Defines the name of the configurations (which
must already be stored in ZooKeeper) to use for this collection. If not provided, Solr
will default to the collection name as the configuration name. Default: <code>compositeId</code></p>
</td></tr>
<tr><td><code id="collection_create_+3A_replicationfactor">replicationFactor</code></td>
<td>
<p>(integer) The number of replicas to be created for each shard.
Default: 1</p>
</td></tr>
<tr><td><code id="collection_create_+3A_router.name">router.name</code></td>
<td>
<p>(character) The router name that will be used. The router defines
how documents will be distributed among the shards. The value can be either <code>implicit</code>,
which uses an internal default hash, or <code>compositeId</code>, which allows defining the specific
shard to assign documents to. When using the 'implicit' router, the shards parameter is
required. When using the 'compositeId' router, the numShards parameter is required.
For more information, see also the section Document Routing. Default: <code>compositeId</code></p>
</td></tr>
<tr><td><code id="collection_create_+3A_shards">shards</code></td>
<td>
<p>(character) A comma separated list of shard names, e.g.,
shard-x,shard-y,shard-z . This is a required parameter when using the 'implicit' router.</p>
</td></tr>
<tr><td><code id="collection_create_+3A_createnodeset.shuffle">createNodeSet.shuffle</code></td>
<td>
<p>(logical)    Controls whether or not the shard-replicas created
for this collection will be assigned to the nodes specified by the createNodeSet in a
sequential manner, or if the list of nodes should be shuffled prior to creating individual
replicas.  A 'false' value makes the results of a collection creation predictible and
gives more exact control over the location of the individual shard-replicas, but 'true'
can be a better choice for ensuring replicas are distributed evenly across nodes. Ignored
if createNodeSet is not also specified. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="collection_create_+3A_router.field">router.field</code></td>
<td>
<p>(character) If this field is specified, the router will look at the
value of the field in an input document to compute the hash and identify a shard instead of
looking at the uniqueKey field. If the field specified is null in the document, the document
will be rejected. Please note that RealTime Get or retrieval by id would also require the
parameter <em>route</em> (or shard.keys) to avoid a distributed search.</p>
</td></tr>
<tr><td><code id="collection_create_+3A_autoaddreplicas">autoAddReplicas</code></td>
<td>
<p>(logical)    When set to true, enables auto addition of replicas on
shared file systems. See the section autoAddReplicas Settings for more details on settings
and overrides. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="collection_create_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be processed
asynchronously</p>
</td></tr>
<tr><td><code id="collection_create_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_create_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="collection_create_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# connect
(conn &lt;- SolrClient$new())

if (!conn$collection_exists("helloWorld")) {
  conn$collection_create(name = "helloWorld")
}
if (!conn$collection_exists("tablesChairs")) {
  conn$collection_create(name = "tablesChairs")
}

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_createalias'>Create an alias for a collection</h2><span id='topic+collection_createalias'></span>

<h3>Description</h3>

<p>Create a new alias pointing to one or more collections. If an
alias by the same name already exists, this action will replace the existing
alias, effectively acting like an atomic &quot;MOVE&quot; command.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_createalias(
  conn,
  alias,
  collections,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_createalias_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_createalias_+3A_alias">alias</code></td>
<td>
<p>(character) Required. The alias name to be created</p>
</td></tr>
<tr><td><code id="collection_createalias_+3A_collections">collections</code></td>
<td>
<p>(character) Required. A character vector of collections
to be aliased</p>
</td></tr>
<tr><td><code id="collection_createalias_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_createalias_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <code><a href="crul.html#topic+HttpClient">HttpClient</a></code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

if (!conn$collection_exists("thingsstuff")) {
  conn$collection_create(name = "thingsstuff")
}

conn$collection_createalias("tstuff", "thingsstuff")
conn$collection_clusterstatus()$cluster$collections$thingsstuff$aliases

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_createshard'>Create a shard</h2><span id='topic+collection_createshard'></span>

<h3>Description</h3>

<p>Create a shard
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_createshard(
  conn,
  name,
  shard,
  createNodeSet = NULL,
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_createshard_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_createshard_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_createshard_+3A_shard">shard</code></td>
<td>
<p>(character) Required. The name of the shard to be created.</p>
</td></tr>
<tr><td><code id="collection_createshard_+3A_createnodeset">createNodeSet</code></td>
<td>
<p>(character) Allows defining the nodes to spread the new
collection across. If not provided, the CREATE operation will create
shard-replica spread across all live Solr nodes. The format is a
comma-separated list of node_names, such as localhost:8983_solr,
localhost:8984_s olr, localhost:8985_solr.</p>
</td></tr>
<tr><td><code id="collection_createshard_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_createshard_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())
## FIXME - doesn't work right now
# conn$collection_create(name = "trees")
# conn$collection_createshard(name = "trees", shard = "newshard")

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_delete'>Add a collection</h2><span id='topic+collection_delete'></span>

<h3>Description</h3>

<p>Add a collection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_delete(conn, name, raw = FALSE, callopts = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_delete_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_delete_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_delete_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_delete_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <code><a href="crul.html#topic+HttpClient">HttpClient</a></code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

if (!conn$collection_exists("helloWorld")) {
  conn$collection_create(name = "helloWorld")
}

collection_delete(conn, name = "helloWorld")

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_deletealias'>Delete a collection alias</h2><span id='topic+collection_deletealias'></span>

<h3>Description</h3>

<p>Delete a collection alias
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_deletealias(conn, alias, raw = FALSE, callopts = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_deletealias_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_deletealias_+3A_alias">alias</code></td>
<td>
<p>(character) Required. The alias name to be created</p>
</td></tr>
<tr><td><code id="collection_deletealias_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_deletealias_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

if (!conn$collection_exists("thingsstuff")) {
  conn$collection_create(name = "thingsstuff")
}

conn$collection_createalias("tstuff", "thingsstuff")
conn$collection_clusterstatus()$cluster$collections$thingsstuff$aliases # new alias
conn$collection_deletealias("tstuff")
conn$collection_clusterstatus()$cluster$collections$thingsstuff$aliases # gone

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_deletereplica'>Delete a replica</h2><span id='topic+collection_deletereplica'></span>

<h3>Description</h3>

<p>Delete a replica from a given collection and shard. If the
corresponding core is up and running the core is unloaded and the entry is
removed from the clusterstate. If the node/core is down , the entry is taken
off the clusterstate and if the core comes up later it is automatically
unregistered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_deletereplica(
  conn,
  name,
  shard = NULL,
  replica = NULL,
  onlyIfDown = FALSE,
  raw = FALSE,
  callopts = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_deletereplica_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_deletereplica_+3A_name">name</code></td>
<td>
<p>(character) Required. The name of the collection.</p>
</td></tr>
<tr><td><code id="collection_deletereplica_+3A_shard">shard</code></td>
<td>
<p>(character) Required. The name of the shard that includes the replica to
be removed.</p>
</td></tr>
<tr><td><code id="collection_deletereplica_+3A_replica">replica</code></td>
<td>
<p>(character) Required. The name of the replica to remove.</p>
</td></tr>
<tr><td><code id="collection_deletereplica_+3A_onlyifdown">onlyIfDown</code></td>
<td>
<p>(logical) When <code>TRUE</code> will not take any action if the replica
is active. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="collection_deletereplica_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_deletereplica_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="collection_deletereplica_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for details on
supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("foobar2")) {
  conn$collection_create(name = "foobar2", maxShardsPerNode = 2)
}

# status
conn$collection_clusterstatus()$cluster$collections$foobar2$shards$shard1

# add replica
conn$collection_addreplica(name = "foobar2", shard = "shard1")

# delete replica
## get replica name
nms &lt;- names(conn$collection_clusterstatus()$cluster$collections$foobar2$shards$shard1$replicas)
conn$collection_deletereplica(name = "foobar2", shard = "shard1", replica = nms[1])

# status again
conn$collection_clusterstatus()$cluster$collections$foobar2$shards$shard1

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_deletereplicaprop'>Delete a replica property</h2><span id='topic+collection_deletereplicaprop'></span>

<h3>Description</h3>

<p>Deletes an arbitrary property from a particular replica.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_deletereplicaprop(
  conn,
  name,
  shard,
  replica,
  property,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_deletereplicaprop_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_deletereplicaprop_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_deletereplicaprop_+3A_shard">shard</code></td>
<td>
<p>(character) Required. The name of the shard the replica
belongs to.</p>
</td></tr>
<tr><td><code id="collection_deletereplicaprop_+3A_replica">replica</code></td>
<td>
<p>(character) Required. The replica, e.g. core_node1.</p>
</td></tr>
<tr><td><code id="collection_deletereplicaprop_+3A_property">property</code></td>
<td>
<p>(character) Required. The property to delete. Note: this
will have the literal 'property.' prepended to distinguish it from
system-maintained properties. So these two forms are equivalent:
<code>property=special</code> and  <code>property=property.special</code></p>
</td></tr>
<tr><td><code id="collection_deletereplicaprop_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_deletereplicaprop_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("deleterep")) {
  conn$collection_create(name = "deleterep")
  # OR bin/solr create -c deleterep
}

# status
conn$collection_clusterstatus()$cluster$collections$deleterep$shards

# add the value bar to the property foo
conn$collection_addreplicaprop(name = "deleterep", shard = "shard1",
  replica = "core_node1", property = "foo", property.value = "bar")

# check status
conn$collection_clusterstatus()$cluster$collections$deleterep$shards
conn$collection_clusterstatus()$cluster$collections$deleterep$shards$shard1$replicas$core_node1

# delete replica property
conn$collection_deletereplicaprop(name = "deleterep", shard = "shard1",
   replica = "core_node1", property = "foo")

# check status - foo should be gone
conn$collection_clusterstatus()$cluster$collections$deleterep$shards$shard1$replicas$core_node1

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_deleteshard'>Delete a shard</h2><span id='topic+collection_deleteshard'></span>

<h3>Description</h3>

<p>Deleting a shard will unload all replicas of the shard and remove
them from clusterstate.json. It will only remove shards that are inactive, or
which have no range given for custom sharding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_deleteshard(conn, name, shard, raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_deleteshard_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_deleteshard_+3A_name">name</code></td>
<td>
<p>(character) Required. The name of the collection that includes the shard
to be deleted</p>
</td></tr>
<tr><td><code id="collection_deleteshard_+3A_shard">shard</code></td>
<td>
<p>(character) Required. The name of the shard to be deleted</p>
</td></tr>
<tr><td><code id="collection_deleteshard_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_deleteshard_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("buffalo")) {
  conn$collection_create(name = "buffalo")
  # OR: bin/solr create -c buffalo
}

# find shard names
names(conn$collection_clusterstatus()$cluster$collections$buffalo$shards)

# split a shard by name
collection_splitshard(conn, name = "buffalo", shard = "shard1")

# now we have three shards
names(conn$collection_clusterstatus()$cluster$collections$buffalo$shards)

# delete shard
conn$collection_deleteshard(name = "buffalo", shard = "shard1_1")

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_exists'>Check if a collection exists</h2><span id='topic+collection_exists'></span>

<h3>Description</h3>

<p>Check if a collection exists
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_exists(conn, name, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_exists_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_exists_+3A_name">name</code></td>
<td>
<p>(character) The name of the core. If not given, all cores.</p>
</td></tr>
<tr><td><code id="collection_exists_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simply calls <code><a href="#topic+collection_list">collection_list()</a></code> internally
</p>


<h3>Value</h3>

<p>A single boolean, <code>TRUE</code> or <code>FALSE</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Cloud mode via the schemaless eg: bin/solr -e cloud
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below
(conn &lt;- SolrClient$new())

# exists
conn$collection_exists("gettingstarted")

# doesn't exist
conn$collection_exists("hhhhhh")

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_list'>List collections</h2><span id='topic+collection_list'></span>

<h3>Description</h3>

<p>List collections
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_list(conn, raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_list_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_list_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="collection_list_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

conn$collection_list()
conn$collection_list()$collections
collection_list(conn)

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_migrate'>Migrate documents to another collection</h2><span id='topic+collection_migrate'></span>

<h3>Description</h3>

<p>Migrate documents to another collection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_migrate(
  conn,
  name,
  target.collection,
  split.key,
  forward.timeout = NULL,
  async = NULL,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_migrate_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_migrate_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_migrate_+3A_target.collection">target.collection</code></td>
<td>
<p>(character) Required. The name of the target collection
to which documents will be migrated</p>
</td></tr>
<tr><td><code id="collection_migrate_+3A_split.key">split.key</code></td>
<td>
<p>(character) Required. The routing key prefix. For example, if
uniqueKey is a!123, then you would use split.key=a!</p>
</td></tr>
<tr><td><code id="collection_migrate_+3A_forward.timeout">forward.timeout</code></td>
<td>
<p>(integer) The timeout (seconds), until which write requests
made to the source collection for the given <code>split.key</code> will be forwarded to the
target shard. Default: 60</p>
</td></tr>
<tr><td><code id="collection_migrate_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be processed
asynchronously</p>
</td></tr>
<tr><td><code id="collection_migrate_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_migrate_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("migrate_from")) {
  conn$collection_create(name = "migrate_from")
  # OR: bin/solr create -c migrate_from
}

# create another collection
if (!conn$collection_exists("migrate_to")) {
  conn$collection_create(name = "migrate_to")
  # OR bin/solr create -c migrate_to
}

# add some documents
file &lt;- system.file("examples", "books.csv", package = "solrium")
x &lt;- read.csv(file, stringsAsFactors = FALSE)
conn$add(x, "migrate_from")

# migrate some documents from one collection to the other
## FIXME - not sure if this is actually working....
# conn$collection_migrate("migrate_from", "migrate_to", split.key = "05535")

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_overseerstatus'>Get overseer status</h2><span id='topic+collection_overseerstatus'></span>

<h3>Description</h3>

<p>Returns the current status of the overseer, performance
statistics of various overseer APIs as well as last 10 failures per
operation type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_overseerstatus(conn, raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_overseerstatus_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_overseerstatus_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_overseerstatus_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())
conn$collection_overseerstatus()
res &lt;- conn$collection_overseerstatus()
res$responseHeader
res$leader
res$overseer_queue_size
res$overseer_work_queue_size
res$overseer_operations
res$collection_operations
res$overseer_queue
res$overseer_internal_queue
res$collection_queue

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_rebalanceleaders'>Rebalance leaders</h2><span id='topic+collection_rebalanceleaders'></span>

<h3>Description</h3>

<p>Reassign leaders in a collection according to the preferredLeader
property across active nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_rebalanceleaders(
  conn,
  name,
  maxAtOnce = NULL,
  maxWaitSeconds = NULL,
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_rebalanceleaders_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_rebalanceleaders_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_rebalanceleaders_+3A_maxatonce">maxAtOnce</code></td>
<td>
<p>(integer) The maximum number of reassignments to have queue
up at once. Values &lt;=0 are use the default value Integer.MAX_VALUE. When
this number is reached, the process waits for one or more leaders to be
successfully assigned before adding more to the queue.</p>
</td></tr>
<tr><td><code id="collection_rebalanceleaders_+3A_maxwaitseconds">maxWaitSeconds</code></td>
<td>
<p>(integer) Timeout value when waiting for leaders to
be reassigned. NOTE: if maxAtOnce is less than the number of reassignments
that will take place, this is the maximum interval that any single wait for
at least one reassignment. For example, if 10 reassignments are to take
place and maxAtOnce is 1 and maxWaitSeconds is 60, the upper bound on the
time that the command may wait is 10 minutes. Default: 60</p>
</td></tr>
<tr><td><code id="collection_rebalanceleaders_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_rebalanceleaders_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("mycollection2")) {
  conn$collection_create(name = "mycollection2")
  # OR: bin/solr create -c mycollection2
}

# balance preferredLeader property
conn$collection_balanceshardunique("mycollection2", property = "preferredLeader")

# balance preferredLeader property
conn$collection_rebalanceleaders("mycollection2")

# examine cluster status
conn$collection_clusterstatus()$cluster$collections$mycollection2

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_reload'>Reload a collection</h2><span id='topic+collection_reload'></span>

<h3>Description</h3>

<p>Reload a collection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_reload(conn, name, raw = FALSE, callopts)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_reload_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_reload_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_reload_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_reload_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

if (!conn$collection_exists("helloWorld")) {
  conn$collection_create(name = "helloWorld")
}

conn$collection_reload(name = "helloWorld")

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_removerole'>Remove a role from a node</h2><span id='topic+collection_removerole'></span>

<h3>Description</h3>

<p>Remove an assigned role. This API is used to undo the roles
assigned using <code><a href="#topic+collection_addrole">collection_addrole</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_removerole(conn, role = "overseer", node, raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_removerole_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_removerole_+3A_role">role</code></td>
<td>
<p>(character) Required. The name of the role. The only supported
role as of now is overseer (set as default).</p>
</td></tr>
<tr><td><code id="collection_removerole_+3A_node">node</code></td>
<td>
<p>(character) Required. The name of the node.</p>
</td></tr>
<tr><td><code id="collection_removerole_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_removerole_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# get list of nodes
nodes &lt;- conn$collection_clusterstatus()$cluster$live_nodes
conn$collection_addrole(node = nodes[1])
conn$collection_removerole(node = nodes[1])

## End(Not run)
</code></pre>

<hr>
<h2 id='collection_requeststatus'>Get request status</h2><span id='topic+collection_requeststatus'></span>

<h3>Description</h3>

<p>Request the status of an already submitted Asynchronous
Collection API call. This call is also used to clear up the stored statuses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_requeststatus(conn, requestid, raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_requeststatus_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_requeststatus_+3A_requestid">requestid</code></td>
<td>
<p>(character) Required. The user defined request-id for the
request. This can be used to track the status of the submitted asynchronous
task. <code>-1</code> is a special request id which is used to cleanup the stored
states for all of the already completed/failed tasks.</p>
</td></tr>
<tr><td><code id="collection_requeststatus_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_requeststatus_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/8_2/defining-core-properties.html)</p>
</td></tr>
</table>

<hr>
<h2 id='collection_splitshard'>Create a shard</h2><span id='topic+collection_splitshard'></span>

<h3>Description</h3>

<p>Create a shard
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collection_splitshard(
  conn,
  name,
  shard,
  ranges = NULL,
  split.key = NULL,
  async = NULL,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collection_splitshard_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collection_splitshard_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="collection_splitshard_+3A_shard">shard</code></td>
<td>
<p>(character) Required. The name of the shard to be split</p>
</td></tr>
<tr><td><code id="collection_splitshard_+3A_ranges">ranges</code></td>
<td>
<p>(character) A comma-separated list of hash ranges in
hexadecimal e.g. ranges=0-1f4,1f5-3e8,3e9-5dc</p>
</td></tr>
<tr><td><code id="collection_splitshard_+3A_split.key">split.key</code></td>
<td>
<p>(character) The key to use for splitting the index</p>
</td></tr>
<tr><td><code id="collection_splitshard_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be
processed asynchronously</p>
</td></tr>
<tr><td><code id="collection_splitshard_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="collection_splitshard_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

# create collection
if (!conn$collection_exists("trees")) {
  conn$collection_create("trees")
}

# find shard names
names(conn$collection_clusterstatus()$cluster$collections$trees$shards)

# split a shard by name
conn$collection_splitshard(name = "trees", shard = "shard1")

# now we have three shards
names(conn$collection_clusterstatus()$cluster$collections$trees$shards)

## End(Not run)
</code></pre>

<hr>
<h2 id='collections'>List collections or cores</h2><span id='topic+collections'></span><span id='topic+cores'></span>

<h3>Description</h3>

<p>List collections or cores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collections(conn, ...)

cores(conn, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collections_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="collections_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calls <code><a href="#topic+collection_list">collection_list()</a></code> or <code><a href="#topic+core_status">core_status()</a></code> internally,
and parses out names for you.
</p>


<h3>Value</h3>

<p>character vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# connect
(conn &lt;- SolrClient$new())

# list collections
conn$collection_list()
collections(conn)

# list cores
conn$core_status()
cores(conn)

## End(Not run)
</code></pre>

<hr>
<h2 id='commit'>Commit</h2><span id='topic+commit'></span>

<h3>Description</h3>

<p>Commit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>commit(
  conn,
  name,
  expunge_deletes = FALSE,
  wait_searcher = TRUE,
  soft_commit = FALSE,
  wt = "json",
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="commit_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="commit_+3A_name">name</code></td>
<td>
<p>(character) A collection or core name. Required.</p>
</td></tr>
<tr><td><code id="commit_+3A_expunge_deletes">expunge_deletes</code></td>
<td>
<p>merge segments with deletes away. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="commit_+3A_wait_searcher">wait_searcher</code></td>
<td>
<p>block until a new searcher is opened and registered as
the main query searcher, making the changes visible. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="commit_+3A_soft_commit">soft_commit</code></td>
<td>
<p>perform a soft commit - this will refresh the 'view' of
the index in a more performant manner, but without &quot;on-disk&quot; guarantees.
Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="commit_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to parse</p>
</td></tr>
<tr><td><code id="commit_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="commit_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>References</h3>

<p>&lt;&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

conn$commit("gettingstarted")
conn$commit("gettingstarted", wait_searcher = FALSE)

# get xml back
conn$commit("gettingstarted", wt = "xml")
## raw xml
conn$commit("gettingstarted", wt = "xml", raw = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='config_get'>Get Solr configuration details</h2><span id='topic+config_get'></span>

<h3>Description</h3>

<p>Get Solr configuration details
</p>


<h3>Usage</h3>

<pre><code class='language-R'>config_get(conn, name, what = NULL, wt = "json", raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="config_get_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="config_get_+3A_name">name</code></td>
<td>
<p>(character) The name of the core. If not given, all cores.</p>
</td></tr>
<tr><td><code id="config_get_+3A_what">what</code></td>
<td>
<p>(character) What you want to look at. One of solrconfig or
schema. Default: solrconfig</p>
</td></tr>
<tr><td><code id="config_get_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. Data type returned.
If json, uses <code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses
<code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to parse.</p>
</td></tr>
<tr><td><code id="config_get_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code></p>
</td></tr>
<tr><td><code id="config_get_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if <code>raw=TRUE</code>, <code>what</code> is ignored. That is,
you get all the data when <code>raw=TRUE</code>.
</p>


<h3>Value</h3>

<p>A list, <code>xml_document</code>, or character
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Cloud mode via the schemaless eg: bin/solr -e cloud
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below

# connect
(conn &lt;- SolrClient$new())

# all config settings
conn$config_get("gettingstarted")

# just znodeVersion
conn$config_get("gettingstarted", "znodeVersion")

# just znodeVersion
conn$config_get("gettingstarted", "luceneMatchVersion")

# just updateHandler
conn$config_get("gettingstarted", "updateHandler")

# just updateHandler
conn$config_get("gettingstarted", "requestHandler")

## Get XML
conn$config_get("gettingstarted", wt = "xml")
conn$config_get("gettingstarted", "updateHandler", wt = "xml")
conn$config_get("gettingstarted", "requestHandler", wt = "xml")

## Raw data - what param ignored when raw=TRUE
conn$config_get("gettingstarted", raw = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='config_overlay'>Get Solr configuration overlay</h2><span id='topic+config_overlay'></span>

<h3>Description</h3>

<p>Get Solr configuration overlay
</p>


<h3>Usage</h3>

<pre><code class='language-R'>config_overlay(conn, name, omitHeader = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="config_overlay_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="config_overlay_+3A_name">name</code></td>
<td>
<p>(character) The name of the core. If not given, all cores.</p>
</td></tr>
<tr><td><code id="config_overlay_+3A_omitheader">omitHeader</code></td>
<td>
<p>(logical) If <code>TRUE</code>, omit header. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="config_overlay_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with response from server
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Cloud mode via the schemaless eg: bin/solr -e cloud
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below

# connect
(conn &lt;- SolrClient$new())

# get config overlay
conn$config_overlay("gettingstarted")

# without header
conn$config_overlay("gettingstarted", omitHeader = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='config_params'>Set Solr configuration params</h2><span id='topic+config_params'></span>

<h3>Description</h3>

<p>Set Solr configuration params
</p>


<h3>Usage</h3>

<pre><code class='language-R'>config_params(
  conn,
  name,
  param = NULL,
  set = NULL,
  unset = NULL,
  update = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="config_params_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="config_params_+3A_name">name</code></td>
<td>
<p>(character) The name of the core. If not given, all cores.</p>
</td></tr>
<tr><td><code id="config_params_+3A_param">param</code></td>
<td>
<p>(character) Name of a parameter</p>
</td></tr>
<tr><td><code id="config_params_+3A_set">set</code></td>
<td>
<p>(list) List of key:value pairs of what to set. Create or
overwrite a parameter set map. Default: NULL (nothing passed)</p>
</td></tr>
<tr><td><code id="config_params_+3A_unset">unset</code></td>
<td>
<p>(list) One or more character strings of keys to unset.
Default: <code>NULL</code> (nothing passed)</p>
</td></tr>
<tr><td><code id="config_params_+3A_update">update</code></td>
<td>
<p>(list) List of key:value pairs of what to update. Updates
a parameter set map. This essentially overwrites the old parameter set,
so all parameters must be sent in each update request.</p>
</td></tr>
<tr><td><code id="config_params_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Request Parameters API allows creating parameter sets that can
override or take the place of parameters defined in solrconfig.xml. It is
really another endpoint of the Config API instead of a separate API, and
has distinct commands. It does not replace or modify any sections of
solrconfig.xml, but instead provides another approach to handling parameters
used in requests. It behaves in the same way as the Config API, by storing
parameters in another file that will be used at runtime. In this case,
the parameters are stored in a file named params.json. This file is kept in
ZooKeeper or in the conf directory of a standalone Solr instance.
</p>


<h3>Value</h3>

<p>A list with response from server
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr in standard or Cloud mode
# connect
(conn &lt;- SolrClient$new())

# set a parameter set
myFacets &lt;- list(myFacets = list(facet = TRUE, facet.limit = 5))
config_params(conn, "gettingstarted", set = myFacets)

# check a parameter
config_params(conn, "gettingstarted", param = "myFacets")

## End(Not run)
</code></pre>

<hr>
<h2 id='config_set'>Set Solr configuration details</h2><span id='topic+config_set'></span>

<h3>Description</h3>

<p>Set Solr configuration details
</p>


<h3>Usage</h3>

<pre><code class='language-R'>config_set(conn, name, set = NULL, unset = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="config_set_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="config_set_+3A_name">name</code></td>
<td>
<p>(character) The name of the core. If not given, all cores.</p>
</td></tr>
<tr><td><code id="config_set_+3A_set">set</code></td>
<td>
<p>(list) List of key:value pairs of what to set.
Default: <code>NULL</code> (nothing passed)</p>
</td></tr>
<tr><td><code id="config_set_+3A_unset">unset</code></td>
<td>
<p>(list) One or more character strings of keys to unset.
Default: <code>NULL</code> (nothing passed)</p>
</td></tr>
<tr><td><code id="config_set_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with response from server
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Cloud mode via the schemaless eg: bin/solr -e cloud
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below

# connect
(conn &lt;- SolrClient$new())

# set a property
conn$config_set("gettingstarted", 
  set = list(query.filterCache.autowarmCount = 1000))

# unset a property
conn$config_set("gettingstarted", unset = "query.filterCache.size", 
  verbose = TRUE)

# many properties
conn$config_set("gettingstarted", set = list(
   query.filterCache.autowarmCount = 1000,
   query.commitWithin.softCommit = 'false'
 )
)

## End(Not run)
</code></pre>

<hr>
<h2 id='core_create'>Create a core</h2><span id='topic+core_create'></span>

<h3>Description</h3>

<p>Create a core
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_create(
  conn,
  name,
  instanceDir = NULL,
  config = NULL,
  schema = NULL,
  dataDir = NULL,
  configSet = NULL,
  collection = NULL,
  shard = NULL,
  async = NULL,
  raw = FALSE,
  callopts = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_create_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_create_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_create_+3A_instancedir">instanceDir</code></td>
<td>
<p>(character) Path to instance directory</p>
</td></tr>
<tr><td><code id="core_create_+3A_config">config</code></td>
<td>
<p>(character) Path to config file</p>
</td></tr>
<tr><td><code id="core_create_+3A_schema">schema</code></td>
<td>
<p>(character) Path to schema file</p>
</td></tr>
<tr><td><code id="core_create_+3A_datadir">dataDir</code></td>
<td>
<p>(character) Name of the data directory relative to
instanceDir.</p>
</td></tr>
<tr><td><code id="core_create_+3A_configset">configSet</code></td>
<td>
<p>(character) Name of the configset to use for this core.
For more information, see
https://lucene.apache.org/solr/guide/6_6/config-sets.html</p>
</td></tr>
<tr><td><code id="core_create_+3A_collection">collection</code></td>
<td>
<p>(character) The name of the collection to which this core
belongs. The default is the name of the <code style="white-space: pre;">&#8288;core.collection.&lt;param&gt;=&lt;value&gt;&#8288;</code>
causes a property of <code style="white-space: pre;">&#8288;&lt;param&gt;=&lt;value&gt;&#8288;</code> to be set if a new collection is being
created. Use <code style="white-space: pre;">&#8288;collection.configName=&lt;configname&gt;&#8288;</code> to point to the
configuration for a new collection.</p>
</td></tr>
<tr><td><code id="core_create_+3A_shard">shard</code></td>
<td>
<p>(character) The shard id this core represents. Normally you
want to be auto-assigned a shard id.</p>
</td></tr>
<tr><td><code id="core_create_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be
processed asynchronously</p>
</td></tr>
<tr><td><code id="core_create_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_create_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="core_create_+3A_...">...</code></td>
<td>
<p>You can pass in parameters like <code>property.name=value</code>    to set
core property name to value. See the section Defining core.properties for
details on supported properties and values.
(https://lucene.apache.org/solr/guide/6_6/defining-core-properties.html)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#   bin/solr start -e schemaless
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or create as below

# connect
(conn &lt;- SolrClient$new())

# Create a core
path &lt;- "~/solr-8.2.0/server/solr/newcore/conf"
dir.create(path, recursive = TRUE)
files &lt;- list.files("~/solr-8.2.0/server/solr/configsets/sample_techproducts_configs/conf/",
full.names = TRUE)
invisible(file.copy(files, path, recursive = TRUE))
conn$core_create(name = "newcore", instanceDir = "newcore",
  configSet = "sample_techproducts_configs")

## End(Not run)
</code></pre>

<hr>
<h2 id='core_exists'>Check if a core exists</h2><span id='topic+core_exists'></span>

<h3>Description</h3>

<p>Check if a core exists
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_exists(conn, name, callopts = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_exists_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_exists_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_exists_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simply calls <code><a href="#topic+core_status">core_status()</a></code> internally
</p>


<h3>Value</h3>

<p>A single boolean, <code>TRUE</code> or <code>FALSE</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#   bin/solr start -e schemaless
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or create as below

# connect
(conn &lt;- SolrClient$new())

# exists
conn$core_exists("gettingstarted")

# doesn't exist
conn$core_exists("hhhhhh")

## End(Not run)
</code></pre>

<hr>
<h2 id='core_mergeindexes'>Merge indexes (cores)</h2><span id='topic+core_mergeindexes'></span>

<h3>Description</h3>

<p>Merges one or more indexes to another index. The indexes must
have completed commits, and should be locked against writes until the merge
is complete or the resulting merged index may become corrupted. The target
core index must already exist and have a compatible schema with the one or
more indexes that will be merged to it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_mergeindexes(
  conn,
  name,
  indexDir = NULL,
  srcCore = NULL,
  async = NULL,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_mergeindexes_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_mergeindexes_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_mergeindexes_+3A_indexdir">indexDir</code></td>
<td>
<p>(character)    Multi-valued, directories that would be merged.</p>
</td></tr>
<tr><td><code id="core_mergeindexes_+3A_srccore">srcCore</code></td>
<td>
<p>(character)    Multi-valued, source cores that would be merged.</p>
</td></tr>
<tr><td><code id="core_mergeindexes_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be
processed asynchronously</p>
</td></tr>
<tr><td><code id="core_mergeindexes_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_mergeindexes_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#  bin/solr start -e schemaless

# connect
(conn &lt;- SolrClient$new())

## FIXME: not tested yet

# use indexDir parameter
# conn$core_mergeindexes(core="new_core_name",
#    indexDir = c("/solr_home/core1/data/index",
#    "/solr_home/core2/data/index"))

# use srcCore parameter
# conn$core_mergeindexes(name = "new_core_name", srcCore = c('core1', 'core2'))

## End(Not run)
</code></pre>

<hr>
<h2 id='core_reload'>Reload a core</h2><span id='topic+core_reload'></span>

<h3>Description</h3>

<p>Reload a core
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_reload(conn, name, raw = FALSE, callopts = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_reload_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_reload_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_reload_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_reload_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#  bin/solr start -e schemaless
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below

# connect
(conn &lt;- SolrClient$new())

# Status of particular cores
if (conn$core_exists("gettingstarted")) {
  conn$core_reload("gettingstarted")
  conn$core_status("gettingstarted")
}

## End(Not run)
</code></pre>

<hr>
<h2 id='core_rename'>Rename a core</h2><span id='topic+core_rename'></span>

<h3>Description</h3>

<p>Rename a core
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_rename(conn, name, other, async = NULL, raw = FALSE, callopts = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_rename_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_rename_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_rename_+3A_other">other</code></td>
<td>
<p>(character) The new name of the core. Required.</p>
</td></tr>
<tr><td><code id="core_rename_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be
processed asynchronously</p>
</td></tr>
<tr><td><code id="core_rename_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_rename_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#   bin/solr start -e schemaless
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below

# connect
(conn &lt;- SolrClient$new())

# Status of particular cores
path &lt;- "~/solr-8.2.0/server/solr/testcore/conf"
dir.create(path, recursive = TRUE)
files &lt;- list.files(
"~/solr-8.2.0/server/solr/configsets/sample_techproducts_configs/conf/",
full.names = TRUE)
invisible(file.copy(files, path, recursive = TRUE))
conn$core_create("testcore") # or create in CLI: bin/solr create -c testcore

# rename
conn$core_rename("testcore", "newtestcore")
## status
conn$core_status("testcore") # core missing
conn$core_status("newtestcore", FALSE) # not missing

# cleanup
conn$core_unload("newtestcore")

## End(Not run)
</code></pre>

<hr>
<h2 id='core_requeststatus'>Request status of asynchronous CoreAdmin API call</h2><span id='topic+core_requeststatus'></span>

<h3>Description</h3>

<p>Request status of asynchronous CoreAdmin API call
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_requeststatus(conn, requestid, raw = FALSE, callopts = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_requeststatus_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_requeststatus_+3A_requestid">requestid</code></td>
<td>
<p>The name of one of the cores to be removed. Required</p>
</td></tr>
<tr><td><code id="core_requeststatus_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_requeststatus_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#   bin/solr start -e schemaless

# FIXME: not tested yet...
# (conn &lt;- SolrClient$new())
# conn$core_requeststatus(requestid = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='core_split'>Split a core</h2><span id='topic+core_split'></span>

<h3>Description</h3>

<p>SPLIT splits an index into two or more indexes. The index being
split can continue to handle requests. The split pieces can be placed into
a specified directory on the server's filesystem or it can be merged into
running Solr cores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_split(
  conn,
  name,
  path = NULL,
  targetCore = NULL,
  ranges = NULL,
  split.key = NULL,
  async = NULL,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_split_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_split_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_split_+3A_path">path</code></td>
<td>
<p>(character) Two or more target directory paths in which a piece
of the index will be written</p>
</td></tr>
<tr><td><code id="core_split_+3A_targetcore">targetCore</code></td>
<td>
<p>(character) Two or more target Solr cores to which a piece
of the index will be merged</p>
</td></tr>
<tr><td><code id="core_split_+3A_ranges">ranges</code></td>
<td>
<p>(character) A list of number ranges, or hash ranges in
hexadecimal format. If numbers, they get converted to hexidecimal format
before being passed to your Solr server.</p>
</td></tr>
<tr><td><code id="core_split_+3A_split.key">split.key</code></td>
<td>
<p>(character) The key to be used for splitting the index</p>
</td></tr>
<tr><td><code id="core_split_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be
processed asynchronously</p>
</td></tr>
<tr><td><code id="core_split_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_split_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The core index will be split into as many pieces as the number of
<code>path</code> or <code>targetCore</code> parameters.
</p>
<p>Either <code>path</code> or <code>targetCore</code> parameter must be specified but not
both. The <code>ranges</code> and <code>split.key</code> parameters are optional and only one of
the two should be specified, if at all required.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg: bin/solr start -e schemaless
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below

# connect
(conn &lt;- SolrClient$new())

# Swap a core
## First, create two cores
# conn$core_split("splitcoretest0") # or create in the CLI: bin/solr create -c splitcoretest0
# conn$core_split("splitcoretest1") # or create in the CLI: bin/solr create -c splitcoretest1
# conn$core_split("splitcoretest2") # or create in the CLI: bin/solr create -c splitcoretest2

## check status
conn$core_status("splitcoretest0", FALSE)
conn$core_status("splitcoretest1", FALSE)
conn$core_status("splitcoretest2", FALSE)

## split core using targetCore parameter
conn$core_split("splitcoretest0", targetCore = c("splitcoretest1", "splitcoretest2"))

## split core using split.key parameter
### Here all documents having the same route key as the split.key i.e. 'A!'
### will be split from the core index and written to the targetCore
conn$core_split("splitcoretest0", targetCore = "splitcoretest1", split.key = "A!")

## split core using ranges parameter
### Solr expects hash ranges in hexidecimal, but since we're in R,
### let's not make our lives any harder, so you can pass in numbers
### but you can still pass in hexidecimal if you want.
rgs &lt;- c('0-1f4', '1f5-3e8')
conn$core_split("splitcoretest0",
  targetCore = c("splitcoretest1", "splitcoretest2"), ranges = rgs)
rgs &lt;- list(c(0, 500), c(501, 1000))
conn$core_split("splitcoretest0",
  targetCore = c("splitcoretest1", "splitcoretest2"), ranges = rgs)

## End(Not run)
</code></pre>

<hr>
<h2 id='core_status'>Get core status</h2><span id='topic+core_status'></span>

<h3>Description</h3>

<p>Get core status
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_status(
  conn,
  name = NULL,
  indexInfo = TRUE,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_status_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_status_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_status_+3A_indexinfo">indexInfo</code></td>
<td>
<p>(logical)</p>
</td></tr>
<tr><td><code id="core_status_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_status_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#   bin/solr start -e schemaless
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below

# connect
(conn &lt;- SolrClient$new())

# Status of all cores
conn$core_status()

# Status of particular cores
conn$core_status("gettingstarted")

# Get index info or not
## Default: TRUE
conn$core_status("gettingstarted", indexInfo = TRUE)
conn$core_status("gettingstarted", indexInfo = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='core_swap'>Swap a core</h2><span id='topic+core_swap'></span>

<h3>Description</h3>

<p>SWAP atomically swaps the names used to access two existing
Solr cores. This can be used to swap new content into production. The
prior core remains available and can be swapped back, if necessary. Each
core will be known by the name of the other, after the swap
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_swap(conn, name, other, async = NULL, raw = FALSE, callopts = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_swap_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_swap_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_swap_+3A_other">other</code></td>
<td>
<p>(character) The name of one of the cores to be swapped.
Required.</p>
</td></tr>
<tr><td><code id="core_swap_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be
processed asynchronously</p>
</td></tr>
<tr><td><code id="core_swap_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_swap_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Do not use <code>core_swap</code> with a SolrCloud node. It is not
supported and can result in the core being unusable. We'll try to stop
you if you try.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#   bin/solr start -e schemaless
# you can create a new core like: bin/solr create -c corename
# where &lt;corename&gt; is the name for your core - or creaate as below

# connect
(conn &lt;- SolrClient$new())

# Swap a core
## First, create two cores
conn$core_create("swapcoretest1")
# - or create on CLI: bin/solr create -c swapcoretest1
conn$core_create("swapcoretest2")
# - or create on CLI: bin/solr create -c swapcoretest2

## check status
conn$core_status("swapcoretest1", FALSE)
conn$core_status("swapcoretest2", FALSE)

## swap core
conn$core_swap("swapcoretest1", "swapcoretest2")

## check status again
conn$core_status("swapcoretest1", FALSE)
conn$core_status("swapcoretest2", FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='core_unload'>Unload (delete) a core</h2><span id='topic+core_unload'></span>

<h3>Description</h3>

<p>Unload (delete) a core
</p>


<h3>Usage</h3>

<pre><code class='language-R'>core_unload(
  conn,
  name,
  deleteIndex = FALSE,
  deleteDataDir = FALSE,
  deleteInstanceDir = FALSE,
  async = NULL,
  raw = FALSE,
  callopts = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="core_unload_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="core_unload_+3A_name">name</code></td>
<td>
<p>(character) The name of the core to be created. Required</p>
</td></tr>
<tr><td><code id="core_unload_+3A_deleteindex">deleteIndex</code></td>
<td>
<p>(logical) If <code>TRUE</code>, will remove the index when
unloading the core. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="core_unload_+3A_deletedatadir">deleteDataDir</code></td>
<td>
<p>(logical)    If <code>TRUE</code>, removes the data directory
and all sub-directories. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="core_unload_+3A_deleteinstancedir">deleteInstanceDir</code></td>
<td>
<p>(logical)    If <code>TRUE</code>, removes everything related to
the core, including the index directory, configuration files and other
related files. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="core_unload_+3A_async">async</code></td>
<td>
<p>(character) Request ID to track this action which will be
processed asynchronously</p>
</td></tr>
<tr><td><code id="core_unload_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data</p>
</td></tr>
<tr><td><code id="core_unload_+3A_callopts">callopts</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr with Schemaless mode via the schemaless eg:
#   bin/solr start -e schemaless

# connect
(conn &lt;- SolrClient$new())

# Create a core
conn$core_create(name = "books")

# Unload a core
conn$core_unload(name = "books")
## not found
# conn$core_unload(name = "books")
# &gt; Error: 400 - Cannot unload non-existent core [books]

## End(Not run)
</code></pre>

<hr>
<h2 id='delete'>Delete documents by ID or query</h2><span id='topic+delete'></span><span id='topic+delete_by_id'></span><span id='topic+delete_by_query'></span>

<h3>Description</h3>

<p>Delete documents by ID or query
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delete_by_id(
  conn,
  ids,
  name,
  commit = TRUE,
  commit_within = NULL,
  overwrite = TRUE,
  boost = NULL,
  wt = "json",
  raw = FALSE,
  ...
)

delete_by_query(
  conn,
  query,
  name,
  commit = TRUE,
  commit_within = NULL,
  overwrite = TRUE,
  boost = NULL,
  wt = "json",
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="delete_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="delete_+3A_ids">ids</code></td>
<td>
<p>Document IDs, one or more in a vector or list</p>
</td></tr>
<tr><td><code id="delete_+3A_name">name</code></td>
<td>
<p>(character) A collection or core name. Required.</p>
</td></tr>
<tr><td><code id="delete_+3A_commit">commit</code></td>
<td>
<p>(logical) If <code>TRUE</code>, documents immediately searchable.
Deafult: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="delete_+3A_commit_within">commit_within</code></td>
<td>
<p>(numeric) Milliseconds to commit the change, the
document will be added within that time. Default: <code>NULL</code></p>
</td></tr>
<tr><td><code id="delete_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical) Overwrite documents with matching keys.
Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="delete_+3A_boost">boost</code></td>
<td>
<p>(numeric) Boost factor. Default: <code>NULL</code></p>
</td></tr>
<tr><td><code id="delete_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to
parse</p>
</td></tr>
<tr><td><code id="delete_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="delete_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="delete_+3A_query">query</code></td>
<td>
<p>Query to use to delete documents</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We use json internally as data interchange format for this function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(cli &lt;- SolrClient$new())

# add some documents first
ss &lt;- list(list(id = 1, price = 100), list(id = 2, price = 500))
cli$add(ss, name = "gettingstarted")

# Now, delete them
# Delete by ID
cli$delete_by_id(ids = 1, "gettingstarted")
## Many IDs
cli$delete_by_id(ids = c(3, 4), "gettingstarted")

# Delete by query 
cli$search("gettingstarted", params=list(q="*:*")) # apple is there
cli$delete_by_query(query = 'id:apple', "gettingstarted") # delete it
cli$search("gettingstarted", params=list(q='id:apple')) # apple is now gone

## End(Not run)
</code></pre>

<hr>
<h2 id='is.sr_facet'>Test for sr_facet class</h2><span id='topic+is.sr_facet'></span><span id='topic+is.sr_high'></span><span id='topic+is.sr_search'></span>

<h3>Description</h3>

<p>Test for sr_facet class
</p>
<p>Test for sr_high class
</p>
<p>Test for sr_search class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.sr_facet(x)

is.sr_high(x)

is.sr_search(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.sr_facet_+3A_x">x</code></td>
<td>
<p>Input</p>
</td></tr>
</table>

<hr>
<h2 id='makemultiargs'>Function to make make multiple args of the same name from a
single input with length &gt; 1</h2><span id='topic+makemultiargs'></span>

<h3>Description</h3>

<p>Function to make make multiple args of the same name from a
single input with length &gt; 1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makemultiargs(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makemultiargs_+3A_x">x</code></td>
<td>
<p>Value</p>
</td></tr>
</table>

<hr>
<h2 id='ping'>Ping a Solr instance</h2><span id='topic+ping'></span>

<h3>Description</h3>

<p>Ping a Solr instance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ping(conn, name, wt = "json", raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ping_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="ping_+3A_name">name</code></td>
<td>
<p>(character) Name of a collection or core. Required.</p>
</td></tr>
<tr><td><code id="ping_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses [xml2::read_xml)] to parse
</p>
<p>[xml2::read_xml)]: R:xml2::read_xml)</p>
</td></tr>
<tr><td><code id="ping_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="ping_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>You likely may not be able to run this function against many public
Solr services as they hopefully don't expose their admin interface to the
public, but works locally.
</p>


<h3>Value</h3>

<p>if <code>wt="xml"</code> an object of class <code>xml_document</code>, if
<code>wt="json"</code> an object of class <code>list</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr, in your CLI, run: `bin/solr start -e cloud -noprompt`
# after that, if you haven't run `bin/post -c gettingstarted docs/` yet,
# do so

# connect: by default we connect to localhost, port 8983
(cli &lt;- SolrClient$new())

# ping the gettingstarted index
cli$ping("gettingstarted")
ping(cli, "gettingstarted")
ping(cli, "gettingstarted", wt = "xml")
ping(cli, "gettingstarted", verbose = FALSE)
ping(cli, "gettingstarted", raw = TRUE)

ping(cli, "gettingstarted", wt="xml", verbose = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='pivot_flatten_tabular'>Flatten facet.pivot responses</h2><span id='topic+pivot_flatten_tabular'></span>

<h3>Description</h3>

<p>Convert a nested hierarchy of facet.pivot elements
to tabular data (rows and columns)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pivot_flatten_tabular(df_w_pivot)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pivot_flatten_tabular_+3A_df_w_pivot">df_w_pivot</code></td>
<td>
<p>a <code>data.frame</code> with another
<code>data.frame</code> nested inside representing a
pivot reponse</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code>
</p>

<hr>
<h2 id='schema'>Get the schema for a collection or core</h2><span id='topic+schema'></span>

<h3>Description</h3>

<p>Get the schema for a collection or core
</p>


<h3>Usage</h3>

<pre><code class='language-R'>schema(conn, name, what = "", raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="schema_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="schema_+3A_name">name</code></td>
<td>
<p>(character) Name of a collection or core. Required.</p>
</td></tr>
<tr><td><code id="schema_+3A_what">what</code></td>
<td>
<p>(character) What to retrieve. By default, we retrieve the entire
schema. Options include: fields, dynamicfields, fieldtypes, copyfields, name,
version, uniquekey, similarity, &quot;solrqueryparser/defaultoperator&quot;</p>
</td></tr>
<tr><td><code id="schema_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="schema_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr, in your CLI, run: `bin/solr start -e cloud -noprompt`
# after that, if you haven't run `bin/post -c gettingstarted docs/` yet, do so

# connect: by default we connect to localhost, port 8983
(cli &lt;- SolrClient$new())

# get the schema for the gettingstarted index
schema(cli, name = "gettingstarted")

# Get parts of the schema
schema(cli, name = "gettingstarted", "fields")
schema(cli, name = "gettingstarted", "dynamicfields")
schema(cli, name = "gettingstarted", "fieldtypes")
schema(cli, name = "gettingstarted", "copyfields")
schema(cli, name = "gettingstarted", "name")
schema(cli, name = "gettingstarted", "version")
schema(cli, name = "gettingstarted", "uniquekey")
schema(cli, name = "gettingstarted", "similarity")
schema(cli, name = "gettingstarted", "solrqueryparser/defaultoperator")

# get raw data
schema(cli, name = "gettingstarted", "similarity", raw = TRUE)
schema(cli, name = "gettingstarted", "uniquekey", raw = TRUE)

# start Solr in Schemaless mode: bin/solr start -e schemaless
# schema(cli, "gettingstarted")

# start Solr in Standalone mode: bin/solr start
# then add a core: bin/solr create -c helloWorld
# schema(cli, "helloWorld")

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_all'>All purpose search</h2><span id='topic+solr_all'></span>

<h3>Description</h3>

<p>Includes documents, facets, groups, mlt, stats, and highlights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_all(
  conn,
  name = NULL,
  params = NULL,
  body = NULL,
  callopts = list(),
  raw = FALSE,
  parsetype = "df",
  concat = ",",
  optimizeMaxRows = TRUE,
  minOptimizedRows = 50000L,
  progress = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_all_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_all_+3A_name">name</code></td>
<td>
<p>Name of a collection or core. Or leave as <code>NULL</code> if not needed.</p>
</td></tr>
<tr><td><code id="solr_all_+3A_params">params</code></td>
<td>
<p>(list) a named list of parameters, results in a GET request
as long as no body parameters given</p>
</td></tr>
<tr><td><code id="solr_all_+3A_body">body</code></td>
<td>
<p>(list) a named list of parameters, if given a POST request
will be performed</p>
</td></tr>
<tr><td><code id="solr_all_+3A_callopts">callopts</code></td>
<td>
<p>Call options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="solr_all_+3A_raw">raw</code></td>
<td>
<p>(logical) If TRUE, returns raw data in format specified by wt param</p>
</td></tr>
<tr><td><code id="solr_all_+3A_parsetype">parsetype</code></td>
<td>
<p>(character) One of 'list' or 'df'</p>
</td></tr>
<tr><td><code id="solr_all_+3A_concat">concat</code></td>
<td>
<p>(character) Character to concatenate elements of longer than length 1.
Note that this only works reliably when data format is json (wt='json'). The parsing
is more complicated in XML format, but you can do that on your own.</p>
</td></tr>
<tr><td><code id="solr_all_+3A_optimizemaxrows">optimizeMaxRows</code></td>
<td>
<p>(logical) If <code>TRUE</code>, then rows parameter will be
adjusted to the number of returned results by the same constraints.
It will only be applied if rows parameter is higher
than <code>minOptimizedRows</code>. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="solr_all_+3A_minoptimizedrows">minOptimizedRows</code></td>
<td>
<p>(numeric) used by <code>optimizedMaxRows</code> parameter,
the minimum optimized rows. Default: 50000</p>
</td></tr>
<tr><td><code id="solr_all_+3A_progress">progress</code></td>
<td>
<p>a function with logic for printing a progress
bar for an HTTP request, ultimately passed down to <span class="pkg">curl</span>. only supports
<code>httr::progress</code> for now. See the README for an example.</p>
</td></tr>
<tr><td><code id="solr_all_+3A_...">...</code></td>
<td>
<p>Further args to be combined into query</p>
</td></tr>
</table>


<h3>Value</h3>

<p>XML, JSON, a list, or data.frame
</p>


<h3>Parameters</h3>


<ul>
<li><p> q Query terms, defaults to '<em>:</em>', or everything.
</p>
</li>
<li><p> sort Field to sort on. You can specify ascending (e.g., score desc) or
descending (e.g., score asc), sort by two fields (e.g., score desc, price asc),
or sort by a function (e.g., sum(x_f, y_f) desc, which sorts by the sum of
x_f and y_f in a descending order).
</p>
</li>
<li><p> start Record to start at, default to beginning.
</p>
</li>
<li><p> rows Number of records to return. Default: 10.
</p>
</li>
<li><p> pageDoc If you expect to be paging deeply into the results (say beyond page 10,
assuming rows=10) and you are sorting by score, you may wish to add the pageDoc
and pageScore parameters to your request. These two parameters tell Solr (and Lucene)
what the last result (Lucene internal docid and score) of the previous page was,
so that when scoring the query for the next set of pages, it can ignore any results
that occur higher than that item. To get the Lucene internal doc id, you will need
to add <code>docid</code> to the &amp;fl list.
</p>
</li>
<li><p> pageScore See pageDoc notes.
</p>
</li>
<li><p> fq Filter query, this does not affect the search, only what gets returned.
This parameter can accept multiple items in a lis or vector. You can't pass more than
one parameter of the same name, so we get around it by passing multiple queries
and we parse internally
</p>
</li>
<li><p> fl Fields to return, can be a character vector like <code>c('id', 'title')</code>,
or a single character vector with one or more comma separated names, like
<code>'id,title'</code>
</p>
</li>
<li><p> defType Specify the query parser to use with this request.
</p>
</li>
<li><p> timeAllowed The time allowed for a search to finish. This value only applies
to the search and not to requests in general. Time is in milliseconds. Values <code>&lt;= 0</code>
mean no time restriction. Partial results may be returned (if there are any).
</p>
</li>
<li><p> qt Which query handler used. Options: dismax, others?
</p>
</li>
<li><p> NOW Set a fixed time for evaluating Date based expresions
</p>
</li>
<li><p> TZ Time zone, you can override the default.
</p>
</li>
<li><p> echoHandler If <code>TRUE</code>, Solr places the name of the handle used in the
response to the client for debugging purposes. Default:
</p>
</li>
<li><p> echoParams The echoParams parameter tells Solr what kinds of Request
parameters should be included in the response for debugging purposes, legal values
include:
</p>

<ul>
<li><p> none - don't include any request parameters for debugging
</p>
</li>
<li><p> explicit - include the parameters explicitly specified by the client in the request
</p>
</li>
<li><p> all - include all parameters involved in this request, either specified explicitly
by the client, or implicit because of the request handler configuration.
</p>
</li></ul>

</li>
<li><p> wt (character) One of json, xml, or csv. Data type returned, defaults
to 'csv'. If json, uses <code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml,
uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to parse. If csv, uses <code><a href="utils.html#topic+read.table">read.table()</a></code> to parse.
<code>wt=csv</code> gives the fastest performance at least in all the cases we have
tested in, thus it's the default value for <code>wt</code>
</p>
</li></ul>



<h3>References</h3>

<p>See https://lucene.apache.org/solr/guide/8_2/searching.html for
more information.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+solr_highlight">solr_highlight()</a></code>, <code><a href="#topic+solr_facet">solr_facet()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# connect
(cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))

solr_all(cli, params = list(q='*:*', rows=2, fl='id'))

# facets
solr_all(cli, params = list(q='*:*', rows=2, fl='id', facet="true",
  facet.field="journal"))

# mlt
solr_all(cli, params = list(q='ecology', rows=2, fl='id', mlt='true',
  mlt.count=2, mlt.fl='abstract'))

# facets and mlt
solr_all(cli, params = list(q='ecology', rows=2, fl='id', facet="true",
  facet.field="journal", mlt='true', mlt.count=2, mlt.fl='abstract'))

# stats
solr_all(cli, params = list(q='ecology', rows=2, fl='id', stats='true',
  stats.field='counter_total_all'))

# facets, mlt, and stats
solr_all(cli, params = list(q='ecology', rows=2, fl='id', facet="true",
  facet.field="journal", mlt='true', mlt.count=2, mlt.fl='abstract',
  stats='true', stats.field='counter_total_all'))

# group
solr_all(cli, params = list(q='ecology', rows=2, fl='id', group='true',
 group.field='journal', group.limit=3))

# facets, mlt, stats, and groups
solr_all(cli, params = list(q='ecology', rows=2, fl='id', facet="true",
 facet.field="journal", mlt='true', mlt.count=2, mlt.fl='abstract',
 stats='true', stats.field='counter_total_all', group='true',
 group.field='journal', group.limit=3))

# using wt = xml
solr_all(cli, params = list(q='*:*', rows=50, fl=c('id','score'),
  fq='doc_type:full', wt="xml"), raw=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_facet'>Faceted search</h2><span id='topic+solr_facet'></span>

<h3>Description</h3>

<p>Returns only facet items
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_facet(
  conn,
  name = NULL,
  params = list(q = "*:*"),
  body = NULL,
  callopts = list(),
  raw = FALSE,
  parsetype = "df",
  concat = ",",
  progress = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_facet_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_facet_+3A_name">name</code></td>
<td>
<p>Name of a collection or core. Or leave as <code>NULL</code> if not needed.</p>
</td></tr>
<tr><td><code id="solr_facet_+3A_params">params</code></td>
<td>
<p>(list) a named list of parameters, results in a GET request
as long as no body parameters given</p>
</td></tr>
<tr><td><code id="solr_facet_+3A_body">body</code></td>
<td>
<p>(list) a named list of parameters, if given a POST request
will be performed</p>
</td></tr>
<tr><td><code id="solr_facet_+3A_callopts">callopts</code></td>
<td>
<p>Call options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="solr_facet_+3A_raw">raw</code></td>
<td>
<p>(logical) If TRUE (default) raw json or xml returned. If FALSE,
parsed data returned.</p>
</td></tr>
<tr><td><code id="solr_facet_+3A_parsetype">parsetype</code></td>
<td>
<p>(character) One of 'list' or 'df'</p>
</td></tr>
<tr><td><code id="solr_facet_+3A_concat">concat</code></td>
<td>
<p>(character) Character to concatenate elements of longer than length 1.
Note that this only works reliably when data format is json (wt='json'). The parsing
is more complicated in XML format, but you can do that on your own.</p>
</td></tr>
<tr><td><code id="solr_facet_+3A_progress">progress</code></td>
<td>
<p>a function with logic for printing a progress
bar for an HTTP request, ultimately passed down to <span class="pkg">curl</span>. only supports
<code>httr::progress</code> for now. See the README for an example.</p>
</td></tr>
<tr><td><code id="solr_facet_+3A_...">...</code></td>
<td>
<p>Further args, usually per field arguments for faceting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of fields can be specified multiple times, in which case you can separate
them by commas, like <code>facet.field='journal,subject'</code>. Those fields are:
</p>

<ul>
<li><p> facet.field
</p>
</li>
<li><p> facet.query
</p>
</li>
<li><p> facet.date
</p>
</li>
<li><p> facet.date.other
</p>
</li>
<li><p> facet.date.include
</p>
</li>
<li><p> facet.range
</p>
</li>
<li><p> facet.range.other
</p>
</li>
<li><p> facet.range.include
</p>
</li>
<li><p> facet.pivot
</p>
</li></ul>

<p><strong>Options for some parameters</strong>:
</p>
<p><strong>facet.sort</strong>: This param determines the ordering of the facet field constraints.
</p>

<ul>
<li> <p>count sort the constraints by count (highest count first)
</p>
</li>
<li> <p>index to return the constraints sorted in their index order (lexicographic
by indexed term). For terms in the ascii range, this will be alphabetically sorted.
</p>
</li></ul>

<p>The default is count if facet.limit is greater than 0, index otherwise. This
parameter can be specified on a per field basis.
</p>
<p><strong>facet.method</strong>:
This parameter indicates what type of algorithm/method to use when faceting a field.
</p>

<ul>
<li> <p>enum Enumerates all terms in a field, calculating the set intersection of
documents that match the term with documents that match the query. This was the
default (and only) method for faceting multi-valued fields prior to Solr 1.4.
</p>
</li>
<li> <p>fc (Field Cache) The facet counts are calculated by iterating over documents
that match the query and summing the terms that appear in each document. This was
the default method for single valued fields prior to Solr 1.4.
</p>
</li>
<li> <p>fcs (Field Cache per Segment) works the same as fc except the underlying
cache data structure is built for each segment of the index individually
</p>
</li></ul>

<p>The default value is fc (except for BoolField which uses enum) since it tends to use
less memory and is faster then the enumeration method when a field has many unique
terms in the index. For indexes that are changing rapidly in NRT situations, fcs may
be a better choice because it reduces the overhead of building the cache structures
on the first request and/or warming queries when opening a new searcher &ndash; but tends
to be somewhat slower then fc for subsequent requests against the same searcher. This
parameter can be specified on a per field basis.
</p>
<p><strong>facet.date.other</strong>: This param indicates that in addition to the counts for each date
range constraint between facet.date.start and facet.date.end, counts should also be
computed for...
</p>

<ul>
<li> <p>before All records with field values lower then lower bound of the first
range
</p>
</li>
<li> <p>after All records with field values greater then the upper bound of the
last range
</p>
</li>
<li> <p>between All records with field values between the start and end bounds
of all ranges
</p>
</li>
<li> <p>none Compute none of this information
</p>
</li>
<li> <p>all Shortcut for before, between, and after
</p>
</li></ul>

<p>This parameter can be specified on a per field basis. In addition to the all option,
this parameter can be specified multiple times to indicate multiple choices &ndash; but
none will override all other options.
</p>
<p><strong>facet.date.include</strong>: By default, the ranges used to compute date faceting between
facet.date.start and facet.date.end are all inclusive of both endpoints, while
the &quot;before&quot; and &quot;after&quot; ranges are not inclusive. This behavior can be modified
by the facet.date.include param, which can be any combination of the following
options...
</p>

<ul>
<li><p>lower All gap based ranges include their lower bound
</p>
</li>
<li><p>upper All gap based ranges include their upper bound
</p>
</li>
<li><p>edge The first and last gap ranges include their edge bounds (ie: lower
for the first one, upper for the last one) even if the corresponding upper/lower
option is not specified
</p>
</li>
<li><p>outer The &quot;before&quot; and &quot;after&quot; ranges will be inclusive of their bounds,
even if the first or last ranges already include those boundaries.
</p>
</li>
<li><p>all Shorthand for lower, upper, edge, outer
</p>
</li></ul>

<p>This parameter can be specified on a per field basis. This parameter can be specified
multiple times to indicate multiple choices.
</p>
<p><strong>facet.date.include</strong>: This param indicates that in addition to the counts for each range
constraint between facet.range.start and facet.range.end, counts should also be
computed for...
</p>

<ul>
<li><p>before All records with field values lower then lower bound of the first
range
</p>
</li>
<li><p>after All records with field values greater then the upper bound of the
last range
</p>
</li>
<li><p>between All records with field values between the start and end bounds
of all ranges
</p>
</li>
<li><p>none Compute none of this information
</p>
</li>
<li><p>all Shortcut for before, between, and after
</p>
</li></ul>

<p>This parameter can be specified on a per field basis. In addition to the all option,
this parameter can be specified multiple times to indicate multiple choices &ndash; but
none will override all other options.
</p>
<p><strong>facet.range.include</strong>: By default, the ranges used to compute range faceting between
facet.range.start and facet.range.end are inclusive of their lower bounds and
exclusive of the upper bounds. The &quot;before&quot; range is exclusive and the &quot;after&quot;
range is inclusive. This default, equivalent to lower below, will not result in
double counting at the boundaries. This behavior can be modified by the
facet.range.include param, which can be any combination of the following options...
</p>

<ul>
<li><p>lower All gap based ranges include their lower bound
</p>
</li>
<li><p>upper All gap based ranges include their upper bound
</p>
</li>
<li><p>edge The first and last gap ranges include their edge bounds (ie: lower
for the first one, upper for the last one) even if the corresponding upper/lower
option is not specified
</p>
</li>
<li><p>outer The &quot;before&quot; and &quot;after&quot; ranges will be inclusive of their bounds,
even if the first or last ranges already include those boundaries.
</p>
</li>
<li><p>all Shorthand for lower, upper, edge, outer
</p>
</li></ul>

<p>Can be specified on a per field basis. Can be specified multiple times to indicate
multiple choices. If you want to ensure you don't double-count, don't choose both
lower &amp; upper, don't choose outer, and don't choose all.
</p>


<h3>Value</h3>

<p>Raw json or xml, or a list of length 4 parsed elements
(usually data.frame's).
</p>


<h3>Facet parameters</h3>


<ul>
<li><p> name Name of a collection or core. Or leave as <code>NULL</code> if not needed.
</p>
</li>
<li><p> q Query terms. See examples.
</p>
</li>
<li><p> facet.query This param allows you to specify an arbitrary query in the
Lucene default syntax to generate a facet count. By default, faceting returns
a count of the unique terms for a &quot;field&quot;, while facet.query allows you to
determine counts for arbitrary terms or expressions. This parameter can be
specified multiple times to indicate that multiple queries should be used as
separate facet constraints. It can be particularly useful for numeric range
based facets, or prefix based facets &ndash; see example below (i.e.
<code>price:[* TO 500]</code> and <code>price:[501 TO *]</code>).
</p>
</li>
<li><p> facet.field This param allows you to specify a field which should be
treated as a facet. It will iterate over each Term in the field and generate a
facet count using that Term as the constraint. This parameter can be specified
multiple times to indicate multiple facet fields. None of the other params in
this section will have any effect without specifying at least one field name
using this param.
</p>
</li>
<li><p> facet.prefix Limits the terms on which to facet to those starting with
the given string prefix. Note that unlike fq, this does not change the search
results &ndash; it merely reduces the facet values returned to those beginning with
the specified prefix. This parameter can be specified on a per field basis.
</p>
</li>
<li><p> facet.sort See Details.
</p>
</li>
<li><p> facet.limit This param indicates the maximum number of constraint counts
that should be returned for the facet fields. A negative value means unlimited.
Default: 100. Can be specified on a per field basis.
</p>
</li>
<li><p> facet.offset This param indicates an offset into the list of constraints
to allow paging. Default: 0. This parameter can be specified on a per field basis.
</p>
</li>
<li><p> facet.mincount This param indicates the minimum counts for facet fields
should be included in the response. Default: 0. This parameter can be specified
on a per field basis.
</p>
</li>
<li><p> facet.missing Set to &quot;true&quot; this param indicates that in addition to the
Term based constraints of a facet field, a count of all matching results which
have no value for the field should be computed. Default: FALSE. This parameter
can be specified on a per field basis.
</p>
</li>
<li><p> facet.method See Details.
</p>
</li>
<li><p> facet.enum.cache.minDf This param indicates the minimum document frequency
(number of documents matching a term) for which the filterCache should be used
when determining the constraint count for that term. This is only used when
facet.method=enum method of faceting. A value greater than zero will decrease
memory usage of the filterCache, but increase the query time. When faceting on
a field with a very large number of terms, and you wish to decrease memory usage,
try a low value of 25 to 50 first. Default: 0, causing the filterCache to be used
for all terms in the field. This parameter can be specified on a per field basis.
</p>
</li>
<li><p> facet.threads This param will cause loading the underlying fields used in
faceting to be executed in parallel with the number of threads specified. Specify
as facet.threads=# where # is the maximum number of threads used. Omitting this
parameter or specifying the thread count as 0 will not spawn any threads just as
before. Specifying a negative number of threads will spin up to Integer.MAX_VALUE
threads. Currently this is limited to the fields, range and query facets are not
yet supported. In at least one case this has reduced warmup times from 20 seconds
to under 5 seconds.
</p>
</li>
<li><p> facet.date Specify names of fields (of type DateField) which should be
treated as date facets. Can be specified multiple times to indicate multiple
date facet fields.
</p>
</li>
<li><p> facet.date.start The lower bound for the first date range for all Date
Faceting on this field. This should be a single date expression which may use
the DateMathParser syntax. Can be specified on a per field basis.
</p>
</li>
<li><p> facet.date.end The minimum upper bound for the last date range for all
Date Faceting on this field (see facet.date.hardend for an explanation of what
the actual end value may be greater). This should be a single date expression
which may use the DateMathParser syntax. Can be specified on a per field basis.
</p>
</li>
<li><p> facet.date.gap The size of each date range expressed as an interval to
be added to the lower bound using the DateMathParser syntax. Eg:
facet.date.gap=+1DAY. Can be specified on a per field basis.
</p>
</li>
<li><p> facet.date.hardend A Boolean parameter instructing Solr what to do in the
event that facet.date.gap does not divide evenly between facet.date.start and
facet.date.end. If this is true, the last date range constraint will have an
upper bound of facet.date.end; if false, the last date range will have the smallest
possible upper bound greater then facet.date.end such that the range is exactly
facet.date.gap wide. Default: FALSE. This parameter can be specified on a per
field basis.
</p>
</li>
<li><p> facet.date.other See Details.
</p>
</li>
<li><p> facet.date.include See Details.
</p>
</li>
<li><p> facet.range Indicates what field to create range facets for. Example:
facet.range=price&amp;facet.range=age
</p>
</li>
<li><p> facet.range.start The lower bound of the ranges. Can be specified on a
per field basis. Example: f.price.facet.range.start=0.0&amp;f.age.facet.range.start=10
</p>
</li>
<li><p> facet.range.end The upper bound of the ranges. Can be specified on a per
field basis. Example: f.price.facet.range.end=1000.0&amp;f.age.facet.range.start=99
</p>
</li>
<li><p> facet.range.gap The size of each range expressed as a value to be added
to the lower bound. For date fields, this should be expressed using the
DateMathParser syntax. (ie: facet.range.gap=+1DAY). Can be specified
on a per field basis. Example: f.price.facet.range.gap=100&amp;f.age.facet.range.gap=10
</p>
</li>
<li><p> facet.range.hardend A Boolean parameter instructing Solr what to do in the
event that facet.range.gap does not divide evenly between facet.range.start and
facet.range.end. If this is true, the last range constraint will have an upper
bound of facet.range.end; if false, the last range will have the smallest possible
upper bound greater then facet.range.end such that the range is exactly
facet.range.gap wide. Default: FALSE. This parameter can be specified on a
per field basis.
</p>
</li>
<li><p> facet.range.other See Details.
</p>
</li>
<li><p> facet.range.include See Details.
</p>
</li>
<li><p> facet.pivot This param allows you to specify a single comma-separated string
of fields to allow you to facet within the results of the parent facet to return
counts in the format of SQL group by operation
</p>
</li>
<li><p> facet.pivot.mincount This param indicates the minimum counts for facet fields
to be included in the response. Default: 0. This parameter should only be specified
once.
</p>
</li>
<li><p> start Record to start at, default to beginning.
</p>
</li>
<li><p> rows Number of records to return.
</p>
</li>
<li><p> key API key, if needed.
</p>
</li>
<li><p> wt (character) Data type returned, defaults to 'json'. One of json or xml. If json,
uses <code><a href="jsonlite.html#topic+fromJSON">fromJSON</a></code> to parse. If xml, uses <code><a href="XML.html#topic+xmlParse">xmlParse</a></code> to
parse. csv is only supported in <code><a href="#topic+solr_search">solr_search</a></code> and <code><a href="#topic+solr_all">solr_all</a></code>.
</p>
</li></ul>



<h3>References</h3>

<p>See https://lucene.apache.org/solr/guide/8_2/faceting.html for
more information on faceting.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+solr_search">solr_search()</a></code>, <code><a href="#topic+solr_highlight">solr_highlight()</a></code>, <code><a href="#topic+solr_parse">solr_parse()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# connect - local Solr instance
(cli &lt;- SolrClient$new())
cli$facet("gettingstarted", params = list(q="*:*", facet.field='name'))
cli$facet("gettingstarted", params = list(q="*:*", facet.field='name'),
  callopts = list(verbose = TRUE))
cli$facet("gettingstarted", body = list(q="*:*", facet.field='name'),
  callopts = list(verbose = TRUE))

# Facet on a single field
solr_facet(cli, "gettingstarted", params = list(q='*:*', facet.field='name'))

# Remote instance
(cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))

# Facet on multiple fields
solr_facet(cli, params = list(q='alcohol',
  facet.field = c('journal','subject')))

# Using mincount
solr_facet(cli, params = list(q='alcohol', facet.field='journal',
  facet.mincount='500'))

# Using facet.query to get counts
solr_facet(cli, params = list(q='*:*', facet.field='journal',
  facet.query=c('cell','bird')))

# Using facet.pivot to simulate SQL group by counts
solr_facet(cli, params = list(q='alcohol', facet.pivot='journal,subject',
             facet.pivot.mincount=10))
## two or more fields are required - you can pass in as a single
## character string
solr_facet(cli, params = list(q='*:*', facet.pivot = "journal,subject",
  facet.limit =  3))
## Or, pass in as a vector of length 2 or greater
solr_facet(cli, params = list(q='*:*', facet.pivot = c("journal", "subject"),
  facet.limit =  3))

# Date faceting
solr_facet(cli, params = list(q='*:*', facet.date='publication_date',
  facet.date.start='NOW/DAY-5DAYS', facet.date.end='NOW',
  facet.date.gap='+1DAY'))
## two variables
solr_facet(cli, params = list(q='*:*',
  facet.date=c('publication_date', 'timestamp'),
  facet.date.start='NOW/DAY-5DAYS', facet.date.end='NOW',
  facet.date.gap='+1DAY'))

# Range faceting
solr_facet(cli, params = list(q='*:*', facet.range='counter_total_all',
  facet.range.start=5, facet.range.end=1000, facet.range.gap=10))

# Range faceting with &gt; 1 field, same settings
solr_facet(cli, params = list(q='*:*',
  facet.range=c('counter_total_all','alm_twitterCount'),
  facet.range.start=5, facet.range.end=1000, facet.range.gap=10))

# Range faceting with &gt; 1 field, different settings
solr_facet(cli, params = list(q='*:*',
  facet.range=c('counter_total_all','alm_twitterCount'),
  f.counter_total_all.facet.range.start=5,
  f.counter_total_all.facet.range.end=1000,
  f.counter_total_all.facet.range.gap=10,
  f.alm_twitterCount.facet.range.start=5,
  f.alm_twitterCount.facet.range.end=1000,
  f.alm_twitterCount.facet.range.gap=10))

# Get raw json or xml
## json
solr_facet(cli, params = list(q='*:*', facet.field='journal'), raw=TRUE)
## xml
solr_facet(cli, params = list(q='*:*', facet.field='journal', wt='xml'),
  raw=TRUE)

# Get raw data back, and parse later, same as what goes on internally if
# raw=FALSE (Default)
out &lt;- solr_facet(cli, params = list(q='*:*', facet.field='journal'),
  raw=TRUE)
solr_parse(out)
out &lt;- solr_facet(cli, params = list(q='*:*', facet.field='journal',
  wt = 'xml'), raw=TRUE)
solr_parse(out)

# Using the USGS BISON API (https://bison.usgs.gov/#solr)
## The occurrence endpoint
(cli &lt;- SolrClient$new(host = "bison.usgs.gov", scheme = "https",
  path = "solr/occurrences/select", port = NULL))
solr_facet(cli, params = list(q='*:*', facet.field='year'))
solr_facet(cli, params = list(q='*:*', facet.field='computedStateFips'))

# using a proxy
# cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL,
#   proxy = list(url = "http://54.195.48.153:8888"))
# solr_facet(cli, params = list(facet.field='journal'),
#   callopts=list(verbose=TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_get'>Real time get</h2><span id='topic+solr_get'></span>

<h3>Description</h3>

<p>Get documents by id
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_get(conn, ids, name, fl = NULL, wt = "json", raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_get_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_get_+3A_ids">ids</code></td>
<td>
<p>Document IDs, one or more in a vector or list</p>
</td></tr>
<tr><td><code id="solr_get_+3A_name">name</code></td>
<td>
<p>(character) A collection or core name. Required.</p>
</td></tr>
<tr><td><code id="solr_get_+3A_fl">fl</code></td>
<td>
<p>Fields to return, can be a character vector like
<code>c('id', 'title')</code>, or a single character vector with one or more
comma separated names, like <code>'id,title'</code></p>
</td></tr>
<tr><td><code id="solr_get_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. Data type returned.
If json, uses <code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses
<code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to parse.</p>
</td></tr>
<tr><td><code id="solr_get_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="solr_get_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>We use json internally as data interchange format for this function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(cli &lt;- SolrClient$new())

# add some documents first
ss &lt;- list(list(id = 1, price = 100), list(id = 2, price = 500))
add(cli, ss, name = "gettingstarted")

# Now, get documents by id
solr_get(cli, ids = 1, "gettingstarted")
solr_get(cli, ids = 2, "gettingstarted")
solr_get(cli, ids = c(1, 2), "gettingstarted")
solr_get(cli, ids = "1,2", "gettingstarted")

# Get raw JSON
solr_get(cli, ids = 1, "gettingstarted", raw = TRUE, wt = "json")
solr_get(cli, ids = 1, "gettingstarted", raw = TRUE, wt = "xml")

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_group'>Grouped search</h2><span id='topic+solr_group'></span>

<h3>Description</h3>

<p>Returns only group items
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_group(
  conn,
  name = NULL,
  params = NULL,
  body = NULL,
  callopts = list(),
  raw = FALSE,
  parsetype = "df",
  concat = ",",
  progress = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_group_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_group_+3A_name">name</code></td>
<td>
<p>Name of a collection or core. Or leave as <code>NULL</code> if not needed.</p>
</td></tr>
<tr><td><code id="solr_group_+3A_params">params</code></td>
<td>
<p>(list) a named list of parameters, results in a GET request
as long as no body parameters given</p>
</td></tr>
<tr><td><code id="solr_group_+3A_body">body</code></td>
<td>
<p>(list) a named list of parameters, if given a POST request
will be performed</p>
</td></tr>
<tr><td><code id="solr_group_+3A_callopts">callopts</code></td>
<td>
<p>Call options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="solr_group_+3A_raw">raw</code></td>
<td>
<p>(logical) If TRUE, returns raw data in format specified by wt param</p>
</td></tr>
<tr><td><code id="solr_group_+3A_parsetype">parsetype</code></td>
<td>
<p>(character) One of 'list' or 'df'</p>
</td></tr>
<tr><td><code id="solr_group_+3A_concat">concat</code></td>
<td>
<p>(character) Character to concatenate elements of longer than length 1.
Note that this only works reliably when data format is json (wt='json'). The parsing
is more complicated in XML format, but you can do that on your own.</p>
</td></tr>
<tr><td><code id="solr_group_+3A_progress">progress</code></td>
<td>
<p>a function with logic for printing a progress
bar for an HTTP request, ultimately passed down to <span class="pkg">curl</span>. only supports
<code>httr::progress</code> for now. See the README for an example.</p>
</td></tr>
<tr><td><code id="solr_group_+3A_...">...</code></td>
<td>
<p>Further args to be combined into query</p>
</td></tr>
</table>


<h3>Value</h3>

<p>XML, JSON, a list, or data.frame
</p>


<h3>Group parameters</h3>


<ul>
<li><p> q Query terms, defaults to '<em>:</em>', or everything.
</p>
</li>
<li><p> fq Filter query, this does not affect the search, only what gets returned
</p>
</li>
<li><p> fl Fields to return
</p>
</li>
<li><p> wt (character) Data type returned, defaults to 'json'. One of json or xml. If json,
uses <code><a href="jsonlite.html#topic+fromJSON">fromJSON</a></code> to parse. If xml, uses <code><a href="XML.html#topic+xmlParse">xmlParse</a></code> to
parse. csv is only supported in <code><a href="#topic+solr_search">solr_search</a></code> and <code><a href="#topic+solr_all">solr_all</a></code>.
</p>
</li>
<li><p> key API key, if needed.
</p>
</li>
<li><p> group.field (fieldname) Group based on the unique values of a field. The
field must currently be single-valued and must be either indexed, or be another
field type that has a value source and works in a function query - such as
ExternalFileField. Note: for Solr 3.x versions the field must by a string like
field such as StrField or TextField, otherwise a http status 400 is returned.
</p>
</li>
<li><p> group.func (function query) Group based on the unique values of a function
query. Solr4.0 This parameter only is supported on 4.0
</p>
</li>
<li><p> group.query (query) Return a single group of documents that also match the
given query.
</p>
</li>
<li><p> rows (number) The number of groups to return. Defaults to 10.
</p>
</li>
<li><p> start (number) The offset into the list of groups.
</p>
</li>
<li><p> group.limit (number) The number of results (documents) to return for each
group. Defaults to 1.
</p>
</li>
<li><p> group.offset (number) The offset into the document list of each group.
</p>
</li>
<li><p> sort How to sort the groups relative to each other. For example,
sort=popularity desc will cause the groups to be sorted according to the highest
popularity doc in each group. Defaults to &quot;score desc&quot;.
</p>
</li>
<li><p> group.sort How to sort documents within a single group. Defaults
to the same value as the sort parameter.
</p>
</li>
<li><p> group.format One of grouped or simple. If simple, the grouped documents are
presented in a single flat list. The start and rows parameters refer to numbers of
documents instead of numbers of groups.
</p>
</li>
<li><p> group.main (logical) If true, the result of the last field grouping command
is used as the main result list in the response, using group.format=simple
</p>
</li>
<li><p> group.ngroups (logical) If true, includes the number of groups that have
matched the query. Default is false. Solr4.1 WARNING: If this parameter is set
to true on a sharded environment, all the documents that belong to the same group
have to be located in the same shard, otherwise the count will be incorrect. If you
are using SolrCloud, consider using &quot;custom hashing&quot;
</p>
</li>
<li><p> group.cache.percent (0-100) If &gt; 0 enables grouping cache. Grouping is executed
actual two searches. This option caches the second search. A value of 0 disables
grouping caching. Default is 0. Tests have shown that this cache only improves search
time with boolean queries, wildcard queries and fuzzy queries. For simple queries like
a term query or a match all query this cache has a negative impact on performance
</p>
</li></ul>



<h3>References</h3>

<p>See
https://lucene.apache.org/solr/guide/8_2/collapse-and-expand-results.html
for more information.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+solr_highlight">solr_highlight()</a></code>, <code><a href="#topic+solr_facet">solr_facet()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# connect
(cli &lt;- SolrClient$new())

# by default we do a GET request
cli$group("gettingstarted",
  params = list(q='*:*', group.field='compName_s'))
# OR
solr_group(cli, "gettingstarted",
  params = list(q='*:*', group.field='compName_s'))

# connect
(cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))

# Basic group query
solr_group(cli, params = list(q='ecology', group.field='journal',
  group.limit=3, fl=c('id','score')))
solr_group(cli, params = list(q='ecology', group.field='journal',
  group.limit=3, fl='article_type'))

# Different ways to sort (notice diff btw sort of group.sort)
# note that you can only sort on a field if you return that field
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
   fl=c('id','score')))
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
   fl=c('id','score','alm_twitterCount'), group.sort='alm_twitterCount desc'))
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
   fl=c('id','score','alm_twitterCount'), sort='score asc',
   group.sort='alm_twitterCount desc'))

# Two group.field values
out &lt;- solr_group(cli, params = list(q='ecology', group.field=c('journal','article_type'),
  group.limit=3, fl='id'), raw=TRUE)
solr_parse(out)
solr_parse(out, 'df')

# Get two groups, one with alm_twitterCount of 0-10, and another group
# with 10 to infinity
solr_group(cli, params = list(q='ecology', group.limit=3, fl=c('id','alm_twitterCount'),
 group.query=c('alm_twitterCount:[0 TO 10]','alm_twitterCount:[10 TO *]')))

# Use of group.format and group.simple.
## The raw data structure of these two calls are slightly different, but
## the parsing inside the function outputs the same results. You can
## of course set raw=TRUE to get back what the data actually look like
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
  fl=c('id','score'), group.format='simple'))
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
  fl=c('id','score'), group.format='grouped'))
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
  fl=c('id','score'), group.format='grouped', group.main='true'))

# xml back
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
  fl=c('id','score'), wt = "xml"))
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
  fl=c('id','score'), wt = "xml"), parsetype = "list")
res &lt;- solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
  fl=c('id','score'), wt = "xml"), raw = TRUE)
library("xml2")
xml2::read_xml(unclass(res))

solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
  fl='article_type', wt = "xml"))
solr_group(cli, params = list(q='ecology', group.field='journal', group.limit=3,
  fl='article_type', wt = "xml"), parsetype = "list")

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_highlight'>Highlighting search</h2><span id='topic+solr_highlight'></span>

<h3>Description</h3>

<p>Returns only highlight items
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_highlight(
  conn,
  name = NULL,
  params = NULL,
  body = NULL,
  callopts = list(),
  raw = FALSE,
  parsetype = "df",
  progress = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_highlight_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_highlight_+3A_name">name</code></td>
<td>
<p>Name of a collection or core. Or leave as <code>NULL</code> if not needed.</p>
</td></tr>
<tr><td><code id="solr_highlight_+3A_params">params</code></td>
<td>
<p>(list) a named list of parameters, results in a GET request
as long as no body parameters given</p>
</td></tr>
<tr><td><code id="solr_highlight_+3A_body">body</code></td>
<td>
<p>(list) a named list of parameters, if given a POST request
will be performed</p>
</td></tr>
<tr><td><code id="solr_highlight_+3A_callopts">callopts</code></td>
<td>
<p>Call options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="solr_highlight_+3A_raw">raw</code></td>
<td>
<p>(logical) If TRUE (default) raw json or xml returned. If FALSE,
parsed data returned.</p>
</td></tr>
<tr><td><code id="solr_highlight_+3A_parsetype">parsetype</code></td>
<td>
<p>One of list of df (data.frame)</p>
</td></tr>
<tr><td><code id="solr_highlight_+3A_progress">progress</code></td>
<td>
<p>a function with logic for printing a progress
bar for an HTTP request, ultimately passed down to <span class="pkg">curl</span>. only supports
<code>httr::progress</code> for now. See the README for an example.</p>
</td></tr>
<tr><td><code id="solr_highlight_+3A_...">...</code></td>
<td>
<p>Further args to be combined into query</p>
</td></tr>
</table>


<h3>Value</h3>

<p>XML, JSON, a list, or data.frame
</p>


<h3>Facet parameters</h3>


<ul>
<li><p> q Query terms. See examples.
</p>
</li>
<li><p> hl.fl A comma-separated list of fields for which to generate highlighted snippets.
If left blank, the fields highlighted for the LuceneQParser are the defaultSearchField
(or the df param if used) and for the DisMax parser the qf fields are used. A '<em>' can
be used to match field globs, e.g. 'text_</em>' or even '<em>' to highlight on all fields where
highlighting is possible. When using '</em>', consider adding hl.requireFieldMatch=TRUE.
</p>
</li>
<li><p> hl.snippets Max no. of highlighted snippets to generate per field. Note:
it is possible for any number of snippets from zero to this value to be generated.
This parameter accepts per-field overrides. Default: 1.
</p>
</li>
<li><p> hl.fragsize The size, in characters, of the snippets (aka fragments) created by
the highlighter. In the original Highlighter, &quot;0&quot; indicates that the whole field value
should be used with no fragmenting.
</p>
</li>
<li><p> hl.q Set a query request to be highlighted. It overrides q parameter for
highlighting. Solr query syntax is acceptable for this parameter.
</p>
</li>
<li><p> hl.mergeContiguous Collapse contiguous fragments into a single fragment. &quot;true&quot;
indicates contiguous fragments will be collapsed into single fragment. This parameter
accepts per-field overrides. This parameter makes sense for the original Highlighter
only. Default: FALSE.
</p>
</li>
<li><p> hl.requireFieldMatch If TRUE, then a field will only be highlighted if the
query matched in this particular field (normally, terms are highlighted in all
requested fields regardless of which field matched the query). This only takes effect
if &quot;hl.usePhraseHighlighter&quot; is TRUE. Default: FALSE.
</p>
</li>
<li><p> hl.maxAnalyzedChars How many characters into a document to look for suitable
snippets. This parameter makes sense for the original Highlighter only. Default: 51200.
You can assign a large value to this parameter and use hl.fragsize=0 to return
highlighting in large fields that have size greater than 51200 characters.
</p>
</li>
<li><p> hl.alternateField If a snippet cannot be generated (due to no terms matching),
you can specify a field to use as the fallback. This parameter accepts per-field overrides.
</p>
</li>
<li><p> hl.maxAlternateFieldLength If hl.alternateField is specified, this parameter
specifies the maximum number of characters of the field to return. Any value less than or
equal to 0 means unlimited. Default: unlimited.
</p>
</li>
<li><p> hl.preserveMulti Preserve order of values in a multiValued list. Default: FALSE.
</p>
</li>
<li><p> hl.maxMultiValuedToExamine When highlighting a multiValued field, stop examining
the individual entries after looking at this many of them. Will potentially return 0
snippets if this limit is reached before any snippets are found. If maxMultiValuedToMatch
is also specified, whichever limit is hit first will terminate looking for more.
Default: Integer.MAX_VALUE
</p>
</li>
<li><p> hl.maxMultiValuedToMatch When highlighting a multiValued field, stop examining
the individual entries after looking at this many matches are found. If
maxMultiValuedToExamine is also specified, whichever limit is hit first will terminate
looking for more. Default: Integer.MAX_VALUE
</p>
</li>
<li><p> hl.formatter Specify a formatter for the highlight output. Currently the only
legal value is &quot;simple&quot;, which surrounds a highlighted term with a customizable pre- and
post text snippet. This parameter accepts per-field overrides. This parameter makes
sense for the original Highlighter only.
</p>
</li>
<li><p> hl.simple.pre The text which appears before and after a highlighted term when using
the simple formatter. This parameter accepts per-field overrides. The default values are
<code>&lt;em&gt;</code> and <code>&lt;/em&gt;</code> This parameter makes sense for the original Highlighter only. Use
hl.tag.pre and hl.tag.post for FastVectorHighlighter (see example under hl.fragmentsBuilder)
</p>
</li>
<li><p> hl.simple.post The text which appears before and after a highlighted term when using
the simple formatter. This parameter accepts per-field overrides. The default values are
<code>&lt;em&gt;</code> and <code>&lt;/em&gt;</code> This parameter makes sense for the original Highlighter only. Use
hl.tag.pre and hl.tag.post for FastVectorHighlighter (see example under hl.fragmentsBuilder)
</p>
</li>
<li><p> hl.fragmenter Specify a text snippet generator for highlighted text. The standard
fragmenter is gap (which is so called because it creates fixed-sized fragments with gaps
for multi-valued fields). Another option is regex, which tries to create fragments that
&quot;look like&quot; a certain regular expression. This parameter accepts per-field overrides.
Default: &quot;gap&quot;
</p>
</li>
<li><p> hl.fragListBuilder Specify the name of SolrFragListBuilder.  This parameter
makes sense for FastVectorHighlighter only. To create a fragSize=0 with the
FastVectorHighlighter, use the SingleFragListBuilder. This field supports per-field
overrides.
</p>
</li>
<li><p> hl.fragmentsBuilder Specify the name of SolrFragmentsBuilder. This parameter makes
sense for FastVectorHighlighter only.
</p>
</li>
<li><p> hl.boundaryScanner Configures how the boundaries of fragments are determined. By
default, boundaries will split at the character level, creating a fragment such as &quot;uick
brown fox jumps over the la&quot;. Valid entries are breakIterator or simple, with breakIterator
being the most commonly used. This parameter makes sense for FastVectorHighlighter only.
</p>
</li>
<li><p> hl.bs.maxScan Specify the length of characters to be scanned by SimpleBoundaryScanner.
Default: 10.  This parameter makes sense for FastVectorHighlighter only.
</p>
</li>
<li><p> hl.bs.chars Specify the boundary characters, used by SimpleBoundaryScanner.
This parameter makes sense for FastVectorHighlighter only.
</p>
</li>
<li><p> hl.bs.type Specify one of CHARACTER, WORD, SENTENCE and LINE, used by
BreakIteratorBoundaryScanner. Default: WORD. This parameter makes sense for
FastVectorHighlighter only.
</p>
</li>
<li><p> hl.bs.language Specify the language for Locale that is used by
BreakIteratorBoundaryScanner. This parameter makes sense for FastVectorHighlighter only.
Valid entries take the form of ISO 639-1 strings.
</p>
</li>
<li><p> hl.bs.country Specify the country for Locale that is used by
BreakIteratorBoundaryScanner. This parameter makes sense for FastVectorHighlighter only.
Valid entries take the form of ISO 3166-1 alpha-2 strings.
</p>
</li>
<li><p> hl.useFastVectorHighlighter Use FastVectorHighlighter. FastVectorHighlighter
requires the field is termVectors=on, termPositions=on and termOffsets=on. This
parameter accepts per-field overrides. Default: FALSE
</p>
</li>
<li><p> hl.usePhraseHighlighter Use SpanScorer to highlight phrase terms only when
they appear within the query phrase in the document. Default: TRUE.
</p>
</li>
<li><p> hl.highlightMultiTerm If the SpanScorer is also being used, enables highlighting
for range/wildcard/fuzzy/prefix queries. Default: FALSE. This parameter makes sense
for the original Highlighter only.
</p>
</li>
<li><p> hl.regex.slop Factor by which the regex fragmenter can stray from the ideal
fragment size (given by hl.fragsize) to accomodate the regular expression. For
instance, a slop of 0.2 with fragsize of 100 should yield fragments between 80
and 120 characters in length. It is usually good to provide a slightly smaller
fragsize when using the regex fragmenter. Default: .6. This parameter makes sense
for the original Highlighter only.
</p>
</li>
<li><p> hl.regex.pattern The regular expression for fragmenting. This could be
used to extract sentences (see example solrconfig.xml) This parameter makes sense
for the original Highlighter only.
</p>
</li>
<li><p> hl.regex.maxAnalyzedChars Only analyze this many characters from a field
when using the regex fragmenter (after which, the fragmenter produces fixed-sized
fragments). Applying a complicated regex to a huge field is expensive.
Default: 10000. This parameter makes sense for the original Highlighter only.
</p>
</li>
<li><p> start Record to start at, default to beginning.
</p>
</li>
<li><p> rows Number of records to return.
</p>
</li>
<li><p> wt (character) Data type returned, defaults to 'json'. One of json or xml. If json,
uses <code><a href="jsonlite.html#topic+fromJSON">fromJSON</a></code> to parse. If xml, uses <code><a href="XML.html#topic+xmlParse">xmlParse</a></code> to
parse. csv is only supported in <code><a href="#topic+solr_search">solr_search</a></code> and <code><a href="#topic+solr_all">solr_all</a></code>.
</p>
</li>
<li><p> fl Fields to return
</p>
</li>
<li><p> fq Filter query, this does not affect the search, only what gets returned
</p>
</li></ul>



<h3>References</h3>

<p>See https://lucene.apache.org/solr/guide/8_2/highlighting.html
for more information on highlighting.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+solr_search">solr_search()</a></code>, <code><a href="#topic+solr_facet">solr_facet()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# connect
(conn &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))

# highlight search
solr_highlight(conn, params = list(q='alcohol', hl.fl = 'abstract', rows=10),
  parsetype = "list")
solr_highlight(conn, params = list(q='alcohol', hl.fl = c('abstract','title'),
  rows=3), parsetype = "list")

# Raw data back
## json
solr_highlight(conn, params = list(q='alcohol', hl.fl = 'abstract', rows=10),
   raw=TRUE)
## xml
solr_highlight(conn, params = list(q='alcohol', hl.fl = 'abstract', rows=10,
   wt='xml'), raw=TRUE)
## parse after getting data back
out &lt;- solr_highlight(conn, params = list(q='theoretical math',
   hl.fl = c('abstract','title'), hl.fragsize=30, rows=10, wt='xml'),
   raw=TRUE)
solr_parse(out, parsetype='list')

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_json_request'>Solr json request</h2><span id='topic+solr_json_request'></span>

<h3>Description</h3>

<p>search using the JSON request API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_json_request(
  conn,
  name = NULL,
  body = NULL,
  callopts = list(),
  progress = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_json_request_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_json_request_+3A_name">name</code></td>
<td>
<p>Name of a collection or core. Or leave as <code>NULL</code> if not needed.</p>
</td></tr>
<tr><td><code id="solr_json_request_+3A_body">body</code></td>
<td>
<p>(list) a named list, or a valid JSON character string</p>
</td></tr>
<tr><td><code id="solr_json_request_+3A_callopts">callopts</code></td>
<td>
<p>Call options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="solr_json_request_+3A_progress">progress</code></td>
<td>
<p>a function with logic for printing a progress
bar for an HTTP request, ultimately passed down to <span class="pkg">curl</span>.
only supports <code>httr::progress</code> for now. See the README for an example.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>JSON character string
</p>


<h3>Note</h3>

<p>SOLR v7.1 was first version to support this. See
<a href="https://issues.apache.org/jira/browse/SOLR-11244">https://issues.apache.org/jira/browse/SOLR-11244</a>
</p>
<p>POST request only, no GET request available
</p>


<h3>References</h3>

<p>See https://lucene.apache.org/solr/guide/7_6/json-request-api.html
for more information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Connect to a local Solr instance
(conn &lt;- SolrClient$new())

## body as JSON 
a &lt;- conn$json_request("gettingstarted", body = '{"query":"*:*"}')
jsonlite::fromJSON(a)
## body as named list
b &lt;- conn$json_request("gettingstarted", body = list(query = "*:*"))
jsonlite::fromJSON(b)

## body as JSON 
a &lt;- solr_json_request(conn, "gettingstarted", body = '{"query":"*:*"}')
jsonlite::fromJSON(a)
## body as named list
b &lt;- solr_json_request(conn, "gettingstarted", body = list(query = "*:*"))
jsonlite::fromJSON(b)

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_mlt'>&quot;more like this&quot; search</h2><span id='topic+solr_mlt'></span>

<h3>Description</h3>

<p>Returns only more like this items
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_mlt(
  conn,
  name = NULL,
  params = NULL,
  body = NULL,
  callopts = list(),
  raw = FALSE,
  parsetype = "df",
  concat = ",",
  optimizeMaxRows = TRUE,
  minOptimizedRows = 50000L,
  progress = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_mlt_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_name">name</code></td>
<td>
<p>Name of a collection or core. Or leave as <code>NULL</code> if not needed.</p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_params">params</code></td>
<td>
<p>(list) a named list of parameters, results in a GET request
as long as no body parameters given</p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_body">body</code></td>
<td>
<p>(list) a named list of parameters, if given a POST request
will be performed</p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_callopts">callopts</code></td>
<td>
<p>Call options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_raw">raw</code></td>
<td>
<p>(logical) If TRUE, returns raw data in format specified by wt param</p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_parsetype">parsetype</code></td>
<td>
<p>(character) One of 'list' or 'df'</p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_concat">concat</code></td>
<td>
<p>(character) Character to concatenate elements of longer than length 1.
Note that this only works reliably when data format is json (wt='json'). The parsing
is more complicated in XML format, but you can do that on your own.</p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_optimizemaxrows">optimizeMaxRows</code></td>
<td>
<p>(logical) If <code>TRUE</code>, then rows parameter will be
adjusted to the number of returned results by the same constraints.
It will only be applied if rows parameter is higher
than <code>minOptimizedRows</code>. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_minoptimizedrows">minOptimizedRows</code></td>
<td>
<p>(numeric) used by <code>optimizedMaxRows</code> parameter,
the minimum optimized rows. Default: 50000</p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_progress">progress</code></td>
<td>
<p>a function with logic for printing a progress
bar for an HTTP request, ultimately passed down to <span class="pkg">curl</span>. only supports
<code>httr::progress</code> for now. See the README for an example.</p>
</td></tr>
<tr><td><code id="solr_mlt_+3A_...">...</code></td>
<td>
<p>Further args to be combined into query</p>
</td></tr>
</table>


<h3>Value</h3>

<p>XML, JSON, a list, or data.frame
</p>


<h3>More like this parameters</h3>


<ul>
<li><p> q Query terms, defaults to '<em>:</em>', or everything.
</p>
</li>
<li><p> fq Filter query, this does not affect the search, only what gets returned
</p>
</li>
<li><p> mlt.count The number of similar documents to return for each result. Default is 5.
</p>
</li>
<li><p> mlt.fl The fields to use for similarity. NOTE: if possible these should have a stored
TermVector DEFAULT_FIELD_NAMES = new String[] &quot;contents&quot;
</p>
</li>
<li><p> mlt.mintf Minimum Term Frequency - the frequency below which terms will be ignored in
the source doc. DEFAULT_MIN_TERM_FREQ = 2
</p>
</li>
<li><p> mlt.mindf Minimum Document Frequency - the frequency at which words will be ignored which
do not occur in at least this many docs. DEFAULT_MIN_DOC_FREQ = 5
</p>
</li>
<li><p> mlt.minwl minimum word length below which words will be ignored.
DEFAULT_MIN_WORD_LENGTH = 0
</p>
</li>
<li><p> mlt.maxwl maximum word length above which words will be ignored.
DEFAULT_MAX_WORD_LENGTH = 0
</p>
</li>
<li><p> mlt.maxqt maximum number of query terms that will be included in any generated query.
DEFAULT_MAX_QUERY_TERMS = 25
</p>
</li>
<li><p> mlt.maxntp maximum number of tokens to parse in each example doc field that is not stored
with TermVector support. DEFAULT_MAX_NUM_TOKENS_PARSED = 5000
</p>
</li>
<li><p> mlt.boost (true/false) set if the query will be boosted by the interesting term relevance.
DEFAULT_BOOST = false
</p>
</li>
<li><p> mlt.qf Query fields and their boosts using the same format as that used in
DisMaxQParserPlugin. These fields must also be specified in mlt.fl.
</p>
</li>
<li><p> fl Fields to return. We force 'id' to be returned so that there is a unique identifier
with each record.
</p>
</li>
<li><p> wt (character) Data type returned, defaults to 'json'. One of json or xml. If json,
uses <code><a href="jsonlite.html#topic+fromJSON">fromJSON</a></code> to parse. If xml, uses <code><a href="XML.html#topic+xmlParse">xmlParse</a></code> to
parse. csv is only supported in <code><a href="#topic+solr_search">solr_search</a></code> and <code><a href="#topic+solr_all">solr_all</a></code>.
</p>
</li>
<li><p> start Record to start at, default to beginning.
</p>
</li>
<li><p> rows Number of records to return. Defaults to 10.
</p>
</li>
<li><p> key API key, if needed.
</p>
</li></ul>



<h3>References</h3>

<p>See https://lucene.apache.org/solr/guide/8_2/morelikethis.html
for more information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# connect
(conn &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))

# more like this search
conn$mlt(params = list(q='*:*', mlt.count=2, mlt.fl='abstract', fl='score',
  fq="doc_type:full"))
conn$mlt(params = list(q='*:*', rows=2, mlt.fl='title', mlt.mindf=1,
  mlt.mintf=1, fl='alm_twitterCount'))
conn$mlt(params = list(q='title:"ecology" AND body:"cell"', mlt.fl='title',
  mlt.mindf=1, mlt.mintf=1, fl='counter_total_all', rows=5))
conn$mlt(params = list(q='ecology', mlt.fl='abstract', fl='title', rows=5))
solr_mlt(conn, params = list(q='ecology', mlt.fl='abstract',
  fl=c('score','eissn'), rows=5))
solr_mlt(conn, params = list(q='ecology', mlt.fl='abstract',
  fl=c('score','eissn'), rows=5, wt = "xml"))

# get raw data, and parse later if needed
out &lt;- solr_mlt(conn, params=list(q='ecology', mlt.fl='abstract', fl='title',
 rows=2), raw=TRUE)
solr_parse(out, "df")

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_optimize'>Optimize</h2><span id='topic+solr_optimize'></span>

<h3>Description</h3>

<p>Optimize
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_optimize(
  conn,
  name,
  max_segments = 1,
  wait_searcher = TRUE,
  soft_commit = FALSE,
  wt = "json",
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_optimize_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_optimize_+3A_name">name</code></td>
<td>
<p>(character) A collection or core name. Required.</p>
</td></tr>
<tr><td><code id="solr_optimize_+3A_max_segments">max_segments</code></td>
<td>
<p>optimizes down to at most this number of segments.
Default: 1</p>
</td></tr>
<tr><td><code id="solr_optimize_+3A_wait_searcher">wait_searcher</code></td>
<td>
<p>block until a new searcher is opened and registered
as the main query searcher, making the changes visible. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="solr_optimize_+3A_soft_commit">soft_commit</code></td>
<td>
<p>perform a soft commit - this will refresh the 'view'
of the index in a more performant manner, but without &quot;on-disk&quot; guarantees.
Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="solr_optimize_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to
parse</p>
</td></tr>
<tr><td><code id="solr_optimize_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="solr_optimize_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
(conn &lt;- SolrClient$new())

solr_optimize(conn, "gettingstarted")
solr_optimize(conn, "gettingstarted", max_segments = 2)
solr_optimize(conn, "gettingstarted", wait_searcher = FALSE)

# get xml back
solr_optimize(conn, "gettingstarted", wt = "xml")
## raw xml
solr_optimize(conn, "gettingstarted", wt = "xml", raw = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_parse'>Parse raw data from solr_search, solr_facet, or solr_highlight.</h2><span id='topic+solr_parse'></span><span id='topic+solr_parse.sr_high'></span><span id='topic+solr_parse.sr_search'></span><span id='topic+solr_parse.sr_all'></span><span id='topic+solr_parse.sr_mlt'></span><span id='topic+solr_parse.sr_stats'></span><span id='topic+solr_parse.sr_group'></span>

<h3>Description</h3>

<p>Parse raw data from solr_search, solr_facet, or solr_highlight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_parse(input, parsetype = NULL, concat)

## S3 method for class 'sr_high'
solr_parse(input, parsetype = "list", concat = ",")

## S3 method for class 'sr_search'
solr_parse(input, parsetype = "list", concat = ",")

## S3 method for class 'sr_all'
solr_parse(input, parsetype = "list", concat = ",")

## S3 method for class 'sr_mlt'
solr_parse(input, parsetype = "list", concat = ",")

## S3 method for class 'sr_stats'
solr_parse(input, parsetype = "list", concat = ",")

## S3 method for class 'sr_group'
solr_parse(input, parsetype = "list", concat = ",")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_parse_+3A_input">input</code></td>
<td>
<p>Output from solr_facet</p>
</td></tr>
<tr><td><code id="solr_parse_+3A_parsetype">parsetype</code></td>
<td>
<p>One of 'list' or 'df' (data.frame)</p>
</td></tr>
<tr><td><code id="solr_parse_+3A_concat">concat</code></td>
<td>
<p>Character to conactenate strings by, e.g,. ',' (character).
Used in solr_parse.sr_search only.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the parser used internally in solr_facet, but if you
output raw data from solr_facet using raw=TRUE, then you can use this
function to parse that data (a sr_facet S3 object) after the fact to a
list of data.frame's for easier consumption. The data format type is
detected from the attribute &quot;wt&quot; on the sr_facet object.
</p>

<hr>
<h2 id='solr_search'>Solr search</h2><span id='topic+solr_search'></span>

<h3>Description</h3>

<p>Returns only matched documents, and doesn't return other items,
including facets, groups, mlt, stats, and highlights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_search(
  conn,
  name = NULL,
  params = list(q = "*:*"),
  body = NULL,
  callopts = list(),
  raw = FALSE,
  parsetype = "df",
  concat = ",",
  optimizeMaxRows = TRUE,
  minOptimizedRows = 50000L,
  progress = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_search_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_search_+3A_name">name</code></td>
<td>
<p>Name of a collection or core. Or leave as <code>NULL</code> if not needed.</p>
</td></tr>
<tr><td><code id="solr_search_+3A_params">params</code></td>
<td>
<p>(list) a named list of parameters, results in a GET request
as long as no body parameters given</p>
</td></tr>
<tr><td><code id="solr_search_+3A_body">body</code></td>
<td>
<p>(list) a named list of parameters, if given a POST request
will be performed</p>
</td></tr>
<tr><td><code id="solr_search_+3A_callopts">callopts</code></td>
<td>
<p>Call options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="solr_search_+3A_raw">raw</code></td>
<td>
<p>(logical) If TRUE, returns raw data in format specified by wt param</p>
</td></tr>
<tr><td><code id="solr_search_+3A_parsetype">parsetype</code></td>
<td>
<p>(character) One of 'list' or 'df'</p>
</td></tr>
<tr><td><code id="solr_search_+3A_concat">concat</code></td>
<td>
<p>(character) Character to concatenate elements of longer than length 1.
Note that this only works reliably when data format is json (wt='json'). The parsing
is more complicated in XML format, but you can do that on your own.</p>
</td></tr>
<tr><td><code id="solr_search_+3A_optimizemaxrows">optimizeMaxRows</code></td>
<td>
<p>(logical) If <code>TRUE</code>, then rows parameter will be
adjusted to the number of returned results by the same constraints.
It will only be applied if rows parameter is higher
than <code>minOptimizedRows</code>. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="solr_search_+3A_minoptimizedrows">minOptimizedRows</code></td>
<td>
<p>(numeric) used by <code>optimizedMaxRows</code> parameter,
the minimum optimized rows. Default: 50000</p>
</td></tr>
<tr><td><code id="solr_search_+3A_progress">progress</code></td>
<td>
<p>a function with logic for printing a progress
bar for an HTTP request, ultimately passed down to <span class="pkg">curl</span>. only supports
<code>httr::progress</code> for now. See the README for an example.</p>
</td></tr>
<tr><td><code id="solr_search_+3A_...">...</code></td>
<td>
<p>Further args to be combined into query</p>
</td></tr>
</table>


<h3>Value</h3>

<p>XML, JSON, a list, or data.frame
</p>


<h3>Parameters</h3>


<ul>
<li><p> q Query terms, defaults to '<em>:</em>', or everything.
</p>
</li>
<li><p> sort Field to sort on. You can specify ascending (e.g., score desc) or
descending (e.g., score asc), sort by two fields (e.g., score desc, price asc),
or sort by a function (e.g., sum(x_f, y_f) desc, which sorts by the sum of
x_f and y_f in a descending order).
</p>
</li>
<li><p> start Record to start at, default to beginning.
</p>
</li>
<li><p> rows Number of records to return. Default: 10.
</p>
</li>
<li><p> pageDoc If you expect to be paging deeply into the results (say beyond page 10,
assuming rows=10) and you are sorting by score, you may wish to add the pageDoc
and pageScore parameters to your request. These two parameters tell Solr (and Lucene)
what the last result (Lucene internal docid and score) of the previous page was,
so that when scoring the query for the next set of pages, it can ignore any results
that occur higher than that item. To get the Lucene internal doc id, you will need
to add <code>docid</code> to the &amp;fl list.
</p>
</li>
<li><p> pageScore See pageDoc notes.
</p>
</li>
<li><p> fq Filter query, this does not affect the search, only what gets returned.
This parameter can accept multiple items in a lis or vector. You can't pass more than
one parameter of the same name, so we get around it by passing multiple queries
and we parse internally
</p>
</li>
<li><p> fl Fields to return, can be a character vector like <code>c('id', 'title')</code>,
or a single character vector with one or more comma separated names, like
<code>'id,title'</code>
</p>
</li>
<li><p> defType Specify the query parser to use with this request.
</p>
</li>
<li><p> timeAllowed The time allowed for a search to finish. This value only applies
to the search and not to requests in general. Time is in milliseconds. Values <code>&lt;= 0</code>
mean no time restriction. Partial results may be returned (if there are any).
</p>
</li>
<li><p> qt Which query handler used. Options: dismax, others?
</p>
</li>
<li><p> NOW Set a fixed time for evaluating Date based expresions
</p>
</li>
<li><p> TZ Time zone, you can override the default.
</p>
</li>
<li><p> echoHandler If <code>TRUE</code>, Solr places the name of the handle used in the
response to the client for debugging purposes. Default:
</p>
</li>
<li><p> echoParams The echoParams parameter tells Solr what kinds of Request
parameters should be included in the response for debugging purposes, legal values
include:
</p>

<ul>
<li><p> none - don't include any request parameters for debugging
</p>
</li>
<li><p> explicit - include the parameters explicitly specified by the client in the request
</p>
</li>
<li><p> all - include all parameters involved in this request, either specified explicitly
by the client, or implicit because of the request handler configuration.
</p>
</li></ul>

</li>
<li><p> wt (character) One of json, xml, or csv. Data type returned, defaults
to 'csv'. If json, uses <code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml,
uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to parse. If csv, uses <code><a href="utils.html#topic+read.table">read.table()</a></code> to parse.
<code>wt=csv</code> gives the fastest performance at least in all the cases we have
tested in, thus it's the default value for <code>wt</code>
</p>
</li></ul>



<h3>number of results</h3>

<p>Because <code>solr_search()</code> returns a data.frame, metadata doesn't fit into the
output data.frame itself. You can access number of results (<code>numFound</code>) in
the attributes of the results. For example, <code>attr(x, "numFound")</code> for
number of results, and <code>attr(x, "start")</code> for the offset value (if one
was given). Or you can get all attributes like <code>attributes(x)</code>. These
metadata are not in the attributes when <code>raw=TRUE</code> as those metadata
are in the payload (unless <code>wt="csv"</code>).
</p>


<h3>Note</h3>

<p>SOLR v1.2 was first version to support csv. See
https://issues.apache.org/jira/browse/SOLR-66
</p>


<h3>References</h3>

<p>See https://lucene.apache.org/solr/guide/8_2/searching.html
for more information.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+solr_highlight">solr_highlight()</a></code>, <code><a href="#topic+solr_facet">solr_facet()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Connect to a local Solr instance
(cli &lt;- SolrClient$new())
cli$search("gettingstarted", params = list(q = "features:notes"))

solr_search(cli, "gettingstarted")
solr_search(cli, "gettingstarted", params = list(q = "features:notes"))
solr_search(cli, "gettingstarted", body = list(query = "features:notes"))

(cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))
cli$search(params = list(q = "*:*"))
cli$search(params = list(q = "title:golgi", fl = c('id', 'title')))

cli$search(params = list(q = "*:*", facet = "true"))


# search
solr_search(cli, params = list(q='*:*', rows=2, fl='id'))

# search and return all rows
solr_search(cli, params = list(q='*:*', rows=-1, fl='id'))

# Search for word ecology in title and cell in the body
solr_search(cli, params = list(q='title:"ecology" AND body:"cell"',
  fl='title', rows=5))

# Search for word "cell" and not "body" in the title field
solr_search(cli, params = list(q='title:"cell" -title:"lines"', fl='title',
  rows=5))

# Wildcards
## Search for word that starts with "cell" in the title field
solr_search(cli, params = list(q='title:"cell*"', fl='title', rows=5))

# Proximity searching
## Search for words "sports" and "alcohol" within four words of each other
solr_search(cli, params = list(q='everything:"sports alcohol"~7',
  fl='abstract', rows=3))

# Range searches
## Search for articles with Twitter count between 5 and 10
solr_search(cli, params = list(q='*:*', fl=c('alm_twitterCount','id'),
  fq='alm_twitterCount:[5 TO 50]', rows=10))

# Boosts
## Assign higher boost to title matches than to body matches
## (compare the two calls)
solr_search(cli, params = list(q='title:"cell" abstract:"science"',
  fl='title', rows=3))
solr_search(cli, params = list(q='title:"cell"^1.5 AND abstract:"science"',
  fl='title', rows=3))

# FunctionQuery queries
## This kind of query allows you to use the actual values of fields to
## calculate relevancy scores for returned documents

## Here, we search on the product of counter_total_all and alm_twitterCount
## metrics for articles in PLOS Journals
solr_search(cli, params = list(q="{!func}product($v1,$v2)",
  v1 = 'sqrt(counter_total_all)',
  v2 = 'log(alm_twitterCount)', rows=5, fl=c('id','title'),
  fq='doc_type:full'))

## here, search on the product of counter_total_all and alm_twitterCount,
## using a new temporary field "_val_"
solr_search(cli,
  params = list(q='_val_:"product(counter_total_all,alm_twitterCount)"',
  rows=5, fl=c('id','title'), fq='doc_type:full'))

## papers with most citations
solr_search(cli, params = list(q='_val_:"max(counter_total_all)"',
   rows=5, fl=c('id','counter_total_all'), fq='doc_type:full'))

## papers with most tweets
solr_search(cli, params = list(q='_val_:"max(alm_twitterCount)"',
   rows=5, fl=c('id','alm_twitterCount'), fq='doc_type:full'))

## many fq values
solr_search(cli, params = list(q="*:*", fl=c('id','alm_twitterCount'),
   fq=list('doc_type:full','subject:"Social networks"',
           'alm_twitterCount:[100 TO 10000]'),
   sort='counter_total_month desc'))

## using wt = csv
solr_search(cli, params = list(q='*:*', rows=50, fl=c('id','score'),
  fq='doc_type:full', wt="csv"))
solr_search(cli, params = list(q='*:*', rows=50, fl=c('id','score'),
  fq='doc_type:full'))

# using a proxy
# cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL,
#   proxy = list(url = "http://186.249.1.146:80"))
# solr_search(cli, q='*:*', rows=2, fl='id', callopts=list(verbose=TRUE))

# Pass on curl options to modify request
## verbose
solr_search(cli, params = list(q='*:*', rows=2, fl='id'),
  callopts = list(verbose=TRUE))

# using a cursor for deep paging
(cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))
## json, raw data
res &lt;- solr_search(cli, params = list(q = '*:*', rows = 100, sort = "id asc", cursorMark = "*"), 
  parsetype = "json", raw = TRUE, callopts=list(verbose=TRUE))
res
## data.frame
res &lt;- solr_search(cli, params = list(q = '*:*', rows = 100, sort = "id asc", cursorMark = "*"))
res
attributes(res)
attr(res, "nextCursorMark")
## list
res &lt;- solr_search(cli, params = list(q = '*:*', rows = 100, sort = "id asc", cursorMark = "*"),
  parsetype = "list")
res
attributes(res)
attr(res, "nextCursorMark")

## End(Not run)
</code></pre>

<hr>
<h2 id='solr_stats'>Solr stats</h2><span id='topic+solr_stats'></span>

<h3>Description</h3>

<p>Returns only stat items
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solr_stats(
  conn,
  name = NULL,
  params = list(q = "*:*", stats.field = NULL, stats.facet = NULL),
  body = NULL,
  callopts = list(),
  raw = FALSE,
  parsetype = "df",
  progress = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="solr_stats_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="solr_stats_+3A_name">name</code></td>
<td>
<p>Name of a collection or core. Or leave as <code>NULL</code> if
not needed.</p>
</td></tr>
<tr><td><code id="solr_stats_+3A_params">params</code></td>
<td>
<p>(list) a named list of parameters, results in a GET request
as long as no body parameters given</p>
</td></tr>
<tr><td><code id="solr_stats_+3A_body">body</code></td>
<td>
<p>(list) a named list of parameters, if given a POST request
will be performed</p>
</td></tr>
<tr><td><code id="solr_stats_+3A_callopts">callopts</code></td>
<td>
<p>Call options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
<tr><td><code id="solr_stats_+3A_raw">raw</code></td>
<td>
<p>(logical) If TRUE, returns raw data in format specified by
wt param</p>
</td></tr>
<tr><td><code id="solr_stats_+3A_parsetype">parsetype</code></td>
<td>
<p>(character) One of 'list' or 'df'</p>
</td></tr>
<tr><td><code id="solr_stats_+3A_progress">progress</code></td>
<td>
<p>a function with logic for printing a progress
bar for an HTTP request, ultimately passed down to <span class="pkg">curl</span>. only supports
<code>httr::progress</code> for now. See the README for an example.</p>
</td></tr>
<tr><td><code id="solr_stats_+3A_...">...</code></td>
<td>
<p>Further args to be combined into query</p>
</td></tr>
</table>


<h3>Value</h3>

<p>XML, JSON, a list, or data.frame
</p>


<h3>Stats parameters</h3>


<ul>
<li><p> q Query terms, defaults to '<em>:</em>', or everything.
</p>
</li>
<li><p> stats.field The number of similar documents to return for each result.
</p>
</li>
<li><p> stats.facet You can not facet on multi-valued fields.
</p>
</li>
<li><p> wt (character) Data type returned, defaults to 'json'. One of json
or xml. If json, uses <code><a href="jsonlite.html#topic+fromJSON">fromJSON</a></code> to parse. If xml,
uses <code><a href="XML.html#topic+xmlParse">xmlParse</a></code> to parse. csv is only supported in
<code><a href="#topic+solr_search">solr_search</a></code> and <code><a href="#topic+solr_all">solr_all</a></code>.
</p>
</li>
<li><p> start Record to start at, default to beginning.
</p>
</li>
<li><p> rows Number of records to return. Defaults to 10.
</p>
</li>
<li><p> key API key, if needed.
</p>
</li></ul>



<h3>References</h3>

<p>See
https://lucene.apache.org/solr/guide/8_2/the-stats-component.html for
more information on Solr stats.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+solr_highlight">solr_highlight()</a></code>, <code><a href="#topic+solr_facet">solr_facet()</a></code>, <code><a href="#topic+solr_search">solr_search()</a></code>, <code><a href="#topic+solr_mlt">solr_mlt()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# connect
(cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))

# get stats
solr_stats(cli, params = list(q='science', stats.field='counter_total_all'),
  raw=TRUE)
solr_stats(cli, params = list(q='title:"ecology" AND body:"cell"',
   stats.field=c('counter_total_all','alm_twitterCount')))
solr_stats(cli, params = list(q='ecology',
  stats.field=c('counter_total_all','alm_twitterCount'),
  stats.facet='journal'))
solr_stats(cli, params = list(q='ecology',
  stats.field=c('counter_total_all','alm_twitterCount'),
  stats.facet=c('journal','volume')))

# Get raw data, then parse later if you feel like it
## json
out &lt;- solr_stats(cli, params = list(q='ecology',
  stats.field=c('counter_total_all','alm_twitterCount'),
  stats.facet=c('journal','volume')), raw=TRUE)
library("jsonlite")
jsonlite::fromJSON(out)
solr_parse(out) # list
solr_parse(out, 'df') # data.frame

## xml
out &lt;- solr_stats(cli, params = list(q='ecology',
  stats.field=c('counter_total_all','alm_twitterCount'),
  stats.facet=c('journal','volume'), wt="xml"), raw=TRUE)
library("xml2")
xml2::read_xml(unclass(out))
solr_parse(out) # list
solr_parse(out, 'df') # data.frame

# Get verbose http call information
solr_stats(cli, params = list(q='ecology', stats.field='alm_twitterCount'),
   callopts=list(verbose=TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='SolrClient'>Solr connection client</h2><span id='topic+SolrClient'></span>

<h3>Description</h3>

<p>Solr connection client
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SolrClient_+3A_host">host</code></td>
<td>
<p>(character) Host url. Deafault: 127.0.0.1</p>
</td></tr>
<tr><td><code id="SolrClient_+3A_path">path</code></td>
<td>
<p>(character) url path.</p>
</td></tr>
<tr><td><code id="SolrClient_+3A_port">port</code></td>
<td>
<p>(character/numeric) Port. Default: 8389</p>
</td></tr>
<tr><td><code id="SolrClient_+3A_scheme">scheme</code></td>
<td>
<p>(character) http scheme, one of http or https. Default: http</p>
</td></tr>
<tr><td><code id="SolrClient_+3A_proxy">proxy</code></td>
<td>
<p>List of arguments for a proxy connection, including one or
more of: url, port, username, password, and auth. See
<a href="crul.html#topic+proxies">crul::proxy</a> for  help, which is used to construct the
proxy connection.</p>
</td></tr>
<tr><td><code id="SolrClient_+3A_errors">errors</code></td>
<td>
<p>(character) One of <code>"simple"</code> or <code>"complete"</code>. Simple gives
http code and  error message on an error, while complete gives both http
code and error message, and stack trace, if available.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SolrClient</code> creates a R6 class object. The object is
not cloneable and is portable, so it can be inherited across packages
without complication.
</p>
<p><code>SolrClient</code> is used to initialize a client that knows about your
Solr instance, with options for setting host, port, http scheme,
and simple vs. complete error reporting
</p>


<h3>Value</h3>

<p>Various output, see help files for each grouping of methods.
</p>


<h3>SolrClient methods</h3>

<p>Each of these methods also has a matching standalone exported
function that you can use by passing in the connection object made
by calling <code>SolrClient$new()</code>. Also, see the docs for each method for
parameter definitions and their default values.
</p>

<ul>
<li> <p><code>ping(name, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>schema(name, what = '', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>commit(name, expunge_deletes = FALSE, wait_searcher = TRUE, soft_commit = FALSE, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>optimize(name, max_segments = 1, wait_searcher = TRUE, soft_commit = FALSE, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>config_get(name, what = NULL, wt = "json", raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>config_params(name, param = NULL, set = NULL, unset = NULL, update = NULL, ...)</code>
</p>
</li>
<li> <p><code>config_overlay(name, omitHeader = FALSE, ...)</code>
</p>
</li>
<li> <p><code>config_set(name, set = NULL, unset = NULL, ...)</code>
</p>
</li>
<li> <p><code>collection_exists(name, ...)</code>
</p>
</li>
<li> <p><code>collection_list(raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_create(name, numShards = 1, maxShardsPerNode = 1, createNodeSet = NULL, collection.configName = NULL, replicationFactor = 1, router.name = NULL, shards = NULL, createNodeSet.shuffle = TRUE, router.field = NULL, autoAddReplicas = FALSE, async = NULL, raw = FALSE, callopts=list(), ...)</code>
</p>
</li>
<li> <p><code>collection_addreplica(name, shard = NULL, route = NULL, node = NULL, instanceDir = NULL, dataDir = NULL, async = NULL, raw = FALSE, callopts=list(), ...)</code>
</p>
</li>
<li> <p><code>collection_addreplicaprop(name, shard, replica, property, property.value, shardUnique = FALSE, raw = FALSE, callopts=list())</code>
</p>
</li>
<li> <p><code>collection_addrole(role = "overseer", node, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_balanceshardunique(name, property, onlyactivenodes = TRUE, shardUnique = NULL, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_clusterprop(name, val, raw = FALSE, callopts=list())</code>
</p>
</li>
<li> <p><code>collection_clusterstatus(name = NULL, shard = NULL, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_createalias(alias, collections, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_createshard(name, shard, createNodeSet = NULL, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_delete(name, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_deletealias(alias, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_deletereplica(name, shard = NULL, replica = NULL, onlyIfDown = FALSE, raw = FALSE, callopts=list(), ...)</code>
</p>
</li>
<li> <p><code>collection_deletereplicaprop(name, shard, replica, property, raw = FALSE, callopts=list())</code>
</p>
</li>
<li> <p><code>collection_deleteshard(name, shard, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_migrate(name, target.collection, split.key, forward.timeout = NULL, async = NULL, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_overseerstatus(raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_rebalanceleaders(name, maxAtOnce = NULL, maxWaitSeconds = NULL, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_reload(name, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_removerole(role = "overseer", node, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_requeststatus(requestid, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>collection_splitshard(name, shard, ranges = NULL, split.key = NULL, async = NULL, raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>core_status(name = NULL, indexInfo = TRUE, raw = FALSE, callopts=list())</code>
</p>
</li>
<li> <p><code>core_exists(name, callopts = list())</code>
</p>
</li>
<li> <p><code>core_create(name, instanceDir = NULL, config = NULL, schema = NULL, dataDir = NULL, configSet = NULL, collection = NULL, shard = NULL, async=NULL, raw = FALSE, callopts=list(), ...)</code>
</p>
</li>
<li> <p><code>core_unload(name, deleteIndex = FALSE, deleteDataDir = FALSE, deleteInstanceDir = FALSE, async = NULL, raw = FALSE, callopts = list())</code>
</p>
</li>
<li> <p><code>core_rename(name, other, async = NULL, raw = FALSE, callopts=list())</code>
</p>
</li>
<li> <p><code>core_reload(name, raw = FALSE, callopts=list())</code>
</p>
</li>
<li> <p><code>core_swap(name, other, async = NULL, raw = FALSE, callopts=list())</code>
</p>
</li>
<li> <p><code>core_mergeindexes(name, indexDir = NULL, srcCore = NULL, async = NULL, raw = FALSE, callopts = list())</code>
</p>
</li>
<li> <p><code>core_requeststatus(requestid, raw = FALSE, callopts = list())</code>
</p>
</li>
<li> <p><code>core_split(name, path = NULL, targetCore = NULL, ranges = NULL, split.key = NULL, async = NULL, raw = FALSE, callopts=list())</code>
</p>
</li>
<li> <p><code>search(name = NULL, params = NULL, body = NULL, callopts = list(), raw = FALSE,  parsetype = 'df', concat = ',', optimizeMaxRows = TRUE, minOptimizedRows = 50000L, progress = NULL, ...)</code>
</p>
</li>
<li> <p><code>facet(name = NULL, params = NULL, body = NULL, callopts = list(), raw = FALSE,  parsetype = 'df', concat = ',', progress = NULL, ...)</code>
</p>
</li>
<li> <p><code>stats(name = NULL, params = list(q = '*:*', stats.field = NULL, stats.facet = NULL), body = NULL, callopts=list(), raw = FALSE, parsetype = 'df', progress = NULL, ...)</code>
</p>
</li>
<li> <p><code>highlight(name = NULL, params = NULL, body = NULL, callopts=list(), raw = FALSE, parsetype = 'df', progress = NULL, ...)</code>
</p>
</li>
<li> <p><code>group(name = NULL, params = NULL, body = NULL, callopts=list(), raw=FALSE, parsetype='df', concat=',', progress = NULL, ...)</code>
</p>
</li>
<li> <p><code>mlt(name = NULL, params = NULL, body = NULL, callopts=list(), raw=FALSE, parsetype='df', concat=',', optimizeMaxRows = TRUE, minOptimizedRows = 50000L, progress = NULL, ...)</code>
</p>
</li>
<li> <p><code>all(name = NULL, params = NULL, body = NULL, callopts=list(), raw=FALSE, parsetype='df', concat=',', optimizeMaxRows = TRUE, minOptimizedRows = 50000L, progress = NULL, ...)</code>
</p>
</li>
<li> <p><code>json_request(name = NULL, body = NULL, callopts=list(),  progress = NULL)</code>
</p>
</li>
<li> <p><code>get(ids, name, fl = NULL, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>add(x, name, commit = TRUE, commit_within = NULL, overwrite = TRUE, boost = NULL, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>delete_by_id(ids, name, commit = TRUE, commit_within = NULL, overwrite = TRUE, boost = NULL, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>delete_by_query(query, name, commit = TRUE, commit_within = NULL, overwrite = TRUE, boost = NULL, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>update_json(files, name, commit = TRUE, optimize = FALSE, max_segments = 1, expunge_deletes = FALSE, wait_searcher = TRUE, soft_commit = FALSE, prepare_commit = NULL, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>update_xml(files, name, commit = TRUE, optimize = FALSE, max_segments = 1, expunge_deletes = FALSE, wait_searcher = TRUE, soft_commit = FALSE, prepare_commit = NULL, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>update_csv(files, name, separator = ',', header = TRUE, fieldnames = NULL, skip = NULL, skipLines = 0, trim = FALSE, encapsulator = NULL, escape = NULL, keepEmpty = FALSE, literal = NULL, map = NULL, split = NULL, rowid = NULL, rowidOffset = NULL, overwrite = NULL, commit = NULL, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>update_atomic_json(body, name, wt = 'json', raw = FALSE, ...)</code>
</p>
</li>
<li> <p><code>update_atomic_xml(body, name, wt = 'json', raw = FALSE, ...)</code>
</p>
</li></ul>



<h3>number of results</h3>

<p>When the <code style="white-space: pre;">&#8288;$search()&#8288;</code> method returns a data.frame, metadata doesn't fit
into the output data.frame itself. You can access number of results
(<code>numFound</code>) in the attributes of the results. For example,
<code>attr(x, "numFound")</code> for number of results, and <code>attr(x, "start")</code>
for the offset value (if one was given). Or you can get all
attributes like <code>attributes(x)</code>. These metadata are not in the
attributes when requesting raw xml or json though as those metadata
are in the payload (unless <code>wt="csv"</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# make a client
(cli &lt;- SolrClient$new())

# variables
cli$host
cli$port
cli$path
cli$scheme

# ping
## ping to make sure it's up
cli$ping("gettingstarted")

# version
## get Solr version information
cli$schema("gettingstarted")
cli$schema("gettingstarted", "fields")
cli$schema("gettingstarted", "name")
cli$schema("gettingstarted", "version")$version

# Search
cli$search("gettingstarted", params = list(q = "*:*"))
cli$search("gettingstarted", body = list(query = "*:*"))

# set a different host
SolrClient$new(host = 'stuff.com')

# set a different port
SolrClient$new(host = 3456)

# set a different http scheme
SolrClient$new(scheme = 'https')

# set a proxy
SolrClient$new(proxy = list(url = "187.62.207.130:3128"))

prox &lt;- list(url = "187.62.207.130:3128", user = "foo", pwd = "bar")
cli &lt;- SolrClient$new(proxy = prox)
cli$proxy

# A remote Solr instance to which you don't have admin access
(cli &lt;- SolrClient$new(host = "api.plos.org", path = "search", port = NULL))
res &lt;- cli$search(params = list(q = "memory"))
res
attr(res, "numFound")
attr(res, "start")
attr(res, "maxScore")

## End(Not run)
</code></pre>

<hr>
<h2 id='update_atomic_json'>Atomic updates with JSON data</h2><span id='topic+update_atomic_json'></span>

<h3>Description</h3>

<p>Atomic updates to parts of Solr documents
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_atomic_json(conn, body, name, wt = "json", raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_atomic_json_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="update_atomic_json_+3A_body">body</code></td>
<td>
<p>(character) JSON as a character string</p>
</td></tr>
<tr><td><code id="update_atomic_json_+3A_name">name</code></td>
<td>
<p>(character) Name of the core or collection</p>
</td></tr>
<tr><td><code id="update_atomic_json_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to parse</p>
</td></tr>
<tr><td><code id="update_atomic_json_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="update_atomic_json_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>References</h3>

<p>https://lucene.apache.org/solr/guide/7_0/updating-parts-of-documents.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr in Cloud mode: bin/solr start -e cloud -noprompt

# connect
(conn &lt;- SolrClient$new())

# create a collection
if (!conn$collection_exists("books")) {
  conn$collection_delete("books")
  conn$collection_create("books")
}

# Add documents
file &lt;- system.file("examples", "books2.json", package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_json(file, "books")

# get a document
conn$get(ids = 343334534545, "books")

# atomic update
body &lt;- '[{
 "id": "343334534545",
 "genre_s": {"set": "mystery" },
 "pages_i": {"inc": 1 }
}]'
conn$update_atomic_json(body, "books")

# get the document again
conn$get(ids = 343334534545, "books")

# another atomic update
body &lt;- '[{
 "id": "343334534545",
 "price": {"remove": "12.5" }
}]'
conn$update_atomic_json(body, "books")

# get the document again
conn$get(ids = 343334534545, "books")

## End(Not run)
</code></pre>

<hr>
<h2 id='update_atomic_xml'>Atomic updates with XML data</h2><span id='topic+update_atomic_xml'></span>

<h3>Description</h3>

<p>Atomic updates to parts of Solr documents
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_atomic_xml(conn, body, name, wt = "json", raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_atomic_xml_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="update_atomic_xml_+3A_body">body</code></td>
<td>
<p>(character) XML as a character string</p>
</td></tr>
<tr><td><code id="update_atomic_xml_+3A_name">name</code></td>
<td>
<p>(character) Name of the core or collection</p>
</td></tr>
<tr><td><code id="update_atomic_xml_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to parse</p>
</td></tr>
<tr><td><code id="update_atomic_xml_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="update_atomic_xml_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>References</h3>

<p>https://lucene.apache.org/solr/guide/7_0/updating-parts-of-documents.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr in Cloud mode: bin/solr start -e cloud -noprompt

# connect
(conn &lt;- SolrClient$new())

# create a collection
if (!conn$collection_exists("books")) {
  conn$collection_delete("books")
  conn$collection_create("books")
}

# Add documents
file &lt;- system.file("examples", "books.xml", package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_xml(file, "books")

# get a document
conn$get(ids = '978-0641723445', "books", wt = "xml")

# atomic update
body &lt;- '
&lt;add&gt;
 &lt;doc&gt;
   &lt;field name="id"&gt;978-0641723445&lt;/field&gt;
   &lt;field name="genre_s" update="set"&gt;mystery&lt;/field&gt;
   &lt;field name="pages_i" update="inc"&gt;1&lt;/field&gt;
 &lt;/doc&gt;
&lt;/add&gt;'
conn$update_atomic_xml(body, name="books")

# get the document again
conn$get(ids = '978-0641723445', "books", wt = "xml")

# another atomic update
body &lt;- '
&lt;add&gt;
 &lt;doc&gt;
   &lt;field name="id"&gt;978-0641723445&lt;/field&gt;
   &lt;field name="price" update="remove"&gt;12.5&lt;/field&gt;
 &lt;/doc&gt;
&lt;/add&gt;'
conn$update_atomic_xml(body, "books")

# get the document again
conn$get(ids = '978-0641723445', "books", wt = "xml")

## End(Not run)
</code></pre>

<hr>
<h2 id='update_csv'>Update documents with CSV data</h2><span id='topic+update_csv'></span>

<h3>Description</h3>

<p>Update documents with CSV data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_csv(
  conn,
  files,
  name,
  separator = ",",
  header = TRUE,
  fieldnames = NULL,
  skip = NULL,
  skipLines = 0,
  trim = FALSE,
  encapsulator = NULL,
  escape = NULL,
  keepEmpty = FALSE,
  literal = NULL,
  map = NULL,
  split = NULL,
  rowid = NULL,
  rowidOffset = NULL,
  overwrite = NULL,
  commit = NULL,
  wt = "json",
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_csv_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="update_csv_+3A_files">files</code></td>
<td>
<p>Path to a single file to load into Solr</p>
</td></tr>
<tr><td><code id="update_csv_+3A_name">name</code></td>
<td>
<p>(character) Name of the core or collection</p>
</td></tr>
<tr><td><code id="update_csv_+3A_separator">separator</code></td>
<td>
<p>Specifies the character to act as the field separator. Default: ','</p>
</td></tr>
<tr><td><code id="update_csv_+3A_header">header</code></td>
<td>
<p>TRUE if the first line of the CSV input contains field or column names.
Default: <code>TRUE</code>. If the fieldnames parameter is absent, these field names
will be used when adding documents to the index.</p>
</td></tr>
<tr><td><code id="update_csv_+3A_fieldnames">fieldnames</code></td>
<td>
<p>Specifies a comma separated list of field names to use when adding
documents to the Solr index. If the CSV input already has a header, the names
specified by this parameter will override them. Example: fieldnames=id,name,category</p>
</td></tr>
<tr><td><code id="update_csv_+3A_skip">skip</code></td>
<td>
<p>A comma separated list of field names to skip in the input. An alternate
way to skip a field is to specify it's name as a zero length string in fieldnames.
For example, <code>fieldnames=id,name,category&amp;skip=name</code> skips the name field,
and is equivalent to <code>fieldnames=id,,category</code></p>
</td></tr>
<tr><td><code id="update_csv_+3A_skiplines">skipLines</code></td>
<td>
<p>Specifies the number of lines in the input stream to discard
before the CSV data starts (including the header, if present). Default: <code>0</code></p>
</td></tr>
<tr><td><code id="update_csv_+3A_trim">trim</code></td>
<td>
<p>If true remove leading and trailing whitespace from values. CSV parsing
already ignores leading whitespace by default, but there may be trailing whitespace,
or there may be leading whitespace that is encapsulated by quotes and is thus not
removed. This may be specified globally, or on a per-field basis.
Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="update_csv_+3A_encapsulator">encapsulator</code></td>
<td>
<p>The character optionally used to surround values to preserve
characters such as the CSV separator or whitespace. This standard CSV format handles
the encapsulator itself appearing in an encapsulated value by doubling the
encapsulator.</p>
</td></tr>
<tr><td><code id="update_csv_+3A_escape">escape</code></td>
<td>
<p>The character used for escaping CSV separators or other reserved
characters. If an escape is specified, the encapsulator is not used unless also
explicitly specified since most formats use either encapsulation or escaping, not both.</p>
</td></tr>
<tr><td><code id="update_csv_+3A_keepempty">keepEmpty</code></td>
<td>
<p>Keep and index empty (zero length) field values. This may be specified
globally, or on a per-field basis. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="update_csv_+3A_literal">literal</code></td>
<td>
<p>Adds fixed field name/value to all documents. Example: Adds a &quot;datasource&quot;
field with value equal to &quot;products&quot; for every document indexed from the CSV
<code>literal.datasource=products</code></p>
</td></tr>
<tr><td><code id="update_csv_+3A_map">map</code></td>
<td>
<p>Specifies a mapping between one value and another. The string on the LHS of
the colon will be replaced with the string on the RHS. This parameter can be specified
globally or on a per-field basis. Example: replaces &quot;Absolutely&quot; with &quot;true&quot; in every
field <code>map=Absolutely:true</code>. Example: removes any values of &quot;RemoveMe&quot; in the
field &quot;foo&quot; <code>f.foo.map=RemoveMe:&amp;f.foo.keepEmpty=false </code></p>
</td></tr>
<tr><td><code id="update_csv_+3A_split">split</code></td>
<td>
<p>If TRUE, the field value is split into multiple values by another
CSV parser. The CSV parsing rules such as separator and encapsulator may be specified
as field parameters.</p>
</td></tr>
<tr><td><code id="update_csv_+3A_rowid">rowid</code></td>
<td>
<p>If not null, add a new field to the document where the passed in parameter
name is the field name to be added and the current line/rowid is the value. This is
useful if your CSV doesn't have a unique id already in it and you want to use the line
number as one. Also useful if you simply want to index where exactly in the original
CSV file the row came from</p>
</td></tr>
<tr><td><code id="update_csv_+3A_rowidoffset">rowidOffset</code></td>
<td>
<p>In conjunction with the rowid parameter, this integer value will be
added to the rowid before adding it the field.</p>
</td></tr>
<tr><td><code id="update_csv_+3A_overwrite">overwrite</code></td>
<td>
<p>If true (the default), check for and overwrite duplicate documents,
based on the uniqueKey field declared in the solr schema. If you know the documents you
are indexing do not contain any duplicates then you may see a considerable speed up
with &amp;overwrite=false.</p>
</td></tr>
<tr><td><code id="update_csv_+3A_commit">commit</code></td>
<td>
<p>Commit changes after all records in this request have been indexed. The
default is commit=false to avoid the potential performance impact of frequent commits.</p>
</td></tr>
<tr><td><code id="update_csv_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> to parse. If xml, uses <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> to parse</p>
</td></tr>
<tr><td><code id="update_csv_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="update_csv_+3A_...">...</code></td>
<td>
<p>curl options passed on to <a href="crul.html#topic+HttpClient">crul::HttpClient</a></p>
</td></tr>
</table>


<h3>Note</h3>

<p>SOLR v1.2 was first version to support csv. See
https://issues.apache.org/jira/browse/SOLR-66
</p>


<h3>See Also</h3>

<p>Other update: 
<code><a href="#topic+update_json">update_json</a>()</code>,
<code><a href="#topic+update_xml">update_xml</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr: bin/solr start -f -c -p 8983

# connect
(conn &lt;- SolrClient$new())

if (!conn$collection_exists("helloWorld")) {
  conn$collection_create(name = "helloWorld", numShards = 2)
}

df &lt;- data.frame(id=1:3, name=c('red', 'blue', 'green'))
write.csv(df, file="df.csv", row.names=FALSE, quote = FALSE)
conn$update_csv("df.csv", "helloWorld", verbose = TRUE)

# give back raw xml
conn$update_csv("df.csv", "helloWorld", wt = "xml")
## raw json
conn$update_csv("df.csv", "helloWorld", wt = "json", raw = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='update_json'>Update documents with JSON data</h2><span id='topic+update_json'></span>

<h3>Description</h3>

<p>Update documents with JSON data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_json(
  conn,
  files,
  name,
  commit = TRUE,
  optimize = FALSE,
  max_segments = 1,
  expunge_deletes = FALSE,
  wait_searcher = TRUE,
  soft_commit = FALSE,
  prepare_commit = NULL,
  wt = "json",
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_json_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="update_json_+3A_files">files</code></td>
<td>
<p>Path to a single file to load into Solr</p>
</td></tr>
<tr><td><code id="update_json_+3A_name">name</code></td>
<td>
<p>(character) Name of the core or collection</p>
</td></tr>
<tr><td><code id="update_json_+3A_commit">commit</code></td>
<td>
<p>(logical) If <code>TRUE</code>, documents immediately searchable.
Deafult: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="update_json_+3A_optimize">optimize</code></td>
<td>
<p>Should index optimization be performed before the method returns.
Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="update_json_+3A_max_segments">max_segments</code></td>
<td>
<p>optimizes down to at most this number of segments. Default: 1</p>
</td></tr>
<tr><td><code id="update_json_+3A_expunge_deletes">expunge_deletes</code></td>
<td>
<p>merge segments with deletes away. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="update_json_+3A_wait_searcher">wait_searcher</code></td>
<td>
<p>block until a new searcher is opened and registered as the
main query searcher, making the changes visible. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="update_json_+3A_soft_commit">soft_commit</code></td>
<td>
<p>perform a soft commit - this will refresh the 'view' of the
index in a more performant manner, but without &quot;on-disk&quot; guarantees.
Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="update_json_+3A_prepare_commit">prepare_commit</code></td>
<td>
<p>The prepareCommit command is an expert-level API that
calls Lucene's IndexWriter.prepareCommit(). Not passed by default</p>
</td></tr>
<tr><td><code id="update_json_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">fromJSON</a></code> to parse. If xml, uses
<code><a href="xml2.html#topic+read_xml">read_xml</a></code> to parse</p>
</td></tr>
<tr><td><code id="update_json_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="update_json_+3A_...">...</code></td>
<td>
<p>curl options passed on to <code><a href="crul.html#topic+HttpClient">HttpClient</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>You likely may not be able to run this function against many
public Solr services, but should work locally.
</p>


<h3>See Also</h3>

<p>Other update: 
<code><a href="#topic+update_csv">update_csv</a>()</code>,
<code><a href="#topic+update_xml">update_xml</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr: bin/solr start -f -c -p 8983

# connect
(conn &lt;- SolrClient$new())

# Add documents
file &lt;- system.file("examples", "books2.json", package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_json(files = file, name = "books")
update_json(conn, files = file, name = "books")

# Update commands - can include many varying commands
## Add file
file &lt;- system.file("examples", "updatecommands_add.json",
  package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_json(file, "books")

## Delete file
file &lt;- system.file("examples", "updatecommands_delete.json",
  package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_json(file, "books")

# Add and delete in the same document
## Add a document first, that we can later delete
ss &lt;- list(list(id = 456, name = "cat"))
conn$add(ss, "books")

## End(Not run)
</code></pre>

<hr>
<h2 id='update_xml'>Update documents with XML data</h2><span id='topic+update_xml'></span>

<h3>Description</h3>

<p>Update documents with XML data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_xml(
  conn,
  files,
  name,
  commit = TRUE,
  optimize = FALSE,
  max_segments = 1,
  expunge_deletes = FALSE,
  wait_searcher = TRUE,
  soft_commit = FALSE,
  prepare_commit = NULL,
  wt = "json",
  raw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_xml_+3A_conn">conn</code></td>
<td>
<p>A solrium connection object, see <a href="#topic+SolrClient">SolrClient</a></p>
</td></tr>
<tr><td><code id="update_xml_+3A_files">files</code></td>
<td>
<p>Path to a single file to load into Solr</p>
</td></tr>
<tr><td><code id="update_xml_+3A_name">name</code></td>
<td>
<p>(character) Name of the core or collection</p>
</td></tr>
<tr><td><code id="update_xml_+3A_commit">commit</code></td>
<td>
<p>(logical) If <code>TRUE</code>, documents immediately searchable.
Deafult: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="update_xml_+3A_optimize">optimize</code></td>
<td>
<p>Should index optimization be performed before the method returns.
Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="update_xml_+3A_max_segments">max_segments</code></td>
<td>
<p>optimizes down to at most this number of segments. Default: 1</p>
</td></tr>
<tr><td><code id="update_xml_+3A_expunge_deletes">expunge_deletes</code></td>
<td>
<p>merge segments with deletes away. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="update_xml_+3A_wait_searcher">wait_searcher</code></td>
<td>
<p>block until a new searcher is opened and registered as the
main query searcher, making the changes visible. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="update_xml_+3A_soft_commit">soft_commit</code></td>
<td>
<p>perform a soft commit - this will refresh the 'view' of the
index in a more performant manner, but without &quot;on-disk&quot; guarantees.
Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="update_xml_+3A_prepare_commit">prepare_commit</code></td>
<td>
<p>The prepareCommit command is an expert-level API that
calls Lucene's IndexWriter.prepareCommit(). Not passed by default</p>
</td></tr>
<tr><td><code id="update_xml_+3A_wt">wt</code></td>
<td>
<p>(character) One of json (default) or xml. If json, uses
<code><a href="jsonlite.html#topic+fromJSON">fromJSON</a></code> to parse. If xml, uses
<code><a href="xml2.html#topic+read_xml">read_xml</a></code> to parse</p>
</td></tr>
<tr><td><code id="update_xml_+3A_raw">raw</code></td>
<td>
<p>(logical) If <code>TRUE</code>, returns raw data in format specified by
<code>wt</code> param</p>
</td></tr>
<tr><td><code id="update_xml_+3A_...">...</code></td>
<td>
<p>curl options passed on to <code><a href="crul.html#topic+HttpClient">HttpClient</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>You likely may not be able to run this function against many
public Solr services, but should work locally.
</p>


<h3>See Also</h3>

<p>Other update: 
<code><a href="#topic+update_csv">update_csv</a>()</code>,
<code><a href="#topic+update_json">update_json</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# start Solr: bin/solr start -f -c -p 8983

# connect
(conn &lt;- SolrClient$new())

# create a collection
if (!conn$collection_exists("books")) {
  conn$collection_create(name = "books", numShards = 2)
}

# Add documents
file &lt;- system.file("examples", "books.xml", package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_xml(file, "books")

# Update commands - can include many varying commands
## Add files
file &lt;- system.file("examples", "books2_delete.xml", package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_xml(file, "books")

## Delete files
file &lt;- system.file("examples", "updatecommands_delete.xml",
package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_xml(file, "books")

## Add and delete in the same document
## Add a document first, that we can later delete
ss &lt;- list(list(id = 456, name = "cat"))
conn$add(ss, "books")
## Now add a new document, and delete the one we just made
file &lt;- system.file("examples", "add_delete.xml", package = "solrium")
cat(readLines(file), sep = "\n")
conn$update_xml(file, "books")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
