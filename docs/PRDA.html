<!DOCTYPE html><html><head><title>Help for package PRDA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PRDA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#PRDA'><p>PRDA: Prospective and Retrospective Design Analysis.</p></a></li>
<li><a href='#prospective'><p>Prospective Design Analysis</p></a></li>
<li><a href='#retrospective'><p>Retrospective Design Analysis</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Conduct a Prospective or Retrospective Design Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of the "Design Analysis" proposed by 
    Gelman and Carlin (2014) &lt;<a href="https://doi.org/10.1177%2F1745691614551642">doi:10.1177/1745691614551642</a>&gt;. It combines 
    the evaluation of Power-Analysis with other inferential-risks as 
    Type-M error (i.e. Magnitude) and Type-S error (i.e. Sign). See also
    Altoè et al. (2020) &lt;<a href="https://doi.org/10.3389%2Ffpsyg.2019.02893">doi:10.3389/fpsyg.2019.02893</a>&gt; and 
    Bertoldo et al. (2020) &lt;<a href="https://doi.org/10.31234%2Fosf.io%2Fq9f86">doi:10.31234/osf.io/q9f86</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, devtools, ggplot2, knitr, rmarkdown, roxygen2,
testthat, tidyverse</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, pbapply, Rcpp</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://claudiozandonella.github.io/PRDA/">https://claudiozandonella.github.io/PRDA/</a>,
<a href="https://github.com/ClaudioZandonella/PRDA">https://github.com/ClaudioZandonella/PRDA</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ClaudioZandonella/PRDA/issues">https://github.com/ClaudioZandonella/PRDA/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-12-05 22:25:33 UTC; claudio</td>
</tr>
<tr>
<td>Author:</td>
<td>Claudio Zandonella Callegher
    <a href="https://orcid.org/0000-0001-7721-6318"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Massimiliano Pastore
    <a href="https://orcid.org/0000-0002-7922-6365"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Angela Andreella <a href="https://orcid.org/0000-0002-1141-3041"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Anna Vesely <a href="https://orcid.org/0000-0001-6696-2390"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Enrico Toffalini <a href="https://orcid.org/0000-0002-1404-5133"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Giulia Bertoldo <a href="https://orcid.org/0000-0002-6960-3980"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Gianmarco Altoè <a href="https://orcid.org/0000-0003-1154-9528"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Claudio Zandonella Callegher &lt;claudiozandonella@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-12-08 10:10:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='PRDA'>PRDA: Prospective and Retrospective Design Analysis.</h2><span id='topic+PRDA'></span>

<h3>Description</h3>

<p>Given an hypothetical value of effect size, PRDA performs a prospective
or retrospective design analysis to evaluate the inferential risks (i.e.,
power, Type M error, and Type S error) related to the study design. See
<code>vignette("PRDA")</code> for a brief introduction to <em>Design
Analysis</em>.
</p>


<h3>Details</h3>

<p>PRDA package can be used for Pearson's correlation between two variables
or mean comparisons (i.e., one-sample, paired, two-sample, and Welch's
t-test) considering an hypothetical value of <code class="reqn">\rho</code> or Cohen's <em>d</em>
respectively. See <code>vignette("retrospective")</code> for more details.
</p>


<h3>Functions</h3>

<p>In PRDA there are two main functions:
</p>

<ul>
<li><p><strong><code>retrospective()</code></strong>. Given the hypothetical population
effect size and the study sample size, the function <code>retrospective()</code>
performs a retrospective design analysis. According to the defined
alternative hypothesis and the significance level, the inferential risks
(i.e., Power level, Type M error, and Type S error) are computed together
with the critical effect value (i.e., the minimum absolute effect size value
that would result significant). To know more about function arguments and
examples see the function documentation
<code><a href="#topic+retrospective">?retrospective</a></code> and
<code>vignette("retrospective")</code>.
</p>
</li>
<li><p><strong><code>prospective()</code></strong>. Given the hypothetical population
effect size and the required power level, the function <code>prospective()</code>
performs a prospective design analysis. According to the defined alternative
hypothesis and the significance level, the required sample size is computed
together with the associated Type M error, Type S error, and the critical
effect value (i.e., the minimum absolute effect size value that would
result significant).  To know more about function arguments and examples see
the function documentation <code><a href="#topic+prospective">?prospective</a></code>
and <code>vignette("prospective")</code>.
</p>
</li></ul>



<h3>Hypothetical Effect Size</h3>

<p>The hypothetical population effect size can be defined as a single value
according to previous results in the literature or experts indications.
Alternatively, PRDA allows users to specify a distribution of plausible
values to account for their uncertainty about the hypothetical population
effect size.  To know how to specify the hypothetical effect size according
to a distribution and an example of application see
<code>vignette("retrospective")</code>.
</p>


<h3>References</h3>

<p>Altoè, G., Bertoldo, G., Zandonella Callegher, C., Toffalini, E.,
Calcagnì, A., Finos, L., &amp; Pastore, M. (2020). Enhancing Statistical
Inference in Psychological Research via Prospective and Retrospective Design
Analysis. Frontiers in Psychology, 10.
<a href="https://doi.org/10.3389/fpsyg.2019.02893">https://doi.org/10.3389/fpsyg.2019.02893</a>
</p>
<p>Bertoldo, G., Altoè, G., &amp; Zandonella Callegher, C. (2020, June 15).
Designing Studies and Evaluating Research Results: Type M and Type S Errors
for Pearson Correlation Coefficient. Retrieved from
<a href="https://psyarxiv.com/q9f86/">https://psyarxiv.com/q9f86/</a>
</p>
<p>Gelman, A., &amp; Carlin, J. (2014). Beyond Power Calculations: Assessing Type S
(Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science,
9(6), 641–651. <a href="https://doi.org/10.1177/1745691614551642">https://doi.org/10.1177/1745691614551642</a>
</p>

<hr>
<h2 id='prospective'>Prospective Design Analysis</h2><span id='topic+prospective'></span>

<h3>Description</h3>

<p>Given the hypothetical population effect size and the required power level,
the function <code>prospective()</code> performs a prospective design analysis for
Pearson's correlation test between two variables or <em>t</em>-test comparing
group means (Cohen's <em>d</em>). According to the defined alternative
hypothesis and the significance level, the required sample size is computed
together with the associated Type M error, Type S error, and the critical
effect value (i.e., the minimum absolute effect size value that would
result significant).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prospective(
  effect_size,
  power,
  ratio_n = 1,
  test_method = c("pearson", "two_sample", "welch", "paired", "one_sample"),
  alternative = c("two_sided", "less", "greater"),
  sig_level = 0.05,
  ratio_sd = 1,
  B = 10000,
  tl = -Inf,
  tu = Inf,
  B_effect = 1000,
  sample_range = c(2, 1000),
  eval_power = c("median", "mean"),
  tol = 0.01,
  display_message = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prospective_+3A_effect_size">effect_size</code></td>
<td>
<p>a numeric value or function (see Details) indicating the
hypothetical population effect size.</p>
</td></tr>
<tr><td><code id="prospective_+3A_power">power</code></td>
<td>
<p>a numeric value indicating the required power level.</p>
</td></tr>
<tr><td><code id="prospective_+3A_ratio_n">ratio_n</code></td>
<td>
<p>a numeric value indicating the ratio between the sample size in
the first group and in the second group. This argument is required when
<code>test_method</code> is set to <code>"two_sample"</code> or <code>"welch"</code>. In the
case of <code>test_method = "paired"</code>, set <code>ratio_n</code> to 1. Whereas in
the case of <code>test_method = "one_sample"</code>, set <code>ratio_n</code> to
<code>NULL</code>. This argument is ignored for <code>test_method = "pearson"</code>.
See Test methods section in Details.</p>
</td></tr>
<tr><td><code id="prospective_+3A_test_method">test_method</code></td>
<td>
<p>a character string specifying the test type, must be one of
<code>"pearson"</code> (default, Pearson's correlation), <code>"two_sample"</code>
(independent two-sample <em>t</em>-test), <code>"welch"</code> (Welch's
<em>t</em>-test), <code>"paired"</code> (dependent <em>t</em>-test for paired
samples), or <code>"one_sample"</code> (one-sample <em>t</em>-test). You can specify
just the initial letters.</p>
</td></tr>
<tr><td><code id="prospective_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of &quot;two_sided&quot; (default), &quot;greater&quot; or &quot;less&quot;. You can specify
just the initial letter.</p>
</td></tr>
<tr><td><code id="prospective_+3A_sig_level">sig_level</code></td>
<td>
<p>a numeric value indicating the significance level on which
the alternative hypothesis is evaluated.</p>
</td></tr>
<tr><td><code id="prospective_+3A_ratio_sd">ratio_sd</code></td>
<td>
<p>a numeric value indicating the ratio between the standard
deviation in the first group and in the second group. This argument is
required only in the case of Welch's <em>t</em>-test.</p>
</td></tr>
<tr><td><code id="prospective_+3A_b">B</code></td>
<td>
<p>a numeric  value indicating the number of iterations. Increase the
number of iterations to obtain more stable results.</p>
</td></tr>
<tr><td><code id="prospective_+3A_tl">tl</code></td>
<td>
<p>optional value indicating the lower truncation point if
<code>effect_size</code> is defined as a function.</p>
</td></tr>
<tr><td><code id="prospective_+3A_tu">tu</code></td>
<td>
<p>optional value indicating the upper truncation point if
<code>effect_size</code> is defined as a function.</p>
</td></tr>
<tr><td><code id="prospective_+3A_b_effect">B_effect</code></td>
<td>
<p>a numeric  value indicating the number of sampled effects
if <code>effect_size</code> is defined as a function. Increase the number to
obtain more stable results.</p>
</td></tr>
<tr><td><code id="prospective_+3A_sample_range">sample_range</code></td>
<td>
<p>a length-2 numeric vector indicating the minimum and
maximum sample size of the first group (<code>sample_n1</code>).</p>
</td></tr>
<tr><td><code id="prospective_+3A_eval_power">eval_power</code></td>
<td>
<p>a character string specifying the function used to summarize
the resulting distribution of power values. Must be one of &quot;median&quot;
(default) or &quot;mean&quot;. You can specify just the initial letters. See Details.</p>
</td></tr>
<tr><td><code id="prospective_+3A_tol">tol</code></td>
<td>
<p>a numeric value indicating the tolerance of required power level.</p>
</td></tr>
<tr><td><code id="prospective_+3A_display_message">display_message</code></td>
<td>
<p>a logical variable indicating whether to display or not
the information about computational steps and the progress bar. Not that the
progress bar is available only when <code>effect_size</code> is defined as a
function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conduct a prospective design analysis to define the required sample
size and the associated inferential risks according to study design. A
general overview is provided in the <code>vignette("prospective")</code>.
</p>
<p><strong>Population effect size</strong>
</p>
<p>The hypothetical population effect size (<code>effect_size</code>) can be set to
a single value or a function that allows sampling values from a given
distribution. The function has to be defined as <code>function(n)
  my_function(n, ...)</code>, with only one single argument <code>n</code> representing
the number of sampled values (e.g., <code>function(n) rnorm(n, mean = 0, sd
  = 1)</code>; <code>function(n) sample(c(.1,.3,.5), n, replace = TRUE)</code>). This
allows users to define hypothetical effect size distribution according to
their needs.
</p>
<p>Argument <code>B_effect</code> allows defining the number of sampled effects.
Users can access sampled effects in the <code>effect_info</code> list included in
the output to evaluate if the sample is representative of their
specification. Increase the number to obtain more accurate results but it
will require more computational time (default is 1000). To avoid long
computational times, we suggest adjusting <code>B</code> when using a function to
define the hypothetical population effect size.
</p>
<p>Optional arguments <code>tl</code> and <code>tu</code> allow truncating the sampling
distribution specifying the lower truncation point and upper truncation
point respectively. Note that if <code>effect_type = "correlation"</code>,
distribution is automatically truncated between -1 and 1.
</p>
<p>When a distribution of effects is specified, a corresponding distribution
of power values is obtained as result. To evaluate whether the required
level of power is obtained, user can decide between the median or the mean
value as a summary of the distribution using the argument
<code>eval_power</code>. They answer two different questions. Which is the
required sample size to obtain 50
than the required level (median)?; Which is the required sample size to
obtain on average a power equal or greater than the required level (mean)?
</p>
<p><strong>Test methods</strong>
</p>
<p>The function <code>retrospective()</code> performs a retrospective design
analysis considering correlations between two variables or comparisons
between group means.
</p>
<p>In the case of a correlation, only Pearson's correlation between two
variables is available, whereas Kendall's <em>tau</em> and Spearman's
<em>rho</em> are not implemented. The <code>test_method</code> argument has to be
set to <code>"pearson"</code> (default) and the <code>effect_size</code> argument is
used to define the hypothetical population effect size in terms of
Pearson's correlation coefficient (<code class="reqn">\rho</code>). The <code>ratio_n</code>
argument is ignored.
</p>
<p>In the case of a comparison between group means, the <code>effect_size</code>
argument is used to define the hypothetical population effect size in terms
of Cohen's <em>d</em> and the available <em>t</em>-tests are selected
specifying the argument <code>test_method</code>. For independent two-sample
<em>t</em>-test, use <code>"two_sample"</code> and indicate the ratio between the
sample size of the first group and the second group (<code>ratio_n</code>). For
Welch's <em>t</em>-test, use <code>"welch"</code> and indicate the ratio between
the sample size of the first group and the second group (<code>ratio_n</code>)
and the ratio between the standard deviation in the first group and in the
second group (<code>ratio_sd</code>). For dependent <em>t</em>-test for paired
samples, use <code>"paired"</code> (<code>ratio_n</code> has to be 1). For one-sample
<em>t</em>-test, use <code>"one_sample"</code> (<code>ratio_n</code> has to be
<code>NULL</code>).
</p>
<p><strong>Study design</strong>
</p>
<p>Study design can be further defined according to statistical test
directionality and required <code class="reqn">\alpha</code>-level using the arguments
<code>alternative</code> and <code>sig_level</code> respectively.
</p>


<h3>Value</h3>

<p>A list with class &quot;design_analysis&quot; containing the following
components:
</p>
<table>
<tr><td><code>design_analysis</code></td>
<td>
<p>a character string indicating the type of design
analysis: &quot;prospective&quot;.</p>
</td></tr>
<tr><td><code>call_arguments</code></td>
<td>
<p>a list with all the arguments passed to the
function and the raw function call.</p>
</td></tr>
<tr><td><code>effect_info</code></td>
<td>
<p>a list with all the information regarding the
considered hypothetical population effect size. The list includes:
<code>effect_type</code> indicating the type of effect; <code>effect_function</code>
indicating the function from which effect are sampled or the string
&quot;single_value&quot; if a single value was provided; <code>effect_summary</code>
summary of the sampled effects; <code>effect_samples</code> vector with the
sampled effects (or unique value in the case of a single value); if
relevant <code>tl</code> and <code>tu</code> specifying the lower upper truncation
point respectively.</p>
</td></tr>
<tr><td><code>test_info</code></td>
<td>
<p>a list with all the information regarding the test
performed. The list includes: <code>test_method</code> character sting
indicating the test method (i.e., &quot;pearson&quot;, &quot;one_sample&quot;, &quot;paired&quot;,
&quot;two_sample&quot;, or &quot;welch&quot;); the required sample size (<code>sample_n1</code> and
if relevant <code>sample_n2</code>), the alternative hypothesis
(<code>alternative</code>), significance level (<code>sig_level</code>)  and  degrees
of freedom (<code>df</code>) of the statistical test; <code>critical_effect</code> the
minimum absolute effect value that would result significant. Note that
<code>critical_effect</code> in the case of <code>alternative = "two_sided"</code> is
the absolute value and both positive and negative values should be
considered.</p>
</td></tr>
<tr><td><code>prospective_res</code></td>
<td>
<p>a data frame with the results of the design
analysis. Columns names are <code>power</code>, <code>typeM</code>, and <code>typeS</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Altoè, G., Bertoldo, G., Zandonella Callegher, C., Toffalini, E.,
Calcagnì, A., Finos, L., &amp; Pastore, M. (2020). Enhancing Statistical
Inference in Psychological Research via Prospective and Retrospective Design
Analysis. Frontiers in Psychology, 10.
<a href="https://doi.org/10.3389/fpsyg.2019.02893">https://doi.org/10.3389/fpsyg.2019.02893</a>
</p>
<p>Bertoldo, G., Altoè, G., &amp; Zandonella Callegher, C. (2020).
Designing Studies and Evaluating Research Results: Type M and Type S Errors
for Pearson Correlation Coefficient. Retrieved from
<a href="https://psyarxiv.com/q9f86/">https://psyarxiv.com/q9f86/</a>
</p>
<p>Gelman, A., &amp; Carlin, J. (2014). Beyond Power Calculations: Assessing Type S
(Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science,
9(6), 641–651. <a href="https://doi.org/10.1177/1745691614551642">https://doi.org/10.1177/1745691614551642</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Pearson's correlation
prospective(effect_size = .3, power = .8, test_method = "pearson", B = 1e3)

# Two-sample t-test
prospective(effect_size = .3, power = .8, ratio_n = 1.5,
            test_method = "two_sample", B = 1e3)
# Welch t-test
prospective(effect_size = .3, power = .8, ratio_n = 2,
            test_method = "welch", ratio_sd = 1.5, B = 1e3)
# Paired t-test
prospective(effect_size = .3, power = .8, ratio_n = 1,
            test_method = "paired", B = 1e3)
# One-sample t-test
prospective(effect_size = .3, power = .8, ratio_n = NULL,
            test_method = "one_sample", B = 1e3)




# Define effect_size using functions (long computational time)
prospective(effect_size = function(n) rnorm(n, .3, .1), power = .8,
            test_method = "pearson", B_effect = 500, B = 500, tl = .15)
prospective(effect_size = function(n) rnorm(n, .3, .1), power = .8,
            test_method = "two_sample", ratio_n = 1, B_effect = 500, B = 500,
            tl = .2, tu = .4)


</code></pre>

<hr>
<h2 id='retrospective'>Retrospective Design Analysis</h2><span id='topic+retrospective'></span>

<h3>Description</h3>

<p>Given the hypothetical population effect size and the study sample size, the
function <code>retrospective()</code> performs a retrospective design analysis for
Pearson's correlation test between two variables or <em>t</em>-test comparing
group means (Cohen's <em>d</em>). According to the defined alternative
hypothesis and the significance level, inferential risks (i.e., Power level,
Type M error, and Type S error) are computed together with the critical
effect value (i.e., the minimum absolute effect size value that would result
significant).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>retrospective(
  effect_size,
  sample_n1,
  sample_n2 = NULL,
  test_method = c("pearson", "two_sample", "welch", "paired", "one_sample"),
  alternative = c("two_sided", "less", "greater"),
  sig_level = 0.05,
  ratio_sd = 1,
  B = 10000,
  tl = -Inf,
  tu = Inf,
  B_effect = 1000,
  display_message = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="retrospective_+3A_effect_size">effect_size</code></td>
<td>
<p>a numeric value or function (see Details) indicating the
hypothetical population effect size.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_sample_n1">sample_n1</code></td>
<td>
<p>a numeric value indicating the sample size of the first
group.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_sample_n2">sample_n2</code></td>
<td>
<p>a numeric value indicating the sample size of the second
group. This argument is required when <code>test_method</code> is set to
<code>"two_sample"</code> or <code>"welch"</code>. In the case of <code>test_method =
"paired"</code>, set <code>sample_n2</code> equal to <code>sample_n1</code>. Whereas in the
case of <code>test_method = "one_sample"</code>, set <code>sample_n2</code> to
<code>NULL</code>. This argument is ignored for <code>test_method = "pearson"</code>.
See Test methods section in Details.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_test_method">test_method</code></td>
<td>
<p>a character string specifying the test type, must be one of
<code>"pearson"</code> (default, Pearson's correlation), <code>"two_sample"</code>
(independent two-sample <em>t</em>-test), <code>"welch"</code> (Welch's
<em>t</em>-test), <code>"paired"</code> (dependent <em>t</em>-test for paired
samples), or <code>"one_sample"</code> (one-sample <em>t</em>-test). You can specify
just the initial letters.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two_sided"</code> (default), <code>"greater"</code> or
<code>"less"</code>. You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_sig_level">sig_level</code></td>
<td>
<p>a numeric value indicating the significance level on which
the alternative hypothesis is evaluated.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_ratio_sd">ratio_sd</code></td>
<td>
<p>a numeric value indicating the ratio between the standard
deviation in the first group and in the second group. This argument is
needed in the case of Welch's <em>t</em>-test.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_b">B</code></td>
<td>
<p>a numeric  value indicating the number of iterations. Increase the
number of iterations to obtain more stable results.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_tl">tl</code></td>
<td>
<p>optional value indicating the lower truncation point if
<code>effect_size</code> is defined as a function.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_tu">tu</code></td>
<td>
<p>optional value indicating the upper truncation point if
<code>effect_size</code> is defined as a function.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_b_effect">B_effect</code></td>
<td>
<p>a numeric  value indicating the number of sampled effects
if <code>effect_size</code> is defined as a function. Increase the number to
obtain more stable results.</p>
</td></tr>
<tr><td><code id="retrospective_+3A_display_message">display_message</code></td>
<td>
<p>a logical variable indicating whether to display or not
the progress bar. Not that this applies only when <code>effect_size</code> is
defined as a function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conduct a retrospective design analysis to evaluate inferential risks
according to study design. A general overview is provided in the
<code>vignette("retrospective")</code>.
</p>
<p><strong>Population effect size</strong>
</p>
<p>The hypothetical population effect size (<code>effect_size</code>) can be set to a
single value or a function that allows sampling values from a given
distribution. The function has to be defined as <code>function(n)
 my_function(n, ...)</code>, with only one single argument <code>n</code> representing
the number of sampled values (e.g., <code>function(n) rnorm(n, mean = 0, sd
 = 1)</code>; <code>function(n) sample(c(.1,.3,.5), n, replace = TRUE)</code>). This
allows users to define hypothetical effect size distribution according to
their needs.
</p>
<p>Argument <code>B_effect</code> allows defining the number of sampled effects.
Users can access sampled effects in the <code>effect_info</code> list included in
the output to evaluate if the sample is representative of their
specification. Increase the number to obtain more accurate results but it
will require more computational time (default is 1000). To avoid long
computational times, we suggest adjusting <code>B</code> when using a function to
define the hypothetical population effect size.
</p>
<p>Optional arguments <code>tl</code> and <code>tu</code> allow truncating the sampling
distribution specifying the lower truncation point and upper  truncation
point respectively. Note that if <code>effect_type = "correlation"</code>,
distribution is automatically truncated between -1 and 1.
</p>
<p><strong>Test methods</strong>
</p>
<p>The function <code>retrospective()</code> performs a retrospective design analysis
considering correlations between two variables or comparisons between group
means.
</p>
<p>In the case of a correlation, only Pearson's correlation between two
variables is available, whereas Kendall's <em>tau</em> and Spearman's
<em>rho</em> are not implemented. The <code>test_method</code> argument has to be
set to <code>"pearson"</code> (default) and the <code>effect_size</code> argument is
used to define the hypothetical population effect size in terms of Pearson's
correlation coefficient (<code class="reqn">\rho</code>). The <code>sample_n2</code> argument is
ignored.
</p>
<p>In the case of a comparison between group means, the <code>effect_size</code>
argument is used to define the hypothetical population effect size in terms
of Cohen's <em>d</em> and the available <em>t</em>-tests are selected specifying
the argument <code>test_method</code>. For independent two-sample <em>t</em>-test,
use <code>"two_sample"</code> and indicate the sample size of the second group
(<code>sample_n2</code>). For Welch's <em>t</em>-test, use <code>"welch"</code> and
indicate and indicate the sample size of the second group (<code>sample_n2</code>)
and the ratio between the standard deviation in the first group and in the
second group (<code>ratio_sd</code>). For dependent <em>t</em>-test for paired
samples, use <code>"paired"</code> (<code>sample_n1</code> and <code>sample_n2</code> have to
be equal). For one-sample <em>t</em>-test, use <code>"one_sample"</code>
(<code>sample_n2</code> has to be <code>NULL</code>).
</p>
<p><strong>Study design</strong>
</p>
<p>Study design can be further defined according to statistical test
directionality and required <code class="reqn">\alpha</code>-level using the arguments
<code>alternative</code> and <code>sig_level</code> respectively.
</p>


<h3>Value</h3>

<p>A list with class &quot;design_analysis&quot; containing the following
components:
</p>
<table>
<tr><td><code>design_analysis</code></td>
<td>
<p>a character string indicating the type of design
analysis: &quot;retrospective&quot;.</p>
</td></tr>
<tr><td><code>call_arguments</code></td>
<td>
<p>a list with all the arguments passed to the
function and the raw function call.</p>
</td></tr>
<tr><td><code>effect_info</code></td>
<td>
<p>a list with all the information regarding the
considered hypothetical population effect size. The list includes:
<code>effect_type</code> indicating the type of effect; <code>effect_function</code>
indicating the function from which effect are sampled or the string
&quot;single_value&quot; if a single value was provided; <code>effect_summary</code>
summary of the sampled effects; <code>effect_samples</code> vector with the
sampled effects (or unique value in the case of a single value). if
relevant <code>tl</code> and <code>tu</code> specifying the lower upper truncation
point respectively.</p>
</td></tr>
<tr><td><code>test_info</code></td>
<td>
<p>a list with all the information regarding the test
performed. The list includes: <code>test_method</code> character sting
indicating the test method (i.e., &quot;pearson&quot;, &quot;one_sample&quot;, &quot;paired&quot;,
&quot;two_sample&quot;, or &quot;welch&quot;); sample size (<code>sample_n1</code> and if relevant
<code>sample_n2</code>), alternative hypothesis (<code>alternative</code>),
significance level (<code>sig_level</code>)  and  degrees of freedom (<code>df</code>)
of the statistical test; <code>critical_effect</code> the minimum absolute
effect value that would result significant. Note that
<code>critical_effect</code> in the case of <code>alternative = "two_sided"</code> is
the absolute value and both positive and negative values should be
considered.</p>
</td></tr>
<tr><td><code>retrospective_res</code></td>
<td>
<p>a data frame with the results of the design
analysis. Columns names are <code>power</code>, <code>typeM</code>, and <code>typeS</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Altoè, G., Bertoldo, G., Zandonella Callegher, C., Toffalini, E.,
Calcagnì, A., Finos, L., &amp; Pastore, M. (2020). Enhancing Statistical
Inference in Psychological Research via Prospective and Retrospective Design
Analysis. Frontiers in Psychology, 10.
<a href="https://doi.org/10.3389/fpsyg.2019.02893">https://doi.org/10.3389/fpsyg.2019.02893</a>
</p>
<p>Bertoldo, G., Altoè, G., &amp; Zandonella Callegher, C. (2020).
Designing Studies and Evaluating Research Results: Type M and Type S Errors
for Pearson Correlation Coefficient. Retrieved from
<a href="https://psyarxiv.com/q9f86/">https://psyarxiv.com/q9f86/</a>
</p>
<p>Gelman, A., &amp; Carlin, J. (2014). Beyond Power Calculations: Assessing Type S
(Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science,
9(6), 641–651. <a href="https://doi.org/10.1177/1745691614551642">https://doi.org/10.1177/1745691614551642</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Pearson's correlation
retrospective(effect_size = .3, sample_n1 = 25, test_method = "pearson")

# Two-sample t-test
retrospective(effect_size = .3, sample_n1 = 25, sample_n2 = 35,
              test_method = "two_sample")
# Welch t-test
retrospective(effect_size = .3, sample_n1 = 25, sample_n2 = 35,
              test_method = "welch", ratio_sd = 1.5)
# Paired t-test
retrospective(effect_size = .3, sample_n1 = 25, sample_n2 = 25,
              test_method = "paired")
# One-sample t-test
retrospective(effect_size = .3, sample_n1 = 25, sample_n2 = NULL,
              test_method = "one_sample")





# Define effect_size using functions (long computational times)
# Remember to adjust B
retrospective(effect_size = function(n) rnorm(n, .3, .1), sample_n1 = 25,
              test_method = "pearson", tl = .15, B = 1e3)
retrospective(effect_size = function(n) rnorm(n, .3, .1), sample_n1 = 25,
              test_method = "one_sample", tl = .2, tu = .4, B = 1e3)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
