<!DOCTYPE html><html><head><title>Help for package FRESHD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FRESHD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#iwt'><p>Inverse discrete wavelet transform</p></a></li>
<li><a href='#magging'><p>Maximin Aggregation</p></a></li>
<li><a href='#maximin'><p>Maximin signal estimation</p></a></li>
<li><a href='#predict.FRESHD'><p>Make Prediction From a FRESHD Object</p></a></li>
<li><a href='#print.FRESHD'><p>Print Function for objects of Class FRESHD</p></a></li>
<li><a href='#RH'><p>The Rotated H-transform of a 3d Array by a Matrix</p></a></li>
<li><a href='#wt'><p>Discrete wavelet transform</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Robust Estimation of Signals in Heterogeneous Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-05-09</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adam Lund &lt;adam.lund@math.ku.dk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Procedure for solving the maximin problem for identical design across heterogeneous data groups. Particularly efficient when the design matrix is either orthogonal or has tensor structure. Orthogonal wavelets can be specified for 1d, 2d or 3d data simply by name. For tensor structured design the tensor components (two or three) may be supplied. The package also provides an efficient implementation of the generic magging estimator.</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.12), glamlasso</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppEigen</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-10 18:35:57 UTC; adam</td>
</tr>
<tr>
<td>Author:</td>
<td>Adam Lund [aut, cre, ctb, cph],
  Benjamin Stephens [ctb, cph],
  Gael Guennebaud [ctb, cph],
  Angelo Furfaro [ctb, cph],
  Luca Di Gaspero [ctb, cph],
  Brandon Whitcher [ctb, cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-12 08:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='iwt'>Inverse discrete wavelet transform</h2><span id='topic+iwt'></span>

<h3>Description</h3>

<p>This function performs a level J decomposition of the input
array (1d, 2d, or 3d) using the pyramid algorithm (Mallat 1989).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iwt(x, wf = "la8", J = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iwt_+3A_x">x</code></td>
<td>
<p>a 1, 2, or 3 dimensional data array. The size of each dimension must
be dyadic.</p>
</td></tr>
<tr><td><code id="iwt_+3A_wf">wf</code></td>
<td>
<p>the type of wavelet family used. See R-package waveslim for options.</p>
</td></tr>
<tr><td><code id="iwt_+3A_j">J</code></td>
<td>
<p>is the level (depth) of the decomposition. For default <code>NULL</code> the max
depth is used  making <code>iwt(x)</code> equal to multiplying <code>x</code> with the
inverse of corresponding wavelet matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a C++/R wrapper function for a C implementation of the
inverse discrete wavelet transform by Brandon Whitcher licensed under the BSD 3 license
https://cran.r-project.org/web/licenses/BSD_3_clause, see the Waveslim package;
Percival and Walden (2000); Gencay, Selcuk and Whitcher (2001).
</p>
<p>Given a data array (1d, 2d or 3d) with dyadic
dimensions sizes this transform is computed efficiently via the pyramid
algorithm see Mallat (1989).
</p>


<h3>Value</h3>

<table>
<tr><td><code>...</code></td>
<td>
<p>An array with dimensions equal to those of <code>x</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adam Lund, Brandon Whitcher
</p>


<h3>References</h3>

<p>Gencay, R., F. Selcuk and B. Whitcher (2001) An Introduction to Wavelets and
Other Filtering Methods in Finance and Economics, Academic Press.
</p>
<p>Mallat, S. G. (1989) A theory for multiresolution signal decomposition: the
wavelet representation, IEEE Transactions on Pattern Analysis and Machine
Intelligence, 11, No. 7, 674-693.
</p>
<p>Percival, D. B. and A. T. Walden (2000) Wavelet Methods for Time Series
Analysis, Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###1d
x &lt;- as.matrix(rnorm(2^3))
range(x - iwt(wt(x)))

###2d
x &lt;- matrix(rnorm(2^(3 + 4)), 2^3, 2^4)
range(x - iwt(wt(x)))

###3d
x &lt;- array(rnorm(2^(3 + 4 + 5)), c(2^3, 2^4, 2^5))
range(x - iwt(wt(x)))

</code></pre>

<hr>
<h2 id='magging'>Maximin Aggregation</h2><span id='topic+magging'></span>

<h3>Description</h3>

<p>R wrapper for a C++ implementation of the generic maximin 
aggregation procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>magging(B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="magging_+3A_b">B</code></td>
<td>
<p>array of size <code class="reqn">p \times G </code> containing the group parameter
estimates where <code class="reqn">p</code> is the number of model  parameters and <code class="reqn">G</code> is the
number of groups.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following <cite>Buhlmann 2016</cite>  this function computes the maximin 
aggregation estimator for given group estimates. This entails solving a 
convex quadratic optimization problem. The function wraps a C++ implementation
of an algorithm by Goldfarb and Idnani for solving a (convex) quadratic 
programming problem by means of a dual method.
</p>
<p>The underlying C++ program solving the convex quadratic optimization problem, 
eiquadprog.hpp, copyright (2011) Benjamin Stephens, GPL v2 see 
https://www.cs.cmu.edu/~bstephe1/eiquadprog.hpp, is based on previous 
libraries:
</p>
<p>QuadProg++, Copyright (C) 2007-2016 Luca Di Gaspero, MIT License. See 
https://github.com/liuq/QuadProgpp
</p>
<p>uQuadProg, Copyright (C) 2006 - 2017 Angelo Furfaro, LGPL v3, 
a port  of QuadProg++  working with ublas data structures. See
https://github.com/fx74/uQuadProg/blob/master/README.md
</p>
<p>QuadProg Copyright (C) 2014-2015 Gael Guennebaud, LGPL v3, a modification of 
uQuadProg, working with Eigen data structures. See
http://www.labri.fr/perso/guenneba/code/QuadProg/.
</p>


<h3>Value</h3>

<p>An object with S3 Class &quot;FRESHD&quot;.
</p>
<table>
<tr><td><code>...</code></td>
<td>
<p>A <code class="reqn">p</code> vector containing the maximin aggregated parameter estimates.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adam Lund, Benjamin Stephens, Gael Guennebaud, Angelo Furfaro, Luca Di Gaspero
</p>
<p>Maintainer: Adam Lund, <a href="mailto:adam.lund@math.ku.dk">adam.lund@math.ku.dk</a>
</p>


<h3>References</h3>

<p>Buhlmann, Peter and Meinshausen, Nicolai (2016). Magging: maximin aggregation for
inhomogeneous large-scale data. Proceedings of the IEEE, 1, 104, 126-135
</p>
<p>D. Goldfarb, A. Idnani. A numerically stable dual method for solving strictly
convex quadratic programs (1983). Mathematical Programming, 27,  1-33.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##size of example
set.seed(42)
G &lt;- 15; n &lt;- c(50, 20, 13); p &lt;- c(7, 5, 4)
nlambda &lt;- 10

##marginal design matrices (Kronecker components)
x &lt;- list()
for(i in 1:length(n)){
x[[i]] &lt;- matrix(rnorm(n[i] * p[i], 0, 1), n[i], p[i])
}

##common features and effects
common_features &lt;- rbinom(prod(p), 1, 0.1)
common_effects &lt;- rnorm(prod(p), 0, 1) * common_features
system.time({
##group response and fit
lambda &lt;- exp(seq(-1, -4, length.out = nlambda))
magbeta &lt;- matrix(0, prod(p), nlambda)
B &lt;- array(NA, c(prod(p), G, nlambda))
y &lt;- array(NA, c(n, G))
for(g in 1:G){
bg &lt;- rnorm(prod(p), 0, 0.1) * (1 - common_features) + common_effects
Bg &lt;- array(bg, p)
mu &lt;- RH(x[[3]], RH(x[[2]], RH(x[[1]], Bg)))
y[,,, g] &lt;- array(rnorm(prod(n)), dim = n) + mu
B[, g, ] &lt;- glamlasso::glamlasso(x, y[,,, g], lambda = lambda)$coef
}
})

##maximin aggregation for all lambdas (models)
for(l in 1:dim(B)[3]){
magbeta[, l] &lt;- magging(B[, , l])
}

##estimated common effects for specific lambda
modelno &lt;- 10
betafit &lt;- magbeta[, modelno]
plot(common_effects, type = "h", ylim = range(betafit, common_effects), col = "red")
lines(betafit, type = "h")

</code></pre>

<hr>
<h2 id='maximin'>Maximin signal estimation</h2><span id='topic+maximin'></span><span id='topic+FRESHD'></span>

<h3>Description</h3>

<p>Efficient procedure for solving the maximin estimation problem 
with identical design across groups, see (Lund, 2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maximin(y,
        x,
        penalty = "lasso", 
        alg ="aradmm",
        kappa = 0.99,
        nlambda = 30,
        lambda_min_ratio = 1e-04,
        lambda = NULL,
        penalty_factor = NULL,
        standardize = TRUE,
        tol = 1e-05,
        maxiter = 1000,
        delta = 1,
        gamma = 1,
        eta = 0.1,
        aux_par = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maximin_+3A_y">y</code></td>
<td>
<p>Array of size <code class="reqn">n_1 \times\cdots\times n_d \times G</code> containing
the response values.</p>
</td></tr>
<tr><td><code id="maximin_+3A_x">x</code></td>
<td>
<p>Either i) the design matrix, ii) a list containing the Kronecker
components (2 or 3) if  the design matrix has Kronecker structure or iii) a 
string indicating the name of the wavelet to use (see <code><a href="#topic+wt">wt</a></code> for options)</p>
</td></tr>
<tr><td><code id="maximin_+3A_penalty">penalty</code></td>
<td>
<p>string specifying the penalty type. Possible values are
<code>"lasso"</code>.</p>
</td></tr>
<tr><td><code id="maximin_+3A_alg">alg</code></td>
<td>
<p>string specifying the optimization algorithm. Possible values are
<code>"admm", "aradmm", "tos", "tosacc"</code>.</p>
</td></tr>
<tr><td><code id="maximin_+3A_kappa">kappa</code></td>
<td>
<p>Strictly positive float controlling the maximum sparsity in the 
solution. Only used with  ADMM type algorithms. Should be between 0 and 1.</p>
</td></tr>
<tr><td><code id="maximin_+3A_nlambda">nlambda</code></td>
<td>
<p>Positive integer giving the number of <code>lambda</code> values.
Used when lambda is not specified.</p>
</td></tr>
<tr><td><code id="maximin_+3A_lambda_min_ratio">lambda_min_ratio</code></td>
<td>
<p>strictly positive float giving the smallest value for
<code>lambda</code>, as a fraction of <code class="reqn">\lambda_{max}</code>; the (data dependent) 
smallest value for which all coefficients are zero. Used when lambda is not 
specified.</p>
</td></tr>
<tr><td><code id="maximin_+3A_lambda">lambda</code></td>
<td>
<p>Sequence of strictly positive floats used as penalty parameters.</p>
</td></tr>
<tr><td><code id="maximin_+3A_penalty_factor">penalty_factor</code></td>
<td>
<p>A vector of length <code class="reqn">p</code> containing positive floats that are 
multiplied with each element in <code>lambda</code> to allow differential penalization 
on the coefficients. For tensor models an array of size <code class="reqn">p_1 \times \cdots \times p_d</code>.</p>
</td></tr>
<tr><td><code id="maximin_+3A_standardize">standardize</code></td>
<td>
<p>Boolean indicating if response <code>y</code> should be scaled. 
Default is TRUE to avoid numerical problems.</p>
</td></tr>
<tr><td><code id="maximin_+3A_tol">tol</code></td>
<td>
<p>Strictly positive float controlling the convergence tolerance.</p>
</td></tr>
<tr><td><code id="maximin_+3A_maxiter">maxiter</code></td>
<td>
<p>Positive integer giving the maximum number of iterations
allowed for each <code>lambda</code> value.</p>
</td></tr>
<tr><td><code id="maximin_+3A_delta">delta</code></td>
<td>
<p>Positive float controlling the step size in the algorithm.</p>
</td></tr>
<tr><td><code id="maximin_+3A_gamma">gamma</code></td>
<td>
<p>Positive float controlling the relaxation parameter in the 
algorithm. Should be between 0 and 2.</p>
</td></tr>
<tr><td><code id="maximin_+3A_eta">eta</code></td>
<td>
<p>Scaling parameter for the step size in the accelerated TOS algorithm. 
Should be between 0 and 1.</p>
</td></tr>
<tr><td><code id="maximin_+3A_aux_par">aux_par</code></td>
<td>
<p>Auxiliary parameters for the algorithms.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code class="reqn">n</code> heterogeneous data points divided into <code class="reqn">G</code> equal sized
groups with <code class="reqn">m&lt;n</code> data points in each, let <code class="reqn">y_g=(y_{g,1},\ldots,y_{g,m})</code>
denote the vector  of observations in group <code class="reqn">g</code>. For a <code class="reqn">m\times p</code>
design matrix <code class="reqn">X</code> consider the model
</p>
<p style="text-align: center;"><code class="reqn">y_g=Xb_g+\epsilon_g</code>
</p>

<p>for <code class="reqn">b_g</code> a random group specific coefficient vector and <code class="reqn">\epsilon_g</code>
an error term, see Meinshausen and Buhlmann (2015). For the model above following 
Lund (2022) this package solves the maximin estimation problem
</p>
<p style="text-align: center;"><code class="reqn">\min_{\beta} -\hat V_g(\beta)) + \lambda\Vert\beta\Vert_1,\lambda \ge 0</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\hat V_g(\beta):=\frac{1}{n}(2\beta^\top X^\top y_g - \beta^\top X^\top X\beta),</code>
</p>

<p>is the empirical explained variance in group <code class="reqn">g</code>. See <cite>Lund, 2022</cite>
for more details and references.
</p>
<p>The package solves the problem using different algorithms depending on <code class="reqn">X</code>:
</p>
<p>i) If <code class="reqn">X</code> is orthogonal (e.g. the inverse wavelet transform) either
an ADMM algorithm (standard or relaxed) or an adaptive relaxed
ADMM (ARADMM) with auto tuned step size is used, see Xu et al (2017).
</p>
<p>ii) For general <code class="reqn">X</code>, a three operator splitting (TOS) algorithm
is implemented, see Damek and Yin (2017). Note if  the design is 
tensor structured, <code class="reqn">X = \bigotimes_{i=1}^d X_i</code> for <code class="reqn">d\in\{1, 2,3\}</code>, 
the procedure  accepts a list containing the tensor components (matrices).
</p>


<h3>Value</h3>

<p>An object with S3 Class &quot;FRESHD&quot;.
</p>
<table>
<tr><td><code>spec</code></td>
<td>
<p>A string indicating the array dimension (1, 2 or 3) and the penalty.</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>A <code class="reqn">p_1\cdots p_d \times</code> <code>nlambda</code> matrix containing the
estimates of the model coefficients (<code>beta</code>) for each <code>lambda</code>-value.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>A vector containing the sequence of penalty values used in the
estimation procedure.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of nonzero coefficients for each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>dimcoef</code></td>
<td>
<p>A vector giving the dimension of the model coefficient array
<code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>dimobs</code></td>
<td>
<p>A vector giving the dimension of the observation (response) array <code>Y</code>.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Integer indicating the dimension of of the array model. Equal to 1
for non array.</p>
</td></tr>
<tr><td><code>wf</code></td>
<td>
<p>A string indicating the wavelet name if used.</p>
</td></tr>
<tr><td><code>diagnostics</code></td>
<td>
<p>A list where item <code>iter</code> is a vector containing  the 
number of iterations for each <code>lambda</code> value for which the algorithm 
converged. Item <code>stop_maxiter</code> is 1 if maximum iterations is reached 
otherwise zero. Item <code>stop_sparse</code> is 1 if  maximum sparsity is reached 
otherwise zero.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adam Lund
</p>
<p>Maintainer: Adam Lund, <a href="mailto:adam.lund@math.ku.dk">adam.lund@math.ku.dk</a>
</p>


<h3>References</h3>

<p>Lund, Adam (2022). Fast Robust Signal Estimation for Heterogeneous data.
<em>In preparation</em>.
</p>
<p>Meinshausen, N and P. Buhlmann (2015). Maximin effects in inhomogeneous large-scale data.
<em>The Annals of Statistics</em>. 43, 4, 1801-1830.
</p>
<p>Davis, Damek and Yin, Wotao, (2017). A three-operator splitting scheme and its
optimization applications. <em>Set-valued and variational analysis</em>. 25, 4,
829-858.
</p>
<p>Xu, Zheng and Figueiredo, Mario AT and Yuan, Xiaoming and Studer, Christoph and Goldstein, Tom
(2017). Adaptive relaxed admm: Convergence theory and practical implementation.
<em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>
7389-7398.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## general 3d tensor design matrix
set.seed(42)
G &lt;- 20; n &lt;- c(65, 26, 13)*3; p &lt;- c(13, 5, 4)*3
sigma &lt;- 1

##marginal design matrices (Kronecker components)
x &lt;- list()
for(i in 1:length(n)){x[[i]] &lt;- matrix(rnorm(n[i] * p[i], 0, sigma), n[i], p[i])}

##common features and effects
common_features &lt;- rbinom(prod(p), 1, 0.1)
common_effects &lt;- rnorm(prod(p), 0, 0.1) * common_features

##simulate group response
y &lt;- array(NA, c(n, G))
for(g in 1:G){
bg &lt;- rnorm(prod(p), 0, 0.1) * (1 - common_features) + common_effects
Bg &lt;- array(bg, p)
mu &lt;- RH(x[[3]], RH(x[[2]], RH(x[[1]], Bg)))
y[,,, g] &lt;- array(rnorm(prod(n), 0, var(mu)), dim = n) + mu
}

##fit model for range of lambda
system.time(fit &lt;- maximin(y, x, penalty = "lasso", alg = "tosacc"))

##estimated common effects for specific lambda
modelno &lt;- 10
betafit &lt;- fit$coef[, modelno]
plot(common_effects, type = "h", ylim = range(betafit, common_effects), col = "red")
lines(betafit, type = "h")

##size of example
set.seed(42)
G &lt;- 50; p &lt;- n &lt;- c(2^6, 2^5, 2^6);

##common features and effects
common_features &lt;- rbinom(prod(p), 1, 0.1) #sparsity of comm. feat.
common_effects &lt;- rnorm(prod(p), 0, 1) * common_features

##group response
y &lt;- array(NA, c(n, G))
for(g in 1:G){
bg &lt;- rnorm(prod(p), 0, 0.1) * (1 - common_features) + common_effects
Bg &lt;- array(bg, p)
mu &lt;- iwt(Bg)
y[,,, g] &lt;- array(rnorm(prod(n),0, 0.5), dim = n) + mu
}

##orthogonal wavelet design with 1d data
G = 50; N1 = 2^10; p = 101; J = 2; amp = 20; sigma2 = 10
y &lt;- matrix(0, N1, G)
z &lt;- seq(0, 2, length.out = N1)
sig &lt;- cos(10 * pi * z) + 1.5 * sin(5 * pi * z)

for (i in 1:G){
freqs &lt;- sample(1:100, size = J, replace = TRUE)
y[, i] &lt;- sig * 2 + rnorm(N1, sd = sqrt(sigma2))
for (j in 1:J){
y[, i] &lt;- y[, i] + amp * sin(freqs[j] * pi * z + runif(1, -pi, pi))
}
}

system.time(fit &lt;- maximin(y, "la8", alg = "aradmm", kappa = 0.9))
mmy &lt;- predict(fit, "la8")
plot(mmy[,1], type = "l")
lines(sig, col = "red")

</code></pre>

<hr>
<h2 id='predict.FRESHD'>Make Prediction From a FRESHD Object</h2><span id='topic+predict.FRESHD'></span><span id='topic+FRESHD_predict'></span><span id='topic+FRESHD.predict'></span>

<h3>Description</h3>

<p>Given covariate data this function computes the linear predictors
based on the estimated model coefficients in an object produced by the function
<code>maximin</code> or <code>magging</code>. Note that the data can be supplied in two different
formats:
i) for wavelet based models as a string indicating the wavelet used to produce
the model object.
ii) for  models with custom design as a list of one, two or three Kronecker component
matrices each of size <code class="reqn">n_i' \times p_i, i = 1, 2, 3</code>. Note <code>x</code> will
typically be the original design (covariate data) that was used to produce <code>object</code>
using <code>maximin</code> or <code>magging</code> so <code class="reqn">n_i'</code> is the number of
marginal data points in the <code class="reqn">i</code>th dimension i.e. <code class="reqn">n_i' = n_i</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FRESHD'
predict(object, x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.FRESHD_+3A_object">object</code></td>
<td>
<p>An object of class FRESHD, produced with <code>maximin</code> or <code>magging</code>.</p>
</td></tr>
<tr><td><code id="predict.FRESHD_+3A_x">x</code></td>
<td>
<p>An object that should be like the input to the call
that produced <code>object</code>. For models with custom design a list like the one
supplied to produce <code>object</code> and for a wavelet design
the name of the wavelet used to produce <code>object</code>.</p>
</td></tr>
<tr><td><code id="predict.FRESHD_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>x</code> is a string indicating a wavelet an array of the same size
as the input data used to produce <code>object</code>. Otherwise an array of size
<code class="reqn">n'_1 \times \cdots \times n'_d</code>, with <code class="reqn">d\in \{1,2,3\}</code>.
</p>


<h3>Author(s)</h3>

<p>Adam Lund
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##size of example
set.seed(42)
G = 50; N1 = 2^10; p = 101; J = 3; amp = 20; sigma2 = 10
y &lt;- matrix(0, N1, G)
z &lt;- seq(0, 2, length.out = N1)
sig &lt;- cos(10 * pi * z) + 1.5 * sin(5 * pi * z)
for (i in 1:G){
freqs &lt;- sample(1:100, size = J, replace = TRUE)
y[, i] &lt;- sig * 2 + rnorm(N1, sd = sqrt(sigma2))
for (j in 1:J){
y[, i] &lt;- y[, i] + amp * sin(freqs[j] * pi * z + runif(1, -pi, pi))
}
}
system.time(fitmm &lt;- maximin(y, "la8", alg = "aradmm", kappa = 0.95))
mmy &lt;- predict(fitmm, "la8")
plot(mmy[, 2], type = "l")
lines(sig, col = "red")

</code></pre>

<hr>
<h2 id='print.FRESHD'>Print Function for objects of Class FRESHD</h2><span id='topic+print.FRESHD'></span>

<h3>Description</h3>

<p>This function will print some information about the FRESHD object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FRESHD'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.FRESHD_+3A_x">x</code></td>
<td>
<p>a FRESHD object</p>
</td></tr>
<tr><td><code id="print.FRESHD_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A three-column data.frame with columns 'sparsity', 'Df' and 'lambda'.
The 'Df' column is the number of nonzero coefficients and 'sparsity' is the 
percentage   of zeros in the solution.
</p>


<h3>Value</h3>

<p>The data.frame above is silently returned
</p>


<h3>Author(s)</h3>

<p>Adam Lund
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##size of example
set.seed(42)
G &lt;- 50; n &lt;- c(65, 26, 13); p &lt;- c(13, 5, 4)
sigma &lt;-0.1
nlambda =30
##marginal design matrices (Kronecker components)
x &lt;- list()
for(i in 1:length(n)){x[[i]] &lt;- matrix(rnorm(n[i] * p[i],0,sigma), n[i], p[i])}

##common features and effects
common_features &lt;- rbinom(prod(p), 1, 0.1)
common_effects &lt;- rnorm(prod(p), 0, 0.1) * common_features

##group response and fit
lambda &lt;- exp(seq(0, -5, length.out = nlambda))
B &lt;- array(NA, c(prod(p), nlambda, G))
y &lt;- array(NA, c(n, G))
for(g in 1:G){
bg &lt;- rnorm(prod(p), 0, 0.1) * (1 - common_features) + common_effects
Bg &lt;- array(bg, p)
mu &lt;- RH(x[[3]], RH(x[[2]], RH(x[[1]], Bg)))
y[,,, g] &lt;- array(rnorm(prod(n), 0, var(mu)), dim = n) + mu
}

##fit model for range of lambda
system.time(fit &lt;- maximin(y, x, penalty = "lasso", alg = "tos"))
Betahat &lt;- fit$coef

##estimated common effects for specific lambda
modelno &lt;- 20;
m &lt;- min(Betahat[, modelno], common_effects)
M &lt;- max(Betahat[, modelno], common_effects)
plot(common_effects, type = "h", ylim = c(m, M), col = "red")
lines(Betahat[, modelno], type = "h")

</code></pre>

<hr>
<h2 id='RH'>The Rotated H-transform of a 3d Array by a Matrix</h2><span id='topic+RH'></span><span id='topic+FRESHD_RH'></span><span id='topic+Rotate'></span><span id='topic+H'></span>

<h3>Description</h3>

<p>This function is an implementation of the <code class="reqn">\rho</code>-operator found in
<cite>Currie et al 2006</cite>. It forms the basis of the GLAM arithmetic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RH(M, A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RH_+3A_m">M</code></td>
<td>
<p>a <code class="reqn">n \times p_1</code> matrix.</p>
</td></tr>
<tr><td><code id="RH_+3A_a">A</code></td>
<td>
<p>a 3d array of size <code class="reqn">p_1 \times p_2 \times p_3</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details see <cite>Currie et al 2006</cite>. Note that this particular implementation
is not used in the  routines underlying the optimization procedure.
</p>


<h3>Value</h3>

<p>A 3d array of size <code class="reqn">p_2 \times p_3 \times n</code>.
</p>


<h3>Author(s)</h3>

<p>Adam Lund
</p>


<h3>References</h3>

<p>Currie, I. D., M. Durban, and P. H. C. Eilers (2006). Generalized linear
array models with applications to multidimensional smoothing.
<em>Journal of the Royal Statistical Society. Series B</em>. 68, 259-280. url = http://dx.doi.org/10.1111/j.1467-9868.2006.00543.x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n1 &lt;- 65; n2 &lt;- 26; n3 &lt;- 13; p1 &lt;- 13; p2 &lt;- 5; p3 &lt;- 4

##marginal design matrices (Kronecker components)
X1 &lt;- matrix(rnorm(n1 * p1), n1, p1)
X2 &lt;- matrix(rnorm(n2 * p2), n2, p2)
X3 &lt;- matrix(rnorm(n3 * p3), n3, p3)

Beta &lt;- array(rnorm(p1 * p2 * p3, 0, 1), c(p1 , p2, p3))
max(abs(c(RH(X3, RH(X2, RH(X1, Beta)))) - kronecker(X3, kronecker(X2, X1)) %*% c(Beta)))

</code></pre>

<hr>
<h2 id='wt'>Discrete wavelet transform</h2><span id='topic+wt'></span>

<h3>Description</h3>

<p>This function performs a level J wavelet transform of the input
array (1d, 2d, or 3d) using the pyramid algorithm (Mallat 1989).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wt(x, wf = "la8", J = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wt_+3A_x">x</code></td>
<td>
<p>a 1, 2, or 3 dimensional data array. The size of each dimension must
be dyadic.</p>
</td></tr>
<tr><td><code id="wt_+3A_wf">wf</code></td>
<td>
<p>the type of wavelet family used. See R-package waveslim for options.</p>
</td></tr>
<tr><td><code id="wt_+3A_j">J</code></td>
<td>
<p>is the level (depth) of the decomposition. For default <code>NULL</code> the max
depth is used making  <code>wt(x)</code> equal to multiplying <code>x</code> with the
corresponding wavelet matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a C++/R wrapper function for a C implementation of the
discrete wavelet transform by Brandon Whitcher licensed under the BSD 3 license
https://cran.r-project.org/web/licenses/BSD_3_clause, see the Waveslim package;
Percival and Walden (2000); Gencay, Selcuk and Whitcher (2001).
</p>
<p>Given a data array (1d, 2d or 3d) with dyadic sizes this transform is computed
efficiently via the pyramid  algorithm see Mallat (1989).
</p>


<h3>Value</h3>

<table>
<tr><td><code>...</code></td>
<td>
<p>An array with dimensions equal to those of <code>x</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adam Lund, Brandon Whitcher
</p>


<h3>References</h3>

<p>Gencay, R., F. Selcuk and B. Whitcher (2001) An Introduction to Wavelets and
Other Filtering Methods in Finance and Economics, Academic Press.
</p>
<p>Mallat, S. G. (1989) A theory for multiresolution signal decomposition: the
wavelet representation, IEEE Transactions on Pattern Analysis and Machine
Intelligence, 11, No. 7, 674-693.
</p>
<p>Percival, D. B. and A. T. Walden (2000) Wavelet Methods for Time Series
Analysis, Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###1d
x &lt;- as.matrix(rnorm(2^3))
range(x - iwt(wt(x)))

###2d
x &lt;- matrix(rnorm(2^(3 + 4)), 2^3, 2^4)
range(x - iwt(wt(x)))

###3d
x &lt;- array(rnorm(2^(3 + 4 + 5)), c(2^3, 2^4, 2^5))
range(x - iwt(wt(x)))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
