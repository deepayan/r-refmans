<!DOCTYPE html><html><head><title>Help for package fastshap</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fastshap}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#explain'><p>Fast approximate Shapley values</p></a></li>
<li><a href='#fastshap-package'><p>fastshap: Fast Approximate Shapley Values</p></a></li>
<li><a href='#gen_friedman'><p>Friedman benchmark data</p></a></li>
<li><a href='#titanic'><p>Survival of Titanic passengers</p></a></li>
<li><a href='#titanic_mice'><p>Survival of Titanic passengers</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Approximate Shapley Values</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes fast (relative to other implementations) approximate 
    Shapley values for any supervised learning model. Shapley values help to 
    explain the predictions from any black box model using ideas from game 
    theory; see Strumbel and Kononenko (2014) &lt;<a href="https://doi.org/10.1007%2Fs10115-013-0679-x">doi:10.1007/s10115-013-0679-x</a>&gt; 
    for details.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bgreenwell/fastshap">https://github.com/bgreenwell/fastshap</a>,
<a href="https://bgreenwell.github.io/fastshap/">https://bgreenwell.github.io/fastshap/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bgreenwell/fastshap/issues">https://github.com/bgreenwell/fastshap/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>foreach, Rcpp (&ge; 1.0.1), utils</td>
</tr>
<tr>
<td>Enhances:</td>
<td>lightgbm, xgboost</td>
</tr>
<tr>
<td>Suggests:</td>
<td>AmesHousing, covr, earth, knitr, ranger, rmarkdown, shapviz
(&ge; 0.8.0), tibble, tinytest (&ge; 1.4.1)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-22 21:28:23 UTC; bgreenwell</td>
</tr>
<tr>
<td>Author:</td>
<td>Brandon Greenwell <a href="https://orcid.org/0000-0002-8120-0084"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brandon Greenwell &lt;greenwell.brandon@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-22 22:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='explain'>Fast approximate Shapley values</h2><span id='topic+explain'></span><span id='topic+explain.default'></span><span id='topic+explain.lm'></span><span id='topic+explain.xgb.Booster'></span><span id='topic+explain.lgb.Booster'></span>

<h3>Description</h3>

<p>Compute fast (approximate) Shapley values for a set of features using the
Monte Carlo algorithm described in Strumbelj and Igor (2014). An efficient
algorithm for tree-based models, commonly referred to as Tree SHAP, is also
supported for <a href="https://cran.r-project.org/package=lightgbm">lightgbm</a> and
<a href="https://cran.r-project.org/package=xgboost">xgboost</a> models; see Lundberg
et. al. (2020) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain(object, ...)

## Default S3 method:
explain(
  object,
  feature_names = NULL,
  X = NULL,
  nsim = 1,
  pred_wrapper = NULL,
  newdata = NULL,
  adjust = FALSE,
  baseline = NULL,
  shap_only = TRUE,
  parallel = FALSE,
  ...
)

## S3 method for class 'lm'
explain(
  object,
  feature_names = NULL,
  X,
  nsim = 1,
  pred_wrapper,
  newdata = NULL,
  adjust = FALSE,
  exact = FALSE,
  baseline = NULL,
  shap_only = TRUE,
  parallel = FALSE,
  ...
)

## S3 method for class 'xgb.Booster'
explain(
  object,
  feature_names = NULL,
  X = NULL,
  nsim = 1,
  pred_wrapper,
  newdata = NULL,
  adjust = FALSE,
  exact = FALSE,
  baseline = NULL,
  shap_only = TRUE,
  parallel = FALSE,
  ...
)

## S3 method for class 'lgb.Booster'
explain(
  object,
  feature_names = NULL,
  X = NULL,
  nsim = 1,
  pred_wrapper,
  newdata = NULL,
  adjust = FALSE,
  exact = FALSE,
  baseline = NULL,
  shap_only = TRUE,
  parallel = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explain_+3A_object">object</code></td>
<td>
<p>A fitted model object (e.g., a <code><a href="ranger.html#topic+ranger">ranger::ranger()</a></code>,
<code><a href="xgboost.html#topic+xgb.train">xgboost::xgboost()</a></code>, or <code><a href="earth.html#topic+earth">earth::earth()</a></code> object, to name
a few).</p>
</td></tr>
<tr><td><code id="explain_+3A_...">...</code></td>
<td>
<p>Additional optional arguments to be passed on to
<code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code> whenever <code>parallel = TRUE</code>. For example, you may need
to supply additional packages that the parallel task depends on via the
<code>.packages</code> argument to <code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code>. <strong>NOTE:</strong>
<code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code>'s <code>.combine</code> argument is already set internally by
<code>explain()</code>, so passing it via the <code>...</code> argument would likely result in an
error.</p>
</td></tr>
<tr><td><code id="explain_+3A_feature_names">feature_names</code></td>
<td>
<p>Character string giving the names of the predictor
variables (i.e., features) of interest. If <code>NULL</code> (default) they will be
taken from the column names of <code>X</code>.</p>
</td></tr>
<tr><td><code id="explain_+3A_x">X</code></td>
<td>
<p>A matrix-like R object (e.g., a data frame or matrix) containing
ONLY the feature columns from the training data (or suitable background data
set). <strong>NOTE:</strong> This argument is required whenever <code>exact = FALSE</code>.</p>
</td></tr>
<tr><td><code id="explain_+3A_nsim">nsim</code></td>
<td>
<p>The number of Monte Carlo repetitions to use for estimating each
Shapley value (only used when <code>exact = FALSE</code>). Default is 1.
<strong>NOTE:</strong> To obtain the most accurate results, <code>nsim</code> should be set
as large as feasibly possible.</p>
</td></tr>
<tr><td><code id="explain_+3A_pred_wrapper">pred_wrapper</code></td>
<td>
<p>Prediction function that requires two arguments,
<code>object</code> and <code>newdata</code>. <strong>NOTE:</strong> This argument is required
whenever <code>exact = FALSE</code>. The output of this function should be
determined according to:
</p>

<dl>
<dt>Regression</dt><dd><p>A numeric vector of predicted outcomes.</p>
</dd>
<dt>Binary classification</dt><dd><p>A vector of predicted class probabilities
for the reference class.</p>
</dd>
<dt>Multiclass classification</dt><dd><p>A vector of predicted class probabilities
for the reference class.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="explain_+3A_newdata">newdata</code></td>
<td>
<p>A matrix-like R object (e.g., a data frame or matrix)
containing ONLY the feature columns for the observation(s) of interest; that
is, the observation(s) you want to compute explanations for. Default is
<code>NULL</code> which will produce approximate Shapley values for all the rows in
<code>X</code> (i.e., the training data).</p>
</td></tr>
<tr><td><code id="explain_+3A_adjust">adjust</code></td>
<td>
<p>Logical indicating whether or not to adjust the sum of the
estimated Shapley values to satisfy the <em>local accuracy</em> property; that is,
to equal the difference between the model's prediction for that sample and
the average prediction over all the training data (i.e., <code>X</code>). Default is
<code>FALSE</code> and setting to <code>TRUE</code> requires <code>nsim</code> &gt; 1.</p>
</td></tr>
<tr><td><code id="explain_+3A_baseline">baseline</code></td>
<td>
<p>Numeric baseline to use when adjusting the computed Shapley
values to achieve <em>local accuracy</em>. Adjusted Shapley values for a single
prediction (<code>fx</code>) will sum to the difference <code>fx - baseline</code>. Defaults to
<code>NULL</code>, which corresponds to the average predictions computed from <code>X</code>, and
zero otherwise (i.e., no additional predictions will be computed and the
baseline attribute of the output will be set to zero).</p>
</td></tr>
<tr><td><code id="explain_+3A_shap_only">shap_only</code></td>
<td>
<p>Logical indicating whether or not to include additional
output useful for plotting (i.e., <code>newdata</code> and the <code>baseline</code> value.). This
is convenient, for example, when using <code><a href="shapviz.html#topic+shapviz">shapviz::shapviz()</a></code> for plotting.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="explain_+3A_parallel">parallel</code></td>
<td>
<p>Logical indicating whether or not to compute the approximate
Shapley values in parallel across features; default is <code>FALSE</code>. <strong>NOTE:</strong>
setting <code>parallel = TRUE</code> requires setting up an appropriate (i.e.,
system-specific) <em>parallel backend</em> as described in the
<a href="https://cran.r-project.org/package=foreach">foreach</a>; for details, see
<code>vignette("foreach", package = "foreach")</code> in R.</p>
</td></tr>
<tr><td><code id="explain_+3A_exact">exact</code></td>
<td>
<p>Logical indicating whether to compute exact Shapley values.
Currently only available for <code><a href="stats.html#topic+lm">stats::lm()</a></code>,
<code><a href="xgboost.html#topic+xgb.train">xgboost::xgboost()</a></code>, and <code><a href="lightgbm.html#topic+lightgbm">lightgbm::lightgbm()</a></code> objects.
Default is <code>FALSE</code>. Note that setting <code>exact = TRUE</code> will return
explanations for each of the <code><a href="stats.html#topic+terms">stats::terms()</a></code> in an
<code><a href="stats.html#topic+lm">stats::lm()</a></code> object. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>shap_only = TRUE</code> (the default), a matrix is returned with one
column for each feature specified in <code>feature_names</code> (if
<code>feature_names = NULL</code>, the default, there will
be one column for each feature in <code>X</code>) and one row for each observation
in <code>newdata</code> (if <code>newdata = NULL</code>, the default, there will be one
row for each observation in <code>X</code>). Additionally, the returned matrix will
have an attribute called <code>"baseline"</code> containing the baseline value. If
<code>shap_only = FALSE</code>, then a list is returned with three components:
</p>

<ul>
<li> <p><code>shapley_values</code> - a matrix of Shapley values (as described above);
</p>
</li>
<li> <p><code>feature_values</code> - the corresponding feature values (for plotting with
<code><a href="shapviz.html#topic+shapviz">shapviz::shapviz()</a></code>);
</p>
</li>
<li> <p><code>baseline</code> - the corresponding baseline value (for plotting with
<code><a href="shapviz.html#topic+shapviz">shapviz::shapviz()</a></code>).
</p>
</li></ul>



<h3>Note</h3>

<p>Setting <code>exact = TRUE</code> with a linear model (i.e., an
<code><a href="stats.html#topic+lm">stats::lm()</a></code> or <code><a href="stats.html#topic+glm">stats::glm()</a></code> object) assumes that the
input features are independent. Also, setting <code>adjust = TRUE</code> is
experimental and we follow the same approach as in
<a href="https://github.com/shap/shap">shap</a>.
</p>


<h3>References</h3>

<p>Strumbelj, E., and Igor K. (2014). Explaining prediction models and
individual predictions with feature contributions. Knowledge and information
systems, 41(3), 647-665.
</p>
<p>Lundberg, S. M., Erion, G., Chen, H., DeGrave, A., Prutkin, J. M., Nair, B.,
Katz, R., Himmelfarb, J., Bansal, N., and Lee, Su-In (2020). From local
explanations to global understanding with explainable AI for trees.
Nature Machine Intelligence, 2(1), 2522â€“5839.
</p>


<h3>See Also</h3>

<p>You can find more examples (with larger and more realistic data
sets) on the <strong>fastshap</strong> GitHub repository:
<a href="https://github.com/bgreenwell/fastshap">https://github.com/bgreenwell/fastshap</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
# A projection pursuit regression (PPR) example
#

# Load the sample data; see ?datasets::mtcars for details
data(mtcars)

# Fit a projection pursuit regression model
fit &lt;- ppr(mpg ~ ., data = mtcars, nterms = 5)

# Prediction wrapper
pfun &lt;- function(object, newdata) {  # needs to return a numeric vector
  predict(object, newdata = newdata)  
}

# Compute approximate Shapley values using 10 Monte Carlo simulations
set.seed(101)  # for reproducibility
shap &lt;- explain(fit, X = subset(mtcars, select = -mpg), nsim = 10, 
                pred_wrapper = pfun)
head(shap)
</code></pre>

<hr>
<h2 id='fastshap-package'>fastshap: Fast Approximate Shapley Values</h2><span id='topic+fastshap'></span><span id='topic+fastshap-package'></span>

<h3>Description</h3>

<p>Computes fast (relative to other implementations) approximate Shapley values for any supervised learning model. Shapley values help to explain the predictions from any black box model using ideas from game theory; see Strumbel and Kononenko (2014) <a href="https://doi.org/10.1007/s10115-013-0679-x">doi:10.1007/s10115-013-0679-x</a> for details.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Brandon Greenwell <a href="mailto:greenwell.brandon@gmail.com">greenwell.brandon@gmail.com</a> (<a href="https://orcid.org/0000-0002-8120-0084">ORCID</a>)
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/bgreenwell/fastshap">https://github.com/bgreenwell/fastshap</a>
</p>
</li>
<li> <p><a href="https://bgreenwell.github.io/fastshap/">https://bgreenwell.github.io/fastshap/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/bgreenwell/fastshap/issues">https://github.com/bgreenwell/fastshap/issues</a>
</p>
</li></ul>


<hr>
<h2 id='gen_friedman'>Friedman benchmark data</h2><span id='topic+gen_friedman'></span>

<h3>Description</h3>

<p>Simulate data from the Friedman 1 benchmark problem. These data were
originally described in Friedman (1991) and Breiman (1996). For details, see
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman1.html">sklearn.datasets.make_friedman1</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_friedman(
  n_samples = 100,
  n_features = 10,
  n_bins = NULL,
  sigma = 0.1,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen_friedman_+3A_n_samples">n_samples</code></td>
<td>
<p>Integer specifying the number of samples (i.e., rows) to
generate. Default is 100.</p>
</td></tr>
<tr><td><code id="gen_friedman_+3A_n_features">n_features</code></td>
<td>
<p>Integer specifying the number of features to generate.
Default is 10.</p>
</td></tr>
<tr><td><code id="gen_friedman_+3A_n_bins">n_bins</code></td>
<td>
<p>Integer specifying the number of (roughly) equal sized bins to
split the response into. Default is <code>NULL</code> for no binning. Setting to
a positive integer &gt; 1 effectively turns this into a classification problem
where <code>n_bins</code> gives the number of classes.</p>
</td></tr>
<tr><td><code id="gen_friedman_+3A_sigma">sigma</code></td>
<td>
<p>Numeric specifying the standard deviation of the noise.</p>
</td></tr>
<tr><td><code id="gen_friedman_+3A_seed">seed</code></td>
<td>
<p>Integer specifying the random seed. If <code>NULL</code> (the default)
the results will be different each time the function is run.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is mostly used for internal testing.
</p>


<h3>References</h3>

<p>Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages 123-140.
</p>
<p>Friedman, Jerome H. (1991) Multivariate adaptive regression splines. The
Annals of Statistics 19 (1), pages 1-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gen_friedman()
</code></pre>

<hr>
<h2 id='titanic'>Survival of Titanic passengers</h2><span id='topic+titanic'></span>

<h3>Description</h3>

<p>A data set containing the survival outcome, passenger class, age, sex, and
the number of family members for a large number of passengers aboard the
ill-fated Titanic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>titanic
</code></pre>


<h3>Format</h3>

<p>A data frame with 1309 observations on the following 6 variables:
</p>

<dl>
<dt>survived</dt><dd><p>binary with levels <code>"yes"</code> for survived and <code>"no"</code>
otherwise;</p>
</dd>
<dt>pclass</dt><dd><p>integer giving the corresponding passenger (i.e., ticket)
class with values 1&ndash;3;</p>
</dd>
<dt>age</dt><dd><p>the age in years of the corresponding passenger (with 263
missing values);</p>
</dd>
<dt>sex</dt><dd><p>factor giving the sex of each passenger with levels
<code>"male"</code> and <code>"female"</code>;</p>
</dd>
<dt>sibsp</dt><dd><p>integer giving the number of siblings/spouses aboard for each
passenger (ranges from 0&ndash;8);</p>
</dd>
<dt>parch</dt><dd><p>integer giving the number of parents/children aboard for each
passenger (ranges from 0&ndash;9).</p>
</dd>
</dl>



<h3>Note</h3>

<p>As mentioned in the column description, <code>age</code> contains 263 <code>NA</code>s (or
missing values). For a complete version (or versions) of the data set, see
<a href="#topic+titanic_mice">titanic_mice</a>.
</p>


<h3>Source</h3>

<p><a href="https://hbiostat.org/data/">https://hbiostat.org/data/</a>.
</p>

<hr>
<h2 id='titanic_mice'>Survival of Titanic passengers</h2><span id='topic+titanic_mice'></span>

<h3>Description</h3>

<p>The <a href="#topic+titanic">titanic</a> data set contains 263 missing values (i.e., <code>NA</code>'s) in the
<code>age</code> column. This version of the data contains imputed values for the
<code>age</code> column using <em>multivariate imputation by chained equations</em> via
the <a href="https://cran.r-project.org/package=mice">mice</a> package. Consequently,
this is a list containing 11 imputed versions of the observations containd
in the <a href="#topic+titanic">titanic</a> data frame; each completed data sets has the same dimension
and column structure as <a href="#topic+titanic">titanic</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>titanic_mice
</code></pre>


<h3>Format</h3>

<p>An object of class <code>mild</code> (inherits from <code>list</code>) of length 21.
</p>


<h3>Source</h3>

<p>Greenwell, Brandon M. (2022). Tree-Based Methods for Statistical Learning in
R. CRC Press.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
