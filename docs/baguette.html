<!DOCTYPE html><html><head><title>Help for package baguette</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {baguette}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bagger'><p>Bagging functions</p></a></li>
<li><a href='#baguette-package'><p>baguette: Efficient Model Functions for Bagging</p></a></li>
<li><a href='#class_cost'><p>Cost parameter for minority class</p></a></li>
<li><a href='#control_bag'><p>Controlling the bagging process</p></a></li>
<li><a href='#nnet_imp_garson'><p>Garson Importance Scores for neural Networks</p></a></li>
<li><a href='#predict.bagger'><p>Predictions from a bagged model</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#var_imp.bagger'><p>Obtain variable importance scores</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Efficient Model Functions for Bagging</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Tree- and rule-based models can be bagged
    (&lt;<a href="https://doi.org/10.1007%2FBF00058655">doi:10.1007/BF00058655</a>&gt;) using this package and their predictions
    equations are stored in an efficient format to reduce the model
    objects size and speed.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://baguette.tidymodels.org">https://baguette.tidymodels.org</a>,
<a href="https://github.com/tidymodels/baguette">https://github.com/tidymodels/baguette</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tidymodels/baguette/issues">https://github.com/tidymodels/baguette/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>parsnip (&ge; 1.0.0), R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>butcher, C50, dials, dplyr, furrr, generics, hardhat (&ge;
1.1.0), magrittr, purrr, rlang, rpart, rsample, tibble, tidyr,
utils, withr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>AmesHousing, covr, earth, modeldata, nnet, recipes,
rmarkdown, spelling, testthat (&ge; 3.0.0), yardstick</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>tidyverse/tidytemplate</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-13 21:46:41 UTC; max</td>
</tr>
<tr>
<td>Author:</td>
<td>Max Kuhn <a href="https://orcid.org/0000-0003-2402-136X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Posit Software, PBC [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Max Kuhn &lt;max@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-13 23:36:47 UTC</td>
</tr>
</table>
<hr>
<h2 id='bagger'>Bagging functions</h2><span id='topic+bagger'></span><span id='topic+bagger.default'></span><span id='topic+bagger.data.frame'></span><span id='topic+bagger.matrix'></span><span id='topic+bagger.formula'></span><span id='topic+bagger.recipe'></span>

<h3>Description</h3>

<p>General suite of bagging functions for several models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bagger(x, ...)

## Default S3 method:
bagger(x, ...)

## S3 method for class 'data.frame'
bagger(
  x,
  y,
  weights = NULL,
  base_model = "CART",
  times = 11L,
  control = control_bag(),
  cost = NULL,
  ...
)

## S3 method for class 'matrix'
bagger(
  x,
  y,
  weights = NULL,
  base_model = "CART",
  times = 11L,
  control = control_bag(),
  cost = NULL,
  ...
)

## S3 method for class 'formula'
bagger(
  formula,
  data,
  weights = NULL,
  base_model = "CART",
  times = 11L,
  control = control_bag(),
  cost = NULL,
  ...
)

## S3 method for class 'recipe'
bagger(
  x,
  data,
  base_model = "CART",
  times = 11L,
  control = control_bag(),
  cost = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bagger_+3A_x">x</code></td>
<td>
<p>A data frame, matrix, or recipe (depending on the method being used).</p>
</td></tr>
<tr><td><code id="bagger_+3A_...">...</code></td>
<td>
<p>Optional arguments to pass to the base model function.</p>
</td></tr>
<tr><td><code id="bagger_+3A_y">y</code></td>
<td>
<p>A numeric or factor vector of outcomes. Categorical outcomes (i.e
classes) should be represented as factors, not integers.</p>
</td></tr>
<tr><td><code id="bagger_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of non-negative case weights. These values are
not used during bootstrap resampling.</p>
</td></tr>
<tr><td><code id="bagger_+3A_base_model">base_model</code></td>
<td>
<p>A single character value for the model being bagged. Possible
values are &quot;CART&quot;, &quot;MARS&quot;, &quot;nnet&quot;, and &quot;C5.0&quot; (classification only).</p>
</td></tr>
<tr><td><code id="bagger_+3A_times">times</code></td>
<td>
<p>A single integer greater than 1 for the maximum number of bootstrap
samples/ensemble members (some model fits might fail).</p>
</td></tr>
<tr><td><code id="bagger_+3A_control">control</code></td>
<td>
<p>A list of options generated by <code>control_bag()</code>.</p>
</td></tr>
<tr><td><code id="bagger_+3A_cost">cost</code></td>
<td>
<p>A non-negative scale (for two class problems) or a cost matrix.</p>
</td></tr>
<tr><td><code id="bagger_+3A_formula">formula</code></td>
<td>
<p>An object of class &quot;formula&quot; (or one that can be coerced to
that class): a symbolic description of the model to be fitted. Note that
this package does not support multivariate outcomes and that, if some
predictors are factors, dummy variables will <em>not</em> be created unless by the
underlying model function.</p>
</td></tr>
<tr><td><code id="bagger_+3A_data">data</code></td>
<td>
<p>A data frame containing the variables used in the formula or
recipe.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>bagger()</code> fits separate models to bootstrap samples. The
prediction function for each model object is encoded in an R expression and
the original model object is discarded. When making predictions, each
prediction formula is evaluated on the new data and aggregated using the
mean.
</p>
<p>Variable importance scores are calculated using implementations in each
package. When requested, the results are in a tibble with column names
<code>term</code> (the predictor), <code>value</code> (the importance score), and <code>used</code> (the
percentage of times that the variable was in the prediction equation).
</p>
<p>The models can be fit in parallel using the <span class="pkg">future</span> package. The
enable parallelism, use the <code>future::plan()</code> function to declare <em>how</em> the
computations should be distributed. Note that this will almost certainly
multiply the memory requirements required to fit the models.
</p>
<p>For neural networks, variable importance is calculated using the method
of Garson described in Gevrey <em>et al</em> (2003)
</p>


<h3>References</h3>

<p>Gevrey, M., Dimopoulos, I., and Lek, S. (2003). Review and
comparison of methods to study the contribution of variables in artificial
neural network models. Ecological Modelling, 160(3), 249-264.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(dplyr)

data(biomass, package = "modeldata")

biomass_tr &lt;-
  biomass %&gt;%
  dplyr::filter(dataset == "Training") %&gt;%
  dplyr::select(-dataset, -sample)

biomass_te &lt;-
  biomass %&gt;%
  dplyr::filter(dataset == "Testing") %&gt;%
  dplyr::select(-dataset, -sample)

# ------------------------------------------------------------------------------

ctrl &lt;- control_bag(var_imp = TRUE)

# ------------------------------------------------------------------------------

# `times` is low to make the examples run faster


set.seed(7687)
cart_bag &lt;- bagger(x = biomass_tr[, -6], y = biomass_tr$HHV,
                   base_model = "CART", times = 5, control = ctrl)
cart_bag

# ------------------------------------------------------------------------------
# Other interfaces

# Recipes can be used
biomass_rec &lt;-
  recipe(HHV ~ ., data = biomass_tr) %&gt;%
  step_pca(all_predictors())

set.seed(7687)
cart_pca_bag &lt;- bagger(biomass_rec, data = biomass_tr, base_model = "CART",
                       times = 5, control = ctrl)

cart_pca_bag

</code></pre>

<hr>
<h2 id='baguette-package'>baguette: Efficient Model Functions for Bagging</h2><span id='topic+baguette'></span><span id='topic+baguette-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Tree- and rule-based models can be bagged (<a href="https://doi.org/10.1007/BF00058655">doi:10.1007/BF00058655</a>) using this package and their predictions equations are stored in an efficient format to reduce the model objects size and speed.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Max Kuhn <a href="mailto:max@posit.co">max@posit.co</a> (<a href="https://orcid.org/0000-0003-2402-136X">ORCID</a>)
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Posit Software, PBC [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://baguette.tidymodels.org">https://baguette.tidymodels.org</a>
</p>
</li>
<li> <p><a href="https://github.com/tidymodels/baguette">https://github.com/tidymodels/baguette</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tidymodels/baguette/issues">https://github.com/tidymodels/baguette/issues</a>
</p>
</li></ul>


<hr>
<h2 id='class_cost'>Cost parameter for minority class</h2><span id='topic+class_cost'></span>

<h3>Description</h3>

<p>Used in <code>bag_treer()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>class_cost(range = c(0, 5), trans = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="class_cost_+3A_range">range</code></td>
<td>
<p>A two-element vector holding the <em>defaults</em> for the smallest and
largest possible values, respectively.</p>
</td></tr>
<tr><td><code id="class_cost_+3A_trans">trans</code></td>
<td>
<p>A <code>trans</code> object from the <code>scales</code> package, such as
<code>scales::log10_trans()</code> or <code>scales::reciprocal_trans()</code>. If not provided,
the default is used which matches the units used in <code>range</code>. If no
transformation, <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This parameter reflects the cost of a misclassified sample relative to a
baseline cost of 1.0. For example, if the first level of an outcome factor
occurred rarely, it might help if this parameter were set to values greater
than 1.0. If the second level of the outcome factor is in the minority,
values less than 1.0 would cause the model to emphasize the minority class
more than the majority class.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>class_cost()
</code></pre>

<hr>
<h2 id='control_bag'>Controlling the bagging process</h2><span id='topic+control_bag'></span>

<h3>Description</h3>

<p><code>control_bag()</code> can set options for ancillary aspects of the bagging process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>control_bag(
  var_imp = TRUE,
  allow_parallel = TRUE,
  sampling = "none",
  reduce = TRUE,
  extract = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="control_bag_+3A_var_imp">var_imp</code></td>
<td>
<p>A single logical: should variable importance scores be calculated?</p>
</td></tr>
<tr><td><code id="control_bag_+3A_allow_parallel">allow_parallel</code></td>
<td>
<p>A single logical: should the model fits be done in
parallel (even if a parallel <code>plan()</code> has been created)?</p>
</td></tr>
<tr><td><code id="control_bag_+3A_sampling">sampling</code></td>
<td>
<p>Either &quot;none&quot; or &quot;down&quot;. For classification only. The
training data, after bootstrapping, will be sampled down within each class
(with replacement) to the size of the smallest class.</p>
</td></tr>
<tr><td><code id="control_bag_+3A_reduce">reduce</code></td>
<td>
<p>Should models be modified to reduce their size on disk?</p>
</td></tr>
<tr><td><code id="control_bag_+3A_extract">extract</code></td>
<td>
<p>A function (or NULL) that can extract model-related aspects
of each ensemble member. See Details and example below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Any arbitrary item can be saved from the model object (including the model
object itself) using the <code>extract</code> argument, which should be a function with
arguments <code>x</code> (for the model object), and <code>...</code>. The results of this
function are saved into a list column called <code>extras</code> (see the example below).
</p>


<h3>Value</h3>

<p>A list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Extracting model components

num_term_nodes &lt;- function(x, ...) {
  tibble::tibble(num_nodes = sum(x$frame$var == "&lt;leaf&gt;"))
}

set.seed(7687)
with_extras &lt;- bagger(mpg ~ ., data = mtcars,
                      base_model = "CART", times = 5,
                      control = control_bag(extract = num_term_nodes))

dplyr::bind_rows(with_extras$model_df$extras)
</code></pre>

<hr>
<h2 id='nnet_imp_garson'>Garson Importance Scores for neural Networks</h2><span id='topic+nnet_imp_garson'></span>

<h3>Description</h3>

<p>Garson Importance Scores for neural Networks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nnet_imp_garson(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nnet_imp_garson_+3A_object">object</code></td>
<td>
<p>A <code>model_fit</code> or <code>nnet</code> object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble.
</p>

<hr>
<h2 id='predict.bagger'>Predictions from a bagged model</h2><span id='topic+predict.bagger'></span>

<h3>Description</h3>

<p>The <code>predict()</code> function computes predictions from each of the
models in the ensembles and returns a single aggregated value
for each sample in <code>new_data</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bagger'
predict(object, new_data, type = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.bagger_+3A_object">object</code></td>
<td>
<p>An object generated by <code>bagger()</code>.</p>
</td></tr>
<tr><td><code id="predict.bagger_+3A_new_data">new_data</code></td>
<td>
<p>A data frame of predictors. If a recipe or
formula were originally used, the <strong>original</strong> data should be
passed here instead of a preprocessed version.</p>
</td></tr>
<tr><td><code id="predict.bagger_+3A_type">type</code></td>
<td>
<p>A single character value for the type of
predictions. For regression models, <code>type = 'numeric'</code> is valid
and <code>'class'</code> and <code>'prob'</code> are valid for classification models.</p>
</td></tr>
<tr><td><code id="predict.bagger_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(airquality)

set.seed(7687)
cart_bag &lt;- bagger(Ozone ~ ., data = airquality, base_model = "CART", times = 5)
predict(cart_bag, new_data = airquality[, -1])
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span><span id='topic+var_imp'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+var_imp">var_imp</a></code></p>
</dd>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
</dl>

<hr>
<h2 id='var_imp.bagger'>Obtain variable importance scores</h2><span id='topic+var_imp.bagger'></span>

<h3>Description</h3>

<p>Obtain variable importance scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bagger'
var_imp(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_imp.bagger_+3A_object">object</code></td>
<td>
<p>An object.</p>
</td></tr>
<tr><td><code id="var_imp.bagger_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>baguette</code> can compute different variable importance scores for
each model in the ensemble. The <code>var_imp()</code> function returns the average
importance score for each model. Additionally, the function returns the
number of times that each predictor is included in the final prediction
equation.
</p>
<p>Specific methods used by the models are:
</p>
<p><em>CART</em>: The model accumulates the improvement of the model that occurs when
a predictor is used in a split. These values are taken form the <code>rpart</code>
object. See <code>rpart::rpart.object()</code>.
</p>
<p><em>MARS</em>: MARS models include a backwards elimination feature selection
routine that looks at reductions in the generalized cross-validation (GCV)
estimate of error. The <code>earth()</code> function tracks the changes in model
statistics, such as the GCV, for each predictor and accumulates the
reduction in the statistic when each predictor's feature is added to the
model. This total reduction is used as the variable importance measure. If a
predictor was never used in any of the MARS basis functions in the final
model (after pruning), it has an importance value of zero. <code>baguette</code> wraps
<code>earth::evimp()</code>.
</p>
<p><em>C5.0</em>: <code>C5.0</code> measures predictor importance by determining the percentage
of training set samples that fall into all the terminal nodes after the
split. For example, the predictor in the first split automatically has an
importance measurement of 100 percent since all samples are affected by this
split. Other predictors may be used frequently in splits, but if the
terminal nodes cover only a handful of training set samples, the importance
scores may be close to zero.
</p>
<p>Note that the <code>value</code> column that is the average of the importance scores
form each model. The divisor of this average (and the corresponding standard
error) is the number of models (as opposed to the number of models that
used the predictor). This means that the importance scores for a predictor
that was not used in the model has an implicit zero importance.
</p>


<h3>Value</h3>

<p>A tibble with columns for <code>term</code> (the predictor), <code>value</code> (the
mean importance score), <code>std.error</code> (the standard error), and <code>used</code> (the
occurrences of the predictors).
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
