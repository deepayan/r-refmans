<!DOCTYPE html><html><head><title>Help for package DMRnet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DMRnet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#DMRnet-package'><p>DMRnet-package</p></a></li>
<li><a href='#coef.cv.DMR'><p>coef.cv.DMR</p></a></li>
<li><a href='#coef.DMR'><p>coef.DMR</p></a></li>
<li><a href='#coef.gic.DMR'><p>coef.gic.DMR</p></a></li>
<li><a href='#cv.DMR'><p>cross-validation for DMR</p></a></li>
<li><a href='#cv.DMRnet'><p>cross-validation for DMRnet</p></a></li>
<li><a href='#DMR'><p>Delete or Merge Regressors</p></a></li>
<li><a href='#DMRnet'><p>Delete or Merge Regressors net</p></a></li>
<li><a href='#gic.DMR'><p>gic.DMR</p></a></li>
<li><a href='#miete'><p>miete dataset</p></a></li>
<li><a href='#plot.cv.DMR'><p>plot.cv.DMR</p></a></li>
<li><a href='#plot.DMR'><p>plot.DMR</p></a></li>
<li><a href='#plot.gic.DMR'><p>plot.gic.DMR</p></a></li>
<li><a href='#predict.cv.DMR'><p>predict.cv.DMR</p></a></li>
<li><a href='#predict.DMR'><p>predict.DMR</p></a></li>
<li><a href='#predict.gic.DMR'><p>predict.gic.DMR</p></a></li>
<li><a href='#print.DMR'><p>print.DMR</p></a></li>
<li><a href='#promoter'><p>promoter dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Delete or Merge Regressors Algorithms for Linear and Logistic
Model Selection and High-Dimensional Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Model selection algorithms for regression and classification, where the predictors can be continuous or categorical and the number of regressors may exceed the number of observations. The selected model consists of a subset of numerical regressors and partitions of levels of factors. Szymon Nowakowski, Piotr Pokarowski, Wojciech Rejchel and Agnieszka Sołtys, 2023. Improving Group Lasso for High-Dimensional Categorical Data. In: Computational Science – ICCS 2023. Lecture Notes in Computer Science, vol 14074, p. 455-470. Springer, Cham. &lt;<a href="https://doi.org/10.1007%2F978-3-031-36021-3_47">doi:10.1007/978-3-031-36021-3_47</a>&gt;. Aleksandra Maj-Kańska, Piotr Pokarowski and Agnieszka Prochenka, 2015. Delete or merge regressors for linear model selection. Electronic Journal of Statistics 9(2): 1749-1778. &lt;<a href="https://doi.org/10.1214%2F15-EJS1050">doi:10.1214/15-EJS1050</a>&gt;. Piotr Pokarowski and Jan Mielniczuk, 2015. Combined l1 and greedy l0 penalized least squares for linear model selection. Journal of Machine Learning Research 16(29): 961-992. <a href="https://www.jmlr.org/papers/volume16/pokarowski15a/pokarowski15a.pdf">https://www.jmlr.org/papers/volume16/pokarowski15a/pokarowski15a.pdf</a>. Piotr Pokarowski, Wojciech Rejchel, Agnieszka Sołtys, Michał Frej and Jan Mielniczuk, 2022. Improving Lasso for model selection and prediction. Scandinavian Journal of Statistics, 49(2): 831–863. &lt;<a href="https://doi.org/10.1111%2Fsjos.12546">doi:10.1111/sjos.12546</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>hclust1d, glmnet, grpreg, stats, graphics, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/SzymonNowakowski/DMRnet">https://github.com/SzymonNowakowski/DMRnet</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/SzymonNowakowski/DMRnet/issues">https://github.com/SzymonNowakowski/DMRnet/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-02 12:36:36 UTC; Szym</td>
</tr>
<tr>
<td>Author:</td>
<td>Agnieszka Prochenka-Sołtys [aut] (previous maintainer for versions &lt;=
    0.2.0),
  Piotr Pokarowski [aut],
  Szymon Nowakowski <a href="https://orcid.org/0000-0002-1939-9512"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Szymon Nowakowski &lt;s.nowakowski@mimuw.edu.pl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-07 14:40:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='DMRnet-package'>DMRnet-package</h2><span id='topic+DMRnet-package'></span>

<h3>Description</h3>

<p>Model selection algorithms for regression and classification, where the predictors can be continuous or categorical and the number of regressors may exceed the number of observations. The selected model consists of a subset of numerical regressors and partitions of levels of factors.
</p>


<h3>DMRnet Functions</h3>

<p>Similar in use to <span class="pkg">glmnet</span>. It consists of the following functions:
</p>
<p><code><a href="#topic+DMR">DMR</a></code> - Model selection algorithm for p&lt;n; produces a path of models.
</p>
<p><code><a href="#topic+DMRnet">DMRnet</a></code> - Model selection algorithm both for p&lt;n and for p&gt;=n; produces a path of models.
</p>
<p><code><a href="#topic+print.DMR">print.DMR</a></code>, <code><a href="#topic+coef.DMR">coef.DMR</a></code>, <code><a href="#topic+plot.DMR">plot.DMR</a></code>, <code><a href="#topic+predict.DMR">predict.DMR</a></code> - Functions for inspection of the models on the path.
</p>
<p><code><a href="#topic+gic.DMR">gic.DMR</a></code>, <code><a href="#topic+cv.DMR">cv.DMR</a></code>, <code><a href="#topic+cv.DMRnet">cv.DMRnet</a></code> - Functions for final model selection, resulting with one model from the path.
</p>
<p><code><a href="#topic+coef.gic.DMR">coef.gic.DMR</a></code>, <code><a href="#topic+coef.cv.DMR">coef.cv.DMR</a></code>, <code><a href="#topic+plot.gic.DMR">plot.gic.DMR</a></code>, <code><a href="#topic+plot.cv.DMR">plot.cv.DMR</a></code>, <code><a href="#topic+predict.gic.DMR">predict.gic.DMR</a></code>, <code><a href="#topic+predict.cv.DMR">predict.cv.DMR</a></code> - Functions for inspection of the final model.
</p>
<p><code>miete</code>, <code>promoter</code> - Two data sets used for vignettes, examples, etc.
</p>
<p>For more information see a friendly &quot;Getting started&quot; vignette:
</p>


<h3>Author(s)</h3>

<p>Agnieszka Prochenka-Sołtys, Piotr Pokarowski, Szymon Nowakowski
</p>
<p>Maintainer: Szymon Nowakowski &lt;s.nowakowski@mimuw.edu.pl&gt;
</p>


<h3>References</h3>

<p>Aleksandra Maj-Kańska, Piotr Pokarowski and Agnieszka Prochenka, 2015. Delete or merge regressors for linear model selection. Electronic Journal of Statistics 9(2): 1749-1778. <a href="https://doi.org/10.1214/15-EJS1050">doi:10.1214/15-EJS1050</a>
</p>
<p>Piotr Pokarowski and Jan Mielniczuk, 2015. Combined l1 and greedy l0 penalized least squares for linear model selection. Journal of Machine Learning Research 16(29): 961-992. <a href="https://www.jmlr.org/papers/volume16/pokarowski15a/pokarowski15a.pdf">https://www.jmlr.org/papers/volume16/pokarowski15a/pokarowski15a.pdf</a>
</p>
<p>Piotr Pokarowski, Wojciech Rejchel, Agnieszka Sołtys, Michał Frej and Jan Mielniczuk, 2022. Improving Lasso for model selection and prediction. Scandinavian Journal of Statistics, 49(2): 831–863. <a href="https://doi.org/10.1111/sjos.12546">doi:10.1111/sjos.12546</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
vignette("getting-started", package="DMRnet")

## End(Not run)

</code></pre>

<hr>
<h2 id='coef.cv.DMR'>coef.cv.DMR</h2><span id='topic+coef.cv.DMR'></span>

<h3>Description</h3>

<p>Extracts coefficients from a <code>cv.DMR</code> object (for the model with minimal cross-validated error /the default/ or the smallest model falling under the upper curve of a prediction error plus one standard deviation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.DMR'
coef(object, md = "df.min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.cv.DMR_+3A_object">object</code></td>
<td>
<p>Fitted <code>cv.DMR</code> object.</p>
</td></tr>
<tr><td><code id="coef.cv.DMR_+3A_md">md</code></td>
<td>
<p>Value of the model dimension parameter at which predictions are required. The default is <code>md="df.min"</code> value indicating the model minimizing the cross validation error. Alternatively, <code>md="df.1se"</code> can be used, indicating the smallest model falling under the upper curve of a prediction error plus one standard deviation.</p>
</td></tr>
<tr><td><code id="coef.cv.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to other <code>coef</code> methods, this function extracts coefficients from a fitted <code>cv.DMR</code> object.
</p>


<h3>Value</h3>

<p>Vector of coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## cv.DMR for linear regression
set.seed(13)
data(miete)
y &lt;- miete$rent
X &lt;- miete$area
cv = cv.DMR(X,y)
coef(cv)

</code></pre>

<hr>
<h2 id='coef.DMR'>coef.DMR</h2><span id='topic+coef.DMR'></span>

<h3>Description</h3>

<p>Extracts coefficients from a DMR object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DMR'
coef(object, df = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.DMR_+3A_object">object</code></td>
<td>
<p>Fitted <code>DMR</code> object.</p>
</td></tr>
<tr><td><code id="coef.DMR_+3A_df">df</code></td>
<td>
<p>Number of parameters in the model for which coefficients are required. Default is the entire path of models.</p>
</td></tr>
<tr><td><code id="coef.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to other <code>coef</code> methods, this function extracts coefficients from a fitted <code>DMR</code> object.
</p>


<h3>Value</h3>

<p>Vector or matrix of coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
y &lt;- miete[,1]
X &lt;- miete[,-1]
m &lt;- DMR(X, y)
coef(m, df = 12)
</code></pre>

<hr>
<h2 id='coef.gic.DMR'>coef.gic.DMR</h2><span id='topic+coef.gic.DMR'></span>

<h3>Description</h3>

<p>Extracts coefficients from a <code>gic.DMR</code> object (for the model with minimal gic).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gic.DMR'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.gic.DMR_+3A_object">object</code></td>
<td>
<p>Fitted <code>gic.DMR</code> object.</p>
</td></tr>
<tr><td><code id="coef.gic.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to other <code>coef</code> methods, this function extracts coefficients from a fitted <code>gic.DMR</code> object for the model with minimal gic.
</p>


<h3>Value</h3>

<p>Vector of coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
y &lt;- miete[,1]
X &lt;- miete[,-1]
m &lt;- DMR(X, y)
g &lt;- gic.DMR(m, c = 2.5)
coef(g)
</code></pre>

<hr>
<h2 id='cv.DMR'>cross-validation for DMR</h2><span id='topic+cv.DMR'></span>

<h3>Description</h3>

<p>Executes k-fold cross-validation for <code>DMR</code> and returns a value for df.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.DMR(
  X,
  y,
  family = "gaussian",
  clust.method = "complete",
  lam = 10^(-7),
  nfolds = 10,
  indexation.mode = "GIC"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.DMR_+3A_x">X</code></td>
<td>
<p>Input data frame, of dimension n x p; <code>DMR</code> works only if p&lt;n, for p&gt;=n see <code><a href="#topic+DMRnet">DMRnet</a></code>; each row is an observation vector. Columns can be numerical or integer for continuous predictors or factors for categorical predictors.</p>
</td></tr>
<tr><td><code id="cv.DMR_+3A_y">y</code></td>
<td>
<p>Response variable. Numerical for <code>family="gaussian"</code> or a factor with two levels for <code>family="binomial"</code>. For <code>family="binomial"</code> the last level in alphabetical order is the target class.</p>
</td></tr>
<tr><td><code id="cv.DMR_+3A_family">family</code></td>
<td>
<p>Response type; one of: <code>"gaussian"</code>, <code>"binomial"</code>.</p>
</td></tr>
<tr><td><code id="cv.DMR_+3A_clust.method">clust.method</code></td>
<td>
<p>Clustering method used for partitioning levels of factors; see function <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html">hclust</a> in package <span class="pkg">stats</span> for details. <code>clust.method="complete"</code> is the default.</p>
</td></tr>
<tr><td><code id="cv.DMR_+3A_lam">lam</code></td>
<td>
<p>The amount of penalization in ridge regression (used for logistic regression in order to allow for parameter estimation in linearly separable setups) or the amount of matrix regularization in case of linear regression. Used only for numerical reasons. The default is 1e-7.</p>
</td></tr>
<tr><td><code id="cv.DMR_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds in cross-validation. The default value is 10.</p>
</td></tr>
<tr><td><code id="cv.DMR_+3A_indexation.mode">indexation.mode</code></td>
<td>
<p>How the cross validation algorithm should index the models for internal quality comparisons; one of: <code>"GIC"</code> (the default) for GIC-indexed cross validation, <code>"dimension"</code>, for model dimension-indexed cross validation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>cv.DMR</code> algorithm does cross-validation for <code>DMR</code> with <code>nfolds</code> folds. The df for the minimal estimated prediction error is returned.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"cv.DMR"</code> is  returned,  which  is  a  list  with  the  ingredients  of  the  cross-validation fit.
</p>

<dl>
<dt>df.min</dt><dd><p>df (number of parameters) of the model with minimal cross-validated error.</p>
</dd>
<dt>df.1se</dt><dd><p>df (number of parameters) of the smallest model falling under the upper curve of a prediction error plus one standard deviation.</p>
</dd>
<dt>dmr.fit</dt><dd><p>Fitted <code>DMR</code> object for the full data.</p>
</dd>
<dt>cvm</dt><dd><p>The mean cross-validated error for the entire sequence of models.</p>
</dd>
<dt>foldid</dt><dd><p>The fold assignments used.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+plot.cv.DMR">plot.cv.DMR</a></code> for plotting, <code><a href="#topic+coef.cv.DMR">coef.cv.DMR</a></code> for extracting coefficients and <code><a href="#topic+predict.cv.DMR">predict.cv.DMR</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## cv.DMR for linear regression
set.seed(13)
data(miete)
ytr &lt;- miete$rent[1:1500]
Xtr &lt;- miete$area[1:1500]
Xte &lt;- miete$area[1501:2053]
cv &lt;- cv.DMR(Xtr, ytr)
print(cv)
plot(cv)
coef(cv)
ypr &lt;- predict(cv, newx = Xte)

</code></pre>

<hr>
<h2 id='cv.DMRnet'>cross-validation for DMRnet</h2><span id='topic+cv.DMRnet'></span>

<h3>Description</h3>

<p>Executes k-fold cross-validation for DMR and returns a value for df.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.DMRnet(
  X,
  y,
  family = "gaussian",
  o = 5,
  nlambda = 100,
  lam = 10^(-7),
  interc = TRUE,
  maxp = ifelse(family == "gaussian", ceiling(length(y)/2), ceiling(length(y)/4)),
  nfolds = 10,
  indexation.mode = "GIC",
  algorithm = "DMRnet",
  clust.method = ifelse(algorithm == "glamer", "single", "complete")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.DMRnet_+3A_x">X</code></td>
<td>
<p>Input data frame, of dimension n x p; each row is an observation vector. Columns can be numerical or integer for continuous predictors or factors for categorical predictors.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_y">y</code></td>
<td>
<p>Response variable. Numerical for <code>family="gaussian"</code> or a factor with two levels for <code>family="binomial"</code>. For <code>family="binomial"</code> the last level in alphabetical order is the target class.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_family">family</code></td>
<td>
<p>Response type; one of: <code>"gaussian"</code>, <code>"binomial"</code>.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_o">o</code></td>
<td>
<p>Parameter of the group lasso screening step, described in <code><a href="#topic+DMRnet">DMRnet</a></code>.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_nlambda">nlambda</code></td>
<td>
<p>Parameter of the group lasso screening step, described in <code><a href="#topic+DMRnet">DMRnet</a></code>. The default value is 100.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_lam">lam</code></td>
<td>
<p>The amount of penalization in ridge regression (used for logistic regression in order to allow for parameter estimation in linearly separable setups) or the amount of matrix regularization in case of linear regression. Used only for numerical reasons. The default value is 1e-7.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_interc">interc</code></td>
<td>
<p>Should intercept(s) be fitted (the default, <code>interc=TRUE</code>) or set to zero (<code>interc=FALSE</code>). If in <code>X</code> there are any categorical variables, <code>interc=TRUE</code> must be set.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_maxp">maxp</code></td>
<td>
<p>Maximal number of parameters of the model, smaller values result in quicker computation.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds in cross-validation. The default value is 10.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_indexation.mode">indexation.mode</code></td>
<td>
<p>How the cross validation algorithm should index the models for internal quality comparisons; one of: <code>"GIC"</code> (the default) for GIC-indexed cross validation, <code>"dimension"</code>, for model dimension-indexed cross validation.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_algorithm">algorithm</code></td>
<td>
<p>The algorithm to be used; for partition selection (merging levels) use one of: <code>"DMRnet"</code> (the default), <code>"glamer"</code> or <code>"PDMR"</code>. Alternatively, use <code>"var_sel"</code> for variable (group) selection with no partition selection.</p>
</td></tr>
<tr><td><code id="cv.DMRnet_+3A_clust.method">clust.method</code></td>
<td>
<p>Clustering method used for partitioning levels of factors; see function <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html">hclust</a> in package <span class="pkg">stats</span> for details. <code>clust.method="complete"</code> is the default for all algorithms except <code>algorithm="glamer"</code>, for which <code>clust.method="single"</code> is the default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>cv.DMRnet algorithm does <code>nfold</code>-fold cross-validation for DMRnet. The df for the minimal estimated prediction error is returned.
</p>


<h3>Value</h3>

<p>An object with S3 class &quot;cv.DMR&quot; is  returned,  which  is  a  list  with  the  ingredients  of  the  cross-validation fit.
</p>

<dl>
<dt>df.min</dt><dd><p>df (number of parameters) of the model with minimal cross-validated error.</p>
</dd>
<dt>df.1se</dt><dd><p>df (number of parameters) of the smallest model falling under the upper curve of a prediction error plus one standard deviation.</p>
</dd>
<dt>dmr.fit</dt><dd><p>Fitted <code>DMR</code> object for the full data.</p>
</dd>
<dt>cvm</dt><dd><p>The mean cross-validated error for the entire sequence of models.</p>
</dd>
<dt>foldid</dt><dd><p>The fold assignments used.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+plot.cv.DMR">plot.cv.DMR</a></code> for plotting, <code><a href="#topic+coef.cv.DMR">coef.cv.DMR</a></code> for extracting coefficients and <code><a href="#topic+predict.cv.DMR">predict.cv.DMR</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## cv.DMRnet for linear regression
set.seed(13)
data(miete)
ytr &lt;- miete$rent[1:1500]
Xtr &lt;- miete$area[1:1500]
Xte &lt;- miete$area[1501:2053]
cv &lt;- cv.DMRnet(Xtr, ytr)
print(cv)
plot(cv)
coef(cv)
ypr &lt;- predict(cv, newx = Xte)

</code></pre>

<hr>
<h2 id='DMR'>Delete or Merge Regressors</h2><span id='topic+DMR'></span>

<h3>Description</h3>

<p>Fits a path of linear (<code>family="gaussian"</code>) or logistic (<code>family="binomial"</code>) regression models, where the number of parameters changes from 1 to p (p is the number of columns in the model matrix). Models are subsets of continuous predictors and partitions of levels of factors in <code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DMR(
  X,
  y,
  family = "gaussian",
  clust.method = "complete",
  lam = 10^(-7),
  lambda = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DMR_+3A_x">X</code></td>
<td>
<p>Input data frame; each row is an observation vector; each column can be numerical or integer for a continuous predictor or a factor for a categorical predictor; DMR works only if p&lt;n (n is the number of observations, p the number of columns in the model matrix), for p&gt;=n see <code><a href="#topic+DMRnet">DMRnet</a></code>.</p>
</td></tr>
<tr><td><code id="DMR_+3A_y">y</code></td>
<td>
<p>Response variable; Numerical for <code>family="gaussian"</code> or a factor with two levels for <code>family="binomial"</code>. For <code>family="binomial"</code> the last level in alphabetical order is the target class.</p>
</td></tr>
<tr><td><code id="DMR_+3A_family">family</code></td>
<td>
<p>Response type; one of: <code>"gaussian"</code>, <code>"binomial"</code>.</p>
</td></tr>
<tr><td><code id="DMR_+3A_clust.method">clust.method</code></td>
<td>
<p>Clustering method used for partitioning levels of factors; see function <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html">hclust</a> in package <span class="pkg">stats</span> for details. <code>clust.method="complete"</code> is the default.</p>
</td></tr>
<tr><td><code id="DMR_+3A_lam">lam</code></td>
<td>
<p>The amount of penalization in ridge regression (used for logistic regression in order to allow for parameter estimation in linearly separable setups) or the amount of matrix regularization in case of linear regression. Used only for numerical reasons. The default is 1e-7.</p>
</td></tr>
<tr><td><code id="DMR_+3A_lambda">lambda</code></td>
<td>
<p>The net of lambda values. It is optional and serves only for consistency with <code>DMRnet</code>. It is not used in <code>DMR</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>DMR</code> algorithm is based on a traditional stepwise method.
A nested family of models is built based on the values of squared Wald statistics:
</p>
<p>1. For each continuous variable the squared Wald statistic is calculated for a hypothesis that the variable is equal to zero (it should be deleted).
</p>
<p>2. For each factor a dissimilarity matrix is constructed using squared Wald statistics for hypotheses that two parameters are equal
(the two levels of factor should be merged). Next, hierarchical clustering is preformed using the dissimilarity matrix. All cutting heights are recorded.
</p>
<p>3. Squared Wald statistics and cutting heights and values of  from steps 2 and 3 are concatenated and sorted, resulting in vector h.
</p>
<p>4. Nested family of models of size 1 to p is built by accepting hypotheses according to increasing values in vector h.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"DMR"</code>, which  is  a  list  with  the  ingredients:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>Matrix p times p of estimated parameters; each column corresponds to a model on the nested path having from p to 1 parameter (denoted as df).</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Vector of degrees of freedom; from p to 1.</p>
</td></tr>
<tr><td><code>rss/loglik</code></td>
<td>
<p>Measure of fit for the nested models: rss (residual sum of squares) is returned for <code>family="gaussian"</code> and loglik (loglikelihood) is returned for <code>family="binomial"</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code>levels.listed</code></td>
<td>
<p>Minimal set of levels of respective factors present in data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The net of lambda values used in the screening step, empty vector in case of <code>DMR</code>.</p>
</td></tr>
<tr><td><code>arguments</code></td>
<td>
<p>List of the chosen arguments from the function call.</p>
</td></tr>
<tr><td><code>interc</code></td>
<td>
<p>If the intercept was fitted: for <code>DMR</code> always equal to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+print.DMR">print.DMR</a></code> for printing, <code><a href="#topic+plot.DMR">plot.DMR</a></code> for plotting, <code><a href="#topic+coef.DMR">coef.DMR</a></code> for extracting coefficients and <code><a href="#topic+predict.DMR">predict.DMR</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## DMR for linear regression
data(miete)
ytr &lt;- miete[1:1500,1]
Xtr &lt;- miete[1:1500,-1]
Xte &lt;- miete[1501:2053,-1]
m1 &lt;- DMR(Xtr, ytr)
print(m1)
plot(m1)
g &lt;- gic.DMR(m1, c = 2.5)
plot(g)
coef(m1, df = g$df.min)
ypr &lt;- predict(m1, newx = Xte, df = g$df.min)

## DMR for logistic regression
# notice that only part of dataset promoter was used: DMR works only if p&lt;n, for p&gt;=n use DMRnet
data(promoter)
ytr &lt;- factor(promoter[1:80,1])
Xtr &lt;- promoter[1:80,2:11]
Xte &lt;- promoter[81:106,2:11]
m2 &lt;- DMR(Xtr, ytr, family = "binomial")
print(m2)
plot(m2)
g &lt;- gic.DMR(m2, c = 2)
plot(g)
coef(m2, df = g$df.min)
ypr &lt;- predict(m2, newx = Xte, df = g$df.min)

</code></pre>

<hr>
<h2 id='DMRnet'>Delete or Merge Regressors net</h2><span id='topic+DMRnet'></span>

<h3>Description</h3>

<p>Fits a path of linear (<code>family="gaussian"</code>) or logistic (<code>family="binomial"</code>) regression models, where models are subsets of continuous predictors and partitions of levels of factors in <code>X</code>. Works even if p&gt;=n (the number of observations is greater than the number of columns in the model matrix).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DMRnet(
  X,
  y,
  family = "gaussian",
  o = 5,
  nlambda = 100,
  lam = 10^(-7),
  interc = TRUE,
  maxp = ifelse(family == "gaussian", ceiling(length(y)/2), ceiling(length(y)/4)),
  lambda = NULL,
  algorithm = "DMRnet",
  clust.method = ifelse(algorithm == "glamer", "single", "complete")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DMRnet_+3A_x">X</code></td>
<td>
<p>Input data frame; each row is an observation vector; each column can be numerical or integer for a continuous predictor or a factor for a categorical predictor.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_y">y</code></td>
<td>
<p>Response variable; Numerical for <code>family="gaussian"</code> or a factor with two levels for <code>family="binomial"</code>. For <code>family="binomial"</code> the last level in alphabetical order is the target class.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_family">family</code></td>
<td>
<p>Response type; one of: <code>"gaussian"</code>, <code>"binomial"</code>.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_o">o</code></td>
<td>
<p>Parameter of the group lasso screening step, described in Details, the default value is 5.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_nlambda">nlambda</code></td>
<td>
<p>Parameter of the group lasso screening step, described in Details, the default value is 100.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_lam">lam</code></td>
<td>
<p>The amount of penalization in ridge regression (used for logistic regression in order to allow for parameter estimation in linearly separable setups) or the amount of matrix regularization in case of linear regression. Used only for numerical reasons. The default is 1e-7.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_interc">interc</code></td>
<td>
<p>Should intercept(s) be fitted (the default, <code>interc=TRUE</code>) or set to zero (<code>interc=FALSE</code>). If in <code>X</code> there are any categorical variables, <code>interc=TRUE</code> must be set.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_maxp">maxp</code></td>
<td>
<p>Maximal number of parameters of the model, smaller values result in quicker computation</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_lambda">lambda</code></td>
<td>
<p>Explicitly provided net of lambda values for the group lasso screening step, described in Details. If provided, it overrides the value of <code>nlambda</code> parameter.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_algorithm">algorithm</code></td>
<td>
<p>The algorithm to be used; for partition selection (merging levels) use one of: <code>"DMRnet"</code> (the default), <code>"glamer"</code> or <code>"PDMR"</code>. Alternatively, use <code>"var_sel"</code> for variable (group) selection with no partition selection.</p>
</td></tr>
<tr><td><code id="DMRnet_+3A_clust.method">clust.method</code></td>
<td>
<p>Clustering method used for partitioning levels of factors; see function <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html">hclust</a> in package <span class="pkg">stats</span> for details. <code>clust.method="complete"</code> is the default for all algorithms except <code>algorithm="glamer"</code>, for which <code>clust.method="single"</code> is the default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>DMRnet</code> algorithm is a generalization of <code><a href="#topic+DMR">DMR</a></code> to high-dimensional data.
It uses a screening step in order to decrease the problem to p&lt;n and then uses <code>DMR</code> subsequently.
The screening is done with the group lasso algorithm implemented in the <a href="https://CRAN.R-project.org/package=grpreg">grpreg</a> package.
</p>
<p>First, the group lasso for the problem is solved for <code>nlambda</code> values of lambda parameter, or for the net of lambda values (if <code>lambda</code> is explicitly provided).
Next, for each value of lambda, the scaled nonzero second norms of the groups' coefficients are sorted in decreasing order.
Finally, the first i over <code>o</code> fraction of the groups with the largest nonzero values are chosen for further analysis, i = 1,2,...,<code>o</code>-1.
E.g., if <code>o</code>=5, first 1/5, first 2/5,..., 4/5 groups with the largest scaled nonzero second norm of coefficients are chosen.
</p>
<p>The final path of models is chosen by minimizing the likelihood of the models for the number of parameters df equal to 1,...,l&lt;=<code>maxp</code> for some integer l. Note that, in contrast to <code>DMR</code>, the models on the path need not to be nested.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"DMR"</code>, which  is  a  list  with  the  ingredients:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>Matrix p times l of estimated parameters; each column corresponds to a model on the nested path having from l to 1 parameter (denoted as df).</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Vector of degrees of freedom; from l to 1.</p>
</td></tr>
<tr><td><code>rss/loglik</code></td>
<td>
<p>Measure of fit for the nested models: rss (residual sum of squares) is returned for <code>family="gaussian"</code> and loglik (loglikelihood) is returned for <code>family="binomial"</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code>levels.listed</code></td>
<td>
<p>Minimal set of levels of respective factors present in data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The net of lambda values used in the screening step.</p>
</td></tr>
<tr><td><code>arguments</code></td>
<td>
<p>List of the chosen arguments from the function call.</p>
</td></tr>
<tr><td><code>interc</code></td>
<td>
<p>If the intercept was fitted: value of parameter <code>interc</code> is returned.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+print.DMR">print.DMR</a></code> for printing, <code><a href="#topic+plot.DMR">plot.DMR</a></code> for plotting, <code><a href="#topic+coef.DMR">coef.DMR</a></code> for extracting coefficients and <code><a href="#topic+predict.DMR">predict.DMR</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## DMRnet for linear regression
data(miete)
ytr &lt;- miete[1:200,1]
Xtr &lt;- miete[1:200,-1]
Xte &lt;- miete[201:250,-1]
m1 &lt;- DMRnet(Xtr, ytr)
print(m1)
plot(m1)
g &lt;- gic.DMR(m1, c = 2.5)
plot(g)
coef(m1, df = g$df.min)
ypr &lt;- predict(m1, newx = Xte, df = g$df.min)

## DMRnet for logistic regression
data(promoter)
ytr &lt;- factor(promoter[1:70,1])
Xtr &lt;- promoter[1:70,-1]
Xte &lt;- promoter[71:106,-1]
m2 &lt;- DMRnet(Xtr, ytr, family = "binomial")
print(m2)
plot(m2)
g &lt;- gic.DMR(m2, c = 2)
plot(g)
coef(m2, df = g$df.min)
ypr &lt;- predict(m2, newx = Xte, df = g$df.min)

## PDMR for linear regression
data(miete)
ytr &lt;- miete[1:200,1]
Xtr &lt;- miete[1:200,-1]
Xte &lt;- miete[201:250,-1]
m1 &lt;- DMRnet(Xtr, ytr, algorithm="PDMR")
print(m1)
plot(m1)
g &lt;- gic.DMR(m1, c = 2.5)
plot(g)
coef(m1, df = g$df.min)
ypr &lt;- predict(m1, newx = Xte, df = g$df.min)

</code></pre>

<hr>
<h2 id='gic.DMR'>gic.DMR</h2><span id='topic+gic.DMR'></span>

<h3>Description</h3>

<p>Computes values of Generalized Information Criterion for the entire sequence of models from a <code>DMR</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gic.DMR(
  x,
  c = ifelse(x$arguments$family == "gaussian", constants()$RIC_gaussian_constant,
    constants()$RIC_binomial_constant)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gic.DMR_+3A_x">x</code></td>
<td>
<p>Fitted <code>DMR</code> object.</p>
</td></tr>
<tr><td><code id="gic.DMR_+3A_c">c</code></td>
<td>
<p>Parameter controlling amount of penalization for complexity of the model in the generalized information criterion (GIC). For linear regression GIC for model M is defined as </p>
<p style="text-align: center;"><code class="reqn">GIC_M = RSS_M + df_M*c* log{p}*s^2,</code>
</p>
<p> where <code class="reqn">RSS_M</code> is the residual sum of squares and <code class="reqn">df_M</code> is the number of parameters in the model M; <code class="reqn">s^2</code> is an estimator of <code class="reqn">sigma^2</code> based on the model in the <code>DMR</code> object with the largest number of parameters. For logistic regression GIC for model M is defined as </p>
<p style="text-align: center;"><code class="reqn">GIC_M = -2*loglik_M + |M|*c* log{p},</code>
</p>
<p> where <code class="reqn">loglik_M</code> is the logarithm of the likelihood function and <code class="reqn">df_M</code> is the number of parameters in the model M. Recommended values are <code>c=2.5</code> for linear regression and <code>c=2</code> for logistic regression.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"gic.DMR"</code> is returned, which is a list with the ingredients of the gic fit.
</p>

<dl>
<dt>df.min</dt><dd><p>df (number of parameters) for the model with minimal GIC.</p>
</dd>
<dt>dmr.fit</dt><dd><p>Fitted <code>DMR</code> object.</p>
</dd>
<dt>gic</dt><dd><p>Vector of GIC values for the entire sequence of models.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+plot.gic.DMR">plot.gic.DMR</a></code> for plotting, <code><a href="#topic+coef.gic.DMR">coef.gic.DMR</a></code> for extracting coefficients and <code><a href="#topic+predict.gic.DMR">predict.gic.DMR</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
y &lt;- miete[,1]
X &lt;- miete[,-1]
m &lt;- DMR(X, y)
(g &lt;- gic.DMR(m, c = 2.5))
</code></pre>

<hr>
<h2 id='miete'>miete dataset</h2><span id='topic+miete'></span>

<h3>Description</h3>

<p>The miete data contains the rent index for Munich in 2003.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(miete)
</code></pre>


<h3>Format</h3>

<p>A data frame with 2053 observations on the following 12 variables.
</p>

<dl>
<dt>rent</dt><dd><p>Rent in euros.</p>
</dd>
<dt>bathextra</dt><dd><p>Special furniture in bathroom, yes = 1, no = 0.</p>
</dd>
<dt>tiles</dt><dd><p>Bathroom with tiles, yes = 0, no = 1.</p>
</dd>
<dt>area</dt><dd><p>Municipality.</p>
</dd>
<dt>kitchen</dt><dd><p>Upmarket kitchen, yes = 1, no = 0.</p>
</dd>
<dt>rooms</dt><dd><p>Number of rooms.</p>
</dd>
<dt>best</dt><dd><p>Best address, yes = 1, no = 0.</p>
</dd>
<dt>good</dt><dd><p>Good address, yes = 1, no =0.</p>
</dd>
<dt>warm</dt><dd><p>Warm water, yes = 0, no = 1.</p>
</dd>
<dt>central</dt><dd><p>Central heating, yes = 0, no = 1.</p>
</dd>
<dt>year</dt><dd><p>Year of construction.</p>
</dd>
<dt>size</dt><dd><p>Living space in square meter.</p>
</dd>
</dl>



<h3>References</h3>

<p>Fahrmeir, L., Künstler, R., Pigeot, I., Tutz, G. (2004) Statistik: der Weg zur Datenanalyse. 5. Auflage, Berlin: Springer-Verlag.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
summary(miete)
</code></pre>

<hr>
<h2 id='plot.cv.DMR'>plot.cv.DMR</h2><span id='topic+plot.cv.DMR'></span>

<h3>Description</h3>

<p>Plots cross-validated error values from a <code>cv.DMR</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.DMR'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.DMR_+3A_x">x</code></td>
<td>
<p>Fitted <code>cv.DMR</code> object.</p>
</td></tr>
<tr><td><code id="plot.cv.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces a plot of cross-validated error values for the entire sequence of models from the fitted <code>cv.DMR</code> object. The horizontal level indicating separation of one standard deviation from the minimum error is indicated with a blue dashed line. The df.min (the smallest model minimizing the cross-validated error) and df.1se (the smallest model falling under the blue dashed line) are marked with red and blue points, respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## cv.DMR for linear regression
set.seed(13)
data(miete)
y &lt;- miete$rent
X &lt;- miete$area
cv = cv.DMR(X,y)
plot(cv)

</code></pre>

<hr>
<h2 id='plot.DMR'>plot.DMR</h2><span id='topic+plot.DMR'></span>

<h3>Description</h3>

<p>Plots coefficients from a <code>DMR</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DMR'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.DMR_+3A_x">x</code></td>
<td>
<p>Fitted <code>DMR</code> object.</p>
</td></tr>
<tr><td><code id="plot.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces a coefficient profile plot of the coefficient paths for a fitted <code>DMR</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
y &lt;- miete[,1]
X &lt;- miete[,-1]
m &lt;- DMR(X, y)
plot(m)
</code></pre>

<hr>
<h2 id='plot.gic.DMR'>plot.gic.DMR</h2><span id='topic+plot.gic.DMR'></span>

<h3>Description</h3>

<p>Plots gic values from a <code>gic.DMR</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gic.DMR'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gic.DMR_+3A_x">x</code></td>
<td>
<p>Fitted <code>gic.DMR</code> object.</p>
</td></tr>
<tr><td><code id="plot.gic.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces a plot of Generalized Information Criterion for the entire sequence of models from the fitted <code>gic.DMR</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
y &lt;- miete[,1]
X &lt;- miete[,-1]
m &lt;- DMR(X, y)
g &lt;- gic.DMR(m, c = 2.5)
plot(g)
</code></pre>

<hr>
<h2 id='predict.cv.DMR'>predict.cv.DMR</h2><span id='topic+predict.cv.DMR'></span>

<h3>Description</h3>

<p>Makes predictions from a cv.DMR object (for the model with minimal cross-validated error /the default/ or the smallest model falling under the upper curve of a prediction error plus one standard deviation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.DMR'
predict(
  object,
  newx,
  type = "link",
  md = "df.min",
  unknown.factor.levels = "error",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.DMR_+3A_object">object</code></td>
<td>
<p>Fitted cv.DMR object.</p>
</td></tr>
<tr><td><code id="predict.cv.DMR_+3A_newx">newx</code></td>
<td>
<p>Data frame of new values for <code>X</code> at which predictions are to be made. The intercept column should NOT be passed in a call to <code>predict</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.DMR_+3A_type">type</code></td>
<td>
<p>One of: <code>"link"</code>, <code>"response"</code>, <code>"class"</code>. For <code>family="gaussian"</code> for all values of <code>type</code> it gives the fitted values. For <code>family="binomial"</code> and <code>type="link"</code> it returns the linear predictors, for <code>type="response"</code> it returns the fitted probabilities and for <code>type="class"</code> it produces the class labels corresponding to the maximum probability.</p>
</td></tr>
<tr><td><code id="predict.cv.DMR_+3A_md">md</code></td>
<td>
<p>Value of the model dimension parameter at which predictions are required. The default is <code>md="df.min"</code> value indicating the model minimizing the cross validation error. Alternatively, <code>md="df.1se"</code> can be used, indicating the smallest model falling under the upper curve of a prediction error plus one standard deviation.</p>
</td></tr>
<tr><td><code id="predict.cv.DMR_+3A_unknown.factor.levels">unknown.factor.levels</code></td>
<td>
<p>The way of handling factor levels in test data not seen while training a model. One of <code>"error"</code> (the default - throwing an error) or <code>"NA"</code> (returning <code>NA</code> in place of legitimate value for problematic rows).</p>
</td></tr>
<tr><td><code id="predict.cv.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to other <code>predict</code> methods, this function predicts fitted values from a fitted <code>cv.DMR</code> object.
</p>


<h3>Value</h3>

<p>Vector of predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## cv.DMR for linear regression
set.seed(13)
data(miete)
ytr &lt;- miete$rent[1:1500]
Xtr &lt;- miete$area[1:1500]
Xte &lt;- miete$area[1501:2053]
cv &lt;- cv.DMR(Xtr, ytr)
print(cv)
plot(cv)
coef(cv)
ypr &lt;- predict(cv, newx = Xte)

</code></pre>

<hr>
<h2 id='predict.DMR'>predict.DMR</h2><span id='topic+predict.DMR'></span>

<h3>Description</h3>

<p>Makes predictions from a <code>DMR</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DMR'
predict(
  object,
  newx,
  df = NULL,
  type = "link",
  unknown.factor.levels = "error",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.DMR_+3A_object">object</code></td>
<td>
<p>Fitted <code>DMR</code> object.</p>
</td></tr>
<tr><td><code id="predict.DMR_+3A_newx">newx</code></td>
<td>
<p>Data frame of new values for <code>X</code> at which predictions are to be made. The intercept column should NOT be passed in a call to <code>predict</code>.</p>
</td></tr>
<tr><td><code id="predict.DMR_+3A_df">df</code></td>
<td>
<p>Number of parameters in the model for which predictions are required. Default is the entire sequence of models for df=1 to df=p.</p>
</td></tr>
<tr><td><code id="predict.DMR_+3A_type">type</code></td>
<td>
<p>One of: <code>"link"</code>, <code>"response"</code>, <code>"class"</code>. For <code>family="gaussian"</code> for all values of <code>type</code> it gives the fitted values. For <code>family="binomial"</code> and <code>type="link"</code> it returns the linear predictors, for <code>type="response"</code> it returns the fitted probabilities and for <code>type="class"</code> it produces the class labels corresponding to the maximum probability.</p>
</td></tr>
<tr><td><code id="predict.DMR_+3A_unknown.factor.levels">unknown.factor.levels</code></td>
<td>
<p>The way of handling factor levels in test data not seen while training a model. One of <code>"error"</code> (the default - throwing an error) or <code>"NA"</code> (returning <code>NA</code> in place of legitimate value for problematic rows).</p>
</td></tr>
<tr><td><code id="predict.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to other <code>predict</code> methods, this function predicts fitted values from a fitted <code>DMR</code> object.
</p>


<h3>Value</h3>

<p>Vector or matrix of predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
ytr &lt;- miete[1:1500,1]
Xtr &lt;- miete[1:1500,-1]
Xte &lt;- miete[1501:2053,-1]
m &lt;- DMR(Xtr, ytr)
ypr &lt;- predict(m, newx = Xte, df = 11)
</code></pre>

<hr>
<h2 id='predict.gic.DMR'>predict.gic.DMR</h2><span id='topic+predict.gic.DMR'></span>

<h3>Description</h3>

<p>Makes predictions from a <code>gic.DMR</code> object (for the model with minimal GIC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gic.DMR'
predict(object, newx, type = "link", unknown.factor.levels = "error", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gic.DMR_+3A_object">object</code></td>
<td>
<p>Fitted <code>gic.DMR</code> object.</p>
</td></tr>
<tr><td><code id="predict.gic.DMR_+3A_newx">newx</code></td>
<td>
<p>Data frame of new values for <code>X</code> at which predictions are to be made. The intercept column should NOT be passed in a call to <code>predict</code>.</p>
</td></tr>
<tr><td><code id="predict.gic.DMR_+3A_type">type</code></td>
<td>
<p>One of: <code>"link"</code>, <code>"response"</code>, <code>"class"</code>. For <code>family="gaussian"</code> for all values of <code>type</code> it gives the fitted values. For <code>family="binomial"</code> and <code>type="link"</code> it returns the linear predictors, for <code>type="response"</code> it returns the fitted probabilities and for <code>type="class"</code> it produces the class labels corresponding to the maximum probability.</p>
</td></tr>
<tr><td><code id="predict.gic.DMR_+3A_unknown.factor.levels">unknown.factor.levels</code></td>
<td>
<p>The way of handling factor levels in test data not seen while training a model. One of <code>"error"</code> (the default - throwing an error) or <code>"NA"</code> (returning <code>NA</code> in place of legitimate value for problematic rows).</p>
</td></tr>
<tr><td><code id="predict.gic.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to other <code>predict</code> methods, this function predicts fitted values from a fitted <code>gic.DMR</code> object for the model with minimal GIC.
</p>


<h3>Value</h3>

<p>Vector of predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
ytr &lt;- miete[1:1500,1]
Xtr &lt;- miete[1:1500,-1]
Xte &lt;- miete[1501:2053,-1]
m &lt;- DMR(Xtr, ytr)
g &lt;- gic.DMR(m, c = 2.5)
ypr &lt;- predict(g, newx = Xte)
</code></pre>

<hr>
<h2 id='print.DMR'>print.DMR</h2><span id='topic+print.DMR'></span>

<h3>Description</h3>

<p>Prints a <code>DMR</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DMR'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.DMR_+3A_x">x</code></td>
<td>
<p>Fitted <code>DMR</code> object.</p>
</td></tr>
<tr><td><code id="print.DMR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Print a summary of the <code>DMR</code> path at each step along the path.
</p>


<h3>Value</h3>

<p>The summary is silently returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(miete)
y &lt;- miete[,1]
X &lt;- miete[,-1]
m &lt;- DMR(X, y)
print(m)
</code></pre>

<hr>
<h2 id='promoter'>promoter dataset</h2><span id='topic+promoter'></span>

<h3>Description</h3>

<p>It consists of E. coli promoter gene sequences starting at position -50 (p-50) and ending at position +7 (p7). Each of these 57 Fields is filled by one of a, g, t, c. The task is to recognize promoters, which are genetic regions which initiate the first step in the expression of adjacent genes (transcription). There are 53 promoters and 53 non-promoter sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(promoter)
</code></pre>


<h3>Format</h3>

<p>A data frame with 106 observations on the following 58 variables.
</p>

<dl>
<dt>y</dt><dd><p>One of 1/0, indicating the class (1 = promoter).</p>
</dd>
<dt>X1</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X2</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X3</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X4</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X5</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X6</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X7</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X8</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X9</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X10</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X11</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X12</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X13</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X14</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X15</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X16</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X17</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X18</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X19</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X20</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X21</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X22</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X23</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X24</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X25</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X26</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X27</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X28</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X29</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X30</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X31</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X32</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X33</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X34</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X35</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X36</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X37</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X38</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X39</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X40</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X41</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X42</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X43</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X44</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X45</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X46</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X47</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X48</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X49</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X50</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X51</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X52</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X53</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X54</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X55</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X56</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd>
<dt>X57</dt><dd><p>Sequence; filled by one of a, g, t, c.</p>
</dd></dl>



<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Promoter+Gene+Sequences%29">UCI machine learning repository: promoter</a>
</p>


<h3>References</h3>

<p>Towell, G., Shavlik, J., Noordewier, M. Refinement of approximate domain theories by knowledge-based neural networks. In Proceedings of the eighth National conference on Artificial intelligence, pages 861-866. Boston, MA, 1990.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(promoter)
summary(promoter)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
