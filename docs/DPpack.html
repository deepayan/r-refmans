<!DOCTYPE html><html lang="en"><head><title>Help for package DPpack</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DPpack}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calibrateAnalyticGaussianMechanism'><p>Calibrate Analytic Gaussian Mechanism</p></a></li>
<li><a href='#covDataAccess'><p>Differentially Private Covariance Data Access Function</p></a></li>
<li><a href='#covDP'><p>Differentially Private Covariance</p></a></li>
<li><a href='#EmpiricalRiskMinimizationDP.CMS'><p>Privacy-preserving Empirical Risk Minimization for Binary Classification</p></a></li>
<li><a href='#EmpiricalRiskMinimizationDP.KST'><p>Privacy-preserving Empirical Risk Minimization for Regression</p></a></li>
<li><a href='#ExponentialMechanism'><p>Exponential Mechanism</p></a></li>
<li><a href='#GaussianMechanism'><p>Gaussian Mechanism</p></a></li>
<li><a href='#generate.loss.gr.huber'><p>Generator for Huber Loss Function Gradient</p></a></li>
<li><a href='#generate.loss.huber'><p>Generator for Huber Loss Function</p></a></li>
<li><a href='#generate.sampling'><p>Generator for Sampling Distribution Function for Gaussian Kernel</p></a></li>
<li><a href='#histogramDataAccess'><p>Differentially Private Histogram Data Access Function</p></a></li>
<li><a href='#histogramDP'><p>Differentially Private Histogram</p></a></li>
<li><a href='#LaplaceMechanism'><p>Laplace Mechanism</p></a></li>
<li><a href='#LinearRegressionDP'><p>Privacy-preserving Linear Regression</p></a></li>
<li><a href='#LogisticRegressionDP'><p>Privacy-preserving Logistic Regression</p></a></li>
<li><a href='#loss.cross.entropy'><p>Cross Entropy Loss Function</p></a></li>
<li><a href='#loss.gr.cross.entropy'><p>Cross Entropy Loss Function Gradient</p></a></li>
<li><a href='#loss.gr.squared.error'><p>Squared error Loss Function Gradient</p></a></li>
<li><a href='#loss.squared.error'><p>Squared Error Loss Function</p></a></li>
<li><a href='#mapXy.gr.linear'><p>Linear Map Function Gradient</p></a></li>
<li><a href='#mapXy.gr.sigmoid'><p>Sigmoid Map Function Gradient</p></a></li>
<li><a href='#mapXy.linear'><p>Linear Map Function</p></a></li>
<li><a href='#mapXy.sigmoid'><p>Sigmoid Map Function</p></a></li>
<li><a href='#meanDataAccess'><p>Differentially Private Mean Data Access Function</p></a></li>
<li><a href='#meanDP'><p>Differentially Private Mean</p></a></li>
<li><a href='#medianDP'><p>Differentially Private Median</p></a></li>
<li><a href='#phi.gaussian'><p>Transform Function for Gaussian Kernel Approximation</p></a></li>
<li><a href='#pooledCovDataAccess'><p>Differentially Private Pooled Covariance Data Access Function</p></a></li>
<li><a href='#pooledCovDP'><p>Differentially Private Pooled Covariance</p></a></li>
<li><a href='#pooledVarDataAccess'><p>Differentially Private Pooled Variance Data Access Function</p></a></li>
<li><a href='#pooledVarDP'><p>Differentially Private Pooled Variance</p></a></li>
<li><a href='#quantileDataAccess'><p>Differentially Private Quantile Data Access Function</p></a></li>
<li><a href='#quantileDP'><p>Differentially Private Quantile</p></a></li>
<li><a href='#regularizer.gr.l2'><p>l2 Regularizer Gradient</p></a></li>
<li><a href='#regularizer.l2'><p>l2 Regularizer</p></a></li>
<li><a href='#sdDP'><p>Differentially Private Standard Deviation</p></a></li>
<li><a href='#svmDP'><p>Privacy-preserving Support Vector Machine</p></a></li>
<li><a href='#tableDataAccess'><p>Differentially Private Contingency Table Data Access Function</p></a></li>
<li><a href='#tableDP'><p>Differentially Private Contingency Table</p></a></li>
<li><a href='#tune_classification_model'><p>Privacy-preserving Hyperparameter Tuning for Binary Classification Models</p></a></li>
<li><a href='#tune_linear_regression_model'><p>Privacy-preserving Hyperparameter Tuning for Linear Regression Models</p></a></li>
<li><a href='#varDataAccess'><p>Differentially Private Variance Data Access Function</p></a></li>
<li><a href='#varDP'><p>Differentially Private Variance</p></a></li>
<li><a href='#WeightedERMDP.CMS'><p>Privacy-preserving Weighted Empirical Risk Minimization</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Differentially Private Statistical Analysis and Machine Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Spencer Giddens &lt;giddens2spencer@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of common statistical analysis and models with
    differential privacy (Dwork et al., 2006a) &lt;<a href="https://doi.org/10.1007%2F11681878_14">doi:10.1007/11681878_14</a>&gt;
    guarantees. The package contains, for example, functions providing
    differentially private computations of mean, variance, median, histograms,
    and contingency tables. It also implements some statistical models and
    machine learning algorithms such as linear regression (Kifer et al., 2012)
    <a href="https://proceedings.mlr.press/v23/kifer12.html">https://proceedings.mlr.press/v23/kifer12.html</a>
    and SVM (Chaudhuri et al., 2011)
    <a href="https://jmlr.org/papers/v12/chaudhuri11a.html">https://jmlr.org/papers/v12/chaudhuri11a.html</a>. In addition, it implements
    some popular randomization mechanisms, including
    the Laplace mechanism (Dwork et al., 2006a)
    &lt;<a href="https://doi.org/10.1007%2F11681878_14">doi:10.1007/11681878_14</a>&gt;, Gaussian mechanism (Dwork et al., 2006b)
    &lt;<a href="https://doi.org/10.1007%2F11761679_29">doi:10.1007/11761679_29</a>&gt;, analytic Gaussian mechanism (Balle &amp; Wang, 2018)
    <a href="https://proceedings.mlr.press/v80/balle18a.html">https://proceedings.mlr.press/v80/balle18a.html</a>, and exponential mechanism
    (McSherry &amp; Talwar, 2007) &lt;<a href="https://doi.org/10.1109%2FFOCS.2007.66">doi:10.1109/FOCS.2007.66</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> | file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>rmutil (&ge; 1.1.5), Rdpack (&ge; 2.1.2), R6 (&ge; 2.5.1), dplyr (&ge;
1.0.1), MASS (&ge; 7.3-51.6), nloptr (&ge; 1.2.2.2), e1071 (&ge;
1.7-9), stats (&ge; 4.0.2), graphics (&ge; 4.0.2), ggplot2 (&ge;
3.3.2)</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-20 02:44:42 UTC; spencergiddens</td>
</tr>
<tr>
<td>Author:</td>
<td>Spencer Giddens [aut, cre],
  Fang Liu [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-20 04:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='calibrateAnalyticGaussianMechanism'>Calibrate Analytic Gaussian Mechanism</h2><span id='topic+calibrateAnalyticGaussianMechanism'></span>

<h3>Description</h3>

<p>Calibrate a Gaussian perturbation for differential privacy using the analytic
Gaussian mechanism (Balle and Wang 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrateAnalyticGaussianMechanism(epsilon, delta, sensitivity, tol = 1e-12)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calibrateAnalyticGaussianMechanism_+3A_epsilon">epsilon</code></td>
<td>
<p>Positive real number defining the epsilon privacy parameter.</p>
</td></tr>
<tr><td><code id="calibrateAnalyticGaussianMechanism_+3A_delta">delta</code></td>
<td>
<p>Positive real number defining the delta privacy parameter.</p>
</td></tr>
<tr><td><code id="calibrateAnalyticGaussianMechanism_+3A_sensitivity">sensitivity</code></td>
<td>
<p>Real number corresponding to the l2-global sensitivity.</p>
</td></tr>
<tr><td><code id="calibrateAnalyticGaussianMechanism_+3A_tol">tol</code></td>
<td>
<p>Error tolerance for binary search.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Standard deviation of Gaussian noise needed to achieve
<code>(epsilon, delta)</code>-DP for given global sensitivity.
</p>


<h3>References</h3>

<p>Balle B, Wang Y (2018).
&ldquo;Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising.&rdquo;
In Dy J, Krause A (eds.), <em>Proceedings of the 35th International Conference on Machine Learning</em>, volume 80 of <em>Proceedings of Machine Learning Research</em>, 394&ndash;403.
<a href="https://proceedings.mlr.press/v80/balle18a.html">https://proceedings.mlr.press/v80/balle18a.html</a>.
</p>

<hr>
<h2 id='covDataAccess'>Differentially Private Covariance Data Access Function</h2><span id='topic+covDataAccess'></span>

<h3>Description</h3>

<p>This function performs the data access step in the computation of a
differentially private covariance. The true values are computed using
<code><a href="stats.html#topic+cov">cov</a></code>, while the sensitivities are calculated based on
bounded and unbounded differential privacy (Kifer and Machanavajjhala 2011)
according to the theoretical values (Liu 2019). For the
covariance, the sensitivities based on bounded and unbounded differential
privacy are identical, so only one value is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covDataAccess(x1, x2, lower.bound1, upper.bound1, lower.bound2, upper.bound2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covDataAccess_+3A_x1">x1</code>, <code id="covDataAccess_+3A_x2">x2</code></td>
<td>
<p>Numeric vectors whose covariance is desired.</p>
</td></tr>
<tr><td><code id="covDataAccess_+3A_lower.bound1">lower.bound1</code>, <code id="covDataAccess_+3A_lower.bound2">lower.bound2</code></td>
<td>
<p>Real numbers giving the lower bounds of x1
and x2, respectively.</p>
</td></tr>
<tr><td><code id="covDataAccess_+3A_upper.bound1">upper.bound1</code>, <code id="covDataAccess_+3A_upper.bound2">upper.bound2</code></td>
<td>
<p>Real numbers giving the upper bounds of x1
and x2, respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of the true covariance and the sensitivity calculated based on
theoretical values.
</p>


<h3>References</h3>

<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>covDataAccess(c(1,4,3,2), c(-2,-3,-4,-1), 0, 5, -5, 0)

</code></pre>

<hr>
<h2 id='covDP'>Differentially Private Covariance</h2><span id='topic+covDP'></span>

<h3>Description</h3>

<p>This function computes the differentially private covariance of a pair of
vectors at user-specified privacy levels of epsilon and delta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covDP(
  x1,
  x2,
  eps,
  lower.bound1,
  upper.bound1,
  lower.bound2,
  upper.bound2,
  which.sensitivity = "bounded",
  mechanism = "Laplace",
  delta = 0,
  type.DP = "aDP"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covDP_+3A_x1">x1</code>, <code id="covDP_+3A_x2">x2</code></td>
<td>
<p>Numeric vectors whose covariance is desired.</p>
</td></tr>
<tr><td><code id="covDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="covDP_+3A_lower.bound1">lower.bound1</code>, <code id="covDP_+3A_lower.bound2">lower.bound2</code></td>
<td>
<p>Real numbers giving the global or public
lower bounds of x1 and x2, respectively.</p>
</td></tr>
<tr><td><code id="covDP_+3A_upper.bound1">upper.bound1</code>, <code id="covDP_+3A_upper.bound2">upper.bound2</code></td>
<td>
<p>Real numbers giving the global or public
upper bounds of x1 and x2, respectively.</p>
</td></tr>
<tr><td><code id="covDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
delta)-differential privacy, but may not do so collectively and in
composition. Care must be taken not to violate differential privacy in this
case.</p>
</td></tr>
<tr><td><code id="covDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'Laplace',
'Gaussian', 'analytic'}. Default is Laplace. See <code><a href="#topic+LaplaceMechanism">LaplaceMechanism</a></code>
and <code><a href="#topic+GaussianMechanism">GaussianMechanism</a></code> for descriptions of the supported
mechanisms.</p>
</td></tr>
<tr><td><code id="covDP_+3A_delta">delta</code></td>
<td>
<p>Nonnegative real number defining the delta privacy parameter. If
0 (default), reduces to eps-DP.</p>
</td></tr>
<tr><td><code id="covDP_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism (if selected). Can be either 'pDP' for probabilistic
DP (Machanavajjhala et al. 2008) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized covariance based on the bounded and/or unbounded
definitions of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008).
&ldquo;Privacy: Theory meets Practice on the Map.&rdquo;
In <em>2008 IEEE 24th International Conference on Data Engineering</em>, 277-286.
<a href="https://doi.org/10.1109/ICDE.2008.4497436">doi:10.1109/ICDE.2008.4497436</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>
<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>D1 &lt;- sort(stats::rnorm(500, mean=3, sd=2))
D2 &lt;- sort(stats::rnorm(500, mean=-1,sd=0.5))
lb1 &lt;- -3 # 3 std devs below mean
lb2 &lt;- -2.5 # 3 std devs below mean
ub1 &lt;- 9 # 3 std devs above mean
ub2 &lt;- .5 # 3 std devs above mean
covDP(D1, D2, 1, lb1, ub1, lb2, ub2)
covDP(D1, D2, .5, lb1, ub1, lb2, ub2, which.sensitivity='unbounded',
  mechanism='Gaussian', delta=0.01)


</code></pre>

<hr>
<h2 id='EmpiricalRiskMinimizationDP.CMS'>Privacy-preserving Empirical Risk Minimization for Binary Classification</h2><span id='topic+EmpiricalRiskMinimizationDP.CMS'></span>

<h3>Description</h3>

<p>This class implements differentially private empirical risk
minimization (Chaudhuri et al. 2011). Either the output or the
objective perturbation method can be used. It is intended to be a framework
for building more specific models via inheritance. See
<code><a href="#topic+LogisticRegressionDP">LogisticRegressionDP</a></code> for an example of this type of
structure.
</p>


<h3>Details</h3>

<p>To use this class for empirical risk minimization, first use the
<code>new</code> method to construct an object of this class with the desired
function values and hyperparameters. After constructing the object, the
<code>fit</code> method can be applied with a provided dataset and data bounds to
fit the model.  In fitting, the model stores a vector of coefficients
<code>coeff</code> which satisfy differential privacy. These can be released
directly, or used in conjunction with the <code>predict</code> method to
privately predict the outcomes of new datapoints.
</p>
<p>Note that in order to guarantee differential privacy for empirical risk
minimization, certain constraints must be satisfied for the values used to
construct the object, as well as for the data used to fit. These conditions
depend on the chosen perturbation method. Specifically, the provided loss
function must be convex and differentiable with respect to <code>y.hat</code>,
and the absolute value of the first derivative of the loss function must be
at most 1. If objective perturbation is chosen, the loss function must also
be doubly differentiable and the absolute value of the second derivative of
the loss function must be bounded above by a constant c for all possible
values of <code>y.hat</code> and <code>y</code>, where <code>y.hat</code> is the predicted
label and <code>y</code> is the true label. The regularizer must be 1-strongly
convex and differentiable. It also must be doubly differentiable if
objective perturbation is chosen. Finally, it is assumed that if x
represents a single row of the dataset X, then the l2-norm of x is at most
1 for all x. Note that because of this, a bias term cannot be included
without appropriate scaling/preprocessing of the dataset. To ensure
privacy, the add.bias argument in the <code>fit</code> and <code>predict</code> methods
should only be utilized in subclasses within this package where appropriate
preprocessing is implemented, not in this class.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>mapXy</code></dt><dd><p>Map function of the form <code>mapXy(X, coeff)</code> mapping input
data matrix <code>X</code> and coefficient vector or matrix <code>coeff</code> to
output labels <code>y</code>.</p>
</dd>
<dt><code>mapXy.gr</code></dt><dd><p>Function representing the gradient of the map function with
respect to the values in <code>coeff</code> and of the form <code>mapXy.gr(X,
  coeff)</code>, where <code>X</code> is a matrix and <code>coeff</code> is a matrix or
numeric vector.</p>
</dd>
<dt><code>loss</code></dt><dd><p>Loss function of the form <code>loss(y.hat, y)</code>, where
<code>y.hat</code> and <code>y</code> are matrices.</p>
</dd>
<dt><code>loss.gr</code></dt><dd><p>Function representing the gradient of the loss function with
respect to <code>y.hat</code> and of the form <code>loss.gr(y.hat, y)</code>, where
<code>y.hat</code> and <code>y</code> are matrices.</p>
</dd>
<dt><code>regularizer</code></dt><dd><p>Regularization function of the form
<code>regularizer(coeff)</code>, where <code>coeff</code> is a vector or matrix.</p>
</dd>
<dt><code>regularizer.gr</code></dt><dd><p>Function representing the gradient of the
regularization function with respect to <code>coeff</code> and of the form
<code>regularizer.gr(coeff)</code>.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Nonnegative real number representing the regularization
constant.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Positive real number defining the epsilon privacy budget. If set
to Inf, runs algorithm without differential privacy.</p>
</dd>
<dt><code>perturbation.method</code></dt><dd><p>String indicating whether to use the 'output' or
the 'objective' perturbation methods (Chaudhuri et al. 2011).</p>
</dd>
<dt><code>c</code></dt><dd><p>Positive real number denoting the upper bound on the absolute
value of the second derivative of the loss function, as required to
ensure differential privacy for the objective perturbation method.</p>
</dd>
<dt><code>coeff</code></dt><dd><p>Numeric vector of coefficients for the model.</p>
</dd>
<dt><code>kernel</code></dt><dd><p>Value only used in child class <code><a href="#topic+svmDP">svmDP</a></code>. String
indicating which kernel to use for SVM. Must be one of {'linear',
'Gaussian'}. If 'linear' (default), linear SVM is used. If
'Gaussian', uses the sampling function corresponding to the Gaussian
(radial) kernel approximation.</p>
</dd>
<dt><code>D</code></dt><dd><p>Value only used in child class <code><a href="#topic+svmDP">svmDP</a></code>. Nonnegative
integer indicating the dimensionality of the transform space
approximating the kernel. Higher values of <code>D</code> provide better kernel
approximations at a cost of computational efficiency.</p>
</dd>
<dt><code>sampling</code></dt><dd><p>Value only used in child class <code><a href="#topic+svmDP">svmDP</a></code>.
Sampling function of the form <code>sampling(d)</code>, where <code>d</code> is the
input dimension, returning a (<code>d</code>+1)-dimensional vector of samples
corresponding to the Fourier transform of the kernel to be approximated.</p>
</dd>
<dt><code>phi</code></dt><dd><p>Value only used in child class <code><a href="#topic+svmDP">svmDP</a></code>. Function of
the form <code>phi(x, theta)</code>, where <code>x</code> is an individual row of the
original dataset, and theta is a (<code>d</code>+1)-dimensional vector sampled
from the Fourier transform of the kernel to be approximated, where
<code>d</code> is the dimension of <code>x</code>. The function returns a numeric
scalar corresponding to the pre-filtered value at the given row with the
given sampled vector.</p>
</dd>
<dt><code>kernel.param</code></dt><dd><p>Value only used in child class <code><a href="#topic+svmDP">svmDP</a></code>.
Positive real number corresponding to the Gaussian kernel parameter.</p>
</dd>
<dt><code>prefilter</code></dt><dd><p>Value only used in child class <code><a href="#topic+svmDP">svmDP</a></code>. Matrix
of pre-filter values used in converting data into transform space.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-EmpiricalRiskMinimizationDP.CMS-new"><code>EmpiricalRiskMinimizationDP.CMS$new()</code></a>
</p>
</li>
<li> <p><a href="#method-EmpiricalRiskMinimizationDP.CMS-fit"><code>EmpiricalRiskMinimizationDP.CMS$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-EmpiricalRiskMinimizationDP.CMS-predict"><code>EmpiricalRiskMinimizationDP.CMS$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-EmpiricalRiskMinimizationDP.CMS-clone"><code>EmpiricalRiskMinimizationDP.CMS$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-EmpiricalRiskMinimizationDP.CMS-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>EmpiricalRiskMinimizationDP.CMS</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmpiricalRiskMinimizationDP.CMS$new(
  mapXy,
  loss,
  regularizer,
  eps,
  gamma,
  perturbation.method = "objective",
  c = NULL,
  mapXy.gr = NULL,
  loss.gr = NULL,
  regularizer.gr = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>mapXy</code></dt><dd><p>Map function of the form <code>mapXy(X, coeff)</code> mapping input
data matrix <code>X</code> and coefficient vector or matrix <code>coeff</code> to
output labels <code>y</code>. Should return a column matrix of predicted labels
for each row of <code>X</code>. See <code><a href="#topic+mapXy.sigmoid">mapXy.sigmoid</a></code> for an example.</p>
</dd>
<dt><code>loss</code></dt><dd><p>Loss function of the form <code>loss(y.hat, y)</code>, where
<code>y.hat</code> and <code>y</code> are matrices. Should be defined such that it
returns a matrix of loss values for each element of <code>y.hat</code> and
<code>y</code>. See <code><a href="#topic+loss.cross.entropy">loss.cross.entropy</a></code> for an example. It must be
convex and differentiable, and the absolute value of the first derivative
of the loss function must be at most 1. Additionally, if the objective
perturbation method is chosen, it must be doubly differentiable and the
absolute value of the second derivative of the loss function must be
bounded above by a constant c for all possible values of <code>y.hat</code> and
<code>y</code>.</p>
</dd>
<dt><code>regularizer</code></dt><dd><p>String or regularization function. If a string, must be
'l2', indicating to use l2 regularization. If a function, must have form
<code>regularizer(coeff)</code>, where <code>coeff</code> is a vector or matrix, and
return the value of the regularizer at <code>coeff</code>. See
<code><a href="#topic+regularizer.l2">regularizer.l2</a></code> for an example. Additionally, in order to
ensure differential privacy, the function must be 1-strongly convex and
differentiable. If the objective perturbation method is chosen, it must
also be doubly differentiable.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Positive real number defining the epsilon privacy budget. If set
to Inf, runs algorithm without differential privacy.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Nonnegative real number representing the regularization
constant.</p>
</dd>
<dt><code>perturbation.method</code></dt><dd><p>String indicating whether to use the 'output' or
the 'objective' perturbation methods (Chaudhuri et al. 2011).
Defaults to 'objective'.</p>
</dd>
<dt><code>c</code></dt><dd><p>Positive real number denoting the upper bound on the absolute
value of the second derivative of the loss function, as required to
ensure differential privacy for the objective perturbation method. This
input is unnecessary if perturbation.method is 'output', but is required
if perturbation.method is 'objective'. Defaults to NULL.</p>
</dd>
<dt><code>mapXy.gr</code></dt><dd><p>Optional function representing the gradient of the map
function with respect to the values in <code>coeff</code>. If given, must be of
the form <code>mapXy.gr(X, coeff)</code>, where <code>X</code> is a matrix and
<code>coeff</code> is a matrix or numeric vector. Should be defined such that
the ith row of the output represents the gradient with respect to the ith
coefficient. See <code><a href="#topic+mapXy.gr.sigmoid">mapXy.gr.sigmoid</a></code> for an example. If not
given, non-gradient based optimization methods are used to compute the
coefficient values in fitting the model.</p>
</dd>
<dt><code>loss.gr</code></dt><dd><p>Optional function representing the gradient of the loss
function with respect to <code>y.hat</code> and of the form
<code>loss.gr(y.hat, y)</code>, where <code>y.hat</code> and <code>y</code> are matrices.
Should be defined such that the ith row of the output represents the
gradient of the loss function at the ith set of input values. See
<code><a href="#topic+loss.gr.cross.entropy">loss.gr.cross.entropy</a></code> for an example. If not given,
non-gradient based optimization methods are used to compute the
coefficient values in fitting the model.</p>
</dd>
<dt><code>regularizer.gr</code></dt><dd><p>Optional function representing the gradient of the
regularization function with respect to <code>coeff</code> and of the form
<code>regularizer.gr(coeff)</code>. Should return a vector. See
<code><a href="#topic+regularizer.gr.l2">regularizer.gr.l2</a></code> for an example. If <code>regularizer</code> is
given as a string, this value is ignored. If not given and
<code>regularizer</code> is a function, non-gradient based optimization methods
are used to compute the coefficient values in fitting the model.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>EmpiricalRiskMinimizationDP.CMS</code> object.
</p>


<hr>
<a id="method-EmpiricalRiskMinimizationDP.CMS-fit"></a>



<h4>Method <code>fit()</code></h4>

<p>Fit the differentially private empirical risk minimization
model. This method runs either the output perturbation or the objective
perturbation algorithm (Chaudhuri et al. 2011), depending on
the value of perturbation.method used to construct the object, to
generate an objective function. A numerical optimization method is then
run to find optimal coefficients for fitting the model given the training
data and hyperparameters. The built-in <code><a href="stats.html#topic+optim">optim</a></code> function using
the &quot;BFGS&quot; optimization method is used. If <code>mapXy.gr</code>,
<code>loss.gr</code>, and <code>regularizer.gr</code> are all given in the
construction of the object, the gradient of the objective function is
utilized by <code>optim</code> as well. Otherwise, non-gradient based
optimization methods are used. The resulting privacy-preserving
coefficients are stored in <code>coeff</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmpiricalRiskMinimizationDP.CMS$fit(
  X,
  y,
  upper.bounds,
  lower.bounds,
  add.bias = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data to be fit.</p>
</dd>
<dt><code>y</code></dt><dd><p>Vector or matrix of true labels for each row of <code>X</code>.</p>
</dd>
<dt><code>upper.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)</code> giving upper
bounds on the values in each column of X. The <code>ncol(X)</code> values are
assumed to be in the same order as the corresponding columns of <code>X</code>.
Any value in the columns of <code>X</code> larger than the corresponding upper
bound is clipped at the bound.</p>
</dd>
<dt><code>lower.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)</code> giving lower
bounds on the values in each column of <code>X</code>. The <code>ncol(X)</code>
values are assumed to be in the same order as the corresponding columns
of <code>X</code>. Any value in the columns of <code>X</code> larger than the
corresponding upper bound is clipped at the bound.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-EmpiricalRiskMinimizationDP.CMS-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict label(s) for given <code>X</code> using the fitted
coefficients.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmpiricalRiskMinimizationDP.CMS$predict(X, add.bias = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data on which to make predictions. Must be of same
form as <code>X</code> used to fit coefficients.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE. If add.bias was set to TRUE when fitting the
coefficients, add.bias should be set to TRUE for predictions.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Matrix of predicted labels corresponding to each row of <code>X</code>.
</p>


<hr>
<a id="method-EmpiricalRiskMinimizationDP.CMS-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmpiricalRiskMinimizationDP.CMS$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Chaudhuri K, Monteleoni C, Sarwate AD (2011).
&ldquo;Differentially Private Empirical Risk Minimization.&rdquo;
<em>Journal of Machine Learning Research</em>, <b>12</b>(29), 1069-1109.
<a href="https://jmlr.org/papers/v12/chaudhuri11a.html">https://jmlr.org/papers/v12/chaudhuri11a.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build train dataset X and y, and test dataset Xtest and ytest
N &lt;- 200
K &lt;- 2
X &lt;- data.frame()
y &lt;- data.frame()
for (j in (1:K)){
  t &lt;- seq(-.25, .25, length.out = N)
  if (j==1) m &lt;- stats::rnorm(N,-.2, .1)
  if (j==2) m &lt;- stats::rnorm(N, .2, .1)
  Xtemp &lt;- data.frame(x1 = 3*t , x2 = m - t)
  ytemp &lt;- data.frame(matrix(j-1, N, 1))
  X &lt;- rbind(X, Xtemp)
  y &lt;- rbind(y, ytemp)
}
Xtest &lt;- X[seq(1,(N*K),10),]
ytest &lt;- y[seq(1,(N*K),10),,drop=FALSE]
X &lt;- X[-seq(1,(N*K),10),]
y &lt;- y[-seq(1,(N*K),10),,drop=FALSE]

# Construct object for logistic regression
mapXy &lt;- function(X, coeff) e1071::sigmoid(X%*%coeff)
# Cross entropy loss
loss &lt;- function(y.hat,y) -(y*log(y.hat) + (1-y)*log(1-y.hat))
regularizer &lt;- 'l2' # Alternatively, function(coeff) coeff%*%coeff/2
eps &lt;- 1
gamma &lt;- 1
perturbation.method &lt;- 'objective'
c &lt;- 1/4 # Required value for logistic regression
mapXy.gr &lt;- function(X, coeff) as.numeric(e1071::dsigmoid(X%*%coeff))*t(X)
loss.gr &lt;- function(y.hat, y) -y/y.hat + (1-y)/(1-y.hat)
regularizer.gr &lt;- function(coeff) coeff
ermdp &lt;- EmpiricalRiskMinimizationDP.CMS$new(mapXy, loss, regularizer, eps,
                                             gamma, perturbation.method, c,
                                             mapXy.gr, loss.gr,
                                             regularizer.gr)

# Fit with data
# Bounds for X based on construction
upper.bounds &lt;- c( 1, 1)
lower.bounds &lt;- c(-1,-1)
ermdp$fit(X, y, upper.bounds, lower.bounds) # No bias term
ermdp$coeff # Gets private coefficients

# Predict new data points
predicted.y &lt;- ermdp$predict(Xtest)
n.errors &lt;- sum(round(predicted.y)!=ytest)

</code></pre>

<hr>
<h2 id='EmpiricalRiskMinimizationDP.KST'>Privacy-preserving Empirical Risk Minimization for Regression</h2><span id='topic+EmpiricalRiskMinimizationDP.KST'></span>

<h3>Description</h3>

<p>This class implements differentially private empirical risk
minimization using the objective perturbation technique
(Kifer et al. 2012). It is intended to be a framework for
building more specific models via inheritance. See
<code><a href="#topic+LinearRegressionDP">LinearRegressionDP</a></code> for an example of this type of structure.
</p>


<h3>Details</h3>

<p>To use this class for empirical risk minimization, first use the
<code>new</code> method to construct an object of this class with the desired
function values and hyperparameters. After constructing the object, the
<code>fit</code> method can be applied with a provided dataset and data bounds to
fit the model. In fitting, the model stores a vector of coefficients
<code>coeff</code> which satisfy differential privacy. These can be released
directly, or used in conjunction with the <code>predict</code> method to privately
predict the outcomes of new datapoints.
</p>
<p>Note that in order to guarantee differential privacy for the empirical risk
minimization model, certain constraints must be satisfied for the values
used to construct the object, as well as for the data used to fit.
Specifically, the following constraints must be met. Let <code class="reqn">l</code> represent
the loss function for an individual dataset row x and output value y and
<code class="reqn">L</code> represent the average loss over all rows and output values. First,
<code class="reqn">L</code> must be convex with a continuous Hessian. Second, the l2-norm of the
gradient of <code class="reqn">l</code> must be bounded above by some constant zeta for all
possible input values in the domain. Third, for all possible inputs to
<code class="reqn">l</code>, the Hessian of <code class="reqn">l</code> must be of rank at most one and its
Eigenvalues must be bounded above by some constant lambda. Fourth, the
regularizer must be convex. Finally, the provided domain of <code class="reqn">l</code> must be
a closed convex subset of the set of all real-valued vectors of dimension p,
where p is the number of columns of X. Note that because of this, a bias
term cannot be included without appropriate scaling/preprocessing of the
dataset. To ensure privacy, the add.bias argument in the <code>fit</code> and
<code>predict</code> methods should only be utilized in subclasses within this
package where appropriate preprocessing is implemented, not in this class.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>mapXy</code></dt><dd><p>Map function of the form <code>mapXy(X, coeff)</code> mapping input
data matrix <code>X</code> and coefficient vector or matrix <code>coeff</code> to
output labels <code>y</code>.</p>
</dd>
<dt><code>mapXy.gr</code></dt><dd><p>Function representing the gradient of the map function with
respect to the values in <code>coeff</code> and of the form <code>mapXy.gr(X,
  coeff)</code>, where <code>X</code> is a matrix and <code>coeff</code> is a matrix or
numeric vector.</p>
</dd>
<dt><code>loss</code></dt><dd><p>Loss function of the form <code>loss(y.hat, y)</code>, where
<code>y.hat</code> and <code>y</code> are matrices.</p>
</dd>
<dt><code>loss.gr</code></dt><dd><p>Function representing the gradient of the loss function with
respect to <code>y.hat</code> and of the form <code>loss.gr(y.hat, y)</code>, where
<code>y.hat</code> and <code>y</code> are matrices.</p>
</dd>
<dt><code>regularizer</code></dt><dd><p>Regularization function of the form
<code>regularizer(coeff)</code>, where <code>coeff</code> is a vector or matrix.</p>
</dd>
<dt><code>regularizer.gr</code></dt><dd><p>Function representing the gradient of the
regularization function with respect to <code>coeff</code> and of the form
<code>regularizer.gr(coeff)</code>.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Nonnegative real number representing the regularization
constant.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Positive real number defining the epsilon privacy budget. If set
to Inf, runs algorithm without differential privacy.</p>
</dd>
<dt><code>delta</code></dt><dd><p>Nonnegative real number defining the delta privacy parameter.
If 0, reduces to pure eps-DP.</p>
</dd>
<dt><code>domain</code></dt><dd><p>List of constraint and jacobian functions representing the
constraints on the search space for the objective perturbation algorithm
used in Kifer et al. (2012).</p>
</dd>
<dt><code>zeta</code></dt><dd><p>Positive real number denoting the upper bound on the l2-norm
value of the gradient of the loss function, as required to ensure
differential privacy.</p>
</dd>
<dt><code>lambda</code></dt><dd><p>Positive real number corresponding to the upper bound of the
Eigenvalues of the Hessian of the loss function for all possible inputs.</p>
</dd>
<dt><code>coeff</code></dt><dd><p>Numeric vector of coefficients for the model.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-EmpiricalRiskMinimizationDP.KST-new"><code>EmpiricalRiskMinimizationDP.KST$new()</code></a>
</p>
</li>
<li> <p><a href="#method-EmpiricalRiskMinimizationDP.KST-fit"><code>EmpiricalRiskMinimizationDP.KST$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-EmpiricalRiskMinimizationDP.KST-predict"><code>EmpiricalRiskMinimizationDP.KST$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-EmpiricalRiskMinimizationDP.KST-clone"><code>EmpiricalRiskMinimizationDP.KST$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-EmpiricalRiskMinimizationDP.KST-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>EmpiricalRiskMinimizationDP.KST</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmpiricalRiskMinimizationDP.KST$new(
  mapXy,
  loss,
  regularizer,
  eps,
  delta,
  domain,
  zeta,
  lambda,
  gamma,
  mapXy.gr = NULL,
  loss.gr = NULL,
  regularizer.gr = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>mapXy</code></dt><dd><p>Map function of the form <code>mapXy(X, coeff)</code> mapping input
data matrix <code>X</code> and coefficient vector or matrix <code>coeff</code> to
output labels <code>y</code>. Should return a column matrix of predicted labels
for each row of <code>X</code>. See <code><a href="#topic+mapXy.linear">mapXy.linear</a></code> for an example.</p>
</dd>
<dt><code>loss</code></dt><dd><p>Loss function of the form <code>loss(y.hat, y)</code>, where
<code>y.hat</code> and <code>y</code> are matrices. Should be defined such that it
returns a matrix of loss values for each element of <code>y.hat</code> and
<code>y</code>. See <code><a href="#topic+loss.squared.error">loss.squared.error</a></code> for an example. This
function must be convex and the l2-norm of its gradient must be bounded
above by zeta for some constant zeta for all possible inputs within the
given domain. Additionally, for all possible inputs within the given
domain, the Hessian of the loss function must be of rank at most one and
its Eigenvalues must be bounded above by some constant lambda.</p>
</dd>
<dt><code>regularizer</code></dt><dd><p>String or regularization function. If a string, must be
'l2', indicating to use l2 regularization. If a function, must have form
<code>regularizer(coeff)</code>, where <code>coeff</code> is a vector or matrix, and
return the value of the regularizer at <code>coeff</code>. See
<code><a href="#topic+regularizer.l2">regularizer.l2</a></code> for an example. Additionally, in order to
ensure differential privacy, the function must be convex.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Positive real number defining the epsilon privacy budget. If set
to Inf, runs algorithm without differential privacy.</p>
</dd>
<dt><code>delta</code></dt><dd><p>Nonnegative real number defining the delta privacy parameter.
If 0, reduces to pure eps-DP.</p>
</dd>
<dt><code>domain</code></dt><dd><p>List of functions representing the constraints on the search
space for the objective perturbation algorithm. Must contain two
functions, labeled &quot;constraints&quot; and &quot;jacobian&quot;, respectively. The
&quot;constraints&quot; function accepts a vector of coefficients from the search
space and returns a value such that the value is nonpositive if and only
if the input coefficient vector is within the constrained search space.
The &quot;jacobian&quot; function also accepts a vector of coefficients and returns
the Jacobian of the constraint function. For example, in linear
regression, the square of the l2-norm of the coefficient vector
<code class="reqn">\theta</code> is assumed to be bounded above by p, where p is the length
of <code class="reqn">\theta</code> (Kifer et al. 2012). So, domain could be
defined as <code>domain &lt;- list("constraints"=function(coeff) coeff%*%coeff-length(coeff), "jacobian"=function(coeff) 2*coeff)</code>.</p>
</dd>
<dt><code>zeta</code></dt><dd><p>Positive real number denoting the upper bound on the l2-norm
value of the gradient of the loss function, as required to ensure
differential privacy.</p>
</dd>
<dt><code>lambda</code></dt><dd><p>Positive real number corresponding to the upper bound of the
Eigenvalues of the Hessian of the loss function for all possible inputs.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Nonnegative real number representing the regularization
constant.</p>
</dd>
<dt><code>mapXy.gr</code></dt><dd><p>Optional function representing the gradient of the map
function with respect to the values in <code>coeff</code>. If given, must be of
the form <code>mapXy.gr(X, coeff)</code>, where <code>X</code> is a matrix and
<code>coeff</code> is a matrix or numeric vector. Should be defined such that
the ith row of the output represents the gradient with respect to the ith
coefficient. See <code><a href="#topic+mapXy.gr.linear">mapXy.gr.linear</a></code> for an example. If not
given, non-gradient based optimization methods are used to compute the
coefficient values in fitting the model.</p>
</dd>
<dt><code>loss.gr</code></dt><dd><p>Optional function representing the gradient of the loss
function with respect to <code>y.hat</code> and of the form
<code>loss.gr(y.hat, y)</code>, where <code>y.hat</code> and <code>y</code> are matrices.
Should be defined such that the ith row of the output represents the
gradient of the loss function at the ith set of input values. See
<code><a href="#topic+loss.gr.squared.error">loss.gr.squared.error</a></code> for an example. If not given,
non-gradient based optimization methods are used to compute the
coefficient values in fitting the model.</p>
</dd>
<dt><code>regularizer.gr</code></dt><dd><p>Optional function representing the gradient of the
regularization function with respect to <code>coeff</code> and of the form
<code>regularizer.gr(coeff)</code>. Should return a vector. See
<code><a href="#topic+regularizer.gr.l2">regularizer.gr.l2</a></code> for an example. If <code>regularizer</code> is
given as a string, this value is ignored. If not given and
<code>regularizer</code> is a function, non-gradient based optimization methods
are used to compute the coefficient values in fitting the model.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new EmpiricalRiskMinimizationDP.KST object.
</p>


<hr>
<a id="method-EmpiricalRiskMinimizationDP.KST-fit"></a>



<h4>Method <code>fit()</code></h4>

<p>Fit the differentially private emprirical risk minimization
model. The function runs the objective perturbation algorithm
(Kifer et al. 2012) to generate an objective function. A
numerical optimization method is then run to find optimal coefficients
for fitting the model given the training data and hyperparameters. The
<code><a href="nloptr.html#topic+nloptr">nloptr</a></code> function is used. If mapXy.gr, loss.gr, and
regularizer.gr are all given in the construction of the object, the
gradient of the objective function and the Jacobian of the constraint
function are utilized for the algorithm, and the NLOPT_LD_MMA method is
used. If one or more of these gradient functions are not given, the
NLOPT_LN_COBYLA method is used. The resulting privacy-preserving
coefficients are stored in coeff.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmpiricalRiskMinimizationDP.KST$fit(
  X,
  y,
  upper.bounds,
  lower.bounds,
  add.bias = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data to be fit.</p>
</dd>
<dt><code>y</code></dt><dd><p>Vector or matrix of true values for each row of <code>X</code>.</p>
</dd>
<dt><code>upper.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)+1</code> giving upper
bounds on the values in each column of <code>X</code> and the values of
<code>y</code>. The last value in the vector is assumed to be the upper bound
on <code>y</code>, while the first <code>ncol(X)</code> values are assumed to be in
the same order as the corresponding columns of <code>X</code>. Any value in the
columns of <code>X</code> and in <code>y</code> larger than the corresponding upper
bound is clipped at the bound.</p>
</dd>
<dt><code>lower.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)+1</code> giving lower
bounds on the values in each column of <code>X</code> and the values of
<code>y</code>. The last value in the vector is assumed to be the lower bound
on <code>y</code>, while the first <code>ncol(X)</code> values are assumed to be in
the same order as the corresponding columns of <code>X</code>. Any value in the
columns of <code>X</code> and in <code>y</code> larger than the corresponding lower
bound is clipped at the bound.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-EmpiricalRiskMinimizationDP.KST-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict y values for given X using the fitted coefficients.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmpiricalRiskMinimizationDP.KST$predict(X, add.bias = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data on which to make predictions. Must be of same
form as <code>X</code> used to fit coefficients.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE. If add.bias was set to TRUE when fitting the
coefficients, add.bias should be set to TRUE for predictions.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Matrix of predicted y values corresponding to each row of X.
</p>


<hr>
<a id="method-EmpiricalRiskMinimizationDP.KST-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>EmpiricalRiskMinimizationDP.KST$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Kifer D, Smith A, Thakurta A (2012).
&ldquo;Private Convex Empirical Risk Minimization and High-dimensional Regression.&rdquo;
In Mannor S, Srebro N, Williamson RC (eds.), <em>Proceedings of the 25th Annual Conference on Learning Theory</em>, volume 23 of <em>Proceedings of Machine Learning Research</em>, 25.1&ndash;25.40.
<a href="https://proceedings.mlr.press/v23/kifer12.html">https://proceedings.mlr.press/v23/kifer12.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build example dataset
n &lt;- 500
X &lt;- data.frame(X=seq(-1,1,length.out = n))
true.theta &lt;- c(-.3,.5) # First element is bias term
p &lt;- length(true.theta)
y &lt;- true.theta[1] + as.matrix(X)%*%true.theta[2:p] + stats::rnorm(n=n,sd=.1)

# Construct object for linear regression
mapXy &lt;- function(X, coeff) X%*%coeff
loss &lt;- function(y.hat, y) (y.hat-y)^2/2
regularizer &lt;- 'l2' # Alternatively, function(coeff) coeff%*%coeff/2
eps &lt;- 1
delta &lt;- 1
domain &lt;- list("constraints"=function(coeff) coeff%*%coeff-length(coeff),
  "jacobian"=function(coeff) 2*coeff)
# Set p to be the number of predictors desired including intercept term (length of coeff)
zeta &lt;- 2*p^(3/2) # Proper bound for linear regression
lambda &lt;- p # Proper bound for linear regression
gamma &lt;- 1
mapXy.gr &lt;- function(X, coeff) t(X)
loss.gr &lt;- function(y.hat, y) y.hat-y
regularizer.gr &lt;- function(coeff) coeff

ermdp &lt;- EmpiricalRiskMinimizationDP.KST$new(mapXy, loss, 'l2', eps, delta,
                                             domain, zeta, lambda,
                                             gamma, mapXy.gr, loss.gr,
                                             regularizer.gr)

# Fit with data
# We must assume y is a matrix with values between -p and p (-2 and 2
#   for this example)
upper.bounds &lt;- c(1, 2) # Bounds for X and y
lower.bounds &lt;- c(-1,-2) # Bounds for X and y
ermdp$fit(X, y, upper.bounds, lower.bounds, add.bias=TRUE)
ermdp$coeff # Gets private coefficients

# Predict new data points
# Build a test dataset
Xtest &lt;- data.frame(X=c(-.5, -.25, .1, .4))
predicted.y &lt;- ermdp$predict(Xtest, add.bias=TRUE)

</code></pre>

<hr>
<h2 id='ExponentialMechanism'>Exponential Mechanism</h2><span id='topic+ExponentialMechanism'></span>

<h3>Description</h3>

<p>This function implements the exponential mechanism for differential privacy
by selecting the index of a vector of candidates to return according to a
user-specified vector of utility function values, epsilon, and global
sensitivity. Sensitivity calculated based either on bounded or unbounded
differential privacy can be used (Kifer and Machanavajjhala 2011). If measure
is provided, the probabilities of selecting each value are scaled according
to the values in measure. If candidates is provided, the function returns the
value of candidates at the selected index, rather than the index itself.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExponentialMechanism(
  utility,
  eps,
  sensitivity,
  measure = NULL,
  candidates = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ExponentialMechanism_+3A_utility">utility</code></td>
<td>
<p>Numeric vector giving the utilities of the possible values.</p>
</td></tr>
<tr><td><code id="ExponentialMechanism_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="ExponentialMechanism_+3A_sensitivity">sensitivity</code></td>
<td>
<p>Real number corresponding to the l1-global sensitivity of
the function generating utility.</p>
</td></tr>
<tr><td><code id="ExponentialMechanism_+3A_measure">measure</code></td>
<td>
<p>Optional numeric vector of scaling measures for the
probabilities of selecting each value. Should be same size as utility.
Defaults to uniform scaling.</p>
</td></tr>
<tr><td><code id="ExponentialMechanism_+3A_candidates">candidates</code></td>
<td>
<p>Optional vector of candidates of same size as utility. If
given, the function returns the candidate at the selected index rather than
the index itself.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Indices (or values if candidates given) selected by the mechanism
based on the bounded and/or unbounded definitions of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>McSherry F, Talwar K (2007).
&ldquo;Mechanism Design via Differential Privacy.&rdquo;
In <em>48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07)</em>, 94-103.
<a href="https://doi.org/10.1109/FOCS.2007.66">doi:10.1109/FOCS.2007.66</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>candidates &lt;- c('a','b','c','d','e','f','g')
# Release index
idx &lt;- ExponentialMechanism(c(0,1,2,3,2,1,0), 1, 1)
candidates[idx] # Randomly chosen candidate

# Release candidate
ExponentialMechanism(c(0,1,2,3,2,1,0), 1, .5, measure=c(1,1,2,1,2,1,1),
  candidates=candidates)

</code></pre>

<hr>
<h2 id='GaussianMechanism'>Gaussian Mechanism</h2><span id='topic+GaussianMechanism'></span>

<h3>Description</h3>

<p>This function implements the Gaussian mechanism for differential privacy by
adding noise to the true value(s) of a function according to specified values
of epsilon, delta, and l2-global sensitivity(-ies). Global sensitivity
calculated based either on bounded or unbounded differential privacy can be
used (Kifer and Machanavajjhala 2011). If true.values is a vector, the provided
epsilon and delta are divided such that (epsilon, delta)-level differential
privacy is satisfied across all function values. In the case that each
element of true.values comes from its own function with different
corresponding sensitivities, a vector of sensitivities may be provided. In
this case, if desired, the user can specify how to divide epsilon and delta
among the function values using alloc.proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GaussianMechanism(
  true.values,
  eps,
  delta,
  sensitivities,
  type.DP = "aDP",
  alloc.proportions = NULL,
  analytic = FALSE,
  tol = 1e-12
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GaussianMechanism_+3A_true.values">true.values</code></td>
<td>
<p>Real number or numeric vector corresponding to the true
value(s) of the desired function.</p>
</td></tr>
<tr><td><code id="GaussianMechanism_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy parameter.</p>
</td></tr>
<tr><td><code id="GaussianMechanism_+3A_delta">delta</code></td>
<td>
<p>Positive real number defining the delta privacy parameter.</p>
</td></tr>
<tr><td><code id="GaussianMechanism_+3A_sensitivities">sensitivities</code></td>
<td>
<p>Real number or numeric vector corresponding to the
l2-global sensitivity(-ies) of the function(s) generating true.values. This
value must be of length 1 or of the same length as true.values. If it is of
length 1 and true.values is a vector, this indicates that the given
sensitivity applies simultaneously to all elements of true.values and that
the privacy budget need not be allocated (alloc.proportions is unused in
this case). If it is of the same length as true.values, this indicates that
each element of true.values comes from its own function with different
corresponding sensitivities. In this case, the l2-norm of the provided
sensitivities is used to generate the Gaussian noise.</p>
</td></tr>
<tr><td><code id="GaussianMechanism_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism. Can be either 'pDP' for probabilistic DP
(Liu 2019) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
<tr><td><code id="GaussianMechanism_+3A_alloc.proportions">alloc.proportions</code></td>
<td>
<p>Optional numeric vector giving the allocation
proportions of epsilon and delta to the function values in the case of
vector-valued sensitivities. For example, if sensitivities is of length two
and alloc.proportions = c(.75, .25), then 75% of the privacy budget eps
(and 75% of delta) is allocated to the noise computation for the first
element of true.values, and the remaining 25% is allocated to the noise
computation for the second element of true.values. This ensures (eps,
delta)-level privacy across all computations. Input does not need to be
normalized, meaning alloc.proportions = c(3,1) produces the same result as
the example above.</p>
</td></tr>
<tr><td><code id="GaussianMechanism_+3A_analytic">analytic</code></td>
<td>
<p>Indicates whether to use the analytic Gaussian mechanism to
compute the noise scale (Balle and Wang 2018). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="GaussianMechanism_+3A_tol">tol</code></td>
<td>
<p>Error tolerance for binary search used in determining the noise
parameter for the analytic Gaussian mechanism. Unused if analytic is FALSE.
Defaults to 1e-12.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized function values based on the bounded and/or unbounded
definitions of differential privacy, sanitized via the Gaussian mechanism.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Balle B, Wang Y (2018).
&ldquo;Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising.&rdquo;
In Dy J, Krause A (eds.), <em>Proceedings of the 35th International Conference on Machine Learning</em>, volume 80 of <em>Proceedings of Machine Learning Research</em>, 394&ndash;403.
<a href="https://proceedings.mlr.press/v80/balle18a.html">https://proceedings.mlr.press/v80/balle18a.html</a>.
</p>
<p>Liu F (2019).
&ldquo;Generalized Gaussian Mechanism for Differential Privacy.&rdquo;
<em>IEEE Transactions on Knowledge and Data Engineering</em>, <b>31</b>(4), 747-756.
<a href="https://doi.org/10.1109/TKDE.2018.2845388">https://doi.org/10.1109/TKDE.2018.2845388</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate dataset
n &lt;- 100
c0 &lt;- 5 # Lower bound
c1 &lt;- 10 # Upper bound
D1 &lt;- stats::runif(n, c0, c1)

# Privacy budget
epsilon &lt;- 0.9 # eps must be in (0, 1) for approximate differential privacy
delta &lt;- 0.01
sensitivity &lt;- (c1-c0)/n

# Approximate differential privacy
private.mean.approx &lt;- GaussianMechanism(mean(D1), epsilon, delta,
                                         sensitivity)
private.mean.approx

# Probabilistic differential privacy
private.mean.prob &lt;- GaussianMechanism(mean(D1), epsilon, delta, sensitivity,
                                       type.DP = 'pDP')
private.mean.prob

# Analytic Gaussian mechanism
epsilon &lt;- 1.1 # epsilon can be &gt; 1 for analytic Gaussian mechanism
private.mean.analytic &lt;- GaussianMechanism(mean(D1), epsilon, delta,
                                           sensitivity, analytic=TRUE)
private.mean.analytic

# Simulate second dataset
d0 &lt;- 3 # Lower bound
d1 &lt;- 6 # Upper bound
D2 &lt;- stats::runif(n, d0, d1)
D &lt;- matrix(c(D1,D2),ncol=2)
sensitivities &lt;- c((c1-c0)/n, (d1-d0)/n)
epsilon &lt;- 0.9 # Total privacy budget for all means
delta &lt;- 0.01

# Here, sensitivities are summed and the result is used to generate Laplace
# noise. This is essentially the same as allocating epsilon proportional to
# the corresponding sensitivity. The results satisfy (0.9,0.01)-approximate
# differential privacy.
private.means &lt;- GaussianMechanism(apply(D, 2, mean), epsilon, delta,
                                   sensitivities)
private.means

# Here, privacy budget is explicitly split so that 75% is given to the first
# vector element and 25% is given to the second.
private.means &lt;- GaussianMechanism(apply(D, 2, mean), epsilon, delta,
                                   sensitivities,
                                   alloc.proportions = c(0.75, 0.25))
private.means

</code></pre>

<hr>
<h2 id='generate.loss.gr.huber'>Generator for Huber Loss Function Gradient</h2><span id='topic+generate.loss.gr.huber'></span>

<h3>Description</h3>

<p>This function generates and returns the Huber loss function gradient used for
privacy-preserving SVM at the specified value of h in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.loss.gr.huber(h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate.loss.gr.huber_+3A_h">h</code></td>
<td>
<p>Positive real number for the Huber loss parameter. Lower values more
closely approximate hinge loss. Higher values produce smoother Huber loss
functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Huber loss function gradient with parameter h in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  h &lt;- 1
  huber &lt;- generate.loss.gr.huber(h)
  y.hat &lt;- c(-.5, 1.2, -0.9)
  y &lt;- c(-1, 1, -1)
  huber(y.hat,y)
  huber(y.hat, y, w=c(0.1, 0.5, 1)) # Weights observation-level loss gradient

</code></pre>

<hr>
<h2 id='generate.loss.huber'>Generator for Huber Loss Function</h2><span id='topic+generate.loss.huber'></span>

<h3>Description</h3>

<p>This function generates and returns the Huber loss function used for
privacy-preserving SVM at the specified value of h in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.loss.huber(h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate.loss.huber_+3A_h">h</code></td>
<td>
<p>Positive real number for the Huber loss parameter. Lower values more
closely approximate hinge loss. Higher values produce smoother Huber loss
functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Huber loss function with parameter h in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  h &lt;- 0.5
  huber &lt;- generate.loss.huber(h)
  y.hat &lt;- c(-.5, 1.2, -0.9)
  y &lt;- c(-1, 1, -1)
  huber(y.hat,y)
  huber(y.hat, y, w=c(0.1, 0.5, 1)) # Weights observation-level loss

</code></pre>

<hr>
<h2 id='generate.sampling'>Generator for Sampling Distribution Function for Gaussian Kernel</h2><span id='topic+generate.sampling'></span>

<h3>Description</h3>

<p>This function generates and returns a sampling function corresponding to the
Fourier transform of a Gaussian kernel with given parameter
(Chaudhuri et al. 2011) of form needed for <code><a href="#topic+svmDP">svmDP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.sampling(kernel.param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate.sampling_+3A_kernel.param">kernel.param</code></td>
<td>
<p>Positive real number for the Gaussian (radial) kernel
parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sampling function for the Gaussian kernel of form required by
<code><a href="#topic+svmDP">svmDP</a></code>.
</p>


<h3>References</h3>

<p>Chaudhuri K, Monteleoni C, Sarwate AD (2011).
&ldquo;Differentially Private Empirical Risk Minimization.&rdquo;
<em>Journal of Machine Learning Research</em>, <b>12</b>(29), 1069-1109.
<a href="https://jmlr.org/papers/v12/chaudhuri11a.html">https://jmlr.org/papers/v12/chaudhuri11a.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  kernel.param &lt;- 0.1
  sample &lt;- generate.sampling(kernel.param)
  d &lt;- 5
  sample(d)

</code></pre>

<hr>
<h2 id='histogramDataAccess'>Differentially Private Histogram Data Access Function</h2><span id='topic+histogramDataAccess'></span>

<h3>Description</h3>

<p>This function performs the data access step in the computation of a
differentially private histogram. The true values are computed using
<code><a href="graphics.html#topic+hist">hist</a></code>, while the sensitivities are calculated based on
bounded and unbounded differential privacy (Kifer and Machanavajjhala 2011)
according to the theoretical values (Liu 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>histogramDataAccess(x, breaks, mechanism)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="histogramDataAccess_+3A_x">x</code></td>
<td>
<p>Numeric vector from which the histogram will be formed..</p>
</td></tr>
<tr><td><code id="histogramDataAccess_+3A_breaks">breaks</code></td>
<td>
<p>Identical to the argument with the same name from
<code><a href="graphics.html#topic+hist">hist</a></code>.</p>
</td></tr>
<tr><td><code id="histogramDataAccess_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. If the 'Laplace' mechanism is chosen, l1 sensitivities are
returned. If the 'Gaussian' or 'analytic' mechanisms are chosen, l2
sensitivities are returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of the true histogram and the sensitivities calculated based on
bounded and unbounded differential privacy.
</p>


<h3>References</h3>

<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>histogramDataAccess(c(1,4,3,2,3), 'Sturges', 'Laplace')

</code></pre>

<hr>
<h2 id='histogramDP'>Differentially Private Histogram</h2><span id='topic+histogramDP'></span>

<h3>Description</h3>

<p>This function computes a differentially private histogram from a vector at
user-specified privacy levels of epsilon and delta. A histogram object is
returned with sanitized values for the counts for easy plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>histogramDP(
  x,
  eps,
  lower.bound,
  upper.bound,
  breaks = "Sturges",
  normalize = FALSE,
  which.sensitivity = "bounded",
  mechanism = "Laplace",
  delta = 0,
  type.DP = "aDP",
  allow.negative = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="histogramDP_+3A_x">x</code></td>
<td>
<p>Numeric vector from which the histogram will be formed.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Scalar representing the global or public lower bound on
values of x.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Scalar representing the global or public upper bound on
values of x.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_breaks">breaks</code></td>
<td>
<p>Identical to the argument with the same name from
<code><a href="graphics.html#topic+hist">hist</a></code>.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_normalize">normalize</code></td>
<td>
<p>Logical value. If FALSE (default), returned histogram counts
correspond to frequencies. If TRUE, returned histogram counts correspond to
densities (i.e. area of histogram is one).</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
delta)-differential privacy, but may not do so collectively and in
composition. Care must be taken not to violate differential privacy in this
case.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'Laplace',
'Gaussian', 'analytic'}. Default is Laplace. See <code><a href="#topic+LaplaceMechanism">LaplaceMechanism</a></code>
and <code><a href="#topic+GaussianMechanism">GaussianMechanism</a></code> for descriptions of the supported
mechanisms.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_delta">delta</code></td>
<td>
<p>Nonnegative real number defining the delta privacy parameter. If
0 (default), reduces to eps-DP.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism (if selected). Can be either 'pDP' for probabilistic
DP (Machanavajjhala et al. 2008) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
<tr><td><code id="histogramDP_+3A_allow.negative">allow.negative</code></td>
<td>
<p>Logical value. If FALSE (default), any negative values
in the sanitized histogram due to the added noise will be set to 0. If
TRUE, the negative values (if any) will be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized histogram based on the bounded and/or unbounded definitions
of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008).
&ldquo;Privacy: Theory meets Practice on the Map.&rdquo;
In <em>2008 IEEE 24th International Conference on Data Engineering</em>, 277-286.
<a href="https://doi.org/10.1109/ICDE.2008.4497436">doi:10.1109/ICDE.2008.4497436</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- stats::rnorm(500)
graphics::hist(x) # Non-private histogram
result &lt;- histogramDP(x, 1, -3, 3)
plot(result) # Private histogram

graphics::hist(x, freq=FALSE) # Normalized non-private histogram
result &lt;- histogramDP(x, .5, -3, 3, normalize=TRUE,
  which.sensitivity='unbounded', mechanism='Gaussian', delta=0.01,
  allow.negative=TRUE)
plot(result) # Normalized private histogram (note negative values allowed)

</code></pre>

<hr>
<h2 id='LaplaceMechanism'>Laplace Mechanism</h2><span id='topic+LaplaceMechanism'></span>

<h3>Description</h3>

<p>This function implements the Laplace mechanism for differential privacy by
adding noise to the true value(s) of a function according to specified values
of epsilon and l1-global sensitivity(-ies). Global sensitivity calculated
based either on bounded or unbounded differential privacy can be used
(Kifer and Machanavajjhala 2011). If true.values is a vector, the provided
epsilon is divided such that epsilon-differential privacy is satisfied across
all function values. In the case that each element of true.values comes from
its own function with different corresponding sensitivities, a vector of
sensitivities may be provided. In this case, if desired, the user can specify
how to divide epsilon among the function values using alloc.proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LaplaceMechanism(true.values, eps, sensitivities, alloc.proportions = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LaplaceMechanism_+3A_true.values">true.values</code></td>
<td>
<p>Real number or numeric vector corresponding to the true
value(s) of the desired function.</p>
</td></tr>
<tr><td><code id="LaplaceMechanism_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy parameter.</p>
</td></tr>
<tr><td><code id="LaplaceMechanism_+3A_sensitivities">sensitivities</code></td>
<td>
<p>Real number or numeric vector corresponding to the
l1-global sensitivity(-ies) of the function(s) generating true.values. This
value must be of length 1 or of the same length as true.values. If it is of
length 1 and true.values is a vector, this indicates that the given
sensitivity applies simultaneously to all elements of true.values and that
the privacy budget need not be allocated (alloc.proportions is unused in
this case). If it is of the same length as true.values, this indicates that
each element of true.values comes from its own function with different
corresponding sensitivities. In this case, the l1-norm of the provided
sensitivities is used to generate the Laplace noise.</p>
</td></tr>
<tr><td><code id="LaplaceMechanism_+3A_alloc.proportions">alloc.proportions</code></td>
<td>
<p>Optional numeric vector giving the allocation
proportions of epsilon to the function values in the case of vector-valued
sensitivities. For example, if sensitivities is of length two and
alloc.proportions = c(.75, .25), then 75% of the privacy budget eps is
allocated to the noise computation for the first element of true.values,
and the remaining 25% is allocated to the noise computation for the second
element of true.values. This ensures eps-level privacy across all
computations. Input does not need to be normalized, meaning
alloc.proportions = c(3,1) produces the same result as the example above.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized function values based on the bounded and/or unbounded
definitions of differential privacy, sanitized via the Laplace mechanism.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate dataset
n &lt;- 100
c0 &lt;- 5 # Lower bound
c1 &lt;- 10 # Upper bound
D1 &lt;- stats::runif(n, c0, c1)
epsilon &lt;- 1 # Privacy budget
sensitivity &lt;- (c1-c0)/n

private.mean &lt;- LaplaceMechanism(mean(D1), epsilon, sensitivity)
private.mean

# Simulate second dataset
d0 &lt;- 3 # Lower bound
d1 &lt;- 6 # Upper bound
D2 &lt;- stats::runif(n, d0, d1)
D &lt;- matrix(c(D1,D2),ncol=2)
sensitivities &lt;- c((c1-c0)/n, (d1-d0)/n)
epsilon &lt;- 1 # Total privacy budget for all means

# Here, sensitivities are summed and the result is used to generate Laplace
# noise. This is essentially the same as allocating epsilon proportional to
# the corresponding sensitivity. The results satisfy 1-differential privacy.
private.means &lt;- LaplaceMechanism(apply(D, 2, mean), epsilon, sensitivities)
private.means

# Here, privacy budget is explicitly split so that 75% is given to the first
# vector element and 25% is given to the second.
private.means &lt;- LaplaceMechanism(apply(D, 2, mean), epsilon, sensitivities,
                                  alloc.proportions = c(0.75, 0.25))
private.means

</code></pre>

<hr>
<h2 id='LinearRegressionDP'>Privacy-preserving Linear Regression</h2><span id='topic+LinearRegressionDP'></span>

<h3>Description</h3>

<p>This class implements differentially private linear regression
using the objective perturbation technique (Kifer et al. 2012).
</p>


<h3>Details</h3>

<p>To use this class for linear regression, first use the <code>new</code>
method to construct an object of this class with the desired function
values and hyperparameters. After constructing the object, the <code>fit</code>
method can be applied with a provided dataset and data bounds to fit the
model. In fitting, the model stores a vector of coefficients <code>coeff</code>
which satisfy differential privacy. These can be released directly, or used
in conjunction with the <code>predict</code> method to privately predict the
outcomes of new datapoints.
</p>
<p>Note that in order to guarantee differential privacy for linear regression,
certain constraints must be satisfied for the values used to construct the
object, as well as for the data used to fit. The regularizer must be
convex. Additionally, it is assumed that if x represents a single row of
the dataset X, then the l2-norm of x is at most p for all x, where p is the
number of predictors (including any possible intercept term). In order to
ensure this constraint is satisfied, the dataset is preprocessed and
scaled, and the resulting coefficients are postprocessed and un-scaled so
that the stored coefficients correspond to the original data. Due to this
constraint on x, it is best to avoid using an intercept term in the model
whenever possible. If an intercept term must be used, the issue can be
partially circumvented by adding a constant column to X before fitting the
model, which will be scaled along with the rest of X. The <code>fit</code> method
contains functionality to add a column of constant 1s to X before scaling,
if desired.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+EmpiricalRiskMinimizationDP.KST">DPpack::EmpiricalRiskMinimizationDP.KST</a></code> -&gt; <code>LinearRegressionDP</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LinearRegressionDP-new"><code>LinearRegressionDP$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LinearRegressionDP-fit"><code>LinearRegressionDP$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-LinearRegressionDP-clone"><code>LinearRegressionDP$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="DPpack" data-topic="EmpiricalRiskMinimizationDP.KST" data-id="predict"><a href='../../DPpack/html/EmpiricalRiskMinimizationDP.KST.html#method-EmpiricalRiskMinimizationDP.KST-predict'><code>DPpack::EmpiricalRiskMinimizationDP.KST$predict()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LinearRegressionDP-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new LinearRegressionDP object.
</p>


<h5>Usage</h5>

<div class="r"><pre>LinearRegressionDP$new(regularizer, eps, delta, gamma, regularizer.gr = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>regularizer</code></dt><dd><p>String or regularization function. If a string, must be
'l2', indicating to use l2 regularization. If a function, must have form
<code>regularizer(coeff)</code>, where <code>coeff</code> is a vector or matrix, and
return the value of the regularizer at <code>coeff</code>. See
<code><a href="#topic+regularizer.l2">regularizer.l2</a></code> for an example. Additionally, in order to
ensure differential privacy, the function must be convex.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Positive real number defining the epsilon privacy budget. If set
to Inf, runs algorithm without differential privacy.</p>
</dd>
<dt><code>delta</code></dt><dd><p>Nonnegative real number defining the delta privacy parameter.
If 0, reduces to pure eps-DP.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Nonnegative real number representing the regularization
constant.</p>
</dd>
<dt><code>regularizer.gr</code></dt><dd><p>Optional function representing the gradient of the
regularization function with respect to <code>coeff</code> and of the form
<code>regularizer.gr(coeff)</code>. Should return a vector. See
<code><a href="#topic+regularizer.gr.l2">regularizer.gr.l2</a></code> for an example. If <code>regularizer</code> is
given as a string, this value is ignored. If not given and
<code>regularizer</code> is a function, non-gradient based optimization methods
are used to compute the coefficient values in fitting the model.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new LinearRegressionDP object.
</p>


<hr>
<a id="method-LinearRegressionDP-fit"></a>



<h4>Method <code>fit()</code></h4>

<p>Fit the differentially private linear regression model. The
function runs the objective perturbation algorithm
(Kifer et al. 2012) to generate an objective function. A
numerical optimization method is then run to find optimal coefficients
for fitting the model given the training data and hyperparameters. The
<code><a href="nloptr.html#topic+nloptr">nloptr</a></code> function is used. If <code>regularizer</code> is given as
'l2' or if <code>regularizer.gr</code> is given in the construction of the
object, the gradient of the objective function and the Jacobian of the
constraint function are utilized for the algorithm, and the NLOPT_LD_MMA
method is used. If this is not the case, the NLOPT_LN_COBYLA method is
used. The resulting privacy-preserving coefficients are stored in coeff.
</p>


<h5>Usage</h5>

<div class="r"><pre>LinearRegressionDP$fit(X, y, upper.bounds, lower.bounds, add.bias = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data to be fit.</p>
</dd>
<dt><code>y</code></dt><dd><p>Vector or matrix of true values for each row of <code>X</code>.</p>
</dd>
<dt><code>upper.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)+1</code> giving upper
bounds on the values in each column of <code>X</code> and the values of
<code>y</code>. The last value in the vector is assumed to be the upper bound
on <code>y</code>, while the first <code>ncol(X)</code> values are assumed to be in
the same order as the corresponding columns of <code>X</code>. Any value in the
columns of <code>X</code> and in <code>y</code> larger than the corresponding upper
bound is clipped at the bound.</p>
</dd>
<dt><code>lower.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)+1</code> giving lower
bounds on the values in each column of <code>X</code> and the values of
<code>y</code>. The last value in the vector is assumed to be the lower bound
on <code>y</code>, while the first <code>ncol(X)</code> values are assumed to be in
the same order as the corresponding columns of <code>X</code>. Any value in the
columns of <code>X</code> and in <code>y</code> larger than the corresponding lower
bound is clipped at the bound.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LinearRegressionDP-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LinearRegressionDP$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Kifer D, Smith A, Thakurta A (2012).
&ldquo;Private Convex Empirical Risk Minimization and High-dimensional Regression.&rdquo;
In Mannor S, Srebro N, Williamson RC (eds.), <em>Proceedings of the 25th Annual Conference on Learning Theory</em>, volume 23 of <em>Proceedings of Machine Learning Research</em>, 25.1&ndash;25.40.
<a href="https://proceedings.mlr.press/v23/kifer12.html">https://proceedings.mlr.press/v23/kifer12.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build example dataset
n &lt;- 500
X &lt;- data.frame(X=seq(-1,1,length.out = n))
true.theta &lt;- c(-.3,.5) # First element is bias term
p &lt;- length(true.theta)
y &lt;- true.theta[1] + as.matrix(X)%*%true.theta[2:p] + stats::rnorm(n=n,sd=.1)

# Construct object for linear regression
regularizer &lt;- 'l2' # Alternatively, function(coeff) coeff%*%coeff/2
eps &lt;- 1
delta &lt;- 0 # Indicates to use pure eps-DP
gamma &lt;- 1
regularizer.gr &lt;- function(coeff) coeff

lrdp &lt;- LinearRegressionDP$new('l2', eps, delta, gamma, regularizer.gr)

# Fit with data
# We must assume y is a matrix with values between -p and p (-2 and 2
#   for this example)
upper.bounds &lt;- c(1, 2) # Bounds for X and y
lower.bounds &lt;- c(-1,-2) # Bounds for X and y
lrdp$fit(X, y, upper.bounds, lower.bounds, add.bias=TRUE)
lrdp$coeff # Gets private coefficients

# Predict new data points
# Build a test dataset
Xtest &lt;- data.frame(X=c(-.5, -.25, .1, .4))
predicted.y &lt;- lrdp$predict(Xtest, add.bias=TRUE)

</code></pre>

<hr>
<h2 id='LogisticRegressionDP'>Privacy-preserving Logistic Regression</h2><span id='topic+LogisticRegressionDP'></span>

<h3>Description</h3>

<p>This class implements differentially private logistic regression
(Chaudhuri et al. 2011). Either the output or the objective
perturbation method can be used.
</p>


<h3>Details</h3>

<p>To use this class for logistic regression, first use the <code>new</code>
method to construct an object of this class with the desired function
values and hyperparameters. After constructing the object, the <code>fit</code>
method can be applied with a provided dataset and data bounds to fit the
model. In fitting, the model stores a vector of coefficients <code>coeff</code>
which satisfy differential privacy. These can be released directly, or used
in conjunction with the <code>predict</code> method to privately predict the
outcomes of new datapoints.
</p>
<p>Note that in order to guarantee differential privacy for logistic
regression, certain constraints must be satisfied for the values used to
construct the object, as well as for the data used to fit. These conditions
depend on the chosen perturbation method. The regularizer must be
1-strongly convex and differentiable. It also must be doubly differentiable
if objective perturbation is chosen. Additionally, it is assumed that if x
represents a single row of the dataset X, then the l2-norm of x is at most
1 for all x. In order to ensure this constraint is satisfied, the dataset
is preprocessed and scaled, and the resulting coefficients are
postprocessed and un-scaled so that the stored coefficients correspond to
the original data. Due to this constraint on x, it is best to avoid using a
bias term in the model whenever possible. If a bias term must be used, the
issue can be partially circumvented by adding a constant column to X before
fitting the model, which will be scaled along with the rest of X. The
<code>fit</code> method contains functionality to add a column of constant 1s to
X before scaling, if desired.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">DPpack::EmpiricalRiskMinimizationDP.CMS</a></code> -&gt; <code>LogisticRegressionDP</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LogisticRegressionDP-new"><code>LogisticRegressionDP$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LogisticRegressionDP-fit"><code>LogisticRegressionDP$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-LogisticRegressionDP-predict"><code>LogisticRegressionDP$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-LogisticRegressionDP-clone"><code>LogisticRegressionDP$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-LogisticRegressionDP-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>LogisticRegressionDP</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>LogisticRegressionDP$new(
  regularizer,
  eps,
  gamma,
  perturbation.method = "objective",
  regularizer.gr = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>regularizer</code></dt><dd><p>String or regularization function. If a string, must be
'l2', indicating to use l2 regularization. If a function, must have form
<code>regularizer(coeff)</code>, where <code>coeff</code> is a vector or matrix, and
return the value of the regularizer at <code>coeff</code>. See
<code><a href="#topic+regularizer.l2">regularizer.l2</a></code> for an example. Additionally, in order to
ensure differential privacy, the function must be 1-strongly convex and
doubly differentiable.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Positive real number defining the epsilon privacy budget. If set
to Inf, runs algorithm without differential privacy.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Nonnegative real number representing the regularization
constant.</p>
</dd>
<dt><code>perturbation.method</code></dt><dd><p>String indicating whether to use the 'output' or
the 'objective' perturbation methods (Chaudhuri et al. 2011).
Defaults to 'objective'.</p>
</dd>
<dt><code>regularizer.gr</code></dt><dd><p>Optional function representing the gradient of the
regularization function with respect to <code>coeff</code> and of the form
<code>regularizer.gr(coeff)</code>. Should return a vector. See
<code><a href="#topic+regularizer.gr.l2">regularizer.gr.l2</a></code> for an example. If <code>regularizer</code> is
given as a string, this value is ignored. If not given and
<code>regularizer</code> is a function, non-gradient based optimization methods
are used to compute the coefficient values in fitting the model.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>LogisticRegressionDP</code> object.
</p>


<hr>
<a id="method-LogisticRegressionDP-fit"></a>



<h4>Method <code>fit()</code></h4>

<p>Fit the differentially private logistic regression model. This
method runs either the output perturbation or the objective perturbation
algorithm (Chaudhuri et al. 2011), depending on the value of
perturbation.method used to construct the object, to generate an
objective function. A numerical optimization method is then run to find
optimal coefficients for fitting the model given the training data and
hyperparameters. The built-in <code><a href="stats.html#topic+optim">optim</a></code> function using the
&quot;BFGS&quot; optimization method is used. If <code>regularizer</code> is given as
'l2' or if <code>regularizer.gr</code> is given in the construction of the
object, the gradient of the objective function is utilized by
<code>optim</code> as well. Otherwise, non-gradient based optimization methods
are used. The resulting privacy-preserving coefficients are stored in
<code>coeff</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>LogisticRegressionDP$fit(X, y, upper.bounds, lower.bounds, add.bias = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data to be fit.</p>
</dd>
<dt><code>y</code></dt><dd><p>Vector or matrix of true labels for each row of <code>X</code>.</p>
</dd>
<dt><code>upper.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)</code> giving upper
bounds on the values in each column of X. The <code>ncol(X)</code> values are
assumed to be in the same order as the corresponding columns of <code>X</code>.
Any value in the columns of <code>X</code> larger than the corresponding upper
bound is clipped at the bound.</p>
</dd>
<dt><code>lower.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)</code> giving lower
bounds on the values in each column of <code>X</code>. The <code>ncol(X)</code>
values are assumed to be in the same order as the corresponding columns
of <code>X</code>. Any value in the columns of <code>X</code> larger than the
corresponding upper bound is clipped at the bound.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LogisticRegressionDP-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict label(s) for given <code>X</code> using the fitted
coefficients.
</p>


<h5>Usage</h5>

<div class="r"><pre>LogisticRegressionDP$predict(X, add.bias = FALSE, raw.value = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data on which to make predictions. Must be of same
form as <code>X</code> used to fit coefficients.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE. If add.bias was set to TRUE when fitting the
coefficients, add.bias should be set to TRUE for predictions.</p>
</dd>
<dt><code>raw.value</code></dt><dd><p>Boolean indicating whether to return the raw predicted
value or the rounded class label. If FALSE (default), outputs the
predicted labels 0 or 1. If TRUE, returns the raw score from the logistic
regression.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Matrix of predicted labels or scores corresponding to each row of
<code>X</code>.
</p>


<hr>
<a id="method-LogisticRegressionDP-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LogisticRegressionDP$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Chaudhuri K, Monteleoni C, Sarwate AD (2011).
&ldquo;Differentially Private Empirical Risk Minimization.&rdquo;
<em>Journal of Machine Learning Research</em>, <b>12</b>(29), 1069-1109.
<a href="https://jmlr.org/papers/v12/chaudhuri11a.html">https://jmlr.org/papers/v12/chaudhuri11a.html</a>.
</p>
<p>Chaudhuri K, Monteleoni C (2009).
&ldquo;Privacy-preserving logistic regression.&rdquo;
In Koller D, Schuurmans D, Bengio Y, Bottou L (eds.), <em>Advances in Neural Information Processing Systems</em>, volume 21.
<a href="https://proceedings.neurips.cc/paper/2008/file/8065d07da4a77621450aa84fee5656d9-Paper.pdf">https://proceedings.neurips.cc/paper/2008/file/8065d07da4a77621450aa84fee5656d9-Paper.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build train dataset X and y, and test dataset Xtest and ytest
N &lt;- 200
K &lt;- 2
X &lt;- data.frame()
y &lt;- data.frame()
for (j in (1:K)){
  t &lt;- seq(-.25, .25, length.out = N)
  if (j==1) m &lt;- stats::rnorm(N,-.2, .1)
  if (j==2) m &lt;- stats::rnorm(N, .2, .1)
  Xtemp &lt;- data.frame(x1 = 3*t , x2 = m - t)
  ytemp &lt;- data.frame(matrix(j-1, N, 1))
  X &lt;- rbind(X, Xtemp)
  y &lt;- rbind(y, ytemp)
}
Xtest &lt;- X[seq(1,(N*K),10),]
ytest &lt;- y[seq(1,(N*K),10),,drop=FALSE]
X &lt;- X[-seq(1,(N*K),10),]
y &lt;- y[-seq(1,(N*K),10),,drop=FALSE]

# Construct object for logistic regression
regularizer &lt;- 'l2' # Alternatively, function(coeff) coeff%*%coeff/2
eps &lt;- 1
gamma &lt;- 1
lrdp &lt;- LogisticRegressionDP$new(regularizer, eps, gamma)

# Fit with data
# Bounds for X based on construction
upper.bounds &lt;- c( 1, 1)
lower.bounds &lt;- c(-1,-1)
lrdp$fit(X, y, upper.bounds, lower.bounds) # No bias term
lrdp$coeff # Gets private coefficients

# Predict new data points
predicted.y &lt;- lrdp$predict(Xtest)
n.errors &lt;- sum(predicted.y!=ytest)

</code></pre>

<hr>
<h2 id='loss.cross.entropy'>Cross Entropy Loss Function</h2><span id='topic+loss.cross.entropy'></span>

<h3>Description</h3>

<p>This function implements cross entropy loss used for logistic regression in
the form required by <code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss.cross.entropy(y.hat, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loss.cross.entropy_+3A_y.hat">y.hat</code></td>
<td>
<p>Vector or matrix of estimated labels.</p>
</td></tr>
<tr><td><code id="loss.cross.entropy_+3A_y">y</code></td>
<td>
<p>Vector or matrix of true labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector or matrix of the cross entropy loss for each element of y.hat
and y.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  y.hat &lt;- c(0.1, 0.88, 0.02)
  y &lt;- c(0, 1, 0)
  loss.cross.entropy(y.hat,y)

</code></pre>

<hr>
<h2 id='loss.gr.cross.entropy'>Cross Entropy Loss Function Gradient</h2><span id='topic+loss.gr.cross.entropy'></span>

<h3>Description</h3>

<p>This function implements cross entropy loss gradient with respect to y.hat
used for logistic regression in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss.gr.cross.entropy(y.hat, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loss.gr.cross.entropy_+3A_y.hat">y.hat</code></td>
<td>
<p>Vector or matrix of estimated labels.</p>
</td></tr>
<tr><td><code id="loss.gr.cross.entropy_+3A_y">y</code></td>
<td>
<p>Vector or matrix of true labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector or matrix of the cross entropy loss gradient for each element
of y.hat and y.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  y.hat &lt;- c(0.1, 0.88, 0.02)
  y &lt;- c(0, 1, 0)
  loss.gr.cross.entropy(y.hat,y)

</code></pre>

<hr>
<h2 id='loss.gr.squared.error'>Squared error Loss Function Gradient</h2><span id='topic+loss.gr.squared.error'></span>

<h3>Description</h3>

<p>This function implements the squared error loss gradient with respect to
y.hat used for linear regression in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.KST">EmpiricalRiskMinimizationDP.KST</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss.gr.squared.error(y.hat, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loss.gr.squared.error_+3A_y.hat">y.hat</code></td>
<td>
<p>Vector or matrix of estimated values.</p>
</td></tr>
<tr><td><code id="loss.gr.squared.error_+3A_y">y</code></td>
<td>
<p>Vector or matrix of true values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector or matrix of the squared error loss gradient for each element
of y.hat and y.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  y.hat &lt;- c(0.1, 0.88, 0.02)
  y &lt;- c(-0.1, 1, .2)
  loss.gr.squared.error(y.hat,y)

</code></pre>

<hr>
<h2 id='loss.squared.error'>Squared Error Loss Function</h2><span id='topic+loss.squared.error'></span>

<h3>Description</h3>

<p>This function implements squared error loss used for linear regression in
the form required by <code><a href="#topic+EmpiricalRiskMinimizationDP.KST">EmpiricalRiskMinimizationDP.KST</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss.squared.error(y.hat, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loss.squared.error_+3A_y.hat">y.hat</code></td>
<td>
<p>Vector or matrix of estimated labels.</p>
</td></tr>
<tr><td><code id="loss.squared.error_+3A_y">y</code></td>
<td>
<p>Vector or matrix of true labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector or matrix of the squared error loss for each element of y.hat
and y.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  y.hat &lt;- c(0.1, 0.88, 0.02)
  y &lt;- c(0, 1, 0)
  loss.squared.error(y.hat,y)

</code></pre>

<hr>
<h2 id='mapXy.gr.linear'>Linear Map Function Gradient</h2><span id='topic+mapXy.gr.linear'></span>

<h3>Description</h3>

<p>This function implements the gradient of the linear map function with respect
to coeff used for linear SVM and linear regression in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code> and
<code><a href="#topic+EmpiricalRiskMinimizationDP.KST">EmpiricalRiskMinimizationDP.KST</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapXy.gr.linear(X, coeff)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapXy.gr.linear_+3A_x">X</code></td>
<td>
<p>Matrix of data.</p>
</td></tr>
<tr><td><code id="mapXy.gr.linear_+3A_coeff">coeff</code></td>
<td>
<p>Vector or matrix of coefficients or weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of values of the gradient of the linear map function with
respect to each value of coeff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  X &lt;- matrix(c(1,2,3,4,5,6),nrow=2)
  coeff &lt;- c(0.5,-1,2)
  mapXy.gr.linear(X,coeff)

</code></pre>

<hr>
<h2 id='mapXy.gr.sigmoid'>Sigmoid Map Function Gradient</h2><span id='topic+mapXy.gr.sigmoid'></span>

<h3>Description</h3>

<p>This function implements the gradient of the sigmoid map function with
respect to coeff used for logistic regression in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapXy.gr.sigmoid(X, coeff)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapXy.gr.sigmoid_+3A_x">X</code></td>
<td>
<p>Matrix of data.</p>
</td></tr>
<tr><td><code id="mapXy.gr.sigmoid_+3A_coeff">coeff</code></td>
<td>
<p>Vector or matrix of coefficients or weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of values of the gradient of the sigmoid function with respect
to each value of coeff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  X &lt;- matrix(c(1,2,3,4,5,6),nrow=2)
  coeff &lt;- c(0.5,-1,2)
  mapXy.gr.sigmoid(X,coeff)

</code></pre>

<hr>
<h2 id='mapXy.linear'>Linear Map Function</h2><span id='topic+mapXy.linear'></span>

<h3>Description</h3>

<p>This function implements the linear map function from data X to labels y used
for linear SVM and linear regression in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code> and
<code><a href="#topic+EmpiricalRiskMinimizationDP.KST">EmpiricalRiskMinimizationDP.KST</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapXy.linear(X, coeff)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapXy.linear_+3A_x">X</code></td>
<td>
<p>Matrix of data.</p>
</td></tr>
<tr><td><code id="mapXy.linear_+3A_coeff">coeff</code></td>
<td>
<p>Vector or matrix of coefficients or weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of values of the linear map function corresponding to each row
of X.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  X &lt;- matrix(c(1,2,3,4,5,6),nrow=2)
  coeff &lt;- c(0.5,-1,2)
  mapXy.linear(X,coeff)

</code></pre>

<hr>
<h2 id='mapXy.sigmoid'>Sigmoid Map Function</h2><span id='topic+mapXy.sigmoid'></span>

<h3>Description</h3>

<p>This function implements the sigmoid map function from data X to labels y
used for logistic regression in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapXy.sigmoid(X, coeff)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapXy.sigmoid_+3A_x">X</code></td>
<td>
<p>Matrix of data.</p>
</td></tr>
<tr><td><code id="mapXy.sigmoid_+3A_coeff">coeff</code></td>
<td>
<p>Vector or matrix of coefficients or weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of values of the sigmoid function corresponding to each row of
X.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  X &lt;- matrix(c(1,2,3,4,5,6),nrow=2)
  coeff &lt;- c(0.5,-1,2)
  mapXy.sigmoid(X,coeff)

</code></pre>

<hr>
<h2 id='meanDataAccess'>Differentially Private Mean Data Access Function</h2><span id='topic+meanDataAccess'></span>

<h3>Description</h3>

<p>This function performs the data access step in the computation of a
differentially private mean. The true values are computed using
<code><a href="base.html#topic+mean">mean</a></code>, while the sensitivities are calculated based on
bounded and unbounded differential privacy (Kifer and Machanavajjhala 2011)
according to the theoretical values (Liu 2019). For the
mean, the sensitivities based on bounded and unbounded differential privacy
are identical, so only one value is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanDataAccess(x, lower.bound, upper.bound)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meanDataAccess_+3A_x">x</code></td>
<td>
<p>Dataset whose mean is desired.</p>
</td></tr>
<tr><td><code id="meanDataAccess_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Scalar representing the global or public lower bound on
values of x.</p>
</td></tr>
<tr><td><code id="meanDataAccess_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Scalar representing the global or public upper bound on
values of x.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of the true mean and the sensitivity calculated based on
theoretical values.
</p>


<h3>References</h3>

<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>meanDataAccess(c(1,4,3,2), 0, 5)

</code></pre>

<hr>
<h2 id='meanDP'>Differentially Private Mean</h2><span id='topic+meanDP'></span>

<h3>Description</h3>

<p>This function computes the differentially private mean of a given dataset at
user-specified privacy levels of epsilon and delta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanDP(
  x,
  eps,
  lower.bound,
  upper.bound,
  which.sensitivity = "bounded",
  mechanism = "Laplace",
  delta = 0,
  type.DP = "aDP"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meanDP_+3A_x">x</code></td>
<td>
<p>Dataset whose mean is desired.</p>
</td></tr>
<tr><td><code id="meanDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="meanDP_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Scalar representing the global or public lower bound on
values of x.</p>
</td></tr>
<tr><td><code id="meanDP_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Scalar representing the global or public upper bound on
values of x.</p>
</td></tr>
<tr><td><code id="meanDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
delta)-differential privacy, but may not do so collectively and in
composition. Care must be taken not to violate differential privacy in this
case.</p>
</td></tr>
<tr><td><code id="meanDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'Laplace',
'Gaussian', 'analytic'}. Default is Laplace. See <code><a href="#topic+LaplaceMechanism">LaplaceMechanism</a></code>
and <code><a href="#topic+GaussianMechanism">GaussianMechanism</a></code> for descriptions of the supported
mechanisms.</p>
</td></tr>
<tr><td><code id="meanDP_+3A_delta">delta</code></td>
<td>
<p>Nonnegative real number defining the delta privacy parameter. If
0 (default), reduces to eps-DP.</p>
</td></tr>
<tr><td><code id="meanDP_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism (if selected). Can be either 'pDP' for probabilistic
DP (Machanavajjhala et al. 2008) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized mean based on the bounded and/or unbounded definitions of
differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008).
&ldquo;Privacy: Theory meets Practice on the Map.&rdquo;
In <em>2008 IEEE 24th International Conference on Data Engineering</em>, 277-286.
<a href="https://doi.org/10.1109/ICDE.2008.4497436">doi:10.1109/ICDE.2008.4497436</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>D &lt;- stats::rnorm(500, mean=3, sd=2)
lb &lt;- -3 # 3 std devs below mean
ub &lt;- 9 # 3 std devs above mean
meanDP(D,  1, lb, ub)
meanDP(D, .5, lb, ub, which.sensitivity='unbounded', mechanism='Gaussian',
  delta=0.01)

</code></pre>

<hr>
<h2 id='medianDP'>Differentially Private Median</h2><span id='topic+medianDP'></span>

<h3>Description</h3>

<p>This function computes the differentially private median of an input vector
at a user-specified privacy level of epsilon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medianDP(
  x,
  eps,
  lower.bound,
  upper.bound,
  which.sensitivity = "bounded",
  mechanism = "exponential"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="medianDP_+3A_x">x</code></td>
<td>
<p>Numeric vector of which the median will be taken.</p>
</td></tr>
<tr><td><code id="medianDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="medianDP_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Real number giving the global or public lower bound of x.</p>
</td></tr>
<tr><td><code id="medianDP_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Real number giving the global or public upper bound of x.</p>
</td></tr>
<tr><td><code id="medianDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
0)-differential privacy, but may not do so collectively and in composition.
Care must be taken not to violate differential privacy in this case.</p>
</td></tr>
<tr><td><code id="medianDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'exponential'}.
See <code><a href="#topic+ExponentialMechanism">ExponentialMechanism</a></code> for a description of the supported
mechanisms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized median based on the bounded and/or unbounded definitions
of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Smith A (2011).
&ldquo;Privacy-Preserving Statistical Estimation with Optimal Convergence Rates.&rdquo;
In <em>Proceedings of the Forty-Third Annual ACM Symposium on Theory of Computing</em>,  STOC '11, 813–822.
ISBN 9781450306911, <a href="https://doi.org/10.1145/1993636.1993743">doi:10.1145/1993636.1993743</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>D &lt;- stats::rnorm(500)
lower.bound &lt;- -3 # 3 standard deviations below mean
upper.bound &lt;- 3 # 3 standard deviations above mean

eps &lt;- 1
# Get median satisfying pure 1-differential privacy
private.median &lt;- medianDP(D, eps, lower.bound, upper.bound)
private.median

</code></pre>

<hr>
<h2 id='phi.gaussian'>Transform Function for Gaussian Kernel Approximation</h2><span id='topic+phi.gaussian'></span>

<h3>Description</h3>

<p>This function maps an input data row x with a given prefilter to an output
value in such a way as to approximate the Gaussian kernel
(Chaudhuri et al. 2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phi.gaussian(x, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phi.gaussian_+3A_x">x</code></td>
<td>
<p>Vector or matrix corresponding to one row of the dataset X.</p>
</td></tr>
<tr><td><code id="phi.gaussian_+3A_theta">theta</code></td>
<td>
<p>Randomly sampled prefilter vector of length n+1, where n is the
length of x.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Mapped value corresponding to one element of the transformed space.
</p>


<h3>References</h3>

<p>Chaudhuri K, Monteleoni C, Sarwate AD (2011).
&ldquo;Differentially Private Empirical Risk Minimization.&rdquo;
<em>Journal of Machine Learning Research</em>, <b>12</b>(29), 1069-1109.
<a href="https://jmlr.org/papers/v12/chaudhuri11a.html">https://jmlr.org/papers/v12/chaudhuri11a.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- c(1,2,3)
  theta &lt;- c(0.1, 1.1, -0.8, 3)
  phi.gaussian(x, theta)

</code></pre>

<hr>
<h2 id='pooledCovDataAccess'>Differentially Private Pooled Covariance Data Access Function</h2><span id='topic+pooledCovDataAccess'></span>

<h3>Description</h3>

<p>This function performs the data access step in the computation of a
differentially private pooled covariance. The true values are computed using
the theoretical formula and <code><a href="stats.html#topic+cov">cov</a></code>, while the sensitivities
are calculated based on bounded and unbounded differential privacy
(Kifer and Machanavajjhala 2011) according to the theoretical values
(Liu 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pooledCovDataAccess(
  samples,
  lower.bound1,
  upper.bound1,
  lower.bound2,
  upper.bound2,
  approx.n.max
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pooledCovDataAccess_+3A_samples">samples</code></td>
<td>
<p>List of two-column matrices from which to compute the pooled
covariance.</p>
</td></tr>
<tr><td><code id="pooledCovDataAccess_+3A_lower.bound1">lower.bound1</code>, <code id="pooledCovDataAccess_+3A_lower.bound2">lower.bound2</code></td>
<td>
<p>Real numbers giving the lower bounds of the
first and second columns of samples, respectively.</p>
</td></tr>
<tr><td><code id="pooledCovDataAccess_+3A_upper.bound1">upper.bound1</code>, <code id="pooledCovDataAccess_+3A_upper.bound2">upper.bound2</code></td>
<td>
<p>Real numbers giving the upper bounds of the
first and second columns of samples, respectively.</p>
</td></tr>
<tr><td><code id="pooledCovDataAccess_+3A_approx.n.max">approx.n.max</code></td>
<td>
<p>Logical indicating whether to approximate n.max, which is
defined to be the length of the largest input vector. Approximation is best
if n.max is very large.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of the true pooled covariance and the sensitivities calculated
based on bounded and unbounded differential privacy.
</p>


<h3>References</h3>

<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- matrix(c(1,4,-2,8,-6,-3),ncol=2)
x2 &lt;- matrix(c(1,2,-5,7),ncol=2)
pooledCovDataAccess(list(x1,x2),-10,10,-10,10,FALSE)

</code></pre>

<hr>
<h2 id='pooledCovDP'>Differentially Private Pooled Covariance</h2><span id='topic+pooledCovDP'></span>

<h3>Description</h3>

<p>This function computes the differentially private pooled covariance from two
or more two-column matrices of data at user-specified privacy levels of
epsilon and delta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pooledCovDP(
  ...,
  eps = 1,
  lower.bound1,
  upper.bound1,
  lower.bound2,
  upper.bound2,
  which.sensitivity = "bounded",
  mechanism = "Laplace",
  delta = 0,
  type.DP = "aDP",
  approx.n.max = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pooledCovDP_+3A_...">...</code></td>
<td>
<p>Two or more matrices, each with two columns from which to compute
the pooled covariance.</p>
</td></tr>
<tr><td><code id="pooledCovDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="pooledCovDP_+3A_lower.bound1">lower.bound1</code>, <code id="pooledCovDP_+3A_lower.bound2">lower.bound2</code></td>
<td>
<p>Real numbers giving the global or public
lower bounds over the first and second columns of all input data,
respectively.</p>
</td></tr>
<tr><td><code id="pooledCovDP_+3A_upper.bound1">upper.bound1</code>, <code id="pooledCovDP_+3A_upper.bound2">upper.bound2</code></td>
<td>
<p>Real numbers giving the global or public
upper bounds over the first and second columns of all input data,
respectively.</p>
</td></tr>
<tr><td><code id="pooledCovDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
delta)-differential privacy, but may not do so collectively and in
composition. Care must be taken not to violate differential privacy in this
case.</p>
</td></tr>
<tr><td><code id="pooledCovDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'Laplace',
'Gaussian', 'analytic'}. Default is Laplace. See <code><a href="#topic+LaplaceMechanism">LaplaceMechanism</a></code>
and <code><a href="#topic+GaussianMechanism">GaussianMechanism</a></code> for descriptions of the supported
mechanisms.</p>
</td></tr>
<tr><td><code id="pooledCovDP_+3A_delta">delta</code></td>
<td>
<p>Nonnegative real number defining the delta privacy parameter. If
0 (default), reduces to eps-DP.</p>
</td></tr>
<tr><td><code id="pooledCovDP_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism (if selected). Can be either 'pDP' for probabilistic
DP (Machanavajjhala et al. 2008) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
<tr><td><code id="pooledCovDP_+3A_approx.n.max">approx.n.max</code></td>
<td>
<p>Logical indicating whether to approximate n.max (defined
to be the length of the largest input vector) in the computation of the
global sensitivity based on the upper and lower bounds of the data
(Liu 2019). Approximation is best if n.max is very
large.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized pooled covariance based on the bounded and/or unbounded
definitions of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008).
&ldquo;Privacy: Theory meets Practice on the Map.&rdquo;
In <em>2008 IEEE 24th International Conference on Data Engineering</em>, 277-286.
<a href="https://doi.org/10.1109/ICDE.2008.4497436">doi:10.1109/ICDE.2008.4497436</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>
<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build datasets
D1 &lt;- sort(stats::rnorm(500, mean=3, sd=2))
D2 &lt;- sort(stats::rnorm(500, mean=-1, sd=0.5))
D3 &lt;- sort(stats::rnorm(200, mean=3, sd=2))
D4 &lt;- sort(stats::rnorm(200, mean=-1, sd=0.5))
M1 &lt;- matrix(c(D1, D2), ncol=2)
M2 &lt;- matrix(c(D3, D4), ncol=2)

lb1 &lt;- -3 # 3 std devs below mean
lb2 &lt;- -2.5 # 3 std devs below mean
ub1 &lt;- 9 # 3 std devs above mean
ub2 &lt;- .5 # 3 std devs above mean
# Pooled covariance satisfying (1,0)-differential privacy
private.pooled.cov &lt;- pooledCovDP(M1, M2, eps = 1, lower.bound1 = lb1,
                                  lower.bound2 = lb2, upper.bound1 = ub1,
                                  upper.bound2 = ub2)
private.pooled.cov

# Pooled covariance satisfying approximate (0.9, 0.01)-differential privacy
# and approximating n.max in the sensitivity calculation
private.pooled.cov &lt;- pooledCovDP(M1, M2, eps = 0.9, lower.bound1 = lb1,
                                  lower.bound2 = lb2, upper.bound1 = ub1,
                                  upper.bound2 = ub2, mechanism = 'Gaussian',
                                  delta = 0.01, approx.n.max = TRUE)
private.pooled.cov

</code></pre>

<hr>
<h2 id='pooledVarDataAccess'>Differentially Private Pooled Variance Data Access Function</h2><span id='topic+pooledVarDataAccess'></span>

<h3>Description</h3>

<p>This function performs the data access step in the computation of a
differentially private pooled variance. The true values are computed using
the theoretical formula and <code><a href="stats.html#topic+var">var</a></code>, while the sensitivities
are calculated based on bounded and unbounded differential privacy
(Kifer and Machanavajjhala 2011) according to the theoretical values
(Liu 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pooledVarDataAccess(samples, lower.bound, upper.bound, approx.n.max)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pooledVarDataAccess_+3A_samples">samples</code></td>
<td>
<p>List of vectors from which to compute the pooled variance.</p>
</td></tr>
<tr><td><code id="pooledVarDataAccess_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Real number giving the lower bound of the input data.</p>
</td></tr>
<tr><td><code id="pooledVarDataAccess_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Real number giving the upper bound of the input data.</p>
</td></tr>
<tr><td><code id="pooledVarDataAccess_+3A_approx.n.max">approx.n.max</code></td>
<td>
<p>Logical indicating whether to approximate n.max, which is
defined to be the length of the largest input vector. Approximation is best
if n.max is very large.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of the true pooled variance and the sensitivities calculated
based on bounded and unbounded differential privacy.
</p>


<h3>References</h3>

<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pooledVarDataAccess(list(c(1,4,-2,8,-6),c(1,2),c(-5,-7)),-10,10,FALSE)

</code></pre>

<hr>
<h2 id='pooledVarDP'>Differentially Private Pooled Variance</h2><span id='topic+pooledVarDP'></span>

<h3>Description</h3>

<p>This function computes the differentially private pooled variance from two or
more vectors of data at user-specified privacy levels of epsilon and delta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pooledVarDP(
  ...,
  eps = 1,
  lower.bound,
  upper.bound,
  which.sensitivity = "bounded",
  mechanism = "Laplace",
  delta = 0,
  type.DP = "aDP",
  approx.n.max = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pooledVarDP_+3A_...">...</code></td>
<td>
<p>Two or more vectors from which to compute the pooled variance.</p>
</td></tr>
<tr><td><code id="pooledVarDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="pooledVarDP_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Real number giving the global or public lower bound of the
input data.</p>
</td></tr>
<tr><td><code id="pooledVarDP_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Real number giving the global or public upper bound of the
input data.</p>
</td></tr>
<tr><td><code id="pooledVarDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
delta)-differential privacy, but may not do so collectively and in
composition. Care must be taken not to violate differential privacy in this
case.</p>
</td></tr>
<tr><td><code id="pooledVarDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'Laplace',
'Gaussian', 'analytic'}. Default is Laplace. See <code><a href="#topic+LaplaceMechanism">LaplaceMechanism</a></code>
and <code><a href="#topic+GaussianMechanism">GaussianMechanism</a></code> for descriptions of the supported
mechanisms.</p>
</td></tr>
<tr><td><code id="pooledVarDP_+3A_delta">delta</code></td>
<td>
<p>Nonnegative real number defining the delta privacy parameter. If
0 (default), reduces to eps-DP.</p>
</td></tr>
<tr><td><code id="pooledVarDP_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism (if selected). Can be either 'pDP' for probabilistic
DP (Machanavajjhala et al. 2008) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
<tr><td><code id="pooledVarDP_+3A_approx.n.max">approx.n.max</code></td>
<td>
<p>Logical indicating whether to approximate n.max (defined
to be the length of the largest input vector) in the computation of the
global sensitivity based on the upper and lower bounds of the data
(Liu 2019). Approximation is best if n.max is very
large.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized pooled variance based on the bounded and/or unbounded
definitions of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008).
&ldquo;Privacy: Theory meets Practice on the Map.&rdquo;
In <em>2008 IEEE 24th International Conference on Data Engineering</em>, 277-286.
<a href="https://doi.org/10.1109/ICDE.2008.4497436">doi:10.1109/ICDE.2008.4497436</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>
<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build datasets
D1 &lt;- stats::rnorm(500, mean=3, sd=2)
D2 &lt;- stats::rnorm(200, mean=3, sd=2)
D3 &lt;- stats::rnorm(100, mean=3, sd=2)
lower.bound &lt;- -3 # 3 standard deviations below mean
upper.bound &lt;- 9 # 3 standard deviations above mean

# Get private pooled variance without approximating n.max
private.pooled.var &lt;- pooledVarDP(D1, D2, D3, eps=1, lower.bound=lower.bound,
                                  upper.bound = upper.bound)
private.pooled.var

# If n.max is sensitive, we can also use
private.pooled.var &lt;- pooledVarDP(D1, D2, D3, eps=1, lower.bound=lower.bound,
                                  upper.bound = upper.bound,
                                  approx.n.max = TRUE)
private.pooled.var

</code></pre>

<hr>
<h2 id='quantileDataAccess'>Differentially Private Quantile Data Access Function</h2><span id='topic+quantileDataAccess'></span>

<h3>Description</h3>

<p>This function performs the data access step in the computation of a
differentially private quantile. The utility vector is computed as in
Smith (2011), while the sensitivities are
calculated based on bounded and unbounded differential privacy
(Kifer and Machanavajjhala 2011) according to the theoretical values
(Gillenwater et al. 2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantileDataAccess(x, quant, lower.bound, upper.bound)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantileDataAccess_+3A_x">x</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="quantileDataAccess_+3A_quant">quant</code></td>
<td>
<p>Real number between 0 and 1 indicating which quantile to return.</p>
</td></tr>
<tr><td><code id="quantileDataAccess_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Real number giving the lower bound of the input data.</p>
</td></tr>
<tr><td><code id="quantileDataAccess_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Real number giving the upper bound of the input data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of a vector corresponding to the utility function, the sorted
and clipped vector of inputs and the sensitivity calculated based on
theoretical values.
</p>


<h3>References</h3>

<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Smith A (2011).
&ldquo;Privacy-Preserving Statistical Estimation with Optimal Convergence Rates.&rdquo;
In <em>Proceedings of the Forty-Third Annual ACM Symposium on Theory of Computing</em>,  STOC '11, 813–822.
ISBN 9781450306911, <a href="https://doi.org/10.1145/1993636.1993743">doi:10.1145/1993636.1993743</a>.
</p>
<p>Gillenwater J, Joseph M, Kulesza A (2021).
&ldquo;Differentially Private Quantiles.&rdquo;
In Meila M, Zhang T (eds.), <em>Proceedings of the 38th International Conference on Machine Learning</em>, volume 139 of <em>Proceedings of Machine Learning Research</em>, 3713&ndash;3722.
<a href="http://proceedings.mlr.press/v139/gillenwater21a/gillenwater21a.pdf">http://proceedings.mlr.press/v139/gillenwater21a/gillenwater21a.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quantileDataAccess(c(1,1,-2,8,-6),.25,-10,10)

</code></pre>

<hr>
<h2 id='quantileDP'>Differentially Private Quantile</h2><span id='topic+quantileDP'></span>

<h3>Description</h3>

<p>This function computes the differentially private quantile of an input vector
at a user-specified privacy level of epsilon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantileDP(
  x,
  quant,
  eps,
  lower.bound,
  upper.bound,
  which.sensitivity = "bounded",
  mechanism = "exponential"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantileDP_+3A_x">x</code></td>
<td>
<p>Numeric vector of which the quantile will be taken.</p>
</td></tr>
<tr><td><code id="quantileDP_+3A_quant">quant</code></td>
<td>
<p>Real number between 0 and 1 indicating which quantile to return.</p>
</td></tr>
<tr><td><code id="quantileDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="quantileDP_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Real number giving the global or public lower bound of x.</p>
</td></tr>
<tr><td><code id="quantileDP_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Real number giving the global or public upper bound of x.</p>
</td></tr>
<tr><td><code id="quantileDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
0)-differential privacy, but may not do so collectively and in composition.
Care must be taken not to violate differential privacy in this case.</p>
</td></tr>
<tr><td><code id="quantileDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'exponential'}.
See <code><a href="#topic+ExponentialMechanism">ExponentialMechanism</a></code> for a description of the supported
mechanisms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized quantile based on the bounded and/or unbounded definitions
of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Smith A (2011).
&ldquo;Privacy-Preserving Statistical Estimation with Optimal Convergence Rates.&rdquo;
In <em>Proceedings of the Forty-Third Annual ACM Symposium on Theory of Computing</em>,  STOC '11, 813–822.
ISBN 9781450306911, <a href="https://doi.org/10.1145/1993636.1993743">doi:10.1145/1993636.1993743</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>D &lt;- stats::rnorm(500)
lower.bound &lt;- -3 # 3 standard deviations below mean
upper.bound &lt;- 3 # 3 standard deviations above mean

quant &lt;- 0.25
eps &lt;- 1
# Get 25th quantile satisfying pure 1-differential privacy
private.quantile &lt;- quantileDP(D, quant, eps, lower.bound, upper.bound)
private.quantile

</code></pre>

<hr>
<h2 id='regularizer.gr.l2'>l2 Regularizer Gradient</h2><span id='topic+regularizer.gr.l2'></span>

<h3>Description</h3>

<p>This function implements the l2 regularizer gradient in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code> and
<code><a href="#topic+EmpiricalRiskMinimizationDP.KST">EmpiricalRiskMinimizationDP.KST</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regularizer.gr.l2(coeff)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="regularizer.gr.l2_+3A_coeff">coeff</code></td>
<td>
<p>Vector or matrix of coefficients or weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Regularizer gradient value at the given coefficient vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  coeff &lt;- c(0.5,-1,2)
  regularizer.gr.l2(coeff)

</code></pre>

<hr>
<h2 id='regularizer.l2'>l2 Regularizer</h2><span id='topic+regularizer.l2'></span>

<h3>Description</h3>

<p>This function implements the l2 regularizer in the form required by
<code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">EmpiricalRiskMinimizationDP.CMS</a></code> and
<code><a href="#topic+EmpiricalRiskMinimizationDP.KST">EmpiricalRiskMinimizationDP.KST</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regularizer.l2(coeff)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="regularizer.l2_+3A_coeff">coeff</code></td>
<td>
<p>Vector or matrix of coefficients or weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Regularizer value at the given coefficient vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  coeff &lt;- c(0.5,-1,2)
  regularizer.l2(coeff)

</code></pre>

<hr>
<h2 id='sdDP'>Differentially Private Standard Deviation</h2><span id='topic+sdDP'></span>

<h3>Description</h3>

<p>This function computes the differentially private standard deviation of a
given dataset at user-specified privacy levels of epsilon and delta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sdDP(
  x,
  eps,
  lower.bound,
  upper.bound,
  which.sensitivity = "bounded",
  mechanism = "Laplace",
  delta = 0,
  type.DP = "aDP"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sdDP_+3A_x">x</code></td>
<td>
<p>Numeric vector whose variance is desired.</p>
</td></tr>
<tr><td><code id="sdDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="sdDP_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Scalar representing the global or public lower bound on
values of x.</p>
</td></tr>
<tr><td><code id="sdDP_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Scalar representing the global or public upper bound on
values of x.</p>
</td></tr>
<tr><td><code id="sdDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
delta)-differential privacy, but may not do so collectively and in
composition. Care must be taken not to violate differential privacy in this
case.</p>
</td></tr>
<tr><td><code id="sdDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'Laplace',
'Gaussian', 'analytic'}. Default is Laplace. See <code><a href="#topic+LaplaceMechanism">LaplaceMechanism</a></code>
and <code><a href="#topic+GaussianMechanism">GaussianMechanism</a></code> for descriptions of the supported
mechanisms.</p>
</td></tr>
<tr><td><code id="sdDP_+3A_delta">delta</code></td>
<td>
<p>Nonnegative real number defining the delta privacy parameter. If
0 (default), reduces to eps-DP.</p>
</td></tr>
<tr><td><code id="sdDP_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism (if selected). Can be either 'pDP' for probabilistic
DP (Machanavajjhala et al. 2008) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized standard deviation based on the bounded and/or unbounded
definitions of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008).
&ldquo;Privacy: Theory meets Practice on the Map.&rdquo;
In <em>2008 IEEE 24th International Conference on Data Engineering</em>, 277-286.
<a href="https://doi.org/10.1109/ICDE.2008.4497436">doi:10.1109/ICDE.2008.4497436</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>
<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>D &lt;- stats::rnorm(500, mean=3, sd=2)
lb &lt;- -3 # 3 std devs below mean
ub &lt;- 9 # 3 std devs above mean
sdDP(D, 1, lb, ub)
sdDP(D,.5, lb, ub, which.sensitivity='unbounded', mechanism='Gaussian',
  delta=0.01)

</code></pre>

<hr>
<h2 id='svmDP'>Privacy-preserving Support Vector Machine</h2><span id='topic+svmDP'></span>

<h3>Description</h3>

<p>This class implements differentially private support vector
machine (SVM) (Chaudhuri et al. 2011). It can be either weighted
(Yang et al. 2005) or unweighted. Either the output or the
objective perturbation method can be used for unweighted SVM, though only
the output perturbation method is currently supported for weighted SVM.
</p>


<h3>Details</h3>

<p>To use this class for SVM, first use the <code>new</code> method to
construct an object of this class with the desired function values and
hyperparameters, including a choice of the desired kernel. After
constructing the object, the <code>fit</code> method can be applied to fit the
model with a provided dataset, data bounds, and optional observation
weights and weight upper bound. In fitting, the model stores a vector of
coefficients <code>coeff</code> which satisfy differential privacy. Additionally,
if a nonlinear kernel is chosen, the models stores a mapping function from
the input data X to a higher dimensional embedding V in the form of a
method <code>XtoV</code> as required (Chaudhuri et al. 2011). These
can be released directly, or used in conjunction with the <code>predict</code>
method to privately predict the label of new datapoints. Note that the
mapping function <code>XtoV</code> is based on an approximation method via
Fourier transforms (Rahimi and Recht 2007; Rahimi and Recht 2008).
</p>
<p>Note that in order to guarantee differential privacy for the SVM model,
certain constraints must be satisfied for the values used to construct the
object, as well as for the data used to fit. These conditions depend on the
chosen perturbation method. First, the loss function is assumed to be
differentiable (and doubly differentiable if the objective perturbation
method is used). The hinge loss, which is typically used for SVM, is not
differentiable at 1. Thus, to satisfy this constraint, this class utilizes
the Huber loss, a smooth approximation to the hinge loss
(Chapelle 2007). The level of approximation to the hinge
loss is determined by a user-specified constant, h, which defaults to 0.5,
a typical value. Additionally, the regularizer must be 1-strongly convex
and differentiable. It also must be doubly differentiable if objective
perturbation is chosen. If weighted SVM is desired, the provided weights
must be nonnegative and bounded above by a global or public value, which
must also be provided.
</p>
<p>Finally, it is assumed that if x represents a single row of the dataset X,
then the l2-norm of x is at most 1 for all x. In order to ensure this
constraint is satisfied, the dataset is preprocessed and scaled, and the
resulting coefficients are postprocessed and un-scaled so that the stored
coefficients correspond to the original data. Due to this constraint on x,
it is best to avoid using a bias term in the model whenever possible. If a
bias term must be used, the issue can be partially circumvented by adding a
constant column to X before fitting the model, which will be scaled along
with the rest of X. The <code>fit</code> method contains functionality to add a
column of constant 1s to X before scaling, if desired.
</p>


<h3>Super classes</h3>

<p><code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">DPpack::EmpiricalRiskMinimizationDP.CMS</a></code> -&gt; <code><a href="#topic+WeightedERMDP.CMS">DPpack::WeightedERMDP.CMS</a></code> -&gt; <code>svmDP</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-svmDP-new"><code>svmDP$new()</code></a>
</p>
</li>
<li> <p><a href="#method-svmDP-fit"><code>svmDP$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-svmDP-XtoV"><code>svmDP$XtoV()</code></a>
</p>
</li>
<li> <p><a href="#method-svmDP-predict"><code>svmDP$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-svmDP-clone"><code>svmDP$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-svmDP-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>svmDP</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>svmDP$new(
  regularizer,
  eps,
  gamma,
  perturbation.method = "objective",
  kernel = "linear",
  D = NULL,
  kernel.param = NULL,
  regularizer.gr = NULL,
  huber.h = 0.5
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>regularizer</code></dt><dd><p>String or regularization function. If a string, must be
'l2', indicating to use l2 regularization. If a function, must have form
<code>regularizer(coeff)</code>, where <code>coeff</code> is a vector or matrix, and
return the value of the regularizer at <code>coeff</code>. See
<code><a href="#topic+regularizer.l2">regularizer.l2</a></code> for an example. Additionally, in order to
ensure differential privacy, the function must be 1-strongly convex and
doubly differentiable.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Positive real number defining the epsilon privacy budget. If set
to Inf, runs algorithm without differential privacy.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Nonnegative real number representing the regularization
constant.</p>
</dd>
<dt><code>perturbation.method</code></dt><dd><p>String indicating whether to use the 'output' or
the 'objective' perturbation methods (Chaudhuri et al. 2011).
Defaults to 'objective'.</p>
</dd>
<dt><code>kernel</code></dt><dd><p>String indicating which kernel to use for SVM. Must be one of
{'linear', 'Gaussian'}. If 'linear' (default), linear SVM is used. If
'Gaussian,' uses the sampling function corresponding to the Gaussian
(radial) kernel approximation.</p>
</dd>
<dt><code>D</code></dt><dd><p>Nonnegative integer indicating the dimensionality of the transform
space approximating the kernel if a nonlinear kernel is used. Higher
values of D provide better kernel approximations at a cost of
computational efficiency. This value must be specified if a nonlinear
kernel is used.</p>
</dd>
<dt><code>kernel.param</code></dt><dd><p>Positive real number corresponding to the Gaussian
kernel parameter. Defaults to 1/p, where p is the number of predictors.</p>
</dd>
<dt><code>regularizer.gr</code></dt><dd><p>Optional function representing the gradient of the
regularization function with respect to <code>coeff</code> and of the form
<code>regularizer.gr(coeff)</code>. Should return a vector. See
<code><a href="#topic+regularizer.gr.l2">regularizer.gr.l2</a></code> for an example. If <code>regularizer</code> is
given as a string, this value is ignored. If not given and
<code>regularizer</code> is a function, non-gradient based optimization methods
are used to compute the coefficient values in fitting the model.</p>
</dd>
<dt><code>huber.h</code></dt><dd><p>Positive real number indicating the degree to which the
Huber loss approximates the hinge loss. Defaults to 0.5
(Chapelle 2007).</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new svmDP object.
</p>


<hr>
<a id="method-svmDP-fit"></a>



<h4>Method <code>fit()</code></h4>

<p>Fit the differentially private SVM model. This method runs
either the output perturbation or the objective perturbation algorithm
(Chaudhuri et al. 2011), depending on the value of
perturbation.method used to construct the object, to generate an
objective function. A numerical optimization method is then run to find
optimal coefficients for fitting the model given the training data,
weights, and hyperparameters. The built-in <code><a href="stats.html#topic+optim">optim</a></code> function
using the &quot;BFGS&quot; optimization method is used. If <code>regularizer</code> is
given as 'l2' or if <code>regularizer.gr</code> is given in the construction of
the object, the gradient of the objective function is utilized by
<code>optim</code> as well. Otherwise, non-gradient based optimization methods
are used. The resulting privacy-preserving coefficients are stored in
<code>coeff</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>svmDP$fit(
  X,
  y,
  upper.bounds,
  lower.bounds,
  add.bias = FALSE,
  weights = NULL,
  weights.upper.bound = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data to be fit.</p>
</dd>
<dt><code>y</code></dt><dd><p>Vector or matrix of true labels for each row of <code>X</code>.</p>
</dd>
<dt><code>upper.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)</code> giving upper
bounds on the values in each column of X. The <code>ncol(X)</code> values are
assumed to be in the same order as the corresponding columns of <code>X</code>.
Any value in the columns of <code>X</code> larger than the corresponding upper
bound is clipped at the bound.</p>
</dd>
<dt><code>lower.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)</code> giving lower
bounds on the values in each column of <code>X</code>. The <code>ncol(X)</code>
values are assumed to be in the same order as the corresponding columns
of <code>X</code>. Any value in the columns of <code>X</code> larger than the
corresponding upper bound is clipped at the bound.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE.</p>
</dd>
<dt><code>weights</code></dt><dd><p>Numeric vector of observation weights of the same length as
<code>y</code>. If not given, no observation weighting is performed.</p>
</dd>
<dt><code>weights.upper.bound</code></dt><dd><p>Numeric value representing the global or public
upper bound on the weights. Required if weights are given.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-svmDP-XtoV"></a>



<h4>Method <code>XtoV()</code></h4>

<p>Convert input data X into transformed data V. Uses sampled
pre-filter values and a mapping function based on the chosen kernel to
produce D-dimensional data V on which to train the model or predict
future values. This method is only used if the kernel is nonlinear. See
Chaudhuri et al. (2011) for more details.
</p>


<h5>Usage</h5>

<div class="r"><pre>svmDP$XtoV(X)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Matrix corresponding to the original dataset.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Matrix V of size n by D representing the transformed dataset, where
n is the number of rows of X, and D is the provided transformed space
dimension.
</p>


<hr>
<a id="method-svmDP-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict label(s) for given <code>X</code> using the fitted
coefficients.
</p>


<h5>Usage</h5>

<div class="r"><pre>svmDP$predict(X, add.bias = FALSE, raw.value = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data on which to make predictions. Must be of same
form as <code>X</code> used to fit coefficients.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE. If add.bias was set to TRUE when fitting the
coefficients, add.bias should be set to TRUE for predictions.</p>
</dd>
<dt><code>raw.value</code></dt><dd><p>Boolean indicating whether to return the raw predicted
value or the rounded class label. If FALSE (default), outputs the
predicted labels 0 or 1. If TRUE, returns the raw score from the SVM
model.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Matrix of predicted labels or scores corresponding to each row of
<code>X</code>.
</p>


<hr>
<a id="method-svmDP-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>svmDP$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Chaudhuri K, Monteleoni C, Sarwate AD (2011).
&ldquo;Differentially Private Empirical Risk Minimization.&rdquo;
<em>Journal of Machine Learning Research</em>, <b>12</b>(29), 1069-1109.
<a href="https://jmlr.org/papers/v12/chaudhuri11a.html">https://jmlr.org/papers/v12/chaudhuri11a.html</a>.
</p>
<p>Yang X, Song Q, Cao A (2005).
&ldquo;Weighted support vector machine for data classification.&rdquo;
In <em>Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.</em>, volume 2, 859-864 vol. 2.
<a href="https://doi.org/10.1109/IJCNN.2005.1555965">doi:10.1109/IJCNN.2005.1555965</a>.
</p>
<p>Chapelle O (2007).
&ldquo;Training a Support Vector Machine in the Primal.&rdquo;
<em>Neural Computation</em>, <b>19</b>(5), 1155-1178.
<a href="https://doi.org/10.1162/neco.2007.19.5.1155">doi:10.1162/neco.2007.19.5.1155</a>.
</p>
<p>Rahimi A, Recht B (2007).
&ldquo;Random Features for Large-Scale Kernel Machines.&rdquo;
In Platt J, Koller D, Singer Y, Roweis S (eds.), <em>Advances in Neural Information Processing Systems</em>, volume 20.
<a href="https://proceedings.neurips.cc/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf">https://proceedings.neurips.cc/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf</a>.
</p>
<p>Rahimi A, Recht B (2008).
&ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning.&rdquo;
In Koller D, Schuurmans D, Bengio Y, Bottou L (eds.), <em>Advances in Neural Information Processing Systems</em>, volume 21.
<a href="https://proceedings.neurips.cc/paper/2008/file/0efe32849d230d7f53049ddc4a4b0c60-Paper.pdf">https://proceedings.neurips.cc/paper/2008/file/0efe32849d230d7f53049ddc4a4b0c60-Paper.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build train dataset X and y, and test dataset Xtest and ytest
N &lt;- 400
X &lt;- data.frame()
y &lt;- data.frame()
for (i in (1:N)){
  Xtemp &lt;- data.frame(x1 = stats::rnorm(1,sd=.28) , x2 = stats::rnorm(1,sd=.28))
  if (sum(Xtemp^2)&lt;.15) ytemp &lt;- data.frame(y=0)
  else ytemp &lt;- data.frame(y=1)
  X &lt;- rbind(X, Xtemp)
  y &lt;- rbind(y, ytemp)
}
Xtest &lt;- X[seq(1,N,10),]
ytest &lt;- y[seq(1,N,10),,drop=FALSE]
X &lt;- X[-seq(1,N,10),]
y &lt;- y[-seq(1,N,10),,drop=FALSE]

# Construct object for SVM
regularizer &lt;- 'l2' # Alternatively, function(coeff) coeff%*%coeff/2
eps &lt;- 1
gamma &lt;- 1
perturbation.method &lt;- 'output'
kernel &lt;- 'Gaussian'
D &lt;- 20
svmdp &lt;- svmDP$new(regularizer, eps, gamma, perturbation.method,
                   kernel=kernel, D=D)

# Fit with data
# Bounds for X based on construction
upper.bounds &lt;- c( 1, 1)
lower.bounds &lt;- c(-1,-1)
weights &lt;- rep(1, nrow(y)) # Uniform weighting
weights[nrow(y)] &lt;- 0.5 # Half weight for last observation
wub &lt;- 1 # Public upper bound for weights
svmdp$fit(X, y, upper.bounds, lower.bounds, weights=weights,
          weights.upper.bound=wub) # No bias term

# Predict new data points
predicted.y &lt;- svmdp$predict(Xtest)
n.errors &lt;- sum(predicted.y!=ytest)

</code></pre>

<hr>
<h2 id='tableDataAccess'>Differentially Private Contingency Table Data Access Function</h2><span id='topic+tableDataAccess'></span>

<h3>Description</h3>

<p>This function performs the data access step in the computation of a
differentially private contingency table. The true values are computed using
<code><a href="base.html#topic+table">table</a></code>,while the sensitivities are calculated based on
bounded and unbounded differential privacy (Kifer and Machanavajjhala 2011)
according to the theoretical values (Liu 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tableDataAccess(..., mechanism = "Laplace")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tableDataAccess_+3A_...">...</code></td>
<td>
<p>Vectors of data from which to create the contingency table.</p>
</td></tr>
<tr><td><code id="tableDataAccess_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. If the 'Laplace' mechanism is chosen, l1 sensitivities are
returned. If the 'Gaussian' or 'analytic' mechanisms are chosen, l2
sensitivities are returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of the true contingency table and the sensitivities calculated
based on bounded and unbounded differential privacy.
</p>


<h3>References</h3>

<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- MASS::Cars93$Type;
y &lt;- MASS::Cars93$Origin;
tableDataAccess(x, y, mechanism='Laplace')

</code></pre>

<hr>
<h2 id='tableDP'>Differentially Private Contingency Table</h2><span id='topic+tableDP'></span>

<h3>Description</h3>

<p>This function computes a differentially private contingency table from given
vectors of data at user-specified privacy levels of epsilon and delta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tableDP(
  ...,
  eps = 1,
  which.sensitivity = "bounded",
  mechanism = "Laplace",
  delta = 0,
  type.DP = "aDP",
  allow.negative = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tableDP_+3A_...">...</code></td>
<td>
<p>Vectors of data from which to create the contingency table.</p>
</td></tr>
<tr><td><code id="tableDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="tableDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
delta)-differential privacy, but may not do so collectively and in
composition. Care must be taken not to violate differential privacy in this
case.</p>
</td></tr>
<tr><td><code id="tableDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'Laplace',
'Gaussian', 'analytic'}. Default is Laplace. See <code><a href="#topic+LaplaceMechanism">LaplaceMechanism</a></code>
and <code><a href="#topic+GaussianMechanism">GaussianMechanism</a></code> for descriptions of the supported
mechanisms.</p>
</td></tr>
<tr><td><code id="tableDP_+3A_delta">delta</code></td>
<td>
<p>Nonnegative real number defining the delta privacy parameter. If
0 (default), reduces to eps-DP.</p>
</td></tr>
<tr><td><code id="tableDP_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism (if selected). Can be either 'pDP' for probabilistic
DP (Machanavajjhala et al. 2008) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
<tr><td><code id="tableDP_+3A_allow.negative">allow.negative</code></td>
<td>
<p>Logical value. If FALSE (default), any negative values
in the sanitized table due to the added noise will be set to 0. If TRUE,
the negative values (if any) will be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized contingency table based on the bounded and/or unbounded
definitions of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008).
&ldquo;Privacy: Theory meets Practice on the Map.&rdquo;
In <em>2008 IEEE 24th International Conference on Data Engineering</em>, 277-286.
<a href="https://doi.org/10.1109/ICDE.2008.4497436">doi:10.1109/ICDE.2008.4497436</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- MASS::Cars93$Type
y &lt;- MASS::Cars93$Origin
z &lt;- MASS::Cars93$AirBags
tableDP(x,y,eps=1,which.sensitivity='bounded',mechanism='Laplace',
  type.DP='pDP')
tableDP(x,y,z,eps=.5,which.sensitivity='unbounded',mechanism='Gaussian',
  delta=0.01)

</code></pre>

<hr>
<h2 id='tune_classification_model'>Privacy-preserving Hyperparameter Tuning for Binary Classification Models</h2><span id='topic+tune_classification_model'></span>

<h3>Description</h3>

<p>This function implements the privacy-preserving hyperparameter tuning
function for binary classification (Chaudhuri et al. 2011) using
the exponential mechanism. It accepts a list of DP models with various chosen
hyperparameters, a dataset X with corresponding labels y, upper and lower
bounds on the columns of X, and a boolean indicating whether to add bias in
the construction of each of the models. The data are split into m+1 equal
groups, where m is the number of models being compared. One group is set
aside as the validation group, and each of the other m groups are used to
train each of the given m models. The number of errors on the validation set
is counted for each model and used as the utility values in the exponential
mechanism (<code><a href="#topic+ExponentialMechanism">ExponentialMechanism</a></code>) to select a tuned model in a
privacy-preserving way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tune_classification_model(
  DPmodels,
  X,
  y,
  upper.bounds,
  lower.bounds,
  add.bias = FALSE,
  weights = NULL,
  weights.upper.bound = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tune_classification_model_+3A_dpmodels">DPmodels</code></td>
<td>
<p>Vector of binary classification model objects, each initialized
with a different combination of hyperparameter values from the search space
for tuning. Each model should be initialized with the same epsilon privacy
parameter value eps. The tuned model satisfies eps-level differential
privacy.</p>
</td></tr>
<tr><td><code id="tune_classification_model_+3A_x">X</code></td>
<td>
<p>Dataframe of data to be used in tuning the model. Note it is assumed
the data rows and corresponding labels are randomly shuffled.</p>
</td></tr>
<tr><td><code id="tune_classification_model_+3A_y">y</code></td>
<td>
<p>Vector or matrix of true labels for each row of X.</p>
</td></tr>
<tr><td><code id="tune_classification_model_+3A_upper.bounds">upper.bounds</code></td>
<td>
<p>Numeric vector giving upper bounds on the values in each
column of X. Should be of length ncol(X). The values are assumed to be in
the same order as the corresponding columns of X. Any value in the columns
of X larger than the corresponding upper bound is clipped at the bound.</p>
</td></tr>
<tr><td><code id="tune_classification_model_+3A_lower.bounds">lower.bounds</code></td>
<td>
<p>Numeric vector giving lower bounds on the values in each
column of X. Should be of length ncol(X). The values are assumed to be in
the same order as the corresponding columns of X. Any value in the columns
of X smaller than the corresponding lower bound is clipped at the bound.</p>
</td></tr>
<tr><td><code id="tune_classification_model_+3A_add.bias">add.bias</code></td>
<td>
<p>Boolean indicating whether to add a bias term to X. Defaults
to FALSE.</p>
</td></tr>
<tr><td><code id="tune_classification_model_+3A_weights">weights</code></td>
<td>
<p>Numeric vector of observation weights of the same length as
<code>y</code>.</p>
</td></tr>
<tr><td><code id="tune_classification_model_+3A_weights.upper.bound">weights.upper.bound</code></td>
<td>
<p>Numeric value representing the global or public
upper bound on the weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Single model object selected from the input list DPmodels with tuned
parameters.
</p>


<h3>References</h3>

<p>Chaudhuri K, Monteleoni C, Sarwate AD (2011).
&ldquo;Differentially Private Empirical Risk Minimization.&rdquo;
<em>Journal of Machine Learning Research</em>, <b>12</b>(29), 1069-1109.
<a href="https://jmlr.org/papers/v12/chaudhuri11a.html">https://jmlr.org/papers/v12/chaudhuri11a.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build train dataset X and y, and test dataset Xtest and ytest
N &lt;- 200
K &lt;- 2
X &lt;- data.frame()
y &lt;- data.frame()
for (j in (1:K)){
  t &lt;- seq(-.25,.25,length.out = N)
  if (j==1) m &lt;- stats::rnorm(N,-.2,.1)
  if (j==2) m &lt;- stats::rnorm(N, .2,.1)
  Xtemp &lt;- data.frame(x1 = 3*t , x2 = m - t)
  ytemp &lt;- data.frame(matrix(j-1, N, 1))
  X &lt;- rbind(X, Xtemp)
  y &lt;- rbind(y, ytemp)
}
Xtest &lt;- X[seq(1,(N*K),10),]
ytest &lt;- y[seq(1,(N*K),10),,drop=FALSE]
X &lt;- X[-seq(1,(N*K),10),]
y &lt;- y[-seq(1,(N*K),10),,drop=FALSE]
y &lt;- as.matrix(y)
weights &lt;- rep(1, nrow(y)) # Uniform weighting
weights[nrow(y)] &lt;- 0.5 # half weight for last observation
wub &lt;- 1 # Public upper bound for weights

# Grid of possible gamma values for tuning logistic regression model
grid.search &lt;- c(100, 1, .0001)

# Construct objects for SVM parameter tuning
eps &lt;- 1 # Privacy budget should be the same for all models
svmdp1 &lt;- svmDP$new("l2", eps, grid.search[1], perturbation.method='output')
svmdp2 &lt;- svmDP$new("l2", eps, grid.search[2], perturbation.method='output')
svmdp3 &lt;- svmDP$new("l2", eps, grid.search[3], perturbation.method='output')
DPmodels &lt;- c(svmdp1, svmdp2, svmdp3)

# Tune using data and bounds for X based on its construction
upper.bounds &lt;- c( 1, 1)
lower.bounds &lt;- c(-1,-1)
tuned.model &lt;- tune_classification_model(DPmodels, X, y, upper.bounds,
                                         lower.bounds, weights=weights,
                                         weights.upper.bound=wub)
tuned.model$gamma # Gives resulting selected hyperparameter

# tuned.model result can be used the same as a trained LogisticRegressionDP model
# Predict new data points
predicted.y &lt;- tuned.model$predict(Xtest)
n.errors &lt;- sum(predicted.y!=ytest)

</code></pre>

<hr>
<h2 id='tune_linear_regression_model'>Privacy-preserving Hyperparameter Tuning for Linear Regression Models</h2><span id='topic+tune_linear_regression_model'></span>

<h3>Description</h3>

<p>This function implements the privacy-preserving hyperparameter tuning
function for linear regression (Kifer et al. 2012) using the
exponential mechanism. It accepts a list of DP models with various chosen
hyperparameters, a dataset X with corresponding values y, upper and lower
bounds on the columns of X and the values of y, and a boolean indicating
whether to add bias in the construction of each of the models. The data are
split into m+1 equal groups, where m is the number of models being compared.
One group is set aside as the validation group, and each of the other m
groups are used to train each of the given m models. The negative of the sum
of the squared error for each model on the validation set is used as the
utility values in the exponential mechanism
(<code><a href="#topic+ExponentialMechanism">ExponentialMechanism</a></code>) to select a tuned model in a
privacy-preserving way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tune_linear_regression_model(
  DPmodels,
  X,
  y,
  upper.bounds,
  lower.bounds,
  add.bias = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tune_linear_regression_model_+3A_dpmodels">DPmodels</code></td>
<td>
<p>Vector of linear regression model objects, each initialized
with a different combination of hyperparameter values from the search space
for tuning. Each model should be initialized with the same epsilon privacy
parameter value eps. The tuned model satisfies eps-level differential
privacy.</p>
</td></tr>
<tr><td><code id="tune_linear_regression_model_+3A_x">X</code></td>
<td>
<p>Dataframe of data to be used in tuning the model. Note it is assumed
the data rows and corresponding labels are randomly shuffled.</p>
</td></tr>
<tr><td><code id="tune_linear_regression_model_+3A_y">y</code></td>
<td>
<p>Vector or matrix of true values for each row of X.</p>
</td></tr>
<tr><td><code id="tune_linear_regression_model_+3A_upper.bounds">upper.bounds</code></td>
<td>
<p>Numeric vector giving upper bounds on the values in each
column of X and the values in y. Should be length ncol(X)+1. The first
ncol(X) values are assumed to be in the same order as the corresponding
columns of X, while the last value in the vector is assumed to be the upper
bound on y. Any value in the columns of X and y larger than the
corresponding upper bound is clipped at the bound.</p>
</td></tr>
<tr><td><code id="tune_linear_regression_model_+3A_lower.bounds">lower.bounds</code></td>
<td>
<p>Numeric vector giving lower bounds on the values in each
column of X and the values in y. Should be length ncol(X)+1. The first
ncol(X) values are assumed to be in the same order as the corresponding
columns of X, while the last value in the vector is assumed to be the lower
bound on y. Any value in the columns of X and y smaller than the
corresponding lower bound is clipped at the bound.</p>
</td></tr>
<tr><td><code id="tune_linear_regression_model_+3A_add.bias">add.bias</code></td>
<td>
<p>Boolean indicating whether to add a bias term to X. Defaults
to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Single model object selected from the input list DPmodels with tuned
parameters.
</p>


<h3>References</h3>

<p>Kifer D, Smith A, Thakurta A (2012).
&ldquo;Private Convex Empirical Risk Minimization and High-dimensional Regression.&rdquo;
In Mannor S, Srebro N, Williamson RC (eds.), <em>Proceedings of the 25th Annual Conference on Learning Theory</em>, volume 23 of <em>Proceedings of Machine Learning Research</em>, 25.1&ndash;25.40.
<a href="https://proceedings.mlr.press/v23/kifer12.html">https://proceedings.mlr.press/v23/kifer12.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build example dataset
n &lt;- 500
X &lt;- data.frame(X=seq(-1,1,length.out = n))
true.theta &lt;- c(-.3,.5) # First element is bias term
p &lt;- length(true.theta)
y &lt;- true.theta[1] + as.matrix(X)%*%true.theta[2:p] + stats::rnorm(n=n,sd=.1)

# Grid of possible gamma values for tuning linear regression model
grid.search &lt;- c(100, 1, .0001)

# Construct objects for logistic regression parameter tuning
# Privacy budget should be the same for all models
eps &lt;- 1
delta &lt;- 0.01
linrdp1 &lt;- LinearRegressionDP$new("l2", eps, delta, grid.search[1])
linrdp2 &lt;- LinearRegressionDP$new("l2", eps, delta, grid.search[2])
linrdp3 &lt;- LinearRegressionDP$new("l2", eps, delta, grid.search[3])
DPmodels &lt;- c(linrdp1, linrdp2, linrdp3)

# Tune using data and bounds for X and y based on their construction
upper.bounds &lt;- c( 1, 2) # Bounds for X and y
lower.bounds &lt;- c(-1,-2) # Bounds for X and y
tuned.model &lt;- tune_linear_regression_model(DPmodels, X, y, upper.bounds,
                                            lower.bounds, add.bias=TRUE)
tuned.model$gamma # Gives resulting selected hyperparameter

# tuned.model result can be used the same as a trained LogisticRegressionDP model
tuned.model$coeff # Gives coefficients for tuned model

# Build a test dataset for prediction
Xtest &lt;- data.frame(X=c(-.5, -.25, .1, .4))
predicted.y &lt;- tuned.model$predict(Xtest, add.bias=TRUE)

</code></pre>

<hr>
<h2 id='varDataAccess'>Differentially Private Variance Data Access Function</h2><span id='topic+varDataAccess'></span>

<h3>Description</h3>

<p>This function performs the data access step in the computation of a
differentially private variance. The true values are computed using
<code><a href="stats.html#topic+var">var</a></code>, while the sensitivities are calculated based on
bounded and unbounded differential privacy (Kifer and Machanavajjhala 2011)
according to the theoretical values (Liu 2019). For the
variance, the sensitivities based on bounded and unbounded differential
privacy are identical, so only one value is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varDataAccess(x, lower.bound, upper.bound)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varDataAccess_+3A_x">x</code></td>
<td>
<p>Dataset whose variance is desired.</p>
</td></tr>
<tr><td><code id="varDataAccess_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Scalar representing the global or public lower bound on
values of x.</p>
</td></tr>
<tr><td><code id="varDataAccess_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Scalar representing the global or public upper bound on
values of x.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of the true variance and the sensitivity calculated based on
theoretical values.
</p>


<h3>References</h3>

<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>varDataAccess(c(1,4,3,2), 0, 5)

</code></pre>

<hr>
<h2 id='varDP'>Differentially Private Variance</h2><span id='topic+varDP'></span>

<h3>Description</h3>

<p>This function computes the differentially private variance of a given dataset
at user-specified privacy levels of epsilon and delta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varDP(
  x,
  eps,
  lower.bound,
  upper.bound,
  which.sensitivity = "bounded",
  mechanism = "Laplace",
  delta = 0,
  type.DP = "aDP"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varDP_+3A_x">x</code></td>
<td>
<p>Numeric vector whose variance is desired.</p>
</td></tr>
<tr><td><code id="varDP_+3A_eps">eps</code></td>
<td>
<p>Positive real number defining the epsilon privacy budget.</p>
</td></tr>
<tr><td><code id="varDP_+3A_lower.bound">lower.bound</code></td>
<td>
<p>Scalar representing the global or public lower bound on
values of x.</p>
</td></tr>
<tr><td><code id="varDP_+3A_upper.bound">upper.bound</code></td>
<td>
<p>Scalar representing the global or public upper bound on
values of x.</p>
</td></tr>
<tr><td><code id="varDP_+3A_which.sensitivity">which.sensitivity</code></td>
<td>
<p>String indicating which type of sensitivity to use.
Can be one of {'bounded', 'unbounded', 'both'}. If 'bounded' (default),
returns result based on bounded definition for differential privacy. If
'unbounded', returns result based on unbounded definition. If 'both',
returns result based on both methods (Kifer and Machanavajjhala 2011). Note
that if 'both' is chosen, each result individually satisfies (eps,
delta)-differential privacy, but may not do so collectively and in
composition. Care must be taken not to violate differential privacy in this
case.</p>
</td></tr>
<tr><td><code id="varDP_+3A_mechanism">mechanism</code></td>
<td>
<p>String indicating which mechanism to use for differential
privacy. Currently the following mechanisms are supported: {'Laplace',
'Gaussian', 'analytic'}. Default is Laplace. See <code><a href="#topic+LaplaceMechanism">LaplaceMechanism</a></code>
and <code><a href="#topic+GaussianMechanism">GaussianMechanism</a></code> for descriptions of the supported
mechanisms.</p>
</td></tr>
<tr><td><code id="varDP_+3A_delta">delta</code></td>
<td>
<p>Nonnegative real number defining the delta privacy parameter. If
0 (default), reduces to eps-DP.</p>
</td></tr>
<tr><td><code id="varDP_+3A_type.dp">type.DP</code></td>
<td>
<p>String indicating the type of differential privacy desired for
the Gaussian mechanism (if selected). Can be either 'pDP' for probabilistic
DP (Machanavajjhala et al. 2008) or 'aDP' for approximate DP
(Dwork et al. 2006). Note that if 'aDP' is chosen, epsilon must
be strictly less than 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sanitized variance based on the bounded and/or unbounded definitions
of differential privacy.
</p>


<h3>References</h3>

<p>Dwork C, McSherry F, Nissim K, Smith A (2006).
&ldquo;Calibrating Noise to Sensitivity in Private Data Analysis.&rdquo;
In Halevi S, Rabin T (eds.), <em>Theory of Cryptography</em>, 265&ndash;284.
ISBN 978-3-540-32732-5, <a href="https://doi.org/10.1007/11681878_14">https://doi.org/10.1007/11681878_14</a>.
</p>
<p>Kifer D, Machanavajjhala A (2011).
&ldquo;No Free Lunch in Data Privacy.&rdquo;
In <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em>,  SIGMOD '11, 193–204.
ISBN 9781450306614, <a href="https://doi.org/10.1145/1989323.1989345">doi:10.1145/1989323.1989345</a>.
</p>
<p>Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008).
&ldquo;Privacy: Theory meets Practice on the Map.&rdquo;
In <em>2008 IEEE 24th International Conference on Data Engineering</em>, 277-286.
<a href="https://doi.org/10.1109/ICDE.2008.4497436">doi:10.1109/ICDE.2008.4497436</a>.
</p>
<p>Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006).
&ldquo;Our Data, Ourselves: Privacy Via Distributed Noise Generation.&rdquo;
In Vaudenay S (ed.), <em>Advances in Cryptology - EUROCRYPT 2006</em>, 486&ndash;503.
ISBN 978-3-540-34547-3, <a href="https://doi.org/10.1007/11761679_29">doi:10.1007/11761679_29</a>.
</p>
<p>Liu F (2019).
&ldquo;Statistical Properties of Sanitized Results from Differentially Private Laplace Mechanism with Univariate Bounding Constraints.&rdquo;
<em>Transactions on Data Privacy</em>, <b>12</b>(3), 169-195.
<a href="http://www.tdp.cat/issues16/tdp.a316a18.pdf">http://www.tdp.cat/issues16/tdp.a316a18.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>D &lt;- stats::rnorm(500, mean=3, sd=2)
lb &lt;- -3 # 3 std devs below mean
ub &lt;- 9 # 3 std devs above mean
varDP(D, 1, lb, ub)
varDP(D,.5, lb, ub, which.sensitivity='unbounded', mechanism='Gaussian',
  delta=0.01)

</code></pre>

<hr>
<h2 id='WeightedERMDP.CMS'>Privacy-preserving Weighted Empirical Risk Minimization</h2><span id='topic+WeightedERMDP.CMS'></span>

<h3>Description</h3>

<p>This class implements differentially private empirical risk
minimization in the case where weighted observation-level losses are
desired (such as weighted SVM (Yang et al. 2005)). Currently,
only the output perturbation method is implemented.
</p>


<h3>Details</h3>

<p>To use this class for weighted empirical risk minimization, first
use the <code>new</code> method to construct an object of this class with the
desired function values and hyperparameters. After constructing the object,
the <code>fit</code> method can be applied with a provided dataset, data bounds,
weights, and weight bounds to fit the model. In fitting, the model stores a
vector of coefficients <code>coeff</code> which satisfy differential privacy.
These can be released directly, or used in conjunction with the
<code>predict</code> method to privately predict the outcomes of new datapoints.
</p>
<p>Note that in order to guarantee differential privacy for weighted empirical
risk minimization, certain constraints must be satisfied for the values
used to construct the object, as well as for the data used to fit. These
conditions depend on the chosen perturbation method, though currently only
output perturbation is implemented. Specifically, the provided loss
function must be convex and differentiable with respect to <code>y.hat</code>,
and the absolute value of the first derivative of the loss function must be
at most 1. If objective perturbation is chosen (not currently implemented),
the loss function must also be doubly differentiable and the absolute value
of the second derivative of the loss function must be bounded above by a
constant c for all possible values of <code>y.hat</code> and <code>y</code>, where
<code>y.hat</code> is the predicted label and <code>y</code> is the true label. The
regularizer must be 1-strongly convex and differentiable. It also must be
doubly differentiable if objective perturbation is chosen. For the data x,
it is assumed that if x represents a single row of the dataset X, then the
l2-norm of x is at most 1 for all x. Note that because of this, a bias term
cannot be included without appropriate scaling/preprocessing of the
dataset. To ensure privacy, the add.bias argument in the <code>fit</code> and
<code>predict</code> methods should only be utilized in subclasses within this
package where appropriate preprocessing is implemented, not in this class.
Finally, if weights are provided, they should be nonnegative, of the same
length as y, and be upper bounded by a global or public bound which must
also be provided.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+EmpiricalRiskMinimizationDP.CMS">DPpack::EmpiricalRiskMinimizationDP.CMS</a></code> -&gt; <code>WeightedERMDP.CMS</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-WeightedERMDP.CMS-new"><code>WeightedERMDP.CMS$new()</code></a>
</p>
</li>
<li> <p><a href="#method-WeightedERMDP.CMS-fit"><code>WeightedERMDP.CMS$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-WeightedERMDP.CMS-predict"><code>WeightedERMDP.CMS$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-WeightedERMDP.CMS-clone"><code>WeightedERMDP.CMS$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-WeightedERMDP.CMS-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>WeightedERMDP.CMS</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>WeightedERMDP.CMS$new(
  mapXy,
  loss,
  regularizer,
  eps,
  gamma,
  perturbation.method = "objective",
  c = NULL,
  mapXy.gr = NULL,
  loss.gr = NULL,
  regularizer.gr = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>mapXy</code></dt><dd><p>Map function of the form <code>mapXy(X, coeff)</code> mapping input
data matrix <code>X</code> and coefficient vector or matrix <code>coeff</code> to
output labels <code>y</code>. Should return a column matrix of predicted labels
for each row of <code>X</code>. See <code><a href="#topic+mapXy.sigmoid">mapXy.sigmoid</a></code> for an example.</p>
</dd>
<dt><code>loss</code></dt><dd><p>Loss function of the form <code>loss(y.hat, y, w)</code>, where
<code>y.hat</code> and <code>y</code> are matrices and <code>w</code> is a matrix or vector
of weights of the same length as <code>y</code>. Should be defined such that it
returns a matrix of weighted loss values for each element of <code>y.hat</code>
and <code>y</code>. If <code>w</code> is not given, the function should operate as if
uniform weights were given. See <code><a href="#topic+generate.loss.huber">generate.loss.huber</a></code> for an
example. It must be convex and differentiable, and the absolute value of
the first derivative of the loss function must be at most 1.
Additionally, if the objective perturbation method is chosen, it must be
doubly differentiable and the absolute value of the second derivative of
the loss function must be bounded above by a constant c for all possible
values of <code>y.hat</code> and <code>y</code>.</p>
</dd>
<dt><code>regularizer</code></dt><dd><p>String or regularization function. If a string, must be
'l2', indicating to use l2 regularization. If a function, must have form
<code>regularizer(coeff)</code>, where <code>coeff</code> is a vector or matrix, and
return the value of the regularizer at <code>coeff</code>. See
<code><a href="#topic+regularizer.l2">regularizer.l2</a></code> for an example. Additionally, in order to
ensure differential privacy, the function must be 1-strongly convex and
differentiable. If the objective perturbation method is chosen, it must
also be doubly differentiable.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Positive real number defining the epsilon privacy budget. If set
to Inf, runs algorithm without differential privacy.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>Nonnegative real number representing the regularization
constant.</p>
</dd>
<dt><code>perturbation.method</code></dt><dd><p>String indicating whether to use the 'output' or
the 'objective' perturbation methods (Chaudhuri et al. 2011).
Defaults to 'objective'. Currently, only the output perturbation method
is supported.</p>
</dd>
<dt><code>c</code></dt><dd><p>Positive real number denoting the upper bound on the absolute
value of the second derivative of the loss function, as required to
ensure differential privacy for the objective perturbation method. This
input is unnecessary if perturbation.method is 'output', but is required
if perturbation.method is 'objective'. Defaults to NULL.</p>
</dd>
<dt><code>mapXy.gr</code></dt><dd><p>Optional function representing the gradient of the map
function with respect to the values in <code>coeff</code>. If given, must be of
the form <code>mapXy.gr(X, coeff)</code>, where <code>X</code> is a matrix and
<code>coeff</code> is a matrix or numeric vector. Should be defined such that
the ith row of the output represents the gradient with respect to the ith
coefficient. See <code><a href="#topic+mapXy.gr.sigmoid">mapXy.gr.sigmoid</a></code> for an example. If not
given, non-gradient based optimization methods are used to compute the
coefficient values in fitting the model.</p>
</dd>
<dt><code>loss.gr</code></dt><dd><p>Optional function representing the gradient of the loss
function with respect to <code>y.hat</code> and of the form
<code>loss.gr(y.hat, y, w)</code>, where <code>y.hat</code> and <code>y</code> are matrices
and <code>w</code> is a matrix or vector of weights. Should be defined such
that the ith row of the output represents the gradient of the (possibly
weighted) loss function at the ith set of input values. See
<code><a href="#topic+generate.loss.gr.huber">generate.loss.gr.huber</a></code> for an example. If not given,
non-gradient based optimization methods are used to compute the
coefficient values in fitting the model.</p>
</dd>
<dt><code>regularizer.gr</code></dt><dd><p>Optional function representing the gradient of the
regularization function with respect to <code>coeff</code> and of the form
<code>regularizer.gr(coeff)</code>. Should return a vector. See
<code><a href="#topic+regularizer.gr.l2">regularizer.gr.l2</a></code> for an example. If <code>regularizer</code> is
given as a string, this value is ignored. If not given and
<code>regularizer</code> is a function, non-gradient based optimization methods
are used to compute the coefficient values in fitting the model.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>WeightedERMDP.CMS</code> object.
</p>


<hr>
<a id="method-WeightedERMDP.CMS-fit"></a>



<h4>Method <code>fit()</code></h4>

<p>Fit the differentially private weighted empirical risk
minimization model. This method runs either the output perturbation or
the objective perturbation algorithm (Chaudhuri et al. 2011)
(only output is currently implemented), depending on the value of
perturbation.method used to construct the object, to generate an
objective function. A numerical optimization method is then run to find
optimal coefficients for fitting the model given the training data,
weights, and hyperparameters. The built-in <code><a href="stats.html#topic+optim">optim</a></code> function
using the &quot;BFGS&quot; optimization method is used. If <code>mapXy.gr</code>,
<code>loss.gr</code>, and <code>regularizer.gr</code> are all given in the
construction of the object, the gradient of the objective function is
utilized by <code>optim</code> as well. Otherwise, non-gradient based
optimization methods are used. The resulting privacy-preserving
coefficients are stored in <code>coeff</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>WeightedERMDP.CMS$fit(
  X,
  y,
  upper.bounds,
  lower.bounds,
  add.bias = FALSE,
  weights = NULL,
  weights.upper.bound = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data to be fit.</p>
</dd>
<dt><code>y</code></dt><dd><p>Vector or matrix of true labels for each row of <code>X</code>.</p>
</dd>
<dt><code>upper.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)</code> giving upper
bounds on the values in each column of X. The <code>ncol(X)</code> values are
assumed to be in the same order as the corresponding columns of <code>X</code>.
Any value in the columns of <code>X</code> larger than the corresponding upper
bound is clipped at the bound.</p>
</dd>
<dt><code>lower.bounds</code></dt><dd><p>Numeric vector of length <code>ncol(X)</code> giving lower
bounds on the values in each column of <code>X</code>. The <code>ncol(X)</code>
values are assumed to be in the same order as the corresponding columns
of <code>X</code>. Any value in the columns of <code>X</code> larger than the
corresponding upper bound is clipped at the bound.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE.</p>
</dd>
<dt><code>weights</code></dt><dd><p>Numeric vector of observation weights of the same length as
<code>y</code>.</p>
</dd>
<dt><code>weights.upper.bound</code></dt><dd><p>Numeric value representing the global or public
upper bound on the weights.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-WeightedERMDP.CMS-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict label(s) for given <code>X</code> using the fitted
coefficients.
</p>


<h5>Usage</h5>

<div class="r"><pre>WeightedERMDP.CMS$predict(X, add.bias = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt><dd><p>Dataframe of data on which to make predictions. Must be of same
form as <code>X</code> used to fit coefficients.</p>
</dd>
<dt><code>add.bias</code></dt><dd><p>Boolean indicating whether to add a bias term to <code>X</code>.
Defaults to FALSE. If add.bias was set to TRUE when fitting the
coefficients, add.bias should be set to TRUE for predictions.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Matrix of predicted labels corresponding to each row of <code>X</code>.
</p>


<hr>
<a id="method-WeightedERMDP.CMS-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>WeightedERMDP.CMS$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Chaudhuri K, Monteleoni C, Sarwate AD (2011).
&ldquo;Differentially Private Empirical Risk Minimization.&rdquo;
<em>Journal of Machine Learning Research</em>, <b>12</b>(29), 1069-1109.
<a href="https://jmlr.org/papers/v12/chaudhuri11a.html">https://jmlr.org/papers/v12/chaudhuri11a.html</a>.
</p>
<p>Yang X, Song Q, Cao A (2005).
&ldquo;Weighted support vector machine for data classification.&rdquo;
In <em>Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.</em>, volume 2, 859-864 vol. 2.
<a href="https://doi.org/10.1109/IJCNN.2005.1555965">doi:10.1109/IJCNN.2005.1555965</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build train dataset X and y, and test dataset Xtest and ytest
N &lt;- 200
K &lt;- 2
X &lt;- data.frame()
y &lt;- data.frame()
for (j in (1:K)){
  t &lt;- seq(-.25, .25, length.out = N)
  if (j==1) m &lt;- stats::rnorm(N,-.2, .1)
  if (j==2) m &lt;- stats::rnorm(N, .2, .1)
  Xtemp &lt;- data.frame(x1 = 3*t , x2 = m - t)
  ytemp &lt;- data.frame(matrix(j-1, N, 1))
  X &lt;- rbind(X, Xtemp)
  y &lt;- rbind(y, ytemp)
}
Xtest &lt;- X[seq(1,(N*K),10),]
ytest &lt;- y[seq(1,(N*K),10),,drop=FALSE]
X &lt;- X[-seq(1,(N*K),10),]
y &lt;- y[-seq(1,(N*K),10),,drop=FALSE]

# Construct object for weighted linear SVM
mapXy &lt;- function(X, coeff) X%*%coeff
# Huber loss from DPpack
huber.h &lt;- 0.5
loss &lt;- generate.loss.huber(huber.h)
regularizer &lt;- 'l2' # Alternatively, function(coeff) coeff%*%coeff/2
eps &lt;- 1
gamma &lt;- 1
perturbation.method &lt;- 'output'
c &lt;- 1/(2*huber.h) # Required value for SVM
mapXy.gr &lt;- function(X, coeff) t(X)
loss.gr &lt;- generate.loss.gr.huber(huber.h)
regularizer.gr &lt;- function(coeff) coeff
wermdp &lt;- WeightedERMDP.CMS$new(mapXy, loss, regularizer, eps,
                                gamma, perturbation.method, c,
                                mapXy.gr, loss.gr,
                                regularizer.gr)

# Fit with data
# Bounds for X based on construction
upper.bounds &lt;- c( 1, 1)
lower.bounds &lt;- c(-1,-1)
weights &lt;- rep(1, nrow(y)) # Uniform weighting
weights[nrow(y)] &lt;- 0.5 # half weight for last observation
wub &lt;- 1 # Public upper bound for weights
wermdp$fit(X, y, upper.bounds, lower.bounds, weights=weights,
           weights.upper.bound=wub)
wermdp$coeff # Gets private coefficients

# Predict new data points
predicted.y &lt;- wermdp$predict(Xtest)
n.errors &lt;- sum(round(predicted.y)!=ytest)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
