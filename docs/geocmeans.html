<!DOCTYPE html><html lang="en-CA"><head><title>Help for package geocmeans</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {geocmeans}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add_matrices_bycol'><p>sum of two matrices by column</p></a></li>
<li><a href='#adj_spconsist_arr_window_globstd'><p>Adjusted spatial inconsistency index for rasters</p></a></li>
<li><a href='#adjustSpatialWeights'><p>Semantic adjusted spatial weights</p></a></li>
<li><a href='#Arcachon'><p>SpatRaster of the bay of Arcachon</p></a></li>
<li><a href='#barPlots'><p>Bar plots</p></a></li>
<li><a href='#belongsFCM'><p>membership matrix calculator for FCM algorithm</p></a></li>
<li><a href='#belongsGFCM'><p>membership matrix calculator for GFCM algorithm</p></a></li>
<li><a href='#belongsSFCM'><p>membership matrix calculator for SFCM algorithm</p></a></li>
<li><a href='#belongsSGFCM'><p>membership matrix calculator for SGFCM algorithm</p></a></li>
<li><a href='#boot_group_validation'><p>Check the robustness of a classification by Bootstrap</p></a></li>
<li><a href='#boot_group_validation.mc'><p>Check that the obtained groups are stable by bootstrap (multicore)</p></a></li>
<li><a href='#boot_worker'><p>Worker function for cluster bootstrapping</p></a></li>
<li><a href='#calc_jaccard_idx'><p>Jaccard similarity coefficient</p></a></li>
<li><a href='#calc_jaccard_mat'><p>Jaccard similarity coefficient between columns of two matrices</p></a></li>
<li><a href='#calc_local_moran_raster'><p>Local Moran I for raster</p></a></li>
<li><a href='#calc_moran_raster'><p>Global Moran I for raster</p></a></li>
<li><a href='#calc_raster_spinconsistency'><p>calculate spatial inconsistency for raster</p></a></li>
<li><a href='#calcBelongMatrix'><p>Calculate the membership matrix</p></a></li>
<li><a href='#calcBelongMatrixNoisy'><p>Calculate the membership matrix with a noise cluster</p></a></li>
<li><a href='#calcCalinskiHarabasz'><p>Calinski-Harabasz index</p></a></li>
<li><a href='#calcCentroids'><p>Calculate the centroids</p></a></li>
<li><a href='#calcDaviesBouldin'><p>Davies-Bouldin index</p></a></li>
<li><a href='#calcELSA'><p>calculate ELSA statistic for a hard partition</p></a></li>
<li><a href='#calcEuclideanDistance'><p>Calculate the Euclidean distance</p></a></li>
<li><a href='#calcEuclideanDistance2'><p>euclidean distance between rows of a matrix and a vector</p></a></li>
<li><a href='#calcEuclideanDistance3'><p>euclidean distance between rows of a matrix and a vector (arma mode)</p></a></li>
<li><a href='#calcexplainedInertia'><p>Explained inertia index</p></a></li>
<li><a href='#calcFGCMBelongMatrix'><p>Calculate the generalized membership matrix</p></a></li>
<li><a href='#calcFGCMBelongMatrixNoisy'><p>Calculate the generalized membership matrix with a noise cluster</p></a></li>
<li><a href='#calcFukuyamaSugeno'><p>Fukuyama and Sugeno index</p></a></li>
<li><a href='#calcFuzzyELSA'><p>calculate ELSA statistic for a fuzzy partition</p></a></li>
<li><a href='#calcFuzzyElsa_raster'><p>Local Fuzzy ELSA statistic for raster</p></a></li>
<li><a href='#calcGD43'><p>Generalized Dunn’s index (43)</p></a></li>
<li><a href='#calcGD53'><p>Generalized Dunn’s index (53)</p></a></li>
<li><a href='#calcLaggedData'><p>Lagged Data</p></a></li>
<li><a href='#calcNegentropyI'><p>Negentropy Increment index</p></a></li>
<li><a href='#calcQualIdx'><p>calculate the quality index required</p></a></li>
<li><a href='#calcqualityIndexes'><p>Quality indexes</p></a></li>
<li><a href='#calcRobustSigmas'><p>Calculate sigmas for the robust version of the c-means algorithm</p></a></li>
<li><a href='#calcSFCMBelongMatrix'><p>Calculate the membership matrix (spatial version)</p></a></li>
<li><a href='#calcSFCMBelongMatrixNoisy'><p>Calculate the membership matrix (spatial version) with a noise cluster</p></a></li>
<li><a href='#calcSFGCMBelongMatrix'><p>Calculate the generalized membership matrix (spatial version)</p></a></li>
<li><a href='#calcSFGCMBelongMatrixNoisy'><p>Calculate the generalized membership matrix (spatial version) with a noise cluster</p></a></li>
<li><a href='#calcSilhouetteIdx'><p>Fuzzy Silhouette index</p></a></li>
<li><a href='#calcSWFCCentroids'><p>Calculate the centroids of SFCM</p></a></li>
<li><a href='#calcUncertaintyIndex'><p>Diversity index</p></a></li>
<li><a href='#calcWdataRaster'><p>Calculate lagged values for a raster dataset</p></a></li>
<li><a href='#cat_to_belongings'><p>Convert categories to membership matrix</p></a></li>
<li><a href='#centersFCM'><p>center matrix calculator for FCM algorithm</p></a></li>
<li><a href='#centersGFCM'><p>center matrix calculator for GFCM algorithm</p></a></li>
<li><a href='#centersSFCM'><p>center matrix calculator for SFCM algorithm</p></a></li>
<li><a href='#centersSGFCM'><p>center matrix calculator for SGFCM algorithm</p></a></li>
<li><a href='#check_matdist'><p>Check validity of a dissimilarity matrix</p></a></li>
<li><a href='#check_raters_dims'><p>Check dimensions of a list of rasters</p></a></li>
<li><a href='#check_window'><p>Check the shape of a window</p></a></li>
<li><a href='#circular_window'><p>Circular window</p></a></li>
<li><a href='#CMeans'><p>C-means</p></a></li>
<li><a href='#div_matrices_bycol'><p>element wise division of two matrices by column</p></a></li>
<li><a href='#Elsa_categorical_matrix_window'><p>Elsa statistic calculated on a matrix with a given window</p></a></li>
<li><a href='#Elsa_fuzzy_matrix_window'><p>Fuzzy Elsa statistic calculated on a matrix with a given window</p></a></li>
<li><a href='#elsa_fuzzy_vector'><p>Local Fuzzy ELSA statistic for vector</p></a></li>
<li><a href='#elsa_raster'><p>calculate ELSA spatial statistic for raster dataset</p></a></li>
<li><a href='#elsa_vector'><p>calculate ELSA spatial statistic for vector dataset</p></a></li>
<li><a href='#eval_parameters'><p>Worker function</p></a></li>
<li><a href='#evaluateMatrices'><p>Matrix evaluation</p></a></li>
<li><a href='#FCMres'><p>Instantiate a FCMres object</p></a></li>
<li><a href='#focal_adj_mean_arr_window'><p>focal mean weighted by inverse of euclidean distance on a cube</p></a></li>
<li><a href='#focal_euclidean'><p>focal euclidean distance on a list of matrices</p></a></li>
<li><a href='#focal_euclidean_arr_window'><p>focal euclidean distance on a matrix with a given window for a cube</p></a></li>
<li><a href='#focal_euclidean_mat_window'><p>focal euclidean distance on a matrix with a given window</p></a></li>
<li><a href='#GCMeans'><p>Generalized C-means</p></a></li>
<li><a href='#geocmeans'><p>geocmeans: A package implementing methods for spatially constrained c-means</p>
algorithm</a></li>
<li><a href='#geocmeans_env'><p>geocmeans general environment</p></a></li>
<li><a href='#groups_matching'><p>Match the groups obtained from two classifications</p></a></li>
<li><a href='#input_raster_data'><p>Raster data preparation</p></a></li>
<li><a href='#is.FCMres'><p>is method for FCMres</p></a></li>
<li><a href='#kppCenters'><p>kpp centers selection</p></a></li>
<li><a href='#local_moranI_matrix_window'><p>Local Moran I calculated on a matrix with a given window</p></a></li>
<li><a href='#LyonIris'><p>social and environmental indicators for the Iris of the metropolitan region of Lyon (France)</p></a></li>
<li><a href='#main_worker'><p>Main worker function</p></a></li>
<li><a href='#mapClusters'><p>Mapping the clusters</p></a></li>
<li><a href='#mapRasters'><p>Mapping the clusters (rasters)</p></a></li>
<li><a href='#mapThis'><p>Mapping the clusters</p></a></li>
<li><a href='#max_mat'><p>maximum in a matrix</p></a></li>
<li><a href='#moranI_matrix_window'><p>Moran I calculated on a matrix with a given window</p></a></li>
<li><a href='#output_raster_data'><p>Raster result transformation</p></a></li>
<li><a href='#plot.FCMres'><p>Plot method for FCMres object</p></a></li>
<li><a href='#pow_matrices_bycol'><p>element wise power of a matrix by column</p></a></li>
<li><a href='#power_mat'><p>power of a matrix</p></a></li>
<li><a href='#predict_membership'><p>Predict matrix membership for new observations</p></a></li>
<li><a href='#predict.FCMres'><p>Predict method for FCMres object</p></a></li>
<li><a href='#print.FCMres'><p>print method for FCMres</p></a></li>
<li><a href='#prod_matrices_bycol'><p>element wise product of two matrices by column</p></a></li>
<li><a href='#rowmins_mat'><p>minimum of each row of a matrix</p></a></li>
<li><a href='#sanity_check'><p>Parameter checking function</p></a></li>
<li><a href='#select_parameters'><p>Select parameters for a clustering algorithm</p></a></li>
<li><a href='#select_parameters.mc'><p>Select parameters for clustering algorithm (multicore)</p></a></li>
<li><a href='#SFCMeans'><p>SFCMeans</p></a></li>
<li><a href='#SGFCMeans'><p>SGFCMeans</p></a></li>
<li><a href='#sp_clust_explorer'><p>Classification result explorer</p></a></li>
<li><a href='#spatialDiag'><p>Spatial diagnostic</p></a></li>
<li><a href='#spConsistency'><p>Spatial consistency index</p></a></li>
<li><a href='#spiderPlots'><p>Spider chart</p></a></li>
<li><a href='#sqrt_matrix_bycol'><p>element wise square root of a matrix by column</p></a></li>
<li><a href='#standardizer'><p>Standardizing helper</p></a></li>
<li><a href='#sub_matrices_bycol'><p>substraction of two matrices by column</p></a></li>
<li><a href='#summarizeClusters'><p>Descriptive statistics by group</p></a></li>
<li><a href='#summary.FCMres'><p>Summary method for FCMres</p></a></li>
<li><a href='#test_inferior_mat'><p>create a logical matrix with inferior comparison</p></a></li>
<li><a href='#uncertaintyMap'><p>Uncertainty map</p></a></li>
<li><a href='#undecidedUnits'><p>Undecided observations</p></a></li>
<li><a href='#vecmin'><p>minimum of a vector</p></a></li>
<li><a href='#vector_out_prod'><p>create a matrix by multiplying a vector by its elements one by one as rows</p></a></li>
<li><a href='#violinPlots'><p>Violin plots</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Implementing Methods for Spatial Fuzzy Unsupervised
Classification</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jeremy Gelb &lt;jeremy.gelb@ucs.inrs.ca&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2 (&ge; 3.2.1), tmap (&ge; 3.3-1), spdep (&ge; 1.1.2), reldist
(&ge; 1.6.6), dplyr (&ge; 0.8.3), fclust (&ge; 2.1.1), fmsb (&ge;
0.7.0), future.apply (&ge; 1.4.0), progressr (&ge; 0.4.0), reshape2
(&ge; 1.4.4), stats (&ge; 3.5), grDevices (&ge; 3.5), shiny (&ge;
1.6.0), sf (&ge; 1.0-6), leaflet (&ge; 2.1.1), plotly (&ge; 4.9.3),
Rdpack (&ge; 2.1.1), matrixStats (&ge; 0.58.0), methods (&ge; 3.5),
terra (&ge; 1.6-47), Rcpp (&ge; 1.0.6)</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr (&ge; 1.28), rmarkdown (&ge; 2.1), markdown (&ge; 1.1),
future (&ge; 1.16.0), ppclust (&ge; 1.1.0), ClustGeo (&ge; 2.0), car
(&ge; 3.0-7), rgl (&ge; 0.100), ggpubr (&ge; 0.2.5), RColorBrewer (&ge;
1.1-2), kableExtra (&ge; 1.1.0), viridis (&ge; 0.5.1), testthat (&ge;
3.0.0), bslib (&ge; 0.2.5), shinyWidgets (&ge; 0.6), shinyhelper
(&ge; 0.3.2), waiter (&ge; 0.2.2), classInt(&ge; 0.4-3), covr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions to apply spatial fuzzy unsupervised classification, visualize and interpret results. This method is well suited when the user wants to analyze data with a fuzzy clustering algorithm and to account for the spatial dimension of the dataset. In addition, indexes for estimating the spatial consistency and classification quality are proposed.
    The methods were originally proposed in the field of brain imagery (seed Cai and al. 2007 &lt;<a href="https://doi.org/10.1016%2Fj.patcog.2006.07.011">doi:10.1016/j.patcog.2006.07.011</a>&gt; and Zaho and al. 2013 &lt;<a href="https://doi.org/10.1016%2Fj.dsp.2012.09.016">doi:10.1016/j.dsp.2012.09.016</a>&gt;) and recently applied in geography (see Gelb and Apparicio &lt;<a href="https://doi.org/10.4000%2Fcybergeo.36414">doi:10.4000/cybergeo.36414</a>&gt;).</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/JeremyGelb/geocmeans">https://github.com/JeremyGelb/geocmeans</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/JeremyGelb/geocmeans/issues">https://github.com/JeremyGelb/geocmeans/issues</a></td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>Language:</td>
<td>en-CA</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-12 02:04:57 UTC; Gelb</td>
</tr>
<tr>
<td>Author:</td>
<td>Jeremy Gelb <a href="https://orcid.org/0000-0002-7114-2714"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Philippe Apparicio
    <a href="https://orcid.org/0000-0001-6466-9342"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-12 03:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='add_matrices_bycol'>sum of two matrices by column</h2><span id='topic+add_matrices_bycol'></span>

<h3>Description</h3>

<p>sum of two matrices by column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_matrices_bycol(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_matrices_bycol_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="add_matrices_bycol_+3A_y">y</code></td>
<td>
<p>a matrix with the same dimensions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix
</p>

<hr>
<h2 id='adj_spconsist_arr_window_globstd'>Adjusted spatial inconsistency index for rasters</h2><span id='topic+adj_spconsist_arr_window_globstd'></span>

<h3>Description</h3>

<p>Adjusted spatial inconsistency index for rasters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adj_spconsist_arr_window_globstd(data, memberships, window, mindist = 1e-11)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adj_spconsist_arr_window_globstd_+3A_data">data</code></td>
<td>
<p>an arma cube of dimension nr,nc,ns</p>
</td></tr>
<tr><td><code id="adj_spconsist_arr_window_globstd_+3A_memberships">memberships</code></td>
<td>
<p>an arma cube of dimension nr, nc, ks</p>
</td></tr>
<tr><td><code id="adj_spconsist_arr_window_globstd_+3A_window">window</code></td>
<td>
<p>a matrix representing the neighbouring of each pixel</p>
</td></tr>
<tr><td><code id="adj_spconsist_arr_window_globstd_+3A_mindist">mindist</code></td>
<td>
<p>A minimum value for distance between two observations. If two
neighbours have exactly the same values, then the euclidean distance
between them is 0, leading to an infinite spatial weight. In that case,
the minimum distance is used instead of 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a double, the adjusted spatial inconsitency index
</p>

<hr>
<h2 id='adjustSpatialWeights'>Semantic adjusted spatial weights</h2><span id='topic+adjustSpatialWeights'></span>

<h3>Description</h3>

<p>Function to adjust the spatial weights so that they represent semantic
distances between neighbours
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjustSpatialWeights(data, listw, style, mindist = 1e-11)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjustSpatialWeights_+3A_data">data</code></td>
<td>
<p>A dataframe with numeric columns</p>
</td></tr>
<tr><td><code id="adjustSpatialWeights_+3A_listw">listw</code></td>
<td>
<p>A nb object from spdep</p>
</td></tr>
<tr><td><code id="adjustSpatialWeights_+3A_style">style</code></td>
<td>
<p>A letter indicating the weighting scheme (see spdep doc)</p>
</td></tr>
<tr><td><code id="adjustSpatialWeights_+3A_mindist">mindist</code></td>
<td>
<p>A minimum value for distance between two observations. If two
neighbours have exactly the same values, then the euclidean distance between
them is 0, leading to an infinite spatial weight. In that case, the minimum
distance is used instead of 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A listw object (spdep like)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
Wqueen2 &lt;- adjustSpatialWeights(dataset,queen,style="C")
</code></pre>

<hr>
<h2 id='Arcachon'>SpatRaster of the bay of Arcachon</h2><span id='topic+Arcachon'></span><span id='topic+load_arcachon'></span>

<h3>Description</h3>

<p>A Landsat 8 image of the bay of Arcachon (France), with a resolution of 30mx30m
and 6 bands: blue, green, red, near infrared, shortwave infrared 1 and shortwave infrared 2.
The dataset is saved as a Large RasterBrick with the package raster and has the
following crs: EPSG:32630. It is provided as a tiff file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_arcachon()
</code></pre>


<h3>Format</h3>

<p>A spaRast with 6 bands
</p>

<dl>
<dt>blue</dt><dd><p>wavelength: 0.45-0.51</p>
</dd>
<dt>green</dt><dd><p>wavelength: 0.53-0.59</p>
</dd>
<dt>red</dt><dd><p>wavelength: 0.64-0.67</p>
</dd>
<dt>near infrared</dt><dd><p>wavelength: 0.85-0.88</p>
</dd>
<dt>shortwave infrared</dt><dd><p>wavelength: 1.57-1.65</p>
</dd>
<dt>shortwave infrared</dt><dd><p>wavelength: 2.11-2.29</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://earthexplorer.usgs.gov/">https://earthexplorer.usgs.gov/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># loading directly from file
Arcachon &lt;- terra::rast(system.file("extdata/Littoral4_2154.tif", package = "geocmeans"))
names(Arcachon) &lt;- c("blue", "green", "red", "infrared", "SWIR1", "SWIR2")

# loading with the provided function
Arcachon &lt;- load_arcachon()
</code></pre>

<hr>
<h2 id='barPlots'>Bar plots</h2><span id='topic+barPlots'></span>

<h3>Description</h3>

<p>Return bar plots to compare groups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>barPlots(data, belongmatrix, ncol = 3, what = "mean")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="barPlots_+3A_data">data</code></td>
<td>
<p>A dataframe with numeric columns</p>
</td></tr>
<tr><td><code id="barPlots_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix</p>
</td></tr>
<tr><td><code id="barPlots_+3A_ncol">ncol</code></td>
<td>
<p>An integer indicating the number of columns for the bar plot</p>
</td></tr>
<tr><td><code id="barPlots_+3A_what">what</code></td>
<td>
<p>Can be &quot;mean&quot; (default) or &quot;median&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a barplot created with ggplot2
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
barPlots(dataset, result$Belongings)

## End(Not run)
</code></pre>

<hr>
<h2 id='belongsFCM'>membership matrix calculator for FCM algorithm</h2><span id='topic+belongsFCM'></span>

<h3>Description</h3>

<p>membership matrix calculator for FCM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>belongsFCM(data, centers, dots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="belongsFCM_+3A_data">data</code></td>
<td>
<p>a matrix (the dataset used for clustering)</p>
</td></tr>
<tr><td><code id="belongsFCM_+3A_centers">centers</code></td>
<td>
<p>a matrix (the centers of the clusters)</p>
</td></tr>
<tr><td><code id="belongsFCM_+3A_dots">dots</code></td>
<td>
<p>a list of other arguments specific to FCM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the new membership values
</p>

<hr>
<h2 id='belongsGFCM'>membership matrix calculator for GFCM algorithm</h2><span id='topic+belongsGFCM'></span>

<h3>Description</h3>

<p>membership matrix calculator for GFCM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>belongsGFCM(data, centers, dots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="belongsGFCM_+3A_data">data</code></td>
<td>
<p>a matrix (the dataset used for clustering)</p>
</td></tr>
<tr><td><code id="belongsGFCM_+3A_centers">centers</code></td>
<td>
<p>a matrix (the centers of the clusters)</p>
</td></tr>
<tr><td><code id="belongsGFCM_+3A_dots">dots</code></td>
<td>
<p>a list of other arguments specific to FCM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the new membership values
</p>

<hr>
<h2 id='belongsSFCM'>membership matrix calculator for SFCM algorithm</h2><span id='topic+belongsSFCM'></span>

<h3>Description</h3>

<p>membership matrix calculator for SFCM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>belongsSFCM(data, centers, dots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="belongsSFCM_+3A_data">data</code></td>
<td>
<p>a matrix (the dataset used for clustering)</p>
</td></tr>
<tr><td><code id="belongsSFCM_+3A_centers">centers</code></td>
<td>
<p>a matrix (the centers of the clusters)</p>
</td></tr>
<tr><td><code id="belongsSFCM_+3A_dots">dots</code></td>
<td>
<p>a list of other arguments specific to FCM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the new membership values
</p>

<hr>
<h2 id='belongsSGFCM'>membership matrix calculator for SGFCM algorithm</h2><span id='topic+belongsSGFCM'></span>

<h3>Description</h3>

<p>membership matrix calculator for SGFCM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>belongsSGFCM(data, centers, dots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="belongsSGFCM_+3A_data">data</code></td>
<td>
<p>a matrix (the dataset used for clustering)</p>
</td></tr>
<tr><td><code id="belongsSGFCM_+3A_centers">centers</code></td>
<td>
<p>a matrix (the centers of the clusters)</p>
</td></tr>
<tr><td><code id="belongsSGFCM_+3A_dots">dots</code></td>
<td>
<p>a list of other arguments specific to FCM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the new membership values
</p>

<hr>
<h2 id='boot_group_validation'>Check the robustness of a classification by Bootstrap</h2><span id='topic+boot_group_validation'></span>

<h3>Description</h3>

<p>Check that the obtained groups are stable by bootstrap
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot_group_validation(
  object,
  nsim = 1000,
  maxiter = 1000,
  tol = 0.01,
  init = "random",
  verbose = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot_group_validation_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans</p>
</td></tr>
<tr><td><code id="boot_group_validation_+3A_nsim">nsim</code></td>
<td>
<p>The number of replications to do for the bootstrap evaluation</p>
</td></tr>
<tr><td><code id="boot_group_validation_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iterations</p>
</td></tr>
<tr><td><code id="boot_group_validation_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="boot_group_validation_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centres must be selected.
&quot;random&quot; indicates that random observations are used as centres &quot;kpp&quot; use
a distance-based method resulting in more dispersed centres at the
beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="boot_group_validation_+3A_verbose">verbose</code></td>
<td>
<p>A boolean to specify if the progress bar should be displayed.</p>
</td></tr>
<tr><td><code id="boot_group_validation_+3A_seed">seed</code></td>
<td>
<p>An integer used for random number generation. It ensures that the
starting centres will be the same if the same value is selected.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Considering that the classification produced by a FCM like algorithm
depends on its initial state, it is important to check if the groups
obtained are stable. This function uses a bootstrap method to do so. During
a selected number of iterations (at least 1000), a sample of size n (with
replacement) is drawn from the original dataset. For each sample, the same
classification algorithm is applied and the results are compared with the
reference results. For each original group, the most similar group is
identified by calculating the Jaccard similarity index between the columns
of the two membership matrices. This index is comprised between 0 (exact
difference) and 1 (perfect similarity) and a value is calculated for each
group at each iteration. One can investigate the values obtained to
determine if the groups are stable. Values under 0.5 are a concern and
indicate that the group is dissolving. Values between 0.6 and 0.75 indicate
a pattern in the data, but a significant uncertainty. Values above 0.8
indicate strong groups. The values of the centres obtained at each
iteration are also returned, it is important to ensure that they approximately
follow a normal distribution (or are at least unimodal).
</p>


<h3>Value</h3>

<p>A list of two values: group_consistency: a dataframe indicating
the consistency across simulations each cluster ; group_centres: a list with
a dataframe for each cluster. The values in the dataframes are the centres
of the clusters at each simulation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LyonIris)

#selecting the columns for the analysis
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14",
                   "Pct_65","Pct_Img","TxChom1564","Pct_brevet","NivVieMed")

#rescaling the columns
Data &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
for (Col in names(Data)){
  Data[[Col]] &lt;- as.numeric(scale(Data[[Col]]))
}

Cmean &lt;- CMeans(Data,4,1.5,500,standardize = FALSE, seed = 456,
    tol = 0.00001, verbose = FALSE)

validation &lt;- boot_group_validation(Cmean, nsim = 1000, maxiter = 1000,
    tol = 0.01, init = "random")

## End(Not run)
</code></pre>

<hr>
<h2 id='boot_group_validation.mc'>Check that the obtained groups are stable by bootstrap (multicore)</h2><span id='topic+boot_group_validation.mc'></span>

<h3>Description</h3>

<p>Check that the obtained groups are stable by bootstrap with
multicore support
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot_group_validation.mc(
  object,
  nsim = 1000,
  maxiter = 1000,
  tol = 0.01,
  init = "random",
  verbose = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot_group_validation.mc_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans</p>
</td></tr>
<tr><td><code id="boot_group_validation.mc_+3A_nsim">nsim</code></td>
<td>
<p>The number of replications to do for the bootstrap evaluation</p>
</td></tr>
<tr><td><code id="boot_group_validation.mc_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iterations</p>
</td></tr>
<tr><td><code id="boot_group_validation.mc_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="boot_group_validation.mc_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centres must be selected.
&quot;random&quot; indicates that random observations are used as centres. &quot;kpp&quot; use
a distance based method resulting in more dispersed centres at the
beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="boot_group_validation.mc_+3A_verbose">verbose</code></td>
<td>
<p>A boolean to specify if the progress bar should be displayed.</p>
</td></tr>
<tr><td><code id="boot_group_validation.mc_+3A_seed">seed</code></td>
<td>
<p>An integer to control randomness, default is NULL</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details, see the documentation of the function
boot_group_validation
</p>


<h3>Value</h3>

<p>A list of two values: group_consistency: a dataframe indicating
the consistency across simulations each cluster ; group_centres: a list with
a dataframe for each cluster. The values in the dataframes are the centres
of the clusters at each simulation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LyonIris)

#selecting the columns for the analysis
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14",
                   "Pct_65","Pct_Img","TxChom1564","Pct_brevet","NivVieMed")

#rescaling the columns
Data &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
for (Col in names(Data)){
  Data[[Col]] &lt;- as.numeric(scale(Data[[Col]]))
}

Cmean &lt;- CMeans(Data,4,1.5,500,standardize = FALSE, seed = 456,
    tol = 0.00001, verbose = FALSE)

future::plan(future::multisession(workers=2))

validation &lt;- boot_group_validation.mc(Cmean, nsim = 1000, maxiter = 1000,
    tol = 0.01, init = "random")
## make sure any open connections are closed afterward
if (!inherits(future::plan(), "sequential")) future::plan(future::sequential)

## End(Not run)
</code></pre>

<hr>
<h2 id='boot_worker'>Worker function for cluster bootstrapping</h2><span id='topic+boot_worker'></span>

<h3>Description</h3>

<p>Worker function for cluster bootstrapping
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot_worker(object, wdata, tol, maxiter, init)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot_worker_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans, GCMeans, SFCMeans, SGFCMeans</p>
</td></tr>
<tr><td><code id="boot_worker_+3A_wdata">wdata</code></td>
<td>
<p>The lagged dataset if necessary, can be NULL if not required</p>
</td></tr>
<tr><td><code id="boot_worker_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="boot_worker_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iteration</p>
</td></tr>
<tr><td><code id="boot_worker_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centres must be selected. &quot;random&quot;
indicates that random observations are used as centres. &quot;kpp&quot; use a distance based method
resulting in more dispersed centres at the beginning. Both of them are heuristic.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The worker function for the functions boot_group_validation and boot_group_validation.mc
</p>


<h3>Value</h3>

<p>A list, similar to a FCMres object, but with only necessary slots for cluster bootstraping.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='calc_jaccard_idx'>Jaccard similarity coefficient</h2><span id='topic+calc_jaccard_idx'></span>

<h3>Description</h3>

<p>Calculate the Jaccard similarity coefficient
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_jaccard_idx(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_jaccard_idx_+3A_x">x</code></td>
<td>
<p>A vector of positive reals</p>
</td></tr>
<tr><td><code id="calc_jaccard_idx_+3A_y">y</code></td>
<td>
<p>A vector of positive reals</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A double: the Jaccard similarity coefficient
</p>

<hr>
<h2 id='calc_jaccard_mat'>Jaccard similarity coefficient between columns of two matrices</h2><span id='topic+calc_jaccard_mat'></span>

<h3>Description</h3>

<p>Calculate the Jaccard similarity coefficient between the
columns of two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_jaccard_mat(matX, matY)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_jaccard_mat_+3A_matx">matX</code></td>
<td>
<p>A matrix</p>
</td></tr>
<tr><td><code id="calc_jaccard_mat_+3A_maty">matY</code></td>
<td>
<p>A matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with the Jaccard index values
</p>

<hr>
<h2 id='calc_local_moran_raster'>Local Moran I for raster</h2><span id='topic+calc_local_moran_raster'></span>

<h3>Description</h3>

<p>Calculate the Local Moran I for a numeric raster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_local_moran_raster(rast, window)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_local_moran_raster_+3A_rast">rast</code></td>
<td>
<p>A SpatRaster or a matrix</p>
</td></tr>
<tr><td><code id="calc_local_moran_raster_+3A_window">window</code></td>
<td>
<p>The window defining the neighbour weights</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A SpatRaster or a matrix depending on the input with the local Moran I values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Arcachon &lt;- terra::rast(system.file("extdata/Littoral4_2154.tif", package = "geocmeans"))
names(Arcachon) &lt;- c("blue", "green", "red", "infrared", "SWIR1", "SWIR2")
rast &lt;- Arcachon[[1]]
w &lt;- matrix(1, nrow = 3, ncol = 3)
calc_local_moran_raster(rast, w)
</code></pre>

<hr>
<h2 id='calc_moran_raster'>Global Moran I for raster</h2><span id='topic+calc_moran_raster'></span>

<h3>Description</h3>

<p>Calculate the global Moran I for a numeric raster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_moran_raster(rast, window)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_moran_raster_+3A_rast">rast</code></td>
<td>
<p>A SpatRaster or a matrix</p>
</td></tr>
<tr><td><code id="calc_moran_raster_+3A_window">window</code></td>
<td>
<p>The window defining the neighbour weights</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A float: the global Moran I
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Arcachon &lt;- terra::rast(system.file("extdata/Littoral4_2154.tif", package = "geocmeans"))
names(Arcachon) &lt;- c("blue", "green", "red", "infrared", "SWIR1", "SWIR2")
rast &lt;- Arcachon[[1]]
w &lt;- matrix(1, nrow = 3, ncol = 3)
calc_moran_raster(rast, w)
</code></pre>

<hr>
<h2 id='calc_raster_spinconsistency'>calculate spatial inconsistency for raster</h2><span id='topic+calc_raster_spinconsistency'></span>

<h3>Description</h3>

<p>Calculate the spatial inconsistency sum for a set of rasters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_raster_spinconsistency(
  matrices,
  window,
  adj = FALSE,
  dataset = NULL,
  mindist = 1e-11
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_raster_spinconsistency_+3A_matrices">matrices</code></td>
<td>
<p>A list of matrices</p>
</td></tr>
<tr><td><code id="calc_raster_spinconsistency_+3A_window">window</code></td>
<td>
<p>The window to use to define spatial neighbouring</p>
</td></tr>
<tr><td><code id="calc_raster_spinconsistency_+3A_adj">adj</code></td>
<td>
<p>A boolean indicating if the adjusted version of the algorithm must be
calculated</p>
</td></tr>
<tr><td><code id="calc_raster_spinconsistency_+3A_dataset">dataset</code></td>
<td>
<p>A list of matrices with the original data (if adj = TRUE)</p>
</td></tr>
<tr><td><code id="calc_raster_spinconsistency_+3A_mindist">mindist</code></td>
<td>
<p>When adj is true, a minimum value for distance between two observations. If two
neighbours have exactly the same values, then the euclidean distance between
them is 0, leading to an infinite spatial weight. In that case, the minimum
distance is used instead of 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A float: the sum of spatial inconsistency
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='calcBelongMatrix'>Calculate the membership matrix</h2><span id='topic+calcBelongMatrix'></span>

<h3>Description</h3>

<p>Calculate the membership matrix according to a set of centroids, the observed
data and the fuzziness degree
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcBelongMatrix(centers, data, m, sigmas)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcBelongMatrix_+3A_centers">centers</code></td>
<td>
<p>A matrix or a dataframe representing the centers of the
clusters with p columns and k rows</p>
</td></tr>
<tr><td><code id="calcBelongMatrix_+3A_data">data</code></td>
<td>
<p>A dataframe or matrix representing the observed data with n rows
and p columns</p>
</td></tr>
<tr><td><code id="calcBelongMatrix_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcBelongMatrix_+3A_sigmas">sigmas</code></td>
<td>
<p>A numeric vector for calculating the robust version of the FCM. Filled with ones
if the classical version is required</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n * k matrix representing the probability of belonging of each
observation to each cluster
</p>

<hr>
<h2 id='calcBelongMatrixNoisy'>Calculate the membership matrix with a noise cluster</h2><span id='topic+calcBelongMatrixNoisy'></span>

<h3>Description</h3>

<p>Calculate the membership matrix according to a set of centroids, the observed
data and the fuzziness degree
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcBelongMatrixNoisy(centers, data, m, delta, sigmas)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcBelongMatrixNoisy_+3A_centers">centers</code></td>
<td>
<p>A matrix or a dataframe representing the centers of the
clusters with p columns and k rows</p>
</td></tr>
<tr><td><code id="calcBelongMatrixNoisy_+3A_data">data</code></td>
<td>
<p>A dataframe or matrix representing the observed data with n rows
and p columns</p>
</td></tr>
<tr><td><code id="calcBelongMatrixNoisy_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcBelongMatrixNoisy_+3A_delta">delta</code></td>
<td>
<p>A float, the value set for delta by the user</p>
</td></tr>
<tr><td><code id="calcBelongMatrixNoisy_+3A_sigmas">sigmas</code></td>
<td>
<p>A numeric vector for calculating the robust version of the FCM. Filled with ones
if the classical version is required</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n * k matrix representing the probability of belonging of each
observation to each cluster
</p>

<hr>
<h2 id='calcCalinskiHarabasz'>Calinski-Harabasz index</h2><span id='topic+calcCalinskiHarabasz'></span>

<h3>Description</h3>

<p>Calculate the Calinski-Harabasz index of clustering quality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcCalinskiHarabasz(data, belongmatrix, centers)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcCalinskiHarabasz_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the clustering (n*p)</p>
</td></tr>
<tr><td><code id="calcCalinskiHarabasz_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
<tr><td><code id="calcCalinskiHarabasz_+3A_centers">centers</code></td>
<td>
<p>The centres of the clusters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Calinski-Harabasz index (Da Silva et al. 2020) is the ratio between the clusters separation (between groups sum of squares) and the clusters cohesion (within groups sum of squares). A greater
value indicates either more separated clusters or more cohesive clusters.
</p>


<h3>Value</h3>

<p>A float: the Calinski-Harabasz index
</p>


<h3>References</h3>

<p>Da Silva LEB, Melton NM, Wunsch DC (2020).
&ldquo;Incremental cluster validity indices for online learning of hard partitions: Extensions and comparative study.&rdquo;
<em>IEEE Access</em>, <b>8</b>, 22025&ndash;22047.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcCalinskiHarabasz(result$Data, result$Belongings, result$Centers)
</code></pre>

<hr>
<h2 id='calcCentroids'>Calculate the centroids</h2><span id='topic+calcCentroids'></span>

<h3>Description</h3>

<p>Calculate the new centroids of the clusters based on the membership matrix
for a classical FCM.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcCentroids_+3A_data">data</code></td>
<td>
<p>A Numeric matrix representing the observed data with n rows
and p columns</p>
</td></tr>
<tr><td><code id="calcCentroids_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A n X k matrix giving for each observation n, its
probability to belong to the cluster k</p>
</td></tr>
<tr><td><code id="calcCentroids_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A a matrix with the centers calculated for each cluster
</p>

<hr>
<h2 id='calcDaviesBouldin'>Davies-Bouldin index</h2><span id='topic+calcDaviesBouldin'></span>

<h3>Description</h3>

<p>Calculate the Davies-Bouldin index of clustering quality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcDaviesBouldin(data, belongmatrix, centers)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcDaviesBouldin_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the clustering (n*p)</p>
</td></tr>
<tr><td><code id="calcDaviesBouldin_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
<tr><td><code id="calcDaviesBouldin_+3A_centers">centers</code></td>
<td>
<p>The centres of the clusters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Davies-Bouldin index (Da Silva et al. 2020) can be seen as the ratio of the within cluster dispersion and the
between cluster separation. A lower value indicates a higher cluster compacity
or a higher cluster separation. The formula is:
</p>
<p style="text-align: center;"><code class="reqn">DB = \frac{1}{k}\sum_{i=1}^k{R_{i}}</code>
</p>

<p>with:
</p>
<p style="text-align: center;"><code class="reqn">R_{i} =\max_{i \neq j}\left(\frac{S_{i}+S_{j}}{M_{i, j}}\right)</code>
</p>

<p style="text-align: center;"><code class="reqn">S_{l} =\left[\frac{1}{n_{l}} \sum_{l=1}^{n}\left\|\boldsymbol{x_{l}}-\boldsymbol{c_{i}}\right\|*u_{i}\right]^{\frac{1}{2}}</code>
</p>

<p style="text-align: center;"><code class="reqn">M_{i, j} =\sum\left\|\boldsymbol{c}_{i}-\boldsymbol{c}_{j}\right\|</code>
</p>

<p>So, the value of the index is an average of <code class="reqn">R_{i}</code> values. For each cluster, they represent
its worst comparison with all the other clusters, calculated
as the ratio between the compactness of the two clusters and the separation
of the two clusters.
</p>


<h3>Value</h3>

<p>A float: the Davies-Bouldin index
</p>


<h3>References</h3>

<p>Da Silva LEB, Melton NM, Wunsch DC (2020).
&ldquo;Incremental cluster validity indices for online learning of hard partitions: Extensions and comparative study.&rdquo;
<em>IEEE Access</em>, <b>8</b>, 22025&ndash;22047.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcDaviesBouldin(result$Data, result$Belongings, result$Centers)
</code></pre>

<hr>
<h2 id='calcELSA'>calculate ELSA statistic for a hard partition</h2><span id='topic+calcELSA'></span>

<h3>Description</h3>

<p>Calculate ELSA statistic for a hard partition. This local indicator of
spatial autocorrelation can be used to determine where observations belong to different
clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcELSA(object, nblistw = NULL, window = NULL, matdist = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcELSA_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans. Can also be a vector of categories. This vector must
be filled with integers starting from 1. -1 can be used to indicate missing categories.</p>
</td></tr>
<tr><td><code id="calcELSA_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input.</p>
</td></tr>
<tr><td><code id="calcELSA_+3A_window">window</code></td>
<td>
<p>A binary (0,1) matrix representing the neighbours spatial weights when working
with rasters. The matrix must have odd dimensions.</p>
</td></tr>
<tr><td><code id="calcELSA_+3A_matdist">matdist</code></td>
<td>
<p>A matrix representing the dissimilarity between the clusters. The matrix must
be squared and the diagonal must be filled with zeros.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ELSA index (Naimi et al. 2019) can be used to measure
local autocorrelation for a categorical variable. It varies between 0 and 1, 0 indicating
a perfect positive spatial autocorrelation and 1 a perfect heterogeneity. It is based on
the Shanon entropy index, and uses a measure of difference between categories. Thus it
can reflect that proximity of two similar categories is still a form of positive
autocorelation. The authors suggest to calculate the mean of the index at several lag
distance to create an entrogram which quantifies global spatial structure and can be
represented as a variogram-like graph.
</p>


<h3>Value</h3>

<p>A depending of the input, a vector of ELSA values or a raster with the ELSA values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
elsa_valus &lt;- calcELSA(result)
</code></pre>

<hr>
<h2 id='calcEuclideanDistance'>Calculate the Euclidean distance</h2><span id='topic+calcEuclideanDistance'></span>

<h3>Description</h3>

<p>Calculate the euclidean distance between a numeric matrix n * p and a numeric
vector of length p
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcEuclideanDistance(m, v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcEuclideanDistance_+3A_m">m</code></td>
<td>
<p>A n * p matrix or dataframe with only numeric columns</p>
</td></tr>
<tr><td><code id="calcEuclideanDistance_+3A_v">v</code></td>
<td>
<p>A numeric vector of length p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length n giving the euclidean distance between all matrix
row and the vector p
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This is an internal function, no example provided
</code></pre>

<hr>
<h2 id='calcEuclideanDistance2'>euclidean distance between rows of a matrix and a vector</h2><span id='topic+calcEuclideanDistance2'></span>

<h3>Description</h3>

<p>euclidean distance between rows of a matrix and a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcEuclideanDistance2(y, x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcEuclideanDistance2_+3A_y">y</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="calcEuclideanDistance2_+3A_x">x</code></td>
<td>
<p>a vector (same length as ncol(matrix))</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector (same length as nrow(matrix))
</p>

<hr>
<h2 id='calcEuclideanDistance3'>euclidean distance between rows of a matrix and a vector (arma mode)</h2><span id='topic+calcEuclideanDistance3'></span>

<h3>Description</h3>

<p>euclidean distance between rows of a matrix and a vector (arma mode)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcEuclideanDistance3(y, x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcEuclideanDistance3_+3A_y">y</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="calcEuclideanDistance3_+3A_x">x</code></td>
<td>
<p>a vector (same length as ncol(matrix))</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector (same length as nrow(matrix))
</p>

<hr>
<h2 id='calcexplainedInertia'>Explained inertia index</h2><span id='topic+calcexplainedInertia'></span>

<h3>Description</h3>

<p>Calculate the explained inertia by a classification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcexplainedInertia(data, belongmatrix)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcexplainedInertia_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the classification (n*p)</p>
</td></tr>
<tr><td><code id="calcexplainedInertia_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A float: the percentage of the total inertia explained
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcexplainedInertia(result$Data,result$Belongings)
</code></pre>

<hr>
<h2 id='calcFGCMBelongMatrix'>Calculate the generalized membership matrix</h2><span id='topic+calcFGCMBelongMatrix'></span>

<h3>Description</h3>

<p>Calculate the generalized membership matrix according to a set of
centroids, the observed data, the fuzziness degree, and a beta parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcFGCMBelongMatrix(centers, data, m, beta, sigmas)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcFGCMBelongMatrix_+3A_centers">centers</code></td>
<td>
<p>A matrix representing the centers of the
clusters with p columns and k rows</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrix_+3A_data">data</code></td>
<td>
<p>A matrix representing the observed data with n rows
and p columns</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrix_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrix_+3A_beta">beta</code></td>
<td>
<p>A float for the beta parameter (control speed convergence and classification crispness)</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrix_+3A_sigmas">sigmas</code></td>
<td>
<p>A numeric vector for calculating the robust version of the FCM. Filled with ones
if the classical version is required</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n * k matrix representing the belonging probabilities of each
observation to each cluster
</p>

<hr>
<h2 id='calcFGCMBelongMatrixNoisy'>Calculate the generalized membership matrix with a noise cluster</h2><span id='topic+calcFGCMBelongMatrixNoisy'></span>

<h3>Description</h3>

<p>Calculate the generalized membership matrix according to a set of
centroids, the observed data, the fuzziness degree, and a beta parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcFGCMBelongMatrixNoisy(centers, data, m, beta, delta, sigmas)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcFGCMBelongMatrixNoisy_+3A_centers">centers</code></td>
<td>
<p>A matrix representing the centers of the
clusters with p columns and k rows</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrixNoisy_+3A_data">data</code></td>
<td>
<p>A matrix representing the observed data with n rows
and p columns</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrixNoisy_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrixNoisy_+3A_beta">beta</code></td>
<td>
<p>A float for the beta parameter (control speed convergence and classification crispness)</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrixNoisy_+3A_delta">delta</code></td>
<td>
<p>A float, the value set for delta by the user</p>
</td></tr>
<tr><td><code id="calcFGCMBelongMatrixNoisy_+3A_sigmas">sigmas</code></td>
<td>
<p>A numeric vector for calculating the robust version of the FCM. Filled with ones
if the classical version is required</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n * k matrix representing the belonging probabilities of each
observation to each cluster
</p>

<hr>
<h2 id='calcFukuyamaSugeno'>Fukuyama and Sugeno index</h2><span id='topic+calcFukuyamaSugeno'></span>

<h3>Description</h3>

<p>Calculate Fukuyama and Sugeno index of clustering quality
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcFukuyamaSugeno(data, belongmatrix, centers, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcFukuyamaSugeno_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the clustering (n*p)</p>
</td></tr>
<tr><td><code id="calcFukuyamaSugeno_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
<tr><td><code id="calcFukuyamaSugeno_+3A_centers">centers</code></td>
<td>
<p>The centres of the clusters</p>
</td></tr>
<tr><td><code id="calcFukuyamaSugeno_+3A_m">m</code></td>
<td>
<p>The fuzziness parameter</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Fukuyama and Sugeno index (Fukuyama 1989) is the difference between the compacity of clusters and the separation of clusters. A smaller value indicates a better clustering.
The formula is:
</p>
<p style="text-align: center;"><code class="reqn">S(c)=\sum_{k=1}^{n} \sum_{i=1}^{c}\left(U_{i k}\right)^{m}\left(\left\|x_{k}-v_{i}\right\|^{2}-\left\|v_{i}-\bar{x}\right\|^{2}\right) 2</code>
</p>

<p>with <em>n</em> the number of observations, <em>k</em> the number of clusters and <code class="reqn">\bar{x}</code> the mean of the dataset.
</p>


<h3>Value</h3>

<p>A float: the Fukuyama and Sugeno index
</p>


<h3>References</h3>

<p>Fukuyama Y (1989).
&ldquo;A new method of choosing the number of clusters for the fuzzy c-mean method.&rdquo;
In <em>Proc. 5th Fuzzy Syst. Symp., 1989</em>, 247&ndash;250.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcFukuyamaSugeno(result$Data,result$Belongings, result$Centers, 1.5)
</code></pre>

<hr>
<h2 id='calcFuzzyELSA'>calculate ELSA statistic for a fuzzy partition</h2><span id='topic+calcFuzzyELSA'></span>

<h3>Description</h3>

<p>Calculate ELSA statistic for a fuzzy partition. This local indicator of
spatial autocorrelation can be used to identify areas where close observations tend to
belong to different clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcFuzzyELSA(object, nblistw = NULL, window = NULL, matdist = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcFuzzyELSA_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans. Can also be a membership matrix. Each row of this matrix
must sum up to 1. Can also be a list of rasters, in which case each raster must represent
the membership values for one cluster and the sum of all the rasters must be a raster filled
with ones.</p>
</td></tr>
<tr><td><code id="calcFuzzyELSA_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input.</p>
</td></tr>
<tr><td><code id="calcFuzzyELSA_+3A_window">window</code></td>
<td>
<p>A binary (0,1) matrix representing the neighbours spatial weights when working
with rasters. The matrix must have odd dimensions.</p>
</td></tr>
<tr><td><code id="calcFuzzyELSA_+3A_matdist">matdist</code></td>
<td>
<p>A matrix representing the dissimilarity between the clusters. The matrix must
be squared and the diagonal must be filled with zeros.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fuzzy ELSA index is a generalization of the ELSA index (Naimi et al. 2019). It can be used to measure
local autocorrelation for a membership matrix. It varies between 0 and 1, 0 indicating
a perfect positive spatial autocorrelation and 1 a perfect heterogeneity. It is based on
the Shannon entropy index, and uses a measure of dissimilarity between categories.
</p>


<h3>Value</h3>

<p>either a vector or a raster with the ELSA values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
elsa_valus &lt;- calcFuzzyELSA(result)
</code></pre>

<hr>
<h2 id='calcFuzzyElsa_raster'>Local Fuzzy ELSA statistic for raster</h2><span id='topic+calcFuzzyElsa_raster'></span>

<h3>Description</h3>

<p>Calculate the Local Fuzzy ELSA statistic for a numeric raster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcFuzzyElsa_raster(rasters, window, matdist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcFuzzyElsa_raster_+3A_rasters">rasters</code></td>
<td>
<p>A List of SpatRaster or a List of matrices, or an array</p>
</td></tr>
<tr><td><code id="calcFuzzyElsa_raster_+3A_window">window</code></td>
<td>
<p>A binary (0,1) matrix representing the neighbours spatial weights when working
with rasters. The matrix must have odd dimensions.</p>
</td></tr>
<tr><td><code id="calcFuzzyElsa_raster_+3A_matdist">matdist</code></td>
<td>
<p>A matrix representing the dissimilarity between the clusters. The matrix must
be squared and the diagonal must be filled with zeros.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A raster or a matrix (depending on the input): the values of
local fuzzy ELSA statistic
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='calcGD43'>Generalized Dunn’s index (43)</h2><span id='topic+calcGD43'></span>

<h3>Description</h3>

<p>Calculate the Generalized Dunn’s index (v43) of clustering quality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcGD43(data, belongmatrix, centers)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcGD43_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the clustering (n*p)</p>
</td></tr>
<tr><td><code id="calcGD43_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
<tr><td><code id="calcGD43_+3A_centers">centers</code></td>
<td>
<p>The centres of the clusters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Generalized Dunn’s index  (Da Silva et al. 2020) is a
ratio of the worst pair-wise separation of clusters and the worst compactness
of clusters. A higher value indicates a better clustering. The formula
is:
</p>
<p style="text-align: center;"><code class="reqn">GD_{r s}=\frac{\min_{i \neq j}\left[\delta_{r}\left(\omega_{i}, \omega_{j}\right)\right]}{\max_{k}\left[\Delta_{s}\left(\omega_{k}\right)\right]}</code>
</p>

<p>The numerator is a measure of the minimal separation between all the clusters
<em>i</em> and <em>j</em> given by the formula:
</p>
<p style="text-align: center;"><code class="reqn">\delta_{r}\left(\omega_{i}, \omega_{j}\right)=\left\|\boldsymbol{c}_{i}-\boldsymbol{c}_{j}\right\|</code>
</p>

<p>which is basically the Euclidean distance between the centres of clusters <code class="reqn">c_{i}</code> and <code class="reqn">c_{j}</code>
</p>
<p>The denominator is a measure of the maximal dispersion of all clusters, given
by the formula:
</p>
<p style="text-align: center;"><code class="reqn">\frac{2*\sum_{l=1}^{n}\left\|\boldsymbol{x}_{l}-\boldsymbol{c_{i}}\right\|^{\frac{1}{2}}}{\sum{u_{i}}}</code>
</p>



<h3>Value</h3>

<p>A float: the  Generalized Dunn’s index (43)
</p>


<h3>References</h3>

<p>Da Silva LEB, Melton NM, Wunsch DC (2020).
&ldquo;Incremental cluster validity indices for online learning of hard partitions: Extensions and comparative study.&rdquo;
<em>IEEE Access</em>, <b>8</b>, 22025&ndash;22047.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcGD43(result$Data, result$Belongings, result$Centers)
</code></pre>

<hr>
<h2 id='calcGD53'>Generalized Dunn’s index (53)</h2><span id='topic+calcGD53'></span>

<h3>Description</h3>

<p>Calculate the Generalized Dunn’s index (v53) of clustering quality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcGD53(data, belongmatrix, centers)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcGD53_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the clustering (n*p)</p>
</td></tr>
<tr><td><code id="calcGD53_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
<tr><td><code id="calcGD53_+3A_centers">centers</code></td>
<td>
<p>The centres of the clusters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Generalized Dunn’s index  (Da Silva et al. 2020) is a
ratio of the worst pair-wise separation of clusters and the worst compactness
of clusters. A higher value indicates a better clustering. The formula
is:
</p>
<p style="text-align: center;"><code class="reqn">GD_{r s}=\frac{\min_{i \neq j}\left[\delta_{r}\left(\omega_{i}, \omega_{j}\right)\right]}{\max_{k}\left[\Delta_{s}\left(\omega_{k}\right)\right]}</code>
</p>

<p>The numerator is a measure of the minimal separation between all the clusters
<em>i</em> and <em>j</em> given by the formula:
</p>
<p style="text-align: center;"><code class="reqn">\delta_{r}\left(\omega_{i}, \omega_{j}\right)=\frac{\sum_{l=1}^{n}\left\|\boldsymbol{x_{l}}-\boldsymbol{c_{i}}\right\|^{\frac{1}{2}} . u_{il}+\sum_{l=1}^{n}\left\|\boldsymbol{x_{l}}-\boldsymbol{c_{j}}\right\|^{\frac{1}{2}} . u_{jl}}{\sum{u_{i}} + \sum{u_{j}}}</code>
</p>

<p>where <em>u</em> is the membership matrix and <code class="reqn">u_{i}</code> is the column of
<em>u</em> describing the membership of the <em>n</em> observations to cluster
<em>i</em>. <code class="reqn">c_{i}</code> is the center of the cluster <em>i</em>.
</p>
<p>The denominator is a measure of the maximal dispersion of all clusters, given
by the formula:
</p>
<p style="text-align: center;"><code class="reqn">\frac{2*\sum_{l=1}^{n}\left\|\boldsymbol{x}_{l}-\boldsymbol{c_{i}}\right\|^{\frac{1}{2}}}{\sum{u_{i}}}</code>
</p>



<h3>Value</h3>

<p>A float: the  Generalized Dunn’s index (53)
</p>


<h3>References</h3>

<p>Da Silva LEB, Melton NM, Wunsch DC (2020).
&ldquo;Incremental cluster validity indices for online learning of hard partitions: Extensions and comparative study.&rdquo;
<em>IEEE Access</em>, <b>8</b>, 22025&ndash;22047.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcGD53(result$Data, result$Belongings, result$Centers)
</code></pre>

<hr>
<h2 id='calcLaggedData'>Lagged Data</h2><span id='topic+calcLaggedData'></span>

<h3>Description</h3>

<p>Calculate Wx, the spatially lagged version of x, by a neighbouring matrix W.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcLaggedData(x, nblistw, method = "mean")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcLaggedData_+3A_x">x</code></td>
<td>
<p>A dataframe with only numeric columns</p>
</td></tr>
<tr><td><code id="calcLaggedData_+3A_nblistw">nblistw</code></td>
<td>
<p>The listw object (spdep like) used to calculate WY</p>
</td></tr>
<tr><td><code id="calcLaggedData_+3A_method">method</code></td>
<td>
<p>A string indicating if a classical lag must be used
(&quot;mean&quot;) or if a weighted median must be used (&quot;median&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A lagged version of x
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This is an internal function, no example provided
</code></pre>

<hr>
<h2 id='calcNegentropyI'>Negentropy Increment index</h2><span id='topic+calcNegentropyI'></span>

<h3>Description</h3>

<p>Calculate the Negentropy Increment index of clustering quality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcNegentropyI(data, belongmatrix, centers)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcNegentropyI_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the clustering (n*p)</p>
</td></tr>
<tr><td><code id="calcNegentropyI_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
<tr><td><code id="calcNegentropyI_+3A_centers">centers</code></td>
<td>
<p>The centres of the clusters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Negentropy Increment index (Da Silva et al. 2020) is based on the assumption that a normally shaped cluster is more
desirable. It uses the difference between the average negentropy
of all the clusters in the partition, and that of the  whole partition.
A smaller value indicates a better partition. The formula is:
</p>
<p style="text-align: center;"><code class="reqn">NI=\frac{1}{2} \sum_{j=1}^{k} p_{i} \ln \left|{\boldsymbol{\Sigma}}_{j}\right|-\frac{1}{2} \ln \left|\boldsymbol{\Sigma}_{d a t a}\right|-\sum_{j=1}^{k} p_{j} \ln p_{j}</code>
</p>

<p>with  a cluster, <em>|.|</em> the determinant of a matrix,
</p>

<ul>
<li> <p><em>j</em> a cluster
</p>
</li>
<li> <p><em>|.|</em> the determinant of a matrix
</p>
</li>
<li> <p><code class="reqn">\left|{\boldsymbol{\Sigma}}_{j}\right|</code> the covariance matrix of the dataset weighted by the membership values to cluster <em>j</em>
</p>
</li>
<li> <p><code class="reqn">\left|\boldsymbol{\Sigma}_{d a t a}\right|</code> the covariance matrix of the dataset
</p>
</li>
<li> <p><code class="reqn">p_{j}</code> the sum of the membership values to cluster <em>j</em> divided by the number of observations.
</p>
</li></ul>



<h3>Value</h3>

<p>A float: the Negentropy Increment index
</p>


<h3>References</h3>

<p>Da Silva LEB, Melton NM, Wunsch DC (2020).
&ldquo;Incremental cluster validity indices for online learning of hard partitions: Extensions and comparative study.&rdquo;
<em>IEEE Access</em>, <b>8</b>, 22025&ndash;22047.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcNegentropyI(result$Data, result$Belongings, result$Centers)
</code></pre>

<hr>
<h2 id='calcQualIdx'>calculate the quality index required</h2><span id='topic+calcQualIdx'></span>

<h3>Description</h3>

<p>A selector function to get the right quality index
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcQualIdx(name, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcQualIdx_+3A_name">name</code></td>
<td>
<p>The name of the index to calculate</p>
</td></tr>
<tr><td><code id="calcQualIdx_+3A_...">...</code></td>
<td>
<p>The parameters needed to calculate the index</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A float: the value of the index
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='calcqualityIndexes'>Quality indexes</h2><span id='topic+calcqualityIndexes'></span>

<h3>Description</h3>

<p>calculate several clustering quality indexes (some of them come from fclust
package)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcqualityIndexes(
  data,
  belongmatrix,
  m,
  indices = c("Silhouette.index", "Partition.entropy", "Partition.coeff",
    "XieBeni.index", "FukuyamaSugeno.index", "Explained.inertia")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcqualityIndexes_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the classification (n*p)</p>
</td></tr>
<tr><td><code id="calcqualityIndexes_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
<tr><td><code id="calcqualityIndexes_+3A_m">m</code></td>
<td>
<p>The fuzziness parameter used for the classification</p>
</td></tr>
<tr><td><code id="calcqualityIndexes_+3A_indices">indices</code></td>
<td>
<p>A character vector with the names of the indices to calculate, default is :
c(&quot;Silhouette.index&quot;, &quot;Partition.entropy&quot;, &quot;Partition.coeff&quot;, &quot;XieBeni.index&quot;, &quot;FukuyamaSugeno.index&quot;,
&quot;Explained.inertia&quot;). Other available indices are : &quot;DaviesBoulin.index&quot;, &quot;CalinskiHarabasz.index&quot;,
&quot;GD43.index&quot;, &quot;GD53.index&quot; and &quot;Negentropy.index&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list with with the values of the required indices
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcqualityIndexes(result$Data,result$Belongings, m=1.5)
</code></pre>

<hr>
<h2 id='calcRobustSigmas'>Calculate sigmas for the robust version of the c-means algorithm</h2><span id='topic+calcRobustSigmas'></span>

<h3>Description</h3>

<p>Calculate sigmas for the robust version of the c-means algorithm
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcRobustSigmas_+3A_data">data</code></td>
<td>
<p>A Numeric matrix representing the observed data with n rows
and p columns</p>
</td></tr>
<tr><td><code id="calcRobustSigmas_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A n X k matrix giving for each observation n, its
probability to belong to the cluster k</p>
</td></tr>
<tr><td><code id="calcRobustSigmas_+3A_centers">centers</code></td>
<td>
<p>A c X k matrix giving for each cluster c, its center in k dimensions</p>
</td></tr>
<tr><td><code id="calcRobustSigmas_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the sigmas for each cluster
</p>

<hr>
<h2 id='calcSFCMBelongMatrix'>Calculate the membership matrix (spatial version)</h2><span id='topic+calcSFCMBelongMatrix'></span>

<h3>Description</h3>

<p>Calculate the membership matrix (spatial version) according to a set of
centroids, the observed data, the fuzziness degree a neighbouring matrix and
a spatial weighting term
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcSFCMBelongMatrix(centers, data, wdata, m, alpha, sigmas, wsigmas)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcSFCMBelongMatrix_+3A_centers">centers</code></td>
<td>
<p>A matrix or a dataframe representing the centers of the
clusters with p columns and k rows</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrix_+3A_data">data</code></td>
<td>
<p>A matrix representing the observed data with n rows and p columns</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrix_+3A_wdata">wdata</code></td>
<td>
<p>A matrix representing the lagged observed data with n rows and p columns</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrix_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrix_+3A_alpha">alpha</code></td>
<td>
<p>A float representing the weight of the space in the analysis (0
is a typical fuzzy-c-mean algorithm, 1 is balanced between the two
dimensions, 2 is twice the weight for space)</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrix_+3A_sigmas">sigmas</code></td>
<td>
<p>A numeric vector for calculating the robust version of the FCM. Filled with ones
if the classical version is required</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrix_+3A_wsigmas">wsigmas</code></td>
<td>
<p>Same as sigmas, but calculated on the spatially lagged dataset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n * k matrix representing the belonging probabilities of each
observation to each cluster
</p>

<hr>
<h2 id='calcSFCMBelongMatrixNoisy'>Calculate the membership matrix (spatial version) with a noise cluster</h2><span id='topic+calcSFCMBelongMatrixNoisy'></span>

<h3>Description</h3>

<p>Calculate the membership matrix (spatial version) according to a set of
centroids, the observed data, the fuzziness degree a neighbouring matrix and
a spatial weighting term
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcSFCMBelongMatrixNoisy(
  centers,
  data,
  wdata,
  m,
  alpha,
  delta,
  sigmas,
  wsigmas
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcSFCMBelongMatrixNoisy_+3A_centers">centers</code></td>
<td>
<p>A matrix or a dataframe representing the centers of the
clusters with p columns and k rows</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrixNoisy_+3A_data">data</code></td>
<td>
<p>A matrix representing the observed data with n rows and p columns</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrixNoisy_+3A_wdata">wdata</code></td>
<td>
<p>A matrix representing the lagged observed data with n rows and p columns</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrixNoisy_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrixNoisy_+3A_alpha">alpha</code></td>
<td>
<p>A float representing the weight of the space in the analysis (0
is a typical fuzzy-c-mean algorithm, 1 is balanced between the two
dimensions, 2 is twice the weight for space)</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrixNoisy_+3A_delta">delta</code></td>
<td>
<p>A float, the value set for delta by the user</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrixNoisy_+3A_sigmas">sigmas</code></td>
<td>
<p>A numeric vector for calculating the robust version of the FCM. Filled with ones
if the classical version is required</p>
</td></tr>
<tr><td><code id="calcSFCMBelongMatrixNoisy_+3A_wsigmas">wsigmas</code></td>
<td>
<p>Same as sigmas, but calculated on the spatially lagged dataset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n * k matrix representing the belonging probabilities of each
observation to each cluster
</p>

<hr>
<h2 id='calcSFGCMBelongMatrix'>Calculate the generalized membership matrix (spatial version)</h2><span id='topic+calcSFGCMBelongMatrix'></span>

<h3>Description</h3>

<p>Calculate the generalized membership matrix (spatial version)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcSFGCMBelongMatrix(centers, data, wdata, m, alpha, beta, sigmas, wsigmas)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcSFGCMBelongMatrix_+3A_centers">centers</code></td>
<td>
<p>A matrix representing the centers of the clusters with p
columns and k rows</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrix_+3A_data">data</code></td>
<td>
<p>A matrix representing the observed data with n rows and p columns</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrix_+3A_wdata">wdata</code></td>
<td>
<p>A matrix representing the lagged observed data with n rows
and p columns</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrix_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrix_+3A_alpha">alpha</code></td>
<td>
<p>A float representing the weight of the space in the analysis (0
is a typical fuzzy-c-mean algorithm, 1 is balanced between the two
dimensions, 2 is twice the weight for space)</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrix_+3A_beta">beta</code></td>
<td>
<p>A float for the beta parameter (control speed convergence and classification crispness)</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrix_+3A_sigmas">sigmas</code></td>
<td>
<p>A numeric vector for calculating the robust version of the FCM. Filled with ones
if the classical version is required</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrix_+3A_wsigmas">wsigmas</code></td>
<td>
<p>Same as sigmas, but calculated on the spatially lagged dataset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n * k matrix representing the belonging probabilities of each
observation to each cluster
</p>

<hr>
<h2 id='calcSFGCMBelongMatrixNoisy'>Calculate the generalized membership matrix (spatial version) with a noise cluster</h2><span id='topic+calcSFGCMBelongMatrixNoisy'></span>

<h3>Description</h3>

<p>Calculate the generalized membership matrix (spatial version) with a noise cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcSFGCMBelongMatrixNoisy(
  centers,
  data,
  wdata,
  m,
  alpha,
  beta,
  delta,
  sigmas,
  wsigmas
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_centers">centers</code></td>
<td>
<p>A matrix representing the centers of the clusters with p
columns and k rows</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_data">data</code></td>
<td>
<p>A matrix representing the observed data with n rows and p columns</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_wdata">wdata</code></td>
<td>
<p>A matrix representing the lagged observed data with n rows
and p columns</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_m">m</code></td>
<td>
<p>A float representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_alpha">alpha</code></td>
<td>
<p>A float representing the weight of the space in the analysis (0
is a typical fuzzy-c-mean algorithm, 1 is balanced between the two
dimensions, 2 is twice the weight for space)</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_beta">beta</code></td>
<td>
<p>A float for the beta parameter (control speed convergence and classification crispness)</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_delta">delta</code></td>
<td>
<p>A float, the value set for delta by the user</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_sigmas">sigmas</code></td>
<td>
<p>A numeric vector for calculating the robust version of the FCM. Filled with ones
if the classical version is required</p>
</td></tr>
<tr><td><code id="calcSFGCMBelongMatrixNoisy_+3A_wsigmas">wsigmas</code></td>
<td>
<p>Same as sigmas, but calculated on the spatially lagged dataset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n * k matrix representing the belonging probabilities of each
observation to each cluster
</p>

<hr>
<h2 id='calcSilhouetteIdx'>Fuzzy Silhouette index</h2><span id='topic+calcSilhouetteIdx'></span>

<h3>Description</h3>

<p>Calculate the Silhouette index of clustering quality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcSilhouetteIdx(data, belongings)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcSilhouetteIdx_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the clustering (n*p)</p>
</td></tr>
<tr><td><code id="calcSilhouetteIdx_+3A_belongings">belongings</code></td>
<td>
<p>A membership matrix (n*k)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The index is calculated with the function SIL.F from the package fclust.
When the dataset is too large, an approach by subsampling is used to avoid
crash.
</p>


<h3>Value</h3>

<p>A float, the fuzzy Silhouette index
</p>

<hr>
<h2 id='calcSWFCCentroids'>Calculate the centroids of SFCM</h2><span id='topic+calcSWFCCentroids'></span>

<h3>Description</h3>

<p>Calculate the new centroids of the clusters based on the membership matrix for SFCM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcSWFCCentroids(data, wdata, belongmatrix, m, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcSWFCCentroids_+3A_data">data</code></td>
<td>
<p>A matrix representing the observed data with n rows and p columns</p>
</td></tr>
<tr><td><code id="calcSWFCCentroids_+3A_wdata">wdata</code></td>
<td>
<p>A matrix representing the lagged observed data with nrows and p columns</p>
</td></tr>
<tr><td><code id="calcSWFCCentroids_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A n X k matrix giving for each observation n, its
probability to belong to the cluster k</p>
</td></tr>
<tr><td><code id="calcSWFCCentroids_+3A_m">m</code></td>
<td>
<p>An integer representing the fuzziness degree</p>
</td></tr>
<tr><td><code id="calcSWFCCentroids_+3A_alpha">alpha</code></td>
<td>
<p>A float representing the weight of the space in the analysis (0
is a typical fuzzy-c-mean algorithm, 1 is balanced between the two
dimensions, 2 is twice the weight for space)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n X k matrix representing the belonging probabilities of each
observation to each cluster
</p>

<hr>
<h2 id='calcUncertaintyIndex'>Diversity index</h2><span id='topic+calcUncertaintyIndex'></span>

<h3>Description</h3>

<p>Calculate the diversity (or entropy) index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcUncertaintyIndex(belongmatrix)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcUncertaintyIndex_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The diversity (or entropy) index (Theil 1972)
is calculated for each observation an varies between 0 and 1. When the value
is close to 0, the observation belong to only one cluster (as in hard
clustering). When the value is close to 1, the observation is undecided and
tends to belong to each cluster. Values above 0.9 should be investigated. The
formula is:
</p>
<p style="text-align: center;"><code class="reqn">H2_{i} = \frac{-\sum[u_{ij}\ln(u_{ij})]}{\ln(k)}</code>
</p>

<p>with <em>i</em> and observation, <em>j</em> a cluster, <em>k</em> the number of clusters and
<em>u</em> the membership matrix.
</p>
<p>It is a simplified formula because the sum of each row of a membership matrix
is 1.
</p>


<h3>Value</h3>

<p>A vector with the values of the diversity (entropy) index
</p>


<h3>References</h3>

<p>Theil H (1972).
<em>Statistical decomposition analysis; with applications in the social and administrative sciences</em>.
North-Holland.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
calcUncertaintyIndex(result$Belongings)
</code></pre>

<hr>
<h2 id='calcWdataRaster'>Calculate lagged values for a raster dataset</h2><span id='topic+calcWdataRaster'></span>

<h3>Description</h3>

<p>Calculate lagged values for a raster dataset given a window
and an agregation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcWdataRaster(w, dataset, fun, missing_pxl)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcWdataRaster_+3A_w">w</code></td>
<td>
<p>A matrix</p>
</td></tr>
<tr><td><code id="calcWdataRaster_+3A_dataset">dataset</code></td>
<td>
<p>A list of rasters</p>
</td></tr>
<tr><td><code id="calcWdataRaster_+3A_fun">fun</code></td>
<td>
<p>A string giving the name of a function or a function or &quot;nl&quot;
for non-local method</p>
</td></tr>
<tr><td><code id="calcWdataRaster_+3A_missing_pxl">missing_pxl</code></td>
<td>
<p>A boolean vector of missing (FALSE) pixels</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='cat_to_belongings'>Convert categories to membership matrix</h2><span id='topic+cat_to_belongings'></span><span id='topic+catToBelongings'></span>

<h3>Description</h3>

<p>Function to convert a character vector to a membership matrix (binary matrix).
The columns of the matrix are ordered with the order function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cat_to_belongings(categories)

catToBelongings(categories)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cat_to_belongings_+3A_categories">categories</code></td>
<td>
<p>A vector with the categories of each observation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A binary matrix
</p>

<hr>
<h2 id='centersFCM'>center matrix calculator for FCM algorithm</h2><span id='topic+centersFCM'></span>

<h3>Description</h3>

<p>center matrix calculator for FCM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centersFCM(data, centers, belongmatrix, dots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="centersFCM_+3A_data">data</code></td>
<td>
<p>a matrix (the dataset used for clustering)</p>
</td></tr>
<tr><td><code id="centersFCM_+3A_centers">centers</code></td>
<td>
<p>a matrix (the centers of the clusters)</p>
</td></tr>
<tr><td><code id="centersFCM_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>a matrix with the membership values</p>
</td></tr>
<tr><td><code id="centersFCM_+3A_dots">dots</code></td>
<td>
<p>a list of other arguments specific to FCM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the new centers
</p>

<hr>
<h2 id='centersGFCM'>center matrix calculator for GFCM algorithm</h2><span id='topic+centersGFCM'></span>

<h3>Description</h3>

<p>center matrix calculator for GFCM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centersGFCM(data, centers, belongmatrix, dots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="centersGFCM_+3A_data">data</code></td>
<td>
<p>a matrix (the dataset used for clustering)</p>
</td></tr>
<tr><td><code id="centersGFCM_+3A_centers">centers</code></td>
<td>
<p>a matrix (the centers of the clusters)</p>
</td></tr>
<tr><td><code id="centersGFCM_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>a matrix with the membership values</p>
</td></tr>
<tr><td><code id="centersGFCM_+3A_dots">dots</code></td>
<td>
<p>a list of other arguments specific to FCM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the new centers
</p>

<hr>
<h2 id='centersSFCM'>center matrix calculator for SFCM algorithm</h2><span id='topic+centersSFCM'></span>

<h3>Description</h3>

<p>center matrix calculator for SFCM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centersSFCM(data, centers, belongmatrix, dots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="centersSFCM_+3A_data">data</code></td>
<td>
<p>a matrix (the dataset used for clustering)</p>
</td></tr>
<tr><td><code id="centersSFCM_+3A_centers">centers</code></td>
<td>
<p>a matrix (the centers of the clusters)</p>
</td></tr>
<tr><td><code id="centersSFCM_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>a matrix with the membership values</p>
</td></tr>
<tr><td><code id="centersSFCM_+3A_dots">dots</code></td>
<td>
<p>a list of other arguments specific to FCM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the new centers
</p>

<hr>
<h2 id='centersSGFCM'>center matrix calculator for SGFCM algorithm</h2><span id='topic+centersSGFCM'></span>

<h3>Description</h3>

<p>center matrix calculator for SGFCM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centersSGFCM(data, centers, belongmatrix, dots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="centersSGFCM_+3A_data">data</code></td>
<td>
<p>a matrix (the dataset used for clustering)</p>
</td></tr>
<tr><td><code id="centersSGFCM_+3A_centers">centers</code></td>
<td>
<p>a matrix (the centers of the clusters)</p>
</td></tr>
<tr><td><code id="centersSGFCM_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>a matrix with the membership values</p>
</td></tr>
<tr><td><code id="centersSGFCM_+3A_dots">dots</code></td>
<td>
<p>a list of other arguments specific to FCM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the new centers
</p>

<hr>
<h2 id='check_matdist'>Check validity of a dissimilarity matrix</h2><span id='topic+check_matdist'></span>

<h3>Description</h3>

<p>Check the validity of a dissimilarity matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_matdist(matdist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_matdist_+3A_matdist">matdist</code></td>
<td>
<p>A dissimilarity matrix</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='check_raters_dims'>Check dimensions of a list of rasters</h2><span id='topic+check_raters_dims'></span>

<h3>Description</h3>

<p>Check if all the rasters in a list have the same dimensions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_raters_dims(rasters)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_raters_dims_+3A_rasters">rasters</code></td>
<td>
<p>A list of rasters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='check_window'>Check the shape of a window</h2><span id='topic+check_window'></span>

<h3>Description</h3>

<p>Check is a window is squarred and have odd dimensions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_window(w)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_window_+3A_w">w</code></td>
<td>
<p>A matrix</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='circular_window'>Circular window</h2><span id='topic+circular_window'></span>

<h3>Description</h3>

<p>Create a matrix that can be used as a window when working with
rasters. It uses a radius to set to 0 the weights of pixels that are farther
than this distance. This is helpful to create circular focals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>circular_window(radius, res)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="circular_window_+3A_radius">radius</code></td>
<td>
<p>The size in metres of the radius of the circular focal</p>
</td></tr>
<tr><td><code id="circular_window_+3A_res">res</code></td>
<td>
<p>The width in metres of a pixel. It is assumed that pixels are squares.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original function comes from here: https://scrogster.wordpress.com/2012/10/05/applying-a-circular-moving-window-filter-to-raster-data-in-r/
but we reworked it to make it faster and to ensure that the result is a matrix with odd dimensions.
</p>


<h3>Value</h3>

<p>A binary weight matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'># wide of 100 metres for pixels of 2 metres
window &lt;- circular_window(100, 2)
# row standardisation
window_row_std &lt;- window / sum(window)
</code></pre>

<hr>
<h2 id='CMeans'>C-means</h2><span id='topic+CMeans'></span>

<h3>Description</h3>

<p>The classical c-mean algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CMeans(
  data,
  k,
  m,
  maxiter = 500,
  tol = 0.01,
  standardize = TRUE,
  robust = FALSE,
  noise_cluster = FALSE,
  delta = NULL,
  verbose = TRUE,
  init = "random",
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CMeans_+3A_data">data</code></td>
<td>
<p>A dataframe with only numerical variables. Can also be a list of
rasters (produced by the package raster). In that case, each raster is
considered as a variable and each pixel is an observation. Pixels with NA
values are not used during the classification.</p>
</td></tr>
<tr><td><code id="CMeans_+3A_k">k</code></td>
<td>
<p>An integer describing the number of cluster to find</p>
</td></tr>
<tr><td><code id="CMeans_+3A_m">m</code></td>
<td>
<p>A float for the fuzziness degree</p>
</td></tr>
<tr><td><code id="CMeans_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iterations</p>
</td></tr>
<tr><td><code id="CMeans_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="CMeans_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variables must be centred and
reduced (default = True)</p>
</td></tr>
<tr><td><code id="CMeans_+3A_robust">robust</code></td>
<td>
<p>A boolean indicating if the &quot;robust&quot; version of the algorithm must be used (see details)</p>
</td></tr>
<tr><td><code id="CMeans_+3A_noise_cluster">noise_cluster</code></td>
<td>
<p>A boolean indicatong if a noise cluster must be added to the solution (see details)</p>
</td></tr>
<tr><td><code id="CMeans_+3A_delta">delta</code></td>
<td>
<p>A float giving the distance of the noise cluster to each observation</p>
</td></tr>
<tr><td><code id="CMeans_+3A_verbose">verbose</code></td>
<td>
<p>A boolean to specify if the progress should be printed</p>
</td></tr>
<tr><td><code id="CMeans_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centres must be selected. &quot;random&quot;
indicates that random observations are used as centres. &quot;kpp&quot; use a distance-based method
resulting in more dispersed centres at the beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="CMeans_+3A_seed">seed</code></td>
<td>
<p>An integer used for random number generation. It ensures that the
starting centres will be the same if the same value is selected.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class FCMres with the following slots
</p>

<ul>
<li><p> Centers: a dataframe describing the final centers of the groups
</p>
</li>
<li><p> Belongings: the final membership matrix
</p>
</li>
<li><p> Groups: a vector with the names of the most likely group for each observation
</p>
</li>
<li><p> Data: the dataset used to perform the clustering (might be standardized)
</p>
</li>
<li><p> isRaster: TRUE if rasters were used as input data, FALSE otherwise
</p>
</li>
<li><p> k: the number of groups
</p>
</li>
<li><p> m: the fuzyness degree
</p>
</li>
<li><p> alpha: the spatial weighting parameter (if SFCM or SGFCM)
</p>
</li>
<li><p> beta: beta parameter for generalized version of FCM (GFCM or SGFCM)
</p>
</li>
<li><p> algo: the name of the algorithm used
</p>
</li>
<li><p> rasters: a list of rasters with membership values and the most likely group (if rasters were used)
</p>
</li>
<li><p> missing: a boolean vector indicating raster cell with data (TRUE) and with NA (FALSE) (if rasters were used)
</p>
</li>
<li><p> maxiter: the maximum number of iterations used
</p>
</li>
<li><p> tol: the convergence criterio
</p>
</li>
<li><p> lag_method: the lag function used (if SFCM or SGFCM)
</p>
</li>
<li><p> nblistw: the neighbours list used (if vector data were used for SFCM or SGFCM)
</p>
</li>
<li><p> window: the window used (if raster data were used for SFCM or SGFCM)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
result &lt;- CMeans(dataset,k = 5, m = 1.5, standardize = TRUE)
</code></pre>

<hr>
<h2 id='div_matrices_bycol'>element wise division of two matrices by column</h2><span id='topic+div_matrices_bycol'></span>

<h3>Description</h3>

<p>element wise division of two matrices by column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>div_matrices_bycol(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="div_matrices_bycol_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="div_matrices_bycol_+3A_y">y</code></td>
<td>
<p>a matrix with the same dimensions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix
</p>

<hr>
<h2 id='Elsa_categorical_matrix_window'>Elsa statistic calculated on a matrix with a given window</h2><span id='topic+Elsa_categorical_matrix_window'></span>

<h3>Description</h3>

<p>method described here : https://doi.org/10.1016/j.spasta.2018.10.001
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Elsa_categorical_matrix_window(mat, window, dist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Elsa_categorical_matrix_window_+3A_mat">mat</code></td>
<td>
<p>an IntegerMatrix, must be filled with integer, -1 indicates NA values, categories must start at 0</p>
</td></tr>
<tr><td><code id="Elsa_categorical_matrix_window_+3A_window">window</code></td>
<td>
<p>the window to use to define neighbours. 0 can be used to indicate that a cell is not a neighbour</p>
</td></tr>
<tr><td><code id="Elsa_categorical_matrix_window_+3A_dist">dist</code></td>
<td>
<p>a distance matrix between the categories</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a NumericVector : the local values of ELSA
</p>

<hr>
<h2 id='Elsa_fuzzy_matrix_window'>Fuzzy Elsa statistic calculated on a matrix with a given window</h2><span id='topic+Elsa_fuzzy_matrix_window'></span>

<h3>Description</h3>

<p>This is an extension to the fuzzy classification case for the Elsa statistic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Elsa_fuzzy_matrix_window(mats, window, dist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Elsa_fuzzy_matrix_window_+3A_mats">mats</code></td>
<td>
<p>An array, each slice must contains the membership values of one group</p>
</td></tr>
<tr><td><code id="Elsa_fuzzy_matrix_window_+3A_window">window</code></td>
<td>
<p>the window to use to define neighbours. 0 can be used to indicate that a cell is not a neighbour</p>
</td></tr>
<tr><td><code id="Elsa_fuzzy_matrix_window_+3A_dist">dist</code></td>
<td>
<p>a distance matrix between the groups</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a NumericVector : the local values of ELSA
</p>

<hr>
<h2 id='elsa_fuzzy_vector'>Local Fuzzy ELSA statistic for vector</h2><span id='topic+elsa_fuzzy_vector'></span>

<h3>Description</h3>

<p>Calculate the Local Fuzzy ELSA statistic using a nblistw object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elsa_fuzzy_vector(memberships, nblistw, matdist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elsa_fuzzy_vector_+3A_memberships">memberships</code></td>
<td>
<p>A membership matrix</p>
</td></tr>
<tr><td><code id="elsa_fuzzy_vector_+3A_nblistw">nblistw</code></td>
<td>
<p>The spatial weight matrix (nblistw object from spdep)</p>
</td></tr>
<tr><td><code id="elsa_fuzzy_vector_+3A_matdist">matdist</code></td>
<td>
<p>A matrix representing the dissimilarity between the clusters. The matrix must
be squared and the diagonal must be filled with zeros.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of local ELSA values
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='elsa_raster'>calculate ELSA spatial statistic for raster dataset</h2><span id='topic+elsa_raster'></span>

<h3>Description</h3>

<p>calculate ELSA spatial statistic for vector dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elsa_raster(rast, window, matdist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elsa_raster_+3A_rast">rast</code></td>
<td>
<p>An integer raster or matrix representing the m categories (0,1,2,..., m)</p>
</td></tr>
<tr><td><code id="elsa_raster_+3A_window">window</code></td>
<td>
<p>A binary (0,1) matrix representing the neighbours spatial weights when working
with rasters. The matrix must have odd dimensions.</p>
</td></tr>
<tr><td><code id="elsa_raster_+3A_matdist">matdist</code></td>
<td>
<p>A matrix representing the dissimilarity between the clusters. The matrix must
be squared and the diagonal must be filled with zeros.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A raster or a matrix: the local values of ELSA
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='elsa_vector'>calculate ELSA spatial statistic for vector dataset</h2><span id='topic+elsa_vector'></span>

<h3>Description</h3>

<p>calculate ELSA spatial statistic for vector dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elsa_vector(categories, nblistw, dist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elsa_vector_+3A_categories">categories</code></td>
<td>
<p>An integer vector representing the m categories (1,2,3,..., m),
-1 is used to indicate missing values.</p>
</td></tr>
<tr><td><code id="elsa_vector_+3A_nblistw">nblistw</code></td>
<td>
<p>A listw object from spdep representing neighbour relations</p>
</td></tr>
<tr><td><code id="elsa_vector_+3A_dist">dist</code></td>
<td>
<p>A numeric matrix (m*m) representing the distances between categories</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector: the local values of ELSA
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='eval_parameters'>Worker function</h2><span id='topic+eval_parameters'></span>

<h3>Description</h3>

<p>Worker function for select_parameters and select_parameters.mc
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval_parameters(
  algo,
  parameters,
  data,
  nblistw = NULL,
  window = NULL,
  standardize = TRUE,
  robust = FALSE,
  noise_cluster = FALSE,
  spconsist = FALSE,
  classidx = TRUE,
  nrep = 30,
  indices = NULL,
  tol,
  maxiter,
  seed = NULL,
  init = "random",
  verbose = TRUE,
  wrapped = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eval_parameters_+3A_algo">algo</code></td>
<td>
<p>A string indicating which method to use (FCM, GFCM, SFCM, SGFCM)</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_parameters">parameters</code></td>
<td>
<p>A dataframe of parameters with columns k,m and alpha</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_data">data</code></td>
<td>
<p>A dataframe with numeric columns</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input.</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_window">window</code></td>
<td>
<p>If data is a list of rasters, then a window must be specified instead of
a list.w object. It will be used to calculate a focal function on each raster. The
window must be a square numeric matrix with odd dimensions (such 3x3). The values in
the matrix indicate the weight to give to each pixel and the centre of the matrix is
the centre of the focal function.</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variable must be centered and
reduce (default = True)</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_spconsist">spconsist</code></td>
<td>
<p>A boolean indicating if the spatial consistency must be
calculated</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_classidx">classidx</code></td>
<td>
<p>A boolean indicating if the quality of classification
indices must be calculated</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_nrep">nrep</code></td>
<td>
<p>An integer indicating the number of permutation to do to simulate
the random distribution of the spatial inconsistency. Only used if spconsist
is TRUE.</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_indices">indices</code></td>
<td>
<p>A character vector with the names of the indices to calculate, to
evaluate clustering quality. default is :c(&quot;Silhouette.index&quot;, &quot;Partition.entropy&quot;,
&quot;Partition.coeff&quot;, &quot;XieBeni.index&quot;, &quot;FukuyamaSugeno.index&quot;, &quot;Explained.inertia&quot;).
Other available indices are : &quot;DaviesBoulin.index&quot;, &quot;CalinskiHarabasz.index&quot;,
&quot;GD43.index&quot;, &quot;GD53.index&quot; and &quot;Negentropy.index&quot;.</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iteration</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_seed">seed</code></td>
<td>
<p>An integer used for random number generation. It ensures that the
start centers will be the same if the same integer is selected.</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centers must be selected. &quot;random&quot;
indicates that random observations are used as centers. &quot;kpp&quot; use a distance based method
resulting in more dispersed centers at the beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_verbose">verbose</code></td>
<td>
<p>A boolean indicating if a progressbar should be displayed</p>
</td></tr>
<tr><td><code id="eval_parameters_+3A_wrapped">wrapped</code></td>
<td>
<p>A boolean indicating if the data passed is wrapped or not (see wrap function of terra)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a DataFrame containing for each combinations of parameters several clustering
quality indexes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#No example provided, this is an internal function
</code></pre>

<hr>
<h2 id='evaluateMatrices'>Matrix evaluation</h2><span id='topic+evaluateMatrices'></span>

<h3>Description</h3>

<p>Evaluate if the algorithm converged by comparing two successive membership
matrices. Calculate the absolute difference between the matrices and then
calculate the max of each row. If all the values of the final vector are
below the fixed tolerance, then return True, else return False
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluateMatrices(mat1, mat2, tol)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evaluateMatrices_+3A_mat1">mat1</code></td>
<td>
<p>A n X k matrix giving for each observation n, its probability to
belong to the cluster k at iteration i</p>
</td></tr>
<tr><td><code id="evaluateMatrices_+3A_mat2">mat2</code></td>
<td>
<p>A n X k matrix giving for each observation n, its probability to
belong to the cluster k at iteration i+1</p>
</td></tr>
<tr><td><code id="evaluateMatrices_+3A_tol">tol</code></td>
<td>
<p>A float representing the algorithm tolerance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean, TRUE if the test is passed, FALSE otherwise
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This is an internal function, no example provided
</code></pre>

<hr>
<h2 id='FCMres'>Instantiate a FCMres object</h2><span id='topic+FCMres'></span>

<h3>Description</h3>

<p>Instantiate a FCMres object from a list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FCMres(obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FCMres_+3A_obj">obj</code></td>
<td>
<p>A list, typically obtained from functions CMeans, GCMeans, SFCMeans, SGFCMeans</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creating manually a FCMres object can be handy to use geocmeans functions
on results from external algorithms. The list given to function FCMres must
contain 5 necessary parameters:
</p>

<ul>
<li><p> Centers: a dataframe or matrix describing the final centers of the groups
</p>
</li>
<li><p> Belongings: a membership matrix
</p>
</li>
<li><p> Data: the dataset used to perform the clustering.
It must be a dataframe or a matrix. If a list is given, then the function
assumes that the classification occured on rasters (see information below)
</p>
</li>
<li><p> m: the fuzyness degree (1 if hard clustering is used)
</p>
</li>
<li><p> algo: the name of the algorithm used
</p>
</li></ul>

<p>Note that the S3 method predict is available only for object created with the functions
CMeans, GCMeans, SFCMeans, SGFCMeans.
</p>
<p>When working with rasters, Data must be a list of rasters, and a second list of rasters
with the membership values must be provided is en extra slot named &quot;rasters&quot;. In that
case, Belongings has not to be defined and will be created automatically.
</p>
<p>Warning: the order of the elements is very important. The first row in the
matrix &quot;Centers&quot;, and the first column in the matrix &quot;Belongings&quot; must both
be related to the same group and so on. When working with raster data, the
first row in the matrix &quot;Centers&quot; must also match with the first rasterLayer
in the list &quot;rasters&quot;.
</p>


<h3>Value</h3>

<p>An object of class FCMres
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This is an internal function, no example provided
</code></pre>

<hr>
<h2 id='focal_adj_mean_arr_window'>focal mean weighted by inverse of euclidean distance on a cube</h2><span id='topic+focal_adj_mean_arr_window'></span>

<h3>Description</h3>

<p>focal mean weighted by inverse of euclidean distance on a cube
</p>


<h3>Usage</h3>

<pre><code class='language-R'>focal_adj_mean_arr_window(mat, window)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="focal_adj_mean_arr_window_+3A_mat">mat</code></td>
<td>
<p>an array (cube)</p>
</td></tr>
<tr><td><code id="focal_adj_mean_arr_window_+3A_window">window</code></td>
<td>
<p>a numeric matrix (squared)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a lagged version of the original cube
</p>

<hr>
<h2 id='focal_euclidean'>focal euclidean distance on a list of matrices</h2><span id='topic+focal_euclidean'></span><span id='topic+focal_euclidean_list'></span>

<h3>Description</h3>

<p>focal euclidean distance on a list of matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>focal_euclidean_list(matrices, window)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="focal_euclidean_+3A_matrices">matrices</code></td>
<td>
<p>a List of matrices with the same dimensions</p>
</td></tr>
<tr><td><code id="focal_euclidean_+3A_window">window</code></td>
<td>
<p>a numeric matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the euclidean distance of each cell to
its neighbours.
</p>

<hr>
<h2 id='focal_euclidean_arr_window'>focal euclidean distance on a matrix with a given window for a cube</h2><span id='topic+focal_euclidean_arr_window'></span>

<h3>Description</h3>

<p>focal euclidean distance on a matrix with a given window for a cube
</p>


<h3>Usage</h3>

<pre><code class='language-R'>focal_euclidean_arr_window(mat, window)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="focal_euclidean_arr_window_+3A_mat">mat</code></td>
<td>
<p>an array (cube)</p>
</td></tr>
<tr><td><code id="focal_euclidean_arr_window_+3A_window">window</code></td>
<td>
<p>a numeric matrix (squared)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the euclidean distance of each cell to
its neighbours.
</p>

<hr>
<h2 id='focal_euclidean_mat_window'>focal euclidean distance on a matrix with a given window</h2><span id='topic+focal_euclidean_mat_window'></span>

<h3>Description</h3>

<p>focal euclidean distance on a matrix with a given window
</p>


<h3>Usage</h3>

<pre><code class='language-R'>focal_euclidean_mat_window(mat, window)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="focal_euclidean_mat_window_+3A_mat">mat</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="focal_euclidean_mat_window_+3A_window">window</code></td>
<td>
<p>a numeric matrix (squared)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the euclidean distance of each cell to
its neighbours.
</p>

<hr>
<h2 id='GCMeans'>Generalized C-means</h2><span id='topic+GCMeans'></span>

<h3>Description</h3>

<p>The generalized c-mean algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GCMeans(
  data,
  k,
  m,
  beta,
  maxiter = 500,
  tol = 0.01,
  standardize = TRUE,
  robust = FALSE,
  noise_cluster = FALSE,
  delta = NULL,
  verbose = TRUE,
  init = "random",
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GCMeans_+3A_data">data</code></td>
<td>
<p>A dataframe with only numerical variables. Can also be a list of
rasters (produced by the package raster). In that case, each raster is
considered as a variable and each pixel is an observation. Pixels with NA
values are not used during the classification.</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_k">k</code></td>
<td>
<p>An integer describing the number of cluster to find</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_m">m</code></td>
<td>
<p>A float for the fuzziness degree</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_beta">beta</code></td>
<td>
<p>A float for the beta parameter (control speed convergence and classification crispness)</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iterations</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variables must be centred and
reduced (default = True)</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_robust">robust</code></td>
<td>
<p>A boolean indicating if the &quot;robust&quot; version of the algorithm must be used (see details)</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_noise_cluster">noise_cluster</code></td>
<td>
<p>A boolean indicatong if a noise cluster must be added to the solution (see details)</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_delta">delta</code></td>
<td>
<p>A float giving the distance of the noise cluster to each observation</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_verbose">verbose</code></td>
<td>
<p>A boolean to specify if the progress should be printed</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centres must be selected. &quot;random&quot;
indicates that random observations are used as centres. &quot;kpp&quot; use a distance-based method
resulting in more dispersed centres at the beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="GCMeans_+3A_seed">seed</code></td>
<td>
<p>An integer used for random number generation. It ensures that the
starting centres will be the same if the same value is selected.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class FCMres with the following slots
</p>

<ul>
<li><p> Centers: a dataframe describing the final centers of the groups
</p>
</li>
<li><p> Belongings: the final membership matrix
</p>
</li>
<li><p> Groups: a vector with the names of the most likely group for each observation
</p>
</li>
<li><p> Data: the dataset used to perform the clustering (might be standardized)
</p>
</li>
<li><p> isRaster: TRUE if rasters were used as input data, FALSE otherwise
</p>
</li>
<li><p> k: the number of groups
</p>
</li>
<li><p> m: the fuzyness degree
</p>
</li>
<li><p> alpha: the spatial weighting parameter (if SFCM or SGFCM)
</p>
</li>
<li><p> beta: beta parameter for generalized version of FCM (GFCM or SGFCM)
</p>
</li>
<li><p> algo: the name of the algorithm used
</p>
</li>
<li><p> rasters: a list of rasters with membership values and the most likely group (if rasters were used)
</p>
</li>
<li><p> missing: a boolean vector indicating raster cell with data (TRUE) and with NA (FALSE) (if rasters were used)
</p>
</li>
<li><p> maxiter: the maximum number of iterations used
</p>
</li>
<li><p> tol: the convergence criterio
</p>
</li>
<li><p> lag_method: the lag function used (if SFCM or SGFCM)
</p>
</li>
<li><p> nblistw: the neighbours list used (if vector data were used for SFCM or SGFCM)
</p>
</li>
<li><p> window: the window used (if raster data were used for SFCM or SGFCM)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
result &lt;- GCMeans(dataset,k = 5, m = 1.5, beta = 0.5, standardize = TRUE)
</code></pre>

<hr>
<h2 id='geocmeans'>geocmeans: A package implementing methods for spatially constrained c-means
algorithm</h2><span id='topic+geocmeans'></span>

<h3>Description</h3>

<p>The geocmeans package implements a modified c-means algorithm more suited to
work with spatial data (characterized by spatial autocorrelation). The
spatial information is introduced with a spatial weight matrix W (n * n)
where wij indicate the strength of the spatial relationship between the
observations i and j. It is recommended to use a matrix standardized by row
(so that the sum of each row is 1). More specifically, the spatial c-means
combine the euclidean distance of each observation in the data matrix X to
each center with the euclidean distance of the lagged version of X by W (WX).
A parameter alpha controls for the weight of the lagged matrix. If
alpha = 0, then the spatial c-means is equal to a classical c-means. If alpha
= 1, then the weights given to  X and WX are equals. If alpha = 2, then the
weight of WX is twice the one of X and so on.
Several indices are provided to assess the quality of a classification on the
semantic and spatial dimensions. To explore results, a shiny app is also
available
</p>

<hr>
<h2 id='geocmeans_env'>geocmeans general environment</h2><span id='topic+geocmeans_env'></span>

<h3>Description</h3>

<p>An environment used by geocmeans to store data, functions and values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geocmeans_env
</code></pre>


<h3>Format</h3>

<p>An object of class <code>environment</code> of length 0.
</p>

<hr>
<h2 id='groups_matching'>Match the groups obtained from two classifications</h2><span id='topic+groups_matching'></span>

<h3>Description</h3>

<p>Match the groups obtained from two classifications based on
the Jaccard index calculated on the membership matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>groups_matching(object.x, object.y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="groups_matching_+3A_object.x">object.x</code></td>
<td>
<p>A FCMres object, or a simple membership matrix. It is used as the reference
for the ordering of the groups</p>
</td></tr>
<tr><td><code id="groups_matching_+3A_object.y">object.y</code></td>
<td>
<p>A FCMres object, or a simple membership matrix. The order of its groups will
be updated to match with the groups of object.x</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We can not expect to obtain the groups in the same order in each run
of a classification algorithm. This function can be used match the clusters of a first
classification with the most similar clusters in a second classification. Thus
it might be easier to compare the results of two algorithms or two runs of the
same algorithm.
</p>


<h3>Value</h3>

<p>The FCMres object or the membership matrix provided for the parameter object.y with
the order of the groups updated.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)

#selecting the columns for the analysis
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14",
                   "Pct_65","Pct_Img","TxChom1564","Pct_brevet","NivVieMed")

#rescaling the columns
Data &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
for (Col in names(Data)){
  Data[[Col]] &lt;- as.numeric(scale(Data[[Col]]))
}

Cmean &lt;- CMeans(Data,4,1.5,500,standardize = FALSE, seed = 456, tol = 0.00001, verbose = FALSE)
Cmean2 &lt;- CMeans(Data,4,1.5,500,standardize = FALSE, seed = 789, tol = 0.00001, verbose = FALSE)
ordered_Cmean2 &lt;- groups_matching(Cmean,Cmean2)
</code></pre>

<hr>
<h2 id='input_raster_data'>Raster data preparation</h2><span id='topic+input_raster_data'></span>

<h3>Description</h3>

<p>Prepare a raster dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>input_raster_data(dataset, w = NULL, fun = sum, standardize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="input_raster_data_+3A_dataset">dataset</code></td>
<td>
<p>A list of rasters</p>
</td></tr>
<tr><td><code id="input_raster_data_+3A_w">w</code></td>
<td>
<p>The window to use in the focal function</p>
</td></tr>
<tr><td><code id="input_raster_data_+3A_fun">fun</code></td>
<td>
<p>the function to use as the focal function</p>
</td></tr>
<tr><td><code id="input_raster_data_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variable must be centered and
reduced (default = True)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the required elements to perform clustering
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='is.FCMres'>is method for FCMres</h2><span id='topic+is.FCMres'></span>

<h3>Description</h3>

<p>Check if an object can be considered as a FCMres object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FCMres'
is(object, class2 = "FCMres")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.FCMres_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans, GCMeans, SFCMeans, SGFCMeans</p>
</td></tr>
<tr><td><code id="is.FCMres_+3A_class2">class2</code></td>
<td>
<p>Character string giving the names of the classe to test (usually &quot;FCMres&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean, TRUE if x can be considered as a FCMres object, FALSE otherwise
group
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
is(result, "FCMres")
</code></pre>

<hr>
<h2 id='kppCenters'>kpp centers selection</h2><span id='topic+kppCenters'></span>

<h3>Description</h3>

<p>Select the initial centers of centroids by using the k++ approach
as suggested in this article: http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kppCenters(data, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kppCenters_+3A_data">data</code></td>
<td>
<p>The dataset used in the classification</p>
</td></tr>
<tr><td><code id="kppCenters_+3A_k">k</code></td>
<td>
<p>The number of groups for the classification</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a DataFrame, each row is the center of a cluster
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This is an internal function, no example provided
</code></pre>

<hr>
<h2 id='local_moranI_matrix_window'>Local Moran I calculated on a matrix with a given window</h2><span id='topic+local_moranI_matrix_window'></span>

<h3>Description</h3>

<p>Local Moran I calculated on a matrix with a given window
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local_moranI_matrix_window(mat, window)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="local_moranI_matrix_window_+3A_mat">mat</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="local_moranI_matrix_window_+3A_window">window</code></td>
<td>
<p>the window to use to define neighbours. 0 can be used to indicate that a cell is not a neighbour</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a double, the value of Moran I
</p>

<hr>
<h2 id='LyonIris'>social and environmental indicators for the Iris of the metropolitan region of Lyon (France)</h2><span id='topic+LyonIris'></span>

<h3>Description</h3>

<p>A dataset containing social and environmental data for the
Iris of Lyon (France)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LyonIris
</code></pre>


<h3>Format</h3>

<p>A SpatialPolygonsDataFrame with 506 rows and 32 variables:
</p>

<dl>
<dt>OBJECTID</dt><dd><p>a simple OID (integer)</p>
</dd>
<dt>INSEE_COM</dt><dd><p>the code of each commune (factor)</p>
</dd>
<dt>CODE_IRIS</dt><dd><p>the code of each unit area : iris (factor)</p>
</dd>
<dt>Lden</dt><dd><p>the annual daily mean noise exposure values in dB (numeric)</p>
</dd>
<dt>NO2</dt><dd><p>the annual mean of NO2 concentration in ug/m3 (numeric)</p>
</dd>
<dt>PM25</dt><dd><p>the annual mean of PM25 concentration in ug/m3 (numeric)</p>
</dd>
<dt>PM10</dt><dd><p>the annual mean of PM25 concentration in ug/m3 (numeric)</p>
</dd>
<dt>Pct0_14</dt><dd><p>the percentage of people that are 0 to 14 year old (numeric)</p>
</dd>
<dt>Pct_65</dt><dd><p>the percentage of people older than 64 (numeric)</p>
</dd>
<dt>Pct_Img</dt><dd><p>the percentage immigrants (numeric)</p>
</dd>
<dt>TxChom1564</dt><dd><p>the unemployment rate (numeric)</p>
</dd>
<dt>Pct_brevet</dt><dd><p>the percentage of people that obtained the college diploma (numeric)</p>
</dd>
<dt>NivVieMed</dt><dd><p>the median standard of living in euros (numeric)</p>
</dd>
<dt>VegHautPrt</dt><dd><p>the percentage of the iris surface covered by trees (numeric)</p>
</dd>
<dt>X</dt><dd><p>the X coordinate of the center of the Iris (numeric)</p>
</dd>
<dt>Y</dt><dd><p>the Y coordinate of the center of the Iris (numeric)</p>
</dd>
</dl>
<p>...

</p>


<h3>Source</h3>

<p><a href="https://data.grandlyon.com/portail/fr/accueil">https://data.grandlyon.com/portail/fr/accueil</a>
</p>

<hr>
<h2 id='main_worker'>Main worker function</h2><span id='topic+main_worker'></span>

<h3>Description</h3>

<p>Execution of the classification algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>main_worker(algo, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="main_worker_+3A_algo">algo</code></td>
<td>
<p>A string indicating the algorithm to use (one of FCM, GFCM, SGFCM)</p>
</td></tr>
<tr><td><code id="main_worker_+3A_...">...</code></td>
<td>
<p>all the required arguments for the algorithm to use</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list with
</p>

<ul>
<li><p> Centers: a dataframe describing the final centers of the groups
</p>
</li>
<li><p> Belongings: the final membership matrix
</p>
</li>
<li><p> Groups: a vector with the names of the most likely group for each observation
</p>
</li>
<li><p> Data: the dataset used to perform the clustering (might be standardized)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>#This is an internal function, no example provided
</code></pre>

<hr>
<h2 id='mapClusters'>Mapping the clusters</h2><span id='topic+mapClusters'></span>

<h3>Description</h3>

<p>Build some maps to visualize the results of the clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapClusters(geodata = NULL, object, undecided = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapClusters_+3A_geodata">geodata</code></td>
<td>
<p>An object of class features collection from sf /
ordered like the original data used for the clustering. Can be Null if object is
a FCMres and has been created with rasters.</p>
</td></tr>
<tr><td><code id="mapClusters_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans. Can also be a simple membership matrix.</p>
</td></tr>
<tr><td><code id="mapClusters_+3A_undecided">undecided</code></td>
<td>
<p>A float between 0 and 1 giving the minimum value that an
observation must get in the membership matrix to not be considered as
uncertain (default = NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list with :
</p>

<ul>
<li><p> ProbaMaps : a list of tmap maps showing for each group the
probability of the observations to belong to that group
</p>
</li>
<li><p> ClusterMap : a tmap map showing the most likely group for
observation
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
MyMaps &lt;- mapClusters(LyonIris, result$Belongings)

## End(Not run)
</code></pre>

<hr>
<h2 id='mapRasters'>Mapping the clusters (rasters)</h2><span id='topic+mapRasters'></span>

<h3>Description</h3>

<p>Internal function to realize maps based on rasters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapRasters(object, undecided)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapRasters_+3A_object">object</code></td>
<td>
<p>A FCMres object</p>
</td></tr>
<tr><td><code id="mapRasters_+3A_undecided">undecided</code></td>
<td>
<p>A float between 0 and 1 giving the minimum value that an
observation must get in the membership matrix to not be considered as
uncertain (default = NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list with :
</p>

<ul>
<li><p> ProbaMaps : a list of ggplot maps showing for each group the
probability of the observations to belong to that group
</p>
</li>
<li><p> ClusterMap : a ggplot map showing the most likely group for each observation
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>#No example provided, this is an internal function, use the general wrapper function mapClusters
</code></pre>

<hr>
<h2 id='mapThis'>Mapping the clusters</h2><span id='topic+mapThis'></span>

<h3>Description</h3>

<p>Internal function to realize maps
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapThis(geodata, belongmatrix, undecided = NULL, geom_type = "polygon")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapThis_+3A_geodata">geodata</code></td>
<td>
<p>feature collections ordered like the original data used
for the clustering</p>
</td></tr>
<tr><td><code id="mapThis_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>The membership matrix obtained at the end of the algorithm</p>
</td></tr>
<tr><td><code id="mapThis_+3A_undecided">undecided</code></td>
<td>
<p>A float between 0 and 1 giving the minimum value that an
observation must get in the membership matrix to not be considered as
uncertain (default = NULL)</p>
</td></tr>
<tr><td><code id="mapThis_+3A_geom_type">geom_type</code></td>
<td>
<p>A string indicating the type of geometry (polygon, string or point)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list with :
</p>

<ul>
<li><p> ProbaMaps : a list of ggplot maps showing for each group the
probability of the observations to belong to that group
</p>
</li>
<li><p> ClusterMap : a ggplot map showing the most likely group for each observation
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>#No example provided, this is an internal function, use the general wrapper function mapClusters
</code></pre>

<hr>
<h2 id='max_mat'>maximum in a matrix</h2><span id='topic+max_mat'></span>

<h3>Description</h3>

<p>maximum in a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_mat(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="max_mat_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a double
</p>

<hr>
<h2 id='moranI_matrix_window'>Moran I calculated on a matrix with a given window</h2><span id='topic+moranI_matrix_window'></span>

<h3>Description</h3>

<p>Moran I calculated on a matrix with a given window
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moranI_matrix_window(mat, window)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="moranI_matrix_window_+3A_mat">mat</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="moranI_matrix_window_+3A_window">window</code></td>
<td>
<p>the window to use to define neighbours. 0 can be used to indicate that a cell is not a neighbour</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a double, the value of Moran I
</p>

<hr>
<h2 id='output_raster_data'>Raster result transformation</h2><span id='topic+output_raster_data'></span>

<h3>Description</h3>

<p>Adapt the results if a raster is used
</p>


<h3>Usage</h3>

<pre><code class='language-R'>output_raster_data(object, missing, rst)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="output_raster_data_+3A_object">object</code></td>
<td>
<p>A FCMres object</p>
</td></tr>
<tr><td><code id="output_raster_data_+3A_missing">missing</code></td>
<td>
<p>A boolean indicating which pixels have no missing values</p>
</td></tr>
<tr><td><code id="output_raster_data_+3A_rst">rst</code></td>
<td>
<p>A raster object used as template to structure the results</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A FCMres object with isRaster = TRUE
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this is an internal function, no example provided
</code></pre>

<hr>
<h2 id='plot.FCMres'>Plot method for FCMres object</h2><span id='topic+plot.FCMres'></span>

<h3>Description</h3>

<p>Method to plot the results of a FCM.res object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FCMres'
plot(x, type = "spider", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.FCMres_+3A_x">x</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans. Can also be a simple membership matrix.</p>
</td></tr>
<tr><td><code id="plot.FCMres_+3A_type">type</code></td>
<td>
<p>A string indicating the type of plot to show. Can be one of
&quot;bar&quot;, &quot;violin&quot;, or &quot;spider&quot;. Default is spider.</p>
</td></tr>
<tr><td><code id="plot.FCMres_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This S3 method is a simple dispatcher for the functions barPlots,
violinPlots and spiderPlots. To be able to use all their specific
parameters, one can use them directly.
</p>


<h3>Value</h3>

<p>a ggplot2 object, a list, or NULL, depending on the type of plot requested
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")

# rescaling all the variables used in the analysis
for (field in AnalysisFields) {
    LyonIris[[field]] &lt;- scale(LyonIris[[field]])
}

# doing the initial clustering
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SGFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, beta = 0.5, standardize = FALSE)

plot(result, type = "spider")
</code></pre>

<hr>
<h2 id='pow_matrices_bycol'>element wise power of a matrix by column</h2><span id='topic+pow_matrices_bycol'></span><span id='topic+pow_matrix_bycol'></span>

<h3>Description</h3>

<p>element wise power of a matrix by column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pow_matrix_bycol(x, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pow_matrices_bycol_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="pow_matrices_bycol_+3A_p">p</code></td>
<td>
<p>the exponent</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix
</p>

<hr>
<h2 id='power_mat'>power of a matrix</h2><span id='topic+power_mat'></span>

<h3>Description</h3>

<p>power of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_mat(x, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power_mat_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="power_mat_+3A_p">p</code></td>
<td>
<p>a float</p>
</td></tr>
</table>


<h3>Value</h3>

<p>x ** p
</p>

<hr>
<h2 id='predict_membership'>Predict matrix membership for new observations</h2><span id='topic+predict_membership'></span>

<h3>Description</h3>

<p>Function to predict the membership matrix of a new set of observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_membership(
  object,
  new_data,
  nblistw = NULL,
  window = NULL,
  standardize = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_membership_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans. Can also be a simple membership matrix.</p>
</td></tr>
<tr><td><code id="predict_membership_+3A_new_data">new_data</code></td>
<td>
<p>A DataFrame with the new observations or a list of rasters if
object$isRaster is TRUE</p>
</td></tr>
<tr><td><code id="predict_membership_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input.</p>
</td></tr>
<tr><td><code id="predict_membership_+3A_window">window</code></td>
<td>
<p>If data is a list of rasters, then a window must be specified instead of
a list.w object. It will be used to calculate a focal function on each raster. The
window must be a square numeric matrix with odd dimensions (such 3x3). The values in
the matrix indicate the weight to give to each pixel and the centre of the matrix is
the centre of the focal function.</p>
</td></tr>
<tr><td><code id="predict_membership_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variable must be centered and
reduced (default = True)</p>
</td></tr>
<tr><td><code id="predict_membership_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric matrix with the membership values for each new observation. If
rasters were used, return a list of rasters with the membership values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")

# rescaling all the variables used in the analysis
for (field in AnalysisFields) {
    LyonIris[[field]] &lt;- scale(LyonIris[[field]])
}

# doing the initial clustering
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SGFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, beta = 0.5, standardize = FALSE)

# using a subset of the original dataframe as "new data"
new_data &lt;- LyonIris[c(1, 27, 36, 44, 73),]
new_dataset &lt;- sf::st_drop_geometry(new_data[AnalysisFields])
new_nb &lt;- spdep::poly2nb(new_data,queen=TRUE)
new_Wqueen &lt;- spdep::nb2listw(new_nb,style="W")

# doing the prediction
predictions &lt;- predict_membership(result, new_dataset, new_Wqueen, standardize = FALSE)
</code></pre>

<hr>
<h2 id='predict.FCMres'>Predict method for FCMres object</h2><span id='topic+predict.FCMres'></span>

<h3>Description</h3>

<p>Function to predict the membership matrix of a new set of observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FCMres'
predict(
  object,
  new_data,
  nblistw = NULL,
  window = NULL,
  standardize = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FCMres_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans. Can also be a simple membership matrix.</p>
</td></tr>
<tr><td><code id="predict.FCMres_+3A_new_data">new_data</code></td>
<td>
<p>A DataFrame with the new observations</p>
</td></tr>
<tr><td><code id="predict.FCMres_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input.</p>
</td></tr>
<tr><td><code id="predict.FCMres_+3A_window">window</code></td>
<td>
<p>If data is a list of rasters, then a window must be specified instead of
a list.w object. It will be used to calculate a focal function on each raster. The
window must be a square numeric matrix with odd dimensions (such 3x3). The values in
the matrix indicate the weight to give to each pixel and the centre of the matrix is
the centre of the focal function.</p>
</td></tr>
<tr><td><code id="predict.FCMres_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variable must be centred and
reduced (default = True)</p>
</td></tr>
<tr><td><code id="predict.FCMres_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric matrix with the membership values for each new observation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")

# rescaling all the variables used in the analysis
for (field in AnalysisFields) {
    LyonIris[[field]] &lt;- scale(LyonIris[[field]])
}

# doing the initial clustering
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SGFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, beta = 0.5, standardize = FALSE)

# using a subset of the original dataframe as "new data"
new_data &lt;- LyonIris[c(1, 27, 36, 44, 73),]
new_dataset &lt;- sf::st_drop_geometry(new_data[AnalysisFields])
new_nb &lt;- spdep::poly2nb(new_data,queen=TRUE)
new_Wqueen &lt;- spdep::nb2listw(new_nb,style="W")

# doing the prediction
predictions &lt;- predict(result, new_dataset, new_Wqueen, standardize = FALSE)
</code></pre>

<hr>
<h2 id='print.FCMres'>print method for FCMres</h2><span id='topic+print.FCMres'></span>

<h3>Description</h3>

<p>print a FCMres object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FCMres'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.FCMres_+3A_x">x</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans, GCMeans, SFCMeans, SGFCMeans</p>
</td></tr>
<tr><td><code id="print.FCMres_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean, TRUE if x can be considered as a FCMres object, FALSE otherwise
group
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
result &lt;- CMeans(dataset, k = 5, m = 1.5, standardize = TRUE)
print(result, "FCMres")
</code></pre>

<hr>
<h2 id='prod_matrices_bycol'>element wise product of two matrices by column</h2><span id='topic+prod_matrices_bycol'></span>

<h3>Description</h3>

<p>element wise product of two matrices by column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prod_matrices_bycol(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prod_matrices_bycol_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="prod_matrices_bycol_+3A_y">y</code></td>
<td>
<p>a matrix with the same dimensions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix
</p>

<hr>
<h2 id='rowmins_mat'>minimum of each row of a matrix</h2><span id='topic+rowmins_mat'></span>

<h3>Description</h3>

<p>minimum of each row of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowmins_mat(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rowmins_mat_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a NumericVector
</p>

<hr>
<h2 id='sanity_check'>Parameter checking function</h2><span id='topic+sanity_check'></span>

<h3>Description</h3>

<p>Check that the provided parameters are valid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sanity_check(dots, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sanity_check_+3A_dots">dots</code></td>
<td>
<p>A list of parameters used</p>
</td></tr>
<tr><td><code id="sanity_check_+3A_data">data</code></td>
<td>
<p>A numeric and complete dataframe</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean, TRUE if all the tests are passed, FALSE otherwise
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This is an internal function, no example provided
</code></pre>

<hr>
<h2 id='select_parameters'>Select parameters for a clustering algorithm</h2><span id='topic+select_parameters'></span><span id='topic+selectParameters'></span>

<h3>Description</h3>

<p>Function to select the parameters for a clustering algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_parameters(
  algo,
  data,
  k,
  m,
  alpha = NA,
  beta = NA,
  nblistw = NULL,
  lag_method = "mean",
  window = NULL,
  spconsist = TRUE,
  classidx = TRUE,
  nrep = 30,
  indices = NULL,
  standardize = TRUE,
  robust = FALSE,
  noise_cluster = FALSE,
  delta = NA,
  maxiter = 500,
  tol = 0.01,
  seed = NULL,
  init = "random",
  verbose = TRUE
)

selectParameters(
  algo,
  data,
  k,
  m,
  alpha = NA,
  beta = NA,
  nblistw = NULL,
  lag_method = "mean",
  window = NULL,
  spconsist = TRUE,
  classidx = TRUE,
  nrep = 30,
  indices = NULL,
  standardize = TRUE,
  robust = FALSE,
  noise_cluster = FALSE,
  delta = NA,
  maxiter = 500,
  tol = 0.01,
  seed = NULL,
  init = "random",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_parameters_+3A_algo">algo</code></td>
<td>
<p>A string indicating which method to use (FCM, GFCM, SFCM, SGFCM)</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_data">data</code></td>
<td>
<p>A dataframe with numeric columns or a list of rasters.</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_k">k</code></td>
<td>
<p>A sequence of values for k to test (&gt;=2)</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_m">m</code></td>
<td>
<p>A sequence of values for m to test</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_alpha">alpha</code></td>
<td>
<p>A sequence of values for alpha to test (NULL if not required)</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_beta">beta</code></td>
<td>
<p>A sequence of values for beta to test (NULL if not required)</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_nblistw">nblistw</code></td>
<td>
<p>A list of list.w objects describing the neighbours typically
produced by the spdep package (NULL if not required)</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_lag_method">lag_method</code></td>
<td>
<p>A string indicating if a classical lag must be used
(&quot;mean&quot;) or if a weighted median must be used (&quot;median&quot;). Both can be
tested by specifying a vector : c(&quot;mean&quot;,&quot;median&quot;). When working with rasters,
the string must be parsable to a function like mean, min, max, sum, etc. and will
be applied to all the pixels values in the window designated by the parameter window
and weighted according to the values of this matrix.</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_window">window</code></td>
<td>
<p>A list of windows to use to calculate neighbouring values if
rasters are used.</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_spconsist">spconsist</code></td>
<td>
<p>A boolean indicating if the spatial consistency must be
calculated</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_classidx">classidx</code></td>
<td>
<p>A boolean indicating if the quality of classification
indices must be calculated</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_nrep">nrep</code></td>
<td>
<p>An integer indicating the number of permutation to do to simulate
the random distribution of the spatial inconsistency. Only used if spconsist
is TRUE.</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_indices">indices</code></td>
<td>
<p>A character vector with the names of the indices to calculate, to
evaluate clustering quality. default is :c(&quot;Silhouette.index&quot;, &quot;Partition.entropy&quot;,
&quot;Partition.coeff&quot;, &quot;XieBeni.index&quot;, &quot;FukuyamaSugeno.index&quot;, &quot;Explained.inertia&quot;).
Other available indices are : &quot;DaviesBoulin.index&quot;, &quot;CalinskiHarabasz.index&quot;,
&quot;GD43.index&quot;, &quot;GD53.index&quot; and &quot;Negentropy.index&quot;.</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variable must be centered and
reduce (default = True)</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_robust">robust</code></td>
<td>
<p>A boolean indicating if the &quot;robust&quot; version of the algorithm must be used (see details)</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_noise_cluster">noise_cluster</code></td>
<td>
<p>A boolean indicatong if a noise cluster must be added to the solution (see details)</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_delta">delta</code></td>
<td>
<p>A float giving the distance of the noise cluster to each observation</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iteration</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_seed">seed</code></td>
<td>
<p>An integer used for random number generation. It ensures that the
start centers will be the same if the same integer is selected.</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centers must be selected. &quot;random&quot;
indicates that random observations are used as centers. &quot;kpp&quot; use a distance based method
resulting in more dispersed centers at the beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_verbose">verbose</code></td>
<td>
<p>A boolean indicating if a progressbar should be displayed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with indicators assessing the quality of classifications
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
#set spconsist to TRUE to calculate the spatial consistency indicator
#FALSE here to reduce the time during package check
values &lt;- select_parameters(algo = "SFCM", dataset, k = 5, m = seq(2,3,0.1),
    alpha = seq(0,2,0.1), nblistw = Wqueen, spconsist=FALSE)


data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
#set spconsist to TRUE to calculate the spatial consistency indicator
#FALSE here to reduce the time during package check
values &lt;- selectParameters(algo = "SFCM", dataset, k = 5, m = seq(2,3,0.1),
    alpha = seq(0,2,0.1), nblistw = Wqueen, spconsist=FALSE)

</code></pre>

<hr>
<h2 id='select_parameters.mc'>Select parameters for clustering algorithm (multicore)</h2><span id='topic+select_parameters.mc'></span><span id='topic+selectParameters.mc'></span>

<h3>Description</h3>

<p>Function to select the parameters for a clustering algorithm.
This version of the function allows to use a plan defined with the package
future to reduce calculation time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_parameters.mc(
  algo,
  data,
  k,
  m,
  alpha = NA,
  beta = NA,
  nblistw = NULL,
  lag_method = "mean",
  window = NULL,
  spconsist = TRUE,
  classidx = TRUE,
  nrep = 30,
  indices = NULL,
  standardize = TRUE,
  robust = FALSE,
  noise_cluster = FALSE,
  delta = NA,
  maxiter = 500,
  tol = 0.01,
  chunk_size = 5,
  seed = NULL,
  init = "random",
  verbose = TRUE
)

selectParameters.mc(
  algo,
  data,
  k,
  m,
  alpha = NA,
  beta = NA,
  nblistw = NULL,
  lag_method = "mean",
  window = NULL,
  spconsist = TRUE,
  classidx = TRUE,
  nrep = 30,
  indices = NULL,
  standardize = TRUE,
  robust = FALSE,
  noise_cluster = FALSE,
  delta = NA,
  maxiter = 500,
  tol = 0.01,
  chunk_size = 5,
  seed = NULL,
  init = "random",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_parameters.mc_+3A_algo">algo</code></td>
<td>
<p>A string indicating which method to use (FCM, GFCM, SFCM, SGFCM)</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_data">data</code></td>
<td>
<p>A dataframe with numeric columns</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_k">k</code></td>
<td>
<p>A sequence of values for k to test (&gt;=2)</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_m">m</code></td>
<td>
<p>A sequence of values for m to test</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_alpha">alpha</code></td>
<td>
<p>A sequence of values for alpha to test (NULL if not required)</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_beta">beta</code></td>
<td>
<p>A sequence of values for beta to test (NULL if not required)</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_nblistw">nblistw</code></td>
<td>
<p>A list of list.w objects describing the neighbours typically
produced by the spdep package (NULL if not required)</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_lag_method">lag_method</code></td>
<td>
<p>A string indicating if a classical lag must be used
(&quot;mean&quot;) or if a weighted median must be used (&quot;median&quot;). Both can be
tested by specifying a vector : c(&quot;mean&quot;,&quot;median&quot;). When working with rasters,
the string must be parsable to a function like mean, min, max, sum, etc. and will
be applied to all the pixels values in the window designated by the parameter window
and weighted according to the values of this matrix.</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_window">window</code></td>
<td>
<p>A list of windows to use to calculate neighbouring values if
rasters are used.</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_spconsist">spconsist</code></td>
<td>
<p>A boolean indicating if the spatial consistency must be
calculated</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_classidx">classidx</code></td>
<td>
<p>A boolean indicating if the quality of classification
indices must be calculated</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_nrep">nrep</code></td>
<td>
<p>An integer indicating the number of permutation to do to simulate
the random distribution of the spatial inconsistency. Only used if spconsist
is TRUE.</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_indices">indices</code></td>
<td>
<p>A character vector with the names of the indices to calculate, to
evaluate clustering quality. default is :c(&quot;Silhouette.index&quot;, &quot;Partition.entropy&quot;,
&quot;Partition.coeff&quot;, &quot;XieBeni.index&quot;, &quot;FukuyamaSugeno.index&quot;, &quot;Explained.inertia&quot;).
Other available indices are : &quot;DaviesBoulin.index&quot;, &quot;CalinskiHarabasz.index&quot;,
&quot;GD43.index&quot;, &quot;GD53.index&quot; and &quot;Negentropy.index&quot;.</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variable must be centered and
reduce (default = True)</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_robust">robust</code></td>
<td>
<p>A boolean indicating if the &quot;robust&quot; version of the algorithm must be used (see details)</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_noise_cluster">noise_cluster</code></td>
<td>
<p>A boolean indicatong if a noise cluster must be added to the solution (see details)</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_delta">delta</code></td>
<td>
<p>A float giving the distance of the noise cluster to each observation</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iteration</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_chunk_size">chunk_size</code></td>
<td>
<p>The size of a chunk used for multiprocessing. Default is 100.</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_seed">seed</code></td>
<td>
<p>An integer used for random number generation. It ensures that the
start centers will be the same if the same integer is selected.</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centers must be selected. &quot;random&quot;
indicates that random observations are used as centers. &quot;kpp&quot; use a distance based method
resulting in more dispersed centers at the beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="select_parameters.mc_+3A_verbose">verbose</code></td>
<td>
<p>A boolean indicating if a progressbar should be displayed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with indicators assessing the quality of classifications
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
future::plan(future::multisession(workers=2))
#set spconsist to TRUE to calculate the spatial consistency indicator
#FALSE here to reduce the time during package check
values &lt;- select_parameters.mc("SFCM", dataset, k = 5, m = seq(1,2.5,0.1),
    alpha = seq(0,2,0.1), nblistw = Wqueen, spconsist=FALSE)
## make sure any open connections are closed afterward
if (!inherits(future::plan(), "sequential")) future::plan(future::sequential)


data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
future::plan(future::multisession(workers=2))
#set spconsist to TRUE to calculate the spatial consistency indicator
#FALSE here to reduce the time during package check
values &lt;- select_parameters.mc("SFCM", dataset, k = 5, m = seq(1,2.5,0.1),
    alpha = seq(0,2,0.1), nblistw = Wqueen, spconsist=FALSE)


</code></pre>

<hr>
<h2 id='SFCMeans'>SFCMeans</h2><span id='topic+SFCMeans'></span>

<h3>Description</h3>

<p>spatial version of the c-mean algorithm (SFCMeans, FCM_S1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SFCMeans(
  data,
  nblistw = NULL,
  k,
  m,
  alpha,
  lag_method = "mean",
  window = NULL,
  noise_cluster = FALSE,
  delta = NULL,
  maxiter = 500,
  tol = 0.01,
  standardize = TRUE,
  robust = FALSE,
  verbose = TRUE,
  init = "random",
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SFCMeans_+3A_data">data</code></td>
<td>
<p>A dataframe with only numerical variables. Can also be a list of
rasters (produced by the package raster). In that case, each raster is
considered as a variable and each pixel is an observation. Pixels with NA
values are not used during the classification.</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input.</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_k">k</code></td>
<td>
<p>An integer describing the number of cluster to find</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_m">m</code></td>
<td>
<p>A float for the fuzziness degree</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_alpha">alpha</code></td>
<td>
<p>A float representing the weight of the space in the analysis (0
is a typical fuzzy-c-mean algorithm, 1 is balanced between the two
dimensions, 2 is twice the weight for space)</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_lag_method">lag_method</code></td>
<td>
<p>A string indicating if a classical lag must be used
(&quot;mean&quot;) or if a weighted median must be used (&quot;median&quot;). When working with rasters, a function
can be given (or a string which will be parsed). It will be applied to all the pixels values
in the matrix designated by the parameter window and weighted according to the values of this matrix.
Typically, to obtain an average of the pixels in a 3x3 matrix one could use the function sum (or &quot;sum&quot;)
and set the window as: window &lt;- matrix(1/9,nrow = 3, ncol = 3). There is one special case when working 
with rasters: one can specify &quot;nl&quot; (standing for non-local) which calculated a lagged version of the 
input rasters, using the inverse of the euclidean distance as spatial weights (see the section Advanced 
examples in the vignette introduction for more details).</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_window">window</code></td>
<td>
<p>If data is a list of rasters, then a window must be specified instead of
a list.w object. It will be used to calculate a focal function on each raster. The
window must be a square numeric matrix with odd dimensions (such 3x3). The values in
the matrix indicate the weight to give to each pixel and the centre of the matrix is
the centre of the focal function.</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_noise_cluster">noise_cluster</code></td>
<td>
<p>A boolean indicatong if a noise cluster must be added to the solution (see details)</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_delta">delta</code></td>
<td>
<p>A float giving the distance of the noise cluster to each observation</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iterations</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variables must be centred and
reduced (default = True)</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_robust">robust</code></td>
<td>
<p>A boolean indicating if the &quot;robust&quot; version of the algorithm must be used (see details)</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_verbose">verbose</code></td>
<td>
<p>A boolean to specify if the progress should be printed</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centres must be selected. &quot;random&quot;
indicates that random observations are used as centres. &quot;kpp&quot; use a distance-based method
resulting in more dispersed centres at the beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="SFCMeans_+3A_seed">seed</code></td>
<td>
<p>An integer used for random number generation. It ensures that the
starting centres will be the same if the same value is selected.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation is based on the following article : <a href="https://doi.org/10.1016/j.patcog.2006.07.011">doi:10.1016/j.patcog.2006.07.011</a>.<br />
</p>
<p>the membership matrix (u) is calculated as follow <br />
</p>
<p style="text-align: center;"><code class="reqn">u_{ik} = \frac{(||x_{k} - v{_i}||^2 + \alpha||\bar{x_{k}} - v{_i}||^2)^{(-1/(m-1))}}{\sum_{j=1}^c(||x_{k} - v{_j}||^2 + \alpha||\bar{x_{k}} - v{_j}||^2)^{(-1/(m-1))}}</code>
</p>

<p>the centers of the groups are updated with the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{i} = \frac{\sum_{k=1}^N u_{ik}^m(x_{k} + \alpha\bar{x_{k}})}{(1 + \alpha)\sum_{k=1}^N u_{ik}^m}</code>
</p>

<p>with
</p>

<ul>
<li><p> vi the center of the group vi
</p>
</li>
<li><p> xk the data point k
</p>
</li>
<li><p> xk_bar the spatially lagged data point k
</p>
</li></ul>



<h3>Value</h3>

<p>An S3 object of class FCMres with the following slots
</p>

<ul>
<li><p> Centers: a dataframe describing the final centers of the groups
</p>
</li>
<li><p> Belongings: the final membership matrix
</p>
</li>
<li><p> Groups: a vector with the names of the most likely group for each observation
</p>
</li>
<li><p> Data: the dataset used to perform the clustering (might be standardized)
</p>
</li>
<li><p> isRaster: TRUE if rasters were used as input data, FALSE otherwise
</p>
</li>
<li><p> k: the number of groups
</p>
</li>
<li><p> m: the fuzyness degree
</p>
</li>
<li><p> alpha: the spatial weighting parameter (if SFCM or SGFCM)
</p>
</li>
<li><p> beta: beta parameter for generalized version of FCM (GFCM or SGFCM)
</p>
</li>
<li><p> algo: the name of the algorithm used
</p>
</li>
<li><p> rasters: a list of rasters with membership values and the most likely group (if rasters were used)
</p>
</li>
<li><p> missing: a boolean vector indicating raster cell with data (TRUE) and with NA (FALSE) (if rasters were used)
</p>
</li>
<li><p> maxiter: the maximum number of iterations used
</p>
</li>
<li><p> tol: the convergence criterio
</p>
</li>
<li><p> lag_method: the lag function used (if SFCM or SGFCM)
</p>
</li>
<li><p> nblistw: the neighbours list used (if vector data were used for SFCM or SGFCM)
</p>
</li>
<li><p> window: the window used (if raster data were used for SFCM or SGFCM)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
</code></pre>

<hr>
<h2 id='SGFCMeans'>SGFCMeans</h2><span id='topic+SGFCMeans'></span>

<h3>Description</h3>

<p>spatial version of the generalized c-mean algorithm (SGFCMeans)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SGFCMeans(
  data,
  nblistw = NULL,
  k,
  m,
  alpha,
  beta,
  lag_method = "mean",
  window = NULL,
  maxiter = 500,
  tol = 0.01,
  standardize = TRUE,
  robust = FALSE,
  noise_cluster = FALSE,
  delta = NULL,
  verbose = TRUE,
  init = "random",
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SGFCMeans_+3A_data">data</code></td>
<td>
<p>A dataframe with only numerical variables. Can also be a list of
rasters (produced by the package raster). In that case, each raster is
considered as a variable and each pixel is an observation. Pixels with NA
values are not used during the classification.</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input.</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_k">k</code></td>
<td>
<p>An integer describing the number of cluster to find</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_m">m</code></td>
<td>
<p>A float for the fuzziness degree</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_alpha">alpha</code></td>
<td>
<p>A float representing the weight of the space in the analysis (0
is a typical fuzzy-c-mean algorithm, 1 is balanced between the two
dimensions, 2 is twice the weight for space)</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_beta">beta</code></td>
<td>
<p>A float for the beta parameter (control speed convergence and classification crispness)</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_lag_method">lag_method</code></td>
<td>
<p>A string indicating if a classical lag must be used
(&quot;mean&quot;) or if a weighted median must be used (&quot;median&quot;). When working with rasters, a function
can be given (or a string which will be parsed). It will be applied to all the pixels values
in the matrix designated by the parameter window and weighted according to the values of this matrix.
Typically, to obtain an average of the pixels in a 3x3 matrix one could use the function sum (or &quot;sum&quot;)
and set the window as: window &lt;- matrix(1/9,nrow = 3, ncol = 3). There is one special case when working 
with rasters: one can specify &quot;nl&quot; (standing for non-local) which calculated a lagged version of the 
input rasters, using the inverse of the euclidean distance as spatial weights (see the section Advanced 
examples in the vignette introduction for more details).</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_window">window</code></td>
<td>
<p>If data is a list of rasters, then a window must be specified instead of
a list.w object. It will be used to calculate a focal function on each raster. The
window must be a square numeric matrix with odd dimensions (such 3x3). The values in
the matrix indicate the weight to give to each pixel and the centre of the matrix is
the centre of the focal function.</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer for the maximum number of iterations</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_tol">tol</code></td>
<td>
<p>The tolerance criterion used in the evaluateMatrices function for
convergence assessment</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_standardize">standardize</code></td>
<td>
<p>A boolean to specify if the variables must be centred and
reduced (default = True)</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_robust">robust</code></td>
<td>
<p>A boolean indicating if the &quot;robust&quot; version of the algorithm must be used (see details)</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_noise_cluster">noise_cluster</code></td>
<td>
<p>A boolean indicatong if a noise cluster must be added to the solution (see details)</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_delta">delta</code></td>
<td>
<p>A float giving the distance of the noise cluster to each observation</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_verbose">verbose</code></td>
<td>
<p>A boolean to specify if the progress should be printed</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_init">init</code></td>
<td>
<p>A string indicating how the initial centres must be selected. &quot;random&quot;
indicates that random observations are used as centres. &quot;kpp&quot; use a distance-based method
resulting in more dispersed centres at the beginning. Both of them are heuristic.</p>
</td></tr>
<tr><td><code id="SGFCMeans_+3A_seed">seed</code></td>
<td>
<p>An integer used for random number generation. It ensures that the
starting centres will be the same if the same value is selected.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation is based on the following article : <a href="https://doi.org/10.1016/j.dsp.2012.09.016">doi:10.1016/j.dsp.2012.09.016</a>.<br />
</p>
<p>the membership matrix (u) is calculated as follow <br />
</p>
<p style="text-align: center;"><code class="reqn">u_{ik} = \frac{(||x_{k} - v{_i}||^2 -b_k + \alpha||\bar{x_{k}} - v{_i}||^2)^{(-1/(m-1))}}{\sum_{j=1}^c(||x_{k} - v{_j}||^2 -b_k + \alpha||\bar{x_{k}} - v{_j}||^2)^{(-1/(m-1))}}</code>
</p>

<p>the centers of the groups are updated with the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{i} = \frac{\sum_{k=1}^N u_{ik}^m(x_{k} + \alpha\bar{x_{k}})}{(1 + \alpha)\sum_{k=1}^N u_{ik}^m}</code>
</p>

<p>with
</p>

<ul>
<li><p> vi the center of the group vi
</p>
</li>
<li><p> xk the data point k
</p>
</li>
<li><p> xk_bar the spatially lagged data point k
</p>
<p style="text-align: center;"><code class="reqn">b_k = \beta \times min(||x_{k} - v||)</code>
</p>

</li></ul>



<h3>Value</h3>

<p>An S3 object of class FCMres with the following slots
</p>

<ul>
<li><p> Centers: a dataframe describing the final centers of the groups
</p>
</li>
<li><p> Belongings: the final membership matrix
</p>
</li>
<li><p> Groups: a vector with the names of the most likely group for each observation
</p>
</li>
<li><p> Data: the dataset used to perform the clustering (might be standardized)
</p>
</li>
<li><p> isRaster: TRUE if rasters were used as input data, FALSE otherwise
</p>
</li>
<li><p> k: the number of groups
</p>
</li>
<li><p> m: the fuzyness degree
</p>
</li>
<li><p> alpha: the spatial weighting parameter (if SFCM or SGFCM)
</p>
</li>
<li><p> beta: beta parameter for generalized version of FCM (GFCM or SGFCM)
</p>
</li>
<li><p> algo: the name of the algorithm used
</p>
</li>
<li><p> rasters: a list of rasters with membership values and the most likely group (if rasters were used)
</p>
</li>
<li><p> missing: a boolean vector indicating raster cell with data (TRUE) and with NA (FALSE) (if rasters were used)
</p>
</li>
<li><p> maxiter: the maximum number of iterations used
</p>
</li>
<li><p> tol: the convergence criterio
</p>
</li>
<li><p> lag_method: the lag function used (if SFCM or SGFCM)
</p>
</li>
<li><p> nblistw: the neighbours list used (if vector data were used for SFCM or SGFCM)
</p>
</li>
<li><p> window: the window used (if raster data were used for SFCM or SGFCM)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SGFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, beta = 0.5, standardize = TRUE)
</code></pre>

<hr>
<h2 id='sp_clust_explorer'>Classification result explorer</h2><span id='topic+sp_clust_explorer'></span>

<h3>Description</h3>

<p>Start a local Shiny App to explore the results of a classification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sp_clust_explorer(
  object = NULL,
  spatial = NULL,
  membership = NULL,
  dataset = NULL,
  port = 8100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sp_clust_explorer_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans</p>
</td></tr>
<tr><td><code id="sp_clust_explorer_+3A_spatial">spatial</code></td>
<td>
<p>A feature collection (sf) used to map the observations. Only needed if object was not created
from rasters.</p>
</td></tr>
<tr><td><code id="sp_clust_explorer_+3A_membership">membership</code></td>
<td>
<p>A matrix or a dataframe representing the membership values
obtained for each observation. If NULL, then the matrix is extracted from
object.</p>
</td></tr>
<tr><td><code id="sp_clust_explorer_+3A_dataset">dataset</code></td>
<td>
<p>A dataframe or matrix representing the data used for the
classification. If NULL, then the matrix is extracted from object.</p>
</td></tr>
<tr><td><code id="sp_clust_explorer_+3A_port">port</code></td>
<td>
<p>An integer of length 4 indicating the port on which to start the
Shiny app. Default is 8100</p>
</td></tr>
<tr><td><code id="sp_clust_explorer_+3A_...">...</code></td>
<td>
<p>Other parameters passed to the function runApp</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LyonIris)

#selecting the columns for the analysis
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14",
                   "Pct_65","Pct_Img","TxChom1564","Pct_brevet","NivVieMed")

#rescaling the columns
Data &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
for (Col in names(Data)){
  Data[[Col]] &lt;- as.numeric(scale(Data[[Col]]))
}

Cmean &lt;- CMeans(Data,4,1.5,500,standardize = FALSE, seed = 456, tol = 0.00001, verbose = FALSE)

sp_clust_explorer(Cmean, LyonIris)

## End(Not run)
</code></pre>

<hr>
<h2 id='spatialDiag'>Spatial diagnostic</h2><span id='topic+spatialDiag'></span>

<h3>Description</h3>

<p>Utility function to facilitate the spatial diagnostic of a classification
</p>
<p>Calculate the following indicators: Moran I index (spdep::moranI) for each
column of the membership matrix, Join count test (spdep::joincount.multi) for
the most likely groups of each datapoint, Spatial consistency index (see
function spConsistency) and the Elsa statistic (see function calcElsa). Note
that if the FCMres object given was constructed with rasters, the joincount
statistic is not calculated and no p-values are provided for the Moran I
indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatialDiag(
  object,
  nblistw = NULL,
  window = NULL,
  undecided = NULL,
  matdist = NULL,
  nrep = 50
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spatialDiag_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans. Can also be a simple membership matrix.</p>
</td></tr>
<tr><td><code id="spatialDiag_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input. Can also be NULL if object is a FCMres object.</p>
</td></tr>
<tr><td><code id="spatialDiag_+3A_window">window</code></td>
<td>
<p>If rasters were used for the classification, the window must be
specified instead of a list.w object. Can also be NULL if object is a FCMres object.</p>
</td></tr>
<tr><td><code id="spatialDiag_+3A_undecided">undecided</code></td>
<td>
<p>A float giving the threslhod to detect undecided observations. An
observation is undecided if its maximum membership value is bellow this float. If
null, no observations are undecided.</p>
</td></tr>
<tr><td><code id="spatialDiag_+3A_matdist">matdist</code></td>
<td>
<p>A matrix representing the dissimilarity between the clusters. The matrix must
be squared and the diagonal must be filled with zeros.</p>
</td></tr>
<tr><td><code id="spatialDiag_+3A_nrep">nrep</code></td>
<td>
<p>An integer indicating the number of permutation to do to simulate
the random distribution of the spatial inconsistency</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list with :
</p>

<ul>
<li><p> MoranValues : the moran I values for each column of the membership
matrix (spdep::MoranI)
</p>
</li>
<li><p> JoinCounts : the result of the join count test calculated with
the most likely group for each datapoint (spdep::joincount.multi)
</p>
</li>
<li><p> SpConsist : the mean value of the spatial consistency index
(the lower, the better, see ?spConsistency for details)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
spatialDiag(result, undecided=0.45, nrep=30)
</code></pre>

<hr>
<h2 id='spConsistency'>Spatial consistency index</h2><span id='topic+spConsistency'></span>

<h3>Description</h3>

<p>Calculate a spatial consistency index
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spConsistency(
  object,
  nblistw = NULL,
  window = NULL,
  nrep = 999,
  adj = FALSE,
  mindist = 1e-11
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spConsistency_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans,
GCMeans, SFCMeans, SGFCMeans. Can also be a simple membership matrix.</p>
</td></tr>
<tr><td><code id="spConsistency_+3A_nblistw">nblistw</code></td>
<td>
<p>A list.w object describing the neighbours typically produced
by the spdep package. Required if data is a dataframe, see the parameter window
if you use a list of rasters as input. Can also be NULL if object is a FCMres object.</p>
</td></tr>
<tr><td><code id="spConsistency_+3A_window">window</code></td>
<td>
<p>if rasters were used for the classification, the window must be
specified instead of a list.w object. Can also be NULL if object is a FCMres object.</p>
</td></tr>
<tr><td><code id="spConsistency_+3A_nrep">nrep</code></td>
<td>
<p>An integer indicating the number of permutation to do to simulate
spatial randomness. Note that if rasters are used, each permutation can be very long.</p>
</td></tr>
<tr><td><code id="spConsistency_+3A_adj">adj</code></td>
<td>
<p>A boolean indicating if the adjusted version of the indicator must be
calculated when working with rasters (globally standardized). When working with vectors, see the function
adjustSpatialWeights to modify the list.w object.</p>
</td></tr>
<tr><td><code id="spConsistency_+3A_mindist">mindist</code></td>
<td>
<p>When adj is true, a minimum value for distance between two observations. If two
neighbours have exactly the same values, then the euclidean distance between
them is 0, leading to an infinite spatial weight. In that case, the minimum
distance is used instead of 0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This index is experimental, it aims to measure how much a clustering solution
is spatially consistent. A classification is spatially inconsistent if
neighbouring observation do not belong to the same group. See detail for
a description of its calculation
</p>
<p>The total spatial inconsistency (*Scr*) is calculated as follow
</p>
<p style="text-align: center;"><code class="reqn">isp = \sum_{i}\sum_{j}\sum_{k} (u_{ik} - u_{jk})^{2} * W_{ij}</code>
</p>

<p>With U the membership matrix, i an observation, k the neighbours of i and W
the spatial weight matrix This represents the total spatial inconsistency of
the solution (true inconsistency) We propose to compare this total with
simulated values obtained by permutations (simulated inconsistency). The
values obtained by permutation are an approximation of the spatial
inconsistency obtained in a random context Ratios between the true
inconsistency and simulated inconsistencies are calculated A value of 0
depict a situation where all observations are identical to their neighbours
A value of 1 depict a situation where all observations are as much different
as their neighbours that what randomness can produce A classification
solution able to reduce this index has a better spatial consistency
</p>


<h3>Value</h3>

<p>A named list with
</p>

<ul>
<li><p> Mean : the mean of the spatial consistency index
</p>
</li>
<li><p> prt05 : the 5th percentile of the spatial consistency index
</p>
</li>
<li><p> prt95 : the 95th percentile of the spatial consistency index
</p>
</li>
<li><p> samples : all the value of the spatial consistency index
</p>
</li>
<li><p> sum_diff : the total sum of squarred difference between observations and their neighbours
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
# NOTE : more replications are needed for proper inference
spConsistency(result$Belongings, nblistw = Wqueen, nrep=25)
</code></pre>

<hr>
<h2 id='spiderPlots'>Spider chart</h2><span id='topic+spiderPlots'></span>

<h3>Description</h3>

<p>Display spider charts to quickly compare values between groups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spiderPlots(data, belongmatrix, chartcolors = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spiderPlots_+3A_data">data</code></td>
<td>
<p>A dataframe with numeric columns</p>
</td></tr>
<tr><td><code id="spiderPlots_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix</p>
</td></tr>
<tr><td><code id="spiderPlots_+3A_chartcolors">chartcolors</code></td>
<td>
<p>A vector of color names used for the spider plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each group, the weighted mean of each variable in data is calculated
based on the probability of belonging to this group of each observation.
On the chart the exterior ring represents the maximum value obtained for
all the groups and the interior ring the minimum. The groups are located
between these two limits in a linear way.
</p>


<h3>Value</h3>

<p>NULL, the plots are displayed directly by the function (see fmsb::radarchart)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
spiderPlots(dataset,result$Belongings)
</code></pre>

<hr>
<h2 id='sqrt_matrix_bycol'>element wise square root of a matrix by column</h2><span id='topic+sqrt_matrix_bycol'></span>

<h3>Description</h3>

<p>element wise square root of a matrix by column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sqrt_matrix_bycol(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sqrt_matrix_bycol_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix
</p>

<hr>
<h2 id='standardizer'>Standardizing helper</h2><span id='topic+standardizer'></span>

<h3>Description</h3>

<p>Create functions to standardize and unstandardize data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardizer(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardizer_+3A_x">x</code></td>
<td>
<p>a numeric vector or a data.frame with only numeric columns.
Non numeric columns are dropped.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If x was a vector, the function returns a list containing two
functions : scale and unscale. The first one is an equivalent of the
classical function scale(x, center = TRUE, scale = TRUE). The second
can be used to reverse the scaling and get back original units. If x
was a data.frame, the same pair of functions is returned inside of
a list for each numeric column.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
LyonScales &lt;- standardizer(sf::st_drop_geometry(LyonIris))
</code></pre>

<hr>
<h2 id='sub_matrices_bycol'>substraction of two matrices by column</h2><span id='topic+sub_matrices_bycol'></span>

<h3>Description</h3>

<p>substraction of two matrices by column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sub_matrices_bycol(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sub_matrices_bycol_+3A_x">x</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="sub_matrices_bycol_+3A_y">y</code></td>
<td>
<p>a matrix with the same dimensions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix
</p>

<hr>
<h2 id='summarizeClusters'>Descriptive statistics by group</h2><span id='topic+summarizeClusters'></span>

<h3>Description</h3>

<p>Calculate some descriptive statistics of each group
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarizeClusters(data, belongmatrix, weighted = TRUE, dec = 3, silent = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarizeClusters_+3A_data">data</code></td>
<td>
<p>The original dataframe used for the classification</p>
</td></tr>
<tr><td><code id="summarizeClusters_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix</p>
</td></tr>
<tr><td><code id="summarizeClusters_+3A_weighted">weighted</code></td>
<td>
<p>A boolean indicating if the summary statistics must use the
membership matrix columns as weights (TRUE) or simply assign each
observation to its most likely cluster and compute the statistics on each
subset (FALSE)</p>
</td></tr>
<tr><td><code id="summarizeClusters_+3A_dec">dec</code></td>
<td>
<p>An integer indicating the number of digits to keep when rounding
(default is 3)</p>
</td></tr>
<tr><td><code id="summarizeClusters_+3A_silent">silent</code></td>
<td>
<p>A boolean indicating if the results must be printed or silently returned</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length k (the number of group). Each element of the list is
a dataframe with summary statistics for the variables of data for each
group
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
summarizeClusters(dataset, result$Belongings)
</code></pre>

<hr>
<h2 id='summary.FCMres'>Summary method for FCMres</h2><span id='topic+summary.FCMres'></span>

<h3>Description</h3>

<p>Calculate some descriptive statistics of each group of a
FCMres object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FCMres'
summary(object, data = NULL, weighted = TRUE, dec = 3, silent = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.FCMres_+3A_object">object</code></td>
<td>
<p>A FCMres object, typically obtained from functions CMeans, GCMeans, SFCMeans, SGFCMeans</p>
</td></tr>
<tr><td><code id="summary.FCMres_+3A_data">data</code></td>
<td>
<p>A dataframe to use for the summary statistics instead of obj$data</p>
</td></tr>
<tr><td><code id="summary.FCMres_+3A_weighted">weighted</code></td>
<td>
<p>A boolean indicating if the summary statistics must use the
membership matrix columns as weights (TRUE) or simply assign each
observation to its most likely cluster and compute the statistics on each
subset (FALSE)</p>
</td></tr>
<tr><td><code id="summary.FCMres_+3A_dec">dec</code></td>
<td>
<p>An integer indicating the number of digits to keep when rounding
(default is 3)</p>
</td></tr>
<tr><td><code id="summary.FCMres_+3A_silent">silent</code></td>
<td>
<p>A boolean indicating if the results must be printed or silently returned</p>
</td></tr>
<tr><td><code id="summary.FCMres_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length k (the number of group). Each element of the list is
a dataframe with summary statistics for the variables of data for each
group
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
summary(result)
</code></pre>

<hr>
<h2 id='test_inferior_mat'>create a logical matrix with inferior comparison</h2><span id='topic+test_inferior_mat'></span>

<h3>Description</h3>

<p>create a logical matrix with inferior comparison
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_inferior_mat(mat, t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_inferior_mat_+3A_mat">mat</code></td>
<td>
<p>a matrix</p>
</td></tr>
<tr><td><code id="test_inferior_mat_+3A_t">t</code></td>
<td>
<p>a double to compare</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a LogicalMatrix
</p>

<hr>
<h2 id='uncertaintyMap'>Uncertainty map</h2><span id='topic+uncertaintyMap'></span>

<h3>Description</h3>

<p>Return a map to visualize membership matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uncertaintyMap(
  geodata,
  belongmatrix,
  njit = 150,
  radius = NULL,
  colors = NULL,
  pt_size = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="uncertaintyMap_+3A_geodata">geodata</code></td>
<td>
<p>An object of class feature collection from sf ordered
like the original data used for the clustering.</p>
</td></tr>
<tr><td><code id="uncertaintyMap_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>A membership matrix</p>
</td></tr>
<tr><td><code id="uncertaintyMap_+3A_njit">njit</code></td>
<td>
<p>The number of points to map on each feature.</p>
</td></tr>
<tr><td><code id="uncertaintyMap_+3A_radius">radius</code></td>
<td>
<p>When mapping points, the radius indicates how far random
points will be plotted around the original features.</p>
</td></tr>
<tr><td><code id="uncertaintyMap_+3A_colors">colors</code></td>
<td>
<p>A vector of colors to use for the groups.</p>
</td></tr>
<tr><td><code id="uncertaintyMap_+3A_pt_size">pt_size</code></td>
<td>
<p>A float giving the size of the random points on the final
map (default is 0.05)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function maps the membership matrix by plotting
random points in polygons, along lines or around points representing the
original observations. Each cluster is associated with a color and each
random point has a probability to be of that color equal to the membership
value of the feature it belongs itself. Thus, it is possible to
visualize regions with uncertainty and to identify the strongest clusters.
</p>


<h3>Value</h3>

<p>a map created with tmap
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
  "TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
uncertaintyMap(LyonIris, result$Belongings)

## End(Not run)
</code></pre>

<hr>
<h2 id='undecidedUnits'>Undecided observations</h2><span id='topic+undecidedUnits'></span>

<h3>Description</h3>

<p>Identify the observation for which the classification is uncertain
</p>


<h3>Usage</h3>

<pre><code class='language-R'>undecidedUnits(belongmatrix, tol = 0.1, out = "character")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="undecidedUnits_+3A_belongmatrix">belongmatrix</code></td>
<td>
<p>The membership matrix obtained at the end of the algorithm</p>
</td></tr>
<tr><td><code id="undecidedUnits_+3A_tol">tol</code></td>
<td>
<p>A float indicating the minimum required level of membership to be
not considered as undecided</p>
</td></tr>
<tr><td><code id="undecidedUnits_+3A_out">out</code></td>
<td>
<p>The format of the output vector. Default is &quot;character&quot;. If
&quot;numeric&quot;, then the undecided units are set to -1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector indicating the most likely group for each observation or
&quot;Undecided&quot; if the maximum probability for the observation does not reach
the value of the tol parameter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometry(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
undecidedUnits(result$Belongings, tol = 0.45)
</code></pre>

<hr>
<h2 id='vecmin'>minimum of a vector</h2><span id='topic+vecmin'></span><span id='topic+vecmax'></span>

<h3>Description</h3>

<p>minimum of a vector
</p>
<p>maximum of a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vecmin(x)

vecmax(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vecmin_+3A_x">x</code></td>
<td>
<p>a NumericVector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a double
</p>
<p>a double
</p>

<hr>
<h2 id='vector_out_prod'>create a matrix by multiplying a vector by its elements one by one as rows</h2><span id='topic+vector_out_prod'></span>

<h3>Description</h3>

<p>create a matrix by multiplying a vector by its elements one by one as rows
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vector_out_prod(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vector_out_prod_+3A_x">x</code></td>
<td>
<p>a vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a NumericMatrix
</p>

<hr>
<h2 id='violinPlots'>Violin plots</h2><span id='topic+violinPlots'></span>

<h3>Description</h3>

<p>Return violin plots to compare the distribution of each variable for each
group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>violinPlots(data, groups)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="violinPlots_+3A_data">data</code></td>
<td>
<p>A dataframe with numeric columns</p>
</td></tr>
<tr><td><code id="violinPlots_+3A_groups">groups</code></td>
<td>
<p>A vector indicating the group of each observation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of plots created with ggplot2
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LyonIris)
AnalysisFields &lt;-c("Lden","NO2","PM25","VegHautPrt","Pct0_14","Pct_65","Pct_Img",
"TxChom1564","Pct_brevet","NivVieMed")
dataset &lt;- sf::st_drop_geometrie(LyonIris[AnalysisFields])
queen &lt;- spdep::poly2nb(LyonIris,queen=TRUE)
Wqueen &lt;- spdep::nb2listw(queen,style="W")
result &lt;- SFCMeans(dataset, Wqueen,k = 5, m = 1.5, alpha = 1.5, standardize = TRUE)
violinPlots(dataset, result$Groups)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
