<!DOCTYPE html><html lang="en"><head><title>Help for package logisticPCA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {logisticPCA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#logisticPCA-package'><p>logisticPCA-package</p></a></li>
<li><a href='#convexLogisticPCA'><p>Convex Logistic Principal Component Analysis</p></a></li>
<li><a href='#cv.clpca'><p>CV for convex logistic PCA</p></a></li>
<li><a href='#cv.lpca'><p>CV for logistic PCA</p></a></li>
<li><a href='#cv.lsvd'><p>CV for logistic SVD</p></a></li>
<li><a href='#fitted.lpca'><p>Fitted values using logistic PCA</p></a></li>
<li><a href='#fitted.lsvd'><p>Fitted values using logistic SVD</p></a></li>
<li><a href='#house_votes84'><p>United States Congressional Voting Records 1984</p></a></li>
<li><a href='#inv.logit.mat'><p>Inverse logit for matrices</p></a></li>
<li><a href='#log_like_Bernoulli'><p>Bernoulli Log Likelihood</p></a></li>
<li><a href='#logisticPCA'><p>Logistic Principal Component Analysis</p></a></li>
<li><a href='#logisticSVD'><p>Logistic Singular Value Decomposition</p></a></li>
<li><a href='#plot.clpca'><p>Plot convex logistic PCA</p></a></li>
<li><a href='#plot.cv.lpca'><p>Plot CV for logistic PCA</p></a></li>
<li><a href='#plot.lpca'><p>Plot logistic PCA</p></a></li>
<li><a href='#plot.lsvd'><p>Plot logistic SVD</p></a></li>
<li><a href='#predict.clpca'><p>Predict Convex Logistic PCA scores or reconstruction on new data</p></a></li>
<li><a href='#predict.lpca'><p>Predict Logistic PCA scores or reconstruction on new data</p></a></li>
<li><a href='#predict.lsvd'><p>Predict Logistic SVD left singular values or reconstruction on new data</p></a></li>
<li><a href='#project.Fantope'><p>Project onto the Fantope</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Binary Dimensionality Reduction</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-03-13</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrew J. Landgraf</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrew J. Landgraf &lt;andland@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Dimensionality reduction techniques for binary data including
    logistic PCA.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/andland/logisticPCA">https://github.com/andland/logisticPCA</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rARPACK (&ge; 0.10-0), testthat (&ge; 0.11.0), knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-03-14 01:30:10 UTC; andrew</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-03-14 07:54:24</td>
</tr>
</table>
<hr>
<h2 id='logisticPCA-package'>logisticPCA-package</h2><span id='topic+logisticPCA-package'></span>

<h3>Description</h3>

<p>Dimension reduction techniques for binary data including logistic PCA
</p>


<h3>Author(s)</h3>

<p>Andrew J. Landgraf
</p>

<hr>
<h2 id='convexLogisticPCA'>Convex Logistic Principal Component Analysis</h2><span id='topic+convexLogisticPCA'></span>

<h3>Description</h3>

<p>Dimensionality reduction for binary data by extending Pearson's
PCA formulation to minimize Binomial deviance. The convex relaxation
to projection matrices, the Fantope, is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convexLogisticPCA(x, k = 2, m = 4, quiet = TRUE, partial_decomp = FALSE,
  max_iters = 1000, conv_criteria = 1e-06, random_start = FALSE, start_H,
  mu, main_effects = TRUE, ss_factor = 4, weights, M)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convexLogisticPCA_+3A_x">x</code></td>
<td>
<p>matrix with all binary entries</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_k">k</code></td>
<td>
<p>number of principal components to return</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_m">m</code></td>
<td>
<p>value to approximate the saturated model</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_quiet">quiet</code></td>
<td>
<p>logical; whether the calculation should give feedback</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_partial_decomp">partial_decomp</code></td>
<td>
<p>logical; if <code>TRUE</code>, the function uses the rARPACK package
to quickly initialize <code>H</code> when <code>ncol(x)</code> is large and <code>k</code> is small</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_max_iters">max_iters</code></td>
<td>
<p>number of maximum iterations</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_conv_criteria">conv_criteria</code></td>
<td>
<p>convergence criteria. The difference between average deviance
in successive iterations</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_random_start">random_start</code></td>
<td>
<p>logical; whether to randomly inititalize the parameters. If <code>FALSE</code>,
function will use an eigen-decomposition as starting value</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_start_h">start_H</code></td>
<td>
<p>starting value for the Fantope matrix</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_mu">mu</code></td>
<td>
<p>main effects vector. Only used if <code>main_effects = TRUE</code></p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_main_effects">main_effects</code></td>
<td>
<p>logical; whether to include main effects in the model</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_ss_factor">ss_factor</code></td>
<td>
<p>step size multiplier. Amount by which to multiply the step size. Quadratic
convergence rate can be proven for <code>ss_factor = 1</code>, but I have found higher values
sometimes work better. The default is <code>ss_factor = 4</code>.
If it is not converging, try <code>ss_factor = 1</code>.</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_weights">weights</code></td>
<td>
<p>an optional matrix of the same size as the <code>x</code> with non-negative weights</p>
</td></tr>
<tr><td><code id="convexLogisticPCA_+3A_m">M</code></td>
<td>
<p>depricated. Use <code>m</code> instead</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>clpca</code> which is a list with the
following components:
</p>
<table role = "presentation">
<tr><td><code>mu</code></td>
<td>
<p>the main effects</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>a rank <code>k</code> Fantope matrix</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>a <code>ceiling(k)</code>-dimentional orthonormal matrix with the loadings</p>
</td></tr>
<tr><td><code>PCs</code></td>
<td>
<p>the princial component scores</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>the parameter inputed</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>
<p>number of iterations required for convergence</p>
</td></tr>
<tr><td><code>loss_trace</code></td>
<td>
<p>the trace of the average negative log likelihood using the Fantope matrix</p>
</td></tr>
<tr><td><code>proj_loss_trace</code></td>
<td>
<p>the trace of the average negative log likelihood using the projection matrix</p>
</td></tr>
<tr><td><code>prop_deviance_expl</code></td>
<td>
<p>the proportion of deviance explained by this model.
If <code>main_effects = TRUE</code>, the null model is just the main effects, otherwise
the null model estimates 0 for all natural parameters.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Landgraf, A.J. &amp; Lee, Y., 2015. Dimensionality reduction for binary data through 
the projection of natural parameters. arXiv preprint arXiv:1510.06112.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run convex logistic PCA on it
clpca = convexLogisticPCA(mat, k = 1, m = 4)
</code></pre>

<hr>
<h2 id='cv.clpca'>CV for convex logistic PCA</h2><span id='topic+cv.clpca'></span>

<h3>Description</h3>

<p>Run cross validation on dimension and <code>m</code> for convex logistic PCA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.clpca(x, ks, ms = seq(2, 10, by = 2), folds = 5, quiet = TRUE, Ms, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.clpca_+3A_x">x</code></td>
<td>
<p>matrix with all binary entries</p>
</td></tr>
<tr><td><code id="cv.clpca_+3A_ks">ks</code></td>
<td>
<p>the different dimensions <code>k</code> to try</p>
</td></tr>
<tr><td><code id="cv.clpca_+3A_ms">ms</code></td>
<td>
<p>the different approximations to the saturated model <code>m</code> to try</p>
</td></tr>
<tr><td><code id="cv.clpca_+3A_folds">folds</code></td>
<td>
<p>if <code>folds</code> is a scalar, then it is the number of folds. If
it is a vector, it should be the same length as the number of rows in <code>x</code></p>
</td></tr>
<tr><td><code id="cv.clpca_+3A_quiet">quiet</code></td>
<td>
<p>logical; whether the function should display progress</p>
</td></tr>
<tr><td><code id="cv.clpca_+3A_ms">Ms</code></td>
<td>
<p>depricated. Use <code>ms</code> instead</p>
</td></tr>
<tr><td><code id="cv.clpca_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to convexLogisticPCA</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of the CV negative log likelihood with <code>k</code> in rows and
<code>m</code> in columns
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

## Not run: 
negloglikes = cv.clpca(mat, ks = 1:9, ms = 3:6)
plot(negloglikes)

## End(Not run)
</code></pre>

<hr>
<h2 id='cv.lpca'>CV for logistic PCA</h2><span id='topic+cv.lpca'></span>

<h3>Description</h3>

<p>Run cross validation on dimension and <code>m</code> for logistic PCA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.lpca(x, ks, ms = seq(2, 10, by = 2), folds = 5, quiet = TRUE, Ms, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.lpca_+3A_x">x</code></td>
<td>
<p>matrix with all binary entries</p>
</td></tr>
<tr><td><code id="cv.lpca_+3A_ks">ks</code></td>
<td>
<p>the different dimensions <code>k</code> to try</p>
</td></tr>
<tr><td><code id="cv.lpca_+3A_ms">ms</code></td>
<td>
<p>the different approximations to the saturated model <code>m</code> to try</p>
</td></tr>
<tr><td><code id="cv.lpca_+3A_folds">folds</code></td>
<td>
<p>if <code>folds</code> is a scalar, then it is the number of folds. If
it is a vector, it should be the same length as the number of rows in <code>x</code></p>
</td></tr>
<tr><td><code id="cv.lpca_+3A_quiet">quiet</code></td>
<td>
<p>logical; whether the function should display progress</p>
</td></tr>
<tr><td><code id="cv.lpca_+3A_ms">Ms</code></td>
<td>
<p>depricated. Use <code>ms</code> instead</p>
</td></tr>
<tr><td><code id="cv.lpca_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>logisticPCA</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of the CV negative log likelihood with <code>k</code> in rows and
<code>m</code> in columns
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

## Not run: 
negloglikes = cv.lpca(mat, ks = 1:9, ms = 3:6)
plot(negloglikes)

## End(Not run)
</code></pre>

<hr>
<h2 id='cv.lsvd'>CV for logistic SVD</h2><span id='topic+cv.lsvd'></span>

<h3>Description</h3>

<p>Run cross validation on dimension for logistic SVD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.lsvd(x, ks, folds = 5, quiet = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.lsvd_+3A_x">x</code></td>
<td>
<p>matrix with all binary entries</p>
</td></tr>
<tr><td><code id="cv.lsvd_+3A_ks">ks</code></td>
<td>
<p>the different dimensions <code>k</code> to try</p>
</td></tr>
<tr><td><code id="cv.lsvd_+3A_folds">folds</code></td>
<td>
<p>if <code>folds</code> is a scalar, then it is the number of folds. If 
it is a vector, it should be the same length as the number of rows in <code>x</code></p>
</td></tr>
<tr><td><code id="cv.lsvd_+3A_quiet">quiet</code></td>
<td>
<p>logical; whether the function should display progress</p>
</td></tr>
<tr><td><code id="cv.lsvd_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to logisticSVD</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of the CV negative log likelihood with <code>k</code> in rows
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

## Not run: 
negloglikes = cv.lsvd(mat, ks = 1:9)
plot(negloglikes)

## End(Not run)
</code></pre>

<hr>
<h2 id='fitted.lpca'>Fitted values using logistic PCA</h2><span id='topic+fitted.lpca'></span>

<h3>Description</h3>

<p>Fit a lower dimentional representation of the binary matrix using logistic PCA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lpca'
fitted(object, type = c("link", "response"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted.lpca_+3A_object">object</code></td>
<td>
<p>logistic PCA object</p>
</td></tr>
<tr><td><code id="fitted.lpca_+3A_type">type</code></td>
<td>
<p>the type of fitting required. <code>type = "link"</code> gives output on the logit scale and
<code>type = "response"</code> gives output on the probability scale</p>
</td></tr>
<tr><td><code id="fitted.lpca_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run logistic PCA on it
lpca = logisticPCA(mat, k = 1, m = 4, main_effects = FALSE)

# construct fitted probability matrix
fit = fitted(lpca, type = "response")
</code></pre>

<hr>
<h2 id='fitted.lsvd'>Fitted values using logistic SVD</h2><span id='topic+fitted.lsvd'></span>

<h3>Description</h3>

<p>Fit a lower dimentional representation of the binary matrix using logistic SVD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lsvd'
fitted(object, type = c("link", "response"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted.lsvd_+3A_object">object</code></td>
<td>
<p>logistic SVD object</p>
</td></tr>
<tr><td><code id="fitted.lsvd_+3A_type">type</code></td>
<td>
<p>the type of fitting required. <code>type = "link"</code> gives output on the logit scale and
<code>type = "response"</code> gives output on the probability scale</p>
</td></tr>
<tr><td><code id="fitted.lsvd_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run logistic SVD on it
lsvd = logisticSVD(mat, k = 1, main_effects = FALSE, partial_decomp = FALSE)

# construct fitted probability matrix
fit = fitted(lsvd, type = "response")
</code></pre>

<hr>
<h2 id='house_votes84'>United States Congressional Voting Records 1984</h2><span id='topic+house_votes84'></span>

<h3>Description</h3>

<p>This data set includes votes for each of the U.S. House of Representatives 
Congressmen on the 16 key votes identified by the CQA. The CQA lists nine 
different types of votes: voted for, paired for, and announced for (these 
three simplified to yea), voted against, paired against, and announced against 
(these three simplified to nay), voted present, voted present to avoid conflict 
of interest, and did not vote or otherwise make a position known (these three 
simplified to an unknown disposition).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>house_votes84
</code></pre>


<h3>Format</h3>

<p>A matrix with all binary or missing entries. There are 435 rows corresponding
members of congress and 16 columns representing the bills being voted on. The row 
names refer to the political party of the members of congress</p>


<h3>Source</h3>

<p>Congressional Quarterly Almanac, 98th Congress, 
2nd session 1984, Volume XL: Congressional Quarterly Inc., 
Washington, D.C., 1985
</p>
<p>Data converted to a matrix from:
</p>
<p>Lichman, M. (2013). UCI Machine Learning Repository 
[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, 
School of Information and Computer Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(house_votes84)
congress_lpca = logisticPCA(house_votes84, k = 2, m = 4)
</code></pre>

<hr>
<h2 id='inv.logit.mat'>Inverse logit for matrices</h2><span id='topic+inv.logit.mat'></span>

<h3>Description</h3>

<p>Apply the inverse logit function to a matrix, element-wise. It 
generalizes the <code>inv.logit</code> function from the <code>gtools</code> 
library to matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv.logit.mat(x, min = 0, max = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inv.logit.mat_+3A_x">x</code></td>
<td>
<p>matrix</p>
</td></tr>
<tr><td><code id="inv.logit.mat_+3A_min">min</code></td>
<td>
<p>Lower end of logit interval</p>
</td></tr>
<tr><td><code id="inv.logit.mat_+3A_max">max</code></td>
<td>
<p>Upper end of logit interval</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>(mat = matrix(rnorm(10 * 5), nrow = 10, ncol = 5))
inv.logit.mat(mat)
</code></pre>

<hr>
<h2 id='log_like_Bernoulli'>Bernoulli Log Likelihood</h2><span id='topic+log_like_Bernoulli'></span>

<h3>Description</h3>

<p>Calculate the Bernoulli log likelihood of matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_like_Bernoulli(x, theta, q)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_like_Bernoulli_+3A_x">x</code></td>
<td>
<p>matrix with all binary entries</p>
</td></tr>
<tr><td><code id="log_like_Bernoulli_+3A_theta">theta</code></td>
<td>
<p>estimated natural parameters with 
same dimensions as x</p>
</td></tr>
<tr><td><code id="log_like_Bernoulli_+3A_q">q</code></td>
<td>
<p>instead of x, you can input matrix q which is 
-1 if <code>x = 0</code>, 1 if <code>x = 1</code>, and 0 if <code>is.na(x)</code></p>
</td></tr>
</table>

<hr>
<h2 id='logisticPCA'>Logistic Principal Component Analysis</h2><span id='topic+logisticPCA'></span>

<h3>Description</h3>

<p>Dimensionality reduction for binary data by extending Pearson's
PCA formulation to minimize Binomial deviance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logisticPCA(x, k = 2, m = 4, quiet = TRUE, partial_decomp = FALSE,
  max_iters = 1000, conv_criteria = 1e-05, random_start = FALSE, start_U,
  start_mu, main_effects = TRUE, validation, M, use_irlba)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logisticPCA_+3A_x">x</code></td>
<td>
<p>matrix with all binary entries</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_k">k</code></td>
<td>
<p>number of principal components to return</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_m">m</code></td>
<td>
<p>value to approximate the saturated model. If <code>m = 0</code>, m is solved for</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_quiet">quiet</code></td>
<td>
<p>logical; whether the calculation should give feedback</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_partial_decomp">partial_decomp</code></td>
<td>
<p>logical; if <code>TRUE</code>, the function uses the rARPACK package
to more quickly calculate the eigen-decomposition. This is usually faster than standard
eigen-decomponsition when <code>ncol(x) &gt; 100</code> and <code>k</code> is small</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_max_iters">max_iters</code></td>
<td>
<p>number of maximum iterations</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_conv_criteria">conv_criteria</code></td>
<td>
<p>convergence criteria. The difference between average deviance
in successive iterations</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_random_start">random_start</code></td>
<td>
<p>logical; whether to randomly inititalize the parameters. If <code>FALSE</code>,
function will use an eigen-decomposition as starting value</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_start_u">start_U</code></td>
<td>
<p>starting value for the orthogonal matrix</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_start_mu">start_mu</code></td>
<td>
<p>starting value for mu. Only used if <code>main_effects = TRUE</code></p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_main_effects">main_effects</code></td>
<td>
<p>logical; whether to include main effects in the model</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_validation">validation</code></td>
<td>
<p>optional validation matrix. If supplied and <code>m = 0</code>, the
validation data is used to solve for <code>m</code></p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_m">M</code></td>
<td>
<p>depricated. Use <code>m</code> instead</p>
</td></tr>
<tr><td><code id="logisticPCA_+3A_use_irlba">use_irlba</code></td>
<td>
<p>depricated. Use <code>partial_decomp</code> instead</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>lpca</code> which is a list with the
following components:
</p>
<table role = "presentation">
<tr><td><code>mu</code></td>
<td>
<p>the main effects</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>a <code>k</code>-dimentional orthonormal matrix with the loadings</p>
</td></tr>
<tr><td><code>PCs</code></td>
<td>
<p>the princial component scores</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>the parameter inputed or solved for</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>
<p>number of iterations required for convergence</p>
</td></tr>
<tr><td><code>loss_trace</code></td>
<td>
<p>the trace of the average negative log likelihood of the algorithm.
Should be non-increasing</p>
</td></tr>
<tr><td><code>prop_deviance_expl</code></td>
<td>
<p>the proportion of deviance explained by this model.
If <code>main_effects = TRUE</code>, the null model is just the main effects, otherwise
the null model estimates 0 for all natural parameters.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Landgraf, A.J. &amp; Lee, Y., 2015. Dimensionality reduction for binary data through 
the projection of natural parameters. arXiv preprint arXiv:1510.06112.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run logistic PCA on it
lpca = logisticPCA(mat, k = 1, m = 4, main_effects = FALSE)

# Logistic PCA likely does a better job finding latent features
# than standard PCA
plot(svd(mat_logit)$u[, 1], lpca$PCs[, 1])
plot(svd(mat_logit)$u[, 1], svd(mat)$u[, 1])
</code></pre>

<hr>
<h2 id='logisticSVD'>Logistic Singular Value Decomposition</h2><span id='topic+logisticSVD'></span>

<h3>Description</h3>

<p>Dimensionality reduction for binary data by extending SVD to 
minimize binomial deviance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logisticSVD(x, k = 2, quiet = TRUE, max_iters = 1000,
  conv_criteria = 1e-05, random_start = FALSE, start_A, start_B, start_mu,
  partial_decomp = TRUE, main_effects = TRUE, use_irlba)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logisticSVD_+3A_x">x</code></td>
<td>
<p>matrix with all binary entries</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_k">k</code></td>
<td>
<p>rank of the SVD</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_quiet">quiet</code></td>
<td>
<p>logical; whether the calculation should give feedback</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_max_iters">max_iters</code></td>
<td>
<p>number of maximum iterations</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_conv_criteria">conv_criteria</code></td>
<td>
<p>convergence criteria. The difference between average deviance
in successive iterations</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_random_start">random_start</code></td>
<td>
<p>logical; whether to randomly inititalize the parameters. If <code>FALSE</code>,
algorithm will use an SVD as starting value</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_start_a">start_A</code></td>
<td>
<p>starting value for the left singular vectors</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_start_b">start_B</code></td>
<td>
<p>starting value for the right singular vectors</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_start_mu">start_mu</code></td>
<td>
<p>starting value for mu. Only used if <code>main_effects = TRUE</code></p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_partial_decomp">partial_decomp</code></td>
<td>
<p>logical; if <code>TRUE</code>, the function uses the rARPACK package
to more quickly calculate the SVD. When the number of columns is small, 
the approximation may be less accurate and slower</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_main_effects">main_effects</code></td>
<td>
<p>logical; whether to include main effects in the model</p>
</td></tr>
<tr><td><code id="logisticSVD_+3A_use_irlba">use_irlba</code></td>
<td>
<p>depricated. Use <code>partial_decomp</code> instead</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>lsvd</code> which is a list with the
following components:
</p>
<table role = "presentation">
<tr><td><code>mu</code></td>
<td>
<p>the main effects</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>a <code>k</code>-dimentional orthogonal matrix with the scaled left singular vectors</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>a <code>k</code>-dimentional orthonormal matrix with the right singular vectors</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>
<p>number of iterations required for convergence</p>
</td></tr>
<tr><td><code>loss_trace</code></td>
<td>
<p>the trace of the average negative log likelihood of the algorithm. 
Should be non-increasing</p>
</td></tr>
<tr><td><code>prop_deviance_expl</code></td>
<td>
<p>the proportion of deviance explained by this model.
If <code>main_effects = TRUE</code>, the null model is just the main effects, otherwise 
the null model estimates 0 for all natural parameters.</p>
</td></tr>
</table>


<h3>References</h3>

<p>de Leeuw, Jan, 2006. Principal component analysis of binary data 
by iterated singular value decomposition. Computational Statistics &amp; Data Analysis 
50 (1), 21&ndash;39.
</p>
<p>Collins, M., Dasgupta, S., &amp; Schapire, R. E., 2001. A generalization of principal 
components analysis to the exponential family. In NIPS, 617&ndash;624.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run logistic SVD on it
lsvd = logisticSVD(mat, k = 1, main_effects = FALSE, partial_decomp = FALSE)

# Logistic SVD likely does a better job finding latent features
# than standard SVD
plot(svd(mat_logit)$u[, 1], lsvd$A[, 1])
plot(svd(mat_logit)$u[, 1], svd(mat)$u[, 1])
</code></pre>

<hr>
<h2 id='plot.clpca'>Plot convex logistic PCA</h2><span id='topic+plot.clpca'></span>

<h3>Description</h3>

<p>Plots the results of a convex logistic PCA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clpca'
plot(x, type = c("trace", "loadings", "scores"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.clpca_+3A_x">x</code></td>
<td>
<p>convex logistic PCA object</p>
</td></tr>
<tr><td><code id="plot.clpca_+3A_type">type</code></td>
<td>
<p>the type of plot <code>type = "trace"</code> plots the algorithms progress by
iteration, <code>type = "loadings"</code> plots the first 2 PC loadings,
<code>type = "scores"</code> plots the first 2 PC scores</p>
</td></tr>
<tr><td><code id="plot.clpca_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run convex logistic PCA on it
clpca = convexLogisticPCA(mat, k = 2, m = 4, main_effects = FALSE)

## Not run: 
plot(clpca)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.cv.lpca'>Plot CV for logistic PCA</h2><span id='topic+plot.cv.lpca'></span>

<h3>Description</h3>

<p>Plot cross validation results logistic PCA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.lpca'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.cv.lpca_+3A_x">x</code></td>
<td>
<p>a <code>cv.lpca</code> object</p>
</td></tr>
<tr><td><code id="plot.cv.lpca_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

## Not run: 
negloglikes = cv.lpca(dat, ks = 1:9, ms = 3:6)
plot(negloglikes)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.lpca'>Plot logistic PCA</h2><span id='topic+plot.lpca'></span>

<h3>Description</h3>

<p>Plots the results of a logistic PCA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lpca'
plot(x, type = c("trace", "loadings", "scores"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.lpca_+3A_x">x</code></td>
<td>
<p>logistic PCA object</p>
</td></tr>
<tr><td><code id="plot.lpca_+3A_type">type</code></td>
<td>
<p>the type of plot <code>type = "trace"</code> plots the algorithms progress by
iteration, <code>type = "loadings"</code> plots the first 2 principal component
loadings, <code>type = "scores"</code> plots the loadings first 2 principal component scores</p>
</td></tr>
<tr><td><code id="plot.lpca_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run logistic PCA on it
lpca = logisticPCA(mat, k = 2, m = 4, main_effects = FALSE)

## Not run: 
plot(lpca)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.lsvd'>Plot logistic SVD</h2><span id='topic+plot.lsvd'></span>

<h3>Description</h3>

<p>Plots the results of a logistic SVD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lsvd'
plot(x, type = c("trace", "loadings", "scores"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.lsvd_+3A_x">x</code></td>
<td>
<p>logistic SVD object</p>
</td></tr>
<tr><td><code id="plot.lsvd_+3A_type">type</code></td>
<td>
<p>the type of plot <code>type = "trace"</code> plots the algorithms progress by
iteration, <code>type = "loadings"</code> plots the first 2 principal component
loadings, <code>type = "scores"</code> plots the loadings first 2 principal component scores</p>
</td></tr>
<tr><td><code id="plot.lsvd_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run logistic SVD on it
lsvd = logisticSVD(mat, k = 2, main_effects = FALSE, partial_decomp = FALSE)

## Not run: 
plot(lsvd)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.clpca'>Predict Convex Logistic PCA scores or reconstruction on new data</h2><span id='topic+predict.clpca'></span>

<h3>Description</h3>

<p>Predict Convex Logistic PCA scores or reconstruction on new data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clpca'
predict(object, newdata, type = c("PCs", "link", "response"),
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.clpca_+3A_object">object</code></td>
<td>
<p>convex logistic PCA object</p>
</td></tr>
<tr><td><code id="predict.clpca_+3A_newdata">newdata</code></td>
<td>
<p>matrix with all binary entries. If missing, will use the
data that <code>object</code> was fit on</p>
</td></tr>
<tr><td><code id="predict.clpca_+3A_type">type</code></td>
<td>
<p>the type of fitting required. <code>type = "PCs"</code> gives the PC scores,
<code>type = "link"</code> gives matrix on the logit scale and <code>type = "response"</code>
gives matrix on the probability scale</p>
</td></tr>
<tr><td><code id="predict.clpca_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrices in the logit scale
rows = 100
cols = 10
set.seed(1)
loadings = rnorm(cols)
mat_logit = outer(rnorm(rows), loadings)
mat_logit_new = outer(rnorm(rows), loadings)

# convert to a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0
mat_new = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit_new)) * 1.0

# run logistic PCA on it
clpca = convexLogisticPCA(mat, k = 1, m = 4, main_effects = FALSE)

PCs = predict(clpca, mat_new)
</code></pre>

<hr>
<h2 id='predict.lpca'>Predict Logistic PCA scores or reconstruction on new data</h2><span id='topic+predict.lpca'></span>

<h3>Description</h3>

<p>Predict Logistic PCA scores or reconstruction on new data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lpca'
predict(object, newdata, type = c("PCs", "link", "response"),
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.lpca_+3A_object">object</code></td>
<td>
<p>logistic PCA object</p>
</td></tr>
<tr><td><code id="predict.lpca_+3A_newdata">newdata</code></td>
<td>
<p>matrix with all binary entries. If missing, will use the
data that <code>object</code> was fit on</p>
</td></tr>
<tr><td><code id="predict.lpca_+3A_type">type</code></td>
<td>
<p>the type of fitting required. <code>type = "PCs"</code> gives the PC scores,
<code>type = "link"</code> gives matrix on the logit scale and <code>type = "response"</code>
gives matrix on the probability scale</p>
</td></tr>
<tr><td><code id="predict.lpca_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrices in the logit scale
rows = 100
cols = 10
set.seed(1)
loadings = rnorm(cols)
mat_logit = outer(rnorm(rows), loadings)
mat_logit_new = outer(rnorm(rows), loadings)

# convert to a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0
mat_new = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit_new)) * 1.0

# run logistic PCA on it
lpca = logisticPCA(mat, k = 1, m = 4, main_effects = FALSE)

PCs = predict(lpca, mat_new)
</code></pre>

<hr>
<h2 id='predict.lsvd'>Predict Logistic SVD left singular values or reconstruction on new data</h2><span id='topic+predict.lsvd'></span>

<h3>Description</h3>

<p>Predict Logistic SVD left singular values or reconstruction on new data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lsvd'
predict(object, newdata, quiet = TRUE, max_iters = 1000,
  conv_criteria = 1e-05, random_start = FALSE, start_A, type = c("PCs",
  "link", "response"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.lsvd_+3A_object">object</code></td>
<td>
<p>logistic SVD object</p>
</td></tr>
<tr><td><code id="predict.lsvd_+3A_newdata">newdata</code></td>
<td>
<p>matrix with all binary entries. If missing, will use the 
data that <code>object</code> was fit on</p>
</td></tr>
<tr><td><code id="predict.lsvd_+3A_quiet">quiet</code></td>
<td>
<p>logical; whether the calculation should give feedback</p>
</td></tr>
<tr><td><code id="predict.lsvd_+3A_max_iters">max_iters</code></td>
<td>
<p>number of maximum iterations</p>
</td></tr>
<tr><td><code id="predict.lsvd_+3A_conv_criteria">conv_criteria</code></td>
<td>
<p>convergence criteria. The difference between average deviance
in successive iterations</p>
</td></tr>
<tr><td><code id="predict.lsvd_+3A_random_start">random_start</code></td>
<td>
<p>logical; whether to randomly inititalize the parameters. If <code>FALSE</code>,
algorithm implicitly starts <code>A</code> with 0 matrix</p>
</td></tr>
<tr><td><code id="predict.lsvd_+3A_start_a">start_A</code></td>
<td>
<p>starting value for the left singular vectors</p>
</td></tr>
<tr><td><code id="predict.lsvd_+3A_type">type</code></td>
<td>
<p>the type of fitting required. <code>type = "PCs"</code> gives the left singular vectors, 
<code>type = "link"</code> gives matrix on the logit scale and <code>type = "response"</code> 
gives matrix on the probability scale</p>
</td></tr>
<tr><td><code id="predict.lsvd_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Minimizes binomial deviance for new data by finding the optimal left singular vector
matrix (<code>A</code>), given <code>B</code> and <code>mu</code>. Assumes the columns of the right 
singular vector matrix (<code>B</code>) are orthonormal.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct a low rank matrices in the logit scale
rows = 100
cols = 10
set.seed(1)
loadings = rnorm(cols)
mat_logit = outer(rnorm(rows), loadings)
mat_logit_new = outer(rnorm(rows), loadings)

# convert to a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0
mat_new = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit_new)) * 1.0

# run logistic PCA on it
lsvd = logisticSVD(mat, k = 1, main_effects = FALSE, partial_decomp = FALSE)

A_new = predict(lsvd, mat_new)
</code></pre>

<hr>
<h2 id='project.Fantope'>Project onto the Fantope</h2><span id='topic+project.Fantope'></span>

<h3>Description</h3>

<p>Project a symmetric matrix onto the convex set of the rank k Fantope
</p>


<h3>Usage</h3>

<pre><code class='language-R'>project.Fantope(x, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="project.Fantope_+3A_x">x</code></td>
<td>
<p>a symmetric matrix</p>
</td></tr>
<tr><td><code id="project.Fantope_+3A_k">k</code></td>
<td>
<p>the rank of the Fantope desired</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>H</code></td>
<td>
<p>a rank <code>k</code> Fantope matrix</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>a <code>k</code>-dimentional orthonormal matrix with the first <code>k</code> eigenvectors of <code>H</code></p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
