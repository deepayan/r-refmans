<!DOCTYPE html><html lang="en"><head><title>Help for package Sequential</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Sequential}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Sequential-package'><p>Analysis Support, Critical Values, Power, Time to Signal and Sample Size for Sequential Analysis with Poisson and Binomial Data.</p></a></li>
<li><a href='#Analyze.Binomial'><p>Function for group sequential analyses for binomial data, without the need to know group sizes a priori.</p></a></li>
<li><a href='#Analyze.CondPoisson'><p>Function to conduct group sequential analyses for conditional Poisson data without the need to know group sizes a priori.</p></a></li>
<li><a href='#Analyze.Poisson'><p>Function to conduct group sequential analyses for Poisson data without the need to know group sizes a priori.</p></a></li>
<li><a href='#Analyze.wBinomial'><p>Function for group sequential analyses of multiple weighted binomial endpoints, without the need to know group sizes a priori.</p></a></li>
<li><a href='#AnalyzeSetUp.Binomial'><p>Function to set up input parameters before using the <code>Analyze.Binomial</code> function for the first time.</p></a></li>
<li><a href='#AnalyzeSetUp.CondPoisson'><p>Function to set up input parameters before using the <code>Analyze.CondPoisson</code> function for the first time.</p></a></li>
<li><a href='#AnalyzeSetUp.Poisson'><p>Function to set up input parameters before using the <code>Analyze.Poisson</code> function for the first time.</p></a></li>
<li><a href='#AnalyzeSetUp.wBinomial'><p>Function to set up input parameters before using the <code>Analyze.wBinomial</code> function for the first time.</p></a></li>
<li><a href='#ConfidenceInterval.Binomial'><p>Confidence Interval for the Relative Risk Following a Sequential Test with Binary Data.</p></a></li>
<li><a href='#CV.Binomial'><p>Calculates exact critical values for group and continuous sequential analysis with binomial data.</p></a></li>
<li><a href='#CV.CondPoisson'><p>Critical values for continuous sequential CMaxSPRT for Poisson data with limited information from historical cohort.</p></a></li>
<li><a href='#CV.Poisson'><p>Critical values for group and continuous sequential analysis with Poisson data.</p></a></li>
<li><a href='#Optimal.Binomial'><p>Optimal alpha spending for minimizing expected time to signal for continuous and group sequential analysis with binomial data.</p></a></li>
<li><a href='#Performance.AlphaSpend.Binomial'><p>Calculates performance and signaling threshold for user-defined alpha spending for sequential analysis with binomial data.</p></a></li>
<li><a href='#Performance.AlphaSpend.CondPoisson'><p>Calculates performance and signaling thresholds for user-defined alpha spending for sequential analysis with conditional Poisson data.</p></a></li>
<li><a href='#Performance.AlphaSpend.Poisson'><p>Calculates performance and signaling thresholds for user-defined alpha spending for sequential analysis with Poisson data.</p></a></li>
<li><a href='#Performance.Binomial'><p>Statistical power, expected time to signal and expected sample size for group and continuous sequential analysis with binomial data.</p></a></li>
<li><a href='#Performance.CondPoisson'><p>Statistical power, expected time to signal and expected sample size for the continuous sequential CMaxSPRT for Poisson data with limited information from historical cohort.</p></a></li>
<li><a href='#Performance.Poisson'><p>Calculates statistical power, expected time to signal and expected sample size for group and continuous sequential analysis with Poisson data.</p></a></li>
<li><a href='#Performance.Threshold.Binomial'><p>Statistical Performance and Alpha Spending For User-defined Signaling Threshold With Binomial Data.</p></a></li>
<li><a href='#Performance.Threshold.CondPoisson'><p>Performance and alpha spending for user-defined signaling threshold for sequential analysis with conditional Poisson data.</p></a></li>
<li><a href='#Performance.Threshold.Poisson'><p>Performance and alpha spending for user-defined signaling threshold for sequential analysis with Poisson data.</p></a></li>
<li><a href='#SampleSize.Binomial'><p>Sample size calculation for continuous sequential analysis with binomial data.</p></a></li>
<li><a href='#SampleSize.CondPoisson'><p>Sample size calculation for the continuous sequential CMaxSPRT for Poisson data with limited information from historical cohort.</p></a></li>
<li><a href='#SampleSize.Poisson'><p>Sample size calculation for continuous sequential analysis with Poisson data.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Exact Sequential Analysis for Poisson and Binomial Data</td>
</tr>
<tr>
<td>Version:</td>
<td>4.3.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-10-24</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ivair Ramos Silva &lt;ivair@ufop.edu.br&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to calculate exact critical values, statistical power, expected time to signal, and required sample sizes for performing exact sequential analysis. All these	calculations can be done for either Poisson or binomial data, for continuous or group sequential analyses, and for different types of rejection boundaries. In case of group sequential analyses, the group sizes do not have to be specified in advance and the alpha spending can be arbitrarily settled.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Imports:</td>
<td>boot</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-24 06:03:48 UTC; User</td>
</tr>
<tr>
<td>Author:</td>
<td>Ivair Ramos Silva [aut, cre],
  Martin Kulldorff [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-24 06:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Sequential-package'>Analysis Support, Critical Values, Power, Time to Signal and Sample Size for Sequential Analysis with Poisson and Binomial Data.</h2><span id='topic+Sequential-package'></span><span id='topic+Sequential'></span>

<h3>Description</h3>

<p><code>Sequential</code> is designed for continuous and group sequential analysis, where statistical hypothesis testing is conducted repeatedly
on accumulating data that gradually increases the sample size. This is different from standard statistical analysis, where a single analysis is performed
using a fixed sample size. It is possible to analyze either Poisson type data or binomial 0/1 type data. For binomial data, it is possible to incorporate an
off-set term to account for variable matching ratios. For Poisson data, the critical value is based on a Wald-type upper boundary, which is flat on the scale
of the log-likelihood ratio, and on a predetermined maximum sample size. Alternatively, it is also possible to apply a user defined alpha spending function
in order to specify non-flat signaling thresholds. For group sequential analyses, there are functions for pre-specified group sizes and for the situation when
the group sizes are not known a priori. It is also possible to perform mixed continuous/group sequential analysis, where, for example, there is at first a big
batch of data that arrives in one group, followed by continuous sequential analysis. All results are exact, based on iterative numerical calculations, rather
than asymptotic theory or computer simulations. In the <code>Sequential</code> package, there are functions to calculate critical values, statistical power,
expected time to signal, and expected sample size at the end of the sequential analyses whether the null hypothesis was rejected or not.
For example, for any desired power, relative risk and alpha level, the package can calculate the required upper limit on the sample size (maximum length of surveillance),
the critical value needed, and the corresponding expected time to signal when the null hypothesis is rejected.</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> Sequential</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 4.3.4</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-10-24</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL 2</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Index: </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Performance.Threshold.Binomial">Performance.Threshold.Binomial</a></code> </td><td style="text-align: left;"> Power, Expected Time to Signal, Expected</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Sample Size and Alpha Spending for User Defined Threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> with Binomial Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Performance.Threshold.CondPoisson">Performance.Threshold.CondPoisson</a></code> </td><td style="text-align: left;"> Power, Expected Time to Signal, Expected</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Sample Size and Alpha Spending for User Defined Threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> with Conditional Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Performance.Threshold.Poisson">Performance.Threshold.Poisson</a></code> </td><td style="text-align: left;"> Power, Expected Time to Signal, Expected</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Sample Size and Alpha Spending for User Defined Threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> with Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Analyze.Binomial">Analyze.Binomial</a></code> </td><td style="text-align: left;"> Function to Conduct Group Sequential Analyses for Binomial</td>
</tr>
<tr>
 <td style="text-align: left;">
                                           </td><td style="text-align: left;"> Data When the Goup Sizes are not Known a Priori.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+AnalyzeSetUp.Binomial">AnalyzeSetUp.Binomial</a></code> </td><td style="text-align: left;"> Function to Set Up the Input Parameters Before Using the</td>
</tr>
<tr>
 <td style="text-align: left;">
                                                </td><td style="text-align: left;"> <code>Analyze.Binomial</code> Function for the First Time.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Analyze.wBinomial">Analyze.wBinomial</a></code> </td><td style="text-align: left;"> Function for group sequential analyses of multiple</td>
</tr>
<tr>
 <td style="text-align: left;">
                                           </td><td style="text-align: left;"> weighted binomial endpoints.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+AnalyzeSetUp.wBinomial">AnalyzeSetUp.wBinomial</a></code> </td><td style="text-align: left;"> Function to set up input parameters before using the</td>
</tr>
<tr>
 <td style="text-align: left;">
                                                </td><td style="text-align: left;"> <code>Analyze.wBinomial</code> function for the first time.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Analyze.Poisson">Analyze.Poisson</a></code> </td><td style="text-align: left;"> Function to Conduct Group Sequential Analyses for Poisson</td>
</tr>
<tr>
 <td style="text-align: left;">
                                           </td><td style="text-align: left;"> Data When the Goup Sizes are not Known a Priori.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+AnalyzeSetUp.Poisson">AnalyzeSetUp.Poisson</a></code> </td><td style="text-align: left;"> Function to Set Up the Input Parameters Before Using the</td>
</tr>
<tr>
 <td style="text-align: left;">
                                                </td><td style="text-align: left;"> <code>Analyze.Poisson</code> Function for the First Time.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Analyze.CondPoisson">Analyze.CondPoisson</a></code> </td><td style="text-align: left;"> Function to Conduct Group Sequential Analyses for Conditional</td>
</tr>
<tr>
 <td style="text-align: left;">
                                           </td><td style="text-align: left;"> Poisson Data When the Goup Sizes are not Known a Priori.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+AnalyzeSetUp.CondPoisson">AnalyzeSetUp.CondPoisson</a></code> </td><td style="text-align: left;"> Function to Set Up the Input Parameters Before Using the</td>
</tr>
<tr>
 <td style="text-align: left;">
                                                </td><td style="text-align: left;"> <code>Analyze.CondPoisson</code> Function for the First Time.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+ConfidenceInterval.Binomial">ConfidenceInterval.Binomial</a></code> </td><td style="text-align: left;"> Confidence interval for the relative risk following</td>
</tr>
<tr>
 <td style="text-align: left;">
                                                      </td><td style="text-align: left;"> a sequential test with binomial data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+CV.Binomial">CV.Binomial</a></code> </td><td style="text-align: left;"> Critical Values for Group and Continuous Sequential</td>
</tr>
<tr>
 <td style="text-align: left;">
                                     </td><td style="text-align: left;"> Analysis with Binomial Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+CV.Poisson">CV.Poisson</a></code> </td><td style="text-align: left;"> Critical Values for Group and Continuous Sequential</td>
</tr>
<tr>
 <td style="text-align: left;">
                                     </td><td style="text-align: left;"> Analysis with Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+CV.CondPoisson">CV.CondPoisson</a></code> </td><td style="text-align: left;"> Critical Values for Continuous Sequential CMaxSPRT for</td>
</tr>
<tr>
 <td style="text-align: left;">
                                     </td><td style="text-align: left;"> Limited Information from Historical Cohort Using</td>
</tr>
<tr>
 <td style="text-align: left;">
                                     </td><td style="text-align: left;"> Conditional Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Optimal.Binomial">Optimal.Binomial</a></code> </td><td style="text-align: left;"> Optimal alpha spending for continuous and group sequential</td>
</tr>
<tr>
 <td style="text-align: left;">
                                     </td><td style="text-align: left;"> analysis with binomial data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Performance.Binomial">Performance.Binomial</a></code>  </td><td style="text-align: left;"> Power, Expected Time to Signal and Expected Sample Size</td>
</tr>
<tr>
 <td style="text-align: left;">
                                               </td><td style="text-align: left;"> for Group and Continuous Sequential Analysis with</td>
</tr>
<tr>
 <td style="text-align: left;">
                                               </td><td style="text-align: left;"> Binomial Data.</td>
</tr>
<tr>
 <td style="text-align: left;"> 
<code><a href="#topic+Performance.Poisson">Performance.Poisson</a></code>  </td><td style="text-align: left;"> Power, Expected Time to Signal and Expected Sample Size</td>
</tr>
<tr>
 <td style="text-align: left;">
                                               </td><td style="text-align: left;"> for Continuous Sequential Analysis with</td>
</tr>
<tr>
 <td style="text-align: left;"> 
                                                </td><td style="text-align: left;"> Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Performance.CondPoisson">Performance.CondPoisson</a></code>  </td><td style="text-align: left;"> Power, Expected Time to Signal and Expected Sample</td>
</tr>
<tr>
 <td style="text-align: left;">
                                               </td><td style="text-align: left;"> Size for Continuous Sequential CMaxSPRT Using</td>
</tr>
<tr>
 <td style="text-align: left;"> 
                                                </td><td style="text-align: left;"> Limited Information from Historical Cohort</td>
</tr>
<tr>
 <td style="text-align: left;">
                                                 </td><td style="text-align: left;"> with Conditional Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+SampleSize.Binomial">SampleSize.Binomial</a></code>  </td><td style="text-align: left;"> Sample Size Calculation for Continuous Sequential Analysis with</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Binomial Data.</td>
</tr>
<tr>
 <td style="text-align: left;">                              
<code><a href="#topic+SampleSize.Poisson">SampleSize.Poisson</a></code>  </td><td style="text-align: left;"> Sample Size Calculation for Continuous Sequential Testing with</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+SampleSize.CondPoisson">SampleSize.CondPoisson</a></code>  </td><td style="text-align: left;"> Sample Size Calculation for Continuous Sequential CMaxSPRT with</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Performance.AlphaSpend.Binomial">Performance.AlphaSpend.Binomial</a></code> </td><td style="text-align: left;"> Power, Expected Time to Signal, Expected</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Sample Size and Threshold for User Defined Alpha Spending </td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> with Binomial Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Performance.AlphaSpend.CondPoisson">Performance.AlphaSpend.CondPoisson</a></code> </td><td style="text-align: left;"> Power, Expected Time to Signal, Expected</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Sample Size and Threshold for User Defined</td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Alpha Spending with Conditional Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code><a href="#topic+Performance.AlphaSpend.Poisson">Performance.AlphaSpend.Poisson</a></code> </td><td style="text-align: left;"> Power, Expected Time to Signal, Expected</td>
</tr>
<tr>
 <td style="text-align: left;">
                                            </td><td style="text-align: left;"> Sample Size and Threshold for User Defined </td>
</tr>
<tr>
 <td style="text-align: left;">
                                              </td><td style="text-align: left;"> Alpha Spending with Poisson Data.</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Overview</h3>

<p>Most of the sequential analysis methods found in the literature are based on asymptotic results. In contrast,
this package contains functions for the exact calculation of critical values, statistical power, expected time
to signal when the null is rejected and the maximum sample size needed when the null is not rejected. This is done for
Poisson and binomial type data with a Wald-type upper boundary, which is flat with respect to the likelihood ratio function,
and a predetermined upper limit on the sample size. For a desired statistical power, it is also possible to calculate the latter.
The motivation for this package is post-market near real-time drug and vaccine safety surveillance, where the goal is to detect rare
but serious safety problems as early as possible, in many cases after only a hand full of adverse events. The package can also be used
in other application areas, such as clinical trials.
</p>
<p>A tutorial paper by Silva et al. (2021) explains the main features of the package up to version 3.3.1, where sequential test designing and
real data analyses are dicussed in more details. 
</p>
<p>The basis for this package is the Maximized Sequential Probability Ratio Test (MaxSPRT) statistic (Kulldorff et al., 2011), which is a variant of
Wald's Sequential Probability Ratio Test (SPRT) (Wald, 1945,47). MaxSPRT uses a composite alternative hypothesis, and upper boundary to reject the
null hypothesis when there are more events than expected, no lower boundary, and an upper limit on the sample size at which time the sequential
analyses end without rejecting the null. MaxSPRT was developed for post-market vaccine safety surveillance as part of the Vaccine Safety Datalink
project run by the Centers for Disease Control and Prevention.
</p>
<p>In this package, all critical values, alpha spending strategies, statistical power, expected time to
signal and required sample size to achieve a certain power, are obtained exactly to whatever decimal precision desired,
using iterative numerical calculations. None of the results are based on asymptotic theory or computer simulations.
</p>
<p><b>Poisson Data</b>
</p>
<p>To start, consider continuous sequential analysis for Poisson data. Let <code class="reqn">C_t</code> be the random variable that counts the number of events up to time t.
Suppose that, under the null hypothesis, <code class="reqn">C_t</code> has a Poisson distribution with mean <code class="reqn">\mu_t</code>, where <code class="reqn">\mu_t</code> is a known function reflecting the population at risk.
Under the alternative hypothesis, suppose that <code class="reqn">C_t</code> has a Poisson distribution with mean RR<code class="reqn">\mu_t</code>, where &quot;RR&quot; is the unknown increased relative risk due to the vaccine.
The MaxSPRT statistic defined in terms of the log likelihood ratio is given by: </p>
<p style="text-align: center;"><code class="reqn">LLR_t=(\mu_t-c_t)+c_t \log{c_t/\mu_t},</code>
</p>
<p> when <code class="reqn">c_t</code> is at least <code class="reqn">\mu_t</code>, and <code class="reqn">LLR_t =0</code>, otherwise.
For continuous sequential analysis, the test statistic, <code class="reqn">LLR_t</code>, is monitored at all times <code class="reqn">t \in (0,T]</code>, where <code class="reqn">T</code>= SampleSize. SampleSize is defined
a priori by the user in order to achieve the desired statistical power, which can be calculated using the <code>SampleSize.Poisson</code> function.
The sequential analysis ends, and <code class="reqn">H_0</code> is rejected if, and when, <code class="reqn">LLR_t \geq CV</code>, where CV is calculated using the <code>CV.Poisson</code> function.
If <code class="reqn">\mu_t</code>= SampleSize, the sequential analysis ends without rejecting the null hypothesis. To calculate other important performance metrics, such as the expected time to signal when
the null hypothesis is rejected, use the <code>Performance.Poisson</code>, <code>Performance.Threshold.Poisson</code> and <code>Performance.AlphaSpend.Poisson</code> functions.
These functions also work for group sequential analysis when the group sizes are fixed a priori.
For with fixed and/or unpredictable group sizes, see the function <code>Analyze.Poisson</code>. 
</p>
<p>If the first event occurs sufficiently early, the sequential analysis may end with the null hypothesis rejected after a single event. There is an option
to require a minimum number of observed events, <code class="reqn">c_t</code>= M, before the null can be rejected.
Setting M in the range [3,6] is often a good choice (Kulldorff and Silva, 2012). If there is a delay until the sequential analysis starts,
but it continuous continuously thereafter, there is an option for that as well, requiring a minimum number <code class="reqn">\mu_t</code>= D of expected events before the null can be rejected.
</p>
<p>With continuous sequential analysis, investigators can repeatedly analyze the data as often as they want, ensuring that the overall probability of falsely
rejecting the null hypothesis at any time during the analysis is controlled at the desired nominal significance level (Wald, 1945, 1947). Continuous sequential
methods are suitable for real-time or near real-time monitoring. When data is only analyzed intermittently, group sequential methods are used instead
(Chin, 2012; Cook and DeMets, 2007; Xia, 2007; Friedman et al., 2010; Ghosh and Sen, 1991; Jennison and Turnbull, 2000; Mukhopadhyay and Silva, 2002; Whitehead, 1997).
The data is then analyzed at regular or irregular discrete time intervals after a certain amount of data is accessible. Group sequential statistical methods are commonly used in
clinical trials, where a trial may be stopped early due to either efficacy or unexpected adverse events (Jennison and Turnbull, 2000). 
</p>
<p>The same test statistic, <code class="reqn">LLR_t</code>, is used for group sequential analyses (Silva and Kulldorff, 2012). The times when <code class="reqn">LLR_t</code> is evaluated can be defined in several ways,
using regular or irregular time intervals that are referenced by calendar period, sample size or some scale involving the distribution of the data. For Poisson data,
the group sequential analysis must be conducted with equal size groups, with a constant expected number of adverse events between looks at the accumulating data.
In another words, <code class="reqn">LLR_t</code> is compared against CV whenever <code class="reqn">\mu_t</code> is a multiple of SampleSize/Looks, where 'Looks' is the total number of looks at the data.
</p>
<p><b>Binomial Data</b>
</p>
<p>The MaxSPRT method can also be applied to binomial/Bernoulli data. Let <code class="reqn">n</code> denote the total number of events that has been observed in a sequential monitoring
up to a certain moment in time. Suppose that these n events are categorized as cases and controls. For example, cases may be adverse events happening
to a person taking drug A, while controls may be the same adverse event happening to someone in a matched set of individuals taking drug B. As another example,
in a self-control sequential analysis, cases may be adverse events happening during the 1-28 days following vaccination, while controls are the same adverse events
happening 29-56 days after vaccination. 
</p>
<p>Let <code class="reqn">C_t</code> to denote the number of cases among the n events, and assume that <code class="reqn">C_t</code> follows a binomial distribution with success probability equal to <code class="reqn">p</code>, where <code class="reqn">p = 1=(1 + z)</code>,
and z is the matching ratio between the occurrence of a case and of a control under the null hypothesis. For example, if the probability of having a case (instead of a control)
is <code class="reqn">p = 1=(1 + z) = 0.5</code>, then z=1 (1:1 matching ratio), or, <code class="reqn">p = 0.25</code> for z=3 (1:3 matching ratio), etc.
</p>
<p>The MaxSPRT statistic (Kulldorff et al., 2011) for a continuous binomial surveillance is:
</p>
<p style="text-align: center;"><code class="reqn">LR_n=\frac{(c_n/n)^{c_n}\left[(n-c_n)/n\right]^{n-c_n}}{\left[1/(1+z)\right]^{c_n}\left[z/(1+z)\right]^{n-c_n}},</code>
</p>

<p>if <code class="reqn">z c_n/(n-c_n)&gt;1</code>, and <code class="reqn">LR_n= 1</code> otherwise.
</p>
<p>The monitoring is continued until either there is a signal rejecting the null hypothesis <code class="reqn">(LR_n &gt; CV)</code>
or until <code class="reqn">n=N</code>, which indicates that the null is not to be rejected. To perform the calculations, use the
<code>CV.Binomial</code>, <code>SampleSize.Binomial</code>, <code>Performance.Binomial</code>, <code>Performance.Threshold.Binomial</code> and <code>Performance.AlphaSpend.Binomial</code> functions
for continuous and group sequential fashions. For group sequential analysis, the group sizes are fixed a priori.
For fixed and/or unpredictable group sizes, see the function <code>Analyze.Binomial</code>.
</p>
<p>The main assumptions behind the method above are: (i) the monitoring is truly performed in a continuous fashion; (ii) the matching ratio (z) is constant for all of the n events,
and (iii) it uses a Wald type rejection boundary that is flat in terms of the likelihood function. Relaxing these assumptions, Fireman et al. (2013) developed exact sequential
analysis for group sequential data with varying matching ratios, and for any user specified alpha rejection plan.
</p>
<p><b>Multiple Weighted Binomial Endpoints</b>
</p>
<p>When there are multiple different outcomes, one can use weights reflecting practical interpretations, such as an outcome
severity in comparison to the others. For example, for two different outcomes, the first with weight w, and the second with weight 1.
This way, a single event of the first outcome is equivalent to w outcomes of the second type. This type of analysis is treated by Silva et al (2019).
To run the analysis with multiple weighted binary endpoints with fixed and/or unpredictable group sizes, see the function <code>Analyze.wBinomial</code>. 
</p>
<p><b>Conditional Poisson data with limited information from historical cohort - CMaxSPRT</b>
</p>
<p>In Poisson MaxSPRT, the expected mean <code class="reqn">\mu_t</code> is assumed to be a known function reflecting the baseline adverse event risk
in the absence of the exposure of interest. In practice, it is estimated with historical data and the uncertainty associated with
the estimated counts may or may not have a non-negligible impact on the performance of the sequential analysis method.
Li and Kulldorff (Li and Kulldorff, 2010) showed in their simulation study that uncertainty in the estimated baseline means can be
ignored when the total number of events in the historical data is at least 5 times the specified upper limit <code class="reqn">T</code>. Otherwise, it
is recommended to implement a statistical procedure that takes in account the variation from the historical data, i.e. a procedure that
conditionates the likelihood function of the historical Poisson data, here simply called &quot;conditional Poisson data&quot;. For this, the
Conditional Maximized Sequential Probabilit Ratio Test (CMaxSPRT) to account for variation in both the historical and surveillance cohorts.
</p>
<p>Let <code class="reqn">c</code> and <code class="reqn">V</code> denote the total number of events and the cumulative person-time in the historical data, let <code class="reqn">P_k</code> denote the
cumulative person-time observed in the surveillance population when the <code class="reqn">k</code>th event occurred. The CMaxSPRT statistic defined in terms
of the log likelihood ratio is given by </p>
<p style="text-align: center;"><code class="reqn">U_k=clog(\frac{c(1+P_k/V)}{c+k})+klog(\frac{k(1+P_k/V)}{P_k/V(c+k)}),</code>
</p>
<p> when <code class="reqn">k/c&gt;P_k/V</code>,
and <code class="reqn">U_k=0,</code> otherwise. In the original publication (Li and Kulldorff, 2010), the method was introduced as a continuous sequential analytic
approach with the upper limit defined in terms of the maximum number of observed events, i.e., <code class="reqn">k \leq K</code>, and the critical value calculated
via a Monte Carlo approach. A large number of Monte Carlo simulations (e.g., 10 million) might be needed to calculate the critical values with
a reasonable precision. 
</p>
<p>In Silva et al. (2019a), the method was extended i) with another option of defining the surveillance length in terms of
the maximum cumulative person-time divided by the total cumulative person-time in the historical cohort, i.e., <code class="reqn">P_k/V \le T</code>, ii) with an exact
calculation of the critical values for both surveillance length definitions, and iii) for group sequential analysis with data updated and analyzed
intermittently instead of continuously. The exact critical values are calculated using the interval havling method to solve for the root of a complex,
non-linear equation such that the overall Type I error rate is preserved at the nominal level. As <code class="reqn">K</code> increases, the computing time for the exact
critical values increases exponentially. 
</p>
<p>Silva et al. (2019a) also proposed two approximation methods to calculate the critical values that require
substantially less computing time. One approch may overestimate the critical values and thus is referred to as the conservative approach as it may
yield lower-than-nominal Type I error rates; the other approach may underestmate the critical values and thus is referred to as the liberal approach
as it may yield higher-than-nominal Type I error rates. The recommendation is to use the exact approach when <code class="reqn">K</code> is small (e.g., 10),
use the conservative approach when <code class="reqn">K</code> is medium or large but <code class="reqn">c</code> is small, and use the liberal approach when <code class="reqn">c</code> is medium (e.g., 50)
or large. Exact calculations for selected tuning parameters show that the three approaches yield very similar results when <code class="reqn">K</code> and <code class="reqn">c</code> are reasonably large.
</p>
<p>For calculating critical values for a Wald type rejection boundary, use the <code>CV.CondPoisson</code> function. For statistical power,
expected time to signal, expected time of surveillance, and maximum sample size requirements, use the
<code>Performance.CondPoisson</code>, <code>Performance.Threshold.CondPoisson</code>, <code>Performance.AlphaSpend.CondPoisson</code>, and <code>SampleSize.CondPoisson</code> functions.
For fixed and/or unpredictable group sizes, see the function <code>Analyze.CondPoisson</code>.
</p>
<p><b>Alpha spending function for unpredictable group sizes</b>
</p>
<p>The alpha spending function specifies the cumulative amount, <code class="reqn">F_{\alpha}(t)</code>, of Type I error probability related to each of the possible values of <code class="reqn">n</code>.
Thus, at the end of the monitoring the alpha spending corresponds to a value smaller than or equal to the overall amount of Type I error probability defined for
the overall nominal significance level, <code class="reqn">\alpha</code>.
</p>
<p>Denote the single probability of rejecting the null hypothesis at the <code class="reqn">j</code>-th test by <code class="reqn">\alpha_j</code>. Then, the alpha spending at test <code class="reqn">i</code> is given by
<code class="reqn">F_{\alpha}(t_i)=\sum_{j=1}^{i}\alpha_j \leq \alpha</code>.
</p>
<p>There is a vast number of proposals for choosing the shape of the alpha spending function.
Jennison and Turnbull (2000) present a rich discussion about this topic. They dedicated a special attention to the alpha spending of the form:
<code class="reqn">F_{\alpha}(t)=\alpha t^{\rho}</code>, where <code class="reqn">\rho&gt;0</code>, and <code class="reqn">t</code> represents a fraction of the maximum length of surveillance. 
</p>
<p>A new aproach for alpha spending selection is the optimal solution, introduced by Silva and Kulldorff (2020).
The optimal solution is based on exact calculations through linear programing, and it is operated through the function <code>Optimal.Binomial</code>.
</p>
<p>For MaxSPRT with Poisson data, Silva (2018b) presents a rule of thumb for a near-optimal alpha spending shape. Likewise, Silva et al. (2019b) discuss
the choice of alpha spending shapes for CMaxSPRT.
</p>
<p>To run continuous or group sequential analysis with an user defined alpha spending function, and/or, when the group sizes are not known a prior,
<code>Analyze.Binomial</code>, <code>Analyze.wBinomial</code> (for multiple weighted binomial endpoints), <code>Analyze.Poisson</code>, and <code>Analyze.CondPoisson</code> should be used for binomial and Poisson, and conditional Poisson data, respectively. 
These functions work differently than the other functions mentioned above.
Those other functions are designed to be used before the start of the sequential analysis, in order to determine what the maximum sample size
and critical value should be. Once the sequential analysis is under way, the test statistic is then calculated using a hand calculator or an
excel spread sheet, and compared with the critical value. The functions <code>Analyze.Binomial</code>, <code>Analyze.Poisson</code>, and <code>Analyze.CondPoisson</code> work very differently, in that they are run at each look at
the accumulating data, whenever a new group of data arrives, and it is meant to perform the test itself, i.e., there is no need to use hand calculators or
excel spread sheets or any other auxiliar code. The results and conclusions, including a descriptive table and illustrative graphics, are automatically
provided after running <code>Analyze.Binomial</code>, <code>Analyze.wBinomial</code>, <code>Analyze.Poisson</code>, or <code>Analyze.CondPoisson</code>.
</p>
<p>Important: before using these functions, though, it is necessary to first run the
functions <code>AnalyzeSetup.Binomial</code>, <code>AnalyzeSetup.wBinomial</code>, <code>AnalyzeSetup.Poisson</code>, or <code>AnalyzeSetup.CondPoisson</code> once in order to set everything up for the sequential analysis.
</p>


<h3>Comparison with Other R Packages for Sequential Analysis</h3>

<p>The R  <code>Sequential</code> package is designed for sequential analysis where statistical hypothesis testing is performed using gradually accumulating data.
It is not designed for quality control problems, where a process is monitored over time to detect an emerging problem due to a sudden increase in the excess risk.
Although the methods for sequential analysis and quality control may seem similar, as they both analyze gradually accumulating data, they are actually very different
in both their purpose and design. Under the sequential hypothesis testing approach, the objective is to quickly determine if there is some intrinsic excess risk,
with the assumption that this risk does not change over time. For example, we may want to know if drug A is better than drug B, and there is no reason to believe
that the behavior of the drugs change over time. In the quality control setting, the objective is instead to detect a possible change in a stochastic process that
may occur in the future, and to detect that change as soon as possible after it occurs. For example, the heart of a hospital patient is beating as it should, but if
there is a sudden deterioration, the alarm should sound as soon as possible without generating a lot of false alarms. This package is only meant for sequential analysis
of the former type, and it should not be used for quality control type problems. For quality control type analyses, there are other R packages available,
such as <code>graphicsQC</code>, <code>IQCC</code>, <code>MetaQC</code>, <code>MSQC</code>, <code>qcc</code>, and <code>qcr</code>.
</p>
<p>In a number of ways, the R Sequential package differs from other R packages for sequential analyses. Historically, most sequential analysis has been conducted
using asymptotic statistical theory, and that is also what is used in the <code>gsDesign</code>, <code>ldbounds</code>, <code>PwrGSD</code>, <code>seqDesign</code>, <code>seqmon</code>, and <code>sglr</code> R packages.
In contrast, the R Sequential package is based on exact results, using iterative numerical calculations, rather than using asymptotic theory or computer simulations.
</p>
<p>With this package, it is only possible to analyze binomial/Bernoulli, Poisson, or conditional Poisson data. For other probability distributions, such as normal or exponential data,
other R packages should be consulted, such as <code>GroupSeq</code> or <code>SPRT</code>. Moreover, all functions in this package uses a one-sided upper bound to reject the null hypothesis,
while the analyses end without rejecting the null when an upper limit on the sample size is reached. For two sided sequential analysis, or other types of rejection
boundaries, other R packages must be used, such as e.g. <code>ldbounds</code> and <code>Binseqtest</code>. Finally, in this package, there are functions for both continuous
and group sequential analysis, and it is also possible to analyze situations where some of the data arrives continuously while other parts of the data arrives in groups.
Most other R packages are exclusively designed for group sequential analysis, but there are some that also do continuous sequential analysis, such as <code>Binseqtest</code> and <code>SPRT</code>,
but <code>Binseqtest</code> is only for binomial data type, and <code>SPRT</code> is for simple alternative hypothis, while <code>Sequential</code> can be used for binomial and Poisson data and is meant to
composite alternative hypothesis. The present package offers the possibility to calculate the expected time to signal through the <code>Performance.Poisson</code>, <code>Performance.G.Poisson</code>,
<code>Performance.Binomial</code>, <code>Performance.G.Binomial</code>, and Performance.CondPoisson functions, which is not offered by the other packages cited above.
Another important advantage of the <code>Sequential</code> package is the possibility of eliciting, through exact calculations, the minimum sample size needed to
accomplish with target statistical powers through the functions <code>SampleSize.Poisson</code>, <code>SampleSize.CondPoisson</code>, and <code>SampleSize.Binomial</code>.     
</p>


<h3>Acknowledgements</h3>

<p>Development of the R Sequential package has been funded and supported by:<br />
-	Food and Drug Administration, USA, through the Mini-Sentinel Project (v1.0,1.1,2.0).<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0 to 3.1).<br />
-	Federal University of Ouro Preto (UFOP), through contract under internal UFOP's resolution CEPE 4600 (v2.0 to 3.1).<br />
-	National Council of Scientific and Technological Development (CNPq), Brazil, process number 301391/2019-0. (v3.1 to v4.3).<br />
-     National Council of Scientific and Technological Development (CNPq), Brazil, process number 302882/2022-7. (v4.3.1).<br />
-	Support Foundation to Minas Gerais State Research-Fapemig, Brazil, grant numbers PQ-00787-21 and RED-00133-21. (v3.1 to v4.3). <br />
-	Bank for Development of the Minas Gerais State (BDMG), Brazil (v1.0).<br />
-	Vaccine Safety Datalink - VSD Infrastructure Activities project at HPHCI. (v4.3.4).<br />
<br />
Feedback from users is greatly appreciated. Very valuable suggestions concerning the R Sequential package have been received from various individuals, including:<br />
-	Ron Berman, University of California Berkeley.<br />
-	Claudia Coronel-Moreno, Harvard Pilgrim Health Care Institute.<br />
-	Bruce Fireman, Kaiser Permanente Northern California.<br />
-	Josh Gagne, Harvard Medical School and Brigham and Women's Hospital.<br />
-	Ned Lewis, Kaiser Permanente Northern California.<br />
-	Judith Maro, Harvard Medical School and Harvard Pilgrim Health Care Institute.<br />
-	Azadeh Shoaibi, Food and Drug Administration.<br />
-	Katherine Yih, Harvard Medical School and Harvard Pilgrim Health Care Institute.<br />
-     Jie Tang, Clinical biostatistics, Janssen R and D US, Johnson and Johnson LLC.<br />
-	Tuomo A. Nieminen, The National Institute for Health and Welfare (THL), Finland.<br />
-	Andreia Leite, Department of Infectious Disease Epidemiology, London School of Hygiene and Tropical Medicine.<br /> 
-	Laura Hou, Harvard Pilgrim Health Care Institute, Boston, USA.<br />
-	Abdurrahman Abdurrob, Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, Brigham and Women's Hospital and Harvard Medical School.<br />
-	Kirk Snyder, Information Management Services, Inc.<br />
-     Joselito M. Montalban, Active Living, Population and Public Health Branch, Winnipeg, Manitoba, Canada.<br /> 
-     Sarah Spruin and Vaccine Safety Surveillance, Public Health Agency of Canada.<br />
-     Lola Adewale, Stateam LLC, New Jersey, United States.<br />
-	Lian Lin, Ph.D., Director, Safety Statistics, Stats and Programming, Moderna.<br />
</p>


<h3>Version History of the R Sequential Package</h3>

<p>Version 1.1, February 2013<br />
Exact sequential analysis for Poisson data:<br />
-	Exact continuous sequential analysis.<br />
-	Exact group sequential analysis with pre-defined and constant groups sizes.<br />
-	Wald type rejection boundary.<br />
-	Statistical power, expected time to signal and sample size calculations.<br />
-	User guide.<br />
<br />
Version 1.2,  January 2014<br />
-	Improved code structure and efficiency.<br />
-	More extensive user guide. <br />
<br />
Version 2.0, June 2015<br />
Exact sequential analysis for binomial data:<br />
-	Continuous sequential analysis.<br />
-	Group sequential analysis with pre-defined group sizes.<br />
-	Group sequential analysis with unpredictable group sizes, not specified a priori.<br />
-	Fixed or variable binomial probabilities (matching ratios).<br />
-	User specified alpha spending function.<br /> 
-	Statistical power, expected time to signal and sample size calculations.<br />
-	Updated user guide.<br />
<br />
Version 2.0.1, June 2015<br />
-       Correction of bugs in <code>CV.Poisson</code> function. <br />
-       Updated user guide.<br />
<br />
Version 2.0.2, Octuber 2015<br />
-       Improved user guide.<br />
<br />
Version 2.1, May 2016<br />
Exact sequential analysis for Poisson data:<br />
-	Group sequential analysis with unpredictable group sizes, not specified a priori.<br />
-	User specified alpha spending function.<br />
-	Mixed group-continuous sequential analysis.<br />
-	Statistical power, expected time to signal and sample size calculations for non-constant groups sizes.<br />
Other:<br />
-	Directory address parameter in AnalyzeSetUp functions.<br />
-	Probability parameter in binomial functions.<br />
-	Updated user guide.<br />
<br />
Version 2.1.1, June 2016<br />
-	Correction of bugs in Poisson functions.<br />
-	Updated user guide.<br />
<br />
Version 2.2, July 2016<br />
-	Critical Value, Performance, and SampleSize calculations for CMaxSPRT with Poisson data.<br />
-	Updated user guide.<br />
<br />
Version 2.2.1, September 2016<br />
-     Correction of bugs in <code>CV.Poisson</code> and <code>CV.G.Poisson</code> functions. <br />
-     Updated user guide.<br />
<br />
Version 2.3, Dec 2016<br />
-     Correction of bugs in the <code>SampleSize.Binomial</code> function.<br />
-	Improvement of SampleSize functions for considering vectors for the input parameters R and power.<br />
-	Inclusion of the new functions <code>AnalyzeSetUp.CondPoisson</code> and <code>Analyze.CondPoisson</code>.<br />
-     Updated user guide.<br />
<br />
Version 2.3.1, Feb 2017<br />
-     Correction of bugs in <code>Analyze.Binomial</code> and <code>AnalyzeSetUp.Poisson</code> functions.<br />
-	Adjustment on the relative risk estimation method for <code>Analyze.Binomial</code> function.<br />
-     Updated user guide.<br />
<br />
Version 2.3.2, Aug 2017<br />
-     Correction of bugs in <code>Analyze.Binomial</code>.<br />
-     Updated user guide.<br />
<br />
Version 3.0, Jan 2019<br />
-     Functions <code>Optimal.Binomial</code> and <code>Analyze.wBinomial</code>.<br />
-     Updated user guide.<br />
<br />
Version 3.0.1, Feb 2019<br />
-     Updated user guide.<br />
<br />
Version 3.1, Sept 2019<br />
-      New Functions <code>Performance.Threshold.Binomial</code>, <code>Performance.Threshold.CondPoisson</code>,<br />
<code>Performance.Threshold.Poisson</code>, <code>Performance.AlphaSpend.Binomial</code>,<br />
<code>Performance.AlphaSpend.CondPoisson</code>, <code>Performance.AlphaSpend.Poisson</code>.<br />
-     Implemented two-tailed testing for the functions: <code>CV.Poisson</code>, <code>Performance.Poisson</code>,<br />
<code>SampleSize.Poisson</code>, <code>Analyze.wBinomial</code>, <code>Optimal.Binomial</code>,<br />
<code>Performance.Threshold.Binomial</code>, <code>Performance.AlphaSpend.Binomial</code>,<br />
<code>Performance.Threshold.Poisson</code>.<br />
-     Updated user guide.<br />
-	Concatenation of functions for continuous and group fashions for critical values and performance.<br /> 
<br />
Version 3.2, Nov 2020<br />
-     Function <code>Analyze.Binomial</code> improved for fixed-width and fixed-accuracy confidence intervals,<br />
-     Function <code>Performance.AlphaSpend.Binomial</code> improved for new inputs having lower and upper alpha spending in two tailed testing,<br />
-     Correction of bugs in <code>Analyze.Poisson</code> and <code>CV.Poisson</code> functions,<br />
-     Updated user guide.<br />
<br />
Version 3.2.1, Dec 2020<br />
-     Correction of bugs in the <code>Analyze.Poisson</code> function,<br />
-     Updated user guide.<br />
<br />
Version 3.3, Feb 2021<br />
-     Optimized <code>Analyze.Poisson</code> function for running three times faster than earlier versions.<br />
-     Updated user guide.<br />
<br />
Version 3.3.1, Feb 2021<br />
-     Adjusted <code>Analyze.Binomial</code> function for a flexible H0:R&lt;=R0 under the null hypothesis.<br />
-     Updated user guide.<br />
<br />
Version 3.3.2, Aug 2021<br />
-     Adjusted functions: <code>Analyze.Poisson</code>, <code>AnalyzeSetUp.Poisson</code>, <code>Performance.AlphaSpend.Poisson</code>, and <code>SampleSize.Poisson</code> for the surveillance of COVID-19 vaccination.<br />
-     Updated user guide.<br />
<br />
Version 3.3.3, Aug 2021<br />
-     Adjusted <code>Performance.AlphaSpend.Poisson</code> function.<br />
-     Updated user guide.<br />
<br />
Version 3.4, Sept 2021<br />
-     Adjusted <code>Analyze.Poisson</code> function.<br />
-     Updated user guide.<br />
<br />
Version 4.0, Sept 2021<br />
-     New function <code>ConfidenceInterval.Binomial</code>, adjusted <code>Analyze.wBinomial</code> and new parameter R0 for <code>Analyze.Poisson</code> and <code>Performance.AlphaSpend.Poisson</code>.<br />
-     Updated user guide.<br />
<br />
Version 4.1, Oct 2021<br />
-     Adjusted <code>SampleSize.Poisson</code>.<br />
-     Updated user guide.<br />
<br />
Version 4.2, Feb 2022<br />
-     Adjusted <code>AnalyzeSetUp.Poisson</code>.<br />
-     Updated user guide.<br />
<br />
Version 4.3, April 2022<br />
-     Adjusted <code>Analyze.Binomial</code> for bugs on the relative risk estimate under variable matching ratio.<br />
-     Updated user guide.<br />
<br />
Version 4.3.1, Oct 2023<br />
-	Updated reference for the bounded-length confidence interval following sequential analysis with binary data.<br />
<br />
Version 4.3.2, Dec 2023<br />
-	Correction of bugs in the Analyze.CondPoisson function.<br />
<br />
Version 4.3.3, Feb 2024<br />
-	Updated user guide.<br />
<br />
Version 4.3.4, Oct 2024<br />
-	Correction of bugs in theAnalyze.CondPoisson function.<br />
<br />
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.<br />
Maintainer: Ivair Ramos Silva &lt;ivair@ufop.edu.br&gt;
</p>


<h3>References</h3>

<p>Chin R. (2012), Adaptive and Flexible Clinical Trials, Boca Raton, FL: Chapman and Hall/CRC.
</p>
<p>Cook TD, DeMets DL. (2007), Introduction to Statistical Methods for Clinical Trials: Chapman and Hall/CRC Texts in Statistical Science. 
</p>
<p>Fireman B, et al. (2013), Exact sequential analysis for binomial data with timevarying probabilities. Manuscript in Preparation.
</p>
<p>Friedman LM, Furberg CD, DeMets D. (2010), Fundamentals of Clinical Trials, 4th ed.: Springer. 
</p>
<p>Ghosh BK, Sen PK. (1991), Handbook of Sequential Analysis, New York: MARCEL DEKKER, Inc. 
</p>
<p>Ghosh M, Mukhopadhyay N, Sen PK. (2011), Sequential Estimation: Wiley.
</p>
<p>Jennison C, Turnbull B. (2000), Group Sequential Methods with Applications to Clinical
Trials, London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011), A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. Sequential Analysis, 30: 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015), Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>
<p>Li L, Kulldorff M. (2010), A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>Mukhopadhyay N, Silva BM. (2002), Sequential Methods and Their Applications, 1th ed.: Chapman and Hall/CRC. 
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2021), Exact sequential test for clinical trials and post-market drug and vaccine safety surveillance with Poisson and binary data. Statistics in Medicine, 40(22), 4890&ndash;4913.
</p>
<p>Silva IR, Kulldorff M, Yih W. Katherine. (2020), Optimal alpha spending for sequential analysis with binomial data. Journal of the Royal Statistical Society Series B, 82(4) p. 1141&ndash;1164.
</p>
<p>Silva IR, Gagne J, Najafzadeh M, Kulldorff M. (2020), Exact Sequential Analysis for Multiple Weighted Binomial Endpoints. Statistics in Medicine, 39(3), 340&ndash;351.
</p>
<p>Silva IR, Li L, Kulldorff M. (2019a), Exact conditional maximized sequential probability ratio test adjusted for covariates. Sequential Analysis, 38(1), 115&ndash;133.
</p>
<p>Silva IR. (2018a), Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance with Binomial Data. Statistics in Medicine, 15;37(1), 107&ndash;118.
</p>
<p>Silva IR. (2018b), Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance With Poisson Data. Methodol Comput Appl Probab, 20(2), 739&ndash;750.
</p>
<p>Silva IR, Lopes LM, Dias P, Yih WK. (2019b), Alpha Spending for Historical Versus Surveillance Poisson Data With CMaxSPRT. Statistics in Medicine, 38(12), 2126&ndash;2138. 
</p>
<p>Silva IR, Montalban, J. (2023), The person-time ratio distribution for the exact monitoring of adverse events: Historical vs surveillance Poisson data, Statistics in Medicine, 42(18), 3283&ndash;3301.
</p>
<p>Silva IR, Oliveira, F. (2023), Matching ratio and sample size for optimal sequential testing with binomial data, Statistical Methods in Medical Research, DOI: 10.1177/0962280223117603.
</p>
<p>Silva IR, Zhuang, Y. (2022), Bounded-width confidence interval following optimal sequential analysis of adverse events with binary data, Statistical Methods in Medical Research, 31(12), 2323&ndash;2337.
</p>
<p>Xia Qi. (2007), A Procedure for Group Sequential Comparative Poisson Trials. Journal of Biopharmaceutical Statistics, 17, 869&ndash;881. 
</p>
<p>Wald A. (1945), Sequential Tests of Statistical Hypotheses, Annals of Mathematical Statistics, 16, 117&ndash;186.
</p>
<p>Wald A. (1947), Sequential Analysis. New York: John Wiley and Sons.
</p>
<p>Whitehead J. (1997), The Design and Analysis of Sequential Clinical Trials, 2th ed.: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Critical value for continuous sequential analyses for Poisson Data.
## Maximum sample size = 10, alpha = 0.05 and minimum number of events = 3:

cvt&lt;- CV.Poisson(SampleSize=10,D=0,M=3,alpha=0.05)

## Statistical power and the expected time to signal for relative risk RR=2:

result&lt;- Performance.Poisson(SampleSize=10,D=0,M=3,cv=cvt,RR=2)

# And if you type:
result

# Then you will see the following:
#          Power ESignalTime ESampleSize
#     [1,] 0.7329625    4.071636    5.654732

</code></pre>

<hr>
<h2 id='Analyze.Binomial'>Function for group sequential analyses for binomial data, without the need to know group sizes a priori.</h2><span id='topic+Analyze.Binomial'></span>

<h3>Description</h3>

<p>The function <code>Analyze.Binomial</code> is used for either continuous or group sequential analysis, or for a  combination of the two. Unlike <code>CV.Binomial</code> and <code>CV.G.Binomial</code>, it is not necessary to pre-specify the group sizes before the sequential analysis starts. Moreover, under the null hypothesis, the binomial probability, p, can be different for different observations. In a matched case-control setting, this means that the matching ratios can be different for different matched sets.  It is possible to use either a Wald type rejection boundary, which is flat with respect to the likelihood ratio, or a user defined alpha spending function. <code>Analyze.Binomial</code> is run at each look at the data. Before running it by the first time, it is necessary to run the <code><a href="#topic+AnalyzeSetUp.Binomial">AnalyzeSetUp.Binomial</a></code> function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Analyze.Binomial(name,test,z="n",p="n",cases,controls,AlphaSpend="n")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Analyze.Binomial_+3A_name">name</code></td>
<td>
<p>The name of the sequential analysis. Must be identical for all looks at the data, and it must be the same as the name given by the <code>AnalyzeSetup.Binomial</code> function. Should never be the same as another sequential analysis that is run simultaneously on the same computer.</p>
</td></tr>
<tr><td><code id="Analyze.Binomial_+3A_test">test</code></td>
<td>
<p>An integer indicating the number of hypothesis tests performed up to and including the current test. For example, if there were four prior looks at the data, and this is the fifth one, then &quot;test=5&quot;. This number should be increased by one each time that the <code>Analyze.Binomial</code> function is run for a new group of data, when it is part of the same sequential analysis.  If not, there is an error message.</p>
</td></tr>
<tr><td><code id="Analyze.Binomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case. For example, if there are 3 controls matched to each case, &quot;z=3&quot;. In a self-control analysis, z is the ratio of the length of the control interval to the length of the risk interval. For example, if the risk interval is 2 days long and the control interval is 7 days long, &quot;z=7/2&quot;. In terms of p, the binomial probability under the null hypothesis, &quot;p=1/(1+z)&quot;, or equivalently, &quot;z=1/p-1&quot;. The parameter z must be a positive number. The default value is z=1 (p=0.5). If the ratio is the same for all observations, then z can be any positive number. If the ratio is different for different observations, then z is a vector of positive numbers.</p>
</td></tr>
<tr><td><code id="Analyze.Binomial_+3A_p">p</code></td>
<td>
<p>The probability of having a case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Analyze.Binomial_+3A_cases">cases</code></td>
<td>
<p>A number or a vector of the same length as z containing the number of cases.</p>
</td></tr>
<tr><td><code id="Analyze.Binomial_+3A_controls">controls</code></td>
<td>
<p>A number or a vector of the same length as z containing the number of controls.</p>
</td></tr>
<tr><td><code id="Analyze.Binomial_+3A_alphaspend">AlphaSpend</code></td>
<td>
<p>The alpha spending function is specified in the <code>AnalyzeSetUp.Binomial</code> function. At any look at the data, it is possible to over ride that pre-specified alpha spending plan by using the AlphaSpend parameter. AlphaSpend is a number representing the maximum amount of alpha (Type I error probabiliy) to be spent up to and including the current test. Because of the discrete nature of the binomial distribution, the actual amount of alpha spent may be less than the maximum amount specified. It must be in the range (0,alpha]. The default value is no override, which means that, if AlphaSpend= &quot;n&quot;, then the function will use the alpha spending plan specified in the <code>AnalyzeSetUp.Binomial</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>Analyze.Binomial</code> performs continuous or group sequential analysis for Bernoulli or binomial data. It can also be used for mixed continuous-group sequential
analysis where some data arrives continuously while other data arrives in groups. Unlike <code>CV.Binomial</code> and <code>CV.G.Binomial</code>, there is (i) no need to pre-specify the
group sizes before the sequential analysis starts, (ii) a variety of alpha spending functions are available, and (iii)  it is possible to include an offset term where,
under the null hypothesis, different observations have different binomial probabilities p.
</p>
<p>In sequential analysis, data is formed by cumulative information, collected in separated chunks or groups, which are observed at different moments in time. <code>Analyze.Binomial</code>
is run each time a new group of data arrives at which time a new sequential test is conducted. When running <code>Analyze.Binomial</code>, only the data from the new group should be
included when calling the function. The prior data has been stored, and it will be automatically retrieved by <code>Analyze.Binomial</code>, with no need to reenter that data. Before
running <code>Analyze.Binomial</code>  for the first time, it is necessary to set up the sequential analysis using the <code>AnalyzeSetUp.Bionimial</code> function, which is run once,
and just once, to define the sequential analysis parameters. For information about this, see the description of the <code><a href="#topic+AnalyzeSetUp.Binomial">AnalyzeSetUp.Binomial</a></code> function. 
</p>
<p>The function <code>Analyze.Binomial</code> calculates critical values to determine if the null hypothesis should be rejected or not at each analysis. Critical values are given in the
scale of the number of cases. This is done for a pre-specified overall statistical significance level (alpha), and for an upper limit on the sample size (N).
The exact analytical solution is obtained through numerical calculations. Based on the data and the critical value, the function determines if the null hypothesis should
be rejected or not, and if subsequent tests should be conducted. After each test, the function also provides information about the amount of alpha that has been spent,
the cumulative number of cases and controls, and the maximum likelihood estimate of the relative risk. 
</p>
<p>For binomial and Bernoulli data, there are a number of 0/1 observations that can either be a case or a control. Under the null hypothesis, the probability of being a case is p,
and the probability of being a control is 1-p. If data comes from a self-control analysis, the observation is a case if the event occurred in the risk interval, and it is a control
if the event occurred in the control interval. Under the null hypothesis, we then have that <code class="reqn">p=1/(1+z)</code>, where z is the ratio of the length of the control interval to the length of the
risk interval. This ratio, and hence p, does not need to be the same for all observations. If data comes from a matched set of exposed and unexposed individuals, then the observation
is a case if the event occurred among one of the exposed, and it is a control if it occurred among one of the unexposed. Under the null hypothesis, <code class="reqn">p=1/(1+z)</code>, where z is the number of
unexposed individuals divided by the number of exposed individuals in the matched set. Again, this ratio does not have to be the same for all matched sets.  The variable z can be any
positive number. 
</p>
<p>If the ratio parameter z, and hence p, is the same for all observations in the same group of data, then z is just a positive number. On the other hand, if different observations in the
same group of data have different values for z, then z is a vector, representing multiple z values. For each value of z, it is necessary to specify the number of cases and the number
of controls. This means that for a group of data, the vector of zs has to be of the same length as the vector of cases and the vector of controls. The first entry of the vector
z is the matching ratio associated to the first entries of cases and of controls. The second entry of z is the matching ratio with respect to the second entries of cases and
of controls, and so on. For example, consider that each of five observations came from four different matching ratios. In this situation, the vectors cases, controls and z are
all of length four. For example, suppose &quot;z=c(2,1,0.5,3)&quot;,  &quot;cases=c(1,1,0,0)&quot; and &quot;controls=c(0,0,1,2)&quot;. The matching ratio for the first observation, which turned out as a case,
is equal to 2. For the second observation, also a case, the matching is equal to 1. With a matching ration of 0.5, the third observation turned out to be a control. The two last
observations both had a matching ratio of 3, and both of them were controls. If all observations in the same data group has the same ratio, the vectors are of size one, that is,
they are simple numbers. For example, if there were ten observations that all had a ratio of 2, with seven cases and three controls, we have &quot;z=2&quot;, &quot;cases=7&quot;, and &quot;controls=3&quot;. 
</p>
<p>Alternatively, instead of z the user can specify p directly.
Note that only one of these inputs, z or p, has to be specified, but if both are entered the code will only work if z and p are such that p=1/(1+z).
Otherwise, an error message will appear to remind that such condition must be complied.
</p>
<p>Before running <code>Analyze.Binomial</code>, it is necessary to specify a planned default alpha spending function, which is done using the AlphaSpendType parameter in the
<code>AnalyzeSetUp.Binomial</code> function. The default alpha spending plan can be either, (i) the optimal alpha spending derived by Silva and Kulldorff (2018), which
demands users to choose between minimizing expected time to signal or expected sample size, or (ii) the polynomial power-type alpha spending plan, which is
parameterized with rho, which, according to Silva (2018), 'rho=0.5' is indicated when expected time to signal is the design criterion, hence the default in <code>AnalyzeSetUp.Binomial</code>,
or (iii) the alpha spending associated to the Wald-type rejection boundary, which is flat with respect to the likelihood ratio. See the
<code><a href="#topic+AnalyzeSetUp.Binomial">AnalyzeSetUp.Binomial</a></code> for more details. 
</p>
<p>In most cases, this pre-specified alpha spending function is used throughout the analysis, but if needed, it is possible to override it at any or each of the sequential tests.
This is done using the AlphaSpend parameter, which specifies the maximum amount of alpha to spend up to and including the current test. In this way, it is possible to use any
alpha spending function, and not only those available in <code>AnalyzeSetUp.Binomial</code>. It is also possible to use a flexible adaptive alpha spending plan that is not set in stone
before the sequential analysis starts. The only requirement is that for a particular test with a new group of data, AlphaSpend must be decided before knowing the number of cases
and controls in that group. To ensure a statistically valid sequential analysis, AlphaSpend can only depend on the number of events (cases + controls) at prior tests and the total
number of events in the current test. This is important.
</p>
<p>The function <code>Analyze.Binomial</code> is meant to perform the binomial sequential analysis with a certain level of autonomy. After running a test, the code offers a synthesis about
the general parameter settings, the main conclusions concerning the acceptance or rejection of the null hypothesis, and the historical information from previous tests.
A table with the main analyses results is automatically printed in the R console. Each column of the table contains a historical characteristic,
including the information for the current test. Each line of the table corresponds to a specific test organized by calendar time. The table is titled with the title
input defined through the function <code>AnalyzeSetUp.Binomial</code>, and its columns are organized and labeled in the following way: &quot;Test&quot;,
&quot;Cases&quot;, &quot;Controls&quot;, &quot;Cumulative Cases&quot;, &quot;Cumulative Controls&quot;, &quot;Cumulative E[Cases]&quot;, &quot;RR&quot;, &quot;LLR&quot;, &quot;target&quot;, &quot;actual&quot;, &quot;CV&quot;, &quot;Reject H0&quot;. Here follows a short description of each column:
</p>
<p>-	&quot;Test&quot; shows the order of the analysis, i.e., the arrival order of each chunk of data. 
</p>
<p>-	&quot;Cases&quot; and &quot;Controls&quot; present the total of cases and controls that entered at each test, respectively.
</p>
<p>-	&quot;Cumulative Cases&quot; and &quot;Cumulative Controls&quot; in the i-th line have the cumulative counts of cases and controls up to the i-th test, respectively. 
</p>
<p>-	&quot;Cumulative E[Cases]&quot; in line i is the expected cumulative number of cases for the i-th test under the null hypothesis.
</p>
<p>-	&quot;RR&quot; is the estimated relative risk for test i. 
</p>
<p>-	&quot;LLR&quot; is the observed log-likelihood ratio test statistic.
</p>
<p>-	&quot;target&quot; is the target alpha spending for the i-th test.
</p>
<p>-	&quot;actual&quot; is the actual alpha spent up to the i-th test. 
</p>
<p>-	&quot;CV&quot; is the critical value in the scale of the number of cases, showing how many casesa re needed to reject the null hypothesis at this test.
</p>
<p>-	&quot;Reject H0&quot; is a logical variable that is &quot;Yes&quot; when the null hypothesis is rejected, and the label &quot;No&quot; when H0 is not to be rejected
</p>
<p>Observe that, because the binomial distribution is discrete, the target alpha spending will rarely be reached. The actual alpha spending is then shown to facilitate
a realistic interpretation of the results. 
</p>
<p>The function <code>Analyze.Binomial</code> was designed to instruct the user with minimal information about bugs from the code, or about non-applicable parameter input usages. Some entries are not
applicable for the parameter inputs. For example, the input &quot;z&quot; must be a positive number, and then if the user sets &quot;z= -1&quot;, the code will report an error with the message &quot;the entries of
the vector &quot;z&quot; must be positive numbers&quot;. Thus, messages will appear when mistakes and inconsistencies are detected, and instructions about how to proceed to solve such problems will automatically appear. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>result</code></td>
<td>
<p>A table containing the main characteristics, conclusions concerning the acceptance or rejection of the null hypothesis, and the historical information from previous tests.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the <code>Analyze.Binomial</code> function was funded by:
- Food and Drug Administration, Center for Drug Evaluation and Research, through Mini-Sentinel Project: base version, documentation, unequal matching ratios;<br />
- National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999: user-defined alpha spending functions, power-type alpha spending function,
increased computational speed, confidence intervals for relative risks, end of schedule analysis using left-over alpha, enhanced error handling and messages, improved documentation.
</p>
<p>We thank Claudia Coronel-Moreno for valuable editorial support, Bruce Fireman for general guidance, and Josh Gagne for important feedback on the unequal matching ratio feature. 
</p>


<h3>See also</h3>

<p><code><a href="#topic+AnalyzeSetUp.Binomial">AnalyzeSetUp.Binomial</a></code>: for setting up sequential analysis with the <code>Analyze.Binomial</code> function, before the first look at the data.<br /> 
<code><a href="#topic+SampleSize.Binomial">SampleSize.Binomial</a></code>: for calculating the needed sample size to achieve the desired statistical power for continuous sequential analysis with binomial data.<br /> 
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva,  Ned Lewis, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Fireman B, et al. (2013). Exact sequential analysis for binomial data with time varying probabilities. Manuscript in preparation.
</p>
<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials. London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. Sequential Analysis, 30, 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous post-market sequential safety surveillance with minimum
events to signal. arxiv:1503.01978 [stat.ap].
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71(3), 851&ndash;858. 
</p>
<p>Silva IR, Kulldorff M, Yih W. Katherine. (2020), Optimal alpha spending for sequential analysis with binomial data. Journal of the Royal Statistical Society Series B, 82(4) p. 1141&ndash;1164.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance with Binomial Data. Statistics in Medicine, 15;37(1), 107-118.
</p>
<p>Silva IR, Zhuang, Y. (2022), Bounded-width confidence interval following optimal sequential analysis of adverse events with binary data, Statistical Methods in Medical Research, 31(12), 2323&ndash;2337.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example. Four chunks of data.

### Firstly, it is necessary to set up the input parameters.
##  Here we use the Wald type alpha spending.
##  Note: cut off the "#" symbol before running the two lines below.
#     AnalyzeSetUp.Binomial(name="VaccineA",N=200,alpha=0.05,zp=1,M=3,
#     AlphaSpendType="Wald", title="Monitoring_vaccineA",
#     address="C:/Users/Ivair/Documents")

### Now we apply sequential tests to each of four chunks of data.
# -------------------------------------------------------------------------
  
## Test 1 - Situation where each individual event came from a different
## matching ratio.
## This first test uses the default Wald type alpha spending (AlphaSpend="n").
## Note: cut off the "#" symbol before running the line below.
#  Analyze.Binomial(name= "VaccineA",test=1,z=c(1.1,1.3,1.2,1),
#  cases= c(1,0,0,0), controls= c(0,1,1,1) )

## Test 2 - Situation where some of the events came from the same matching
## ratio.
## Observe that here we use an arbitrary alpha spending of 0.02.
## Note: cut off the "#" symbol before running the line below.
#  Analyze.Binomial(name= "VaccineA",test=2,z=c(1,1.5),cases= c(12,1),
#  controls= c(0,10), AlphaSpend=0.02)

## Test 3 - Situation of elevated number of events, but now the
## arbitrary alpha spending is of 0.04, and p is entered instead of z.
## Note: cut off the "#" symbol before running the line below.
#  Analyze.Binomial(name= "VaccineA",test=3,p=c(0.4,0.5),cases= c(12,10),
#  controls= c(10,14), AlphaSpend=0.04)
 
## Test 4 - Situation where all the events came from the same matching
## ratio.
## Here the original target alpha spending is used.
## Note: cut off the "#" symbol before running the line below.
#  Analyze.Binomial(name= "VaccineA",test=4,z=2,cases= 20,controls= 10)
</code></pre>

<hr>
<h2 id='Analyze.CondPoisson'>Function to conduct group sequential analyses for conditional Poisson data without the need to know group sizes a priori.</h2><span id='topic+Analyze.CondPoisson'></span>

<h3>Description</h3>

<p>The function <code>Analyze.CondPoisson</code> is used for either continuous, group, or mixed continuous-group sequential analysis for Poisson data conditioned on observed historical data. Unlike <code>CV.CondPoisson</code>, it is not necessary that data arrives in a near-continuous fashion. It is possible to use either a Wald type rejection boundary, which is flat with respect to the likelihood ratio, or a user defined alpha spending function. <code>Analyze.CondPoisson</code> is run at each look at the data. Before running it by the first time, it is necessary to run the <code><a href="#topic+AnalyzeSetUp.CondPoisson">AnalyzeSetUp.CondPoisson</a></code> function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Analyze.CondPoisson(name,test,events,PersonTimeRatio,AlphaSpend="n")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Analyze.CondPoisson_+3A_name">name</code></td>
<td>
<p>The name of the sequential analysis. Must be identical for all looks at the data, and it must be the same as the name given by the <code>AnalyzeSetup.CondPoisson</code> function. Should never be the same as another sequential analysis that is run simultaneously on the same computer.</p>
</td></tr>
<tr><td><code id="Analyze.CondPoisson_+3A_test">test</code></td>
<td>
<p>An integer indicating the number of hypothesis tests performed up to and including the current test. For example, if there were four prior looks at the data, and this is the fifth one, then &quot;test=5&quot;. This number should be increased by one each time that the <code>Analyze.CondPoisson</code> function is run for a new group of data, when it is part of the same sequential analysis.  If not, there is an error message.</p>
</td></tr>
<tr><td><code id="Analyze.CondPoisson_+3A_events">events</code></td>
<td>
<p>The test-specific number of events, instead of the cumulative number, observed during the surveillance period.</p>
</td></tr>
<tr><td><code id="Analyze.CondPoisson_+3A_persontimeratio">PersonTimeRatio</code></td>
<td>
<p>The observed ratio between the punctual, instead of cumulative from previous tests, person-time observed in the current test, by the total person-time observed in the historical period.</p>
</td></tr>
<tr><td><code id="Analyze.CondPoisson_+3A_alphaspend">AlphaSpend</code></td>
<td>
<p>The alpha spending function is specified in the <code>AnalyzeSetUp.CondPoisson</code> function. At any look at the data, it is possible to over ride that pre-specified alpha spending plan by using the AlphaSpend parameter. AlphaSpend is a number representing the maximum amount of alpha (Type I error probabiliy) to be spent up to and including the current test. Because of the discrete nature of the Poisson distribution, the actual amount of alpha spent may be less than the maximum amount specified. It must be in the range (0,alpha]. The default value is no override, which means that, if AlphaSpend= &quot;n&quot;, then the function will use the alpha spending plan specified in the <code>AnalyzeSetUp.CondPoisson</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>Analyze.CondPoisson</code> performs continuous or group sequential analysis for Poisson data conditioned on observed historical data, (Li and Kulldorff, 2010).
It can also be used for mixed continuous-group sequential analysis where some data arrives continuously while other data arrives in groups.
Unlike <code>CV.CondPoisson</code>, there is a variety of alpha spending functions are available.
</p>
<p>In sequential analysis, data is formed by cumulative information, collected in separated chunks or groups, which are observed at different moments in time.
<code>Analyze.CondPoisson</code> is run each time a new group of data arrives at which time a new sequential test is conducted. When running <code>Analyze.CondPoisson</code>,
only the data from the new group should be included when calling the function. The prior data has been stored, and it will be automatically retrieved by
<code>Analyze.CondPoisson</code>, with no need to reenter that data. Before
running <code>Analyze.CondPoisson</code> for the first time, it is necessary to set up the sequential analysis using the <code>AnalyzeSetUp.CondPoisson</code> function, which
is run once, and just once, to define the sequential analysis parameters. For information about this, see the description of the
<code><a href="#topic+AnalyzeSetUp.CondPoisson">AnalyzeSetUp.CondPoisson</a></code> function. 
</p>
<p>The function <code>Analyze.CondPoisson</code> calculates critical values to determine if the null hypothesis should be rejected or not at each analysis.
Critical values are given in the
scale of the number of events. This is done for a pre-specified overall statistical significance level (alpha), and for an upper limit on the sample size, which is
given by &quot;T&quot; or &quot;K&quot;. Go to the documentation of <code><a href="#topic+AnalyzeSetUp.CondPoisson">AnalyzeSetUp.CondPoisson</a></code> for more details about the choice between &quot;T&quot; or &quot;K&quot;.
</p>
<p>The exact analytical solution is obtained through numerical calculations. Based on the data and the critical value, the function determines if the null hypothesis should
be rejected or not, and if subsequent tests should be conducted. After each test, the function also provides information about the amount of alpha that has been spent,
the cumulative number of events, and the observed log-likelihood ratio statistic. 
</p>
<p>Before running <code>Analyze.CondPoisson</code>, it is necessary to specify a planned default alpha spending function, which is done using the AlphaSpendType parameter in the
<code>AnalyzeSetUp.CondPoisson</code> function. The default alpha spending plan can be either, (i) the polynomial power-type alpha spending plan, which is parameterized with rho,
or (ii) the alpha spending associated to the Wald-type rejection boundary, which is flat with respect to the likelihood ratio. See the <code><a href="#topic+AnalyzeSetUp.CondPoisson">AnalyzeSetUp.CondPoisson</a></code>
for more details. 
</p>
<p>In most cases, this pre-specified alpha spending function is used throughout the analysis, but if needed, it is possible to override it at any or each of the sequential tests.
This is done using the AlphaSpend parameter, which specifies the maximum amount of alpha to spend up to and including the current test. In this way, it is possible to use any
alpha spending function, and not only those available in <code>AnalyzeSetUp.CondPoisson</code>. It is also possible to use a flexible adaptive alpha spending plan that is not set in stone
before the sequential analysis starts. The only requirement is that for a particular test with a new group of data, AlphaSpend must be decided before knowing the PersonTimeRatio
in that group. Hence, in order to ensure a statistically valid sequential analysis, AlphaSpend can only depend on the cumulative events.
This is important.
</p>
<p>The function <code>Analyze.CondPoisson</code> is meant to perform the conditional Poisson sequential analysis with a certain level of autonomy. After running a test, the code offers a synthesis about
the general parameter settings, the main conclusions concerning the acceptance or rejection of the null hypothesis, and the historical information from previous tests.
A table with the main analyses results is automatically printed in the R console. Each column of the table contains a historical characteristic,
including the information for the current test. Each line of the table corresponds to a specific test organized by calendar time. The table is titled with the title
input defined through the function <code>AnalyzeSetUp.CondPoisson</code>, and its columns are organized and labeled in the following way:
&quot;Test&quot;,&quot;Person-timeR&quot;,&quot;events&quot;,&quot;Cumulative Person-timeR&quot;,&quot;Cumulative events&quot;,&quot;LLR&quot;, &quot;target&quot;,&quot;actual&quot;,&quot;CV&quot;,&quot;Reject H0&quot;. Here follows a short description of each column:
</p>
<p>-	&quot;Test&quot; shows the order of the analysis, i.e., the arrival order of each chunk of data. 
</p>
<p>-	&quot;Person-timeR&quot; shows the observed ratio between the punctual person-time observed in the current test by the total person-time observed in the historical period.
</p>
<p>-	&quot;Events&quot; presents the observed number of events from the Poisson counting entered at each test.
</p>
<p>-	&quot;Cumulative Person-timeR&quot; shows the observed person-time ratio up to the current test.
</p>
<p>-	&quot;Cumulative events&quot; presents the observed number of events from the Poisson counting up to the current test.
</p>
<p>-	&quot;LLR&quot; is the observed log-likelihood ratio test statistic.
</p>
<p>-	&quot;target&quot; is the target alpha spending for the i-th test.
</p>
<p>-	&quot;actual&quot; is the actual alpha spent up to the i-th test. 
</p>
<p>-	&quot;CV&quot; is the critical value in the scale of the log-likelihood ratio test statistic.
</p>
<p>-	&quot;Reject H0&quot; is a logical variable that receives the label &quot;Yes&quot; when the null hypothesis is rejected, and the label &quot;No&quot; when H0 is not to be rejected
</p>
<p>Observe that, depending on the choices of the input parameters M and alpha through the <code><a href="#topic+AnalyzeSetUp.CondPoisson">AnalyzeSetUp.CondPoisson</a></code> function,
the actual alpha spending can differ from the target one. The actual alpha spending is then shown in order to favor a realistic interpretation of the results. 
</p>
<p>The function <code>Analyze.CondPoisson</code> was designed to instruct the user with minimal information about bugs from the code, or about non-applicable input parameters
usage. Some entries are not applicable. For example, the input &quot;Person-timeR&quot; must be a positive number, and then if the user sets &quot;Person-timeR= -1&quot;,
then the code will report an error with the message &quot;the entry of &quot;Person-timeR&quot; must be a number greater than zero&quot;. Thus, messages will appear when mistakes
and inconsistencies are detected. Instructions about how to proceed to solve such problems will automatically appear too. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>result</code></td>
<td>
<p>A table containing the main characteristics, conclusions concerning the acceptance or rejection of the null hypothesis, and the historical information from previous tests.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the <code>Analyze.CondPoisson</code> function was funded by:
- National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999.
- Foundation for Research Support of Minas Gerais State (FAPEMIG), MG, Brazil, through the grant Demanda Universal.
</p>


<h3>See also</h3>

<p><code><a href="#topic+AnalyzeSetUp.CondPoisson">AnalyzeSetUp.CondPoisson</a></code>: for setting up sequential analysis with the <code>Analyze.CondPoisson</code> function, before the first look at the data.<br />
<code><a href="#topic+AnalyzeSetUp.Poisson">AnalyzeSetUp.Poisson</a></code>: for setting up sequential analysis with the <code>Analyze.Poisson</code> function, before the first look at the data.<br /> 
<code><a href="#topic+SampleSize.Poisson">SampleSize.Poisson</a></code>: for calculating the needed sample size to achieve the desired statistical power for continuous sequential analysis with Poisson data.<br />
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Fireman B, et al. (2013). Exact sequential analysis for Poisson data with time varying probabilities. Manuscript in preparation.
</p>
<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials. London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. Sequential Analysis, 30, 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>
<p>Li L, Kulldorff M. (2010). A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71(3), 851&ndash;858.
</p>
<p>Silva IR, Li L, Kulldorff M. (2019). Exact conditional maximized sequential probability ratio test adjusted for covariates. Sequential Analysis, 38(1), 115&ndash;133.
</p>
<p>Silva IR., Lopes LM., Dias P., Yih WK. (2019). Alpha Spending for Historical Versus Surveillance Poisson Data With CMaxSPRT. Statistics in Medicine, DOI: 10.1002/sim.8097, 1&ndash;13. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example. Three chunks of data with a total person time
#   in the historical period equal to 10,000. 

### Firstly, it is necessary to set up the input parameters.
##  Here we use the Wald type alpha spending.
##  Note: cut off the "#" symbol before running the two lines below, and,
##  Important: choose an actual "address" to save your set up information. 
#   AnalyzeSetUp.CondPoisson(name="TestA", SampleSizeType="Events", K=100,
#   cc=20,alpha=0.05, M=1,AlphaSpendType="power-type",rho=0.5,title="n",
#   address="C:/Users/Ivair/Documents")

### Now we apply a test for each one of three chunks of data.
# -------------------------------------------------------------------------
  
## Test 1 - Situation where the fixed number of events is equal to 5.
## The observed information is "PersonTimeRatio=5000/10000=0.5".
## Note: cut off the "#" symbol before running the line below.

#  Analyze.CondPoisson(name="TestA",test=1,events=5,PersonTimeRatio=0.5)


## Test 2 - Situation where the fixed number of new events is equal to 6.
## The observed information is "PersonTimeRatio=3000/10000=0.3".

#Analyze.CondPoisson(name="TestA",test=2,events=6,PersonTimeRatio=0.3)


## Test 3 - Situation where the fixed number of events is equal to 10.
## The observed information is "PersonTimeRatio=1000/10000=0.1".

#Analyze.CondPoisson(name="TestA",test=3,events=10,PersonTimeRatio=0.1)
 
</code></pre>

<hr>
<h2 id='Analyze.Poisson'>Function to conduct group sequential analyses for Poisson data without the need to know group sizes a priori.</h2><span id='topic+Analyze.Poisson'></span>

<h3>Description</h3>

<p>The function <code>Analyze.Poisson</code> is used for either continuous or group sequential analysis, or for a  combination of the two. Unlike <code>CV.Poisson</code> and <code>CV.G.Poisson</code>, it is not necessary to pre-specify the group sizes before the sequential analysis starts. Moreover, under the null hypothesis, the expected number of events, mu0, can be different for different observations.  It is possible to use either a Wald type rejection boundary, which is flat with respect to the likelihood ratio, or a user defined alpha spending function. <code>Analyze.Poisson</code> is run at each look at the data. Before running it by the first time, it is necessary to run the <code><a href="#topic+AnalyzeSetUp.Poisson">AnalyzeSetUp.Poisson</a></code> function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Analyze.Poisson(name,test,mu0="n",cum.mu0="n",events,AlphaSpend="n")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Analyze.Poisson_+3A_name">name</code></td>
<td>
<p>The name of the sequential analysis. Must be identical for all looks at the data, and it must be the same as the name given by the <code>AnalyzeSetup.Poisson</code> function. Should never be the same as another sequential analysis that is run simultaneously on the same computer.</p>
</td></tr>
<tr><td><code id="Analyze.Poisson_+3A_test">test</code></td>
<td>
<p>An integer indicating the number of hypothesis tests performed up to and including the current test. For example, if there were four prior looks at the data, and this is the fifth one, then &quot;test=5&quot;. This number should be increased by one each time that the <code>Analyze.Poisson</code> function is run for a new group of data, when it is part of the same sequential analysis.  If not, there is an error message.</p>
</td></tr>
<tr><td><code id="Analyze.Poisson_+3A_mu0">mu0</code></td>
<td>
<p>The test specific expected number of events under the null hypothesis. The parameter mu0 must be a positive number. There is no default value unless cum.mu0 is specified instead.</p>
</td></tr>
<tr><td><code id="Analyze.Poisson_+3A_cum.mu0">cum.mu0</code></td>
<td>
<p>The cumulative expected number of events under the null hypothesis. The parameter cum.mu0 must be a positive number. There is no default value unless mu0 specified instead.</p>
</td></tr>
<tr><td><code id="Analyze.Poisson_+3A_events">events</code></td>
<td>
<p>The number of observed events.</p>
</td></tr>
<tr><td><code id="Analyze.Poisson_+3A_alphaspend">AlphaSpend</code></td>
<td>
<p>The alpha spending function is specified in the <code>AnalyzeSetUp.Poisson</code> function. At any look at the data, it is possible to over ride that pre-specified alpha spending plan by using the AlphaSpend parameter. AlphaSpend is a number representing the maximum amount of alpha (Type I error probabiliy) to be spent up to and including the current test. Because of the discrete nature of the Poisson distribution, the actual amount of alpha spent may be less than the maximum amount specified. It must be in the range (0,alpha]. The default value is no override, which means that, if AlphaSpend= &quot;n&quot;, then the function will use the alpha spending plan specified in the <code>AnalyzeSetUp.Poisson</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>Analyze.Poisson</code> performs continuous or group sequential analysis for Poisson data. It can also be used for mixed continuous-group sequential
analysis where some data arrives continuously while other data arrives in groups. Unlike <code>CV.Poisson</code> and <code>CV.G.Poisson</code>, there is (i) no need to pre-specify the
group sizes before the sequential analysis starts, (ii) a variety of alpha spending functions are available, and (iii)  it is possible to include an offset term where,
under the null hypothesis, different observations have different Poisson rates mu0.
</p>
<p>In sequential analysis, data is formed by cumulative information, collected in separated chunks or groups, which are observed at different moments in time. <code>Analyze.Poisson</code>
is run each time a new group of data arrives at which time a new sequential test is conducted. When running <code>Analyze.Poisson</code>, only the data from the new group should be
included when calling the function. The prior data has been stored, and it will be automatically retrieved by <code>Analyze.Poisson</code>, with no need to reenter that data. Before
running <code>Analyze.Poisson</code>  for the first time, it is necessary to set up the sequential analysis using the <code>AnalyzeSetUp.Poisson</code> function, which is run once,
and just once, to define the sequential analysis parameters. For information about this, see the description of the <code><a href="#topic+AnalyzeSetUp.Poisson">AnalyzeSetUp.Poisson</a></code> function. 
</p>
<p>The function <code>Analyze.Poisson</code> calculates critical values to determine if the null hypothesis should be rejected or not at each analysis. Critical values are given in the
scale of the number of events. This is done for a pre-specified overall statistical significance level (alpha), and for an upper limit on the sample size (N).
The exact analytical solution is obtained through numerical calculations. Based on the data and the critical value, the function determines if the null hypothesis should
be rejected or not, and if subsequent tests should be conducted. After each test, the function also provides information about the amount of alpha that has been spent,
the cumulative number of events, and the estimated relative risk. 
</p>
<p>Before running <code>Analyze.Poisson</code>, it is necessary to specify a planned default alpha spending function, which is done using the AlphaSpendType parameter in the
<code>AnalyzeSetUp.Poisson</code> function. The default alpha spending plan can be either, (i) the polynomial power-type alpha spending plan, which is parameterized with rho,
and the default is rho=0.5 as suggested by Silva (2018), or (ii) the alpha spending associated to the Wald-type rejection boundary, which is flat with respect to the likelihood ratio. See the <code><a href="#topic+AnalyzeSetUp.Poisson">AnalyzeSetUp.Poisson</a></code>
for more details. 
</p>
<p>In most cases, this pre-specified alpha spending function is used throughout the analysis, but if needed, it is possible to override it at any or each of the sequential tests.
This is done using the AlphaSpend parameter, which specifies the maximum amount of alpha to spend up to and including the current test. In this way, it is possible to use any
alpha spending function, and not only those available in <code>AnalyzeSetUp.Poisson</code>. It is also possible to use a flexible adaptive alpha spending plan that is not set in stone
before the sequential analysis starts. The only requirement is that for a particular test with a new group of data, AlphaSpend must be decided before knowing the number of events
in that group. To ensure a statistically valid sequential analysis, AlphaSpend can only depend on cumulative mu0 values at prior tests and of the mu0 value in the current test.
This is important.
</p>
<p>The function <code>Analyze.Poisson</code> is meant to perform the Poisson sequential analysis with a certain level of autonomy. After running a test, the code offers a synthesis about
the general parameter settings, the main conclusions concerning the acceptance or rejection of the null hypothesis, and the historical information from previous tests.
A table with the main analyses results is automatically printed in the R console. Each column of the table contains a historical characteristic,
including the information for the current test. Each line of the table corresponds to a specific test organized by calendar time. The table is titled with the title
input defined through the function <code>AnalyzeSetUp.Poisson</code>, and its columns are organized and labeled in the following way: &quot;Test&quot;,
&quot;mu0&quot;, &quot;Events&quot;, &quot;Cumulative mu0&quot;, &quot;Cumulative Events&quot;, &quot;RR&quot;, &quot;LLR&quot;, &quot;target&quot;, &quot;actual&quot;, &quot;CV&quot;, &quot;Reject H0&quot;. Here follows a short description of each column:
</p>
<p>-	&quot;Test&quot; shows the order of the analysis, i.e., the arrival order of each chunk of data. 
</p>
<p>-     &quot;mu0&quot; is the expected number of events under the null hypothesis for the chunck of data to be analyzed at each test. 
</p>
<p>-	&quot;Events&quot; presents the observed number of events from the Poisson counting entered at each test.
</p>
<p>-     &quot;Cumulative mu0&quot; expected number of events under the null hypothesis up to the i-th test.
</p>
<p>-     &quot;Cumulative Events&quot; observed number of events up to the i-th test.
</p>
<p>-	&quot;RR&quot; is the estimated relative risk for test i. 
</p>
<p>-	&quot;LLR&quot; is the observed log-likelihood ratio test statistic.
</p>
<p>-	&quot;target&quot; is the target alpha spending for the i-th test.
</p>
<p>-	&quot;actual&quot; is the actual alpha spent up to the i-th test. 
</p>
<p>-	&quot;CV&quot; is the critical value in the scale of the number of events, showing how many events are needed to reject the null hypothesis at this test.
</p>
<p>-	&quot;Reject H0&quot; is a logical variable that is &quot;Yes&quot; when the null hypothesis is rejected, and the label &quot;No&quot; when H0 is not to be rejected
</p>
<p>Observe that, because the Poisson distribution is discrete, the target alpha spending will rarely be reached. The actual alpha spending is then shown to facilitate
a realistic interpretation of the results. 
</p>
<p>The function <code>Analyze.Poisson</code> was designed to instruct the user with minimal information about bugs from the code, or about non-applicable parameter input usages. Some entries are not
applicable for the parameter inputs. For example, the input &quot;mu0&quot; must be a positive number, and then if the user sets &quot;mu0= -1&quot;, the code will report an error with the message &quot;the entry of &quot;mu0&quot; must be a number greater than zero&quot;. Thus, messages will appear when mistakes and inconsistencies are detected, and instructions about how to proceed to solve such problems will automatically appear. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>result</code></td>
<td>
<p>A table containing the main characteristics, conclusions concerning the acceptance or rejection of the null hypothesis, and the historical information from previous tests.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the <code>Analyze.Poisson</code> function was funded by:
- National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999.
</p>


<h3>See also</h3>

<p><code><a href="#topic+AnalyzeSetUp.Poisson">AnalyzeSetUp.Poisson</a></code>: for setting up sequential analysis with the <code>Analyze.Poisson</code> function, before the first look at the data.<br /> 
<code><a href="#topic+SampleSize.Poisson">SampleSize.Poisson</a></code>: for calculating the needed sample size to achieve the desired statistical power for continuous sequential analysis with Poisson data.<br /> 
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva,  Ned Lewis, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Fireman B, et al. (2013). Exact sequential analysis for Poisson data with time varying probabilities. Manuscript in preparation.
</p>
<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials. London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. Sequential Analysis, 30, 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance With Poisson Data. Methodol Comput Appl Probab, 20(2), 739-750.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2021). Exact sequential test for clinical trials and post-market drug and vaccine safety surveillance with Poisson and binary data. Statistics in Medicine, DOI: 10.1002/sim.9094.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example. Four chunks of data.

### Firstly, it is necessary to set up the input parameters.
##  Here we use the Wald type alpha spending.
##  Note: cut off the "#" symbol before running the two lines below, and,
##  very important, choose an actual "address" to save your set up information. 
#   AnalyzeSetUp.Poisson(name="VaccineA", SampleSize=100, alpha=0.05,
#   M=1,AlphaSpendType="power-type",rho=0.5,title="n",
#   address="C:/Users/Ivair/Documents")

### Now we can sequentially apply a test for each one of three chunks of data.
# -------------------------------------------------------------------------
  
## Test 1 - Situation where the expected number of events under H0 is equal to 2.
## This first test uses the default Wald type alpha spending (AlphaSpend="n").
## Note: cut off the "#" symbol before running the line below.
#  Analyze.Poisson(name="VaccineA",test=1,mu0=2,events=1,AlphaSpend="n")

## Test 2 - Situation where the expected number of events under H0 is equal to 0.8.
## Observe that here we use an arbitrary alpha spending of 0.02.
## Note: cut off the "#" symbol before running the line below.
#  Analyze.Poisson(name="VaccineA",test=2,mu0=0.8,events=2, AlphaSpend=0.02)

## Test 3 - Situation of elevated number of events, but now the
## arbitrary alpha spending is of 0.04.
## Note: cut off the "#" symbol before running the line below.
#  Analyze.Poisson(name="VaccineA",test=3,mu0=9,events=10, AlphaSpend=0.04)
 
</code></pre>

<hr>
<h2 id='Analyze.wBinomial'>Function for group sequential analyses of multiple weighted binomial endpoints, without the need to know group sizes a priori.</h2><span id='topic+Analyze.wBinomial'></span>

<h3>Description</h3>

<p>The function <code>Analyze.wBinomial</code> is used for either continuous or group sequential analysis, or for a  combination of the two. Unlike <code>CV.Binomial</code> and <code>CV.G.Binomial</code>, it is not necessary to pre-specify the group sizes before the sequential analysis starts. More important, this function is designed specifically when multiple outcomes with weights are analyzed. This is done using user defined alpha spending functions. For single binomial outcomes, please use <code>Analyze.Binomial</code>. <code>Analyze.wBinomial</code> is run at each look at the data. Before running it by the first time, it is necessary to run the <code><a href="#topic+AnalyzeSetUp.wBinomial">AnalyzeSetUp.wBinomial</a></code> function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Analyze.wBinomial(name,test,z,w,ExposureA,ExposureB,AlphaSpend="n")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Analyze.wBinomial_+3A_name">name</code></td>
<td>
<p>The name of the sequential analysis. Must be identical for all looks at the data, and it must be the same as the name given by the <code>AnalyzeSetup.wBinomial</code> function. Should never be the same as another sequential analysis that is run simultaneously on the same computer.</p>
</td></tr>
<tr><td><code id="Analyze.wBinomial_+3A_test">test</code></td>
<td>
<p>An integer indicating the number of hypothesis tests performed up to and including the current test. For example, if there were four prior looks at the data, and this is the fifth one, then &quot;test=5&quot;. This number should be increased by one each time that the <code>Analyze.wBinomial</code> function is run for a new group of data, when it is part of the same sequential analysis.  If not, there is an error message.</p>
</td></tr>
<tr><td><code id="Analyze.wBinomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case. For example, if there are 3 controls matched to each case, &quot;z=3&quot;. In a self-control analysis, z is the ratio of the length of the control interval to the length of the risk interval. For example, if the risk interval is 2 days long and the control interval is 7 days long, &quot;z=7/2&quot;. In terms of p, the binomial probability under the null hypothesis, &quot;p=1/(1+z)&quot;, or equivalently, &quot;z=1/p-1&quot;. The parameter z must be a positive number. The default value is z=1 (p=0.5). If the ratio is the same for all observations, then z can be any positive number.</p>
</td></tr>
<tr><td><code id="Analyze.wBinomial_+3A_w">w</code></td>
<td>
<p>A vector containing the weights associated to each outcome.</p>
</td></tr>
<tr><td><code id="Analyze.wBinomial_+3A_exposurea">ExposureA</code></td>
<td>
<p>A number or a vector of the same length as w containing the number of cases from an exposure A per outcome. The length of ExposureA equals to the number of outcomes.</p>
</td></tr>
<tr><td><code id="Analyze.wBinomial_+3A_exposureb">ExposureB</code></td>
<td>
<p>A number or a vector of the same length as w containing the number of cases from an exposure B per outcome. The length of ExposureB equals to the number of outcomes.</p>
</td></tr>
<tr><td><code id="Analyze.wBinomial_+3A_alphaspend">AlphaSpend</code></td>
<td>
<p>The alpha spending function is specified in the <code>AnalyzeSetUp.wBinomial</code> function. At any look at the data, it is possible to over ride that pre-specified alpha spending plan by using the AlphaSpend parameter. AlphaSpend is a number representing the maximum amount of alpha (Type I error probabiliy) to be spent up to and including the current test. Because of the discrete nature of the binomial distribution, the actual amount of alpha spent may be less than the maximum amount specified. It must be in the range (0,alpha]. The default value is no override, which means that, if AlphaSpend= &quot;n&quot;, then the function will use the alpha spending plan specified in the <code>AnalyzeSetUp.wBinomial</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>Analyze.wBinomial</code> performs exact sequential testing for
multiple weighted binomial endpoints, that is, the analysis reflects the drugs combined benefit and safety profile.
It works with a variety of alpha spending functions for continuous, group or mixed group-continuous sequential analysis.
The binomial probabilities, given by <code class="reqn">p=1/(1+z)</code>. 
</p>
<p>The test statistic is based on the weighted sum of binomial endpoints introduced by Silva et al (2020). 
</p>
<p>Unlike <code>CV.Binomial</code> and <code>CV.G.Binomial</code>, there is (i) no need to pre-specify the
group sizes before the sequential analysis starts, (ii) a variety of alpha spending functions are available,
and (iii) it is designed for multiple weighted binomial endpoints.
</p>
<p>In sequential analysis, data is formed by cumulative information, collected in separated chunks or groups, which are observed at different moments in time. <code>Analyze.wBinomial</code>
is run each time a new group of data arrives at which time a new sequential test is conducted. When running <code>Analyze.wBinomial</code>, only the data from the new group should be
included when calling the function. The prior data has been stored, and it will be automatically retrieved by <code>Analyze.wBinomial</code>, with no need to reenter that data. Before
running <code>Analyze.wBinomial</code> for the first time, it is necessary to set up the sequential analysis using the <code>AnalyzeSetUp.wBionimial</code> function, which is run once,
and just once, to define the sequential analysis parameters. For information about this, see the description of the <code><a href="#topic+AnalyzeSetUp.wBinomial">AnalyzeSetUp.wBinomial</a></code> function. 
</p>
<p>The function <code>Analyze.wBinomial</code> calculates critical values to determine if the null hypothesis should be rejected or not at each analysis.
The null hypothesis is that the relative risk of each outcome is equal to 1.
</p>
<p>Critical values are given in the scale of the ratio <code class="reqn">S_A/S_B</code>, where <code class="reqn">S_A=w_1 ExposeA_1+w_2 ExposeA_2+...+w_k ExposeA_k</code>,
and <code class="reqn">S_B=w_1 ExposeB_1 +w_2 ExposeB_2+...+w_kExposeB_k</code>, and <code class="reqn">k</code> is the length of w.  
</p>
<p>Critical values for each test are elicited for a pre-specified overall statistical significance level (alpha), and for an upper limit on the sample size (N).
The exact analytical solution is obtained through numerical calculations. Based on the data and the critical value, the function determines if the null hypothesis
should be rejected or not, and if subsequent tests should be conducted. After each test, the function also provides information about the amount of alpha that
has been spent, the cumulative number of cases and controls, and the maximum likelihood estimate of the relative risk. 
</p>
<p>For binomial and Bernoulli data, there are a number of 0/1 observations that can either be an ExposureA or an ExposureB. Under the null hypothesis,
the probability of being an ExposureA is p, and the probability of being an ExposureB is 1-p. If data comes from a self-control analysis,
the observation is an ExposureA if the event occurred in the risk interval, and it is an ExposureB
if the event occurred in the control interval. Under the null hypothesis, we then have that <code class="reqn">p=1/(1+z)</code>, where z is the ratio of the length of
the control interval to the length of the risk interval. 
</p>
<p>Before running <code>Analyze.wBinomial</code>, it is necessary to specify a planned default alpha spending function, which is done using the AlphaSpendType parameter in the
<code>AnalyzeSetUp.wBinomial</code> function. The default alpha spending is of the polynomial power-type
parameterized with rho, which, according to Silva (2018), 'rho=0.5' is indicated when expected time to signal is the design criterion,
hence the default in <code>AnalyzeSetUp.wBinomial</code>. See the <code><a href="#topic+AnalyzeSetUp.wBinomial">AnalyzeSetUp.wBinomial</a></code> for more details. 
</p>
<p>In most cases, this pre-specified alpha spending function is used throughout the analysis, but if needed, it is possible to override it
at any or each of the sequential tests. This is done using the AlphaSpend parameter, which specifies the maximum amount of alpha to
spend up to and including the current test. In this way, it is possible to use any alpha spending function, and not only those available
in <code>AnalyzeSetUp.wBinomial</code>. It is also possible to use a flexible adaptive alpha spending plan that is not set in stone
before the sequential analysis starts. The only requirement is that for a particular test with a new group of data,
AlphaSpend must be decided before knowing the number of ExposureA and ExposureB in that group.
To ensure a statistically valid sequential analysis, AlphaSpend can only depend on the number of events (ExposureA + ExposureB)
at prior tests and the total number of events in the current test. This is important.
</p>
<p>The function <code>Analyze.WBinomial</code> is meant to perform the binomial sequential analysis with a certain level of autonomy.
After running a test, the code offers a synthesis about the general parameter settings, the main conclusions concerning the
acceptance or rejection of the null hypothesis, and the historical information from previous tests.
A table with the main analyses results is automatically printed in the R console. Each column of the table contains a historical characteristic,
including the information for the current test. Each line of the table corresponds to a specific test organized by calendar time. The table is titled with the title
input defined through the function <code>AnalyzeSetUp.wBinomial</code>, and its columns are organized and labeled in the following way: &quot;Test&quot;,
&quot;#Events&quot;, &quot;Relative Risk&quot;, &quot;Test Statistic&quot;, &quot;Critical Value&quot;, &quot;Alpha&quot;, &quot;Reject H0&quot;. Here follows a short description of each column:
</p>
<p>-	&quot;Test&quot; shows the order of the analysis, i.e., the arrival order of each chunk of data. 
</p>
<p>-	&quot;#Events&quot; present the total of events per outcome.
</p>
<p>-	&quot;Relative Risk&quot; is the estimated relative risk per outcome. 
</p>
<p>-	&quot;Test Statistic&quot; the ratio of weighted sum of binomial endpoints between ExposureA and ExposureB.
</p>
<p>-	&quot;Critical Value&quot; is the signaling threshold for each test.
</p>
<p>-	&quot;Alpha&quot; shows the target and actual alpha spending up to the i-th test. 
</p>
<p>-	&quot;Reject H0&quot; is a logical variable that is &quot;Yes&quot; when the null hypothesis is rejected, and the label &quot;No&quot; when H0 is not to be rejected
</p>
<p>Observe that, because the binomial distribution is discrete, the target alpha spending will rarely be reached. The actual alpha spending is then shown to facilitate
a realistic interpretation of the results. 
</p>
<p>The function <code>Analyze.wBinomial</code> was designed to instruct the user with minimal information about bugs from the code,
or about non-applicable parameter input usages. Some entries are not applicable for the parameter inputs. For example,
the input &quot;z&quot; must be a positive number, and then if the user sets &quot;z= -1&quot;, the code will report an error with the message &quot;z must be a positive number&quot;.
Thus, messages will appear when mistakes and inconsistencies are detected, and instructions about how to proceed to solve such problems will automatically appear.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>result</code></td>
<td>
<p>A table containing the main characteristics, conclusions concerning the acceptance or rejection of the null hypothesis, and the historical information from previous tests.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the <code>Analyze.wBinomial</code> function was funded by:
- National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999: user-defined alpha spending functions, power-type alpha spending function,
increased computational speed, end of schedule analysis using left-over alpha, enhanced error handling and messages, improved documentation.
</p>


<h3>See also</h3>

<p><code><a href="#topic+AnalyzeSetUp.wBinomial">AnalyzeSetUp.wBinomial</a></code>: for setting up sequential analysis with the <code>Analyze.wBinomial</code> function, before the first look at the data.<br /> 
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.</p>


<h3>References</h3>

<p>Silva IR, Gagne J, Najafzadeh M, Kulldorff M. (2020). Exact Sequential Analysis for Multiple Weighted Binomial Endpoints. Statistics in Medicine, 39(3), 340&ndash;351.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance with Binomial Data. Statistics in Medicine, 15;37(1), 107&ndash;118.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example. Four chunks of data.

### Firstly, it is necessary to set up the input parameters.
##  Note: cut off the "#" symbol before running the two lines below.

#   AnalyzeSetUp.wBinomial(name="Rofe_Naisds",N=1000,alpha=0.05,M=1,
#   rho=0.5,title="rofecoxib (Vioxx) vs. NSAID comparison",
#   address="C:/Users/Ivair/Documents",
#   Tailed="two")

### Now we apply sequential tests to each of two chunks of data.
# -------------------------------------------------------------------------

## This example is based on two outcomes, myocardinal
#  infarction (w1=2.2), and major bleeding (w2=0.04), obtained
#  from a study comparing risk of myocardial infarction and
#  gastrointestinal bleeding. See details in Silva et al (2020).
  
## Test 1
## Note: cut off the "#" symbol before running the line below.
#  Analyze.wBinomial(name="Rofe_Naisds",test=1,z=1,w=c(2.2,0.04),
#  ExposureA=c(11,12),ExposureB=c(13,10),AlphaSpend="n" )

## Test 2
## Note: cut off the "#" symbol before running the line below.
#  Analyze.wBinomial(name="Rofe_Naisds",test=2,z=c(1,1),
#  w=c(2.2,0.04),ExposureA=c(19,12),ExposureB=c(16,11),AlphaSpend="n")
</code></pre>

<hr>
<h2 id='AnalyzeSetUp.Binomial'>Function to set up input parameters before using the <code>Analyze.Binomial</code> function for the first time.</h2><span id='topic+AnalyzeSetUp.Binomial'></span>

<h3>Description</h3>

<p>The function <code>AnalyzeSetUp.Binomial</code> must be run ahead of <code>Analyze.Binomial</code> in order to set up the sequential analysis before the first group of data is analyzed. The function obtains the main parameter settings and performs basic calculations that are necessary for the subsequent sequential analysis.</p>


<h3>Usage</h3>

<pre><code class='language-R'>AnalyzeSetUp.Binomial(name,N="n",alpha=0.05,zp="n",pp="n",
M=1,AlphaSpendType="optimal",power=0.9,RR=2,ConfIntWidth="n",ConfTimes=1,
Gamma=0.9,R0=1,ObjectiveMin="ETimeToSignal",rho=0.5,title="n",
address="n",Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_name">name</code></td>
<td>
<p>The name of the sequential analysis. Must be identical for all looks at the data, and the same as the name given in the subsequent calls to the <code>Analyze.Binomial</code> function. It cannot be the same as for another sequential analysis that is run simultaneously on the same computer. There is no default.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_n">N</code></td>
<td>
<p>The maximum sample size, at which the sequential analysis stops without rejecting the null hypothesis. The default N=&quot;n&quot; means that the optimal procedure will also find out the optimal sample size for the target power.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_alpha">alpha</code></td>
<td>
<p>The overall significance level. Must be in the range (0,0.5]. The default is &quot;alpha=0.05&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_zp">zp</code></td>
<td>
<p>The prediction for z, the expected ratio between cases and controls under the null hypothesis that will be specified in the <code>Analyze.Binomial</code> function. This variable is only needed when AlphaSpendType= &quot;Wald&quot;, and it is used to calculate the appropriate rejection boundary. If the z used in <code>Analyze.Binomial</code> during the actual sequential analysis is different from zp, that is okay, and the sequential analysis will still maintain the correct alpha level. The default value is &quot;z=1&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_pp">pp</code></td>
<td>
<p>The prediction for p, the expected probability under the null hypothesis that will be specified in the <code>Analyze.Binomial</code> function. This variable is only needed when AlphaSpendType= &quot;Wald&quot;, and it is used to calculate the appropriate rejection boundary. If the p used in <code>Analyze.Binomial</code> during the actual sequential analysis is different from pp, that is okay, and the sequential analysis will still maintain the correct alpha level. There is no default value.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_m">M</code></td>
<td>
<p>The minimum number of events required before the null hypothesis can be rejected. It must be a positive integer. The default value is &quot;M=1&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_alphaspendtype">AlphaSpendType</code></td>
<td>
<p>The type of alpha spending function to be used. The options are AlphaSpendType= &quot;optimal&quot;, the default, AlphaSpendType= &quot;Wald&quot;, AlphaSpendType= &quot;power-type&quot;. With the 'Wald' option, the Wald type upper rejection boundary is used, which is flat with respect to the likelihood ratio. With the power-type option, the alpha spending uses a power function with parameter rho, with rho defined by the user. With the optimal option, the code uses the alpha spending that minimizes expected time to signal or expected sample size. For more information, see Details. The alpha spending setting is automatically used when the <code>Analyze.Binomial</code> function is run, but, during the sequential analysis, and before each test, the user can always specify an arbitrary amount of alpha spending to be used up until and including that test. See below for details. The default is &quot;optimal&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_power">power</code></td>
<td>
<p>The target power to be used as a constraint in the optimal alpha spending soluation. It is only applicable for 'AlphaSpendType=optimal'.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_rr">RR</code></td>
<td>
<p>The relative risk for the target power. It is only applicable for 'AlphaSpendType=optimal'.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_confintwidth">ConfIntWidth</code></td>
<td>
<p>Positive value for a fixed-width and fixed accuracy confidence interval for the relative risk. Default is without confidence coeficient.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_conftimes">ConfTimes</code></td>
<td>
<p>Times where the restriction on the confidence interval width is initiated for each entry of ConfIntWidth. Default is 1.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_gamma">Gamma</code></td>
<td>
<p>Confidence coefficient for the bounded width interval estimator of the relative risk for AlphaSpendType= &quot;optimal&quot;. Default is 0.9. It has no effect when ConfIntWidth=&quot;n&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_r0">R0</code></td>
<td>
<p>A positive real-valued number for the relative risk under H0, where R&lt;=R0 if &quot;Tailed=lower&quot;, R&gt;=R0 if &quot;Tailed=upper&quot;, or a two-dimensional vector for H0: R0_1&lt;= R &lt;= R0_2 if &quot;Tailed=two&quot;. Default is 1.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_objectivemin">ObjectiveMin</code></td>
<td>
<p>The objective function to minimize in case of 'AlphaSpendType=optimal'. The default is 'ObjectiveMin=ETimeToSignal'. The other option is 'ObjectiveMin=ESampleSize'.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_rho">rho</code></td>
<td>
<p>The parameter rho is used to build the target alpha spending function according to a power-type function. See below for details. It is not used for other alpha spending options. The variable rho must be a positive number. The default value is &quot;rho=0.5&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_title">title</code></td>
<td>
<p>Title for the results shown in the output tables and the illustrative graphics. It can be any text string. The default is that there is no title.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_address">address</code></td>
<td>
<p>The address of the directory where the settings information of this sequential analysis is saved.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Binomial_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1. For this version of the package, only Tailed=&quot;upper&quot; is active.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>AnalyzeSetUp.Binomial</code> has to be executed once, but just once, to set up the general statistical characteristics of the intended
sequential analysis, which is performed using the companion <code>Analyze.Binomial</code> function. 
</p>
<p>Sequential analysis methods are devoted to analyze data sets that accrue cumulatively over time, by conducting multiple statistical tests sequentially
as more data accrues. In such a setting, it is important to carefully plan the sequential analysis before the first data arrives. For example,
it is important to maintain certain analysis parameter values over time to avoid counting the same data twice, and to make sure that there
are no changes in the past data that has already been included in a prior test. To avoid these kinds of problems, the <code>AnalyzeSetUp.Binomial</code>
function is used to set the analysis parameters a priori and to create a place to save the data as it accumulates over time. At the time of each sequential test,
this information is then automatically imported by the <code>Analyze.Binomial</code> function, to ensure the correct concatenation of old and new information.
</p>
<p>At each test, the function <code>Analyze.Binomial</code> makes this concatenation automatically, but it will only work if the function <code>AnalyzeSetUp.Binomial</code>
is executed before performing the very first test. 
</p>
<p>When running <code>AnalyzeSetUp.Binomial</code>, the user has the opportunity to choose the directory where the file with the general setup information and
the historical data are to be saved. Important: The location of this parameter and data file is saved in the temporary directory, so that directory cannot be cleaned until
the sequential analysis has been completed. Each sequential analysis needs a different identifier, which is set using the &quot;name&quot; parameter. Once a name is chosen,
it has to be written exactly the same way when running the function <code>Analyze.Binomial</code>. 
</p>
<p><code>AnalyzeSetUp.Binomial</code> and <code>Analyze.Binomial</code> works for different types of alpha spending plans (<code class="reqn">F(t)</code>). One option is to use the classical
Wald type upper rejection boundary, which is flat with respect to the likelihood function. This is the same boundary used by the <code>CV.Binomial</code> and
<code>CV.G.Binomial</code> functions. In order to use this boundary, one should pre-specify the binomial probability p under the null hypothesis, or,
equivalently, the ratio <code class="reqn">z=1/p-1</code>, which is the number of controls matched to each case in a matched analysis. For example, if the probability of having
a case (instead of a control) is <code class="reqn">p = 1=(1 + z) = 0.5</code>, then we have &quot;z=1&quot; (1:1 matching ratio), and, if p = 0.25, we have &quot;z=3&quot; (1:3 matching ratio). A third
option, the default, is the optimal alpha spending derived by Silva and Kulldorff (2018), which
demands users to choose between minimizing expected time to signal or expected sample size. In this case, it is necessary to specify target power and relative risk.
The faults are 'power=0.9' and 'RR=2'.
</p>
<p>In <code>AnalyzeSetUp.Binomial</code>, the predicted z is specified (the input zp), but if it turns out that the actual z is different, that is okay,
since the actual z that is specified in <code>Analyze.Binomial</code> does not have to be the same as the predicted zp that is specified
in <code>AnalyzeSetUp.Binomial</code>. The latter is only used to set the alpha spending plan. The former, the actual z, is used to calculate the
likelihood function which in turn determines whether the null hypothesis should be rejected or not. If the actual z is variable, so that
it is different for different observations, we recommend setting the predicted z to be our best guess about the average of the actual zs.
Alternatively, instead of zp the user can specify pp, the best guess about the average of the actual ps.
Note that only one of these parameters has to be specified, but if both are entered the code will only work if zp and pp are such that pp=1/(1+zp).
Otherwise, an error message will appear to remind that such condition must be complied. 
</p>
<p>Another alpha spending option is the power-type alpha spending plan (Kim and DeMetz 1987, p150; Jennison and Turnbull 2000, p148), with parameter rho: <code class="reqn">F(t)= alpha*t^{rho}</code>, 
where <code class="reqn">alpha</code> is the overall significance level and <code class="reqn">t</code> is a fraction of N, the maximum length of sequential analysis.
According to Silva (2018), 'rho=0.5' is indicated when expected time to signal is the design criterion, hence this is the default in <code>AnalyzeSetUp.Binomial</code>. 
</p>
<p>The third option for alpha spending selection is the optimal solution. This is the default. In this case, the alpha spending is obtained by means of the method introduced by
Silva and Kulldorff method (Silva and Kulldorff, 2018), which is an exact method for finding the optimal alpha spending through linera programing.
The optimal option works for large sample sizes such as N=300, but it can take very long time to run in such cases. For moderate N values, such as N=120, the code takes around 10 minutes to run in a regular PC(Windows 7, Intel(R) Core(TM) i7-2675QM CPU, 2.20GHz). Although &quot;optimal&quot; is the default, an
error message will appear, asking for another AlphaSpendType choice, if this default is used combined with N greater than 300.
</p>
<p>Another important issue involving the option &quot;optimal&quot; is the choice of tuning parameters behind the method of Silva and Kulldorff (2018).
According to Silva and Kulldorff (2018), the user has to specify a target power and a target relative risk, besides the sample size N, to use
their proposed optimal method. For simplicity, as there are probabilistical restrictions to use certain combinations of target power and relative
risk with cetain N values, the default values are 'power=0.9' and 'RR=2'.
This is no a critical issue because, as explained by  Silva and Kulldorff (2018), there
is no serious impact from chosen RR very different from the actual relative risk.    
</p>
<p>In addition to selecting the alpha spending plan, it is necessary to specify the overall alpha, or maximum Type I error probability, for the sequential analysis as a whole.
It is also necessary to specify the maximum length of the sequential analysis, N, so that the sequential analysis stops without rejecting the null hypothesis when
a total of N observations are obtained.  
</p>
<p>The possibility of constructing the alpha spending restricted to a desired maximum length for the confidence interval, activated by the &quot;ConfIntWidth&quot; parameter, is based on the method proposed by Silva and Zhuang (2022).  
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>inputSetUp</code></td>
<td>
<p>The <code>AnalyzeSetUp.Binomial</code> function creates a data.frame with the main information concerning the tuning parameterization for the planned surveillance and the historical information about the performed tests. The 'inputSetUp' data.frame is used by <code>Analyze.Binomial</code>, then it must be available when running <code>Analyze.Binomial</code>, but there is no need to manually look at it.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the AnalyzeSetUp.Binomial function was funded by:<br />
-	Food and Drug Administration, Center for Drug Evaluation and Research, through the Mini-Sentinel Project (base version, documentation);<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (user defined alpha spending functions, improved documentation);<br />
We thank Claudia Coronel-Moreno for valuable editorial support.
</p>


<h3>See also</h3>

<p><code><a href="#topic+Analyze.Binomial">Analyze.Binomial</a></code>: for running the sequential analysis that was set up using the <code>AnalyzeSetUp.Binomial</code> function.
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000), Group Sequential Methods with Applications to Clinical
Trials, <em>no. ISBN 0-8493-0316-8, London: Chapman and Hall/CRC</em>.
</p>
<p>Kim K, DeMets DL. (1987), Design and Analysis of Group Sequential Tests Based on the Type I Error Spending Rate Function. Biometrika, <b>74</b>, n.1: 149&ndash;154.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous post-market sequential safety surveillance with minimum events to signal. arxiv:1503.01978 [stat.ap].
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR, Kulldorff M, Yih W. Katherine. (2020), Optimal alpha spending for sequential analysis with binomial data. Journal of the Royal Statistical Society Series B, 82(4) p. 1141&ndash;1164.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance with Binomial Data. Statistics in Medicine, 15;37(1), 107-118.
</p>
<p>Silva IR, Zhuang, Y. (2022), Bounded-width confidence interval following optimal sequential analysis of adverse events with binary data, Statistical Methods in Medical Research, 31(12), 2323&ndash;2337.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See example in the description of the Analyze.Binomial function. 

</code></pre>

<hr>
<h2 id='AnalyzeSetUp.CondPoisson'>Function to set up input parameters before using the <code>Analyze.CondPoisson</code> function for the first time.</h2><span id='topic+AnalyzeSetUp.CondPoisson'></span>

<h3>Description</h3>

<p>The function <code>AnalyzeSetUp.CondPoisson</code> must be run ahead of <code>Analyze.CondPoisson</code> in order to set up the sequential analysis before the first group of data is analyzed. The function obtains the main parameter settings and performs basic calculations that are necessary for the subsequent sequential analysis.</p>


<h3>Usage</h3>

<pre><code class='language-R'>AnalyzeSetUp.CondPoisson(name,SampleSizeType="Events",T="n",K="n",cc,
alpha=0.05,M=1, AlphaSpendType="Wald",rho="n",title="n",address="n",Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_name">name</code></td>
<td>
<p>The name of the sequential analysis. Must be identical for all looks at the data, and the same as the name given in the subsequent calls to the <code>Analyze.CondPoisson</code> function. It cannot be the same as for another sequential analysis that is run simultaneously on the same computer. There is no default.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_samplesizetype">SampleSizeType</code></td>
<td>
<p>It is a string specifying the scale of the maximum sample size at which the sequential analysis stops without rejecting the null hypothesis. The only two possibilities are &quot;SampleSizeType=PersonTimeRatio&quot; or &quot;SampleSizeType=Events&quot;. The default is &quot;SampleSizeType=Events&quot;. See details.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_t">T</code></td>
<td>
<p>Maximum sample size defined in the scale of the ratio between surveillance and historical person-time. This only produces effects when &quot;SampleSizeType=PersonTimeRatio&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_k">K</code></td>
<td>
<p>Maximum sample size defined in the scale of the number of events observed in the surveillance period. This only produces effects when &quot;SampleSizeType=Events&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_cc">cc</code></td>
<td>
<p>Number of events observed in the historical period.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_alpha">alpha</code></td>
<td>
<p>The overall significance level. Must be in the range (0,0.5]. The default is &quot;alpha=0.05&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events required before the null hypothesis can be rejected. It must be a positive integer. The default value is &quot;M=1&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_alphaspendtype">AlphaSpendType</code></td>
<td>
<p>The type of alpha spending function to be used. The options are AlphaSpendType=&quot;Wald&quot; and AlphaSpendType=&quot;power-type&quot;. With the 'Wald' option, the Wald type upper rejection boundary is used, which is flat with respect to the likelihood ratio. With the power-type option, the alpha spending uses a power function with parameter rho, with rho defined by the user. This alpha spending setting is automatically used when the <code>Analyze.CondPoisson</code> function is run, but, during the sequential analysis, and before each test, the user can always specify an arbitrary amount of alpha spending to be used up until and including that test. See below for details.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_rho">rho</code></td>
<td>
<p>The parameter rho is used to build the target alpha spending function according to a power-type function. See below for details. It is not used for other alpha spending options. The variable rho must be a positive number. The default value is &quot;rho=1&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_title">title</code></td>
<td>
<p>Title for the results shown in the output tables and the illustrative graphics. It can be any text string. The default is that there is no title.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_address">address</code></td>
<td>
<p>The address of the directory where the settings information of this sequential analysis is saved.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.CondPoisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>AnalyzeSetUp.CondPoisson</code> has to be executed once, but just once, to set up the general statistical characteristics of the intended
sequential analysis, which is performed using the companion <code>Analyze.CondPoisson</code> function. 
</p>
<p>Sequential analysis methods are devoted to analyze data sets that accrue cumulatively over time, by conducting multiple statistical tests sequentially
as more data accrues. In such a setting, it is important to carefully plan the sequential analysis before the first data arrives. For example,
it is important to maintain certain analysis parameter values over time to avoid counting the same data twice, and to make sure that there
are no changes in the past data that has already been included in a prior test. To avoid these kinds of problems, the <code>AnalyzeSetUp.CondPoisson</code>
function is used to set the analysis parameters a priori and to create a place to save the data as it accumulates over time. At the time of each sequential test,
this information is then automatically imported by the <code>Analyze.CondPoisson</code> function, to ensure the correct concatenation of old and new information.
</p>
<p>At each test, the function <code>Analyze.CondPoisson</code> makes this concatenation automatically, but it will only work if the function <code>AnalyzeSetUp.CondPoisson</code>
is executed before performing the very first test. 
</p>
<p>When running <code>AnalyzeSetUp.CondPoisson</code>, the user has to choose the directory where the file with the general setup information and
the historical data are to be saved. This step is mandatory and error messages are reported if a non-valid address is informed. Important:
The location of this parameter and data file is saved in the temporary directory, so that directory cannot be cleaned until
the sequential analysis has been completed. Each sequential analysis needs a different identifier, which is set using the &quot;name&quot; parameter. Once a name is chosen,
it has to be written exactly in the same way when running the function <code>Analyze.CondPoisson</code>. 
</p>
<p><code>AnalyzeSetUp.CondPoisson</code> and <code>Analyze.CondPoisson</code> work for different types of alpha spending plans (<code class="reqn">F(t)</code>). One option is to use the classical
Wald type upper rejection boundary, which is flat with respect to the likelihood function. This is the same boundary used by the <code>CV.CondPoisson</code> function.
</p>
<p>Another alpha spending option is the power-type alpha spending plan (Kim and DeMetz 1987, p150; Jennison and Turnbull 2000, p148), with parameter rho:
<code class="reqn">F(t)= alpha*t^{rho}</code>, 
where <code class="reqn">alpha</code> is the overall significance level and <code class="reqn">t</code> is a fraction of SampleSize, the maximum length of sequential analysis.
</p>
<p>Attention is required for the input parameter &quot;SampleSizeType&quot;. With this parameter, the user can choose the scale of the maximum sample size
at which the surveillance is stoped without rejecting the null hypothesis. The idea of having two options for defining the scale of the maximum sample size,
&quot;SampleSizeType=PersonTimeRatio&quot; or &quot;SampleSizeType=Events&quot;,
was introduced by Silva et al. (2019a). With SampleSizeType=&quot;PersonTimeRatio&quot;, the upper limit on the time of surveillance is given in the scale of the ratio
between the cumulative person-time from the surveillance data up to the kth event, <code class="reqn">P_{k}</code>, by the person-time from
the historical data, denoted by <code class="reqn">V</code>. These are the notations used  by Silva et al. (2019a) and Silva et al. (2019b).
</p>
<p>If SampleSizeType=&quot;PersonTimeRatio&quot;, then the user has to inform a positive value for the input parameter &quot;T&quot;. Usually, choices between 2 and 5 are adequate.
With SampleSizeType=&quot;Events&quot;, the upper limit is given in the scale of the number of events observed during the surveillance, and hence the user must
specify a positive integer for the input parameter &quot;K&quot;, such as e.g. &quot;K=50&quot; or &quot;K=150&quot;. For more details on the exact calculations of critical values and alpha spending
implemented in this package, and of all the other statistical performance measures also available, see the works of Silva et al. (2019a) and Silva et al. (2019b). 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>inputSetUp</code></td>
<td>
<p>The <code>AnalyzeSetUp.CondPoisson</code> function creates a data.frame with the main information concerning the tuning parameterization for the planned surveillance and the historical information about the performed tests. The 'inputSetUp' data.frame is used by <code>Analyze.CondPoisson</code>, then it must be available when running <code>Analyze.CondPoisson</code>, but there is no need to manually look at it.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the AnalyzeSetUp.CondPoisson function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999.
- Foundation for Research Support of Minas Gerais State (FAPEMIG), MG, Brazil, through the grant Demanda Universal.
</p>


<h3>See also</h3>

<p><code><a href="#topic+Analyze.CondPoisson">Analyze.CondPoisson</a></code>: for running the sequential analysis that was set up using the <code>AnalyzeSetUp.CondPoisson</code> function.
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000), Group Sequential Methods with Applications to Clinical
Trials, <em>no. ISBN 0-8493-0316-8, London: Chapman and Hall/CRC</em>.
</p>
<p>Kim K, DeMets DL. (1987), Design and Analysis of Group Sequential Tests Based on the Type I Error Spending Rate Function. Biometrika, <b>74</b>, n.1: 149&ndash;154.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. Sequential Analysis, 30: 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>
<p>Li L, Kulldorff M. (2010). A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71(3), 851&ndash;858.
</p>
<p>Silva IR, Li L, Kulldorff M. (2019a), Exact conditional maximized sequential probability ratio test adjusted for covariates. Sequential Analysis, 38(1), 115&ndash;133.
</p>
<p>Silva IR., Lopes LM., Dias P., Yih WK. (2019b). Alpha Spending for Historical Versus Surveillance Poisson Data With CMaxSPRT. Statistics in Medicine, 38(12), 2126&ndash;2138. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See example in the description of the Analyze.CondPoisson function. 

</code></pre>

<hr>
<h2 id='AnalyzeSetUp.Poisson'>Function to set up input parameters before using the <code>Analyze.Poisson</code> function for the first time.</h2><span id='topic+AnalyzeSetUp.Poisson'></span>

<h3>Description</h3>

<p>The function <code>AnalyzeSetUp.Poisson</code> must be run ahead of <code>Analyze.Poisson</code> in order to set up the sequential analysis before the first group of data is analyzed. The function obtains the main parameter settings and performs basic calculations that are necessary for the subsequent sequential analysis.</p>


<h3>Usage</h3>

<pre><code class='language-R'>AnalyzeSetUp.Poisson(name,SampleSize,alpha=0.05,D=0,M=1,
AlphaSpendType="Wald",rho="n",R0=1,title="n",address="n",
Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_name">name</code></td>
<td>
<p>The name of the sequential analysis. Must be identical for all looks at the data, and the same as the name given in the subsequent calls to the <code>Analyze.Poisson</code> function. It cannot be the same as for another sequential analysis that is run simultaneously on the same computer. There is no default.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_samplesize">SampleSize</code></td>
<td>
<p>The maximum length of surveillance at which the sequential analysis stops without rejecting the null hypothesis. It is defined in terms of the expected sample size under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_alpha">alpha</code></td>
<td>
<p>The overall significance level. Must be in the range (0,0.5]. The default is &quot;alpha=0.05&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_d">D</code></td>
<td>
<p>The expected number of events under the null hypothesis at the first look at the data.
This is used when there is an initial large chunk of data arriving, followed by continuous sequential analysis. The default value is D=0, which is
also the best choice. This means that there is no delay in the start of the sequential analyses. If D is very large, the maximum 
sample size will be set equal to D if a non-sequential analysis provides the desired power.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. It must be a positive integer.
A good rule of thumb is to set M=4 (Kulldorff and Silva, 2015). The default value is M=1, which means that even a single event
can reject the null hypothesis if it occurs sufficiently early.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_alphaspendtype">AlphaSpendType</code></td>
<td>
<p>The type of alpha spending function to be used. The options are AlphaSpendType=&quot;Wald&quot; and AlphaSpendType=&quot;power-type&quot;. With the 'Wald' option, the Wald type upper rejection boundary is used, which is flat with respect to the likelihood ratio. With the power-type option, the alpha spending uses a power function with parameter rho, with rho defined by the user. This alpha spending setting is automatically used when the <code>Analyze.Poisson</code> function is run, but, during the sequential analysis, and before each test, the user can always specify an arbitrary amount of alpha spending to be used up until and including that test. See below for details.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_rho">rho</code></td>
<td>
<p>The parameter rho is used to build the target alpha spending function according to a power-type function. See below for details. It is not used for other alpha spending options. The variable rho must be a positive number. The default value is &quot;rho=1&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_r0">R0</code></td>
<td>
<p>A positive real-valued number for the relative risk under H0, where R&lt;=R0 if &quot;Tailed=lower&quot;, R&gt;=R0 if &quot;Tailed=upper&quot;, or a two-dimensional vector for H0: R0_1&lt;= R &lt;= R0_2 if &quot;Tailed=two&quot;. Default is 1.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_title">title</code></td>
<td>
<p>Title for the results shown in the output tables and the illustrative graphics. It can be any text string. The default is that there is no title.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_address">address</code></td>
<td>
<p>The address of the directory where the settings information of this sequential analysis is saved.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.Poisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>AnalyzeSetUp.Poisson</code> has to be executed once, but just once, to set up the general statistical characteristics of the intended
sequential analysis, which is performed using the companion <code>Analyze.Poisson</code> function. 
</p>
<p>Sequential analysis methods are devoted to analyze data sets that accrue cumulatively over time, by conducting multiple statistical tests sequentially
as more data accrues. In such a setting, it is important to carefully plan the sequential analysis before the first data arrives. For example,
it is important to maintain certain analysis parameter values over time to avoid counting the same data twice, and to make sure that there
are no changes in the past data that has already been included in a prior test. To avoid these kinds of problems, the <code>AnalyzeSetUp.Poisson</code>
function is used to set the analysis parameters a priori and to create a place to save the data as it accumulates over time. At the time of each sequential test,
this information is then automatically imported by the <code>Analyze.Poisson</code> function, to ensure the correct concatenation of old and new information.
</p>
<p>At each test, the function <code>Analyze.Poisson</code> makes this concatenation automatically, but it will only work if the function <code>AnalyzeSetUp.Poisson</code>
is executed before performing the very first test. 
</p>
<p>When running <code>AnalyzeSetUp.Poisson</code>, the user has to choose the directory where the file with the general setup information and
the historical data are to be saved. This step is mandatory and error messages are reported if non-valid address is informed. Important: The location of this parameter and data file is saved in the temporary directory, so that directory cannot be cleaned until
the sequential analysis has been completed. Each sequential analysis needs a different identifier, which is set using the &quot;name&quot; parameter. Once a name is chosen,
it has to be written exactly the same way when running the function <code>Analyze.Poisson</code>. 
</p>
<p><code>AnalyzeSetUp.Poisson</code> and <code>Analyze.Poisson</code> work for different types of alpha spending plans (<code class="reqn">F(t)</code>). One option is to use the classical
Wald type upper rejection boundary, which is flat with respect to the likelihood function. This is the same boundary used by the <code>CV.Poisson</code> and
<code>CV.G.Poisson</code> functions.
</p>
<p>Another alpha spending option is the power-type alpha spending plan (Kim and DeMetz 1987, p150; Jennison and Turnbull 2000, p148), with parameter rho: <code class="reqn">F(t)= alpha*t^{rho}</code>, 
where <code class="reqn">alpha</code> is the overall significance level and <code class="reqn">t</code> is a fraction of SampleSize, the maximum length of sequential analysis.
According to Silva (2018), the choice 'rho=1' is indicated when minimization of expected time to signal is a design criterion,
which is then the default in <code>AnalyzeSetUp.Poisson.</code>. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>inputSetUp</code></td>
<td>
<p>The <code>AnalyzeSetUp.Poisson</code> function creates a data.frame with the main information concerning the tuning parameterization for the planned surveillance and the historical information about the performed tests. The 'inputSetUp' data.frame is used by <code>Analyze.Poisson</code>, then it must be available when running <code>Analyze.Poisson</code>, but there is no need to manually look at it.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the AnalyzeSetUp.Poisson function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999.
</p>


<h3>See also</h3>

<p><code><a href="#topic+Analyze.Poisson">Analyze.Poisson</a></code>: for running the sequential analysis that was set up using the <code>AnalyzeSetUp.Poisson</code> function.
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000), Group Sequential Methods with Applications to Clinical
Trials, <em>no. ISBN 0-8493-0316-8, London: Chapman and Hall/CRC</em>.
</p>
<p>Kim K, DeMets DL. (1987), Design and Analysis of Group Sequential Tests Based on the Type I Error Spending Rate Function. Biometrika, <b>74</b>, n.1: 149&ndash;154.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance With Poisson Data. Methodol Comput Appl Probab, 20(2), 739-750.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2021). Exact sequential test for clinical trials and post-market drug and vaccine safety surveillance with Poisson and binary data. Statistics in Medicine, DOI: 10.1002/sim.9094.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See example in the description of the Analyze.Poisson function. 

</code></pre>

<hr>
<h2 id='AnalyzeSetUp.wBinomial'>Function to set up input parameters before using the <code>Analyze.wBinomial</code> function for the first time.</h2><span id='topic+AnalyzeSetUp.wBinomial'></span>

<h3>Description</h3>

<p>The function <code>AnalyzeSetUp.wBinomial</code> must be run ahead of <code>Analyze.wBinomial</code> in order to set up the sequential analysis before the first group of data is analyzed. The function obtains the main parameter settings and performs basic calculations that are necessary for the subsequent sequential analysis.</p>


<h3>Usage</h3>

<pre><code class='language-R'>AnalyzeSetUp.wBinomial(name,N,alpha=0.05,M=1,rho=0.5,
title="n",address="n",Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AnalyzeSetUp.wBinomial_+3A_name">name</code></td>
<td>
<p>The name of the sequential analysis. Must be identical for all looks at the data, and the same as the name given in the subsequent calls to the <code>Analyze.wBinomial</code> function. It cannot be the same as for another sequential analysis that is run simultaneously on the same computer. There is no default.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.wBinomial_+3A_n">N</code></td>
<td>
<p>The maximum sample size, at which the sequential analysis stops without rejecting the null hypothesis.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.wBinomial_+3A_alpha">alpha</code></td>
<td>
<p>The overall significance level. Must be in the range (0,0.5]. The default is &quot;alpha=0.05&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.wBinomial_+3A_m">M</code></td>
<td>
<p>The minimum number of events required before the null hypothesis can be rejected. It must be a positive integer. The default value is &quot;M=1&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.wBinomial_+3A_rho">rho</code></td>
<td>
<p>The parameter rho is used to build the target alpha spending function according to a power-type function. See below for details. It is not used for other alpha spending options. The variable rho must be a positive number. The default value is &quot;rho=0.5&quot;.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.wBinomial_+3A_title">title</code></td>
<td>
<p>Title for the results shown in the output tables and the illustrative graphics. It can be any text string. The default is that there is no title.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.wBinomial_+3A_address">address</code></td>
<td>
<p>The address of the directory where the settings information of this sequential analysis is saved.</p>
</td></tr>
<tr><td><code id="AnalyzeSetUp.wBinomial_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>AnalyzeSetUp.wBinomial</code> has to be executed once, but just once, to set up the general statistical characteristics of the intended
sequential analysis, which is performed using the companion <code>Analyze.wBinomial</code> function. 
</p>
<p>Sequential analysis methods are devoted to analyze data sets that accrue cumulatively over time, by conducting multiple statistical tests sequentially
as more data accrues. In such a setting, it is important to carefully plan the sequential analysis before the first data arrives. For example,
it is important to maintain certain analysis parameter values over time to avoid counting the same data twice, and to make sure that there
are no changes in the past data that has already been included in a prior test. To avoid these kinds of problems, the <code>AnalyzeSetUp.wBinomial</code>
function is used to set the analysis parameters a priori and to create a place to save the data as it accumulates over time. At the time of each sequential test,
this information is then automatically imported by the <code>Analyze.wBinomial</code> function, to ensure the correct concatenation of old and new information.
</p>
<p>At each test, the function <code>Analyze.wBinomial</code> makes this concatenation automatically, but it will only work if the function <code>AnalyzeSetUp.wBinomial</code>
is executed before performing the very first test. 
</p>
<p>When running <code>AnalyzeSetUp.wBinomial</code>, the user has the opportunity to choose the directory where the file with the general setup information and
the historical data are to be saved. Important: The location of this parameter and data file is saved in the temporary directory, so that directory cannot be cleaned until
the sequential analysis has been completed. Each sequential analysis needs a different identifier, which is set using the &quot;name&quot; parameter. Once a name is chosen,
it has to be written exactly the same way when running the function <code>Analyze.wBinomial</code>. 
</p>
<p><code>AnalyzeSetUp.wBinomial</code> and <code>Analyze.wBinomial</code> works for different types of alpha spending plans (<code class="reqn">F(t)</code>).
The alpha spending option is the power-type alpha spending plan (Kim and DeMetz 1987, p150; Jennison and Turnbull 2000, p148), with parameter rho: <code class="reqn">F(t)= alpha*t^{rho}</code>, 
where <code class="reqn">alpha</code> is the overall significance level and <code class="reqn">t</code> is a fraction of N, the maximum length of sequential analysis.
According to Silva (2018), 'rho=0.5' is indicated when expected time to signal is the design criterion, hence this is the default in <code>AnalyzeSetUp.wBinomial</code>. 
</p>
<p>In addition to selecting the alpha spending plan, it is necessary to specify the overall alpha, or maximum Type I error probability, for the sequential analysis as a whole.
It is also necessary to specify the maximum length of the sequential analysis, N, so that the sequential analysis stops without rejecting the null hypothesis when
a total of N observations are obtained.  
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>inputSetUp</code></td>
<td>
<p>The <code>AnalyzeSetUp.wBinomial</code> function creates a data.frame with the main information concerning the tuning parameterization for the planned surveillance and the historical information about the performed tests. The 'inputSetUp' data.frame is used by <code>Analyze.wBinomial</code>, then it must be available when running <code>Analyze.wBinomial</code>, but there is no need to manually look at it.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the AnalyzeSetUp.Binomial function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (user defined alpha spending functions, improved documentation);<br />
</p>


<h3>See also</h3>

<p><code><a href="#topic+Analyze.wBinomial">Analyze.wBinomial</a></code>: for running the sequential analysis that was set up using the <code>AnalyzeSetUp.wBinomial</code> function.
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000), Group Sequential Methods with Applications to Clinical
Trials, <em>no. ISBN 0-8493-0316-8, London: Chapman and Hall/CRC</em>.
</p>
<p>Kim K, DeMets DL. (1987), Design and Analysis of Group Sequential Tests Based on the Type I Error Spending Rate Function. Biometrika, <b>74</b>, n.1: 149&ndash;154.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous post-market sequential safety surveillance with minimum events to signal. arxiv:1503.01978 [stat.ap].
</p>
<p>Silva IR, Gagne J, Najafzadeh M, Kulldorff M. (2020). Exact Sequential Analysis for Multiple Weighted Binomial Endpoints. Statistics in Medicine, 39(3), 340&ndash;351.
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva, IR and Kulldorff, M. and Yih, W. Katherine (2020). Optimal alpha spending for sequential analysis with binomial data. Journal of the Royal Statistical Society Series B, 82(4) p. 1141&ndash;1164.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance with Binomial Data. Statistics in Medicine, 15;37(1), 107-118.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See example in the description of the Analyze.wBinomial function. 

</code></pre>

<hr>
<h2 id='ConfidenceInterval.Binomial'>Confidence Interval for the Relative Risk Following a Sequential Test with Binary Data.</h2><span id='topic+ConfidenceInterval.Binomial'></span>

<h3>Description</h3>

<p>The function <code>ConfidenceInterval.Binomial</code> is used for constructing confidence interval for the relative risk in either continuous or group sequential analysis, or for a  combination of the two, on termination of the sequential surveillance. This function is useful, for example, in combination with the <code>Analyze.Binomial</code> function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConfidenceInterval.Binomial(Gamma=0.9,CV.lower="n",CV.upper="n",
GroupSizes,z="n",p="n",Cum.cases,Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ConfidenceInterval.Binomial_+3A_gamma">Gamma</code></td>
<td>
<p>Confidence coefficient for the interval estimator of the relative risk. The default is Gamma=0.9.</p>
</td></tr>
<tr><td><code id="ConfidenceInterval.Binomial_+3A_cv.lower">CV.lower</code></td>
<td>
<p>Signaling threshold for the evidence of &quot;RR&lt;R0&quot;, where R0 is a user-defined positive value when constructing this lower signaling threshold. It is given in the scale of the binomial cumulative data. Put NA for initial looks at the data when tests were not applicable. The default CV.lower=&quot;n&quot; means that the sequential test was not designed to detect RR&lt;R0 by the time of the confidence interval construction.</p>
</td></tr>
<tr><td><code id="ConfidenceInterval.Binomial_+3A_cv.upper">CV.upper</code></td>
<td>
<p>Signaling threshold for evidence of &quot;RR&gt;R0&quot;, where R0 is a user-defined positive value when constructing this upper signaling threshold. It is given in the scale of the the binomial cumulative data. Put NA for initial looks at the data when tests were not applicable. The default CV.upper=&quot;n&quot; means that the sequential test was not designed to detect RR&gt;R0 by the time of the confidence interval construction.</p>
</td></tr>
<tr><td><code id="ConfidenceInterval.Binomial_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector with the total number of events (cases+controls) between two looks at the data with regular and irregular group sizes. There is no default value.</p>
</td></tr>
<tr><td><code id="ConfidenceInterval.Binomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case under the null hypothesis. If just a single number is given, then it will be used as a constant matching ratio for all groups. Otherwise, the dimension of z must coincide with the dimension of GroupSizes. The default z=&quot;n&quot; means that the input p will be used instead.</p>
</td></tr>
<tr><td><code id="ConfidenceInterval.Binomial_+3A_p">p</code></td>
<td>
<p>The probability of having a case under the null hypothesis H0:RR&lt;=1. If just a single number is given, then it will be used as a constant probability for all groups. Otherwise, the dimension of p must coincide with the dimension of GroupSizes. The default p=&quot;n&quot; means that the input z will be used instead.</p>
</td></tr>
<tr><td><code id="ConfidenceInterval.Binomial_+3A_cum.cases">Cum.cases</code></td>
<td>
<p>Total number of cumulative cases on termination of the analysis. There is no default.</p>
</td></tr>
<tr><td><code id="ConfidenceInterval.Binomial_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=R0, Tailed=&quot;lower&quot; for H0:RR&gt;=R0 or Tailed=&quot;two&quot; for H0:R01&lt;=RR&lt;=R02. Important: R0, R01, and R02 are not parameters of this function. It is supposed that they were used when the user somehow constructed CV.lower and CV.upper.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous and group sequential analysis with binomial data, the confidence interval for the relative risk, RR, is constructed with <code>ConfidenceInterval.Binomial</code>.
</p>
<p>For two-tailed testing (<code>Tailed="two"</code>), both lower and upper signaling thresholds must be informed through
<code>CV.lower</code> and <code>CV.upper</code>. See details in Silva et al (2021).
</p>
<p><code>z</code> is a vector of positive numbers representing the matching ratios for each test (group). If a single number is given, then it will be used as a constant
matching ratio for all tests (groups). Otherwise, the dimension of <code>z</code> must coincide with the dimension of <code>GroupSizes</code>.
<code>z</code> represents the number of controls matched to each case. For example, if there are 3 controls matched to each case, <code>z</code>=3. 
In a self-control analysis, z is the ratio of the control interval to the risk interval.
For example, if the risk interval is 2 days long and the control interval is 7 days long, <code>z</code>=7/2.
In terms of <code>p</code>, the binomial probability under the null hypothesis, <code>p=1/(1+z)</code>, or equivalently, <code>z=1/p-1</code>.
</p>
<p>Alternatively, instead of <code>z</code> the user can specify <code>p</code> directly.
Note that only one of these inputs, <code>z</code> or <code>p</code>, has to be specified, but if both are entered the code will only work if <code>z</code>
and <code>p</code> are such that <code>p=1/(1+z)</code>. Otherwise, an error message will appear to remind that such condition must be complied.
</p>
<p>With <code>GroupSizes</code> the user informs the sample size of each subsequent test. Therefore, only positive integers are accepted in <code>GroupSizes</code>. 
</p>
<p>The confidence interval is calculated by pivoting the probability of rejecting the null hypothesis with one of the thresholds CV.lower or CV.upper. This is equivalent to inverting the two-tailed testing as described by Jennison and Turnbull (2000), page 181 of Section 8.5. See also Silva and Zhuang (2022) for more details on the calculations.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>RRl</code></td>
<td>
<p>The lower limit of the confidence interval for RR.</p>
</td></tr>
<tr><td><code>RRu</code></td>
<td>
<p>The upper limit of the confidence interval for RR.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the ConfidenceInterval.Binomial function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0,2.0 to 3.1).<br />
-     National Council of Scientific and Technological Development (CNPq), Brazil, process number 301391/2019-0. (v1.0).<br />
-     Research Support Foundation of the State of Minas Gerais (FAPEMIG), Brazil, grant number PQ-00787-21.<br />  
-	Federal University of Ouro Preto (UFOP), through contract under internal UFOP's resolution CEPE 4600 (v2.0 to 3.1).<br />
</p>


<h3>See also</h3>

<p><code><a href="#topic+Performance.AlphaSpend.Binomial">Performance.AlphaSpend.Binomial</a></code>: for calculating signaling threshold for user-specified alpha spending with binomial data.<br />
<code><a href="#topic+CV.Binomial">CV.Binomial</a></code>: for calculating Wald-type signaling thresholds for continuous sequential analysis with binomial data.<br />
<code><a href="#topic+Analyze.Binomial">Analyze.Binomial</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion with binomial data.
<code><a href="#topic+Analyze.wBinomial">Analyze.wBinomial</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion with multiple weighted binary endpoints.<br />
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva and Martin Kulldorf.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000), Group Sequential Methods with Applications to Clinical Trials, London: Chapman and Hall/CRC.
</p>
<p>Silva IR, Zhuang, Y. (2022), Bounded-width confidence interval following optimal sequential analysis of adverse events with binary data, Statistical Methods in Medical Research, 31(12), 2323&ndash;2337.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2021), Exact sequential test for clinical trials and post-market drug and vaccine safety surveillance with Poisson and binary data. Statistics in Medicine, DOI: 10.1002/sim.9094.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# ConfidenceInterval.Binomial(Gamma=0.9,CV.lower=c(NA,1,1,2),
# CV.upper=c(8,13,15,18), GroupSizes=c(8,5,5,6),z=1,
# Cum.cases=18,Tailed="two")

</code></pre>

<hr>
<h2 id='CV.Binomial'>Calculates exact critical values for group and continuous sequential analysis with binomial data.</h2><span id='topic+CV.Binomial'></span>

<h3>Description</h3>

<p>The function <code>CV.Binomial</code> obtains critical values for the group continuous sequential MaxSPRT test with binomial data, using a Wald-type upper boundary,
which is flat with respect to the likelihood ratio function, and an pre-specified upper limit on the sample size.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.Binomial(N,alpha=0.05,M=1,z="n",p="n",GroupSizes=1,Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CV.Binomial_+3A_n">N</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the total number of events (cases plus controls). 
&quot;N&quot; must be a positive integer. To avoid very large computation times, we suggest not using values greater than 1000. Typically,
this is not a major restriction. For example, for &quot;RR=1.1&quot;, &quot;alpha=0.01&quot; and &quot;z=1&quot;, the statistical power is approximately 1 for &quot;N&gt;500&quot;. There is no default value.</p>
</td></tr>
<tr><td><code id="CV.Binomial_+3A_alpha">alpha</code></td>
<td>
<p>The significance level. The &quot;alpha&quot; level must be in the range (0,0.5]. The default value is &quot;alpha=0.05&quot;.</p>
</td></tr>
<tr><td><code id="CV.Binomial_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. &quot;M&quot; must be a positive integer, and the default value is &quot;M=1&quot;.</p>
</td></tr>
<tr><td><code id="CV.Binomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="CV.Binomial_+3A_p">p</code></td>
<td>
<p>The probability of having a case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="CV.Binomial_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector with the number of events (cases+controls) between two consecutive looks (tests) at the data, i.e, the group sizes. The
length of this vector is equal to the maximum number of tests. The entries do not have to be the same, but they must sum up &quot;N&quot;.
If the group sizes is an integer instead of a vector, then that integer is the group size for all looks at the data, and the number of looks is &quot;N/GroupSizes&quot;. The default is GroupSizes=1 for continuous sequential analysis.</p>
</td></tr>
<tr><td><code id="CV.Binomial_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the continuous and group binomial MaxSPRT, <code>CV.Binomial</code> calculates the upper boundary used to 
determine if the null hypothesis is to be rejected at each analysis. This is done for pre-specified values of the statistical significance level (alpha) and 
an upper limit on the sample size equal to N. 
</p>
<p>The input z represents the number of controls matched to each case. For example, if there are 3 controls matched to each case, &quot;z=3&quot;. 
In a self-control analysis, z is the ratio of the control interval to the risk interval.
For example, if the risk interval is 2 days long and the control interval is 7 days long, z=7/2.
In terms of p, the binomial probability under the null hypothesis, p=1/(1+z), or equivalently, z=1/p-1. The parameter z must be a positive number.
</p>
<p>Alternatively, instead of z the user can specify p directly.
Note that only one of these inputs, z or p, has to be specified, but if both are entered the code will only work if z and p are such that p=1/(1+z).
Otherwise, an error message will appear to remind that such condition must be complied.
</p>
<p>For details about the algorithm used to calculate the critical value, see the paper by Kulldorff et al. (2011).
</p>
<p>For some configurations of N and alpha and GroupSizes, there is no critical value that gives a Type I error probability that is exactly equal to the
requested &quot;alpha&quot;. This is because of the discrete nature of binomial data. In such situations, <code>CV.Binomial</code> returns the greatest critical value that guarantees a Type I error probability smaller than &quot;alpha&quot;. Thus 
the critical value for the binomial sequential analysis is conservative in this sense. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>cv</code></td>
<td>
<p>The critical value for a significance level equal to alpha. The largest conservative value is provided when
it is not possible to have an Type I error exactly equal to alpha.</p>
</td></tr>
<tr><td><code>Type_I_Error</code></td>
<td>
<p>The exact Type I error probability given cv. Always less than or equal to alpha.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the CV.Binomial function was funded by:<br />
-	Food and Drug Administration, Center for Drug Evaluation and Research, through the Mini-Sentinel Project; base version, documentation;<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999; code revisions, increased computational speed, improved documentation.<br />
<br />
We thank Ron Berman, University of California, Berkeley, for a key suggestion to speed up the calculations, and Bruce Fireman for helpful discussions.
</p>


<h3>See also</h3>

<p><code><a href="#topic+Analyze.Binomial">Analyze.Binomial</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion.
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Ned Lewis, Ron Berman, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Silva IR, Kulldorff M. (2015), Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example 1:
## Critical value for continuous binomial sequential analysis with
#  a maximum sample size of 20 events, requiring at 
#  least 3 events to reject the null, and with a significance level of 0.05:

CV.Binomial(N=20,alpha=0.05,M=3,z=1.1)

# Example 2:
## Critical value for five-group sequential analysis with
#  a maximum sample size of 25 events, requiring at 
#  least 1 event to reject the null, and with a significance level of 0.05:
result&lt;- CV.Binomial(N=25,alpha=0.05,M=1,z=7/2,GroupSizes=5)
# if you type:
result
# then you will get the following output:
# [[1]]
# [1] 1.9852

# [[2]]
# [1] 0.04775995

# Example 3:
## Critical value for four-group sequential analysis with
#  a maximum sample size of 50 events, requiring at 
#  least 1 event to reject the null, and with a significance level of 0.05:
result&lt;- CV.Binomial(N=50,alpha=0.05,M=1,z=7/2,GroupSizes=c(10,10,15,15))
cv&lt;- as.numeric(result[1])
# if you type:
cv
# then you will get the following output:
# [1] 1.99202

</code></pre>

<hr>
<h2 id='CV.CondPoisson'>Critical values for continuous sequential CMaxSPRT for Poisson data with limited information from historical cohort.</h2><span id='topic+CV.CondPoisson'></span>

<h3>Description</h3>

<p>The function <code>CV.CondPoisson</code> calculates critical values for the continuous sequential CMaxSPRT, using a Wald-type upper boundary,
which is flat with respect to the likelihood ratio function, and a pre-specified upper limit on surveillance length. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.CondPoisson(Inference="exact", StopType="Cases",T="n",K="n",cc,
D=0,M=1,alpha=0.05,Tailed="upper")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CV.CondPoisson_+3A_inference">Inference</code></td>
<td>
<p>Inference='liberal', 'exact', or 'conservative' for the computation approach. Inference='liberal' for the liberal approach with possibly underestimated critival values and higher-than-nominal Type I error rate, Inference='exact' for the exact approach with exact critival values and nominal Type I error rates, Inference='conservative' for the conservative approach with possibly overestimated critival values and lower-than-nominal Type I error rates. The default is Inference=&quot;exact&quot;.</p>
</td></tr>
<tr><td><code id="CV.CondPoisson_+3A_stoptype">StopType</code></td>
<td>
<p>StopType='Tal' or 'Cases' for the type of surveillance length definition. With StopType='Tal', the maximum surveillance length (i.e., the upper limit) is defined in terms of the ratio of the cumulative person-time in the surveillance population divided by the total cumulative person-time in historical data, i.e., <code class="reqn">P_k/V \leq T</code>; with StopType='Cases', the maximum surveillance length is defined interms of the observed number of events in the surveillance population, i.e., <code class="reqn">k \leq K</code>. The default is StopType=&quot;Cases&quot;</p>
</td></tr>
<tr><td><code id="CV.CondPoisson_+3A_cc">cc</code></td>
<td>
<p>The total number of observed adverse events in the historical data. There is no default value.</p>
</td></tr>
<tr><td><code id="CV.CondPoisson_+3A_k">K</code></td>
<td>
<p>The upper limit on length of surveillance expressed in terms of the observed number of events in the surveillance population, i.e., <code class="reqn">k \leq K</code>. This argument <code class="reqn">K</code> is used if and only if StopType='Cases'. There is no default value.</p>
</td></tr>
<tr><td><code id="CV.CondPoisson_+3A_t">T</code></td>
<td>
<p>The upper limit on length of surveillance expressed in terms of the ratio of the cumulative person-time in the surveillance population divided by the total cumulative person-time in historical data, i.e., <code class="reqn">P_k/V \le T</code>. This argument <code class="reqn">T</code> is used if and only if StopType='Tal'. There is no default value.</p>
</td></tr>
<tr><td><code id="CV.CondPoisson_+3A_d">D</code></td>
<td>
<p>The minium number for the ratio <code class="reqn">P_k/V</code> before the null hypothesis can be rejected. This argument is used together with <code class="reqn">T</code>. The default value is <code class="reqn">D=0</code>. A delayed start with <code class="reqn">D&gt;0</code> is recommended to avoid signaling very early on such that very little information would be available to judge whether the signal is more likely to be a true signal or chance finding.</p>
</td></tr>
<tr><td><code id="CV.CondPoisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. This argument is used together with <code class="reqn">K</code>. A delayed start with <code class="reqn">M&gt;1</code> is recommended to avoid signaling very early on such that very little information would be available to judge whether the signal is more likely to be a true signal or chance finding. The default value is M=1.</p>
</td></tr>
<tr><td><code id="CV.CondPoisson_+3A_alpha">alpha</code></td>
<td>
<p>The significance level, or the type 1 error probability, which is the probability of rejecting the null hypothesis when it is true. The alpha level  must be in the range (0,0.5]. The default value is alpha=0.05.</p>
</td></tr>
<tr><td><code id="CV.CondPoisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous sequential analysis with CMaxSPRT by Li and Kulldorff (2010) for Poisson data and limited historical data, <code>CV.CondPoisson</code> calculates the critical
value that constitutes the upper boundary used to determine if the null hypothesis should be rejected. This is done for pre-specified values
of the statistical significance level (alpha) and an upper limit which can be defined based on either the observed number of events, &quot;K&quot;, or the ratio &quot;T&quot;
between the cumulative person-times in the surveillance population versus the historical data, as well as other parameter settings.
</p>
<p>The test is one-sided, so that the null hypothesis is only rejected when there are more events than expected. 
</p>
<p>Following the results of Silva et al. (2016), the function offers three computation approaches which calculate liberal, exact, and conservative critical values respectively.
When the upper limit is medium (e.g., <code class="reqn">K=50</code>) or large, the computational requirements for the exact approach can be high.
The recommendation is to use the exact approach when the upper limit is small (e.g., <code class="reqn">K=10</code>), use the conservative approach
when the upper limit is medium (<code class="reqn">K=50</code>) or large but <code class="reqn">cc</code> is small, and use the liberal approach when <code class="reqn">cc</code> is medium (e.g., 50)
or large. Exact numerical results show that the three approaches yield very similar results when <code class="reqn">K</code> and <code class="reqn">cc</code> are reasonably large. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Type_I_Error</code></td>
<td>
<p>The actual Type I error, for the exact approach. It equals the nominal level specified by the argument &quot;alpha&quot;.
For the liberal approach, the actual Type I error rate may be higher than the specified nominal level. For the conservative approach,
the actual Type I error rate may be lower than the specified nominal level.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>The critical value for a significance level. For the exact approach, it is the exact critical value, for the liberal
approach, it is the smallest liberal vaue, for the conservative approach, it is the largest conservative value.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the <code>CV.CondPoisson</code> function was funded by:<br />
- National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0.1, v2.0.2).
</p>


<h3>See also</h3>

<p><code><a href="#topic+SampleSize.CondPoisson">SampleSize.CondPoisson</a></code>: calculating the upper limit with given Alpha, RR, and a desired power level for continuous CMaxSPRT.<br />
<code><a href="#topic+Performance.CondPoisson">Performance.CondPoisson</a></code>: calculating the statistical power, expected time to signal and expected
time of analysis for continuous CMaxSPRT.<br />
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Lingling Li</p>


<h3>References</h3>

<p>Li L, Kulldorff M. (2010). A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>Silva IR, Li L, Kulldorff M. (2019). Exact Conditional Sequential Testing for Poisson Data. Sequential Analysis, in press.
</p>
<p>Silva IR., Lopes LM., Dias P., Yih WK. (2019). Alpha Spending for Historical Versus Surveillance Poisson Data With CMaxSPRT. Statistics in Medicine, DOI: 10.1002/sim.8097, 1&ndash;13. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Calculates the exact critical value with upper limit of
# K=20 and a delayed start of a minimum of 2 cases, historical
# data has 20 events, and for a statistical significance level
# of 0.05. 
# res&lt;- CV.CondPoisson(Inference="exact", StopType="Cases",K=20,cc=20,
# M=2,alpha=0.05)

# which gives the results:
# res
# $Type_I_Error
# [1] 0.05
# $cv
# [1] 3.149115

# Calculates the liberal critical value with a uppe limit of
# T=0.5 and a delayed start of D=0.1, i.e., the cumulative
# person-time in the surveillance population is at least
# one-tenth of the total cumulative person-time in historical
# data, historical data has 20 events, and for a statistical
# significance level of 0.05. 
# res2&lt;- CV.CondPoisson(Inference="liberal",StopType="Tal",T=0.5,cc=20,
# D=0.1,alpha=0.05)

# which gives the results:
# res2
# $Type_I_Error
# [1] 0.05
# $cv
# [1] 2.874993


</code></pre>

<hr>
<h2 id='CV.Poisson'>Critical values for group and continuous sequential analysis with Poisson data.</h2><span id='topic+CV.Poisson'></span>

<h3>Description</h3>

<p>The function <code>CV.Poisson</code> obtains critical values for the group and continuous sequential MaxSPRT test with Poisson data, using a Wald 
type upper boundary, which is flat with respect to the likelihood ratio function, and with a pre-specified upper limit on the sample size.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.Poisson(SampleSize,D=0,M=1,alpha=0.05,GroupSizes="n",Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CV.Poisson_+3A_samplesize">SampleSize</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the expected number of events under the null hypothesis.
The SampleSize must be greater than 0. To avoid very large computation times, we suggest not using values greater than 1000. Typically,
this is not a major restriction. For example, for RR=1.1 and alpha=0.01, the statistical power is approximately 1 for a maximum 
sample size greater than 500. There is no default value.</p>
</td></tr>
<tr><td><code id="CV.Poisson_+3A_d">D</code></td>
<td>
<p>The expected number of events under the null hypothesis before the first look at the data. The default is D=0, which is
also the best choice. This means that there is no delay in the start of the sequential analyses. It is required that D&lt;=SampleSize. </p>
</td></tr>
<tr><td><code id="CV.Poisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. The default value is M=1, 
which means that even a single event can reject the null hypothesis if it occurs sufficiently early. A good rule of thumb is to set M=4
(Kulldorff and Silva, 2015).</p>
</td></tr>
<tr><td><code id="CV.Poisson_+3A_alpha">alpha</code></td>
<td>
<p>The significance level, or the type 1 error probability, which is the probability of rejecting the null hypothesis when it is true. The alpha level  must be in the range (0,0.5]. The default value is alpha=0.05.</p>
</td></tr>
<tr><td><code id="CV.Poisson_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector containing the expected number of events under H0 for each test. The values must be positive numbers. The dimension of this vector must be equal to the maximum number of sequential tests. Thus, the sum of the entries in GroupSizes has to be equal to SampleSize. The default is GroupSizes=&quot;n&quot; for continuous sequential analysis.</p>
</td></tr>
<tr><td><code id="CV.Poisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the group and continuous sequential analysis with Poisson data, using the maximized sequential probability ratio test (MaxSPRT), <code>CV.Poisson</code> calculates the upper boundary used to 
determine if the null hypothesis should be rejected. This is done for pre-specified values on the statistical significance level (alpha) and
the upper limit on the sample size, determining the maximum length of surveillance. The
algorithm used to calculate the critical value is described by Kulldorff et al. (2011). 
</p>
<p>For some configurations of SampleSize, D and alpha, there is no critical value that gives a significance level that is exactly equal to the
requested alpha. In such situations, <code>CV.Poisson</code> returns the greatest critical value that will guarantee an alpha level less than the alpha specified, 
so that sequential analysis is conservative.
</p>
<p>For large values of SampleSize, such as 200 or more, 
the computational requirements can be high. To speed things up, the function will sometimes use one of two look-up tables that contain
pre-calculated critical values for a pre-selected set of parameter values (<code>TableCV.PoissonD</code> and <code>TableCV.PoissonM</code>). 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>cv</code></td>
<td>
<p>The critical value for a significance level equal to alpha. The largest conservative value is provided when
it is not possible to have a Type I error exactly equal to alpha.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the CV.Poisson function was funded by:<br />
-	Food and Drug Administration, Center for Biologics Evaluation and Research, through the Mini-Sentinel Post-Rapid Immunization Safety Monitoring (PRISM) program (v1.0).<br />
-	National Council of Scientific and Technological Development (CNPq), Brazil (v1.0).<br />
-	Bank for Development of the Minas Gerais State (BDMG), Brazil (v1.0).<br />
-     National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0.1, 2.0.2).
</p>


<h3>See also</h3>

<p><code><a href="#topic+SampleSize.Poisson">SampleSize.Poisson</a></code>: for calculating the sample size needed for Continuous Sequential Analysis with Poisson Data.<br />
<code><a href="#topic+Performance.Poisson">Performance.Poisson</a></code>: for calculating the statistical power, expected time to signal and expected time of analysis for continuous sequential analysis with Poisson data.<br />
<code><a href="#topic+CV.Binomial">CV.Binomial</a></code>: for calculating critical values in continuous sequential analysis with binomial data.
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Calculates the critical value for continuous sequential analysis with
## a maximum sample size of ten expected cases under the null hypothesis,
## requiring at least 3 events to reject the null, and with a significance
## level of 0.05:

CV.Poisson(SampleSize=10,D=0,M=3,alpha=0.05)

#  Example 1:
## In this example, no critical value exist that will give the desired 0.05
## alpha level exactly. Instead, the function produces the critical value
## that makes the alpha as large as possible without exceeding 0.05.

CV.Poisson(SampleSize=3,D=1,M=1,alpha=0.05)

#  Example 2:
## Calculates the critical value for five-group sequential looks, at 5, 11,
## 17, 22 and 30 expected events under the null hypothesis, and for a
## statistical signifi-
## cance level of 0.05. 

CV.Poisson(SampleSize=30,alpha=0.05,GroupSizes= c(5,6,6,5,8))

</code></pre>

<hr>
<h2 id='Optimal.Binomial'>Optimal alpha spending for minimizing expected time to signal for continuous and group sequential analysis with binomial data.</h2><span id='topic+Optimal.Binomial'></span>

<h3>Description</h3>

<p>The function <code>Optimal.Binomial</code> obtains the optimal alpha spending function that minimizes the expected time to signal for target statistical power and fixed relative risk, when doing continuous or group sequential analysis for binomial data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Optimal.Binomial(Objective="ETimeToSignal",N="n",
z="n",p="n",alpha,power,RR,GroupSizes="n",Tailed= "upper",
ConfIntWidth="n",ConfTimes=1,Gamma=0.9,R0=1)
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Optimal.Binomial_+3A_objective">Objective</code></td>
<td>
<p>Statistical performance measure to minimize. Options are &quot;ETimeToSignal&quot;, for minimizing expected time to signal, and &quot;ESampleSize&quot;, for minimizing expected sample size. Default is &quot;ETimeToSignal&quot;.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_n">N</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the total number of events (cases plus controls). &quot;N&quot; must be a positive integer. To avoid very large computation times, we restrict the usage of values greater than 240. Typically, this is not a major restriction. For example, for &quot;RR=2.5&quot;, &quot;alpha=0.05&quot; and &quot;z=1&quot;, the statistical power is approximately 1 for &quot;N&gt;=150&quot;. Default is 'n', which means that the optimal 'N' will also be delivered by this function.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_p">p</code></td>
<td>
<p>The probability of having a case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_alpha">alpha</code></td>
<td>
<p>The significance level. The default value is &quot;alpha=0.05&quot;. Must be in the range (0, 0.5].</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_power">power</code></td>
<td>
<p>The target statistical power to detect an increased risk of the relative risk (RR). There is no default value.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_rr">RR</code></td>
<td>
<p>A target relative risk to be detected with the requested statistical power.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector with the number of events (exposed+unexposed) between two looks at the data, i.e, irregular group sizes. Important: Must sums up N. The default 'n' means continuous sequential testing.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_tailed">Tailed</code></td>
<td>
<p>Defines between one-tailed and two-tailed testing. Possible entries are &quot;lower&quot;, &quot;upper&quot;, and &quot;two&quot;.  Default is &quot;upper&quot;.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_confintwidth">ConfIntWidth</code></td>
<td>
<p>Positive values for a bounded-width confidence interval for the relative risk. The default ConfIntWidth=&quot;n&quot; means no constraint for ensuring the confidence interval width bound.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_conftimes">ConfTimes</code></td>
<td>
<p>Times when the bound on the confidence interval width are initiated for each entry of ConfIntWidth. Default is 1.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_gamma">Gamma</code></td>
<td>
<p>Confidence coefficient. Default is 0.9.</p>
</td></tr>
<tr><td><code id="Optimal.Binomial_+3A_r0">R0</code></td>
<td>
<p>A positive real-valued number for the relative risk under H0, where R0&lt;=1 if &quot;Tailed=lower&quot;, R0&gt;=1 if &quot;Tailed=upper&quot;, or a two-dimensional vector for H0: R0_1&lt;= R &lt;= R0_2 if &quot;Tailed=two&quot;. Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>Optimal.Binomial</code> elicits the optimal alpha spending for continuous and group binomial sequential testing
in order to provide the desired statistical power for a user-specified relative risk RR. The alpha spending provided minimizes the expected time to signal,
for Objective=&quot;ETimeToSignal&quot;, which is expected number of events when the null hypothesis is rejected, or expected length of surveillance if Objective=&quot;ESampleSize&quot;. 
</p>
<p>The sample size, N, is given in the scale of the total number of events (cases+controls). The input z represents the number of controls matched to each case.
For example, if there are 3 controls matched to each case, &quot;z=3&quot;. 
</p>
<p>In a self-control analysis, z is the ratio of the control interval to the risk interval. For example, if the risk interval is 2 days long and the control
interval is 7 days long, z=7/2. In terms of p, the binomial probability under the null hypothesis, p=1/(1+z), or equivalently, z=1/p-1.
The parameter z must be a positive number.
</p>
<p>Alternatively, instead of z the user can specify p directly.
Note that only one of these inputs, z or p, has to be specified, but if both are entered the code will only work if z and p are such that p=1/(1+z).
Otherwise, an error message will appear to remind that such condition must be complied.
</p>
<p>The optimal alpha spending solution is obtained by means of linear programing, which is possible following the exact derivations introduced by Silva and Kulldorff (2018).
For the linear programing part, the code uses the function <code>simplex</code>.
</p>
<p><code>Optimal.Binomial</code> works for large sample sizes such as 300 in the continuous sequential fashion, but it can take very long time to run in such cases.
Thus, for continuous sequential analysis, the usage is restricted for N values of at most 240. The computation time for N=240 under continuous fashion can
take one day or more. But, for smaller values, like e.g. N=150, the execution time is around 2 hours.
For N=120 this time reduces to something around 10 minuts, and, for N&lt;100, <code>Optimal.Binomial</code> takes only a few seconds to run.
But, processing time is much smaller for group sequential analysis. For example, take N=240. In this case, the optimum solution for two-stage (G=2) group
sequential analysis takes 16 minutes to run. The cases of N values of 200 or less, for G values of 10 or less, it will take just a few seconds to run.
These execution times were estimated using a regular PC(Windows 7, Intel(R) Core(TM) i7-2675QM CPU, 2.20GHz). 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>optimal_alpha_spending</code></td>
<td>
<p>The optimal cumulative alpha spending. In case of Tailed=&quot;two&quot;, there are 'optimal_alpha_spending_lower' and 'optimal_alpha_spending_upper', for the lower and upper signaling threshold, respectively.</p>
</td></tr>
<tr><td><code>minTimeToSignal</code></td>
<td>
<p>The minimum expected time to signal under RR. This is provided only if Objective=&quot;ETimeToSignal&quot;.</p>
</td></tr>
<tr><td><code>minESampleSize</code></td>
<td>
<p>The minimum expected time to signal under RR. This is provided only if Objective=&quot;ESampleSize&quot;.</p>
</td></tr>
<tr><td><code>ETimeToSignal</code></td>
<td>
<p>The expected time to signal associated to the alpha spending solution irrespectively to the content of the input 'Objective' under RR.</p>
</td></tr>
<tr><td><code>EsampleSize</code></td>
<td>
<p>The expected sample size associated to the alpha spending solution irrespectively to the content of the input 'Objective' under RR.</p>
</td></tr>
<tr><td><code>Power</code></td>
<td>
<p>Statistical power, obtained by usage of the optimal alpha spending with relative risk equal to RRtrue.</p>
</td></tr>
<tr><td><code>solved</code></td>
<td>
<p>Logical variable. It is equal to 1 if the linear programing procedure reached the optimal solution, 0 for inconclusive solution, and -1 if the method fails to find the solution.</p>
</td></tr>
<tr><td><code>Optimal_N</code></td>
<td>
<p>The maximum length of surveillance at which the optimal alpha spending reaches 'alpha' by a precision of 10^-6. This is returned only for N=&quot;n&quot;.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Optimal.Binomial function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999.
</p>


<h3>See also</h3>

<p><code><a href="#topic+CV.Binomial">CV.Binomial</a></code>: for calculating critical values in continuous sequential analysis with binomial data.<br />
<code><a href="#topic+Performance.Binomial">Performance.Binomial</a></code>: for calculating the statistical power, expected time to signal and expected time of analysis for continuous sequential analysis with binomial data.<br />
<code><a href="#topic+SampleSize.Poisson">SampleSize.Poisson</a></code>: sample size calculation for continuous sequential analysis with Poisson data.  
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Silva, I.R. and Kulldorff, M. and Yih, W. Katherine (2020). Optimal alpha spending for sequential analysis with binomial data. Journal of the Royal Statistical Society Series B, 82(4) p. 1141&ndash;1164.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#system.time(resESS&lt;- Optimal.Binomial(Objective="ESampleSize",
# N=120,z=1,p="n",alpha=0.05,power=0.9,RR=2,GroupSizes="n",Tailed= "upper"))

</code></pre>

<hr>
<h2 id='Performance.AlphaSpend.Binomial'>Calculates performance and signaling threshold for user-defined alpha spending for sequential analysis with binomial data.</h2><span id='topic+Performance.AlphaSpend.Binomial'></span>

<h3>Description</h3>

<p>The function <code>Performance.AlphaSpend.Binomial</code> calculates power, expected time to signal, expected sample size and signaling threshold (critical values) associated to any user-specified alpha spending for continuous or group sequential analysis with binomial data.
The user can select the scale for the signaling threshold among MaxSPRT, Pocock, OBrien-Fleming, or Wang-Tsiatis test statistics, all for a pre-specified upper limit on the sample size.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.AlphaSpend.Binomial(N,alpha,AlphaSpend=1,AlphaSpendLower="n",
AlphaSpendUpper="n",z="n",p="n",GroupSizes="n",
Tailed="upper",rho=0.5,gamma="n",RR=2,Statistic=c("MaxSPRT", "Pocock",
"OBrien-Fleming", "Wang-Tsiatis"),Delta="n")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_n">N</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the total number of events (cases plus controls). There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_alpha">alpha</code></td>
<td>
<p>Overall significance level. Must be a number in the (0, 0.5] interval. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_alphaspend">AlphaSpend</code></td>
<td>
<p>A vector with the cummulative Type I error probabiliy to be spent up to each test when &quot;Tailed=lower&quot; or &quot;Tailed=upper&quot;. Alternatively, one can use an integer between 1 to 4. Default is 1. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_alphaspendlower">AlphaSpendLower</code></td>
<td>
<p>A vector with the cummulative Type I error probabiliy regarding the lower signaling threshold to be spent up to each test when &quot;Tailed=two&quot;. Alternatively, one can use an integer between 1 to 4. Default is &quot;n&quot;, which means the specified &quot;AlphaSpend&quot; divided by 2.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_alphaspendupper">AlphaSpendUpper</code></td>
<td>
<p>A vector with the cummulative Type I error probabiliy regarding the upper signaling threshold to be spent up to each test when &quot;Tailed=two&quot;. Alternatively, one can use an integer between 1 to 4. Default is &quot;n&quot;, which means the specified &quot;AlphaSpend&quot; divided by 2.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_p">p</code></td>
<td>
<p>The probability of having a case under the null hypothesis. If just a single number is given, then it will be used as a constant probability for all groups. Otherwise, the dimension of p must coincide with the dimension of GroupSizes. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector with the total number of events (cases+controls) between two looks at the data with regular and irregular group sizes. Important: Must sums up N. For continuos sequential analysis, specify GroupSizes=1. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_rho">rho</code></td>
<td>
<p>Positive number used for the power-type alpha spending function (<code>AlphaSpend=1</code>) only. The default value is &quot;rho=0.5&quot;. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_gamma">gamma</code></td>
<td>
<p>Positive number used for the gamma-type alpha spending function (<code>AlphaSpend=4</code>) only. There is no default value. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_rr">RR</code></td>
<td>
<p>Vector of relative risks for performance calculation. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_statistic">Statistic</code></td>
<td>
<p>The test statistic scale used for &quot;cvs.lower&quot; and &quot;cvs.upper&quot;, therefore, this input has no effect if &quot;cases.lower&quot; and &quot;cases.upper&quot; are used instead. There is no default.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Binomial_+3A_delta">Delta</code></td>
<td>
<p>Parameter needed for calculation of Wang-Tsiatis test statistic if this is the option selected in &quot;Statistic&quot;. Must be a number in the (0, 0.5] interval. There is no default value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous and group sequential analysis with binomial data, signaling thresholds for
user-specified alpha spending are calculated with <code>Performance.AlphaSpend.Binomial</code>.
</p>
<p><code>N</code> must be a positive integer defining the maximum length of surveillance. To avoid very large computation times,
we suggest not using values greater than 1000.
</p>
<p><code>AlphaSpend</code> is used for arbitrary cumulative type I error probability spending defined by the user.
Alternatively, the user can select among one of the four classical alpha spending shapes bellow:<br />
<code class="reqn">F_{1}(t)=\alpha t^{\rho}</code>, where <code class="reqn">\rho&gt;0</code>,<br /> 
<code class="reqn">F_{2}(t)=2-2\Phi(x_{\alpha}\sqrt{t^{-1}})</code>, where <code class="reqn">x_{\alpha}=\Phi^{-1}(1-\alpha/2)</code>,<br /> 
<code class="reqn">F_{3}(t)= \alpha \times log(1+[exp{1}-1]\times t) </code>,<br />
<code class="reqn">F_{4}(t)=\alpha[1-exp(-t\gamma)]/[1-exp(-\gamma)]</code> with <code class="reqn">\gamma \in \Re</code>,<br />
and <code class="reqn">t</code> represents a fraction of the maximum length of surveillance. For more details on these alpha spending choices,
see the paper by Silva et al. (2019), Section 2.6.
</p>
<p>To select one of the four alpha spending types above, and using an integer <code class="reqn">i</code> to indicate the type among
<code class="reqn">i=</code> 1, 2, 3, and 4, for <code class="reqn">F_{1}(t)</code>, <code class="reqn">F_{2}(t)</code>, <code class="reqn">F_{3}(t)</code> and <code class="reqn">F_{4}(t)</code>, respectively,
one needs to set <code>AlphaSpend=i</code>. Specifically for <code>AlphaSpend=1</code>, it is necessary to choose a <code>rho</code> value,
or a <code>gamma</code> value if <code>AlphaSpend=4</code> is used.
</p>
<p><code>z</code> is a vector of positive numbers representing the matching ratios for each test (group). If a single number is given, then it will be used as a constant
matching ratio for all tests (groups). Otherwise, the dimension of <code>z</code> must coincide with the dimension of <code>GroupSizes</code>.
<code>z</code> represents the number of controls matched to each case. For example, if there are 3 controls matched to each case, <code>z</code>=3. 
In a self-control analysis, z is the ratio of the control interval to the risk interval.
For example, if the risk interval is 2 days long and the control interval is 7 days long, <code>z</code>=7/2.
In terms of <code>p</code>, the binomial probability under the null hypothesis, <code>p=1/(1+z)</code>, or equivalently, <code>z=1/p-1</code>.
</p>
<p>Alternatively, instead of <code>z</code> the user can specify <code>p</code> directly.
Note that only one of these inputs, <code>z</code> or <code>p</code>, has to be specified, but if both are entered the code will only work if <code>z</code>
and <code>p</code> are such that <code>p=1/(1+z)</code>. Otherwise, an error message will appear to remind that such condition must be complied.
</p>
<p>For details about the algorithm used to calculate the critical value, see the paper by Silva (2018).
</p>
<p>With <code>GroupSizes</code> the user informs the sample size of each subsequent test. Therefore, only positive integers are accepted in <code>GroupSizes</code>. 
</p>
<p>The input <code>Statistic</code> specifies the scale selected by the user to inform <code>cvs.lower</code> and <code>cvs.upper</code>among the classic methods:
MaxSPRT (Kulldorf et al., 2011), Pocock (Pocock, 1977), OBrien-Fleming (O'Brien and Fleming, 1979), or Wang-Tsiatis (Jennison and Turnbull, 2000). 
For <code>Statistic="Wang-Tsiatis"</code>, the user has to choose a number in the (0, 0.5] interval for <code>Delta</code>. 
</p>
<p>For <code>RR</code> the user must specify the target relative risks for calculation of the statistical performance measures to be delivered in the output.
It can be a vector of positive number or a single number. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>CV</code></td>
<td>
<p>Signaling threshold in the scale of the selected <code>Statistic</code> for the user-defined alpha spending.</p>
</td></tr>
<tr><td><code>CV.cases</code></td>
<td>
<p>Signaling threshold in the scale of the binomial data for the user-defined alpha spending.</p>
</td></tr>
<tr><td><code>ActualSpend</code></td>
<td>
<p>The actual Type I error probability with the calculated threshold.</p>
</td></tr>
<tr><td><code>Performance</code></td>
<td>
<p>A matrix with the following three performance measures for each target RR: statistical power, expected time to signal and expected sample size.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Performance.AlphaSpend.Binomial function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0,2.0 to 3.1).<br />
-	Federal University of Ouro Preto (UFOP), through contract under internal UFOP's resolution CEPE 4600 (v2.0 to 3.1).<br />
<br />
</p>


<h3>See also</h3>

<p><code><a href="#topic+Performance.Threshold.Binomial">Performance.Threshold.Binomial</a></code>: for calculating performance and alpha spending for user-specified signaling threshold with binomial data.<br />
<code><a href="#topic+CV.Binomial">CV.Binomial</a></code>: for calculating Wald-type signaling thresholds for continuous sequential analysis with binomial data.<br />
<code><a href="#topic+Analyze.Binomial">Analyze.Binomial</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion with binomial data.
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials, London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>O'Brien PC, Fleming TR. (1979). A multiple testing procedure for clinical trials. Biometrics. 35:549&ndash;556.
</p>
<p>Pocock SJ. (1977).Group sequential methods in the design and analysis of clinical trials. Biometrika. 64:191&ndash;199.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance with Binomial Data. Statistics in Medicine, 15;37(1), 107-118.
</p>
<p>Silva IR, Kulldorff M. (2015). Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2019). Exact Sequential Analysis Using R Sequential. Working Paper.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Performance and threshold for group binomial sequential analysis
#  with a maximum sample size of 50 events for upper-tailed testing
#  that is, H0:RR&lt;=1, with irregular group sizes 15, 15, 10, and 10.
#  This is done for alpha spending of the power-type.
#  The statistical performance is evaluated for RR= 2:

# res&lt;- Performance.AlphaSpend.Binomial(N=50,alpha=0.05,AlphaSpend=1,z=c(1,1.5,2,1.3),
# p="n",GroupSizes=c(15,15,10,10),Tailed="upper",RR=2,rho=0.5)

</code></pre>

<hr>
<h2 id='Performance.AlphaSpend.CondPoisson'>Calculates performance and signaling thresholds for user-defined alpha spending for sequential analysis with conditional Poisson data.</h2><span id='topic+Performance.AlphaSpend.CondPoisson'></span>

<h3>Description</h3>

<p>The function <code>Performance.AlphaSpend.CondPoisson</code> calculates power, expected time to signal and signaling threshold (critical values) associated to any user-specified alpha spending, flat or non-flat, for continuous or group sequential analysis with conditional Poisson data,
all for a pre-specified upper limit on the sample size.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.AlphaSpend.CondPoisson(K,cc,alpha,AlphaSpend="n",
GroupSizes="n",rho=0.5,gamma="n",Tailed="upper",RR)
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_k">K</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the number of events arriving in the surveillance period. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_cc">cc</code></td>
<td>
<p>Number of events observed in the historical period. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_alpha">alpha</code></td>
<td>
<p>The overall significance level.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_alphaspend">AlphaSpend</code></td>
<td>
<p>A vector with the cummulative Type I error probabiliy to be spent up to each test. Alternatively, one can use an integer between 1 to 4. There is no default value. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Test-specific number of events between two looks at the data for group or continuous sequential analysis. There is no default value. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_rho">rho</code></td>
<td>
<p>Positive number used for the power-type alpha spending function (<code>AlphaSpend=1</code>) only. The default value is &quot;rho=0.5&quot;. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_gamma">gamma</code></td>
<td>
<p>Positive number used for the gamma-type alpha spending function (<code>AlphaSpend=4</code>) only. There is no default value. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.CondPoisson_+3A_rr">RR</code></td>
<td>
<p>Vector of relative risks for performance calculation. There is no default value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous and group sequential analysis based on monitoring Poisson data conditioned on matched
historical Poisson data, the threshold impplied by user-specified alpha spending is calculated with
<code>Performance.AlphaSpend.CondPoisson</code>. The function delivers the threshold in two scales, the the Conditional Maximized Sequential
Probability Ratio Test statistic (CMaxSPRT) scale (Li and Kulldorff, 2010), and the surveillance versus historical person-time ratio (Silva et al., 2019a).
For the CMaxSPRT scale, the null hypothesis is rejected if the test statistic exceeds the critical value at some test. Regarding the person-time ratio scale,
using the notation by Silva et al. (2019a) and Silva et al. (2019b), let <code class="reqn">V</code> denote the
total person-time from the historical data, where <code>cc</code> events were observed, and let <code class="reqn">P_{k(i)}</code> denote the the cummulative
person-time from the surveillance data at the i-th test with a cummulative <code class="reqn">k(i)</code> events. Suppose that for
a three-group sequential plan, with sample sizes of 20, 15, 25, the critival values were 0.1, 0.5, and 1. This way, H0 is rejected if: <code class="reqn">P_20/V</code> &lt;= 0.1 in the first test,
or <code class="reqn">P_35/V</code> &lt;= 0.5 in the second test, or <code class="reqn">P_60/V</code> &lt;= 1 in the third test. 
</p>
<p><code>AlphaSpend</code> is used for arbitrary cumulative type I error probability spending defined by the user.
Alternatively, the user can select among one of the four classical alpha spending shapes bellow:<br />
<code class="reqn">F_{1}(t)=\alpha t^{\rho}</code>, where <code class="reqn">\rho&gt;0</code>,<br /> 
<code class="reqn">F_{2}(t)=2-2\Phi(x_{\alpha}\sqrt{t^{-1}})</code>, where <code class="reqn">x_{\alpha}=\Phi^{-1}(1-\alpha/2)</code>,<br /> 
<code class="reqn">F_{3}(t)= \alpha \times log(1+[exp{1}-1]\times t) </code>,<br />
<code class="reqn">F_{4}(t)=\alpha[1-exp(-t\gamma)]/[1-exp(-\gamma)]</code> with <code class="reqn">\gamma \in \Re</code>,<br />
and <code class="reqn">t</code> represents a fraction of the maximum length of surveillance. For more details on these alpha spending choices,
see the paper by Silva et al. (2019c), Section 2.6.
</p>
<p>To select one of the four alpha spending types above, and using an integer <code class="reqn">i</code> to indicate the type among
<code class="reqn">i=</code> 1, 2, 3, and 4, for <code class="reqn">F_{1}(t)</code>, <code class="reqn">F_{2}(t)</code>, <code class="reqn">F_{3}(t)</code> and <code class="reqn">F_{4}(t)</code>, respectively,
one needs to set <code>AlphaSpend=i</code>. Specifically for <code>AlphaSpend=1</code>, it is necessary to choose a <code>rho</code> value,
or a <code>gamma</code> value if  <code>AlphaSpend=4</code> is used.
</p>
<p>With <code>GroupSizes</code> the user informs the sample size of each test in the scale of the
number of events in the surveillance period. Therefore, only positive
numbers are accepted in <code>GroupSizes</code>. For irregular group sizes, a vector must be informed
with each test-specific number of events between two looks at the data, therefore the entries of
<code>GroupSizes</code> must sums up <code>K</code>. For regular group sizes, a single number can be informed
for the constant sample size of each test. For example, for continuous sequential analysis,
<code>GroupSizes=1</code>. For ten-group sequential analysis with <code>K=50</code>, <code>GroupSizes=5</code>. 
</p>
<p>For <code>RR</code> the user must specify the target relative risks for calculation of statistical performance measures.
It can be a vector of positive numbers or a single number. 
</p>
<p>For details on the calculation of signaling thresholds and alpha spending for Poisson data conditioned to historical data,
see the papers by Silva et al. (2019a) and Silva et al. (2019b), respectively.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>CV</code></td>
<td>
<p>Signaling threshold in the scale of CMaxSPRT associated to the user-specified alpha spending.</p>
</td></tr>
<tr><td><code>Person-timeRatioH0</code></td>
<td>
<p>Signaling threshold in the <code class="reqn">P_k/V</code> scale.</p>
</td></tr>
<tr><td><code>Performance</code></td>
<td>
<p>A matrix with the following three performance measures for each target RR: statistical power, expected time to signal and expected sample size.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Performance.AlphaSpend.CondPoisson function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0,2.0 to 3.1).<br />
-	Federal University of Ouro Preto (UFOP), through contract under internal UFOP's resolution CEPE 4600 (v2.0 to 3.1).<br />
<br />
</p>


<h3>See also</h3>

<p><code><a href="#topic+Performance.Threshold.CondPoisson">Performance.Threshold.CondPoisson</a></code>: for calculating performance and alpha spending for user-specified signaling threshold with conditional Poisson data.<br />
<code><a href="#topic+CV.CondPoisson">CV.CondPoisson</a></code>: for calculating Wald-type signaling thresholds for continuous sequential analysis with conditional Poisson data based on the CMaxSPRT test statistic.<br />
<code><a href="#topic+Analyze.CondPoisson">Analyze.CondPoisson</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion for condicional Poisson data based on the CMaxSPRT test statistic.
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials, London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Li L, Kulldorff M. (2010). A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>O'Brien PC, Fleming TR. (1979). A multiple testing procedure for clinical trials. Biometrics. 35:549&ndash;556.
</p>
<p>Pocock SJ. (1977). Group sequential methods in the design and analysis of clinical trials. Biometrika. 64:191&ndash;199.
</p>
<p>Silva IR, Li L, Kulldorff M. (2019a), Exact conditional maximized sequential probability ratio test adjusted for covariates. Sequential Analysis, 38(1), 115&ndash;133.
</p>
<p>Silva IR., Lopes LM., Dias P., Yih WK. (2019b). Alpha Spending for Historical Versus Surveillance Poisson Data With CMaxSPRT. Statistics in Medicine, 38(12), 2126&ndash;2138.
</p>
<p>Silva IR, Kulldorff M. (2015). Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2019c). Exact Sequential Analysis Using R Sequential. Working Paper.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Example 1
## Performance and threshold for three group CMaxSPRT sequential with
#  a maximum sample size of 30 events for upper-tailed
#  testing, i.e. H0:RR&lt;=1, with regular groups of sizes 10
#  and alpha spending of 0.01, 0.02, and 0.05 for tests
#  1, 2 and 3, respectively. 
#  The statistical performance is evaluated for three
#  target RR= 1.2, 1.5, 2:

# res&lt;- Performance.AlphaSpend.CondPoisson(K=30,cc=10,alpha=0.05,
# AlphaSpend=c(0.01,0.02,0.05),GroupSizes=c(10,10,10),RR=c(1.2,1.5,2))

#### Example 2
## Performance and threshold for three group CMaxSPRT with
#  a maximum sample size of 30 events for upper-tailed
#  testing, i.e. H0:RR&lt;=1, with regular groups of sizes 10
#  and alpha spending of the power-type.
#  The statistical performance is evaluated for three
#  target RR= 1.2, 1.5, 2:

# res&lt;- Performance.AlphaSpend.CondPoisson(K=30,cc=10,alpha=0.05,
# AlphaSpend=1,GroupSizes=c(10,10,10),rho=0.75,RR=c(1.2,1.5,2))

</code></pre>

<hr>
<h2 id='Performance.AlphaSpend.Poisson'>Calculates performance and signaling thresholds for user-defined alpha spending for sequential analysis with Poisson data.</h2><span id='topic+Performance.AlphaSpend.Poisson'></span>

<h3>Description</h3>

<p>The function <code>Performance.AlphaSpend.Poisson</code> calculates power, expected time to signal, expected sample size and the signaling threshold (critical values) associated to any user-specified alpha spending for continuous sequential analysis with Poisson data,
or for a pre-specified upper limit on the sample size.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.AlphaSpend.Poisson(SampleSize,alpha=0.05,D=0,M=1,RR,alphaSpend=1,rho=0.5,
R0=1,gamma="n",Statistic=c("MaxSPRT", "Pocock", "OBrien-Fleming", "Wang-Tsiatis"),
Delta="n",Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_samplesize">SampleSize</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the expected number of events under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_alpha">alpha</code></td>
<td>
<p>The overall significance level.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_d">D</code></td>
<td>
<p>The expected number of events under the null hypothesis at the first look at the data.
This is used when there is an initial large chunk of data arriving, followed by continuous sequential analysis. The default value is D=0, which is
also the best choice. This means that there is no delay in the start of the sequential analyses. If D is very large, the maximum 
sample size will be set equal to D if a non-sequential analysis provides the desired power.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. It must be a positive integer.
A good rule of thumb is to set M=4 (Kulldorff and Silva, 2015). The default value is M=1, which means that even a single event
can reject the null hypothesis if it occurs sufficiently early.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_rr">RR</code></td>
<td>
<p>Vector of relative risks for performance calculation. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_alphaspend">alphaSpend</code></td>
<td>
<p>A vector with the cummulative Type I error probabiliy to be spent up to each test. Alternatively, one can use an integer between 1 to 4. Default is 1. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_rho">rho</code></td>
<td>
<p>Positive number used for the power-type alpha spending function (<code>AlphaSpend=1</code>) only. The default value is &quot;rho=0.5&quot;. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_r0">R0</code></td>
<td>
<p>A positive real-valued number for the relative risk under H0, where R&lt;=R0 if &quot;Tailed=lower&quot;, R&gt;=R0 if &quot;Tailed=upper&quot;, or a two-dimensional vector for H0: R0_1&lt;= R &lt;= R0_2 if &quot;Tailed=two&quot;. Default is 1.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_gamma">gamma</code></td>
<td>
<p>Positive number used for the gamma-type alpha spending function (<code>AlphaSpend=4</code>) only. There is no default value. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_statistic">Statistic</code></td>
<td>
<p>The test statistic scale to deliver the signaling threshold. See Details.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_delta">Delta</code></td>
<td>
<p>Parameter needed for calculation of Wang-Tsiatis test statistic if this is the option selected in &quot;Statistic&quot;. Must be a number in the (0, 0.5] interval. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.AlphaSpend.Poisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous and group sequential analysis based on monitoring Poisson data, the threshold impplied by user-specified alpha spending is calculated with
<code>Performance.AlphaSpend.Poisson</code>. The function delivers the threshold in the scale of a test statistic selected by the user with the input
<code>Statistic</code> among the classic methods:
MaxSPRT (Kulldorf et al., 2011), Pocock (Pocock, 1977), OBrien-Fleming (O'Brien and Fleming, 1979), or Wang-Tsiatis (Jennison and Turnbull, 2000). 
For <code>Statistic="Wang-Tsiatis"</code>, the user has to choose a number in the (0, 0.5] interval for <code>Delta</code>.
</p>
<p><code>alphaSpend</code> is used for arbitrary cumulative type I error probability spending defined by the user.
Alternatively, the user can select among one of the four classical alpha spending shapes bellow:<br />
<code class="reqn">F_{1}(t)=\alpha t^{\rho}</code>, where <code class="reqn">\rho&gt;0</code>,<br /> 
<code class="reqn">F_{2}(t)=2-2\Phi(x_{\alpha}\sqrt{t^{-1}})</code>, where <code class="reqn">x_{\alpha}=\Phi^{-1}(1-\alpha/2)</code>,<br /> 
<code class="reqn">F_{3}(t)= \alpha \times log(1+[exp{1}-1]\times t) </code>,<br />
<code class="reqn">F_{4}(t)=\alpha[1-exp(-t\gamma)]/[1-exp(-\gamma)]</code> with <code class="reqn">\gamma \in \Re</code>,<br />
and <code class="reqn">t</code> represents a fraction of the maximum length of surveillance.
</p>
<p>To select one of the four alpha spending types above, and using an integer <code class="reqn">i</code> to indicate the type among
<code class="reqn">i=</code> 1, 2, 3, and 4, for <code class="reqn">F_{1}(t)</code>, <code class="reqn">F_{2}(t)</code>, <code class="reqn">F_{3}(t)</code> and <code class="reqn">F_{4}(t)</code>, respectively,
one needs to set <code>alphaSpend=i</code>. Specifically for <code>alphaSpend=1</code>, it is necessary to choose a <code>rho</code> value,
or a <code>gamma</code> value if <code>alphaSpend=4</code> is used.
</p>
<p>For more details on these alpha spending choices,
see the paper by Silva et al. (2021), Section 2.7.
</p>
<p>For <code>RR</code> the user must specify the target relative risks for calculation of statistical performance measures.
It can be a vector of positive numbers or a single number. 
</p>
<p>For details on the calculation of signaling thresholds and alpha spending for Poisson data,
see the paper by Silva et al. (2018).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>cvs</code></td>
<td>
<p>Signaling threshold in the scale of the <code>Statistic</code> selected for the user-specified alpha spending.</p>
</td></tr>
<tr><td><code>Performance</code></td>
<td>
<p>A matrix with the following three performance measures for each target RR: statistical power, expected time to signal and expected sample size.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Performance.AlphaSpend.Poisson function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0,2.0 to 3.1).<br />
-	Federal University of Ouro Preto (UFOP), through contract under internal UFOP's resolution CEPE 4600 (v2.0 to 3.1).<br />
<br />
</p>


<h3>See also</h3>

<p><code><a href="#topic+Performance.Threshold.Poisson">Performance.Threshold.Poisson</a></code>: for calculating performance and alpha spending for user-specified signaling threshold with Poisson data.<br />
<code><a href="#topic+CV.Poisson">CV.Poisson</a></code>: for calculating Wald-type signaling thresholds for continuous sequential analysis with Poisson data based on the CMaxSPRT test statistic.<br />
<code><a href="#topic+Analyze.Poisson">Analyze.Poisson</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion for Poisson data based on the CMaxSPRT test statistic.
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials, London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Li L, Kulldorff M. (2010). A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>O'Brien PC, Fleming TR. (1979). A multiple testing procedure for clinical trials. Biometrics. 35:549&ndash;556.
</p>
<p>Pocock SJ. (1977). Group sequential methods in the design and analysis of clinical trials. Biometrika. 64:191&ndash;199.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance With Poisson Data. Methodol Comput Appl Probab, 20(2), 739&ndash;750.
</p>
<p>Silva IR, Kulldorff M. (2015). Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2021). Exact sequential test for clinical trials and post-market drug and vaccine safety surveillance with Poisson and binary data. Statistics in Medicine, DOI: 10.1002/sim.9094.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Example
## Perfofmance and threshold for continuous sequential analysis
#  with a maximum sample size of 30 events for upper-tailed
#  testing, i.e. H0:RR&lt;=1, with alpha spending of the
#  power-type and threshold delivered in the MaxSPRT
#  test statistic scale.  
#  The statistical performance is evaluated for three
#  target RR= 1.5:

# res&lt;- Performance.AlphaSpend.Poisson(SampleSize=30, alpha=0.05,alphaSpend=1,
# RR=1.5,rho=0.5,gamma="n",Statistic="MaxSPRT")

</code></pre>

<hr>
<h2 id='Performance.Binomial'>Statistical power, expected time to signal and expected sample size for group and continuous sequential analysis with binomial data.</h2><span id='topic+Performance.Binomial'></span>

<h3>Description</h3>

<p>The function <code>Performance.Binomial</code> calculates several performance 
metrics for group and continuous binomial MaxSPRT for fixed upper limit on the sample 
size (&quot;N&quot;), minimum number of events required before rejecting the null hypothesis (&quot;M&quot;), critical value (&quot;cv&quot;) and a relative risk (&quot;RR&quot;).
The metrics calculated are the statistical power, the expected time to signal when the null hypothesis is 
rejected, and the expected sample size at the end of the analysis whether the null hypothesis was rejected or not.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.Binomial(N,M=1,cv,z="n",p="n",RR=2,GroupSizes=1,Tailed="upper")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.Binomial_+3A_n">N</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the total number of events. 
&quot;N&quot; must be greater than 0. To avoid very large computation times, we suggest not using values greater than 1000. Typically,
this is not a major restriction. For example, for &quot;RR=1.1&quot; and &quot;alpha=0.01&quot; and &quot;z=1&quot;, the statistical power is approximately 1 for &quot;N&gt;500&quot;. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Binomial_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. The default value is 'M=1', 
which means that even a single event can reject the null hypothesis if it occurs sufficiently early. A good rule of thumb is to set 'M=4'
(Kulldorff and Silva, 2015). It must be a positive integer.</p>
</td></tr>
<tr><td><code id="Performance.Binomial_+3A_cv">cv</code></td>
<td>
<p>Critical value, defining the upper rejection boundary. The null hypothesis is rejected when the log-likelihood value is greater than &quot;cv&quot;. The &quot;cv&quot; parameter is usually obtained by first running <code>CV.Binomial</code>. It must be a positive number. The default is GroupSizes=1 for continuous sequential analysis.</p>
</td></tr>
<tr><td><code id="Performance.Binomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Binomial_+3A_p">p</code></td>
<td>
<p>The probability of having a case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Binomial_+3A_rr">RR</code></td>
<td>
<p>The relative risk (&gt;=1) for which statistical power, expected signal time and expected length of surveillance are calculated. The default is RR=2.</p>
</td></tr>
<tr><td><code id="Performance.Binomial_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector with the number of events (cases+controls) between two consecutive looks (tests) at the data, i.e, the group sizes. The
length of this vector is equal to the maximum number of looks. The entries do not have the same, but they sum up to N.
If the group sizes is an integer instead of a vector, then that integer is the group size for all looks at the data, and the number of looks is &quot;N/GroupSizes&quot;.</p>
</td></tr>
<tr><td><code id="Performance.Binomial_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For group and continuous Binomial MaxSPRT, the function <code>Performance.Binomial</code> calculates the statistical power, the expected time to signal 
when the null hypothesis is rejected, and the expected sample size until the analysis ends whether the null is rejected or not. When the null hypothesis is true, the probability of
having a case, instead of a control, is <code class="reqn">p=1/(1+z)</code>. But, if the null hypothesis is false, and the true relative risk is a value 'RR&gt;1', then the
probability of having a case is <code class="reqn">p=RR/(RR+z)</code>.
If the user wants to calculate the exact Type I error probability for a given &quot;cv&quot;, that can be done by setting &quot;RR=1&quot;, in which case the power output value is the exact size of the test.
</p>
<p>The input z represents the number of controls matched to each case. For example, if there are 3 controls matched to each case, &quot;z=3&quot;. 
In a self-control analysis, z is the ratio of the control interval to the risk interval.
For example, if the risk interval is 2 days long and the control interval is 7 days long, z=7/2.
In terms of p, the binomial probability under the null hypothesis, p=1/(1+z), or equivalently, z=1/p-1. The parameter z must be a positive number.
</p>
<p>Alternatively, instead of z the user can specify p directly.
Note that only one of these inputs, z or p, has to be specified, but if both are entered the code will only work if z and p are such that p=1/(1+z).
Otherwise, an error message will appear to remind that such condition must be complied.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Power</code></td>
<td>
<p>The statistical power.</p>
</td></tr>
<tr><td><code>ESignaltime</code></td>
<td>
<p>The expected time to signal given that the null hypothesis is rejected.</p>
</td></tr>
<tr><td><code>EsampleSize</code></td>
<td>
<p>The expected sample size when the analysis ends (length of surveillance) whether the null hypothesis was rejected or not.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Performance.Binomial function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999.
</p>


<h3>See also</h3>

<p><code><a href="#topic+CV.Binomial">CV.Binomial</a></code>: for calculating critical values in continuous sequential analysis with binomial data.<br />
<code><a href="#topic+SampleSize.Binomial">SampleSize.Binomial</a></code>: for calculating the minimum sample size given a target power in continuous sequential analysis with binomial data.<br />
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva and Martin Kulldorff.
</p>


<h3>References</h3>

<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example 1:
# Performance of a continuous MaxSPRT sequential analysis
result&lt;- Performance.Binomial(N=30,M=1,cv=2,z=1,RR=2)
# if you type:
result
# then you will get the following output:
# $power
# [1] 0.658732

# $signaltime
# [1] 10.7893

# $surveillancetime
# [1] 17.3453

# Example 2:
# Performance of a 20-group MaxSPRT sequential analysis
result&lt;- Performance.Binomial(N=40,M=1,cv=2.5,z=1,RR=2,GroupSizes=2)
# if you type:
result
# then you will get the following output:
# $Power
# [1] 0.6594118

# $`ESignalTime`
# [1] 17.18626

# $`ESampleSize`
# [1] 24.95635

</code></pre>

<hr>
<h2 id='Performance.CondPoisson'>Statistical power, expected time to signal and expected sample size for the continuous sequential CMaxSPRT for Poisson data with limited information from historical cohort.</h2><span id='topic+Performance.CondPoisson'></span>

<h3>Description</h3>

<p>The function <code>Performance.CondPoisson</code> calculates several performance metrics for the continuous CMaxSPRT for selected computation approach,
the type of upper limit definition and its value, critical value, number of historical data events, criteria of delayed start, the Type I error rate,
and a relative risk. The metrics calculated are the statistical power, the expected time to signal when the null hypothesis
is rejected, and the expected sample size at the end of the analysis whether the null hypothesis was rejected or not.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.CondPoisson(Inference="exact",cv,StopType="Cases",
T="n",K="n",cc,D=0,M=1,RR=2,Tailed="upper")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.CondPoisson_+3A_inference">Inference</code></td>
<td>
<p>Inference='liberal', 'exact', or 'conservative' for the computation approach. Inference='liberal' for the liberal approach with possibly underestimated critival values and higher-than-nominal Type I error rate, Inference='exact' for the exact approach with exact critival values and nominal Type I error rates, Inference='conservative' for the conservative approach with possibly overestimated critival values and lower-than-nominal Type I error rates. The default is Inference='exact'.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_cv">cv</code></td>
<td>
<p>Critical value, defining the upper rejection boundary for the log-likelihood ratio test statistic. The null hypothesis is rejected when the log-likelihood value is greater than 'cv'. The 'cv' parameter is
usually obtained by first running <code>CV.CondPoisson</code>. It must be a positive number,and there is no default.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_stoptype">StopType</code></td>
<td>
<p>StopType='Tal' or 'Cases' for the type of surveillance length definition. The default value is 'StopType=Cases'. See details.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_t">T</code></td>
<td>
<p>The upper limit on length of surveillance expressed in terms of the ratio of the cumulative person-time in the surveillance population divided by the total cumulative person-time in historical data, i.e., <code class="reqn">P_k/V \leq T</code>. This argument <code class="reqn">T</code> is used if and only if StopType='Tal'. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_k">K</code></td>
<td>
<p>The upper limit on length of surveillance expressed in terms of the observed number of events in the surveillance population, i.e., <code class="reqn">k \leq K</code>. This argument <code class="reqn">K</code> is used if and only if StopType='Cases'. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_cc">cc</code></td>
<td>
<p>The total number of observed adverse events in the historical data. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_d">D</code></td>
<td>
<p>The minium number for the ratio <code class="reqn">P_k/V</code> before the null hypothesis can be rejected. This argument is used together with StopType='Tal'. The default value is <code class="reqn">D=0</code>.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. This argument is used together with StopType='Cases'. The default value is M=1.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_rr">RR</code></td>
<td>
<p>The target relative risk for which statistical power, expected signal time and expected length of surveillance are calculated. The default is 'RR=2'.</p>
</td></tr>
<tr><td><code id="Performance.CondPoisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous sequential analysis with Poisson data with limited historical information, (Li and Kulldorff, 2010), the <code>Performance.CondPoisson</code> function calculates the
statistical power, the expected time to signal when the null hypothesis is rejected and the expected sample size until the analysis ends whether the
null is rejected or not. The sample size (i.e., the upper limit) can be expressed either in terms of the ratio &quot;T&quot; of the cumulative person-time in the surveillance population
divided by the total cumulative person-time in historical data (StopType=&quot;Tal&quot;), i.e., <code class="reqn">P_k/V \leq T</code>, or in terms of the observed number of events &quot;K&quot; in the surveillance
population (StopType=&quot;Cases&quot;), i.e., <code class="reqn">k \leq K</code>. Large values of the SampleSize, greater than say 1000, may leads to long computing times. When the statistical power
is close to 1, then the expected time to signal will be very close to the expected sample size.
</p>
<p>For the parameter of delayed start, &quot;D&quot;, a delayed start with <code class="reqn">D&gt;0</code> is recommended to avoid signaling very early on such that very little
information would be available to judge whether the signal is more likely to be a true signal or chance finding. Similarly, if the delayed start is defined in
terms of the number of events, &quot;M&quot;, a setting such that <code class="reqn">M&gt;1</code> is recommended to avoid signaling very early on such that very little information would
be available to judge whether the signal is more likely to be a true signal or chance finding.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Power</code></td>
<td>
<p>The statistical power.</p>
</td></tr>
<tr><td><code>ESignalTime</code></td>
<td>
<p>The expected time to signal given that the null hypothesis is rejected.</p>
</td></tr>
<tr><td><code>ESampleSize</code></td>
<td>
<p>The expected sample size when the sequential analysis ends (length of surveillance) whether the null hypothesis was rejected or not.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the <code>Performance.CondPoisson</code> function was funded by:<br />
- National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0.1, v2.0.2).
- Foundation for Research Support of Minas Gerais State (FAPEMIG), MG, Brazil, through the grant Demanda Universal.
</p>


<h3>See also</h3>

<p><code><a href="#topic+CV.CondPoisson">CV.CondPoisson</a></code>: calculating the critical value for continuous CMaxSPRT.  <br />
<code><a href="#topic+SampleSize.CondPoisson">SampleSize.CondPoisson</a></code>: calculating the sample size for continuous CMaxSPRT.<br />
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Lingling Li</p>


<h3>References</h3>

<p>Li L, Kulldorff M. (2010). A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>Silva IR, Li L, Kulldorff M. (2019). Exact conditional maximized sequential probability ratio test adjusting for covariates. Sequential Analysis, in press.
</p>
<p>Silva IR., Lopes LM., Dias P., Yih WK. (2019). Alpha Spending for Historical Versus Surveillance Poisson Data With CMaxSPRT. Statistics in Medicine, DOI: 10.1002/sim.8097, 1&ndash;13. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## First calculate the critical value with upper limit defined in terms of
## the number of observed events in surveillance population (K=50), with 50
## events in historical data, no delayed start, and alpha=0.05: 
# res&lt;-CV.CondPoisson(Inference="exact",StopType="Cases",K=20,cc=50,M=1,
# alpha=0.05)

# cvt&lt;- res[[2]] 

## calculate the performance using the critical value 'cvt' from the previous
## step, under RR=1.5:
#Performance.CondPoisson(Inference="exact",cv=cvt,StopType="Cases",K=20,cc=50,
# M=1,RR=1.5) 

</code></pre>

<hr>
<h2 id='Performance.Poisson'>Calculates statistical power, expected time to signal and expected sample size for group and continuous sequential analysis with Poisson data.</h2><span id='topic+Performance.Poisson'></span>

<h3>Description</h3>

<p>The <code>Performance.Poisson</code> function calculates three different performance metrics for group and continuous sequential analysis with Poisson data:
the statistical power, the expected time to signal when the null hypothesis is rejected and the expected sample size at the end of the analysis whether the
null hypothesis was rejected or not. The user specifies the relative risk under the alternative hypothesis (RR), as well as the sequential analysis parameters. 
To calculate the statistical significance level alpha, RR=1, in which case the power output value is the alpha level.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.Poisson(SampleSize, D = 0, M = 1, cv, RR = 2,GroupSizes="n",Tailed="upper")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.Poisson_+3A_samplesize">SampleSize</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the expected number of events under the null hypothesis.
The SampleSize must be greater than 0. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Poisson_+3A_d">D</code></td>
<td>
<p>The expected number of events under the null hypothesis at the first look at the data. The default is D=0, which is
also the best choice. This means that there is no delay in the start of the sequential analysis. It is required that D<code class="reqn">\leq</code>SampleSize.</p>
</td></tr>
<tr><td><code id="Performance.Poisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed to be observed before the null hypothesis can be rejected. The default is M=1, 
which means that even a single event can reject the null hypothesis if it occurs sufficiently early. A good rule of thumb is to set M=4
(Kulldorff and Silva, 2015).</p>
</td></tr>
<tr><td><code id="Performance.Poisson_+3A_cv">cv</code></td>
<td>
<p>The critical value constituting the upper rejection boundary. This can be calculated using the <code><a href="#topic+CV.Poisson">CV.Poisson</a></code> function.</p>
</td></tr>
<tr><td><code id="Performance.Poisson_+3A_rr">RR</code></td>
<td>
<p>The relative risk under the alternative hypothesis. It is required that RR<code class="reqn">\geq 1</code>. The default value is RR=2.</p>
</td></tr>
<tr><td><code id="Performance.Poisson_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector containing the expected number of events under H0 for each test. The values must be positive numbers. The dimension of this vector must be equal to the maximum number of sequential tests. Thus, the sum of the entries in GroupSizes has to be equal to SampleSize. The default is GroupSizes=&quot;n&quot; for continuous sequential analysis.</p>
</td></tr>
<tr><td><code id="Performance.Poisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For group and continuous sequential analysis with Poisson data, the <code>Performance.Poisson</code> function calculates the statistical power, the expected time to signal when
the null hypothesis is rejected and the expected sample size until the analysis ends whether the null is rejected or not. The sample size is expressed in terms of
the expected number of events under the null hypothesis. Large values of the SampleSize, greater than say 1000, may leads to long computing times.
When the statistical power is close to 1, then the expected time to signal will be very close to the expected sample size, since both are measured in information time,
using the expected events under the null hypothesis as the unit.
</p>
<p>To avoid very large computation times, we suggest not using values greater than 1000. Typically, this is not a major restriction. For example,
for RR=1.1 and alpha=0.01, the statistical power is approximately 1 for a maximum sample size greater than 500.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Power</code></td>
<td>
<p>The statistical power.</p>
</td></tr>
<tr><td><code>ESignalTime</code></td>
<td>
<p>The expected time to signal given that the null hypothesis is rejected.</p>
</td></tr>
<tr><td><code>ESampleSize</code></td>
<td>
<p>The expected sample size when the sequential analysis ends (length of surveillance) whether the null hypothesis was rejected or not.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Performance.Poisson function was funded by:<br />
-	Food and Drug Administration, Center for Biologics Evaluation and Research, through the Mini-Sentinel Post-Rapid Immunization Safety Monitoring (PRISM) program (v1.0).<br />
-	National Council of Scientific and Technological Development (CNPq), Brazil (v1.0).<br />
-	Bank for Development of the Minas Gerais State (BDMG), Brazil (v1.0).<br />
-     National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0.1,2.0.2).  
</p>


<h3>See also</h3>

<p><code><a href="#topic+CV.Poisson">CV.Poisson</a></code>: Calculates critical values for continuous sequential analysis with Poisson data.<br /> 
<code><a href="#topic+SampleSize.Poisson">SampleSize.Poisson</a></code>: Sample size calculations for continuous sequential analysis with Poisson data.
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva and Martin Kulldorff
</p>


<h3>References</h3>

<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Vaccine Safety Surveillance. Sequential Analysis, 30: 58&ndash;78.
Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example 1:
## Suppose we want to find the statistical power to detect a relative risk
## of 2 when doing up to at most 20 months of surveillance, as well as the
## expected time to signal when the null hypothesis is rejected. During 
## each month, we expected to see 0.5 events if the null hypothesis is true. 
## This means that the upper limit on the sample size is 20*0.5=10 expected
## events under the null hypothesis. We will then first calculate the critical
## value for an upper limit on the sample size equal to 10 and a significance
## level of alpha=0.05:

# cvt&lt;- CV.Poisson(SampleSize=10,alpha=0.05)
# cvt
# [1] 3.467952

## After that, we use the Performance.Poisson function to calculate the
## power and the expected time to signal when the null hypothesis is
## rejected for the alternative hypothesis with a relative risk equal to 2:

## Power, expected signal time and expected sample size for a relative risk
## equal to 2:
# Performance.Poisson(SampleSize=10,cv=cvt,RR=2)
#         Power    ESignalTime    ESampleSize 
# [1,] 0.6850634     4.130985      5.979353

## From the results, we see that the statistical power is 68.5%. When the null
## is rejected, the expected time to signal is 4.13 in the unit of events
## expected under the null. If data is collected uniformly over time at the
## rate of 0.5 expected counts per month,the expected time to signal is
## 4.13/0.5= 8.26 months.

## The above calculations can also be accomplished using one single command line:

#  Performance.Poisson(SampleSize=10,cv=CV.Poisson(SampleSize=10,alpha=0.05),RR=2)
#         Power    ESignalTime    ESampleSize
#  [1,] 0.6850634     4.130985      5.979353

# Example 2:
## First use the CV.Poisson function to calculate the critical value for
## 5 sequential looks  at the data, spaced six units apart, and with a
## statistical significance level of 0.05:

cvt&lt;- CV.Poisson(SampleSize=30,alpha=0.05,GroupSizes=c(6,6,6,6,6))

## For an alternative hypothesis of a relative risk of RR=1.5, calculates the
## statistical power, the expected time to signal, and the expected sample size
## at the end of the sequential analysis.

(Performance.Poisson(SampleSize=30,cv=cvt,GroupSizes=c(6,6,6,6,6),RR=1.5))
</code></pre>

<hr>
<h2 id='Performance.Threshold.Binomial'>Statistical Performance and Alpha Spending For User-defined Signaling Threshold With Binomial Data.</h2><span id='topic+Performance.Threshold.Binomial'></span>

<h3>Description</h3>

<p>The function <code>Performance.Threshold.Binomial</code> calculates power, expected time to signal, expected sample size and alpha spending associated to any user-specified signaling threshold, flat or non-flat, for continuous or group sequential analysis with binomial data.
The user can select the scale for the signaling threshold among MaxSPRT, Pocock, OBrien-Fleming, or Wang-Tsiatis test statistics. Alternatively, the threshold can be informed also in the scale of the binomial data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.Threshold.Binomial(N,CV.lower="n",CV.upper="n",z="n",p="n",
GroupSizes="n",Tailed="upper",Statistic=c("MaxSPRT", "Pocock",
"OBrien-Fleming", "Wang-Tsiatis","Cases"),Delta="n",RR)
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.Threshold.Binomial_+3A_n">N</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the total number of events (cases plus controls). There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_cv.lower">CV.lower</code></td>
<td>
<p>Signaling threshold for evidence of &quot;RR&lt;1&quot;. It is given in the scale of the selected test statistic infomed in &quot;Statistic&quot;. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_cv.upper">CV.upper</code></td>
<td>
<p>Signaling threshold for evidence of &quot;RR&gt;1&quot;. It is given in the scale of the selected test statistic infomed in &quot;Statistic&quot;. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_p">p</code></td>
<td>
<p>The probability of having a case under the null hypothesis. If just a single number is given, then it will be used as a constant probability for all groups. Otherwise, the dimension of p must coincide with the dimension of GroupSizes. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector with the total number of events (cases+controls) between two looks at the data with regular and irregular group sizes. Important: Must sums up N. For continuos sequential analysis, specify GroupSizes=1. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_statistic">Statistic</code></td>
<td>
<p>The test statistic scale used for &quot;CV.lower&quot; and &quot;CV.upper&quot;. There is no default.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_delta">Delta</code></td>
<td>
<p>Parameter needed when &quot;Statistic=Wang-Tsiatis&quot; is selected. Must be a number in the (0, 0.5] interval. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Binomial_+3A_rr">RR</code></td>
<td>
<p>Vector of relative risks for performance calculation. There is no default value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous and group sequential analysis with binomial data, alpha spending for
user-specified thresholds are calculated with <code>Performance.Threshold.Binomial</code>.
</p>
<p><code>N</code> must be a positive integer defining the maximum length of surveillance. To avoid very large computation times,
we suggest not using values greater than 1000.
</p>
<p>For two-tailed testing (<code>Tailed="two"</code>), both lower and upper signaling thresholds must be informed through
<code>CV.lower</code> and <code>CV.upper</code>. If the user
desires a constant threshold (critical value) in the scale of a test statistic, then a single number can be informed.
For time-variable (non-constant) thresholds, the length of <code>CV.upper</code> and <code>CV.lower</code> must coincide with the length of <code>GroupSizes</code>.
</p>
<p><code>z</code> is a vector of positive numbers representing the matching ratios for each test (group). If a single number is given, then it will be used as a constant
matching ratio for all tests (groups). Otherwise, the dimension of <code>z</code> must coincide with the dimension of <code>GroupSizes</code>.
<code>z</code> represents the number of controls matched to each case. For example, if there are 3 controls matched to each case, <code>z</code>=3. 
In a self-control analysis, z is the ratio of the control interval to the risk interval.
For example, if the risk interval is 2 days long and the control interval is 7 days long, <code>z</code>=7/2.
In terms of <code>p</code>, the binomial probability under the null hypothesis, <code>p=1/(1+z)</code>, or equivalently, <code>z=1/p-1</code>.
</p>
<p>Alternatively, instead of <code>z</code> the user can specify <code>p</code> directly.
Note that only one of these inputs, <code>z</code> or <code>p</code>, has to be specified, but if both are entered the code will only work if <code>z</code>
and <code>p</code> are such that <code>p=1/(1+z)</code>. Otherwise, an error message will appear to remind that such condition must be complied.
</p>
<p>With <code>GroupSizes</code> the user informs the sample size of each subsequent test. Therefore, only positive integers are accepted in <code>GroupSizes</code>. 
</p>
<p>The input <code>Statistic</code> specifies the scale selected by the user to inform <code>CV.lower</code> and <code>cvs.upper</code>among the classic methods:
MaxSPRT (Kulldorf et al., 2011), Pocock (Pocock, 1977), OBrien-Fleming (O'Brien and Fleming, 1979), or Wang-Tsiatis (Jennison and Turnbull, 2000). 
For <code>Statistic="Wang-Tsiatis"</code>, the user has to choose a number in the (0, 0.5] interval for <code>Delta</code>.
</p>
<p>Important: for time-variable matching ratios (i.e. when <code>z</code> or <code>p</code> changes from a test to another), only the &quot;Statistic=Cases&quot; option works.
This is because the test statistic options are non-monotone with the number of cumulative cases under a variable <code>p</code> or <code>z</code> situation.
</p>
<p>For <code>RR</code> the user must specify the target relative risks for calculation of the statistical performance measures to be delivered in the output.
It can be a vector of positive number or a single number. 
</p>
<p>For details about the algorithm used to calculate the critical value, see the paper by Silva (2018).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>AlphaSpend</code></td>
<td>
<p>The alpha spending associated to the user-specified threshold.</p>
</td></tr>
<tr><td><code>Performance</code></td>
<td>
<p>A matrix with the following three performance measures for each target RR: statistical power, expected time to signal and expected sample size.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Performance.Threshold.Binomial function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0,2.0 to 3.1).<br />
-	Federal University of Ouro Preto (UFOP), through contract under internal UFOP's resolution CEPE 4600 (v2.0 to 3.1).<br />
<br />
</p>


<h3>See also</h3>

<p><code><a href="#topic+Performance.AlphaSpend.Binomial">Performance.AlphaSpend.Binomial</a></code>: for calculating signaling threshold for user-specified alpha spending with binomial data.<br />
<code><a href="#topic+CV.Binomial">CV.Binomial</a></code>: for calculating Wald-type signaling thresholds for continuous sequential analysis with binomial data.<br />
<code><a href="#topic+Analyze.Binomial">Analyze.Binomial</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion with binomial data.
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials, London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>O'Brien PC, Fleming TR. (1979). A multiple testing procedure for clinical trials. Biometrics. 35:549&ndash;556.
</p>
<p>Pocock SJ. (1977).Group sequential methods in the design and analysis of clinical trials. Biometrika. 64:191&ndash;199.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance with Binomial Data. Statistics in Medicine, 15;37(1), 107-118.
</p>
<p>Silva IR, Kulldorff M. (2015). Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2021), Exact sequential test for clinical trials and post-market drug and vaccine safety surveillance with Poisson and binary data. Statistics in Medicine, DOI: 10.1002/sim.9094.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Performance and Alpha spending of a four-group sequential
#  analysis with threshold informed in the scale of the
#  binomial data, i.e. Statistic="Cases". 
#  The analysis is for a maximum sample size of 50 events under 
#  upper-tailed testing, that is, H0:RR&lt;=1, with irregular group
#  sizes of 12, 25, 35, and 45. 
#  The matching ratio also changes in time with z= 1, 1.5, 2, 1.3.
#  The statistical performance is evaluated for RR= 1.2, 1.5, 2:

# res&lt;- Performance.Threshold.Binomial(N=50,CV.upper=c(12,25,35,45),
# z=c(1,1.5,2,1.3),GroupSizes=c(15,15,10,10),Tailed="upper",
# Statistic="Cases", RR=c(1.2,1.5,2))

</code></pre>

<hr>
<h2 id='Performance.Threshold.CondPoisson'>Performance and alpha spending for user-defined signaling threshold for sequential analysis with conditional Poisson data.</h2><span id='topic+Performance.Threshold.CondPoisson'></span>

<h3>Description</h3>

<p>The function <code>Performance.Threshold.CondPoisson</code> calculates the statistical power, expected time to signal, expected sample size and alpha spending associated to any user-specified signaling threshold, flat or non-flat, for continuous or group sequential analysis with conditional Poisson data,
all for a pre-specified upper limit on the sample size.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.Threshold.CondPoisson(K,cc,CV.upper="n",
Person_timeRatioH0="n",GroupSizes="n",Tailed="upper",RR)
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.Threshold.CondPoisson_+3A_k">K</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the number of events arriving in the surveillance period. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.CondPoisson_+3A_cc">cc</code></td>
<td>
<p>Number of events observed in the historical period. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.CondPoisson_+3A_cv.upper">CV.upper</code></td>
<td>
<p>User-specified signaling threshold given in the scale of the CMaxSPRT test statistic. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.CondPoisson_+3A_person_timeratioh0">Person_timeRatioH0</code></td>
<td>
<p>Test-specific amount of information of each test given in terms of the ratio between the person-time in the surveillance period and the overall person-time of the historical period. See Details. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.CondPoisson_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Test-specific number of events between two looks at the data for group or continuous sequential analysis. There is no default value. See Details.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.CondPoisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.CondPoisson_+3A_rr">RR</code></td>
<td>
<p>Vector of relative risks for performance calculation. There is no default value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous and group sequential analysis based on monitoring Poisson data conditioned on matched
historical Poisson data, the power, expected time to signal, expected sample size and alpha spending impplied by user-specified thresholds are calculated with
<code>Performance.Threshold.CondPoisson</code>. The user can select one between two scales to enter with the
threshold, the the Conditional Maximized Sequential
Probability Ratio Test statistic (CMaxSPRT) scale (Li and Kulldorff, 2010), or the surveillance versus historical person-time ratio (Silva et al., 2019a).
For the CMaxSRT scale, the input is <code>CV.upper</code>. This can be entered as a vector for group sequential analysis. For example, for a three-group sequential test,
the i-th entry represents the critical value for the i-th test, with i=1, 2, 3. If a single number is informed in <code>CV.upper</code>, then
a flat critical value for all tests is used for both continuous or group sequential fashions. The number of tests is defined with the input <code>GroupSizes</code>,
as shall be detailed here after the desciption of <code>Person_timeRatioH0</code>. 
</p>
<p>An alternative way to inform the threshold is by using <code>Person_timeRatioH0</code>, which is in the scale of the ratio between the person-time
in the surveillance period and the
overall person-time of the historical period. Using the notation by Silva et al. (2019a) and Silva et al. (2019b), let <code class="reqn">V</code> denote the
total person-time from the historical data, where <code>cc</code> events were observed, and let <code class="reqn">P_{k(i)}</code> denote the the cummulative
person-time from the surveillance data at the i-th test with a cummulative <code class="reqn">k(i)</code> events. With <code>Person_timeRatioH0</code>,
the entries must have increasing numbers, from the first to the last. For example,
for a three-group sequential plan with sample sizes of 20, 15, 25, a hypothetical choice is
<code>Person_timeRatioH0=c(0.1, 0.5, 1)</code>. This way, H0 is rejected if: <code class="reqn">P_20/V</code> &lt;= 0.1 in the first test,
or <code class="reqn">P_35/V</code> &lt;= 0.5 in the second test, or <code class="reqn">P_60/V</code> &lt;= 1 in the third test. 
</p>
<p>Note: only one of the inputs <code>CV.upper</code> or <code>Person_timeRatioH0</code> is to be used.
</p>
<p>With <code>GroupSizes</code> the user informs the sample size of each test in the scale of the
number of events in the surveillance period. Therefore, only positive
numbers are accepted in <code>GroupSizes</code>. For irregular group sizes, a vector must be informed
with each test-specific number of events between two looks at the data, therefore the entries of
<code>GroupSizes</code> must sums up <code>K</code>. For regular group sizes, a single number can be informed
for the constant sample size of each test. For example, for continuous sequential analysis,
<code>GroupSizes=1</code>. For ten-group sequential analysis with <code>K=50</code>, <code>GroupSizes=5</code>. 
</p>
<p>For <code>RR</code> the user must specify the target relative risks for calculation of statistical performance measures.
It can be a vector of positive numbers or a single number. 
</p>
<p>For details on the calculation of signaling thresholds and alpha spending for Poisson data conditioned to historical data,
see the papers by Silva et al. (2019a) and Silva et al. (2019b), respectively.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Performance</code></td>
<td>
<p>A matrix with the following three performance measures for each target RR: statistical power, expected time to signal and expected sample size.</p>
</td></tr>
<tr><td><code>AlphaSpend</code></td>
<td>
<p>The alpha spending associated to the user-specified threshold.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Performance.Threshold.CondPoisson function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0,2.0 to 3.1).<br />
-	Federal University of Ouro Preto (UFOP), through contract under internal UFOP's resolution CEPE 4600 (v2.0 to 3.1).<br />
<br />
</p>


<h3>See also</h3>

<p><code><a href="#topic+Performance.AlphaSpend.CondPoisson">Performance.AlphaSpend.CondPoisson</a></code>: for calculating performance and signaling threshold for user-specified alpha spending with conditional Poisson data.<br />
<code><a href="#topic+CV.CondPoisson">CV.CondPoisson</a></code>: for calculating Wald-type signaling thresholds for continuous sequential analysis with conditional Poisson data based on the CMaxSPRT test statistic.<br />
<code><a href="#topic+Analyze.CondPoisson">Analyze.CondPoisson</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion for condicional Poisson data based on the CMaxSPRT test statistic.
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials, London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>Li L, Kulldorff M. (2010). A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>O'Brien PC, Fleming TR. (1979). A multiple testing procedure for clinical trials. Biometrics. 35:549&ndash;556.
</p>
<p>Pocock SJ. (1977). Group sequential methods in the design and analysis of clinical trials. Biometrika. 64:191&ndash;199.
</p>
<p>Silva IR, Li L, Kulldorff M. (2019a), Exact conditional maximized sequential probability ratio test adjusted for covariates. Sequential Analysis, 38(1), 115&ndash;133.
</p>
<p>Silva IR., Lopes LM., Dias P., Yih WK. (2019b). Alpha Spending for Historical Versus Surveillance Poisson Data With CMaxSPRT. Statistics in Medicine, 38(12), 2126&ndash;2138.
</p>
<p>Silva IR, Kulldorff M. (2015). Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2019). Exact Sequential Analysis Using R Sequential. Working Paper.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Example 1
## Power, expected time to signal, expected sample size and
## alpha spending of three group CMaxSPRT sequential analysis with
#  a maximum sample size of 30 events for upper-tailed
#  testing, i.e. H0:RR&lt;=1, with regular groups of sizes 10
#  and a flat threshold equal to 3.6. 
#  The statistical performance is evaluated for two
#  target RR= 1.5, 2:

# Performance.Threshold.CondPoisson(K=30,cc=10,CV.upper=3.6, Person_timeRatioH0="n",
# GroupSizes=10,RR=c(1.5,2))

#### Example 2
## Power, expected time to signal, expected sample size and
#  alpha spending of three group CMaxSPRT sequential analysis with
#  a maximum sample size of 30 events for upper-tailed
#  testing, i.e. H0:RR&lt;=1, with regular groups of sizes 10
#  and thresholds given in the P_k/V scale:
#  "Person_timeRatioH0=c(0.1, 0.5, 1)". 
#  The statistical performance is evaluated for two
#  target RR= 1.5, 2:

# Performance.Threshold.CondPoisson(K=30,cc=10,CV.upper="n", Person_timeRatioH0=c(0.1, 0.5, 1),
# GroupSizes=10,RR=c(1.5,2))

</code></pre>

<hr>
<h2 id='Performance.Threshold.Poisson'>Performance and alpha spending for user-defined signaling threshold for sequential analysis with Poisson data.</h2><span id='topic+Performance.Threshold.Poisson'></span>

<h3>Description</h3>

<p>The function <code>Performance.Threshold.Poisson</code> calculates power, expected time to signal and alpha spending associated to any user-specified signaling threshold, flat or non-flat, for continuous or group sequential analysis with Poisson data.
The user can select the scale for the signaling threshold among MaxSPRT, Pocock, OBrien-Fleming, or Wang-Tsiatis test statistics, all for a pre-specified upper limit on the sample size.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Performance.Threshold.Poisson(SampleSize,CV.lower="n",CV.upper="n",
CV.events.upper="n",M=1,D=0,GroupSizes="n",Tailed="upper",
Statistic=c("MaxSPRT", "Pocock", "OBrien-Fleming", "Wang-Tsiatis"),
Delta="n",RR)
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Performance.Threshold.Poisson_+3A_samplesize">SampleSize</code></td>
<td>
<p>The upper limit on the sample size (length of surveillance) expressed in terms of the expected number of events under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_cv.lower">CV.lower</code></td>
<td>
<p>Signaling threshold for evidence of &quot;RR&lt;1&quot;. It is given in the scale of the selected test statistic infomed in &quot;Statistic&quot;. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_cv.upper">CV.upper</code></td>
<td>
<p>Signaling threshold for evidence of &quot;RR&gt;1&quot;. It is given in the scale of the selected test statistic infomed in &quot;Statistic&quot;. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_cv.events.upper">CV.events.upper</code></td>
<td>
<p>Signaling threshold for evidence of &quot;RR&gt;1&quot;. It is given in the scale of the events. The is no default value unless when one uses &quot;CV.upper&quot; instead.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. It must be a positive integer.
A good rule of thumb is to set M=4 (Kulldorff and Silva, 2015). The default value is M=1, which means that even a single event
can reject the null hypothesis if it occurs sufficiently early.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_d">D</code></td>
<td>
<p>The expected number of events under the null hypothesis at the first look at the data.
This is used when there is an initial large chunk of data arriving, followed by continuous sequential analysis. The default value is D=0, which is
also the best choice. This means that there is no delay in the start of the sequential analyses. If D is very large, the maximum 
sample size will be set equal to D if a non-sequential analysis provides the desired power.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_groupsizes">GroupSizes</code></td>
<td>
<p>Vector with the test-specific expected number of events under the null hypothesis between two looks at the data. Important: Must sums up &quot;SampleSize&quot;. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_statistic">Statistic</code></td>
<td>
<p>The test statistic scale used for &quot;CV.lower&quot; and &quot;CV.upper&quot;. There is no default.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_delta">Delta</code></td>
<td>
<p>Parameter needed for calculation of Wang-Tsiatis test statistic if this is the option selected in &quot;Statistic&quot;. Must be a number in the (0, 0.5] interval. There is no default value.</p>
</td></tr>
<tr><td><code id="Performance.Threshold.Poisson_+3A_rr">RR</code></td>
<td>
<p>Vector of relative risks for performance calculation. There is no default value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous and group sequential analysis with Poisson data, the alpha spending for
user-specified thresholds are calculated with <code>Performance.Threshold.Poisson</code>. 
</p>
<p>The inputs <code>CV.lower</code>, <code>CV.upper</code>, if two-tailed testing (<code>Tailed="two"</code>),
both lower and upper signaling thresholds must be informed. If the user
desires a constant threshold (critical value), then a single number can be informed for each of these inputs.
For time-variable (non-constant) thresholds, the length of <code>CV.lower</code> and <code>CV.upper</code> must coincide with the length of <code>GroupSizes</code>.
</p>
<p>For details about the algorithm used to calculate the critical value, see the paper by Silva (2018).
</p>
<p>With <code>GroupSizes</code> the user informs the sample size of each subsequent test. Therefore, only positive numbers are accepted in <code>GroupSizes</code>. 
</p>
<p>The input <code>Statistic</code> specifies the scale selected by the user to inform <code>CV.lower</code> and <code>CV.upper</code> among the classic methods:
MaxSPRT (Kulldorf et al., 2011), Pocock (Pocock, 1977), OBrien-Fleming (O'Brien and Fleming, 1979), or Wang-Tsiatis (Jennison and Turnbull, 2000). 
For <code>Statistic="Wang-Tsiatis"</code>, the user has to choose a number in the (0, 0.5] interval for <code>Delta</code>. 
</p>
<p>For <code>RR</code> the user must specify the target relative risks for calculation of the statistical performance measures to be delivered in the output.
It can be a vector of positive number or a single number. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>AlphaSpend</code></td>
<td>
<p>The alpha spending associated to the user-specified threshold.</p>
</td></tr>
<tr><td><code>Performance</code></td>
<td>
<p>A matrix with the following three performance measures for each target RR: statistical power, expected time to signal and expected sample size.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the Performance.Threshold.Poisson function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0,2.0 to 3.1).<br />
-	Federal University of Ouro Preto (UFOP), through contract under internal UFOP's resolution CEPE 4600 (v2.0 to 3.1).<br />
<br />
</p>


<h3>See also</h3>

<p><code><a href="#topic+Performance.AlphaSpend.Poisson">Performance.AlphaSpend.Poisson</a></code>: for calculating performance and signaling threshold for user-specified alpha spending with Poisson data.<br />
<code><a href="#topic+CV.Poisson">CV.Poisson</a></code>: for calculating Wald-type signaling thresholds for continuous and group sequential analysis with Poisson data.<br />
<code><a href="#topic+Analyze.Poisson">Analyze.Poisson</a></code>: for performing sequential analysis with group, continuous or unpredictable sequential fashion for Poisson data.
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Jennison C, Turnbull B. (2000). Group Sequential Methods with Applications to Clinical Trials, London: Chapman and Hall/CRC.
</p>
<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. <em>Sequential Analysis</em>, <b>30</b>: 58&ndash;78.
</p>
<p>O'Brien PC, Fleming TR. (1979). A multiple testing procedure for clinical trials. Biometrics. 35:549&ndash;556.
</p>
<p>Pocock SJ. (1977). Group sequential methods in the design and analysis of clinical trials. Biometrika. 64:191&ndash;199.
</p>
<p>Silva IR. (2018). Type I Error Probability Spending for Post-Market Drug and Vaccine Safety Surveillance With Poisson Data. Methodol Comput Appl Probab, 20(2), 739&ndash;750.
</p>
<p>Silva IR, Kulldorff M. (2015). Continuous versus Group Sequential Analysis for Vaccine and Drug Safety Surveillance. Biometrics, 71 (3), 851&ndash;858.
</p>
<p>Silva IR, Maro J, Kulldorff M. (2021). Exact sequential test for clinical trials and post-market drug and vaccine safety surveillance with Poisson and binary data. Statistics in Medicine, DOI: 10.1002/sim.9094.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example 1
#  Performance and alpha spending of group Poisson sequential analysis
#  with a maximum sample size of 90 expected events for two-tailed
#  testing, i.e. H0:RR=1, with irregular group sizes and different
#  and lower and upper thresholds with irregular
#  sample sizes 25, 20, 20, and 25. 
#  The statistical performance is evaluated for four different
#  target RR= 1, 1.2, 2, 3:

# res&lt;- Performance.Threshold.Poisson(SampleSize=90,CV.lower=c(2.5,2.6,2.7,2.8),
# CV.upper=c(3,3.1,3.2,3.3),GroupSizes=c(25,20,20,25),Tailed="two",
# Statistic="MaxSPRT",Delta="n",RR=c(1,1.2,2,3))

## Example 2
#  Suppose that the Analyze.Poisson function was used for an actual analysis.
#  For evaluating the cumulative power after a certain number of subsequent tests,
#  one can enter with the critical values delivered by Analyze.Poisson in the
#  Performance.Threshold.Poisson.
#  For example, suppose that the following thresholds in the scale of the events
#  were printed by Analyze.Poisson for the first three tests:
#     cv.events&lt;- c(2,3,5)
#  which were obtained for the following specific sample sizes:
#     mus&lt;- c(0.05,0.5,1.2)
#  Calculating the cumulative power, the expected time to signal, and 
#  the expected sample size for RR=2:

# res&lt;-Performance.Threshold.Poisson(SampleSize=sum(mus),CV.events.upper=cv.events,
# GroupSizes=mus, Statistic="MaxSPRT",RR=2)


# This returns a power about 30%.

</code></pre>

<hr>
<h2 id='SampleSize.Binomial'>Sample size calculation for continuous sequential analysis with binomial data.</h2><span id='topic+SampleSize.Binomial'></span>

<h3>Description</h3>

<p>The function <code>SampleSize.Binomial</code> obtains the sample size needed to guarantee a desired statistical power, for a fixed true relative risk, when doing continuous sequential analysis for binomial data with a Wald-type upper boundary, which is flat with respect to the log-likelihood ratio. It can also be used to approximate the sample size needed when doing group sequential analysis for binomial data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>SampleSize.Binomial(RR,alpha=0.05,power=0.9,M=1,z="n",p="n",Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SampleSize.Binomial_+3A_rr">RR</code></td>
<td>
<p>A target vector of relative risks to be detected with the requested statistical powers.</p>
</td></tr>
<tr><td><code id="SampleSize.Binomial_+3A_alpha">alpha</code></td>
<td>
<p>The significance level. The default value is &quot;alpha=0.05&quot;. Must be in the range (0, 0.5].</p>
</td></tr>
<tr><td><code id="SampleSize.Binomial_+3A_power">power</code></td>
<td>
<p>The target vector of overall statistical powers to detect an increased risk of the relative risk (RR). The default value is &quot;power=0.90&quot;.</p>
</td></tr>
<tr><td><code id="SampleSize.Binomial_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. It must be a positive integer. The default value is &quot;M=1&quot;.</p>
</td></tr>
<tr><td><code id="SampleSize.Binomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to each case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="SampleSize.Binomial_+3A_p">p</code></td>
<td>
<p>The probability of having a case under the null hypothesis. There is no default value.</p>
</td></tr>
<tr><td><code id="SampleSize.Binomial_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>SampleSize.Binomial</code> calculates the sample size N, to be used for the continuous binomial MaxSPRT in order to provide the desired statistical power for a user-specified relative risk RR. The required sample size (Required_N) is expressed in terms of the total number of observations, and it is the number of observations by which the sequential analysis will end without rejected the null hypothesis. The solution is  exact using iterative numerical calculations. 
</p>
<p>The required sample size, N, increases for increasing values of power, while N decreases for increasing values of alpha, the relative risk RR and the minimum number of events needed to signal M. For increasing values of z, the required sample size N can either decrease or increase.
</p>
<p>While this function calculates the required sample size for continuous sequential analysis, it can also be used as an approximation for group sequential analyses. With the same Required_N, and all other parameters being the same, a group sequential analysis will always give higher statistical power than a continuous sequential analysis, so <code>SampleSize.Binomial</code> can be use to ensure the required statistical power for group sequential analyses. 
</p>
<p>The input z represents the number of controls matched to each case. For example, if there are 3 controls matched to each case, &quot;z=3&quot;. 
In a self-control analysis, z is the ratio of the control interval to the risk interval.
For example, if the risk interval is 2 days long and the control interval is 7 days long, z=7/2.
In terms of p, the binomial probability under the null hypothesis, p=1/(1+z), or equivalently, z=1/p-1. The parameter z must be a positive number.
</p>
<p>Alternatively, instead of z the user can specify p directly.
Note that only one of these inputs, z or p, has to be specified, but if both are entered the code will only work if z and p are such that p=1/(1+z).
Otherwise, an error message will appear to remind that such condition must be complied.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>SampleSize_by_RR_Power</code></td>
<td>
<p>A table containing the main performance measures associated to the required samples sizes for each combination of RR and power. The sample size N is provided in terms of the total number of observations. In the case-control setting, this is equal to the total number of cases and controls. In the self-control setting, it is equal to the total number of events in either the risk or the control interval.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the SampleSize.Binomial function was funded by:<br />
-	National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999.
</p>


<h3>See also</h3>

<p><code><a href="#topic+CV.Binomial">CV.Binomial</a></code>: for calculating critical values in continuous sequential analysis with binomial data.<br />
<code><a href="#topic+Performance.Binomial">Performance.Binomial</a></code>: for calculating the statistical power, expected time to signal and expected time of analysis for continuous sequential analysis with binomial data.<br />
<code><a href="#topic+SampleSize.Poisson">SampleSize.Poisson</a></code>: sample size calculation for continuous sequential analysis with Poisson data.  
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.
</p>


<h3>References</h3>

<p>Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
result&lt;- SampleSize.Binomial(RR=5,alpha=0.01,power=0.88,M=1,z=2)
# if you type:
result
# then you will get the following output:
# $Required_N
# [1] 25

# $cv
# [1] 4.59581

# $Type_I_Error
# [1] 0.009755004

# $Actual_power
# [1] 0.8855869

</code></pre>

<hr>
<h2 id='SampleSize.CondPoisson'>Sample size calculation for the continuous sequential CMaxSPRT for Poisson data with limited information from historical cohort.</h2><span id='topic+SampleSize.CondPoisson'></span>

<h3>Description</h3>

<p>The function <code>SampleSize.CondPoisson</code> obtains the required sample size (length of surveillance) needed
to guarantee a desired statistical power for a pre-specified relative risk, when doing continuous sequential CMaxSPRT, using a Wald-type upper boundary,
which is flat with respect to the likelihood ratio function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>SampleSize.CondPoisson(cc,D=0,M=1,alpha=0.05,power=0.9,RR=2,Tailed="upper")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SampleSize.CondPoisson_+3A_cc">cc</code></td>
<td>
<p>The total number of observed adverse events in the historical data. There is no default.</p>
</td></tr>
<tr><td><code id="SampleSize.CondPoisson_+3A_d">D</code></td>
<td>
<p>The minium number for the ratio <code class="reqn">P_k/V</code> before the null hypothesis can be rejected. The default value is <code class="reqn">D=0</code>. A delayed start with <code class="reqn">D&gt;0</code> is recommended to avoid signaling very early on such that very little information would be available to judge whether the signal is more likely to be a true signal or chance finding.</p>
</td></tr>
<tr><td><code id="SampleSize.CondPoisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. The default value is M=1. A delayed start with <code class="reqn">M&gt;1</code> is recommended to avoid signaling very early on such that very little information would be available to judge whether the signal is more likely to be a true signal or chance finding.</p>
</td></tr>
<tr><td><code id="SampleSize.CondPoisson_+3A_alpha">alpha</code></td>
<td>
<p>The significance level. It must be in the range (0,0.5]. The default value is alpha=0.05.</p>
</td></tr>
<tr><td><code id="SampleSize.CondPoisson_+3A_power">power</code></td>
<td>
<p>The target vector of overall statistical powers to detect an increased relative risk (RR). The default value is power=0.90.</p>
</td></tr>
<tr><td><code id="SampleSize.CondPoisson_+3A_rr">RR</code></td>
<td>
<p>The target vector of relative risks to be detected with the requested vector of statistical powers. The default value is RR=2.</p>
</td></tr>
<tr><td><code id="SampleSize.CondPoisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When using the CMaxSPRT (Li and Kulldorff, 2010) and the <code>CV.CondPoisson</code> function to conduct continuous sequential analysis
for Poisson data and limited historical data, the null hypothesis is rejected when the log likelihood ratio
exceeds the predetermined critical value calculated by <code>CV.CondPoisson</code>. The sequential analysis ends
without rejecting the null hypothesis when a predetermined upper limit on the sample size is reached, expressed 
either in terms of the ratio of the cumulative person-time in the surveillance population divided by the total
cumulative person-time in historical data (StopType=&quot;Tal&quot;), or in terms of the observed number of events in the
surveillance population (StopType=&quot;Cases&quot;). For example, the sequential analysis may end as soon as the sample size
is such that the cumulative person-time in the surveillance population is twice the cumulative person-time in historical data,
or there are 50 observed events in the surveillance population. The function <code>SampleSize.CondPoisson</code> calculates what
the upper limit on the sample size (length of surveillance) that is required for the continuous CMaxSPRT to achieve the desired
statistical power for a pre-specified relative risk RR. It outputs the upper limit on sample size for both definitions of the
surveillance length, one expressed in terms of the ratio of the cumulative person-time in the surveillance population divided by
the total cumulative person-time in historical data (<code class="reqn">T</code>), and the other one expressed in terms of the observed number of
events in the surveillance population (<code class="reqn">K</code>). To save computing time, the liberal computation approach proposed by Silva et al. (2016)
is used in <code>SampleSize.CondPoisson</code> to find the solution.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>SampleSize_by_RR_Power</code></td>
<td>
<p>A table containing the main performance measures associated to the required samples sizes, expressed in the scale of the number of events in the surveillance period, for each combination of RR and power.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the <code>SampleSize.CondPoisson</code> function was funded by:<br />
- National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0.1, v2.0.2).
- Foundation for Research Support of Minas Gerais State (FAPEMIG), MG, Brazil, through the grant Demanda Universal.
</p>


<h3>See also</h3>

<p><code><a href="#topic+CV.CondPoisson">CV.CondPoisson</a></code>: calculating the critical value for continuous CMaxSPRT.<br />
<code><a href="#topic+Performance.CondPoisson">Performance.CondPoisson</a></code>: calculating the statistical power, expected time to signal and expected time of analysis for continuous CMaxSPRT.<br />
</p>


<h3>Author(s)</h3>

<p>Ivair Ramos Silva, Lingling Li</p>


<h3>References</h3>

<p>Li L, Kulldorff M. (2010). A conditional maximized sequential probability ratio test for Pharmacovigilance. Statistics in Medicine, 29 (2), 284&ndash;295. 
</p>
<p>Silva IR, Li L, Kulldorff M. (2019). Exact Conditional Sequential Testing for Poisson Data. Sequential Analysis, in press.
</p>
<p>Silva IR., Lopes LM., Dias P., Yih WK. (2019). Alpha Spending for Historical Versus Surveillance Poisson Data With CMaxSPRT. Statistics in Medicine, DOI: 10.1002/sim.8097, 1&ndash;13. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Sample size required to obtain a power of 90%, for a relative risk of 1.5,
# no delay for starting the surveilla# nce (D=0), under an alpha level of 5%,
# with 5 events in the historical data.

# res&lt;- SampleSize.CondPoisson(cc=50,D=0,M=1,alpha=0.05,power=0.9,RR=2)

# If we write:
# res
# then we get:

# $K
# [1] 66

# $Tal
# [1] 0.7890625

# $cv
# [1] 3.626436

</code></pre>

<hr>
<h2 id='SampleSize.Poisson'>Sample size calculation for continuous sequential analysis with Poisson data.</h2><span id='topic+SampleSize.Poisson'></span>

<h3>Description</h3>

<p>The function <code>SampleSize.Poisson</code> obtains the required sample size (length of surveillance) needed to guarantee a desired statistical
power for a pre-specified relative risk, when doing continuous sequential analysis for Poisson data with a flat upper boundary in the scale of the Wald
type MaxSPRT (log-likelihood ratio scale), Pocock, OBrien-Fleming, or Wang-Tsiatis scales. Alternatively, <code>SampleSize.Poisson</code> calculates sample
sizes for non-flat signaling thresholds for user-defined alpha spending functions. It can also be used to approximate the sample size needed when doing
group sequential analysis for Poisson data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SampleSize.Poisson(alpha=0.05,power=0.9,M=1,D=0,RR=2,
precision=0.001,alphaSpend="n",rho="n",gamma="n",
Statistic=c("MaxSPRT", "Pocock", "OBrien-Fleming", "Wang-Tsiatis"),
Delta="n",Tailed="upper")
      </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SampleSize.Poisson_+3A_alpha">alpha</code></td>
<td>
<p>The significance level. The default value is alpha=0.05. Must be in the range (0,0.5].</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_power">power</code></td>
<td>
<p>The target vector of overall statistical powers to detect an increased relative risk (RR). The default value is power=0.90.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_m">M</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected. It must be a positive integer.
A good rule of thumb is to set M=4 (Kulldorff and Silva, 2015). The default value is M=1, which means that even a single event
can reject the null hypothesis if it occurs sufficiently early.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_d">D</code></td>
<td>
<p>The expected number of events under the null hypothesis at the first look at the data.
This is used when there is an initial large chunk of data arriving, followed by continuous sequential analysis. The default value is D=0, which is
also the best choice. This means that there is no delay in the start of the sequential analyses. If D is very large, the maximum 
sample size will be set equal to D if a non-sequential analysis provides the desired power.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_rr">RR</code></td>
<td>
<p>The target vector of relative risks to be detected with the requested statistical vector of powers. The default value is RR=2.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_precision">precision</code></td>
<td>
<p>The tolerance for the difference between the requested and actual statistical power. Should be very small. The default value is precision=0.001.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_alphaspend">alphaSpend</code></td>
<td>
<p>An integer between 1 to 4. Default is &quot;n&quot;. See Details.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_rho">rho</code></td>
<td>
<p>Positive number used for the power-type alpha spending function (<code>AlphaSpend=1</code>) only. The default value is &quot;rho=0.5&quot;. See Details.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_gamma">gamma</code></td>
<td>
<p>Positive number used for the gamma-type alpha spending function (<code>AlphaSpend=4</code>) only. There is no default value. See Details.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_statistic">Statistic</code></td>
<td>
<p>The test statistic scale to deliver the signaling threshold. See Details.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_delta">Delta</code></td>
<td>
<p>Parameter needed for calculation of Wang-Tsiatis test statistic if this is the option selected in &quot;Statistic&quot;. Must be a number in the (0, 0.5] interval. There is no default value.</p>
</td></tr>
<tr><td><code id="SampleSize.Poisson_+3A_tailed">Tailed</code></td>
<td>
<p>Tailed=&quot;upper&quot; (default) for H0:RR&lt;=1, and Tailed=&quot;lower&quot; for H0:RR&gt;=1 or Tailed=&quot;two&quot; for H0:RR=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When using the MaxSPRT and the <code>CV.Poisson</code> function to conduct continuous sequential analysis for Poisson data, the null
hypothesis is rejected when the log likelihood ratio exceeds the pre-determined critical value calculated by <code>CV.Poisson</code>.
The sequential analysis ends without rejecting the null hypothesis when a predetermined upper limit on the sample size is
reached, expressed in terms of the expected number of events under the null hypothesis. For example, the sequential analysis
may end as soon as the sample size is such that there are 50 expected events under the null.
</p>
<p>The default in the function <code>SampleSize.Poisson</code> is for calculating the upper limit on the sample size (length of surveillance) required
for the continuous Poisson based MaxSPRT (alphaSpend=&quot;n&quot;) to achieve the desired statistical power for a pre-specified relative risk RR.
The solution is exact using iterative numerical calculations (Kulldorff et al., (2011).
</p>
<p>While designed for continuous sequential analysis with flat threshold in the scale of the MaxSPRT statistic, the <code>SampleSize.Poisson</code> function can also be used to approximate the
required upper limit on the sample size that is needed when doing group sequential analysis for Poisson data, using the <code>CV.G.Poisson function</code>.
</p>
<p>There is also the possibility to calculate the sample size for an user-defined alpha spending plan. This is possible with the input parameter <code>alphaSpend</code>.
The user can select among one of the four classical alpha spending shapes bellow:<br />
<code class="reqn">F_{1}(t)=\alpha t^{\rho}</code>, where <code class="reqn">\rho&gt;0</code>,<br /> 
<code class="reqn">F_{2}(t)=2-2\Phi(x_{\alpha}\sqrt{t^{-1}})</code>, where <code class="reqn">x_{\alpha}=\Phi^{-1}(1-\alpha/2)</code>,<br /> 
<code class="reqn">F_{3}(t)= \alpha \times log(1+[exp{1}-1]\times t) </code>,<br />
<code class="reqn">F_{4}(t)=\alpha[1-exp(-t\gamma)]/[1-exp(-\gamma)]</code> with <code class="reqn">\gamma \in \Re</code>,<br />
and <code class="reqn">t</code> represents a fraction of the maximum length of surveillance. 
</p>
<p>To select one of the four alpha spending types above, and using an integer <code class="reqn">i</code> to indicate the type among
<code class="reqn">i=</code> 1, 2, 3, and 4, for <code class="reqn">F_{1}(t)</code>, <code class="reqn">F_{2}(t)</code>, <code class="reqn">F_{3}(t)</code> and <code class="reqn">F_{4}(t)</code>, respectively,
one needs to set <code>alphaSpend=i</code>. Specifically for <code>alphaSpend=1</code>, it is necessary to choose a <code>rho</code> value,
or a <code>gamma</code> value if <code>alphaSpend=4</code> is used.
</p>
<p>For more details on these alpha spending choices,
see the paper by Silva et al. (2021), Section 2.7.
</p>
<p>When one sets <code>alphaSpend=i</code>, the threshold impplied by the correspondent alpha spending is calculated.
The function delivers the threshold in the scale of a test statistic selected by the user with the input
<code>Statistic</code> among the classic methods:
MaxSPRT (Kulldorf et al., 2011), Pocock (Pocock, 1977), OBrien-Fleming (O'Brien and Fleming, 1979), or Wang-Tsiatis (Jennison and Turnbull, 2000). 
For <code>Statistic="Wang-Tsiatis"</code>, the user has to choose a number in the (0, 0.5] interval for <code>Delta</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>SampleSize_by_RR_Power</code></td>
<td>
<p>A table containing the main performance measures associated to the required samples sizes, expressed in terms of the expected number of events under the null hypothesis, for each combination of RR and power.</p>
</td></tr>
</table>


<h3>Acknowledgements</h3>

<p>Development of the <code>SampleSize.Poisson</code> function was funded by:<br />
-	National Council of Scientific and Technological Development (CNPq), Brazil (v1.0).<br />
-	Bank for Development of the Minas Gerais State (BDMG), Brazil (v1.0).<br />
-     National Institute of General Medical Sciences, NIH, USA, through grant number R01GM108999 (v2.0.1,2.0.2). 
</p>


<h3>See also</h3>

 
<p><code><a href="#topic+CV.Poisson">CV.Poisson</a></code>: for calculating critical values for continuous sequential analysis with Poisson data.<br />
<code><a href="#topic+Performance.Poisson">Performance.Poisson</a></code>: for calculating the statistical power, expected time to signal and expected sample size for continuous sequential analysis with Poisson data<br />
<code><a href="#topic+SampleSize.Binomial">SampleSize.Binomial</a></code>: for calculating the minimum sample size given a target power in continuous sequential analysis with binomial data. 
</p>


<h3>Author(s)</h3>

<p> Ivair Ramos Silva, Martin Kulldorff.</p>


<h3>References</h3>

<p>Kulldorff M, Davis RL, Kolczak M, Lewis E, Lieu T, Platt R. (2011). A Maximized Sequential Probability Ratio Test for Drug and Safety Surveillance. Sequential Analysis, 30: 58&ndash;78.
Kulldorff M, Silva IR. (2015). Continuous Post-market Sequential Safety Surveillance with Minimum Events to Signal. REVSTAT Statistical Journal, 15(3): 373&ndash;394.
Silva IR, Maro J, Kulldorff M. (2021). Exact sequential test for clinical trials and post-market drug and vaccine safety surveillance with Poisson and binary data. Statistics in Medicine, DOI: 10.1002/sim.9094.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example 1:   
##  Sample size required to obtain a power of 80%, for a relati-
##  ve risk of 3, no delay for starting the surveillance (D=0),
##  and when the null hypothesis can be rejected with one event
##  (M=1) under an alpha level of 5%.

# result1&lt;- SampleSize.Poisson(alpha=0.05,power=0.8,M=1,D=0,RR=3)
# result1


## Example 2:
##  Sample size required to obtain a power of 90%, for a relati-
##  ve risk of 2, no delay for starting the surveillance (D=0),
##  and when the null hypothesis can be rejected only after 2
##  events (M=2) under an alpha level of 10%.
##
# result2&lt;- SampleSize.Poisson(alpha=0.1,power=0.9,M=2,D=0,RR=2)
# result2

## Example 3:
##  Sample size calculated for the non-flat threshold using the
##  power-type alpha spending (alphaSpend=1), with rho=1,
##  to obtain a power of 80% for a relative risk of 2.5, delay to
##  start the surveillance equal to 1 (D=1), and the null hypo-
##  thesis can be rejected with 3 events (M=3) under an alpha
##  level of 5%. The critical values will be shown in the scale
##  of the MaxSPRT statistic.

# result3&lt;- SampleSize.Poisson(alpha=0.05,power=0.8,M=3,D=1,RR=2.5,
# alphaSpend=1,rho=1,Statistic="MaxSPRT")
# result3

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
