<!DOCTYPE html><html><head><title>Help for package searchConsoleR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {searchConsoleR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add_sitemap'><p>Submit a sitemap.</p></a></li>
<li><a href='#add_website'><p>Adds website to Search Console</p></a></li>
<li><a href='#check.Url'><p>Checks Urls are in right format for API request</p></a></li>
<li><a href='#crawl_errors'><p>Fetch a time-series of Googlebot crawl errors.</p></a></li>
<li><a href='#delete_sitemap'><p>Delete a sitemap.</p></a></li>
<li><a href='#delete_website'><p>Deletes website in Search Console</p></a></li>
<li><a href='#error_sample_url'><p>Shows details of errors for individual sample URLs</p></a></li>
<li><a href='#fix_sample_url'><p>Mark As Fixed the individual sample URLs</p></a></li>
<li><a href='#is.error'><p>Is this a try error?</p></a></li>
<li><a href='#is.valid.category.platform'><p>Checks valid parameters for Google Search Console</p></a></li>
<li><a href='#list_crawl_error_samples'><p>Lists a site's sample URLs for crawl errors.</p></a></li>
<li><a href='#list_sitemaps'><p>Gets sitemap information for the URL supplied.</p></a></li>
<li><a href='#list_websites'><p>Retrieves dataframe of websites user has in Search Console</p></a></li>
<li><a href='#lookupCountryCode'><p>Look up the country codes</p></a></li>
<li><a href='#parse_crawlerror_sample'><p>Parsing function for <code>list_crawl_error_samples</code></p></a></li>
<li><a href='#parse_crawlerrors'><p>Parsing function for <code>crawl_errors</code></p></a></li>
<li><a href='#parse_errorsample_url'><p>Parsing function for <code>error_sample_url</code></p></a></li>
<li><a href='#parse_search_analytics'><p>Parsing function for <code>search_analytics</code></p></a></li>
<li><a href='#parse_sitemaps'><p>Parsing function for <code>list_sitemaps</code></p></a></li>
<li><a href='#parseDimFilterGroup'><p>Helper function for the query dimension filters</p></a></li>
<li><a href='#RFC_convert'><p>Converts RFC3339 to as.Date</p></a></li>
<li><a href='#scr_auth'><p>Do OAuth2 authentication</p></a></li>
<li><a href='#search_analytics'><p>Query search traffic keyword data</p></a></li>
<li><a href='#searchConsoleR'><p>searchConsoleR</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Google Search Console R Client</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides an interface with the Google Search Console,
    formally called Google Webmaster Tools.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://code.markedmondson.me/searchConsoleR/">http://code.markedmondson.me/searchConsoleR/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/MarkEdmondson1234/searchConsoleR/issues">https://github.com/MarkEdmondson1234/searchConsoleR/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>googleAuthR (&ge; 1.0.0), stringr (&ge; 1.0.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>shiny (&ge; 0.12.1), knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-09-05 20:32:55 UTC; mark</td>
</tr>
<tr>
<td>Author:</td>
<td>Mark Edmondson [aut, cre],
  Jennifer Bryan [ctb],
  Parzakonis Manos [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mark Edmondson &lt;r@sunholo.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-09-06 10:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='add_sitemap'>Submit a sitemap.</h2><span id='topic+add_sitemap'></span>

<h3>Description</h3>

<p>See here for details: https://developers.google.com/webmaster-tools/v3/sitemaps/submit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_sitemap(siteURL, feedpath)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_sitemap_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website to delete. Must include protocol (http://).</p>
</td></tr>
<tr><td><code id="add_sitemap_+3A_feedpath">feedpath</code></td>
<td>
<p>The URL of the sitemap to submit. Must include protocol (http://).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if successful, raises an error if not.
</p>


<h3>See Also</h3>

<p>Other sitemap admin functions: <code><a href="#topic+delete_sitemap">delete_sitemap</a></code>,
<code><a href="#topic+list_sitemaps">list_sitemaps</a></code>
</p>

<hr>
<h2 id='add_website'>Adds website to Search Console</h2><span id='topic+add_website'></span>

<h3>Description</h3>

<p>Adds website to Search Console
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_website(siteURL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_website_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website to add.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if successful, raises an error if not.
</p>


<h3>See Also</h3>

<p>Other search console website functions: <code><a href="#topic+delete_website">delete_website</a></code>,
<code><a href="#topic+list_websites">list_websites</a></code>
</p>

<hr>
<h2 id='check.Url'>Checks Urls are in right format for API request</h2><span id='topic+check.Url'></span>

<h3>Description</h3>

<p>Checks Urls are in right format for API request
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.Url(url, checkProtocol = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.Url_+3A_url">url</code></td>
<td>
<p>The URL to check for use in API request</p>
</td></tr>
<tr><td><code id="check.Url_+3A_checkprotocol">checkProtocol</code></td>
<td>
<p>Check if URL starts with 'http'</p>
</td></tr>
<tr><td><code id="check.Url_+3A_...">...</code></td>
<td>
<p>Passed to URLencode()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified url if successful, raises an error if not.
</p>

<hr>
<h2 id='crawl_errors'>Fetch a time-series of Googlebot crawl errors.</h2><span id='topic+crawl_errors'></span>

<h3>Description</h3>

<p>Get a list of errors detected by Googlebot over time.
See here for details: https://developers.google.com/webmaster-tools/v3/urlcrawlerrorscounts/query
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crawl_errors(siteURL, category = "all", platform = c("all", "mobile",
  "smartphoneOnly", "web"), latestCountsOnly = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crawl_errors_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website to delete. Must include protocol (http://).</p>
</td></tr>
<tr><td><code id="crawl_errors_+3A_category">category</code></td>
<td>
<p>Crawl error category. Defaults to 'all'</p>
</td></tr>
<tr><td><code id="crawl_errors_+3A_platform">platform</code></td>
<td>
<p>The user agent type. 'all', 'mobile', 'smartphoneOnly' or 'web'.</p>
</td></tr>
<tr><td><code id="crawl_errors_+3A_latestcountsonly">latestCountsOnly</code></td>
<td>
<p>Default FALSE. Only the latest crawl error counts returned if TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The timestamp is converted to a date as they are only available daily.
</p>
<p>Category is one of: authPermissions, manyToOneRedirect, notFollowed, notFound,
other, roboted, serverError, soft404.
</p>
<p>Platform is one of: mobile, smartphoneOnly or web.
</p>


<h3>Value</h3>

<p>dataframe of errors with $platform $category $count and $timecount.
</p>


<h3>See Also</h3>

<p>Other working with search console errors: <code><a href="#topic+error_sample_url">error_sample_url</a></code>,
<code><a href="#topic+fix_sample_url">fix_sample_url</a></code>,
<code><a href="#topic+list_crawl_error_samples">list_crawl_error_samples</a></code>
</p>

<hr>
<h2 id='delete_sitemap'>Delete a sitemap.</h2><span id='topic+delete_sitemap'></span>

<h3>Description</h3>

<p>See here for details: https://developers.google.com/webmaster-tools/v3/sitemaps/delete
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delete_sitemap(siteURL, feedpath)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delete_sitemap_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website you are deleting the sitemap from. Must include protocol (http://).</p>
</td></tr>
<tr><td><code id="delete_sitemap_+3A_feedpath">feedpath</code></td>
<td>
<p>The URL of the sitemap to delete. Must include protocol (http://).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if successful, raises an error if not.
</p>


<h3>See Also</h3>

<p>Other sitemap admin functions: <code><a href="#topic+add_sitemap">add_sitemap</a></code>,
<code><a href="#topic+list_sitemaps">list_sitemaps</a></code>
</p>

<hr>
<h2 id='delete_website'>Deletes website in Search Console</h2><span id='topic+delete_website'></span>

<h3>Description</h3>

<p>Deletes website in Search Console
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delete_website(siteURL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delete_website_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website to delete.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if successful, raises an error if not.
</p>


<h3>See Also</h3>

<p>Other data fetching functions: <code><a href="#topic+list_sitemaps">list_sitemaps</a></code>
</p>
<p>Other search console website functions: <code><a href="#topic+add_website">add_website</a></code>,
<code><a href="#topic+list_websites">list_websites</a></code>
</p>

<hr>
<h2 id='error_sample_url'>Shows details of errors for individual sample URLs</h2><span id='topic+error_sample_url'></span>

<h3>Description</h3>

<p>pageURL is the relative path (without the site) of the sample URL.
It must be one of the URLs returned by list_crawl_error_samples.
For example, for the URL https://www.example.com/pagename on the site https://www.example.com/,
the url value is pagename (string)
</p>
<p>Category is one of: authPermissions, manyToOneRedirect, notFollowed, notFound,
other, roboted, serverError, soft404.
</p>
<p>Platform is one of: mobile, smartphoneOnly or web.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>error_sample_url(siteURL, pageURL, category = "notFound",
  platform = "web")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="error_sample_url_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website to delete. Must include protocol (http://).</p>
</td></tr>
<tr><td><code id="error_sample_url_+3A_pageurl">pageURL</code></td>
<td>
<p>A PageUrl taken from list_crawl_error_samples.</p>
</td></tr>
<tr><td><code id="error_sample_url_+3A_category">category</code></td>
<td>
<p>Crawl error category. Default 'notFound'.</p>
</td></tr>
<tr><td><code id="error_sample_url_+3A_platform">platform</code></td>
<td>
<p>User agent type. Default 'web'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See here for details: https://developers.google.com/webmaster-tools/v3/urlcrawlerrorssamples/get
</p>


<h3>Value</h3>

<p>Dataframe of $linkedFrom, with the calling URLs $last_crawled, $first_detected and a $exampleURL
</p>


<h3>See Also</h3>

<p>Other working with search console errors: <code><a href="#topic+crawl_errors">crawl_errors</a></code>,
<code><a href="#topic+fix_sample_url">fix_sample_url</a></code>,
<code><a href="#topic+list_crawl_error_samples">list_crawl_error_samples</a></code>
</p>

<hr>
<h2 id='fix_sample_url'>Mark As Fixed the individual sample URLs</h2><span id='topic+fix_sample_url'></span>

<h3>Description</h3>

<p>pageURL is the relative path (without the site) of the sample URL.
It must be one of the URLs returned by list_crawl_error_samples.
For example, for the URL https://www.example.com/pagename on the site https://www.example.com/,
the url value is pagename (string)
</p>
<p>Category is one of: authPermissions, manyToOneRedirect, notFollowed, notFound,
other, roboted, serverError, soft404.
</p>
<p>Platform is one of: mobile, smartphoneOnly or web.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fix_sample_url(siteURL, pageURL, category = "notFound",
  platform = "web")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fix_sample_url_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website to delete. Must include protocol (http://).</p>
</td></tr>
<tr><td><code id="fix_sample_url_+3A_pageurl">pageURL</code></td>
<td>
<p>A PageUrl taken from list_crawl_error_samples.</p>
</td></tr>
<tr><td><code id="fix_sample_url_+3A_category">category</code></td>
<td>
<p>Crawl error category. Default 'notFound'.</p>
</td></tr>
<tr><td><code id="fix_sample_url_+3A_platform">platform</code></td>
<td>
<p>User agent type. Default 'web'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See here for details:
https://developers.google.com/webmaster-tools/v3/urlcrawlerrorssamples/markAsFixed
</p>


<h3>Value</h3>

<p>TRUE if successful, raises an error if not.
</p>


<h3>See Also</h3>

<p>Other working with search console errors: <code><a href="#topic+crawl_errors">crawl_errors</a></code>,
<code><a href="#topic+error_sample_url">error_sample_url</a></code>,
<code><a href="#topic+list_crawl_error_samples">list_crawl_error_samples</a></code>
</p>

<hr>
<h2 id='is.error'>Is this a try error?</h2><span id='topic+is.error'></span>

<h3>Description</h3>

<p>Utility to test errors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.error(test_me)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.error_+3A_test_me">test_me</code></td>
<td>
<p>an object created with try()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Boolean
</p>

<hr>
<h2 id='is.valid.category.platform'>Checks valid parameters for Google Search Console</h2><span id='topic+is.valid.category.platform'></span>

<h3>Description</h3>

<p>The error type listings have certain categories/platform allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.valid.category.platform(category, platform, include.all = FALSE)
</code></pre>


<h3>Value</h3>

<p>TRUE if valid, raises an error if not.
</p>

<hr>
<h2 id='list_crawl_error_samples'>Lists a site's sample URLs for crawl errors.</h2><span id='topic+list_crawl_error_samples'></span>

<h3>Description</h3>

<p>Category is one of: authPermissions, manyToOneRedirect, notFollowed, notFound,
other, roboted, serverError, soft404.
</p>
<p>Platform is one of: mobile, smartphoneOnly or web.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_crawl_error_samples(siteURL, category = "notFound",
  platform = "web")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="list_crawl_error_samples_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website to delete. Must include protocol (http://).</p>
</td></tr>
<tr><td><code id="list_crawl_error_samples_+3A_category">category</code></td>
<td>
<p>Crawl error category. Default 'notFound'.</p>
</td></tr>
<tr><td><code id="list_crawl_error_samples_+3A_platform">platform</code></td>
<td>
<p>User agent type. Default 'web'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See here for details: <a href="https://developers.google.com/webmaster-tools/v3/urlcrawlerrorssamples">https://developers.google.com/webmaster-tools/v3/urlcrawlerrorssamples</a>
</p>


<h3>Value</h3>

<p>A dataframe of $pageUrl, $last_crawled, $first_detected, $response
</p>


<h3>See Also</h3>

<p>Other working with search console errors: <code><a href="#topic+crawl_errors">crawl_errors</a></code>,
<code><a href="#topic+error_sample_url">error_sample_url</a></code>,
<code><a href="#topic+fix_sample_url">fix_sample_url</a></code>
</p>

<hr>
<h2 id='list_sitemaps'>Gets sitemap information for the URL supplied.</h2><span id='topic+list_sitemaps'></span>

<h3>Description</h3>

<p>See here for details: https://developers.google.com/webmaster-tools/v3/sitemaps
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_sitemaps(siteURL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="list_sitemaps_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website to get sitemap information from. Must include protocol (http://).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two dataframes: $sitemap with general info and $contents with sitemap info.
</p>


<h3>See Also</h3>

<p>Other data fetching functions: <code><a href="#topic+delete_website">delete_website</a></code>
</p>
<p>Other sitemap admin functions: <code><a href="#topic+add_sitemap">add_sitemap</a></code>,
<code><a href="#topic+delete_sitemap">delete_sitemap</a></code>
</p>

<hr>
<h2 id='list_websites'>Retrieves dataframe of websites user has in Search Console</h2><span id='topic+list_websites'></span>

<h3>Description</h3>

<p>Retrieves dataframe of websites user has in Search Console
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_websites()
</code></pre>


<h3>Value</h3>

<p>a dataframe of siteUrl and permissionLevel
</p>


<h3>See Also</h3>

<p>Other search console website functions: <code><a href="#topic+add_website">add_website</a></code>,
<code><a href="#topic+delete_website">delete_website</a></code>
</p>

<hr>
<h2 id='lookupCountryCode'>Look up the country codes</h2><span id='topic+lookupCountryCode'></span>

<h3>Description</h3>

<p>Look up the country codes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lookupCountryCode(country.code, name_type = "Name")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lookupCountryCode_+3A_name_type">name_type</code></td>
<td>
<p>One of &quot;Name&quot;, &quot;Official_name&quot; or &quot;Common_name&quot;</p>
</td></tr>
<tr><td><code id="lookupCountryCode_+3A_code">code</code></td>
<td>
<p>the ISO 3166-1 alpha-3 country code (as used in searchConsoleR)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The country name string
</p>


<h3>See Also</h3>

<p>Other search analytics: <code><a href="#topic+parseDimFilterGroup">parseDimFilterGroup</a></code>
</p>

<hr>
<h2 id='parse_crawlerror_sample'>Parsing function for <code><a href="#topic+list_crawl_error_samples">list_crawl_error_samples</a></code></h2><span id='topic+parse_crawlerror_sample'></span>

<h3>Description</h3>

<p>Parsing function for <code><a href="#topic+list_crawl_error_samples">list_crawl_error_samples</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_crawlerror_sample(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_crawlerror_sample_+3A_x">x</code></td>
<td>
<p>req$content from API response</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsing functions: <code><a href="#topic+parse_crawlerrors">parse_crawlerrors</a></code>,
<code><a href="#topic+parse_errorsample_url">parse_errorsample_url</a></code>,
<code><a href="#topic+parse_search_analytics">parse_search_analytics</a></code>,
<code><a href="#topic+parse_sitemaps">parse_sitemaps</a></code>
</p>

<hr>
<h2 id='parse_crawlerrors'>Parsing function for <code><a href="#topic+crawl_errors">crawl_errors</a></code></h2><span id='topic+parse_crawlerrors'></span>

<h3>Description</h3>

<p>Parsing function for <code><a href="#topic+crawl_errors">crawl_errors</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_crawlerrors(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_crawlerrors_+3A_x">x</code></td>
<td>
<p>req$content from API response</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsing functions: <code><a href="#topic+parse_crawlerror_sample">parse_crawlerror_sample</a></code>,
<code><a href="#topic+parse_errorsample_url">parse_errorsample_url</a></code>,
<code><a href="#topic+parse_search_analytics">parse_search_analytics</a></code>,
<code><a href="#topic+parse_sitemaps">parse_sitemaps</a></code>
</p>

<hr>
<h2 id='parse_errorsample_url'>Parsing function for <code><a href="#topic+error_sample_url">error_sample_url</a></code></h2><span id='topic+parse_errorsample_url'></span>

<h3>Description</h3>

<p>Parsing function for <code><a href="#topic+error_sample_url">error_sample_url</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_errorsample_url(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_errorsample_url_+3A_x">x</code></td>
<td>
<p>req$content from API response</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsing functions: <code><a href="#topic+parse_crawlerror_sample">parse_crawlerror_sample</a></code>,
<code><a href="#topic+parse_crawlerrors">parse_crawlerrors</a></code>,
<code><a href="#topic+parse_search_analytics">parse_search_analytics</a></code>,
<code><a href="#topic+parse_sitemaps">parse_sitemaps</a></code>
</p>

<hr>
<h2 id='parse_search_analytics'>Parsing function for <code><a href="#topic+search_analytics">search_analytics</a></code></h2><span id='topic+parse_search_analytics'></span>

<h3>Description</h3>

<p>Parsing function for <code><a href="#topic+search_analytics">search_analytics</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_search_analytics(x, dim, prettyNames = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_search_analytics_+3A_x">x</code></td>
<td>
<p>req$content from API response</p>
</td></tr>
<tr><td><code id="parse_search_analytics_+3A_dim">dim</code></td>
<td>
<p>the dimensions passed from search_analytics</p>
</td></tr>
<tr><td><code id="parse_search_analytics_+3A_pn">pn</code></td>
<td>
<p>PrettyNames passed from search_analytics</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsing functions: <code><a href="#topic+parse_crawlerror_sample">parse_crawlerror_sample</a></code>,
<code><a href="#topic+parse_crawlerrors">parse_crawlerrors</a></code>,
<code><a href="#topic+parse_errorsample_url">parse_errorsample_url</a></code>,
<code><a href="#topic+parse_sitemaps">parse_sitemaps</a></code>
</p>

<hr>
<h2 id='parse_sitemaps'>Parsing function for <code><a href="#topic+list_sitemaps">list_sitemaps</a></code></h2><span id='topic+parse_sitemaps'></span>

<h3>Description</h3>

<p>Parsing function for <code><a href="#topic+list_sitemaps">list_sitemaps</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_sitemaps(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_sitemaps_+3A_x">x</code></td>
<td>
<p>req$content from API response</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsing functions: <code><a href="#topic+parse_crawlerror_sample">parse_crawlerror_sample</a></code>,
<code><a href="#topic+parse_crawlerrors">parse_crawlerrors</a></code>,
<code><a href="#topic+parse_errorsample_url">parse_errorsample_url</a></code>,
<code><a href="#topic+parse_search_analytics">parse_search_analytics</a></code>
</p>

<hr>
<h2 id='parseDimFilterGroup'>Helper function for the query dimension filters</h2><span id='topic+parseDimFilterGroup'></span>

<h3>Description</h3>

<p>Saves the need for 3 parameters when you just have one
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parseDimFilterGroup(dfe)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parseDimFilterGroup_+3A_dfe">dfe</code></td>
<td>
<p>A string of form: dimension operator expression e.g. country!~GBR</p>
</td></tr>
</table>


<h3>Details</h3>

<p>dimension = c('country','device','page','query','searchAppearance')
operator = c(&lsquo;~~' = &rsquo;contains',
&lsquo;==' = &rsquo;equals',
&lsquo;!~' = &rsquo;notContains',
&lsquo;!=' = &rsquo;notEquals)
</p>
<p>expression = country: an ISO 3166-1 alpha-3 country code.
device: 'DESKTOP','MOBILE','TABLET'
page: not checked
query: not checked
searchAppearance: 'AMP_BLUE_LINK', 'RICHCARD'
</p>


<h3>See Also</h3>

<p>Other search analytics: <code><a href="#topic+lookupCountryCode">lookupCountryCode</a></code>
</p>

<hr>
<h2 id='RFC_convert'>Converts RFC3339 to as.Date</h2><span id='topic+RFC_convert'></span>

<h3>Description</h3>

<p>Converts RFC3339 to as.Date
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RFC_convert(RFC, drop_time = FALSE)
</code></pre>

<hr>
<h2 id='scr_auth'>Do OAuth2 authentication</h2><span id='topic+scr_auth'></span>

<h3>Description</h3>

<p>Do OAuth2 authentication
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scr_auth(token = NULL, email = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scr_auth_+3A_token">token</code></td>
<td>
<p>Where you want to save the auth file, or an existing token or file location of a token to authenticate with</p>
</td></tr>
<tr><td><code id="scr_auth_+3A_email">email</code></td>
<td>
<p>An email you have authenticated with previously</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Run this function first time to authenticate with Google in your browser.  
</p>
<p>After initial authentication, a <code>sc.oauth</code> will be saved to your working directory, where your authentication details are kept.  Keep this file safe.
</p>
<p>If you want to reauthenticate, delete this file from your directory or run <code>scr_auth(new_user = TRUE)</code>
</p>


<h3>Multiple accounts</h3>

<p>You can authenticate with a new auth file for each account. Supply argument <code>token</code> with the name of the cache file you want to use e.g. <code>scr_auth(token = "one.httr-oauth")</code> for one account, 
<code>scr_auth(token = "another.httr-oauth")</code> for a different account.
</p>


<h3>Auto-authentication</h3>

<p>You can choose to auto-authenticate by moving your <code>sc.httr-oauth</code> or by 
creating a Google OAuth service account JSON file.
</p>
<p>Specify an environment variable in R via a <code>.Renviron</code> file or using <a href="base.html#topic+Sys.setenv">Sys.setenv</a> which point to the file location of your chosen authentication file.  See <a href="base.html#topic+Startup">Startup</a>
</p>
<p>Once you have set the environment variable <code>SC_AUTH_FILE</code> to a valid file location,
the function will look there for authentication details upon loading the library meaning 
you will not need to call <code>scr_auth()</code> yourself as you would normally.
</p>
<p>An example <code>.Renviron</code> file is below:
</p>
<p><code>SC_AUTH_FILE = "/Users/bob/auth/sc.oauth"</code>
</p>
<p><code>SC_AUTH_FILE</code> can be either a auth file for a token generated by <a href="googleAuthR.html#topic+gar_auth">gar_auth</a> or
service account JSON ending with file extension <code>.json</code>
</p>


<h3>Your own Google Project</h3>

<p>Be default the Google Project used is shared by all users, this is usually sufficient, but  
you could choose to create your own Google Project and turn on the Webmaster APIs.
</p>
<p>You can then download your own client JSON, and set by placing in the <code>GAR_CLIENT_JSON</code> environment argument.  See <a href="googleAuthR.html#topic+gar_set_client">gar_set_client</a> for details.
</p>


<h3>Service accounts</h3>

<p>If you use the service account JSON, you will need to add the service account email 
to your Search Console users to see data e.g. <code>xxxx@yyyyyy.iam.gserviceaccount.com</code>
</p>


<h3>See Also</h3>

<p><code><a href="googleAuthR.html#topic+gar_auth">gar_auth</a></code>
</p>

<hr>
<h2 id='search_analytics'>Query search traffic keyword data</h2><span id='topic+search_analytics'></span>

<h3>Description</h3>

<p>Download your Google SEO data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search_analytics(siteURL, startDate = Sys.Date() - 93,
  endDate = Sys.Date() - 3, dimensions = NULL, searchType = c("web",
  "video", "image"), dimensionFilterExp = NULL,
  aggregationType = c("auto", "byPage", "byProperty"), rowLimit = 1000,
  prettyNames = TRUE, walk_data = c("byBatch", "byDate", "none"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="search_analytics_+3A_siteurl">siteURL</code></td>
<td>
<p>The URL of the website you have auth access to.</p>
</td></tr>
<tr><td><code id="search_analytics_+3A_startdate">startDate</code></td>
<td>
<p>Start date of requested range, in YYYY-MM-DD.</p>
</td></tr>
<tr><td><code id="search_analytics_+3A_enddate">endDate</code></td>
<td>
<p>End date of the requested date range, in YYYY-MM-DD.</p>
</td></tr>
<tr><td><code id="search_analytics_+3A_dimensions">dimensions</code></td>
<td>
<p>Zero or more dimensions to group results by:
<code>"date", "country", "device", "page" , "query" or "searchAppearance"</code></p>
</td></tr>
<tr><td><code id="search_analytics_+3A_searchtype">searchType</code></td>
<td>
<p>Search type filter, default 'web'.</p>
</td></tr>
<tr><td><code id="search_analytics_+3A_dimensionfilterexp">dimensionFilterExp</code></td>
<td>
<p>A character vector of expressions to filter.
e.g. <code>("device==TABLET", "country~~GBR")</code></p>
</td></tr>
<tr><td><code id="search_analytics_+3A_aggregationtype">aggregationType</code></td>
<td>
<p>How data is aggregated.</p>
</td></tr>
<tr><td><code id="search_analytics_+3A_rowlimit">rowLimit</code></td>
<td>
<p>How many rows to fetch.  Ignored if <code>walk_data</code> is &quot;byDate&quot;</p>
</td></tr>
<tr><td><code id="search_analytics_+3A_prettynames">prettyNames</code></td>
<td>
<p>If TRUE, converts SO 3166-1 alpha-3 country code to full name and
creates new column called countryName.</p>
</td></tr>
<tr><td><code id="search_analytics_+3A_walk_data">walk_data</code></td>
<td>
<p>Make multiple API calls. One of <code>("byBatch","byDate","none")</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>startDate</strong>: Start date of the requested date range, in YYYY-MM-DD format,
in PST time (UTC - 8:00). Must be less than or equal to the end date.
This value is included in the range.
</p>
<p><strong>endDate</strong>: End date of the requested date range, in YYYY-MM-DD format,
in PST time (UTC - 8:00). Must be greater than or equal to the start date.
This value is included in the range.
</p>
<p><strong>dimensions</strong>: [Optional] Zero or more dimensions to group results by.
</p>

<ul>
<li><p> 'date'
</p>
</li>
<li><p> 'country'
</p>
</li>
<li><p> 'device'
</p>
</li>
<li><p> 'page'
</p>
</li>
<li><p> 'query'
</p>
</li>
<li><p> 'searchAppearance' (can only appear on its own)
</p>
</li></ul>

<p>The grouping dimension values are combined to create a unique key
for each result row. If no dimensions are specified,
all values will be combined into a single row.
There is no limit to the number of dimensions that you can group by apart from <code>searchAppearance</code> can only be grouped alone.
You cannot group by the same dimension twice. 
</p>
<p>Example: <code>c('country', 'device')</code>
</p>
<p><strong>dimensionFilterExp</strong>:
Results are grouped in the order that you supply these dimensions.
dimensionFilterExp expects a character vector of expressions in the form:
(&quot;device==TABLET&quot;, &quot;country~~GBR&quot;, &quot;dimension operator expression&quot;)
</p>

<ul>
<li><p> dimension
</p>

<ul>
<li><p> 'country'
</p>
</li>
<li><p> 'device'
</p>
</li>
<li><p> 'page'
</p>
</li>
<li><p> 'query'
</p>
</li>
<li><p> 'searchAppearance'
</p>
</li></ul>

</li>
<li><p> operator
</p>

<ul>
<li><p> '~~' meaning 'contains'
</p>
</li>
<li><p> '==' meaning 'equals'
</p>
</li>
<li><p> '!~' meaning 'notContains'
</p>
</li>
<li><p> '!=' meaning 'notEquals
</p>
</li></ul>

</li>
<li><p> expression
</p>

<ul>
<li><p> country: an ISO 3166-1 alpha-3 country code.
</p>
</li>
<li><p> device: 'DESKTOP','MOBILE','TABLET'.
</p>
</li>
<li><p> page: not checked, a string in page URLs without hostname.
</p>
</li>
<li><p> query: not checked, a string in keywords.
</p>
</li>
<li><p> searchAppearance: 'AMP_BLUE_LINK', 'RICHCARD'
</p>
</li></ul>

</li></ul>

<p><strong>searchType</strong>: [Optional] The search type to filter for. Acceptable values are:
</p>

<ul>
<li><p> &quot;web&quot;: [Default] Web search results
</p>
</li>
<li><p> &quot;image&quot;: Image search results
</p>
</li>
<li><p> &quot;video&quot;: Video search results
</p>
</li></ul>

<p><strong>aggregationType</strong>: [Optional] How data is aggregated.
</p>

<ul>
<li><p> If aggregated by property, all data for the same property is aggregated;
</p>
</li>
<li><p> If aggregated by page, all data is aggregated by canonical URI.
</p>
</li>
<li><p> If you filter or group by page, choose auto; otherwise you can aggregate either by property or by page, depending on how you want your data calculated;
</p>
</li></ul>

<p>See the API documentation to learn how data is calculated differently by site versus by page.
Note: If you group or filter by page, you cannot aggregate by property.
If you specify any value other than auto, the aggregation type in the result will match the requested type, or if you request an invalid type, you will get an error.
The API will never change your aggregation type if the requested type is invalid.
Acceptable values are:
</p>

<ul>
<li><p> &quot;auto&quot;: [Default] Let the service decide the appropriate aggregation type.
</p>
</li>
<li><p> &quot;byPage&quot;: Aggregate values by URI.
</p>
</li>
<li><p> &quot;byProperty&quot;: Aggregate values by property.
</p>
</li></ul>

<p><strong>batchType</strong>: [Optional] Batching data into multiple API calls
</p>

<ul>
<li><p> byBatch Use the API call to batch
</p>
</li>
<li><p> byData Runs a call over each day in the date range.
</p>
</li>
<li><p> none No batching
</p>
</li></ul>



<h3>Value</h3>

<p>A dataframe with columns in order of dimensions plus metrics, with attribute &quot;aggregationType&quot;
</p>


<h3>See Also</h3>

<p>Guide to Search Analytics: <a href="https://support.google.com/webmasters/answer/6155685">https://support.google.com/webmasters/answer/6155685</a>
API docs: <a href="https://developers.google.com/webmaster-tools/v3/searchanalytics/query">https://developers.google.com/webmaster-tools/v3/searchanalytics/query</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

   library(searchConsoleR)
   scr_auth()
   sc_websites &lt;- list_websites()
   
   default_fetch &lt;- search_analytics("http://www.example.com")

   gbr_desktop_queries &lt;-
       search_analytics("http://www.example.com",
                         start = "2016-01-01", end = "2016-03-01",
                         dimensions = c("query", "page"),
                         dimensionFilterExp = c("device==DESKTOP", "country==GBR"),
                         searchType = "web", rowLimit = 100)

   batching &lt;-
        search_analytics("http://www.example.com",
                         start = "2016-01-01", end = "2016-03-01",
                         dimensions = c("query", "page", "date"),
                         searchType = "web", rowLimit = 100000,
                         walk_data = "byBatch")

  
## End(Not run)
</code></pre>

<hr>
<h2 id='searchConsoleR'>searchConsoleR</h2><span id='topic+searchConsoleR'></span><span id='topic+searchConsoleR-package'></span>

<h3>Description</h3>

<p>Provides an interface with the Google Search Console API v3, 
formally called Google Webmaster Tools. 
</p>
<p>To get started, use <code>googleAuthR::gar_auth()</code> to authenticate.
</p>


<h3>Search analytics</h3>

<p><code><a href="#topic+search_analytics">search_analytics</a></code> - download Google SEO data into an R dataframe.
</p>


<h3>Website admin</h3>

<p><code><a href="#topic+list_websites">list_websites</a></code> - list websites in your Google Search Console.
</p>
<p><code><a href="#topic+add_website">add_website</a></code> - add a website to your Google Search Console.
</p>
<p><code><a href="#topic+delete_website">delete_website</a></code> - delete a website from your Google Search Console.
</p>


<h3>Sitemaps</h3>

<p><code><a href="#topic+list_sitemaps">list_sitemaps</a></code> - list sitemaps recognised in Google Search Console.
</p>
<p><code><a href="#topic+add_sitemap">add_sitemap</a></code> - add sitemap URL location to Google Search Console.
</p>
<p><code><a href="#topic+delete_sitemap">delete_sitemap</a></code> - remove sitemap URL location in Google Search
Console.
</p>


<h3>Error listings</h3>

<p><code><a href="#topic+crawl_errors">crawl_errors</a></code> - list types of crawl errors googlebot has found.
</p>
<p><code><a href="#topic+list_crawl_error_samples">list_crawl_error_samples</a></code> - lists example URLs with errors.
</p>
<p><code><a href="#topic+error_sample_url">error_sample_url</a></code> - details about an example URL error.
</p>
<p><code><a href="#topic+fix_sample_url">fix_sample_url</a></code> - mark a URL as fixed.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
