<!DOCTYPE html><html><head><title>Help for package modi</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {modi}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BEM'><p>BACON-EEM Algorithm for multivariate outlier detection in incomplete</p>
multivariate survey data</a></li>
<li><a href='#bushfire'><p>Bushfire scars.</p></a></li>
<li><a href='#bushfire.weights'><p>Weights for Bushfire scars.</p></a></li>
<li><a href='#bushfirem'><p>Bushfire scars with missing data.</p></a></li>
<li><a href='#EA.dist'><p>Utility function for EAdet and EAimp</p></a></li>
<li><a href='#EAdet'><p>Epidemic Algorithm for detection of multivariate outliers in incomplete survey data</p></a></li>
<li><a href='#EAimp'><p>Epidemic Algorithm for imputation of multivariate outliers in incomplete</p>
survey data.</a></li>
<li><a href='#EM.normal'><p>EM for multivariate normal data</p></a></li>
<li><a href='#ER'><p>Robust EM-algorithm ER</p></a></li>
<li><a href='#ER.normal'><p>Utility for ER function</p></a></li>
<li><a href='#GIMCD'><p>Gaussian imputation followed by MCD</p></a></li>
<li><a href='#ind.dij'><p>Addressing function for Epidemic Algorithm</p></a></li>
<li><a href='#ind.dijs'><p>Addressing function for Epidemic Algorithm</p></a></li>
<li><a href='#lival'><p>Living Standards Measurement Survey Albania 2012</p></a></li>
<li><a href='#MDmiss'><p>Mahalanobis distance (MD) for data with missing values</p></a></li>
<li><a href='#modi'><p>modi: Multivariate outlier detection for incomplete survey data.</p></a></li>
<li><a href='#nz.min'><p>Non-zero non-missing minimum function</p></a></li>
<li><a href='#plotIT'><p>Plot of  infection times of the EA algorithm</p></a></li>
<li><a href='#PlotMD'><p>QQ-Plot of Mahalanobis distances</p></a></li>
<li><a href='#POEM'><p>Nearest Neighbour Imputation with Mahalanobis distance</p></a></li>
<li><a href='#psi.lismi'><p>psi-function</p></a></li>
<li><a href='#sepe'><p>Sample Environment Protection Expenditure Survey.</p></a></li>
<li><a href='#sweep.operator'><p>Sweep operator</p></a></li>
<li><a href='#TRC'><p>Transformed rank correlations for multivariate outlier detection</p></a></li>
<li><a href='#weighted.quantile'><p>Quantiles of a weighted cdf</p></a></li>
<li><a href='#weighted.var'><p>Weighted univariate variance coping with missing values</p></a></li>
<li><a href='#weightsum'><p>Utility function for TRC.R among others</p></a></li>
<li><a href='#Winsimp'><p>Winsorization followed by imputation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multivariate Outlier Detection and Imputation for Incomplete
Survey Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Algorithms for multivariate outlier detection when missing values
    occur. Algorithms are based on Mahalanobis distance or data depth.
    Imputation is based on the multivariate normal model or uses nearest
    neighbour donors. The algorithms take sample designs, in particular
    weighting, into account. The methods are described in Bill and Hulliger
    (2016) &lt;<a href="https://doi.org/10.17713%2Fajs.v45i1.86">doi:10.17713/ajs.v45i1.86</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/martinSter/modi">https://github.com/martinSter/modi</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/martinSter/modi/issues">https://github.com/martinSter/modi/issues</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS (&ge; 7.3-50), norm (&ge; 1.0-9.5), stats, graphics, utils</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, survey, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-13 19:20:51 UTC; beat.hulliger</td>
</tr>
<tr>
<td>Author:</td>
<td>Beat Hulliger [aut, cre],
  Martin Sterchi [ctb],
  Tobias Schoch [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Beat Hulliger &lt;beat.hulliger@fhnw.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-14 09:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BEM'>BACON-EEM Algorithm for multivariate outlier detection in incomplete
multivariate survey data</h2><span id='topic+BEM'></span>

<h3>Description</h3>

<p><code>BEM</code> starts from a set of uncontaminated data with possible
missing values, applies a version of the EM-algorithm to estimate
the center and scatter of the good data, then adds (or deletes)
observations to the good data which have a Mahalanobis distance
below a threshold. This process iterates until the good data remain
stable. Observations not among the good data are outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BEM(
  data,
  weights,
  v = 2,
  c0 = 3,
  alpha = 0.01,
  md.type = "m",
  em.steps.start = 10,
  em.steps.loop = 5,
  better.estimation = FALSE,
  monitor = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BEM_+3A_data">data</code></td>
<td>
<p>a matrix or data frame. As usual, rows are observations and
columns are variables.</p>
</td></tr>
<tr><td><code id="BEM_+3A_weights">weights</code></td>
<td>
<p>a non-negative and non-zero vector of weights for each
observation. Its length must equal the number of rows of the data.
Default is <code>rep(1, nrow(data))</code>.</p>
</td></tr>
<tr><td><code id="BEM_+3A_v">v</code></td>
<td>
<p>an integer indicating the distance for the definition of the
starting good subset: <code>v = 1</code> uses the Mahalanobis distance based
on the weighted mean and covariance, <code>v = 2</code> uses the Euclidean
distance from the componentwise median.</p>
</td></tr>
<tr><td><code id="BEM_+3A_c0">c0</code></td>
<td>
<p>the size of initial subset is <code>c0 * ncol(data)</code>.</p>
</td></tr>
<tr><td><code id="BEM_+3A_alpha">alpha</code></td>
<td>
<p>a small probability indicating the level <code>(1 - alpha)</code>
of the cutoff quantile for good observations.</p>
</td></tr>
<tr><td><code id="BEM_+3A_md.type">md.type</code></td>
<td>
<p>type of Mahalanobis distance: <code>"m"</code> marginal,
<code>"c"</code> conditional.</p>
</td></tr>
<tr><td><code id="BEM_+3A_em.steps.start">em.steps.start</code></td>
<td>
<p>number of iterations of EM-algorithm for starting
good subset.</p>
</td></tr>
<tr><td><code id="BEM_+3A_em.steps.loop">em.steps.loop</code></td>
<td>
<p>number of iterations of EM-algorithm for good subset.</p>
</td></tr>
<tr><td><code id="BEM_+3A_better.estimation">better.estimation</code></td>
<td>
<p>if <code>better.estimation = TRUE</code>, then the
EM-algorithm for the final good subset iterates <code>em.steps.start</code> more.</p>
</td></tr>
<tr><td><code id="BEM_+3A_monitor">monitor</code></td>
<td>
<p>if <code>TRUE</code>, verbose output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The BACON algorithm with <code>v = 1</code> is not robust but affine equivariant
while <code>v = 1</code> is robust but not affine equivariant. The threshold for
the (squared) Mahalanobis distances, beyond which an observation is an
outlier, is a standardised chisquare quantile at <code>(1 - alpha)</code>. For
large data sets it may be better to choose <code>alpha / n</code> instead. The
internal function <code>EM.normal</code> is usually called from <code>BEM</code>.
<code>EM.normal</code> is implementing the EM-algorithm in such a way that
part of the calculations can be saved to be reused in the <code>BEM</code>
algorithm. <code>EM.normal</code> does not contain the computation of the
observed sufficient statistics, they will be computed in the main
program of <code>BEM</code> and passed as parameters as well as the statistics
on the missingness patterns.
</p>


<h3>Value</h3>

<p><code>BEM</code> returns a list whose first component <code>output</code> is a
sublist with the following components:
</p>

<dl>
<dt><code>sample.size</code></dt><dd><p>Number of observations</p>
</dd>
<dt><code>discarded.observations</code></dt><dd><p>Number of discarded observations</p>
</dd>
<dt><code>number.of.variables</code></dt><dd><p>Number of variables</p>
</dd>
<dt><code>significance.level</code></dt><dd><p>The probability used for the cutpoint,
i.e. <code>alpha</code></p>
</dd>
<dt><code>initial.basic.subset.size</code></dt><dd><p>Size of initial good subset</p>
</dd>
<dt><code>final.basic.subset.size</code></dt><dd><p>Size of final good subset</p>
</dd>
<dt><code>number.of.iterations</code></dt><dd><p>Number of iterations of the BACON step</p>
</dd>
<dt><code>computation.time</code></dt><dd><p>Elapsed computation time</p>
</dd>
<dt><code>center</code></dt><dd><p>Final estimate of the center</p>
</dd>
<dt><code>scatter</code></dt><dd><p>Final estimate of the covariance matrix</p>
</dd>
<dt><code>cutpoint</code></dt><dd><p>The threshold MD-value for the cut-off of outliers</p>
</dd>
</dl>

<p>The further components returned by <code>BEM</code> are:
</p>

<dl>
<dt><code>outind</code></dt><dd><p>Indicator of outliers</p>
</dd>
<dt><code>dist</code></dt><dd><p>Final Mahalanobis distances</p>
</dd>
</dl>



<h3>Note</h3>

<p><code>BEM</code> uses an adapted version of the EM-algorithm in function
<code>.EM-normal</code>.
</p>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Béguin, C. and Hulliger, B. (2008) The BACON-EEM Algorithm for
Multivariate Outlier Detection in Incomplete Survey Data, Survey Methodology,
Vol. 34, No. 1, pp. 91-103.
</p>
<p>Billor, N., Hadi, A.S. and Vellemann, P.F. (2000). BACON: Blocked Adaptative
Computationally-efficient Outlier Nominators. Computational Statistics and
Data Analysis, 34(3), 279-298.
</p>
<p>Schafer J.L. (2000), Analysis of Incomplete Multivariate Data, Monographs on
Statistics and Applied Probability 72, Chapman &amp; Hall.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Bushfire data set with 20% MCAR
data(bushfirem, bushfire.weights)
bem.res &lt;- BEM(bushfirem, bushfire.weights,
               alpha = (1 - 0.01 / nrow(bushfirem)))
print(bem.res$output)
</code></pre>

<hr>
<h2 id='bushfire'>Bushfire scars.</h2><span id='topic+bushfire'></span>

<h3>Description</h3>

<p>The bushfire data set was used by Campbell (1984, 1989) to locate bushfire scars.
The dataset contains satellite measurements on five frequency bands, corresponding
to each of 38 pixels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bushfire
</code></pre>


<h3>Format</h3>

<p>A data frame with 38 rows and 5 variables.
</p>


<h3>Details</h3>

<p>The data contains an outlying cluster of observations 33 to 38 a second outlier
cluster of observations 7 to 11 and a few more isolated outliers, namely observations
12, 13, 31 and 32.
</p>
<p>For testing purposes weights are provided:
<code>bushfire.weights &lt;- rep(c(1,2,5), length = nrow(bushfire))</code>
</p>


<h3>References</h3>

<p>Campbell, N. (1989) Bushfire Mapping using NOAA AVHRR Data. Technical Report.
Commonwealth Scientific and Industrial Research Organisation, North Ryde.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfire)
</code></pre>

<hr>
<h2 id='bushfire.weights'>Weights for Bushfire scars.</h2><span id='topic+bushfire.weights'></span>

<h3>Description</h3>

<p>The bushfire data set was used by Campbell (1984, 1989) to locate bushfire scars.
The dataset contains satellite measurements on five frequency bands, corresponding
to each of 38 pixels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bushfire.weights
</code></pre>


<h3>Format</h3>

<p>A vector of length 38.
</p>


<h3>Details</h3>

<p>For testing purposes, <code>bushfire.weights</code> provides artificial weights created
according to: <code>bushfire.weights &lt;- rep(c(1,2,5), length = nrow(bushfire))</code>
</p>


<h3>References</h3>

<p>Campbell, N. (1989) Bushfire Mapping using NOAA AVHRR Data. Technical Report.
Commonwealth Scientific and Industrial Research Organisation, North Ryde.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfire.weights)
</code></pre>

<hr>
<h2 id='bushfirem'>Bushfire scars with missing data.</h2><span id='topic+bushfirem'></span>

<h3>Description</h3>

<p>The bushfire data set was used by Campbell (1984, 1989) to locate bushfire scars.
The dataset contains satellite measurements on five frequency bands, corresponding
to each of 38 pixels. However, this dataset contains missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bushfirem
</code></pre>


<h3>Format</h3>

<p>A data frame with 38 rows and 5 variables.
</p>


<h3>Details</h3>

<p>The data contains an outlying cluster of observations 33 to 38 a second outlier
cluster of observations 7 to 11 and a few more isolated outliers, namely observations
12, 13, 31 and 32.
</p>
<p><code>bushfirem</code> is created from bushfire by setting a proportion of 0.2 of the values
to missing.
</p>
<p>For testing purposes weights are provided:
<code>bushfire.weights &lt;- rep(c(1,2,5), length = nrow(bushfire))</code>
</p>


<h3>References</h3>

<p>Campbell, N. (1989) Bushfire Mapping using NOAA AVHRR Data. Technical Report.
Commonwealth Scientific and Industrial Research Organisation, North Ryde.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem)
</code></pre>

<hr>
<h2 id='EA.dist'>Utility function for EAdet and EAimp</h2><span id='topic+EA.dist'></span>

<h3>Description</h3>

<p>Calculation of distances for EPIDEMIC Algorithm for
multivariate outlier detection and imputation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EA.dist(
  data,
  n,
  p,
  weights,
  reach,
  transmission.function,
  power,
  distance.type,
  maxl
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EA.dist_+3A_data">data</code></td>
<td>
<p>a data frame or matrix with data.</p>
</td></tr>
<tr><td><code id="EA.dist_+3A_n">n</code></td>
<td>
<p>number of rows.</p>
</td></tr>
<tr><td><code id="EA.dist_+3A_p">p</code></td>
<td>
<p>number of columns.</p>
</td></tr>
<tr><td><code id="EA.dist_+3A_weights">weights</code></td>
<td>
<p>a vector of positive sampling weights.</p>
</td></tr>
<tr><td><code id="EA.dist_+3A_reach">reach</code></td>
<td>
<p>if <code>reach = "max"</code> the maximal nearest
neighbor distance is used as the basis for the transmission
function, otherwise the weighted</p>
</td></tr>
<tr><td><code id="EA.dist_+3A_transmission.function">transmission.function</code></td>
<td>
<p>form of the transmission function
of distance d: <code>"step"</code> is a heaviside function which jumps
to <code>1</code> at <code>d0</code>, <code>"linear"</code> is linear between
<code>0</code> and <code>d0</code>, <code>"power"</code> is <code>(beta*d+1)^(-p)</code>
for <code>p = ncol(data)</code> as default, <code>"root"</code> is the function
<code>1-(1-d/d0)^(1/maxl)</code>.</p>
</td></tr>
<tr><td><code id="EA.dist_+3A_power">power</code></td>
<td>
<p>sets <code>p = power</code>.</p>
</td></tr>
<tr><td><code id="EA.dist_+3A_distance.type">distance.type</code></td>
<td>
<p>distance type in function <code>dist()</code>.</p>
</td></tr>
<tr><td><code id="EA.dist_+3A_maxl">maxl</code></td>
<td>
<p>maximum number of steps without infection.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>

<hr>
<h2 id='EAdet'>Epidemic Algorithm for detection of multivariate outliers in incomplete survey data</h2><span id='topic+EAdet'></span>

<h3>Description</h3>

<p>In <code>EAdet</code> an epidemic is started at a center of the data. The epidemic
spreads out and infects neighbouring points (probabilistically or deterministically).
The last points infected are outliers. After running <code>EAdet</code> an imputation
with <code>EAimp</code> may be run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EAdet(
  data,
  weights,
  reach = "max",
  transmission.function = "root",
  power = ncol(data),
  distance.type = "euclidean",
  maxl = 5,
  plotting = TRUE,
  monitor = FALSE,
  prob.quantile = 0.9,
  random.start = FALSE,
  fix.start,
  threshold = FALSE,
  deterministic = TRUE,
  rm.missobs = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EAdet_+3A_data">data</code></td>
<td>
<p>a data frame or matrix with data.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_weights">weights</code></td>
<td>
<p>a vector of positive sampling weights.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_reach">reach</code></td>
<td>
<p>if <code>reach = "max"</code> the maximal nearest neighbor distance is
used as the basis for the transmission function, otherwise the weighted
<code class="reqn">(1 - (p + 1) / n)</code> quantile of the nearest neighbor distances is used.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_transmission.function">transmission.function</code></td>
<td>
<p>form of the transmission function of distance d:
<code>"step"</code> is a heaviside function which jumps to <code>1</code> at <code>d0</code>,
<code>"linear"</code> is linear between <code>0</code> and <code>d0</code>, <code>"power"</code> is
<code>(beta*d+1)^(-p)</code> for <code>p = ncol(data)</code> and <code>beta &lt;- as.single((0.01^(-1 / power) - 1) / d0))</code> as default, <code>"root"</code> is the
function <code>1-(1-d/d0)^(1/maxl)</code>.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_power">power</code></td>
<td>
<p>sets <code>p = power</code>.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_distance.type">distance.type</code></td>
<td>
<p>distance type in function <code>dist()</code>.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_maxl">maxl</code></td>
<td>
<p>maximum number of steps without infection.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_plotting">plotting</code></td>
<td>
<p>if <code>TRUE</code>, the cdf of infection times is plotted.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_monitor">monitor</code></td>
<td>
<p>if <code>TRUE</code>, verbose output on epidemic.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_prob.quantile">prob.quantile</code></td>
<td>
<p>if mads fail, take this quantile absolute deviation.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_random.start">random.start</code></td>
<td>
<p>if <code>TRUE</code>, take a starting point at random instead of the
spatial median.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_fix.start">fix.start</code></td>
<td>
<p>force epidemic to start at a specific observation.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_threshold">threshold</code></td>
<td>
<p>infect all remaining points with infection probability above
the threshold <code>1-0.5^(1/maxl)</code>.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_deterministic">deterministic</code></td>
<td>
<p>if <code>TRUE</code>, the number of infections is the expected
number and the infected observations are the ones with largest infection probabilities.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_rm.missobs">rm.missobs</code></td>
<td>
<p>set <code>rm.missobs=TRUE</code> if completely missing observations
should be discarded. This has to be done actively as a safeguard to avoid mismatches
when imputing.</p>
</td></tr>
<tr><td><code id="EAdet_+3A_verbose">verbose</code></td>
<td>
<p>more output with <code>verbose=TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The form and parameters of the transmission function should be chosen such that the
infection times have at least a range of 10. The default cutting point to decide on
outliers is the median infection time plus three times the mad of infection times.
A better cutpoint may be chosen by visual inspection of the cdf of infection times.
<code>EAdet</code> calls the function <code>EA.dist</code>, which passes the counterprobabilities
of infection (a <code class="reqn">n * (n - 1) / 2</code> size vector!) and three parameters (sample
spatial median index, maximal distance to nearest neighbor and transmission distance =
reach) as arguments to <code>EAdet</code>. The distances vector may be too large to be passed
as arguments. Then either the memory size must be increased. Former versions of the
code used a global variable to store the distances in order to save memory.
</p>


<h3>Value</h3>

<p><code>EAdet</code> returns a list whose first component <code>output</code> is a sub-list
with the following components:
</p>

<dl>
<dt><code>sample.size</code></dt><dd><p>Number of observations</p>
</dd>
<dt><code>discarded.observations</code></dt><dd><p>Indices of discarded observations</p>
</dd>
<dt><code>missing.observations</code></dt><dd><p>Indices of completely missing observations</p>
</dd>
<dt><code>number.of.variables</code></dt><dd><p>Number of variables</p>
</dd>
<dt><code>n.complete.records</code></dt><dd><p>Number of records without missing values</p>
</dd>
<dt><code>n.usable.records</code></dt><dd><p>Number of records with less than half of values
missing (unusable observations are discarded)</p>
</dd>
<dt><code>medians</code></dt><dd><p>Component wise medians</p>
</dd>
<dt><code>mads</code></dt><dd><p>Component wise mads</p>
</dd>
<dt><code>prob.quantile</code></dt><dd><p>Use this quantile if mads fail, i.e. if one of the mads is 0</p>
</dd>
<dt><code>quantile.deviations</code></dt><dd><p>Quantile of absolute deviations</p>
</dd>
<dt><code>start</code></dt><dd><p>Starting observation</p>
</dd>
<dt><code>transmission.function</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>power</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>maxl</code></dt><dd><p>Maximum number of steps without infection</p>
</dd>
<dt><code>min.nn.dist</code></dt><dd><p>Maximal nearest neighbor distance</p>
</dd>
<dt><code>transmission.distance</code></dt><dd><p><code>d0</code></p>
</dd>
<dt><code>threshold</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>distance.type</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>deterministic</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>number.infected</code></dt><dd><p>Number of infected observations</p>
</dd>
<dt><code>cutpoint</code></dt><dd><p>Cutpoint of infection times for outlier definition</p>
</dd>
<dt><code>number.outliers</code></dt><dd><p>Number of outliers</p>
</dd>
<dt><code>outliers</code></dt><dd><p>Indices of outliers</p>
</dd>
<dt><code>duration</code></dt><dd><p>Duration of epidemic</p>
</dd>
<dt><code>computation.time</code></dt><dd><p>Elapsed computation time</p>
</dd>
<dt><code>initialisation.computation.time</code></dt><dd><p>Elapsed computation time for
standardisation and calculation of distance matrix</p>
</dd>
</dl>

<p>The further components returned by <code>EAdet</code> are:
</p>

<dl>
<dt><code>infected</code></dt><dd><p>Indicator of infection</p>
</dd>
<dt><code>infection.time</code></dt><dd><p>Time of infection</p>
</dd>
<dt><code>outind</code></dt><dd><p>Indicator of outliers</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Béguin, C. and Hulliger, B. (2004) Multivariate outlier detection in
incomplete survey data: the epidemic algorithm and transformed rank correlations,
JRSS-A, 167, Part 2, pp. 275-294.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EAimp">EAimp</a></code> for imputation with the Epidemic Algorithm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem, bushfire.weights)
det.res &lt;- EAdet(bushfirem, bushfire.weights)
</code></pre>

<hr>
<h2 id='EAimp'>Epidemic Algorithm for imputation of multivariate outliers in incomplete
survey data.</h2><span id='topic+EAimp'></span>

<h3>Description</h3>

<p>After running <code>EAdet</code> an imputation of the detected outliers with
<code>EAimp</code> may be run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EAimp(
  data,
  weights,
  outind,
  reach = "max",
  transmission.function = "root",
  power = ncol(data),
  distance.type = "euclidean",
  duration = 5,
  maxl = 5,
  kdon = 1,
  monitor = FALSE,
  threshold = FALSE,
  deterministic = TRUE,
  fixedprop = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EAimp_+3A_data">data</code></td>
<td>
<p>a data frame or matrix with the data.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_weights">weights</code></td>
<td>
<p>a vector of positive sampling weights.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_outind">outind</code></td>
<td>
<p>a logical vector with component <code>TRUE</code> for outliers.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_reach">reach</code></td>
<td>
<p>reach of the threshold function (usually set to the maximum
distance to a nearest neighbour, see internal function <code>EA.dist</code>).</p>
</td></tr>
<tr><td><code id="EAimp_+3A_transmission.function">transmission.function</code></td>
<td>
<p>form of the transmission function of distance d:
<code>"step"</code> is a heaviside function which jumps to <code>1</code> at <code>d0</code>,
<code>"linear"</code> is linear between <code>0</code> and <code>d0</code>, <code>"power"</code> is
<code>beta*d+1^(-p)</code> for <code>p=ncol(data)</code> as default, <code>"root"</code> is the
function <code>1-(1-d/d0)^(1/maxl)</code>.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_power">power</code></td>
<td>
<p>sets <code>p=power</code>, where <code>p</code> is the parameter in the above
transmission function.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_distance.type">distance.type</code></td>
<td>
<p>distance type in function <code>dist()</code>.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_duration">duration</code></td>
<td>
<p>the duration of the detection epidemic.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_maxl">maxl</code></td>
<td>
<p>maximum number of steps without infection.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_kdon">kdon</code></td>
<td>
<p>the number of donors that should be infected before imputation.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_monitor">monitor</code></td>
<td>
<p>if <code>TRUE</code> verbose output on epidemic.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_threshold">threshold</code></td>
<td>
<p>Infect all remaining points with infection probability above
the threshold <code>1-0.5^(1/maxl)</code>.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_deterministic">deterministic</code></td>
<td>
<p>if <code>TRUE</code> the number of infections is the expected
number and the infected observations are the ones with largest infection
probabilities.</p>
</td></tr>
<tr><td><code id="EAimp_+3A_fixedprop">fixedprop</code></td>
<td>
<p>if <code>TRUE</code> a fixed proportion of observations is infected
at each step.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>EAimp</code> uses the distances calculated in <code>EAdet</code> (actually the
counterprobabilities, which are stored in a global data set) and starts an
epidemic at each observation to be imputed until donors for the missing values
are infected. Then a donor is selected randomly.
</p>


<h3>Value</h3>

<p><code>EAimp</code> returns a list with two components: <code>parameters</code> and
<code>imputed.data</code>.
<code>parameters</code> contains the following elements:
</p>

<dl>
<dt><code>sample.size</code></dt><dd><p>Number of observations</p>
</dd>
<dt><code>number.of.variables</code></dt><dd><p>Number of variables</p>
</dd>
<dt><code>n.complete.records</code></dt><dd><p>Number of records without missing values</p>
</dd>
<dt><code>n.usable.records</code></dt><dd><p>Number of records with less than half of values
missing (unusable observations are discarded)</p>
</dd>
<dt><code>duration</code></dt><dd><p>Duration of epidemic</p>
</dd>
<dt><code>reach</code></dt><dd><p>Transmission distance (<code>d0</code>)</p>
</dd>
<dt><code>threshold</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>deterministic</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>computation.time</code></dt><dd><p>Elapsed computation time</p>
</dd>
</dl>

<p><code>imputed.data</code> contains the imputed data.
</p>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Béguin, C. and Hulliger, B. (2004) Multivariate outlier detection in
incomplete survey data: the epidemic algorithm and transformed rank correlations,
JRSS-A, 167, Part 2, pp. 275-294.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EAdet">EAdet</a></code> for outlier detection with the Epidemic Algorithm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem, bushfire.weights)
det.res &lt;- EAdet(bushfirem, bushfire.weights)
imp.res &lt;- EAimp(bushfirem, bushfire.weights, outind = det.res$outind, kdon = 3)
print(imp.res$output)
</code></pre>

<hr>
<h2 id='EM.normal'>EM for multivariate normal data</h2><span id='topic+EM.normal'></span>

<h3>Description</h3>

<p>This version of EM does not contain the computation of the
observed sufficient statistics, they will be computed in the
main program of BEM and passed as parameters as well as the
statistics on the missingness patterns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EM.normal(
  data,
  weights = rep(1, nrow(data)),
  n = sum(weights),
  p = ncol(data),
  s.counts,
  s.id,
  S,
  T.obs,
  start.mean = rep(0, p),
  start.var = diag(1, p),
  numb.it = 10,
  Estep.output = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EM.normal_+3A_data">data</code></td>
<td>
<p>matrix or dataframe with data.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_weights">weights</code></td>
<td>
<p>vector of weights.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_n">n</code></td>
<td>
<p>number of rows.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_p">p</code></td>
<td>
<p>number of columns.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_s.counts">s.counts</code></td>
<td>
<p>s.counts.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_s.id">s.id</code></td>
<td>
<p>s.id.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_s">S</code></td>
<td>
<p>S.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_t.obs">T.obs</code></td>
<td>
<p>T.obs.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_start.mean">start.mean</code></td>
<td>
<p>initial center.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_start.var">start.var</code></td>
<td>
<p>initial variance.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_numb.it">numb.it</code></td>
<td>
<p>numb.it.</p>
</td></tr>
<tr><td><code id="EM.normal_+3A_estep.output">Estep.output</code></td>
<td>
<p>Estep.output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>

<hr>
<h2 id='ER'>Robust EM-algorithm ER</h2><span id='topic+ER'></span>

<h3>Description</h3>

<p>The <code>ER</code> function is an implementation of the ER-algorithm
of Little and Smith (1987).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ER(
  data,
  weights,
  alpha = 0.01,
  psi.par = c(2, 1.25),
  em.steps = 100,
  steps.output = FALSE,
  Estep.output = FALSE,
  tolerance = 1e-06
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ER_+3A_data">data</code></td>
<td>
<p>a data frame or matrix with the data.</p>
</td></tr>
<tr><td><code id="ER_+3A_weights">weights</code></td>
<td>
<p>sampling weights.</p>
</td></tr>
<tr><td><code id="ER_+3A_alpha">alpha</code></td>
<td>
<p>probability for the quantile of the cut-off.</p>
</td></tr>
<tr><td><code id="ER_+3A_psi.par">psi.par</code></td>
<td>
<p>further parameters passed to the psi-function.</p>
</td></tr>
<tr><td><code id="ER_+3A_em.steps">em.steps</code></td>
<td>
<p>number of iteration steps of the EM-algorithm.</p>
</td></tr>
<tr><td><code id="ER_+3A_steps.output">steps.output</code></td>
<td>
<p>if <code>TRUE</code>, verbose output.</p>
</td></tr>
<tr><td><code id="ER_+3A_estep.output">Estep.output</code></td>
<td>
<p>if <code>TRUE</code>, estimators are output at each iteration.</p>
</td></tr>
<tr><td><code id="ER_+3A_tolerance">tolerance</code></td>
<td>
<p>convergence criterion (relative change).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The M-step of the EM-algorithm uses a one-step M-estimator.
</p>


<h3>Value</h3>


<dl>
<dt><code>sample.size</code></dt><dd><p>Number of observations</p>
</dd>
<dt><code>number.of.variables</code></dt><dd><p>Number of variables</p>
</dd>
<dt><code>significance.level</code></dt><dd><p>alpha</p>
</dd>
<dt><code>computation.time</code></dt><dd><p>Elapsed computation time</p>
</dd>
<dt><code>good.data</code></dt><dd><p>Indices of the data in the final good subset</p>
</dd>
<dt><code>outliers</code></dt><dd><p>Indices of the outliers</p>
</dd>
<dt><code>center</code></dt><dd><p>Final estimate of the center</p>
</dd>
<dt><code>scatter</code></dt><dd><p>Final estimate of the covariance matrix</p>
</dd>
<dt><code>dist</code></dt><dd><p>Final Mahalanobis distances</p>
</dd>
<dt><code>rob.weights</code></dt><dd><p>Robustness weights in the final EM step</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Little, R. and P. Smith (1987). Editing and imputation for
quantitative survey data. Journal of the American Statistical Association, 82, 58-68.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BEM">BEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem, bushfire.weights)
det.res &lt;- ER(bushfirem, weights = bushfire.weights, alpha = 0.05,
steps.output = TRUE, em.steps = 100, tol = 2e-6)
PlotMD(det.res$dist, ncol(bushfirem))
</code></pre>

<hr>
<h2 id='ER.normal'>Utility for ER function</h2><span id='topic+ER.normal'></span>

<h3>Description</h3>

<p>The <code>ER</code> function is an implementation of the
ER-algorithm of Little and Smith (1987).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ER.normal(
  data,
  weights = rep(1, nrow(data)),
  psi.par = c(2, 1.25),
  np = sum(weights),
  p = ncol(data),
  s.counts,
  s.id,
  S,
  missing.items,
  nb.missing.items,
  start.mean = rep(0, p),
  start.var = diag(1, p),
  numb.it = 10,
  Estep.output = FALSE,
  tolerance = 1e-06
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ER.normal_+3A_data">data</code></td>
<td>
<p>matrix or dataframe with data.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_weights">weights</code></td>
<td>
<p>vector of weights.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_psi.par">psi.par</code></td>
<td>
<p>parameters for psi function.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_np">np</code></td>
<td>
<p>np.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_p">p</code></td>
<td>
<p>number of columns.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_s.counts">s.counts</code></td>
<td>
<p>s.counts.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_s.id">s.id</code></td>
<td>
<p>s.id.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_s">S</code></td>
<td>
<p>S.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_missing.items">missing.items</code></td>
<td>
<p>missing items.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_nb.missing.items">nb.missing.items</code></td>
<td>
<p>number of missing items.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_start.mean">start.mean</code></td>
<td>
<p>initial center.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_start.var">start.var</code></td>
<td>
<p>initial variance.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_numb.it">numb.it</code></td>
<td>
<p>number of iterations.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_estep.output">Estep.output</code></td>
<td>
<p>Estep.output.</p>
</td></tr>
<tr><td><code id="ER.normal_+3A_tolerance">tolerance</code></td>
<td>
<p>tolerance.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>

<hr>
<h2 id='GIMCD'>Gaussian imputation followed by MCD</h2><span id='topic+GIMCD'></span>

<h3>Description</h3>

<p>Gaussian imputation uses the classical non-robust mean and covariance
estimator and then imputes predictions under the multivariate normal model.
Outliers may be created by this procedure. Then a high-breakdown robust
estimate of the location and scatter with the Minimum Covariance Determinant
algorithm is obtained and finally outliers are determined based on Mahalanobis
distances based on the robust location and scatter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GIMCD(data, alpha = 0.05, seedem = 23456789, seedmcd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GIMCD_+3A_data">data</code></td>
<td>
<p>a data frame or matrix with the data.</p>
</td></tr>
<tr><td><code id="GIMCD_+3A_alpha">alpha</code></td>
<td>
<p>a threshold value for the cut-off for the outlier
Mahalanobis distances.</p>
</td></tr>
<tr><td><code id="GIMCD_+3A_seedem">seedem</code></td>
<td>
<p>random number generator seed for EM algorithm</p>
</td></tr>
<tr><td><code id="GIMCD_+3A_seedmcd">seedmcd</code></td>
<td>
<p>random number generator seed for MCD algorithm,
if <code>seedmcd</code> is missing, an internal seed will be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Normal imputation from package <code>norm</code> and MCD from package <code>MASS</code>.
Note that currently MCD does not accept weights.
</p>


<h3>Value</h3>

<p>Result is stored in a global list GIMCD.r:
</p>

<dl>
<dt><code>center</code></dt><dd><p>robust center</p>
</dd>
<dt><code>scatter</code></dt><dd><p>robust covariance</p>
</dd>
<dt><code>alpha</code></dt><dd><p>quantile for cut-off value</p>
</dd>
<dt><code>computation.time</code></dt><dd><p>elapsed computation time</p>
</dd>
<dt><code>outind</code></dt><dd><p>logical vector of outlier indicators</p>
</dd>
<dt><code>dist</code></dt><dd><p>Mahalanobis distances</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Béguin, C. and Hulliger, B. (2008), The BACON-EEM Algorithm
for Multivariate Outlier Detection, in Incomplete Survey Data, Survey
Methodology, Vol. 34, No. 1, pp. 91-103.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+cov.rob">cov.rob</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem)
det.res &lt;- GIMCD(bushfirem, alpha = 0.1)
print(det.res$center)
PlotMD(det.res$dist, ncol(bushfirem))
</code></pre>

<hr>
<h2 id='ind.dij'>Addressing function for Epidemic Algorithm</h2><span id='topic+ind.dij'></span>

<h3>Description</h3>

<p>Utility function for Epidemic Algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ind.dij(i, j, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ind.dij_+3A_i">i</code></td>
<td>
<p>index i.</p>
</td></tr>
<tr><td><code id="ind.dij_+3A_j">j</code></td>
<td>
<p>index j.</p>
</td></tr>
<tr><td><code id="ind.dij_+3A_n">n</code></td>
<td>
<p>number of rows.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Cédric Béguin
</p>

<hr>
<h2 id='ind.dijs'>Addressing function for Epidemic Algorithm</h2><span id='topic+ind.dijs'></span>

<h3>Description</h3>

<p>Utility function for Epidemic Algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ind.dijs(i, js, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ind.dijs_+3A_i">i</code></td>
<td>
<p>index i.</p>
</td></tr>
<tr><td><code id="ind.dijs_+3A_js">js</code></td>
<td>
<p>indexes js.</p>
</td></tr>
<tr><td><code id="ind.dijs_+3A_n">n</code></td>
<td>
<p>number of rows.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Cédric Béguin
</p>

<hr>
<h2 id='lival'>Living Standards Measurement Survey Albania 2012</h2><span id='topic+lival'></span>

<h3>Description</h3>

<p>The dataset is an extended version of the public micro data file of the LSMS 2012 of
Albania available at (<a href="https://www.instat.gov.al/en/figures/micro-data/">https://www.instat.gov.al/en/figures/micro-data/</a>, accessed 13 February 2023).
Documentation of the LSMS 2012 of Albania is from the
World Bank (<a href="https://microdata.worldbank.org/index.php/catalog/1970">https://microdata.worldbank.org/index.php/catalog/1970</a>,
accessed 5 November 2020). The data set is ported to R and updated with
approximate survey design information derived from the data itself.
The units are households and the variables are expenditures on main categories,
poverty measures and structural information including weights and sample design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lival
</code></pre>


<h3>Format</h3>

<p>A data frame with 6671 rows and 26 variables
</p>

<dl>
<dt> psu </dt><dd><p> primary sampling unit (psu) </p>
</dd>
<dt> hhid </dt><dd><p> unique household identifier (100*psu+hh) </p>
</dd>
<dt> hh </dt><dd><p> household number per psu </p>
</dd>
<dt> prefectu </dt><dd><p> prefecture </p>
</dd>
<dt> urban </dt><dd><p> urbanicity (Urban=1, Rural=2) </p>
</dd>
<dt> strat </dt><dd><p> stratum </p>
</dd>
<dt> region </dt><dd><p> region </p>
</dd>
<dt> totcons </dt><dd><p> total consumption of hh </p>
</dd>
<dt> rcons </dt><dd><p> real mean per capita consumption </p>
</dd>
<dt> rfood </dt><dd><p> real food consumption per capita </p>
</dd>
<dt> rtotnfoo </dt><dd><p> real non food consumption per capita </p>
</dd>
<dt> reduexpp </dt><dd><p> real education consumption per capita </p>
</dd>
<dt> rdurcons </dt><dd><p> real durable consumption per capita </p>
</dd>
<dt> rtotutil </dt><dd><p> real utilities consumption per capita</p>
</dd>
<dt> egap0 </dt><dd><p> extreme headcount poverty </p>
</dd>
<dt> egap1 </dt><dd><p> extreme poverty gap </p>
</dd>
<dt> egap2 </dt><dd><p> extreme poverty depth </p>
</dd>
<dt> agap0 </dt><dd><p> absolute headcount poverty </p>
</dd>
<dt> agap1 </dt><dd><p> absolute poverty gap </p>
</dd>
<dt> agap2 </dt><dd><p> absolute poverty depth </p>
</dd>
<dt> weight </dt><dd><p> final cross-sectional weight </p>
</dd>
<dt> nph </dt><dd><p> number of psu in stratum population </p>
</dd>
<dt> mph </dt><dd><p> number of households in stratum population </p>
</dd>
<dt> mphi </dt><dd><p> number of households in sampled psu </p>
</dd>
<dt> pi1 </dt><dd><p> psu inclusion probability </p>
</dd>
<dt> pi2 </dt><dd><p> household inclusion probability </p>
</dd>
</dl>



<h3>Details</h3>

<p>Absolute poverty measures use a poverty line of Lek 4891 (2002 prices).
Extreme poverty measures use a poverty line where the basic nutritional needs are
difficult to meet.
The headcount poverty variable is an indicator for the income of the household <code class="reqn">y_i</code>
being below the (absolute or extreme) poverty line <code class="reqn">z</code>.
The poverty gap variable measures the relative distance to the poverty line: <code class="reqn">(z-y_i)/z</code>.
The poverty depth variable is the square of the poverty gap variable, i.e. <code class="reqn">[(z-y_i)/z]^2</code>,
giving more weight to the poorer among the poor and thus describing the inequality
among the poor.
</p>
<p>The survey design is a stratified clustered two stage design.
The primary sampling units are enumeration zones.
The strata are the crossing of prefecture and urbanicity and the allocation of the
psu sample to the strata is proportional to the number of households.
Within strata the psu are sampled with probability proportional to number of households.
Within psu a simple random sample of 8 households was selected.
The weights are calibrated to population margins.
All survey design informations except the strata and the weights are approximated
through the weights using assumptions on the design.
Since the data set has undergone data protection measures and the survey design
is approximate only, inference to the population does not yield exact results.
However, the complexity of the data and of the survey design are realistic.
</p>
<p>The size of the household is not on the original data set.
However, the transformation <code>capita &lt;- round(0.07527689 * totcons/rcons, 0)</code>
yields the number of persons in the household.
</p>


<h3>Note</h3>

<p>With R package <code><a href="MASS.html#topic+survey">survey</a></code> a survey design object can be built with, e.g., <code>svydesign(~psu + hhid , strata= ~strat, fpc= ~pi1 +pi2,  weight= ~weight, data=lival, pps="brewer")</code>.
</p>


<h3>References</h3>

<p><a href="https://www.instat.gov.al/en/figures/micro-data/">https://www.instat.gov.al/en/figures/micro-data/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lival)
lival$capita &lt;- with(lival, round(0.07527689 * totcons / rcons, 0))
## Not run: 
library(survey)
lival.des &lt;- svydesign(~psu + hhid , strata= ~strat, fpc= ~pi1 +pi2,
                      weight= ~weight, data=lival, pps="brewer")
svymean(~totcons, lival.des, deff=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='MDmiss'>Mahalanobis distance (MD) for data with missing values</h2><span id='topic+MDmiss'></span>

<h3>Description</h3>

<p>For each observation the missing dimensions are omitted
before calculating the MD. The MD contains a correction
factor <code class="reqn">p/q</code> to account for the number of observed values,
where <code class="reqn">p</code> is the number of variables and <code class="reqn">q</code> is the number of
observed dimensions for the particular observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MDmiss(data, center, cov)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MDmiss_+3A_data">data</code></td>
<td>
<p>the data as a dataframe or matrix.</p>
</td></tr>
<tr><td><code id="MDmiss_+3A_center">center</code></td>
<td>
<p>the center to be used (may not contain missing values).</p>
</td></tr>
<tr><td><code id="MDmiss_+3A_cov">cov</code></td>
<td>
<p>the covariance to be used (may not contain missing values).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function loops over the observations. This is not optimal if
only a few missingness patterns occur. If no missing values occur
the function returns the Mahalanobis distance.
</p>


<h3>Value</h3>

<p>The function returns a vector of the (squared) Mahalanobis distances.
</p>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Béguin, C., and Hulliger, B. (2004). Multivariate outlier detection
in incomplete survey data: The epidemic algorithm and transformed rank correlations.
Journal of the Royal Statistical Society, A167 (Part 2.), pp. 275-294.
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+mahalanobis">mahalanobis</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem, bushfire)
MDmiss(bushfirem, apply(bushfire, 2, mean), var(bushfire))
</code></pre>

<hr>
<h2 id='modi'>modi: Multivariate outlier detection for incomplete survey data.</h2><span id='topic+modi'></span>

<h3>Description</h3>

<p>The package modi is a collection of functions for multivariate outlier
detection and imputation. The aim is to provide a set of functions which
cope with missing values and take sampling weights into account. The original
functions were developed in the EUREDIT project. This work was partially
supported by the EU FP5 ICT programme, the Swiss Federal Office of Education
and Science and the Swiss Federal Statistical Office. Subsequent development
was in the AMELI project of the EU FP7 SSH Programme and also supported by the
University of Applied Sciences and Arts Northwestern Switzerland (FHNW).
</p>


<h3>modi functions</h3>

<p>BACON-EEM algorithm in <code>BEM()</code>, Epidemic algorithm in <code>EAdet()</code> and
<code>EAimp()</code>, Transformed Rank Correlations in <code>TRC()</code>, Gaussian
imputation with MCD in <code>GIMCD()</code>.
</p>


<h3>References</h3>

<p>Béguin, C., and Hulliger, B. (2004). Multivariate outlier detection in incomplete
survey data: The epidemic algorithm and transformed rank correlations. Journal of
the Royal Statistical Society, A167 (Part 2.), pp. 275-294.
</p>
<p>Béguin, C., and Hulliger, B. (2008). The BACON-EEM Algorithm for Multivariate
Outlier Detection in Incomplete Survey Data, Survey Methodology, Vol. 34, No. 1,
pp. 91-103.
</p>

<hr>
<h2 id='nz.min'>Non-zero non-missing minimum function</h2><span id='topic+nz.min'></span>

<h3>Description</h3>

<p>Returns the non-zero non-missing minimum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nz.min(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nz.min_+3A_x">x</code></td>
<td>
<p>vector of data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>

<hr>
<h2 id='plotIT'>Plot of  infection times of the EA algorithm</h2><span id='topic+plotIT'></span>

<h3>Description</h3>

<p>The (weighted) cdf of infection times is plotted. The infection times
jumps of the cdf are shown by the points with the
same infection times stacked vertically and respecting the weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotIT(infection.time, weights, cutpoint)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotIT_+3A_infection.time">infection.time</code></td>
<td>
<p>vector of infection.times of the observations</p>
</td></tr>
<tr><td><code id="plotIT_+3A_weights">weights</code></td>
<td>
<p>vector of (survey) weights of the observations</p>
</td></tr>
<tr><td><code id="plotIT_+3A_cutpoint">cutpoint</code></td>
<td>
<p>a cutpoint to for declaring outliers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The infection times of <code>EAdet</code> are the main input. In addition the weights
may be needed. The default cutpoint from <code>EAdet</code> may be used for the cutpoint.
Points that are never infected have a missing infection time. These missing infection times
are (temporarily) imputed by 1.2 times the maximum infection time
to show them on the plot marked with an x.
</p>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>it &lt;- c(rep(NA, 3), rep(1:7, times=c(1, 4, 10, 8, 5, 3, 2)))
wt &lt;- rep(c(1,2,5), times=12)
plotIT(it, wt, 6)
</code></pre>

<hr>
<h2 id='PlotMD'>QQ-Plot of Mahalanobis distances</h2><span id='topic+PlotMD'></span>

<h3>Description</h3>

<p>QQ-plot of (squared) Mahalanobis distances vs. scaled F-distribution (or a scaled chisquare distribution).
In addition, two default cutpoints are proposed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMD(dist, p, alpha = 0.95, chisquare = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotMD_+3A_dist">dist</code></td>
<td>
<p>a vector of Mahalanobis distances.</p>
</td></tr>
<tr><td><code id="PlotMD_+3A_p">p</code></td>
<td>
<p>the number of variables involved in the Mahalanobis distances.</p>
</td></tr>
<tr><td><code id="PlotMD_+3A_alpha">alpha</code></td>
<td>
<p>a probability for cut-off, usually close to 1.</p>
</td></tr>
<tr><td><code id="PlotMD_+3A_chisquare">chisquare</code></td>
<td>
<p>a logical indicating the the chisquare distribution should be used instead of the F-distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Scaling of the F-distribution as <code>median(dist)*qf((1:n)/(n+1), p, n-p)/qf(0.5, p, n-p)</code>.
First default cutpoint is <code>median(dist)*qf(alpha, p, n-p)/qf(0.5, p, n-p)</code> and the second default
cutpoint is the alpha quantile of the Mahalanobis distances.
</p>


<h3>Value</h3>

<table>
<tr><td><code>hmed</code></td>
<td>
<p>first proposed cutpoint based on F-distribution</p>
</td></tr>
<tr><td><code>halpha</code></td>
<td>
<p>second proposed cutpoint (alpha-quantile)</p>
</td></tr>
<tr><td><code>QQ-plot</code></td>
<td>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Little, R. &amp; Smith, P. (1987) Editing and imputation for quantitative survey data,
Journal of the American Statistical Association, 82, 58-68
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem, bushfire.weights)
det.res &lt;- TRC(bushfirem, weights = bushfire.weights)
PlotMD(det.res$dist, ncol(bushfirem))
</code></pre>

<hr>
<h2 id='POEM'>Nearest Neighbour Imputation with Mahalanobis distance</h2><span id='topic+POEM'></span>

<h3>Description</h3>

<p>POEM takes into account missing values, outlier indicators, error indicators
and sampling weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>POEM(
  data,
  weights,
  outind,
  errors,
  missing.matrix,
  alpha = 0.5,
  beta = 0.5,
  reweight.out = FALSE,
  c = 5,
  preliminary.mean.imputation = FALSE,
  monitor = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="POEM_+3A_data">data</code></td>
<td>
<p>a data frame or matrix with the data.</p>
</td></tr>
<tr><td><code id="POEM_+3A_weights">weights</code></td>
<td>
<p>sampling weights.</p>
</td></tr>
<tr><td><code id="POEM_+3A_outind">outind</code></td>
<td>
<p>an indicator vector for the outliers with <code>1</code> indicating
an outlier.</p>
</td></tr>
<tr><td><code id="POEM_+3A_errors">errors</code></td>
<td>
<p>matrix of indicators for items which failed edits.</p>
</td></tr>
<tr><td><code id="POEM_+3A_missing.matrix">missing.matrix</code></td>
<td>
<p>the missingness matrix can be given as input. Otherwise,
it will be recalculated.</p>
</td></tr>
<tr><td><code id="POEM_+3A_alpha">alpha</code></td>
<td>
<p>scalar giving the weight attributed to an item that is failing.</p>
</td></tr>
<tr><td><code id="POEM_+3A_beta">beta</code></td>
<td>
<p>minimal overlap to accept a donor.</p>
</td></tr>
<tr><td><code id="POEM_+3A_reweight.out">reweight.out</code></td>
<td>
<p>if <code>TRUE</code>, the outliers are redefined.</p>
</td></tr>
<tr><td><code id="POEM_+3A_c">c</code></td>
<td>
<p>tuning constant when redefining the outliers (cutoff for Mahalanobis
distance).</p>
</td></tr>
<tr><td><code id="POEM_+3A_preliminary.mean.imputation">preliminary.mean.imputation</code></td>
<td>
<p>assume the problematic observation is at
the mean of good observations.</p>
</td></tr>
<tr><td><code id="POEM_+3A_monitor">monitor</code></td>
<td>
<p>if <code>TRUE</code> verbose output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>POEM</code> assumes that an multivariate outlier detection has been carried out
beforehand and assumes the result is summarized in the vector <code>outind</code>.
In addition, further observations may have been flagged as failing edit-rules
and this information is given in the vector <code>errors</code>. The mean and
covariance estimate is calculated with the good observations (no outliers and
downweighted errors). Preliminary mean imputation is sometimes needed to avoid
a non-positive definite covariance estimate at this stage. Preliminary mean
imputation assumes that the problematic values of an observation (with errors,
outliers or missing) can be replaced by the mean of the rest of the non-problematic
observations. Note that the algorithm imputes these problematic observations
afterwards and therefore the final covariance matrix with imputed data is not
the same as the working covariance matrix (which may be based on preliminary mean
imputation).
</p>


<h3>Value</h3>

<p><code>POEM</code> returns a list whose first component <code>output</code> is a
sub-list with the following components:
</p>

<dl>
<dt><code>preliminary.mean.imputation</code></dt><dd><p>Logical. <code>TRUE</code> if preliminary
mean imputation should be used</p>
</dd>
<dt><code>completely.missing</code></dt><dd><p>Number of observations with no observed values</p>
</dd>
<dt><code>good.values</code></dt><dd><p>Weighted number of of good values (not missing, not
outlying, not erroneous)</p>
</dd>
<dt><code>nonoutliers.before</code></dt><dd><p>Number of nonoutliers before reweighting</p>
</dd>
<dt><code>weighted.nonoutliers.before</code></dt><dd><p>Weighted number of nonoutliers
before reweighting</p>
</dd>
<dt><code>nonoutliers.after</code></dt><dd><p>Number of nonoutliers after reweighting</p>
</dd>
<dt><code>weighted.nonoutliers.after</code></dt><dd><p>Weighted number of nonoutliers after
reweighting</p>
</dd>
<dt><code>old.center</code></dt><dd><p>Coordinate means after weighting, before imputation</p>
</dd>
<dt><code>old.variances</code></dt><dd><p>Coordinate variances after weighting, before imputation</p>
</dd>
<dt><code>new.center</code></dt><dd><p>Coordinate means after weighting, after imputation</p>
</dd>
<dt><code>new.variances</code></dt><dd><p>Coordinate variances after weighting, after imputation</p>
</dd>
<dt><code>covariance</code></dt><dd><p>Covariance (of standardised observations) before imputation</p>
</dd>
<dt><code>imputed.observations</code></dt><dd><p>Indices of observations with imputed values</p>
</dd>
<dt><code>donors</code></dt><dd><p>Indices of donors for imputed observations</p>
</dd>
<dt><code>new.outind</code></dt><dd><p>Indices of new outliers</p>
</dd>
</dl>

<p>The further component returned by <code>POEM</code> is:
</p>

<dl>
<dt><code>imputed.data</code></dt><dd><p>Imputed data set</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Béguin, C. and Hulliger B., (2002), EUREDIT Workpackage x.2
D4-5.2.1-2.C Develop and evaluate new methods for statistical outlier
detection and outlier robust multivariate imputation, Technical report,
EUREDIT 2002.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem, bushfire.weights)
outliers &lt;- rep(0, nrow(bushfirem))
outliers[31:38] &lt;- 1
imp.res &lt;- POEM(bushfirem, bushfire.weights, outliers,
preliminary.mean.imputation = TRUE)
print(imp.res$output)
var(imp.res$imputed.data)
</code></pre>

<hr>
<h2 id='psi.lismi'>psi-function</h2><span id='topic+psi.lismi'></span>

<h3>Description</h3>

<p>Defined in Little and Smith for ER algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psi.lismi(d, present, psi.par = c(2, 1.25))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psi.lismi_+3A_d">d</code></td>
<td>
<p>vector of distances.</p>
</td></tr>
<tr><td><code id="psi.lismi_+3A_present">present</code></td>
<td>
<p>present.</p>
</td></tr>
<tr><td><code id="psi.lismi_+3A_psi.par">psi.par</code></td>
<td>
<p>parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>

<hr>
<h2 id='sepe'>Sample Environment Protection Expenditure Survey.</h2><span id='topic+sepe'></span>

<h3>Description</h3>

<p>The sepe data set is a sample of the pilot survey in 1993 of the Swiss Federal Statistical
Office on environment protection expenditures of Swiss private economy in the previous
accounting year. The units are enterprises, the monetary variables are in thousand Swiss
Francs (CHF). From the original sample a random subsample was chosen of which certain
enterprises were excluded for confidentiality reasons. In addition, noise has been added
to certain variables, and certain categories have been collapsed. The data set has missing
values. The data set has first been prepared for the EU FP5 project EUREDIT and later been
data protected for educational purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sepe
</code></pre>


<h3>Format</h3>

<p>A data frame with 675 rows and 23 variables:
</p>

<dl>
<dt>idnr</dt><dd><p>identifier (anonymous)</p>
</dd>
<dt>exp</dt><dd><p>categorical variable where 1 = 'non-zero total expenditure' and
2 = 'zero total expenditure, and 3 = 'no answer'</p>
</dd>
<dt>totinvwp</dt><dd><p>total investment for water protection</p>
</dd>
<dt>totinvwm</dt><dd><p>total investment for waste management</p>
</dd>
<dt>totinvap</dt><dd><p>total investment for air protection</p>
</dd>
<dt>totinvnp</dt><dd><p>total investment for noise protection</p>
</dd>
<dt>totinvot</dt><dd><p>total investment for other environmental protection</p>
</dd>
<dt>totinvto</dt><dd><p>overall total investment in all environmental protection areas</p>
</dd>
<dt>totexpwp</dt><dd><p>total current expenditure in environmental protection area water protection</p>
</dd>
<dt>totexpwm</dt><dd><p>total current expenditure in environmental protection area waste management</p>
</dd>
<dt>totexpap</dt><dd><p>total current expenditure in environmental protection area air protection</p>
</dd>
<dt>totexpnp</dt><dd><p>total current expenditure in environmental protection area noise protection</p>
</dd>
<dt>totexpot</dt><dd><p>total current expenditure in other environmental protection</p>
</dd>
<dt>totexpto</dt><dd><p>overall total current expenditure in all environmental protection</p>
</dd>
<dt>subtot</dt><dd><p>total subsidies for environmental protection received</p>
</dd>
<dt>rectot</dt><dd><p>total receipts from environmental protection</p>
</dd>
<dt>employ</dt><dd><p>number of employees</p>
</dd>
<dt>sizeclass</dt><dd><p>size class (according to number of employees)</p>
</dd>
<dt>stratum</dt><dd><p>stratum number of sample design</p>
</dd>
<dt>activity</dt><dd><p>code of economic activity (aggregated)</p>
</dd>
<dt>popsize</dt><dd><p>number of enterprises in the population-stratum</p>
</dd>
<dt>popempl</dt><dd><p>number of employees in population activity group</p>
</dd>
<dt>weight</dt><dd><p>sampling weight (for extrapolation to the population)</p>
</dd>
</dl>



<h3>Details</h3>

<p>The sample design is stratified random sampling with different sampling rates. Use package
survey or sampling to obtain correct point and variance estimates. In addition a ratio
estimator may be built using the variable popemple which gives the total employment per
activity.
</p>
<p>There are two balance rules: the subtotals of the investment variables should
sum to totinvto and the expenditure subtotals should sum to totexpto.
</p>
<p>The missing values stem from the survey itself. In the actual survey the missing
values were declared as 'guessed' rather than copied from records.
</p>
<p>The sampling weight weight is adjusted for non-response in the stratum,
i.e. <code>weight=popsize/sampsize</code>.
</p>


<h3>References</h3>

<p>Swiss Federal Statistical Office (1996), Umweltausgaben und -investitionen in der
Schweiz 1992/1993, Ergebnisse einer Pilotstudie.
</p>
<p>Charlton, J. (ed.), Towards Effective Statistical Editing and Imputation Strategies -
Findings of the Euredit project, unpublished manuscript available from Eurostat
and <a href="https://www.cs.york.ac.uk/euredit/euredit-main.html">https://www.cs.york.ac.uk/euredit/euredit-main.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sepe)
</code></pre>

<hr>
<h2 id='sweep.operator'>Sweep operator</h2><span id='topic+sweep.operator'></span>

<h3>Description</h3>

<p>Definition of the sweep and reverse-sweep operator (Schafer pp 159-160)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sweep.operator(M, k, reverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sweep.operator_+3A_m">M</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="sweep.operator_+3A_k">k</code></td>
<td>
<p>column.</p>
</td></tr>
<tr><td><code id="sweep.operator_+3A_reverse">reverse</code></td>
<td>
<p>either <code>TRUE</code> or <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>

<hr>
<h2 id='TRC'>Transformed rank correlations for multivariate outlier detection</h2><span id='topic+TRC'></span>

<h3>Description</h3>

<p><code>TRC</code> starts from bivariate Spearman correlations and obtains
a positive definite covariance matrix by back-transforming robust
univariate medians and mads of the eigenspace. <code>TRC</code> can cope
with missing values by a regression imputation using the a robust
regression on the best predictor and it takes sampling weights
into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TRC(
  data,
  weights,
  overlap = 3,
  mincor = 0,
  robust.regression = "rank",
  gamma = 0.5,
  prob.quantile = 0.75,
  alpha = 0.05,
  md.type = "m",
  monitor = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TRC_+3A_data">data</code></td>
<td>
<p>a data frame or matrix with the data.</p>
</td></tr>
<tr><td><code id="TRC_+3A_weights">weights</code></td>
<td>
<p>sampling weights.</p>
</td></tr>
<tr><td><code id="TRC_+3A_overlap">overlap</code></td>
<td>
<p>minimum number of jointly observed values for calculating
the rank correlation.</p>
</td></tr>
<tr><td><code id="TRC_+3A_mincor">mincor</code></td>
<td>
<p>minimal absolute correlation to impute.</p>
</td></tr>
<tr><td><code id="TRC_+3A_robust.regression">robust.regression</code></td>
<td>
<p>type of regression: <code>"irls"</code> is iteratively
reweighted least squares M-estimator, <code>"rank"</code> is based on the rank
correlations.</p>
</td></tr>
<tr><td><code id="TRC_+3A_gamma">gamma</code></td>
<td>
<p>minimal number of jointly observed values to impute.</p>
</td></tr>
<tr><td><code id="TRC_+3A_prob.quantile">prob.quantile</code></td>
<td>
<p>if mads are 0, try this quantile of absolute deviations.</p>
</td></tr>
<tr><td><code id="TRC_+3A_alpha">alpha</code></td>
<td>
<p><code>(1 - alpha)</code> Quantile of F-distribution is used for cut-off.</p>
</td></tr>
<tr><td><code id="TRC_+3A_md.type">md.type</code></td>
<td>
<p>type of Mahalanobis distance when missing values occur:
<code>"m"</code> marginal (default), <code>"c"</code> conditional.</p>
</td></tr>
<tr><td><code id="TRC_+3A_monitor">monitor</code></td>
<td>
<p>if <code>TRUE</code>, verbose output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>TRC</code> is similar to a one-step OGK estimator where the starting
covariances are obtained from rank correlations and an ad hoc missing
value imputation plus weighting is provided.
</p>


<h3>Value</h3>

<p><code>TRC</code> returns a list whose first component <code>output</code> is a
sublist with the following components:
</p>

<dl>
<dt><code>sample.size</code></dt><dd><p>Number of observations</p>
</dd>
<dt><code>number.of.variables</code></dt><dd><p>Number of variables</p>
</dd>
<dt><code>number.of.missing.items</code></dt><dd><p>Number of missing values</p>
</dd>
<dt><code>significance.level</code></dt><dd><p><code>1 - alpha</code></p>
</dd>
<dt><code>computation.time</code></dt><dd><p>Elapsed computation time</p>
</dd>
<dt><code>medians</code></dt><dd><p>Componentwise medians</p>
</dd>
<dt><code>mads</code></dt><dd><p>Componentwise mads</p>
</dd>
<dt><code>center</code></dt><dd><p>Location estimate</p>
</dd>
<dt><code>scatter</code></dt><dd><p>Covariance estimate</p>
</dd>
<dt><code>robust.regression</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>md.type</code></dt><dd><p>Input parameter</p>
</dd>
<dt><code>cutpoint</code></dt><dd><p>The default threshold MD-value for the cut-off of outliers</p>
</dd>
</dl>

<p>The further components returned by <code>TRC</code> are:
</p>

<dl>
<dt><code>outind</code></dt><dd><p>Indicator of outliers</p>
</dd>
<dt><code>dist</code></dt><dd><p>Mahalanobis distances (with missing values)</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Béguin, C. and Hulliger, B. (2004) Multivariate outlier detection in
incomplete survey data: the epidemic algorithm and transformed rank correlations,
JRSS-A, 167, Part 2, pp. 275-294.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem, bushfire.weights)
det.res &lt;- TRC(bushfirem, weights = bushfire.weights)
PlotMD(det.res$dist, ncol(bushfirem))
print(det.res)
</code></pre>

<hr>
<h2 id='weighted.quantile'>Quantiles of a weighted cdf</h2><span id='topic+weighted.quantile'></span>

<h3>Description</h3>

<p>A weighted cdf is calculated and quantiles are evaluated. Missing values are discarded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile(x, w, prob = 0.5, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.quantile_+3A_x">x</code></td>
<td>
<p>a vector of data.</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_w">w</code></td>
<td>
<p>a vector of (sampling) weights.</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_prob">prob</code></td>
<td>
<p>the probability for the quantile.</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, the weighted cdf is plotted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Weighted linear interpolation in case of non-unique inverse. Gives a warning when the
contribution of the weight of the smallest observation to the total weight is larger
than <code>prob</code>.
</p>


<h3>Value</h3>

<p>The quantile according to <code>prob</code> (by default it returns the weighted median).
</p>


<h3>Note</h3>

<p>No variance calculation.
</p>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>See Also</h3>

<p><a href="https://www.rdocumentation.org/packages/survey/versions/3.33-2/topics/svyquantile">svyquantile</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
x[sample(1:100, 20)] &lt;- NA
w &lt;- rchisq(100, 2)
weighted.quantile(x, w, 0.2, TRUE)
</code></pre>

<hr>
<h2 id='weighted.var'>Weighted univariate variance coping with missing values</h2><span id='topic+weighted.var'></span>

<h3>Description</h3>

<p>This function is analogous to weighted.mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.var(x, w, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.var_+3A_x">x</code></td>
<td>
<p>a vector of data.</p>
</td></tr>
<tr><td><code id="weighted.var_+3A_w">w</code></td>
<td>
<p>a vector of positive weights (may not have missings where x is observed).</p>
</td></tr>
<tr><td><code id="weighted.var_+3A_na.rm">na.rm</code></td>
<td>
<p>if <code>TRUE</code> remove missing values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The weights are standardised such that <code class="reqn">\sum_{observed} w_i</code> equals the number of observed
values in <code class="reqn">x</code>. The function calculates </p>
<p style="text-align: center;"><code class="reqn">\sum_{observed} w_i(x_i -
weighted.mean(x, w, na.rm = TRUE))^2/((\sum_{observed} w_i) - 1)</code>
</p>



<h3>Value</h3>

<p>The weighted variance of <code>x</code> with weights <code>w</code> (with missing values removed
when <code>na.rm = TRUE</code>).
</p>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>See Also</h3>

<p><a href="http://stat.ethz.ch/R-manual/R-devel/library/stats/html/weighted.mean.html">weighted.mean</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
x[sample(1:100, 20)] &lt;- NA
w &lt;- rchisq(100, 2)
weighted.var(x, w, na.rm = TRUE)
</code></pre>

<hr>
<h2 id='weightsum'>Utility function for TRC.R among others</h2><span id='topic+weightsum'></span>

<h3>Description</h3>

<p>Sum of weights for observations &lt; value (if lt = TRUE)
or observations=value (if lt = FALSE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightsum(observations, weights, value, lt = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightsum_+3A_observations">observations</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="weightsum_+3A_weights">weights</code></td>
<td>
<p>vector of weights.</p>
</td></tr>
<tr><td><code id="weightsum_+3A_value">value</code></td>
<td>
<p>value.</p>
</td></tr>
<tr><td><code id="weightsum_+3A_lt">lt</code></td>
<td>
<p>either <code>TRUE</code> or <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beat Hulliger
</p>

<hr>
<h2 id='Winsimp'>Winsorization followed by imputation</h2><span id='topic+Winsimp'></span>

<h3>Description</h3>

<p>Winsorization of outliers according to the Mahalanobis distance
followed by an imputation under the multivariate normal model.
Only the outliers are winsorized. The Mahalanobis distance MDmiss
allows for missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Winsimp(data, center, scatter, outind, seed = 1000003)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Winsimp_+3A_data">data</code></td>
<td>
<p>a data frame with the data.</p>
</td></tr>
<tr><td><code id="Winsimp_+3A_center">center</code></td>
<td>
<p>(robust) estimate of the center (location) of the observations.</p>
</td></tr>
<tr><td><code id="Winsimp_+3A_scatter">scatter</code></td>
<td>
<p>(robust) estimate of the scatter (covariance-matrix) of the
observations.</p>
</td></tr>
<tr><td><code id="Winsimp_+3A_outind">outind</code></td>
<td>
<p>logical vector indicating outliers with 1 or TRUE for outliers.</p>
</td></tr>
<tr><td><code id="Winsimp_+3A_seed">seed</code></td>
<td>
<p>seed for random number generator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is assumed that <code>center</code>, <code>scatter</code> and <code>outind</code>
stem from a multivariate outlier detection algorithm which produces
robust estimates and which declares outliers observations with a large
Mahalanobis distance. The cutpoint is calculated as the least (unsquared)
Mahalanobis distance among the outliers. The winsorization reduces the
weight of the outliers:
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}_i = \mu_R + (y_i - \mu_R) \cdot c/d_i</code>
</p>

<p>where <code class="reqn">\mu_R</code> is the robust center and <code class="reqn">d_i</code> is the (unsquared) Mahalanobis
distance of observation i.
</p>


<h3>Value</h3>

<p><code>Winsimp</code> returns a list whose first component <code>output</code> is a
sublist with the following components:
</p>

<dl>
<dt><code>cutpoint</code></dt><dd><p>Cutpoint for outliers</p>
</dd>
<dt><code>proc.time</code></dt><dd><p>Processing time</p>
</dd>
<dt><code>n.missing.before</code></dt><dd><p>Number of missing values before imputation</p>
</dd>
<dt><code>n.missing.after</code></dt><dd><p>Number of missing values after imputation</p>
</dd>
</dl>

<p>The further component returned by <code>winsimp</code> is:
</p>

<dl>
<dt><code>imputed.data</code></dt><dd><p>Imputed data set</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Beat Hulliger
</p>


<h3>References</h3>

<p>Hulliger, B. (2007), Multivariate Outlier Detection and Treatment
in Business Surveys, Proceedings of the III International Conference on
Establishment Surveys, Montréal.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MDmiss">MDmiss</a></code>. Uses <code><a href="norm.html#topic+imp.norm">imp.norm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfirem, bushfire.weights)
det.res &lt;- TRC(bushfirem, weight = bushfire.weights)
imp.res &lt;- Winsimp(bushfirem, det.res$center, det.res$scatter, det.res$outind)
print(imp.res$n.missing.after)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
