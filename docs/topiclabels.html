<!DOCTYPE html><html lang="en"><head><title>Help for package topiclabels</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {topiclabels}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#topiclabels-package'><p>Automated Topic Labeling with Language Models</p></a></li>
<li><a href='#as.lm_topic_labels'><p>lm_topic_labels object</p></a></li>
<li><a href='#label_topics'><p>Automatically label topics using language models based on top terms</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Automated Topic Labeling with Language Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-10-21</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jonas Rieger &lt;rieger@statistik.tu-dortmund.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Leveraging (large) language models for automatic topic labeling. The main function converts a list of top terms into a label for each topic. Hence, it is complementary to any topic modeling package that produces a list of top terms for each topic. While human judgement is indispensable for topic validation (i.e., inspecting top terms and most representative documents), automatic topic labeling can be a valuable tool for researchers in various scenarios.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>checkmate (&ge; 1.8.5), httr, progress, stats, jsonlite</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/PetersFritz/topiclabels">https://github.com/PetersFritz/topiclabels</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/PetersFritz/topiclabels/issues">https://github.com/PetersFritz/topiclabels/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-21 14:06:56 UTC; riege</td>
</tr>
<tr>
<td>Author:</td>
<td>Jonas Rieger <a href="https://orcid.org/0000-0002-0007-4478"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Fritz Peters <a href="https://orcid.org/0009-0003-8471-4931"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Andreas Fischer <a href="https://orcid.org/0009-0006-0748-6076"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Tim Lauer <a href="https://orcid.org/0009-0003-1625-1672"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  André Bittermann <a href="https://orcid.org/0000-0003-2942-9831"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-21 14:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='topiclabels-package'>Automated Topic Labeling with Language Models</h2><span id='topic+topiclabels'></span><span id='topic+topiclabels-package'></span>

<h3>Description</h3>

<p>Leveraging (large) language models for automatic topic labeling.
The main function converts a list of top terms into a label for each topic.
Hence, it is complementary to any topic modeling package that produces a list
of top terms for each topic. While human judgement is indispensable for
topic validation (i.e., inspecting top terms and most representative documents),
automatic topic labeling can be a valuable tool for researchers in various scenarios.
</p>


<h3>Labeling function</h3>

<p><code><a href="#topic+label_topics">label_topics</a></code>
</p>


<h3>Constructor</h3>

<p><code><a href="#topic+as.lm_topic_labels">as.lm_topic_labels</a></code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jonas Rieger <a href="mailto:rieger@statistik.tu-dortmund.de">rieger@statistik.tu-dortmund.de</a> (<a href="https://orcid.org/0000-0002-0007-4478">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Fritz Peters <a href="mailto:fpeters3@sheffield.ac.uk">fpeters3@sheffield.ac.uk</a> (<a href="https://orcid.org/0009-0003-8471-4931">ORCID</a>)
</p>
</li>
<li><p> Andreas Fischer <a href="mailto:andreasfischer1985@web.de">andreasfischer1985@web.de</a> (<a href="https://orcid.org/0009-0006-0748-6076">ORCID</a>)
</p>
</li>
<li><p> Tim Lauer <a href="mailto:tl@leibniz-psychology.org">tl@leibniz-psychology.org</a> (<a href="https://orcid.org/0009-0003-1625-1672">ORCID</a>)
</p>
</li>
<li><p> André Bittermann <a href="mailto:abi@leibniz-psychology.org">abi@leibniz-psychology.org</a> (<a href="https://orcid.org/0000-0003-2942-9831">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/PetersFritz/topiclabels">https://github.com/PetersFritz/topiclabels</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/PetersFritz/topiclabels/issues">https://github.com/PetersFritz/topiclabels/issues</a>
</p>
</li></ul>


<hr>
<h2 id='as.lm_topic_labels'>lm_topic_labels object</h2><span id='topic+as.lm_topic_labels'></span><span id='topic+is.lm_topic_labels'></span>

<h3>Description</h3>

<p>Constructor for lm_topic_labels objects used in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.lm_topic_labels(
  x,
  terms,
  prompts,
  model,
  params,
  with_token,
  time,
  model_output,
  labels
)

is.lm_topic_labels(obj, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.lm_topic_labels_+3A_x">x</code></td>
<td>
<p>[<code>named list</code>]<br />
<code><a href="#topic+as.lm_topic_labels">lm_topic_labels</a></code> object. Alternatively each element can be passed for
individual results. Individually set elements overwrite elements from <code>x</code>.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_terms">terms</code></td>
<td>
<p>[<code>list(n) of character</code>]<br />
List of <code>character</code> vectors, whereas each vector represents the top terms
of a topic. Topics may consist of different numbers of top terms.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_prompts">prompts</code></td>
<td>
<p>[<code>character(n)</code>]<br />
Optional.<br />
Each entry of the <code>character</code> vector contains the original prompt that
was used to obtain the corresponding entry of <code>model_output</code>.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_model">model</code></td>
<td>
<p>[<code>character(1)</code>]<br />
The language model used for labeling the topics.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_params">params</code></td>
<td>
<p>[<code>named list</code>]<br />
Optional.<br />
Model parameters passed.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_with_token">with_token</code></td>
<td>
<p>[<code>logical(1)</code>]<br />
Optional.<br />
Was the labeling executed using a Huggingface token?</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_time">time</code></td>
<td>
<p>[<code>numeric(1)</code>]<br />
Optional.<br />
Time needed for the labeling.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_model_output">model_output</code></td>
<td>
<p>[<code>character(n)</code>]<br />
Optional.<br />
Each entry of the <code>character</code> vector contains the original model output
obtained using the corresponding prompt from <code>prompts</code>.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_labels">labels</code></td>
<td>
<p>[<code>character(n)</code>]<br />
The extracted labels from <code>model_output</code>.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_obj">obj</code></td>
<td>
<p>[<code>R</code> object]<br />
Object to test.</p>
</td></tr>
<tr><td><code id="as.lm_topic_labels_+3A_verbose">verbose</code></td>
<td>
<p>[<code>logical(1)</code>]<br />
Should test information be given in the console?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you call <code>as.lm_topic_labels</code> on an object <code>x</code> which already is of
the structure of a <code>lm_topic_labels</code> object (in particular a <code>lm_topic_labels</code>
object itself), the additional arguments <code>id, param, ...</code>
may be used to override the specific elements.
</p>


<h3>Value</h3>

<p>[<code>named list</code>] <code><a href="#topic+as.lm_topic_labels">lm_topic_labels</a></code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
token = "" # please insert your hf token here
topwords_matrix = matrix(c("zidane", "figo", "kroos",
                           "gas", "power", "wind"), ncol = 2)
obj = label_topics(topwords_matrix, token = token)
obj$model
obj_modified = as.lm_topic_labels(obj, model = "It is possible to modify individual entries")
obj_modified$model

obj_modified$model = 3.5 # example for an invalid modification
is.lm_topic_labels(obj_modified, verbose = TRUE)

obj_manual = as.lm_topic_labels(terms = list(c("zidane", "figo", "kroos"),
                                             c("gas", "power", "wind")),
                                model = "manual labels",
                                labels = c("Football Players", "Energy Supply"))

## End(Not run)
</code></pre>

<hr>
<h2 id='label_topics'>Automatically label topics using language models based on top terms</h2><span id='topic+label_topics'></span><span id='topic+label_topics.default'></span><span id='topic+label_topics.labelTopics'></span>

<h3>Description</h3>

<p>Performs an automated labeling process of topics from topic models using
language models. For this, the top terms and (optionally) a short context
description are used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>label_topics(...)

## Default S3 method:
label_topics(
  terms,
  model = "mistralai/Mixtral-8x7B-Instruct-v0.1",
  params = list(),
  token = NA_character_,
  context = "",
  sep_terms = "; ",
  max_length_label = 5L,
  prompt_type = c("json", "plain", "json-roles"),
  max_wait = 0L,
  progress = TRUE,
  ...
)

## S3 method for class 'labelTopics'
label_topics(terms, stm_type = c("prob", "frex", "lift", "score"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="label_topics_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
<tr><td><code id="label_topics_+3A_terms">terms</code></td>
<td>
<p>[<code>list (k) of character</code>]<br />
List (each list entry represents one topic) of <code>character</code> vectors
containing the top terms representing the topics that are to be labeled.
If a single <code>character</code> vector is passed, this is interpreted as
the top terms of a single topic. If a <code>character</code> matrix is passed,
each column is interpreted as the top terms of a topic.
The outputs of the packages <code>stm</code> (<code>label_topics</code> object, please
specify the type of output using the parameter <code>stm_type</code>) and the
<code>BTM</code> package (<code>list</code> of <code>data.frame</code>s with entries
<code>token</code> and <code>probability</code> each) are also supported.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_model">model</code></td>
<td>
<p>[<code>character(1)</code>]<br />
Optional.<br />
The language model to use for labeling the topics.
The model must be accessible via the Huggingface API. Default is
<code>mistralai/Mixtral-8x7B-Instruct-v0.1</code>. Other promising models are
<code>HuggingFaceH4/zephyr-7b-beta</code> or <code>tiiuae/falcon-7b-instruct</code>.
To find more models see: https://huggingface.co/models?other=conversational&amp;sort=likes.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_params">params</code></td>
<td>
<p>[<code>named list</code>]<br />
Optional.<br />
Model parameters to pass. Default parameters for common models are
given in the details section.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_token">token</code></td>
<td>
<p>[<code>character(1)</code>]<br />
Optional.<br />
If you want to address the Huggingface API with a Huggingface token, enter
it here. The main advantage of this is a higher rate limit.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_context">context</code></td>
<td>
<p>[<code>character(1)</code>]<br />
Optional.<br />
Explanatory context for the topics to be labeled. Using a (very) brief
explanation of the thematic context may greatly improve the usefulness of
automatically generated topic labels.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_sep_terms">sep_terms</code></td>
<td>
<p>[<code>character(1)</code>]<br />
How should the top terms of a single topic be separated in the generated
prompts? Default is separation via semicolon and space.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_max_length_label">max_length_label</code></td>
<td>
<p>[<code>integer(1)</code>]<br />
What is the maximum number of words a label should consist of? Default is five words.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_prompt_type">prompt_type</code></td>
<td>
<p>[<code>character(1)</code>]<br />
Which prompt type should be applied. We implemented various prompt types that
differ mainly in how the response of the language model is requested. Examples
are given in the details section. Default is the request of a json output.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_max_wait">max_wait</code></td>
<td>
<p>[<code>integer(1)</code>]<br />
In the case that the rate limit on Huggingface is reached: How long
(in minutes) should the system wait until it asks the user whether
to continue (in other words: to wait). The default is zero minutes, i.e the
user is asked every time the rate limit is reached.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_progress">progress</code></td>
<td>
<p>[<code>logical(1)</code>]<br />
Should a nice progress bar be shown? Turning it off, could lead to
significantly faster calculation. Default ist <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="label_topics_+3A_stm_type">stm_type</code></td>
<td>
<p>[<code>character(1)</code>]<br />
For stm topics, which type of word weighting should be used? Default is &quot;prob&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function builds helpful prompts based on the top terms and sends these
prompts to language models on Huggingface. The output is in turn
post-processed so that the labels for each topic are extracted automatically.
If the automatically extracted labels show any errors, they can alternatively
be extracted using custom functions or manually from the original output of
the model using the <code>model_output</code> entry of the lm_topic_labels object.
</p>
<p>Implemented default parameters for the models <code>HuggingFaceH4/zephyr-7b-beta</code>,
<code>tiiuae/falcon-7b-instruct</code>, and <code>mistralai/Mixtral-8x7B-Instruct-v0.1</code> are:
</p>

<dl>
<dt><code>max_new_tokens</code></dt><dd><p>300</p>
</dd>
<dt><code>return_full_text</code></dt><dd><p><code>FALSE</code></p>
</dd>
</dl>

<p>Implemented prompt types are:
</p>

<dl>
<dt><code>json</code></dt><dd><p>the language model is asked to respond in JSON format
with a single field called 'label', specifying the best label for the topic</p>
</dd>
<dt><code>plain</code></dt><dd><p>the language model is asked to return an answer that
should only consist of the best label for the topic</p>
</dd>
<dt><code>json-roles</code></dt><dd><p>the language model is asked to respond in JSON format
with a single field called 'label', specifying the best label for the topic;
in addition, the model is queried using identifiers for &lt;|user|&gt; input and
the beginning of the &lt;|assistant|&gt; output</p>
</dd>
</dl>



<h3>Value</h3>

<p>[<code>named list</code>] <code><a href="#topic+as.lm_topic_labels">lm_topic_labels</a></code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
token = "" # please insert your hf token here
topwords_matrix = matrix(c("zidane", "figo", "kroos",
                           "gas", "power", "wind"), ncol = 2)
label_topics(topwords_matrix, token = token)
label_topics(list(c("zidane", "figo", "kroos"),
                  c("gas", "power", "wind")),
             token = token)
label_topics(list(c("zidane", "figo", "ronaldo"),
                  c("gas", "power", "wind")),
             token = token)

label_topics(list("wind", "greta", "hambach"),
             token = token)
label_topics(list("wind", "fire", "air"),
             token = token)
label_topics(list("wind", "feuer", "luft"),
             token = token)
label_topics(list("wind", "feuer", "luft"),
             context = "Elements of the Earth",
             token = token)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
