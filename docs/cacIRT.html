<!DOCTYPE html><html><head><title>Help for package cacIRT</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cacIRT}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cacIRT-package'>
<p>Classification accuracy and consistency under Item Response Theory</p></a></li>
<li><a href='#class.Lee'>
<p>Computes classification accuracy and consistency with Lee's approach.</p></a></li>
<li><a href='#class.Rud'>
<p>Computes classification accuracy and consistency with Rudner's approach.</p></a></li>
<li><a href='#Lee.poly'>
<p>Computes classification accuracy and consistency with Lee's approach for polytomous IRT models.</p></a></li>
<li><a href='#Nonparametric Approach to CA and CC'>
<p>Computes classification accuracy and consistency using Lathrop and Cheng's (2014) nonparametric approach.</p></a></li>
<li><a href='#recursive.raw'>
<p>Recursive computation of conditional total score</p></a></li>
<li><a href='#Useful IRT Functions'>
<p>A collection of useful IRT functions.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Classification Accuracy and Consistency under Item Response
Theory</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-08-15</td>
</tr>
<tr>
<td>Author:</td>
<td>Quinn N. Lathrop</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Quinn N. Lathrop &lt;quinn.lathrop@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes classification accuracy and consistency indices under Item Response Theory. Implements the total score IRT-based methods in Lee, Hanson &amp; Brennen (2002) and Lee (2010), the IRT-based methods in Rudner (2001, 2005), and the total score nonparametric methods in Lathrop &amp; Cheng (2014). For dichotomous and polytomous tests.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2015-08-27 16:50:46 UTC; quinn.lathrop</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2015-08-28 01:08:33</td>
</tr>
</table>
<hr>
<h2 id='cacIRT-package'>
Classification accuracy and consistency under Item Response Theory
</h2><span id='topic+cacIRT-package'></span><span id='topic+cacIRT'></span>

<h3>Description</h3>

<p>Computes classification accuracy and consistency under Item Response Theory by the approach proposed by Lee, Hanson &amp; Brennen (2002) and Lee (2010), the approach proposed by Rudner (2001, 2005), and the approach proposed by Lathrop &amp; Cheng (2014).
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> cacIRT</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2015-08-15</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>This packages computes classification accuracy and consistency indices with two approaches proposed by Lee, Hanson &amp; Brennan (2002) and Lee (2010) or by Rudner (2001, 2005). The two functions <code>class.Lee()</code> and <code>class.Rud()</code> are the wrapper functions for the most common implementations of the respective approaches. They accept a range of inputs: ability estimates, quadrature points, or response data matrix and item parameters. Marginal indices are computed with either the D (using a theoretical or simulated distribution) or P (using the sample directly) method (see Lee (2010)). The function <code>recursive.raw()</code> computes the probabilities of total scores given ability and item parameters and may be of interest outside of classification.
</p>
<p>The major difference between the Lee approach and the Rudner approach is the scale that the classification occurs on. The Lee approach uses the total score scale, and finds the probability of each total score given an examinee's latent ability estimate and the item parameters. The cut score is also given as a total score. The Rudner approach occurs on the latent trait scale, and is given a cut score on the latent trait scale. Dispite their similarities, the two estimators generally do not estimate the same index, see Lathrop &amp; Cheng (2013) and Lathrop (2015) for discussion and simulation studies.
</p>
<p>A new nonparametric approach is also provided with <code>pnr()</code> and <code>Lee.pnr()</code>. It is a nonparametric extension to the Lee approach and is explained and tested in Lathrop &amp; Cheng (2014). This approach does not require an assumption of a parametric IRT model or a parametric ability distribution and is often more accurate when those assumptions are violated compared to parametric approaches.
</p>
<p>Polytomous tests (where item responses are in more categories than two ordered categories) are easily computed with <code>Lee.pnr()</code> and <code>class.Rud</code>. To use Lee's (2010) approach with polytomous or mixed format tests, use <code>Lee.poly.P()</code>, <code>Lee.poly.D()</code>, and/or <code>gen.rec.raw()</code>.
</p>


<h3>Author(s)</h3>

<p>Quinn N. Lathrop
</p>
<p>Maintainer: &lt;quinn.lathrop @ gmail.edu&gt;
</p>


<h3>References</h3>

<p>Lathrop, Q. N., &amp; Cheng, Y. (2013) Two Approaches to Estimation of Classification Accuracy Rate Under Item Response Theory. Applied Psychological Measurement, 37, 226-241.
</p>
<p>Lathrop, Q. N., &amp; Cheng, Y. (2014). A Nonparametric Approach to Estimate Classification Accuracy and Consistency. Journal of Educational Measurement, 51(3), 318-334.
</p>
<p>Lee, W. (2010) Classification consistency and accuracy for complex assessments using item response theory. Journal of Educational Measurement, 47, 1-17.
</p>
<p>Lee, W., Hanson, B. A., &amp; Brennan, R. L. (2002) Estimating consistency and accuracy indices for multiple classifications. Applied Psychological Measurement, 26, 412-432.
</p>
<p>Lee, W., &amp; Kolen, M. J. (2008) IRT-class: IRT classification consistency and accuracy (version 2.0). 
</p>
<p>Rudner, L. M. (2001) Computing the expected proportions of misclassified examinees. Practical Assessment, Research &amp; Evaluation, 7(14), 1-5. 
</p>
<p>Rudner, L. M. (2005) Expected classification accuracy. Practical Assessment Research &amp; Evaluation, 10(13), 1-4.
</p>

<hr>
<h2 id='class.Lee'>
Computes classification accuracy and consistency with Lee's approach.
</h2><span id='topic+class.Lee'></span><span id='topic+Lee.D'></span><span id='topic+Lee.P'></span>

<h3>Description</h3>

<p>Computes classification accuracy and consistency with Lee's approach. The probability of each possible total score conditional on ability is found with  <code>recursive.raw</code>. Those probabilities are grouped according to the cut scores and used to estimate the indices. See references or code for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>class.Lee(cutscore, ip, ability = NULL, rdm = NULL, quadrature = NULL, D = 1.7)
Lee.D(cutscore,  ip, quadrature, D = 1.7)
Lee.P(cutscore,  ip, theta, D = 1.7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="class.Lee_+3A_cutscore">cutscore</code></td>
<td>

<p>A scalar or vector of cut scores on the True Score scale. If you have cut scores on the theta scale, you can transform them with <code>irf</code> (See example for <code>irf</code>). Should not include 0 or the max total score, as the end points are added internally.
</p>
</td></tr>
<tr><td><code id="class.Lee_+3A_ip">ip</code></td>
<td>

<p>Matrix of item parameters, columns are discrimination, difficultly, guessing, respectively. For 1PL and 2PL, still give a Jx3 matrix, with <code>ip[,1] = 1</code> and <code>ip[,3] = 0</code> for the 1PL for example.
</p>
</td></tr>
<tr><td><code id="class.Lee_+3A_ability">ability</code>, <code id="class.Lee_+3A_theta">theta</code></td>
<td>

<p>Ability estimates for each subject.
</p>
</td></tr>
<tr><td><code id="class.Lee_+3A_rdm">rdm</code></td>
<td>

<p>The response data matrix with rows as subjects and columns as items
</p>
</td></tr>
<tr><td><code id="class.Lee_+3A_quadrature">quadrature</code></td>
<td>

<p>A list containing 1) The quadrature points and 2) Their corresponding weights
</p>
</td></tr>
<tr><td><code id="class.Lee_+3A_d">D</code></td>
<td>

<p>Scaling constant for IRT parameters, defaults to 1.7, alternatively often set to 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Must give only one ability, rdm, or quadrature. If ability is given, those scores are used for the P method. If rdm is given, ability is estimated with MLE (perfect response patterns given a -4 or 4) and used for the P method. If quadrature, the D method is used. <code>class.Lee</code> calls <code>Lee.D</code> or <code>Lee.P</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Marginal</code></td>
<td>
<p>A matrix with two columns of marginal accuracy and consistency per cut score (and simultaneous if multiple cutscores are given)</p>
</td></tr>
<tr><td><code>Conditional</code></td>
<td>
<p>A list of two matrixes, one for conditional accuracy and  one for conditional consistency. Each matrix has one row per subject (or quadrature point).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In order to score above a cut, an examinee must score at or above the cut score. Since we are working on the total score scale, be aware that if a cut score is given with a decimal (like 2.4), the examinee must have a total score at the next integer or more (so 3 or more) to score above the cut.
</p>


<h3>Author(s)</h3>

<p>Quinn N. Lathrop</p>


<h3>References</h3>

<p>Lee, W. (2010) Classification consistency and accuracy for complex assessments using item response theory. Journal of Educational Measurement, 47, 1&ndash;17.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##from rdm, item parameters denote 4 item 1PL test, cut score at x=2
##only print marginal indices

params&lt;-matrix(c(1,1,1,1,-2,1,0,1,0,0,0,0),4,3)
rdm&lt;-sim(params, rnorm(100))

class.Lee(2, params, rdm = rdm)$Marginal

##or from 40 quadrature points and weights, 2 cut scores

quad &lt;- normal.qu(40)

class.Lee(c(2,3), params, quadrature = quad, D = 1)$Marginal


</code></pre>

<hr>
<h2 id='class.Rud'>
Computes classification accuracy and consistency with Rudner's approach.
</h2><span id='topic+class.Rud'></span><span id='topic+Rud.P'></span><span id='topic+Rud.D'></span>

<h3>Description</h3>

<p>Computes classification accuracy and consistency with Rudner's approach. For each examinee, a normal distribution is created with mean at the ability estimate and standard deviation equal to the standard error of the ability estimate. Rudner's method assumes the standard error is conditionally normally distributed. The area under this normal curve between cut scores is used to estimate the indices. See references.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>class.Rud(cutscore, ip, ability = NULL, se = NULL, rdm = NULL, quadrature = NULL, D = 1.7)
Rud.D(cutscore, quadrature, sem)
Rud.P(cutscore, theta, sem)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="class.Rud_+3A_cutscore">cutscore</code></td>
<td>

<p>A scalar or vector of cut scores on the theta scale. Should not include +- inf, the function will include them.
</p>
</td></tr>
<tr><td><code id="class.Rud_+3A_ip">ip</code></td>
<td>

<p>Matrix of item parameters, columns are discrimination, difficultly, guessing. For 1PL and 2PL, still give a Jx3 matrix, with <code>ip[,1] = 1</code> and <code>ip[,3] = 0</code> for example.
</p>
</td></tr>
<tr><td><code id="class.Rud_+3A_ability">ability</code>, <code id="class.Rud_+3A_theta">theta</code></td>
<td>

<p>Ability estimates for each subject.
</p>
</td></tr>
<tr><td><code id="class.Rud_+3A_se">se</code>, <code id="class.Rud_+3A_sem">sem</code></td>
<td>

<p>Standard errors of ability estimates
</p>
</td></tr>
<tr><td><code id="class.Rud_+3A_rdm">rdm</code></td>
<td>

<p>The response data matrix with rows as subjects and columns as items
</p>
</td></tr>
<tr><td><code id="class.Rud_+3A_quadrature">quadrature</code></td>
<td>

<p>A list containing [[1]] The quadrature points and [[2]] Their corresponding weights
</p>
</td></tr>
<tr><td><code id="class.Rud_+3A_d">D</code></td>
<td>

<p>The scaling constant for the IRT parameters, defaults to 1.7, alternatively often set to 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Must give only ability and se, rdm, or quadrature. If ability and se are given, those scores are used for the P method. If rdm is given, ability and se are estimated with MLE (perfect response patterns given a -4 or 4) and used for the P method. If quadrature, the D method is used. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Marginal</code></td>
<td>
<p>A matrix with two columns of marginal accuracy and consistency per cut score and/or simultaneous</p>
</td></tr>
<tr><td><code>Conditional</code></td>
<td>
<p>A list of two matrixes, one for conditional accuracy and  one for conditional consistency. Each matrix has one row per subject (or quadrature point).</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>class.Rud</code> is a wrapper for <code>Rud.P</code> and <code>Rud.D</code>.
</p>


<h3>Author(s)</h3>

<p>Quinn Lathrop
</p>


<h3>References</h3>

<p>Rudner, L. M. (2001) Computing the expected proportions of misclassified examinees. Practical Assessment, Research &amp; Evaluation, <b>7(14)</b>, 1&ndash;5. 
</p>
<p>Rudner, L. M. (2005) Expected classification accuracy. Practical Assessment Research &amp; Evaluation, <b>10(13)</b>, 1&ndash;4.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##from rdm, item parameters denote 4 item 1PL test, cut score at theta=.5
##only return marginal indices

params&lt;-matrix(c(1,1,1,1,-2,1,0,1,0,0,0,0),4,3)
rdm&lt;-sim(params, rnorm(100))

class.Rud(.5, params, rdm = rdm)$Marginal

##or from 40 quadrature points and weights, 2 cut scores

quad &lt;- normal.qu(40)

class.Rud(c(-.5,1.5), params, quadrature = quad, D = 1)$Marginal

</code></pre>

<hr>
<h2 id='Lee.poly'>
Computes classification accuracy and consistency with Lee's approach for polytomous IRT models.
</h2><span id='topic+Lee.poly.D'></span><span id='topic+Lee.poly.P'></span>

<h3>Description</h3>

<p>Computes classification accuracy and consistency with Lee's approach for polytomous tests. The probability of each possible total score conditional on ability is found with  <code>gen.rec.raw()</code>. Those probabilities are grouped according to the cut scores and used to estimate the indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lee.poly.D(cutscore, Pij, quadrature)
Lee.poly.P(cutscore, Pij, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lee.poly_+3A_cutscore">cutscore</code></td>
<td>

<p>A scalar or vector of cut scores on the True Score scale. If you have cut scores on the theta scale, you can transform them with <code>irf</code> (See example for <code>irf</code>). Should not include 0 or the max total score, as the end points are added internally.
</p>
</td></tr>
<tr><td><code id="Lee.poly_+3A_pij">Pij</code></td>
<td>
<p>An NxMxJ array of probabilities. Each slice of the array represents an item. Within a slice, each row corresponds to the respective element in <code>theta</code> and each column represents a response category from 0, 1, ..., M. At a minimum, M=1, in which case the array is Nx2xJ and represents the dichotomous item case. 
</p>
</td></tr>
<tr><td><code id="Lee.poly_+3A_theta">theta</code></td>
<td>

<p>Ability estimates for each subject. Must correspond to the first dimension of <code>Pij</code>.
</p>
</td></tr>
<tr><td><code id="Lee.poly_+3A_quadrature">quadrature</code></td>
<td>

<p>A list containing 1) The quadrature points and 2) Their corresponding weights. Must correspond to the first dimension of <code>Pij</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The polytomous generalization to <code>class.Lee</code>. Requires the user build the <code>Pij</code> array.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Marginal</code></td>
<td>
<p>A matrix with two columns of marginal accuracy and consistency per cut score (and simultaneous if multiple cutscores are given)</p>
</td></tr>
<tr><td><code>Conditional</code></td>
<td>
<p>A matrix of conditional accuracy and conditional consistency</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In order to score above a cut, an examinee must score at or above the cut score. Since we are working on the total score scale, be aware that if a cut score is given with a decimal (like 2.4), the examinee must have a total score at the next integer or more (so 3 or more) to score above the cut.
</p>
<p>If the test is mixed format (some dichotomous, some polytomous items), <code>Pij</code> must be of an appropriate size for the item with the most response categories. The response categories that do no appear in other items can be filled with zeros. Note also that the function assumes response categories are scored as 0,1,2,3,...,M
</p>


<h3>Note</h3>

<p>While this function is needed for polytomous tests for the Lee approach, <code>class.Rud()</code> works directly with polytomous tests when given the ability estimate and the standard error and so does not need an analogous set of functions.</p>


<h3>Author(s)</h3>

<p>Quinn N. Lathrop</p>


<h3>References</h3>

<p>Lee, W. (2010) Classification consistency and accuracy for complex assessments using item response theory. Journal of Educational Measurement, 47, 1&ndash;17.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Same example as \code{class.Lee()}, 
  #build \code{Pij} the same as in the example for \code{gen.rec.raw()}.

params &lt;- matrix(c(1,1,1,1,-2,1,0,1,0,0,0,0),4,3)
theta &lt;- rnorm(100)

Pij.flat &lt;- irf(params, theta)$f
Pij.array &lt;- array(NA, dim = c(length(theta), 2, nrow(params)))
Pij.array[,1,] &lt;- 1 - Pij.flat #P(X_j = 0 | theta_i)
Pij.array[,2,] &lt;- Pij.flat     #P(X_j = 1 | theta_i)

Lee.poly.P(2, Pij.array, theta)$Marginal

#in the dichotomous case, identical to \code{Lee.P()}
Lee.P(2, params, theta)$Marginal

#For Rudner and polytomous tests, compute the theta estimate and se and use those as input
theta.est &lt;- theta 
#just for example

theta.se &lt;- SEM(params, theta.est) 
#also for example, SEM() assumes 3PL model, 
#but if you use mirt or similar package, 
#the theta estimates and their se will be available

Rud.P(.5, theta.est, theta.se)$Marginal

</code></pre>

<hr>
<h2 id='Nonparametric+20Approach+20to+20CA+20and+20CC'>
Computes classification accuracy and consistency using Lathrop and Cheng's (2014) nonparametric approach.
</h2><span id='topic+Lee.pnr'></span><span id='topic+pnr'></span>

<h3>Description</h3>

<p>Computes classification accuracy and consistency with Lathrop &amp; Cheng's (2014) approach. First, the kernel-smoothed estimate of the probability of a correct response, conditional on observed total score, is found with <code>pnr()</code>. Then, the method proceeds similar to <code>class.Lee()</code>. Using the nonparametric approach does not require a parametric IRT model, keeps the problem on the total score scale, and can produce more accurate CA and CC estimates when the IRT model's assumptions are violated (see Lathrop &amp; Cheng, 2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lee.pnr(cutscore, pnr.out)
pnr(resp, bw.g = NULL, alpha = .5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Nonparametric+2B20Approach+2B20to+2B20CA+2B20and+2B20CC_+3A_cutscore">cutscore</code></td>
<td>

<p>A scalar or vector of cut scores on the total score scale. Should not include 0 or the max total score, as the end points are added internally.
</p>
</td></tr>
<tr><td><code id="Nonparametric+2B20Approach+2B20to+2B20CA+2B20and+2B20CC_+3A_pnr.out">pnr.out</code></td>
<td>

<p>The output from <code>pnr()</code>. It is a list of length 3 where
</p>
<p><code>pnr.out[[1]]</code> is a vector of T evaluation points on the total score scale (integers from 0 to the max total score)
</p>
<p><code>pnr.out[[2]]</code> is a vector of the observed density at each evaluation point
</p>
<p><code>pnr.out[[3]]</code> is a TxMxJ array. Each slice is an item. Within a slice, rows are for evaluation points and columns are for the probability of the score category. This has a similar structure to <code>Pij</code> seen in <code>Lee.poly()</code>
</p>
</td></tr>
<tr><td><code id="Nonparametric+2B20Approach+2B20to+2B20CA+2B20and+2B20CC_+3A_resp">resp</code></td>
<td>

<p>The response data matrix with rows as subjects and columns as items. Because the method is based on total score, the method is not robust to missing data. Any <code>NA</code> in <code>resp</code> will propogate to the output.
</p>
</td></tr>
<tr><td><code id="Nonparametric+2B20Approach+2B20to+2B20CA+2B20and+2B20CC_+3A_bw.g">bw.g</code></td>
<td>

<p>The global bandwidth parameter. The default of NULL will estimate the global bandwidth with the optimal (in terms of MSE) estimate of the bandwidth for normally distributed variables. The default is generally a good starting point.
</p>
</td></tr>
<tr><td><code id="Nonparametric+2B20Approach+2B20to+2B20CA+2B20and+2B20CC_+3A_alpha">alpha</code></td>
<td>

<p>The adaptivity of the bandwidth parameter. A value of 0 means no adaptation and each evaluation point uses the value in <code>bw.g</code>. For, other values (up to and including 1), the bandwidth parameter will shrink if the evaluation point is in an area of high density and grow when the evaluation point is in an area of low density. A value of 0.5 is default and generally recommended.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Marginal</code></td>
<td>
<p>A matrix with two columns of marginal accuracy and consistency per cut score (and simultaneous if multiple cutscores are given)</p>
</td></tr>
<tr><td><code>Conditional</code></td>
<td>
<p>A list of two matrixes, one for conditional accuracy and  one for conditional consistency. Each matrix has one row per evaluation point.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function <code>pnr()</code> is modified from Ramsay's (1991) kernel-smoothed response functions, specifically because they occur conditional total score (and not conditional on a latent trait) and the addition of an adaptive bandwidth (which helps performance when the distribution of total scores is not normal.)
</p>
<p>There is no &quot;D&quot; method of marginalization (as there is for <code>class.Rud</code> and <code>class.Lee</code>). But if there is a theoretical distribution of total scores, the <code>pnr.out[[2]]</code> can be adjusted to match this theoretical distribution.
</p>


<h3>Author(s)</h3>

<p>Quinn N. Lathrop</p>


<h3>References</h3>

<p>Lathrop, Q. N., &amp; Cheng, Y. (2014). A Nonparametric Approach to Estimate Classification Accuracy and Consistency. Journal of Educational Measurement, 51(3), 318-334.
</p>
<p>Lee, W. (2010) Classification consistency and accuracy for complex assessments using item response theory. Journal of Educational Measurement, 47, 1-17.
</p>
<p>Ramsay, J. O. (1991). Kernel Smoothing Approaches to Item Characteristic Curve Estimation. Psychometrika, 56(4), 611-630.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate simple response data

params &lt;- matrix(c(1,1,1,1,-2,1,0,1,0,0,0,0),4,3)
theta &lt;- rnorm(100)
rdm &lt;- sim(params, theta)

pnr.out &lt;- pnr(rdm)

resultsNP &lt;- Lee.pnr(3, pnr.out)
</code></pre>

<hr>
<h2 id='recursive.raw'>
Recursive computation of conditional total score
</h2><span id='topic+recursive.raw'></span><span id='topic+gen.rec.raw'></span>

<h3>Description</h3>

<p>Recursively computes the probabilities of each possible total score conditional on ability.</p>


<h3>Usage</h3>

<pre><code class='language-R'>recursive.raw(ip, theta, D = 1.7)
gen.rec.raw(Pij, theta.names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recursive.raw_+3A_ip">ip</code></td>
<td>

<p>Jx3 matrix of item parameters, columns are discrimination, difficulty, and guessing; in that order.
</p>
</td></tr>
<tr><td><code id="recursive.raw_+3A_theta">theta</code></td>
<td>

<p>Vector of abilities or points to condition on.
</p>
</td></tr>
<tr><td><code id="recursive.raw_+3A_d">D</code></td>
<td>

<p>The scaling constant for the IRT parameters, defaults to 1.7, alternatively often set to 1.
</p>
</td></tr>
<tr><td><code id="recursive.raw_+3A_pij">Pij</code></td>
<td>
<p>Either: 
</p>
<p>(1) an NxJ matrix of probabilities of correct response, where each row corresponds to the respective element in <code>theta</code> and each column represents an item (as in the result of <code>irf()$f</code>)
</p>
<p>or
</p>
<p>(2) an NxMxJ array of probabilities. Each slice of the array represents an item. Within a slice, each row corresponds to the respective element in <code>theta</code> and each column represents a response category from 0, 1, ..., M. At a minimum, M=1, in which case the array is Nx2xJ and represents the dichotomous item case. 
</p>
</td></tr>
<tr><td><code id="recursive.raw_+3A_theta.names">theta.names</code></td>
<td>

<p>Optional vector to use as row.names in the output matrix. Should correspond to the first dimension of <code>Pij</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of theta points by possible total score 0,1, . . . ,J.
</p>


<h3>Note</h3>

<p>As described in Huynh 1990. 
</p>
<p>If the test is mixed format (some dichotomous, some polytomous items), to use <code>gen.rec.raw()</code>, <code>Pij</code> must be of an appropriate size for the item with the most response categories. The response categories that do no appear in other items can be filled with zeros. Note also that the function assumes response categories are scored as 0,1,2,3,...,M
</p>


<h3>Author(s)</h3>

<p>Quinn Lathrop
</p>


<h3>Examples</h3>

<pre><code class='language-R'>theta &lt;- c(-1,0, 1)
params&lt;-matrix(c(1,1,1,1,-2,1,0,1,0,0,0,0),4,3)

#using IRT model and item parameters
rec.mat &lt;- recursive.raw(params, theta)

#using user supplied probability array
Pij.flat &lt;- irf(params, theta)$f

#through matrix input
rec.mat2 &lt;- gen.rec.raw(Pij.flat, theta)

#through array input (this can be generalized to polytomous tests)
Pij.array &lt;- array(NA, dim = c(length(theta), 2, nrow(params)))

Pij.array[,1,] &lt;- 1 - Pij.flat #P(X_j = 0 | theta_i)
Pij.array[,2,] &lt;- Pij.flat     #P(X_j = 1 | theta_i)

rec.mat3 &lt;- gen.rec.raw(Pij.array, theta)

#same results
max(c(rec.mat-rec.mat3, rec.mat2-rec.mat3))
</code></pre>

<hr>
<h2 id='Useful+20IRT+20Functions'>
A collection of useful IRT functions.
</h2><span id='topic+Useful+20IRT+20Functions'></span><span id='topic+iif'></span><span id='topic+irf'></span><span id='topic+MLE'></span><span id='topic+normal.qu'></span><span id='topic+SEM'></span><span id='topic+sim'></span><span id='topic+tif'></span>

<h3>Description</h3>

<p>Modified from the package <code>irtoys</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iif(ip, x, D = 1.7)
irf(ip, x, D = 1.7)
MLE(resp, ip, D = 1.7, min= -4, max = 4)
normal.qu(n = 15, lower = -4, upper = 4, mu = 0, sigma = 1)
SEM(ip, x, D = 1.7)
sim(ip, x, D = 1.7)
tif(ip, x, D = 1.7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Useful+2B20IRT+2B20Functions_+3A_ip">ip</code></td>
<td>

<p>A Jx3 matrix of item parameters. Columns are discrimination, difficulty, and guessing</p>
</td></tr>
<tr><td><code id="Useful+2B20IRT+2B20Functions_+3A_x">x</code></td>
<td>
<p>Vector of theta points</p>
</td></tr>
<tr><td><code id="Useful+2B20IRT+2B20Functions_+3A_resp">resp</code></td>
<td>
<p>Response data matrix, subjects by items</p>
</td></tr>
<tr><td><code id="Useful+2B20IRT+2B20Functions_+3A_min">min</code>, <code id="Useful+2B20IRT+2B20Functions_+3A_max">max</code></td>
<td>
<p>MLE is undefined for perfect scores. These parameters define the range in which to search for the MLE, if the score is perfect, the min or max will be returned.</p>
</td></tr>
<tr><td><code id="Useful+2B20IRT+2B20Functions_+3A_n">n</code></td>
<td>
<p>Number of quadrature points wanted</p>
</td></tr>
<tr><td><code id="Useful+2B20IRT+2B20Functions_+3A_lower">lower</code>, <code id="Useful+2B20IRT+2B20Functions_+3A_upper">upper</code></td>
<td>
<p>Range of points wanted</p>
</td></tr>
<tr><td><code id="Useful+2B20IRT+2B20Functions_+3A_mu">mu</code>, <code id="Useful+2B20IRT+2B20Functions_+3A_sigma">sigma</code></td>
<td>
<p>The normal distribution from which points and weights are taken</p>
</td></tr>
<tr><td><code id="Useful+2B20IRT+2B20Functions_+3A_d">D</code></td>
<td>

<p>The scaling constant for the IRT parameters, defaults to 1.7, alternatively often set to 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>iif</code> gives item information, <code>irf</code> gives item response function, <code>MLE</code> returns maximum likelihood estimates of theta (perfect scores get +-4), <code>normal.qu</code> returns a list length 2 of normal quadrature points and weights, <code>SEM</code> gives the standard error of measurement at the given ability points, <code>sim</code> returns simulated response matrix, <code>tif</code> gives the test information function.
</p>


<h3>Author(s)</h3>

<p>Quinn N. Lathrop
</p>


<h3>References</h3>

<p>Partchev, I. (2014) irtoys: Simple interface to the estimation and plotting of IRT models. R package version 0.1.7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>params&lt;-matrix(c(1,1,1,1,-2,1,0,1,0,0,0,0),4,3)
rdm&lt;-sim(params, rnorm(100))

theta.hat &lt;- MLE(rdm, params)
theta.se  &lt;- SEM(rdm, params)

## transform a cut score of theta = 0 to the expected true score scale

	t.cut &lt;- 0
	x.cut &lt;- sum(irf(params, t.cut)$f)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
