<!DOCTYPE html><html lang="en-US"><head><title>Help for package glossa</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {glossa}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#buffer_polygon'><p>Enlarge/Buffer a Polygon</p></a></li>
<li><a href='#clean_coordinates'><p>Clean Coordinates of Presence/Absence Data</p></a></li>
<li><a href='#create_coords_layer'><p>Create Geographic Coordinate Layers</p></a></li>
<li><a href='#cv_bart'><p>Cross-Validation for BART Model</p></a></li>
<li><a href='#downloadActionButton'><p>Create a Download Action Button</p></a></li>
<li><a href='#export_plot_server'><p>Server Logic for Export Plot Functionality</p></a></li>
<li><a href='#export_plot_ui'><p>Create UI for Export Plot Button</p></a></li>
<li><a href='#extract_noNA_cov_values'><p>Extract Non-NA Covariate Values</p></a></li>
<li><a href='#file_input_area_server'><p>Server-side Logic for Custom File Input</p></a></li>
<li><a href='#file_input_area_ui'><p>Custom File Input UI</p></a></li>
<li><a href='#fit_bart_model'><p>Fit a BART Model Using Environmental Covariate Layers</p></a></li>
<li><a href='#generate_cv_plot'><p>Generate Cross-Validation Plot</p></a></li>
<li><a href='#generate_prediction_plot'><p>Generate Prediction Plot</p></a></li>
<li><a href='#generate_pseudo_absences'><p>Generate Pseudo-Absence Points Based on Presence Points, Covariates, and Study Area Polygon</p></a></li>
<li><a href='#get_covariate_names'><p>Get Covariate Names</p></a></li>
<li><a href='#getFprTpr'><p>Compute specificity and sensitivity</p></a></li>
<li><a href='#glossa_analysis'><p>Main Analysis Function for GLOSSA Package</p></a></li>
<li><a href='#glossa_export'><p>Export Glossa Model Results</p></a></li>
<li><a href='#invert_polygon'><p>Invert a Polygon</p></a></li>
<li><a href='#layer_mask'><p>Apply Polygon Mask to Raster Layers</p></a></li>
<li><a href='#misClassError'><p>Misclassification Error</p></a></li>
<li><a href='#optimalCutoff'><p>Compute the optimal probability cutoff score</p></a></li>
<li><a href='#pa_optimal_cutoff'><p>Optimal Cutoff for Presence-Absence Prediction</p></a></li>
<li><a href='#predict_bart'><p>Make Predictions Using a BART Model</p></a></li>
<li><a href='#read_extent_polygon'><p>Read and Validate Extent Polygon</p></a></li>
<li><a href='#read_layers_zip'><p>Load Covariate Layers from ZIP Files</p></a></li>
<li><a href='#read_presences_absences_csv'><p>Read and validate presences/absences CSV file</p></a></li>
<li><a href='#remove_duplicate_points'><p>Remove Duplicated Points from a Dataframe</p></a></li>
<li><a href='#remove_points_polygon'><p>Remove Points Inside or Outside a Polygon</p></a></li>
<li><a href='#response_curve_bart'><p>Calculate Response Curve Using BART Model</p></a></li>
<li><a href='#run_glossa'><p>Run GLOSSA Shiny App</p></a></li>
<li><a href='#sensitivity'><p>Calculate the sensitivity for a given logit model</p></a></li>
<li><a href='#sparkvalueBox'><p>Create a Sparkline Value Box</p></a></li>
<li><a href='#specificity'><p>Calculate the specificity for a given logit model</p></a></li>
<li><a href='#validate_fit_projection_layers'><p>Validate Fit and Projection Layers</p></a></li>
<li><a href='#validate_layers_zip'><p>Validate Layers Zip</p></a></li>
<li><a href='#validate_pa_fit_time'><p>Validate Match Between Presence/Absence Files and Fit Layers</p></a></li>
<li><a href='#variable_importance'><p>Variable Importance in BART Model</p></a></li>
<li><a href='#youdensIndex'><p>Calculate Youden's index</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>User-Friendly 'shiny' App for Bayesian Species Distribution
Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A user-friendly 'shiny' application for Bayesian machine
    learning analysis of marine species distributions. GLOSSA (Global
    Species Spatiotemporal Analysis) uses Bayesian Additive Regression
    Trees (BART; Chipman, George, and McCulloch (2010)
    &lt;<a href="https://doi.org/10.1214%2F09-AOAS285">doi:10.1214/09-AOAS285</a>&gt;) to model species distributions with
    intuitive workflows for data upload, processing, model fitting, and
    result visualization. It supports presence-absence and presence-only
    data (with pseudo-absence generation), spatial thinning,
    cross-validation, and scenario-based projections. GLOSSA is designed
    to facilitate ecological research by providing easy-to-use tools for
    analyzing and visualizing marine species distributions across
    different spatial and temporal scales.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/iMARES-group/glossa">https://github.com/iMARES-group/glossa</a>,
<a href="https://iMARES-group.github.io/glossa/">https://iMARES-group.github.io/glossa/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/iMARES-group/glossa/issues">https://github.com/iMARES-group/glossa/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>bs4Dash, R (&ge; 4.0.0), shiny</td>
</tr>
<tr>
<td>Imports:</td>
<td>dbarts, dplyr, DT, GeoThinneR, ggplot2, htmltools, jsonlite,
leaflet, markdown, mcp, pROC, sf, shinyWidgets, sparkline,
svglite, terra, tidyterra, waiter, zip</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, matrixStats, rmarkdown, testthat (&ge; 3.0.0), tidyr,
tidyverse</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-11 07:35:34 UTC; jorge</td>
</tr>
<tr>
<td>Author:</td>
<td>Jorge Mestre-Tomás
    <a href="https://orcid.org/0000-0002-8983-3417"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Alba Fuster-Alonso
    <a href="https://orcid.org/0000-0002-7283-291X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jorge Mestre-Tomás &lt;jorge.mestre.tomas@csic.es&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-15 15:10:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='buffer_polygon'>Enlarge/Buffer a Polygon</h2><span id='topic+buffer_polygon'></span>

<h3>Description</h3>

<p>This function enlarges a polygon by applying a buffer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>buffer_polygon(polygon, buffer_distance)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="buffer_polygon_+3A_polygon">polygon</code></td>
<td>
<p>An sf object representing the polygon to be buffered.</p>
</td></tr>
<tr><td><code id="buffer_polygon_+3A_buffer_distance">buffer_distance</code></td>
<td>
<p>Numeric. The buffer distance in decimal degrees (arc degrees).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An sf object representing the buffered polygon.
</p>

<hr>
<h2 id='clean_coordinates'>Clean Coordinates of Presence/Absence Data</h2><span id='topic+clean_coordinates'></span>

<h3>Description</h3>

<p>This function cleans coordinates of presence/absence data by removing NA coordinates, rounding coordinates if specified, removing duplicated points, and removing points outside specified spatial polygon boundaries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_coordinates(
  df,
  study_area,
  overlapping = FALSE,
  decimal_digits = NULL,
  coords = c("decimalLongitude", "decimalLatitude"),
  by_timestamp = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clean_coordinates_+3A_df">df</code></td>
<td>
<p>A dataframe object with rows representing points. Coordinates are in WGS84 (EPSG:4326) coordinate system.</p>
</td></tr>
<tr><td><code id="clean_coordinates_+3A_study_area">study_area</code></td>
<td>
<p>A spatial polygon in WGS84 (EPSG:4326) representing the boundaries within which coordinates should be kept.</p>
</td></tr>
<tr><td><code id="clean_coordinates_+3A_overlapping">overlapping</code></td>
<td>
<p>Logical indicating whether points overlapping the polygon should be removed (TRUE) or kept (FALSE).</p>
</td></tr>
<tr><td><code id="clean_coordinates_+3A_decimal_digits">decimal_digits</code></td>
<td>
<p>An integer specifying the number of decimal places to which coordinates should be rounded.</p>
</td></tr>
<tr><td><code id="clean_coordinates_+3A_coords">coords</code></td>
<td>
<p>Character vector specifying the column names for longitude and latitude.</p>
</td></tr>
<tr><td><code id="clean_coordinates_+3A_by_timestamp">by_timestamp</code></td>
<td>
<p>If TRUE, clean coordinates taking into account different time periods defined in the column 'timestamp'.</p>
</td></tr>
<tr><td><code id="clean_coordinates_+3A_seed">seed</code></td>
<td>
<p>Optional; an integer seed for reproducibility of results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a data frame containing presence/absence data with longitude and latitude coordinates, a spatial polygon representing boundaries within which to keep points, and parameters for rounding coordinates and handling duplicated points. It returns a cleaned data frame with valid coordinates within the specified boundaries.
</p>


<h3>Value</h3>

<p>A cleaned data frame containing presence/absence data with valid coordinates.
</p>

<hr>
<h2 id='create_coords_layer'>Create Geographic Coordinate Layers</h2><span id='topic+create_coords_layer'></span>

<h3>Description</h3>

<p>Generates raster layers for longitude and latitude from given raster data,
applies optional scaling, and restricts the output to a specified spatial mask.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_coords_layer(layers, study_area = NULL, scale_layers = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_coords_layer_+3A_layers">layers</code></td>
<td>
<p>Raster or stack of raster layers to derive geographic extent and resolution.</p>
</td></tr>
<tr><td><code id="create_coords_layer_+3A_study_area">study_area</code></td>
<td>
<p>Spatial object for masking output layers.</p>
</td></tr>
<tr><td><code id="create_coords_layer_+3A_scale_layers">scale_layers</code></td>
<td>
<p>Logical indicating if scaling is applied. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Raster stack with layers lon and lat.
</p>

<hr>
<h2 id='cv_bart'>Cross-Validation for BART Model</h2><span id='topic+cv_bart'></span>

<h3>Description</h3>

<p>This function performs k-fold cross-validation for a Bayesian Additive Regression Trees (BART) model
using presence-absence data and environmental covariate layers. It calculates various performance metrics
for model evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_bart(data, k = 10, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv_bart_+3A_data">data</code></td>
<td>
<p>Data frame with a column (named 'pa') indicating presence (1) or absence (0) and columns for the predictor variables.</p>
</td></tr>
<tr><td><code id="cv_bart_+3A_k">k</code></td>
<td>
<p>Integer; number of folds for cross-validation (default is 10).</p>
</td></tr>
<tr><td><code id="cv_bart_+3A_seed">seed</code></td>
<td>
<p>Optional; random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the true positives (TP), false positives (FP), false negatives (FN), true negatives (TN),
and various performance metrics including precision (PREC), sensitivity (SEN), specificity (SPC), false discovery rate (FDR),
negative predictive value (NPV), false negative rate (FNR), false positive rate (FPR), F-score, accuracy (ACC), balanced accuracy (BA),
and true skill statistic (TSS) for each fold.
</p>

<hr>
<h2 id='downloadActionButton'>Create a Download Action Button</h2><span id='topic+downloadActionButton'></span>

<h3>Description</h3>

<p>This function generates a download action button that triggers the download of a file when clicked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadActionButton(
  outputId,
  label = "Download",
  icon = NULL,
  width = NULL,
  status = NULL,
  outline = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="downloadActionButton_+3A_outputid">outputId</code></td>
<td>
<p>The output ID for the button.</p>
</td></tr>
<tr><td><code id="downloadActionButton_+3A_label">label</code></td>
<td>
<p>The label text displayed on the button. Default is &quot;Download&quot;.</p>
</td></tr>
<tr><td><code id="downloadActionButton_+3A_icon">icon</code></td>
<td>
<p>The icon to be displayed on the button. Default is NULL.</p>
</td></tr>
<tr><td><code id="downloadActionButton_+3A_width">width</code></td>
<td>
<p>The width of the button. Default is NULL.</p>
</td></tr>
<tr><td><code id="downloadActionButton_+3A_status">status</code></td>
<td>
<p>The status of the button. Default is NULL.</p>
</td></tr>
<tr><td><code id="downloadActionButton_+3A_outline">outline</code></td>
<td>
<p>Logical indicating whether to use outline style for the button. Default is FALSE.</p>
</td></tr>
<tr><td><code id="downloadActionButton_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the actionButton function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a download action button with the specified parameters.
</p>

<hr>
<h2 id='export_plot_server'>Server Logic for Export Plot Functionality</h2><span id='topic+export_plot_server'></span>

<h3>Description</h3>

<p>Sets up server-side functionality for exporting plots, including creating a modal dialog
for user input on export preferences (height, width, format) and processing the download.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>export_plot_server(id, exported_plot)
</code></pre>


<h3>Value</h3>

<p>No return value, this function is used for its side effects within a Shiny app.
</p>

<hr>
<h2 id='export_plot_ui'>Create UI for Export Plot Button</h2><span id='topic+export_plot_ui'></span>

<h3>Description</h3>

<p>This function generates a UI element (action button) for exporting plots.
The button is styled to be minimalistic, featuring only a download icon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>export_plot_ui(id)
</code></pre>


<h3>Value</h3>

<p>Returns an actionButton for use in a Shiny UI that triggers plot export modal when clicked.
</p>

<hr>
<h2 id='extract_noNA_cov_values'>Extract Non-NA Covariate Values</h2><span id='topic+extract_noNA_cov_values'></span>

<h3>Description</h3>

<p>This function extracts covariate values for species occurrences, excluding NA values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_noNA_cov_values(data, covariate_layers, predictor_variables)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_noNA_cov_values_+3A_data">data</code></td>
<td>
<p>A data frame containing species occurrence data with columns x/long (first column) and y/lat (second column).</p>
</td></tr>
<tr><td><code id="extract_noNA_cov_values_+3A_covariate_layers">covariate_layers</code></td>
<td>
<p>A list of raster layers representing covariates.</p>
</td></tr>
<tr><td><code id="extract_noNA_cov_values_+3A_predictor_variables">predictor_variables</code></td>
<td>
<p>Variables to select from all the layers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function extracts covariate values for each species occurrence location from the provided covariate layers. It returns a data frame containing species occurrence data with covariate values, excluding any NA values.
</p>


<h3>Value</h3>

<p>A data frame containing species occurrence data with covariate values, excluding NA values.
</p>

<hr>
<h2 id='file_input_area_server'>Server-side Logic for Custom File Input</h2><span id='topic+file_input_area_server'></span>

<h3>Description</h3>

<p>Processes the file input from the UI component created by <code><a href="#topic+file_input_area_ui">file_input_area_ui</a></code> and provides access to the uploaded file data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>file_input_area_server(id)
</code></pre>


<h3>Value</h3>

<p>A reactive expression that returns a data frame containing information about the uploaded files, or NULL if no files have been uploaded.
</p>

<hr>
<h2 id='file_input_area_ui'>Custom File Input UI</h2><span id='topic+file_input_area_ui'></span>

<h3>Description</h3>

<p>Creates a customized file input area in a Shiny application. The file input is designed to be visually distinct and supports features such as multiple file selection and file type restrictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>file_input_area_ui(
  id,
  label = "Input text: ",
  multiple = FALSE,
  accept = NULL,
  width = NULL,
  button_label = "Browse...",
  icon_name = NULL
)
</code></pre>


<h3>Value</h3>

<p>A Shiny UI object that can be added to a Shiny application.
</p>

<hr>
<h2 id='fit_bart_model'>Fit a BART Model Using Environmental Covariate Layers</h2><span id='topic+fit_bart_model'></span>

<h3>Description</h3>

<p>This function fits a Bayesian Additive Regression Trees (BART) model using
presence/absence data and environmental covariate layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_bart_model(y, x, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_bart_model_+3A_y">y</code></td>
<td>
<p>A numeric vector indicating presence (1) or absence (0).</p>
</td></tr>
<tr><td><code id="fit_bart_model_+3A_x">x</code></td>
<td>
<p>A data frame with the same number of rows as the length of the vector 'y', containing the covariate values.</p>
</td></tr>
<tr><td><code id="fit_bart_model_+3A_seed">seed</code></td>
<td>
<p>An optional integer value for setting the random seed for reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A BART model object.
</p>

<hr>
<h2 id='generate_cv_plot'>Generate Cross-Validation Plot</h2><span id='topic+generate_cv_plot'></span>

<h3>Description</h3>

<p>This function generates a cross-validation plot based on evaluation metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_cv_plot(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_cv_plot_+3A_data">data</code></td>
<td>
<p>Dataframe containing cross-validation results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot object representing the cross-validation plot.
</p>

<hr>
<h2 id='generate_prediction_plot'>Generate Prediction Plot</h2><span id='topic+generate_prediction_plot'></span>

<h3>Description</h3>

<p>This function generates a plot based on prediction raster layers and presence/absence points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_prediction_plot(
  prediction_layer,
  pa_points,
  legend_label,
  non_study_area_mask,
  coords
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_prediction_plot_+3A_prediction_layer">prediction_layer</code></td>
<td>
<p>Raster prediction layer.</p>
</td></tr>
<tr><td><code id="generate_prediction_plot_+3A_pa_points">pa_points</code></td>
<td>
<p>Presence/absence points.</p>
</td></tr>
<tr><td><code id="generate_prediction_plot_+3A_legend_label">legend_label</code></td>
<td>
<p>Label for the legend.</p>
</td></tr>
<tr><td><code id="generate_prediction_plot_+3A_non_study_area_mask">non_study_area_mask</code></td>
<td>
<p>Spatial polygon representing the non study areas.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot object representing the world prediction plot.
</p>

<hr>
<h2 id='generate_pseudo_absences'>Generate Pseudo-Absence Points Based on Presence Points, Covariates, and Study Area Polygon</h2><span id='topic+generate_pseudo_absences'></span>

<h3>Description</h3>

<p>This function generates pseudo-absence points within the study area.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_pseudo_absences(
  presences,
  study_area,
  raster_stack,
  predictor_variables,
  coords = c("decimalLongitude", "decimalLatitude"),
  decimal_digits = NULL,
  attempts = 100
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_pseudo_absences_+3A_presences">presences</code></td>
<td>
<p>Data frame containing presence points.</p>
</td></tr>
<tr><td><code id="generate_pseudo_absences_+3A_study_area">study_area</code></td>
<td>
<p>Spatial polygon defining the study area ('sf' object).</p>
</td></tr>
<tr><td><code id="generate_pseudo_absences_+3A_raster_stack">raster_stack</code></td>
<td>
<p>'SpatRaster' object containing covariate data.</p>
</td></tr>
<tr><td><code id="generate_pseudo_absences_+3A_predictor_variables">predictor_variables</code></td>
<td>
<p>Character vector of the predictor variables selected for this species.</p>
</td></tr>
<tr><td><code id="generate_pseudo_absences_+3A_coords">coords</code></td>
<td>
<p>Character vector specifying the column names for latitude and longitude. Defaults to 'c(&quot;decimalLongitude&quot;, &quot;decimalLatitude&quot;)'.</p>
</td></tr>
<tr><td><code id="generate_pseudo_absences_+3A_decimal_digits">decimal_digits</code></td>
<td>
<p>An integer specifying the number of decimal places to which coordinates should be rounded.</p>
</td></tr>
<tr><td><code id="generate_pseudo_absences_+3A_attempts">attempts</code></td>
<td>
<p>Integer specifying the number of attempts to generate exact pseudo-absences. Defaults to 100.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame containing both presence and pseudo-absence points.
</p>

<hr>
<h2 id='get_covariate_names'>Get Covariate Names</h2><span id='topic+get_covariate_names'></span>

<h3>Description</h3>

<p>This function extracts the names of covariates from a ZIP file containing covariate layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_covariate_names(file_path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_covariate_names_+3A_file_path">file_path</code></td>
<td>
<p>Path to the ZIP file containing covariate layers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function extracts the names of covariates from a ZIP file containing covariate layers.
</p>


<h3>Value</h3>

<p>A character vector containing the names of covariates.
</p>

<hr>
<h2 id='getFprTpr'>Compute specificity and sensitivity</h2><span id='topic+getFprTpr'></span>

<h3>Description</h3>

<p>Compute specificity and sensitivity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFprTpr(actuals, predictedScores, threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getFprTpr_+3A_actuals">actuals</code></td>
<td>
<p>The actual binary flags for the response variable. It can take a numeric vector containing values of either 1 or 0, where 1 represents the 'Good' or 'Events' while 0 represents 'Bad' or 'Non-Events'.</p>
</td></tr>
<tr><td><code id="getFprTpr_+3A_predictedscores">predictedScores</code></td>
<td>
<p>The prediction probability scores for each observation. If your classification model gives the 1/0 predcitions, convert it to a numeric vector of 1's and 0's.</p>
</td></tr>
<tr><td><code id="getFprTpr_+3A_threshold">threshold</code></td>
<td>
<p>If predicted value is above the threshold, it will be considered as an event (1), else it will be a non-event (0). Defaults to 0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was obtained from the InformationValue R package (<a href="https://github.com/selva86/InformationValue">https://github.com/selva86/InformationValue</a>).
</p>


<h3>Value</h3>

<p>A list with two elements: fpr (false positive rate) and tpr (true positive rate).
</p>

<hr>
<h2 id='glossa_analysis'>Main Analysis Function for GLOSSA Package</h2><span id='topic+glossa_analysis'></span>

<h3>Description</h3>

<p>This function wraps all the analysis that the GLOSSA package performs. It processes presence-absence data,
environmental covariates, and performs species distribution modeling and projections under past and future scenarios.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glossa_analysis(
  pa_data = NULL,
  fit_layers = NULL,
  proj_files = NULL,
  study_area_poly = NULL,
  predictor_variables = NULL,
  decimal_digits = NULL,
  scale_layers = FALSE,
  buffer = NULL,
  native_range = NULL,
  suitable_habitat = NULL,
  other_analysis = NULL,
  seed = NA,
  waiter = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glossa_analysis_+3A_pa_data">pa_data</code></td>
<td>
<p>A list of data frames containing presence-absence data.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_fit_layers">fit_layers</code></td>
<td>
<p>A SpatRaster stack containing model fitting environmental layers.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_proj_files">proj_files</code></td>
<td>
<p>A list of file paths containing environmental layers for projection scenarios.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_study_area_poly">study_area_poly</code></td>
<td>
<p>A spatial polygon defining the study area.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_predictor_variables">predictor_variables</code></td>
<td>
<p>A list of predictor variables to be used in the analysis.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_decimal_digits">decimal_digits</code></td>
<td>
<p>An integer specifying the number of decimal places to which coordinates should be rounded.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_scale_layers">scale_layers</code></td>
<td>
<p>Logical; if TRUE, covariate layers will be scaled based on fit layers.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_buffer">buffer</code></td>
<td>
<p>Buffer value or distance in decimal degrees (arc_degrees).</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_native_range">native_range</code></td>
<td>
<p>A vector of scenarios ('fit_layers', 'projections') where native range modeling should be performed.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_suitable_habitat">suitable_habitat</code></td>
<td>
<p>A vector of scenarios ('fit_layers', 'projections') where habitat suitability modeling should be performed.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_other_analysis">other_analysis</code></td>
<td>
<p>A vector of additional analyses to perform (e.g., 'variable_importance', 'functional_responses', 'cross_validation').</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_seed">seed</code></td>
<td>
<p>Optional; an integer seed for reproducibility of results.</p>
</td></tr>
<tr><td><code id="glossa_analysis_+3A_waiter">waiter</code></td>
<td>
<p>Optional; a waiter instance to update progress in a Shiny application.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing structured outputs from each major section of the analysis, including model data, projections,
variable importance scores, and habitat suitability assessments.
</p>

<hr>
<h2 id='glossa_export'>Export Glossa Model Results</h2><span id='topic+glossa_export'></span>

<h3>Description</h3>

<p>This function exports various types of Glossa model results, including native range predictions, suitable habitat predictions, model data, variable importance, functional response results, and presence/absence probability cutoffs. It generates raster files for prediction results, CSV files for model data and variable importance, and CSV files for functional response results. Additionally, it creates a CSV file for presence/absence probability cutoffs if provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glossa_export(
  species = NULL,
  models = NULL,
  layer_results = NULL,
  fields = NULL,
  model_data = FALSE,
  model_summary = FALSE,
  fr = FALSE,
  prob_cut = FALSE,
  varimp = FALSE,
  cross_val = FALSE,
  layer_format = "tif",
  projections_results = NULL,
  presence_absence_list = NULL,
  other_results = NULL,
  pa_cutoff = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glossa_export_+3A_species">species</code></td>
<td>
<p>A character vector specifying the species names.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_models">models</code></td>
<td>
<p>A character vector specifying the types of models to export results for.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_layer_results">layer_results</code></td>
<td>
<p>A list containing layer results for native range and suitable habitat predictions.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_fields">fields</code></td>
<td>
<p>A character vector specifying the fields to include in the exported results.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_model_data">model_data</code></td>
<td>
<p>Logical, indicating whether to export model data.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_fr">fr</code></td>
<td>
<p>Logical, indicating whether to export functional response results.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_prob_cut">prob_cut</code></td>
<td>
<p>Logical, indicating whether to export presence/absence probability cutoffs.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_varimp">varimp</code></td>
<td>
<p>Logical, indicating whether to export variable importance.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_cross_val">cross_val</code></td>
<td>
<p>Logical, indicating whether to export cross-validation metrics.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_layer_format">layer_format</code></td>
<td>
<p>A character vector specifying the format of the exported raster files.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_projections_results">projections_results</code></td>
<td>
<p>A list containing projections results.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_presence_absence_list">presence_absence_list</code></td>
<td>
<p>A list containing presence/absence lists.</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_other_results">other_results</code></td>
<td>
<p>A list containing other types of results (e.g., variable importance, functional responses, cross-validation).</p>
</td></tr>
<tr><td><code id="glossa_export_+3A_pa_cutoff">pa_cutoff</code></td>
<td>
<p>A list containing presence/absence probability cutoffs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of file paths for the exported files or directories.
</p>

<hr>
<h2 id='invert_polygon'>Invert a Polygon</h2><span id='topic+invert_polygon'></span>

<h3>Description</h3>

<p>This function inverts a polygon by calculating the difference between the bounding box and the polygon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invert_polygon(polygon, bbox = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="invert_polygon_+3A_polygon">polygon</code></td>
<td>
<p>An sf object representing the polygon to be inverted.</p>
</td></tr>
<tr><td><code id="invert_polygon_+3A_bbox">bbox</code></td>
<td>
<p>Optional. An sf or bbox object representing the bounding box. If NULL, the bounding box of the input polygon is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An sf object representing the inverted polygon.
</p>

<hr>
<h2 id='layer_mask'>Apply Polygon Mask to Raster Layers</h2><span id='topic+layer_mask'></span>

<h3>Description</h3>

<p>This function crops and extends raster layers to a study area extent (bbox) defined by longitude
and latitude then applies a mask based on a provided spatial polygon to remove areas outside the polygon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_mask(layers, study_area)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="layer_mask_+3A_layers">layers</code></td>
<td>
<p>A stack of raster layers ('SpatRaster' object) to be processed.</p>
</td></tr>
<tr><td><code id="layer_mask_+3A_study_area">study_area</code></td>
<td>
<p>A spatial polygon ('sf' object) used to mask the raster layers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 'SpatRaster' object representing the masked raster layers.
</p>

<hr>
<h2 id='misClassError'>Misclassification Error</h2><span id='topic+misClassError'></span>

<h3>Description</h3>

<p>Misclassification Error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>misClassError(actuals, predictedScores, threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="misClassError_+3A_actuals">actuals</code></td>
<td>
<p>The actual binary flags for the response variable. It can take a numeric vector containing values of either 1 or 0, where 1 represents the 'Good' or 'Events' while 0 represents 'Bad' or 'Non-Events'.</p>
</td></tr>
<tr><td><code id="misClassError_+3A_predictedscores">predictedScores</code></td>
<td>
<p>The prediction probability scores for each observation. If your classification model gives the 1/0 predcitions, convert it to a numeric vector of 1's and 0's.</p>
</td></tr>
<tr><td><code id="misClassError_+3A_threshold">threshold</code></td>
<td>
<p>If predicted value is above the threshold, it will be considered as an event (1), else it will be a non-event (0). Defaults to 0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was obtained from the InformationValue R package (<a href="https://github.com/selva86/InformationValue">https://github.com/selva86/InformationValue</a>).
</p>


<h3>Value</h3>

<p>The misclassification error, which tells what proportion of predicted direction did not match with the actuals.
</p>

<hr>
<h2 id='optimalCutoff'>Compute the optimal probability cutoff score</h2><span id='topic+optimalCutoff'></span>

<h3>Description</h3>

<p>Compute the optimal probability cutoff score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimalCutoff(
  actuals,
  predictedScores,
  optimiseFor = "misclasserror",
  returnDiagnostics = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optimalCutoff_+3A_actuals">actuals</code></td>
<td>
<p>The actual binary flags for the response variable. It can take a numeric vector containing values of either 1 or 0, where 1 represents the 'Good' or 'Events' while 0 represents 'Bad' or 'Non-Events'.</p>
</td></tr>
<tr><td><code id="optimalCutoff_+3A_predictedscores">predictedScores</code></td>
<td>
<p>The prediction probability scores for each observation. If your classification model gives the 1/0 predcitions, convert it to a numeric vector of 1's and 0's.</p>
</td></tr>
<tr><td><code id="optimalCutoff_+3A_optimisefor">optimiseFor</code></td>
<td>
<p>The maximization criterion for which probability cutoff score needs to be optimised. Can take either of following values: &quot;Ones&quot; or &quot;Zeros&quot; or &quot;Both&quot; or &quot;misclasserror&quot;(default). If &quot;Ones&quot; is used, 'optimalCutoff' will be chosen to maximise detection of &quot;One's&quot;. If 'Both' is specified, the probability cut-off that gives maximum Youden's Index is chosen. If 'misclasserror' is specified, the probability cut-off that gives minimum mis-clasification error is chosen.</p>
</td></tr>
<tr><td><code id="optimalCutoff_+3A_returndiagnostics">returnDiagnostics</code></td>
<td>
<p>If TRUE, would return additional diagnostics such as 'sensitivityTable', 'misclassificationError', 'TPR', 'FPR' and 'specificity' for the chosen cut-off.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was obtained from the InformationValue R package (<a href="https://github.com/selva86/InformationValue">https://github.com/selva86/InformationValue</a>).
</p>


<h3>Value</h3>

<p>The optimal probability score cutoff that maximises a given criterion. If 'returnDiagnostics' is TRUE, then the following items are returned in a list:
</p>

<hr>
<h2 id='pa_optimal_cutoff'>Optimal Cutoff for Presence-Absence Prediction</h2><span id='topic+pa_optimal_cutoff'></span>

<h3>Description</h3>

<p>This function calculates the optimal cutoff for presence-absence prediction using a BART model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pa_optimal_cutoff(y, x, model, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pa_optimal_cutoff_+3A_y">y</code></td>
<td>
<p>Vector indicating presence (1) or absence (0).</p>
</td></tr>
<tr><td><code id="pa_optimal_cutoff_+3A_x">x</code></td>
<td>
<p>Dataframe with same number of rows as the length of the vector 'y' with the covariate values.</p>
</td></tr>
<tr><td><code id="pa_optimal_cutoff_+3A_model">model</code></td>
<td>
<p>A BART model object.</p>
</td></tr>
<tr><td><code id="pa_optimal_cutoff_+3A_seed">seed</code></td>
<td>
<p>Random seed for reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The optimal cutoff value for presence-absence prediction.
</p>

<hr>
<h2 id='predict_bart'>Make Predictions Using a BART Model</h2><span id='topic+predict_bart'></span>

<h3>Description</h3>

<p>This function makes predictions using a Bayesian Additive Regression Trees (BART) model
on a stack of environmental covariates ('SpatRaster').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_bart(bart_model, layers, cutoff = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_bart_+3A_bart_model">bart_model</code></td>
<td>
<p>A BART model object obtained from fitting BART using the 'dbarts' package.</p>
</td></tr>
<tr><td><code id="predict_bart_+3A_layers">layers</code></td>
<td>
<p>A SpatRaster object containing environmental covariates for prediction.</p>
</td></tr>
<tr><td><code id="predict_bart_+3A_cutoff">cutoff</code></td>
<td>
<p>An optional numeric cutoff value for determining potential presences. If NULL, potential presences and absences will not be computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A SpatRaster containing the mean, median, standard deviation, and quantiles
of the posterior predictive distribution, as well as a potential presences layer if cutoff is provided.
</p>

<hr>
<h2 id='read_extent_polygon'>Read and Validate Extent Polygon</h2><span id='topic+read_extent_polygon'></span>

<h3>Description</h3>

<p>This function reads and validates a polygon file containing the extent. It checks if the file has the correct format and extracts the geometry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_extent_polygon(file_path, show_modal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_extent_polygon_+3A_file_path">file_path</code></td>
<td>
<p>Path to the polygon file containing the extent.</p>
</td></tr>
<tr><td><code id="read_extent_polygon_+3A_show_modal">show_modal</code></td>
<td>
<p>Optional. Logical. Whether to show a modal notification for warnings. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A spatial object representing the extent if the file is valid, NULL otherwise.
</p>

<hr>
<h2 id='read_layers_zip'>Load Covariate Layers from ZIP Files</h2><span id='topic+read_layers_zip'></span>

<h3>Description</h3>

<p>This function loads covariate layers from a ZIP file, verifies their spatial characteristics, and returns them as a list of raster layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_layers_zip(
  file_path,
  extend = TRUE,
  first_layer = FALSE,
  show_modal = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_layers_zip_+3A_file_path">file_path</code></td>
<td>
<p>Path to the ZIP file containing covariate layers.</p>
</td></tr>
<tr><td><code id="read_layers_zip_+3A_extend">extend</code></td>
<td>
<p>If TRUE it will take the largest extent, if FALSE the smallest.</p>
</td></tr>
<tr><td><code id="read_layers_zip_+3A_first_layer">first_layer</code></td>
<td>
<p>If TRUE it will return only the layers from the first timestamp.</p>
</td></tr>
<tr><td><code id="read_layers_zip_+3A_show_modal">show_modal</code></td>
<td>
<p>Optional. Logical. Whether to show a modal notification for warnings. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing raster layers for each covariate.
</p>

<hr>
<h2 id='read_presences_absences_csv'>Read and validate presences/absences CSV file</h2><span id='topic+read_presences_absences_csv'></span>

<h3>Description</h3>

<p>This function reads and validates a CSV file containing presences and absences data for species occurrences.
It checks if the file has the expected columns and formats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_presences_absences_csv(
  file_path,
  file_name = NULL,
  show_modal = FALSE,
  coords = c("decimalLongitude", "decimalLatitude"),
  sep = "\t",
  dec = "."
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_presences_absences_csv_+3A_file_path">file_path</code></td>
<td>
<p>The file path to the CSV file.</p>
</td></tr>
<tr><td><code id="read_presences_absences_csv_+3A_file_name">file_name</code></td>
<td>
<p>Optional. The name of the file. If not provided, the base name of the file path is used.</p>
</td></tr>
<tr><td><code id="read_presences_absences_csv_+3A_show_modal">show_modal</code></td>
<td>
<p>Optional. Logical. Whether to show a modal notification for warnings (use in Shiny). Default is FALSE.</p>
</td></tr>
<tr><td><code id="read_presences_absences_csv_+3A_coords">coords</code></td>
<td>
<p>Optional. Character vector of length 2 specifying the names of the columns containing the longitude and latitude coordinates. Default is c(&quot;decimalLongitude&quot;, &quot;decimalLatitude&quot;).</p>
</td></tr>
<tr><td><code id="read_presences_absences_csv_+3A_sep">sep</code></td>
<td>
<p>Optional. The field separator character. Default is tab-separated.</p>
</td></tr>
<tr><td><code id="read_presences_absences_csv_+3A_dec">dec</code></td>
<td>
<p>Optional. The decimal point character. Default is &quot;.&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the validated data if the file has the expected columns and formats, NULL otherwise.
</p>

<hr>
<h2 id='remove_duplicate_points'>Remove Duplicated Points from a Dataframe</h2><span id='topic+remove_duplicate_points'></span>

<h3>Description</h3>

<p>This function removes duplicated points from a dataframe based on specified coordinate columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_duplicate_points(df, coords = c("decimalLongitude", "decimalLatitude"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="remove_duplicate_points_+3A_df">df</code></td>
<td>
<p>A dataframe object with each row representing one point.</p>
</td></tr>
<tr><td><code id="remove_duplicate_points_+3A_coords">coords</code></td>
<td>
<p>A character vector specifying the names of the coordinate columns used for identifying duplicate points. Default is c(&quot;decimalLongitude&quot;, &quot;decimalLatitude&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe without duplicated points.
</p>

<hr>
<h2 id='remove_points_polygon'>Remove Points Inside or Outside a Polygon</h2><span id='topic+remove_points_polygon'></span>

<h3>Description</h3>

<p>This function removes points from a dataframe based on their location relative to a specified polygon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_points_polygon(
  df,
  polygon,
  overlapping = FALSE,
  coords = c("decimalLongitude", "decimalLatitude")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="remove_points_polygon_+3A_df">df</code></td>
<td>
<p>A dataframe object with rows representing points.</p>
</td></tr>
<tr><td><code id="remove_points_polygon_+3A_polygon">polygon</code></td>
<td>
<p>An sf polygon object defining the region for point removal.</p>
</td></tr>
<tr><td><code id="remove_points_polygon_+3A_overlapping">overlapping</code></td>
<td>
<p>Logical indicating whether points overlapping the polygon should be removed (TRUE) or kept (FALSE).</p>
</td></tr>
<tr><td><code id="remove_points_polygon_+3A_coords">coords</code></td>
<td>
<p>Character vector specifying the column names for longitude and latitude. Default is c(&quot;decimalLongitude&quot;, &quot;decimalLatitude&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe containing the filtered points.
</p>

<hr>
<h2 id='response_curve_bart'>Calculate Response Curve Using BART Model</h2><span id='topic+response_curve_bart'></span>

<h3>Description</h3>

<p>This function calculates the response curve (functional responses) using a Bayesian Additive Regression Trees (BART) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>response_curve_bart(bart_model, data, predictor_names)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="response_curve_bart_+3A_bart_model">bart_model</code></td>
<td>
<p>A BART model object obtained from fitting BART ('dbarts::bart').</p>
</td></tr>
<tr><td><code id="response_curve_bart_+3A_data">data</code></td>
<td>
<p>A data frame containing the predictor variables (the design matrix) used in the BART model.</p>
</td></tr>
<tr><td><code id="response_curve_bart_+3A_predictor_names">predictor_names</code></td>
<td>
<p>A character vector containing the names of the predictor variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a data frame for each independent variable with mean, 2.5th percentile, 97.5th percentile, and corresponding values of the variables.
</p>

<hr>
<h2 id='run_glossa'>Run GLOSSA Shiny App</h2><span id='topic+run_glossa'></span>

<h3>Description</h3>

<p>This function launches the GLOSSA Shiny web application.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_glossa(
  request_size_mb = 2000,
  launch.browser = TRUE,
  port = getOption("shiny.port")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="run_glossa_+3A_request_size_mb">request_size_mb</code></td>
<td>
<p>Maximum request size for file uploads, in megabytes. Default is 2000 MB.</p>
</td></tr>
<tr><td><code id="run_glossa_+3A_launch.browser">launch.browser</code></td>
<td>
<p>Logical indicating whether to launch the app in the browser (default is TRUE).</p>
</td></tr>
<tr><td><code id="run_glossa_+3A_port">port</code></td>
<td>
<p>Port number for the Shiny app. Uses the port specified by 'getOption(&quot;shiny.port&quot;)' by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GLOSSA Shiny app provides an interactive interface for users to access GLOSSA functionalities.
</p>


<h3>Value</h3>

<p>No return value, called to launch the GLOSSA app.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(interactive()) {
run_glossa()
}
</code></pre>

<hr>
<h2 id='sensitivity'>Calculate the sensitivity for a given logit model</h2><span id='topic+sensitivity'></span>

<h3>Description</h3>

<p>Calculate the sensitivity for a given logit model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sensitivity(actuals, predictedScores, threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sensitivity_+3A_actuals">actuals</code></td>
<td>
<p>The actual binary flags for the response variable. It can take a numeric vector containing values of either 1 or 0, where 1 represents the 'Good' or 'Events' while 0 represents 'Bad' or 'Non-Events'.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_predictedscores">predictedScores</code></td>
<td>
<p>The prediction probability scores for each observation. If your classification model gives the 1/0 predcitions, convert it to a numeric vector of 1's and 0's.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_threshold">threshold</code></td>
<td>
<p>If predicted value is above the threshold, it will be considered as an event (1), else it will be a non-event (0). Defaults to 0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was obtained from the InformationValue R package (<a href="https://github.com/selva86/InformationValue">https://github.com/selva86/InformationValue</a>).
</p>


<h3>Value</h3>

<p>The sensitivity of the given binary response actuals and predicted probability scores, which is, the number of observations with the event AND predicted to have the event divided by the nummber of observations with the event.
</p>

<hr>
<h2 id='sparkvalueBox'>Create a Sparkline Value Box</h2><span id='topic+sparkvalueBox'></span>

<h3>Description</h3>

<p>This function creates a custom value box with a sparkline plot embedded in it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparkvalueBox(
  title,
  sparkline_data,
  description,
  type = "line",
  box_color = "white",
  width = 4,
  elevation = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparkvalueBox_+3A_title">title</code></td>
<td>
<p>The title or heading of the value box.</p>
</td></tr>
<tr><td><code id="sparkvalueBox_+3A_sparkline_data">sparkline_data</code></td>
<td>
<p>The data used to generate the sparkline plot.</p>
</td></tr>
<tr><td><code id="sparkvalueBox_+3A_description">description</code></td>
<td>
<p>A short description or additional information displayed below the value box.</p>
</td></tr>
<tr><td><code id="sparkvalueBox_+3A_type">type</code></td>
<td>
<p>The type of sparkline plot to generate. Default is &quot;line&quot;.</p>
</td></tr>
<tr><td><code id="sparkvalueBox_+3A_box_color">box_color</code></td>
<td>
<p>The background color of the value box.</p>
</td></tr>
<tr><td><code id="sparkvalueBox_+3A_width">width</code></td>
<td>
<p>The width of the value box. Default is 4.</p>
</td></tr>
<tr><td><code id="sparkvalueBox_+3A_elevation">elevation</code></td>
<td>
<p>The elevation of the value box. Default is 0.</p>
</td></tr>
<tr><td><code id="sparkvalueBox_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the sparkline function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a custom value box with the specified parameters.
</p>

<hr>
<h2 id='specificity'>Calculate the specificity for a given logit model</h2><span id='topic+specificity'></span>

<h3>Description</h3>

<p>Calculate the specificity for a given logit model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specificity(actuals, predictedScores, threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="specificity_+3A_actuals">actuals</code></td>
<td>
<p>The actual binary flags for the response variable. It can take a numeric vector containing values of either 1 or 0, where 1 represents the 'Good' or 'Events' while 0 represents 'Bad' or 'Non-Events'.</p>
</td></tr>
<tr><td><code id="specificity_+3A_predictedscores">predictedScores</code></td>
<td>
<p>The prediction probability scores for each observation. If your classification model gives the 1/0 predcitions, convert it to a numeric vector of 1's and 0's.</p>
</td></tr>
<tr><td><code id="specificity_+3A_threshold">threshold</code></td>
<td>
<p>If predicted value is above the threshold, it will be considered as an event (1), else it will be a non-event (0). Defaults to 0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was obtained from the InformationValue R package (<a href="https://github.com/selva86/InformationValue">https://github.com/selva86/InformationValue</a>).
</p>


<h3>Value</h3>

<p>The specificity of the given binary response actuals and predicted probability scores, which is, the number of observations without the event AND predicted to not have the event divided by the nummber of observations without the event.
</p>

<hr>
<h2 id='validate_fit_projection_layers'>Validate Fit and Projection Layers</h2><span id='topic+validate_fit_projection_layers'></span>

<h3>Description</h3>

<p>This function validates fit and projection layers by checking their covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_fit_projection_layers(
  fit_layers_path,
  proj_layers_path,
  show_modal = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate_fit_projection_layers_+3A_fit_layers_path">fit_layers_path</code></td>
<td>
<p>Path to the ZIP file containing fit layers.</p>
</td></tr>
<tr><td><code id="validate_fit_projection_layers_+3A_proj_layers_path">proj_layers_path</code></td>
<td>
<p>Path to the ZIP file containing projection layers.</p>
</td></tr>
<tr><td><code id="validate_fit_projection_layers_+3A_show_modal">show_modal</code></td>
<td>
<p>Optional. Logical. Whether to show a modal notification for warnings. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if the layers pass validation criteria, FALSE otherwise.
</p>

<hr>
<h2 id='validate_layers_zip'>Validate Layers Zip</h2><span id='topic+validate_layers_zip'></span>

<h3>Description</h3>

<p>This function validates a ZIP file containing environmental layers. It checks if the layers have the same number of files, CRS (Coordinate Reference System), and resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_layers_zip(file_path, show_modal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate_layers_zip_+3A_file_path">file_path</code></td>
<td>
<p>Path to the ZIP file containing environmental layers.</p>
</td></tr>
<tr><td><code id="validate_layers_zip_+3A_show_modal">show_modal</code></td>
<td>
<p>Optional. Logical. Whether to show a modal notification for warnings. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if the layers pass validation criteria, FALSE otherwise.
</p>

<hr>
<h2 id='validate_pa_fit_time'>Validate Match Between Presence/Absence Files and Fit Layers</h2><span id='topic+validate_pa_fit_time'></span>

<h3>Description</h3>

<p>This function validates whether the time periods of the presence/absence data match the environmental layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_pa_fit_time(pa_data, fit_layers_path, show_modal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate_pa_fit_time_+3A_pa_data">pa_data</code></td>
<td>
<p>Data frame containing the presence/absence data with a 'timestamp' column.</p>
</td></tr>
<tr><td><code id="validate_pa_fit_time_+3A_fit_layers_path">fit_layers_path</code></td>
<td>
<p>Path to the ZIP file containing fit layers.</p>
</td></tr>
<tr><td><code id="validate_pa_fit_time_+3A_show_modal">show_modal</code></td>
<td>
<p>Optional. Logical. Whether to show a modal notification for warnings. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if the timestamps match the fit layers, FALSE otherwise.
</p>

<hr>
<h2 id='variable_importance'>Variable Importance in BART Model</h2><span id='topic+variable_importance'></span>

<h3>Description</h3>

<p>This function computes the variable importance scores for a fitted BART (Bayesian Additive Regression Trees) model
using a permutation-based approach. It measures the impact of each predictor variable on the model's performance
by permuting the values of that variable and evaluating the change in performance (F-score is the performance metric).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable_importance(bart_model, cutoff = 0, n_repeats = 10, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variable_importance_+3A_bart_model">bart_model</code></td>
<td>
<p>A BART model object.</p>
</td></tr>
<tr><td><code id="variable_importance_+3A_cutoff">cutoff</code></td>
<td>
<p>A numeric threshold for converting predicted probabilities into presence-absence.</p>
</td></tr>
<tr><td><code id="variable_importance_+3A_n_repeats">n_repeats</code></td>
<td>
<p>An integer indicating the number of times to repeat the permutation for each variable.</p>
</td></tr>
<tr><td><code id="variable_importance_+3A_seed">seed</code></td>
<td>
<p>An optional seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame where each column corresponds to a predictor variable, and each row contains the variable importance scores across permutations.
</p>

<hr>
<h2 id='youdensIndex'>Calculate Youden's index</h2><span id='topic+youdensIndex'></span>

<h3>Description</h3>

<p>Calculate Youden's index
</p>


<h3>Usage</h3>

<pre><code class='language-R'>youdensIndex(actuals, predictedScores, threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="youdensIndex_+3A_actuals">actuals</code></td>
<td>
<p>The actual binary flags for the response variable. It can take a numeric vector containing values of either 1 or 0, where 1 represents the 'Good' or 'Events' while 0 represents 'Bad' or 'Non-Events'.</p>
</td></tr>
<tr><td><code id="youdensIndex_+3A_predictedscores">predictedScores</code></td>
<td>
<p>The prediction probability scores for each observation. If your classification model gives the 1/0 predcitions, convert it to a numeric vector of 1's and 0's.</p>
</td></tr>
<tr><td><code id="youdensIndex_+3A_threshold">threshold</code></td>
<td>
<p>If predicted value is above the threshold, it will be considered as an event (1), else it will be a non-event (0). Defaults to 0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was obtained from the InformationValue R package (<a href="https://github.com/selva86/InformationValue">https://github.com/selva86/InformationValue</a>).
</p>


<h3>Value</h3>

<p>The youdensIndex of the given binary response actuals and predicted probability scores, which is calculated as Sensitivity + Specificity - 1
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
