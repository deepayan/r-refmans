<!DOCTYPE html><html><head><title>Help for package KFAS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {KFAS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#[&lt;-.SSModel'><p>Extract or Replace Parts of a State Space Model</p></a></li>
<li><a href='#alcohol'><p>Alcohol related deaths in Finland 1969&ndash;2013</p></a></li>
<li><a href='#approxSSM'><p>Linear Gaussian Approximation for Exponential Family State Space Model</p></a></li>
<li><a href='#artransform'><p>Mapping real valued parameters to stationary region</p></a></li>
<li><a href='#boat'><p>Oxford-Cambridge boat race results 1829-2011</p></a></li>
<li><a href='#coef.SSModel'><p>Smoothed Estimates or One-step-ahead Predictions of States</p></a></li>
<li><a href='#confint.KFS'><p>Confidence Intervals of Smoothed States</p></a></li>
<li><a href='#fitSSM'><p>Maximum Likelihood Estimation of a State Space Model</p></a></li>
<li><a href='#fitted.SSModel'><p>Smoothed Estimates or One-step-ahead Predictions of Fitted Values</p></a></li>
<li><a href='#GlobalTemp'><p>Two series of average global temperature deviations for years 1880-1987</p></a></li>
<li><a href='#hatvalues.KFS'><p>Extract Hat Values from KFS Output</p></a></li>
<li><a href='#importanceSSM'><p>Importance Sampling of Exponential Family State Space Model</p></a></li>
<li><a href='#is.SSModel'><p>Test whether object is a valid <code>SSModel</code> object</p></a></li>
<li><a href='#KFAS'><p>KFAS: Functions for Exponential Family State Space Models</p></a></li>
<li><a href='#KFAS-defunct'><p>Defunct Functions of Package KFAS</p></a></li>
<li><a href='#KFS'><p>Kalman Filter and Smoother with Exact Diffuse Initialization for Exponential</p>
Family State Space Models</a></li>
<li><a href='#ldl'><p>LDL Decomposition of a Matrix</p></a></li>
<li><a href='#logLik.SSModel'><p>Log-likelihood of the State Space Model.</p></a></li>
<li><a href='#mvInnovations'><p>Multivariate Innovations</p></a></li>
<li><a href='#plot.SSModel'><p>Diagnostic Plots of State Space Models</p></a></li>
<li><a href='#predict.SSModel'><p>State Space Model Predictions</p></a></li>
<li><a href='#print.KFS'><p>Print Ouput of Kalman Filter and Smoother</p></a></li>
<li><a href='#print.SSModel'><p>Print SSModel Object</p></a></li>
<li><a href='#rename_states'><p>Rename the States of SSModel Object</p></a></li>
<li><a href='#residuals.KFS'><p>Extract Residuals of KFS output</p></a></li>
<li><a href='#rstandard.KFS'><p>Extract Standardized Residuals from KFS output</p></a></li>
<li><a href='#sexratio'><p>Number of males and females born in Finland from 1751 to 2011</p></a></li>
<li><a href='#signal'><p>Extracting the Partial Signal Of a State Space Model</p></a></li>
<li><a href='#simulateSSM'><p>Simulation of a Gaussian State Space Model</p></a></li>
<li><a href='#SSMarima'><p>Create a State Space Model Object of Class SSModel</p></a></li>
<li><a href='#transformSSM'><p>Transform Multivariate State Space Model for Sequential Processing</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.5.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Kalman Filter and Smoother for Exponential Family State Space
Models</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, lme4, MASS, Matrix, testthat</td>
</tr>
<tr>
<td>Description:</td>
<td>State space modelling is an efficient and flexible framework for 
    statistical inference of a broad class of time series and other data. KFAS 
    includes computationally efficient functions for Kalman filtering, smoothing, 
    forecasting, and simulation of multivariate exponential family state space models, 
    with observations from Gaussian, Poisson, binomial, negative binomial, and gamma 
    distributions. See the paper by Helske (2017) &lt;<a href="https://doi.org/10.18637%2Fjss.v078.i10">doi:10.18637/jss.v078.i10</a>&gt; for details.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/helske/KFAS/issues">https://github.com/helske/KFAS/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/helske/KFAS">https://github.com/helske/KFAS</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-25 17:15:33 UTC; jovetale</td>
</tr>
<tr>
<td>Author:</td>
<td>Jouni Helske <a href="https://orcid.org/0000-0001-7130-793X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jouni Helske &lt;jouni.helske@iki.fi&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-05 08:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+5B+26lt+3B-.SSModel'>Extract or Replace Parts of a State Space Model</h2><span id='topic++5B+3C-.SSModel'></span><span id='topic++5B.SSModel'></span>

<h3>Description</h3>

<p>S3 methods for getting and setting parts of object of class
<code>SSModel</code>. These methods ensure that dimensions of system matrices are
not altered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 replacement method for class 'SSModel'
x[element, states, etas, series, times, ...] &lt;- value

## S3 method for class 'SSModel'
x[element, states, etas, series, times, drop = TRUE, ...]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_x">x</code></td>
<td>
<p>Object of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_element">element</code></td>
<td>
<p>Which element(s) is chosen.  Typical values are <code>"y"</code>, 
<code>"Z"</code>, <code>"H"</code>, <code>"T"</code>, <code>"R"</code>, <code>"Q"</code>, <code>"a1"</code>, 
<code>"P1"</code>, <code>"P1inf"</code>, and <code>"u"</code>. See details.</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_states">states</code></td>
<td>
<p>Which states are chosen. Either a numeric vector containing the indices of the
states, or a character vector defining the types of the states. Possible choices are
<code>"all"</code>,  <code>"level"</code>, <code>"slope"</code>,
<code>"trend"</code>,  <code>"regression"</code>, <code>"arima"</code>, <code>"custom"</code>,
<code>"cycle"</code> or <code>"seasonal"</code>, where <code>"trend"</code> extracts all states relating to trend.
These can be combined. Default is <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_etas">etas</code></td>
<td>
<p>Which disturbances eta are chosen. Used for elements <code>"R"</code> and <code>"Q"</code>.
Either a numeric vector containing the indices of the etas, or a character vector defining the
types of the etas. Possible choices are <code>"all"</code>,  <code>"level"</code>, <code>"slope"</code>,
<code>"trend"</code>,  <code>"regression"</code>, <code>"arima"</code>, <code>"custom"</code>,
<code>"cycle"</code> or <code>"seasonal"</code>, where <code>"trend"</code> extracts all etas relating to trend.
These can be combined. Default is <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_series">series</code></td>
<td>
<p>Numeric. Which series are chosen. Used for elements
<code>"y"</code>, <code>"Z"</code>, and <code>"u"</code>.</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_times">times</code></td>
<td>
<p>Numeric. Which time points are chosen.</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_value">value</code></td>
<td>
<p>A value to be assigned to x.</p>
</td></tr>
<tr><td><code id="+2B5B+2B26lt+2B3B-.SSModel_+3A_drop">drop</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default) the result is coerced to the lowest possible
dimension.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>element</code> is not one of 
<code>"y"</code>, <code>"Z"</code>, <code>"H"</code>, <code>"T"</code>, <code>"R"</code>, <code>"Q"</code>, 
<code>"a1"</code>, <code>"P1"</code>, <code>"P1inf"</code>, <code>"u"</code>,
the default single bracket list extraction 
and assignments (<code>x[element]</code> and <code>x[element] &lt;- value</code>) 
are used (and other arguments are ignored). 
</p>
<p>If <code>element</code> is one of 
<code>"y"</code>, <code>"Z"</code>, <code>"H"</code>, <code>"T"</code>, <code>"R"</code>, <code>"Q"</code>, 
<code>"a1"</code>, <code>"P1"</code>, <code>"P1inf"</code>, <code>"u"</code> and if the arguments 
<code>states</code>, <code>etas</code>, <code>times</code> and <code>series</code> are 
all missing, the double bracket list 
extraction <code>x[[element]]</code> and modified double bracket list assignment
<code>x[[element]][] &lt;- value</code> are used.
</p>
<p>If neither of above holds, then for example in case of <code>element = Z</code> 
the extraction is of form <code>x$Z[series, states, times, drop]</code>.
</p>


<h3>Value</h3>

<p>A selected subset of the chosen element or a value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
model &lt;- SSModel(rnorm(10) ~ 1)
model["H"]
model["H"] &lt;- 10
# H is still an array:
model["H"]
logLik(model)
model$H &lt;- 1
# model["H"] throws an error as H is now scalar:
model$H
logLik(model, check.model = TRUE) #with check.model = FALSE R crashes!
</code></pre>

<hr>
<h2 id='alcohol'>Alcohol related deaths in Finland 1969&ndash;2013</h2><span id='topic+alcohol'></span>

<h3>Description</h3>

<p>A multivariate time series object containing the number of alcohol related
deaths and population sizes (divided by 100000) of Finland in four age groups.
See JSS paper for examples.
</p>


<h3>Format</h3>

<p>A multivariate time series object with 45 times 8 observations.
</p>


<h3>Source</h3>

<p>Statistics Finland <a href="https://statfin.stat.fi/PxWeb/pxweb/en/StatFin/">https://statfin.stat.fi/PxWeb/pxweb/en/StatFin/</a>.
</p>

<hr>
<h2 id='approxSSM'>Linear Gaussian Approximation for Exponential Family State Space Model</h2><span id='topic+approxSSM'></span>

<h3>Description</h3>

<p>Function <code>approxSMM</code> performs a linear Gaussian approximation of an
exponential family state space model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>approxSSM(
  model,
  theta,
  maxiter = 50,
  tol = 1e-08,
  expected = FALSE,
  H_tol = 1e+15
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="approxSSM_+3A_model">model</code></td>
<td>
<p>A non-Gaussian state space model object of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="approxSSM_+3A_theta">theta</code></td>
<td>
<p>Initial values for conditional mode theta.</p>
</td></tr>
<tr><td><code id="approxSSM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations used in approximation.
Default is 50.</p>
</td></tr>
<tr><td><code id="approxSSM_+3A_tol">tol</code></td>
<td>
<p>Tolerance parameter for convergence checks.</p>
</td></tr>
<tr><td><code id="approxSSM_+3A_expected">expected</code></td>
<td>
<p>Logical value defining the approximation of H_t in case of Gamma 
and negative binomial distribution. Default is <code>FALSE</code> which matches the 
algorithm of Durbin &amp; Koopman (1997), whereas <code>TRUE</code> uses the expected value
of observations in the equations, leading to results which match with <code>glm</code> (where applicable).
The latter case was the default behaviour of KFAS before version 1.3.8.
Essentially this is the difference between observed and expected information.</p>
</td></tr>
<tr><td><code id="approxSSM_+3A_h_tol">H_tol</code></td>
<td>
<p>Tolerance parameter for check <code>max(H) &gt; tol_H</code>, which suggests that the approximation 
converged to degenerate case with near zero signal-to-noise ratio. Default is very generous 1e15.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is rarely needed itself, it is mainly available for
illustrative and debugging purposes. The underlying Fortran code is used by
other functions of KFAS for non-Gaussian state space modelling.
</p>
<p>The linear Gaussian approximating model is defined by
</p>
<p style="text-align: center;"><code class="reqn">\tilde y_t = Z_t \alpha_t + \epsilon_t, \quad \epsilon_t \sim N(0,\tilde H_t),</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha_{t+1} = T_t \alpha_t + R_t \eta_t, \quad \eta_t \sim N(0,Q_t),</code>
</p>

<p>and <code class="reqn">\alpha_1 \sim N(a_1,P_1)</code>,
</p>
<p>where <code class="reqn">\tilde y</code> and <code class="reqn">\tilde H</code> are chosen in a way
that the linear Gaussian approximating model has the same conditional mode of
<code class="reqn">\theta=Z\alpha</code> given the observations <code class="reqn">y</code> as the original
non-Gaussian model. Models also have a same curvature at the mode.
</p>
<p>The approximation of the exponential family state space model is based on
iterative weighted least squares method, see McCullagh and Nelder (1983) p.31
and Durbin Koopman (2012) p. 243.
</p>


<h3>Value</h3>

<p>An object of class <code>SSModel</code> which contains the approximating Gaussian state space model
with following additional components:
</p>
<table>
<tr><td><code>thetahat</code></td>
<td>
<p>Mode of <code class="reqn">p(\theta|y)</code>. </p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>Number of iterations used. </p>
</td></tr>
<tr><td><code>difference</code></td>
<td>
<p>Relative difference in the last step of approximation
algorithm. </p>
</td></tr>
</table>


<h3>References</h3>

 <ul>
<li><p> McCullagh, P. and Nelder, J. A. (1983).
Generalized linear models. Chapman and Hall.
</p>
</li>
<li><p> Koopman, S.J. and Durbin, J. (2012).
Time Series Analysis by State Space Methods. Second edition. Oxford University Press. </p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+importanceSSM">importanceSSM</a></code>, <code><a href="#topic+SSModel">SSModel</a></code>,
<code><a href="#topic+KFS">KFS</a></code>, <code><a href="#topic+KFAS">KFAS</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# A Gamma example modified from ?glm (with log-link)
clotting &lt;- data.frame(
  u = c(5,10,15,20,30,40,60,80,100),
  lot1 = c(118,58,42,35,27,25,21,19,18),
  lot2 = c(69,35,26,21,18,16,13,12,12))

glmfit1 &lt;- glm(lot1 ~ log(u), data = clotting, family = Gamma(link = "log"))
glmfit2 &lt;- glm(lot2 ~ log(u), data = clotting, family = Gamma(link = "log"))

# Model lot1 and lot2 together (they are still assumed independent)
# Note that Gamma distribution is parameterized by 1/dispersion i.e. shape parameter
model &lt;- SSModel(cbind(lot1, lot2) ~ log(u),
                u = 1/c(summary(glmfit1)$dispersion, summary(glmfit2)$dispersion),
                data = clotting, distribution = "gamma")
approxmodel &lt;- approxSSM(model)

# Conditional modes of linear predictor:
approxmodel$thetahat
cbind(glmfit1$linear.predictor, glmfit2$linear.predictor)

KFS(approxmodel)
summary(glmfit1)
summary(glmfit2)

# approxSSM uses modified step-halving for more robust convergence than glm:
y &lt;- rep (0:1, c(15, 10))
suppressWarnings(glm(formula = y ~ 1, family = binomial(link = "logit"), start = 2))
model &lt;- SSModel(y~1, dist = "binomial")
KFS(model, theta = 2)
KFS(model, theta = 7)
</code></pre>

<hr>
<h2 id='artransform'>Mapping real valued parameters to stationary region</h2><span id='topic+artransform'></span>

<h3>Description</h3>

<p>Function <code>artransform</code> transforms <code class="reqn">p</code> real valued parameters to
stationary region of <code class="reqn">p</code>th order autoregressive process using
parametrization suggested by Jones (1980). Fortran code is a converted from
<code>stats</code> package's C-function <code>partrans</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>artransform(param)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="artransform_+3A_param">param</code></td>
<td>
<p>Real valued parameters for the transformation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>transformed The parameters satisfying the stationary constrains.
</p>


<h3>Note</h3>

<p>This should in theory always work, but in practice the initial transformation 
by <code>tanh</code> can produce values numerically identical to 1, leading to AR coefficients 
which do not satisfy the stationarity constraints. See example in <code>logLik.SSModel</code> on how
to scope with those issues.
</p>


<h3>References</h3>

<p>Jones, R. H (1980). Maximum likelihood fitting
of ARMA models to time series with missing observations, Technometrics
Vol 22. p. 389&ndash;395.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>artransform(1:3)
</code></pre>

<hr>
<h2 id='boat'>Oxford-Cambridge boat race results 1829-2011</h2><span id='topic+boat'></span>

<h3>Description</h3>

<p>Results of the annual boat race between universities of Oxford (0) and Cambridge (1).
</p>


<h3>Format</h3>

<p>A time series object containing 183 observations (including 28 missing observations).
</p>


<h3>Source</h3>

<p>http://www.ssfpack.com/DKbook.html
</p>


<h3>References</h3>

<p>Koopman, S.J. and Durbin J. (2012). Time Series Analysis by State Space Methods. Oxford: Oxford University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("boat")

# Model from DK2012, bernoulli response based on random walk
model &lt;- SSModel(boat ~ SSMtrend(1, Q = NA), distribution = "binomial")

fit_nosim &lt;- fitSSM(model, inits = log(0.25), method = "BFGS", hessian = TRUE)
# nsim set to small for faster execution of example
# doesn't matter here as the model/data is so poor anyway
fit_sim &lt;- fitSSM(model, inits = log(0.25), method = "BFGS", hessian = TRUE, nsim = 100)

# Compare with the results from DK2012
model_DK &lt;- SSModel(boat ~ SSMtrend(1, Q = 0.33), distribution = "binomial")

# Big difference in variance parameters:
fit_nosim$model["Q"]
fit_sim$model["Q"]

# approximate 95% confidence intervals for variance parameter:
# very wide, there really isn't enough information in the data
# as a comparison, a fully Bayesian approach (using BUGS) with [0, 10] uniform prior for sigma
# gives posterior mode for Q as 0.18, and 95% credible interval [0.036, 3.083]

exp(fit_nosim$optim.out$par + c(-1, 1)*qnorm(0.975)*sqrt(1/fit_nosim$optim.out$hessian[1]))
exp(fit_sim$optim.out$par + c(-1, 1)*qnorm(0.975)*sqrt(1/fit_sim$optim.out$hessian[1]))

# 95% confidence intervals for probability that Cambridge wins
pred_nosim &lt;- predict(fit_nosim$model, interval = "confidence")
pred_sim &lt;- predict(fit_sim$model, interval = "confidence")
ts.plot(pred_nosim, pred_sim, col = c(1, 2, 2, 3, 4, 4), lty = c(1, 2, 2), ylim = c(0, 1))
points(x = time(boat), y = boat, pch = 15, cex = 0.5)

# if we trust the approximation, fit_nosim gives largest log-likelihood:
logLik(fit_nosim$model)
logLik(fit_sim$model)
logLik(model_DK)

# and using importance sampling fit_sim is the best:
logLik(fit_nosim$model, nsim = 100)
logLik(fit_sim$model, nsim = 100)
logLik(model_DK, nsim = 100)

## Not run: 
# only one unknown parameter, easy to check the shape of likelihood:
# very flat, as was expected based on Hessian
ll_nosim &lt;- Vectorize(function(x) {
  model["Q"] &lt;- x
  logLik(model)
})
ll_sim &lt;- Vectorize(function(x) {
  model["Q"] &lt;- x
  logLik(model, nsim = 100)
})
curve(ll_nosim(x), from = 0.1, to = 0.5, ylim = c(-106, -104.5))
curve(ll_sim(x), from = 0.1, to = 0.5, add = TRUE, col = "red")

## End(Not run)
</code></pre>

<hr>
<h2 id='coef.SSModel'>Smoothed Estimates or One-step-ahead Predictions of States</h2><span id='topic+coef.SSModel'></span><span id='topic+coef.KFS'></span>

<h3>Description</h3>

<p>Compute smoothed estimates or one-step-ahead predictions of states of
<code>SSModel</code> object or extract them from output of <code>KFS</code>.
For non-Gaussian models without simulation (<code>nsim = 0</code>),
these are the estimates of conditional modes of
states. For Gaussian models and non-Gaussian models with importance sampling,
these are the estimates of conditional means of states.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KFS'
coef(
  object,
  start = NULL,
  end = NULL,
  filtered = FALSE,
  states = "all",
  last = FALSE,
  ...
)

## S3 method for class 'SSModel'
coef(
  object,
  start = NULL,
  end = NULL,
  filtered = FALSE,
  states = "all",
  last = FALSE,
  nsim = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.SSModel_+3A_object">object</code></td>
<td>
<p>An object of class <code>KFS</code> or <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="coef.SSModel_+3A_start">start</code></td>
<td>
<p>The start time of the period of interest. Defaults to first time
point of the object.</p>
</td></tr>
<tr><td><code id="coef.SSModel_+3A_end">end</code></td>
<td>
<p>The end time of the period of interest. Defaults to the last time
point of the object.</p>
</td></tr>
<tr><td><code id="coef.SSModel_+3A_filtered">filtered</code></td>
<td>
<p>Logical, return filtered instead of smoothed estimates of
state vector. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="coef.SSModel_+3A_states">states</code></td>
<td>
<p>Which states to extract? Either a numeric vector containing
the indices of the corresponding states, or a character vector defining the
types of the corresponding states. Possible choices are
<code>"all"</code>,  <code>"level"</code>, <code>"slope"</code>,
<code>"trend"</code>,  <code>"regression"</code>, <code>"arima"</code>, <code>"custom"</code>,
<code>"cycle"</code> or <code>"seasonal"</code>, where <code>"trend"</code> extracts all states
relating to trend. These can be combined. Default is <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="coef.SSModel_+3A_last">last</code></td>
<td>
<p>If <code>TRUE</code>, extract only the last time point as numeric vector
(ignoring <code>start</code> and <code>end</code>). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="coef.SSModel_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="#topic+KFS">KFS</a></code>.
Ignored in method for object of class <code>KFS</code>.</p>
</td></tr>
<tr><td><code id="coef.SSModel_+3A_nsim">nsim</code></td>
<td>
<p>Only for method for for non-Gaussian model of class <code>SSModel</code>.
The number of independent samples used in importance sampling.
Default is 0, which computes the
approximating Gaussian model by <code><a href="#topic+approxSSM">approxSSM</a></code> and performs the
usual Gaussian filtering/smoothing so that the smoothed state estimates
equals to the conditional mode of <code class="reqn">p(\alpha_t|y)</code>.
In case of <code>nsim = 0</code>, the mean estimates and their variances are computed using
the Delta method (ignoring the covariance terms).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Multivariate time series containing estimates states.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- SSModel(log(drivers) ~ SSMtrend(1, Q = list(1)) +
 SSMseasonal(period = 12, sea.type = "trigonometric") +
 log(PetrolPrice) + law, data = Seatbelts, H = 1)

coef(model, states = "regression", last = TRUE)
coef(model, start = c(1983, 12), end = c(1984, 2))
out &lt;- KFS(model)
coef(out, states = "regression", last = TRUE)
coef(out, start = c(1983, 12), end = c(1984, 2))

</code></pre>

<hr>
<h2 id='confint.KFS'>Confidence Intervals of Smoothed States</h2><span id='topic+confint.KFS'></span>

<h3>Description</h3>

<p>Extract confidence intervals of the smoothed estimates of states from the 
output of <code>KFS</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KFS'
confint(object, parm = "all", level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.KFS_+3A_object">object</code></td>
<td>
<p>An object of class <code>KFS</code>.</p>
</td></tr>
<tr><td><code id="confint.KFS_+3A_parm">parm</code></td>
<td>
<p>Which states to extract? Either a numeric vector containing
the indices of the corresponding states, or a character vector defining the
types of the corresponding states. Possible choices are
<code>"all"</code>,  <code>"level"</code>, <code>"slope"</code>,
<code>"trend"</code>,  <code>"regression"</code>, <code>"arima"</code>, <code>"custom"</code>,
<code>"cycle"</code> or <code>"seasonal"</code>, where <code>"trend"</code> extracts all states
relating to trend. These can be combined. Default is <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="confint.KFS_+3A_level">level</code></td>
<td>
<p>The confidence level required. Defaults to 0.95.</p>
</td></tr>
<tr><td><code id="confint.KFS_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of confidence intervals for each state
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- SSModel(log(drivers) ~ SSMtrend(1, Q = list(1)) +
 SSMseasonal(period = 12, sea.type = "trigonometric") +
 log(PetrolPrice) + law, data = Seatbelts, H = 1)
out &lt;- KFS(model)

confint(out, parm = "regression")

</code></pre>

<hr>
<h2 id='fitSSM'>Maximum Likelihood Estimation of a State Space Model</h2><span id='topic+fitSSM'></span>

<h3>Description</h3>

<p>Function <code>fitSSM</code> finds the maximum likelihood estimates for unknown
parameters of an arbitary state space model, given the user-defined model
updating function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitSSM(model, inits, updatefn, checkfn, update_args = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitSSM_+3A_model">model</code></td>
<td>
<p>Model object of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="fitSSM_+3A_inits">inits</code></td>
<td>
<p>Initial values for <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
<tr><td><code id="fitSSM_+3A_updatefn">updatefn</code></td>
<td>
<p>User defined function which updates the model given the
parameters. Must be of form <code>updatefn(pars, model, ...)</code>,
where <code>...</code> correspond to optional additional arguments.
Function should return the original model with updated parameters.
See details for description of the default <code>updatefn</code>.</p>
</td></tr>
<tr><td><code id="fitSSM_+3A_checkfn">checkfn</code></td>
<td>
<p>Optional function of form <code>checkfn(model)</code> for checking
the validity of the model. Should return <code>TRUE</code> if the model is valid,
and <code>FALSE</code> otherwise. See details.</p>
</td></tr>
<tr><td><code id="fitSSM_+3A_update_args">update_args</code></td>
<td>
<p>Optional list containing additional arguments to <code>updatefn</code>.</p>
</td></tr>
<tr><td><code id="fitSSM_+3A_...">...</code></td>
<td>
<p>Further arguments for functions <code>optim</code> and
<code>logLik.SSModel</code>, such as <code>nsim = 1000</code>, <code>marginal = TRUE</code>, 
and <code>method = "BFGS"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>fitSSM</code> actually minimizes <code>-logLik(model)</code>, so for
example the Hessian matrix returned by <code>hessian = TRUE</code> has an opposite
sign than expected.
</p>
<p>This function is simple wrapper around <code><a href="stats.html#topic+optim">optim</a></code>. For optimal performance in
complicated problems, it is more efficient to use problem specific codes with
calls to <code>logLik</code> method directly.
</p>
<p>In <code>fitSSM</code>, the objective function for <code><a href="stats.html#topic+optim">optim</a></code> first
updates the model based on the current values of the parameters under optimization,
using function <code>updatefn</code>. Then function <code>checkfn</code>
is used for checking that the resulting model is valid
(the default <code>checkfn</code> checks for non-finite values and overly large (&gt;1e7)
values in covariance matrices). If <code>checkfn</code> returns <code>TRUE</code>,  the
log-likelihood is computed using a call <code>-logLik(model,check.model = FALSE)</code>.
Otherwise objective function returns value corresponding to
<code>.Machine$double.xmax^0.75</code>.
</p>
<p>The default <code>updatefn</code> can be used to estimate the values marked as <code>NA</code>
in unconstrained time-invariant covariance matrices Q and H. Note that the
default <code>updatefn</code> function cannot be used with trigonometric seasonal
components as its covariance structure is of form <code class="reqn">\sigma</code>I,
i.e. not all <code>NA</code>'s correspond to unique value.
</p>
<p>The code for the default <code>updatefn</code> can be found in the examples.
As can be seen from the function definition, it is assumed that
unconstrained optimization method such as <code>BFGS</code> is used.
</p>
<p>Note that for non-Gaussian models derivative-free optimization methods such as
Nelder-Mead might be more reliable than methods which use finite difference
approximations. This is due to noise caused by the relative stopping criterion
used for finding approximating Gaussian model. In most cases this does not
seem to cause any problems though.
</p>


<h3>Value</h3>

<p>A list with elements
</p>
<table>
<tr><td><code>optim.out</code></td>
<td>
<p>Output from function <code>optim</code>. </p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Model with estimated parameters. </p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+logLik">logLik</a></code>, <code><a href="#topic+KFAS">KFAS</a></code>, 
<code><a href="#topic+boat">boat</a></code>, <code><a href="#topic+sexratio">sexratio</a></code>,
<code><a href="#topic+GlobalTemp">GlobalTemp</a></code>, <code><a href="#topic+SSModel">SSModel</a></code>, 
<code><a href="#topic+importanceSSM">importanceSSM</a></code>, <code><a href="#topic+approxSSM">approxSSM</a></code> for more examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example function for updating covariance matrices H and Q
# (also used as a default function in fitSSM)

updatefn &lt;- function(pars, model){
  if(any(is.na(model$Q))){
    Q &lt;- as.matrix(model$Q[,,1])
    naQd  &lt;- which(is.na(diag(Q)))
    naQnd &lt;- which(upper.tri(Q[naQd,naQd]) &amp; is.na(Q[naQd,naQd]))
    Q[naQd,naQd][lower.tri(Q[naQd,naQd])] &lt;- 0
    diag(Q)[naQd] &lt;- exp(0.5 * pars[1:length(naQd)])
    Q[naQd,naQd][naQnd] &lt;- pars[length(naQd)+1:length(naQnd)]
    model$Q[naQd,naQd,1] &lt;- crossprod(Q[naQd,naQd])
  }
 if(!identical(model$H,'Omitted') &amp;&amp; any(is.na(model$H))){#'
   H&lt;-as.matrix(model$H[,,1])
   naHd  &lt;- which(is.na(diag(H)))
   naHnd &lt;- which(upper.tri(H[naHd,naHd]) &amp; is.na(H[naHd,naHd]))
   H[naHd,naHd][lower.tri(H[naHd,naHd])] &lt;- 0
   diag(H)[naHd] &lt;-
     exp(0.5 * pars[length(naQd)+length(naQnd)+1:length(naHd)])
   H[naHd,naHd][naHnd] &lt;-
     pars[length(naQd)+length(naQnd)+length(naHd)+1:length(naHnd)]
   model$H[naHd,naHd,1] &lt;- crossprod(H[naHd,naHd])
   }
 model
}

# Example function for checking the validity of covariance matrices.

checkfn &lt;- function(model){
  #test positive semidefiniteness of H and Q
  !inherits(try(ldl(model$H[,,1]),TRUE),'try-error') &amp;&amp;
  !inherits(try(ldl(model$Q[,,1]),TRUE),'try-error')
}


model &lt;- SSModel(Nile ~ SSMtrend(1, Q = list(matrix(NA))), H = matrix(NA))

#function for updating the model
update_model &lt;- function(pars, model) {
  model["H"] &lt;- pars[1]
  model["Q"] &lt;- pars[2]
  model
}

#check that variances are non-negative
check_model &lt;- function(model) {
  (model["H"] &gt; 0 &amp;&amp; model["Q"] &gt; 0)
}

fit &lt;- fitSSM(inits = rep(var(Nile)/5, 2), model = model,
                 updatefn = update_model, checkfn = check_model)

# More complex model

set.seed(1)

n &lt;- 1000

x1 &lt;- rnorm(n)
x2 &lt;- rnorm(n)
beta1 &lt;- 1 + cumsum(rnorm(n, sd = 0.1)) # time-varying regression effect
beta2 &lt;- -0.3 # time-invariant effect

# ARMA(2, 1) errors
z &lt;- arima.sim(model = list(ar = c(0.7, -0.4), ma = 0.5), n = n, sd = 0.5)

# generate data, regression part + ARMA errors
y &lt;- beta1 * x1 + beta2 * x2 + z
ts.plot(y)

# build the model using just zeros for now
# But note no extra white noise term so H is fixed to zero
model &lt;- SSModel(y ~ SSMregression(~ x1 + x2, Q = 0, R = matrix(c(1, 0), 2, 1)) +
  SSMarima(rep(0, 2), 0, Q = 0), H = 0) 

# update function for fitSSM

update_function &lt;- function(pars, model){

  ## separate calls for model components, use exp to ensure positive variances
  tmp_reg &lt;- SSMregression(~ x1 + x2, Q = exp(pars[1]), R = matrix(c(1, 0), 2, 1))
  tmp_arima &lt;- try(SSMarima(artransform(pars[2:3]), 
    artransform(pars[4]), Q = exp(pars[5])), silent = TRUE)
  
  # stationary check, see note in artransform docs
  if(inherits(tmp_arima, "try-error")) {
    model$Q[] &lt;- NA # set something to NA just in case original model is ok
    return(model) # this goes to checkfn and causes rejection due to NA values
  }
  
  model["Q", etas = "regression"] &lt;- tmp_reg$Q
  model["Q", etas = "arima"] &lt;- tmp_arima$Q
  
  model["T", "arima"] &lt;- tmp_arima$T
  model["R", states = "arima", etas = "arima"] &lt;- tmp_arima$R
  model["P1", "arima"] &lt;- tmp_arima$P1
  
  # you could also directly build the whole model here again, i.e.
  # model &lt;- SSModel(y ~ 
  #   SSMregression(~ x1 + x2, Q = exp(pars[1]), R = matrix(c(1, 0), 2, 1)) +
  #   SSMarima(artransform(pars[2:3]), artransform(pars[4]), Q = exp(pars[5])), 
  #   H = 0)
  
  model
  
}
fit  &lt;- fitSSM(model = model,
  inits = rep(0.1, 5),
  updatefn = update_function, method = "BFGS")

ts.plot(cbind(beta1, KFS(fit$model)$alphahat[, "x1"]), col = 1:2)

</code></pre>

<hr>
<h2 id='fitted.SSModel'>Smoothed Estimates or One-step-ahead Predictions of Fitted Values</h2><span id='topic+fitted.SSModel'></span><span id='topic+fitted.KFS'></span>

<h3>Description</h3>

<p>Computes fitted values from output of <code>KFS</code>
(or using the <code>SSModel</code> object), i.e. one-step-ahead
predictions  <code class="reqn">f(\theta_t | y_{t-1}, \ldots, y_1)</code> (<code>m</code>) or smoothed estimates
<code class="reqn">f(\theta_t | y_n, \ldots, y_1)</code> (<code>muhat</code>),
where <code class="reqn">f</code> is the inverse of the link function
(identity in Gaussian case), except in case of Poisson distribution where
<code class="reqn">f</code> is multiplied with the exposure <code class="reqn">u_t</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KFS'
fitted(object, start = NULL, end = NULL, filtered = FALSE, ...)

## S3 method for class 'SSModel'
fitted(object, start = NULL, end = NULL, filtered = FALSE, nsim = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.SSModel_+3A_object">object</code></td>
<td>
<p>An object of class <code>KFS</code> or <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="fitted.SSModel_+3A_start">start</code></td>
<td>
<p>The start time of the period of interest. Defaults to first time
point of the object.</p>
</td></tr>
<tr><td><code id="fitted.SSModel_+3A_end">end</code></td>
<td>
<p>The end time of the period of interest. Defaults to the last time
point of the object.</p>
</td></tr>
<tr><td><code id="fitted.SSModel_+3A_filtered">filtered</code></td>
<td>
<p>Logical, return filtered instead of smoothed estimates of
state vector. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fitted.SSModel_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="#topic+KFS">KFS</a></code>.
Ignored in method for object of class <code>KFS</code>.</p>
</td></tr>
<tr><td><code id="fitted.SSModel_+3A_nsim">nsim</code></td>
<td>
<p>Only for method for for non-Gaussian model of class <code>SSModel</code>.
The number of independent samples used in importance sampling.
Default is 0, which computes the
approximating Gaussian model by <code><a href="#topic+approxSSM">approxSSM</a></code> and performs the
usual Gaussian filtering/smoothing so that the smoothed state estimates
equals to the conditional mode of <code class="reqn">p(\alpha_t|y)</code>.
In case of <code>nsim = 0</code>, the mean estimates and their variances are computed using
the Delta method (ignoring the covariance terms).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Multivariate time series containing fitted values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+signal">signal</a></code> for partial signals and their covariances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("sexratio")
model &lt;- SSModel(Male ~ SSMtrend(1,Q = list(NA)),u = sexratio[, "Total"],
  data = sexratio, distribution = "binomial")
model &lt;- fitSSM(model,inits = -15, method = "BFGS")$model
out &lt;- KFS(model)
identical(drop(out$muhat), fitted(out))

fitted(model)
</code></pre>

<hr>
<h2 id='GlobalTemp'>Two series of average global temperature deviations for years 1880-1987</h2><span id='topic+GlobalTemp'></span>

<h3>Description</h3>

<p>This data set contains two series of average global temperature deviations
for years 1880-1987. These series are same as used in Shumway and Stoffer
(2006), where they are known as HL and Folland series. For more details, see
Shumway and Stoffer (2006, p. 327).
</p>


<h3>Format</h3>

<p>A time series object containing 108 times 2 observations.
</p>


<h3>Source</h3>

<p>http://lib.stat.cmu.edu/general/stoffer/tsa2/
</p>


<h3>References</h3>

<p>Shumway, Robert H. and Stoffer, David S. (2006). Time Series
Analysis and Its Applications: With R examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example of multivariate local level model with only one state
# Two series of average global temperature deviations for years 1880-1987
# See Shumway and Stoffer (2006), p. 327 for details

data("GlobalTemp")

model_temp &lt;- SSModel(GlobalTemp ~ SSMtrend(1, Q = NA, type = "common"),
  H = matrix(NA, 2, 2))

# Estimating the variance parameters
inits &lt;- chol(cov(GlobalTemp))[c(1, 4, 3)]
inits[1:2] &lt;- log(inits[1:2])
fit_temp &lt;- fitSSM(model_temp, c(0.5*log(.1), inits), method = "BFGS")

out_temp &lt;- KFS(fit_temp$model)

ts.plot(cbind(model_temp$y, coef(out_temp)), col = 1:3)
legend("bottomright",
  legend = c(colnames(GlobalTemp), "Smoothed signal"), col = 1:3, lty = 1)

</code></pre>

<hr>
<h2 id='hatvalues.KFS'>Extract Hat Values from KFS Output</h2><span id='topic+hatvalues.KFS'></span>

<h3>Description</h3>

<p>Extract hat values from KFS output, when <code>KFS</code> was run with signal
(non-Gaussian case) or mean smoothing (Gaussian case).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KFS'
hatvalues(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hatvalues.KFS_+3A_model">model</code></td>
<td>
<p>An object of class <code>KFS</code>.</p>
</td></tr>
<tr><td><code id="hatvalues.KFS_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code>approxSSM</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hat values in <code>KFAS</code> are defined as the diagonal elements of <code>V_t/H_t</code> where V_t
is the covariance matrix of signal/mean at time t and H_t is the covariance
matrix of disturbance vector <code class="reqn">\epsilon</code> of (approximating) Gaussian model
at time t. This definition gives identical results with the standard
definition in case of GLMs. Note that it is possible to construct a state
space model where this definition is not meaningful (for example the
covariance matrix H_t can contain zeros on diagonal).
</p>


<h3>Value</h3>

<p>Multivariate time series containing hat values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- SSModel(sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings)
out &lt;- KFS(model, filtering = "state", smoothing = "none")
# estimate sigma2
model["H"] &lt;- mean(c(out$v[1:out$d][out$Finf==0]^2/out$F[1:out$d][out$Finf==0],
                     out$v[-(1:out$d)]^2/out$F[-(1:out$d)]))
c(hatvalues(KFS(model)))

</code></pre>

<hr>
<h2 id='importanceSSM'>Importance Sampling of Exponential Family State Space Model</h2><span id='topic+importanceSSM'></span>

<h3>Description</h3>

<p>Function <code>importanceSSM</code> simulates states or signals of the exponential
family state space model conditioned with the observations, returning the
simulated samples of the states/signals with the corresponding importance
weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importanceSSM(
  model,
  type = c("states", "signals"),
  filtered = FALSE,
  nsim = 1000,
  save.model = FALSE,
  theta,
  antithetics = FALSE,
  maxiter = 50,
  expected = FALSE,
  H_tol = 1e+15
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importanceSSM_+3A_model">model</code></td>
<td>
<p>Exponential family state space model of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_type">type</code></td>
<td>
<p>What to simulate, <code>"states"</code> or <code>"signals"</code>. Default is
<code>"states"</code></p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_filtered">filtered</code></td>
<td>
<p>Simulate from <code class="reqn">p(\alpha_t|y_{t-1},...,y_1)</code> instead of
<code class="reqn">p(\alpha|y)</code>. Note that for large models this can be very slow. Default is FALSE.</p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_nsim">nsim</code></td>
<td>
<p>Number of independent samples. Default is 1000.</p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_save.model">save.model</code></td>
<td>
<p>Return the original model with the samples. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_theta">theta</code></td>
<td>
<p>Initial values for the conditional mode theta.</p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_antithetics">antithetics</code></td>
<td>
<p>Logical. If TRUE, two antithetic variables are used in
simulations, one for location and another for scale. Default is FALSE.</p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations used in linearisation. Default is
50.</p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_expected">expected</code></td>
<td>
<p>Logical value defining the approximation of H_t in case of Gamma 
and negative binomial distribution. Default is <code>FALSE</code> which matches the 
algorithm of Durbin &amp; Koopman (1997), whereas <code>TRUE</code> uses the expected value
of observations in the equations, leading to results which match with <code>glm</code> (where applicable).
The latter case was the default behaviour of KFAS before version 1.3.8.
Essentially this is the difference between observed and expected information.</p>
</td></tr>
<tr><td><code id="importanceSSM_+3A_h_tol">H_tol</code></td>
<td>
<p>Tolerance parameter for check <code>max(H) &gt; H_tol</code>, which suggests that the approximation 
converged to degenerate case with near zero signal-to-noise ratio. Default is very generous 1e15.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function can use two antithetic variables, one for location and other for
scale, so output contains four blocks of simulated values which correlate
which each other (ith block correlates negatively with (i+1)th block, and
positively with (i+2)th block etc.).
</p>


<h3>Value</h3>

<p>A list containing elements
</p>
<table>
<tr><td><code>samples</code></td>
<td>
<p>Simulated samples. </p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>Importance weights. </p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Original model in case of <code>save.model==TRUE</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data("sexratio")
model &lt;- SSModel(Male ~ SSMtrend(1, Q = list(NA)), u = sexratio[,"Total"], data = sexratio,
                distribution = "binomial")
fit &lt;- fitSSM(model, inits = -15, method = "BFGS")
fit$model$Q #1.107652e-06
# Computing confidence intervals for sex ratio
# Uses importance sampling on response scale (1000 samples with antithetics)
set.seed(1)
imp &lt;- importanceSSM(fit$model, nsim = 250, antithetics = TRUE)
sexratio.smooth &lt;- numeric(length(model$y))
sexratio.ci &lt;- matrix(0, length(model$y), 2)
w &lt;- imp$w/sum(imp$w)
for(i in 1:length(model$y)){
  sexr &lt;- exp(imp$sample[i,1,])
  sexratio.smooth[i]&lt;-sum(sexr*w)
  oo &lt;- order(sexr)
  sexratio.ci[i,] &lt;- c(sexr[oo][which.min(abs(cumsum(w[oo]) - 0.05))],
                   sexr[oo][which.min(abs(cumsum(w[oo]) - 0.95))])
}

## Not run: 
# Filtered estimates
impf &lt;- importanceSSM(fit$model, nsim = 250, antithetics = TRUE,filtered=TRUE)
sexratio.filter &lt;- rep(NA,length(model$y))
sexratio.fci &lt;- matrix(NA, length(model$y), 2)
w &lt;- impf$w/rowSums(impf$w)
for(i in 2:length(model$y)){
  sexr &lt;- exp(impf$sample[i,1,])
  sexratio.filter[i] &lt;- sum(sexr*w[i,])
  oo&lt;-order(sexr)
  sexratio.fci[i,] &lt;- c(sexr[oo][which.min(abs(cumsum(w[i,oo]) - 0.05))],
                    sexr[oo][which.min(abs(cumsum(w[i,oo]) - 0.95))])
}

ts.plot(cbind(sexratio.smooth,sexratio.ci,sexratio.filter,sexratio.fci),
        col=c(1,1,1,2,2,2),lty=c(1,2,2,1,2,2))

## End(Not run)
</code></pre>

<hr>
<h2 id='is.SSModel'>Test whether object is a valid <code>SSModel</code> object</h2><span id='topic+is.SSModel'></span>

<h3>Description</h3>

<p>Function <code>is.SSModel</code> tests whether the object is a valid <code>SSModel</code>
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.SSModel(object, na.check = FALSE, return.logical = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.SSModel_+3A_object">object</code></td>
<td>
<p>An object to be tested.</p>
</td></tr>
<tr><td><code id="is.SSModel_+3A_na.check">na.check</code></td>
<td>
<p>Test the system matrices for <code>NA</code> and infinite values.
Also checks for large values (&gt; 1e7) in covariance matrices <code>H</code>
and <code>Q</code> which could cause large rounding errors in filtering.
Positive semidefiniteness of these matrices is not checked. Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="is.SSModel_+3A_return.logical">return.logical</code></td>
<td>
<p>If <code>FALSE</code> (default), an error is given if the the model is not
a valid <code>SSModel</code> object. Otherwise logical value is returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the validity of the values in <code>y</code> and <code>Z</code> are not tested.
These can contain NA values (but not infinite values),  with condition that
when <code>Z[i,,t]</code> contains NA value, the corresponding <code>y[t,i]</code> must
also have NA value. In this case <code>Z[i,,t]</code> is not referenced in
filtering and smoothing, and algorithms works properly.
</p>


<h3>Value</h3>

<p>Logical value or nothing, depending on the value of
<code>return.logical</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- SSModel(rnorm(10) ~ 1)
is.SSModel(model)
model['H'] &lt;- 1
is.SSModel(model)
model$H[] &lt;- 1
is.SSModel(model)
model$H[,,1] &lt;- 1
is.SSModel(model)
model$H &lt;- 1
is.SSModel(model)
</code></pre>

<hr>
<h2 id='KFAS'>KFAS: Functions for Exponential Family State Space Models</h2><span id='topic+KFAS'></span><span id='topic+KFAS-package'></span>

<h3>Description</h3>

<p>Package KFAS contains functions for Kalman filtering, smoothing and
simulation of linear state space models with exact diffuse initialization.
</p>


<h3>Details</h3>

<p>Note, this help page might be more readable in pdf format due to the mathematical
formulas containing subscripts.
</p>
<p>The linear Gaussian state space model is given by
</p>
<p style="text-align: center;"><code class="reqn">y_t = Z_t \alpha_t + \epsilon_t, (\textrm{observation equation})</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha_{t+1} = T_t \alpha_t + R_t \eta_t, (\textrm{transition equation})</code>
</p>

<p>where <code class="reqn">\epsilon_t \sim N(0, H_t)</code>, <code class="reqn">\eta_t
\sim N(0, Q_t)</code> and <code class="reqn">\alpha_1 \sim
N(a_1, P_1)</code> independently of each other.
</p>
<p>All system and covariance matrices <code>Z</code>, <code>H</code>, <code>T</code>, <code>R</code> and
<code>Q</code> can be time-varying, and partially or totally missing observations
<code class="reqn">y_t</code> are allowed.
</p>
<p>Covariance matrices H and Q has to be positive semidefinite (although this is
not checked).
</p>
<p>Model components in <code>KFAS</code> are defined as
</p>

<dl>
<dt>y</dt><dd><p>A n x p matrix containing the observations. </p>
</dd>
<dt>Z</dt><dd><p>A p x m x 1 or p x m x n array corresponding to the system matrix
of observation equation. </p>
</dd>
<dt>H</dt><dd><p>A p x p x 1 or p x p x n array
corresponding to the covariance matrix of observational disturbances
epsilon. </p>
</dd>
<dt>T</dt><dd><p>A m x m x 1 or m x m x n array corresponding to the
first system matrix of state equation. </p>
</dd>
<dt>R</dt><dd><p>A m x k x 1 or m x k x n array corresponding to the second system matrix of state equation. </p>
</dd>
<dt>Q</dt><dd><p>A k x k x 1 or k x k x n array corresponding to the covariance
matrix of state disturbances eta </p>
</dd>
<dt>a1</dt><dd><p>A m x 1 matrix containing the
expected values of the initial states. </p>
</dd>
<dt>P1</dt><dd><p>A m x m matrix
containing the covariance matrix of the nondiffuse part of the initial
state vector. </p>
</dd>
<dt>P1inf</dt><dd><p>A m x m matrix containing the covariance
matrix of the diffuse part of the initial state vector. </p>
</dd>
<dt>u</dt><dd><p>A n x p
matrix of an additional parameters in case of non-Gaussian model.</p>
</dd>
</dl>

<p>In case of any of the series in model is defined as non-Gaussian, the
observation equation is of form </p>
<p style="text-align: center;"><code class="reqn">\prod_i^p
p_i(y_{t, p}|\theta_t)</code>
</p>
<p> with
<code class="reqn">\theta_{t, i} = Z_{i, t}\alpha_t</code> being one of
the following:
</p>

<ul>
<li> <p><code class="reqn">y_t \sim N(\mu_t, u_t), </code> with identity link <code class="reqn">\theta_t = \mu_t</code>.
Note that now variances are defined using <code class="reqn">u_t</code>, not <code class="reqn">H_t</code>.
If the correlation between Gaussian observation equations is needed, one can use
<code class="reqn">u_t = 0</code> and add correlating disturbances into state equation (although care is
then needed when making inferences about signal which contains the error terms also).
</p>
</li>
<li> <p><code class="reqn">y_t \sim \textrm{Poisson}(u_t\lambda_t), </code> where <code class="reqn">u_t</code>
is an offset term, with <code class="reqn">\theta_t = log(\lambda_t)</code>.
</p>
</li>
<li> <p><code class="reqn">y_t \sim \textrm{binomial}(u_t, \pi_t), </code> with <code class="reqn">\theta_t =
log[\pi_t/(1-\pi_t)]</code>, where
<code class="reqn">\pi_t</code> is the probability of success at time <code class="reqn">t</code>.
</p>
</li>
<li> <p><code class="reqn">y_t \sim \textrm{gamma}(u_t, \mu_t), </code> with <code class="reqn">\theta_t =
log(\mu_t)</code>, where <code class="reqn">\mu_t</code> is the mean
parameter and <code class="reqn">u_t</code> is the shape parameter.
</p>
</li>
<li> <p><code class="reqn">y_t \sim \textrm{negative binomial}(u_t, \mu_t), </code>
with expected value <code class="reqn">\mu_t</code> and variance <code class="reqn">\mu_t+ \mu_t^2/u_t</code> (see <code><a href="stats.html#topic+dnbinom">dnbinom</a></code>), then <code class="reqn">\theta_t =
log(\mu_t)</code>.
</p>
</li></ul>

<p>For exponential family models <code class="reqn">u_t = 1</code> as a default.
For completely Gaussian models, parameter is omitted. Note that series can
have different distributions in case of multivariate models.
</p>
<p>For the unknown elements of initial state vector <code class="reqn">a_1</code>, KFAS uses
exact diffuse initialization by Koopman and Durbin (2000, 2012, 2003), where
the unknown initial states are set to have a zero mean and infinite variance,
so </p>
<p style="text-align: center;"><code class="reqn">P_1 = P_{\ast, 1} + \kappa P_{\infty, 1}, </code>
</p>
<p> with <code class="reqn">\kappa</code> going to infinity and
<code class="reqn">P_{\infty, 1}</code> being diagonal matrix with ones on diagonal
elements corresponding to unknown initial states.
</p>
<p>This method is basically a equivalent of setting uninformative priors for the
initial states in a Bayesian framework.
</p>
<p>Diffuse phase is continued until rank of <code class="reqn">P_{\infty, t}</code> becomes
zero. Rank of <code class="reqn">P_{\infty, t}</code> decreases by 1, if
<code class="reqn">F_{\infty, t}&gt;\xi_t&gt;0</code>, where <code class="reqn">\xi_t</code> is by default
<code>.Machine$double.eps^0.5*min(X)^2)</code>, where X is absolute values of non-zero
elements of array Z. Usually the number of diffuse time points
equals the number unknown elements of initial state vector, but missing
observations or time-varying system matrices can affect this. See Koopman and
Durbin (2000, 2012, 2003) for details for exact diffuse and non-diffuse
filtering.  If the number of diffuse states is large compared to the data, it
is possible that the model is degenerate in a sense that not enough
information is available for leaving the diffuse phase.
</p>
<p>To lessen the notation and storage space, KFAS uses letters P, F and K for
non-diffuse part of the corresponding matrices, omitting the asterisk in
diffuse phase.
</p>
<p>All functions of KFAS use the univariate approach (also known as sequential
processing, see Anderson and Moore (1979)) which is from Koopman and Durbin
(2000, 2012). In univariate approach the observations are introduced one
element at the time. Therefore the prediction error variance matrices F and
Finf do not need to be non-singular, as there is no matrix inversions in
univariate approach algorithm.  This provides possibly more
faster filtering and smoothing than normal multivariate Kalman filter
algorithm, and simplifies the formulas for diffuse filtering and smoothing.
If covariance matrix H is not diagonal, it is possible to transform the model by either using
LDL decomposition on H, or augmenting the state vector with <code class="reqn">\epsilon</code>
disturbances (this is done automatically in KFAS if needed).
See <code><a href="#topic+transformSSM">transformSSM</a></code> for more details.
</p>


<h3>References</h3>

<p>Helske J. (2017). KFAS: Exponential Family State Space Models in R,
Journal of Statistical Software, 78(10), 1-39. doi:10.18637/jss.v078.i10
</p>
<p>Koopman, S.J. and Durbin J. (2000).  Fast filtering and
smoothing for non-stationary time series models, Journal of American
Statistical Assosiation, 92, 1630-38.
</p>
<p>Koopman, S.J. and Durbin J. (2012).  Time Series Analysis by State Space
Methods. Second edition. Oxford: Oxford University Press.
</p>
<p>Koopman, S.J. and Durbin J. (2003).  Filtering and smoothing of state vector
for diffuse state space models, Journal of Time Series Analysis, Vol. 24,
No. 1.
</p>
<p>Shumway, Robert H. and Stoffer, David S. (2006).  Time Series Analysis and
Its Applications: With R examples.  <br />
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+logLik">logLik</a></code>, <code><a href="#topic+fitSSM">fitSSM</a></code>,
<code><a href="#topic+boat">boat</a></code>, <code><a href="#topic+sexratio">sexratio</a></code>,
<code><a href="#topic+GlobalTemp">GlobalTemp</a></code>, <code><a href="#topic+SSModel">SSModel</a></code>,
<code><a href="#topic+importanceSSM">importanceSSM</a></code>, <code><a href="#topic+approxSSM">approxSSM</a></code> for more examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
################################################
# Example of local level model for Nile series #
################################################
# See Durbin and Koopman (2012) and also ?SSModel for another Nile example

model_Nile &lt;- SSModel(Nile ~
  SSMtrend(1, Q = list(matrix(NA))), H = matrix(NA))
model_Nile
model_Nile &lt;- fitSSM(model_Nile, c(log(var(Nile)), log(var(Nile))),
  method = "BFGS")$model

# Filtering and state smoothing
out_Nile &lt;- KFS(model_Nile, filtering = "state", smoothing = "state")
out_Nile

# Confidence and prediction intervals for the expected value and the observations.
# Note that predict uses original model object, not the output from KFS.
conf_Nile &lt;- predict(model_Nile, interval = "confidence", level = 0.9)
pred_Nile &lt;- predict(model_Nile, interval = "prediction", level = 0.9)

ts.plot(cbind(Nile, pred_Nile, conf_Nile[, -1]), col = c(1:2, 3, 3, 4, 4),
        ylab = "Predicted Annual flow", main = "River Nile")


# Missing observations, using the same parameter estimates

NileNA &lt;- Nile
NileNA[c(21:40, 61:80)] &lt;- NA
model_NileNA &lt;- SSModel(NileNA ~ SSMtrend(1, Q = list(model_Nile$Q)),
H = model_Nile$H)

out_NileNA &lt;- KFS(model_NileNA, "mean", "mean")

# Filtered and smoothed states
ts.plot(NileNA, fitted(out_NileNA, filtered = TRUE), fitted(out_NileNA),
  col = 1:3, ylab = "Predicted Annual flow",
  main = "River Nile")


## Not run: 
##################
# Seatbelts data #
##################
# See Durbin and Koopman (2012)

model_drivers &lt;- SSModel(log(drivers) ~ SSMtrend(1, Q = list(NA))+
   SSMseasonal(period = 12, sea.type = "trigonometric", Q = NA) +
   log(PetrolPrice) + law, data = Seatbelts, H = NA)

# As trigonometric seasonal contains several disturbances which are all
# identically distributed, default behaviour of fitSSM is not enough,
# as we have constrained Q. We can either provide our own
# model updating function with fitSSM, or just use optim directly:

# option 1:
ownupdatefn &lt;- function(pars, model){
  model$H[] &lt;- exp(pars[1])
  diag(model$Q[, , 1]) &lt;- exp(c(pars[2], rep(pars[3], 11)))
  model #for optim, replace this with -logLik(model) and call optim directly
}

fit_drivers &lt;- fitSSM(model_drivers,
  log(c(var(log(Seatbelts[, "drivers"])), 0.001, 0.0001)),
  ownupdatefn, method = "BFGS")

out_drivers &lt;- KFS(fit_drivers$model, smoothing = c("state", "mean"))
out_drivers
ts.plot(out_drivers$model$y, fitted(out_drivers), lty = 1:2, col = 1:2,
  main = "Observations and smoothed signal with and without seasonal component")
lines(signal(out_drivers, states = c("regression", "trend"))$signal,
  col = 4, lty = 1)
legend("bottomleft", col = c(1, 2, 4), lty = c(1, 2, 1),
  legend = c("Observations", "Smoothed signal", "Smoothed level"))

# Multivariate model with constant seasonal pattern,
# using the the seat belt law dummy only for the front seat passangers,
# and restricting the rank of the level component by using custom component

model_drivers2 &lt;- SSModel(log(cbind(front, rear)) ~ -1 +
    log(PetrolPrice) + log(kms) +
    SSMregression(~law, data = Seatbelts, index = 1) +
    SSMcustom(Z = diag(2), T = diag(2), R = matrix(1, 2, 1),
      Q = matrix(1), P1inf = diag(2)) +
    SSMseasonal(period = 12, sea.type = "trigonometric"),
  data = Seatbelts, H = matrix(NA, 2, 2))

# An alternative way for defining the rank deficient trend component:

# model_drivers2 &lt;- SSModel(log(cbind(front, rear)) ~ -1 +
#     log(PetrolPrice) + log(kms) +
#     SSMregression(~law, data = Seatbelts, index = 1) +
#     SSMtrend(degree = 1, Q = list(matrix(0, 2, 2))) +
#     SSMseasonal(period = 12, sea.type = "trigonometric"),
#   data = Seatbelts, H = matrix(NA, 2, 2))
#
# Modify model manually:
# model_drivers2$Q &lt;- array(1, c(1, 1, 1))
# model_drivers2$R &lt;- model_drivers2$R[, -2, , drop = FALSE]
# attr(model_drivers2, "k") &lt;- 1L
# attr(model_drivers2, "eta_types") &lt;- attr(model_drivers2, "eta_types")[1]


likfn &lt;- function(pars, model, estimate = TRUE){
  diag(model$H[, , 1]) &lt;- exp(0.5 * pars[1:2])
  model$H[1, 2, 1] &lt;- model$H[2, 1, 1] &lt;-
    tanh(pars[3]) * prod(sqrt(exp(0.5 * pars[1:2])))
  model$R[28:29] &lt;- exp(pars[4:5])
  if(estimate) return(-logLik(model))
  model
}

fit_drivers2 &lt;- optim(f = likfn, p = c(-8, -8, 1, -1, -3), method = "BFGS",
  model = model_drivers2)
model_drivers2 &lt;- likfn(fit_drivers2$p, model_drivers2, estimate = FALSE)
model_drivers2$R[28:29, , 1]%*%t(model_drivers2$R[28:29, , 1])
model_drivers2$H

out_drivers2 &lt;- KFS(model_drivers2)
out_drivers2
ts.plot(signal(out_drivers2, states = c("custom", "regression"))$signal,
  model_drivers2$y, col = 1:4)

# For confidence or prediction intervals, use predict on the original model
pred &lt;- predict(model_drivers2,
  states = c("custom", "regression"), interval = "prediction")

# Note that even though the intervals were computed without seasonal pattern,
# PetrolPrice induces seasonal pattern to predictions
ts.plot(pred$front, pred$rear, model_drivers2$y,
  col = c(1, 2, 2, 3, 4, 4, 5, 6), lty = c(1, 2, 2, 1, 2, 2, 1, 1))

## End(Not run)

######################
# ARMA(2, 2) process #
######################
set.seed(1)
y &lt;- arima.sim(n = 1000, list(ar = c(0.8897, -0.4858), ma = c(-0.2279, 0.2488)),
               innov = rnorm(1000) * sqrt(0.5))


model_arima &lt;- SSModel(y ~ SSMarima(ar = c(0, 0), ma = c(0, 0), Q = 1), H = 0)

likfn &lt;- function(pars, model, estimate = TRUE){
  tmp &lt;- try(SSMarima(artransform(pars[1:2]), artransform(pars[3:4]),
    Q = exp(pars[5])), silent = TRUE)
  if(!inherits(tmp, "try-error")){
    model["T", "arima"] &lt;- tmp$T
    model["R", states = "arima", etas = "arima"] &lt;- tmp$R
    model["P1", "arima"] &lt;- tmp$P1
    model["Q", etas = "arima"] &lt;- tmp$Q
    if(estimate){
      -logLik(model)
    } else model
  } else {
    if(estimate){
      1e100
    } else model
  }
}

fit_arima &lt;- optim(par = c(rep(0, 4), log(1)), fn = likfn, method = "BFGS",
  model = model_arima)
model_arima &lt;- likfn(fit_arima$par, model_arima, FALSE)

# AR coefficients:
model_arima$T[2:3, 2, 1]
# MA coefficients:
model_arima$R[3:4]
# sigma2:
model_arima$Q[1]
# intercept
KFS(model_arima)
# same with arima:
arima(y, c(2, 0, 2))
# small differences because the intercept is handled differently in arima

## Not run: 
#################
# Poisson model #
#################
# See Durbin and Koopman (2012)
model_van &lt;- SSModel(VanKilled ~ law + SSMtrend(1, Q = list(matrix(NA)))+
               SSMseasonal(period = 12, sea.type = "dummy", Q = NA),
               data = Seatbelts, distribution = "poisson")

# Estimate variance parameters
fit_van &lt;- fitSSM(model_van, c(-4, -7), method = "BFGS")

model_van &lt;- fit_van$model

# use approximating model, gives posterior modes
out_nosim &lt;- KFS(model_van, nsim = 0)
# State smoothing via importance sampling
out_sim &lt;- KFS(model_van, nsim = 1000)

out_nosim
out_sim

## End(Not run)

## using deterministic inputs in observation and state equations
model_Nile &lt;- SSModel(Nile ~
  SSMcustom(Z=1, T = 1, R = 0, a1 = 100, P1inf = 0, P1 = 0, Q = 0, state_names = "d_t") +
  SSMcustom(Z=0, T = 1, R = 0, a1 = 100, P1inf = 0, P1 = 0, Q = 0, state_names = "c_t") +
  SSMtrend(1, Q = 1500), H = 15000)
model_Nile$T
model_Nile$T[1, 3, 1] &lt;- 1 # add c_t to level
model_Nile0 &lt;- SSModel(Nile ~
  SSMtrend(2, Q = list(1500, 0), a1 = c(0, 100), P1inf = diag(c(1, 0))),
  H = 15000)

ts.plot(KFS(model_Nile0)$mu, KFS(model_Nile)$mu, col = 1:2)

##########################################################
### Examples of generalized linear modelling with KFAS ###
##########################################################

# Same example as in ?glm
counts &lt;- c(18, 17, 15, 20, 10, 20, 25, 13, 12)
outcome &lt;- gl(3, 1, 9)
treatment &lt;- gl(3, 3)
glm_D93 &lt;- glm(counts ~ outcome + treatment, family = poisson())

model_D93 &lt;- SSModel(counts ~ outcome + treatment,
  distribution = "poisson")

out_D93 &lt;- KFS(model_D93)
coef(out_D93, last = TRUE)
coef(glm_D93)

summary(glm_D93)$cov.s
out_D93$V[, , 1]

# approximating model as in GLM
out_D93_nosim &lt;- KFS(model_D93, smoothing = c("state", "signal", "mean"),
  expected = TRUE)

# with importance sampling. Number of simulations is too small here,
# with large enough nsim the importance sampling actually gives
# very similar results as the approximating model in this case
set.seed(1)
out_D93_sim &lt;- KFS(model_D93,
  smoothing = c("state", "signal", "mean"), nsim = 1000)


## linear predictor
# GLM
glm_D93$linear.predictor
# approximate model, this is the posterior mode of p(theta|y)
c(out_D93_nosim$thetahat)
# importance sampling on theta, gives E(theta|y)
c(out_D93_sim$thetahat)


## predictions on response scale
# GLM
fitted(glm_D93)
# approximate model with backtransform, equals GLM
fitted(out_D93_nosim)
# importance sampling on exp(theta)
fitted(out_D93_sim)

# prediction variances on link scale
# GLM
as.numeric(predict(glm_D93, type = "link", se.fit = TRUE)$se.fit^2)
# approx, equals to GLM results
c(out_D93_nosim$V_theta)
# importance sampling on theta
c(out_D93_sim$V_theta)


# prediction variances on response scale
# GLM
as.numeric(predict(glm_D93, type = "response", se.fit = TRUE)$se.fit^2)
# approx, equals to GLM results
c(out_D93_nosim$V_mu)
# importance sampling on theta
c(out_D93_sim$V_mu)

# A Gamma example modified from ?glm
# Now with log-link, and identical intercept terms
clotting &lt;- data.frame(
u = c(5,10,15,20,30,40,60,80,100),
lot1 = c(118,58,42,35,27,25,21,19,18),
lot2 = c(69,35,26,21,18,16,13,12,12))

model_gamma &lt;- SSModel(cbind(lot1, lot2) ~ -1 + log(u) +
    SSMregression(~ 1, type = "common", remove.intercept = FALSE),
  data = clotting, distribution = "gamma")

update_shapes &lt;- function(pars, model) {
  model$u[, 1] &lt;- pars[1]
  model$u[, 2] &lt;- pars[2]
  model
}
fit_gamma &lt;- fitSSM(model_gamma, inits = c(1, 1), updatefn = update_shapes,
method = "L-BFGS-B", lower = 0, upper = 100)
logLik(fit_gamma$model)
KFS(fit_gamma$model)
fit_gamma$model["u", times = 1]



## Not run: 
####################################
### Linear mixed model with KFAS ###
####################################

# example from ?lmer of lme4 package
data("sleepstudy", package = "lme4")

model_lmm &lt;- SSModel(Reaction ~ Days +
    SSMregression(~ Days, Q = array(0, c(2, 2, 180)),
       P1 = matrix(NA, 2, 2), remove.intercept = FALSE), sleepstudy, H = NA)

# The first 10 time points the third and fouth state
# defined with SSMregression correspond to the first subject, and next 10 time points
# are related to second subject and so on.

# need to use ordinary $ assignment as [ assignment operator for SSModel
# object guards against dimension altering
model_lmm$T &lt;- array(model_lmm["T"], c(4, 4, 180))
attr(model_lmm, "tv")[3] &lt;- 1L #needs to be integer type!

# "cut the connection" between the subjects
times &lt;- seq(10, 180, by = 10)
model_lmm["T",states = 3:4, times = times] &lt;- 0

# for the first subject the variance of the random effect is defined via P1
# for others, we use Q
model_lmm["Q", times = times] &lt;- NA

update_lmm &lt;- function(pars = init, model){
  P1 &lt;- diag(exp(pars[1:2]))
  P1[1, 2] &lt;- pars[3]
  model["P1", states = 3:4] &lt;- model["Q", times = times] &lt;-
    crossprod(P1)
  model["H"] &lt;- exp(pars[4])
  model
}

inits &lt;- c(0, 0, 0, 3)

fit_lmm &lt;- fitSSM(model_lmm, inits, update_lmm, method = "BFGS")
out_lmm &lt;- KFS(fit_lmm$model)
# unconditional covariance matrix of random effects
fit_lmm$model["P1", states = 3:4]

# conditional covariance matrix of random effects
# same for each subject and time point due to model structure
# these differ from the ones obtained from lmer as these are not conditioned
# on the fixed effects
out_lmm$V[3:4,3:4,1]

## End(Not run)
## Not run: 
#########################################
### Example of cubic spline smoothing ###
#########################################
# See Durbin and Koopman (2012)
require("MASS")
data("mcycle")

model &lt;- SSModel(accel ~ -1 +
    SSMcustom(Z = matrix(c(1, 0), 1, 2),
      T = array(diag(2), c(2, 2, nrow(mcycle))),
      Q = array(0, c(2, 2, nrow(mcycle))),
      P1inf = diag(2), P1 = diag(0, 2)), data = mcycle)

model$T[1, 2, ] &lt;- c(diff(mcycle$times), 1)
model$Q[1, 1, ] &lt;- c(diff(mcycle$times), 1)^3/3
model$Q[1, 2, ] &lt;- model$Q[2, 1, ] &lt;- c(diff(mcycle$times), 1)^2/2
model$Q[2, 2, ] &lt;- c(diff(mcycle$times), 1)


updatefn &lt;- function(pars, model, ...){
  model["H"] &lt;- exp(pars[1])
  model["Q"] &lt;- model["Q"] * exp(pars[2])
  model
}

fit &lt;- fitSSM(model, inits = c(4, 4), updatefn = updatefn, method = "BFGS")

pred &lt;- predict(fit$model, interval = "conf", level = 0.95)
plot(x = mcycle$times, y = mcycle$accel, pch = 19)
lines(x = mcycle$times, y = pred[, 1])
lines(x = mcycle$times, y = pred[, 2], lty = 2)
lines(x = mcycle$times, y = pred[, 3], lty = 2)

## End(Not run)

## Not run: 
##################################################################
# Example of multivariate model with common parameters           #
# and unknown intercept terms in state and observation equations #
##################################################################
set.seed(1)
n1 &lt;- 20
n2 &lt;- 30
z1 &lt;- sin(1:n1)
z2 &lt;- cos(1:n2)

C &lt;- 0.6
D &lt;- -0.4
# random walk with drift D
x1 &lt;- cumsum(rnorm(n1) + D)
x2 &lt;- cumsum(rnorm(n2) + D)

y1 &lt;- rnorm(n1, z1 * x1 + C * 1)
y2 &lt;- rnorm(n2, z2 * x2 + C * 2)

n &lt;- max(n1, n2)
Y &lt;- matrix(NA, n, 2)
Y[1:n1, 1] &lt;- y1
Y[1:n2, 2] &lt;- y2

Z &lt;- array(0, c(2, 4, n))
Z[1, 1, 1:n1] &lt;- z1
Z[2, 2, 1:n2] &lt;- z2 # trailing zeros are ok, as corresponding y is NA
Z[1, 3, ] &lt;- 1 # x = 1
Z[2, 3, ] &lt;- 2 # x = 2
# last state is only used in state equation so zeros in Z

T &lt;- diag(4) # a1_t for y1, a2_t for y2, C, D
T[1, 4] &lt;- 1 # D affects a_t
T[2, 4] &lt;- 1 # D affects a_t
Q &lt;- diag(c(NA, NA, 0, 0))
P1inf &lt;- diag(4)
model &lt;- SSModel(Y ~ -1 + SSMcustom(Z = Z, T = T, Q = Q, P1inf = P1inf,
  state_names = c("a1", "a2", "C", "D")), H = diag(NA, 2))

updatefn &lt;- function(pars, model) {
  model$Q[] &lt;- diag(c(exp(pars[1]), exp(pars[1]), 0, 0))
  model$H[] &lt;- diag(exp(pars[2]), 2)
  model
}

fit &lt;- fitSSM(model, inits = rep(-1, 2), updatefn = updatefn)

fit$model$H[1]
fit$model$Q[1]
KFS(fit$model)


## End(Not run)

</code></pre>

<hr>
<h2 id='KFAS-defunct'>Defunct Functions of Package KFAS</h2><span id='topic+KFAS-defunct'></span><span id='topic+deviance.KFS'></span><span id='topic+subset+3C-.SSModel'></span><span id='topic+subset+3C-'></span><span id='topic+subset.SSModel'></span>

<h3>Description</h3>

<p>The function listed here are removed from KFAS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KFS'
deviance(object, ...)

## S3 replacement method for class 'SSModel'
subset(x, element, states, etas, series, times, ...) &lt;- value

subset(x, ...) &lt;- value

## S3 method for class 'SSModel'
subset(x, element, states, etas, series, times, ...)
</code></pre>


<h3>Details</h3>

<p>Subset-based methods were removed as they were somewhat confusingly
named as the <code>subset</code> generic in <code>base</code>, and most likely not
that useful (compared to <code><a href="#topic++5B+3C-.SSModel">[&lt;-.SSModel</a></code>).
</p>
<p>Deviance.KFS was removed as it was mostly useless. The value was not a <code class="reqn">-2*(logL-logL*)</code>
where <code class="reqn">L</code> is the likelihood and <code class="reqn">L*</code> is the saturated likelihood.
Instead it was based on the conditional likelihood <code class="reqn">p(y|theta)</code> i.e. it disregards
the effect of hidden states. Therefore the value
returned by this function did not make much sense in non-GLM setting.
</p>
<p>From <code>rstandard.KFS</code> and <code>residuals.KFS</code>: Computation of deviance residuals. 
This option was meant to be used only for the GLM comparisons, as their 
generalization to other models is lacking, but in order to avoid misleading 
results in non-GLM settings, these are now completely removed.
</p>

<hr>
<h2 id='KFS'>Kalman Filter and Smoother with Exact Diffuse Initialization for Exponential
Family State Space Models</h2><span id='topic+KFS'></span>

<h3>Description</h3>

<p>Performs Kalman filtering and smoothing with exact diffuse initialization
using univariate approach for exponential family state space models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KFS(
  model,
  filtering,
  smoothing,
  simplify = TRUE,
  transform = c("ldl", "augment"),
  nsim = 0,
  theta,
  maxiter = 50,
  convtol = 1e-08,
  return_model = TRUE,
  expected = FALSE,
  H_tol = 1e+15,
  transform_tol
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KFS_+3A_model">model</code></td>
<td>
<p>Object of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="KFS_+3A_filtering">filtering</code></td>
<td>
<p>Types of filtering. Possible choices are <code>"state"</code>,
<code>"signal"</code>, <code>"mean"</code>, and <code>"none"</code>. Default is
<code>"state"</code> for Gaussian and <code>"none"</code> for non-Gaussian models.
Multiple values are allowed. For Gaussian models, the signal is the mean.
Note that filtering for non-Gaussian models with importance sampling can be
very slow with large models.</p>
</td></tr>
<tr><td><code id="KFS_+3A_smoothing">smoothing</code></td>
<td>
<p>Types of smoothing. Possible choices are <code>"state"</code>,
<code>"signal"</code>, <code>"mean"</code>, <code>"disturbance"</code>, and <code>"none"</code>. Default is <code>"state"</code> and <code>"mean"</code>. For
non-Gaussian models, option <code>"disturbance"</code> is not supported, and for
Gaussian models option <code>"mean"</code> is identical to <code>"signal"</code>. Multiple values are
allowed.</p>
</td></tr>
<tr><td><code id="KFS_+3A_simplify">simplify</code></td>
<td>
<p>If <code>FALSE</code> and the model is completely Gaussian, <code>KFS</code> returns some
generally not so interesting variables from filtering and smoothing. Default
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="KFS_+3A_transform">transform</code></td>
<td>
<p>How to transform the model in case of non-diagonal
covariance matrix <code>H</code>. Defaults to <code>"ldl"</code>. See function
<code><a href="#topic+transformSSM">transformSSM</a></code> for details.</p>
</td></tr>
<tr><td><code id="KFS_+3A_nsim">nsim</code></td>
<td>
<p>The number of independent samples used in importance sampling.
Only used for non-Gaussian models. Default is 0, which computes the
approximating Gaussian model by <code><a href="#topic+approxSSM">approxSSM</a></code> and performs the
usual Gaussian filtering/smoothing so that the smoothed state estimates
equals to the conditional mode of <code class="reqn">p(\alpha_t|y)</code>.
In case of <code>nsim = 0</code>, the mean estimates and their variances are computed using
the Delta method (ignoring the covariance terms).</p>
</td></tr>
<tr><td><code id="KFS_+3A_theta">theta</code></td>
<td>
<p>Initial values for conditional mode theta. Only used for
non-Gaussian models.</p>
</td></tr>
<tr><td><code id="KFS_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations used in Gaussian
approximation. Default is 50. Only used for non-Gaussian models.</p>
</td></tr>
<tr><td><code id="KFS_+3A_convtol">convtol</code></td>
<td>
<p>Tolerance parameter for convergence checks for Gaussian
approximation. Only used for non-Gaussian models.</p>
</td></tr>
<tr><td><code id="KFS_+3A_return_model">return_model</code></td>
<td>
<p>Logical, indicating whether the original input model should be 
returned as part of the output. Defaults to TRUE, but for large models can be set 
to FALSE in order to save memory. However, many of the methods operating on the 
output of <code>KFS</code> use this model so this will not work if <code>return_model=FALSE</code>.</p>
</td></tr>
<tr><td><code id="KFS_+3A_expected">expected</code></td>
<td>
<p>Logical value defining the approximation of H_t in case of Gamma 
and negative binomial distribution. Default is <code>FALSE</code> which matches the 
algorithm of Durbin &amp; Koopman (1997), whereas <code>TRUE</code> uses the expected value
of observations in the equations, leading to results which match with <code>glm</code> (where applicable).
The latter case was the default behaviour of KFAS before version 1.3.8.
Essentially this is the difference between observed and expected information in the GLM context. 
Only used for non-Gaussian model.</p>
</td></tr>
<tr><td><code id="KFS_+3A_h_tol">H_tol</code></td>
<td>
<p>Tolerance parameter for check <code>max(H) &gt; tol_H</code>, which suggests that the approximation 
converged to degenerate case with near zero signal-to-noise ratio. Default is very generous 1e15. 
Only used for non-Gaussian model.</p>
</td></tr>
<tr><td><code id="KFS_+3A_transform_tol">transform_tol</code></td>
<td>
<p>Tolerance parameter for LDL decomposition in case of a 
non-diagonal H and <code>transform = "ldl"</code>. See <code><a href="#topic+transformSSM">transformSSM</a></code> and 
<code><a href="#topic+ldl">ldl</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Notice that in case of multivariate Gaussian observations, <code>v</code>, <code>F</code>,
<code>Finf</code>, <code>K</code> and <code>Kinf</code> are usually not the same as those
calculated in usual multivariate Kalman filter. As filtering is done one
observation element at the time, the elements of the prediction error
<code class="reqn">v_t</code> are uncorrelated, and <code>F</code>, <code>Finf</code>, <code>K</code> and
<code>Kinf</code> contain only the diagonal elemens of the corresponding covariance
matrices. The usual multivariate versions of <code>F</code> and <code>v</code> can be
obtained from the output of <code>KFS</code> using the function
<code><a href="#topic+mvInnovations">mvInnovations</a></code>.
</p>
<p>In rare cases (typically with regression components with high multicollinearity or 
long cyclic patterns), the cumulative rounding errors in Kalman filtering and 
smoothing can cause the diffuse phase end too early,
or the backward smoothing gives negative variances (in diffuse and nondiffuse cases). 
Since version 1.4.0, filtering and smoothing algorithms truncate these values to zero during the 
recursions, but this can still leads some numerical problems.
In these cases, redefining the  prior state variances more informative is often helpful. 
Changing the tolerance parameter <code>tol</code> of the model (see <code><a href="#topic+SSModel">SSModel</a></code>) to smaller 
(or larger), or scaling the model input can sometimes help as well. These numerical issues 
are well known in Kalman filtering/smoothing in general 
(there are other numerically more stable versions available, but these are in general slower).
</p>
<p>Fon non-Gaussian models the components corresponding to diffuse filtering
(<code>Finf</code>, <code>Pinf</code>, <code>d</code>, <code>Kinf</code>) are not returned even
when <code>filtering</code> is used. Results based on approximating Gaussian model
can be obtained by running <code>KFS</code> using the output of <code>approxSSM</code>.
</p>
<p>In case of non-Gaussian models with <code>nsim = 0</code>, the smoothed estimates
relate to the conditional mode of <code class="reqn">p(\alpha|y)</code>. When using importance
sampling (<code>nsim&gt;0</code>), results correspond to the conditional mean of
<code class="reqn">p(\alpha|y)</code>.
</p>


<h3>Value</h3>

<p>What <code>KFS</code> returns depends on the arguments <code>filtering</code>,
<code>smoothing</code> and <code>simplify</code>, and whether the model is Gaussian or
not:
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>Original state space model. </p>
</td></tr>
<tr><td><code>KFS_transform</code></td>
<td>
<p>How the non-diagonal <code>H</code> was handled. </p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>Value of the log-likelihood function. Only returned for fully
Gaussian models. </p>
</td></tr>
<tr><td><code>a</code></td>
<td>
<p>One-step-ahead predictions of states, <code class="reqn">a_t = E(\alpha_t | y_{t-1},
  \ldots, y_{1})</code>. </p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>Non-diffuse parts of the error covariance matrix of predicted states,
<code class="reqn">P_t = Var(\alpha_t | y_{t-1}, \ldots, y_{1})
  </code>. </p>
</td></tr>
<tr><td><code>Pinf</code></td>
<td>
<p>Diffuse part of the error covariance matrix of predicted states.
Only returned for Gaussian models. </p>
</td></tr>
<tr><td><code>att</code></td>
<td>
<p>Filtered estimates of states, <code class="reqn">a_tt = E(\alpha_t | y_{t},
  \ldots, y_{1})</code>. </p>
</td></tr>
<tr><td><code>Ptt</code></td>
<td>
<p>Non-diffuse parts of the error covariance matrix of filtered states,
<code class="reqn">P_tt = Var(\alpha_t | y_{t}, \ldots, y_{1})
  </code>. </p>
</td></tr>
<tr><td><code>t</code></td>
<td>
<p>One-step-ahead predictions of signals, <code class="reqn">E(Z_t\alpha_t | y_{t-1},
  \ldots, y_{1})</code>. </p>
</td></tr>
<tr><td><code>P_theta</code></td>
<td>
<p>Non-diffuse part of <code class="reqn">Var(Z_t\alpha_t | y_{t-1}, \ldots,
  y_{1})</code>. </p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>One-step-ahead predictions <code class="reqn">f(\theta_t) | y_{t-1}, \ldots,
  y_{1})</code>, where <code class="reqn">f</code> is the
inverse link function. In case of Poisson distribution these predictions are
multiplied with exposure <code class="reqn">u_t</code>.  </p>
</td></tr>
<tr><td><code>P_mu</code></td>
<td>
<p>Non-diffuse part of <code class="reqn">Var(f(\theta_t) |
  y_{t-1}, \ldots, y_{1})</code>.
In case of Poisson distribution this is <code class="reqn">Var(u_t f(\theta_t) | y_{t-1},
  \ldots, y_{1})</code>.
If <code>nsim = 0</code>, only diagonal elements (variances) are computed, using the
Delta method. </p>
</td></tr>
<tr><td><code>alphahat</code></td>
<td>
<p>Smoothed estimates of states, <code class="reqn">E(\alpha_t | y_1, \ldots,
  y_n)</code>. </p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>Error covariance matrices of smoothed states, <code class="reqn">Var(\alpha_t | y_1,
  \ldots, y_n)</code>. </p>
</td></tr>
<tr><td><code>thetahat</code></td>
<td>
<p>Smoothed estimates of signals, <code class="reqn">E(Z_t\alpha_t | y_1,
  \ldots, y_n)</code>. </p>
</td></tr>
<tr><td><code>V_theta</code></td>
<td>
<p>Error covariance matrices of smoothed signals
<code class="reqn">Var(Z[t]\alpha_t | y_1, \ldots, y_n).</code>. </p>
</td></tr>
<tr><td><code>muhat</code></td>
<td>
<p>Smoothed estimates of <code class="reqn">f(\theta_t) | y_1, \ldots,
  y_n)</code>, where <code class="reqn">f</code> is the inverse
link function, or in Poisson case <code class="reqn">u_t f(\theta_t) | y_1, \ldots,
  y_n)</code>, where <code class="reqn">u</code> is the exposure term. </p>
</td></tr>
<tr><td><code>V_mu</code></td>
<td>
<p>Error covariances <code class="reqn">Cov(f(\theta_t)| y_1, \ldots,
  y_n)</code> (or the covariances of
<code class="reqn">u_t f(\theta_t)</code> given the data in case of Poisson
distribution). If <code>nsim = 0</code>, only diagonal elements (variances) are
computed, using the Delta method.  </p>
</td></tr>
<tr><td><code>etahat</code></td>
<td>
<p>Smoothed disturbance terms <code class="reqn">E(\eta_t | y_1, \ldots,
  y_n)</code>. Only for Gaussian models. </p>
</td></tr>
<tr><td><code>V_eta</code></td>
<td>
<p>Error covariances <code class="reqn">Var(\eta_t | y_1, \ldots, y_n)</code>. Note that for computing auxiliary residuals you shoud use method
<code><a href="#topic+rstandard.KFS">rstandard.KFS</a></code>.</p>
</td></tr>
<tr><td><code>epshat</code></td>
<td>
<p>Smoothed disturbance terms <code class="reqn">E(\epsilon_{t,i} | y_1,
  \ldots, y_n)</code>. Note that due to
the possible diagonalization these are on transformed scale.
Only for Gaussian models. </p>
</td></tr>
<tr><td><code>V_eps</code></td>
<td>
<p>Diagonal elements of <code class="reqn">Var(\epsilon_{t} | y_1, \ldots,
  y_n)</code>. Note that due to the
diagonalization the off-diagonal elements are zero.
Only for Gaussian models. Note that for computing auxiliary residuals you shoud use method
<code><a href="#topic+rstandard.KFS">rstandard.KFS</a></code>.</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>The number of iterations used in linearization of
non-Gaussian model. </p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>Prediction errors <code class="reqn">v_{t,i} = y_{t,i} - Z_{i,t}a_{t,i},
  i = 1, \ldots,p</code>, where
</p>
<p style="text-align: center;"><code class="reqn">a_{t,i} = E(\alpha_t | y_{t,i-1}, \ldots, y_{t,1}, \ldots,
  y_{1,1})</code>
</p>
<p>.
Only returned for Gaussian models.  </p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>Prediction error variances <code class="reqn">Var(v_{t,i})</code>. Only
returned for Gaussian models. </p>
</td></tr>
<tr><td><code>Finf</code></td>
<td>
<p>Diffuse part of prediction error variances. Only returned for Gaussian
models. </p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The last time index of diffuse phase, i.e. the non-diffuse
phase began at time <code class="reqn">d+1</code>. Only returned for Gaussian models.  </p>
</td></tr>
<tr><td><code>j</code></td>
<td>
<p>The last observation index <code class="reqn">i</code> of <code class="reqn">y_{i,t}</code> of the
diffuse phase. Only returned for Gaussian models.  </p>
</td></tr>
</table>
<p>In addition, if argument <code>simplify = FALSE</code>, list contains following
components:
</p>
<table>
<tr><td><code>K</code></td>
<td>
<p>Covariances <code class="reqn">Cov(\alpha_{t,i}, y_{t,i} | y_{t,i-1}, \ldots,
  y_{t,1}, y_{t-1}, \ldots , y_{1}), \quad i = 1, \ldots, p</code>.
</p>
</td></tr>
<tr><td><code>Kinf</code></td>
<td>
<p>Diffuse part of <code class="reqn">K_t</code>.  </p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>Weighted sums of innovations <code class="reqn">v_{t+1}, \ldots, v_{n}</code>.  Notice that in literature <code class="reqn">t</code> in <code class="reqn">r_t</code> goes from
<code class="reqn">0, \ldots, n</code>. Here <code class="reqn">t = 1, \ldots, n + 1</code>. Same applies to all <code class="reqn">r</code> and
<code class="reqn">N</code> variables.  </p>
</td></tr>
<tr><td><code>r0</code>, <code>r1</code></td>
<td>
<p>Diffuse phase decomposition of <code class="reqn">r_t</code>.  </p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>Covariances <code class="reqn">Var(r_t)</code>.  </p>
</td></tr>
<tr><td><code>N0</code>, <code>N1</code>, <code>N2</code></td>
<td>
<p>Diffuse phase decomposition of <code class="reqn">N_t</code>.   </p>
</td></tr>
</table>


<h3>References</h3>

<p>Koopman, S.J. and Durbin J. (2000).  Fast filtering and
smoothing for non-stationary time series models, Journal of American
Statistical Assosiation, 92, 1630-38.  <br />
</p>
<p>Koopman, S.J. and Durbin J. (2001).  Time Series Analysis by State Space
Methods. Oxford: Oxford University Press.  <br />
</p>
<p>Koopman, S.J. and Durbin J. (2003).  Filtering and smoothing of state vector
for diffuse state space models, Journal of Time Series Analysis, Vol. 24,
No. 1.  <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KFAS">KFAS</a></code> for examples
</p>
<p><code><a href="#topic+logLik">logLik</a></code>, <code><a href="#topic+KFAS">KFAS</a></code>, <code><a href="#topic+fitSSM">fitSSM</a></code>, 
<code><a href="#topic+boat">boat</a></code>, <code><a href="#topic+sexratio">sexratio</a></code>,
<code><a href="#topic+GlobalTemp">GlobalTemp</a></code>, <code><a href="#topic+SSModel">SSModel</a></code>, 
<code><a href="#topic+importanceSSM">importanceSSM</a></code>, <code><a href="#topic+approxSSM">approxSSM</a></code> for examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- cumsum(rnorm(100, 0, 0.1))
y &lt;- rnorm(100, x, 0.1)
model &lt;- SSModel(y ~ SSMtrend(1, Q = 0.01), H = 0.01)
out &lt;- KFS(model)
ts.plot(ts(x), out$a, out$att, out$alpha, col = 1:4)

</code></pre>

<hr>
<h2 id='ldl'>LDL Decomposition of a Matrix</h2><span id='topic+ldl'></span>

<h3>Description</h3>

<p>Function <code>ldl</code> computes the LDL decomposition of a positive semidefinite matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldl(x, tol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldl_+3A_x">x</code></td>
<td>
<p>Symmetrix matrix.</p>
</td></tr>
<tr><td><code id="ldl_+3A_tol">tol</code></td>
<td>
<p>Tolerance parameter for LDL decomposition, determines which
diagonal values are counted as zero. Same value is used in isSymmetric function. 
Default is <code>max(100, max(abs(diag(as.matrix(x))))) * .Machine$double.eps</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Transformed matrix with D in diagonal, L in strictly lower diagonal
and zeros on upper diagonal.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Positive semidefinite matrix, example matrix taken from ?chol
x &lt;- matrix(c(1:5, (1:5)^2), 5, 2)
x &lt;- cbind(x, x[, 1] + 3*x[, 2])
m &lt;- crossprod(x)
l &lt;- ldl(m, tol = 1e-8) # arm64 Mac setup in CRAN fails with default tolerance
d &lt;- diag(diag(l))
diag(l) &lt;- 1
all.equal(l %*% d %*% t(l), m, tol = 1e-15)
</code></pre>

<hr>
<h2 id='logLik.SSModel'>Log-likelihood of the State Space Model.</h2><span id='topic+logLik.SSModel'></span><span id='topic+logLik'></span>

<h3>Description</h3>

<p>Function <code>logLik.SSmodel</code> computes the log-likelihood value of a state
space model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SSModel'
logLik(
  object,
  marginal = FALSE,
  nsim = 0,
  antithetics = TRUE,
  theta,
  check.model = TRUE,
  transform = c("ldl", "augment"),
  maxiter = 50,
  seed,
  convtol = 1e-08,
  expected = FALSE,
  H_tol = 1e+15,
  transform_tol,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.SSModel_+3A_object">object</code></td>
<td>
<p>State space model of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_marginal">marginal</code></td>
<td>
<p>Logical. Compute marginal instead of diffuse likelihood (see
details). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_nsim">nsim</code></td>
<td>
<p>Number of independent samples used in estimating the
log-likelihood of the non-Gaussian state space model. Default is 0, which
gives good starting value for optimization. Only used for non-Gaussian
model.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_antithetics">antithetics</code></td>
<td>
<p>Logical. If TRUE, two antithetic variables are used in
simulations, one for location and another for scale. Default is TRUE. Only
used for non-Gaussian model.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_theta">theta</code></td>
<td>
<p>Initial values for conditional mode theta. Only used for
non-Gaussian model.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_check.model">check.model</code></td>
<td>
<p>Logical. If TRUE, function <code>is.SSModel</code> is called
before computing the likelihood. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_transform">transform</code></td>
<td>
<p>How to transform the model in case of non-diagonal
covariance matrix <code class="reqn">H</code>. Defaults to <code>"ldl"</code>. See function
<code><a href="#topic+transformSSM">transformSSM</a></code> for details.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations used in linearisation.
Default is 50. Only used for non-Gaussian model.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_seed">seed</code></td>
<td>
<p>The value is used as a seed via <code>set.seed</code> function. Only used for
non-Gaussian model.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_convtol">convtol</code></td>
<td>
<p>Tolerance parameter for convergence checks for Gaussian
approximation. Only used for non-Gaussian model.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_expected">expected</code></td>
<td>
<p>Logical value defining the approximation of H_t in case of Gamma 
and negative binomial distribution. Default is <code>FALSE</code> which matches the 
algorithm of Durbin &amp; Koopman (1997), whereas <code>TRUE</code> uses the expected value
of observations in the equations, leading to results which match with <code>glm</code> (where applicable).
The latter case was the default behaviour of KFAS before version 1.3.8.
Essentially this is the difference between observed and expected information. Only used for non-Gaussian model.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_h_tol">H_tol</code></td>
<td>
<p>Tolerance parameter for check <code>max(H) &gt; tol_H</code>, which suggests that the approximation 
converged to degenerate case with near zero signal-to-noise ratio. Default is very generous 1e15. 
Only used for non-Gaussian model.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_transform_tol">transform_tol</code></td>
<td>
<p>Tolerance parameter for LDL decomposition in case of a 
non-diagonal H and <code>transform = "ldl"</code>. See <code><a href="#topic+transformSSM">transformSSM</a></code> and <code><a href="#topic+ldl">ldl</a></code> for details.</p>
</td></tr>
<tr><td><code id="logLik.SSModel_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As KFAS is based on diffuse initialization, the log-likelihood is also diffuse,
which coincides with restricted likelihood (REML) in an appropriate (mixed)
models. However, in typical REML estimation constant term <code class="reqn">log|X'X|</code> is
omitted from the log-likelihood formula. Similar term is also missing in
diffuse log-likelihood formulations of state space models, but unlike in simpler
linear models this term is not necessarily constant. Therefore omitting this
term can lead to suboptimal results in model estimation if there is unknown
parameters in diffuse parts of Zt or Tt (Francke et al. 2011). Therefore
so called marginal log-likelihood (diffuse likelihood + extra term) is
recommended. See also Gurka (2006) for model comparison in mixed model
settings using REML with and without the additional (constant) term.
The marginal log-likelihood can be computed by setting <code>marginal = TRUE</code>.
</p>
<p>Note that for non-Gaussian models with importance sampling derivative-free
optimization methods such as Nelder-Mead might be more reliable than methods
which use finite difference approximations. This is due to noise caused by
the relative stopping criterion used for finding approximating Gaussian
model.
</p>


<h3>Value</h3>

<p>Log-likelihood of the model.
</p>


<h3>References</h3>

<p>Francke, M. K., Koopman, S. J. and De Vos, A. F. (2010),
Likelihood functions for state space models with diffuse initial
conditions. Journal of Time Series Analysis, 31: 407&ndash;414.<br />
</p>
<p>Gurka, M. J (2006), Selecting the Best Linear Mixed Model Under REML. The
American Statistician, Vol. 60.<br />
</p>
<p>Casals, J., Sotoca, S., Jerez, M. (2014), Minimally conditioned likelihood
for a nonstationary state space model. Mathematics and Computers in
Simulation, Vol. 100.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example of estimating AR model with covariates, and how to deal with possible
# non-stationarity in optimization.

set.seed(1)
x &lt;- rnorm(100)
y &lt;- 2 * x + arima.sim(n = 100, model = list(ar = c(0.5, -0.3)))

model&lt;- SSModel(y ~ SSMarima(ar = c(0.5, -0.3),  Q = 1) + x, H = 0)

obj &lt;- function(pars, model, estimate = TRUE) {
  #guard against stationarity
  armamod &lt;- try(SSMarima(ar = artransform(pars[1:2]), Q = exp(pars[3])), silent = TRUE)
  if(class(armamod) == "try-error") {
    return(Inf)
  } else {
    # use advanced subsetting method for SSModels, see ?`[.SSModel`
    model["T", states = "arima"] &lt;- armamod$T
    model["Q", eta = "arima"]  &lt;- armamod$Q
    model["P1", states = "arima"]  &lt;- armamod$P1
    if(estimate) {
      -logLik(model)
    } else {
      model
    }
  }
}
fit &lt;- optim(p = c(0.5,-0.5,1), fn = obj, model = model, method ="BFGS")

model &lt;- obj(fit$par, model, FALSE)
model$T
model$Q
coef(KFS(model), last = TRUE)

</code></pre>

<hr>
<h2 id='mvInnovations'>Multivariate Innovations</h2><span id='topic+mvInnovations'></span>

<h3>Description</h3>

<p>Function <code>mvInnovations</code> computes the multivariate versions of one 
step-ahead prediction errors and their variances using the output of <code><a href="#topic+KFS">KFS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvInnovations(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvInnovations_+3A_x">x</code></td>
<td>
<p>Object of class <code>KFS</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>v</code></td>
<td>
<p>Multivariate prediction errors <code class="reqn">v_{t} = y_{t} - Z_{t}a_{t}
</code></p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>Prediction error variances <code class="reqn">Var(v_{t})</code>. </p>
</td></tr>
<tr><td><code>Finf</code></td>
<td>
<p>Diffuse part of <code class="reqn">F_t</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Compute the filtered estimates based on the KFS output

filtered &lt;- function(x) {
  innov &lt;- mvInnovations(x)
  att &lt;- window(x$a, end = end(x$a) - 1)
  tvz &lt;- attr(x$model,"tv")[1]
  
  for (i in 1:nrow(att)) {
    att[i,] &lt;- att[i,] + 
      x$P[,,i] %*% 
      t(solve(innov$F[,,i], x$model$Z[, , tvz * (i - 1) + 1, drop = FALSE])) %*%
      innov$v[i, ]
  }
  att
}
</code></pre>

<hr>
<h2 id='plot.SSModel'>Diagnostic Plots of State Space Models</h2><span id='topic+plot.SSModel'></span>

<h3>Description</h3>

<p>Diagnostic plots based on standardized residuals for objects of class <code>SSModel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SSModel'
plot(x, nsim = 0, zerotol = 0, expected = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SSModel_+3A_x">x</code></td>
<td>
<p>Object of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="plot.SSModel_+3A_nsim">nsim</code></td>
<td>
<p>The number of independent samples used in importance sampling.
Only used for non-Gaussian model. Default is 0, which computes the
approximating Gaussian model by <code><a href="#topic+approxSSM">approxSSM</a></code> and performs the
usual Gaussian filtering/smoothing so that the smoothed state estimates
equals to the conditional mode of <code class="reqn">p(\alpha_t|y)</code>.
In case of <code>nsim = 0</code>, the mean estimates and their variances are computed using
the Delta method (ignoring the covariance terms).</p>
</td></tr>
<tr><td><code id="plot.SSModel_+3A_zerotol">zerotol</code></td>
<td>
<p>Tolerance parameter for positivity checking in standardization. Default is zero. 
The values of D &lt;= zerotol * max(D, 0) are deemed to zero.</p>
</td></tr>
<tr><td><code id="plot.SSModel_+3A_expected">expected</code></td>
<td>
<p>Logical value defining the approximation of H_t in case of Gamma 
and negative binomial distribution. Default is <code>FALSE</code> which matches the 
algorithm of Durbin &amp; Koopman (1997), whereas <code>TRUE</code> uses the expected value
of observations in the equations, leading to results which match with <code>glm</code> (where applicable).
The latter case was the default behaviour of KFAS before version 1.3.8.
Essentially this is the difference between observed and expected information.</p>
</td></tr>
<tr><td><code id="plot.SSModel_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>modelNile &lt;- SSModel(Nile ~ SSMtrend(1, Q = list(matrix(NA))), H = matrix(NA))
modelNile &lt;- fitSSM(inits = c(log(var(Nile)),log(var(Nile))), model = modelNile,
 method = "BFGS")$model

if (interactive()) {
  plot(modelNile)
}
</code></pre>

<hr>
<h2 id='predict.SSModel'>State Space Model Predictions</h2><span id='topic+predict.SSModel'></span><span id='topic+predict'></span>

<h3>Description</h3>

<p>Function <code>predict.SSModel</code> predicts the future observations of a state
space model of class <code><a href="#topic+SSModel">SSModel</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SSModel'
predict(
  object,
  newdata,
  n.ahead,
  interval = c("none", "confidence", "prediction"),
  level = 0.95,
  type = c("response", "link"),
  states = NULL,
  se.fit = FALSE,
  nsim = 0,
  prob = TRUE,
  maxiter = 50,
  filtered = FALSE,
  expected = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.SSModel_+3A_object">object</code></td>
<td>
<p>Object of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_newdata">newdata</code></td>
<td>
<p>A compatible <code>SSModel</code> object to be added in the end of
the old object for which the predictions are required. If omitted,
predictions are either for the past data points, or if argument
<code>n.ahead</code> is given, <code>n.ahead</code> time steps ahead.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_n.ahead">n.ahead</code></td>
<td>
<p>Number of steps ahead at which to predict. Only used if
<code>newdata</code> is omitted. Note that when using <code>n.ahead</code>, object
cannot contain time varying system matrices.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_interval">interval</code></td>
<td>
<p>Type of interval calculation.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_level">level</code></td>
<td>
<p>Confidence level for intervals.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_type">type</code></td>
<td>
<p>Scale of the prediction, <code>"response"</code> or <code>"link"</code>.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_states">states</code></td>
<td>
<p>Which states are used in computing the predictions. Either a
numeric vector containing the indices of the corresponding states, or a
character vector defining the types of the corresponding states. Possible choices are
<code>"all"</code>,  <code>"level"</code>, <code>"slope"</code> (which does not make sense as the corresponding Z is zero.),
<code>"trend"</code>,  <code>"regression"</code>, <code>"arima"</code>, <code>"custom"</code>,
<code>"cycle"</code> or <code>"seasonal"</code>, where <code>"trend"</code> extracts all states relating to trend.
These can be combined. Default is <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_se.fit">se.fit</code></td>
<td>
<p>If TRUE, standard errors of fitted values are computed. Default is FALSE.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_nsim">nsim</code></td>
<td>
<p>Number of independent samples used in importance sampling. Used
only for non-Gaussian models.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_prob">prob</code></td>
<td>
<p>if TRUE (default), the predictions in binomial case are
probabilities instead of counts.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations used in approximation Default
is 50. Only used for non-Gaussian model.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_filtered">filtered</code></td>
<td>
<p>If <code>TRUE</code>, compute predictions based on filtered
(one-step-ahead) estimates. Default is FALSE i.e. predictions are based on
all available observations given by user. For diffuse phase,
interval bounds and standard errors of fitted values are set to <code>-Inf</code>/<code>Inf</code>
(If the interest is in the first time points it might be useful to use
non-exact diffuse initialization.).</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_expected">expected</code></td>
<td>
<p>Logical value defining the approximation of H_t in case of Gamma 
and negative binomial distribution. Default is <code>FALSE</code> which matches the 
algorithm of Durbin &amp; Koopman (1997), whereas <code>TRUE</code> uses the expected value
of observations in the equations, leading to results which match with <code>glm</code> (where applicable).
The latter case was the default behaviour of KFAS before version 1.3.8.
Essentially this is the difference between observed and expected information in GLM context.</p>
</td></tr>
<tr><td><code id="predict.SSModel_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For non-Gaussian models, the results depend whether importance sampling is
used (<code>nsim&gt;0</code>). without simulations, the confidence intervals are based
on the Gaussian approximation of <code class="reqn">p(\alpha | y)</code>. Confidence intervals in
response scale are computed in linear predictor scale, and then transformed
to response scale. The prediction intervals are not supported. With
importance sampling, the confidence intervals are computed as the empirical
quantiles from the weighted sample, whereas the prediction intervals contain
additional step of simulating the response variables from the sampling
distribution <code class="reqn">p(y|\theta^i)</code>.
</p>
<p>Predictions take account the uncertainty in state estimation
(given the prior distribution for the initial states), but not the uncertainty
of estimating the parameters in the system matrices (i.e. <code class="reqn">Z</code>, <code class="reqn">Q</code> etc.).
Thus the obtained confidence/prediction intervals can underestimate the true
uncertainty for short time series and/or complex models.
</p>
<p>If no simulations are used, the standard errors in response scale are
computed using the Delta method.
</p>


<h3>Value</h3>

<p>A matrix or list of matrices containing the predictions, and
optionally standard errors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
x &lt;- runif(n=100,min=1,max=3)
y &lt;- rpois(n=100,lambda=exp(x-1))
model &lt;- SSModel(y~x,distribution="poisson")
xnew &lt;- seq(0.5,3.5,by=0.1)
newdata &lt;- SSModel(rep(NA,length(xnew))~xnew,distribution="poisson")
pred &lt;- predict(model,newdata=newdata,interval="prediction",level=0.9,nsim=100)
plot(x=x,y=y,pch=19,ylim=c(0,25),xlim=c(0.5,3.5))
matlines(x=xnew,y=pred,col=c(2,2,2),lty=c(1,2,2),type="l")

model &lt;- SSModel(Nile~SSMtrend(1,Q=1469),H=15099)
pred &lt;- predict(model,n.ahead=10,interval="prediction",level=0.9)
pred
</code></pre>

<hr>
<h2 id='print.KFS'>Print Ouput of Kalman Filter and Smoother</h2><span id='topic+print.KFS'></span>

<h3>Description</h3>

<p>Print Ouput of Kalman Filter and Smoother
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KFS'
print(x, type = "state", digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.KFS_+3A_x">x</code></td>
<td>
<p>output object from function KFS.</p>
</td></tr>
<tr><td><code id="print.KFS_+3A_type">type</code></td>
<td>
<p>What to print. Possible values are <code>"state"</code> (default),
<code>"signal"</code>, and  <code>"mean"</code>. Multiple choices are allowed.</p>
</td></tr>
<tr><td><code id="print.KFS_+3A_digits">digits</code></td>
<td>
<p>minimum number of digits to be printed.</p>
</td></tr>
<tr><td><code id="print.KFS_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='print.SSModel'>Print SSModel Object</h2><span id='topic+print.SSModel'></span>

<h3>Description</h3>

<p>Print SSModel Object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SSModel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.SSModel_+3A_x">x</code></td>
<td>
<p>SSModel object</p>
</td></tr>
<tr><td><code id="print.SSModel_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='rename_states'>Rename the States of SSModel Object</h2><span id='topic+rename_states'></span>

<h3>Description</h3>

<p>A simple function for renaming the states of <code><a href="#topic+SSModel">SSModel</a></code> object. 
Note that since KFAS version 1.2.3 the auxiliary functions such as 
<code><a href="#topic+SSMtrend">SSMtrend</a></code> have argument <code>state_names</code> which can be used to 
overwrite the default state names when building the model with <code><a href="#topic+SSModel">SSModel</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rename_states(model, state_names)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rename_states_+3A_model">model</code></td>
<td>
<p>Object of class SSModel</p>
</td></tr>
<tr><td><code id="rename_states_+3A_state_names">state_names</code></td>
<td>
<p>Character vector giving new names for the states.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Original model with dimnames corresponding to states renamed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>custom_model &lt;- SSModel(1:10 ~ -1 + 
SSMcustom(Z = 1, T = 1, R = 1, Q = 1, P1inf = 1), H = 1) 
custom_model &lt;- rename_states(custom_model, "level")
ll_model &lt;- SSModel(1:10 ~ SSMtrend(1, Q = 1), H = 1)
test_these &lt;- c("y", "Z", "H", "T", "R", "Q", "a1", "P1", "P1inf")
identical(custom_model[test_these], ll_model[test_these])

</code></pre>

<hr>
<h2 id='residuals.KFS'>Extract Residuals of KFS output</h2><span id='topic+residuals.KFS'></span>

<h3>Description</h3>

<p>Extract Residuals of KFS output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KFS'
residuals(object, type = c("recursive", "pearson", "response", "state"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.KFS_+3A_object">object</code></td>
<td>
<p>KFS object</p>
</td></tr>
<tr><td><code id="residuals.KFS_+3A_type">type</code></td>
<td>
<p>Character string defining the type of residuals.</p>
</td></tr>
<tr><td><code id="residuals.KFS_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For object of class KFS, several types of residuals can be computed:
</p>
 
<ul>
<li>  <p><code>"recursive"</code>: One-step-ahead prediction residuals
<code class="reqn">v_{t,i}=y_{t,i}-Z_{t,i}a_{t,i}</code>. For non-Gaussian case recursive
residuals are computed as <code class="reqn">y_{t}-f(Z_{t}a_{t})</code>, i.e.
non-sequentially. Computing recursive residuals for large non-Gaussian
models can be time consuming as filtering is needed.
</p>
</li>
<li> <p><code>"pearson"</code>:  </p>
<p style="text-align: center;"><code class="reqn">(y_{t,i}-\theta_{t,i})/\sqrt{V(\mu_{t,i})},
  \quad i=1,\ldots,p,t=1,\ldots,n,</code>
</p>
<p> where <code class="reqn">V(\mu_{t,i})</code> is the
variance function of the series <code class="reqn">i</code>
</p>
</li>
<li> <p><code>"response"</code>: Data minus fitted values, <code class="reqn">y-E(y)</code>.
</p>
</li>
<li> <p><code>"state"</code>:  Residuals based on the smoothed disturbance terms
<code class="reqn">\eta</code> are defined as </p>
<p style="text-align: center;"><code class="reqn">\hat \eta_t, \quad t=1,\ldots,n.</code>
</p>

<p>Only defined for fully Gaussian models.
</p>
</li></ul>


<hr>
<h2 id='rstandard.KFS'>Extract Standardized Residuals from KFS output</h2><span id='topic+rstandard.KFS'></span>

<h3>Description</h3>

<p>Extract Standardized Residuals from KFS output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KFS'
rstandard(
  model,
  type = c("recursive", "pearson", "state"),
  standardization_type = c("marginal", "cholesky"),
  zerotol = 0,
  expected = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rstandard.KFS_+3A_model">model</code></td>
<td>
<p>KFS object</p>
</td></tr>
<tr><td><code id="rstandard.KFS_+3A_type">type</code></td>
<td>
<p>Type of residuals. See details.</p>
</td></tr>
<tr><td><code id="rstandard.KFS_+3A_standardization_type">standardization_type</code></td>
<td>
<p>Type of standardization. Either <code>"marginal"</code>
(default) for marginal standardization or  <code>"cholesky"</code> for Cholesky-type standardization.</p>
</td></tr>
<tr><td><code id="rstandard.KFS_+3A_zerotol">zerotol</code></td>
<td>
<p>Tolerance parameter for positivity checking in standardization. Default is zero.
The values of D &lt;= zerotol * max(D, 0) are deemed to zero.</p>
</td></tr>
<tr><td><code id="rstandard.KFS_+3A_expected">expected</code></td>
<td>
<p>Logical value defining the approximation of H_t in case of Gamma
and negative binomial distribution. Default is <code>FALSE</code> which matches the
algorithm of Durbin &amp; Koopman (1997), whereas <code>TRUE</code> uses the expected value
of observations in the equations, leading to results which match with <code>glm</code> (where applicable).
The latter case was the default behaviour of KFAS before version 1.3.8.
Essentially this is the difference between observed and expected information.</p>
</td></tr>
<tr><td><code id="rstandard.KFS_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For object of class KFS with fully Gaussian observations, several
types of standardized residuals can be computed. Also the standardization
for multivariate residuals can be done either by Cholesky decomposition
<code class="reqn">L^{-1}_t residual_t,</code> or component-wise
<code class="reqn">residual_t/sd(residual_t),</code>.
</p>

<ul>
<li><p> &quot;recursive&quot;: For Gaussian models the vector standardized one-step-ahead prediction
residuals are defined as
</p>
<p style="text-align: center;"><code class="reqn">v_{t,i}/\sqrt{F_{i,t}},</code>
</p>
<p> with residuals
being undefined in diffuse phase. Note that even in multivariate case these
standardized residuals coincide with the ones obtained from the Kalman
filter without the sequential processing (which is not true for the
non-standardized innovations).
For non-Gaussian models the vector standardized recursive residuals are obtained as
</p>
<p style="text-align: center;"><code class="reqn">L^{-1}_t (y_{t}-\mu_{t}),</code>
</p>
<p> where
<code class="reqn">L_t</code> is the lower triangular matrix from Cholesky decomposition
of <code class="reqn">Var(y_t|y_{t-1},\ldots,y_1)</code>. Computing these for large
non-Gaussian models can be time consuming as filtering is needed.
</p>
<p>For Gaussian models the component-wise standardized one-step-ahead prediction
residuals are defined as
</p>
<p style="text-align: center;"><code class="reqn">v_{t}/\sqrt{diag(F_{t})},</code>
</p>
<p> where <code class="reqn">v_{t}</code> and
<code class="reqn">F_{t}</code> are based on the standard multivariate processing.
For non-Gaussian models these are obtained as
</p>
<p style="text-align: center;"><code class="reqn">(y_{t}-\mu_{t})/\sqrt{diag(F_t)},</code>
</p>
<p> where
<code class="reqn">F_t=Var(y_t|y_{t-1},\ldots,y_1)</code>.
</p>
</li>
<li><p> &quot;state&quot;:  Residuals based on the smoothed state disturbance terms
<code class="reqn">\eta</code> are defined as </p>
<p style="text-align: center;"><code class="reqn">L^{-1}_t \hat \eta_t, \quad
  t=1,\ldots,n,</code>
</p>
<p> where <code class="reqn">L_t</code> is
either the lower triangular matrix from Cholesky decomposition of
<code class="reqn">Var(\hat\eta_t) = Q_t - V_{\eta,t}</code>, or the diagonal of the same
matrix.
</p>
</li>
<li><p> &quot;pearson&quot;:  Standardized Pearson residuals
</p>
<p style="text-align: center;"><code class="reqn">L^{-1}_t(y_{t}-\theta_{i}), \quad t=1,\ldots,n,</code>
</p>
<p> where
<code class="reqn">L_t</code> is the lower triangular matrix from Cholesky decomposition
of <code class="reqn">Var(\hat\mu_t) = H_t - V_{\mu,t}</code>, or the diagonal of the same
matrix. For Gaussian models, these coincide with the standardized smoothed
<code class="reqn">\epsilon</code> disturbance residuals
(as <code class="reqn">V_{\mu,t} = V_{\epsilon,t}</code>),
and for generalized linear models
these coincide with the standardized Pearson residuals (hence the name).
</p>
</li></ul>

<p>Note that the variance estimates from <code>KFS</code> are of form Var(x | y),
e.g., <code>V_eps</code> from <code>KFS</code> is <code class="reqn">Var(\epsilon_t | Y)</code>
and matches with equation 4.69 in Section 4.5.3 of Durbin and Koopman (2012).
(in case of univariate Gaussian model). But for the standardization we need
Var(E(x | y)) (e.g., Var(<code>epshat</code>) which we get with the law
of total variance as <code class="reqn">H_t - V_eps</code> for example.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replication of residual plot of Section 8.2 of Durbin and Koopman (2012)
model &lt;- SSModel(log(drivers) ~ SSMtrend(1, Q = list(NA))+
    SSMseasonal(period = 12, sea.type = "trigonometric", Q = NA),
  data = Seatbelts, H = NA)

updatefn &lt;- function(pars, model){
  model$H[] &lt;- exp(pars[1])
  diag(model$Q[, , 1]) &lt;- exp(c(pars[2], rep(pars[3], 11)))
  model
}

fit &lt;- fitSSM(model = model,
  inits = log(c(var(log(Seatbelts[, "drivers"])), 0.001, 0.0001)),
  updatefn = updatefn)

# tiny differences due to different optimization algorithms
setNames(c(diag(fit$model$Q[,,1])[1:2], fit$model$H[1]),
  c("level", "seasonal", "irregular"))

out &lt;- KFS(fit$model, smoothing = c("state", "mean", "disturbance"))

plot(cbind(
  recursive = rstandard(out),
  irregular = rstandard(out, "pearson"),
  state = rstandard(out, "state")[,1]),
  main = "recursive and state residuals", type = "h")

# Figure 2.8 in DK2012
model_Nile &lt;- SSModel(Nile ~
    SSMtrend(1, Q = list(matrix(NA))), H = matrix(NA))
model_Nile &lt;- fitSSM(model_Nile, c(log(var(Nile)), log(var(Nile))),
  method = "BFGS")$model

out_Nile &lt;- KFS(model_Nile,  smoothing = c("state", "mean", "disturbance"))

par(mfrow = c(2, 2))
res_p &lt;- rstandard(out_Nile, "pearson")
ts.plot(res_p)
abline(a = 0, b= 0, lty = 2)
hist(res_p, freq = FALSE)
lines(density(res_p))
res_s &lt;- rstandard(out_Nile, "state")
ts.plot(res_s)
abline(a = 0, b= 0, lty = 2)
hist(res_s, freq = FALSE)
lines(density(res_s))

</code></pre>

<hr>
<h2 id='sexratio'>Number of males and females born in Finland from 1751 to 2011</h2><span id='topic+sexratio'></span>

<h3>Description</h3>

<p>A time series object containing the number of males and females born in Finland from 1751 to 2011.
</p>


<h3>Format</h3>

<p>A time series object containing the number of males and females born in Finland from 1751 to 2011.
</p>


<h3>Source</h3>

<p>Statistics Finland <a href="https://statfin.stat.fi/PxWeb/pxweb/en/StatFin/">https://statfin.stat.fi/PxWeb/pxweb/en/StatFin/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("sexratio")
model &lt;- SSModel(Male ~ SSMtrend(1, Q = NA), u = sexratio[, "Total"],
  data = sexratio, distribution = "binomial")
fit &lt;- fitSSM(model, inits = -15, method = "BFGS")
fit$model["Q"]

# Computing confidence intervals in response scale
# Uses importance sampling on response scale (400 samples with antithetics)

pred &lt;- predict(fit$model, type = "response", interval = "conf", nsim = 100)

ts.plot(cbind(model$y/model$u, pred), col = c(1, 2, 3, 3), lty = c(1, 1, 2, 2))

## Not run: 
# Now with sex ratio instead of the probabilities:
imp &lt;- importanceSSM(fit$model, nsim = 1000, antithetics = TRUE)
sexratio.smooth &lt;- numeric(length(model$y))
sexratio.ci &lt;- matrix(0, length(model$y), 2)
w &lt;- imp$w/sum(imp$w)
for(i in 1:length(model$y)){
 sexr &lt;- exp(imp$sample[i, 1, ])
 sexratio.smooth[i] &lt;- sum(sexr*w)
 oo &lt;- order(sexr)
 sexratio.ci[i, ] &lt;- c(sexr[oo][which.min(abs(cumsum(w[oo]) - 0.05))],
                      sexr[oo][which.min(abs(cumsum(w[oo]) - 0.95))])
}

# Same by direct transformation:
out &lt;- KFS(fit$model, smoothing = "signal", nsim = 1000)
sexratio.smooth2 &lt;- exp(out$thetahat)
sexratio.ci2 &lt;- exp(c(out$thetahat) + qnorm(0.025) *
  sqrt(drop(out$V_theta))%o%c(1, -1))

ts.plot(cbind(sexratio.smooth, sexratio.ci, sexratio.smooth2, sexratio.ci2),
        col = c(1, 1, 1, 2, 2, 2), lty = c(1, 2, 2, 1, 2, 2))

## End(Not run)
</code></pre>

<hr>
<h2 id='signal'>Extracting the Partial Signal Of a State Space Model</h2><span id='topic+signal'></span>

<h3>Description</h3>

<p>Function <code>signal</code> returns the signal of a state space model using only
subset of states.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signal(object, states = "all", filtered = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="signal_+3A_object">object</code></td>
<td>
<p>Object of class <code>KFS</code>.</p>
</td></tr>
<tr><td><code id="signal_+3A_states">states</code></td>
<td>
<p>Which states are combined? Either a numeric vector containing
the indices of the corresponding states, or a character vector defining the
types of the corresponding states. Possible choices are
<code>"all"</code>,  <code>"level"</code>, <code>"slope"</code>,
<code>"trend"</code>,  <code>"regression"</code>, <code>"arima"</code>, <code>"custom"</code>,
<code>"cycle"</code> or <code>"seasonal"</code>, where <code>"trend"</code> extracts states relating to trend.
These can be combined. Default is <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="signal_+3A_filtered">filtered</code></td>
<td>
<p>If <code>TRUE</code>, filtered signal is used. Otherwise smoothed signal is
used.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>signal</code></td>
<td>
<p>Time series object of filtered signal <code class="reqn">Z_ta_t</code> or
smoothed signal <code class="reqn">Z_t\hat\alpha_t</code> using only the defined states. </p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>Cov(<code class="reqn">Z_ta_t</code>) or Cov(<code class="reqn">Z_t\hat\alpha_t</code>) using only the defined states.
For the covariance matrices of the filtered signal, only the non-diffuse part of P is used.  </p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- SSModel(log(drivers) ~ SSMtrend(1, NA) +
    SSMseasonal(12, sea.type = 'trigonometric', Q = NA) +
    log(PetrolPrice) + law,data = Seatbelts, H = NA)

ownupdatefn &lt;- function(pars,model,...){
  model$H[] &lt;- exp(pars[1])
  diag(model$Q[,,1]) &lt;- exp(c(pars[2], rep(pars[3], 11)))
  model
}

fit &lt;- fitSSM(inits = log(c(var(log(Seatbelts[,'drivers'])), 0.001, 0.0001)),
  model = model, updatefn = ownupdatefn, method = 'BFGS')

out &lt;- KFS(fit$model, smoothing = c('state', 'mean'))
ts.plot(cbind(out$model$y, fitted(out)),lty = 1:2, col = 1:2,
  main = 'Observations and smoothed signal with and without seasonal component')
lines(signal(out, states = c('regression', 'trend'))$signal, col = 4, lty = 1)
legend('bottomleft',
  legend = c('Observations', 'Smoothed signal','Smoothed level'),
  col = c(1, 2, 4), lty = c(1, 2, 1))

</code></pre>

<hr>
<h2 id='simulateSSM'>Simulation of a Gaussian State Space Model</h2><span id='topic+simulateSSM'></span>

<h3>Description</h3>

<p>Function <code>simulateSMM</code> simulates states, signals, disturbances or missing observations of
the Gaussian state space model either conditional on the data (simulation smoother) or
unconditionally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateSSM(
  object,
  type = c("states", "signals", "disturbances", "observations", "epsilon", "eta"),
  filtered = FALSE,
  nsim = 1,
  antithetics = FALSE,
  conditional = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulateSSM_+3A_object">object</code></td>
<td>
<p>Gaussian state space object of class <code>SSModel</code>.</p>
</td></tr>
<tr><td><code id="simulateSSM_+3A_type">type</code></td>
<td>
<p>What to simulate.</p>
</td></tr>
<tr><td><code id="simulateSSM_+3A_filtered">filtered</code></td>
<td>
<p>Simulate from <code class="reqn">p(\alpha_t|y_{t-1},...,y_1)</code>
instead of <code class="reqn">p(\alpha|y)</code>.</p>
</td></tr>
<tr><td><code id="simulateSSM_+3A_nsim">nsim</code></td>
<td>
<p>Number of independent samples. Default is 1.</p>
</td></tr>
<tr><td><code id="simulateSSM_+3A_antithetics">antithetics</code></td>
<td>
<p>Use antithetic variables in simulation. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="simulateSSM_+3A_conditional">conditional</code></td>
<td>
<p>Simulations are conditional to data. If <code>FALSE</code>, the
states having exact diffuse initial distribution (as defined by <code>P1inf</code>
are fixed to corresponding values of <code>a1</code>. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulation smoother algorithm is based on article by J. Durbin and S.J. Koopman (2002).
The simulation filter (<code>filtered = TRUE</code>) is a straightforward modification
of the simulations smoother, where only filtering steps are performed.
</p>
<p>Function can use two antithetic variables, one for location and other for scale, so output
contains four blocks of simulated values which correlate which each other (ith block correlates
negatively with (i+1)th block, and positively with (i+2)th block etc.).
</p>
<p>Note that KFAS versions 1.2.0 and older, for unconditional simulation the initial
distribution of states was fixed so that <code>a1</code> was set to the smoothed estimates
of the first state and the initial variance was set to zero. Now original
<code>a1</code> and <code>P1</code> are used, and <code>P1inf</code> is ignored (i.e. diffuse states are
fixed to corresponding elements of <code>a1</code>).
</p>


<h3>Value</h3>

<p>An n x k x nsim array containing the simulated series, where k is number of observations,
signals, states or disturbances.
</p>


<h3>References</h3>

<p>Durbin J. and Koopman, S.J. (2002). A simple and efficient simulation smoother for
state space time series analysis, Biometrika, Volume 89, Issue 3
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# simulate new observations from the "fitted" model
model &lt;- SSModel(Nile ~ SSMtrend(1, Q = 1469), H = 15099)
# signal conditional on the data i.e. samples from p(theta | y)
# unconditional simulation is not reasonable as the model is nonstationary
signal_sim &lt;- simulateSSM(model, type = "signals", nsim = 10)
# and add unconditional noise term i.e samples from p(epsilon)
epsilon_sim &lt;- simulateSSM(model, type = "epsilon", nsim = 10,
  conditional = FALSE)
observation_sim &lt;- signal_sim + epsilon_sim

ts.plot(observation_sim[,1,], Nile, col = c(rep(2, 10), 1),
  lty = c(rep(2, 10), 1), lwd = c(rep(1, 10), 2))

# fully unconditional simulation:
observation_sim2 &lt;- simulateSSM(model, type = "observations", nsim = 10,
  conditional = FALSE)
ts.plot(observation_sim[,1,], observation_sim2[,1,], Nile,
col = c(rep(2:3, each = 10), 1), lty = c(rep(2, 20), 1),
lwd = c(rep(1, 20), 2))

# illustrating use of antithetics
model &lt;- SSModel(matrix(NA, 100, 1) ~ SSMtrend(1, 1, P1inf = 0), H = 1)

set.seed(123)
sim &lt;- simulateSSM(model, "obs", nsim = 2, antithetics = TRUE)
# first time points
sim[1,,]
# correlation structure between simulations with two antithetics
cor(sim[,1,])

out_NA &lt;- KFS(model, filtering = "none", smoothing = "state")
model["y"] &lt;- sim[, 1, 1]
out_obs &lt;- KFS(model, filtering = "none", smoothing = "state")

set.seed(40216)
# simulate states from the p(alpha | y)
sim_conditional &lt;- simulateSSM(model, nsim = 10, antithetics = TRUE)

# mean of the simulated states is exactly correct due to antithetic variables
mean(sim_conditional[2, 1, ])
out_obs$alpha[2]
# for variances more simulations are needed
var(sim_conditional[2, 1, ])
out_obs$V[2]

set.seed(40216)
# no data, simulations from p(alpha)
sim_unconditional &lt;- simulateSSM(model, nsim = 10, antithetics = TRUE,
  conditional = FALSE)
mean(sim_unconditional[2, 1, ])
out_NA$alpha[2]
var(sim_unconditional[2, 1, ])
out_NA$V[2]

ts.plot(cbind(sim_conditional[,1,1:5], sim_unconditional[,1,1:5]),
  col = rep(c(2,4), each = 5))
lines(out_obs$alpha, lwd=2)

</code></pre>

<hr>
<h2 id='SSMarima'>Create a State Space Model Object of Class SSModel</h2><span id='topic+SSMarima'></span><span id='topic+SSMcustom'></span><span id='topic+SSMcycle'></span><span id='topic+SSModel'></span><span id='topic+SSMregression'></span><span id='topic+SSMseasonal'></span><span id='topic+SSMtrend'></span>

<h3>Description</h3>

<p>Function <code>SSModel</code> creates a state space object object of class
<code>SSModel</code> which can be used as an input object for various functions of
<code>KFAS</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SSMarima(
  ar = NULL,
  ma = NULL,
  d = 0,
  Q,
  stationary = TRUE,
  index,
  n = 1,
  state_names = NULL,
  ynames
)

SSMcustom(Z, T, R, Q, a1, P1, P1inf, index, n = 1, state_names = NULL)

SSMcycle(
  period,
  Q,
  type,
  index,
  a1,
  P1,
  P1inf,
  damping = 1,
  n = 1,
  state_names = NULL,
  ynames
)

SSModel(formula, data, H, u, distribution, tol = .Machine$double.eps^0.5)

SSMregression(
  rformula,
  data,
  type,
  Q,
  index,
  R,
  a1,
  P1,
  P1inf,
  n = 1,
  remove.intercept = TRUE,
  state_names = NULL,
  ynames
)

SSMseasonal(
  period,
  Q,
  sea.type = c("dummy", "trigonometric"),
  type,
  index,
  a1,
  P1,
  P1inf,
  n = 1,
  state_names = NULL,
  ynames,
  harmonics
)

SSMtrend(
  degree = 1,
  Q,
  type,
  index,
  a1,
  P1,
  P1inf,
  n = 1,
  state_names = NULL,
  ynames
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SSMarima_+3A_ar">ar</code></td>
<td>
<p>For arima component, a numeric vector containing the autoregressive
coeffients.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_ma">ma</code></td>
<td>
<p>For arima component, a numericvector containing the moving average
coeffients.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_d">d</code></td>
<td>
<p>For arima component, a degree of differencing.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_q">Q</code></td>
<td>
<p>For arima, cycle and seasonal component, a <code class="reqn">p \times p</code>
covariance matrix of the disturbances (or in the time varying case <code class="reqn">p
\times p \times n</code> array), where where $p$ = <code>length(index)</code>.
For trend component, list of length <code>degree</code> containing the <code class="reqn">p
\times p</code> or <code class="reqn">p \times p \times n</code> covariance matrices. For a custom
component, arbitrary covariance matrix or array of disturbance terms
<code class="reqn">\eta_t</code></p>
</td></tr>
<tr><td><code id="SSMarima_+3A_stationary">stationary</code></td>
<td>
<p>For arima component, logical value indicating whether a
stationarity of the arima part is assumed. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_index">index</code></td>
<td>
<p>A vector indicating for which series the corresponding
components are constructed.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_n">n</code></td>
<td>
<p>Length of the series, only used internally for dimensionality check.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_state_names">state_names</code></td>
<td>
<p>A character vector giving the state names.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_ynames">ynames</code></td>
<td>
<p>names of the times series, used internally.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_z">Z</code></td>
<td>
<p>For a custom component, system matrix or array of observation
equation.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_t">T</code></td>
<td>
<p>For a custom component, system matrix or array of transition
equation.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_r">R</code></td>
<td>
<p>For a custom and regression components, optional <code class="reqn">m \times k</code>
system matrix or array of transition equation.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_a1">a1</code></td>
<td>
<p>Optional <code class="reqn">m \times 1</code> matrix giving the expected value
of the initial state vector <code class="reqn">\alpha_1</code>.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_p1">P1</code></td>
<td>
<p>Optional <code class="reqn">m \times m</code> matrix giving the covariance
matrix of <code class="reqn">\alpha_1</code>. In the diffuse case the non-diffuse
part of <code class="reqn">P_1</code>.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_p1inf">P1inf</code></td>
<td>
<p>Optional <code class="reqn">m \times m</code> matrix giving the diffuse part
of <code class="reqn">P_1</code>. Diagonal matrix with ones on diagonal elements which
correspond to the diffuse initial states. If <code>P1inf[i,i]&gt;0</code>, corresponding
row and column of <code>P1</code> should be zero.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_period">period</code></td>
<td>
<p>For a cycle and seasonal components, the length of the
cycle/seasonal pattern.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_type">type</code></td>
<td>
<p>For cycle, seasonal, trend and regression components, character
string defining if <code>"distinct"</code> or <code>"common"</code> states are used for
different series.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_damping">damping</code></td>
<td>
<p>A damping factor for cycle component. Defaults to 1.
Note that there are no checks for the range of the factor.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_formula">formula</code></td>
<td>
<p>An object of class <code><a href="stats.html#topic+formula">formula</a></code> containing the
symbolic description of the model. The intercept term can be removed with
<code>-1</code> as in <code>lm</code>. In case of trend or differenced arima component the
intercept is removed automatically in order to keep the model identifiable.
See package vignette and examples in <code><a href="#topic+KFAS">KFAS</a></code> for special functions
used in model construction.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment containing the
variables in the model.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_h">H</code></td>
<td>
<p>Covariance matrix or array of disturbance terms
<code class="reqn">\epsilon_t</code> of observation equation. Defaults to an identity matrix.
Omitted in case of non-Gaussian distributions (augment the state vector if you want to add
additional noise).</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_u">u</code></td>
<td>
<p>Additional parameters for non-Gaussian models. See details in
<code><a href="#topic+KFAS">KFAS</a></code>.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_distribution">distribution</code></td>
<td>
<p>A vector of distributions of the observations. Default is
<code>rep("gaussian", p)</code>, where <code>p</code> is the number of series.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_tol">tol</code></td>
<td>
<p>A tolerance parameter used in checking whether <code>Finf</code> or <code>F</code> is numerically zero.
Defaults to <code>.Machine$double.eps^0.5</code>. If <code>F &lt; tol * max(abs(Z[Z &gt; 0]))^2</code>,
then F is deemed to be zero (i.e. differences are due to numerical precision).
This has mostly effect only on determining when to end exact diffuse phase. Tweaking this
and/or scaling model parameters/observations can sometimes help with numerical issues.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_rformula">rformula</code></td>
<td>
<p>For regression component, right hand side formula or list of
of such formulas defining the custom regression part.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_remove.intercept">remove.intercept</code></td>
<td>
<p>Remove intercept term from regression model. Default
is <code>TRUE</code>. This tries to ensure that there are no extra intercept
terms in the model.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_sea.type">sea.type</code></td>
<td>
<p>For seasonal component, character string defining whether to
use <code>"dummy"</code> or <code>"trigonometric"</code> form of the seasonal
component.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_harmonics">harmonics</code></td>
<td>
<p>For univariate trigonometric seasonal, argument
<code>harmonics</code> can be used to specify which subharmonics
are added to the model. Note that for multivariate model you can call
<code>SSMseasonal</code> multiple times with different values of <code>index</code>.</p>
</td></tr>
<tr><td><code id="SSMarima_+3A_degree">degree</code></td>
<td>
<p>For trend component, integer defining the degree of the
polynomial trend. 1 corresponds to local level, 2 for local linear trend
and so forth.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Formula of the model can contain the usual regression part and additional
functions defining different types of components of the model, named as
<code>SSMarima</code>, <code>SSMcustom</code>, <code>SSMcycle</code>, <code>SSMregression</code>,
<code>SSMseasonal</code> and <code>SSMtrend</code>.
</p>
<p>For more details, see package vignette (the mathematical notation is somewhat non-readable in ASCII).
</p>


<h3>Value</h3>

<p>Object of class <code>SSModel</code>, which is a list with the following
components:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>A n x p matrix containing the observations. </p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>A p x m x 1 or p x m x n array corresponding to the system matrix
of observation equation. </p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>A p x p x 1 or p x p x n array
corresponding to the covariance matrix of observational disturbances
epsilon. </p>
</td></tr>
<tr><td><code>T</code></td>
<td>
<p>A m x m x 1 or m x m x n array corresponding to the
first system matrix of state equation. </p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>A m x k x 1 or m x k x n
array corresponding to the second system matrix of state equation. </p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>A k x k x 1 or k x k x n array corresponding to the covariance
matrix of state disturbances eta </p>
</td></tr>
<tr><td><code>a1</code></td>
<td>
<p>A m x 1 matrix containing the
expected values of the initial states. </p>
</td></tr>
<tr><td><code>P1</code></td>
<td>
<p>A m x m matrix
containing the covariance matrix of the nondiffuse part of the initial
state vector. </p>
</td></tr>
<tr><td><code>P1inf</code></td>
<td>
<p>A m x m matrix containing the covariance
matrix of the diffuse part of the initial state vector.
If <code>P1[i,i]</code> is non-zero then <code>P1inf[i,i]</code> is automatically set to zero. </p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>A n x p
matrix of an additional parameters in case of non-Gaussian model.</p>
</td></tr>
<tr><td><code>distribution</code></td>
<td>
<p>A vector of length p giving the distributions of the
observations. </p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>A tolerance parameter for Kalman filtering. </p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>Original call to the function. </p>
</td></tr></table>
<p> In addition, object of class
<code>SSModel</code> contains following attributes:
</p>
<table>
<tr><td><code>names</code></td>
<td>
<p>Names of the
list components. </p>
</td></tr>
<tr><td><code>p</code>, <code>m</code>, <code>k</code>, <code>n</code></td>
<td>
<p>Integer valued scalars defining the
dimensions of the model components. </p>
</td></tr>
<tr><td><code>state_types</code></td>
<td>
<p>Types of the
states in the model. </p>
</td></tr>
<tr><td><code>eta_types</code></td>
<td>
<p>Types of the
state disturbances in the model. </p>
</td></tr>
<tr><td><code>tv</code></td>
<td>
<p>Integer vector stating whether <code>Z</code>,<code>H</code>,<code>T</code>,<code>R</code> or <code>Q</code> is
time-varying (indicated by 1 in <code>tv</code> and 0 otherwise).
If you manually change the dimensions of the matrices you must change this attribute also.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>artransform</code>
</p>
<p><code><a href="#topic+KFAS">KFAS</a></code> for more examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># add intercept to state equation by augmenting the state vector:
# diffuse initialization for the intercept, gets estimated like other states:
# for known fixed intercept, just set P1 = P1inf = 0 (default in SSMcustom).
intercept &lt;- 0
model_int &lt;- SSModel(Nile ~ SSMtrend(1, Q = 1469) +
SSMcustom(Z = 0, T = 1, Q = 0, a1 = intercept, P1inf = 1), H = 15099)

model_int$T
model_int$T[1, 2, 1] &lt;- 1 # add the intercept value to level
out &lt;- KFS(model_int)

# An example of a time-varying variance

model_drivers &lt;- SSModel(log(cbind(front, rear)) ~ SSMtrend(1, Q = list(diag(2))),
data = Seatbelts, H = array(NA, c(2, 2, 192)))

ownupdatefn &lt;- function(pars, model){
  diag(model$Q[, , 1]) &lt;- exp(pars[1:2])
  model$H[,,1:169] &lt;- diag(exp(pars[3:4])) # break in variance
  model$H[,,170:192] &lt;- diag(exp(pars[5:6]))
  model
}

fit_drivers &lt;- fitSSM(model_drivers, inits = rep(-1, 6),
  updatefn = ownupdatefn, method = "BFGS")
fit_drivers$model$H[,,1]
fit_drivers$model$H[,,192]

# An example of shift in the level component

Tt &lt;- array(diag(2), c(2, 2, 100))
Tt[1,2,28] &lt;- 1
Z &lt;- matrix(c(1,0), 1, 2)
Q &lt;- diag(c(NA, 0), 2)
model &lt;- SSModel(Nile ~ -1 + SSMcustom(Z, Tt, Q = Q, P1inf = diag(2)),
  H = matrix(NA))

model &lt;- fitSSM(model, c(10,10), method = "BFGS")$model
model$Q
model$H

conf_Nile &lt;- predict(model, interval = "confidence", level = 0.9)
pred_Nile &lt;- predict(model, interval = "prediction", level = 0.9)

ts.plot(cbind(Nile, pred_Nile, conf_Nile[, -1]), col = c(1:2, 3, 3, 4, 4),
        ylab = "Predicted Annual flow", main = "River Nile")

# dynamic regression model

set.seed(1)
x1 &lt;- rnorm(100)
x2 &lt;- rnorm(100)
b1 &lt;- 1 + cumsum(rnorm(100, sd = 1))
b2 &lt;- 2 + cumsum(rnorm(100, sd = 0.1))
y &lt;- 1 + b1 * x1 + b2 * x2 + rnorm(100, sd = 0.1)

model &lt;- SSModel(y ~ SSMregression(~ x1 + x2, Q = diag(NA,2)), H = NA)

fit &lt;- fitSSM(model, inits = c(0,0,0), method = "BFGS")

model &lt;- fit$model
model$Q
model$H
out &lt;- KFS(model)

ts.plot(out$alphahat[,-1], b1, b2, col = 1:4)

# SSMregression with multivariate observations

x &lt;- matrix(rnorm(30), 10, 3) # one variable per each series
y &lt;- x + rnorm(30)
model &lt;- SSModel(y ~ SSMregression(list(~ X1, ~ X2, ~ X3), data = data.frame(x)))
# more generally SSMregression(sapply(1:3, function(i) formula(paste0("~ X",i))), ...)

# three covariates per series, with same coefficients:
y &lt;- x[,1] + x[,2] + x[,3] + matrix(rnorm(30), 10, 3)
model &lt;- SSModel(y ~ -1 + SSMregression(~ X1 + X2 + X3, remove.intercept = FALSE,
  type = "common", data = data.frame(x)))

# the above cases can be combined in various ways, you can call SSMregression multiple times:
model &lt;- SSModel(y ~  SSMregression(~ X1 + X2, type = "common") +
  SSMregression(~ X2), data = data.frame(x))

# examples of using data argument
y &lt;- x &lt;- rep(1, 3)
data1 &lt;- data.frame(x = rep(2, 3))
data2 &lt;- data.frame(x = rep(3, 3))

f &lt;- formula(~ -1 + x)
# With data missing the environment of formula is checked,
# and if not found in there a calling environment via parent.frame is checked.

c(SSModel(y ~ -1 + x)["Z"]) # 1
c(SSModel(y ~ -1 + x, data = data1)["Z"]) # 2

c(SSModel(y ~ -1 + SSMregression(~ -1 + x))["Z"]) # 1
c(SSModel(y ~ -1 + SSMregression(~ -1 + x, data = data1))["Z"]) # 2
c(SSModel(y ~ -1 + SSMregression(~ -1 + x), data = data1)["Z"]) # 2
SSModel(y ~ -1 + x + SSMregression(~ -1 + x, data = data1))["Z"] # 1 and 2
SSModel(y ~ -1 + x + SSMregression(~ -1 + x), data = data1)["Z"] # both are 2
SSModel(y ~ -1 + x + SSMregression(~ -1 + x, data = data1), data = data2)["Z"] # 3 and 2

SSModel(y ~ -1 + x + SSMregression(f))["Z"] # 1 and 1
SSModel(y ~ -1 + x + SSMregression(f), data = data1)["Z"] # 2 and 1
SSModel(y ~ -1 + x + SSMregression(f,data = data1))["Z"] # 1 and 2

rm(x)
c(SSModel(y ~ -1 + SSMregression(f, data = data1))$Z) # 2
## Not run: 
# This fails as there is no x in the environment of f
try(c(SSModel(y ~ -1 + SSMregression(f), data = data1)$Z))

## End(Not run)
</code></pre>

<hr>
<h2 id='transformSSM'>Transform Multivariate State Space Model for Sequential Processing</h2><span id='topic+transformSSM'></span>

<h3>Description</h3>

<p><code>transformSSM</code> transforms the general multivariate Gaussian state space model
to form suitable for sequential processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformSSM(object, type = c("ldl", "augment"), tol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transformSSM_+3A_object">object</code></td>
<td>
<p>State space model object from function <code><a href="#topic+SSModel">SSModel</a></code>.</p>
</td></tr>
<tr><td><code id="transformSSM_+3A_type">type</code></td>
<td>
<p>Option <code>"ldl"</code> performs LDL decomposition for covariance matrix <code class="reqn">H_t</code>,
and multiplies the observation equation with the <code class="reqn">L_t^{-1}</code>, so <code class="reqn">\epsilon_t^* 
\sim N(0,D_t)</code>. Option <code>"augment"</code> adds 
<code class="reqn">\epsilon_t</code> to the state vector, so <code class="reqn">Q_t</code> becomes block diagonal 
with blocks <code class="reqn">Q_t</code> and <code class="reqn">H_t</code>.</p>
</td></tr>
<tr><td><code id="transformSSM_+3A_tol">tol</code></td>
<td>
<p>Tolerance parameter for LDL decomposition (see <code><a href="#topic+ldl">ldl</a></code>). Default is 
<code>max(100, max(abs(apply(object$H, 3, diag)))) * .Machine$double.eps</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As all the functions in KFAS use univariate approach i.e. sequential processing, 
the covariance matrix <code class="reqn">H_t</code> of the observation equation needs to be 
either diagonal or zero matrix. Function <code>transformSSM</code> performs either 
the LDL decomposition of <code class="reqn">H_t</code>, or augments the state vector with
the disturbances of the observation equation.
</p>
<p>In case of a LDL decomposition, the new <code class="reqn">H_t</code> contains the diagonal part of the 
decomposition, whereas observations <code class="reqn">y_t</code> and system matrices <code class="reqn">Z_t</code> are 
multiplied with the inverse of <code class="reqn">L_t</code>. Note that although the state estimates and 
their error covariances obtained by Kalman filtering and smoothing are identical with those 
obtained from ordinary multivariate filtering, the one-step-ahead errors 
<code class="reqn">v_t</code> and their variances <code class="reqn">F_t</code> do differ. The typical 
multivariate versions can be obtained from output of <code><a href="#topic+KFS">KFS</a></code>
using <code><a href="#topic+mvInnovations">mvInnovations</a></code> function.
</p>
<p>In case of augmentation of the state vector, some care is needed interpreting the 
subsequent filtering/smoothing results: For example the <code>muhat</code> from the output of <code>KFS</code> 
now contains also the smoothed observational level noise as that is part of the state vector.
</p>


<h3>Value</h3>

<table>
<tr><td><code>model</code></td>
<td>
<p>Transformed model.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
