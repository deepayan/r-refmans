<!DOCTYPE html><html><head><title>Help for package partools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {partools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ca,cabase,calm,caglm,caprcomp,cakm,cameans,caquantile,caagg,caknn'><p>Software Alchemy: Turning Complex Statistical Computations into</p>
Embarrassingly-Parallel Ones</a></li>
<li><a href='#caclassfit,caclasspred,vote,re_code'><p>Software Alchemy for Machine Learning</p></a></li>
<li><a href='#dbs'>
<p>Debugging aid for <span class="pkg">parallel</span> cluster code.</p></a></li>
<li><a href='#formrowchunks,addlists,matrixtolist,setclsinfo,getpte,distribsplit,distribcat,distribagg,distribrange,distribcounts,distribgetrows,docmd,doclscmd,geteltis,distribmeans,distribisdt,ipstrcat,dwhich.min,dwhich.max'>
<p>Utilities for <span class="pkg">parallel</span> cluster code.</p></a></li>
<li><a href='#newadult'>
<p>UCI adult income data set, adapted</p></a></li>
<li><a href='#parpdist'><p>Partools Apps</p></a></li>
<li><a href='#prgeng'>
<p>Silicon Valley programmers and engineers</p></a></li>
<li><a href='#snowdoop,filechunkname, etc...'>
<p>Snowdoop.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1.6</td>
</tr>
<tr>
<td>Author:</td>
<td>Norm Matloff &lt;normmatloff@gmail.com&gt; [cre,aut], 
   Clark Fitzgerald &lt;clarkfitzg@gmail.com&gt; [aut], with
   contributions by Alex Rumbaugh &lt;aprumbaugh@ucdavis.edu&gt; and
   Hadley Wickham &lt;h.wickham@gmail.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Norm Matloff &lt;normmatloff@gmail.com&gt;</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for the 'Parallel' Package</td>
</tr>
<tr>
<td>Description:</td>
<td>Miscellaneous utilities for parallelizing large
   computations.  Alternative to MapReduce.
   File splitting and distributed operations such as sort and aggregate.
   "Software Alchemy" method for parallelizing most statistical methods,
   presented in N. Matloff, Parallel Computation for Data Science,
   Chapman and Hall, 2015.  Includes a debugging aid.</td>
</tr>
<tr>
<td>Depends:</td>
<td>regtools,parallel,stats,utils,data.table,pdist,methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rpart,e1071,testthat</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/matloff/partools">https://github.com/matloff/partools</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/matloff/partools/issues">https://github.com/matloff/partools/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-04-10 05:17:39 UTC; nm</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-04-10 09:16:20 UTC</td>
</tr>
</table>
<hr>
<h2 id='ca+2Ccabase+2Ccalm+2Ccaglm+2Ccaprcomp+2Ccakm+2Ccameans+2Ccaquantile+2Ccaagg+2Ccaknn'>Software Alchemy: Turning Complex Statistical Computations into
Embarrassingly-Parallel Ones</h2><span id='topic+ca'></span><span id='topic+cabase'></span><span id='topic+calm'></span><span id='topic+caglm'></span><span id='topic+caprcomp'></span><span id='topic+cakm'></span><span id='topic+cameans'></span><span id='topic+caquantile'></span><span id='topic+caagg'></span><span id='topic+caknn'></span>

<h3>Description</h3>

<p>Easy parallelization of most statistical computations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ca(cls,z,ovf,estf,estcovf=NULL,findmean=TRUE,scramble=FALSE)
cabase(cls,ovf,estf,estcovf=NULL,findmean=TRUE,cacall=FALSE,z=NULL,scramble=FALSE)
calm(cls,lmargs) 
caglm(cls,glmargs) 
caprcomp(cls,prcompargs, p)
cakm(cls,mtdf,ncenters,p)
cameans(cls,cols,na.rm=FALSE) 
caquantile(cls,vec, probs = c(0.25, 0.5, 0.75),na.rm=FALSE) 
caagg(cls,ynames,xnames,dataname,FUN)
caknn(cls, yname, k, xname='')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_cls">cls</code></td>
<td>
<p>A cluster run under the <span class="pkg">parallel</span> package.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_z">z</code></td>
<td>
<p>A data frame, matrix or vector, one observation per row/element.</p>
</td></tr> 
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_ovf">ovf</code></td>
<td>
<p>Overall statistical function, say <code>glm</code>.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_estf">estf</code></td>
<td>
<p>Function to extract the point estimate (typically
vector-valued) from the output of <code>ovf</code>.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_estcovf">estcovf</code></td>
<td>
<p>If provided, function to extract the estimated 
covariance matrix of the output of <code>estf</code></p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_findmean">findmean</code></td>
<td>
<p>If TRUE, output the average of the estimates from the
chunks; otherwise, output only the estimates themselves.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_lmargs">lmargs</code></td>
<td>
<p>Quoted string representing arguments to <code>lm</code>,
e.g. R formula, <code>data</code> specification.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_glmargs">glmargs</code></td>
<td>
<p>Quoted string representing arguments to <code>glm</code>,
e.g. R formula, <code>data</code> specification, and <code>family</code>
argument.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_prcompargs">prcompargs</code></td>
<td>
<p>Quoted string representing arguments to 
<code>prcomp</code>.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_p">p</code></td>
<td>
<p>Number of columns in data</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_na.rm">na.rm</code></td>
<td>
<p>If TRUE, remove NA values from the analysis.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_mtdf">mtdf</code></td>
<td>
<p>Quoted name of a distributed matrix or data frame.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_ncenters">ncenters</code></td>
<td>
<p>Number of clusters to find.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_cacall">cacall</code></td>
<td>
<p>If TRUE, indicates that <code>cabase</code> had been called by
<code>ca</code></p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_scramble">scramble</code></td>
<td>
<p>If this and <code>cacall</code> are TRUE, randomize the data
before distributing.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_cols">cols</code></td>
<td>
<p>A quoted string that evaluates to a data frame or matrix.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_vec">vec</code></td>
<td>
<p>A quoted string that evaluates to a vector.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_yname">yname</code></td>
<td>
<p>A quoted variable name, for the Y vector.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_k">k</code></td>
<td>
<p>Number of nearest neighbors.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_xname">xname</code></td>
<td>
<p>A quoted variable name, for the X matrix/data frame.  If
empty, it is assumed that <code>preprocessx</code> has already been run on
the nodes; if nonempty, that function is run on this X data.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_ynames">ynames</code></td>
<td>
<p>A vector of quoted variable names.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_xnames">xnames</code></td>
<td>
<p>A vector of quoted variable names.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_dataname">dataname</code></td>
<td>
<p>Quoted name of a data frame or matrix.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_probs">probs</code></td>
<td>
<p>As in the argument with the same name in
<code>quantile</code>. Should not be 0.00 or 1.00, as asymptotic
normality doesn't hold.</p>
</td></tr>
<tr><td><code id="ca+2B2Ccabase+2B2Ccalm+2B2Ccaglm+2B2Ccaprcomp+2B2Ccakm+2B2Ccameans+2B2Ccaquantile+2B2Ccaagg+2B2Ccaknn_+3A_fun">FUN</code></td>
<td>
<p>Quoted name of a function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implements the &ldquo;Software Alchemy&rdquo; (SA) method for
parallelizing statistical computations (N. Matloff, <em>Parallel
Computation for Data Science</em>, Chapman and Hall, 2015, with further
details in N. Matloff, Software Alchemy: Turning Complex Statistical
Computations into Embarrassingly-Parallel Ones, <em>Journal of
Statistical Software</em>, 2016.)  This can result in substantial speedups
in computation, as well as address limits on physical memory.
</p>
<p>The method involves breaking the data into chunks, and then applying the
given estimator to each one.  The results are averaged, and an estimated
covariance matrix computed (optional).  
</p>
<p>Except for <code>ca</code>, it is assumed that the chunking has already been
done, say via <code>distribsplit</code> or <code>readnscramble</code>. 
</p>
<p>Note that in <code>cabase</code>, the data object is not specified explicitly
in the argument list.  This is done through the function <code>ovf</code>.
</p>
<p>Key point:  <em>The SA estimator is statistically equivalent to the
original, nonparallel one, in the sense that they have the SAME
asymptotic statistical accuracy.  Neither the non-SA nor the SA
estimator is &quot;better&quot; than the other</em>, and usually they will be quite
close to each other anyway.  Since we would use SA only with large data
sets anyway (otherwise, parallel computation would not be needed for
speed), the asymptotic aspect should not be an issue.  In other words,
with SA we achieve the same statistical accuracy while possibly
attaining much faster computation.
</p>
<p>It is vital to keep in mind that <em>The memory space issue can be
just as important as run time</em>.  Even if the problem is run on many
cores, if the total memory space needed exceeds that of the machine,
the run may fail.
</p>
<p>Wrapper functions, applying SA to the corresponding R
function (or function elsewere in this package):
</p>

<ul>
<li> <p><code>calm</code>: Wrapper for <code>lm</code>.
</p>
</li>
<li> <p><code>caglm</code>: Wrapper for <code>glm</code>.
</p>
</li>
<li> <p><code>caprcomp</code>: Wrapper for <code>prcomp</code>.
</p>
</li>
<li> <p><code>cakm</code>: Wrapper for <code>kmeans</code>.
</p>
</li>
<li> <p><code>cameans</code>: Wrapper for <code>colMeans</code>.
</p>
</li>
<li> <p><code>caquantile</code>: Wrapper for <code>quantile</code>.
</p>
</li>
<li> <p><code>caagg</code>: Like <code>distribagg</code>, but finds the
average value of <code>FUN</code> across the cluster nodes.
</p>
</li></ul>

<p>A note on NA values:  Some R functions such as <code>lm</code>, <code>glm</code> and
<code>prcomp</code> have an <code>na.action</code> argument.  The default is
<code>na.omit</code>, which means that cases with at least one NA value will
be discarded. (This is also settable via <code>options()</code>.) However,
<code>na.omit</code> seems to have no effect in <code>prcomp</code> unless that
function's <code>formula</code> option is used. When in doubt, apply the
function <code>na.omit</code> directly; e.g. <code>na.omit(d)</code> for a data
frame <code>d</code> returns a data frame consisting of only the intact rows of
<code>d</code>.
</p>
<p>The method assumes that the base estimator is asymptotically normal, and
assumes i.i.d. data.  If your data set had been stored in some sorted
order, it must be randomized first, say using the <code>scramble</code> option
in <code>distribsplit</code> or by calling <code>readnscramble</code>, depending on
whether your data is already in memory or still in a file.
</p>


<h3>Value</h3>

<p>R list with these components:
</p>

<ul>
<li> <p><code>thts</code>, the results of applying the requested estimator to
the chunks; the estimator from chunk i is in row i
</p>
</li>
<li> <p><code>tht</code>, the chunk-averaged overall estimator, if requested
</p>
</li>
<li> <p><code>thtcov</code>, the estimated covariance matrix of <code>tht</code>,
if available
</p>
</li></ul>

<p>The wrapper functions return the following list elements:
</p>

<ul>
<li> <p><code>calm</code>, <code>caglm</code>: estimated regression coefficients
and their estimated covariance matrix
</p>
</li>
<li> <p><code>caprcomp</code>: <code>sdev</code> (square roots of the
eigenvalues) and <code>rotation</code>, as with <code>prcomp</code>;
<code>thts</code> is returned as well.
</p>
</li>
<li> <p><code>cakm</code>: <code>centers</code> and <code>size</code>, as with
<code>kmeans</code>; <code>thts</code> is returned as well.
</p>
</li></ul>

<p>The wrappers that return <code>thts</code> are useful for algorithms that may
expose some instability in the original (i.e. non-SA) algorithm.  With
<code>prcomp</code>, for instance, the eigenvectors corresponding to the
smaller eigenvalues may have high variances in the nonparallel version,
which will be reflected in large differences from chunk to chunk in SA,
visible in <code>thts</code>.  Note that this reflects a fundamental problem
with the algorithm on the given data set, not due to Software Alchemy;
on the contrary, an important advantage of the SA approach is to expose
such problems.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>References</h3>

<p>N. Matloff N (2016). &quot;Software Alchemy: Turning Complex Statistical
Computations into Embarrassingly-Parallel Ones.&quot; <em>Journal of Statistical
Software</em>, <b>71(4)</b>, 1-15.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# set up 'parallel' cluster
cls &lt;- makeCluster(2)
setclsinfo(cls)

# generate simulated test data, as distributed data frame
n &lt;- 10000
p &lt;- 2
tmp &lt;- matrix(rnorm((p+1)*n),nrow=n)
u &lt;- tmp[,1:p]  # "X" values
# add a "Y" col
u &lt;- cbind(u,u %*% rep(1,p) + tmp[,p+1])
# now in u, cols 1,2 are the "X" variables, and col 3 is "Y", 
# with regress coefs (0,1,1), with tmp[,p+1] being the error term
distribsplit(cls,"u")  # form distributed d.f.
# apply the function
#### calm(cls,"u[,3] ~ u[,1]+u[,2]")$tht
calm(cls,"V3 ~ .,data=u")$tht
# check; results should be approximately the same
lm(u[,3] ~ u[,1]+u[,2])
# without the wrapper
ovf &lt;- function(dummy=NULL) lm(V3 ~ .,data=z168)
ca(cls,u,ovf,estf=coef,estcovf=vcov)$tht

## Not run: 
# Census data on programmers and engineers; include a quadratic term for
# age, due to nonmonotone relation to income
data(prgeng) 
distribsplit(cls,"prgeng") 
caout &lt;- calm(cls,"wageinc ~ age+I(age^2)+sex+wkswrkd,data=prgeng")
caout$tht
# compare to nonparallel
lm(wageinc ~ age+I(age^2)+sex+wkswrkd,data=prgeng)
# get standard errors of the beta-hats
sqrt(diag(caout$thtcov))

# find mean age for all combinations of the cit and sex variables
caagg(cls,"age",c("cit","sex"),"prgeng","mean") 
# compare to nonparallel
aggregate(age ~ cit+sex,data=prgeng,mean)  

data(newadult) 
distribsplit(cls,"newadult") 
caglm(cls," gt50 ~ ., family = binomial,data=newadult")$tht 

caprcomp(cls,'newadult,scale=TRUE',5)$sdev
prcomp(newadult,scale=TRUE)$sdev

cameans(cls,"prgeng")
cameans(cls,"prgeng[,c('age','wageinc')]")
caquantile(cls,'prgeng$age')

pe &lt;- prgeng[,c(1,3,8)] 
distribsplit(cls,"pe") 
z1 &lt;- cakm(cls,'pe',3,3); z1$size; z1$centers 
# check algorithm unstable
z1$thts  # looks unstable

pe &lt;- prgeng 
pe$ms &lt;- as.integer(pe$educ == 14) 
pe$phd &lt;- as.integer(pe$educ == 16) 
pe &lt;- pe[,c(1,7,8,9,12,13)] 
distribsplit(cls,'pe',scramble=TRUE)
kout &lt;- caknn(cls,'pe[,3]',50,'pe[,-3]') 

## End(Not run)

stopCluster(cls)

</code></pre>

<hr>
<h2 id='caclassfit+2Ccaclasspred+2Cvote+2Cre_code'>Software Alchemy for Machine Learning</h2><span id='topic+caclassfit'></span><span id='topic+caclasspred'></span><span id='topic+vote'></span><span id='topic+re_code'></span>

<h3>Description</h3>

<p>Parallelization of machine learning algorithms. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>caclassfit(cls,fitcmd) 
caclasspred(fitobjs,newdata,yidx=NULL,...)
vote(preds)
re_code(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="caclassfit+2B2Ccaclasspred+2B2Cvote+2B2Cre_code_+3A_cls">cls</code></td>
<td>
<p>A cluster run under the <span class="pkg">parallel</span> package.</p>
</td></tr>
<tr><td><code id="caclassfit+2B2Ccaclasspred+2B2Cvote+2B2Cre_code_+3A_fitcmd">fitcmd</code></td>
<td>
<p>A string containing a model-fitting command to be
run on each cluster node.  This will typically include
specification of the distributed data set.</p>
</td></tr>
<tr><td><code id="caclassfit+2B2Ccaclasspred+2B2Cvote+2B2Cre_code_+3A_fitobjs">fitobjs</code></td>
<td>
<p>An R list of objects returned by the <code>fitcmd</code>
calls.</p>
</td></tr>
<tr><td><code id="caclassfit+2B2Ccaclasspred+2B2Cvote+2B2Cre_code_+3A_newdata">newdata</code></td>
<td>
<p>Data to be predicted from the fit computed by
<code>caclassfit</code>.</p>
</td></tr>
<tr><td><code id="caclassfit+2B2Ccaclasspred+2B2Cvote+2B2Cre_code_+3A_yidx">yidx</code></td>
<td>
<p>If provided, index of the true class values in
<code>newdata</code>, typically in a cross-validation setting.</p>
</td></tr>
<tr><td><code id="caclassfit+2B2Ccaclasspred+2B2Cvote+2B2Cre_code_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to the underlying prediction
function for the given method, e.g. <code>predict.rpart</code>.</p>
</td></tr>
<tr><td><code id="caclassfit+2B2Ccaclasspred+2B2Cvote+2B2Cre_code_+3A_preds">preds</code></td>
<td>
<p>A vector of predicted classes, from which the &quot;winner&quot;
will be selected by voting.</p>
</td></tr>
<tr><td><code id="caclassfit+2B2Ccaclasspred+2B2Cvote+2B2Cre_code_+3A_x">x</code></td>
<td>
<p>A vector of integers, in this context class codes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This should work for almost any classification code that has a
&ldquo;fit&rdquo; function and a <code>predict</code> method.
</p>
<p>The method assumes i.i.d. data.  If your data set had been stored in
some sorted order, it must be randomized first, say using the
<code>scramble</code> option in <code>distribsplit</code> or by calling
<code>readnscramble</code>, depending on whether your data is already in
memory or still in a file.
</p>
<p>It is assumed that class labels are 1,2,...  If not, use
<code>re_code</code>.
</p>


<h3>Value</h3>

<p>The <code>caclassfit</code> function returns an R list of objects as in
<code>fitobjs</code> above.
</p>
<p>The <code>caclasspred</code> function returns an R list with these components:
</p>

<ul>
<li> <p><code>predmat</code>, a matrix of predicted classes for
<code>newdata</code>, one row per cluster node
</p>
</li>
<li> <p><code>preds</code>, the final predicted classes, after using
<code>vote</code> to resolve possible differences in predictions among
nodes
</p>
</li>
<li> <p><code>consensus</code>, the proportion of cases for which all
nodes gave the same predictions (higher values indicating more
stability)
</p>
</li>
<li> <p><code>acc</code>, if <code>yidx</code> is non-NULL, the proportion of
cases in which <code>preds</code> is correct
</p>
</li>
<li> <p><code>confusion</code>, if <code>yidx</code> is non-NULL, the confusion matrix
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# set up 'parallel' cluster
cls &lt;- makeCluster(2)
setclsinfo(cls)
# data prep
data(prgeng)
prgeng$occ &lt;- re_code(prgeng$occ)
prgeng$bs &lt;- as.integer(prgeng$educ == 13)
prgeng$ms &lt;- as.integer(prgeng$educ == 14)
prgeng$phd &lt;- as.integer(prgeng$educ == 15)
prgeng$sex &lt;- prgeng$sex - 1
pe &lt;- prgeng[,c(1,7,8,9,12,13,14,5)]
pe$occ &lt;- as.factor(pe$occ)   # needed for rpart!
# go
distribsplit(cls,'pe')
library(rpart)
clusterEvalQ(cls,library(rpart))
fit &lt;- caclassfit(cls,"rpart(occ ~ .,data=pe)")
predout &lt;- caclasspred(fit,pe,8,type='class')
predout$acc  # 0.36 

stopCluster(cls)

## End(Not run)
</code></pre>

<hr>
<h2 id='dbs'>
Debugging aid for <span class="pkg">parallel</span> cluster code.
</h2><span id='topic+dbs'></span><span id='topic+writemgrscreen'></span><span id='topic+writewrkrscreens'></span><span id='topic+killdebug'></span><span id='topic+dbsmsg'></span><span id='topic+dbsdump'></span><span id='topic+dbsmsgstart'></span>

<h3>Description</h3>

<p>Aids in debugging of code written for the cluster operations in the
<span class="pkg">parallel</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbs(nwrkrs,xterm=NULL,src=NULL,ftn=NULL)
writemgrscreen(cmd)
killdebug()
dbsmsgstart(cls)
dbsmsg(msg)
dbsdump()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbs_+3A_cls">cls</code></td>
<td>
<p>A cluster for the <span class="pkg">parallel</span> package.</p>
</td></tr>
<tr><td><code id="dbs_+3A_nwrkrs">nwrkrs</code></td>
<td>
<p>Number of workers, i.e. size of the cluster.</p>
</td></tr>
<tr><td><code id="dbs_+3A_xterm">xterm</code></td>
<td>
<p>The string &quot;xterm&quot; or name of compatible terminal.</p>
</td></tr>
<tr><td><code id="dbs_+3A_src">src</code></td>
<td>
<p>Name of the source file to be debugged.</p>
</td></tr>
<tr><td><code id="dbs_+3A_ftn">ftn</code></td>
<td>
<p>Name of the function to be debugged.</p>
</td></tr>
<tr><td><code id="dbs_+3A_cmd">cmd</code></td>
<td>
<p>R command to be executed in manager screen.</p>
</td></tr>
<tr><td><code id="dbs_+3A_msg">msg</code></td>
<td>
<p>A message to write to the debugging record file. Can be
either a character string or any expression that is printable by
<code>cat</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A major obstacle to debugging cluster-based <span class="pkg">parallel</span>
applications is the lack of a terminal, thus precluding direct use of
<code>debug</code> and <code>browser</code>.  This set of functions consists of
two groups, one for &ldquo;quick and dirty&rdquo; debugging, that writes
debugging information to disk files, and the other for more
sophisticated work that deals with the terminal restriction.  For both
methods, make sure <code>setclsinfo</code> has been called.
</p>
<p>For &ldquo;quick and dirty&rdquo; debugging, there is <code>dbsmsg</code>, which prints
messages to files, invoked from within code running at the cluster
nodes.  There is one file for each member of the cluster, e.g.
<code>dbs.001</code>, <code>dbs.002</code> and so on, and <code>dbsmsg</code> writes to
the file associated with the worker invoking it.  Initialize via
<code>dbsmsgstart</code>.  
</p>
<p>Another quick approach is to call <code>dbsdump</code>, which will call R's
<code>dump.frames</code>, making a separate output file for each cluster node.
These can then be input to <code>debugger</code> to examine stack frames.
</p>
<p>The more elaborate debugging tool, <code>dbs</code>, is the only one in this
<span class="pkg">partools</span> package requiring a Unix-family system (Linux, Mac).  To
discuss it, suppose you wish to debug the function <code>f</code> in the file
<code>x.R</code>.  Run, say, <code>dbs(2,xterm="xterm",src="x.R",ftn="f")</code>.
Then three new terminal windows will be created, one for the cluster
manager and two for the cluster workers.  The cluster will be named
<code>cls</code>.  Automatically, the file <code>x.R</code> will be sourced by the
worker windows, and <code>debug(f)</code> will be run in them.
</p>
<p>Then you simply debug as usual.  Go to the manager window, and run
your <span class="pkg">parallel</span> application launch call in the usual way, say
<code>clusterEvalQ(cls,f(5))</code>.  The function <code>f</code> will run in each
worker window, with execution automatically entering browser mode.  You
are now ready to single-step through them, or execute any other browser
operation.
</p>
<p>If <code>xterm</code> is NULL, you will be prompted to create the terminal
windows by hand (or use existing ones), and run <code>screen</code> there as
instructed.  <code>Terminal</code> works on Macs; label the windows by hand,
by clicking &quot;Shell&quot; then &quot;Edit&quot;.
</p>
<p>When finished with the debugging session, run <code>killdebug</code> from the
original window (the one from which you invoked <code>dbs</code>) to quit the
various <code>screen</code> processes.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# quick-and-dirty method
cls &lt;- makeCluster(2) 
setclsinfo(cls)
# define 'buggy' function
g &lt;- function(x,y) {u&lt;-x+y; v&lt;-x-y; dbsmsg(c(u,v)); u^2+v^2} 
clusterExport(cls,"g") 
# set x and y at cluster nodes
clusterEvalQ(cls,{x &lt;- runif(1); y &lt;- runif(1)}) 
# start debugging session
dbsmsgstart(cls) 
# run
clusterEvalQ(cls,g(x,y)) 
# files dbs.1 and dbs.2 created, each reporting u,v values

# dbs() method
# make a test file
cat(c("f &lt;- function(x) {","   x &lt;- x + 1","   x^2","}"),file="x.R",sep="\n")
dbs(2,src="x.R",ftn="f")
# now type in manager window:
clusterEvalQ(cls,f(5))
# the 2 worker windows are now in the browser, ready for debugging

stopCluster(cls)

## End(Not run)
</code></pre>

<hr>
<h2 id='formrowchunks+2Caddlists+2Cmatrixtolist+2Csetclsinfo+2Cgetpte+2Cdistribsplit+2Cdistribcat+2Cdistribagg+2Cdistribrange+2Cdistribcounts+2Cdistribgetrows+2Cdocmd+2Cdoclscmd+2Cgeteltis+2Cdistribmeans+2Cdistribisdt+2Cipstrcat+2Cdwhich.min+2Cdwhich.max'>
Utilities for <span class="pkg">parallel</span> cluster code.
</h2><span id='topic+formrowchunks'></span><span id='topic+matrixtolist'></span><span id='topic+addlists'></span><span id='topic+setclsinfo'></span><span id='topic+getpte'></span><span id='topic+exportlibpaths'></span><span id='topic+distribsplit'></span><span id='topic+distribcat'></span><span id='topic+distribagg'></span><span id='topic+distribrange'></span><span id='topic+distribcounts'></span><span id='topic+distribgetrows'></span><span id='topic+distribmeans'></span><span id='topic+dwhich.min'></span><span id='topic+dwhich.max'></span><span id='topic+docmd'></span><span id='topic+doclscmd'></span><span id='topic+distribisdt'></span><span id='topic+geteltis'></span><span id='topic+ipstrcat'></span>

<h3>Description</h3>

<p>Miscellaneous code snippets for use with the <span class="pkg">parallel</span> package,
including &ldquo;Snowdoop.&rdquo;</p>


<h3>Usage</h3>

<pre><code class='language-R'>formrowchunks(cls,m,mchunkname,scramble=FALSE) 
matrixtolist(rc,m) 
addlists(lst1,lst2,add)
setclsinfo(cls)
getpte()
exportlibpaths(cls)
distribsplit(cls,dfname,scramble=FALSE)
distribcat(cls,dfname) 
distribagg(cls,ynames,xnames,dataname,FUN,FUNdim=1,FUN1=FUN) 
distribrange(cls,vec,na.rm=FALSE) 
distribcounts(cls,xnames,dataname)
distribmeans(cls,ynames,xnames,dataname,saveni=FALSE)
dwhich.min(cls,vecname)
dwhich.max(cls,vecname)
distribgetrows(cls,cmd)
distribisdt(cls,dataname) 
docmd(toexec) 
doclscmd(cls,toexec) 
geteltis(lst,i)
ipstrcat(str1 = stop("str1 not supplied"), ..., outersep = "", innersep = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_cls">cls</code></td>
<td>
<p>A cluster for the <span class="pkg">parallel</span> package.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_scramble">scramble</code></td>
<td>
<p>If TRUE, randomize the row order in the resulting data
frame.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_rc">rc</code></td>
<td>
<p>Set to 1 for rows, other for columns.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_m">m</code></td>
<td>
<p>A matrix or data frame.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_mchunkname">mchunkname</code></td>
<td>
<p>Quoted name to be given to the created chunks.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_lst1">lst1</code></td>
<td>
<p>An R list.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_lst2">lst2</code></td>
<td>
<p>An R list.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_add">add</code></td>
<td>
<p>&ldquo;Addition&rdquo; function, which could be summation,
concatenation and so on.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_dfname">dfname</code></td>
<td>
<p>Quoted name of a data frame, either centralized or
distributed.</p>
</td></tr> 
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_ynames">ynames</code></td>
<td>
<p>Vector of quoted names of variables on which <code>FUN</code> 
is to be applied.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_vecname">vecname</code></td>
<td>
<p>Quoted name of a vector.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_...">...</code></td>
<td>
<p>One of more vectors of character strings, where the vectors
are typically of length 1.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_xnames">xnames</code></td>
<td>
<p>Vector of quoted names of variables that define the
grouping.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_dataname">dataname</code></td>
<td>
<p>Quoted name of a distributed data frame or data.table.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_saveni">saveni</code></td>
<td>
<p>If TRUE, save the chunk sizes.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_fun">FUN</code></td>
<td>
<p>Quoted name of a single-argument function to be used in
aggregating within cluster nodes.  If <code>dataname</code> is the name
of a data.table, <code>FUN</code> must be a vector of function names, of
length equal to that of <code>ynames</code>.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_fundim">FUNdim</code></td>
<td>
<p>Number of elements in the return value of <code>FUN</code>.
Must be 1 for data.tables.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_fun1">FUN1</code></td>
<td>
<p>Quoted name of function to be used in
aggregation between cluster nodes.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_vec">vec</code></td>
<td>
<p>Quoted expression that evaluates to a vector.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove NA values.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_cmd">cmd</code></td>
<td>
<p>An R command.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_toexec">toexec</code></td>
<td>
<p>Quoted string containing command to be executed.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_lst">lst</code></td>
<td>
<p>An R list of vectors.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_i">i</code></td>
<td>
<p>A column index</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_str1">str1</code></td>
<td>
<p>A character string.</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_outersep">outersep</code></td>
<td>
<p>Separator, e.g. a comma, between strings specified in
...</p>
</td></tr>
<tr><td><code id="formrowchunks+2B2Caddlists+2B2Cmatrixtolist+2B2Csetclsinfo+2B2Cgetpte+2B2Cdistribsplit+2B2Cdistribcat+2B2Cdistribagg+2B2Cdistribrange+2B2Cdistribcounts+2B2Cdistribgetrows+2B2Cdocmd+2B2Cdoclscmd+2B2Cgeteltis+2B2Cdistribmeans+2B2Cdistribisdt+2B2Cipstrcat+2B2Cdwhich.min+2B2Cdwhich.max_+3A_innersep">innersep</code></td>
<td>
<p>Separator, e.g. a comma, within string vectors specified in
...</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>setclsinfo</code> function does initialization needed for
use of the tools in the package.
</p>
<p>The function <code>formrowchunks</code> forms chunks of rows of
<code>m</code>, corresponding to the number of worker nodes
in the cluster <code>m</code>.  For any given worker, the code places its
chunk in <code>mchunk</code> in the global space of the worker.
</p>
<p>A call to <code>matrixtolist</code> extracts the rows or columns of a matrix
or data frame and forms an R list from them.
</p>
<p>The function <code>addlists</code> does the following:  Say we have two lists,
with numeric values.  We wish to form a new list, with all the keys
(names) from the two input lists appearing in the new list.  In the case
of a key in common to the two lists, the value in the new list will be
the sum of the two individual values for that key.  (Here &ldquo;sum&rdquo; means
the result of applying <code>add</code>.) For a key appearing in one list and
not the other, the value in the new list will be the value in the input
list.  
</p>
<p>The function <code>exportlibpaths</code>, invoked from the manager, exports
the manager's R search path to the workers.
</p>
<p>The function <code>distribsplit</code> splits a data frame <code>dfname</code> into
approximately  equal-sized chunks of rows, placing the chunks on the
cluster nodes, as global variables of the same name. The opposite action
is taken by <code>distribcat</code>, coalsecing variables of the given name in
the cluster nodes into one grand data frame as the calling (i.e.
manager) node.
</p>
<p>The package's <code>distribagg</code> function is a distributed (and somewhat
restricted) form of <code>aggregate</code>.  The latter is called to each
distributed chunk with the function <code>FUN</code>.  The manager collects
the results and calls <code>FUN1</code>.
</p>
<p>The special cases of aggregating counts and means is handled by the
wrappers <code>distribcounts</code> and <code>distribmeans</code>.  In each case,
cells are defined by <code>xnames</code>, and aggregation done first within
workers and then across workers. 
</p>
<p>The <code>distribrange</code> function is a distributed form of <code>range</code>.
</p>
<p>The <code>dwhich.min</code> and <code>dwhich.max</code> functions are distributed
analogs of R's <code>which.min</code> and <code>which.max</code>.
</p>
<p>The <code>distribgetrows</code> function is useful in a variety of situations.
It can be used, for instance, as a distributed form of <code>select</code>.
In the latter case, the specified rows will be selected at each cluster
node, then <code>rbind</code>-ed together at the caller.
</p>
<p>The <code>docmd</code> function executes the quoted command, useful for
building up complex command for remote execution.  The <code>doclscmd</code>
function does that directly.
</p>
<p>An R <code>formula</code> will be constructed from the arguments <code>ynames</code>
and <code>xnames</code>, with the latter put on the left side of the <code>~</code>
sign, with <code>cbind</code> for combining, and the latter put on the right
side, with <code>+</code> signs as delimiters.
</p>
<p>The <code>geteltis</code> function extracts from an R list of vectors element
<code>i</code> from each.
</p>


<h3>Value</h3>

<p>In the case of <code>addlists</code>, the return value is the new list.
</p>
<p>The <code>distribcat</code> function returns the concatenated data frame;
<code>distribgetrows</code> works similarly.
</p>
<p>The <code>distribagg</code> function returns a data frame, the same as would a
call to <code>aggregate</code>, though possibly in different row order;
<code>distribcounts</code> works similarly.
</p>
<p>The <code>dwhich.min</code> and <code>dwhich.max</code> functions each return a
two-tuple, consisting of the node number and row number which node at
which the min or max occurs.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'># examples of addlists()
l1 &lt;- list(a=2, b=5, c=1)
l2 &lt;- list(a=8, c=12, d=28)
addlists(l1,l2,sum)  # list with a=10, b=5, c=13, d=28
z1 &lt;- list(x = c(5,12,13), y = c(3,4,5))
z2 &lt;- list(y = c(8,88))
addlists(z1,z2,c)  # list with x=(5,12,13), y=(3,4,5,8,88)

# need 'parallel' cluster for the remaining examples
cls &lt;- makeCluster(2)
setclsinfo(cls)

# check it
clusterEvalQ(cls,partoolsenv$myid)  # returns 1, 2
clusterEvalQ(cls,partoolsenv$ncls)  # returns 2, 2

# formrowchunks example; see up a matrix to be distributed first
m &lt;- rbind(1:2,3:4,5:6)
# apply the function
formrowchunks(cls,m,"mc")
# check results
clusterEvalQ(cls,mc)  # list of a 1x2 and a 2x2 matrix

matrixtolist(1,m)  # 3-component list, first is (1,2)

# test of of distribagg(): 
# form and distribute test data
x &lt;- sample(1:3,10,replace=TRUE)
y &lt;- sample(0:1,10,replace=TRUE)
u &lt;- runif(10)
v &lt;- runif(10)
d &lt;- data.frame(x,y,u,v)
distribsplit(cls,"d")
# check that it's there at the cluster nodes, in distributed form
clusterEvalQ(cls,d) 
d
# try the aggregation function
distribagg(cls,c("u","v"), c("x","y"),"d","max")
# check result
aggregate(cbind(u,v) ~ x+y,d,max)

# real data
mtc &lt;- mtcars
distribsplit(cls,"mtc")

distribagg(cls,c("mpg","disp","hp"),c("cyl","gear"),"mtc","max")
# check
aggregate(cbind(mpg,disp,hp) ~ cyl+gear,data=mtcars,FUN=max)

distribcounts(cls,c("cyl","gear"),"mtc")
# check
table(mtc$cyl,mtc$gear)

# find mean mpg, hp for each cyl/gear combination
distribmeans(cls,c('mpg','hp'),c('cyl','gear'),'mtc')

# extract and collect all the mtc rows in which the number of cylinders is 8
distribgetrows(cls,'mtc[mtc$cyl == 8,]')
# check
mtc[mtc$cyl == 8,]

# same for data.tables
mtc &lt;- as.data.table(mtc)
setkey(mtc,cyl)
distribsplit(cls,'mtc')
distribcounts(cls,c("cyl","gear"),"mtc")
distribmeans(cls,c('mpg','hp'),c('cyl','gear'),'mtc')

dwhich.min(cls,'mtc$mpg')  # smallest is at node 1, row 15
dwhich.max(cls,'mtc$mpg')  # largest is at node 2, row 4

stopCluster(cls)

</code></pre>

<hr>
<h2 id='newadult'>
UCI adult income data set, adapted
</h2><span id='topic+newadult'></span>

<h3>Description</h3>

<p>This data set is adapted from
the Adult data from the UCI Machine Learning Repository,
which was in turn adapted from Census data on adult incomes and other 
demographic variables.  The UCI data is used here with permission 
from Ronny Kohavi.
</p>
<p>The variables are:
</p>

<ul>
<li> <p><code>gt50</code>, which converts the original <code>&gt;50K</code> variable
to an indicator variable; 1 for income greater than $50,000, else 0
</p>
</li>
<li> <p><code>edu</code>, which converts a set of education levels to
approximate number of years of schooling
</p>
</li>
<li> <p><code>age</code>
</p>
</li>
<li> <p><code>gender</code>, 1 for male, 0 for female
</p>
</li>
<li> <p><code>mar</code>, 1 for married, 0 for single
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(newadult); newadult
</code></pre>

<hr>
<h2 id='parpdist'>Partools Apps</h2><span id='topic+parpdist'></span>

<h3>Description</h3>

<p>General parallel applications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parpdist(x,y,cls)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parpdist_+3A_cls">cls</code></td>
<td>
<p>A cluster run under the <span class="pkg">parallel</span> package.</p>
</td></tr>
<tr><td><code id="parpdist_+3A_x">x</code></td>
<td>
<p>A data matrix</p>
</td></tr> 
<tr><td><code id="parpdist_+3A_y">y</code></td>
<td>
<p>A data matrix</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Parallel wrapper for <code>pdist</code> from package of the same
name. Finds all the distances from rows in <code>x</code> to rows in
<code>y</code>.</p>


<h3>Value</h3>

<p>Object of type <code>"pdist"</code>.</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set up 'parallel' cluster
cls &lt;- makeCluster(2)
setclsinfo(cls)

x &lt;- matrix(runif(20),nrow=5)
y &lt;- matrix(runif(32),nrow=8)
# 2 calls should have identical resultsW
pdist(x,y,cls)@dist
parpdist(x,y,cls)@dist

stopCluster(cls)

</code></pre>

<hr>
<h2 id='prgeng'>
Silicon Valley programmers and engineers
</h2><span id='topic+prgeng'></span>

<h3>Description</h3>

<p>This data set is adapted from the 2000 Census (5% sample, person
records).  It is restricted to programmers and engineers in the 
Silicon Valley area.
</p>
<p>The variable codes, e.g. occupational codes, are available from the Census
Bureau, at
<a href="http://www.census.gov/prod/cen2000/doc/pums.pdf">http://www.census.gov/prod/cen2000/doc/pums.pdf</a>.
(Short code lists are given in the record layout, but longer ones are in
the appendix Code Lists.)
</p>
<p>The variables are:
</p>

<ul>
<li><p><code>age</code>, with a U(0,1) variate added for jitter
</p>
</li>
<li><p><code>cit</code>, citizenship; 1-4 code various categories of
citizens; 5 means noncitizen (including permanent residents
</p>
</li>
<li><p><code>educ</code>: 01-09 code no college; 10-12 means some college;
13 is a bachelor's degree, 14 a master's, 15 a professiona deal and
16 is a doctorate
</p>
</li>
<li><p><code>occ</code>, occupation
</p>
</li>
<li><p><code>birth</code>, place of birth
</p>
</li>
<li><p><code>wageinc</code>, wage income
</p>
</li>
<li><p><code>wkswrkd</code>, number of weeks worked
</p>
</li>
<li><p><code>yrentry</code>, year of entry to the U.S. (0 for natives)
</p>
</li>
<li><p><code>powpuma</code>, location of work 
</p>
</li>
<li><p><code>gender</code>, 1 for male, 2 for female
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(prgeng); prgeng
</code></pre>

<hr>
<h2 id='snowdoop+2Cfilechunkname+2C+20etc...'>
Snowdoop.
</h2><span id='topic+snowdoop'></span><span id='topic+filechunkname'></span><span id='topic+filesort'></span><span id='topic+filesplit'></span><span id='topic+filesplitrand'></span><span id='topic+fileshuffle'></span><span id='topic+filecat'></span><span id='topic+readnscramble'></span><span id='topic+linecount'></span><span id='topic+getnumdigs'></span><span id='topic+filesave'></span><span id='topic+fileread'></span><span id='topic+fileagg'></span><span id='topic+dfileagg'></span><span id='topic+filegetrows'></span><span id='topic+dfilegetrows'></span>

<h3>Description</h3>

<p>&ldquo;Snowdoop&rdquo;: Utilities for distributed file storage, access and 
related operations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filechunkname(basenm,ndigs,nodenum=NULL)
filesort(cls,infilenm,colnum,outdfnm,infiledst=FALSE,
   ndigs=0,nsamp=1000,header=FALSE,sep="",usefread=FALSE)
filesplit(nch,basenm,header=FALSE,seqnums=FALSE)
filesplitrand(cls,fname,newbasename,ndigs,header=FALSE,sep)
fileshuffle(inbasename, nout, outbasename, header = FALSE)
linecount(infile,header=FALSE,chunksize=100000)
filecat(cls, basenm, header = FALSE)  
readnscramble(cls,basenm,header=FALSE,sep= " ")
filesave(cls,dname,newbasename,ndigs,sep)
fileread(cls,fname,dname,ndigs,header=FALSE,sep=" ",usefread=FALSE)
getnumdigs(nch)
fileagg(fnames,ynames,xnames,header=FALSE,sep= " ",FUN,FUN1=FUN) 
dfileagg(cls,fnames,ynames,xnames,header=FALSE,sep=" ",FUN,FUN1=FUN) 
filegetrows(fnames,tmpdataexpr,header=FALSE,sep=" ") 
dfilegetrows(cls,fnames,tmpdataexpr,header=FALSE,sep=" ") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_cls">cls</code></td>
<td>
<p>A cluster for the <span class="pkg">parallel</span> package.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_nch">nch</code></td>
<td>
<p>Number of chunks for the file split.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_basenm">basenm</code></td>
<td>
<p>A chunked file name, minus suffix.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_infile">infile</code></td>
<td>
<p>Name of a nonchunked file.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_ndigs">ndigs</code></td>
<td>
<p>Number of digits in the chunked file name suffix.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_nodenum">nodenum</code></td>
<td>
<p>If non-NULL, get the name of the file chunk of cluster node
<code>nodenum</code>; otherwise, get the name for the chunk associated
with this node.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_infilenm">infilenm</code></td>
<td>
<p>Name of input file (without suffix, if distributed).</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_outdfnm">outdfnm</code></td>
<td>
<p>Name of output file (without suffix).</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_infiledst">infiledst</code></td>
<td>
<p>If TRUE, infilenm is distributed.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_colnum">colnum</code></td>
<td>
<p>Column number on which the sort will be done.  It is
assumed that this data column is free of NAs.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_usefread">usefread</code></td>
<td>
<p>If true, use <code>fread</code> instead of <code>read.table</code>;
generally much faster; requires <code>data.table</code> package.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_nsamp">nsamp</code></td>
<td>
<p>Number of records to sample in each file chunk to
determine bins for the bucket sort.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_header">header</code></td>
<td>
<p>TRUE if the file chunks have headers.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_seqnums">seqnums</code></td>
<td>
<p>TRUE if the file chunks will have sequence numbers.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_sep">sep</code></td>
<td>
<p>Field delimiter used in <code>read.table</code>.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_chunksize">chunksize</code></td>
<td>
<p>Number of lines to read at a time, for efficient I/O.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_dname">dname</code></td>
<td>
<p>Quoted name of a distributed data frame or matrix.  For
<code>filesave</code>, the object must have column names.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_fname">fname</code></td>
<td>
<p>Quoted name of a distributed file.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_fnames">fnames</code></td>
<td>
<p>Character vector of file names.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_newbasename">newbasename</code></td>
<td>
<p>Quoted name of the prefix of a distributed file,
e.g. <code>xyz</code> for a distributed file <code>xyz.01</code>, <code>xyz.02</code>
etc.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_ynames">ynames</code></td>
<td>
<p>Vector of quoted names of variables on which <code>FUN</code>
is to be applied.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_xnames">xnames</code></td>
<td>
<p>Vector of quoted names of variables to be used for cell
definition.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_tmpdataexpr">tmpdataexpr</code></td>
<td>
<p>Expression involving a data frame
<code>tmpdataexpr</code>.  See below.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_fun">FUN</code></td>
<td>
<p>First-level aggregation function.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_fun1">FUN1</code></td>
<td>
<p>Second-level aggregation function.</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_inbasename">inbasename</code></td>
<td>
<p>basename of the input files, e.g. x for x.1, x.2, ...</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_outbasename">outbasename</code></td>
<td>
<p>basename of the output files</p>
</td></tr>
<tr><td><code id="snowdoop+2B2Cfilechunkname+2B2C+2B20etc..._+3A_nout">nout</code></td>
<td>
<p>number of output files</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use <code>filesplit</code> to convert a single file into distributed one, with
<code>nch</code> chunks.  The file header, if present, will be retained in the
chunks. If <code>seqnums</code> is TRUE, each line in a chunk will be preceded
by the line number it had in the original file.  
</p>
<p>The reverse operation to <code>filesplit</code> is performed by
<code>filecat</code>, which converts a distributed file into a single one.
</p>
<p>The <code>fileagg</code> function does an out-of-memory, multifile version of
<code>aggregate</code>, reading the specified files one at a time, and
returning a grand aggregation.  The function <code>dfileagg</code> partitions
the specified group of files to a <code>partools</code> cluster, has each
call <code>fileagg</code>, and again aggregates the results.
</p>
<p>The function <code>filegetrows</code> reads in the files in <code>fnames</code>, one
at a time, naming the resulting in-memory data <code>tmpdata</code> each time.
(It is assumed that the data fit in memory.)  The function applies the
user command <code>tmpdataexpr</code> to <code>tmpdata</code>, producing a subset of
<code>tmpdata</code>.  All of these subsets are combined using <code>rbind</code>,
yielding the return value.  The paired function <code>dfilegetrows</code> is a
distributed wrapper for <code>filegetrows</code>, just as <code>dfileagg</code> is
for <code>fileagg</code>.
</p>
<p>Use <code>filesort</code> to do a file sort, with the input file being either
distributed or ordinary, placing the result as a distributed data
frame/matrix in the memories of the cluster nodes.  The first
<code>nsamp</code> records are read from the file, and are used to form one
quantile range for each cluster node.  Each node then reads the input
file, retaining the records in its assigned range, and sorts them.  This
results in the input file being sorted, in memory, in a distributed
manner across nodes, under the specifid name.  At present, this
utility is not very efficient.
</p>
<p>Operations such as <code>ca</code> need i.i.d. data. If the original file
storage was ordered on some variable, one needs to randomize the data
first.  There are several options:
</p>

<ul>
<li> <p><code>readnscramble</code>:  This produces a distributed data 
frame/matrix under the name <code>basenm</code>.  Note that a record in chunk
<code>i</code> of the distributed file will likely end up in chunk <code>j</code> 
in the distributed data frame/matrix, with <code>j</code> different from
<code>i</code>.  
</p>
</li>
<li> <p><code>filesplitrand</code>: Use this you wish to directly produce a
randomized distributed file from a monolithic one.  It will read
the file into memory, chunk it at the cluster nodes, each of which
will save its chunk to disk.
</p>
</li>
<li> <p><code>fileshuffle</code>: If you need to avoid reading big files 
into memory, use this.  You must run <code>filesplit</code> first, and
then run <code>fileshuffle</code> several times for a good shuffle.
</p>
<p>Note that this function is also useful if your cluster size
changes.  A distributed file of m chunks can now be converted to
one with n chunks, either more or fewer than before.
</p>
</li></ul>

<p>If you wish to use this same randomized data in a future session, you
can save it as a distributed file by calling <code>filesave</code>. Of course,
this function is also useful if one wishes to save a distributed data
frame or matrix that was created computationally rather than from read
from a distributed file.  To go the other direction, i.e. read a
distributed file, use <code>fileread</code>.
</p>
<p>Some of the functions here are useful mainly as intermediate operations
for the others:
</p>

<ul>
<li><p> The function <code>filechunkname</code> returns the name of the file
chunk for the calling cluster node.
</p>
</li>
<li><p> The <code>linecount</code> function returns the number of lines in a
text file.
</p>
</li>
<li><p> A call to <code>getnumdigs</code> returns the number of digits in a
distributed file name suffix.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cls &lt;- makeCluster(2)
setclsinfo(cls)

# example of filesplit()
# make test input file
m &lt;- rbind(1:2,3:4,5:6) 
write.table(m,"m",row.names=FALSE,col.names=FALSE) 
# apply the function
filesplit(2,"m",seqnums=TRUE)
# file m.1 and m.2 created, with contents c(1,1,2) and
# rbind(c(2,3,4),c(3,5,6)), respectively
# check it
read.table("m.1",header=FALSE,row.names=1)
read.table("m.2",header=FALSE,row.names=1)
m

# example of filecat(); assumes filesplit() example above already done
# delete file m so we can make sure we are re-creating it
unlink("m")
filecat(cls,"m")
# check that file m is back
read.table("m",row.names=1)

# example of filesave(), fileread()
# make test distributed data frame
clusterEvalQ(cls,x &lt;- data.frame(u = runif(5),v = runif(5)))
# apply filesave()
filesave(cls,'x','xfile',1,' ')
# check it
fileread(cls,'xfile','xx',1,header=TRUE,sep=' ')
clusterEvalQ(cls,xx)
clusterEvalQ(cls,x)


# example of filesort()
# make test distributed input file
m1 &lt;- matrix(c(5,12,13,3,4,5,8,8,8,1,2,3,6,5,4),byrow=TRUE,ncol=3)
m2 &lt;- matrix(c(0,22,88,44,5,5,2,6,10,7,7,7),byrow=TRUE,ncol=3)
write.table(m1,"m.1",row.names=FALSE)
write.table(m2,"m.2",row.names=FALSE)
# sort on column 2 and check result
filesort(cls,"m",2,"msort",infiledst=TRUE,ndigs=1,nsamp=3,header=TRUE)
clusterEvalQ(cls,msort)  # data should be sorted on V2
# check by comparing to input
m1
m2
m &lt;- rbind(m1,m2)
write.table(m,"m",row.names=FALSE)
clusterEvalQ(cls,rm(msort))
filesort(cls,"m",2,"msort",infiledst=FALSE,nsamp=3,header=TRUE)
clusterEvalQ(cls,msort)  # data should be sorted on V2

# example of readnscramble()
co2 &lt;- head(CO2,25) 
write.table(co2,"co2",row.names=FALSE)  # creates file 'co2'
filesplit(2,"co2",header=TRUE)  # creates files 'co2.1', 'co2.2'
readnscramble(cls,"co2",header=TRUE)  # now have distrib. d.f.
# save the scrambled version to disk
filesave(cls,'co2','co2s',1,sep=',')

# example of fileshuffle()
# make test file, 'test'
cat('a','bc','def','i','j','k',file='test',sep='\n')
filesplit(2,'test')  # creates files 'test.1','test.2'
fileshuffle('test',2,'testa')  # creates shuffled files 'testa.1','testa.2'

# example of filechunkname()
clusterEvalQ(cls,filechunkname("x",3))  # returns "x.001", "x.002"

# example of getnumdigs()
getnumdigs(156)  # should be 3

# examples of filesave() and fileread()
mtc &lt;- mtcars
distribsplit(cls,"mtc")
# save distributed data frame to distributed file
filesave(cls,'mtc','ctm',1,',') 
# read it back in to a new distributed data frame
fileread(cls,'ctm','ctmnew',1,header=TRUE,sep=',') 
# check it
clusterEvalQ(cls,ctmnew) 
# try dfileagg() on it (not same as distribagg())
dfileagg(cls,c('ctm.1','ctm.2'),c("mpg","disp","hp"),c("cyl","gear"),header=TRUE,sep=",","max")
# check
aggregate(cbind(mpg,disp,hp) ~ cyl+gear,data=mtcars,FUN=max)
# extract the records with 4 cylinders and 4 gears (again, different
# from distribgetrows())
cmd &lt;- 'tmpdata[tmpdata$cyl == 4 &amp; tmpdata$gear == 4,]'
dfilegetrows(cls,c('ctm.1','ctm.2'),cmd,header=TRUE,sep=',') 
# check
mtc[mtc$cyl == 4 &amp; mtc$gear == 4,]

stopCluster(cls)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
