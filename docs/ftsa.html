<!DOCTYPE html><html lang="en"><head><title>Help for package ftsa</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ftsa}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ftsa-package'>
<p>Functional Time Series Analysis</p></a></li>
<li><a href='#all_hmd_female_data'>
<p>The US female log-mortality rate from 1959-2020 and 3 states (New York, California, Illinois).</p></a></li>
<li><a href='#all_hmd_male_data'>
<p>The US male log-mortality rate from 1959-2020 and 3 states (New York, California, Illinois).</p></a></li>
<li><a href='#centre'>
<p>Mean function, variance function, median function, trim mean function of functional data</p></a></li>
<li><a href='#CoDa_BayesNW'>
<p>Compositional data analytic approach and nonparametric function-on-function regression for forecasting density</p></a></li>
<li><a href='#CoDa_FPCA'>
<p>Compositional data analytic approach and functional principal component analysis for forecasting density</p></a></li>
<li><a href='#diff.fts'><p>Differences of a functional time series</p></a></li>
<li><a href='#DJI_return'>
<p>Dow Jones Industrial Average (DJIA)</p></a></li>
<li><a href='#dmfpca'>
<p>Dynamic multilevel functional principal component analysis</p></a></li>
<li><a href='#dynamic_FLR'>
<p>Dynamic updates via functional linear regression</p></a></li>
<li><a href='#dynupdate'><p>Dynamic updates via BM, OLS, RR and PLS methods</p></a></li>
<li><a href='#ER_GR'>
<p>Selection of the number of principal components</p></a></li>
<li><a href='#error'><p>Forecast error measure</p></a></li>
<li><a href='#extract'><p>Extract variables or observations</p></a></li>
<li><a href='#facf'>
<p>Functional autocorrelation function</p></a></li>
<li><a href='#farforecast'>
<p>Functional data forecasting through functional principal component autoregression</p></a></li>
<li><a href='#fbootstrap'><p>Bootstrap independent and identically distributed functional data</p></a></li>
<li><a href='#forecast.ftsm'><p>Forecast functional time series</p></a></li>
<li><a href='#forecast.hdfpca'>
<p>Forecasting via a high-dimensional functional principal component regression</p></a></li>
<li><a href='#forecastfplsr'><p>Forecast functional time series</p></a></li>
<li><a href='#fplsr'><p>Functional partial least squares regression</p></a></li>
<li><a href='#ftsm'><p>Fit functional time series model</p></a></li>
<li><a href='#ftsmiterativeforecasts'><p>Forecast functional time series</p></a></li>
<li><a href='#ftsmweightselect'>
<p>Selection of the weight parameter used in the weighted functional time series model.</p></a></li>
<li><a href='#GAEVforecast'>
<p>Fit a generalized additive extreme value model to the functional data with given basis numbers</p></a></li>
<li><a href='#hd_data'>
<p>Simulated high-dimensional functional time series</p></a></li>
<li><a href='#hdfpca'>
<p>High-dimensional functional principal component analysis</p></a></li>
<li><a href='#Horta_Ziegelmann_FPCA'>
<p>Dynamic functional principal component analysis for density forecasting</p></a></li>
<li><a href='#is.fts'><p>Test for functional time series</p></a></li>
<li><a href='#isfe.fts'><p>Integrated Squared Forecast Error for models of various orders</p></a></li>
<li><a href='#long_run_covariance_estimation'>
<p>Estimating long-run covariance function for a functional time series</p></a></li>
<li><a href='#LQDT_FPCA'>
<p>Log quantile density transform</p></a></li>
<li><a href='#MAF_multivariate'>
<p>Maximum autocorrelation factors</p></a></li>
<li><a href='#mean.fts'><p>Mean functions for functional time series</p></a></li>
<li><a href='#median.fts'><p>Median functions for functional time series</p></a></li>
<li><a href='#MFDM'>
<p>Multilevel functional data method</p></a></li>
<li><a href='#MFPCA'>
<p>Multilevel functional principal component analysis for clustering</p></a></li>
<li><a href='#mftsc'>
<p>Multiple funtional time series clustering</p></a></li>
<li><a href='#pcscorebootstrapdata'>
<p>Bootstrap independent and identically distributed functional data or functional time series</p></a></li>
<li><a href='#plot.fm'><p>Plot fitted model components for a functional model</p></a></li>
<li><a href='#plot.fmres'><p>Plot residuals from a fitted functional model.</p></a></li>
<li><a href='#plot.ftsf'><p>Plot fitted model components for a functional time series model</p></a></li>
<li><a href='#plot.ftsm'><p>Plot fitted model components for a functional time series model</p></a></li>
<li><a href='#plotfplsr'>
<p>Plot fitted model components for a functional time series model</p></a></li>
<li><a href='#pm_10_GR'>
<p>Particulate Matter Concentrations (pm10)</p></a></li>
<li><a href='#quantile'><p>Quantile</p></a></li>
<li><a href='#quantile.fts'><p>Quantile functions for functional time series</p></a></li>
<li><a href='#residuals.fm'><p>Compute residuals from a functional model</p></a></li>
<li><a href='#sd'><p>Standard deviation</p></a></li>
<li><a href='#sd.fts'><p>Standard deviation functions for functional time series</p></a></li>
<li><a href='#sim_ex_cluster'>
<p>Simulated multiple sets of functional time series</p></a></li>
<li><a href='#skew_t_fun'>
<p>Skewed t distribution</p></a></li>
<li><a href='#stop_time_detect'>
<p>Detection of the optimal stopping time in a curve time series</p></a></li>
<li><a href='#stop_time_sim_data'>
<p>Simulated functional time series from a functional autoregression of order one</p></a></li>
<li><a href='#summary.fm'><p>Summary for functional time series model</p></a></li>
<li><a href='#T_stationary'>
<p>Testing stationarity of functional time series</p></a></li>
<li><a href='#var'><p>Variance</p></a></li>
<li><a href='#var.fts'><p>Variance functions for functional time series</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functional Time Series Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>6.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-02-22</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), forecast, rainbow, sde</td>
</tr>
<tr>
<td>Suggests:</td>
<td>fds, R2jags, meboot</td>
</tr>
<tr>
<td>Imports:</td>
<td>colorspace, MASS, pcaPP, fda, pdfCluster, ecp, strucchange,
e1071, psych, fGarch, KernSmooth, vars, boot, fdapace,
LaplacesDemon, evgam, ROOPSD, glue, methods</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Han Lin Shang &lt;hanlin.shang@mq.edu.au&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for visualizing, modeling, forecasting and hypothesis testing of functional time series.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-22 12:00:48 UTC; hanlinshang</td>
</tr>
<tr>
<td>Author:</td>
<td>Rob Hyndman <a href="https://orcid.org/0000-0002-2140-5352"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Han Lin Shang <a href="https://orcid.org/0000-0003-1769-6430"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-22 13:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ftsa-package'>
Functional Time Series Analysis
</h2><span id='topic+ftsa-package'></span><span id='topic+ftsa'></span>

<h3>Description</h3>

<p>This package presents descriptive statistics of functional data; implements principal component regression and partial least squares regression to provide point and distributional forecasts for functional data; utilizes functional linear regression, ordinary least squares, penalized least squares, ridge regression, and moving block approaches to dynamically update point and distributional forecasts when partial data points in the most recent curve are observed; performs stationarity test for a functional time series;
estimates a long-run covariance function by kernel sandwich estimator.
</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman and Han Lin Shang 
</p>
<p>Maintainer: Han Lin Shang &lt;hanlin.shang@anu.edu.au&gt;
</p>


<h3>References</h3>

<p>###########################
# References in Statistics
###########################
</p>
<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series (with discussion)&quot;, <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>
<p>R. J. Hyndman and H. L. Shang (2010) &quot;Rainbow plots, bagplots, and boxplots for functional data&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>19</b>(1), 29-45.
</p>
<p>H. L. Shang and R. J. Hyndman (2011) &quot;Nonparametric time series forecasting with dynamic updating&quot;, <em>Mathematics and Computers in Simulation</em>, <b>81</b>(7), 1310-1324.
</p>
<p>H. L. Shang (2011) &quot;rainbow: an R package for visualizing functional time series, <em>The R Journal</em>, <b>3</b>(2), 54-59.
</p>
<p>H. L. Shang (2013) &quot;Functional time series approach for forecasting very short-term electricity demand&quot;, <em>Journal of Applied Statistics</em>, <b>40</b>(1), 152-168.
</p>
<p>H. L. Shang (2013) &quot;ftsa: An R package for analyzing functional time series&quot;, <em>The R Journal</em>, <b>5</b>(1), 64-72.
</p>
<p>H. L. Shang (2014) &quot;A survey of functional principal component analysis&quot;, <em>Advances in Statistical Analysis</em>, <b>98</b>(2), 121-142.
</p>
<p>H. L. Shang (2014) &quot;Bayesian bandwidth estimation for a functional nonparametric regression model with mixed types of regressors and unknown error density&quot;, <em>Journal of Nonparametric Statistics</em>, <b>26</b>(3), 599-615.
</p>
<p>H. L. Shang (2014) &quot;Bayesian bandwidth estimation for a semi-functional partial linear regression model with unknown error density&quot;, <em>Computational Statistics</em>, <b>29</b>(3-4), 829-848.
</p>
<p>H. L. Shang (2015) &quot;Resampling techniques for estimating the distribution of descriptive statistics of functional data&quot;, <em>Communications in Statistics - Simulation and Computation</em>, <b>44</b>(3), 614- 635.
</p>
<p>H. L. Shang (2016) &quot;Mortality and life expectancy forecasting for a group of populations in developed countries: A robust multilevel functional data method&quot;, in C. Agostinelli, A. Basu, P. Filzmoser, D. Mukherjee (ed.), Recent Advances in Robust Statistics: Theory and Applications, Springer, India, pp. 169-184.
</p>
<p>H. L. Shang (2016) &quot;Mortality and life expectancy forecasting for a group of populations in developed countries: A multilevel functional data method&quot;, <em>Annals of Applied Statistics</em>, <b>10</b>(3), 1639-1672. 
</p>
<p>H. L. Shang (2016) &quot;A Bayesian approach for determining the optimal semi-metric and bandwidth in scalar-on-function quantile regression with unknown error density and dependent functional data&quot;, <em>Journal of Multivariate Analysis</em>, <b>146</b>, 95-104.
</p>
<p>H. L. Shang (2017) &quot;Functional time series forecasting with dynamic updating: An application to intraday particulate matter concentration&quot;, <em>Econometrics and Statistics</em>, <b>1</b>, 184-200.
</p>
<p>H. L. Shang (2017) &quot;Forecasting Intraday S&amp;P 500 Index Returns: A Functional Time Series Approach&quot;, <em>Journal of Forecasting</em>, <b>36</b>(7), 741-755.
</p>
<p>H. L. Shang and R. J. Hyndman (2017) &quot;Grouped functional time series forecasting: An application to age-specific mortality rates&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>26</b>(2), 330-343.
</p>
<p>G. Rice and H. L. Shang (2017) &quot;A plug-in bandwidth selection procedure for long-run covariance estimation with stationary functional time series&quot;, <em>Journal of Time Series Analysis</em>, <b>38</b>(4), 591-609.
</p>
<p>P. Reiss, J. Goldsmith, H. L. Shang and R. T. Ogden (2017) &quot;Methods for scalar-on-function regression&quot;, <em>International Statistical Review</em>, <b>85</b>(2), 228-249.
</p>
<p>P. Kokoszka, G. Rice and H. L. Shang (2017) &quot;Inference for the autocovariance of a functional time series under conditional heteroscedasticity&quot;, <em>Journal of Multivariate Analysis</em>, <b>162</b>, 32-50.
</p>
<p>Y. Gao, H. L. Shang and Y. Yang (2017) &quot;High-dimensional functional time series forecasting&quot;, in G. Aneiros, E. Bongiorno, R. Cao and P. Vieu (ed.), Functional Statistics and Related Fields, Springer, Cham, pp. 131-136.
</p>
<p>Y. Gao and H. L. Shang (2017) &quot;Multivariate functional time series forecasting: An application to age-specific mortality rates&quot;, <em>Risks</em>, <b>5</b>(2), Article 21.
</p>
<p>H. L. Shang (2018) &quot;Visualizing rate of change: An application to age-specific fertility rates&quot;, <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, <b>182</b>(1), 249-262.
</p>
<p>H. L. Shang (2018) &quot;Bootstrap methods for stationary functional time series&quot;, <em>Statistics and Computing</em>, <b>28</b>(1), 1-10.
</p>
<p>Y. Gao, H. L. Shang and Y. Yang (2019) &quot;High-dimensional functional time series forecasting: An application to age-specific mortality rates&quot;, <em>Journal of Multivariate Analysis</em>, <b>170</b>, 232-243.
</p>
<p>D. Li, P. M. Robinson and H. L. Shang (2020) &quot;Long-range dependent curve time series&quot;, <em>Journal of the American Statistical Association: Theory and Methods</em>, <b>115</b>(530), 957-971.
</p>
<p>H. L. Shang (2020) &quot;A comparison of Hurst exponent estimators in long-range dependent curve time series&quot;, <em>Journal of Time Series Econometrics</em>, <b>12</b>(1).
</p>
<p>D. Li, P. M. Robinson and H. L. Shang (2021) &quot;Local Whittle estimation of long range dependence for functional time series&quot;, <em>Journal of Time Series Analysis</em>, <b>42</b>(5-6), 685-695.
</p>
<p>H. L. Shang and R. Xu (2021) &quot;Functional time series forecasting of extreme values&quot;, <em>Communications in Statistics: Case Studies, Data Analysis and Applications</em>, <b>7</b>(2), 182-199.
</p>
<p>U. Beyaztas, H. L. Shang and Z. Yaseen (2021) &quot;Development of functional autoregressive model based exogenous hydrometeorological variables for river flow prediction&quot;, <em>Journal of Hydrology</em>, <b>598</b>, 126380.
</p>
<p>U. Beyaztas and H. L. Shang (2022) &quot;Machine learning-based functional time series forecasting: Application to age-specific mortality rates&quot;, <em>Forecasting</em>, <b>4</b>(1), 394-408.
</p>
<p>Y. Yang, Y. Yang and H. L. Shang (2022) &quot;Feature extraction for functional time series: Theory and application to NIR spectroscopy data&quot;, <em>Journal of Multivariate Analysis</em>, <b>189</b>, 104863.
</p>
<p>A. E. Fernandez, R. Jimenez and H. L. Shang (2022) &quot;On projection methods for functional time series forecasting&quot;, <em>Journal of Multivariate Analysis</em>, <b>189</b>, 104890.
</p>
<p>H. L. Shang (2022) &quot;Not all long-memory estimators are born equal: A case of non-stationary curve time series&quot;, <em>The Canadian Journal of Statistics</em>, <b>50</b>(1), 357-380.
</p>
<p>X. Huang, H. L. Shang and D. Pitt (2022) &quot;Permutation entropy and its variants for measuring temporal dependence&quot;, <em>Australian and New Zealand Journal of Statistics</em>, <b>64</b>(4), 442-477.
</p>
<p>H. L. Shang, J. Cao and P. Sang (2022) &quot;Stopping time detection of wood panel compression: A functional time series approach&quot;, <em>Journal of the Royal Statistical Society: Series C</em>, <b>71</b>(5), 1205-1224.
</p>
<p>C. Tang, H. L. Shang and Y. Yang (2022) &quot;Clustering and forecasting multiple functional time series&quot;, <em>The Annals of Applied Statistics</em>, <b>16</b>(4), 2523-2553.
</p>
<p>J. Trinka, H. Haghbin, M. Maadooliat and H. L. Shang (2023) &quot;Functional time series forecasting: Functional singular spectrum analysis approaches&quot;, <em>Stat</em>, <b>12</b>(1), e621.
</p>
<p>D. Li, P. M. Robinson and H. L. Shang (2023) &quot;Nonstationary fractionally integrated functional time series&quot;, <em>Bernoulli</em>, <b>29</b>(2), 1505-1526.
</p>
<p>X. Huang and H. L. Shang (2023) &quot;Nonlinear autocorrelation function of functional time series&quot;, <em>Nonlinear Dynamics: An International Journal of Nonlinear Dynamics and Chaos in Engineering Systems</em>, <b>111</b>, 2537-2554.
</p>
<p>H. L. Shang (2023) &quot;Sieve bootstrapping memory parameter in long-range dependent stationary functional time series&quot;, <em>AStA Advances in Statistical Analysis</em>, <b>107</b>, 421-441.
</p>
<p>E. Paparoditis and H. L. Shang (2023) &quot;Bootstrap prediction bands for functional time series&quot;, <em>Journal of the American Statistical Association: Theory and Methods</em>, <b>118</b>(542), 972-986.
</p>
<p>Y. Gao, H. L. Shang and Y. Yang (2024) &quot;Factor-augmented smoothing model for functional data&quot;, <em>Statistica Sinica</em>, <b>34</b>(1), 1-26.
</p>
<p>#############################
# References in Population Studies
#############################
</p>
<p>H. L. Shang, H. Booth and R. J. Hyndman (2011) &quot;Point and interval forecasts of mortality rates and life expectancy: a comparison of ten principal component methods, <em>Demographic Research</em>, <b>25</b>(5), 173-214.
</p>
<p>H. L. Shang (2012) &quot;Point and interval forecasts of age-specific fertility rates: a comparison of functional principal component methods&quot;, <em>Journal of Population Research</em>, <b>29</b>(3), 249-267.
</p>
<p>H. L. Shang (2012) &quot;Point and interval forecasts of age-specific life expectancies: a model averaging&quot;, <em>Demographic Research</em>, <b>27</b>, 593-644.
</p>
<p>H. L. Shang, A. Wisniowski, J. Bijak, P. W. F. Smith and J. Raymer (2014) &quot;Bayesian functional models for population forecasting&quot;, in M. Marsili and G. Capacci (eds), Proceedings of the Sixth Eurostat/UNECE Work Session on Demographic Projections, Istituto nazionale di statistica, Rome, pp. 313-325.
</p>
<p>H. L. Shang (2015) &quot;Selection of the optimal Box-Cox transformation parameter for modelling and forecasting age-specific fertility&quot;, <em>Journal of Population Research</em>, <b>32</b>(1), 69-79.
</p>
<p>H. L. Shang (2015) &quot;Forecast accuracy comparison of age-specific mortality and life expectancy: Statistical tests of the results&quot;, <em>Population Studies</em>, 69(3), 317-335.
</p>
<p>H. L. Shang, P. W. F. Smith, J. Bijak, A. Wisniowski (2016) &quot;A multilevel functional data method for forecasting population, with an application to the United Kingdom, <em>International Journal of Forecasting</em>, 32(3), 629-649.
</p>
<p>H. L. Shang (2017) &quot;Reconciling forecasts of infant mortality rates at national and sub-national levels: Grouped time-series method&quot;, <em>Population Research and Policy Review</em>, 36(1), 55-84.
</p>
<p>R. J. Hyndman, Y. Zeng and H. L. Shang (2021) &quot;Forecasting the old-age dependency ratio to determine the best pension age&quot;, <em>Australian and New Zealand Journal of Statistics</em>, <b>63</b>(2), 241-256.
</p>
<p>Y. Yang and H. L. Shang (2022) &quot;Is the group structure important in grouped functional time series?&quot;, <em>Journal of Data Science</em>, <b>20</b>(3), 303-324.
</p>
<p>H. L. Shang and Y. Yang (2022) &quot;Forecasting Australian subnational age-specific mortality rates&quot;, <em>Journal of Population Research</em>, <b>38</b>, 1-24.
</p>
<p>Y. Yang, H. L. Shang and J. Raymer (2024) &quot;Forecasting Australian fertility by age, region, and birthplace&quot;, <em>International Journal of Forecasting</em>, in press.
</p>
<p>###########################
# References in Actuarial Studies
###########################
</p>
<p>H. L. Shang and S. Haberman (2017) &quot;Grouped multivariate and functional time series forecasting: An application to annuity pricing&quot;, Presented at the Living to 100 Symposium, Orlando Florida, January 4-6, 2017.
</p>
<p>H. L. Shang and S. Haberman (2017) &quot;Grouped multivariate and functional time series forecasting: An application to annuity pricing&quot;, <em>Insurance: Mathematics and Economics</em>, <b>75</b>, 166-179.
</p>
<p>H. L. Shang and S. Haberman (2018) &quot;Model confidence sets and forecast combination: An application to age-specific mortality&quot;, <em>Genus - Journal of Population Sciences</em>, <b>74</b>, Article number: 19.
</p>
<p>H. L. Shang and S. Haberman (2020) &quot;Forecasting multiple functional time series in a group structure: an application to mortality&quot;, <em>ASTIN Bulletin</em>, <b>50</b>(2), 357-379.
</p>
<p>H. L. Shang (2020) &quot;Dynamic principal component regression for forecasting functional time series in a group structure&quot;, <em>Scandinavian Actuarial Journal</em>, <b>2020</b>(4), 307-322.
</p>
<p>H. L. Shang and S. Haberman (2020) &quot;Forecasting age distribution of death counts: An application to annuity pricing&quot;, <em>Annals of Actuarial Science</em>, <b>14</b>(1), 150-169.
</p>
<p>H. L .Shang and S. Haberman and R. Xu (2022) &quot;Multi-population modelling and forecasting age-specific life-table death counts&quot;, <em>Insurance: Mathematics and Economics</em>, <b>106</b>, 239-253.
</p>
<p>####################
# References in Finance
####################
</p>
<p>F. Kearney and H. L. Shang (2020) &quot;Uncovering predictability in the evolution of the WTI oil futures curve&quot;, <em>European Financial Management</em>, <b>26</b>(1), 238-257.
</p>
<p>H. L. Shang, K. Ji and U. Beyaztas (2021) &quot;Granger causality of bivariate stationary curve time series&quot;, <em>Journal of Forecasting</em>, <b>40</b>(4), 626-635.
</p>
<p>S. Butler, P. Kokoszka, H. Miao and H. L. Shang (2021) &quot;Neural network prediction of crude oil futures using B-splines&quot;, <em>Energy Economics</em>, <b>94</b>, 105080.
</p>
<p>H. L. Shang and F. Kearney (2022) &quot;Dynamic functional time series forecasts of foreign exchange implied volatility surfaces&quot;, <em>International Journal of Forecasting</em>, <b>38</b>(3), 1025-1049. 
</p>
<p>H. L. Shang and K. Ji (2023) &quot;Forecasting intraday financial time series with sieve bootstrapping and dynamic updating&quot;, <em>Journal of Forecasting</em>, <b>42</b>(8), 1973-1988.
</p>

<hr>
<h2 id='all_hmd_female_data'>
The US female log-mortality rate from 1959-2020 and 3 states (New York, California, Illinois).
</h2><span id='topic+all_hmd_female_data'></span>

<h3>Description</h3>

<p>We generate for the female population in the US. The functional time series corresponding to the log mortality data in each of the 3 states. Each functional time series comprises the ages from 0 to 100+.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("all_hmd_male_data")</code></pre>


<h3>Format</h3>

<p>A n x p matrix with n=186 observations on the following p=101 ages from 0 to 100+.
</p>


<h3>Details</h3>

<p>The data generated corresponds to the FTS for the female US log-mortality. The matrix contains 186 FTS stacked by rows. They correspond to 62 (number of years) times 3 (states). Each FTS contains 101 functional values. 
</p>


<h3>References</h3>

<p>United States Mortality Database (2023). University of California, Berkeley (USA). Department of
Demography at the University of California, Berkeley. Available at usa.mortality.org (data
downloaded on March 15, 2023).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(all_hmd_male_data)
</code></pre>

<hr>
<h2 id='all_hmd_male_data'>
The US male log-mortality rate from 1959-2020 and 3 states (New York, California, Illinois).
</h2><span id='topic+all_hmd_male_data'></span>

<h3>Description</h3>

<p>We generate for the male population in the US. The functional time series corresponding to the log mortality data in each of the 3 states. Each functional time series comprises the ages from 0 to 100+.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("all_hmd_male_data")</code></pre>


<h3>Format</h3>

<p>A n x p matrix with n=186 observations on the following p=101 ages from 0 to 100+.
</p>


<h3>Details</h3>

<p>The data generated corresponds to the FTS for the male US log-mortality. The matrix contains 186 FTS stacked by rows. They correspond to 62 (number of years) times 3 (states). Each FTS contains 101 functional values. 
</p>


<h3>References</h3>

<p>United States Mortality Database (2023). University of California, Berkeley (USA). Department of
Demography at the University of California, Berkeley. Available at usa.mortality.org (data
downloaded on March 15, 2023).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(all_hmd_male_data)
</code></pre>

<hr>
<h2 id='centre'>
Mean function, variance function, median function, trim mean function of functional data
</h2><span id='topic+centre'></span>

<h3>Description</h3>

<p>Mean function, variance function, median function, trim mean function of functional data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centre(x, type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="centre_+3A_x">x</code></td>
<td>
<p>An object of class <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="centre_+3A_type">type</code></td>
<td>
<p>Mean, variance, median or trim mean?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return mean function, variance function, median function or trim mean function.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcscorebootstrapdata">pcscorebootstrapdata</a></code>, <code><a href="#topic+mean.fts">mean.fts</a></code>, <code><a href="#topic+median.fts">median.fts</a></code>, <code><a href="#topic+sd.fts">sd.fts</a></code>, <code><a href="#topic+var.fts">var.fts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># mean function is often removed in the functional principal component analysis.
# trimmed mean function is sometimes employed for robustness in the presence of outliers.
# In calculating trimmed mean function, several functional depth measures were employed.	
centre(x = ElNino_ERSST_region_1and2$y, type = "mean")
centre(x = ElNino_ERSST_region_1and2$y, type = "var")
centre(x = ElNino_ERSST_region_1and2$y, type = "median")
centre(x = ElNino_ERSST_region_1and2$y, type = "trimmed")
</code></pre>

<hr>
<h2 id='CoDa_BayesNW'>
Compositional data analytic approach and nonparametric function-on-function regression for forecasting density
</h2><span id='topic+CoDa_BayesNW'></span>

<h3>Description</h3>

<p>Log-ratio transformation from constrained space to unconstrained space, where a standard nonparametric function-on-function regression can be applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoDa_BayesNW(data, normalization, m = 5001, 
	band_choice = c("Silverman", "DPI"), 
	kernel = c("gaussian", "epanechnikov"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CoDa_BayesNW_+3A_data">data</code></td>
<td>
<p>Densities or raw data matrix of dimension N by p, where N denotes sample size and p denotes dimensionality</p>
</td></tr>
<tr><td><code id="CoDa_BayesNW_+3A_normalization">normalization</code></td>
<td>
<p>If a standardization should be performed?</p>
</td></tr>
<tr><td><code id="CoDa_BayesNW_+3A_m">m</code></td>
<td>
<p>Grid points within the data range</p>
</td></tr>
<tr><td><code id="CoDa_BayesNW_+3A_band_choice">band_choice</code></td>
<td>
<p>Selection of optimal bandwidth</p>
</td></tr>
<tr><td><code id="CoDa_BayesNW_+3A_kernel">kernel</code></td>
<td>
<p>Type of kernel function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1) Compute the geometric mean function
2) Apply the centered log-ratio transformation
3) Apply a nonparametric function-on-function regression to the transformed data
4) Transform forecasts back to the compositional data
5) Add back the geometric means, to obtain the forecasts of the density function
</p>


<h3>Value</h3>

<p>Out-of-sample density forecasts
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>Egozcue, J. J., Diaz-Barrero, J. L. and Pawlowsky-Glahn, V. (2006) &lsquo;Hilbert space of probability density functions based on Aitchison geometry&rsquo;, <em>Acta Mathematica Sinica</em>, <b>22</b>, 1175-1182.
</p>
<p>Ferraty, F. and Shang, H. L. (2021) &lsquo;Nonparametric density-on-density regression&rsquo;, working paper.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoDa_FPCA">CoDa_FPCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
CoDa_BayesNW(data = DJI_return, normalization = "TRUE", 
		band_choice = "DPI", kernel = "epanechnikov")

## End(Not run)	
</code></pre>

<hr>
<h2 id='CoDa_FPCA'>
Compositional data analytic approach and functional principal component analysis for forecasting density
</h2><span id='topic+CoDa_FPCA'></span>

<h3>Description</h3>

<p>Log-ratio transformation from constrained space to unconstrained space, where a standard functional principal component analysis can be applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoDa_FPCA(data, normalization, h_scale = 1, m = 5001, 
	band_choice = c("Silverman", "DPI"), 
	kernel = c("gaussian", "epanechnikov"), 
	varprop = 0.99, fmethod)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CoDa_FPCA_+3A_data">data</code></td>
<td>
<p>Densities or raw data matrix of dimension n by p, where n denotes sample size and p denotes dimensionality</p>
</td></tr>
<tr><td><code id="CoDa_FPCA_+3A_normalization">normalization</code></td>
<td>
<p>If a standardization should be performed?</p>
</td></tr>
<tr><td><code id="CoDa_FPCA_+3A_h_scale">h_scale</code></td>
<td>
<p>Scaling parameter in the kernel density estimator</p>
</td></tr>
<tr><td><code id="CoDa_FPCA_+3A_m">m</code></td>
<td>
<p>Grid point within the data range</p>
</td></tr>
<tr><td><code id="CoDa_FPCA_+3A_band_choice">band_choice</code></td>
<td>
<p>Selection of optimal bandwidth</p>
</td></tr>
<tr><td><code id="CoDa_FPCA_+3A_kernel">kernel</code></td>
<td>
<p>Type of kernel functions</p>
</td></tr>
<tr><td><code id="CoDa_FPCA_+3A_varprop">varprop</code></td>
<td>
<p>Proportion of variance explained</p>
</td></tr>
<tr><td><code id="CoDa_FPCA_+3A_fmethod">fmethod</code></td>
<td>
<p>Univariate time series forecasting method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1) Compute the geometric mean function
2) Apply the centered log-ratio transformation
3) Apply FPCA to the transformed data
4) Forecast principal component scores
5) Transform forecasts back to the compositional data
6) Add back the geometric means, to obtain the forecasts of the density function
</p>


<h3>Value</h3>

<p>Out-of-sample forecast densities
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>Boucher, M.-P. B., Canudas-Romo, V., Oeppen, J. and Vaupel, J. W. (2017) &lsquo;Coherent forecasts of mortality with compositional data analysis&rsquo;, <em>Demographic Research</em>, <b>37</b>, 527-566.
</p>
<p>Egozcue, J. J., Diaz-Barrero, J. L. and Pawlowsky-Glahn, V. (2006) &lsquo;Hilbert space of probability density functions based on Aitchison geometry&rsquo;, <em>Acta Mathematica Sinica</em>, <b>22</b>, 1175-1182.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Horta_Ziegelmann_FPCA">Horta_Ziegelmann_FPCA</a></code>, <code><a href="#topic+LQDT_FPCA">LQDT_FPCA</a></code>, <code><a href="#topic+skew_t_fun">skew_t_fun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
CoDa_FPCA(data = DJI_return, normalization = "TRUE", band_choice = "DPI", 
	kernel = "epanechnikov", varprop = 0.9, fmethod = "ETS")

## End(Not run)
</code></pre>

<hr>
<h2 id='diff.fts'>Differences of a functional time series</h2><span id='topic+diff.fts'></span>

<h3>Description</h3>

<p>Computes differences of a <code>fts</code> object at each variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fts'
diff(x, lag = 1, differences = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="diff.fts_+3A_x">x</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="diff.fts_+3A_lag">lag</code></td>
<td>
<p>An integer indicating which lag to use.</p>
</td></tr>
<tr><td><code id="diff.fts_+3A_differences">differences</code></td>
<td>
<p>An integer indicating the order of the difference.</p>
</td></tr>
<tr><td><code id="diff.fts_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>fts</code>.</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>Examples</h3>

<pre><code class='language-R'># ElNino is an object of sliced functional time series.
# Differencing is sometimes used to achieve stationarity.	
diff(x = ElNino_ERSST_region_1and2)
</code></pre>

<hr>
<h2 id='DJI_return'>
Dow Jones Industrial Average (DJIA)
</h2><span id='topic+DJI_return'></span>

<h3>Description</h3>

<p>Dow Jones Industrial Average (DJIA) is a stock market index that shows how 30 large publicly owned companies based in the United States have traded during a standard NYSE trading session. We consider monthly cross-sectional returns from April 2004 to December 2017. The data were obtained from the CRSP (Center for Research in Security Prices) database.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("DJI_return")</code></pre>


<h3>Format</h3>

<p>A data matrix
</p>


<h3>References</h3>

<p>Kokoszka, P., Miao, H., Petersen, A. and Shang, H. L. (2019) &lsquo;Forecasting of density functions with an application to cross-sectional and intraday returns&rsquo;, <em>International Journal of Forecasting</em>, <b>35</b>(4), 1304-1317.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DJI_return)
</code></pre>

<hr>
<h2 id='dmfpca'>
Dynamic multilevel functional principal component analysis
</h2><span id='topic+dmfpca'></span>

<h3>Description</h3>

<p>Functional principal component analysis is used to decompose multiple functional time series. This function uses a functional panel data model to reduce dimensions for multiple functional time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmfpca(y, M = NULL, J = NULL, N = NULL, tstart = 0, tlength = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dmfpca_+3A_y">y</code></td>
<td>
<p>A data matrix containing functional responses. Each row contains measurements from a function at a set of grid points, and each column contains measurements of all functions at a particular grid point</p>
</td></tr>
<tr><td><code id="dmfpca_+3A_m">M</code></td>
<td>
<p>Number of <code>fts</code> obejcts</p>
</td></tr>
<tr><td><code id="dmfpca_+3A_j">J</code></td>
<td>
<p>Number of functions in each object</p>
</td></tr>
<tr><td><code id="dmfpca_+3A_n">N</code></td>
<td>
<p>Number of grid points per function</p>
</td></tr>
<tr><td><code id="dmfpca_+3A_tstart">tstart</code></td>
<td>
<p>Start point of the grid points</p>
</td></tr>
<tr><td><code id="dmfpca_+3A_tlength">tlength</code></td>
<td>
<p>Length of the interval that the functions are evaluated at</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>K1</code></td>
<td>
<p>Number of components for the common time-trend</p>
</td></tr>
<tr><td><code>K2</code></td>
<td>
<p>Number of components for the residual component</p>
</td></tr>
<tr><td><code>lambda1</code></td>
<td>
<p>A vector containing all common time-trend eigenvalues in non-increasing order</p>
</td></tr>
<tr><td><code>lambda2</code></td>
<td>
<p>A vector containing all residual component eigenvalues in non-increasing order</p>
</td></tr>
<tr><td><code>phi1</code></td>
<td>
<p>A matrix containing all common time-trend eigenfunctions. Each row contains an eigenfunction evaluated at the same set of grid points as the input data. The eigenfunctions are in the same order as the corresponding eigenvalues</p>
</td></tr>
<tr><td><code>phi2</code></td>
<td>
<p>A matrix containing all residual component eigenfunctions. Each row contains an eigenfunction               evaluated at the same set of grid points as the input data.  The eigenfunctions are in the same order as the corresponding eigenvalues.</p>
</td></tr>
<tr><td><code>scores1</code></td>
<td>
<p>A matrix containing estimated common time-trend principal component scores. Each row corresponding to the common time-trend scores for a particular subject in a cluster. The number of rows is the same as that of the input matrix y. Each column contains the scores for a common time-trend component for all subjects.</p>
</td></tr>
<tr><td><code>scores2</code></td>
<td>
<p>A matrix containing estimated residual component principal component scores. Each row corresponding to the level 2 scores for a particular subject in a cluster.  The number of rows is the same as that of the input matrix y. Each column contains the scores for a residual component for all subjects.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A vector containing the overall mean function.</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>A matrix containing the deviation from overall mean function to country specific mean function. The number of rows is the number of countries.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chen Tang and Han Lin Shang
</p>


<h3>References</h3>

<p>Rice, G. and Shang, H. L. (2017) &quot;A plug-in bandwidth selection procedure for long-run covariance estimation with stationary functional time series&quot;, <em>Journal of Time Series Analysis</em>, <b>38</b>, 591-609.
</p>
<p>Shang, H. L. (2016) &quot;Mortality and life expectancy forecasting for a group of populations in developed countries: A multilevel functional data method&quot;, <em>The Annals of Applied Statistics</em>, <b>10</b>, 1639-1672.
</p>
<p>Di, C.-Z., Crainiceanu, C. M., Caffo, B. S. and Punjabi, N. M. (2009) &quot;Multilevel functional principal component analysis&quot;, <em>The Annals of Applied Statistics</em>, <b>3</b>, 458-488.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mftsc">mftsc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The following takes about 10 seconds to run ##
## Not run: 
y &lt;- do.call(rbind, sim_ex_cluster) 
MFPCA.sim &lt;- dmfpca(y, M = length(sim_ex_cluster), J = nrow(sim_ex_cluster[[1]]), 
				    N = ncol(sim_ex_cluster[[1]]), tlength = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='dynamic_FLR'>
Dynamic updates via functional linear regression
</h2><span id='topic+dynamic_FLR'></span>

<h3>Description</h3>

<p>A functional linear regression is used to address the problem of dynamic updating, when partial data in the most recent curve are observed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynamic_FLR(dat, newdata, holdoutdata, order_k_percent = 0.9, order_m_percent = 0.9, 
    pcd_method = c("classical", "M"), robust_lambda = 2.33, bootrep = 100, 
    	pointfore, level = 80)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dynamic_FLR_+3A_dat">dat</code></td>
<td>
<p>An object of class <code>sfts</code>.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_newdata">newdata</code></td>
<td>
<p>A data vector of newly arrived observations.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_holdoutdata">holdoutdata</code></td>
<td>
<p>A data vector of holdout sample to evaluate point forecast accuracy.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_order_k_percent">order_k_percent</code></td>
<td>
<p>Select the number of components that explains at least 90 percent of the total variation.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_order_m_percent">order_m_percent</code></td>
<td>
<p>Select the number of components that explains at least 90 percent of the total variation.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_pcd_method">pcd_method</code></td>
<td>
<p>Method to use for principal components decomposition. Possibilities are &quot;M&quot;, &quot;rapca&quot; and &quot;classical&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_robust_lambda">robust_lambda</code></td>
<td>
<p>Tuning parameter in the two-step robust functional principal component analysis, when <code>pcdmethod = "M"</code>.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_bootrep">bootrep</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_pointfore">pointfore</code></td>
<td>
<p>If <code>pointfore = TRUE</code>, point forecasts are produced.</p>
</td></tr>
<tr><td><code id="dynamic_FLR_+3A_level">level</code></td>
<td>
<p>Nominal coverage probability.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is designed to dynamically update point and interval forecasts, when partial data in the most recent curve are observed.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>update_forecast</code></td>
<td>
<p>Updated forecasts.</p>
</td></tr>
<tr><td><code>holdoutdata</code></td>
<td>
<p>Holdout sample.</p>
</td></tr>
<tr><td><code>err</code></td>
<td>
<p>Forecast errors.</p>
</td></tr>
<tr><td><code>order_k</code></td>
<td>
<p>Number of principal components in the first block of functions.</p>
</td></tr>
<tr><td><code>order_m</code></td>
<td>
<p>Number of principal components in the second block of functions.</p>
</td></tr>
<tr><td><code>update_comb</code></td>
<td>
<p>Bootstrapped forecasts for the dynamically updating time period.</p>
</td></tr>
<tr><td><code>update_comb_lb_ub</code></td>
<td>
<p>By taking corresponding quantiles, obtain lower and upper prediction bounds.</p>
</td></tr>
<tr><td><code>err_boot</code></td>
<td>
<p>Bootstrapped in-sample forecast error for the dynamically updating time period.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>H. Shen and J. Z. Huang (2008) &quot;Interday forecasting and intraday updating of call center arrivals&quot;, <em>Manufacturing and Service Operations Management</em>, <b>10</b>(3), 391-410.
</p>
<p>H. Shen (2009) &quot;On modeling and forecasting time series of curves&quot;, <em>Technometrics</em>, <b>51</b>(3), 227-238.
</p>
<p>H. L. Shang and R. J. Hyndman (2011) &quot;Nonparametric time series forecasting with dynamic updating&quot;, Mathematics and Computers in Simulation, <b>81</b>(7), 1310-1324.
</p>
<p>J-M. Chiou (2012) &quot;Dynamical functional prediction and classification with application to traffic flow prediction&quot;, <em>Annals of Applied Statistics</em>, <b>6</b>(4), 1588-1614.
</p>
<p>H. L. Shang (2013) &quot;Functional time series approach for forecasting very short-term electricity demand&quot;, <em>Journal of Applied Statistics</em>, <b>40</b>(1), 152-168.
</p>
<p>H. L. Shang (2015) &quot;Forecasting Intraday S&amp;P 500 Index Returns: A Functional Time Series Approach&quot;, <em>Journal of Forecasting</em>, <b>36</b>(7), 741-755.
</p>
<p>H. L. Shang (2017) &quot;Functional time series forecasting with dynamic updating: An application to intraday particulate matter concentration&quot;, <em>Econometrics and Statistics</em>, <b>1</b>, 184-200.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dynupdate">dynupdate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dynamic_FLR_point = dynamic_FLR(dat = ElNino_ERSST_region_1and2$y[,1:68], 
	newdata = ElNino_ERSST_region_1and2$y[1:4,69], 
	holdoutdata = ElNino_ERSST_region_1and2$y[5:12,69], pointfore = TRUE)

dynamic_FLR_interval = dynamic_FLR(dat = ElNino_ERSST_region_1and2$y[,1:68], 
	newdata = ElNino_ERSST_region_1and2$y[1:4,69], 
	holdoutdata = ElNino_ERSST_region_1and2$y[5:12,69], pointfore = FALSE)
</code></pre>

<hr>
<h2 id='dynupdate'>Dynamic updates via BM, OLS, RR and PLS methods</h2><span id='topic+dynupdate'></span>

<h3>Description</h3>

 
<p>Four methods, namely block moving (BM), ordinary least squares (OLS) regression, 
ridge regression (RR), penalized least squares (PLS) regression, were proposed to 
address the problem of dynamic updating, when partial data in the most recent curve 
are observed. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynupdate(data, newdata = NULL, holdoutdata, method = c("ts", "block", 
 "ols", "pls", "ridge"), fmethod = c("arima", "ar", "ets", "ets.na", 
  "rwdrift", "rw"), pcdmethod = c("classical", "M", "rapca"), 
   ngrid = max(1000, ncol(data$y)), order = 6, 
    robust_lambda = 2.33, lambda = 0.01, value = FALSE, 
     interval = FALSE, level = 80, 
      pimethod = c("parametric", "nonparametric"), B = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dynupdate_+3A_data">data</code></td>
<td>
<p>An object of class <code>sfts</code>.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_newdata">newdata</code></td>
<td>
<p>A data vector of newly arrived observations.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_holdoutdata">holdoutdata</code></td>
<td>
<p>A data vector of holdout sample to evaluate point forecast accuracy.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_method">method</code></td>
<td>
<p>Forecasting methods. The latter four can dynamically update point forecasts.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_fmethod">fmethod</code></td>
<td>
<p>Univariate time series forecasting methods used in <code>method = "ts"</code> 
or <code>method = "block"</code>.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_pcdmethod">pcdmethod</code></td>
<td>
<p>Method to use for principal components decomposition. Possibilities are &quot;M&quot;, &quot;rapca&quot; and &quot;classical&quot;.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_ngrid">ngrid</code></td>
<td>
<p>Number of grid points to use in calculations. Set to maximum of 1000 and <code>ncol(data$y)</code>.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_order">order</code></td>
<td>
<p>Number of principal components to fit.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_robust_lambda">robust_lambda</code></td>
<td>
<p>Tuning parameter in the two-step robust functional principal component analysis, when <code>pcdmethod = "M"</code>.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_lambda">lambda</code></td>
<td>
<p>Penalty parameter used in <code>method = "pls"</code> or <code>method = "ridge"</code>.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_value">value</code></td>
<td>
<p>When <code>value = TRUE</code>, returns forecasts or when <code>value = FALSE</code>, returns forecast errors.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_interval">interval</code></td>
<td>
<p>When <code>interval = TRUE</code>, produces distributional forecasts.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_level">level</code></td>
<td>
<p>Nominal coverage probability.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_pimethod">pimethod</code></td>
<td>
<p>Parametric or nonparametric method to construct prediction intervals.</p>
</td></tr>
<tr><td><code id="dynupdate_+3A_b">B</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>This function is designed to dynamically update point and interval forecasts, when partial data in the most recent curve are observed.
</p>
<p>If <code>method = "classical"</code>, then standard functional principal component decomposition is used, as described by Ramsay and Dalzell (1991). 
</p>
<p>If <code>method = "rapca"</code>, then the robust principal component algorithm of Hubert, Rousseeuw and Verboven (2002) is used. 
</p>
<p>If <code>method = "M"</code>, then the hybrid algorithm of Hyndman and Ullah (2005) is used. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>forecasts</code></td>
<td>
<p>An object of class <code>fts</code> containing the dynamic updated point forecasts.</p>
</td></tr>
<tr><td><code>bootsamp</code></td>
<td>
<p>An object of class <code>fts</code> containing the bootstrapped point forecasts, which are updated by the PLS method.</p>
</td></tr>
<tr><td><code>low</code></td>
<td>
<p>An object of class <code>fts</code> containing the lower bound of prediction intervals.</p>
</td></tr>
<tr><td><code>up</code></td>
<td>
<p>An object of class <code>fts</code> containing the upper bound of prediction intervals.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>References</h3>

<p>J. O. Ramsay and C. J. Dalzell (1991) &quot;Some tools for functional data analysis (with discussion)&quot;, <em>Journal of the Royal Statistical Society: Series B</em>, <b>53</b>(3), 539-572. 
</p>
<p>M. Hubert and P. J. Rousseeuw and S. Verboven (2002) &quot;A fast robust method for principal components with applications to chemometrics&quot;, <em>Chemometrics and Intelligent Laboratory Systems</em>, <b>60</b>(1-2), 101-111. 
</p>
<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>H. Shen and J. Z. Huang (2008) &quot;Interday forecasting and intraday updating of call center arrivals&quot;, <em>Manufacturing and Service Operations Management</em>, <b>10</b>(3), 391-410.
</p>
<p>H. Shen (2009) &quot;On modeling and forecasting time series of curves&quot;, <em>Technometrics</em>, <b>51</b>(3), 227-238.
</p>
<p>H. L. Shang and R. J. Hyndman (2011) &quot;Nonparametric time series forecasting with dynamic updating&quot;, Mathematics and Computers in Simulation, <b>81</b>(7), 1310-1324.
</p>
<p>H. L. Shang (2013) &quot;Functional time series approach for forecasting very short-term electricity demand&quot;, <em>Journal of Applied Statistics</em>, <b>40</b>(1), 152-168.
</p>
<p>H. L. Shang (2017) &quot;Forecasting Intraday S&amp;P 500 Index Returns: A Functional Time Series Approach&quot;, <em>Journal of Forecasting</em>, <b>36</b>(7), 741-755.
</p>
<p>H. L. Shang (2017) &quot;Functional time series forecasting with dynamic updating: An application to intraday particulate matter concentration&quot;, <em>Econometrics and Statistics</em>, <b>1</b>, 184-200.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  
# ElNino is an object of sliced functional time series, constructed from a univariate time series. 
# When we observe some newly arrived information in the most recent time period, this function  
# allows us to update the point and interval forecasts for the remaining time period. 
dynupdate(data = ElNino_ERSST_region_1and2, newdata = ElNino_ERSST_region_1and2$y[1:4,69], 
	holdoutdata = ElNino_ERSST_region_1and2$y[5:12,57], method = "block", interval = FALSE) 
</code></pre>

<hr>
<h2 id='ER_GR'>
Selection of the number of principal components
</h2><span id='topic+ER_GR'></span>

<h3>Description</h3>

<p>Eigenvalue ratio and growth ratio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ER_GR(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ER_GR_+3A_data">data</code></td>
<td>
<p>An n by p matrix, where n denotes sample size and p denotes the number of discretized data points in a curve</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>k_ER</code></td>
<td>
<p>The number of components selected by the eigenvalue ratio</p>
</td></tr>
<tr><td><code>k_GR</code></td>
<td>
<p>The number of components selected by the growth ratio</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>Lam, C. and Yao, Q. (2012). Factor modelling for high-dimensional time series: Inference for the number of factors. The Annals of Statistics, 40, 694-726.
</p>
<p>Ahn, S. and Horenstein, A. (2013). Eigenvalue ratio test for the number of factors. Econometrica, 81, 1203-1227.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ER_GR(pm_10_GR$y)
</code></pre>

<hr>
<h2 id='error'>Forecast error measure</h2><span id='topic+error'></span>

<h3>Description</h3>

<p>Computes the forecast error measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>error(forecast, forecastbench, true, insampletrue, method = c("me", "mpe", "mae", 
 "mse", "sse", "rmse", "mdae", "mdse", "mape", "mdape", "smape", 
  "smdape", "rmspe", "rmdspe", "mrae", "mdrae", "gmrae", 
   "relmae", "relmse", "mase", "mdase", "rmsse"), giveall = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="error_+3A_forecast">forecast</code></td>
<td>
<p>Out-of-sample forecasted values.</p>
</td></tr>
<tr><td><code id="error_+3A_forecastbench">forecastbench</code></td>
<td>
<p>Forecasted values using a benchmark method, such as random walk.</p>
</td></tr>
<tr><td><code id="error_+3A_true">true</code></td>
<td>
<p>Out-of-sample holdout values.</p>
</td></tr>
<tr><td><code id="error_+3A_insampletrue">insampletrue</code></td>
<td>
<p>Insample values.</p>
</td></tr>
<tr><td><code id="error_+3A_method">method</code></td>
<td>
<p>Method of forecast error measure.</p>
</td></tr>
<tr><td><code id="error_+3A_giveall">giveall</code></td>
<td>
<p>If <code>giveall = TRUE</code>, all error measures are provided.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em><b>Bias measure</b></em>:
</p>
<p>If <code>method = "me"</code>, the forecast error measure is mean error.
</p>
<p>If <code>method = "mpe"</code>, the forecast error measure is mean percentage error.
</p>
<p><em><b>Forecast accuracy error measure</b></em>:
</p>
<p>If <code>method = "mae"</code>, the forecast error measure is mean absolute error.
</p>
<p>If <code>method = "mse"</code>, the forecast error measure is mean square error.
</p>
<p>If <code>method = "sse"</code>, the forecast error measure is sum square error.
</p>
<p>If <code>method = "rmse"</code>, the forecast error measure is root mean square error.
</p>
<p>If <code>method = "mdae"</code>, the forecast error measure is median absolute error.
</p>
<p>If <code>method = "mape"</code>, the forecast error measure is mean absolute percentage error.
</p>
<p>If <code>method = "mdape"</code>, the forecast error measure is median absolute percentage error.
</p>
<p>If <code>method = "rmspe"</code>, the forecast error measure is root mean square percentage error.
</p>
<p>If <code>method = "rmdspe"</code>, the forecast error measure is root median square percentage error.
</p>
<p><em><b>Forecast accuracy symmetric error measure</b></em>:
</p>
<p>If <code>method = "smape"</code>, the forecast error measure is symmetric mean absolute percentage error.
</p>
<p>If <code>method = "smdape"</code>, the forecast error measure is symmetric median absolute percentage error.
</p>
<p><em><b>Forecast accuracy relative error measure</b></em>:
</p>
<p>If <code>method = "mrae"</code>, the forecast error measure is mean relative absolute error.
</p>
<p>If <code>method = "mdrae"</code>, the forecast error measure is median relative absolute error.
</p>
<p>If <code>method = "gmrae"</code>, the forecast error measure is geometric mean relative absolute error.
</p>
<p>If <code>method = "relmae"</code>, the forecast error measure is relative mean absolute error.
</p>
<p>If <code>method = "relmse"</code>, the forecast error measure is relative mean square error.
</p>
<p><em><b>Forecast accuracy scaled error measure</b></em>:
</p>
<p>If <code>method = "mase"</code>, the forecast error measure is mean absolute scaled error.
</p>
<p>If <code>method = "mdase"</code>, the forecast error measure is median absolute scaled error.
</p>
<p>If <code>method = "rmsse"</code>, the forecast error measure is root mean square scaled error.
</p>


<h3>Value</h3>

<p>A numeric value.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>References</h3>

<p>P. A. Thompson (1990) &quot;An MSE statistic for comparing forecast accuracy across series&quot;, <em>International Journal of Forecasting</em>, <b>6</b>(2), 219-227.
</p>
<p>C. Chatfield (1992) &quot;A commentary on error measures&quot;, <em>International Journal of Forecasting</em>, <b>8</b>(1), 100-102.
</p>
<p>S. Makridakis (1993) &quot;Accuracy measures: theoretical and practical concerns&quot;, <em>International Journal of Forecasting</em>, <b>9</b>(4), 527-529.
</p>
<p>R. J. Hyndman and A. Koehler (2006) &quot;Another look at measures of forecast accuracy&quot;, <em>International Journal of Forecasting</em>, <b>22</b>(3), 443-473.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Forecast error measures can be categorized into three groups: (1) scale-dependent, 
# (2) scale-independent but with possible zero denominator, 
# (3) scale-independent with non-zero denominator.
error(forecast = 1:2, true = 3:4, method = "mae")
error(forecast = 1:5, forecastbench = 6:10, true = 11:15, method = "mrae")
error(forecast = 1:5, forecastbench = 6:10, true = 11:15, insampletrue = 16:20, 
	giveall = TRUE)
</code></pre>

<hr>
<h2 id='extract'>Extract variables or observations</h2><span id='topic+extract'></span>

<h3>Description</h3>

<p>Creates subsets of a <code>fts</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract(data, direction = c("time", "x"), timeorder, xorder)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_+3A_data">data</code></td>
<td>
<p>An object of <code>fts</code>.</p>
</td></tr>
<tr><td><code id="extract_+3A_direction">direction</code></td>
<td>
<p>In time direction or x variable direction?</p>
</td></tr>
<tr><td><code id="extract_+3A_timeorder">timeorder</code></td>
<td>
<p>Indexes of time order.</p>
</td></tr>
<tr><td><code id="extract_+3A_xorder">xorder</code></td>
<td>
<p>Indexes of x variable order.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>When <code>xorder</code> is specified, it returns a <code>fts</code> object with same argument as 
data but with a subset of <code>x</code> variables.<br />
</p>
<p>When <code>timeorder</code> is specified, it returns a <code>fts</code> object with same argument 
as data but with a subset of <code>time</code> variables.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>Examples</h3>

<pre><code class='language-R'># ElNino is an object of class sliced functional time series.
# This function truncates the data series rowwise or columnwise.	
extract(data = ElNino_ERSST_region_1and2, direction = "time", 
	timeorder = 1980:2006) # Last 27 curves
extract(data = ElNino_ERSST_region_1and2, direction = "x", 
	xorder = 1:8) # First 8 x variables
</code></pre>

<hr>
<h2 id='facf'>
Functional autocorrelation function
</h2><span id='topic+facf'></span>

<h3>Description</h3>

<p>Compute functional autocorrelation function at various lags
</p>


<h3>Usage</h3>

<pre><code class='language-R'>facf(fun_data, lag_value_range = seq(0, 20, by = 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="facf_+3A_fun_data">fun_data</code></td>
<td>
<p>A data matrix of dimension (n by p), where n denotes sample size; and p denotes dimensionality</p>
</td></tr>
<tr><td><code id="facf_+3A_lag_value_range">lag_value_range</code></td>
<td>
<p>Lag value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The autocovariance at lag <code class="reqn">i</code> is estimated by the function <code class="reqn">\widehat{\gamma}_i(t,s)</code>, a functional analog of the autocorrelation is defined as
</p>
<p style="text-align: center;"><code class="reqn">\widehat{\rho}_i = \frac{\|\widehat{\gamma}_i\|}{\int \widehat{\gamma}_0(t,t)dt}.</code>
</p>



<h3>Value</h3>

<p>A vector of functional autocorrelation function at various lags
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>L. Horv\'ath, G. Rice and S. Whipple (2016) Adaptive bandwidth selection in the long run covariance estimator of functional time series, <em>Computational Statistics and Data Analysis</em>, <b>100</b>, 676-693.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>facf_value = facf(fun_data = t(ElNino_ERSST_region_1and2$y))
</code></pre>

<hr>
<h2 id='farforecast'>
Functional data forecasting through functional principal component autoregression
</h2><span id='topic+farforecast'></span>

<h3>Description</h3>

<p>The coefficients from the fitted object are forecasted using a multivariate time-series forecasting method.
The forecast coefficients are then multiplied by the functional principal components to obtain a forecast curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>farforecast(object, h = 10, var_type = "const", Dmax_value, Pmax_value,
	level = 80, PI = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="farforecast_+3A_object">object</code></td>
<td>
<p>An object of <code><a href="rainbow.html#topic+fds">fds</a></code>.</p>
</td></tr>
<tr><td><code id="farforecast_+3A_h">h</code></td>
<td>
<p>Forecast horizon.</p>
</td></tr>
<tr><td><code id="farforecast_+3A_var_type">var_type</code></td>
<td>
<p>Type of multivariate time series forecasting method; see <code><a href="vars.html#topic+VAR">VAR</a></code> for details.</p>
</td></tr>
<tr><td><code id="farforecast_+3A_dmax_value">Dmax_value</code></td>
<td>
<p>Maximum number of components considered.</p>
</td></tr>
<tr><td><code id="farforecast_+3A_pmax_value">Pmax_value</code></td>
<td>
<p>Maximum order of VAR model considered.</p>
</td></tr>
<tr><td><code id="farforecast_+3A_level">level</code></td>
<td>
<p>Nominal coverage probability of prediction error bands.</p>
</td></tr>
<tr><td><code id="farforecast_+3A_pi">PI</code></td>
<td>
<p>When <code>PI = TRUE</code>, a prediction interval will be given along with the point forecast.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1. Decompose the smooth curves via a functional principal component analysis (FPCA).
</p>
<p>2. Fit a multivariate time-series model to the principal component score matrix.
</p>
<p>3. Forecast the principal component scores using the fitted multivariate time-series models. The order of VAR is selected optimally via an information criterion.
</p>
<p>4. Multiply the forecast principal component scores by estimated principal components to obtain forecasts of <code class="reqn">f_{n+h}(x)</code>.
</p>
<p>5. Prediction intervals are constructed by taking quantiles of the one-step-ahead forecast errors.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>point_fore</code></td>
<td>
<p>Point forecast</p>
</td></tr>
<tr><td><code>order_select</code></td>
<td>
<p>Selected VAR order and number of components</p>
</td></tr>
<tr><td><code>PI_lb</code></td>
<td>
<p>Lower bound of a prediction interval</p>
</td></tr>
<tr><td><code>PI_ub</code></td>
<td>
<p>Upper bound of a prediction interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>A. Aue, D. D. Norinho and S. Hormann (2015) &quot;On the prediction of stationary functional time series&quot;, <em>Journal of the American Statistical Association</em>, <b>110</b>(509), 378-392.
</p>
<p>J. Klepsch, C. Kl\&quot;uppelberg and T. Wei (2017) &quot;Prediction of functional ARMA processes with an application to traffic data&quot;, <em>Econometrics and Statistics</em>, <b>1</b>, 128-149.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+forecastfplsr">forecastfplsr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sqrt_pm10 = sqrt(pm_10_GR$y)
multi_forecast_sqrt_pm10 = farforecast(object = fts(seq(0, 23.5, by = 0.5), sqrt_pm10),
	h = 1, Dmax_value = 5, Pmax_value = 3)
</code></pre>

<hr>
<h2 id='fbootstrap'>Bootstrap independent and identically distributed functional data</h2><span id='topic+fbootstrap'></span>

<h3>Description</h3>

<p>Computes bootstrap or smoothed bootstrap samples based on independent and identically distributed functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fbootstrap(data, estad = func.mean, alpha = 0.05, nb = 200, suav = 0,
 media.dist = FALSE, graph = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fbootstrap_+3A_data">data</code></td>
<td>
<p>An object of class <code>fds</code> or <code>fts</code>.</p>
</td></tr>
<tr><td><code id="fbootstrap_+3A_estad">estad</code></td>
<td>
<p>Estimate function of interest. Default is to estimate the mean function. Other options are <code>func.mode</code> or <code>func.var</code>.</p>
</td></tr>
<tr><td><code id="fbootstrap_+3A_alpha">alpha</code></td>
<td>
<p>Significance level used in the smooth bootstrapping.</p>
</td></tr>
<tr><td><code id="fbootstrap_+3A_nb">nb</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="fbootstrap_+3A_suav">suav</code></td>
<td>
<p>Smoothing parameter.</p>
</td></tr>
<tr><td><code id="fbootstrap_+3A_media.dist">media.dist</code></td>
<td>
<p>Estimate mean function.</p>
</td></tr>
<tr><td><code id="fbootstrap_+3A_graph">graph</code></td>
<td>
<p>Graphical output.</p>
</td></tr>
<tr><td><code id="fbootstrap_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components is returned.
</p>
<table role = "presentation">
<tr><td><code>estimate</code></td>
<td>
<p>Estimate function.</p>
</td></tr>
<tr><td><code>max.dist</code></td>
<td>
<p>Max distance of bootstrap samples.</p>
</td></tr>
<tr><td><code>rep.dist</code></td>
<td>
<p>Distances of bootstrap samples.</p>
</td></tr>
<tr><td><code>resamples</code></td>
<td>
<p>Bootstrap samples.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>Functional mean.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>References</h3>

<p>A. Cuevas and M. Febrero and R. Fraiman (2006), &quot;On the use of the bootstrap for estimating functions with functional data&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(2), 1063-1074.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2007), &quot;Robust estimation and classification for functional data via projection-based depth notions&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 481-496.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2007) &quot;A functional analysis of NOx levels: location and scale estimation and outlier detection&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 411-427.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2008) &quot;Outlier detection in functional data by depth measures, with application to identify abnormal NOx levels&quot;, <em>Environmetrics</em>, <b>19</b>(4), 331-345.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2010) &quot;Measures of influence for the functional linear model with scalar response&quot;, <em>Journal of Multivariate Analysis</em>, <b>101</b>(2), 327-339. 
</p>
<p>J. A. Cuesta-Albertos and A. Nieto-Reyes (2010) &quot;Functional classification and the random Tukey depth. Practical issues&quot;, Combining Soft Computing and Statistical Methods in Data Analysis, <em>Advances in Intelligent and Soft Computing</em>, <b>77</b>, 123-130.
</p>
<p>D. Gervini (2012) &quot;Outlier detection and trimmed estimation in general functional spaces&quot;, <em>Statistica Sinica</em>, <b>22</b>(4), 1639-1660.
</p>
<p>H. L. Shang (2015) &quot;Re-sampling techniques for estimating the distribution of descriptive statistics of functional data&quot;, <em>Communication in Statistics&ndash;Simulation and Computation</em>, <b>44</b>(3), 614-635.
</p>
<p>H. L. Shang (2018) Bootstrap methods for stationary functional time series, <em>Statistics and Computing</em>, <b>28</b>(1), 1-10.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcscorebootstrapdata">pcscorebootstrapdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Bootstrapping the distribution of a summary statistics of functional data.
fbootstrap(data = ElNino_ERSST_region_1and2)
</code></pre>

<hr>
<h2 id='forecast.ftsm'>Forecast functional time series</h2><span id='topic+forecast.ftsm'></span>

<h3>Description</h3>

<p>The coefficients from the fitted object are forecasted
using either an ARIMA model (<code>method = "arima"</code>), an AR model (<code>method = "ar"</code>), 
an exponential smoothing method (<code>method = "ets"</code>), a linear exponential smoothing 
method allowing missing values (<code>method = "ets.na"</code>), or a random walk with drift model 
(<code>method = "rwdrift"</code>). The forecast coefficients are then multiplied by the principal 
components to obtain a forecast curve.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ftsm'
forecast(object, h = 10, method = c("ets", "arima", "ar", "ets.na", 
 "rwdrift", "rw", "struct", "arfima"), level = 80, jumpchoice = c("fit", 
  "actual"), pimethod = c("parametric", "nonparametric"), B = 100, 
   usedata = nrow(object$coeff), adjust = TRUE, model = NULL,
    damped = NULL, stationary = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forecast.ftsm_+3A_object">object</code></td>
<td>
<p>Output from <code><a href="#topic+ftsm">ftsm</a></code>.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_h">h</code></td>
<td>
<p>Forecast horizon.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_method">method</code></td>
<td>
<p>Univariate time series forecasting methods. Current possibilities are &ldquo;ets&rdquo;, &ldquo;arima&rdquo;, &ldquo;ets.na&rdquo;, &ldquo;rwdrift&rdquo; and &ldquo;rw&rdquo;.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_level">level</code></td>
<td>
<p>Coverage probability of prediction intervals.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_jumpchoice">jumpchoice</code></td>
<td>
<p>Jump-off point for forecasts. Possibilities are &ldquo;actual&rdquo; and &ldquo;fit&rdquo;.
If &ldquo;actual&rdquo;, the forecasts are bias-adjusted by the difference between the fit and the last year of observed data.
Otherwise, no adjustment is used. See Booth et al. (2006) for the detail on jump-off point.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_pimethod">pimethod</code></td>
<td>
<p>Indicates if parametric method is used to construct prediction intervals.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_b">B</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_usedata">usedata</code></td>
<td>
<p>Number of time periods to use in forecasts. Default is to use all.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_adjust">adjust</code></td>
<td>
<p>If <code>adjust = TRUE</code>, adjusts the variance so that the one-step forecast variance matches the empirical one-step forecast variance.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_model">model</code></td>
<td>
<p>If the <code>ets</code> method is used, <code>model</code> allows a model specification to be passed to <code><a href="forecast.html#topic+ets">ets</a>()</code>.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_damped">damped</code></td>
<td>
<p>If the <code>ets</code> method is used, <code>damped</code> allows the damping specification to be passed to <code><a href="forecast.html#topic+ets">ets</a>()</code>.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_stationary">stationary</code></td>
<td>
<p>If <code>stationary = TRUE</code>, <code>method</code> is set to <code>method = "ar"</code> and only stationary AR models are used.</p>
</td></tr>
<tr><td><code id="forecast.ftsm_+3A_...">...</code></td>
<td>
<p>Other arguments passed to forecast routine.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1. Obtain a smooth curve <code class="reqn">f_t(x)</code> for each <code class="reqn">t</code> using a nonparametric smoothing technique.
</p>
<p>2. Decompose the smooth curves via a functional principal component analysis.
</p>
<p>3. Fit a univariate time series model to each of the principal component scores.
</p>
<p>4. Forecast the principal component scores using the fitted time series models.
</p>
<p>5. Multiply the forecast principal component scores by fixed principal components to obtain forecasts of <code class="reqn">f_{n+h}(x)</code>.
</p>
<p>6. The estimated variances of the error terms (smoothing error and model residual error) are used to compute prediction intervals for the forecasts.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table role = "presentation">
<tr><td><code>mean</code></td>
<td>
<p>An object of class <code>fts</code> containing point forecasts.</p>
</td></tr>
<tr><td><code>lower</code></td>
<td>
<p>An object of class <code>fts</code> containing lower bound for prediction intervals.</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>An object of class <code>fts</code> containing upper bound for prediction intervals.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>An object of class <code>fts</code> of one-step-ahead forecasts for historical data.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>An object of class <code>fts</code> of one-step-ahead errors for historical data.</p>
</td></tr>
<tr><td><code>coeff</code></td>
<td>
<p>List of objects of type <code>forecast</code> containing the coefficients and their forecasts.</p>
</td></tr>
<tr><td><code>coeff.error</code></td>
<td>
<p>One-step-ahead forecast errors for each of the coefficients.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>List containing the various components of variance: model, error, mean, total and coeff.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Fitted <code><a href="#topic+ftsm">ftsm</a></code> model.</p>
</td></tr>
<tr><td><code>bootsamp</code></td>
<td>
<p>An array of <code class="reqn">dimension = c(p, B, h)</code> containing the bootstrapped point forecasts. 
<code class="reqn">p</code> is the number of variables. <code class="reqn">B</code> is the number of bootstrap samples.
<code class="reqn">h</code> is the forecast horizon.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>References</h3>

<p>H. Booth and R. J. Hyndman and L. Tickle and P. D. Jong (2006) &quot;Lee-Carter mortality forecasting: A multi-country comparison of variants and extensions&quot;, <em>Demographic Research</em>, <b>15</b>, 289-310.
</p>
<p>B. Erbas and R. J. Hyndman and D. M. Gertig (2007) &quot;Forecasting age-specific breast cancer mortality using functional data model&quot;, <em>Statistics in Medicine</em>, <b>26</b>(2), 458-470.
</p>
<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>R. J. Hyndman and H. Booth (2008) &quot;Stochastic population forecasts using functional data models for mortality, fertility and migration&quot;, <em>International Journal of Forecasting</em>, <b>24</b>(3), 323-342.
</p>
<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series&quot; (with discussion), <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>
<p>H. L. Shang (2012) &quot;Functional time series approach for forecasting very short-term electricity demand&quot;, <em>Journal of Applied Statistics</em>, <b>40</b>(1), 152-168.
</p>
<p>H. L. Shang (2013) &quot;ftsa: An R package for analyzing functional time series&quot;, <em>The R Journal</em>, <b>5</b>(1), 64-72.
</p>
<p>H. L. Shang, A. Wisniowski, J. Bijak, P. W. F. Smith and J. Raymer (2014) &quot;Bayesian functional models for population forecasting&quot;, in M. Marsili and G. Capacci (eds), Proceedings of the Sixth Eurostat/UNECE Work Session on Demographic Projections, Istituto nazionale di statistica, Rome, pp. 313-325.
</p>
<p>H. L. Shang (2015) &quot;Selection of the optimal Box-Cox transformation parameter for modelling and forecasting age-specific fertility&quot;, <em>Journal of Population Research</em>, <b>32</b>(1), 69-79.
</p>
<p>H. L. Shang (2015) &quot;Forecast accuracy comparison of age-specific mortality and life expectancy: Statistical tests of the results&quot;, <em>Population Studies</em>, <b>69</b>(3), 317-335.
</p>
<p>H. L. Shang, P. W. F. Smith, J. Bijak, A. Wisniowski (2016) &quot;A multilevel functional data method for forecasting population, with an application to the United Kingdom&quot;, <em>International Journal of Forecasting</em>, <b>32</b>(3), 629-649.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecastfplsr">forecastfplsr</a></code>, <code><a href="#topic+plot.ftsf">plot.ftsf</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># ElNino is an object of class sliced functional time series.
# Via functional principal component decomposition, the dynamic was captured 
# by a few principal components and principal component scores. 
# By using an exponential smoothing method, 
# the principal component scores are forecasted.
# The forecasted curves are constructed by forecasted principal components 
# times fixed principal components plus the mean function.	
forecast(object = ftsm(ElNino_ERSST_region_1and2), h = 10, method = "ets")              
forecast(object = ftsm(ElNino_ERSST_region_1and2, weight = TRUE))
</code></pre>

<hr>
<h2 id='forecast.hdfpca'>
Forecasting via a high-dimensional functional principal component regression
</h2><span id='topic+forecast.hdfpca'></span>

<h3>Description</h3>

<p>Forecast high-dimensional functional principal component model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hdfpca'
forecast(object, h = 3, level = 80, B = 50, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forecast.hdfpca_+3A_object">object</code></td>
<td>
<p>An object of class 'hdfpca'</p>
</td></tr>
<tr><td><code id="forecast.hdfpca_+3A_h">h</code></td>
<td>
<p>Forecast horizon</p>
</td></tr>
<tr><td><code id="forecast.hdfpca_+3A_level">level</code></td>
<td>
<p>Prediction interval level, the default is 80 percent</p>
</td></tr>
<tr><td><code id="forecast.hdfpca_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replications</p>
</td></tr>
<tr><td><code id="forecast.hdfpca_+3A_...">...</code></td>
<td>
<p>Other arguments passed to forecast routine.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The low-dimensional factors are forecasted with autoregressive integrated moving average (ARIMA) models separately. The forecast functions are then calculated using the forecast factors. Bootstrap prediction intervals are constructed by resampling from the forecast residuals of the ARIMA models.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>forecast</code></td>
<td>
<p>A list containing the h-step-ahead forecast functions for each population</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>Upper confidence bound for each population</p>
</td></tr>
<tr><td><code>lower</code></td>
<td>
<p>Lower confidence bound for each population</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Y. Gao and H. L. Shang
</p>


<h3>References</h3>

<p>Y. Gao, H. L. Shang and Y. Yang (2018) High-dimensional functional time series forecasting: An application to age-specific mortality rates, <em>Journal of Multivariate Analysis</em>, <b>forthcoming</b>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hdfpca">hdfpca</a></code>, <code><a href="#topic+hd_data">hd_data</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
hd_model = hdfpca(hd_data, order = 2, r = 2)
hd_model_fore = forecast.hdfpca(object = hd_model, h = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='forecastfplsr'>Forecast functional time series</h2><span id='topic+forecastfplsr'></span>

<h3>Description</h3>

<p>The decentralized response is forecasted by multiplying the estimated regression coefficient with the new decentralized predictor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forecastfplsr(object, components, h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forecastfplsr_+3A_object">object</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="forecastfplsr_+3A_components">components</code></td>
<td>
<p>Number of optimal components.</p>
</td></tr>
<tr><td><code id="forecastfplsr_+3A_h">h</code></td>
<td>
<p>Forecast horizon.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>fts</code> class object, containing forecasts of responses.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series&quot; (with discussion), <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.ftsf">plot.ftsf</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A set of functions are decomposed by functional partial least squares decomposition.	
# By forecasting univariate partial least squares scores, the forecasted curves are 
# obtained by multiplying the forecasted scores by fixed functional partial least 
# squares function plus fixed mean function.
forecastfplsr(object = ElNino_ERSST_region_1and2, components = 2, h = 5)
</code></pre>

<hr>
<h2 id='fplsr'>Functional partial least squares regression</h2><span id='topic+fplsr'></span>

<h3>Description</h3>

<p>Fits a functional partial least squares (PLSR) model using nonlinear partial least squares
(NIPALS) algorithm or simple partial least squares (SIMPLS) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fplsr(data, order = 6, type = c("simpls", "nipals"), unit.weights =
 TRUE, weight = FALSE, beta = 0.1, interval = FALSE, method =
  c("delta", "boota"), alpha = 0.05, B = 100, adjust = FALSE,
   backh = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fplsr_+3A_data">data</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_order">order</code></td>
<td>
<p>Number of principal components to fit.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_type">type</code></td>
<td>
<p>When <code>type = "nipals"</code>, uses the NIPALS algorithm; when <code>type = "simpls"</code>, uses the SIMPLS algorithm.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_unit.weights">unit.weights</code></td>
<td>
<p>Constrains predictor loading weights to have unit norm.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_weight">weight</code></td>
<td>
<p>When <code>weight = TRUE</code>, a set of geometrically decaying weights is applied to the decentralized data.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_beta">beta</code></td>
<td>
<p>When <code>weight = TRUE</code>, the speed of geometric decay is governed by a weight parameter.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_interval">interval</code></td>
<td>
<p>When <code>interval = TRUE</code>, produces distributional forecasts.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_method">method</code></td>
<td>
<p>Method used for computing prediction intervals.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_alpha">alpha</code></td>
<td>
<p><code>1-alpha</code> gives the nominal coverage probability.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_b">B</code></td>
<td>
<p>Number of replications.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_adjust">adjust</code></td>
<td>
<p>When <code>adjust = TRUE</code>, an adjustment is performed.</p>
</td></tr>
<tr><td><code id="fplsr_+3A_backh">backh</code></td>
<td>
<p>When <code>adjust = TRUE</code>, an adjustment is performed by evaluating the difference between
predicted and actual values in a testing set. <code>backh</code> specifies the testing set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em><b>Point forecasts:</b></em><br />
</p>
<p>The NIPALS function implements the orthogonal scores algorithm, as described in Martens and Naes (1989).
This is one of the two classical PLSR algorthms, the other is the simple partial least squares regression in DeJong (1993).
The difference between these two approaches is that the NIPALS deflates the original predictors and responses,
while the SIMPLS deflates the covariance matrix of original predictors and responses. Thus, SIMPLS is more computationally efficient than NIPALS.
</p>
<p>In a functional data set, the functional PLSR can be performed by setting the functional responses to be 1 lag ahead of the functional predictors.
This idea has been adopted from the Autoregressive Hilbertian processes of order 1 (ARH(1)) of Bosq (2000).
</p>
<p><em><b>Distributional forecasts:</b></em><br />
</p>
<p><em>Parametric method:</em>
</p>
<p>Influenced by the works of Denham (1997) and Phatak et al. (1993), one way of constructing prediction intervals in the PLSR
is via a local linearization method (also known as the Delta method). It can be easily understood as the first two terms in a Taylor series
expansion. The variance of coefficient estimators can be approximated, from which an analytic-formula based prediction intervals are constructed.
</p>
<p><em>Nonparametric method:</em>
</p>
<p>After discretizing and decentralizing functional data <code class="reqn">f_t(x)</code> and <code class="reqn">g_s(y)</code>, a PLSR model with <code class="reqn">K</code> latent components is built.
Then, the fit residuals <code class="reqn">o_s(y_i)</code> between <code class="reqn">g_s(y_i)</code> and <code class="reqn">\hat{g}_s(y_i)</code> are calculated as
</p>
<p style="text-align: center;"><code class="reqn">o_s(y_i)=g_s(y_i)-\hat{g}_s(y_i), i=1,...,p.</code>
</p>

<p>The next step is to generate <code class="reqn">B</code> bootstrap samples <code class="reqn">o_s^b(y_i)</code> by randomly sampling with replacement
from <code class="reqn">[o_1(y_i),...,o_n(y_i)]</code>. Adding bootstrapped residuals to the original
response variables in order to generate new bootstrap responses,
</p>
<p style="text-align: center;"><code class="reqn">g_s^b(y_i)=g_s(y_i)+o_s^b(y_i).</code>
</p>
<p><br />
Then, the PLSR models are constructed using the centered and discretized predictors and bootstrapped responses
to obtain the boostrapped regression coefficients and point forecasts, from which the empirical prediction intervals and kernel density plots are constructed.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned.
</p>
<table role = "presentation">
<tr><td><code>B</code></td>
<td>
<p><code class="reqn">(p \times m)</code> matrix containing the regression coefficients. <code class="reqn">p</code> is the number of variables in
the predictors and <code class="reqn">m</code> is the number of variables in the responses.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p><code class="reqn">(p \times order)</code> matrix containing the predictor loadings.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p><code class="reqn">(m \times order)</code> matrix containing the response loadings.</p>
</td></tr>
<tr><td><code>T</code></td>
<td>
<p><code>(ncol(data$y)-1) x order</code> matrix containing the predictor scores.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p><code class="reqn">(p\times order)</code> matrix containing the weights used to construct the latent components of predictors.</p>
</td></tr>
<tr><td><code>Yscores</code></td>
<td>
<p><code>(ncol(data$y)-1) x order</code> matrix containing the response scores.</p>
</td></tr>
<tr><td><code>projection</code></td>
<td>
<p><code class="reqn">(p\times order)</code> projection matrix used to convert predictors to predictor scores.</p>
</td></tr>
<tr><td><code>meanX</code></td>
<td>
<p>An object of class <code>fts</code> containing the column means of predictors.</p>
</td></tr>
<tr><td><code>meanY</code></td>
<td>
<p>An object of class <code>fts</code> containing the column means of responses.</p>
</td></tr>
<tr><td><code>Ypred</code></td>
<td>
<p>An object of class <code>fts</code> containing the 1-step-ahead predicted values of the responses.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>An object of class <code>fts</code> containing the fitted values.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>An object of class <code>fts</code> containing the regression residuals.</p>
</td></tr>
<tr><td><code>Xvar</code></td>
<td>
<p>A vector with the amount of predictor variance explained by each number of component.</p>
</td></tr>
<tr><td><code>Xtotvar</code></td>
<td>
<p>Total variance in predictors.</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>
<p>When <code>weight = TRUE</code>, a set of geometrically decaying weights is given. When <code>weight = FALSE</code>, weights are all equal 1.</p>
</td></tr>
<tr><td><code>x1</code></td>
<td>
<p>Time period of a <code>fts</code> object, which can be obtained from <code>colnames(data$y)</code>.</p>
</td></tr>
<tr><td><code>y1</code></td>
<td>
<p>Variables of a <code>fts</code> object, which can be obtained from <code>data$x</code>.</p>
</td></tr>
<tr><td><code>ypred</code></td>
<td>
<p>Returns the original functional predictors.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Returns the original functional responses.</p>
</td></tr>
<tr><td><code>bootsamp</code></td>
<td>
<p>Bootstrapped point forecasts.</p>
</td></tr>
<tr><td><code>lb</code></td>
<td>
<p>Lower bound of prediction intervals.</p>
</td></tr>
<tr><td><code>ub</code></td>
<td>
<p>Upper bound of prediction intervals.</p>
</td></tr>
<tr><td><code>lbadj</code></td>
<td>
<p>Adjusted lower bound of prediction intervals.</p>
</td></tr>
<tr><td><code>ubadj</code></td>
<td>
<p>Adjusted upper bound of prediction intervals.</p>
</td></tr>
<tr><td><code>lbadjfactor</code></td>
<td>
<p>Adjusted lower bound factor, which lies generally between 0.9 and 1.1.</p>
</td></tr>
<tr><td><code>ubadjfactor</code></td>
<td>
<p>Adjusted upper bound factor, which lies generally between 0.9 and 1.1.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>References</h3>

<p>S. Wold and A. Ruhe and H. Wold and W. J. Dunn (1984) &quot;The collinearity problem in linear regression. The partial least squares (PLS) approach to generalized inverses&quot;, <em>SIAM Journal of Scientific and Statistical Computing</em>, <b>5</b>(3), 735-743.
</p>
<p>S. de Jong (1993) &quot;SIMPLS: an alternative approach to partial least square regression&quot;, <em>Chemometrics and Intelligent Laboratory Systems</em>, <b>18</b>(3), 251-263.
</p>
<p>C J. F. Ter Braak and S. de Jong (1993) &quot;The objective function of partial least squares regression&quot;, <em>Journal of Chemometrics</em>, <b>12</b>(1), 41-54.
</p>
<p>B. Dayal and J. MacGregor (1997) &quot;Recursive exponentially weighted PLS and its applications to adaptive	control and prediction&quot;, <em>Journal of Process Control</em>, <b>7</b>(3), 169-179.
</p>
<p>B. D. Marx (1996) &quot;Iteratively reweighted partial least squares estimation for generalized linear regression&quot;, <em>Technometrics</em>, <b>38</b>(4), 374-381.
</p>
<p>L. Xu and J-H. Jiang and W-Q. Lin and Y-P. Zhou and H-L. Wu and G-L. Shen and R-Q. Yu (2007) &quot;Optimized sample-weighted partial least squares&quot;, <em>Talanta</em>, <b>71</b>(2), 561-566.
</p>
<p>A. Phatak and P. Reilly and A. Penlidis (1993) &quot;An approach to interval estimation in partial least squares regression&quot;, <em>Analytica Chimica Acta</em>, <b>277</b>(2), 495-501.
</p>
<p>M. Denham (1997) &quot;Prediction intervals in partial least squares&quot;, <em>Journal of Chemometrics</em>, <b>11</b>(1), 39-52.
</p>
<p>D. Bosq (2000) <em>Linear Processes in Function Spaces</em>, New York: Springer.
</p>
<p>N. Faber (2002) &quot;Uncertainty estimation for multivariate regression coefficients&quot;, <em>Chemometrics and Intelligent Laboratory Systems</em>, <b>64</b>(2), 169-179.
</p>
<p>J. A. Fernandez Pierna and L. Jin and F. Wahl and N. M. Faber and D. L. Massart (2003) &quot;Estimation of partial least squares regression prediction uncertainty when the reference values carry a sizeable measurement error&quot;, <em>Chemometrics and Intelligent Laboratory Systems</em>, <b>65</b>(2), 281-291.
</p>
<p>P. T. Reiss and R. T. Ogden (2007), &quot;Functional principal component regression and functional partial least squares&quot;, <em>Journal of the American Statistical Association</em>, <b>102</b>(479), 984-996.
</p>
<p>C. Preda, G. Saporta (2005) &quot;PLS regression on a stochastic process&quot;, <em>Computational Statistics and Data Analysis</em>, <b>48</b>(1), 149-158.
</p>
<p>C. Preda, G. Saporta, C. Leveder (2007) &quot;PLS classification of functional data&quot;, <em>Computational Statistics</em>, <b>22</b>, 223-235.
</p>
<p>A. Delaigle and P. Hall (2012), &quot;Methodology and theory for partial least squares applied to functional data&quot;, <em>Annals of Statistics</em>, <b>40</b>(1), 322-352.
</p>
<p>M. Febrero-Bande, P. Galeano, W. Gonz\'alez-Manteiga (2017), &quot;Functional principal component regression and functional partial least-squares regression: An overview and a comparative study&quot;, <em>International Statistical Review</em>, <b>85</b>(1), 61-83.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>,
<code><a href="#topic+summary.fm">summary.fm</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+plot.fmres">plot.fmres</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># When weight = FALSE, all observations are assigned equally.
# When weight = TRUE, all observations are assigned geometrically decaying weights.
fplsr(data = ElNino_ERSST_region_1and2, order = 6, type = "nipals")
fplsr(data = ElNino_ERSST_region_1and2, order = 6)
fplsr(data = ElNino_ERSST_region_1and2, weight = TRUE)
fplsr(data = ElNino_ERSST_region_1and2, unit.weights = FALSE)
fplsr(data = ElNino_ERSST_region_1and2, unit.weights = FALSE, weight = TRUE)

# The prediction intervals are calculated numerically.
fplsr(data = ElNino_ERSST_region_1and2, interval = TRUE, method = "delta")

# The prediction intervals are calculated by bootstrap method.
fplsr(data = ElNino_ERSST_region_1and2, interval = TRUE, method = "boota")
</code></pre>

<hr>
<h2 id='ftsm'>Fit functional time series model</h2><span id='topic+ftsm'></span>

<h3>Description</h3>

<p>Fits a principal component model to a <code>fts</code> object. The
function uses optimal orthonormal principal components obtained from a
principal components decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ftsm(y, order = 6, ngrid = max(500, ncol(y$y)), method = c("classical", 
 "M", "rapca"), mean = TRUE, level = FALSE, lambda = 3, 
  weight = FALSE, beta = 0.1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ftsm_+3A_y">y</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_order">order</code></td>
<td>
<p>Number of principal components to fit.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_ngrid">ngrid</code></td>
<td>
<p>Number of grid points to use in calculations. Set to maximum of 500 and <code>ncol(y$y)</code>.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_method">method</code></td>
<td>
<p>Method to use for principal components decomposition. Possibilities are &ldquo;M&rdquo;, &ldquo;rapca&rdquo; and &ldquo;classical&rdquo;.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_mean">mean</code></td>
<td>
<p>If <code>mean = TRUE</code>, it will estimate mean term in the model before computing basis terms. 
If <code>mean = FALSE</code>, the mean term is assumed to be zero.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_level">level</code></td>
<td>
<p>If <code>mean = TRUE</code>, it will include an additional (intercept) term that depends on <code class="reqn">t</code> but not on <code class="reqn">x</code>.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_lambda">lambda</code></td>
<td>
<p>Tuning parameter for robustness when <code>method = "M"</code>.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_weight">weight</code></td>
<td>
<p>When <code>weight = TRUE</code>, a set of geometrically decaying weights is applied to the decentralized data.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_beta">beta</code></td>
<td>
<p>When <code>weight = TRUE</code>, the speed of geometric decay is governed by a weight parameter.</p>
</td></tr>
<tr><td><code id="ftsm_+3A_...">...</code></td>
<td>
<p>Additional arguments controlling the fitting procedure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "classical"</code>, then standard functional principal component decomposition is used, as described by
Ramsay and Dalzell (1991). 
</p>
<p>If <code>method = "rapca"</code>, then the robust principal component algorithm of Hubert, Rousseeuw and Verboven (2002) is used. 
</p>
<p>If <code>method = "M"</code>, then the hybrid algorithm of Hyndman and Ullah (2005) is used.
</p>


<h3>Value</h3>

<p>Object of class &ldquo;ftsm&rdquo; with the following components:
</p>
<table role = "presentation">
<tr><td><code>x1</code></td>
<td>
<p>Time period of a <code>fts</code> object, which can be obtained from <code>colnames(y$y)</code>.</p>
</td></tr>
<tr><td><code>y1</code></td>
<td>
<p>Variables of a <code>fts</code> object, which can be obtained from <code>y$x</code>.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Original functional time series or sliced functional time series.</p>
</td></tr>
<tr><td><code>basis</code></td>
<td>
<p>Matrix of principal components evaluated at value of <code>y$x</code> (one column for each principal component).
The first column is the fitted mean or median.</p>
</td></tr>
<tr><td><code>basis2</code></td>
<td>
<p>Matrix of principal components excluded from the selected model.</p>
</td></tr>
<tr><td><code>coeff</code></td>
<td>
<p>Matrix of coefficients (one column for each coefficient series). The first column is all ones.</p>
</td></tr>
<tr><td><code>coeff2</code></td>
<td>
<p>Matrix of coefficients associated with the principal components excluded from the selected model.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>An object of class <code>fts</code> containing the fitted values.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>An object of class <code>fts</code> containing the regression residuals (difference between observed and fitted).</p>
</td></tr>
<tr><td><code>varprop</code></td>
<td>
<p>Proportion of variation explained by each principal component.</p>
</td></tr>
<tr><td><code>wt</code></td>
<td>
<p>Weight associated with each time period.</p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>Measure of variation for each time period.</p>
</td></tr>
<tr><td><code>mean.se</code></td>
<td>
<p>Measure of standar error associated with the mean.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>References</h3>

<p>J. O. Ramsay and C. J. Dalzell (1991) &quot;Some tools for functional data analysis (with discussion)&quot;, <em>Journal of the Royal Statistical Society: Series B</em>, <b>53</b>(3), 539-572.
</p>
<p>M. Hubert and P. J. Rousseeuw and S. Verboven (2002) &quot;A fast robust method for principal components with applications to chemometrics&quot;, <em>Chemometrics and Intelligent Laboratory Systems</em>, <b>60</b>(1-2), 101-111.
</p>
<p>B. Erbas and R. J. Hyndman and D. M. Gertig (2007) &quot;Forecasting age-specific breast cancer mortality using functional data model&quot;, <em>Statistics in Medicine</em>, <b>26</b>(2), 458-470.
</p>
<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>R. J. Hyndman and H. Booth (2008) &quot;Stochastic population forecasts using functional data models for mortality, fertility and migration&quot;, <em>International Journal of Forecasting</em>, <b>24</b>(3), 323-342.
</p>
<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series (with discussion)&quot;, <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsmweightselect">ftsmweightselect</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.ftsf">plot.ftsf</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ElNino is an object of class sliced functional time series, constructed 
# from a univariate time series. 
# By default, all observations are assigned with equal weighting. 	
ftsm(y = ElNino_ERSST_region_1and2, order = 6, method = "classical", weight = FALSE)
# When weight = TRUE, geometrically decaying weights are used.
ftsm(y = ElNino_ERSST_region_1and2, order = 6, method = "classical", weight = TRUE)
</code></pre>

<hr>
<h2 id='ftsmiterativeforecasts'>Forecast functional time series</h2><span id='topic+ftsmiterativeforecasts'></span>

<h3>Description</h3>

<p>The coefficients from the fitted object are forecasted
using either an ARIMA model (<code>method = "arima"</code>), an AR model (<code>method = "ar"</code>), 
an exponential smoothing method (<code>method = "ets"</code>), a linear exponential smoothing 
method allowing missing values (<code>method = "ets.na"</code>), or a random walk with drift model 
(<code>method = "rwdrift"</code>). The forecast coefficients are then multiplied by the principal 
components to obtain a forecast curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ftsmiterativeforecasts(object, components, iteration = 20)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ftsmiterativeforecasts_+3A_object">object</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="ftsmiterativeforecasts_+3A_components">components</code></td>
<td>
<p>Number of principal components.</p>
</td></tr>
<tr><td><code id="ftsmiterativeforecasts_+3A_iteration">iteration</code></td>
<td>
<p>Number of iterative one-step-ahead forecasts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1. Obtain a smooth curve <code class="reqn">f_t(x)</code> for each <code class="reqn">t</code> using a nonparametric smoothing technique.
</p>
<p>2. Decompose the smooth curves via a functional principal component analysis.
</p>
<p>3. Fit a univariate time series model to each of the principal component scores.
</p>
<p>4. Forecast the principal component scores using the fitted time series models.
</p>
<p>5. Multiply the forecast principal component scores by fixed principal components to obtain forecasts of <code class="reqn">f_{n+h}(x)</code>.
</p>
<p>6. The estimated variances of the error terms (smoothing error and model residual error) are used to compute prediction intervals for the forecasts.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table role = "presentation">
<tr><td><code>mean</code></td>
<td>
<p>An object of class <code>fts</code> containing point forecasts.</p>
</td></tr>
<tr><td><code>lower</code></td>
<td>
<p>An object of class <code>fts</code> containing lower bound for prediction intervals.</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>An object of class <code>fts</code> containing upper bound for prediction intervals.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>An object of class <code>fts</code> of one-step-ahead forecasts for historical data.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>An object of class <code>fts</code> of one-step-ahead errors for historical data.</p>
</td></tr>
<tr><td><code>coeff</code></td>
<td>
<p>List of objects of type <code>forecast</code> containing the coefficients and their forecasts.</p>
</td></tr>
<tr><td><code>coeff.error</code></td>
<td>
<p>One-step-ahead forecast errors for each of the coefficients.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>List containing the various components of variance: model, error, mean, total and coeff.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Fitted <code><a href="#topic+ftsm">ftsm</a></code> model.</p>
</td></tr>
<tr><td><code>bootsamp</code></td>
<td>
<p>An array of <code class="reqn">dim = c(p, B, h)</code> containing the bootstrapped point forecasts. 
<code class="reqn">p</code> is the number of variables. <code class="reqn">B</code> is the number of bootstrap samples.
<code class="reqn">h</code> is the forecast horizon.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>H. Booth and R. J. Hyndman and L. Tickle and P. D. Jong (2006) &quot;Lee-Carter mortality forecasting: A multi-country comparison of variants and extensions&quot;, <em>Demographic Research</em>, <b>15</b>, 289-310.
</p>
<p>B. Erbas and R. J. Hyndman and D. M. Gertig (2007) &quot;Forecasting age-specific breast cancer mortality using functional data model&quot;, <em>Statistics in Medicine</em>, <b>26</b>(2), 458-470.
</p>
<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>R. J. Hyndman and H. Booth (2008) &quot;Stochastic population forecasts using functional data models for mortality, fertility and migration&quot;, <em>International Journal of Forecasting</em>, <b>24</b>(3), 323-342.
</p>
<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series&quot; (with discussion), <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+plot.ftsf">plot.ftsf</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Iterative one-step-ahead forecasts via functional principal component analysis.	
ftsmiterativeforecasts(object = Australiasmoothfertility, components = 2, iteration = 5)
</code></pre>

<hr>
<h2 id='ftsmweightselect'>
Selection of the weight parameter used in the weighted functional time series model.
</h2><span id='topic+ftsmweightselect'></span>

<h3>Description</h3>

<p>The geometrically decaying weights are used to estimate the mean curve and functional principal components, where more weights are assigned to the more recent data than the data from the distant past.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ftsmweightselect(data, ncomp = 6, ntestyear, errorcriterion = c("mae", "mse", "mape"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ftsmweightselect_+3A_data">data</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="ftsmweightselect_+3A_ncomp">ncomp</code></td>
<td>
<p>Number of components.</p>
</td></tr>
<tr><td><code id="ftsmweightselect_+3A_ntestyear">ntestyear</code></td>
<td>
<p>Number of holdout observations used to assess the forecast accuracy.</p>
</td></tr>
<tr><td><code id="ftsmweightselect_+3A_errorcriterion">errorcriterion</code></td>
<td>
<p>Error measure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data set is split into a fitting period and forecasting period. Using the data in the fitting period, we compute the one-step-ahead forecasts and calculate
the forecast error. Then, we increase the fitting period by one, and carry out the same forecasting procedure until the fitting period covers entire data set. 
The forecast accuracy is determined by the averaged forecast error across the years in the forecasting period. By using an optimization algorithm, we select the
optimal weight parameter that would result in the minimum forecast error.
</p>


<h3>Value</h3>

<p>Optimal weight parameter.
</p>


<h3>Note</h3>

<p>Can be computational intensive, as it takes about half-minute to compute. For example, ftsmweightselect(ElNinosmooth, ntestyear = 1).
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series (with discussion)&quot;, <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>
</p>

<hr>
<h2 id='GAEVforecast'>
Fit a generalized additive extreme value model to the functional data with given basis numbers
</h2><span id='topic+GAEVforecast'></span>

<h3>Description</h3>

<p>One-step-ahead forecast for any given quantile(s) of functional time sereies of extreme values using a generalized additive extreme value (GAEV) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GAEVforecast(data, q, d.loc.max = 10, d.logscale.max = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GAEVforecast_+3A_data">data</code></td>
<td>
<p>a n by p data matrix, where n denotes the number of functional objects and p denotes the number of realizations on each functional object</p>
</td></tr>
<tr><td><code id="GAEVforecast_+3A_q">q</code></td>
<td>
<p>a required scalar or vector of GEV quantiles that are of forecasting interest</p>
</td></tr>
<tr><td><code id="GAEVforecast_+3A_d.loc.max">d.loc.max</code></td>
<td>
<p>the maximum number of basis functions considered for the location parameter</p>
</td></tr>
<tr><td><code id="GAEVforecast_+3A_d.logscale.max">d.logscale.max</code></td>
<td>
<p>the maximum number of basis functions considered for the (log-)scale parameter</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the functional time seres <code class="reqn">\{X_t(u),t=1,...,T,u\in \mathcal{I}\}</code>, the GAEV model is given as
</p>
<p style="text-align: center;"><code class="reqn">
X_{t}(u) ~ GEV[\mu_{t}(u),\sigma_t(u),\xi_t], 
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
\mu_t(u) = \beta^{(\mu)}_{t,0} + \sum_{i=1}^{d_1}\beta^{(\mu)}_{t,i}b^{(\mu)}_{i}(u),
</code>
</p>

<p style="text-align: center;"><code class="reqn">
\ln(\sigma_t(u)) = \beta^{(\sigma)}_{t,0} + \sum_{i=1}^{d_2}\beta^{(\sigma)}_{t,i}b^{(\sigma)}_{i}(u), \xi_t \in [0,\infty),
</code>
</p>

<p>where <code class="reqn">d_{j},j=1,2</code> are positive integers of basis numbers, <code class="reqn">\{b^{(\mu)}_{i}(u),i=1,\dots,d_{1}\}</code> and <code class="reqn">\{b^{(\sigma)}_{i}(u),i=1,\dots,d_{2}\}</code> are the cubic regression spline basis functions.
</p>
<p>The optimal number of basis functions <code class="reqn">(d_1,d_2)</code> are chosen by minimizing the Kullback-Leibler divergence on the test set using a leave-one-out cross-validation technique.
</p>
<p>The one-step-ahead forecast of the joint coefficients <code class="reqn">(\widehat{\beta^{(\mu)}}_{T+1,i},\widehat{\beta^{(\sigma)}}_{T+1,j},\widehat{\xi}_{T+1},i=0,...,d_1,j=0,...,d_2)</code> are produced using a vector autoregressive model, whose order is selected via the corrected Akaike information criterion. Then the one-step-ahead forecast of the GEV parameter <code class="reqn">(\widehat{\mu}_{T+1}(u),\widehat{\sigma}_{T+1}(u),\widehat{\xi}_{T+1})</code> can be computed accordingly.
</p>
<p>The one-step-ahead forecast for the <code class="reqn">\tau</code>-th quantile of the extreme values <code class="reqn">\widehat{X}_{T+1}(u)</code> is computed by
</p>
<p style="text-align: center;"><code class="reqn">
    Q_{\tau}(u|\widehat{\mu}_{T+1},\widehat{\sigma}_{T+1},\widehat{\xi}_{T+1})</code>
</p>

<p>= </p>
<p style="text-align: center;"><code class="reqn">
   \widehat{\mu}_{T+1}(u) + \frac{\widehat{\sigma}_{T+1}(u) \big[(-\ln(\tau))^{-\widehat{\xi}_{T+1}}-1\big]}{\widehat{\xi}_{T+1}},  \xi &gt; 0, \tau\in [0,1);\ \xi &lt; 0, \tau\in (0,1], \\
   \widehat{\mu}_{T+1}(u) - \widehat{\sigma}_{T+1}(u) \cdot \ln[-\ln\big(\tau)], \xi=0, \tau \in (0,1).
</code>
</p>



<h3>Value</h3>

<table role = "presentation">
<tr><td><code>kdf.location</code></td>
<td>
<p>the optimal number of basis functions considered for the location parameter</p>
</td></tr>
<tr><td><code>kdf.logscale</code></td>
<td>
<p>the optimal number of basis functions considered for the (log-)scale parameter</p>
</td></tr>
<tr><td><code>basis.location</code></td>
<td>
<p>the basis functions for the location parameter</p>
</td></tr>
<tr><td><code>basis.logscale</code></td>
<td>
<p>the basis functions for the (log-)scale parameter</p>
</td></tr>
<tr><td><code>para.location.pred</code></td>
<td>
<p>the predicted location function</p>
</td></tr>
<tr><td><code>para.scale.pred</code></td>
<td>
<p>the predicted scale function</p>
</td></tr>
<tr><td><code>para.shape.pred</code></td>
<td>
<p>the predicted shape parameter</p>
</td></tr>
<tr><td><code>density.pred</code></td>
<td>
<p>the prediced density function(s) for the given quantile(s)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ruofan Xu and Han Lin Shang
</p>


<h3>References</h3>

<p>Shang, H. L. and Xu, R. (2021) &lsquo;Functional time series forecasting of extreme values&rsquo;, <em>Communications in Statistics Case Studies Data Analysis and Applications</em>, <b>in press</b>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(evd)
data = matrix(rgev(1000),ncol=50) 
GAEVforecast(data = data, q = c(0.02,0.7), d.loc.max = 5, d.logscale.max = 5)

## End(Not run)
</code></pre>

<hr>
<h2 id='hd_data'>
Simulated high-dimensional functional time series
</h2><span id='topic+hd_data'></span>

<h3>Description</h3>

<p>We generate <code class="reqn">N</code> populations of functional time series. For each <code class="reqn">i\in \{1,\dots, N\}</code>, the <code class="reqn">i</code>th function at time <code class="reqn">t\in \{1,\dots, T\}</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">X_t^{(i)}(u) = \sum^2_{p=1}\beta_{p,t}^{(i)}\gamma_p^{(i)}(u) + \theta_t^{(i)}(u),</code>
</p>

<p>where <code class="reqn">\theta_t^{(i)}(u) = \sum^{\infty}_{p=3}\beta_{p,t}^{(i)}\gamma_p^{(i)}(u)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("hd_data")
</code></pre>


<h3>Details</h3>

<p>The coefficients <code class="reqn">\beta_{p,t}^{(i)}</code> for all <code class="reqn">N</code> populations are combined and generated, for all <code class="reqn">p\in N</code>, by
</p>
<p style="text-align: center;"><code class="reqn">\bm{\beta}_{p,t} = \bm{A}_p\bm{f}_{p,t},</code>
</p>

<p>where <code class="reqn">\bm{\beta}_{p,t}=\{\beta_{p,t}^{1},\dots,\beta_{p,t}^N\}</code>. Here, <code class="reqn">\bm{A}_p</code> is an <code class="reqn">N\times N</code> matrix, and <code class="reqn">\bm{f}_{p,t}</code> is an <code class="reqn">N\times 1</code> vector. Furthermore, we assume that the <code class="reqn">\beta_{p,t}^{(i)}</code>s have mean 0 and variance 0 when <code class="reqn">p&gt;3</code>, so we only construct the coefficients <code class="reqn">\bm{\beta}_{p,t}</code> for <code class="reqn">p\in\{1, 2, 3\}</code>.
</p>
<p>The first set of coefficients <code class="reqn">\bm{\beta}_{1,t}</code> for <code class="reqn">N</code> populations are generated with <code class="reqn">\bm{\beta}_{1,t}=\bm{A}_1\bm{f}_{1,t}</code>. Each element in the matrix <code class="reqn">\bm{A}_1</code> is generated by <code class="reqn">a_{ij}=N^{-1/4}\times b_{ij}</code>, where <code class="reqn">b_{ij}\sim N(2,4)</code>.
</p>
<p>The factors <code class="reqn">\bm{f}_{1,t}</code> are generated using an autoregressive model of order 1, i.e., AR(1). Define the <code class="reqn">i</code>th element in vector <code class="reqn">\bm{f}_{1,t}</code> as <code class="reqn">f_{1,t}^{(i)}</code>. Then, <code class="reqn">f_{1,t}^{1}</code> is generated by <code class="reqn">f_{1,t}^{1}=0.5\times f_{1,t-1}^{1}+\omega_t</code>, where <code class="reqn">\omega_t</code> are independent <code class="reqn">N(0,1)</code> random variables. We generate <code class="reqn">f_{1,t}^{(i)}</code> for all <code class="reqn">i\in \{2,\dots, N\}</code> by <code class="reqn">f_{1,t}^{(i)}=(1/N) \times g_t^{(i)}</code>, where <code class="reqn">g_t^{(2)},\dots,g_t^{(N)}</code> are also AR(1) and follow <code class="reqn">g_t^{(i)} = 0.2\times g_{t-1}^{(i)}+\omega_t</code>. It is then ensured that most of the variance of <code class="reqn">\bm{\beta}_{1,t}</code> can be explained by one factor. The second coefficient <code class="reqn">\bm{\beta}_{2,t}</code> are constructed the same way as <code class="reqn">\bm{\beta}_{1,t}</code>.
</p>
<p>We also generate the third functional principal component scores <code class="reqn">\bm{\beta}_{3,t}</code> but with small values. Moreover, <code class="reqn">\bm{A}_3</code> is generated by <code class="reqn">a_{ij}=N^{-1/4}\times b_{ij}</code>, where <code class="reqn">b_{ij}\sim N(0, 0.04)</code>. The factors <code class="reqn">bm{f}_{3,t}</code> are generated as <code class="reqn">\bm{f}_{1,t}</code>.
</p>
<p>The three basis functions are constructed by <code class="reqn">\gamma_1^{(i)}(u) = \sin(2\pi u + \pi i/2)</code>, <code class="reqn">\gamma_2^{(i)}(u) = \cos(2\pi u + \pi i/2)</code> and <code class="reqn">\gamma_3^{(i)}(u) = \sin(4\pi u + \pi i/2)</code>, where <code class="reqn">u\in [0,1]</code>. Finally, the functional time series for the <code class="reqn">i</code>th population is constructed by
</p>
<p style="text-align: center;"><code class="reqn">\bm{X}_t^{(i)}(u) = \bm{\beta}_{1,t}\gamma_1^{(i)}(u) + \bm{\beta}_{2,t}\gamma_2^{(i)}(u) + \bm{\beta}_{3,t}\gamma_3^{(i)}(u),</code>
</p>

<p>where <code class="reqn">(\cdot)_i</code> denotes the <code class="reqn">i</code>th element of the vector.
</p>


<h3>References</h3>

<p>Y. Gao, H. L. Shang and Y. Yang (2018) High-dimensional functional time series forecasting: An application to age-specific mortality rates, <em>Journal of Multivariate Analysis</em>, <b>forthcoming</b>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hdfpca">hdfpca</a></code>, <code><a href="#topic+forecast.hdfpca">forecast.hdfpca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hd_data)
</code></pre>

<hr>
<h2 id='hdfpca'>
High-dimensional functional principal component analysis
</h2><span id='topic+hdfpca'></span>

<h3>Description</h3>

<p>Fit a high dimensional functional principal component analysis model to a multiple-population of functional time series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdfpca(y, order, q = sqrt(dim(y[[1]])[2]), r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hdfpca_+3A_y">y</code></td>
<td>
<p>A list, where each item is a population of functional time series. Each item is a data matrix of dimension p by n, where p is the number of discrete points in each function and n is the sample size</p>
</td></tr>
<tr><td><code id="hdfpca_+3A_order">order</code></td>
<td>
<p>The number of principal component scores to retain in the first step dimension reduction</p>
</td></tr>
<tr><td><code id="hdfpca_+3A_q">q</code></td>
<td>
<p>The tuning parameter used in the first step dimension reduction, by default it is equal to the square root of the sample size</p>
</td></tr>
<tr><td><code id="hdfpca_+3A_r">r</code></td>
<td>
<p>The number of factors to retain in the second step dimension reduction</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the first step, dynamic functional principal component analysis is performed on each population and then in the second step, factor models are fitted to the resulting principal component scores. The high-dimensional functional time series are thus reduced to low-dimensional factors.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>y</code></td>
<td>
<p>The input data</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>The number of discrete points in each function</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>A list containing the fitted functions for each population</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>The number of populations</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Model 1 includes the first step dynamic functional principal component analysis models, model 2 includes the second step high-dimensional principal component analysis models</p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>Input order</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>Input r</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Y. Gao and H. L. Shang
</p>


<h3>References</h3>

<p>Y. Gao, H. L. Shang and Y. Yang (2018) High-dimensional functional time series forecasting: An application to age-specific mortality rates, <em>Journal of Multivariate Analysis</em>, <b>forthcoming</b>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+forecast.hdfpca">forecast.hdfpca</a></code>, <code><a href="#topic+hd_data">hd_data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hd_model = hdfpca(hd_data, order = 2, r = 2)
</code></pre>

<hr>
<h2 id='Horta_Ziegelmann_FPCA'>
Dynamic functional principal component analysis for density forecasting
</h2><span id='topic+Horta_Ziegelmann_FPCA'></span>

<h3>Description</h3>

<p>Implementation of a dynamic functional principal component analysis to forecast densities.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Horta_Ziegelmann_FPCA(data, gridpoints, h_scale = 1, p = 5, m = 5001, 
	kernel = c("gaussian", "epanechnikov"), band_choice = c("Silverman", "DPI"), 
	VAR_type = "both", lag_maximum = 6, no_boot = 1000, alpha_val = 0.1, 
	ncomp_select = "TRUE", D_val = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_data">data</code></td>
<td>
<p>Densities or raw data matrix of dimension N by p, where N denotes sample size and p denotes dimensionality</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_gridpoints">gridpoints</code></td>
<td>
<p>Grid points</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_h_scale">h_scale</code></td>
<td>
<p>Scaling parameter in the kernel density estimator</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_p">p</code></td>
<td>
<p>Number of backward parameters </p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_m">m</code></td>
<td>
<p>Number of grid points</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_kernel">kernel</code></td>
<td>
<p>Type of kernel function</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_band_choice">band_choice</code></td>
<td>
<p>Selection of optimal bandwidth</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_var_type">VAR_type</code></td>
<td>
<p>Type of vector autoregressive process</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_lag_maximum">lag_maximum</code></td>
<td>
<p>A tuning parameter in the <code>super_fun</code> function</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_no_boot">no_boot</code></td>
<td>
<p>A tuning parameter in the <code>super_fun</code> function</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_alpha_val">alpha_val</code></td>
<td>
<p>A tuning parameter in the <code>super_fun</code> function</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_ncomp_select">ncomp_select</code></td>
<td>
<p>A tuning parameter in the <code>super_fun</code> function</p>
</td></tr>
<tr><td><code id="Horta_Ziegelmann_FPCA_+3A_d_val">D_val</code></td>
<td>
<p>A tuning parameter in the <code>super_fun</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1) Compute a kernel covariance function
2) Via eigen-decomposition, a density can be decomposed into a set of functional principal components and their associated scores
3) Fit a vector autoregressive model to the scores with the order selected by Akaike information criterion
4) By multiplying the estimated functional principal components with the forecast scores, obtain forecast densities
5) Since forecast densities may neither be non-negative nor sum to one, normalize the forecast densities accordingly
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Yhat.fix_den</code></td>
<td>
<p>Forecast density</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>Grid points</p>
</td></tr>
<tr><td><code>du</code></td>
<td>
<p>Distance between two successive grid points</p>
</td></tr>
<tr><td><code>Ybar_est</code></td>
<td>
<p>Mean of density functions</p>
</td></tr>
<tr><td><code>psihat_est</code></td>
<td>
<p>Estimated functional principal components</p>
</td></tr>
<tr><td><code>etahat_est</code></td>
<td>
<p>Estimated principal component scores</p>
</td></tr>
<tr><td><code>etahat_pred_val</code></td>
<td>
<p>Forecast principal component scores</p>
</td></tr>
<tr><td><code>selected_d0</code></td>
<td>
<p>Selected number of components</p>
</td></tr>
<tr><td><code>selected_d0_pvalues</code></td>
<td>
<p>p-values associated with the selected functional principal components</p>
</td></tr>
<tr><td><code>thetahat_val</code></td>
<td>
<p>Estimated eigenvalues</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>Horta, E. and Ziegelmann, F. (2018) &lsquo;Dynamics of financial returns densities: A functional approach applied to the Bovespa intraday index&rsquo;, <em>International Journal of Forecasting</em>, <b>34</b>, 75-88.
</p>
<p>Bathia, N., Yao, Q. and Ziegelmann, F. (2010) &lsquo;Identifying the finite dimensionality of curve time series&rsquo;, <em>The Annals of Statistics</em>, <b>38</b>, 3353-3386.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoDa_FPCA">CoDa_FPCA</a></code>, <code><a href="#topic+LQDT_FPCA">LQDT_FPCA</a></code>, <code><a href="#topic+skew_t_fun">skew_t_fun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Horta_Ziegelmann_FPCA(data = DJI_return, kernel = "epanechnikov", 
				band_choice = "DPI", ncomp_select = "FALSE")

## End(Not run)
</code></pre>

<hr>
<h2 id='is.fts'>Test for functional time series</h2><span id='topic+is.fts'></span>

<h3>Description</h3>

<p>Tests whether an object is of class <code>fts</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.fts(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.fts_+3A_x">x</code></td>
<td>
<p>Arbitrary R object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>Examples</h3>

<pre><code class='language-R'># check if ElNino is the class of the functional time series.	
is.fts(x = ElNino_ERSST_region_1and2)
</code></pre>

<hr>
<h2 id='isfe.fts'>Integrated Squared Forecast Error for models of various orders</h2><span id='topic+isfe.fts'></span>

<h3>Description</h3>

<p>Computes integrated squared forecast error (ISFE) values for functional time series models of various orders.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isfe.fts(data, max.order = N - 3, N = 10, h = 5:10, method = 
 c("classical", "M", "rapca"), mean = TRUE, level = FALSE, 
  fmethod = c("arima", "ar", "ets", "ets.na", "struct", "rwdrift", 
   "rw", "arfima"), lambda = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isfe.fts_+3A_data">data</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_max.order">max.order</code></td>
<td>
<p>Maximum number of principal components to fit.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_n">N</code></td>
<td>
<p>Minimum number of functional observations to be used in fitting a model.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_h">h</code></td>
<td>
<p>Forecast horizons over which to average.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_method">method</code></td>
<td>
<p>Method to use for principal components decomposition. Possibilities are &ldquo;M&rdquo;, &ldquo;rapca&rdquo; and &ldquo;classical&rdquo;.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_mean">mean</code></td>
<td>
<p>Indicates if mean term should be included.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_level">level</code></td>
<td>
<p>Indicates if level term should be included.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_fmethod">fmethod</code></td>
<td>
<p>Method used for forecasting. Current possibilities are &ldquo;ets&rdquo;, &ldquo;arima&rdquo;, &ldquo;ets.na&rdquo;,
&ldquo;struct&rdquo;, &ldquo;rwdrift&rdquo; and &ldquo;rw&rdquo;.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_lambda">lambda</code></td>
<td>
<p>Tuning parameter for robustness when <code>method = "M"</code>.</p>
</td></tr>
<tr><td><code id="isfe.fts_+3A_...">...</code></td>
<td>
<p>Additional arguments controlling the fitting procedure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric matrix with <code>(max.order+1)</code> rows and <code>length(h)</code> columns
containing ISFE values for models of orders <code>0:(max.order)</code>. 
</p>


<h3>Note</h3>

<p>This function can be very time consuming for data with large dimensionality or large sample size.
By setting <code>max.order</code> small, computational speed can be dramatically increased.
</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>References</h3>

<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.fmres">plot.fmres</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code></p>

<hr>
<h2 id='long_run_covariance_estimation'>
Estimating long-run covariance function for a functional time series
</h2><span id='topic+long_run_covariance_estimation'></span>

<h3>Description</h3>

<p>Bandwidth estimation in the long-run covariance function for a functional time series, using different types of kernel function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>long_run_covariance_estimation(dat, C0 = 3, H = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="long_run_covariance_estimation_+3A_dat">dat</code></td>
<td>
<p>A matrix of p by n, where p denotes the number of grid points and n denotes sample size</p>
</td></tr>
<tr><td><code id="long_run_covariance_estimation_+3A_c0">C0</code></td>
<td>
<p>A tuning parameter used in the adaptive bandwidth selection algorithm of Rice</p>
</td></tr>
<tr><td><code id="long_run_covariance_estimation_+3A_h">H</code></td>
<td>
<p>A tuning parameter used in the adaptive bandwidth selection algorithm of Rice</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An estimated covariance function of size (p by p)
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>L. Horvath, G. Rice and S. Whipple (2016) Adaptive bandwidth selection in the long run covariance estimation of functional time series, <em>Computational Statistics and Data Analysis</em>, <b>100</b>, 676-693.
</p>
<p>G. Rice and H. L. Shang (2017) A plug-in bandwidth selection procedure for long run covariance estimation with stationary functional time series, <em>Journal of Time Series Analysis</em>, <b>38</b>(4), 591-609.
</p>
<p>D. Li, P. M. Robinson and H. L. Shang (2018) Long-range dependent curve time series, <em>Journal of the American Statistical Association: Theory and Methods</em>, under revision.
</p>


<h3>See Also</h3>

<p><code><a href="rainbow.html#topic+fts">fts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dum = long_run_covariance_estimation(dat = ElNino_OISST_region_1and2$y[,1:5])
</code></pre>

<hr>
<h2 id='LQDT_FPCA'>
Log quantile density transform
</h2><span id='topic+LQDT_FPCA'></span>

<h3>Description</h3>

<p>Probability density function, cumulative distribution function and quantile density function are three characterizations of a distribution. Of these three, quantile density function is the least constrained. The only constrain is nonnegative. By taking a log transformation, there is no constrain. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LQDT_FPCA(data, gridpoints, h_scale = 1, M = 3001, m = 5001, lag_maximum = 4, 
		no_boot = 1000, alpha_val = 0.1, p = 5, 
		band_choice = c("Silverman", "DPI"), 
		kernel = c("gaussian", "epanechnikov"), 
		forecasting_method = c("uni", "multi"), 
		varprop = 0.85, fmethod, VAR_type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LQDT_FPCA_+3A_data">data</code></td>
<td>
<p>Densities or raw data matrix of dimension N by p, where N denotes sample size and p denotes dimensionality</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_gridpoints">gridpoints</code></td>
<td>
<p>Grid points</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_h_scale">h_scale</code></td>
<td>
<p>Scaling parameter in the kernel density estimator</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_m">M</code></td>
<td>
<p>Number of grid points between 0 and 1</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_m">m</code></td>
<td>
<p>Number of grid points within the data range</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_lag_maximum">lag_maximum</code></td>
<td>
<p>A tuning parameter in the <code>super_fun</code> function</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_no_boot">no_boot</code></td>
<td>
<p>A tuning parameter in the <code>super_fun</code> function</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_alpha_val">alpha_val</code></td>
<td>
<p>A tuning parameter in the <code>super_fun</code> function</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_p">p</code></td>
<td>
<p>Number of backward parameters</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_band_choice">band_choice</code></td>
<td>
<p>Selection of optimal bandwidth</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_kernel">kernel</code></td>
<td>
<p>Type of kernel function</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_forecasting_method">forecasting_method</code></td>
<td>
<p>Univariate or multivariate time series forecasting method</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_varprop">varprop</code></td>
<td>
<p>Proportion of variance explained</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_fmethod">fmethod</code></td>
<td>
<p>If <code>forecasting_method = "uni"</code>, specify a particular forecasting method</p>
</td></tr>
<tr><td><code id="LQDT_FPCA_+3A_var_type">VAR_type</code></td>
<td>
<p>If <code>forecasting_method = "multi"</code>, specify a particular type of vector autoregressive model</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1) Transform the densities f into log quantile densities Y and c specifying the value of the cdf at 0 for the target density f.
2) Compute the predictions for future log quantile density and c value.
3) Transform the forecasts in Step 2) into the predicted density f.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>L2Diff</code></td>
<td>
<p>L2 norm difference between reconstructed and actual densities</p>
</td></tr>
<tr><td><code>unifDiff</code></td>
<td>
<p>Uniform Metric excluding missing boundary values (due to boundary cutoff)</p>
</td></tr>
<tr><td><code>density_reconstruct</code></td>
<td>
<p>Reconstructed densities</p>
</td></tr>
<tr><td><code>density_original</code></td>
<td>
<p>Actual densities</p>
</td></tr>
<tr><td><code>dens_fore</code></td>
<td>
<p>Forecast densities</p>
</td></tr>
<tr><td><code>totalMass</code></td>
<td>
<p>Assess loss of mass incurred by boundary cutoff</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>m number of grid points</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>Petersen, A. and Muller, H.-G. (2016) &lsquo;Functional data analysis for density functions by transformation to a Hilbert space&rsquo;, <em>The Annals of Statistics</em>, <b>44</b>, 183-218.
</p>
<p>Jones, M. C. (1992) &lsquo;Estimating densities, quantiles, quantile densities and density quantiles&rsquo;, <em>Annals of the Institute of Statistical Mathematics</em>, <b>44</b>, 721-727.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoDa_FPCA">CoDa_FPCA</a></code>, <code><a href="#topic+Horta_Ziegelmann_FPCA">Horta_Ziegelmann_FPCA</a></code>, <code><a href="#topic+skew_t_fun">skew_t_fun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LQDT_FPCA(data = DJI_return, band_choice = "DPI", kernel = "epanechnikov", 
			forecasting_method = "uni", fmethod = "ets")

## End(Not run)		
</code></pre>

<hr>
<h2 id='MAF_multivariate'>
Maximum autocorrelation factors
</h2><span id='topic+MAF_multivariate'></span>

<h3>Description</h3>

<p>Dimension reduction via maximum autocorrelation factors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAF_multivariate(data, threshold)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MAF_multivariate_+3A_data">data</code></td>
<td>
<p>A p by n data matrix, where p denotes the number of variables and n denotes the sample size</p>
</td></tr>
<tr><td><code id="MAF_multivariate_+3A_threshold">threshold</code></td>
<td>
<p>A threshold level for retaining the optimal number of factors</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>MAF</code></td>
<td>
<p>Maximum autocorrelation factor scores</p>
</td></tr>
<tr><td><code>MAF_loading</code></td>
<td>
<p>Maximum autocorrelation factors</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>Standardized original data</p>
</td></tr>
<tr><td><code>recon</code></td>
<td>
<p>Reconstruction via maximum autocorrelation factors</p>
</td></tr>
<tr><td><code>recon_err</code></td>
<td>
<p>Reconstruction errors between the standardized original data and reconstruction via maximum autocorrelation factors</p>
</td></tr>
<tr><td><code>ncomp_threshold</code></td>
<td>
<p>Number of maximum autocorrelation factors selected by explaining autocorrelation at and above a given level of threshold</p>
</td></tr>
<tr><td><code>ncomp_eigen_ratio</code></td>
<td>
<p>Number of maximum autocorrelation factors selected by eigenvalue ratio tests</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>M. A. Haugen, B. Rajaratnam and P. Switzer (2015). Extracting common time trends from concurrent time series: Maximum autocorrelation factors with applications, arXiv paper https://arxiv.org/abs/1502.01073.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MAF_multivariate(data = pm_10_GR_sqrt$y, threshold = 0.85)
</code></pre>

<hr>
<h2 id='mean.fts'>Mean functions for functional time series</h2><span id='topic+mean.fts'></span>

<h3>Description</h3>

<p>Computes mean of functional time series at each variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fts'
mean(x, method = c("coordinate", "FM", "mode", "RP", "RPD", "radius"), 
 na.rm = TRUE, alpha, beta, weight, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean.fts_+3A_x">x</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="mean.fts_+3A_method">method</code></td>
<td>
<p>Method for computing the mean function.</p>
</td></tr>
<tr><td><code id="mean.fts_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether NA values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="mean.fts_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter when <code>method="radius"</code>.</p>
</td></tr>
<tr><td><code id="mean.fts_+3A_beta">beta</code></td>
<td>
<p>Trimming percentage, by default it is 0.25, when <code>method="radius"</code>.</p>
</td></tr>
<tr><td><code id="mean.fts_+3A_weight">weight</code></td>
<td>
<p>Hard thresholding or soft thresholding.</p>
</td></tr>
<tr><td><code id="mean.fts_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "coordinate"</code>, it computes the coordinate-wise functional mean.
</p>
<p>If <code>method = "FM"</code>, it computes the mean of trimmed functional data ordered by the functional depth of Fraiman and Muniz (2001).
</p>
<p>If <code>method = "mode"</code>, it computes the mean of trimmed functional data ordered by <code class="reqn">h</code>-modal functional depth.
</p>
<p>If <code>method = "RP"</code>, it computes the mean of trimmed functional data ordered by random projection depth.
</p>
<p>If <code>method = "RPD"</code>, it computes the mean of trimmed functional data ordered by random projection derivative depth.
</p>
<p>If <code>method = "radius"</code>, it computes the mean of trimmed functional data ordered by the notion of alpha-radius. 
</p>


<h3>Value</h3>

<p>A list containing <code>x</code> = variables and <code>y</code> = mean rates.</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman, Han Lin Shang</p>


<h3>References</h3>

<p>O. Hossjer and C. Croux (1995) &quot;Generalized univariate signed rank statistics for testing and estimating a multivariate location parameter&quot;, <em>Journal of Nonparametric Statistics</em>, <b>4</b>(3), 293-308.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2006) &quot;On the use of bootstrap for estimating functions with functional data&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(2), 1063-1074.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2007), &quot;Robust estimation and classification for functional data via projection-based depth notions&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 481-496.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2007) &quot;A functional analysis of NOx levels: location and scale estimation and outlier detection&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 411-427.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2008) &quot;Outlier detection in functional data by depth measures, with application to identify abnormal NOx levels&quot;, <em>Environmetrics</em>, <b>19</b>(4), 331-345.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2010) &quot;Measures of influence for the functional linear model with scalar response&quot;, <em>Journal of Multivariate Analysis</em>, <b>101</b>(2), 327-339. 
</p>
<p>J. A. Cuesta-Albertos and A. Nieto-Reyes (2010) &quot;Functional classification and the random Tukey depth. Practical issues&quot;, Combining Soft Computing and Statistical Methods in Data Analysis, <em>Advances in Intelligent and Soft Computing</em>, <b>77</b>, 123-130.
</p>
<p>D. Gervini (2012) &quot;Outlier detection and trimmed estimation in general functional spaces&quot;, <em>Statistica Sinica</em>, <b>22</b>(4), 1639-1660.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+median.fts">median.fts</a></code>, <code><a href="#topic+var.fts">var.fts</a></code>, <code><a href="#topic+sd.fts">sd.fts</a></code>, <code><a href="#topic+quantile.fts">quantile.fts</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Calculate the mean function by the different depth measures.	
mean(x = ElNino_ERSST_region_1and2, method = "coordinate")
mean(x = ElNino_ERSST_region_1and2, method = "FM")
mean(x = ElNino_ERSST_region_1and2, method = "mode")
mean(x = ElNino_ERSST_region_1and2, method = "RP")
mean(x = ElNino_ERSST_region_1and2, method = "RPD")
mean(x = ElNino_ERSST_region_1and2, method = "radius", 
	alpha = 0.5, beta = 0.25, weight = "hard")
mean(x = ElNino_ERSST_region_1and2, method = "radius", 
	alpha = 0.5, beta = 0.25, weight = "soft")
</code></pre>

<hr>
<h2 id='median.fts'>Median functions for functional time series</h2><span id='topic+median.fts'></span>

<h3>Description</h3>

<p>Computes median of functional time series at each variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fts'
median(x, na.rm, method = c("hossjercroux", "coordinate", "FM", "mode", 
 "RP", "RPD", "radius"), alpha, beta, weight, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="median.fts_+3A_x">x</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="median.fts_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove any missing value.</p>
</td></tr>
<tr><td><code id="median.fts_+3A_method">method</code></td>
<td>
<p>Method for computing median.</p>
</td></tr>
<tr><td><code id="median.fts_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter when <code>method="radius"</code>.</p>
</td></tr>
<tr><td><code id="median.fts_+3A_beta">beta</code></td>
<td>
<p>Trimming percentage, by default it is 0.25, when <code>method="radius"</code>.</p>
</td></tr>
<tr><td><code id="median.fts_+3A_weight">weight</code></td>
<td>
<p>Hard thresholding or soft thresholding.</p>
</td></tr>
<tr><td><code id="median.fts_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "coordinate"</code>, it computes a coordinate-wise median.
</p>
<p>If <code>method = "hossjercroux"</code>, it computes the L1-median using the Hossjer-Croux algorithm.
</p>
<p>If <code>method = "FM"</code>, it computes the median of trimmed functional data ordered by the functional depth of Fraiman and Muniz (2001).
</p>
<p>If <code>method = "mode"</code>, it computes the median of trimmed functional data ordered by <code class="reqn">h</code>-modal functional depth.
</p>
<p>If <code>method = "RP"</code>, it computes the median of trimmed functional data ordered by random projection depth.
</p>
<p>If <code>method = "RPD"</code>, it computes the median of trimmed functional data ordered by random projection derivative depth.
</p>
<p>If <code>method = "radius"</code>, it computes the mean of trimmed functional data ordered by the notion of alpha-radius.
</p>


<h3>Value</h3>

<p>A list containing <code>x</code> = variables and <code>y</code> = median rates.
</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman, Han Lin Shang</p>


<h3>References</h3>

<p>O. Hossjer and C. Croux (1995) &quot;Generalized univariate signed rank statistics for testing and estimating a multivariate location parameter&quot;, <em>Journal of Nonparametric Statistics</em>, <b>4</b>(3), 293-308.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2006) &quot;On the use of bootstrap for estimating functions with functional data&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(2), 1063-1074.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2007), &quot;Robust estimation and classification for functional data via projection-based depth notions&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 481-496.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2007) &quot;A functional analysis of NOx levels: location and scale estimation and outlier detection&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 411-427.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2008) &quot;Outlier detection in functional data by depth measures, with application to identify abnormal NOx levels&quot;, <em>Environmetrics</em>, <b>19</b>(4), 331-345.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2010) &quot;Measures of influence for the functional linear model with scalar response&quot;, <em>Journal of Multivariate Analysis</em>, <b>101</b>(2), 327-339. 
</p>
<p>J. A. Cuesta-Albertos and A. Nieto-Reyes (2010) &quot;Functional classification and the random Tukey depth. Practical issues&quot;, Combining Soft Computing and Statistical Methods in Data Analysis, <em>Advances in Intelligent and Soft Computing</em>, <b>77</b>, 123-130.
</p>
<p>D. Gervini (2012) &quot;Outlier detection and trimmed estimation in general functional spaces&quot;, <em>Statistica Sinica</em>, <b>22</b>(4), 1639-1660.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mean.fts">mean.fts</a></code>, <code><a href="#topic+var.fts">var.fts</a></code>, <code><a href="#topic+sd.fts">sd.fts</a></code>, <code><a href="#topic+quantile.fts">quantile.fts</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Calculate the median function by the different depth measures.	
median(x = ElNino_ERSST_region_1and2, method = "hossjercroux")
median(x = ElNino_ERSST_region_1and2, method = "coordinate")
median(x = ElNino_ERSST_region_1and2, method = "FM")
median(x = ElNino_ERSST_region_1and2, method = "mode")
median(x = ElNino_ERSST_region_1and2, method = "RP")
median(x = ElNino_ERSST_region_1and2, method = "RPD")
median(x = ElNino_ERSST_region_1and2, method = "radius", 
	alpha = 0.5, beta = 0.25, weight = "hard")
median(x = ElNino_ERSST_region_1and2, method = "radius", 
	alpha = 0.5, beta = 0.25, weight = "soft")
</code></pre>

<hr>
<h2 id='MFDM'>
Multilevel functional data method
</h2><span id='topic+MFDM'></span>

<h3>Description</h3>

<p>Fit a multilevel functional principal component model. The function uses two-step functional principal component decompositions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MFDM(mort_female, mort_male, mort_ave, percent_1 = 0.95, percent_2 = 0.95, fh, 
	     level = 80, alpha = 0.2, MCMCiter = 100, fmethod = c("auto_arima", "ets"), 
		   BC = c(FALSE, TRUE), lambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MFDM_+3A_mort_female">mort_female</code></td>
<td>
<p>Female mortality (p by n matrix), where p denotes the dimension and n denotes the sample size.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_mort_male">mort_male</code></td>
<td>
<p>Male mortality (p by n matrix).</p>
</td></tr>
<tr><td><code id="MFDM_+3A_mort_ave">mort_ave</code></td>
<td>
<p>Total mortality (p by n matrix).</p>
</td></tr>
<tr><td><code id="MFDM_+3A_percent_1">percent_1</code></td>
<td>
<p>Cumulative percentage used for determining the number of common functional principal components.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_percent_2">percent_2</code></td>
<td>
<p>Cumulative percentage used for determining the number of sex-specific functional principal components.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_fh">fh</code></td>
<td>
<p>Forecast horizon.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_level">level</code></td>
<td>
<p>Nominal coverage probability of a prediction interval.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_alpha">alpha</code></td>
<td>
<p>1 - Nominal coverage probability.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_mcmciter">MCMCiter</code></td>
<td>
<p>Number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_fmethod">fmethod</code></td>
<td>
<p>Univariate time-series forecasting method.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_bc">BC</code></td>
<td>
<p>If Box-Cox transformation is performed.</p>
</td></tr>
<tr><td><code id="MFDM_+3A_lambda">lambda</code></td>
<td>
<p>If <code>BC = TRUE</code>, specify a Box-Cox transformation parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basic idea of multilevel functional data method is to decompose functions from different sub-populations into an aggregated average, a sex-specific deviation from the aggregated average, a common trend, a sex-specific trend and measurement error. The common and sex-specific trends are modelled by projecting them onto the eigenvectors of covariance operators of the aggregated and sex-specific centred stochastic process, respectively.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>first_percent</code></td>
<td>
<p>Percentage of total variation explained by the first common functional principal component.</p>
</td></tr>
<tr><td><code>female_percent</code></td>
<td>
<p>Percentage of total variation explained by the first female functional principal component in the residual.</p>
</td></tr>
<tr><td><code>male_percent</code></td>
<td>
<p>Percentage of total variation explained by the first male functional principal component in the residual.</p>
</td></tr>
<tr><td><code>mort_female_fore</code></td>
<td>
<p>Forecast female mortality in the original scale.</p>
</td></tr>
<tr><td><code>mort_male_fore</code></td>
<td>
<p>Forecast male mortality in the original scale.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>It can be quite time consuming, especially when MCMCiter is large.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>C. M. Crainiceanu and J. Goldsmith (2010) &quot;Bayesian functional data analysis using WinBUGS&quot;, <em>Journal of Statistical Software</em>, <b>32</b>(11).
</p>
<p>C-Z. Di and C. M. Crainiceanu and B. S. Caffo and N. M. Punjabi (2009) &quot;Multilevel functional principal component analysis&quot;, <em>The Annals of Applied Statistics</em>, <b>3</b>(1), 458-488.
</p>
<p>V. Zipunnikov and B. Caffo and D. M. Yousem and C. Davatzikos and B. S. Schwartz and C. Crainiceanu (2015) &quot;Multilevel functional principal component analysis for high-dimensional data&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>20</b>, 852-873.
</p>
<p>H. L. Shang, P. W. F. Smith, J. Bijak, A. Wisniowski (2016) &quot;A multilevel functional data method for forecasting population, with an application to the United Kingdom&quot;, <em>International Journal of Forecasting</em>, <b>32</b>(3), 629-649.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+fplsr">fplsr</a></code>, <code><a href="#topic+forecastfplsr">forecastfplsr</a></code>
</p>

<hr>
<h2 id='MFPCA'>
Multilevel functional principal component analysis for clustering
</h2><span id='topic+MFPCA'></span>

<h3>Description</h3>

<p>A multilevel functional principal component analysis for performing clustering analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MFPCA(y, M = NULL, J = NULL, N = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MFPCA_+3A_y">y</code></td>
<td>
<p>A data matrix containing functional responses. Each row contains measurements from a function at a set of grid points, and each column contains measurements of all functions at a particular grid point</p>
</td></tr>
<tr><td><code id="MFPCA_+3A_m">M</code></td>
<td>
<p>Number of countries</p>
</td></tr>
<tr><td><code id="MFPCA_+3A_j">J</code></td>
<td>
<p>Number of functional responses in each country</p>
</td></tr>
<tr><td><code id="MFPCA_+3A_n">N</code></td>
<td>
<p>Number of grid points per function</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>K1</code></td>
<td>
<p>Number of components at level 1</p>
</td></tr>
<tr><td><code>K2</code></td>
<td>
<p>Number of components at level 2</p>
</td></tr>
<tr><td><code>K3</code></td>
<td>
<p>Number of components at level 3</p>
</td></tr>
<tr><td><code>lambda1</code></td>
<td>
<p>A vector containing all level 1 eigenvalues in non-increasing order</p>
</td></tr>
<tr><td><code>lambda2</code></td>
<td>
<p>A vector containing all level 2 eigenvalues in non-increasing order</p>
</td></tr>
<tr><td><code>lambda3</code></td>
<td>
<p>A vector containing all level 3 eigenvalues in non-increasing order</p>
</td></tr>
<tr><td><code>phi1</code></td>
<td>
<p>A matrix containing all level 1 eigenfunctions. Each row contains an eigenfunction evaluated at the same set of grid points as the input data. The eigenfunctions are in the same order as the corresponding eigenvalues</p>
</td></tr>
<tr><td><code>phi2</code></td>
<td>
<p>A matrix containing all level 2 eigenfunctions. Each row contains an eigenfunction evaluated at the same set of grid points as the input data. The eigenfunctions are in the same order as the corresponding eigenvalues</p>
</td></tr>
<tr><td><code>phi3</code></td>
<td>
<p>A matrix containing all level 3 eigenfunctions. Each row contains an eigenfunction evaluated at the same set of grid points as the input data. The eigenfunctions are in the same order as the corresponding eigenvalues</p>
</td></tr>
<tr><td><code>scores1</code></td>
<td>
<p>A matrix containing estimated level 1 principal component scores. Each row corresponds to the level 1 scores for a particular subject in a cluster. The number of rows is the same as that of the input matrix <code>y</code>. Each column contains the scores for a level 1 component for all subjects</p>
</td></tr>
<tr><td><code>scores2</code></td>
<td>
<p>A matrix containing estimated level 2 principal component scores. Each row corresponds to the level 2 scores for a particular subject in a cluster. The number of rows is the same as that of the input matrix <code>y</code>. Each column contains the scores for a level 2 component for all subjects.</p>
</td></tr>
<tr><td><code>scores3</code></td>
<td>
<p>A matrix containing estimated level 3 principal component scores. Each row corresponds to the level 3 scores for a particular subject in a cluster. The number of rows is the same as that of the input matrix <code>y</code>. Each column contains the scores for a level 3 component for all subjects.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A vector containing the overall mean function</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>A matrix containing the deviation from overall mean function to country-specific mean function. The number of rows is the number of countries</p>
</td></tr>
<tr><td><code>Rj</code></td>
<td>
<p>Common trend</p>
</td></tr>
<tr><td><code>Uij</code></td>
<td>
<p>Country-specific mean function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chen Tang, Yanrong Yang and Han Lin Shang
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mftsc">mftsc</a></code>
</p>

<hr>
<h2 id='mftsc'>
Multiple funtional time series clustering
</h2><span id='topic+mftsc'></span>

<h3>Description</h3>

<p>Clustering the multiple functional time series. The function uses the functional panel data model to cluster different time series into subgroups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mftsc(X, alpha)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mftsc_+3A_x">X</code></td>
<td>
<p>A list of sets of smoothed functional time series to be clustered, for each object, it is a p x q matrix, where p is the sample size and q is the number of grid points of the function</p>
</td></tr>
<tr><td><code id="mftsc_+3A_alpha">alpha</code></td>
<td>
<p>A value input for adjusted rand index to measure similarity of the memberships with last iteration, can be any value big than 0.9</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As an initial step, conventional k-means clustering is performed on the dynamic FPC scores, then an iterative membership updating process is applied by fitting the MFPCA model.</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>iteration</code></td>
<td>
<p>the number of iterations until convergence</p>
</td></tr>
<tr><td><code>memebership</code></td>
<td>
<p>a list of all the membership matrices at each iteration</p>
</td></tr>
<tr><td><code>member.final</code></td>
<td>
<p>the final membership</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chen Tang, Yanrong Yang and Han Lin Shang</p>


<h3>See Also</h3>

<p><code><a href="#topic+MFPCA">MFPCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sim_ex_cluster)
cluster_result&lt;-mftsc(X=sim_ex_cluster, alpha=0.99)
cluster_result$member.final

## End(Not run)
</code></pre>

<hr>
<h2 id='pcscorebootstrapdata'>
Bootstrap independent and identically distributed functional data or functional time series
</h2><span id='topic+pcscorebootstrapdata'></span>

<h3>Description</h3>

<p>Computes bootstrap or smoothed bootstrap samples based on either independent and identically distributed functional data or functional time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcscorebootstrapdata(dat, bootrep, statistic, bootmethod = c("st", "sm", 
	"mvn", "stiefel", "meboot"), smo)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcscorebootstrapdata_+3A_dat">dat</code></td>
<td>
<p>An object of class <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="pcscorebootstrapdata_+3A_bootrep">bootrep</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="pcscorebootstrapdata_+3A_statistic">statistic</code></td>
<td>
<p>Summary statistics.</p>
</td></tr>
<tr><td><code id="pcscorebootstrapdata_+3A_bootmethod">bootmethod</code></td>
<td>
<p>Bootstrap method. When <code>bootmethod = "st"</code>, the sampling with replacement is implemented. To avoid the repeated bootstrap samples, 
the smoothed boostrap method can be implemented by adding multivariate Gaussian random noise. When <code>bootmethod = "mvn"</code>, the bootstrapped principal 
component scores are drawn from a multivariate Gaussian distribution with the mean and covariance matrices of the original principal component scores. 
When <code>bootmethod = "stiefel"</code>, the bootstrapped principal component scores are drawn from a Stiefel manifold with the mean and covariance matrices of
the original principal component scores. When <code>bootmethod = "meboot"</code>, the bootstrapped principal component scores are drawn from a maximum entropy algorithm of Vinod (2004).</p>
</td></tr>
<tr><td><code id="pcscorebootstrapdata_+3A_smo">smo</code></td>
<td>
<p>Smoothing parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We will presume that each curve is observed on a grid of <code class="reqn">T</code> points with <code class="reqn">0\leq t_1&lt;t_2\dots&lt;t_T\leq \tau</code>. 
Thus, the raw data set <code class="reqn">(X_1,X_2,\dots,X_n)</code> of <code class="reqn">n</code> observations will consist of an <code class="reqn">n</code> by <code class="reqn">T</code> data matrix.
By applying the singular value decomposition, <code class="reqn">X_1,X_2,\dots,X_n</code> can be decomposed into <code class="reqn">X = ULR^{\top}</code>, 
where the crossproduct of <code class="reqn">U</code> and <code class="reqn">R</code> is identity matrix.  
</p>
<p>Holding the mean and <code class="reqn">L</code> and <code class="reqn">R</code> fixed at their realized values, there are four re-sampling methods that differ mainly by the ways of re-sampling U.
</p>
<p>(a) Obtain the re-sampled singular column matrix by randomly sampling with replacement from the original principal component scores.
</p>
<p>(b) To avoid the appearance of repeated values in bootstrapped principal component scores, we adapt a smooth bootstrap procedure by adding a white noise component to the bootstrap.
</p>
<p>(c) Because principal component scores follow a standard multivariate normal distribution asymptotically, we can randomly draw principal component scores from a multivariate normal distribution with mean vector and covariance matrix of original principal component scores.
</p>
<p>(d) Because the crossproduct of U is identitiy matrix, U is considered as a point on the Stiefel manifold, that is the space of <code class="reqn">n</code> orthogonal vectors, thus we can randomly draw principal component scores from the Stiefel manifold.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>bootdata</code></td>
<td>
<p>Bootstrap samples. If the original data matrix is <code class="reqn">p</code> by <code class="reqn">n</code>, then the bootstrapped data are <code class="reqn">p</code> by <code class="reqn">n</code> by <code class="reqn">bootrep</code>.</p>
</td></tr>
<tr><td><code>meanfunction</code></td>
<td>
<p>Bootstrap summary statistics. If the original data matrix is <code class="reqn">p</code> by <code class="reqn">n</code>, then the bootstrapped summary statistics is <code class="reqn">p</code> by <code class="reqn">bootrep</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>H. D. Vinod (2004), &quot;Ranking mutual funds using unconventional utility theory and stochastic dominance&quot;, <em>Journal of Empirical Finance</em>, <b>11</b>(3), 353-377.
</p>
<p>A. Cuevas, M. Febrero, R. Fraiman (2006), &quot;On the use of the bootstrap for estimating functions with functional data&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(2), 1063-1074.
</p>
<p>D. S. Poskitt and A. Sengarapillai (2013), &quot;Description length and dimensionality reduction in functional data analysis&quot;, <em>Computational Statistics and Data Analysis</em>, <b>58</b>, 98-113.
</p>
<p>H. L. Shang (2015), &quot;Re-sampling techniques for estimating the distribution of descriptive statistics of functional data&quot;, <em>Communications in Statistics&ndash;Simulation and Computation</em>, <b>44</b>(3), 614-635.
</p>
<p>H. L. Shang (2018), &quot;Bootstrap methods for stationary functional time series&quot;, <em>Statistics and Computing</em>, <b>28</b>(1), 1-10.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fbootstrap">fbootstrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Bootstrapping the distribution of a summary statistics of functional data.	
boot1 = pcscorebootstrapdata(dat = ElNino_ERSST_region_1and2$y, bootrep = 200, 
	statistic = "mean", bootmethod = "st")
boot2 = pcscorebootstrapdata(dat = ElNino_ERSST_region_1and2$y, bootrep = 200, 
	statistic = "mean", bootmethod = "sm", smo = 0.05)
boot3 = pcscorebootstrapdata(dat = ElNino_ERSST_region_1and2$y, bootrep = 200, 
	statistic = "mean", bootmethod = "mvn")
boot4 = pcscorebootstrapdata(dat = ElNino_ERSST_region_1and2$y, bootrep = 200, 
	statistic = "mean", bootmethod = "stiefel")
boot5 = pcscorebootstrapdata(dat = ElNino_ERSST_region_1and2$y, bootrep = 200, 
	statistic = "mean", bootmethod = "meboot")
</code></pre>

<hr>
<h2 id='plot.fm'>Plot fitted model components for a functional model</h2><span id='topic+plot.fm'></span>

<h3>Description</h3>

<p>When <code>class(x)[1] = ftsm</code>, plot showing the principal components in the top row of plots and the coefficients in the bottom row of plots.
</p>
<p>When <code>class(x)[1] = fm</code>, plot showing the predictor scores in the top row of plots and the response loadings in the bottom row of plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fm'
plot(x, order, xlab1 = x$y$xname, ylab1 = "Principal component", 
 xlab2 = "Time", ylab2 = "Coefficient", mean.lab = "Mean", 
  level.lab = "Level", main.title = "Main effects", interaction.title 
   = "Interaction", basiscol = 1, coeffcol = 1, outlier.col = 2, 
    outlier.pch = 19, outlier.cex = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.fm_+3A_x">x</code></td>
<td>
<p>Output from <code><a href="#topic+ftsm">ftsm</a></code> or <code><a href="#topic+fplsr">fplsr</a></code>.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_order">order</code></td>
<td>
<p>Number of principal components to plot. Default is all principal components in a model.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_xlab1">xlab1</code></td>
<td>
<p>x-axis label for principal components.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_xlab2">xlab2</code></td>
<td>
<p>x-axis label for coefficient time series.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_ylab1">ylab1</code></td>
<td>
<p>y-axis label for principal components.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_ylab2">ylab2</code></td>
<td>
<p>y-axis label for coefficient time series.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_mean.lab">mean.lab</code></td>
<td>
<p>Label for mean component.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_level.lab">level.lab</code></td>
<td>
<p>Label for level component.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_main.title">main.title</code></td>
<td>
<p>Title for main effects.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_interaction.title">interaction.title</code></td>
<td>
<p>Title for interaction terms.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_basiscol">basiscol</code></td>
<td>
<p>Colors for principal components if <code>plot.type = "components"</code>.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_coeffcol">coeffcol</code></td>
<td>
<p>Colors for time series coefficients if <code>plot.type = "components"</code>.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_outlier.col">outlier.col</code></td>
<td>
<p>Colors for outlying years.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_outlier.pch">outlier.pch</code></td>
<td>
<p>Plotting character for outlying years.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_outlier.cex">outlier.cex</code></td>
<td>
<p>Size of plotting character for outlying years.</p>
</td></tr>
<tr><td><code id="plot.fm_+3A_...">...</code></td>
<td>
<p>Plotting parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Function produces a plot.
</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>References</h3>

<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>R. J. Hyndman and H. Booth (2008) &quot;Stochastic population forecasts using functional data models for mortality, fertility and migration&quot;, <em>International Journal of Forecasting</em>, <b>24</b>(3), 323-342.
</p>
<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series (with discussion)&quot;, <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code>, <code><a href="#topic+plot.fmres">plot.fmres</a></code>, <code><a href="#topic+plot.ftsf">plot.ftsf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(x = ftsm(y = ElNino_ERSST_region_1and2))
</code></pre>

<hr>
<h2 id='plot.fmres'>Plot residuals from a fitted functional model.</h2><span id='topic+plot.fmres'></span>

<h3>Description</h3>

<p>Functions to produce a plot of residuals from a fitted functional model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fmres'
plot(x, type = c("image", "fts", "contour", "filled.contour", 
 "persp"), xlab = "Year", ylab = "Age", zlab = "Residual", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.fmres_+3A_x">x</code></td>
<td>
<p>Generated by <code>residuals(fit)</code>, where fit is the output from <code><a href="#topic+ftsm">ftsm</a></code> or <code><a href="#topic+fplsr">fplsr</a></code>.</p>
</td></tr>
<tr><td><code id="plot.fmres_+3A_type">type</code></td>
<td>
<p>Type of plot to use. Possibilities are <code><a href="graphics.html#topic+image">image</a></code>, <code>fts</code>, 
<code><a href="graphics.html#topic+contour">contour</a></code>, <code><a href="graphics.html#topic+filled.contour">filled.contour</a></code> and <code><a href="graphics.html#topic+persp">persp</a></code>.</p>
</td></tr>
<tr><td><code id="plot.fmres_+3A_xlab">xlab</code></td>
<td>
<p>Label for <code>x</code>-axis.</p>
</td></tr>
<tr><td><code id="plot.fmres_+3A_ylab">ylab</code></td>
<td>
<p>Label for <code>y</code>-axis.</p>
</td></tr>
<tr><td><code id="plot.fmres_+3A_zlab">zlab</code></td>
<td>
<p>Label for <code>z</code>-axis.</p>
</td></tr>
<tr><td><code id="plot.fmres_+3A_...">...</code></td>
<td>
<p>Plotting parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Produces a plot.
</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.fmres">plot.fmres</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># colorspace package was used to provide a more coherent color option.	
plot(residuals(ftsm(y = ElNino_ERSST_region_1and2)), type = "filled.contour", xlab = "Month", 
     ylab = "Residual sea surface temperature")
</code></pre>

<hr>
<h2 id='plot.ftsf'>Plot fitted model components for a functional time series model</h2><span id='topic+plot.ftsf'></span>

<h3>Description</h3>

<p>Plot fitted model components for a <code>fts</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ftsf'
plot(x, plot.type = c("function", "components", "variance"), 
 components, xlab1 = fit$y$xname, ylab1 = "Basis function", 
  xlab2 = "Time", ylab2 = "Coefficient", mean.lab = "Mean", 
   level.lab = "Level", main.title = "Main effects", 
    interaction.title = "Interaction", vcol = 1:3, shadecols = 7, 
     fcol = 4, basiscol = 1, coeffcol = 1, outlier.col = 2,
      outlier.pch = 19, outlier.cex = 0.5,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.ftsf_+3A_x">x</code></td>
<td>
<p>Output from <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_plot.type">plot.type</code></td>
<td>
<p>Type of plot.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_components">components</code></td>
<td>
<p>Number of principal components.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_xlab1">xlab1</code></td>
<td>
<p>x-axis label for principal components.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_xlab2">xlab2</code></td>
<td>
<p>x-axis label for coefficient time series.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_ylab1">ylab1</code></td>
<td>
<p>y-axis label for principal components.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_ylab2">ylab2</code></td>
<td>
<p>y-axis label for coefficient time series.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_mean.lab">mean.lab</code></td>
<td>
<p>Label for mean component.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_level.lab">level.lab</code></td>
<td>
<p>Label for level component.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_main.title">main.title</code></td>
<td>
<p>Title for main effects.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_interaction.title">interaction.title</code></td>
<td>
<p>Title for interaction terms.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_vcol">vcol</code></td>
<td>
<p>Colors to use if <code>plot.type = "variance"</code>.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_shadecols">shadecols</code></td>
<td>
<p>Color for shading of prediction intervals when <code>plot.type = "components"</code>.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_fcol">fcol</code></td>
<td>
<p>Color of point forecasts when <code>plot.type = "components"</code>.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_basiscol">basiscol</code></td>
<td>
<p>Colors for principal components if <code>plot.type = "components"</code>.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_coeffcol">coeffcol</code></td>
<td>
<p>Colors for time series coefficients if <code>plot.type = "components"</code>.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_outlier.col">outlier.col</code></td>
<td>
<p>Colors for outlying years.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_outlier.pch">outlier.pch</code></td>
<td>
<p>Plotting character for outlying years.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_outlier.cex">outlier.cex</code></td>
<td>
<p>Size of plotting character for outlying years.</p>
</td></tr>
<tr><td><code id="plot.ftsf_+3A_...">...</code></td>
<td>
<p>Plotting parameters.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>When <code>plot.type = "function"</code>, it produces a plot of the forecast functions; 
</p>
<p>When <code>plot.type = "components"</code>, it produces a plot of the principla components and coefficients with forecasts and prediction intervals for each coefficient;
</p>
<p>When <code>plot.type = "variance"</code>, it produces a plot of the variance components.
</p>


<h3>Value</h3>

<p>Function produces a plot.</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>References</h3>

<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>R. J. Hyndman and H. Booth (2008) &quot;Stochastic population forecasts using functional data models for mortality, fertility and migration&quot;, <em>International Journal of Forecasting</em>, <b>24</b>(3), 323-342.
</p>
<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series (with discussion)&quot;, <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>
<p>H. L. Shang, H. Booth and R. J. Hyndman (2011) &quot;Point and interval forecasts of mortality rates and life expectancy: A comparison of ten principal component methods&quot;, <em>Demographic Research</em>, <b>25</b>(5), 173-214.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.fmres">plot.fmres</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(x = forecast(object = ftsm(y = ElNino_ERSST_region_1and2)))
</code></pre>

<hr>
<h2 id='plot.ftsm'>Plot fitted model components for a functional time series model</h2><span id='topic+plot.ftsm'></span>

<h3>Description</h3>

<p>Plot showing the basis functions in the top row of plots and the coefficients in the bottom row of plots. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ftsm'
plot(x, components, components.start = 0, xlab1 = x$y$xname, ylab1 = "Basis function", 
 xlab2 = "Time", ylab2 = "Coefficient", mean.lab = "Mean", 
  level.lab = "Level", main.title = "Main effects", 
   interaction.title = "Interaction", basiscol = 1, coeffcol = 1, 
    outlier.col = 2, outlier.pch = 19, outlier.cex = 0.5, ...)   
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.ftsm_+3A_x">x</code></td>
<td>
<p>Output from <code><a href="#topic+ftsm">ftsm</a></code>.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_components">components</code></td>
<td>
<p>Number of principal components to plot.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_components.start">components.start</code></td>
<td>
<p>Plotting specified component.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_xlab1">xlab1</code></td>
<td>
<p>x-axis label for basis functions.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_xlab2">xlab2</code></td>
<td>
<p>x-axis label for coefficient time series.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_ylab1">ylab1</code></td>
<td>
<p>y-axis label for basis functions.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_ylab2">ylab2</code></td>
<td>
<p>y-axis label for coefficient time series.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_mean.lab">mean.lab</code></td>
<td>
<p>Label for mean component.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_level.lab">level.lab</code></td>
<td>
<p>Label for level component.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_main.title">main.title</code></td>
<td>
<p>Title for main effects.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_interaction.title">interaction.title</code></td>
<td>
<p>Title for interaction terms.</p>
</td></tr> 
<tr><td><code id="plot.ftsm_+3A_basiscol">basiscol</code></td>
<td>
<p>Colors for basis functions if plot.type=&quot;components&quot;.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_coeffcol">coeffcol</code></td>
<td>
<p>Colors for time series coefficients if plot.type=&quot;components&quot;.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_outlier.col">outlier.col</code></td>
<td>
<p>Colour for outlying years.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_outlier.pch">outlier.pch</code></td>
<td>
<p>Plotting character for outlying years.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_outlier.cex">outlier.cex</code></td>
<td>
<p>Size of plotting character for outlying years.</p>
</td></tr>
<tr><td><code id="plot.ftsm_+3A_...">...</code></td>
<td>
<p>Plotting parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None. Function produces a plot.
</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>References</h3>

<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series&quot; (with discussion), <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.ftsf">plot.ftsf</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># plot different principal components.	
plot.ftsm(ftsm(y = ElNino_ERSST_region_1and2, order = 2), components = 2)
</code></pre>

<hr>
<h2 id='plotfplsr'>
Plot fitted model components for a functional time series model
</h2><span id='topic+plotfplsr'></span>

<h3>Description</h3>

<p>Plot showing the basis functions of the predictors in the top row, followed by the basis functions of the responses in the second row, then the coefficients in the bottom row of plots. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotfplsr(x, xlab1 = x$ypred$xname, ylab1 = "Basis function", xlab2 = "Time", 
 ylab2 = "Coefficient", mean.lab = "Mean", interaction.title = "Interaction")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotfplsr_+3A_x">x</code></td>
<td>
<p>Output from <code><a href="#topic+fplsr">fplsr</a></code>.</p>
</td></tr>
<tr><td><code id="plotfplsr_+3A_xlab1">xlab1</code></td>
<td>
<p>x-axis label for basis functions.</p>
</td></tr>
<tr><td><code id="plotfplsr_+3A_ylab1">ylab1</code></td>
<td>
<p>y-axis label for basis functions.</p>
</td></tr>
<tr><td><code id="plotfplsr_+3A_xlab2">xlab2</code></td>
<td>
<p>x-axis label for coefficient time series.</p>
</td></tr>
<tr><td><code id="plotfplsr_+3A_ylab2">ylab2</code></td>
<td>
<p>y-axis label for coefficient time series.</p>
</td></tr>
<tr><td><code id="plotfplsr_+3A_mean.lab">mean.lab</code></td>
<td>
<p>Label for mean component.</p>
</td></tr>
<tr><td><code id="plotfplsr_+3A_interaction.title">interaction.title</code></td>
<td>
<p>Title for interaction terms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None. Function produces a plot.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>R. J. Hyndman and H. L. Shang (2009) &quot;Forecasting functional time series&quot; (with discussion), <em>Journal of the Korean Statistical Society</em>, <b>38</b>(3), 199-221.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.ftsf">plot.ftsf</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit the data by the functional partial least squares.	
ausfplsr = fplsr(data = ElNino_ERSST_region_1and2, order = 2)
plotfplsr(x = ausfplsr)
</code></pre>

<hr>
<h2 id='pm_10_GR'>
Particulate Matter Concentrations (pm10)
</h2><span id='topic+pm_10_GR'></span><span id='topic+pm_10_GR_sqrt'></span>

<h3>Description</h3>

<p>This data set consists of half-hourly measurement of the concentrations (measured in ug/m3) of particular matter with
an aerodynamic diameter of less than 10um, abbreviated PM10, in ambient air taken in Graz-Mitte, Austria from October 1, 
2010 until March 31, 2011. To stabilise the variance, a square-root transformation can be applied to the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pm_10_GR)
</code></pre>


<h3>Details</h3>

<p>As epidemiological and toxicological studies have pointed to negative health effects, European Union (EU) regulation sets
pollution standards for the level of the concentration. Policy makers have to ensure compliance with these EU rules and need 
reliable statistical tools to determine, and justify the public, appropriate measures such as partial traffic regulation 
(see Stadlober, Hormann and Pfeiler, 2008). 
</p>


<h3>Source</h3>

<p>Thanks Professor Siegfried. Hormann for providing this data set. The original data source is <a href="https://zenodo.org/records/7959116">https://zenodo.org/records/7959116</a> 
</p>


<h3>References</h3>

<p>A. Aue, D. D. Norinho, S. Hormann (2015) &quot;On the prediction of stationary functional time series&quot;, <em>Journal of the American Statistical Association</em>, <b>110</b>(509), 378-392.
</p>
<p>E. Stadlober, S. Hormann, B. Pfeiler (2008) &quot;Quality and performance of a PM10 daily forecasting model&quot;, <em>Atmospheric Environment</em>, <b>42</b>, 1098-1109.
</p>
<p>S. Hormann, B. Pfeiler, E. Stadlober (2005) &quot;Analysis and prediction of particulate matter PM10 for the winter season in Graz&quot;, <em>Austrian Journal of Statistics</em>, <b>34</b>(4), 307-326.
</p>
<p>H. L. Shang (2017) &quot;Functional time series forecasting with dynamic updating: An application to intraday particulate matter concentration&quot;, <em>Econometrics and Statistics</em>, <b>1</b>, 184-200. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(pm_10_GR)
</code></pre>

<hr>
<h2 id='quantile'>Quantile</h2><span id='topic+quantile'></span>

<h3>Description</h3>

<p>Generic functions for quantile.</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_+3A_x">x</code></td>
<td>
<p>Numeric vector whose sample quantiles are wanted, or an object of a class for which a method has been defined.</p>
</td></tr>
<tr><td><code id="quantile_+3A_...">...</code></td>
<td>
<p>Arguments passed to specific methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Refer to specific methods. For numeric vectors, see the <code><a href="stats.html#topic+quantile">quantile</a></code> functions in the <code>stats</code> package.</p>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>See Also</h3>

<p><code><a href="#topic+quantile.fts">quantile.fts</a></code></p>

<hr>
<h2 id='quantile.fts'>Quantile functions for functional time series</h2><span id='topic+quantile.fts'></span>

<h3>Description</h3>

<p>Computes quantiles of functional time series at each variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fts'
quantile(x, probs, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile.fts_+3A_x">x</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="quantile.fts_+3A_probs">probs</code></td>
<td>
<p>Quantile percentages.</p>
</td></tr>
<tr><td><code id="quantile.fts_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return quantiles for each variable.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>See Also</h3>

<p><code><a href="#topic+mean.fts">mean.fts</a></code>, <code><a href="#topic+median.fts">median.fts</a></code>, <code><a href="#topic+var.fts">var.fts</a></code>, <code><a href="#topic+sd.fts">sd.fts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quantile(x = ElNino_ERSST_region_1and2)
</code></pre>

<hr>
<h2 id='residuals.fm'>Compute residuals from a functional model</h2><span id='topic+residuals.fm'></span>

<h3>Description</h3>

<p>After fitting a functional model, it is useful to inspect the residuals. 
This function extracts the relevant information from the fit object and puts it in a form suitable for
plotting with <code>image</code>, <code>persp</code>, <code>contour</code>, <code>filled.contour</code>, etc.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fm'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residuals.fm_+3A_object">object</code></td>
<td>
<p>Output from <code><a href="#topic+ftsm">ftsm</a></code> or <code><a href="#topic+fplsr">fplsr</a></code>.</p>
</td></tr>
<tr><td><code id="residuals.fm_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Produces an object of class &ldquo;fmres&rdquo; containing the residuals from the model.
</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>References</h3>

<p>B. Erbas and R. J. Hyndman and D. M. Gertig (2007) &quot;Forecasting age-specific breast cancer mortality using functional data model&quot;, <em>Statistics in Medicine</em>, <b>26</b>(2), 458-470.
</p>
<p>R. J. Hyndman and M. S. Ullah (2007) &quot;Robust forecasting of mortality and fertility rates: A functional data approach&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(10), 4942-4956.
</p>
<p>R. J. Hyndman and H. Booth (2008) &quot;Stochastic population forecasts using functional data models for mortality, fertility and migration&quot;, <em>International Journal of Forecasting</em>, <b>24</b>(3), 323-342.
</p>
<p>H. L. Shang (2012) &quot;Point and interval forecasts of age-specific fertility rates: a comparison of functional principal component methods&quot;, <em>Journal of Population Research</em>, <b>29</b>(3), 249-267.
</p>
<p>H. L. Shang (2012) &quot;Point and interval forecasts of age-specific life expectancies: a model averaging&quot;, <em>Demographic Research</em>, <b>27</b>, 593-644.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+summary.fm">summary.fm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.fmres">plot.fmres</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(residuals(object = ftsm(y = ElNino_ERSST_region_1and2)), 
	xlab = "Year", ylab = "Month")
</code></pre>

<hr>
<h2 id='sd'>Standard deviation</h2><span id='topic+sd'></span><span id='topic+sd.default'></span>

<h3>Description</h3>

<p>Generic functions for standard deviation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sd(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sd_+3A_...">...</code></td>
<td>
<p>Arguments passed to specific methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="stats.html#topic+sd">sd</a></code> functions in the <code>stats</code> package are replaced by <code>sd.default</code>.</p>


<h3>Value</h3>

<p>Refer to specific methods. For numeric vectors, see the <code><a href="stats.html#topic+sd">sd</a></code> functions in the <code>stats</code>
package.</p>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>See Also</h3>

<p><code><a href="#topic+sd.fts">sd.fts</a></code></p>

<hr>
<h2 id='sd.fts'>Standard deviation functions for functional time series</h2><span id='topic+sd.fts'></span>

<h3>Description</h3>

<p>Computes standard deviation of functional time series at each variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fts'
sd(x, method = c("coordinate", "FM", "mode", "RP", "RPD", "radius"), 
 trim = 0.25, alpha, weight,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sd.fts_+3A_x">x</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="sd.fts_+3A_method">method</code></td>
<td>
<p>Method for computing median.</p>
</td></tr>
<tr><td><code id="sd.fts_+3A_trim">trim</code></td>
<td>
<p>Percentage of trimming.</p>
</td></tr>
<tr><td><code id="sd.fts_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter when <code>method="radius"</code>.</p>
</td></tr>
<tr><td><code id="sd.fts_+3A_weight">weight</code></td>
<td>
<p>Hard thresholding or soft thresholding.</p>
</td></tr>
<tr><td><code id="sd.fts_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "coordinate"</code>, it computes coordinate-wise standard deviation functions.
</p>
<p>If <code>method = "FM"</code>, it computes the standard deviation functions of trimmed functional data ordered by the functional depth of 
Fraiman and Muniz (2001).
</p>
<p>If <code>method = "mode"</code>, it computes the standard deviation functions of trimmed functional data ordered by <code class="reqn">h</code>-modal functional 
depth.
</p>
<p>If <code>method = "RP"</code>, it computes the standard deviation functions of trimmed functional data ordered by random projection 
depth.
</p>
<p>If <code>method = "RPD"</code>, it computes the standard deviation functions of trimmed functional data ordered by random projection with
derivative depth.
</p>
<p>If <code>method = "radius"</code>, it computes the standard deviation function of trimmed functional data ordered by the notion of alpha-radius.
</p>


<h3>Value</h3>

<p>A list containing <code>x</code> = variables and <code>y</code> = standard deviation rates.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>References</h3>

<p>O. Hossjer and C. Croux (1995) &quot;Generalized univariate signed rank statistics for testing and estimating a multivariate location parameter&quot;, <em>Nonparametric Statistics</em>, <b>4</b>(3), 293-308.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2006) &quot;On the use of bootstrap for estimating functions with functional data&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(2), 1063-1074.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2007), &quot;Robust estimation and classification for functional data via projection-based depth notions&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 481-496.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2007) &quot;A functional analysis of NOx levels: location and scale estimation and outlier detection&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 411-427.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2008) &quot;Outlier detection in functional data by depth measures, with application to identify abnormal NOx levels&quot;, <em>Environmetrics</em>, <b>19</b>(4), 331-345.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2010) &quot;Measures of influence for the functional linear model with scalar response&quot;, <em>Journal of Multivariate Analysis</em>, <b>101</b>(2), 327-339. 
</p>
<p>J. A. Cuesta-Albertos and A. Nieto-Reyes (2010) &quot;Functional classification and the random Tukey depth. Practical issues&quot;, Combining Soft Computing and Statistical Methods in Data Analysis, <em>Advances in Intelligent and Soft Computing</em>, <b>77</b>, 123-130.
</p>
<p>D. Gervini (2012) &quot;Outlier detection and trimmed estimation in general functional spaces&quot;, <em>Statistica Sinica</em>, <b>22</b>(4), 1639-1660.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mean.fts">mean.fts</a></code>, <code><a href="#topic+median.fts">median.fts</a></code>, <code><a href="#topic+var.fts">var.fts</a></code>, 
<code><a href="#topic+quantile.fts">quantile.fts</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Fraiman-Muniz depth was arguably the oldest functional depth.	
sd(x = ElNino_ERSST_region_1and2, method = "FM")
sd(x = ElNino_ERSST_region_1and2, method = "coordinate")
sd(x = ElNino_ERSST_region_1and2, method = "mode")
sd(x = ElNino_ERSST_region_1and2, method = "RP")
sd(x = ElNino_ERSST_region_1and2, method = "RPD")
sd(x = ElNino_ERSST_region_1and2, method = "radius", 
	alpha = 0.5, weight = "hard")
sd(x = ElNino_ERSST_region_1and2, method = "radius", 
	alpha = 0.5, weight = "soft")
</code></pre>

<hr>
<h2 id='sim_ex_cluster'>
Simulated multiple sets of functional time series
</h2><span id='topic+sim_ex_cluster'></span><span id='topic+sim_ex_cluster.smooth'></span>

<h3>Description</h3>

<p>We generate  2 groups of <code class="reqn">m</code> functional time series. For each <code class="reqn">i</code> in {1, ..., m} in a given cluster <code class="reqn">c</code>, <code class="reqn">c</code> in {1,2}, the <code class="reqn">t</code> th function, <code class="reqn">t</code> in {1,..., T}, is given by
</p>
<p style="text-align: center;"><code class="reqn">Y_{it}^{(c)} (x)= \mu^{(c)}(x) + \sum_{k=1}^{2}\xi_{tk}^{(c)} \rho_k^{(c)} (x) + \sum_{l=1}^{2}\zeta_{itl}^{(c)} \psi_l^{(c)} (x) + \upsilon_{it}^{(c)} (x)</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>data("sim_ex_cluster")</code></pre>


<h3>Details</h3>

<p>The mean functions for each of these two clusters are set to be <code class="reqn">\mu^{(1)}(x) = 2(x-0.25)^{2}</code> and <code class="reqn">\mu^{(2)}(x) = 2(x-0.4)^{2}+0.1</code>. 
</p>
<p>While the variates <code class="reqn">\mathbf{\xi_{tk}^{(c)}}=(\xi_{1k}^{(c)}, \xi_{2k}^{(c)}, \ldots, \xi_{Tk}^{(c)})^{\top}</code> for both clusters, are generated from autoregressive of order 1 with parameter 0.7, while the variates <code class="reqn">\zeta_{it1}^{(c)}</code> and <code class="reqn">\zeta_{it2}^{(c)}</code> for both clusters, are generated from independent and identically distributed <code class="reqn">N(0,0.5)</code> and <code class="reqn">N(0,0.25)</code>, respectively.
</p>
<p>The basis functions for the common-time trend for the first cluster, <code class="reqn">\rho_k^{(1)} (x)</code>, for <code class="reqn">k</code> in {1,2} are <code class="reqn">sqrt(2)*sin(\pi*(0:200/200))</code> and <code class="reqn">sqrt(2)*cos(\pi*(0:200/200))</code> respectively; and the basis functions for the common-time trend for the second cluster, <code class="reqn">\rho_k^{(2)} (x)</code>, for <code class="reqn">k</code> in {1,2} are <code class="reqn">sqrt(2)*sin(2\pi*(0:200/200))</code> and <code class="reqn">sqrt(2)*cos(2\pi*(0:200/200))</code> respectively.
</p>
<p>The basis functions for the residual for the first cluster, <code class="reqn">\psi_l^{(1)} (x)</code>, for <code class="reqn">l</code> in {1,2} are <code class="reqn">sqrt(2)*sin(3\pi*(0:200/200))</code> and <code class="reqn">sqrt(2)*cos(3\pi*(0:200/200))</code> respectively; and the basis functions for the residual for the second cluster, <code class="reqn">\psi_l^{(2)} (x)</code>, for <code class="reqn">l</code> in {1,2} are <code class="reqn">sqrt(2)*sin(4\pi*(0:200/200))</code> and <code class="reqn">sqrt(2)*cos(4\pi*(0:200/200))</code> respectively.
</p>
<p>The measurement error <code class="reqn">\upsilon_{it}</code> for each continuum x is generated from independent and identically distributed <code class="reqn">N(0, 0.2^2)</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sim_ex_cluster)
</code></pre>

<hr>
<h2 id='skew_t_fun'>
Skewed t distribution
</h2><span id='topic+skew_t_fun'></span>

<h3>Description</h3>

<p>Fitting a parametric skewed t distribution of Fernandez and Steel's (1998) method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skew_t_fun(data, gridpoints, M = 5001)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="skew_t_fun_+3A_data">data</code></td>
<td>
<p>a data matrix of dimension <code>n</code> by <code>p</code></p>
</td></tr>
<tr><td><code id="skew_t_fun_+3A_gridpoints">gridpoints</code></td>
<td>
<p>Grid points</p>
</td></tr>
<tr><td><code id="skew_t_fun_+3A_m">M</code></td>
<td>
<p>number of grid points</p>
</td></tr>
</table>


<h3>Details</h3>

<p>1) Fit a skewed t distribution to data, and obtain four latent parameters;
2) Transform the four latent parameters so that they are un-constrained;
3) Fit a vector autoregressive model to these transformed latent parameters;
4) Obtain their forecasts, and then back-transform them to the original scales;
5) Via the skewed t distribution in Step 1), we obtain forecast density using the forecast latent parameters.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>m</code></td>
<td>
<p>Grid points within data range</p>
</td></tr>
<tr><td><code>skewed_t_den_fore</code></td>
<td>
<p>Density forecasts via a skewed t distribution</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This is a parametric approach for fitting and forecasting density.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>Fernandez, C. and Steel, M. F. J. (1998), &lsquo;On Bayesian modeling of fat tails and skewness&rsquo;, <em>Journal of the American Statistical Association: Theory and Methods</em>, <b>93</b>(441), 359-371.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CoDa_FPCA">CoDa_FPCA</a></code>, <code><a href="#topic+Horta_Ziegelmann_FPCA">Horta_Ziegelmann_FPCA</a></code>, <code><a href="#topic+LQDT_FPCA">LQDT_FPCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>skew_t_fun(DJI_return)
</code></pre>

<hr>
<h2 id='stop_time_detect'>
Detection of the optimal stopping time in a curve time series
</h2><span id='topic+stop_time_detect'></span>

<h3>Description</h3>

<p>Detecting the optimal stopping time for the glue curing of wood panels in an automatic process environment. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stop_time_detect(data, forecasting_method = c("ets", "arima", "rw"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stop_time_detect_+3A_data">data</code></td>
<td>
<p>An object of class <code>fts</code></p>
</td></tr>
<tr><td><code id="stop_time_detect_+3A_forecasting_method">forecasting_method</code></td>
<td>
<p>A univariate time series forecasting method</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>break_points_strucchange</code></td>
<td>
<p>Breakpoints detected by the regression approach</p>
</td></tr>
<tr><td><code>break_points_ecp</code></td>
<td>
<p>Breakpoints detected by the distance-based approach</p>
</td></tr>
<tr><td><code>err_forward</code></td>
<td>
<p>Forward integrated squared forecast errors</p>
</td></tr>
<tr><td><code>err_backward</code></td>
<td>
<p>Backward integrated squared forecast errors (ISFEs)</p>
</td></tr>
<tr><td><code>ncomp_select_forward</code></td>
<td>
<p>Number of components selected by the eigenvalue ratio tests based on the forward ISFEs</p>
</td></tr>
<tr><td><code>ncomp_select_backward</code></td>
<td>
<p>Number of components selected by the eigenvalue ratio tests based on the backward ISFEs</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>References</h3>

<p>Bekhta, P., Ortynska, G. and Sedliacik, J. (2014). Properties of modified phenol-formaldehyde adhesive for plywood panels manufactured from high moisture content veneer. Drvna Industrija 65(4), 293-301.
</p>

<hr>
<h2 id='stop_time_sim_data'>
Simulated functional time series from a functional autoregression of order one
</h2><span id='topic+stop_time_sim_data'></span>

<h3>Description</h3>

<p>For detecting the optimal stopping time, we simulate a curve time series that follows a functional autoregression of order 1, with a breakpoint in the middle point of the entire sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stop_time_sim_data(sample_size, omega, seed_number)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stop_time_sim_data_+3A_sample_size">sample_size</code></td>
<td>
<p>Number of curves</p>
</td></tr>
<tr><td><code id="stop_time_sim_data_+3A_omega">omega</code></td>
<td>
<p>Noise level</p>
</td></tr>
<tr><td><code id="stop_time_sim_data_+3A_seed_number">seed_number</code></td>
<td>
<p>Random seed number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>fts</code>
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stop_time_detect">stop_time_detect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>stop_time_sim_data(sample_size = 401, omega = 0.1, seed_number = 123)
</code></pre>

<hr>
<h2 id='summary.fm'>Summary for functional time series model</h2><span id='topic+summary.fm'></span>

<h3>Description</h3>

<p>Summarizes a basis function model fitted to a functional time series. It returns various measures of goodness-of-fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.fm_+3A_object">object</code></td>
<td>
<p>Output from <code><a href="#topic+ftsm">ftsm</a></code> or <code><a href="#topic+fplsr">fplsr</a></code>.</p>
</td></tr>
<tr><td><code id="summary.fm_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftsm">ftsm</a></code>, <code><a href="#topic+forecast.ftsm">forecast.ftsm</a></code>, <code><a href="#topic+residuals.fm">residuals.fm</a></code>, <code><a href="#topic+plot.fm">plot.fm</a></code>, <code><a href="#topic+plot.fmres">plot.fmres</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(object = ftsm(y = ElNino_ERSST_region_1and2))
</code></pre>

<hr>
<h2 id='T_stationary'>
Testing stationarity of functional time series
</h2><span id='topic+T_stationary'></span>

<h3>Description</h3>

<p>A hypothesis test for stationarity of functional time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>T_stationary(sample, L = 49, J = 500, MC_rep = 1000, cumulative_var = .90,
		    Ker1 = FALSE, Ker2 = TRUE, h = ncol(sample)^.5, pivotal = FALSE,
		    use_table = FALSE, significance)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="T_stationary_+3A_sample">sample</code></td>
<td>
<p>A matrix of discretised curves of dimension (p by n), where p represents the dimensionality and n represents sample size.</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_l">L</code></td>
<td>
<p>Number of Fourier basis functions.</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_j">J</code></td>
<td>
<p>Truncation level used to approximate the distribution of the squared integrals of Brownian bridges that appear in the limit distribution.</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_mc_rep">MC_rep</code></td>
<td>
<p>Number of replications.</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_cumulative_var">cumulative_var</code></td>
<td>
<p>Amount of variance explained.</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_ker1">Ker1</code></td>
<td>
<p>Flat top kernel in (4.1) of Horvath et al. (2014).</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_ker2">Ker2</code></td>
<td>
<p>Flat top kernel in (7) of Politis (2003).</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_h">h</code></td>
<td>
<p>Kernel bandwidth.</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_pivotal">pivotal</code></td>
<td>
<p>If <code>pivotal = TRUE</code>, a pivotal statistic is used.</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_use_table">use_table</code></td>
<td>
<p>If <code>use_table = TRUE</code>, use the critical values that are available in the book titled Inference for Functional Data (Table 6.1, page 88).</p>
</td></tr>
<tr><td><code id="T_stationary_+3A_significance">significance</code></td>
<td>
<p>Level of significance. Possibilities are &ldquo;10%&rdquo;, &ldquo;5%&rdquo;, &ldquo;1%&rdquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As in traditional (scalar and vector) time series analysis, many inferential procedures for functional time series assume stationarity. Stationarity is required for functional dynamic regression models, for bootstrap and resampling methods for functional time series and for the functional analysis of volatility.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>p-value</code></td>
<td>
<p>When <code>p-value</code> is less than any level of significance, we reject the null hypothesis and conclude that the tested functional time series is not stationary.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Greg. Rice and Han Lin Shang
</p>


<h3>References</h3>

<p>L. Horvath and Kokoszka, P. (2012) Inference for Functional Data with Applications, Springer, New York.
</p>
<p>L. Horvath, P. Kokoszka, G. Rice (2014) &quot;Testing stationarity of functional time series&quot;, <em>Journal of Econometrics</em>, <b>179</b>(1), 66-82.
</p>
<p>D. N. Politis (2003) &quot;Adaptive bandwidth choice&quot;, <em>Journal of Nonparametric Statistics</em>, <b>15</b>(4-5), 517-533.
</p>
<p>A. Aue, G. Rice, O. S\&quot;onmez (2018) &quot;Detecting and dating structural breaks in functional data without dimension reduction&quot;, <em>Journal of the Royal Statistical Society: Series B</em>, <b>80</b>(3), 509-529.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+farforecast">farforecast</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>result = T_stationary(sample = pm_10_GR_sqrt$y)
result_pivotal = T_stationary(sample = pm_10_GR_sqrt$y, J = 100, MC_rep = 5000,
				h = 20, pivotal = TRUE)
</code></pre>

<hr>
<h2 id='var'>Variance</h2><span id='topic+var'></span><span id='topic+var.default'></span>

<h3>Description</h3>

<p>Generic functions for variance.</p>


<h3>Usage</h3>

<pre><code class='language-R'>var(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="var_+3A_...">...</code></td>
<td>
<p>Arguments passed to specific methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="stats.html#topic+cor">cor</a></code> functions in the <code>stats</code> package are replaced by <code>var.default</code>.</p>


<h3>Value</h3>

<p>Refer to specific methods. For numeric vectors, see the <code><a href="stats.html#topic+cor">cor</a></code> functions in the <code>stats</code> 
package.</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman and Han Lin Shang</p>


<h3>See Also</h3>

<p><code><a href="#topic+var.fts">var.fts</a></code></p>

<hr>
<h2 id='var.fts'>Variance functions for functional time series</h2><span id='topic+var.fts'></span>

<h3>Description</h3>

<p>Computes variance functions of functional time series at each variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fts'
var(x, method = c("coordinate", "FM", "mode", "RP", "RPD", "radius"), 
 trim = 0.25, alpha, weight, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="var.fts_+3A_x">x</code></td>
<td>
<p>An object of class <code>fts</code>.</p>
</td></tr>
<tr><td><code id="var.fts_+3A_method">method</code></td>
<td>
<p>Method for computing median.</p>
</td></tr>
<tr><td><code id="var.fts_+3A_trim">trim</code></td>
<td>
<p>Percentage of trimming.</p>
</td></tr>
<tr><td><code id="var.fts_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter when <code>method="radius"</code>.</p>
</td></tr>
<tr><td><code id="var.fts_+3A_weight">weight</code></td>
<td>
<p>Hard thresholding or soft thresholding.</p>
</td></tr>
<tr><td><code id="var.fts_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "coordinate"</code>, it computes coordinate-wise variance.
</p>
<p>If <code>method = "FM"</code>, it computes the variance of trimmed functional data ordered by the functional depth of Fraiman and Muniz (2001).
</p>
<p>If <code>method = "mode"</code>, it computes the variance of trimmed functional data ordered by <code class="reqn">h</code>-modal functional depth.
</p>
<p>If <code>method = "RP"</code>, it computes the variance of trimmed functional data ordered by random projection depth.
</p>
<p>If <code>method = "RPD"</code>, it computes the variance of trimmed functional data ordered by random projection derivative depth.
</p>
<p>If <code>method = "radius"</code>, it computes the standard deviation function of trimmed functional data ordered by the notion of alpha-radius.
</p>


<h3>Value</h3>

<p>A list containing <code>x</code> = variables and <code>y</code> = variance rates.
</p>


<h3>Author(s)</h3>

<p>Han Lin Shang</p>


<h3>References</h3>

<p>O. Hossjer and C. Croux (1995) &quot;Generalized univariate signed rank statistics for testing and estimating a multivariate location parameter&quot;, <em>Nonparametric Statistics</em>, <b>4</b>(3), 293-308.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2006) &quot;On the use of bootstrap for estimating functions with functional data&quot;, <em>Computational Statistics and Data Analysis</em>, <b>51</b>(2), 1063-1074.
</p>
<p>A. Cuevas and M. Febrero and R. Fraiman (2007), &quot;Robust estimation and classification for functional data via projection-based depth notions&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 481-496.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2007) &quot;A functional analysis of NOx levels: location and scale estimation and outlier detection&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 411-427.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2008) &quot;Outlier detection in functional data by depth measures, with application to identify abnormal NOx levels&quot;, <em>Environmetrics</em>, <b>19</b>(4), 331-345.
</p>
<p>M. Febrero and P. Galeano and W. Gonzalez-Manteiga (2010) &quot;Measures of influence for the functional linear model with scalar response&quot;, <em>Journal of Multivariate Analysis</em>, <b>101</b>(2), 327-339. 
</p>
<p>J. A. Cuesta-Albertos and A. Nieto-Reyes (2010) &quot;Functional classification and the random Tukey depth. Practical issues&quot;, Combining Soft Computing and Statistical Methods in Data Analysis, <em>Advances in Intelligent and Soft Computing</em>, <b>77</b>, 123-130.
</p>
<p>D. Gervini (2012) &quot;Outlier detection and trimmed estimation in general functional spaces&quot;, <em>Statistica Sinica</em>, <b>22</b>(4), 1639-1660.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mean.fts">mean.fts</a></code>, <code><a href="#topic+median.fts">median.fts</a></code>, <code><a href="#topic+sd.fts">sd.fts</a></code>, <code><a href="#topic+quantile.fts">quantile.fts</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Fraiman-Muniz depth was arguably the oldest functional depth.	
var(x = ElNino_ERSST_region_1and2, method = "FM")
var(x = ElNino_ERSST_region_1and2, method = "coordinate")
var(x = ElNino_ERSST_region_1and2, method = "mode")
var(x = ElNino_ERSST_region_1and2, method = "RP")
var(x = ElNino_ERSST_region_1and2, method = "RPD")
var(x = ElNino_ERSST_region_1and2, method = "radius", 
alpha = 0.5, weight = "hard")
var(x = ElNino_ERSST_region_1and2, method = "radius", 
alpha = 0.5, weight = "soft")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
