<!DOCTYPE html><html><head><title>Help for package LightLogR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LightLogR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#LightLogR-package'><p>LightLogR: Process Data from Wearable Light Loggers and Optical Radiation Dosimeters</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#aggregate_Date'><p>Aggregate dates to a single day</p></a></li>
<li><a href='#aggregate_Datetime'><p>Aggregate Datetime data</p></a></li>
<li><a href='#barroso_lighting_metrics'><p>Circadian lighting metrics from Barroso et al. (2014)</p></a></li>
<li><a href='#bright_dark_period'><p>Brightest or darkest continuous period</p></a></li>
<li><a href='#Brown_check'><p>Check whether a value is within the recommended illuminance/MEDI levels by</p>
Brown et al. (2022)</a></li>
<li><a href='#Brown_rec'><p>Set the recommended illuminance/MEDI levels by Brown et al. (2022)</p></a></li>
<li><a href='#Brown2reference'><p>Add Brown et al. (2022) reference illuminance to a dataset</p></a></li>
<li><a href='#centroidLE'><p>Centroid of light exposure</p></a></li>
<li><a href='#count_difftime'><p>Counts the Time differences (epochs) per group (in a grouped dataset)</p></a></li>
<li><a href='#create_Timedata'><p>Create a Time-of-Day column in the dataset</p></a></li>
<li><a href='#cut_Datetime'><p>Create Datetime bins for visualization and calculation</p></a></li>
<li><a href='#data2reference'><p>Create reference data from other data</p></a></li>
<li><a href='#Datetime_breaks'><p>Create a (shifted) sequence of Datetimes for axis breaks</p></a></li>
<li><a href='#Datetime_limits'><p>Find or set sensible limits for Datetime axis</p></a></li>
<li><a href='#disparity_index'><p>Disparity index</p></a></li>
<li><a href='#dominant_epoch'><p>Determine the dominant epoch/interval of a dataset</p></a></li>
<li><a href='#dst_change_handler'><p>Handle jumps in Daylight Savings (DST) that are missing in the data</p></a></li>
<li><a href='#dst_change_summary'><p>Get a summary of groups where a daylight saving time change occurs.</p></a></li>
<li><a href='#duration_above_threshold'><p>Duration above/below threshold or within threshold range</p></a></li>
<li><a href='#exponential_moving_average'><p>Exponential moving average filter (EMA)</p></a></li>
<li><a href='#filter_Datetime'><p>Filter Datetimes in a dataset.</p></a></li>
<li><a href='#filter_Datetime_multiple'><p>Filter multiple times based on a list of arguments.</p></a></li>
<li><a href='#filter_Time'><p>Filter Times in a dataset.</p></a></li>
<li><a href='#frequency_crossing_threshold'><p>Frequency of crossing light threshold</p></a></li>
<li><a href='#gap_finder'><p>Check for and output gaps in a dataset</p></a></li>
<li><a href='#gap_handler'><p>Fill implicit gaps in a light logger dataset</p></a></li>
<li><a href='#gapless_Datetimes'><p>Create a gapless sequence of Datetimes</p></a></li>
<li><a href='#gg_day'><p>Create a simple Time-of-Day plot of light logger data, faceted by Date</p></a></li>
<li><a href='#gg_days'><p>Create a simple datetime plot of light logger data, faceted by group</p></a></li>
<li><a href='#gg_doubleplot'><p>Double Plots</p></a></li>
<li><a href='#gg_overview'><p>Plot an overview of dataset intervals with implicit missing data</p></a></li>
<li><a href='#import_adjustment'><p>Adjust device imports or make your own</p></a></li>
<li><a href='#import_Dataset'><p>Import a light logger dataset or related data</p></a></li>
<li><a href='#import_Statechanges'><p>Import data that contain <code>Datetimes</code> of <code>Statechanges</code></p></a></li>
<li><a href='#interdaily_stability'><p>Interdaily stability (IS)</p></a></li>
<li><a href='#interval2state'><p>Adds a state column to a dataset from interval data</p></a></li>
<li><a href='#intradaily_variability'><p>Intradaily variability (IV)</p></a></li>
<li><a href='#join_datasets'><p>Join similar Datasets</p></a></li>
<li><a href='#ll_import_expr'><p>A list of the specific device import functions</p></a></li>
<li><a href='#midpointCE'><p>Midpoint of cumulative light exposure.</p></a></li>
<li><a href='#nvRC'><p>Non-visual circadian response</p></a></li>
<li><a href='#nvRC_metrics'><p>Performance metrics for circadian response</p></a></li>
<li><a href='#nvRD'><p>Non-visual direct response</p></a></li>
<li><a href='#nvRD_cumulative_response'><p>Cumulative non-visual direct response</p></a></li>
<li><a href='#period_above_threshold'><p>Length of longest continuous period above/below threshold</p></a></li>
<li><a href='#pulses_above_threshold'><p>Pulses above threshold</p></a></li>
<li><a href='#sample.data.environment'><p>Sample of wearable data combined with environmental data</p></a></li>
<li><a href='#sc2interval'><p>Statechange (sc) Timestamps to Intervals</p></a></li>
<li><a href='#sleep_int2Brown'><p>Recode Sleep/Wake intervals to Brown state intervals</p></a></li>
<li><a href='#supported.devices'><p>A vector of all supported devices for import functions</p></a></li>
<li><a href='#symlog_trans'><p>Scale positive and negative values on a log scale</p></a></li>
<li><a href='#threshold_for_duration'><p>Find threshold for given duration</p></a></li>
<li><a href='#timing_above_threshold'><p>Mean/first/last timing above/below threshold.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Process Data from Wearable Light Loggers and Optical Radiation
Dosimeters</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.8</td>
</tr>
<tr>
<td>Description:</td>
<td>Import, processing, validation, and visualization of personal light exposure measurement data from wearable devices. The package implements features such as the import of data and metadata files, conversion of common file formats, validation of light logging data, verification of crucial metadata, calculation of common parameters, and semi-automated analysis and visualization.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tscnlab/LightLogR">https://github.com/tscnlab/LightLogR</a>,
<a href="https://tscnlab.github.io/LightLogR/">https://tscnlab.github.io/LightLogR/</a>,
<a href="https://zenodo.org/doi/10.5281/zenodo.11562600">https://zenodo.org/doi/10.5281/zenodo.11562600</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tscnlab/LightLogR/issues">https://github.com/tscnlab/LightLogR/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>cowplot, dplyr, flextable, ggplot2, ggsci, ggtext, hms,
lubridate, magrittr, pkgload, plotly, purrr, readr, rlang,
rsconnect, scales, slider, stats, stringr, tibble, tidyr, utils</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, gghighlight, gt, gtsummary, knitr, patchwork,
rmarkdown, testthat (&ge; 3.0.0), tidyverse</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-04 09:38:03 UTC; zauner</td>
</tr>
<tr>
<td>Author:</td>
<td>Johannes Zauner <a href="https://orcid.org/0000-0003-2171-4566"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Manuel Spitschan <a href="https://orcid.org/0000-0002-8572-9268"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Steffen Hartmeyer <a href="https://orcid.org/0000-0002-2813-2668"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  MeLiDos [fnd],
  EURAMET [fnd] (European Association of National Metrology Institutes.
    Website: www.euramet.org. Grant Number: 22NRM05 MeLiDos. Grant
    Statement: The project (22NRM05 MeLiDos) has received funding from
    the European Partnership on Metrology, co-financed from the
    European Unionâ€™s Horizon Europe Research and Innovation Programme
    and by the Participating States.),
  European Union [fnd] (Co-funded by the European Union. Views and
    opinions expressed are however those of the author(s) only and do
    not necessarily reflect those of the European Union or EURAMET.
    Neither the European Union nor the granting authority can be held
    responsible for them.),
  TSCN-Lab [cph] (www.tscnlab.org)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Johannes Zauner &lt;johannes.zauner@tum.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-04 17:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='LightLogR-package'>LightLogR: Process Data from Wearable Light Loggers and Optical Radiation Dosimeters</h2><span id='topic+LightLogR'></span><span id='topic+LightLogR-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Import, processing, validation, and visualization of personal light exposure measurement data from wearable devices. The package implements features such as the import of data and metadata files, conversion of common file formats, validation of light logging data, verification of crucial metadata, calculation of common parameters, and semi-automated analysis and visualization.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Johannes Zauner <a href="mailto:johannes.zauner@tum.de">johannes.zauner@tum.de</a> (<a href="https://orcid.org/0000-0003-2171-4566">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Manuel Spitschan <a href="mailto:manuel.spitschan@tum.de">manuel.spitschan@tum.de</a> (<a href="https://orcid.org/0000-0002-8572-9268">ORCID</a>)
</p>
</li>
<li><p> Steffen Hartmeyer <a href="mailto:steffen.hartmeyer@epfl.ch">steffen.hartmeyer@epfl.ch</a> (<a href="https://orcid.org/0000-0002-2813-2668">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> MeLiDos [funder]
</p>
</li>
<li><p> EURAMET (European Association of National Metrology Institutes. Website: www.euramet.org. Grant Number: 22NRM05 MeLiDos. Grant Statement: The project (22NRM05 MeLiDos) has received funding from the European Partnership on Metrology, co-financed from the European Unionâ€™s Horizon Europe Research and Innovation Programme and by the Participating States.) [funder]
</p>
</li>
<li><p> European Union (Co-funded by the European Union. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or EURAMET. Neither the European Union nor the granting authority can be held responsible for them.) [funder]
</p>
</li>
<li><p> TSCN-Lab (www.tscnlab.org) [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tscnlab/LightLogR">https://github.com/tscnlab/LightLogR</a>
</p>
</li>
<li> <p><a href="https://tscnlab.github.io/LightLogR/">https://tscnlab.github.io/LightLogR/</a>
</p>
</li>
<li> <p><a href="https://zenodo.org/doi/10.5281/zenodo.11562600">https://zenodo.org/doi/10.5281/zenodo.11562600</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tscnlab/LightLogR/issues">https://github.com/tscnlab/LightLogR/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling <code>rhs(lhs)</code>.
</p>

<hr>
<h2 id='aggregate_Date'>Aggregate dates to a single day</h2><span id='topic+aggregate_Date'></span>

<h3>Description</h3>

<p>Condenses a <code>dataset</code> by aggregating the data to a single day per group, with
a resolution of choice <code>unit</code>. <code><a href="#topic+aggregate_Date">aggregate_Date()</a></code> is opinionated in the sense
that it sets default handlers for each data type of <code>numeric</code>, <code>character</code>,
<code>logical</code>, and <code>factor</code>. These can be overwritten by the user. Columns that
do not fall into one of these categories need to be handled individually by
the user (<code>...</code> argument) or will be removed during aggregation. If no unit
is specified the data will simply be aggregated to the most common interval
(<code>dominant.epoch</code>) in every group. <code><a href="#topic+aggregate_Date">aggregate_Date()</a></code> is especially useful
for summary plots that show an average day.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_Date(
  dataset,
  Datetime.colname = Datetime,
  unit = "none",
  type = c("round", "floor", "ceiling"),
  date.handler = stats::median,
  numeric.handler = mean,
  character.handler = function(x) names(which.max(table(x, useNA = "ifany"))),
  logical.handler = function(x) mean(x) &gt;= 0.5,
  factor.handler = function(x) factor(names(which.max(table(x, useNA = "ifany")))),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate_Date_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="aggregate_Date_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="aggregate_Date_+3A_unit">unit</code></td>
<td>
<p>Unit of binning. See <code><a href="lubridate.html#topic+round_date">lubridate::round_date()</a></code> for examples. The
default is <code>"none"</code>, which will not aggregate the data at all, but is only
recommended for regular data, as the condensation across different days
will be performed by time. Another option is <code>"dominant.epoch"</code>, which
means everything will be aggregated to the most common interval. This is
especially useful for slightly irregular data, but can be computationally
expensive.</p>
</td></tr>
<tr><td><code id="aggregate_Date_+3A_type">type</code></td>
<td>
<p>One of <code>"round"</code>(the default), <code>"ceiling"</code> or <code>"floor"</code>. Setting
chooses the relevant function from <span class="pkg">lubridate</span>.</p>
</td></tr>
<tr><td><code id="aggregate_Date_+3A_date.handler">date.handler</code></td>
<td>
<p>A function that calculates the aggregated day for each
group. By default, this is set to <code>median</code>.</p>
</td></tr>
<tr><td><code id="aggregate_Date_+3A_numeric.handler">numeric.handler</code>, <code id="aggregate_Date_+3A_character.handler">character.handler</code>, <code id="aggregate_Date_+3A_logical.handler">logical.handler</code>, <code id="aggregate_Date_+3A_factor.handler">factor.handler</code></td>
<td>
<p>functions that handle the respective data types. The default handlers
calculate the <code>mean</code> for <code>numeric</code> and the <code>mode</code> for <code>character</code>, <code>factor</code>
and <code>logical</code> types.</p>
</td></tr>
<tr><td><code id="aggregate_Date_+3A_...">...</code></td>
<td>
<p>arguments given over to <code><a href="dplyr.html#topic+summarise">dplyr::summarize()</a></code> to handle columns
that do not fall into one of the categories above.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+aggregate_Date">aggregate_Date()</a></code> splits the <code>Datetime</code> column into a <code>Date.data</code>
and a <code>Time.data</code> column. It will create subgroups for each <code>Time.data</code>
present in a group and aggregate each group into a single day, then remove
the sub grouping.
</p>
<p>Use the <code>...</code> to create summary statistics for each group, e.g. maximum or
minimum values for each time point group.
</p>
<p>Performing <code><a href="#topic+aggregate_Datetime">aggregate_Datetime()</a></code> with any <code>unit</code> and then
<code><a href="#topic+aggregate_Date">aggregate_Date()</a></code> with a <code>unit</code> of <code>"none"</code> is equivalent to just using
<code><a href="#topic+aggregate_Date">aggregate_Date()</a></code> with that <code>unit</code> directly (provided the other arguments
are set the same between the functions). Disentangling the two functions
can be useful to split the computational cost for very small instances of
<code>unit</code> in large datasets. It can also be useful to apply different handlers
when aggregating data to the desired <code>unit</code> of time, before further
aggregation to a single day, as these handlers as well as <code>...</code> are used
twice if the <code>unit</code> is not set to <code>"none"</code>.
</p>


<h3>Value</h3>

<p>A <code>tibble</code> with aggregated <code>Datetime</code> data, at maximum one day per
group. If the handler arguments capture all column types, the number of
columns will be the same as in the input <code>dataset</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
#gg_days without aggregation
sample.data.environment %&gt;%
 gg_days()

#with daily aggregation
sample.data.environment %&gt;%
 aggregate_Date() %&gt;%
 gg_days()

#with daily aggregation and a different time aggregation
sample.data.environment %&gt;%
 aggregate_Date(unit = "15 mins", type = "floor") %&gt;%
 gg_days()

#adding further summary statistics about the range of MEDI
 sample.data.environment %&gt;%
 aggregate_Date(unit = "15 mins", type = "floor",
                MEDI_max = max(MEDI),
                MEDI_min = min(MEDI)) %&gt;%
 gg_days() +
 geom_ribbon(aes(ymin = MEDI_min, ymax = MEDI_max), alpha = 0.5)
</code></pre>

<hr>
<h2 id='aggregate_Datetime'>Aggregate Datetime data</h2><span id='topic+aggregate_Datetime'></span>

<h3>Description</h3>

<p>Condenses a <code>dataset</code> by aggregating the data to a given (shorter) interval
<code>unit</code>. <code><a href="#topic+aggregate_Datetime">aggregate_Datetime()</a></code> is opinionated in the sense that it sets
default handlers for each data type of <code>numeric</code>, <code>character</code>, <code>logical</code>, and
<code>factor</code>. These can be overwritten by the user. Columns that do not fall into
one of these categories need to be handled individually by the user (<code>...</code>
argument) or will be removed during aggregation. If no unit is specified the
data will simply be aggregated to the most common interval
(<code>dominant.epoch</code>), which is most often not an aggregation but a rounding.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_Datetime(
  dataset,
  Datetime.colname = Datetime,
  unit = "dominant.epoch",
  type = c("round", "floor", "ceiling"),
  numeric.handler = mean,
  character.handler = function(x) names(which.max(table(x, useNA = "ifany"))),
  logical.handler = function(x) mean(x) &gt;= 0.5,
  factor.handler = function(x) factor(names(which.max(table(x, useNA = "ifany")))),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate_Datetime_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="aggregate_Datetime_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="aggregate_Datetime_+3A_unit">unit</code></td>
<td>
<p>Unit of binning. See <code><a href="lubridate.html#topic+round_date">lubridate::round_date()</a></code> for examples. The
default is <code>"dominant.epoch"</code>, which means everything will be aggregated to
the most common interval. This is especially useful for slightly irregular
data, but can be computationally expensive. <code>"none"</code> will not aggregate the
data at all.</p>
</td></tr>
<tr><td><code id="aggregate_Datetime_+3A_type">type</code></td>
<td>
<p>One of <code>"round"</code>(the default), <code>"ceiling"</code> or <code>"floor"</code>. Setting
chooses the relevant function from <span class="pkg">lubridate</span>.</p>
</td></tr>
<tr><td><code id="aggregate_Datetime_+3A_numeric.handler">numeric.handler</code>, <code id="aggregate_Datetime_+3A_character.handler">character.handler</code>, <code id="aggregate_Datetime_+3A_logical.handler">logical.handler</code>, <code id="aggregate_Datetime_+3A_factor.handler">factor.handler</code></td>
<td>
<p>functions that handle the respective data types. The default handlers
calculate the <code>mean</code> for <code>numeric</code> and the <code>mode</code> for <code>character</code>, <code>factor</code>
and <code>logical</code> types.</p>
</td></tr>
<tr><td><code id="aggregate_Datetime_+3A_...">...</code></td>
<td>
<p>arguments given over to <code><a href="dplyr.html#topic+summarise">dplyr::summarize()</a></code> to handle columns
that do not fall into one of the categories above.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>tibble</code> with aggregated <code>Datetime</code> data. Usually the number of
rows will be smaller than the input <code>dataset</code>. If the handler arguments
capture all column types, the number of columns will be the same as in the
input <code>dataset</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#dominant epoch without aggregation
sample.data.environment %&gt;%
 dominant_epoch()

#dominant epoch with 5 minute aggregation
sample.data.environment %&gt;%
 aggregate_Datetime(unit = "5 mins") %&gt;%
 dominant_epoch()

#dominant epoch with 1 day aggregation
sample.data.environment %&gt;%
 aggregate_Datetime(unit = "1 day") %&gt;%
 dominant_epoch()
</code></pre>

<hr>
<h2 id='barroso_lighting_metrics'>Circadian lighting metrics from Barroso et al. (2014)</h2><span id='topic+barroso_lighting_metrics'></span>

<h3>Description</h3>

<p>This function calculates the metrics proposed by Barroso et al. (2014)
for light-dosimetry in the context of research on the non-visual effects of light.
The following metrics are calculated:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>barroso_lighting_metrics(
  Light.vector,
  Time.vector,
  epoch = "dominant.epoch",
  loop = FALSE,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="barroso_lighting_metrics_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="barroso_lighting_metrics_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>, <a href="hms.html#topic+hms">hms</a>,
<a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="barroso_lighting_metrics_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="barroso_lighting_metrics_+3A_loop">loop</code></td>
<td>
<p>Logical. Should the data be looped? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="barroso_lighting_metrics_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values (NA) be removed for the calculation?
Defaults to <code>FALSE</code>. If <code>TRUE</code>, for the calculation of <code>bright_cluster</code> and
<code>dark_cluster</code>, missing values will be replaced by 0
(see <code><a href="#topic+period_above_threshold">period_above_threshold</a></code>).</p>
</td></tr>
<tr><td><code id="barroso_lighting_metrics_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should a data frame be returned? If <code>TRUE</code>, a data
frame with seven columns will be returned. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>bright_threshold</code></dt><dd><p>The maximum light intensity for which at least six
hours of measurements are at the same or higher level.</p>
</dd>
<dt><code>dark_threshold</code></dt><dd><p>The minimum light intensity for which at least eight
hours of measurements are at the same or lower level.</p>
</dd>
<dt><code>bright_mean_level</code></dt><dd><p>The 20% trimmed mean of all light intensity measurements
equal or above the <code>bright_threshold</code>.</p>
</dd>
<dt><code>dark_mean_level</code></dt><dd><p>The 20% trimmed mean of all light intensity measurements
equal or below the <code>dark_threshold</code>.</p>
</dd>
<dt><code>bright_cluster</code></dt><dd><p>The longest continuous time interval above the <code>bright_threshold</code>.</p>
</dd>
<dt><code>dark_cluster</code></dt><dd><p>The longest continuous time interval below the <code>dark_threshold</code>.</p>
</dd>
<dt><code>circadian_variation</code></dt><dd><p>A measure of periodicity of the daily lighting
schedule over a given set of days. Calculated as the coefficient of variation
of input light data.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>List or dataframe with the seven values: <code>bright_threshold</code>, <code>dark_threshold</code>,
<code>bright_mean_level</code>, <code>dark_mean_level</code>, <code>bright_cluster</code>, <code>dark_cluster</code>,
<code>circadian_variation</code>. The output type of <code>bright_cluster</code>, <code>dark_cluster</code>,
is a <a href="lubridate.html#topic+duration">duration</a> object.
</p>


<h3>References</h3>

<p>Barroso, A., Simons, K., &amp; Jager, P. de. (2014). Metrics of circadian
lighting for clinical investigations. <em>Lighting Research &amp; Technology</em>,
46(6), 637â€“649. <a href="https://doi.org/10.1177/1477153513502664">doi:10.1177/1477153513502664</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dataset1 &lt;-
  tibble::tibble(
    Id = rep("B", 60 * 24),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),
    MEDI = c(rep(sample(seq(0,1,0.1), 60*8, replace = TRUE)), 
             rep(sample(1:1000, 16, replace = TRUE), each = 60))
  )

dataset1 %&gt;%
  dplyr::reframe(barroso_lighting_metrics(MEDI, Datetime, as.df = TRUE))
  
</code></pre>

<hr>
<h2 id='bright_dark_period'>Brightest or darkest continuous period</h2><span id='topic+bright_dark_period'></span>

<h3>Description</h3>

<p>This function finds the brightest or darkest continuous period of a given
timespan and calculates its <code>mean</code> light level, as well as the timing of the period's
<code>onset</code>, <code>midpoint</code>, and <code>offset</code>. It is defined as the period with the maximum
or minimum mean light level. Note that the data need to be regularly spaced
(i.e., no gaps) for correct results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bright_dark_period(
  Light.vector,
  Time.vector,
  period = c("brightest", "darkest"),
  timespan = "10 hours",
  epoch = "dominant.epoch",
  loop = FALSE,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bright_dark_period_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="bright_dark_period_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>,
<a href="hms.html#topic+hms">hms</a>, <a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="bright_dark_period_+3A_period">period</code></td>
<td>
<p>String indicating the type of period to look for. Can be either
<code>"brightest"</code>(the default) or <code>"darkest"</code>.</p>
</td></tr>
<tr><td><code id="bright_dark_period_+3A_timespan">timespan</code></td>
<td>
<p>The timespan across which to calculate. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a <a href="lubridate.html#topic+duration">duration</a> string, e.g.,
<code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="bright_dark_period_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="bright_dark_period_+3A_loop">loop</code></td>
<td>
<p>Logical. Should the data be looped? If <code>TRUE</code>, a full copy of the data
will be concatenated at the end of the data. Makes only sense for 24 h data.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bright_dark_period_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed for the calculation?
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bright_dark_period_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should the output be returned as a data frame? Defaults
to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assumes regular 24h light data. Otherwise, results may not be
meaningful. Looping the data is recommended for finding the darkest period.
</p>


<h3>Value</h3>

<p>A named list with the <code>mean</code>, <code>onset</code>, <code>midpoint</code>, and <code>offset</code> of the
calculated brightest or darkest period, or if <code>as.df == TRUE</code> a data frame
with columns named <code style="white-space: pre;">&#8288;{period}_{timespan}_{metric}&#8288;</code>. The output type corresponds
to the type of <code>Time.vector</code>, e.g., if <code>Time.vector</code> is HMS, the timing metrics
will be also HMS, and vice versa for POSIXct.
</p>


<h3>References</h3>

<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Dataset with light &gt; 250lx between 06:00 and 18:00
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )

dataset1 %&gt;%
  dplyr::reframe(bright_dark_period(MEDI, Datetime, "brightest", "10 hours",
    as.df = TRUE))
dataset1 %&gt;%
  dplyr::reframe(bright_dark_period(MEDI, Datetime, "darkest", "7 hours",
    loop = TRUE, as.df = TRUE))

# Dataset with duration as Time.vector
dataset2 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Datetime = lubridate::dhours(0:23),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )

dataset2 %&gt;%
  dplyr::reframe(bright_dark_period(MEDI, Datetime, "brightest", "10 hours",
                                    as.df = TRUE))
dataset2 %&gt;%
  dplyr::reframe(bright_dark_period(MEDI, Datetime, "darkest", "5 hours",
                                    loop = TRUE, as.df = TRUE))

</code></pre>

<hr>
<h2 id='Brown_check'>Check whether a value is within the recommended illuminance/MEDI levels by
Brown et al. (2022)</h2><span id='topic+Brown_check'></span>

<h3>Description</h3>

<p>This is a lower level function. It checks a given value against a threshold
for the states given by Brown et al. (2022). The function is vectorized. For
<code>day</code> the threshold is a lower limit, for <code>evening</code> and <code>night</code> the threshold
is an upper limit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Brown_check(
  value,
  state,
  Brown.day = "day",
  Brown.evening = "evening",
  Brown.night = "night",
  Brown.day.th = 250,
  Brown.evening.th = 10,
  Brown.night.th = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Brown_check_+3A_value">value</code></td>
<td>
<p>Illuminance value to check against the recommendation. needs to
be numeric, can be a vector.</p>
</td></tr>
<tr><td><code id="Brown_check_+3A_state">state</code></td>
<td>
<p>The state from Brown et al. (2022). Needs to be a character
vector with the same length as <code>value</code>.</p>
</td></tr>
<tr><td><code id="Brown_check_+3A_brown.day">Brown.day</code>, <code id="Brown_check_+3A_brown.evening">Brown.evening</code>, <code id="Brown_check_+3A_brown.night">Brown.night</code></td>
<td>
<p>The names of the states from Brown
et al. (2022). These are the default values (<code>"day"</code>, <code>"evening"</code>,
<code>"night"</code>), but can be changed if the names in <code>state</code> are different. Needs
to be a character scalar.</p>
</td></tr>
<tr><td><code id="Brown_check_+3A_brown.day.th">Brown.day.th</code>, <code id="Brown_check_+3A_brown.evening.th">Brown.evening.th</code>, <code id="Brown_check_+3A_brown.night.th">Brown.night.th</code></td>
<td>
<p>The thresholds for the
states from Brown et al. (2022). These are the default values (<code>250</code>, <code>10</code>,
<code>1</code>), but can be changed if the thresholds should be different. Needs to be
a numeric scalar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical vector with the same length as <code>value</code> that indicates
whether the value is within the recommended illuminance levels.
</p>


<h3>References</h3>

<p>https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571
</p>


<h3>See Also</h3>

<p>Other Brown: 
<code><a href="#topic+Brown2reference">Brown2reference</a>()</code>,
<code><a href="#topic+Brown_rec">Brown_rec</a>()</code>,
<code><a href="#topic+sleep_int2Brown">sleep_int2Brown</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>states &lt;- c("day", "evening", "night", "day")
values &lt;- c(100, 10, 1, 300)
Brown_check(values, states)
Brown_check(values, states, Brown.day.th = 100)

</code></pre>

<hr>
<h2 id='Brown_rec'>Set the recommended illuminance/MEDI levels by Brown et al. (2022)</h2><span id='topic+Brown_rec'></span>

<h3>Description</h3>

<p>This is a lower level function. It sets the recommended
illuminance/MEDI levels by Brown et al. (2022) for a given state. The
function is vectorized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Brown_rec(
  state,
  Brown.day = "day",
  Brown.evening = "evening",
  Brown.night = "night",
  Brown.day.th = 250,
  Brown.evening.th = 10,
  Brown.night.th = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Brown_rec_+3A_state">state</code></td>
<td>
<p>The state from Brown et al. (2022). Needs to be a character
vector.</p>
</td></tr>
<tr><td><code id="Brown_rec_+3A_brown.day">Brown.day</code>, <code id="Brown_rec_+3A_brown.evening">Brown.evening</code>, <code id="Brown_rec_+3A_brown.night">Brown.night</code></td>
<td>
<p>The names of the states from Brown
et al. (2022). These are the default values (<code>"day"</code>, <code>"evening"</code>,
<code>"night"</code>), but can be changed if the names in <code>state</code> are different. Needs
to be a character scalar.</p>
</td></tr>
<tr><td><code id="Brown_rec_+3A_brown.day.th">Brown.day.th</code>, <code id="Brown_rec_+3A_brown.evening.th">Brown.evening.th</code>, <code id="Brown_rec_+3A_brown.night.th">Brown.night.th</code></td>
<td>
<p>The thresholds for the
states from Brown et al. (2022). These are the default values (<code>250</code>, <code>10</code>,
<code>1</code>), but can be changed if the thresholds should be different. Needs to be
a numeric scalar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with the same length as <code>state</code> that contains the
recommended illuminance/MEDI levels.
</p>


<h3>References</h3>

<p>https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571
</p>


<h3>See Also</h3>

<p>Other Brown: 
<code><a href="#topic+Brown2reference">Brown2reference</a>()</code>,
<code><a href="#topic+Brown_check">Brown_check</a>()</code>,
<code><a href="#topic+sleep_int2Brown">sleep_int2Brown</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>states &lt;- c("day", "evening", "night")
Brown_rec(states)
Brown_rec(states, Brown.day.th = 100)

</code></pre>

<hr>
<h2 id='Brown2reference'>Add Brown et al. (2022) reference illuminance to a dataset</h2><span id='topic+Brown2reference'></span>

<h3>Description</h3>

<p>Adds several columns to a light logger dataset. It requires a column that
contains the Brown states, e.g. &quot;daytime&quot;, &quot;evening&quot;, and &quot;night&quot;. From that
the function will add a column with the recommended illuminance, a column
that checks if the illuminance of the dataset is within the recommended
illuminance levels, and a column that gives a label to the reference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Brown2reference(
  dataset,
  MEDI.colname = MEDI,
  Brown.state.colname = State.Brown,
  Brown.rec.colname = Reference,
  Reference.label = "Brown et al. (2022)",
  overwrite = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Brown2reference_+3A_dataset">dataset</code></td>
<td>
<p>A dataframe that contains a column with the Brown states</p>
</td></tr>
<tr><td><code id="Brown2reference_+3A_medi.colname">MEDI.colname</code></td>
<td>
<p>The name of the column that contains the MEDI values
which are used for checks against the Brown reference illuminance. Must be
part of the dataset.</p>
</td></tr>
<tr><td><code id="Brown2reference_+3A_brown.state.colname">Brown.state.colname</code></td>
<td>
<p>The name of the column that contains the Brown
states. Must be part of the dataset.</p>
</td></tr>
<tr><td><code id="Brown2reference_+3A_brown.rec.colname">Brown.rec.colname</code></td>
<td>
<p>The name of the column that will contain the
recommended illuminance. Must not be part of the dataset, otherwise it will
throw an error.</p>
</td></tr>
<tr><td><code id="Brown2reference_+3A_reference.label">Reference.label</code></td>
<td>
<p>The label that will be used for the reference. Expects
a <code>character</code> scalar.</p>
</td></tr>
<tr><td><code id="Brown2reference_+3A_overwrite">overwrite</code></td>
<td>
<p>If <code>TRUE</code> (defaults to <code>FALSE</code>), the function will
overwrite the <code>Brown.rec.colname</code> column if it already exists.</p>
</td></tr>
<tr><td><code id="Brown2reference_+3A_...">...</code></td>
<td>
<p>Additional arguments that will be passed to <code><a href="#topic+Brown_rec">Brown_rec()</a></code> and
<code><a href="#topic+Brown_check">Brown_check()</a></code>. This is only relevant to correct the names of the daytime
states or the thresholds used within these states. See the documentation of
these functions for more information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>On a lower level, the function uses <code><a href="#topic+Brown_rec">Brown_rec()</a></code> and <code><a href="#topic+Brown_check">Brown_check()</a></code> to
create the required information.
</p>


<h3>Value</h3>

<p>A dataframe on the basis of the <code>dataset</code> that contains the added
columns.
</p>


<h3>References</h3>

<p>https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571
</p>


<h3>See Also</h3>

<p>Other Brown: 
<code><a href="#topic+Brown_check">Brown_check</a>()</code>,
<code><a href="#topic+Brown_rec">Brown_rec</a>()</code>,
<code><a href="#topic+sleep_int2Brown">sleep_int2Brown</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#add Brown reference illuminance to some sample data
testdata &lt;- tibble::tibble(MEDI = c(100, 10, 1, 300),
                  State.Brown = c("day", "evening", "night", "day"))
Brown2reference(testdata)

</code></pre>

<hr>
<h2 id='centroidLE'>Centroid of light exposure</h2><span id='topic+centroidLE'></span>

<h3>Description</h3>

<p>This function calculates the centroid of light exposure as the mean of the
time vector weighted in proportion to the corresponding binned light intensity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centroidLE(
  Light.vector,
  Time.vector,
  bin.size = NULL,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="centroidLE_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="centroidLE_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>, <a href="hms.html#topic+hms">hms</a>,
<a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="centroidLE_+3A_bin.size">bin.size</code></td>
<td>
<p>Value specifying size of bins to average the light data over.
Must be either a <a href="lubridate.html#topic+duration">duration</a> or a <a href="lubridate.html#topic+duration">duration</a> string, e.g.,
<code>"1 day"</code> or <code>"10 sec"</code>. If nothing is provided, no binning will be performed.</p>
</td></tr>
<tr><td><code id="centroidLE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed for the calculation?
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="centroidLE_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should the output be returned as a data frame? If <code>TRUE</code>, a data
frame with a single column named <code>centroidLE</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Single column data frame or vector.
</p>


<h3>References</h3>

<p>Phillips, A. J. K., Clerx, W. M., Oâ€™Brien, C. S., Sano, A., Barger,
L. K., Picard, R. W., Lockley, S. W., Klerman, E. B., &amp; Czeisler, C. A. (2017).
Irregular sleep/wake patterns are associated with poorer academic performance
and delayed circadian and sleep/wake timing. <em>Scientific Reports</em>,
7(1), 3216. <a href="https://doi.org/10.1038/s41598-017-03171-4">doi:10.1038/s41598-017-03171-4</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Dataset with POSIXct time vector
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )
dataset1 %&gt;%
  dplyr::reframe(
    "Centroid of light exposure" = centroidLE(MEDI, Datetime, "2 hours")
  )

# Dataset with hms time vector
dataset2 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Time = hms::as_hms(lubridate::as_datetime(0) + lubridate::hours(0:23)),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )
dataset2 %&gt;%
  dplyr::reframe(
    "Centroid of light exposure" = centroidLE(MEDI, Time, "2 hours")
  )

# Dataset with duration time vector
dataset3 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Hour = lubridate::duration(0:23, "hours"),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )
dataset3 %&gt;%
  dplyr::reframe(
    "Centroid of light exposure" = centroidLE(MEDI, Hour, "2 hours")
  )

</code></pre>

<hr>
<h2 id='count_difftime'>Counts the Time differences (epochs) per group (in a grouped dataset)</h2><span id='topic+count_difftime'></span>

<h3>Description</h3>

<p>Counts the Time differences (epochs) per group (in a grouped dataset)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_difftime(dataset, Datetime.colname = Datetime)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="count_difftime_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="count_difftime_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>tibble</code> with the number of occurences of each time difference per
group
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#get a dataset with irregular intervals
filepath &lt;- system.file("extdata/sample_data_LYS.csv", package = "LightLogR")
dataset &lt;- import$LYS(filepath)

#count_difftime returns the number of occurences of each time difference
#and is more comprehensive in terms of a summary than `gap_finder` or 
#`dominant_epoch`
count_difftime(dataset)
dominant_epoch(dataset)
gap_finder(dataset)

#irregular data can be regularized with `aggregate_Datetime`
dataset %&gt;% aggregate_Datetime(unit = "15 secs") %&gt;% count_difftime()
</code></pre>

<hr>
<h2 id='create_Timedata'>Create a Time-of-Day column in the dataset</h2><span id='topic+create_Timedata'></span>

<h3>Description</h3>

<p>Create a Time-of-Day column in the dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_Timedata(
  dataset,
  Datetime.colname = Datetime,
  Time.data = Time.data,
  output.dataset = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_Timedata_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="create_Timedata_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="create_Timedata_+3A_time.data">Time.data</code></td>
<td>
<p>Name of the newly created column. Expects a <code>symbol</code>. The
default(<code>Time.data</code>) works well with other functions in <a href="#topic+LightLogR">LightLogR</a>.</p>
</td></tr>
<tr><td><code id="create_Timedata_+3A_output.dataset">output.dataset</code></td>
<td>
<p>should the output be a <code>data.frame</code> (Default <code>TRUE</code>) or
a vector with <code>hms</code> (<code>FALSE</code>) times? Expects a <code>logical</code> scalar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> object identical to <code>dataset</code> but with the added
column of Time-of-Day data, or a <code>vector</code> with the Time-of-Day-data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample.data.environment %&gt;% create_Timedata()
</code></pre>

<hr>
<h2 id='cut_Datetime'>Create Datetime bins for visualization and calculation</h2><span id='topic+cut_Datetime'></span>

<h3>Description</h3>

<p><code>cut_Datetime</code> is a wrapper around <code><a href="lubridate.html#topic+round_date">lubridate::round_date()</a></code> (and friends)
combined with <code><a href="dplyr.html#topic+mutate">dplyr::mutate()</a></code>, to create a new column in a light logger
dataset with a specified binsize. This can be <code>"3 hours"</code>, <code>"15 secs"</code>, or
<code>"0.5 days"</code>. It is a useful step between a dataset and a visualization or
summary step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cut_Datetime(
  dataset,
  unit = "3 hours",
  type = c("round", "floor", "ceiling"),
  Datetime.colname = Datetime,
  New.colname = Datetime.rounded,
  group_by = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cut_Datetime_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="cut_Datetime_+3A_unit">unit</code></td>
<td>
<p>Unit of binning. See <code><a href="lubridate.html#topic+round_date">lubridate::round_date()</a></code> for examples. The default is <code>"3 hours"</code>.</p>
</td></tr>
<tr><td><code id="cut_Datetime_+3A_type">type</code></td>
<td>
<p>One of <code>"round"</code>(the default), <code>"ceiling"</code> or <code>"floor"</code>. Setting
chooses the relevant function from <span class="pkg">lubridate</span>.</p>
</td></tr>
<tr><td><code id="cut_Datetime_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="cut_Datetime_+3A_new.colname">New.colname</code></td>
<td>
<p>Column name for the added column in the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="cut_Datetime_+3A_group_by">group_by</code></td>
<td>
<p>Should the data be grouped by the new column? Defaults to <code>FALSE</code></p>
</td></tr>
<tr><td><code id="cut_Datetime_+3A_...">...</code></td>
<td>
<p>Parameter handed over to <code><a href="lubridate.html#topic+round_date">lubridate::round_date()</a></code> and siblings</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> object identical to <code>dataset</code> but with the added
column of binned datetimes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#compare Datetime and Datetime.rounded
sample.data.environment %&gt;%
  cut_Datetime() %&gt;%
  dplyr::slice_sample(n = 5)
</code></pre>

<hr>
<h2 id='data2reference'>Create reference data from other data</h2><span id='topic+data2reference'></span>

<h3>Description</h3>

<p>Create reference data from almost any other data that has a datetime column
and a data column. The reference data can even be created from subsets of the
same data. Examples are that one participant can be used as a reference for
all other participants, or that the first (second,...) day of every
participant data is the reference for any other day. <strong>This function needs to
be carefully handled, when the reference data time intervals are shorter than
the data time intervals. In that case, use <code>aggregate_Datetime()</code> on the
reference data beforehand to lengthen the interval.</strong>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data2reference(
  dataset,
  Reference.data = dataset,
  Datetime.column = Datetime,
  Data.column = MEDI,
  Id.column = Id,
  Reference.column = Reference,
  overwrite = FALSE,
  filter.expression.reference = NULL,
  across.id = FALSE,
  shift.start = FALSE,
  length.restriction.seconds = 60,
  shift.intervals = "auto",
  Reference.label = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data2reference_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset</p>
</td></tr>
<tr><td><code id="data2reference_+3A_reference.data">Reference.data</code></td>
<td>
<p>The data that should be used as reference. By default
the <code>dataset</code> will be used as reference.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_datetime.column">Datetime.column</code></td>
<td>
<p>Datetime column of the <code>dataset</code> and <code>Reference.data</code>.
Need to be the same in both sets. Default is <code>Datetime</code>.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_data.column">Data.column</code></td>
<td>
<p>Data column in the <code>Reference.data</code> that is then converted
to a reference. Default is <code>MEDI</code>.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_id.column">Id.column</code></td>
<td>
<p>Name of the <code>Id.column</code> in both the <code>dataset</code> and the
<code>Reference.data</code>.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_reference.column">Reference.column</code></td>
<td>
<p>Name of the reference column that will be added to
the <code>dataset</code>. Default is <code>Reference</code>. Cannot be the same as any other
column in the <code>dataset</code> and will throw an error if it is.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_overwrite">overwrite</code></td>
<td>
<p>If <code>TRUE</code> (defaults to <code>FALSE</code>), the function will
overwrite the <code>Reference.colname</code> column if it already exists.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_filter.expression.reference">filter.expression.reference</code></td>
<td>
<p>Expression that is used to filter the
<code>Reference.data</code> before it is used as reference. Default is <code>NULL</code>. See</p>
</td></tr>
<tr><td><code id="data2reference_+3A_across.id">across.id</code></td>
<td>
<p>Grouping variables that should be ignored when creating the
reference data. Default is <code>FALSE</code>. If <code>TRUE</code>, all grouping variables are
ignored. If <code>FALSE</code>, no grouping variables are ignored. If a vector of
grouping variables is given, these are ignored.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_shift.start">shift.start</code></td>
<td>
<p>If <code>TRUE</code>, the reference data is shifted to the start of
the respective group. Default is <code>FALSE</code>. The shift ignores the groups
specified in <code>across.id</code>.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_length.restriction.seconds">length.restriction.seconds</code></td>
<td>
<p>Restricts the application of reference data
to a maximum length in seconds. Default is <code>60</code> seconds. This is useful to
avoid reference data being applied to long periods of time, e.g., when
there are gaps in the reference data</p>
</td></tr>
<tr><td><code id="data2reference_+3A_shift.intervals">shift.intervals</code></td>
<td>
<p>Time shift in seconds, that is applied to every data
point in the reference data. Default is <code>"auto"</code>. If <code>"auto"</code>, the shift is
calculated by halving the most frequent time difference between two data
points in the reference data. If a number is given, this number in seconds
is used as the shift. Can also use <code><a href="lubridate.html#topic+duration">lubridate::duration()</a></code> to specify the
shift.</p>
</td></tr>
<tr><td><code id="data2reference_+3A_reference.label">Reference.label</code></td>
<td>
<p>Label that is added to the reference data. If <code>NULL</code>,
no label is added.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To use subsets of data, use the <code>filter.expression.reference</code> argument to
specify the subsets of data. The <code>across.id</code> argument specifies whether the
reference data should be used across all or some grouping variables (e.g.,
across participants). The <code>shift.start</code> argument enables a shift of the
reference data start time to the start of the respective group.
</p>
<p>and @examples for more information. The expression is evaluated
within <code><a href="dplyr.html#topic+filter">dplyr::filter()</a></code>.
</p>


<h3>Value</h3>

<p>A <code>dataset</code> with a new column <code>Reference</code> that contains the reference
data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(lubridate)
library(ggplot2)

gg_reference &lt;- function(dataset) {
dataset %&gt;%
ggplot(aes(x = Datetime, y = MEDI, color = Id)) +
geom_line(linewidth = 1) +
geom_line(aes(y = Reference), color = "black", size = 0.25, linetype = "dashed") +
theme_minimal() + facet_wrap(~ Id, scales = "free_y")
}

#in this example, each data point is its own reference
sample.data.environment %&gt;%
  data2reference() %&gt;%
  gg_reference()

#in this example, the first day of each ID is the reference for the other days
#this requires grouping of the Data by Day, which is then specified in across.id
#also, shift.start needs to be set to TRUE, to shift the reference data to the
#start of the groupings
sample.data.environment %&gt;% group_by(Id, Day = as_date(Datetime)) %&gt;%
data2reference(
  filter.expression.reference =  as_date(Datetime) == min(as_date(Datetime)),
  shift.start = TRUE,
  across.id = "Day") %&gt;%
  gg_reference()

#in this example, the Environment Data will be used as a reference
sample.data.environment %&gt;%
data2reference(
  filter.expression.reference =  Id == "Environment",
  across.id = TRUE) %&gt;%
  gg_reference()
</code></pre>

<hr>
<h2 id='Datetime_breaks'>Create a (shifted) sequence of Datetimes for axis breaks</h2><span id='topic+Datetime_breaks'></span>

<h3>Description</h3>

<p>Take a vector of Datetimes and create a sequence of Datetimes with a given
shift and interval. This is a helper function to create breaks for plotting,
e.g. in <code><a href="#topic+gg_days">gg_days()</a></code>, and is best used in conjunction with
<code><a href="#topic+Datetime_limits">Datetime_limits()</a></code>. The function is a thin wrapper around <code><a href="base.html#topic+seq">seq()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Datetime_breaks(x, shift = lubridate::duration(12, "hours"), by = "1 day")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Datetime_breaks_+3A_x">x</code></td>
<td>
<p>a vector of <code>Datetimes</code></p>
</td></tr>
<tr><td><code id="Datetime_breaks_+3A_shift">shift</code></td>
<td>
<p>a <code>numeric</code> giving the number of  <code>duration</code> object, e.g.
<code>lubridate::duration(12, "hours")</code></p>
</td></tr>
<tr><td><code id="Datetime_breaks_+3A_by">by</code></td>
<td>
<p>a <code>character</code> scalar giving the unit of the interval in
<code><a href="base.html#topic+seq">base::seq()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>vector</code> of <code>Datetimes</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- c("2023-08-15", "2023-08-20")
Datetime_breaks(dataset)
Datetime_breaks(dataset, shift = 0)
Datetime_breaks(dataset, by = "12 hours")
</code></pre>

<hr>
<h2 id='Datetime_limits'>Find or set sensible limits for Datetime axis</h2><span id='topic+Datetime_limits'></span>

<h3>Description</h3>

<p>Take a vector of <code>Datetimes</code> and return the start of the first and end of the
last day of data. The <code>start</code> and the <code>length</code> can be adjusted by
<code>durations</code>, like <code><a href="lubridate.html#topic+duration">lubridate::ddays()</a></code>. It is used in the <code><a href="#topic+gg_days">gg_days()</a></code>
function to return a sensible x-axis. This function is a thin wrapper around
<code><a href="lubridate.html#topic+round_date">lubridate::floor_date()</a></code> and <code><a href="lubridate.html#topic+round_date">lubridate::ceiling_date()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Datetime_limits(
  x,
  start = NULL,
  length = NULL,
  unit = "1 day",
  midnight.rollover = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Datetime_limits_+3A_x">x</code></td>
<td>
<p>a vector of <code>Datetimes</code></p>
</td></tr>
<tr><td><code id="Datetime_limits_+3A_start">start</code></td>
<td>
<p>optional <code>duration</code> object, e.g. <code>lubridate::ddays(1)</code> that
shifts the start of the <code>Datetime</code> vector by this amount.</p>
</td></tr>
<tr><td><code id="Datetime_limits_+3A_length">length</code></td>
<td>
<p>optional <code>duration</code> object, e.g. <code>lubridate::ddays(7)</code> that
shifts the end of the <code>Datetime</code> vector by this amount from the (adjusted)
start. Depending on the data, you might have to subtract one day from the
desired length to get the correct axis-scaling if you start at midnight.</p>
</td></tr>
<tr><td><code id="Datetime_limits_+3A_unit">unit</code></td>
<td>
<p>a <code>character</code> scalar giving the unit of rounding in
<code><a href="lubridate.html#topic+round_date">lubridate::floor_date()</a></code> and <code><a href="lubridate.html#topic+round_date">lubridate::ceiling_date()</a></code></p>
</td></tr>
<tr><td><code id="Datetime_limits_+3A_midnight.rollover">midnight.rollover</code></td>
<td>
<p>a <code>logical</code> scalar indicating whether to rollover in cases of exact matches of rounded values and input values. Helpful if some cases fall exactly on the rounded values and others don't.</p>
</td></tr>
<tr><td><code id="Datetime_limits_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code><a href="lubridate.html#topic+round_date">lubridate::floor_date()</a></code> and
<code><a href="lubridate.html#topic+round_date">lubridate::ceiling_date()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a 2 item <code>vector</code> of <code>Datetimes</code> with the (adjusted) start and end of
the input vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- c("2023-08-15", "2023-08-20")
breaks &lt;- Datetime_breaks(dataset)
Datetime_limits(breaks)
Datetime_limits(breaks, start = lubridate::ddays(1))
Datetime_limits(breaks, length = lubridate::ddays(2))
</code></pre>

<hr>
<h2 id='disparity_index'>Disparity index</h2><span id='topic+disparity_index'></span>

<h3>Description</h3>

<p>This function calculates the continuous disparity index as described in
FernÃ¡ndez-MartÃ­nez et al. (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disparity_index(Light.vector, na.rm = FALSE, as.df = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disparity_index_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="disparity_index_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed? Defaults to FALSE</p>
</td></tr>
<tr><td><code id="disparity_index_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should the output be returned as a data frame? If <code>TRUE</code>, a data
frame with a single column named <code>disparity_index</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Single column data frame or vector.
</p>


<h3>References</h3>

<p>FernÃ¡ndez-MartÃ­nez, M., Vicca, S., Janssens, I. A., Carnicer, J.,
MartÃ­n-Vide, J., &amp; PeÃ±uelas, J. (2018).
The consecutive disparity index, D: A measure of temporal variability in
ecological studies. <em>Ecosphere</em>, 9(12), e02527.
<a href="https://doi.org/10.1002/ecs2.2527">doi:10.1002/ecs2.2527</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),
    MEDI = sample(0:1000, 24),
  )
dataset1 %&gt;%
  dplyr::reframe(
    "Disparity index" = disparity_index(MEDI)
  )

</code></pre>

<hr>
<h2 id='dominant_epoch'>Determine the dominant epoch/interval of a dataset</h2><span id='topic+dominant_epoch'></span>

<h3>Description</h3>

<p>Calculate the dominant epoch/interval of a dataset. The dominant
epoch/interval is the epoch/interval that is most frequent in the dataset.
The calculation is done per group, so that you might get multiple variables.
If two or more epochs/intervals are equally frequent, the first one (shortest
one) is chosen.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dominant_epoch(dataset, Datetime.colname = Datetime)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dominant_epoch_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Needs to be a dataframe.</p>
</td></tr>
<tr><td><code id="dominant_epoch_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>The column that contains the datetime. Needs to be a
<code>POSIXct</code> and part of the dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>tibble</code> with one row per group and a column with the
<code>dominant.epoch</code> as a <code><a href="lubridate.html#topic+duration">lubridate::duration()</a></code>. Also a column with the
<code>group.indices</code>, which is helpful for referencing the <code>dominant.epoch</code>
across dataframes of equal grouping.
</p>


<h3>See Also</h3>

<p>Other regularize: 
<code><a href="#topic+gap_finder">gap_finder</a>()</code>,
<code><a href="#topic+gap_handler">gap_handler</a>()</code>,
<code><a href="#topic+gapless_Datetimes">gapless_Datetimes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;-
tibble::tibble(Id = c("A", "A", "A", "B", "B", "B"),
              Datetime = lubridate::as_datetime(1) +
                         lubridate::days(c(0:2, 4, 6, 8)))
dataset
#get the dominant epoch by group
dataset %&gt;%
dplyr::group_by(Id) %&gt;%
dominant_epoch()

#get the dominant epoch of the whole dataset
dataset %&gt;%
dominant_epoch()              
</code></pre>

<hr>
<h2 id='dst_change_handler'>Handle jumps in Daylight Savings (DST) that are missing in the data</h2><span id='topic+dst_change_handler'></span>

<h3>Description</h3>

<p>When data is imported through <code>LightLogR</code> and a timezone applied, it is
assumed that the timestamps are correct - which is the case, e.g., if
timestamps are stored in <code>UTC</code>, or they are in local time. Some if not most
measurement devices are set to local time before a recording interval starts.
If during the recording a daylight savings jump happens (in either
direction), the device might not adjust timestamps for this change. This
results in an unwanted shift in the data, starting at the time of the DST
jump and likely continues until the end of a file. <code>dst_change_handler</code> is
used to detect such jumps within a group and apply the correct shift in the
data (i.e., the shift that should have been applied by the device).
</p>
<p><strong>important</strong> Note that this function is only useful if the time stamp in
the raw data deviates from the actual date-time. Note also, that this
function results in a gap during the DST jump, which should be handled by
<code>gap_handler()</code> afterwards. It will also result in potentially double the
timestamps during the jum back from DST to standard time. This will result
in some inconsistencies with some functions, so we recommend to use
<code>aggregate_Datetime()</code> afterwards with a <code>unit</code> equal to the dominant epoch.
Finally, the function is not equipped to handle more than one jump per group.
The jump is based on whether the group starts out with DST or not. <strong>the
function will remove datetime rows with <code>NA</code> values</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dst_change_handler(
  dataset,
  Datetime.colname = Datetime,
  filename.colname = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dst_change_handler_+3A_dataset">dataset</code></td>
<td>
<p>dataset to be summarized, must be a <code>dataframe</code></p>
</td></tr>
<tr><td><code id="dst_change_handler_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>name of the column that contains the Datetime data, expects a <code>symbol</code></p>
</td></tr>
<tr><td><code id="dst_change_handler_+3A_filename.colname">filename.colname</code></td>
<td>
<p>(optional) column name that contains the filename.
If provided, it will use this column as a temporary grouping variable
additionally to the <code>dataset</code> grouping.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The detection of a DST jump is based on the function <code>lubridate::dst()</code> and jumps are only applied within a group. During import, this function is used if <code>dst_adjustment = TRUE</code> is set and includes by default the filename as the grouping variable, additionally to <code>Id</code>.
</p>


<h3>Value</h3>

<p>A <code>tibble</code> with the same columns as the input dataset, but shifted
</p>


<h3>See Also</h3>

<p>Other DST: 
<code><a href="#topic+dst_change_summary">dst_change_summary</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#create some data that crosses a DST jump
data &lt;- 
 tibble::tibble(
 Datetime = seq.POSIXt(from = as.POSIXct("2023-03-26 01:30:00", tz = "Europe/Berlin"),
                     to = as.POSIXct("2023-03-26 03:00:00", tz = "Europe/Berlin"),
                     by = "30 mins"),
                     Value = 1)
 #as can be seen next, there is a gap in the data - this is necessary when
 #using a timezone with DST. 
 data$Datetime
 #Let us say now, that the device did not adjust for the DST - thus the 03:00 
 #timestamp is actually 04:00 in local time. This can be corrected for by:
 data %&gt;% dst_change_handler() %&gt;% .$Datetime
</code></pre>

<hr>
<h2 id='dst_change_summary'>Get a summary of groups where a daylight saving time change occurs.</h2><span id='topic+dst_change_summary'></span>

<h3>Description</h3>

<p>Get a summary of groups where a daylight saving time change occurs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dst_change_summary(dataset, Datetime.colname = Datetime)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dst_change_summary_+3A_dataset">dataset</code></td>
<td>
<p>dataset to be summarized, must be a <code>dataframe</code></p>
</td></tr>
<tr><td><code id="dst_change_summary_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>name of the column that contains the Datetime data, expects a <code>symbol</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>tibble</code> with the groups where a dst change occurs. The column <code>dst_start</code> is a boolean that indicates whether the start of this group occurs during daylight savings.
</p>


<h3>See Also</h3>

<p>Other DST: 
<code><a href="#topic+dst_change_handler">dst_change_handler</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample.data.environment %&gt;% 
  dplyr::mutate(Datetime = 
  lubridate::with_tz(Datetime, "Europe/Berlin") + lubridate::dweeks(10)) %&gt;%
  dst_change_summary()
</code></pre>

<hr>
<h2 id='duration_above_threshold'>Duration above/below threshold or within threshold range</h2><span id='topic+duration_above_threshold'></span>

<h3>Description</h3>

<p>This function calculates the duration spent above/below a specified threshold
light level or within a specified range of light levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duration_above_threshold(
  Light.vector,
  Time.vector,
  comparison = c("above", "below"),
  threshold,
  epoch = "dominant.epoch",
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duration_above_threshold_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="duration_above_threshold_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>, <a href="hms.html#topic+hms">hms</a>,
<a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="duration_above_threshold_+3A_comparison">comparison</code></td>
<td>
<p>String specifying whether the time above or below threshold
should be calculated. Can be either <code>"above"</code> (the default) or <code>"below"</code>. If
two values are provided for <code>threshold</code>, this argument will be ignored.</p>
</td></tr>
<tr><td><code id="duration_above_threshold_+3A_threshold">threshold</code></td>
<td>
<p>Single numeric value or two numeric values specifying the
threshold light level(s) to compare with. If a vector with two values is provided,
the time within the two thresholds will be calculated.</p>
</td></tr>
<tr><td><code id="duration_above_threshold_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="duration_above_threshold_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values (NA) be removed for the calculation?
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="duration_above_threshold_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should a data frame with be returned? If <code>TRUE</code>, a data
frame with a single column named <code style="white-space: pre;">&#8288;duration_{comparison}_{threshold}&#8288;</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="lubridate.html#topic+duration">duration</a> object as single value, or single column data frame.
</p>


<h3>References</h3>

<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 60
# Dataset with epoch = 1min
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", N),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),
    MEDI = sample(c(sample(1:249, N / 2), sample(250:1000, N / 2))),
  )
# Dataset with epoch = 30s
dataset2 &lt;-
  tibble::tibble(
    Id = rep("B", N),
    Datetime = lubridate::as_datetime(0) + lubridate::seconds(seq(30, N * 30, 30)),
    MEDI = sample(c(sample(1:249, N / 2), sample(250:1000, N / 2))),
  )
dataset.combined &lt;- rbind(dataset1, dataset2)

dataset1 %&gt;%
  dplyr::reframe("TAT &gt;250lx" = duration_above_threshold(MEDI, Datetime, threshold = 250))

dataset1 %&gt;%
  dplyr::reframe(duration_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE))

# Group by Id to account for different epochs
dataset.combined %&gt;%
  dplyr::group_by(Id) %&gt;%
  dplyr::reframe("TAT &gt;250lx" = duration_above_threshold(MEDI, Datetime, threshold = 250))

</code></pre>

<hr>
<h2 id='exponential_moving_average'>Exponential moving average filter (EMA)</h2><span id='topic+exponential_moving_average'></span>

<h3>Description</h3>

<p>This function smoothes the data using an exponential moving average filter
with a specified decay half-life.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exponential_moving_average(
  Light.vector,
  Time.vector,
  decay = "90 min",
  epoch = "dominant.epoch"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exponential_moving_average_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data. Missing values are
replaced by 0.</p>
</td></tr>
<tr><td><code id="exponential_moving_average_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>, <a href="hms.html#topic+hms">hms</a>,
<a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="exponential_moving_average_+3A_decay">decay</code></td>
<td>
<p>The decay half-life controlling the exponential smoothing.
Can be either a <a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it
needs to be a valid <a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.
The default is set to <code>"90 mins"</code> for a biologically relevant estimate (see
the reference paper).</p>
</td></tr>
<tr><td><code id="exponential_moving_average_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The timeseries is assumed to be regular. Missing values in the
light data will be replaced by 0.
</p>


<h3>Value</h3>

<p>A numeric vector containing the smoothed light data. The output has the same
length as <code>Light.vector</code>.
</p>


<h3>References</h3>

<p>Price, L. L. A. (2014). On the Role of Exponential Smoothing in Circadian
Dosimetry. <em>Photochemistry and Photobiology</em>, 90(5), 1184-1192.
<a href="https://doi.org/10.1111/php.12282">doi:10.1111/php.12282</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample.data.environment.EMA = sample.data.environment %&gt;%
  dplyr::filter(Id == "Participant") %&gt;%
  filter_Datetime(length = lubridate::days(2)) %&gt;%
  dplyr::mutate(MEDI.EMA = exponential_moving_average(MEDI, Datetime))

# Plot to compare results
sample.data.environment.EMA %&gt;%
  ggplot2::ggplot(ggplot2::aes(x = Datetime)) +
  ggplot2::geom_line(ggplot2::aes(y = MEDI), colour = "black") +
  ggplot2::geom_line(ggplot2::aes(y = MEDI.EMA), colour = "red")
  
</code></pre>

<hr>
<h2 id='filter_Datetime'>Filter Datetimes in a dataset.</h2><span id='topic+filter_Datetime'></span><span id='topic+filter_Date'></span>

<h3>Description</h3>

<p>Filtering a dataset based on Dates or Datetimes may often be necessary prior
to calcuation or visualization. The functions allow for a filtering based on
simple <code>strings</code> or <code>Datetime</code> scalars, or by specifying a length. They also
support prior <span class="pkg">dplyr</span> grouping, which is useful, e.g., when you only want to
filter the first two days of measurement data for every participant,
regardless of the actual date. If you want to filter based on times of the
day, look to <code><a href="#topic+filter_Time">filter_Time()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter_Datetime(
  dataset,
  Datetime.colname = Datetime,
  start = NULL,
  end = NULL,
  length = NULL,
  length_from_start = TRUE,
  full.day = FALSE,
  tz = NULL,
  only_Id = NULL,
  filter.expr = NULL
)

filter_Date(..., start = NULL, end = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filter_Datetime_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_start">start</code>, <code id="filter_Datetime_+3A_end">end</code></td>
<td>
<p>For <code><a href="#topic+filter_Datetime">filter_Datetime()</a></code> a <code>POSIXct</code> or <code>character</code> scalar in
the form of <code>"yyyy-mm-dd hh-mm-ss"</code> giving the respective start and end
time positions for the filtered dataframe. If you only want to provide
<code>dates</code> in the form of <code>"yyyy-mm-dd"</code>, use the wrapper function
<code><a href="#topic+filter_Date">filter_Date()</a></code>.
</p>

<ul>
<li><p> If one or both of start/end are not provided, the times will be taken from the respective extreme values of the <code>dataset</code>.
</p>
</li>
<li><p> If <code>length</code> is provided and one of start/end is not, the other will be calculated based on the given value.
</p>
</li>
<li><p> If <code>length</code> is provided and both of start/end are NULL, the time from the
respective start is taken.
</p>
</li></ul>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_length">length</code></td>
<td>
<p>Either a Period or Duration from <span class="pkg">lubridate</span>. E.g., <code>days(2) + hours(12)</code> will give a period of 2.5 days, whereas <code>ddays(2) + dhours(12)</code>
will give a duration. For the difference between periods and durations look
at the documentation from <span class="pkg">lubridate</span>. Basically, periods model clocktimes,
whereas durations model physical processes. This matters on several
occasions, like leap years, or daylight savings. You can also provide a
<code>character</code> scalar in the form of e.g. &quot;1 day&quot;, which will be converted
into a period.</p>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_length_from_start">length_from_start</code></td>
<td>
<p>A <code>logical</code> indicating whether the <code>length</code> argument
should be applied to the start (default, TRUE) or the end of the data
(FALSE). Only relevant if neither the <code>start</code> nor the <code>end</code> arguments are
provided.</p>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_full.day">full.day</code></td>
<td>
<p>A <code>logical</code> indicating whether the <code>start</code> param should be
rounded to a full day, when only the <code>length</code> argument is provided (Default
is FALSE). This is useful, e.g., when the first observation in the dataset
is slightly after midnight. If TRUE, it will count the length from midnight
on to avoid empty days in plotting with <code><a href="#topic+gg_day">gg_day()</a></code>.</p>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_tz">tz</code></td>
<td>
<p>Timezone of the start/end times. If <code>NULL</code> (the default), it will
take the timezone from the <code>Datetime.colname</code> column.</p>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_only_id">only_Id</code></td>
<td>
<p>An expression of <code>ids</code> where the filtering should be applied
to. If <code>NULL</code> (the default), the filtering will be applied to all <code>ids</code>.
Based on the this expression, the dataset will be split in two and only
where the given expression evaluates to <code>TRUE</code>, will the filtering take
place. Afterwards both sets are recombined and sorted by <code>Datetime</code>.</p>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_filter.expr">filter.expr</code></td>
<td>
<p>Advanced filtering conditions. If not <code>NULL</code> (default) and
given an <code>expression</code>, this is used to <code><a href="dplyr.html#topic+filter">dplyr::filter()</a></code> the results. This
can be useful to filter, e.g. for group-specific conditions, like starting
after the first two days of measurement (see examples).</p>
</td></tr>
<tr><td><code id="filter_Datetime_+3A_...">...</code></td>
<td>
<p>Parameter handed over to <code><a href="lubridate.html#topic+round_date">lubridate::round_date()</a></code> and siblings</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> object identical to <code>dataset</code> but with only the
specified Dates/Times.
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filter_Time">filter_Time</a>()</code>
</p>
<p>Other filter: 
<code><a href="#topic+filter_Time">filter_Time</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(lubridate)
library(dplyr)
#baseline
range.unfiltered &lt;- sample.data.environment$Datetime %&gt;% range()
range.unfiltered

#setting the start of a dataset
sample.data.environment %&gt;%
filter_Datetime(start = "2023-08-18 12:00:00") %&gt;%
pull(Datetime) %&gt;%
range()

#setting the end of a dataset
sample.data.environment %&gt;%
filter_Datetime(end = "2023-08-18 12:00:00") %&gt;% pull(Datetime) %&gt;% range()

#setting a period of a dataset
sample.data.environment %&gt;%
filter_Datetime(end = "2023-08-18 12:00:00", length = days(2)) %&gt;%
pull(Datetime) %&gt;% range()

#setting only the period of a dataset
sample.data.environment %&gt;%
filter_Datetime(length = days(2)) %&gt;%
pull(Datetime) %&gt;% range()

#advanced filtering based on grouping (second day of each group)
sample.data.environment %&gt;%
#shift the "Environment" group by one day
mutate(
Datetime = ifelse(Id == "Environment", Datetime + ddays(1), Datetime) %&gt;%
as_datetime()) -&gt; sample
sample %&gt;% summarize(Daterange = paste(min(Datetime), max(Datetime), sep = " - "))
#now we can use the `filter.expr` argument to filter from the second day of each group
sample %&gt;%
filter_Datetime(filter.expr = Datetime &gt; Datetime[1] + days(1)) %&gt;%
summarize(Daterange = paste(min(Datetime), max(Datetime), sep = " - "))
sample.data.environment %&gt;% filter_Date(end = "2023-08-17")
</code></pre>

<hr>
<h2 id='filter_Datetime_multiple'>Filter multiple times based on a list of arguments.</h2><span id='topic+filter_Datetime_multiple'></span>

<h3>Description</h3>

<p><code><a href="#topic+filter_Datetime_multiple">filter_Datetime_multiple()</a></code> is a wrapper around <code><a href="#topic+filter_Datetime">filter_Datetime()</a></code> or
<code><a href="#topic+filter_Date">filter_Date()</a></code> that allows the cumulative filtering of <code>Datetimes</code> based on
varying filter conditions. It is most useful in conjunction with the
<code>only_Id</code> argument, e.g., to selectively cut off dates depending on
participants (see examples)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter_Datetime_multiple(
  dataset,
  arguments,
  filter_function = filter_Datetime,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filter_Datetime_multiple_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset</p>
</td></tr>
<tr><td><code id="filter_Datetime_multiple_+3A_arguments">arguments</code></td>
<td>
<p>A list of arguments to be passed to <code><a href="#topic+filter_Datetime">filter_Datetime()</a></code> or
<code><a href="#topic+filter_Date">filter_Date()</a></code>. each list entry must itself be a list of arguments, e.g,
<code>list(start = "2021-01-01", only_Id = quote(Id == 216))</code>. Expressions have
to be quoted with <code><a href="base.html#topic+quote">quote()</a></code> or <code><a href="rlang.html#topic+expr">rlang::expr()</a></code>.</p>
</td></tr>
<tr><td><code id="filter_Datetime_multiple_+3A_filter_function">filter_function</code></td>
<td>
<p>The function to be used for filtering, either
<code>filter_Datetime</code> (the default) or <code>filter_Date</code></p>
</td></tr>
<tr><td><code id="filter_Datetime_multiple_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the filter function. If the
<code>length</code> argument is provided here instead of the <code>argument</code>, it has to be
written as a string, e.g., <code>length = "1 day"</code>, instead of <code>length = lubridate::days(1)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with the filtered data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>arguments &lt;- list(
 list(start = "2023-08-17", only_Id = quote(Id == "Participant")),
 list(end = "2023-08-17", only_Id = quote(Id == "Environment")))
 #compare the unfiltered dataset
 sample.data.environment %&gt;% gg_overview(Id.colname = Id)
 #compare the unfiltered dataset
 sample.data.environment %&gt;%
 filter_Datetime_multiple(arguments = arguments, filter_Date) %&gt;%
 gg_overview(Id.colname = Id)
</code></pre>

<hr>
<h2 id='filter_Time'>Filter Times in a dataset.</h2><span id='topic+filter_Time'></span>

<h3>Description</h3>

<p>Filter Times in a dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter_Time(
  dataset,
  Datetime.colname = Datetime,
  start = NULL,
  end = NULL,
  length = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filter_Time_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="filter_Time_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="filter_Time_+3A_start">start</code>, <code id="filter_Time_+3A_end">end</code>, <code id="filter_Time_+3A_length">length</code></td>
<td>
<p>a <code>character</code> scalar in the form of <code>"hh-mm-ss"</code>
giving the respective start, end, or length for the filtered dataframe. The
input can also come from a <code>POSIXct</code> datetime, where only the time
component will be used.
</p>

<ul>
<li><p> If one or both of start/end are not provided, the times will be taken from the respective extreme values of the <code>dataset</code>.
</p>
</li>
<li><p> If <code>length</code> is provided and one of start/end is not, the other will be calculated based on the given value.
</p>
</li>
<li><p> If <code>length</code> is provided and both of start/end are not, the time from the
respective start is taken.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> object identical to <code>dataset</code> but with only the
specified Times.
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filter_Datetime">filter_Datetime</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample.data.environment %&gt;%
filter_Time(start = "4:00:34", length = "12:00:00") %&gt;%
dplyr::pull(Time.data) %&gt;% range() %&gt;% hms::as_hms()
</code></pre>

<hr>
<h2 id='frequency_crossing_threshold'>Frequency of crossing light threshold</h2><span id='topic+frequency_crossing_threshold'></span>

<h3>Description</h3>

<p>This functions calculates the number of times a given threshold
light level is crossed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frequency_crossing_threshold(
  Light.vector,
  threshold,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frequency_crossing_threshold_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="frequency_crossing_threshold_+3A_threshold">threshold</code></td>
<td>
<p>Single numeric value specifying the threshold light level to compare with.</p>
</td></tr>
<tr><td><code id="frequency_crossing_threshold_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing light values be removed? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="frequency_crossing_threshold_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should the output be returned as a data frame? If <code>TRUE</code>, a data
frame with a single column named <code style="white-space: pre;">&#8288;frequency_crossing_{threshold}&#8288;</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame or matrix with pairs of threshold and calculated values.
</p>


<h3>References</h3>

<p>Alvarez, A. A., &amp; Wildsoet, C. F. (2013). Quantifying light
exposure patterns in young adult students. <em>Journal of Modern Optics</em>,
60(14), 1200â€“1208. <a href="https://doi.org/10.1080/09500340.2013.845700">doi:10.1080/09500340.2013.845700</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N = 60
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", N),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),
    MEDI = sample(c(sample(1:249, N / 2), sample(250:1000, N / 2))),
  )

dataset1 %&gt;%
  dplyr::reframe("Frequency crossing 250lx" = frequency_crossing_threshold(MEDI, threshold = 250))

dataset1 %&gt;%
  dplyr::reframe(frequency_crossing_threshold(MEDI, threshold = 250, as.df = TRUE))

</code></pre>

<hr>
<h2 id='gap_finder'>Check for and output gaps in a dataset</h2><span id='topic+gap_finder'></span>

<h3>Description</h3>

<p>Quickly check for implicit missing <code>Datetime</code> data. Outputs a message with a
short summary, and can optionally return the gaps as a <code>tibble</code>. Uses
<code>gap_handler()</code> internally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gap_finder(
  dataset,
  Datetime.colname = Datetime,
  epoch = "dominant.epoch",
  gap.data = FALSE,
  silent = FALSE,
  full.days = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gap_finder_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Needs to be a dataframe.</p>
</td></tr>
<tr><td><code id="gap_finder_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>The column that contains the datetime. Needs to be a
<code>POSIXct</code> and part of the dataset.</p>
</td></tr>
<tr><td><code id="gap_finder_+3A_epoch">epoch</code></td>
<td>
<p>The epoch to use for the gapless sequence. Can be either a
<code>lubridate::duration()</code> or a string. If it is a string, it needs to be
either '&quot;dominant.epoch&quot;' (the default) for a guess based on the data or a valid <code>lubridate::duration()</code> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="gap_finder_+3A_gap.data">gap.data</code></td>
<td>
<p>Logical. If <code>TRUE</code>, returns a <code>tibble</code> of the gaps in the
dataset. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gap_finder_+3A_silent">silent</code></td>
<td>
<p>Logical. If <code>TRUE</code>, suppresses the message with the summary of
the gaps in the dataset. Default is <code>FALSE</code>. Only used for unit tests.</p>
</td></tr>
<tr><td><code id="gap_finder_+3A_full.days">full.days</code></td>
<td>
<p>If <code>TRUE</code>, the gapless sequence will include the whole first and last day where there is data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>gap_finder()</code> function is a wrapper around <code>gap_handler()</code> with the
<code>behavior</code> argument set to <code>"gaps"</code>. The main difference is that
<code>gap_finder()</code> returns a message with a short summary of the gaps in the
dataset, and that the <code>tibble</code> with the gaps contains a column <code>gap.id</code> that
indicates the gap number, which is useful to determine, e.g., the consecutive
number of gaps between measurement data.
</p>


<h3>Value</h3>

<p>Prints message with a short summary of the gaps in the dataset. If
<code>gap.data = TRUE</code>, returns a <code>tibble</code> of the gaps in the dataset.
</p>


<h3>See Also</h3>

<p>Other regularize: 
<code><a href="#topic+dominant_epoch">dominant_epoch</a>()</code>,
<code><a href="#topic+gap_handler">gap_handler</a>()</code>,
<code><a href="#topic+gapless_Datetimes">gapless_Datetimes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;-
tibble::tibble(Id = c("A", "A", "A", "B", "B", "B"),
              Datetime = lubridate::as_datetime(1) +
                         lubridate::days(c(0:2, 4, 6, 8)) +
                         lubridate::hours(c(0,12,rep(0,4)))) %&gt;%
dplyr::group_by(Id)
dataset

#look for gaps assuming the epoch is the dominant epoch of each group
gap_finder(dataset)

#return the gaps as a tibble
gap_finder(dataset, gap.data = TRUE)

#assuming the epoch is 1 day, we have different gaps, and the datapoint at noon is now `irregular`
gap_finder(dataset, epoch = "1 day")
</code></pre>

<hr>
<h2 id='gap_handler'>Fill implicit gaps in a light logger dataset</h2><span id='topic+gap_handler'></span>

<h3>Description</h3>

<p>Datasets from light loggers often have implicit gaps. These gaps are implicit in the sense that consecutive timestamps (<code>Datetimes</code>) might not follow a regular epoch/interval. This function fills these implicit gaps by creating a gapless sequence of <code>Datetimes</code> and joining it to the dataset. The gapless sequence is determined by the minimum and maximum <code>Datetime</code> in the dataset (per group) and an epoch. The epoch can either be guessed from the dataset or specified by the user. A sequence of gapless <code>Datetimes</code> can be created with the <code><a href="#topic+gapless_Datetimes">gapless_Datetimes()</a></code> function, whereas the dominant epoch in the data can be checked with the <code><a href="#topic+dominant_epoch">dominant_epoch()</a></code> function. The <code>behaviour</code> argument specifies how the data is combined. By default, the data is joined with a full join, which means that all rows from the gapless sequence are kept, even if there is no matching row in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gap_handler(
  dataset,
  Datetime.colname = Datetime,
  epoch = "dominant.epoch",
  behavior = c("full_sequence", "regulars", "irregulars", "gaps"),
  full.days = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gap_handler_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Needs to be a dataframe.</p>
</td></tr>
<tr><td><code id="gap_handler_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>The column that contains the datetime. Needs to be a
<code>POSIXct</code> and part of the dataset.</p>
</td></tr>
<tr><td><code id="gap_handler_+3A_epoch">epoch</code></td>
<td>
<p>The epoch to use for the gapless sequence. Can be either a
<code>lubridate::duration()</code> or a string. If it is a string, it needs to be
either '&quot;dominant.epoch&quot;' (the default) for a guess based on the data or a valid <code>lubridate::duration()</code> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="gap_handler_+3A_behavior">behavior</code></td>
<td>
<p>The behavior of the join of the <code>dataset</code> with the <code>gapless</code> sequence. Can be one of <code>"full_sequence"</code> (the default), <code>"regulars"</code>, <code>"irregulars"</code>, or <code>"gaps"</code>. See @return for details.</p>
</td></tr>
<tr><td><code id="gap_handler_+3A_full.days">full.days</code></td>
<td>
<p>If <code>TRUE</code>, the gapless sequence will include the whole first and last day where there is data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A modified <code>tibble</code> similar to <code>dataset</code> but with handling of implicit gaps, depending on the <code>behavior</code> argument:
</p>

<ul>
<li> <p><code>"full_sequence"</code> adds timestamps to the <code>dataset</code> that are missing based on a full sequence of <code>Datetimes</code> (i.e., the gapless sequence). The <code>dataset</code> is this equal (no gaps) or greater in the number of rows than the input. One column is added. <code>is.implicit</code> indicates whether the row was added (<code>TRUE</code>) or not (<code>FALSE</code>). This helps differentiating measurement values from values that might be imputed later on.
</p>
</li>
<li> <p><code>"regulars"</code> keeps only rows from the gapless sequence that have a matching row in the dataset. This can be interpreted as a row-reduced <code>dataset</code> with only regular timestamps according to the <code>epoch</code>. In case of no gaps this tibble has the same number of rows as the input.
</p>
</li>
<li> <p><code>"irregulars"</code> keeps only rows from the <code>dataset</code> that do not follow the regular sequence of <code>Datetimes</code> according to the <code>epoch</code>. In case of no gaps this tibble has 0 rows.
</p>
</li>
<li> <p><code>"gaps"</code> returns a <code>tibble</code> of all implicit gaps in the dataset. In case of no gaps this tibble has 0 rows.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other regularize: 
<code><a href="#topic+dominant_epoch">dominant_epoch</a>()</code>,
<code><a href="#topic+gap_finder">gap_finder</a>()</code>,
<code><a href="#topic+gapless_Datetimes">gapless_Datetimes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;-
tibble::tibble(Id = c("A", "A", "A", "B", "B", "B"),
              Datetime = lubridate::as_datetime(1) +
                         lubridate::days(c(0:2, 4, 6, 8)) +
                         lubridate::hours(c(0,12,rep(0,4)))) %&gt;% 
dplyr::group_by(Id)
dataset
#assuming the epoch is 1 day, we can add implicit data to our dataset
dataset %&gt;% gap_handler(epoch = "1 day")

#we can also check whether there are irregular Datetimes in our dataset
dataset %&gt;% gap_handler(epoch = "1 day", behavior = "irregulars")

#to get to the gaps, we can use the "gaps" behavior
dataset %&gt;% gap_handler(epoch = "1 day", behavior = "gaps")
 
#finally, we can also get just the regular Datetimes
dataset %&gt;% gap_handler(epoch = "1 day", behavior = "regulars")
</code></pre>

<hr>
<h2 id='gapless_Datetimes'>Create a gapless sequence of Datetimes</h2><span id='topic+gapless_Datetimes'></span>

<h3>Description</h3>

<p>Create a gapless sequence of Datetimes. The Datetimes are determined by the
minimum and maximum Datetime in the dataset and an epoch. The epoch can
either be guessed from the dataset or specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gapless_Datetimes(
  dataset,
  Datetime.colname = Datetime,
  epoch = "dominant.epoch",
  full.days = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gapless_Datetimes_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Needs to be a dataframe.</p>
</td></tr>
<tr><td><code id="gapless_Datetimes_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>The column that contains the datetime. Needs to be a
<code>POSIXct</code> and part of the dataset.</p>
</td></tr>
<tr><td><code id="gapless_Datetimes_+3A_epoch">epoch</code></td>
<td>
<p>The epoch to use for the gapless sequence. Can be either a
<code>lubridate::duration()</code> or a string. If it is a string, it needs to be
either '&quot;dominant.epoch&quot;' (the default) for a guess based on the data or a valid <code>lubridate::duration()</code> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="gapless_Datetimes_+3A_full.days">full.days</code></td>
<td>
<p>If <code>TRUE</code>, the gapless sequence will include the whole first and last day where there is data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>tibble</code> with a gapless sequence of <code>Datetime</code> as specified by
<code>epoch</code>.
</p>


<h3>See Also</h3>

<p>Other regularize: 
<code><a href="#topic+dominant_epoch">dominant_epoch</a>()</code>,
<code><a href="#topic+gap_finder">gap_finder</a>()</code>,
<code><a href="#topic+gap_handler">gap_handler</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  dataset &lt;- 
  tibble::tibble(Id = c("A", "A", "A", "B", "B", "B"),
                 Datetime = lubridate::as_datetime(1) +
                 lubridate::days(c(0:2, 4, 6, 8))) %&gt;% 
                 dplyr::group_by(Id)
  
  dataset %&gt;% gapless_Datetimes()
  dataset %&gt;% dplyr::ungroup() %&gt;%  gapless_Datetimes()
  dataset %&gt;% gapless_Datetimes(epoch = "1 day")
</code></pre>

<hr>
<h2 id='gg_day'>Create a simple Time-of-Day plot of light logger data, faceted by Date</h2><span id='topic+gg_day'></span>

<h3>Description</h3>

<p><code><a href="#topic+gg_day">gg_day()</a></code> will create a simple ggplot for every data in a dataset. The
result can further be manipulated like any ggplot. This will be sensible to
refine styling or guides.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_day(
  dataset,
  start.date = NULL,
  end.date = NULL,
  x.axis = Datetime,
  y.axis = MEDI,
  aes_col = NULL,
  aes_fill = NULL,
  group = Id,
  geom = "point",
  scales = c("fixed", "free_x", "free_y", "free"),
  x.axis.breaks = hms::hms(hours = seq(0, 24, by = 3)),
  y.axis.breaks = c(-10^(5:0), 0, 10^(0:5)),
  y.scale = "symlog",
  y.scale.sc = FALSE,
  x.axis.label = "Time of Day",
  y.axis.label = "Illuminance (lx, MEDI)",
  format.day = "%d/%m",
  title = NULL,
  subtitle = NULL,
  interactive = FALSE,
  facetting = TRUE,
  jco_color = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_day_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the <code>x.axis.</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_start.date">start.date</code>, <code id="gg_day_+3A_end.date">end.date</code></td>
<td>
<p>Choose an optional start or end date within your
<code>dataset</code>. Expects a <code>date</code>, which can also be a <code>character</code> that is
interpretable as a date, e.g., <code>"2023-06-03"</code>. If you need a Datetime or
want to cut specific times of each day, use the <code><a href="#topic+filter_Datetime">filter_Datetime()</a></code>
function. Defaults to <code>NULL</code>, which means that the plot starts/ends with
the earliest/latest date within the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_x.axis">x.axis</code>, <code id="gg_day_+3A_y.axis">y.axis</code></td>
<td>
<p>column name that contains the datetime (x, defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>) and the dependent variable (y, defaults to <code>"MEDI"</code>, or
melanopic EDI, which is a standard measure of stimulus strength for the
nonvisual effects of light). Expects a <code>symbol</code>. Needs to be part of the
<code>dataset</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_aes_col">aes_col</code>, <code id="gg_day_+3A_aes_fill">aes_fill</code></td>
<td>
<p>optional arguments that define separate sets and
colors or fills them. Expects anything that works with the layer data
<code><a href="ggplot2.html#topic+aes">ggplot2::aes()</a></code>. The default color palette can be overwritten outside the
function (see examples).</p>
</td></tr>
<tr><td><code id="gg_day_+3A_group">group</code></td>
<td>
<p>Optional column name that defines separate sets. Useful for
certain geoms like <code>boxplot</code>.Expects anything that works with the layer
data <code><a href="ggplot2.html#topic+aes">ggplot2::aes()</a></code></p>
</td></tr>
<tr><td><code id="gg_day_+3A_geom">geom</code></td>
<td>
<p>What geom should be used for visualization? Expects a <code>character</code>
</p>

<ul>
<li> <p><code>"point"</code> for <code><a href="ggplot2.html#topic+geom_point">ggplot2::geom_point()</a></code>
</p>
</li>
<li> <p><code>"line"</code>  for <code><a href="ggplot2.html#topic+geom_path">ggplot2::geom_line()</a></code>
</p>
</li>
<li> <p><code>"ribbon"</code> for <code><a href="ggplot2.html#topic+geom_ribbon">ggplot2::geom_ribbon()</a></code>
</p>
</li>
<li><p> as the value is just input into the <code>geom_</code> function from <span class="pkg">ggplot2</span>, other variants work as well, but are not extensively tested.
</p>
</li></ul>
</td></tr>
<tr><td><code id="gg_day_+3A_scales">scales</code></td>
<td>
<p>For <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code>, should scales be &quot;fixed&quot;, &quot;free&quot;
or free in one dimension (&quot;free_y&quot; is the default). Expects a <code>character</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_x.axis.breaks">x.axis.breaks</code>, <code id="gg_day_+3A_y.axis.breaks">y.axis.breaks</code></td>
<td>
<p>Where should breaks occur on the x and
y.axis? Expects a <code style="white-space: pre;">&#8288;numeric vector&#8288;</code> with all the breaks. If you want to
activate the default behaviour of <span class="pkg">ggplot2</span>, you need to put in
<code><a href="ggplot2.html#topic+waiver">ggplot2::waiver()</a></code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_y.scale">y.scale</code></td>
<td>
<p>How should the y-axis be scaled?
</p>

<ul>
<li><p> Defaults to <code>"symlog"</code>, which is a logarithmic scale that can also handle negative values.
</p>
</li>
<li> <p><code>"log10"</code> would be a straight logarithmic scale, but cannot handle negative values.
</p>
</li>
<li> <p><code>"identity"</code> does nothing (continuous scaling).
</p>
</li>
<li><p> a transforming function, such as <code><a href="#topic+symlog_trans">symlog_trans()</a></code> or <code><a href="scales.html#topic+transform_identity">scales::identity_trans()</a></code>, which allow for more control.
</p>
</li></ul>
</td></tr>
<tr><td><code id="gg_day_+3A_y.scale.sc">y.scale.sc</code></td>
<td>
<p><code>logical</code> for whether scientific notation shall be used.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_x.axis.label">x.axis.label</code>, <code id="gg_day_+3A_y.axis.label">y.axis.label</code></td>
<td>
<p>labels for the x- and y-axis. Expects a
<code>character</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_format.day">format.day</code></td>
<td>
<p>Label for each day. Default is <code style="white-space: pre;">&#8288;%d/%m&#8288;</code>, which shows the day
and month. Expects a <code>character</code>. For an overview of sensible options look
at <code><a href="base.html#topic+strptime">base::strptime()</a></code></p>
</td></tr>
<tr><td><code id="gg_day_+3A_title">title</code></td>
<td>
<p>Plot title. Expects a <code>character</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_subtitle">subtitle</code></td>
<td>
<p>Plot subtitle. Expects a <code>character</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_interactive">interactive</code></td>
<td>
<p>Should the plot be interactive? Expects a <code>logical</code>.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_facetting">facetting</code></td>
<td>
<p>Should an automated facet by day be applied? Default is
<code>TRUE</code> and uses the <code>Day.data</code> variable that the function also creates if
not present.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_jco_color">jco_color</code></td>
<td>
<p>Should the <code><a href="ggsci.html#topic+scale_jco">ggsci::scale_color_jco()</a></code> color palette be used?
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="gg_day_+3A_...">...</code></td>
<td>
<p>Other options that get passed to the main geom function. Can be
used to adjust to adjust size, linewidth, or linetype.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Besides plotting, the function creates two new variables from the given
<code>Datetime</code>:
</p>

<ul>
<li> <p><code>Day.data</code> is a factor that is used for facetting with <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code>. Make sure to use this variable, if you change the faceting manually. Also, the function checks, whether this variable already exists. If it does, it will only convert it to a factor and do the faceting on that variable.
</p>
</li>
<li> <p><code>Time.data</code> is an <code>hms</code> created with <code><a href="hms.html#topic+hms">hms::as_hms()</a></code> that is used for the x.axis
</p>
</li></ul>

<p>The default scaling of the y-axis is a <code>symlog</code> scale, which is a logarithmic
scale that only starts scaling after a given threshold (default = 0). This
enables values of 0 in the plot, which are common in light logger data, and
even enables negative values, which might be sensible for non-light data. See
<code><a href="#topic+symlog_trans">symlog_trans()</a></code> for details on tweaking this scale. The scale can also be
changed to a normal or logarithmic scale - see the y.scale argument for more.
</p>
<p>The default scaling of the color and fill scales is discrete, with the
<code><a href="ggsci.html#topic+scale_jco">ggsci::scale_color_jco()</a></code> and <code><a href="ggsci.html#topic+scale_jco">ggsci::scale_fill_jco()</a></code> scales. To use a
continuous scale, use the <code>jco_color = FALSE</code> setting. Both <code>fill</code> and
<code>color</code> aesthetics are set to <code>NULL</code> by default. For most geoms, this is not
important, but geoms that automatically use those aesthetics (like
geom_bin2d, where fill = stat(count)) are affected by this. Manually adding
the required aesthetic (like <code>aes_fill = ggplot2::stat(count)</code> will fix
this).
</p>


<h3>Value</h3>

<p>A ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#use `col`for separation of different sets
plot &lt;- gg_day(
sample.data.environment,
scales = "fixed",
end.date = "2023-08-16",
y.axis.label = "mEDI (lx)",
aes_col = Id)
plot

#you can easily overwrite the color scale afterwards
plot + ggplot2::scale_color_discrete()

#or change the facetting
plot + ggplot2::facet_wrap(~Day.data + Id)
</code></pre>

<hr>
<h2 id='gg_days'>Create a simple datetime plot of light logger data, faceted by group</h2><span id='topic+gg_days'></span>

<h3>Description</h3>

<p><code><a href="#topic+gg_days">gg_days()</a></code> will create a simple ggplot along the timeline. The result can
further be manipulated like any ggplot. This will be sensible to refine
styling or guides. Through the <code>x.axis.limits</code> arguments, the plot can be
much refined to align several groups of differing datetime ranges. It uses
the <code><a href="#topic+Datetime_limits">Datetime_limits()</a></code> function to calculate the limits of the x-axis.
Another notable functions that are used are <code><a href="#topic+Datetime_breaks">Datetime_breaks()</a></code> to calculate
the breaks of the x-axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_days(
  dataset,
  x.axis = Datetime,
  y.axis = MEDI,
  aes_col = NULL,
  aes_fill = NULL,
  group = NULL,
  geom = "line",
  scales = c("free_x", "free_y", "fixed", "free"),
  x.axis.breaks = Datetime_breaks,
  y.axis.breaks = c(-10^(5:0), 0, 10^(0:5)),
  y.scale = "symlog",
  y.scale.sc = FALSE,
  x.axis.label = "Datetime",
  y.axis.label = "Illuminance (lx, MEDI)",
  x.axis.limits = Datetime_limits,
  x.axis.format = "%a %D",
  title = NULL,
  subtitle = NULL,
  interactive = FALSE,
  facetting = TRUE,
  jco_color = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_days_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the <code>x.axis.</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_x.axis">x.axis</code>, <code id="gg_days_+3A_y.axis">y.axis</code></td>
<td>
<p>column name that contains the datetime (x, defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>) and the dependent variable (y, defaults to <code>"MEDI"</code>, or
melanopic EDI, which is a standard measure of stimulus strength for the
nonvisual effects of light). Expects a <code>symbol</code>. Needs to be part of the
<code>dataset</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_aes_col">aes_col</code>, <code id="gg_days_+3A_aes_fill">aes_fill</code></td>
<td>
<p>optional input that defines separate sets and colors
or fills them. Expects anything that works with the layer data
<code><a href="ggplot2.html#topic+aes">ggplot2::aes()</a></code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_group">group</code></td>
<td>
<p>Optional column name that defines separate sets. Useful for
certain geoms like <code>boxplot</code>.Expects anything that works with the layer
data <code><a href="ggplot2.html#topic+aes">ggplot2::aes()</a></code></p>
</td></tr>
<tr><td><code id="gg_days_+3A_geom">geom</code></td>
<td>
<p>What geom should be used for visualization? Expects a <code>character</code>
</p>

<ul>
<li> <p><code>"point"</code> for <code><a href="ggplot2.html#topic+geom_point">ggplot2::geom_point()</a></code>
</p>
</li>
<li> <p><code>"line"</code>  for <code><a href="ggplot2.html#topic+geom_path">ggplot2::geom_line()</a></code>
</p>
</li>
<li> <p><code>"ribbon"</code> for <code><a href="ggplot2.html#topic+geom_ribbon">ggplot2::geom_ribbon()</a></code>
</p>
</li>
<li><p> as the value is just input into the <code>geom_</code> function from <span class="pkg">ggplot2</span>, other variants work as well, but are not extensively tested.
</p>
</li></ul>
</td></tr>
<tr><td><code id="gg_days_+3A_scales">scales</code></td>
<td>
<p>For <code><a href="ggplot2.html#topic+facet_wrap">ggplot2::facet_wrap()</a></code>, should scales be <code>"fixed"</code>,
<code>"free"</code> or <code>"free"</code> in one dimension (<code>"free_x"</code> is the default). Expects
a <code>character</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_x.axis.breaks">x.axis.breaks</code></td>
<td>
<p>The (major) breaks of the x-axis. Defaults to
<code><a href="#topic+Datetime_breaks">Datetime_breaks()</a></code>. The function has several options for adjustment. The
default setting place a major break every 12 hours, starting at 12:00 of
the first day.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_y.axis.breaks">y.axis.breaks</code></td>
<td>
<p>Where should breaks occur on the y.axis? Expects a
<code style="white-space: pre;">&#8288;numeric vector&#8288;</code> with all the breaks or a function that calculates them
based on the limits. If you want to activate the default behaviour of
<span class="pkg">ggplot2</span>, you need to put in <code><a href="ggplot2.html#topic+waiver">ggplot2::waiver()</a></code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_y.scale">y.scale</code></td>
<td>
<p>How should the y-axis be scaled?
</p>

<ul>
<li><p> Defaults to <code>"symlog"</code>, which is a logarithmic scale that can also handle negative values.
</p>
</li>
<li> <p><code>"log10"</code> would be a straight logarithmic scale, but cannot handle negative values.
</p>
</li>
<li> <p><code>"identity"</code> does nothing (continuous scaling).
</p>
</li>
<li><p> a transforming function, such as <code><a href="#topic+symlog_trans">symlog_trans()</a></code> or <code><a href="scales.html#topic+transform_identity">scales::identity_trans()</a></code>, which allow for more control.
</p>
</li></ul>
</td></tr>
<tr><td><code id="gg_days_+3A_y.scale.sc">y.scale.sc</code></td>
<td>
<p><code>logical</code> for whether scientific notation shall be used.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_x.axis.label">x.axis.label</code>, <code id="gg_days_+3A_y.axis.label">y.axis.label</code></td>
<td>
<p>labels for the x- and y-axis. Expects a
<code>character</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_x.axis.limits">x.axis.limits</code></td>
<td>
<p>The limits of the x-axis. Defaults to
<code><a href="#topic+Datetime_limits">Datetime_limits()</a></code>. Can and should be adjusted to shift the x-axis to
align different groups of data.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_x.axis.format">x.axis.format</code></td>
<td>
<p>The format of the x-axis labels. Defaults to <code>"%a %D"</code>,
which is the weekday and date. See <code><a href="base.html#topic+strptime">base::strptime()</a></code> for more options.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_title">title</code></td>
<td>
<p>Plot title. Expects a <code>character</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_subtitle">subtitle</code></td>
<td>
<p>Plot subtitle. Expects a <code>character</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_interactive">interactive</code></td>
<td>
<p>Should the plot be interactive? Expects a <code>logical</code>.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_facetting">facetting</code></td>
<td>
<p>Should an automated facet by grouping be applied? Default is
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_jco_color">jco_color</code></td>
<td>
<p>Should the <code><a href="ggsci.html#topic+scale_jco">ggsci::scale_color_jco()</a></code> color palette be used?
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="gg_days_+3A_...">...</code></td>
<td>
<p>Other options that get passed to the main geom function. Can be
used to adjust to adjust size, linewidth, or linetype.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default scaling of the y-axis is a <code>symlog</code> scale, which is a logarithmic
scale that only starts scaling after a given threshold (default = 0). This
enables values of 0 in the plot, which are common in light logger data, and
even enables negative values, which might be sensible for non-light data. See
<code><a href="#topic+symlog_trans">symlog_trans()</a></code> for details on tweaking this scale. The scale can also be
changed to a normal or logarithmic scale - see the y.scale argument for more.
</p>


<h3>Value</h3>

<p>A ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;-
sample.data.environment %&gt;%
aggregate_Datetime(unit = "5 mins")

dataset %&gt;% gg_days()
#restrict the x-axis to 3 days
dataset %&gt;%
gg_days(
x.axis.limits = \(x) Datetime_limits(x, length = lubridate::ddays(3))
)
</code></pre>

<hr>
<h2 id='gg_doubleplot'>Double Plots</h2><span id='topic+gg_doubleplot'></span>

<h3>Description</h3>

<p>The function is by default opinionated, and will automatically select the best way to display the double date plot. However, the user can also manually select the type of double date plot to be displayed: repeating each day (default when there is only one day in all of the groups), or displaying consecutive days (default when there are multiple days in the groups).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_doubleplot(
  dataset,
  Datetime.colname = Datetime,
  type = c("auto", "repeat", "next"),
  geom = "ribbon",
  alpha = 0.5,
  col = "grey40",
  fill = "#EFC000FF",
  linewidth = 0.4,
  x.axis.breaks.next = Datetime_breaks,
  x.axis.format.next = "%a %D",
  x.axis.breaks.repeat = ~Datetime_breaks(.x, by = "6 hours", shift =
    lubridate::duration(0, "hours")),
  x.axis.format.repeat = "%H:%M",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_doubleplot_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="gg_doubleplot_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="gg_doubleplot_+3A_type">type</code></td>
<td>
<p>One of &quot;auto&quot;, &quot;repeat&quot;, or &quot;next&quot;. The default is &quot;auto&quot;, which will automatically select the best way to display the double date plot based on the amount of days in the dataset (<code style="white-space: pre;">&#8288;all = 1 &gt;&gt; "repeat", else "next&#8288;</code>). &quot;repeat&quot; will repeat each day in the plot, and &quot;next&quot; will display consecutive days.</p>
</td></tr>
<tr><td><code id="gg_doubleplot_+3A_geom">geom</code></td>
<td>
<p>The type of geom to be used in the plot. The default is &quot;ribbon&quot;.</p>
</td></tr>
<tr><td><code id="gg_doubleplot_+3A_alpha">alpha</code>, <code id="gg_doubleplot_+3A_linewidth">linewidth</code></td>
<td>
<p>The alpha and linewidth setting of the geom. The default is 0.5 and 0.4, respectively.</p>
</td></tr>
<tr><td><code id="gg_doubleplot_+3A_col">col</code>, <code id="gg_doubleplot_+3A_fill">fill</code></td>
<td>
<p>The color and fill of the geom. The default is &quot;#EFC000FF&quot;. If the parameters <code>aes_col</code> or <code>aes_fill</code> are used through <code>...</code>, these will override the respective <code>col</code> and <code>fill</code> parameters.</p>
</td></tr>
<tr><td><code id="gg_doubleplot_+3A_x.axis.breaks.next">x.axis.breaks.next</code>, <code id="gg_doubleplot_+3A_x.axis.breaks.repeat">x.axis.breaks.repeat</code></td>
<td>
<p>Datetime breaks when consecutive days are displayed (<code>type = "next"</code>) or days are repeated (<code>type = "repeat"</code>). Must be a function. The default for <code>next</code> is a label at 12:00 am of each day, and for <code>repeat</code> is a label every 6 hours.</p>
</td></tr>
<tr><td><code id="gg_doubleplot_+3A_x.axis.format.next">x.axis.format.next</code>, <code id="gg_doubleplot_+3A_x.axis.format.repeat">x.axis.format.repeat</code></td>
<td>
<p>Datetime label format when consecutive days are displayed (<code>type = "next"</code>) or days are repeated (<code>type = "repeat"</code>). The default for <code>next</code> is <code>"%a %D"</code>, showing the date, and for <code>repeat</code> ist <code>"%H:%M"</code>, showing hours and minutes. See <code><a href="base.html#topic+strptime">base::strptime()</a></code> for more options.</p>
</td></tr>
<tr><td><code id="gg_doubleplot_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+gg_days">gg_days()</a></code>. When the arguments <code>aes_col</code> and <code>aes_fill</code> are used, they will invalidate the <code>col</code> and <code>fill</code> parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+gg_doubleplot">gg_doubleplot()</a></code> is a wrapper function for <code><a href="#topic+gg_days">gg_days()</a></code>, combined with an internal function to duplicate and reorganize dates in a dataset for a <em>double plot</em> view. This means that the same day is displayed multiple times within the plot in order to reveal pattern across days.
</p>


<h3>Value</h3>

<p>a ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#take only the Participant data from sample data, and three days
library(dplyr)
library(lubridate)
library(ggplot2)
sample.data &lt;- 
sample.data.environment %&gt;% 
dplyr::filter(Id == "Participant") %&gt;% 
filter_Date(length = ddays(3))

#create a double plot with the default settings
sample.data %&gt;% gg_doubleplot()

#repeat the same day in the plot
sample.data %&gt;% gg_doubleplot(type = "repeat")

#use the function with more than one Id
sample.data.environment %&gt;% 
filter_Date(length = ddays(3)) %&gt;% 
gg_doubleplot(aes_fill = Id, aes_col = Id) +
facet_wrap(~ Date.data, ncol = 1, scales = "free_x", strip.position = "left")

#if data is already grouped by days, type = "repeat" will be automatic
sample.data.environment %&gt;% 
dplyr::group_by(Date = date(Datetime), .add = TRUE) %&gt;% 
filter_Date(length = ddays(3)) %&gt;% 
gg_doubleplot(aes_fill = Id, aes_col = Id) + 
guides(fill = "none", col = "none") + #remove the legend
facet_wrap(~ Date.data, ncol = 1, scales = "free_x", strip.position = "left")

#combining `aggregate_Date()` with `gg_doubleplot()` easily creates a good
#overview of the data
sample.data.environment %&gt;%
aggregate_Date() %&gt;%
gg_doubleplot()
</code></pre>

<hr>
<h2 id='gg_overview'>Plot an overview of dataset intervals with implicit missing data</h2><span id='topic+gg_overview'></span>

<h3>Description</h3>

<p>Plot an overview of dataset intervals with implicit missing data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_overview(
  dataset,
  Datetime.colname = Datetime,
  Id.colname = Id,
  gap.data = NULL,
  ...,
  interactive = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_overview_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the <code>x.axis.</code>.</p>
</td></tr>
<tr><td><code id="gg_overview_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="gg_overview_+3A_id.colname">Id.colname</code></td>
<td>
<p>The column name of the Id column (default is <code>Id</code>), needs
to be in the <code>dataset</code>. This is also used as the y-axis variable and is the
minimum grouping variable.</p>
</td></tr>
<tr><td><code id="gg_overview_+3A_gap.data">gap.data</code></td>
<td>
<p>Optionally provide a <code>tibble</code> with <code>start</code> and <code>end</code>
<code>Datetimes</code> of gaps per group. If not provided, the function uses
<code><a href="#topic+gap_finder">gap_finder()</a></code> to calculate implicit missing data. This might be
computationally intensive for large datasets and many missing data. In
these cases it can make sense to calculate those gaps beforehand and
provide them to the function. If an empty <code>tibble</code> (<code><a href="tibble.html#topic+tibble">tibble::tibble()</a></code>) is
provided, the function will just plot the start and end dates of the
dataset, which is computationally very fast at the cost of additional info.</p>
</td></tr>
<tr><td><code id="gg_overview_+3A_...">...</code></td>
<td>
<p>Additional arguments given to the main <code><a href="ggplot2.html#topic+aes">ggplot2::aes()</a></code> used for
styling depending on data within the <code>dataset</code></p>
</td></tr>
<tr><td><code id="gg_overview_+3A_interactive">interactive</code></td>
<td>
<p>Should the plot be interactive? Expects a <code>logical</code>.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample.data.environment %&gt;% gg_overview()
</code></pre>

<hr>
<h2 id='import_adjustment'>Adjust device imports or make your own</h2><span id='topic+import_adjustment'></span>

<h3>Description</h3>

<p>Adjust device imports or make your own
</p>


<h3>Usage</h3>

<pre><code class='language-R'>import_adjustment(import_expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="import_adjustment_+3A_import_expr">import_expr</code></td>
<td>
<p>A named list of import expressions. The basis for
<code>LightLogR</code>'s import functions is the included dataset <code>ll_import_expr</code>. If
this function were to be given that exact dataset, and bound to a variable
called <code>import</code>, it would be identical to the <code>import</code> function. See
<code>details</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should only be used with some knowledge of how
expressions work in R. The minimal required output for an expression to work
as expected, it must lead to a data frame containing a <code>Datetime</code> column with
the correct time zone. It has access to all arguments defined in the
description of <code>import_Dataset()</code>. The <code>...</code> argument should be passed to
whatever csv reader function is used, so that it works as expected. Look at
<code>ll_import_expr$LYS</code> for a quite minimal example.
</p>


<h3>Value</h3>

<p>A list of import functions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#create a new import function for the LYS device, same as the old
new_import &lt;- import_adjustment(ll_import_expr)
#the new one is identical to the old one in terms of the function body
identical(body(import$LYS), body(new_import$LYS))

#change the import expression for the LYS device to add a message at the top
ll_import_expr$LYS[[4]] &lt;-
rlang::expr({ cat("**This is a new import function**\n")
data
})
new_import &lt;- import_adjustment(ll_import_expr)
filepath &lt;- system.file("extdata/sample_data_LYS.csv", package = "LightLogR")
#Now, a message is printed when the import function is called
new_import &lt;- new_import$LYS(filepath)
</code></pre>

<hr>
<h2 id='import_Dataset'>Import a light logger dataset or related data</h2><span id='topic+import_Dataset'></span><span id='topic+import'></span>

<h3>Description</h3>

<p>Imports a dataset and does the necessary transformations to get the right
column formats. Unless specified otherwise, the function will set the
timezone of the data to <code>UTC</code>. It will also enforce an <code>Id</code> to separate
different datasets and will order/arrange the dataset within each <code>Id</code> by
Datetime. See the Details and Devices section for more information and the
full list of arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>import_Dataset(device, ...)

import
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="import_Dataset_+3A_device">device</code></td>
<td>
<p>From what device do you want to import? For a few devices,
there is a sample data file that you can use to test the function (see the
examples). See <a href="#topic+supported.devices">supported.devices</a> for a list of supported devices and see
below for more information on devices with specific requirements.</p>
</td></tr>
<tr><td><code id="import_Dataset_+3A_...">...</code></td>
<td>
<p>Parameters that get handed down to the specific import functions</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 10.
</p>


<h3>Details</h3>

<p>There are specific and a general import function. The general import function
is described below, whereas the specific import functions take the form of
<code>import$device()</code>. The general import function is a thin wrapper around the
specific import functions. The specific import functions take the following
arguments:
</p>

<ul>
<li> <p><code>filename</code>: Filename(s) for the Dataset. Can also contain the filepath,
but <code>path</code> must then be <code>NULL</code>. Expects a <code>character</code>. If the vector is
longer than <code>1</code>, multiple files will be read in into one Tibble.
</p>
</li>
<li> <p><code>path</code>: Optional path for the dataset(s). <code>NULL</code> is the default. Expects
a <code>character</code>.
</p>
</li>
<li> <p><code>n_max</code>: maximum number of lines to read. Default is <code>Inf</code>.
</p>
</li>
<li> <p><code>tz</code>: Timezone of the data. <code>"UTC"</code> is the default. Expects a
<code>character</code>. You can look up the supported timezones with <code><a href="base.html#topic+OlsonNames">OlsonNames()</a></code>.
</p>
</li>
<li> <p><code>Id.colname</code>: Lets you specify a column for the id of a dataset. Expects a
symbol (Default is <code>Id</code>). This column will be used for grouping
(<code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>).
</p>
</li>
<li> <p><code>auto.id</code>: If the <code>Id.colname</code> column is not part of the <code>dataset</code>, the <code>Id</code>
can be automatically extracted from the filename. The argument expects a
regular expression <a href="base.html#topic+regex">regex</a> and will by default just give the whole filename
without file extension.
</p>
</li>
<li> <p><code>manual.id</code>: If this argument is not <code>NULL</code>, and no <code>Id</code> column is part
of the <code>dataset</code>, this <code>character</code> scalar will be used. <strong>We discourage the
use of this arguments when importing more than one file</strong>
</p>
</li>
<li> <p><code>locale</code>: The locale controls defaults that vary from place to place.
</p>
</li>
<li> <p><code>dst_adjustment</code>: If a file crosses daylight savings time, but the device does not adjust time stamps accordingly, you can set this argument to <code>TRUE</code>, to apply this shift manually. It is selective, so it will only be done in files that cross between DST and standard time. Default is <code>FALSE</code>. Uses <code>dst_change_handler()</code> to do the adjustment. Look there for more infos. It is not equipped to handle two jumps in one file (so back and forth between DST and standard time), but will work fine if jums occur in separate files.
</p>
</li>
<li> <p><code>auto.plot</code>: a logical on whether to call <code><a href="#topic+gg_overview">gg_overview()</a></code> after import. Default is <code>TRUE</code>.
</p>
</li>
<li> <p><code>...</code>: supply additional arguments to the <span class="pkg">readr</span> import functions, like <code>na</code>. Might also be used to supply arguments to the specific import functions, like <code>column_names</code> for <code>Actiwatch_Spectrum</code> devices. Those devices will always throw a helpful error message if you forget to supply the necessary arguments.
If the <code>Id</code> column is already part of the <code>dataset</code> it will just use
this column. If the column is not present it will add this column and fill
it with the filename of the importfile (see param <code>auto.id</code>).
<code>print_n</code> can be used if you want to see more rows from the observation intervals
</p>
</li></ul>



<h3>Value</h3>

<p>Tibble/Dataframe with a POSIXct column for the datetime
</p>


<h3>Devices</h3>

<p>The set of import functions provide a convenient way to import light logger
data that is then perfectly formatted to add metadata, make visualizations
and analyses. There are a number of devices supported, where import should
just work out of the box. To get an overview, you can simply call the
<code>supported.devices</code> dataset. The list will grow continuously as the package
is maintained.
</p>
<div class="sourceCode r"><pre>supported.devices
#&gt;  [1] "Actiwatch_Spectrum" "ActLumus"           "ActTrust"          
#&gt;  [4] "DeLux"              "LiDo"               "LightWatcher"      
#&gt;  [7] "LYS"                "nanoLambda"         "Speccy"            
#&gt; [10] "SpectraWear"
</pre></div>


<h4>ActLumus</h4>

<p>Manufacturer: Condor Instruments
Model: ActLumus
Implemented: 2023
A sample file is provided with the package, it can be accessed through
<code>system.file("extdata/205_actlumus_Log_1020_20230904101707532.txt.zip", package = "LightLogR")</code>. It does not need to be unzipped to be imported.
This sample file is a good example for a regular dataset without gaps
</p>



<h4>LYS</h4>

<p>Manufacturer: LYS Technologies
Model: LYS Button
Implemented: 2023
A sample file is provided with the package, it can be accessed
through <code>system.file("extdata/sample_data_LYS.csv", package = "LightLogR")</code>. This sample file is a good example for an irregular dataset.
</p>



<h4>Actiwatch_Spectrum</h4>

<p>Manufacturer: Philips Respironics
Model: Actiwatch Spectrum
Implemented: 2023
<strong>Required Argument: <code>column_names</code></strong> A character vector containing column
names in the order in which they appear in the file. This is necessary to
find the starting point of actual data.
</p>



<h4>ActTrust</h4>

<p>Manufacturer: Condor Instruments
Model: ActTrust1, ActTrust2
Implemented: 2024
This function works for both ActTrust 1 and 2 devices
</p>



<h4>Speccy</h4>

<p>Manufacturer: Monash University
Model: Speccy
Implemented: 2024
</p>



<h4>DeLux</h4>

<p>Manufacturer: Intelligent Automation Inc
Model: DeLux
Implemented: 2023
</p>



<h4>LiDo</h4>

<p>Manufacturer: University of Lucerne
Model: LiDo
Implemented: 2023
</p>



<h4>SpectraWear</h4>

<p>Manufacturer:
Model: SpectraWear
Implemented: 2024
</p>



<h4>NanoLambda</h4>

<p>Manufacturer: NanoLambda
Model: XL-500 BLE
Implemented: 2024
</p>



<h4>LightWatcher</h4>

<p>Manufacturer: Object-Tracker
Model: LightWatcher
Implemented: 2024
</p>



<h3>Examples</h3>



<h4>Imports made easy</h4>

<p>To import a file, simple specify the filename (and path) and feed it to the
<code>import_Dataset</code> function. There are sample datasets for all devices.
</p>
<p>The import functions provide a basic overview of the data after import,
such as the intervals between measurements or the start and end dates.
</p>
<div class="sourceCode r"><pre>filepath &lt;- system.file("extdata/sample_data_LYS.csv", package = "LightLogR")
dataset &lt;- import_Dataset("LYS", filepath, auto.plot = FALSE)
#&gt; 
#&gt; Successfully read in 11'422 observations across 1 Ids from 1 LYS-file(s).
#&gt; Timezone set is UTC.
#&gt; The system timezone is Europe/Berlin. Please correct if necessary!
#&gt; 
#&gt; First Observation: 2023-06-21 00:00:12
#&gt; Last Observation: 2023-06-22 23:59:48
#&gt; Timespan: 2 days
#&gt; 
#&gt; Observation intervals: 
#&gt;   Id              interval.time     n pct    
#&gt; 1 sample_data_LYS 15s           10015 87.689%
#&gt; 2 sample_data_LYS 16s            1367 11.969%
#&gt; 3 sample_data_LYS 17s              23 0.201% 
#&gt; 4 sample_data_LYS 18s              16 0.140%
</pre></div>
<p>Import functions can also be called directly:
</p>
<div class="sourceCode r"><pre>filepath &lt;- system.file("extdata/205_actlumus_Log_1020_20230904101707532.txt.zip", package = "LightLogR")
dataset &lt;- import$ActLumus(filepath, auto.plot = FALSE)
#&gt; 
#&gt; Successfully read in 61'016 observations across 1 Ids from 1 ActLumus-file(s).
#&gt; Timezone set is UTC.
#&gt; The system timezone is Europe/Berlin. Please correct if necessary!
#&gt; 
#&gt; First Observation: 2023-08-28 08:47:54
#&gt; Last Observation: 2023-09-04 10:17:04
#&gt; Timespan: 7.1 days
#&gt; 
#&gt; Observation intervals: 
#&gt;   Id                                          interval.time     n pct  
#&gt; 1 205_actlumus_Log_1020_20230904101707532.txt 10s           61015 100%
dataset %&gt;% gg_days()
</pre></div>
<p><img src="../help/figures/unnamed-chunk-1-1.png" alt="unnamed-chunk-1-1.png" />
</p>
<div class="sourceCode r"><pre>dataset %&gt;%
dplyr::select(Datetime, TEMPERATURE, LIGHT, MEDI, Id) %&gt;%
dplyr::slice(1500:1505)
#&gt; # A tibble: 6 x 5
#&gt; # Groups:   Id [1]
#&gt;   Datetime            TEMPERATURE LIGHT  MEDI Id                                
#&gt;   &lt;dttm&gt;                    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;                             
#&gt; 1 2023-08-28 12:57:44        26.9  212.  202. 205_actlumus_Log_1020_20230904101~
#&gt; 2 2023-08-28 12:57:54        26.9  208.  199. 205_actlumus_Log_1020_20230904101~
#&gt; 3 2023-08-28 12:58:04        26.9  205.  196. 205_actlumus_Log_1020_20230904101~
#&gt; 4 2023-08-28 12:58:14        26.8  204.  194. 205_actlumus_Log_1020_20230904101~
#&gt; 5 2023-08-28 12:58:24        26.9  203.  194. 205_actlumus_Log_1020_20230904101~
#&gt; 6 2023-08-28 12:58:34        26.8  204.  195. 205_actlumus_Log_1020_20230904101~
</pre></div>



<h3>See Also</h3>

<p><a href="#topic+supported.devices">supported.devices</a>
</p>

<hr>
<h2 id='import_Statechanges'>Import data that contain <code>Datetimes</code> of <code>Statechanges</code></h2><span id='topic+import_Statechanges'></span>

<h3>Description</h3>

<p>Auxiliary data greatly enhances data analysis. This function allows the
import of files that contain <code>Statechanges</code>, i.e., specific time points of
when a <code>State</code> (like <code>sleep</code> or <code>wake</code>) starts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>import_Statechanges(
  filename,
  path = NULL,
  sep = ",",
  dec = ".",
  structure = c("wide", "long"),
  Datetime.format = "ymdHMS",
  tz = "UTC",
  State.colnames,
  State.encoding = State.colnames,
  Datetime.column = Datetime,
  Id.colname,
  State.newname = State,
  Id.newname = Id,
  keep.all = FALSE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="import_Statechanges_+3A_filename">filename</code></td>
<td>
<p>Filename(s) for the Dataset. Can also contain the filepath,
but <code>path</code> must then be <code>NULL</code>. Expects a <code>character</code>. If the vector is
longer than <code>1</code>, multiple files will be read in into one Tibble.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_path">path</code></td>
<td>
<p>Optional path for the dataset(s). <code>NULL</code> is the default. Expects
a <code>character</code>.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_sep">sep</code></td>
<td>
<p>String that separates columns in the import file. Defaults to
<code>","</code>.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_dec">dec</code></td>
<td>
<p>String that indicates a decimal separator in the import file.
Defaults to <code>"."</code>.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_structure">structure</code></td>
<td>
<p>String that specifies whether the import file is in the
<code>long</code> or <code>wide</code> format. Defaults to <code>"wide"</code>.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_datetime.format">Datetime.format</code></td>
<td>
<p>String that specifies the format of the <code>Datetimes</code> in
the file. The default <code>"ymdHMS"</code> specifies a format like &quot;2023-07-10
10:00:00&quot;. In the function, <code><a href="lubridate.html#topic+parse_date_time">lubridate::parse_date_time()</a></code> does the actual
conversion - the documentation can be searched for valid inputs.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_tz">tz</code></td>
<td>
<p>Timezone of the data. <code>"UTC"</code> is the default. Expects a
<code>character</code>. You can look up the supported timezones with <code><a href="base.html#topic+OlsonNames">OlsonNames()</a></code>.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_state.colnames">State.colnames</code></td>
<td>
<p>Column name or vector of column names (the latter only
in the <code>wide</code> format). Expects a <code>character</code>.
</p>

<ul>
<li><p> In the <code>wide</code> format, the column names indicate the <code>State</code> and must contain <code>Datetimes</code>. The columns will be pivoted to the columns specified in <code>Datetime.column</code> and <code>State.newname</code>.
</p>
</li>
<li><p> In the <code>long</code> format, the column contains the <code>State</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_state.encoding">State.encoding</code></td>
<td>
<p>In the <code>wide</code> format, this enables recoding the column
names to state names, if there are any differences. The default uses the
<code>State.colnames</code> argument. Expects a <code>character</code> (vector) with the same
length as <code>State.colnames</code>.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_datetime.column">Datetime.column</code></td>
<td>
<p>Symbol of the <code>Datetime</code> column (which is also the
default).
</p>

<ul>
<li><p> In the <code>wide</code> format, this is the newly created column from the <code>Datetimes</code> in the <code>State.colnames</code>.
</p>
</li>
<li><p> In the <code>long</code> format, this is the existing column that contains the <code>Datetimes</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_id.colname">Id.colname</code></td>
<td>
<p>Symbol of the column that contains the <code>ID</code> of the subject.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_state.newname">State.newname</code></td>
<td>
<p>Symbol of the column that will contain the <code>State</code> of
the subject. In the <code>wide</code> format, this is the newly created column from
the <code>State.colnames</code>. In the <code>long</code> format, this argument is used to rename
the <code>State</code> column.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_id.newname">Id.newname</code></td>
<td>
<p>Column name used for renaming the <code>Id.colname</code> column.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_keep.all">keep.all</code></td>
<td>
<p>Logical that specifies whether all columns should be
kept in the output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="import_Statechanges_+3A_silent">silent</code></td>
<td>
<p>Logical that specifies whether a summary of the
imported data should be shown. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Data can be present in the long or wide format.
</p>

<ul>
<li><p> In the <code>wide</code> format, multiple <code>Datetime</code> columns indicate the state through the column name. These get pivoted to the <code>long</code> format and can be recoded through the <code>State.encoding</code> argument.
</p>
</li>
<li><p> In the <code>long</code> format, one column indicates the <code>State</code>, while the other gives the <code>Datetime</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>a dataset with the <code>ID</code>, <code>State</code>, and <code>Datetime</code> columns. May contain
additional columns if <code>keep.all</code> is <code>TRUE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#get the example file from within the package
path &lt;- system.file("extdata/",
package = "LightLogR")
file.sleep &lt;- "205_sleepdiary_all_20230904.csv"

#import Data in the wide format (sleep/wake times)
import_Statechanges(file.sleep, path,
Datetime.format = "dmyHM",
State.colnames = c("sleep", "offset"),
State.encoding = c("sleep", "wake"),
Id.colname = record_id,
sep = ";",
dec = ",")

#import in the long format (Comments on sleep)
import_Statechanges(file.sleep, path,
                   Datetime.format = "dmyHM",
                   State.colnames = "comments",
                   Datetime.column = sleep,
                   Id.colname = record_id,
                   sep = ";",
                   dec = ",", structure = "long")
</code></pre>

<hr>
<h2 id='interdaily_stability'>Interdaily stability (IS)</h2><span id='topic+interdaily_stability'></span>

<h3>Description</h3>

<p>This function calculates the variability of 24h light exposure patterns across
multiple days. Calculated as the ratio of the variance of the average daily
pattern to the total variance across all days. Calculated with mean hourly
light levels. Ranges between 0 (Gaussian noise) and 1 (Perfect Stability).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interdaily_stability(
  Light.vector,
  Datetime.vector,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interdaily_stability_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="interdaily_stability_+3A_datetime.vector">Datetime.vector</code></td>
<td>
<p>Vector containing the time data. Must be POSIXct.</p>
</td></tr>
<tr><td><code id="interdaily_stability_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="interdaily_stability_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should the output be returned as a data frame? If <code>TRUE</code>, a data
frame with a single column named <code>interdaily_stability</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this metric will always be 1 if the data contains only one 24 h day.
</p>


<h3>Value</h3>

<p>Numeric value or dataframe with column 'IS'.
</p>


<h3>References</h3>

<p>Van Someren, E. J. W., Swaab, D. F., Colenda, C. C., Cohen, W.,
McCall, W. V., &amp; Rosenquist, P. B. (1999). Bright Light Therapy: Improved
Sensitivity to Its Effects on Rest-Activity Rhythms in Alzheimer Patients
by Application of Nonparametric Methods. <em>Chronobiology International</em>,
16(4), 505â€“518. <a href="https://doi.org/10.3109/07420529908998724">doi:10.3109/07420529908998724</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
N &lt;- 24 * 7
# Calculate metric for seven 24 h days with two measurements per hour
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", N * 2),
    Datetime = lubridate::as_datetime(0) + c(lubridate::minutes(seq(0, N * 60 - 30, 30))),
    MEDI = sample(1:1000, N * 2)
  )
dataset1 %&gt;%
  dplyr::summarise(
    "Interdaily stability" = interdaily_stability(MEDI, Datetime)
  )

</code></pre>

<hr>
<h2 id='interval2state'>Adds a state column to a dataset from interval data</h2><span id='topic+interval2state'></span>

<h3>Description</h3>

<p>This function can make use of <code>Interval</code> data that contain <code>States</code> (like
<code>"sleep"</code>, <code>"wake"</code>, <code>"wear"</code>) and add a column to a light logger <code>dataset</code>,
where the <code>State</code> of  every <code>Datetime</code> is specified, based on the
participant's <code>Id</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interval2state(
  dataset,
  State.interval.dataset,
  Datetime.colname = Datetime,
  State.colname = State,
  Interval.colname = Interval,
  Id.colname.dataset = Id,
  Id.colname.interval = Id,
  overwrite = FALSE,
  output.dataset = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interval2state_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="interval2state_+3A_state.interval.dataset">State.interval.dataset</code></td>
<td>
<p>Name of the dataset that contains <code>State</code> and
<code>Interval</code> columns. Interval data can be created, e.g., through
<code><a href="#topic+sc2interval">sc2interval()</a></code>.</p>
</td></tr>
<tr><td><code id="interval2state_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="interval2state_+3A_state.colname">State.colname</code>, <code id="interval2state_+3A_interval.colname">Interval.colname</code></td>
<td>
<p>Column names of the <code>State</code> and
<code>Interval</code> in the <code>State.interval.dataset</code>. Expects a <code>symbol</code>. <code>State</code>
can't be in the <code>dataset</code> yet or the function will give an error. You can
also set <code>overwrite = TRUE</code>.</p>
</td></tr>
<tr><td><code id="interval2state_+3A_id.colname.dataset">Id.colname.dataset</code>, <code id="interval2state_+3A_id.colname.interval">Id.colname.interval</code></td>
<td>
<p>Column names of the
participant's <code>Id</code> in both the <code>dataset</code> and the <code>State.interval.dataset</code>.
On the off-chance that there are inconsistencies, the names can be
different. If the datasets where imported and preprocessed with
<a href="#topic+LightLogR">LightLogR</a>, this just works. Both datasets need an <code>Id</code>, because the
states will be added based not only on the <code>Datetime</code>, but also depending
on the dataset.</p>
</td></tr>
<tr><td><code id="interval2state_+3A_overwrite">overwrite</code></td>
<td>
<p>If <code>TRUE</code> (defaults to <code>FALSE</code>), the function will
overwrite the <code>State.colname</code> column if it already exists.</p>
</td></tr>
<tr><td><code id="interval2state_+3A_output.dataset">output.dataset</code></td>
<td>
<p>should the output be a <code>data.frame</code> (Default <code>TRUE</code>) or
a vector with <code>hms</code> (<code>FALSE</code>) times? Expects a <code>logical</code> scalar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>One of
</p>

<ul>
<li><p> a <code>data.frame</code> object identical to <code>dataset</code> but with the state column added
</p>
</li>
<li><p> a <code>vector</code> with the states
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>#create a interval dataset
library(tibble)
library(dplyr)
library(lubridate)
library(rlang)
library(purrr)
states &lt;- tibble::tibble(Datetime = c("2023-08-15 6:00:00",
                                      "2023-08-15 23:00:00",
                                      "2023-08-16 6:00:00",
                                      "2023-08-16 22:00:00",
                                      "2023-08-17 6:30:00",
                                      "2023-08-18 1:00:00",
                                      "2023-08-18 6:00:00",
                                      "2023-08-18 22:00:00",
                                      "2023-08-19 6:00:00",
                                      "2023-08-19 23:00:00",
                                      "2023-08-20 6:00:00",
                                      "2023-08-20 22:00:00"),
                         State = rep(c("wake", "sleep"), 6),
                         Wear = rep(c("wear", "no wear"), 6),
                         Performance = rep(c(100, 0), 6),
                         Id = "Participant")
intervals &lt;- sc2interval(states)

#create a dataset with states
dataset_with_states &lt;-
sample.data.environment %&gt;%
interval2state(State.interval.dataset = intervals)

#visualize the states - note that the states are only added to the respective ID in the dataset
library(ggplot2)
ggplot(dataset_with_states, aes(x = Datetime, y = MEDI, color = State)) +
 geom_point() +
 facet_wrap(~Id, ncol = 1)

#import multiple State columns from the interval dataset
#interval2state will only add a single State column to the dataset, 
#which represents sleep/wake in our case
dataset_with_states[8278:8283,]

#if we want to add multiple columns we can either perfom the function 
#multiple times with different states:
dataset_with_states2 &lt;- 
dataset_with_states %&gt;%
interval2state(State.interval.dataset = intervals, State.colname = Wear)
dataset_with_states2[8278:8283,]

#or we can use `purrr::reduce` to add multiple columns at once
dataset_with_states3 &lt;-
syms(c("State", "Wear", "Performance")) %&gt;% 
reduce(\(x,y) interval2state(x, State.interval.dataset = intervals, State.colname = !!y), 
.init = sample.data.environment)

#Note: 
# - the State.colnames have to be provided as symbols (`rlang::syms`)
# - the reduce function requires a two argument function `\(x,y)`, where `x` 
#   is the dataset to be continiously modified and `y` is the symbol of the
#   State column name to be added
# - the `!!` operator from `rlang` is used to exchange `y` with each symbol
# - the `.init` argument is the initial dataset to be modified

#this results in all states being applied
dataset_with_states3[8278:8283,]
</code></pre>

<hr>
<h2 id='intradaily_variability'>Intradaily variability (IV)</h2><span id='topic+intradaily_variability'></span>

<h3>Description</h3>

<p>This function calculates the variability of consecutive Light levels within
a 24h day. Calculated as the ratio of the variance of the differences between
consecutive Light levels to the total variance across the day. Calculated with
mean hourly Light levels. Higher values indicate more fragmentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intradaily_variability(
  Light.vector,
  Datetime.vector,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intradaily_variability_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="intradaily_variability_+3A_datetime.vector">Datetime.vector</code></td>
<td>
<p>Vector containing the time data. Must be POSIXct.</p>
</td></tr>
<tr><td><code id="intradaily_variability_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="intradaily_variability_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should the output be returned as a data frame? If <code>TRUE</code>, a data
frame with a single column named <code>intradaily_variability</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value or dataframe with column 'IV'.
</p>


<h3>References</h3>

<p>Van Someren, E. J. W., Swaab, D. F., Colenda, C. C., Cohen, W.,
McCall, W. V., &amp; Rosenquist, P. B. (1999). Bright Light Therapy: Improved
Sensitivity to Its Effects on Rest-Activity Rhythms in Alzheimer Patients
by Application of Nonparametric Methods. <em>Chronobiology International</em>,
16(4), 505â€“518. <a href="https://doi.org/10.3109/07420529908998724">doi:10.3109/07420529908998724</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
N &lt;- 24 * 2
# Calculate metric for two 24 h days with two measurements per hour
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", N * 2),
    Datetime = lubridate::as_datetime(0) + c(lubridate::minutes(seq(0, N * 60 - 30, 30))),
    MEDI = sample(1:1000, N * 2)
  )
dataset1 %&gt;%
  dplyr::summarise(
    "Intradaily variability" = intradaily_variability(MEDI, Datetime)
  )

</code></pre>

<hr>
<h2 id='join_datasets'>Join similar Datasets</h2><span id='topic+join_datasets'></span>

<h3>Description</h3>

<p>Join Light logging datasets that have a common structure. The least commonality are identical columns for <code>Datetime</code> and <code>Id</code> across all sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>join_datasets(
  ...,
  Datetime.column = Datetime,
  Id.column = Id,
  add.origin = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="join_datasets_+3A_...">...</code></td>
<td>
<p><code style="white-space: pre;">&#8288;Object names&#8288;</code> of datasets that need to be joined.</p>
</td></tr>
<tr><td><code id="join_datasets_+3A_datetime.column">Datetime.column</code>, <code id="join_datasets_+3A_id.column">Id.column</code></td>
<td>
<p>Column names for the <code>Datetime</code> and <code>id</code> columns. The defaults (<code>Datetime</code>, <code>Id</code>) are already set up for data imported with <a href="#topic+LightLogR">LightLogR</a>.</p>
</td></tr>
<tr><td><code id="join_datasets_+3A_add.origin">add.origin</code></td>
<td>
<p>Should a column named <code>dataset</code> in the joined data indicate from which dataset each observation originated? Defaults to <code>FALSE</code> as the <code>Id</code> column should suffice. Expects a <code>logical</code>.</p>
</td></tr>
<tr><td><code id="join_datasets_+3A_debug">debug</code></td>
<td>
<p>Output changes to a tibble indicating which dataset is missing the respective <code>Datetime</code> or <code>Id</code> column. Expects a <code>logical</code> and defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>One of
</p>

<ul>
<li><p> a <code>data.frame</code> of joined datasets
</p>
</li>
<li><p> a <code>tibble</code> of datasets with missing columns. Only if <code>debug = TRUE</code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>#load in two datasets
path &lt;- system.file("extdata", 
package = "LightLogR")
file.LL &lt;- "205_actlumus_Log_1020_20230904101707532.txt.zip"
file.env &lt;- "cyepiamb_CW35_Log_1431_20230904081953614.txt.zip"
dataset.LL &lt;- import$ActLumus(file.LL, path, auto.id = "^(\\d{3})")
dataset.env &lt;- import$ActLumus(file.env, path, manual.id = "CW35")

#join the datasets
joined &lt;- join_datasets(dataset.LL, dataset.env)

#compare the number of rows
nrow(dataset.LL) + nrow(dataset.env) == nrow(joined)

#debug, when set to TRUE, will output a tibble of datasets with missing necessary columns
dataset.LL &lt;- dataset.LL %&gt;% dplyr::select(-Datetime)
join_datasets(dataset.LL, dataset.env, debug = TRUE)
</code></pre>

<hr>
<h2 id='ll_import_expr'>A list of the specific device import functions</h2><span id='topic+ll_import_expr'></span>

<h3>Description</h3>

<p>These expressions are used to import and prepare data from specific devices.
The list is made explicit, so that a user, requiring slight changes to the
import functions, (e.g., because a timestamp is formatted differently) can
modify or add to the list. The list can be turned into a fully functional
import function through <code>import_adjustment()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ll_import_expr
</code></pre>


<h3>Format</h3>

<p><code>ll_import_expr</code> A list, with specific expressions for each supported device
</p>

<dl>
<dt>ll_import_expr</dt><dd><p>expressions</p>
</dd>
</dl>


<hr>
<h2 id='midpointCE'>Midpoint of cumulative light exposure.</h2><span id='topic+midpointCE'></span>

<h3>Description</h3>

<p>This function calculates the timing corresponding to half of the cumulative
light exposure within the given time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>midpointCE(Light.vector, Time.vector, na.rm = FALSE, as.df = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="midpointCE_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="midpointCE_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>, <a href="hms.html#topic+hms">hms</a>,
<a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="midpointCE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed for the calculation? If <code>TRUE</code>,
missing values will be replaced by zero. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="midpointCE_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should the output be returned as a data frame? If <code>TRUE</code>, a data
frame with a single column named <code>midpointCE</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Single column data frame or vector.
</p>


<h3>References</h3>

<p>Shochat, T., Santhi, N., Herer, P., Flavell, S. A., Skeldon, A. C.,
&amp; Dijk, D.-J. (2019). Sleep Timing in Late Autumn and Late Spring Associates
With Light Exposure Rather Than Sun Time in College Students.
<em>Frontiers in Neuroscience</em>, 13. <a href="https://doi.org/10.3389/fnins.2019.00882">doi:10.3389/fnins.2019.00882</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )
dataset1 %&gt;%
  dplyr::reframe(
    "Midpoint of cmulative exposure" = midpointCE(MEDI, Datetime)
  )

# Dataset with HMS time vector
dataset2 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Time = hms::as_hms(lubridate::as_datetime(0) + lubridate::hours(0:23)),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )
dataset2 %&gt;%
  dplyr::reframe(
    "Midpoint of cmulative exposure" = midpointCE(MEDI, Time)
  )

# Dataset with duration time vector
dataset3 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Hour = lubridate::duration(0:23, "hours"),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )
dataset3 %&gt;%
  dplyr::reframe(
    "Midpoint of cmulative exposure" = midpointCE(MEDI, Hour)
  )

</code></pre>

<hr>
<h2 id='nvRC'>Non-visual circadian response</h2><span id='topic+nvRC'></span>

<h3>Description</h3>

<p>This function calculates the non-visual circadian response (nvRC). It takes into account
the assumed response dynamics of the non-visual system and the circadian rhythm
and processes the light exposure signal to quantify the effective circadian-weighted
input to the non-visual system (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nvRC(
  MEDI.vector,
  Illuminance.vector,
  Time.vector,
  epoch = "dominant.epoch",
  sleep.onset = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nvRC_+3A_medi.vector">MEDI.vector</code></td>
<td>
<p>Numeric vector containing the melanopic EDI data.</p>
</td></tr>
<tr><td><code id="nvRC_+3A_illuminance.vector">Illuminance.vector</code></td>
<td>
<p>Numeric vector containing the Illuminance data.</p>
</td></tr>
<tr><td><code id="nvRC_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>,
<a href="hms.html#topic+hms">hms</a>, <a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="nvRC_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="nvRC_+3A_sleep.onset">sleep.onset</code></td>
<td>
<p>The time of habitual sleep onset. Can be HMS, numeric, or NULL.
If NULL (the default), then the data is assumed to start at habitual sleep onset.
If <code>Time.vector</code> is HMS or POSIXct, <code>sleep.onset</code> must be HMS. Likewise, if
<code>Time.vector</code> is numeric, <code>sleep.onset</code> must be numeric.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The timeseries is assumed to be regular. Missing values in the
light data will be replaced by 0.
</p>


<h3>Value</h3>

<p>A numeric vector containing the nvRC data. The output has the same
length as <code>Time.vector</code>.
</p>


<h3>References</h3>

<p>Amundadottir, M.L. (2016). Light-driven model for identifying
indicators of non-visual health potential in the built environment
[Doctoral dissertation, EPFL]. EPFL infoscience.
<a href="https://doi.org/10.5075/epfl-thesis-7146">doi:10.5075/epfl-thesis-7146</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dataset1 &lt;-
  tibble::tibble(
    Id = rep("B", 60 * 48),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*48-1)),
    Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60),
                    rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60)),
    MEDI = Illuminance * rep(sample(0.5:1.5, 48, replace = TRUE), each = 60)
  )
# Time.vector as POSIXct
dataset1.nvRC &lt;- dataset1 %&gt;%
  dplyr::mutate(
    nvRC = nvRC(MEDI, Illuminance, Datetime, sleep.onset = hms::as_hms("22:00:00"))
  )

# Time.vector as difftime
dataset2 &lt;- dataset1 %&gt;% 
  dplyr::mutate(Datetime = Datetime - lubridate::as_datetime(lubridate::dhours(22)))
dataset2.nvRC &lt;- dataset2 %&gt;%
  dplyr::mutate(
    nvRC = nvRC(MEDI, Illuminance, Datetime, sleep.onset = lubridate::dhours(0))
  )
  
</code></pre>

<hr>
<h2 id='nvRC_metrics'>Performance metrics for circadian response</h2><span id='topic+nvRC_metrics'></span><span id='topic+nvRC_circadianDisturbance'></span><span id='topic+nvRC_circadianBias'></span><span id='topic+nvRC_relativeAmplitudeError'></span>

<h3>Description</h3>

<p>These functions compare the non-visual circadian response (see <code><a href="#topic+nvRC">nvRC</a></code>)
for measured personal light exposure to the nvRC for a reference light exposure pattern,
such as daylight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nvRC_circadianDisturbance(nvRC, nvRC.ref, as.df = FALSE)

nvRC_circadianBias(nvRC, nvRC.ref, as.df = FALSE)

nvRC_relativeAmplitudeError(nvRC, nvRC.ref, as.df = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nvRC_metrics_+3A_nvrc">nvRC</code></td>
<td>
<p>Time series of non-visual circadian response
(see <code><a href="#topic+nvRC">nvRC</a></code>.</p>
</td></tr>
<tr><td><code id="nvRC_metrics_+3A_nvrc.ref">nvRC.ref</code></td>
<td>
<p>Time series of non-visual circadian response
circadian response (see <code><a href="#topic+nvRC">nvRC</a></code> for a reference light exposure
pattern (e.g., daylight). Must be the same length as <code>nvRC</code>.</p>
</td></tr>
<tr><td><code id="nvRC_metrics_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should the output be returned as a data frame? Defaults
to TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nvRC_circadianDisturbance()</code> calculates the circadian disturbance (CD).
It is expressed as
</p>
<p style="text-align: center;"><code class="reqn">CD(i,T)=\frac{1}{T}\int_{t_{i}}^{t_{i}+T}
   {\lvert r_{C}(t)-r_{C}^{ref}(t)\rvert dt},</code>
</p>

<p>and quantifies the total difference between the measured circadian response
and the circadian response to a reference profile.
</p>
<p><code>nvRC_circadianBias()</code> calculates the circadian bias (CB).
It is expressed as
</p>
<p style="text-align: center;"><code class="reqn">CB(i,T)=\frac{1}{T}\int_{t_{i}}^{t_{i}+T}
   {(r_{C}(t)-r_{C}^{ref}(t))dt},</code>
</p>

<p>and provides a measure of the overall trend for the difference in
circadian response, i.e. positive values for overestimating and negative
for underestimating between the measured circadian response
and the circadian response to a reference profile.
</p>
<p><code>nvRC_relativeAmplitudeError()</code> calculates the relative amplitude error (RAE).
It is expressed as
</p>
<p style="text-align: center;"><code class="reqn">RAE(i,T)=r_{C,max}-r_{C,max}^{ref},</code>
</p>

<p>and quantifies the difference between the maximum response achieved in a period
to the reference signal.
</p>


<h3>Value</h3>

<p>A numeric value or single column data frame.
</p>


<h3>References</h3>

<p>Amundadottir, M.L. (2016). Light-driven model for identifying
indicators of non-visual health potential in the built environment
[Doctoral dissertation, EPFL]. EPFL infoscience.
<a href="https://doi.org/10.5075/epfl-thesis-7146">doi:10.5075/epfl-thesis-7146</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dataset1 &lt;- 
  tibble::tibble(
    Id = rep("B", 60 * 24),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),
    Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60)),
    MEDI = Illuminance * rep(sample(0.5:1.5, 24, replace = TRUE), each = 60),
  ) %&gt;%
  dplyr::mutate(
    nvRC = nvRC(MEDI, Illuminance, Datetime, sleep.onset = hms::as_hms("22:00:00"))
  )

dataset.reference &lt;-
  tibble::tibble(
    Id = rep("Daylight", 60 * 24),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),
    Illuminance = c(rep(0, 60*6), rep(10000, 12*60), rep(0, 60*6)),
    MEDI = Illuminance
  ) %&gt;%
  dplyr::mutate(
    nvRC = nvRC(MEDI, Illuminance, Datetime, sleep.onset = hms::as_hms("22:00:00"))
  )

# Circadian disturbance
nvRC_circadianDisturbance(dataset1$nvRC, dataset.reference$nvRC)

# Circadian bias
nvRC_circadianBias(dataset1$nvRC, dataset.reference$nvRC)

# Relative amplitude error
nvRC_relativeAmplitudeError(dataset1$nvRC, dataset.reference$nvRC)
</code></pre>

<hr>
<h2 id='nvRD'>Non-visual direct response</h2><span id='topic+nvRD'></span>

<h3>Description</h3>

<p>This function calculates the non-visual direct response (nvRD). It takes into account
the assumed response dynamics of the non-visual system and processes the light
exposure signal to quantify the effective direct input to the non-visual system
(see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nvRD(MEDI.vector, Illuminance.vector, Time.vector, epoch = "dominant.epoch")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nvRD_+3A_medi.vector">MEDI.vector</code></td>
<td>
<p>Numeric vector containing the melanopic EDI data.</p>
</td></tr>
<tr><td><code id="nvRD_+3A_illuminance.vector">Illuminance.vector</code></td>
<td>
<p>Numeric vector containing the Illuminance data.</p>
</td></tr>
<tr><td><code id="nvRD_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <code><a href="base.html#topic+POSIXct">POSIXct()</a></code>,<code><a href="hms.html#topic+hms">hms::hms()</a></code>,
<code><a href="lubridate.html#topic+duration">lubridate::duration()</a></code>, <code><a href="base.html#topic+difftime">difftime()</a></code>.</p>
</td></tr>
<tr><td><code id="nvRD_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<code><a href="lubridate.html#topic+duration">lubridate::duration()</a></code> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<code><a href="lubridate.html#topic+duration">lubridate::duration()</a></code> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The timeseries is assumed to be regular. Missing values in the
light data will be replaced by 0.
</p>


<h3>Value</h3>

<p>A numeric vector containing the nvRD data. The output has the same
length as <code>Time.vector</code>.
</p>


<h3>References</h3>

<p>Amundadottir, M.L. (2016). Light-driven model for identifying
indicators of non-visual health potential in the built environment
[Doctoral dissertation, EPFL]. EPFL infoscience.
<a href="https://doi.org/10.5075/epfl-thesis-7146">doi:10.5075/epfl-thesis-7146</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Dataset 1 with 24h measurement
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", 60 * 24),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),
    Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60)),
    MEDI = Illuminance * rep(sample(0.5:1.5, 24, replace = TRUE), each = 60)
  ) 
# Dataset 2 with 48h measurement
dataset2 &lt;-
  tibble::tibble(
    Id = rep("B", 60 * 48),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*48-1)),
    Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60), 
                    rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60)),
    MEDI = Illuminance * rep(sample(0.5:1.5, 48, replace = TRUE), each = 60)
  )
# Combined datasets
dataset.combined &lt;- rbind(dataset1, dataset2)

# Calculate nvRD per ID
dataset.combined.nvRD &lt;- dataset.combined %&gt;% 
  dplyr::group_by(Id) %&gt;% 
  dplyr::mutate(
    nvRD = nvRD(MEDI, Illuminance, Datetime)
  )

</code></pre>

<hr>
<h2 id='nvRD_cumulative_response'>Cumulative non-visual direct response</h2><span id='topic+nvRD_cumulative_response'></span>

<h3>Description</h3>

<p>This function calculates the cumulative non-visual direct response (nvRD). This is
basically the integral of the nvRD over the provided time period in hours. The
unit of the resulting value thus is &quot;nvRD*h&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nvRD_cumulative_response(
  nvRD,
  Time.vector,
  epoch = "dominant.epoch",
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nvRD_cumulative_response_+3A_nvrd">nvRD</code></td>
<td>
<p>Numeric vector containing the non-visual direct response.
See <code><a href="#topic+nvRD">nvRD</a></code>.</p>
</td></tr>
<tr><td><code id="nvRD_cumulative_response_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>, <a href="hms.html#topic+hms">hms</a>,
<a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="nvRD_cumulative_response_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="nvRD_cumulative_response_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should a data frame with be returned? If <code>TRUE</code>, a data
frame with a single column named <code>nvRD_cumulative</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value or single column data frame.
</p>


<h3>References</h3>

<p>Amundadottir, M.L. (2016). Light-driven model for identifying
indicators of non-visual health potential in the built environment
[Doctoral dissertation, EPFL]. EPFL infoscience.
<a href="https://doi.org/10.5075/epfl-thesis-7146">doi:10.5075/epfl-thesis-7146</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", 60 * 24),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),
    Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 14, replace = TRUE), each = 60), rep(0, 60*2)),
    MEDI = Illuminance * rep(sample(0.5:1.5, 24, replace = TRUE), each = 60)
  ) %&gt;%
  dplyr::mutate(
    nvRD = nvRD(MEDI, Illuminance, Datetime)
  ) 
dataset1 %&gt;% 
  dplyr::summarise(
    "cumulative nvRD" = nvRD_cumulative_response(nvRD, Datetime)
  )

</code></pre>

<hr>
<h2 id='period_above_threshold'>Length of longest continuous period above/below threshold</h2><span id='topic+period_above_threshold'></span>

<h3>Description</h3>

<p>This function finds the length of the longest continous period above/below
a specified threshold light level or within a specified range of light levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>period_above_threshold(
  Light.vector,
  Time.vector,
  comparison = c("above", "below"),
  threshold,
  epoch = "dominant.epoch",
  loop = FALSE,
  na.replace = FALSE,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="period_above_threshold_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="period_above_threshold_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>,
<a href="hms.html#topic+hms">hms</a>, <a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="period_above_threshold_+3A_comparison">comparison</code></td>
<td>
<p>String specifying whether the period of light levels above or
below threshold should be calculated. Can be either <code>"above"</code> (the default)
or <code>"below"</code>. If two values are provided for <code>threshold</code>, this argument will be ignored.</p>
</td></tr>
<tr><td><code id="period_above_threshold_+3A_threshold">threshold</code></td>
<td>
<p>Single numeric value or two numeric values specifying the
threshold light level(s) to compare with. If a vector with two values is provided,
the period of light levels within the two thresholds will be calculated.</p>
</td></tr>
<tr><td><code id="period_above_threshold_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="period_above_threshold_+3A_loop">loop</code></td>
<td>
<p>Logical. Should the data be looped? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="period_above_threshold_+3A_na.replace">na.replace</code></td>
<td>
<p>Logical. Should missing values (NA) be replaced
for the calculation? If <code>TRUE</code> missing values will not be removed but will
result in <code>FALSE</code> when comparing <code>Light.vector</code> with <code>threshold</code>.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="period_above_threshold_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values (NA) be removed for the calculation?
If <code>TRUE</code>, this argument will override <code>na.replace</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="period_above_threshold_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should a data frame be returned? If <code>TRUE</code>, a data
frame with a single column named <code style="white-space: pre;">&#8288;period_{comparison}_{threshold}&#8288;</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A duration object (see <code><a href="lubridate.html#topic+duration">duration</a></code>) as single value,
or single column data frame.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
N &lt;- 60
# Dataset with continous period of &gt;250lx for 35min
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", N),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),
    MEDI = c(sample(1:249, N-35, replace = TRUE), 
             sample(250:1000, 35, replace = TRUE))
  )

dataset1 %&gt;%
  dplyr::reframe("Period &gt;250lx" = period_above_threshold(MEDI, Datetime, threshold = 250))

dataset1 %&gt;%
  dplyr::reframe("Period &lt;250lx" = period_above_threshold(MEDI, Datetime, "below", threshold = 250))

# Dataset with continous period of 100-250lx for 20min
dataset2 &lt;-
  tibble::tibble(
    Id = rep("B", N),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),
    MEDI = c(sample(c(1:99, 251-1000), N-20, replace = TRUE), 
             sample(100:250, 20, replace = TRUE)),
  )
dataset2 %&gt;%
  dplyr::reframe("Period 250lx" = period_above_threshold(MEDI, Datetime, threshold = c(100,250)))

# Return data frame
dataset1 %&gt;%
  dplyr::reframe(period_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE))

</code></pre>

<hr>
<h2 id='pulses_above_threshold'>Pulses above threshold</h2><span id='topic+pulses_above_threshold'></span>

<h3>Description</h3>

<p>This function clusters the light data into continuous clusters (pulses) of
light above/below a given threshold. Clustering may be fine-tuned by setting
the minimum length of the clusters and by allowing brief interruptions to be
included in a single cluster, with a specified maximum length of interruption
episodes and proportion of total amount of interruptions to light above
threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pulses_above_threshold(
  Light.vector,
  Time.vector,
  comparison = c("above", "below"),
  threshold,
  min.length = "8 mins",
  max.interrupt = "2 mins",
  prop.interrupt = 0.25,
  epoch = "dominant.epoch",
  return.indices = FALSE,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pulses_above_threshold_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data. Missing values will
be considered as <code>FALSE</code> when comparing light levels against the threshold.</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>,
<a href="hms.html#topic+hms">hms</a>, <a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_comparison">comparison</code></td>
<td>
<p>String specifying whether the time above or below threshold
should be calculated. Can be either <code>"above"</code> (the default) or <code>"below"</code>. If
two values are provided for <code>threshold</code>, this argument will be ignored.</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_threshold">threshold</code></td>
<td>
<p>Single numeric value or two numeric values specifying the
threshold light level(s) to compare with. If a vector with two values is provided,
the timing corresponding to light levels between the two thresholds will be
calculated.</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_min.length">min.length</code></td>
<td>
<p>The minimum length of a pulse. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>. Defaults to
<code>"8 mins"</code> as in Wilson et al. (2018).</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_max.interrupt">max.interrupt</code></td>
<td>
<p>Maximum length of each episode of interruptions. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>. Defaults to
<code>"2 mins"</code> as in Wilson et al. (2018).</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_prop.interrupt">prop.interrupt</code></td>
<td>
<p>Numeric value between <code>0</code> and <code>1</code> specifying the
maximum proportion of the total number of interruptions. Defaults to <code>0.25</code>
as in Wilson et al. (2018).</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_return.indices">return.indices</code></td>
<td>
<p>Logical. Should the cluster indices be returned? Only works if
<code>as.df</code> is <code>FALSE</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed for the calculation of
pulse metrics? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pulses_above_threshold_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should a data frame be returned? If <code>TRUE</code>, a data
frame with seven columns (&quot;n&quot;, &quot;mean_level&quot;, &quot;mean_duration&quot;, &quot;total_duration&quot;,
&quot;mean_onset&quot;, &quot;mean_midpoint&quot;, &quot;mean_offset&quot;) and the threshold (e.g., <code style="white-space: pre;">&#8288;_{threshold}&#8288;</code>)
will be returned. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The timeseries is assumed to be regular. Missing values in the
light data will be replaced by 0.
</p>


<h3>Value</h3>

<p>List or data frame with calculated values.
</p>


<h3>References</h3>

<p>Wilson, J., Reid, K. J., Braun, R. I., Abbott, S. M., &amp; Zee, P. C.
(2018). Habitual light exposure relative to circadian timing in delayed
sleep-wake phase disorder. <em>Sleep</em>, 41(11).
<a href="https://doi.org/10.1093/sleep/zsy166">doi:10.1093/sleep/zsy166</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Sample data
data = sample.data.environment %&gt;%
  dplyr::filter(Id == "Participant") %&gt;%
  filter_Datetime(length = lubridate::days(1)) %&gt;% 
  dplyr::mutate(
    Time = hms::as_hms(Datetime),
  )

# Time vector as datetime
data %&gt;%
  dplyr::reframe(pulses_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE))

# Time vector as hms time
data %&gt;%
  dplyr::reframe(pulses_above_threshold(MEDI, Time, threshold = 250, as.df = TRUE))

# Pulses below threshold 
data %&gt;%
  dplyr::reframe(pulses_above_threshold(MEDI, Datetime, "below", threshold = 250, as.df = TRUE))

# Pulses within threshold range
data %&gt;%
  dplyr::reframe(pulses_above_threshold(MEDI, Datetime, threshold = c(250,1000), as.df = TRUE))

</code></pre>

<hr>
<h2 id='sample.data.environment'>Sample of wearable data combined with environmental data</h2><span id='topic+sample.data.environment'></span>

<h3>Description</h3>

<p>A subset of data from a study at the TSCN-Lab using the ActLumus light
logger. This dataset contains personal light exposure information for one
participant over the course of five full days. The dataset is measured with a
10 second epoch and is complete (no missing values). Additionally
environmental light data was captured with a second light logger mounted
horizontally at the TUM university roof, without any obstructions (besides a
transparent plastic halfdome). The epoch for this data is 30 seconds. This
dataset allows for some interesting calculations based on <em>available</em>
daylight at a given point in time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.data.environment
</code></pre>


<h3>Format</h3>

<p><code>sample.data.environment</code> A tibble with 69,120 rows and 3 columns:
</p>

<dl>
<dt>Datetime</dt><dd><p>POSIXct Datetime</p>
</dd>
<dt>MEDI</dt><dd><p>melanopic EDI measurement data. Unit is lux.</p>
</dd>
<dt>Id</dt><dd><p>A <code>character</code> vector indicating whether the data is from the <code>Participant</code> or from the <code>Environment</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://www.tscnlab.org">https://www.tscnlab.org</a>
</p>

<hr>
<h2 id='sc2interval'>Statechange (sc) Timestamps to Intervals</h2><span id='topic+sc2interval'></span>

<h3>Description</h3>

<p>Takes an input of <code>datetimes</code> and <code>Statechanges</code> and creates a column with
<code>Intervals</code>. If <code>full = TRUE</code>, it will also create intervals for the day
prior to the first state change and after the last. If <code>output.dataset = FALSE</code> it will give a named vector, otherwise a <code>tibble</code>. The <code style="white-space: pre;">&#8288;state change&#8288;</code>
info requires a description or name of the state (like <code>"sleep"</code> or <code>"wake"</code>,
or <code>"wear"</code>) that goes into effect at the given <code>Datetime</code>. Works for grouped
data so that it does not mix up intervals between participants. Missing data
should be explicit if at all possible. Also, the maximum allowed length of an
interval can be set, so that implicit missing timestamps after a set period
of times can be enforced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc2interval(
  dataset,
  Datetime.colname = Datetime,
  Statechange.colname = State,
  State.colname = State,
  Interval.colname = Interval,
  full = TRUE,
  starting.state = NA,
  output.dataset = TRUE,
  Datetime.keep = FALSE,
  length.restriction = 60 * 60 * 24
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc2interval_+3A_dataset">dataset</code></td>
<td>
<p>A light logger dataset. Expects a <code>dataframe</code>. If not imported
by <a href="#topic+LightLogR">LightLogR</a>, take care to choose a sensible variable for the
<code>Datetime.colname</code>.</p>
</td></tr>
<tr><td><code id="sc2interval_+3A_datetime.colname">Datetime.colname</code></td>
<td>
<p>column name that contains the datetime. Defaults to
<code>"Datetime"</code> which is automatically correct for data imported with
<a href="#topic+LightLogR">LightLogR</a>. Expects a <code>symbol</code>. Needs to be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="sc2interval_+3A_statechange.colname">Statechange.colname</code>, <code id="sc2interval_+3A_interval.colname">Interval.colname</code>, <code id="sc2interval_+3A_state.colname">State.colname</code></td>
<td>
<p>Column names that
do contain the name/description of the <code style="white-space: pre;">&#8288;state change&#8288;</code> and that will contain
the <code>Interval</code> and <code>State</code> (which are also the default). Expects a <code>symbol</code>. The
<code>Statechange</code> column needs do be part of the <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="sc2interval_+3A_full">full</code>, <code id="sc2interval_+3A_starting.state">starting.state</code></td>
<td>
<p>These arguments handle the state on the first day
before the first state change and after the last state change on the last
day. If <code>full = TRUE</code>(the default, expects a <code>logical</code>), it will create an
interval on the first day from 00:00:00 up until the state change. This
interval will be given the state specified in <code>starting.state</code>, which is <code>NA</code>
by default, but can be any <code>character</code> scalar. It will further extend the
interval for the last state change until the end of the last given day
(more specifically until 00:00:00 the next day).</p>
</td></tr>
<tr><td><code id="sc2interval_+3A_output.dataset">output.dataset</code></td>
<td>
<p>should the output be a <code>data.frame</code> (Default <code>TRUE</code>) or
a vector with <code>hms</code> (<code>FALSE</code>) times? Expects a <code>logical</code> scalar.</p>
</td></tr>
<tr><td><code id="sc2interval_+3A_datetime.keep">Datetime.keep</code></td>
<td>
<p>If <code>TRUE</code>, the original <code>Datetime</code> column will be kept.</p>
</td></tr>
<tr><td><code id="sc2interval_+3A_length.restriction">length.restriction</code></td>
<td>
<p>If the length between intervals is too great, the
interval state can be set to <code>NA</code>, which effectively produces a gap in the
data. This makes sense when intervals are implausibly wrong (e.g. someone
slept for 50 hours), because when this data is combined with light logger
data, e.g., through <code><a href="#topic+interval2state">interval2state()</a></code>, metrics and visualizations will
remove the interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>One of
</p>

<ul>
<li><p> a <code>data.frame</code> object identical to <code>dataset</code> but with the interval instead of the datetime. The original <code>Statechange</code> column now indicates the <code>State</code> during the <code>Interval</code>.
</p>
</li>
<li><p> a named <code>vector</code> with the intervals, where the names are the states
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(tibble)
library(lubridate)
library(dplyr)
sample &lt;- tibble::tibble(Datetime = c("2023-08-15 6:00:00",
                                      "2023-08-15 23:00:00",
                                      "2023-08-16 6:00:00",
                                      "2023-08-16 22:00:00",
                                      "2023-08-17 6:30:00",
                                      "2023-08-18 1:00:00"),
                         State = rep(c("wake", "sleep"), 3),
                         Id = "Participant")
#intervals from sample
sc2interval(sample)

#compare sample (y) and intervals (x)
sc2interval(sample) %&gt;%
 mutate(Datetime = int_start(Interval)) %&gt;%
 dplyr::left_join(sample, by = c("Id", "State"),
                  relationship = "many-to-many") %&gt;%
 head()

</code></pre>

<hr>
<h2 id='sleep_int2Brown'>Recode Sleep/Wake intervals to Brown state intervals</h2><span id='topic+sleep_int2Brown'></span>

<h3>Description</h3>

<p>Takes a dataset with sleep/wake intervals and recodes them to Brown state
intervals. Specifically, it recodes the <code>sleep</code> intervals to <code>night</code>, reduces
<code>wake</code> intervals by a specified <code>evening.length</code> and recodes them to
<code>evening</code> and <code>day</code> intervals. The <code>evening.length</code> is the time between <code>day</code>
and <code>night</code>. The result can be used as input for <code><a href="#topic+interval2state">interval2state()</a></code> and might
be used subsequently with <code><a href="#topic+Brown2reference">Brown2reference()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sleep_int2Brown(
  dataset,
  Interval.colname = Interval,
  Sleep.colname = State,
  wake.state = "wake",
  sleep.state = "sleep",
  Brown.day = "day",
  Brown.evening = "evening",
  Brown.night = "night",
  evening.length = lubridate::dhours(3),
  Brown.state.colname = State.Brown,
  output.dataset = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sleep_int2Brown_+3A_dataset">dataset</code></td>
<td>
<p>A dataset with sleep/wake intervals.</p>
</td></tr>
<tr><td><code id="sleep_int2Brown_+3A_interval.colname">Interval.colname</code></td>
<td>
<p>The name of the column with the intervals. Defaults to <code>Interval</code>.</p>
</td></tr>
<tr><td><code id="sleep_int2Brown_+3A_sleep.colname">Sleep.colname</code></td>
<td>
<p>The name of the column with the sleep/wake states. Defaults to <code>State</code>.</p>
</td></tr>
<tr><td><code id="sleep_int2Brown_+3A_wake.state">wake.state</code>, <code id="sleep_int2Brown_+3A_sleep.state">sleep.state</code></td>
<td>
<p>The names of the wake and sleep states in the <code>Sleep.colname</code>. Default to <code>"wake"</code> and <code>"sleep"</code>. Expected to be a <code>character</code> scalar and must be an exact match.</p>
</td></tr>
<tr><td><code id="sleep_int2Brown_+3A_brown.day">Brown.day</code>, <code id="sleep_int2Brown_+3A_brown.evening">Brown.evening</code>, <code id="sleep_int2Brown_+3A_brown.night">Brown.night</code></td>
<td>
<p>The names of the Brown states that will be used. Defaults to <code>"day"</code>, <code>"evening"</code> and <code>"night"</code>.</p>
</td></tr>
<tr><td><code id="sleep_int2Brown_+3A_evening.length">evening.length</code></td>
<td>
<p>The length of the evening interval in seconds. Can also use <span class="pkg">lubridate</span> duration or period objects. Defaults to 3 hours.</p>
</td></tr>
<tr><td><code id="sleep_int2Brown_+3A_brown.state.colname">Brown.state.colname</code></td>
<td>
<p>The name of the column with the newly created Brown states. Works as a simple renaming of the <code>Sleep.colname</code>.</p>
</td></tr>
<tr><td><code id="sleep_int2Brown_+3A_output.dataset">output.dataset</code></td>
<td>
<p>Whether to return the whole <code>dataset</code> or a <code>vector</code> with the Brown states.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will filter out any non-sleep intervals that are shorter than the specified <code>evening.length</code>. This prevents problematic behaviour when the <code>evening.length</code> is longer than the <code>wake</code> intervals or, e.g., when the first state is sleep after midnight and there is a prior <code>NA</code> interval from midnight till sleep. This behavior might, however, result in problematic results for specialized experimental setups with ultra short wake/sleep cycles. The <code>sleep_int2Brown()</code> function would not be applicable in those cases anyways.
</p>


<h3>Value</h3>

<p>A dataset with the Brown states or a vector with the Brown states. The Brown states are created in a new column with the name specified in <code>Brown.state.colname</code>. The dataset will have more rows than the original dataset, because the <code>wake</code> intervals are split into <code>day</code> and <code>evening</code> intervals.
</p>


<h3>References</h3>

<p>https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571
</p>


<h3>See Also</h3>

<p>Other Brown: 
<code><a href="#topic+Brown2reference">Brown2reference</a>()</code>,
<code><a href="#topic+Brown_check">Brown_check</a>()</code>,
<code><a href="#topic+Brown_rec">Brown_rec</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#create a sample dataset
sample &lt;- tibble::tibble(Datetime = c("2023-08-15 6:00:00",
                                         "2023-08-15 23:00:00",
                                         "2023-08-16 6:00:00",
                                         "2023-08-16 22:00:00",
                                         "2023-08-17 6:30:00",
                                         "2023-08-18 1:00:00"),
                         State = rep(c("wake", "sleep"), 3),
                         Id = "Participant")
#intervals from sample
sc2interval(sample) 
#recoded intervals                       
sc2interval(sample) %&gt;% sleep_int2Brown()
                                         
</code></pre>

<hr>
<h2 id='supported.devices'>A vector of all supported devices for import functions</h2><span id='topic+supported.devices'></span>

<h3>Description</h3>

<p>These are all supported devices where there is a dedicated import function.
Import functions can be called either through <code><a href="#topic+import_Dataset">import_Dataset()</a></code> with the
respective <code>device = "device"</code> argument, or directly, e.g.,
<code>import$ActLumus()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>supported.devices
</code></pre>


<h3>Format</h3>

<p><code>supported.devices</code> A character vector, listing all supported devices
</p>

<dl>
<dt>suppored.devices</dt><dd><p>strings</p>
</dd>
</dl>


<hr>
<h2 id='symlog_trans'>Scale positive and negative values on a log scale</h2><span id='topic+symlog_trans'></span>

<h3>Description</h3>

<p>To create a plot with positive and negative (unscaled) values on a log-transformed axis, the values need to be scaled accordingly. R or <span class="pkg">ggplot2</span> do not have a built-in function for this, but the following function can be used to create a transformation function for this purpose. The function was coded based on a <a href="https://stackoverflow.com/a/14674703">post on stack overflow</a>. The <code>symlog</code> transformation is the standard transformation used e.g., in <code><a href="#topic+gg_day">gg_day()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>symlog_trans(base = 10, thr = 1, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symlog_trans_+3A_base">base</code></td>
<td>
<p>Base for the logarithmic transformation. The default is 10.</p>
</td></tr>
<tr><td><code id="symlog_trans_+3A_thr">thr</code></td>
<td>
<p>Threshold after which a logarithmic transformation is applied. If the absolute value is below this <code>threshold</code>, the value is not transformed. The default is 1.</p>
</td></tr>
<tr><td><code id="symlog_trans_+3A_scale">scale</code></td>
<td>
<p>Scaling factor for logarithmically transformed values above the <code>threshold</code>. The default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>symlog</code> transformation can be accessed either via the <code>trans = "symlog"</code> argument in a scaling function, or via <code>trans = symlog_trans()</code>. The latter allows setting the individual arguments.
</p>


<h3>Value</h3>

<p>a transformation function that can be used in <span class="pkg">ggplot2</span> or <span class="pkg">plotly</span> to scale positive and negative values on a log scale.
</p>


<h3>References</h3>

<p>This function's code is a straight copy from a post on <a href="https://stackoverflow.com/a/14674703">stack overflow</a>.
The author of the answer is <a href="https://stackoverflow.com/users/1320535/julius-vainora">Julius Vainora</a>, and the author of the question <a href="https://stackoverflow.com/users/1212562/brian-b">Brian B</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- 
sample.data.environment %&gt;%
filter_Date(end = "2023-08-15") %&gt;% 
dplyr::mutate(MEDI = dplyr::case_when(
                                     Id == "Environment" ~ -MEDI,
                                     .default = MEDI))
#basic application where transformation, breaks and labels are set manually
dataset %&gt;%                                     
gg_day(aes_col = Id) +
ggplot2::scale_y_continuous(
trans = "symlog")

#the same plot, but with breaks and labels set manually                            
dataset %&gt;%                                     
gg_day(aes_col = Id) +
ggplot2::scale_y_continuous(
trans = "symlog", 
breaks = c(-10^(5:0), 0, 10^(0:5)),
labels = function(x) format(x, scientific = FALSE, big.mark = " "))

#setting individual arguments of the symlog function manually allows
#e.g., to emphasize values smaller than 1
dataset %&gt;%                                     
gg_day(aes_col = Id) +
ggplot2::scale_y_continuous(
trans = symlog_trans(thr = 0.01),
breaks = c(-10^(5:-1), 0, 10^(-1:5)),
labels = function(x) format(x, scientific = FALSE, big.mark = " "))

</code></pre>

<hr>
<h2 id='threshold_for_duration'>Find threshold for given duration</h2><span id='topic+threshold_for_duration'></span>

<h3>Description</h3>

<p>This function finds the threshold for which light levels are above/below for
a given duration. This function can be considered as the inverse of
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>threshold_for_duration(
  Light.vector,
  Time.vector,
  duration,
  comparison = c("above", "below"),
  epoch = "dominant.epoch",
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="threshold_for_duration_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="threshold_for_duration_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>,
<a href="hms.html#topic+hms">hms</a>, <a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="threshold_for_duration_+3A_duration">duration</code></td>
<td>
<p>The duration for which the threshold should be found. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="threshold_for_duration_+3A_comparison">comparison</code></td>
<td>
<p>String specifying whether light levels above or below the threshold
should be considered. Can be either <code>"above"</code> (the default) or <code>"below"</code>.</p>
</td></tr>
<tr><td><code id="threshold_for_duration_+3A_epoch">epoch</code></td>
<td>
<p>The epoch at which the data was sampled. Can be either a
<a href="lubridate.html#topic+duration">duration</a> or a string. If it is a string, it needs to be
either <code>"dominant.epoch"</code> (the default) for a guess based on the data, or a valid
<a href="lubridate.html#topic+duration">duration</a> string, e.g., <code>"1 day"</code> or <code>"10 sec"</code>.</p>
</td></tr>
<tr><td><code id="threshold_for_duration_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values (NA) be removed for the calculation?
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="threshold_for_duration_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should a data frame with be returned? If <code>TRUE</code>, a data
frame with a single column named <code style="white-space: pre;">&#8288;threshold_{comparison}_for_{duration}&#8288;</code> will be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Single numeric value or single column data frame.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+timing_above_threshold">timing_above_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 60
# Dataset with 30 min &lt; 250lx and 30min &gt; 250lx
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", N),
    Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),
    MEDI = sample(c(sample(1:249, N / 2, replace = TRUE), 
                    sample(250:1000, N / 2, replace = TRUE))),
  )

dataset1 %&gt;%
  dplyr::reframe("Threshold above which for 30 mins" = 
                   threshold_for_duration(MEDI, Datetime, duration = "30 mins"))

dataset1 %&gt;%
  dplyr::reframe("Threshold below which for 30 mins" = 
                   threshold_for_duration(MEDI, Datetime, duration = "30 mins",
                                          comparison = "below"))

dataset1 %&gt;%
  dplyr::reframe(threshold_for_duration(MEDI, Datetime, duration = "30 mins",
                                        as.df = TRUE))

</code></pre>

<hr>
<h2 id='timing_above_threshold'>Mean/first/last timing above/below threshold.</h2><span id='topic+timing_above_threshold'></span>

<h3>Description</h3>

<p>This function calculates the mean, first, and last timepoint (MLiT, FLiT, LLiT)
where light levels are above or below a given threshold intensity within the given
time interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timing_above_threshold(
  Light.vector,
  Time.vector,
  comparison = c("above", "below"),
  threshold,
  na.rm = FALSE,
  as.df = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timing_above_threshold_+3A_light.vector">Light.vector</code></td>
<td>
<p>Numeric vector containing the light data.</p>
</td></tr>
<tr><td><code id="timing_above_threshold_+3A_time.vector">Time.vector</code></td>
<td>
<p>Vector containing the time data. Can be <a href="base.html#topic+POSIXct">POSIXct</a>,
<a href="hms.html#topic+hms">hms</a>, <a href="lubridate.html#topic+duration">duration</a>, or <a href="base.html#topic+difftime">difftime</a>.</p>
</td></tr>
<tr><td><code id="timing_above_threshold_+3A_comparison">comparison</code></td>
<td>
<p>String specifying whether the time above or below threshold
should be calculated. Can be either <code>"above"</code> (the default) or <code>"below"</code>. If
two values are provided for <code>threshold</code>, this argument will be ignored.</p>
</td></tr>
<tr><td><code id="timing_above_threshold_+3A_threshold">threshold</code></td>
<td>
<p>Single numeric value or two numeric values specifying the
threshold light level(s) to compare with. If a vector with two values is provided,
the timing corresponding to light levels between the two thresholds will be
calculated.</p>
</td></tr>
<tr><td><code id="timing_above_threshold_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed for the calculation?
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="timing_above_threshold_+3A_as.df">as.df</code></td>
<td>
<p>Logical. Should a data frame be returned? If <code>TRUE</code>, a data
frame with three columns (MLiT, FLiT, LLiT) and the threshold (e.g., <code style="white-space: pre;">&#8288;MLiT_{threshold}&#8288;</code>)
will be returned. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List or dataframe with the three values: <code>mean</code>, <code>first</code>, and <code>last</code> timing
above threshold. The output type corresponds to the type of <code>Time.vector</code>,
e.g., if <code>Time.vector</code> is HMS, the timing metrics will be also
HMS, and vice versa for POSIXct and numeric.
</p>


<h3>References</h3>

<p>Reid, K. J., Santostasi, G., Baron, K. G., Wilson, J., Kang, J.,
&amp; Zee, P. C. (2014). Timing and Intensity of Light Correlate with Body Weight
in Adults. <em>PLOS ONE</em>, 9(4), e92251.
<a href="https://doi.org/10.1371/journal.pone.0092251">doi:10.1371/journal.pone.0092251</a>
</p>
<p>Hartmeyer, S.L., Andersen, M. (2023). Towards a framework for light-dosimetry studies:
Quantification metrics. <em>Lighting Research &amp; Technology</em>.
<a href="https://doi.org/10.1177/14771535231170500">doi:10.1177/14771535231170500</a>
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+bright_dark_period">bright_dark_period</a>()</code>,
<code><a href="#topic+centroidLE">centroidLE</a>()</code>,
<code><a href="#topic+disparity_index">disparity_index</a>()</code>,
<code><a href="#topic+duration_above_threshold">duration_above_threshold</a>()</code>,
<code><a href="#topic+exponential_moving_average">exponential_moving_average</a>()</code>,
<code><a href="#topic+frequency_crossing_threshold">frequency_crossing_threshold</a>()</code>,
<code><a href="#topic+interdaily_stability">interdaily_stability</a>()</code>,
<code><a href="#topic+intradaily_variability">intradaily_variability</a>()</code>,
<code><a href="#topic+midpointCE">midpointCE</a>()</code>,
<code><a href="#topic+nvRC">nvRC</a>()</code>,
<code><a href="#topic+nvRD">nvRD</a>()</code>,
<code><a href="#topic+nvRD_cumulative_response">nvRD_cumulative_response</a>()</code>,
<code><a href="#topic+period_above_threshold">period_above_threshold</a>()</code>,
<code><a href="#topic+pulses_above_threshold">pulses_above_threshold</a>()</code>,
<code><a href="#topic+threshold_for_duration">threshold_for_duration</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Dataset with light &gt; 250lx between 06:00 and 18:00
dataset1 &lt;-
  tibble::tibble(
    Id = rep("A", 24),
    Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),
    MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))
  )

# Above threshold
dataset1 %&gt;%
  dplyr::reframe(timing_above_threshold(MEDI, Datetime, "above", 250, as.df = TRUE))

# Below threshold
dataset1 %&gt;%
  dplyr::reframe(timing_above_threshold(MEDI, Datetime, "below", 10, as.df = TRUE))

# Input = HMS -&gt; Output = HMS
dataset1 %&gt;%
  dplyr::reframe(timing_above_threshold(MEDI, hms::as_hms(Datetime), "above", 250, as.df = TRUE))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
