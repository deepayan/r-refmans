<!DOCTYPE html><html><head><title>Help for package cassowaryr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cassowaryr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#anscombe_tidy'><p>Data from Anscombe's famous example in tidy format</p></a></li>
<li><a href='#calc_scags'><p>Compute selected scagnostics on subsets</p></a></li>
<li><a href='#calc_scags_wide'><p>Compute scagnostics on all possible scatter plots for the given data</p></a></li>
<li><a href='#datasaurus_dozen'><p>datasaurus_dozen data</p></a></li>
<li><a href='#draw_alphahull'><p>Drawing the alphahull</p></a></li>
<li><a href='#draw_convexhull'><p>Drawing the Convex Hull</p></a></li>
<li><a href='#draw_mst'><p>Drawing the MST</p></a></li>
<li><a href='#features'><p>Simulated data with special features</p></a></li>
<li><a href='#numbat'><p>A toy data set with a numbat shape hidden among noise variables</p></a></li>
<li><a href='#pk'><p>Parkinsons data from UCI machine learning archive</p></a></li>
<li><a href='#sc_clumpy'><p>Compute clumpy scagnostic measure using MST</p></a></li>
<li><a href='#sc_clumpy_r'><p>Compute robust clumpy scagnostic measure using MST</p></a></li>
<li><a href='#sc_clumpy2'><p>Compute adjusted clumpy measure using MST</p></a></li>
<li><a href='#sc_convex'><p>Compute convex scagnostic measure</p></a></li>
<li><a href='#sc_dcor'><p>Distance correlation index.</p></a></li>
<li><a href='#sc_monotonic'><p>Measure of Spearman Correlation</p></a></li>
<li><a href='#sc_outlying'><p>Compute outlying scagnostic measure using MST</p></a></li>
<li><a href='#sc_skewed'><p>Compute skewed scagnostic measure using MST</p></a></li>
<li><a href='#sc_skinny'><p>Compute skinny scagnostic measure</p></a></li>
<li><a href='#sc_sparse'><p>Compute sparse scagnostic measure using MST</p></a></li>
<li><a href='#sc_sparse2'><p>Compute  adjusted sparse measure using the alpha hull</p></a></li>
<li><a href='#sc_splines'><p>Spline based index.</p></a></li>
<li><a href='#sc_striated'><p>Compute striated scagnostic measure using MST</p></a></li>
<li><a href='#sc_striated2'><p>Compute angle adjusted striated measure using MST</p></a></li>
<li><a href='#sc_stringy'><p>Compute stringy scagnostic measure using MST</p></a></li>
<li><a href='#sc_striped'><p>Measure of Discreteness</p></a></li>
<li><a href='#scree'><p>Pre-processing to generate scagnostic measures</p></a></li>
<li><a href='#top_pairs'><p>Calculate the top scagnostic for each pair of variables</p></a></li>
<li><a href='#top_scags'><p>Calculate the top pair of variables or group for each scagnostic</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Compute Scagnostics on Pairs of Numeric Variables in a Data Set</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes a range of scatterplot diagnostics (scagnostics) on pairs
  of numerical variables in a data set. A range of scagnostics, including graph
  and association-based scagnostics described by Leland Wilkinson and Graham
  Wills (2008) &lt;<a href="https://doi.org/10.1198%2F106186008X320465">doi:10.1198/106186008X320465</a>&gt; and association-based
  scagnostics described by Katrin Grimm (2016,ISBN:978-3-8439-3092-5) can be 
  computed. Summary and plotting functions are provided.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/numbats/cassowaryr">https://github.com/numbats/cassowaryr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/numbats/cassowaryr/issues">https://github.com/numbats/cassowaryr/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>igraph, alphahull (&ge; 2.5), splancs, interp, energy, dplyr,
ggplot2, magrittr, progress, tibble, stats, tidyselect</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, mgcv, GGally, tidyr, testthat (&ge; 3.0.0),
covr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-22 08:47:29 UTC; hmas0003</td>
</tr>
<tr>
<td>Author:</td>
<td>Harriet Mason [aut, cre],
  Stuart Lee <a href="https://orcid.org/0000-0003-1179-8436"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Ursula Laa <a href="https://orcid.org/0000-0002-0249-6439"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Di Cook <a href="https://orcid.org/0000-0002-3813-7155"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Harriet Mason &lt;harriet.m.mason@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-09 12:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='anscombe_tidy'>Data from Anscombe's famous example in tidy format</h2><span id='topic+anscombe_tidy'></span>

<h3>Description</h3>

<p>All variables and pairs of variables have same
summary statistics but are very different data,
as can be seen by visualisation.
</p>


<h3>Format</h3>

<p>A tibble with 44 observations and 3 variables
</p>

<dl>
<dt>set</dt><dd><p>label of the data set, each set has 11 observations</p>
</dd>
<dt>x</dt><dd><p>variable for horizontal axis</p>
</dd>
<dt>y</dt><dd><p>variable for vertical axis</p>
</dd>
</dl>


<hr>
<h2 id='calc_scags'>Compute selected scagnostics on subsets</h2><span id='topic+calc_scags'></span>

<h3>Description</h3>

<p>Compute selected scagnostics on subsets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_scags(
  x,
  y,
  scags = c("outlying", "stringy", "striated", "striated2", "clumpy", "clumpy2",
    "sparse", "skewed", "convex", "skinny", "monotonic", "splines", "dcor"),
  out.rm = TRUE,
  euclid = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_scags_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="calc_scags_+3A_y">y</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="calc_scags_+3A_scags">scags</code></td>
<td>
<p>collection of strings matching names of
scagnostics to calculate: outlying, stringy, striated,
striated2, striped, clumpy, clumpy2, sparse, skewed, convex,
skinny, monotonic, splines, dcor</p>
</td></tr>
<tr><td><code id="calc_scags_+3A_out.rm">out.rm</code></td>
<td>
<p>logical indicator to indicate if outliers should be removed before calculating non outlying measures</p>
</td></tr>
<tr><td><code id="calc_scags_+3A_euclid">euclid</code></td>
<td>
<p>logical indicator to use Euclidean distance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame that gives the single plot's scagnostic score.
</p>


<h3>See Also</h3>

<p>calc_scags_wide
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Calculate selected scagnostics on a single pair
calc_scags(anscombe$x1, anscombe$y1, scags=c("monotonic", "outlying"))

# Compute on long form data, or subsets
# defined by a categorical variable
require(dplyr)
datasaurus_dozen %&gt;%
  group_by(dataset) %&gt;%
  summarise(calc_scags(x,y, scags=c("monotonic", "outlying", "convex")))

</code></pre>

<hr>
<h2 id='calc_scags_wide'>Compute scagnostics on all possible scatter plots for the given data</h2><span id='topic+calc_scags_wide'></span>

<h3>Description</h3>

<p>Compute scagnostics on all possible scatter plots for the given data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_scags_wide(
  all_data,
  scags = c("outlying", "stringy", "striated", "striated2", "clumpy", "clumpy2",
    "sparse", "skewed", "convex", "skinny", "monotonic", "splines", "dcor"),
  out.rm = TRUE,
  euclid = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_scags_wide_+3A_all_data">all_data</code></td>
<td>
<p>tibble of multivariate data on which to compute scagnostics</p>
</td></tr>
<tr><td><code id="calc_scags_wide_+3A_scags">scags</code></td>
<td>
<p>collection of strings matching names of
scagnostics to calculate: outlying, stringy, striated,
striated2, striped, clumpy, clumpy2, sparse, skewed, convex,
skinny, monotonic, splines, dcor</p>
</td></tr>
<tr><td><code id="calc_scags_wide_+3A_out.rm">out.rm</code></td>
<td>
<p>logical indicator to indicate if outliers should be removed before calculating non outlying measures</p>
</td></tr>
<tr><td><code id="calc_scags_wide_+3A_euclid">euclid</code></td>
<td>
<p>logical indicator to use Euclidean distance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame that gives the data's scagnostic scores for each possible variable combination.
</p>


<h3>See Also</h3>

<p>calc_scags
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Calculate selected scagnostics
data(pk)
calc_scags_wide(pk[,2:5], scags=c("outlying","monotonic"))

</code></pre>

<hr>
<h2 id='datasaurus_dozen'>datasaurus_dozen data</h2><span id='topic+datasaurus_dozen'></span><span id='topic+datasaurus_dozen_wide'></span>

<h3>Description</h3>

<p>From the datasauRus package. A modern update of Anscombe.
All plots have same x and y mean, variance and correlation,
but look different visually.
</p>
<p>All variables and pairs of variables have same
summary statistics but are very different data,
as can be seen by visualisation.
</p>


<h3>Format</h3>

<p>A tibble with 1,846 observations and 3 variables
</p>

<dl>
<dt>dataset</dt><dd><p>label of data set</p>
</dd>
<dt>x</dt><dd><p>variable for horizontal axis</p>
</dd>
<dt>y</dt><dd><p>variable for vertical axis</p>
</dd>
</dl>

<p>A tibble with 142 observations and 26 variables
</p>

<dl>
<dt>away_x, away_y</dt><dd><p>x and y variables for away data</p>
</dd>
<dt>bullseye_x, bullseye_y</dt><dd><p>x and y variables for bullseye data</p>
</dd>
<dt>circle_x, circle_y</dt><dd><p>x and y variables for circle data</p>
</dd>
<dt>dino_x, dino_y</dt><dd><p>x and y variables for dino data</p>
</dd>
<dt>dots_x, dots_y</dt><dd><p>x and y variables for dots data</p>
</dd>
<dt>h_lines_x, h_lines_y</dt><dd><p>x and y variables for h_lines data</p>
</dd>
<dt>high_lines_x, high_lines_y</dt><dd><p>x and y variables for high_lines data</p>
</dd>
<dt>slant_down_x, slant_down_y</dt><dd><p>x and y variables for slant_down data</p>
</dd>
<dt>slant_up_x, slant_up_y</dt><dd><p>x and y variables for slant_up data</p>
</dd>
<dt>star_x, star_y</dt><dd><p>x and y variables for star data</p>
</dd>
<dt>v_lines_x, v_lines_y</dt><dd><p>x and y variables for v_lines data</p>
</dd>
<dt>wide_lines_x, wide_lines_y</dt><dd><p>x and y variables for wide_lines data</p>
</dd>
<dt>star_x, star_y</dt><dd><p>x and y variables for star data</p>
</dd>
<dt>x_shape_x, x_shape_y</dt><dd><p>x and y variables for x_shape data</p>
</dd>
</dl>


<hr>
<h2 id='draw_alphahull'>Drawing the alphahull</h2><span id='topic+draw_alphahull'></span>

<h3>Description</h3>

<p>This function will draw the alphahull for a
scatterplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw_alphahull(x, y, alpha = 0.5, clr = "black", fill = FALSE, out.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw_alphahull_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="draw_alphahull_+3A_y">y</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="draw_alphahull_+3A_alpha">alpha</code></td>
<td>
<p>transparency value of points</p>
</td></tr>
<tr><td><code id="draw_alphahull_+3A_clr">clr</code></td>
<td>
<p>optional colour of points and lines, default black</p>
</td></tr>
<tr><td><code id="draw_alphahull_+3A_fill">fill</code></td>
<td>
<p>Fill the polygon</p>
</td></tr>
<tr><td><code id="draw_alphahull_+3A_out.rm">out.rm</code></td>
<td>
<p>option to return the outlier removed alphahull</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A alphahull::ahull(del, alpha = alpha) &quot;gg&quot; object that draws the plot's alpha hull.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(dplyr)
require(ggplot2)
require(alphahull)
data("features")
nl &lt;- features %&gt;% filter(feature == "clusters")
draw_alphahull(nl$x, nl$y)
</code></pre>

<hr>
<h2 id='draw_convexhull'>Drawing the Convex Hull</h2><span id='topic+draw_convexhull'></span>

<h3>Description</h3>

<p>This function will draw the Convex Hull for a
scatterplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw_convexhull(x, y, alpha = 0.5, clr = "black", fill = FALSE, out.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw_convexhull_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="draw_convexhull_+3A_y">y</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="draw_convexhull_+3A_alpha">alpha</code></td>
<td>
<p>transparency value of points</p>
</td></tr>
<tr><td><code id="draw_convexhull_+3A_clr">clr</code></td>
<td>
<p>optional colour of points and lines, default black</p>
</td></tr>
<tr><td><code id="draw_convexhull_+3A_fill">fill</code></td>
<td>
<p>Fill the polygon</p>
</td></tr>
<tr><td><code id="draw_convexhull_+3A_out.rm">out.rm</code></td>
<td>
<p>option to return the outlier removed convex hull</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;gg&quot; object that draws the plot's convex hull.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(dplyr)
require(ggplot2)
data("features")
nl &lt;- features %&gt;% filter(feature == "clusters")
draw_convexhull(nl$x, nl$y, fill=TRUE, out.rm=FALSE)
</code></pre>

<hr>
<h2 id='draw_mst'>Drawing the MST</h2><span id='topic+draw_mst'></span>

<h3>Description</h3>

<p>This function will draw the MST for a
scatterplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw_mst(x, y, alpha = 0.5, out.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw_mst_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="draw_mst_+3A_y">y</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="draw_mst_+3A_alpha">alpha</code></td>
<td>
<p>The alpha value used to build the graph object. Larger values allow points further apart to be connected.</p>
</td></tr>
<tr><td><code id="draw_mst_+3A_out.rm">out.rm</code></td>
<td>
<p>option to return the outlier removed MST</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;gg&quot; object that draws the plot's MST.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(dplyr)
require(ggplot2)
data("features")
nl &lt;- features %&gt;% filter(feature == "nonlinear2")
draw_mst(nl$x, nl$y)
</code></pre>

<hr>
<h2 id='features'>Simulated data with special features</h2><span id='topic+features'></span>

<h3>Description</h3>

<p>Simulated data with common features that might
be seen in 2D data. Variable are feature, x, y.
</p>


<h3>Format</h3>

<p>A tibble with 1,013 observations and 3 variables,
and 15 different patterns
</p>

<dl>
<dt>feature</dt><dd><p>label of data set</p>
</dd>
<dt>x</dt><dd><p>variable for horizontal axis</p>
</dd>
<dt>y</dt><dd><p>variable for vertical axis</p>
</dd>
</dl>


<hr>
<h2 id='numbat'>A toy data set with a numbat shape hidden among noise variables</h2><span id='topic+numbat'></span>

<h3>Description</h3>

<p>There are 7 variables (x1-x7) and 2,100 observations.
Variables 4 and 7 have the numbat. The rest are
noise. Group A has the numbat, and group B is all noise.
</p>

<hr>
<h2 id='pk'>Parkinsons data from UCI machine learning archive</h2><span id='topic+pk'></span>

<h3>Description</h3>

<p>Biomedical voice measurements from 31 people,
23 with Parkinson's disease (PD). Each column
in the table is a particular voice measure, and
each row corresponds one of 195 voice recording
from these individuals (&quot;name&quot; column). The main
aim of the data is to discriminate healthy people
from those with PD, according to &quot;status&quot; column
which is set to 0 for healthy and 1 for PD.
</p>


<h3>Format</h3>

<p>A tibble with 1,013 observations and 3 variables
</p>

<dl>
<dt>name</dt><dd><p>ASCII subject name and recording number</p>
</dd>
<dt><code>MDVP:Fo(Hz)</code></dt><dd><p>Average vocal fundamental frequency</p>
</dd>
<dt><code>MDVP:Fhi(Hz)</code></dt><dd><p>Maximum vocal fundamental frequency</p>
</dd>
<dt><code>MDVP:Flo(Hz)</code></dt><dd><p>Minimum vocal fundamental frequency</p>
</dd>
<dt><code>MDVP:Jitter</code>,<code>MDVP:Jitter(Abs)</code>,<code>MDVP:RAP</code>,<code>MDVP:PPQ</code>,<code>Jitter:DDP</code></dt><dd><p>Several measures of variation in fundamental frequency</p>
</dd>
<dt><code>MDVP:Shimmer</code>,<code>MDVP:Shimmer(dB)</code>,<code>Shimmer:APQ3</code>,<code>Shimmer:APQ5</code>,<code>MDVP:APQ</code>,<code>Shimmer:DDA</code></dt><dd><p>Several measures of variation in amplitude</p>
</dd>
<dt><code>NHR</code>,<code>HNR</code></dt><dd><p>Two measures of ratio of noise to tonal components in the voice</p>
</dd>
<dt><code>status</code></dt><dd><p>Health status of the subject (one) - Parkinson's, (zero) - healthy</p>
</dd>
<dt><code>RPDE</code>,<code>D2</code></dt><dd><p>Two nonlinear dynamical complexity measures</p>
</dd>
<dt><code>DFA</code></dt><dd><p>Signal fractal scaling exponent</p>
</dd>
<dt><code>spread1</code>,<code>spread2</code>,<code>PPE</code></dt><dd><p>Three nonlinear measures of fundamental frequency variation</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data is available at <a href="https://archive.ics.uci.edu/ml/datasets/Parkinsons">The UCI Machine Learning Repository</a>
in ASCII CSV format. The rows of the CSV file contain
an instance corresponding to one voice recording.
There are around six recordings per patient, the name
of the patient is identified in the first column.
</p>
<p>The data are originally analysed in:
Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008),
'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease',
IEEE Transactions on Biomedical Engineering.
</p>

<hr>
<h2 id='sc_clumpy'>Compute clumpy scagnostic measure using MST</h2><span id='topic+sc_clumpy'></span><span id='topic+sc_clumpy.default'></span><span id='topic+sc_clumpy.scree'></span><span id='topic+sc_clumpy.igraph'></span>

<h3>Description</h3>

<p>Compute clumpy scagnostic measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_clumpy(x, y)

## Default S3 method:
sc_clumpy(x, y)

## S3 method for class 'scree'
sc_clumpy(x, y = NULL)

## S3 method for class 'igraph'
sc_clumpy(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_clumpy_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_clumpy_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's clumpy score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(dplyr)
  ggplot(features, aes(x=x, y=y)) +
     geom_point() +
     facet_wrap(~feature, ncol = 5, scales = "free")
  features %&gt;% group_by(feature) %&gt;% summarise(clumpy = sc_clumpy(x,y))
  sc_clumpy(datasaurus_dozen_wide$away_x, datasaurus_dozen_wide$away_y)

</code></pre>

<hr>
<h2 id='sc_clumpy_r'>Compute robust clumpy scagnostic measure using MST</h2><span id='topic+sc_clumpy_r'></span><span id='topic+sc_clumpy_r.default'></span><span id='topic+sc_clumpy_r.scree'></span><span id='topic+sc_clumpy_r.igraph'></span>

<h3>Description</h3>

<p>Compute robust clumpy scagnostic measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_clumpy_r(x, y)

## Default S3 method:
sc_clumpy_r(x, y)

## S3 method for class 'scree'
sc_clumpy_r(x, y = NULL)

## S3 method for class 'igraph'
sc_clumpy_r(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_clumpy_r_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_clumpy_r_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's robust clumpy score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(dplyr)
  ggplot(features, aes(x=x, y=y)) +
     geom_point() +
     facet_wrap(~feature, ncol = 5, scales = "free")
  features %&gt;% group_by(feature) %&gt;% summarise(clumpy = sc_clumpy_r(x,y))
  sc_clumpy_r(datasaurus_dozen_wide$away_x, datasaurus_dozen_wide$away_y)

</code></pre>

<hr>
<h2 id='sc_clumpy2'>Compute adjusted clumpy measure using MST</h2><span id='topic+sc_clumpy2'></span><span id='topic+sc_clumpy2.default'></span><span id='topic+sc_clumpy2.scree'></span><span id='topic+sc_clumpy2.igraph'></span>

<h3>Description</h3>

<p>Compute adjusted clumpy measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_clumpy2(x, y)

## Default S3 method:
sc_clumpy2(x, y)

## S3 method for class 'scree'
sc_clumpy2(x, y = NULL)

## S3 method for class 'igraph'
sc_clumpy2(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_clumpy2_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_clumpy2_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's clumpy2 score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(dplyr)
  ggplot(features, aes(x=x, y=y)) +
     geom_point() +
     facet_wrap(~feature, ncol = 5, scales = "free")
  features %&gt;% group_by(feature) %&gt;% summarise(clumpy = sc_clumpy2(x,y))
  sc_clumpy2(datasaurus_dozen_wide$away_x, datasaurus_dozen_wide$away_y)

</code></pre>

<hr>
<h2 id='sc_convex'>Compute convex scagnostic measure</h2><span id='topic+sc_convex'></span><span id='topic+sc_convex.default'></span><span id='topic+sc_convex.scree'></span><span id='topic+sc_convex.list'></span>

<h3>Description</h3>

<p>Compute convex scagnostic measure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_convex(x, y)

## Default S3 method:
sc_convex(x, y)

## S3 method for class 'scree'
sc_convex(x, y = NULL)

## S3 method for class 'list'
sc_convex(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_convex_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_convex_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's convex score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(dplyr)
  ggplot(features, aes(x=x, y=y)) +
     geom_point() +
     facet_wrap(~feature, ncol = 5, scales = "free")
  features %&gt;% group_by(feature) %&gt;% summarise(convex = sc_convex(x,y))
  sc_convex(datasaurus_dozen_wide$away_x, datasaurus_dozen_wide$away_y)
</code></pre>

<hr>
<h2 id='sc_dcor'>Distance correlation index.</h2><span id='topic+sc_dcor'></span>

<h3>Description</h3>

<p>(Taken from tourr package)
Computes the distance correlation based index on
2D projections of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_dcor(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_dcor_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="sc_dcor_+3A_y">y</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's dcor score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(tidyr)
  require(dplyr)
  data(anscombe)
  anscombe_tidy &lt;- anscombe %&gt;%
  pivot_longer(cols = everything(),
    names_to = c(".value", "set"),
    names_pattern = "(.)(.)")
  ggplot(anscombe_tidy, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~set, ncol=2, scales = "free")
  sc_dcor(anscombe$x1, anscombe$y1)
  sc_dcor(anscombe$x2, anscombe$y2)
  sc_dcor(anscombe$x3, anscombe$y3)
  sc_dcor(anscombe$x4, anscombe$y4)

</code></pre>

<hr>
<h2 id='sc_monotonic'>Measure of Spearman Correlation</h2><span id='topic+sc_monotonic'></span>

<h3>Description</h3>

<p>Measure of Spearman Correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_monotonic(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_monotonic_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="sc_monotonic_+3A_y">y</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's monotonic score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(tidyr)
  require(dplyr)
  data(anscombe)
  anscombe_tidy &lt;- anscombe %&gt;%
  pivot_longer(cols = everything(),
    names_to = c(".value", "set"),
    names_pattern = "(.)(.)")
  ggplot(anscombe_tidy, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~set, ncol=2, scales = "free")
  sc_monotonic(anscombe$x1, anscombe$y1)
  sc_monotonic(anscombe$x2, anscombe$y2)
  sc_monotonic(anscombe$x3, anscombe$y3)
  sc_monotonic(anscombe$x4, anscombe$y4)

</code></pre>

<hr>
<h2 id='sc_outlying'>Compute outlying scagnostic measure using MST</h2><span id='topic+sc_outlying'></span><span id='topic+sc_outlying.default'></span><span id='topic+sc_outlying.scree'></span><span id='topic+sc_outlying.igraph'></span>

<h3>Description</h3>

<p>Compute outlying scagnostic measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_outlying(x, y)

## Default S3 method:
sc_outlying(x, y)

## S3 method for class 'scree'
sc_outlying(x, y = NULL)

## S3 method for class 'igraph'
sc_outlying(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_outlying_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_outlying_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's outlying score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(tidyr)
  require(dplyr)
  ggplot(datasaurus_dozen, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~dataset, ncol=3, scales = "free")
  sc_outlying(datasaurus_dozen_wide$dino_x, datasaurus_dozen_wide$dino_y)
  sc_outlying(datasaurus_dozen_wide$dots_x, datasaurus_dozen_wide$dots_y)
  sc_outlying(datasaurus_dozen_wide$h_lines_x, datasaurus_dozen_wide$h_lines_y)

</code></pre>

<hr>
<h2 id='sc_skewed'>Compute skewed scagnostic measure using MST</h2><span id='topic+sc_skewed'></span><span id='topic+sc_skewed.default'></span><span id='topic+sc_skewed.scree'></span><span id='topic+sc_skewed.igraph'></span>

<h3>Description</h3>

<p>Compute skewed scagnostic measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_skewed(x, y)

## Default S3 method:
sc_skewed(x, y)

## S3 method for class 'scree'
sc_skewed(x, y = NULL)

## S3 method for class 'igraph'
sc_skewed(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_skewed_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_skewed_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's skewed score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(tidyr)
  require(dplyr)
  data(anscombe_tidy)
  ggplot(datasaurus_dozen, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~dataset, ncol=3, scales = "free")
  sc_skewed(datasaurus_dozen_wide$dots_x, datasaurus_dozen_wide$dots_y)
  sc_skewed(datasaurus_dozen_wide$h_lines_x, datasaurus_dozen_wide$h_lines_y)
  sc_skewed(datasaurus_dozen_wide$x_shape_x, datasaurus_dozen_wide$x_shape_y)

</code></pre>

<hr>
<h2 id='sc_skinny'>Compute skinny scagnostic measure</h2><span id='topic+sc_skinny'></span><span id='topic+sc_skinny.default'></span><span id='topic+sc_skinny.scree'></span><span id='topic+sc_skinny.list'></span>

<h3>Description</h3>

<p>Compute skinny scagnostic measure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_skinny(x, y)

## Default S3 method:
sc_skinny(x, y)

## S3 method for class 'scree'
sc_skinny(x, y = NULL)

## S3 method for class 'list'
sc_skinny(x, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_skinny_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_skinny_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's skinny score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(dplyr)
  ggplot(features, aes(x=x, y=y)) +
     geom_point() +
     facet_wrap(~feature, ncol = 5, scales = "free")
  features %&gt;% group_by(feature) %&gt;% summarise(skinny = sc_skinny(x,y))
  sc_skinny(datasaurus_dozen_wide$away_x, datasaurus_dozen_wide$away_y)
</code></pre>

<hr>
<h2 id='sc_sparse'>Compute sparse scagnostic measure using MST</h2><span id='topic+sc_sparse'></span><span id='topic+sc_sparse.default'></span><span id='topic+sc_sparse.scree'></span><span id='topic+sc_sparse.igraph'></span>

<h3>Description</h3>

<p>Compute sparse scagnostic measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_sparse(x, y)

## Default S3 method:
sc_sparse(x, y)

## S3 method for class 'scree'
sc_sparse(x, y = NULL)

## S3 method for class 'igraph'
sc_sparse(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_sparse_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_sparse_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's sparse score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(tidyr)
  require(dplyr)
  ggplot(datasaurus_dozen, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~dataset, ncol=3, scales = "free")
  sc_sparse(datasaurus_dozen_wide$away_x, datasaurus_dozen_wide$away_y)
  sc_sparse(datasaurus_dozen_wide$circle_x, datasaurus_dozen_wide$circle_y)
  sc_sparse(datasaurus_dozen_wide$dino_x, datasaurus_dozen_wide$dino_y)

</code></pre>

<hr>
<h2 id='sc_sparse2'>Compute  adjusted sparse measure using the alpha hull</h2><span id='topic+sc_sparse2'></span><span id='topic+sc_sparse2.default'></span><span id='topic+sc_sparse2.scree'></span><span id='topic+sc_sparse2.list'></span>

<h3>Description</h3>

<p>Compute  adjusted sparse measure using the alpha hull
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_sparse2(x, y)

## Default S3 method:
sc_sparse2(x, y)

## S3 method for class 'scree'
sc_sparse2(x, y = NULL)

## S3 method for class 'list'
sc_sparse2(x, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_sparse2_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_sparse2_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's sparse2 score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(tidyr)
  require(dplyr)
  data(anscombe_tidy)
  ggplot(anscombe_tidy, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~set, ncol=2, scales = "free")
  sc_sparse2(anscombe$x1, anscombe$y1)

</code></pre>

<hr>
<h2 id='sc_splines'>Spline based index.</h2><span id='topic+sc_splines'></span>

<h3>Description</h3>

<p>(Taken from tourr git repo)
Compares the variance in residuals of a fitted
spline model to the overall variance to find
functional dependence in 2D projections
of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_splines(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_splines_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="sc_splines_+3A_y">y</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's spines score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(tidyr)
  require(dplyr)
  data(anscombe)
  anscombe_tidy &lt;- anscombe %&gt;%
  pivot_longer(cols = everything(),
    names_to = c(".value", "set"),
    names_pattern = "(.)(.)")
  ggplot(anscombe_tidy, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~set, ncol=2, scales = "free")
  sc_splines(anscombe$x1, anscombe$y1)
  sc_splines(anscombe$x2, anscombe$y2)
  sc_splines(anscombe$x3, anscombe$y3)

</code></pre>

<hr>
<h2 id='sc_striated'>Compute striated scagnostic measure using MST</h2><span id='topic+sc_striated'></span><span id='topic+sc_striated.default'></span><span id='topic+sc_striated.scree'></span><span id='topic+sc_striated.igraph'></span>

<h3>Description</h3>

<p>Compute striated scagnostic measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_striated(x, y)

## Default S3 method:
sc_striated(x, y)

## S3 method for class 'scree'
sc_striated(x, y = NULL)

## S3 method for class 'igraph'
sc_striated(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_striated_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_striated_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's striated score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(dplyr)
  data(anscombe_tidy)
  ggplot(anscombe_tidy, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~set, ncol=2, scales = "free")
  sc_striated(anscombe$x1, anscombe$y1)
  sc_striated(anscombe$x2, anscombe$y2)

</code></pre>

<hr>
<h2 id='sc_striated2'>Compute angle adjusted striated measure using MST</h2><span id='topic+sc_striated2'></span><span id='topic+sc_striated2.default'></span><span id='topic+sc_striated2.scree'></span><span id='topic+sc_striated2.igraph'></span>

<h3>Description</h3>

<p>Compute angle adjusted striated measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_striated2(x, y)

## Default S3 method:
sc_striated2(x, y)

## S3 method for class 'scree'
sc_striated2(x, y = NULL)

## S3 method for class 'igraph'
sc_striated2(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_striated2_+3A_x">x</code></td>
<td>
<p>numeric vector of x values, or an MST object</p>
</td></tr>
<tr><td><code id="sc_striated2_+3A_y">y</code></td>
<td>
<p>numeric vector of y values, or a scree object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's striated2 score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(dplyr)
  ggplot(features, aes(x=x, y=y)) +
     geom_point() +
     facet_wrap(~feature, ncol = 5, scales = "free")
  features %&gt;% group_by(feature) %&gt;% summarise(striated = sc_striated2(x,y))
  sc_striated2(datasaurus_dozen_wide$away_x, datasaurus_dozen_wide$away_y)

</code></pre>

<hr>
<h2 id='sc_stringy'>Compute stringy scagnostic measure using MST</h2><span id='topic+sc_stringy'></span><span id='topic+sc_stringy.default'></span><span id='topic+sc_stringy.scree'></span><span id='topic+sc_stringy.igraph'></span>

<h3>Description</h3>

<p>Compute stringy scagnostic measure using MST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_stringy(x, y)

## Default S3 method:
sc_stringy(x, y)

## S3 method for class 'scree'
sc_stringy(x, y = NULL)

## S3 method for class 'igraph'
sc_stringy(x, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_stringy_+3A_x">x</code></td>
<td>
<p>numeric vector of x values</p>
</td></tr>
<tr><td><code id="sc_stringy_+3A_y">y</code></td>
<td>
<p>numeric vector of y values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;numeric&quot; object that gives the plot's stringy score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(ggplot2)
  require(tidyr)
  require(dplyr)
  data(anscombe_tidy)
  ggplot(anscombe_tidy, aes(x=x, y=y)) +
    geom_point() +
    facet_wrap(~set, ncol=2, scales = "free")
  sc_stringy(anscombe$x1, anscombe$y1)
  sc_stringy(anscombe$x2, anscombe$y2)
  sc_stringy(anscombe$x3, anscombe$y3)
  sc_stringy(anscombe$x4, anscombe$y4)

</code></pre>

<hr>
<h2 id='sc_striped'>Measure of Discreteness</h2><span id='topic+sc_striped'></span>

<h3>Description</h3>

<p>This metric computes the 1-(ratio between the
number of unique values to total data values)
on number of rotations of the data, and
returns the smallest value. If this value is
large it means that there are only a few unique
data values, and hence the distribution is
discrete
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc_striped(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc_striped_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="sc_striped_+3A_y">y</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>double
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("datasaurus_dozen_wide")
sc_striped(datasaurus_dozen_wide$v_lines_x,
           datasaurus_dozen_wide$v_lines_y)
sc_striped(datasaurus_dozen_wide$dino_x,
           datasaurus_dozen_wide$dino_y)
</code></pre>

<hr>
<h2 id='scree'>Pre-processing to generate scagnostic measures</h2><span id='topic+scree'></span>

<h3>Description</h3>

<p>Pre-processing to generate scagnostic measures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scree(x, y, binner = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scree_+3A_x">x</code>, <code id="scree_+3A_y">y</code></td>
<td>
<p>numeric vectors</p>
</td></tr>
<tr><td><code id="scree_+3A_binner">binner</code></td>
<td>
<p>an optional function that bins the x and y vectors prior
to triangulation</p>
</td></tr>
<tr><td><code id="scree_+3A_...">...</code></td>
<td>
<p>other args</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;scree&quot; that consists of three elements:
</p>

<ul>
<li> <p><code>del</code>: the Delauney-Voronoi tesselation from <code><a href="alphahull.html#topic+delvor">alphahull::delvor()</a></code>
</p>
</li>
<li> <p><code>weights</code>: the lengths of each edge in the Delauney triangulation
</p>
</li>
<li> <p><code>alpha</code>: the radius or <code>alpha</code> value that will be used to generate the
alphahull
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- runif(100)
y &lt;- runif(100)
scree(x,y)

</code></pre>

<hr>
<h2 id='top_pairs'>Calculate the top scagnostic for each pair of variables</h2><span id='topic+top_pairs'></span>

<h3>Description</h3>

<p>Calculate the top scagnostic for each pair of variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>top_pairs(scags_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="top_pairs_+3A_scags_data">scags_data</code></td>
<td>
<p>A dataset of scagnostic values that was returned by calc_scags or calc_scags_wide</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame where each row is a each scatter plot, its highest valued scagnostic, and its respective value
</p>


<h3>See Also</h3>

<p>calc_scags calc_scags_wide top_scags
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#an example using calc_scags
require(dplyr)
datasaurus_dozen %&gt;%
  group_by(dataset) %&gt;%
  summarise(calc_scags(x,y, scags=c("monotonic", "outlying", "convex"))) %&gt;%
  top_pairs()
 #an example using calc_scags_wide
 data(pk)
 scags_data &lt;- calc_scags_wide(pk[,2:5], scags=c("outlying","clumpy","monotonic"))
 top_pairs(scags_data)
</code></pre>

<hr>
<h2 id='top_scags'>Calculate the top pair of variables or group for each scagnostic</h2><span id='topic+top_scags'></span>

<h3>Description</h3>

<p>Calculate the top pair of variables or group for each scagnostic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>top_scags(scags_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="top_scags_+3A_scags_data">scags_data</code></td>
<td>
<p>A dataset of scagnostic values that was returned by calc_scags or calc_scags_wide</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame where each row is a scagnostic with its highest pair and the associated value
</p>


<h3>See Also</h3>

<p>calc_scags calc_scags_wide top_pairs
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#an example using calc_scags
require(dplyr)
datasaurus_dozen %&gt;%
  group_by(dataset) %&gt;%
  summarise(calc_scags(x,y, scags=c("monotonic", "outlying", "convex"))) %&gt;%
  top_scags()
 #an example using calc_scags_wide
 data(pk)
 scags_data &lt;- calc_scags_wide(pk[,2:5], scags=c("outlying","clumpy","monotonic"))
 top_scags(scags_data)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
