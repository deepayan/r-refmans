<!DOCTYPE html><html><head><title>Help for package parallelMCMCcombine</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {parallelMCMCcombine}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#parallelMCMCcombine-package'><p>parallelMCMCcombine</p></a></li>
<li><a href='#consensusMCcov'><p>Consensus Monte Carlo Algorithm (for correlated parameters)</p>
</p></a></li>
<li><a href='#consensusMCindep'><p> Consensus Monte Carlo Algorithm (for independent parameters)</p></a></li>
<li><a href='#sampleAvg'><p> Sample Averaging Method</p></a></li>
<li><a href='#semiparamDPE'><p> Semiparametric Density Product Estimator Method</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Combining Subset MCMC Samples to Estimate a Posterior Density</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-06-18</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexey Miroshnikov, Erin Conlon</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Erin Conlon &lt;econlon@umass.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>See Miroshnikov and Conlon (2014) &lt;<a href="https://doi.org/10.1371%2Fjournal.pone.0108425">doi:10.1371/journal.pone.0108425</a>&gt;. Recent Bayesian Markov chain Monto Carlo (MCMC) methods have been developed for big data sets that are too large to be analyzed using traditional statistical methods. These methods partition the data into non-overlapping subsets, and perform parallel independent Bayesian MCMC analyses on the data subsets, creating independent subposterior samples for each data subset. These independent subposterior samples are combined through four functions in this package, including averaging across subset samples, weighted averaging across subsets samples, and kernel smoothing across subset samples. The four functions assume the user has previously run the Bayesian analysis and has produced the independent subposterior samples outside of the package; the functions use as input the array of subposterior samples. The methods have been demonstrated to be useful for Bayesian MCMC models including Bayesian logistic regression, Bayesian Gaussian mixture models and Bayesian hierarchical Poisson-Gamma models. The methods are appropriate for Bayesian hierarchical models with hyperparameters, as long as data values in a single level of the hierarchy are not split into subsets.</td>
</tr>
<tr>
<td>Depends:</td>
<td>mvtnorm</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-06-23 01:55:38 UTC; admin1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-06-23 07:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='parallelMCMCcombine-package'>parallelMCMCcombine
</h2><span id='topic+parallelMCMCcombine-package'></span>

<h3>Description</h3>

<p>Recent Bayesian Markov chain Monto Carlo (MCMC) methods have been developed for big data sets that are too large to be analyzed using traditional statistical methods. These methods partition the data into non-overlapping subsets, and perform parallel independent Bayesian MCMC analyses on the data subsets, creating independent subposterior samples for each data subset. These independent subposterior samples are combined through four functions in this package, including averaging across subset samples, weighted averaging across subsets samples, and kernel smoothing across subset samples. The four functions assume the user has previously run the Bayesian analysis and has produced the independent subposterior samples outside of the package; the functions use as input the array of subposterior samples. The methods have been demonstrated to be useful for Bayesian MCMC models including Bayesian logistic regression, Bayesian Gaussian mixture models and Bayesian hierarchical Poisson-Gamma models. The methods are appropriate for Bayesian hierarchical models with hyperparameters, as long as data values in a single level of the hierarchy are not split into subsets.</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> parallelMCMCcombine</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2021-06-18</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td>
</tr>

</table>

<p>The package contains the following functions:
</p>
<p><code><a href="#topic+consensusMCcov">consensusMCcov</a></code>   Consensus Monte Carlo Algorithm (for correlated parameters) 
</p>
<p><code><a href="#topic+consensusMCindep">consensusMCindep</a></code> Consensus Monte Carlo Algorithm (for independent parameters)
</p>
<p><code><a href="#topic+sampleAvg">sampleAvg</a></code>  Sample Averaging Method
</p>
<p><code><a href="#topic+semiparamDPE">semiparamDPE</a></code>  Semiparametric Method
</p>


<h3>Author(s)</h3>

<p>Alexey Miroshnikov, Erin Conlon
</p>
<p>Maintainer: Erin Conlon <a href="mailto:econlon@umass.edu">econlon@umass.edu</a>
</p>


<h3>References</h3>

<p>Scott, S.L., Blocker, A. W., Bonassi (2013) Bayes and Big Data: The consensus Monte Carlo Algorithm. <em>Bayes 250</em>.
</p>
<p>Neiswanger, W., Wang, C., Xing, E. (2014) Asymptotically exact, embarrassingly parallel MCMC. <em>arXiv:1311.4780v2.</em>
</p>
<p>Silverman, B.W. (1986). Density Estimation for Statistics and Data Analysis. <em>Chapman &amp; Hall/CRC. pp. 7-11</em>. 
</p>

<hr>
<h2 id='consensusMCcov'>Consensus Monte Carlo Algorithm (for correlated parameters)
</h2><span id='topic+consensusMCcov'></span>

<h3>Description</h3>

<p>The function uses the Consensus Monte Carlo algorithm introduced by Scott et al. (see References) to combine the independent subset posterior samples subchains into the set of samples that estimate the posterior density given the full data set. The Consensus Monte Carlo algorithm uses a weighted average of the subset posterior samples to produce the combined posterior samples, where the weights are based on the inverse variance-covariance matrix of the subset posterior samples.</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusMCcov(subchain, shuff = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="consensusMCcov_+3A_subchain">subchain</code></td>
<td>

<p>array of subset posterior samples of the dimension <span class="option">c(d,sampT,M).</span> Here <span class="option">d</span> is the dimension of the parameter space, <span class="option">sampT</span> is the number of samples, and <span class="option">M</span> is the number of subposterior datasets.
</p>
</td></tr>
<tr><td><code id="consensusMCcov_+3A_shuff">shuff</code></td>
<td>
<p>shuff: logical; if TRUE, each of the <span class="option">M</span> subsets of <span class="option">d</span> dimensional parameters  in <span class="option">subchain</span> is shuffled.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The array <span class="option">subchain</span> must have dimension <span class="option">c(d,sampT,M)</span>. Here <span class="option">d</span> is the dimension of the parameter space, <span class="option">sampT</span> is the number of samples, and <span class="option">M</span> is the number of subposterior datasets.
</p>


<h3>Value</h3>

<p>Returns an array of samples of dimension dim=c(d,sampT)
representing an estimated (combined) full posterior density.</p>


<h3>References</h3>

<p>Scott, S.L., Blocker, A. W., Bonassi (2013) Bayes and Big Data: The consensus Monte Carlo Algorithm. <em>Bayes 250</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d      &lt;- 2     # dimension of the parameter space  
sampT  &lt;- 1000  # number of subset posterior samples
M      &lt;- 3     # total number of subsets

## simulate Gaussian subposterior samples

theta &lt;- array(NA,c(d,sampT,M)) 

norm.mean &lt;- c(1.0, 2.0)
norm.sd   &lt;- c(0.5, 1.0)

for (i in 1:d)
  for (s in 1:M)        
    theta[i,,s] &lt;- rnorm(sampT, mean=norm.mean[i]+runif(1,-0.01,0.01), sd=norm.sd[i])

## combine samples:

full.theta &lt;- consensusMCcov(subchain=theta, shuff=FALSE)
</code></pre>

<hr>
<h2 id='consensusMCindep'> Consensus Monte Carlo Algorithm (for independent parameters)</h2><span id='topic+consensusMCindep'></span>

<h3>Description</h3>

<p>The function uses the Consensus Monte Carlo algorithm introduced by Scott et al. (see References) to combine the independent subset posterior samples subchains into the set of samples that estimate the posterior density given the full data set. The Consensus Monte Carlo algorithm uses a weighted average of the subset posterior samples to produce the combined posterior samples, where the weights are based on the inverse variance-covariance matrix of the subset posterior samples. Here, the model parameters are assumed to be independent, so that the covariance between model parameters is equal to zero.</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusMCindep(subchain, shuff = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="consensusMCindep_+3A_subchain">subchain</code></td>
<td>

<p>array of subset posterior samples of the dimension <span class="option">c(d,sampT,M).</span> Here <span class="option">d</span> is the dimension of the parameter space, <span class="option">sampT</span> is the number of samples, and <span class="option">M</span> is the number of subposterior datasets.
</p>
</td></tr>
<tr><td><code id="consensusMCindep_+3A_shuff">shuff</code></td>
<td>
<p>shuff: logical; if TRUE, each of the <span class="option">M</span> subsets of <span class="option">d</span> dimensional parameters  in <span class="option">subchain</span> is shuffled.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The array <span class="option">subchain</span> must have dimension <span class="option">c(d,sampT,M)</span>. Here <span class="option">d</span> is the dimension of the parameter space, <span class="option">sampT</span> is the number of samples, and <span class="option">M</span> is the number of subposterior datasets.
</p>


<h3>Value</h3>

<p>Returns an array of samples of dimension dim=c(d,sampT)
representing an estimated (combined) full posterior density.</p>


<h3>References</h3>

<p>Scott, S.L., Blocker, A. W., Bonassi (2013) Bayes and Big Data: The consensus Monte Carlo Algorithm. <em>Bayes 250 day</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d      &lt;- 2     # dimension of the parameter space  
sampT  &lt;- 1000  # number of subset posterior samples
M      &lt;- 3     # total number of subsets

## simulate Gaussian subposterior samples

theta &lt;- array(NA,c(d,sampT,M)) 

norm.mean &lt;- c(1.0, 2.0)
norm.sd   &lt;- c(0.5, 1.0)

for (i in 1:d)
  for (s in 1:M)        
    theta[i,,s] &lt;- rnorm(sampT, mean=norm.mean[i]+runif(1,-0.01,0.01), sd=norm.sd[i])

## combine samples:

full.theta &lt;- consensusMCindep(subchain=theta, shuff=FALSE)
</code></pre>

<hr>
<h2 id='sampleAvg'> Sample Averaging Method </h2><span id='topic+sampleAvg'></span>

<h3>Description</h3>

<p>The function combines the independent subset posterior samples subchains into  the set of samples that estimate the posterior density given the full data set, by averaging the samples across subsets. Individual model
parameters are assumed to be independent.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleAvg(subchain, shuff = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleAvg_+3A_subchain">subchain</code></td>
<td>

<p>array of subset posterior samples of the dimension <span class="option">c(d,sampT,M).</span> Here <span class="option">d</span> is the dimension of the parameter space, <span class="option">sampT</span> is the number of samples, and <span class="option">M</span> is the number of subposterior datasets.
</p>
</td></tr>
<tr><td><code id="sampleAvg_+3A_shuff">shuff</code></td>
<td>
<p>shuff: logical; if TRUE, each of the <span class="option">M</span> subsets of <span class="option">d</span> dimensional parameters  in <span class="option">subchain</span> is shuffled.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The array <span class="option">subchain</span> must have dimension <span class="option">c(d,sampT,M)</span>. Here <span class="option">d</span> is the dimension of the parameter space, <span class="option">sampT</span> is the number of samples, and <span class="option">M</span> is the number of subposterior datasets.
</p>


<h3>Value</h3>

<p>Returns an array of samples of dimension dim=c(d,sampT) representing an estimated (combined) full posterior density.</p>


<h3>Examples</h3>

<pre><code class='language-R'>d      &lt;- 2     # dimension of the parameter space  
sampT  &lt;- 1000  # number of subset posterior samples
M      &lt;- 3     # total number of subsets

## simulate Gaussian subposterior samples

theta &lt;- array(NA,c(d,sampT,M)) 

norm.mean &lt;- c(1.0, 2.0)
norm.sd   &lt;- c(0.5, 1.0)

for (i in 1:d)
  for (s in 1:M)        
    theta[i,,s] &lt;- rnorm(sampT, mean=norm.mean[i]+runif(1,-0.01,0.01), sd=norm.sd[i])

## combine samples:

full.theta &lt;- sampleAvg(subchain=theta, shuff=FALSE)
</code></pre>

<hr>
<h2 id='semiparamDPE'> Semiparametric Density Product Estimator Method</h2><span id='topic+semiparamDPE'></span>

<h3>Description</h3>

<p>The function uses the Semiparametric Density Product Estimator method introduced by Neiswanger et al. (see References) to combine the independent subset posterior samples subchains into the set of samples that estimate the posterior density given the full data set. The semiparametric density product estimator method uses kernel smoothing techniques to estimate each subset posterior density; the subposterior densities are then multiplied together to approximate the posterior density based on the full data set.</p>


<h3>Usage</h3>

<pre><code class='language-R'>semiparamDPE(subchain, bandw = rep(1.0, dim(subchain)[1]), anneal = TRUE, shuff = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semiparamDPE_+3A_subchain">subchain</code></td>
<td>

<p>array of subset posterior samples of the dimension <span class="option">c(d,sampT,M).</span> Here <span class="option">d</span> is the dimension of the parameter space, <span class="option">sampT</span> is the number of samples, and <span class="option">M</span> is the number of subposterior datasets.
</p>
</td></tr>
<tr><td><code id="semiparamDPE_+3A_bandw">bandw</code></td>
<td>
<p> bandwidth vector of the length <span class="option">d=dim(subchain)[1]</span>. It is a vector of tuning parameters used in kernel density approximation employed by the semiparametric method. When <span class="option">anneal=TRUE</span> then one of the choices for <span class="option">bandw</span> could be the vector consisting of standard deviations for each of the <span class="option">d</span> parameters. When <span class="option">anneal=FALSE</span> then one of the choices for <span class="option">bandw</span> could be the diagonal of the optimal bandwidth matrix obtained via Silverman's rule of thumb; see Examples. By default <span class="option">bandw=rep(1.0,d)</span>. </p>
</td></tr>
<tr><td><code id="semiparamDPE_+3A_anneal">anneal</code></td>
<td>
<p> logical; if TRUE, the bandwidth <span class="option">bandw</span> (instead of being fixed) is annealed as <span class="option">bandw*i^(-1/(4+d))</span>; here <span class="option">i</span> is the index corresponding to a sample; see References. </p>
</td></tr>
<tr><td><code id="semiparamDPE_+3A_shuff">shuff</code></td>
<td>
<p>logical; if TRUE, each of the <span class="option">M</span> subsets of <span class="option">d</span> dimensional parameters  in <span class="option">subchain</span> is shuffled.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an array of samples of dimension dim=c(d,sampT)
representing an estimated (combined) full posterior density.</p>


<h3>References</h3>

<p>Neiswanger, W., Wang, C., Xing E. (2014) Asymptotically exact, embarrassingly parallel MCMC. arXiv:1311.4780v2.
</p>
<p>Silverman, B.W. (1986). Density Estimation for Statistics and Data Analysis. <em> Chapman &amp; Hall/CRC. pp. 7-11</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d      &lt;- 2     # dimension of the parameter space
sampT  &lt;- 300   # number of subset posterior samples
M      &lt;- 3     # total number of subsets

## simulate Gaussian subposterior samples

theta &lt;- array(NA,c(d,sampT,M))

norm.mean &lt;- c(1.0, 2.0)
norm.sd   &lt;- c(0.5, 1.0)

for (i in 1:d)
  for (s in 1:M)
    theta[i,,s] &lt;- rnorm(sampT, mean=norm.mean[i]+runif(1,-0.01,0.01), sd=norm.sd[i])

## estimate (mean) standard deviations for each parameter across the subsets

norm.var.est &lt;- rep(0,d)

for(i in 1:d)
  for(s in 1:M)
    norm.var.est[i] &lt;- norm.var.est[i] + var(theta[i,,s])

norm.sd.est &lt;- sqrt(norm.var.est/M)


## Compute the diagonal of the optimal bandwidth
## matrix according to Silverman's rule

h_opt1 = (4/(d+2))^(1/(4+d)) * (sampT^(-1/(4+d))) * norm.sd.est

## Combine samples. The bandwidth matrix is fixed:

full.theta1 &lt;- semiparamDPE( subchain = theta, bandw = h_opt1 * 2, anneal = FALSE)

## Compute the diagonal of the optimal bandwidth
## matrix for the method that uses annealing

h_opt2 = (4/(d+2))^(1/(4+d)) * norm.sd.est

## Combine samples. The bandwidth matrix will be annealed:

full.theta2 &lt;- semiparamDPE(subchain = theta, bandw = h_opt2 * 2, anneal = TRUE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
