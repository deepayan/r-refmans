<!DOCTYPE html><html><head><title>Help for package SLOPE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SLOPE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abalone'><p>Abalone</p></a></li>
<li><a href='#bodyfat'><p>Bodyfat</p></a></li>
<li><a href='#caretSLOPE'><p>Model objects for model tuning with caret (deprecated)</p></a></li>
<li><a href='#coef.SLOPE'><p>Obtain coefficients</p></a></li>
<li><a href='#deviance.SLOPE'><p>Model deviance</p></a></li>
<li><a href='#heart'><p>Heart disease</p></a></li>
<li><a href='#interpolateCoefficients'><p>Interpolate coefficients</p></a></li>
<li><a href='#interpolatePenalty'><p>Interpolate penalty values</p></a></li>
<li><a href='#plot.SLOPE'><p>Plot coefficients</p></a></li>
<li><a href='#plot.TrainedSLOPE'><p>Plot results from cross-validation</p></a></li>
<li><a href='#plotDiagnostics'><p>Plot results from diagnostics collected during model fitting</p></a></li>
<li><a href='#predict.SLOPE'><p>Generate predictions from SLOPE models</p></a></li>
<li><a href='#print.SLOPE'><p>Print results from SLOPE fit</p></a></li>
<li><a href='#regularizationWeights'><p>Generate Regularization (Penalty) Weights for SLOPE</p></a></li>
<li><a href='#score'><p>Compute one of several loss metrics on a new data set</p></a></li>
<li><a href='#setupDiagnostics'><p>Setup a data.frame of diagnostics</p></a></li>
<li><a href='#SLOPE'><p>Sorted L-One Penalized Estimation</p></a></li>
<li><a href='#SLOPE-package'><p>SLOPE: Sorted L1 Penalized Estimation</p></a></li>
<li><a href='#sortedL1Prox'><p>Sorted L1 Proximal Operator</p></a></li>
<li><a href='#student'><p>Student performance</p></a></li>
<li><a href='#trainSLOPE'><p>Train a SLOPE model</p></a></li>
<li><a href='#wine'><p>Wine cultivars</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Sorted L1 Penalized Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient implementations for Sorted L-One Penalized Estimation
    (SLOPE): generalized linear models regularized with the sorted L1-norm
    (Bogdan et al. (2015) &lt;<a href="https://doi.org/10%2Fgfgwzt">doi:10/gfgwzt</a>&gt;). Supported models include ordinary
    least-squares regression, binomial regression, multinomial regression, and
    Poisson regression. Both dense and sparse  predictor matrices are supported.
    In addition, the package features predictor screening rules that enable fast
    and efficient solutions to high-dimensional problems.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>checkmate, foreach, ggplot2, glmnet, Matrix, methods, mice,
Rcpp</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo (&ge; 0.9.850.1.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bench, caret, covr, dplyr, knitr, rmarkdown, scales,
spelling, stringr, testthat (&ge; 2.1.0), tidyr, vdiffr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://jolars.github.io/SLOPE/">https://jolars.github.io/SLOPE/</a>, <a href="https://github.com/jolars/SLOPE">https://github.com/jolars/SLOPE</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jolars/SLOPE/issues">https://github.com/jolars/SLOPE/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-09 15:19:25 UTC; gerd-jln</td>
</tr>
<tr>
<td>Author:</td>
<td>Johan Larsson <a href="https://orcid.org/0000-0002-4029-5945"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Jonas Wallin <a href="https://orcid.org/0000-0003-0381-6593"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Malgorzata Bogdan [aut],
  Ewout van den Berg [aut],
  Chiara Sabatti [aut],
  Emmanuel Candes [aut],
  Evan Patterson [aut],
  Weijie Su [aut],
  Jakub Ka≈Ça [aut],
  Krystyna Grzesiak [aut],
  Michal Burdukiewicz
    <a href="https://orcid.org/0000-0001-8926-582X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Jerome Friedman [ctb] (code adapted from 'glmnet'),
  Trevor Hastie [ctb] (code adapted from 'glmnet'),
  Rob Tibshirani [ctb] (code adapted from 'glmnet'),
  Balasubramanian Narasimhan [ctb] (code adapted from 'glmnet'),
  Noah Simon [ctb] (code adapted from 'glmnet'),
  Junyang Qian [ctb] (code adapted from 'glmnet'),
  Akarsh Goyal [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Johan Larsson &lt;johan.larsson@stat.lu.se&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-09 22:40:18 UTC</td>
</tr>
</table>
<hr>
<h2 id='abalone'>Abalone</h2><span id='topic+abalone'></span>

<h3>Description</h3>

<p>This data set contains observations of abalones, the common
name for any of a group of sea snails. The goal is to predict the
age of an individual abalone given physical measurements such as
sex, weight, and height.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abalone
</code></pre>


<h3>Format</h3>

<p>A list with two items representing 211 observations from
9 variables
</p>

<dl>
<dt>sex</dt><dd><p>sex of abalone, 1 for female</p>
</dd>
<dt>infant</dt><dd><p>indicates that the person is an infant</p>
</dd>
<dt>length</dt><dd><p>longest shell measurement in mm</p>
</dd>
<dt>diameter</dt><dd><p>perpendicular to length in mm</p>
</dd>
<dt>height</dt><dd><p>height in mm including meat in shell</p>
</dd>
<dt>weight_whole</dt><dd><p>weight of entire abalone</p>
</dd>
<dt>weight_shucked</dt><dd><p>weight of meat</p>
</dd>
<dt>weight_viscera</dt><dd><p>weight of viscera</p>
</dd>
<dt>weight_shell</dt><dd><p>weight of shell</p>
</dd>
<dt>rings</dt><dd><p>rings. +1.5 gives the age in years</p>
</dd>
</dl>



<h3>Details</h3>

<p>Only a stratified sample of 211 rows of the original data set are used here.
</p>


<h3>Source</h3>

<p>Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,
Statistics and Probability Letters, 33 (1997) 291-297.
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+bodyfat">bodyfat</a></code>,
<code><a href="#topic+heart">heart</a></code>,
<code><a href="#topic+student">student</a></code>,
<code><a href="#topic+wine">wine</a></code>
</p>

<hr>
<h2 id='bodyfat'>Bodyfat</h2><span id='topic+bodyfat'></span>

<h3>Description</h3>

<p>The response (<code>y</code>) corresponds to
estimates of percentage of body fat from application of
Siri's 1956 equation to measurements of underwater weighing, as well as
age, weight, height, and a variety of
body circumference measurements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bodyfat
</code></pre>


<h3>Format</h3>

<p>A list with two items representing 252 observations from
14 variables
</p>

<dl>
<dt>age</dt><dd><p>age (years)</p>
</dd>
<dt>weight</dt><dd><p>weight (lbs)</p>
</dd>
<dt>height</dt><dd><p>height (inches)</p>
</dd>
<dt>neck</dt><dd><p>neck circumference (cm)</p>
</dd>
<dt>chest</dt><dd><p>chest circumference (cm)</p>
</dd>
<dt>abdomen</dt><dd><p>abdomen circumference (cm)</p>
</dd>
<dt>hip</dt><dd><p>hip circumference (cm)</p>
</dd>
<dt>thigh</dt><dd><p>thigh circumference (cm)</p>
</dd>
<dt>knee</dt><dd><p>knee circumference (cm)</p>
</dd>
<dt>ankle</dt><dd><p>ankle circumference (cm)</p>
</dd>
<dt>biceps</dt><dd><p>biceps circumference (cm)</p>
</dd>
<dt>forearm</dt><dd><p>forearm circumference (cm)</p>
</dd>
<dt>wrist</dt><dd><p>wrist circumference (cm)</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://lib.stat.cmu.edu/datasets/bodyfat
</p>
<p>https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+abalone">abalone</a></code>,
<code><a href="#topic+heart">heart</a></code>,
<code><a href="#topic+student">student</a></code>,
<code><a href="#topic+wine">wine</a></code>
</p>

<hr>
<h2 id='caretSLOPE'>Model objects for model tuning with caret (deprecated)</h2><span id='topic+caretSLOPE'></span>

<h3>Description</h3>

<p>This function can be used in a call to <code><a href="caret.html#topic+train">caret::train()</a></code> to enable
model tuning using caret. Note that this function does not properly work
with sparse feature matrices and standardization due to the way
resampling is implemented in caret. So for these cases, please
check out <code><a href="#topic+trainSLOPE">trainSLOPE()</a></code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>caretSLOPE()
</code></pre>


<h3>Value</h3>

<p>A model description list to be used in the <code>method</code> argument
in <code><a href="caret.html#topic+train">caret::train()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="caret.html#topic+train">caret::train()</a></code>, <code><a href="#topic+trainSLOPE">trainSLOPE()</a></code>, <code><a href="#topic+SLOPE">SLOPE()</a></code>
</p>
<p>Other model-tuning: 
<code><a href="#topic+plot.TrainedSLOPE">plot.TrainedSLOPE</a>()</code>,
<code><a href="#topic+trainSLOPE">trainSLOPE</a>()</code>
</p>

<hr>
<h2 id='coef.SLOPE'>Obtain coefficients</h2><span id='topic+coef.SLOPE'></span>

<h3>Description</h3>

<p>This function returns coefficients from a model fit by <code><a href="#topic+SLOPE">SLOPE()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLOPE'
coef(object, alpha = NULL, exact = FALSE, simplify = TRUE, sigma, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.SLOPE_+3A_object">object</code></td>
<td>
<p>an object of class <code>'SLOPE'</code>.</p>
</td></tr>
<tr><td><code id="coef.SLOPE_+3A_alpha">alpha</code></td>
<td>
<p>penalty parameter for SLOPE models; if <code>NULL</code>, the
values used in the original fit will be used</p>
</td></tr>
<tr><td><code id="coef.SLOPE_+3A_exact">exact</code></td>
<td>
<p>if <code>TRUE</code> and the given parameter values differ from those in
the original fit, the model will be refit by calling <code><a href="stats.html#topic+update">stats::update()</a></code> on
the object with the new parameters. If <code>FALSE</code>, the predicted values
will be based on interpolated coefficients from the original
penalty path.</p>
</td></tr>
<tr><td><code id="coef.SLOPE_+3A_simplify">simplify</code></td>
<td>
<p>if <code>TRUE</code>, <code><a href="base.html#topic+drop">base::drop()</a></code> will be called before returning
the coefficients to drop extraneous dimensions</p>
</td></tr>
<tr><td><code id="coef.SLOPE_+3A_sigma">sigma</code></td>
<td>
<p>deprecated. Please use <code>alpha</code> instead.</p>
</td></tr>
<tr><td><code id="coef.SLOPE_+3A_...">...</code></td>
<td>
<p>arguments that are passed on to <code><a href="stats.html#topic+update">stats::update()</a></code> (and therefore
also to <code><a href="#topic+SLOPE">SLOPE()</a></code>) if <code>exact = TRUE</code> and the given penalty
is not in <code>object</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>exact = FALSE</code> and <code>alpha</code> is not in <code>object</code>,
then the returned coefficients will be approximated by linear interpolation.
If coefficients from another type of penalty sequence
(with a different <code>lambda</code>) are required, however,
please use <code><a href="#topic+SLOPE">SLOPE()</a></code> to refit the model.
</p>


<h3>Value</h3>

<p>Coefficients from the model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.SLOPE">predict.SLOPE()</a></code>, <code><a href="#topic+SLOPE">SLOPE()</a></code>
</p>
<p>Other SLOPE-methods: 
<code><a href="#topic+deviance.SLOPE">deviance.SLOPE</a>()</code>,
<code><a href="#topic+plot.SLOPE">plot.SLOPE</a>()</code>,
<code><a href="#topic+predict.SLOPE">predict.SLOPE</a>()</code>,
<code><a href="#topic+print.SLOPE">print.SLOPE</a>()</code>,
<code><a href="#topic+score">score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- SLOPE(mtcars$mpg, mtcars$vs, path_length = 1)
coef(fit)
</code></pre>

<hr>
<h2 id='deviance.SLOPE'>Model deviance</h2><span id='topic+deviance.SLOPE'></span>

<h3>Description</h3>

<p>Model deviance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLOPE'
deviance(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deviance.SLOPE_+3A_object">object</code></td>
<td>
<p>an object of class <code>'SLOPE'</code>.</p>
</td></tr>
<tr><td><code id="deviance.SLOPE_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For Gaussian models this is twice the residual sums of squares. For
all other models, two times the negative loglikelihood is returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLOPE">SLOPE()</a></code>
</p>
<p>Other SLOPE-methods: 
<code><a href="#topic+coef.SLOPE">coef.SLOPE</a>()</code>,
<code><a href="#topic+plot.SLOPE">plot.SLOPE</a>()</code>,
<code><a href="#topic+predict.SLOPE">predict.SLOPE</a>()</code>,
<code><a href="#topic+print.SLOPE">print.SLOPE</a>()</code>,
<code><a href="#topic+score">score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- SLOPE(abalone$x, abalone$y, family = "poisson")
deviance(fit)
</code></pre>

<hr>
<h2 id='heart'>Heart disease</h2><span id='topic+heart'></span>

<h3>Description</h3>

<p>Diagnostic attributes of patients classified as having heart disease or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heart
</code></pre>


<h3>Format</h3>

<p>270 observations from 17 variables represented as a list consisting
of a binary factor response vector <code>y</code>,
with levels 'absence' and 'presence' indicating the absence or presence of
heart disease and <code>x</code>: a sparse feature matrix of class 'dgCMatrix' with the
following variables:
</p>

<dl>
<dt>age</dt><dd><p>age</p>
</dd>
<dt>bp</dt><dd><p>diastolic blood pressure</p>
</dd>
<dt>chol</dt><dd><p>serum cholesterol in mg/dl</p>
</dd>
<dt>hr</dt><dd><p>maximum heart rate achieved</p>
</dd>
<dt>old_peak</dt><dd><p>ST depression induced by exercise relative to rest</p>
</dd>
<dt>vessels</dt><dd><p>the number of major blood vessels (0 to 3) that were
colored by fluoroscopy</p>
</dd>
<dt>sex</dt><dd><p>sex of the participant: 0 for male, 1 for female</p>
</dd>
<dt>angina</dt><dd><p>a dummy variable indicating whether the person suffered
angina-pectoris during exercise</p>
</dd>
<dt>glucose_high</dt><dd><p>indicates a fasting blood sugar over 120 mg/dl</p>
</dd>
<dt>cp_typical</dt><dd><p>typical angina</p>
</dd>
<dt>cp_atypical</dt><dd><p>atypical angina</p>
</dd>
<dt>cp_nonanginal</dt><dd><p>non-anginal pain</p>
</dd>
<dt>ecg_abnormal</dt><dd><p>indicates a ST-T wave abnormality
(T wave inversions and/or ST elevation or depression of
&gt; 0.05 mV)</p>
</dd>
<dt>ecg_estes</dt><dd><p>probable or definite left ventricular hypertrophy by
Estes' criteria</p>
</dd>
<dt>slope_flat</dt><dd><p>a flat ST curve during peak exercise</p>
</dd>
<dt>slope_downsloping</dt><dd><p>a downwards-sloping ST curve during peak exercise</p>
</dd>
<dt>thal_reversible</dt><dd><p>reversible defect</p>
</dd>
<dt>thal_fixed</dt><dd><p>fixed defect</p>
</dd>
</dl>



<h3>Preprocessing</h3>

<p>The original dataset contained 13 variables. The nominal of these were
dummycoded, removing the first category. No precise information regarding
variables <code>chest_pain</code>, <code>thal</code> and <code>ecg</code> could be found, which explains
their obscure definitions here.
</p>


<h3>Source</h3>

<p>Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository
<a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>. Irvine, CA: University of California,
School of Information and Computer Science.
</p>
<p><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#heart">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#heart</a>
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+abalone">abalone</a></code>,
<code><a href="#topic+bodyfat">bodyfat</a></code>,
<code><a href="#topic+student">student</a></code>,
<code><a href="#topic+wine">wine</a></code>
</p>

<hr>
<h2 id='interpolateCoefficients'>Interpolate coefficients</h2><span id='topic+interpolateCoefficients'></span>

<h3>Description</h3>

<p>Interpolate coefficients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpolateCoefficients(beta, interpolation_list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interpolateCoefficients_+3A_beta">beta</code></td>
<td>
<p>coefficients</p>
</td></tr>
<tr><td><code id="interpolateCoefficients_+3A_interpolation_list">interpolation_list</code></td>
<td>
<p>a list generated from <code><a href="#topic+interpolatePenalty">interpolatePenalty()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix (or list of matrices) with new coefficients based
on linearly interpolating from new and old lambda values.
</p>

<hr>
<h2 id='interpolatePenalty'>Interpolate penalty values</h2><span id='topic+interpolatePenalty'></span>

<h3>Description</h3>

<p>Interpolate penalty values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpolatePenalty(penalty, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interpolatePenalty_+3A_penalty">penalty</code></td>
<td>
<p>current penalty sequence</p>
</td></tr>
<tr><td><code id="interpolatePenalty_+3A_x">x</code></td>
<td>
<p>new sequence</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Interpolated values of lambda
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie, Rob Tibshirani, and Noah Simon
</p>

<hr>
<h2 id='plot.SLOPE'>Plot coefficients</h2><span id='topic+plot.SLOPE'></span>

<h3>Description</h3>

<p>Plot the fitted model's regression
coefficients along the regularization path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLOPE'
plot(
  x,
  intercept = FALSE,
  x_variable = c("alpha", "deviance_ratio", "step"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SLOPE_+3A_x">x</code></td>
<td>
<p>an object of class <code>"SLOPE"</code></p>
</td></tr>
<tr><td><code id="plot.SLOPE_+3A_intercept">intercept</code></td>
<td>
<p>whether to plot the intercept</p>
</td></tr>
<tr><td><code id="plot.SLOPE_+3A_x_variable">x_variable</code></td>
<td>
<p>what to plot on the x axis. <code>"alpha"</code> plots
the scaling parameter for the sequence, <code>"deviance_ratio"</code> plots
the fraction of deviance explained, and <code>"step"</code> plots step number.</p>
</td></tr>
<tr><td><code id="plot.SLOPE_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"ggplot"</code>, which will be plotted on the
current device unless stored in a variable.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLOPE">SLOPE()</a></code>, <code><a href="#topic+plotDiagnostics">plotDiagnostics()</a></code>
</p>
<p>Other SLOPE-methods: 
<code><a href="#topic+coef.SLOPE">coef.SLOPE</a>()</code>,
<code><a href="#topic+deviance.SLOPE">deviance.SLOPE</a>()</code>,
<code><a href="#topic+predict.SLOPE">predict.SLOPE</a>()</code>,
<code><a href="#topic+print.SLOPE">print.SLOPE</a>()</code>,
<code><a href="#topic+score">score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- SLOPE(heart$x, heart$y)
plot(fit)
</code></pre>

<hr>
<h2 id='plot.TrainedSLOPE'>Plot results from cross-validation</h2><span id='topic+plot.TrainedSLOPE'></span>

<h3>Description</h3>

<p>Plot results from cross-validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TrainedSLOPE'
plot(
  x,
  measure = c("auto", "mse", "mae", "deviance", "auc", "misclass"),
  plot_min = TRUE,
  ci_alpha = 0.2,
  ci_border = FALSE,
  ci_col = "salmon",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.TrainedSLOPE_+3A_x">x</code></td>
<td>
<p>an object of class <code>'TrainedSLOPE'</code>, typically from a call
to <code><a href="#topic+trainSLOPE">trainSLOPE()</a></code></p>
</td></tr>
<tr><td><code id="plot.TrainedSLOPE_+3A_measure">measure</code></td>
<td>
<p>any of the measures used in the call to <code><a href="#topic+trainSLOPE">trainSLOPE()</a></code>. If
<code>measure = "auto"</code> then deviance will be used for binomial and multinomial
models, whilst mean-squared error will be used for Gaussian and Poisson
models.</p>
</td></tr>
<tr><td><code id="plot.TrainedSLOPE_+3A_plot_min">plot_min</code></td>
<td>
<p>whether to mark the location of the penalty corresponding
to the best prediction score</p>
</td></tr>
<tr><td><code id="plot.TrainedSLOPE_+3A_ci_alpha">ci_alpha</code></td>
<td>
<p>alpha (opacity) for fill in confidence limits</p>
</td></tr>
<tr><td><code id="plot.TrainedSLOPE_+3A_ci_border">ci_border</code></td>
<td>
<p>color (or flag to turn off and on) the border of the
confidence limits</p>
</td></tr>
<tr><td><code id="plot.TrainedSLOPE_+3A_ci_col">ci_col</code></td>
<td>
<p>color for border of confidence limits</p>
</td></tr>
<tr><td><code id="plot.TrainedSLOPE_+3A_...">...</code></td>
<td>
<p>words</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"ggplot"</code>, which will be plotted on the
current device unless stored in a variable.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trainSLOPE">trainSLOPE()</a></code>
</p>
<p>Other model-tuning: 
<code><a href="#topic+caretSLOPE">caretSLOPE</a>()</code>,
<code><a href="#topic+trainSLOPE">trainSLOPE</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Cross-validation for a SLOPE binomial model
set.seed(123)
tune &lt;- trainSLOPE(subset(mtcars, select = c("mpg", "drat", "wt")),
  mtcars$hp,
  q = c(0.1, 0.2),
  number = 10
)
plot(tune, ci_col = "salmon")
</code></pre>

<hr>
<h2 id='plotDiagnostics'>Plot results from diagnostics collected during model fitting</h2><span id='topic+plotDiagnostics'></span>

<h3>Description</h3>

<p>This function plots various diagnostics collected during
the model fitting resulting from a call to <code><a href="#topic+SLOPE">SLOPE()</a></code> <em>provided that
<code>diagnostics = TRUE</code></em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDiagnostics(
  object,
  ind = max(object$diagnostics$penalty),
  xvar = c("time", "iteration")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDiagnostics_+3A_object">object</code></td>
<td>
<p>an object of class <code>"SLOPE"</code>.</p>
</td></tr>
<tr><td><code id="plotDiagnostics_+3A_ind">ind</code></td>
<td>
<p>either &quot;last&quot;</p>
</td></tr>
<tr><td><code id="plotDiagnostics_+3A_xvar">xvar</code></td>
<td>
<p>what to place on the x axis. <code>iteration</code> plots each iteration,
<code>time</code> plots the wall-clock time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"ggplot"</code>, which will be plotted on the
current device unless stored in a variable.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLOPE">SLOPE()</a></code>, <code><a href="ggplot2.html#topic+theme">ggplot2::theme()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- SLOPE(abalone$x, abalone$y, diagnostics = TRUE)
plotDiagnostics(x)
</code></pre>

<hr>
<h2 id='predict.SLOPE'>Generate predictions from SLOPE models</h2><span id='topic+predict.SLOPE'></span><span id='topic+predict.GaussianSLOPE'></span><span id='topic+predict.BinomialSLOPE'></span><span id='topic+predict.PoissonSLOPE'></span><span id='topic+predict.MultinomialSLOPE'></span>

<h3>Description</h3>

<p>Return predictions from models fit by <code><a href="#topic+SLOPE">SLOPE()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLOPE'
predict(object, x, alpha = NULL, type = "link", simplify = TRUE, sigma, ...)

## S3 method for class 'GaussianSLOPE'
predict(
  object,
  x,
  sigma = NULL,
  type = c("link", "response"),
  simplify = TRUE,
  ...
)

## S3 method for class 'BinomialSLOPE'
predict(
  object,
  x,
  sigma = NULL,
  type = c("link", "response", "class"),
  simplify = TRUE,
  ...
)

## S3 method for class 'PoissonSLOPE'
predict(
  object,
  x,
  sigma = NULL,
  type = c("link", "response"),
  exact = FALSE,
  simplify = TRUE,
  ...
)

## S3 method for class 'MultinomialSLOPE'
predict(
  object,
  x,
  sigma = NULL,
  type = c("link", "response", "class"),
  exact = FALSE,
  simplify = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.SLOPE_+3A_object">object</code></td>
<td>
<p>an object of class <code>"SLOPE"</code>, typically the result of
a call to <code><a href="#topic+SLOPE">SLOPE()</a></code></p>
</td></tr>
<tr><td><code id="predict.SLOPE_+3A_x">x</code></td>
<td>
<p>new data</p>
</td></tr>
<tr><td><code id="predict.SLOPE_+3A_alpha">alpha</code></td>
<td>
<p>penalty parameter for SLOPE models; if <code>NULL</code>, the
values used in the original fit will be used</p>
</td></tr>
<tr><td><code id="predict.SLOPE_+3A_type">type</code></td>
<td>
<p>type of prediction; <code>"link"</code> returns the linear predictors,
<code>"response"</code> returns the result of applying the link function,
and <code>"class"</code> returns class predictions.</p>
</td></tr>
<tr><td><code id="predict.SLOPE_+3A_simplify">simplify</code></td>
<td>
<p>if <code>TRUE</code>, <code><a href="base.html#topic+drop">base::drop()</a></code> will be called before returning
the coefficients to drop extraneous dimensions</p>
</td></tr>
<tr><td><code id="predict.SLOPE_+3A_sigma">sigma</code></td>
<td>
<p>deprecated. Please use <code>alpha</code> instead.</p>
</td></tr>
<tr><td><code id="predict.SLOPE_+3A_...">...</code></td>
<td>
<p>ignored and only here for method consistency</p>
</td></tr>
<tr><td><code id="predict.SLOPE_+3A_exact">exact</code></td>
<td>
<p>if <code>TRUE</code> and the given parameter values differ from those in
the original fit, the model will be refit by calling <code><a href="stats.html#topic+update">stats::update()</a></code> on
the object with the new parameters. If <code>FALSE</code>, the predicted values
will be based on interpolated coefficients from the original
penalty path.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions from the model with scale determined by <code>type</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+predict">stats::predict()</a></code>, <code><a href="stats.html#topic+predict.glm">stats::predict.glm()</a></code>, <code><a href="#topic+coef.SLOPE">coef.SLOPE()</a></code>
</p>
<p>Other SLOPE-methods: 
<code><a href="#topic+coef.SLOPE">coef.SLOPE</a>()</code>,
<code><a href="#topic+deviance.SLOPE">deviance.SLOPE</a>()</code>,
<code><a href="#topic+plot.SLOPE">plot.SLOPE</a>()</code>,
<code><a href="#topic+print.SLOPE">print.SLOPE</a>()</code>,
<code><a href="#topic+score">score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- with(mtcars, SLOPE(cbind(mpg, hp), vs, family = "binomial"))
predict(fit, with(mtcars, cbind(mpg, hp)), type = "class")
</code></pre>

<hr>
<h2 id='print.SLOPE'>Print results from SLOPE fit</h2><span id='topic+print.SLOPE'></span><span id='topic+print.TrainedSLOPE'></span>

<h3>Description</h3>

<p>Print results from SLOPE fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLOPE'
print(x, ...)

## S3 method for class 'TrainedSLOPE'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.SLOPE_+3A_x">x</code></td>
<td>
<p>an object of class <code>'SLOPE'</code> or <code>'TrainedSLOPE'</code></p>
</td></tr>
<tr><td><code id="print.SLOPE_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code><a href="base.html#topic+print">print()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints output on the screen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLOPE">SLOPE()</a></code>, <code><a href="#topic+print.SLOPE">print.SLOPE()</a></code>
</p>
<p>Other SLOPE-methods: 
<code><a href="#topic+coef.SLOPE">coef.SLOPE</a>()</code>,
<code><a href="#topic+deviance.SLOPE">deviance.SLOPE</a>()</code>,
<code><a href="#topic+plot.SLOPE">plot.SLOPE</a>()</code>,
<code><a href="#topic+predict.SLOPE">predict.SLOPE</a>()</code>,
<code><a href="#topic+score">score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- SLOPE(wine$x, wine$y, family = "multinomial")
print(fit, digits = 1)
</code></pre>

<hr>
<h2 id='regularizationWeights'>Generate Regularization (Penalty) Weights for SLOPE</h2><span id='topic+regularizationWeights'></span>

<h3>Description</h3>

<p>This function generates sequences of regularizations weights for use in
<code><a href="#topic+SLOPE">SLOPE()</a></code> (or elsewhere).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regularizationWeights(
  n_lambda = 100,
  type = c("bh", "gaussian", "oscar", "lasso"),
  q = 0.2,
  theta1 = 1,
  theta2 = 0.5,
  n = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regularizationWeights_+3A_n_lambda">n_lambda</code></td>
<td>
<p>The number of lambdas to generate. This should typically
be equal to the number of predictors in your data set.</p>
</td></tr>
<tr><td><code id="regularizationWeights_+3A_type">type</code></td>
<td>
<p>The type of lambda sequence to use. See documentation for
in <code><a href="#topic+SLOPE">SLOPE()</a></code>, including that related to the <code>lambda</code> parameter in that
function.</p>
</td></tr>
<tr><td><code id="regularizationWeights_+3A_q">q</code></td>
<td>
<p>parameter controlling the shape of the lambda sequence, with
usage varying depending on the type of path used and has no effect
is a custom <code>lambda</code> sequence is used. Must be greater than <code>1e-6</code> and
smaller than 1.</p>
</td></tr>
<tr><td><code id="regularizationWeights_+3A_theta1">theta1</code></td>
<td>
<p>parameter controlling the shape of the lambda sequence
when <code>lambda == "OSCAR"</code>. This parameter basically sets the intercept
for the lambda sequence and is equivalent to <code class="reqn">\lambda_1</code> in the
original OSCAR formulation.</p>
</td></tr>
<tr><td><code id="regularizationWeights_+3A_theta2">theta2</code></td>
<td>
<p>parameter controlling the shape of the lambda sequence
when <code>lambda == "OSCAR"</code>. This parameter basically sets the slope
for the lambda sequence and is equivalent to <code class="reqn">\lambda_2</code> in the
original OSCAR formulation.</p>
</td></tr>
<tr><td><code id="regularizationWeights_+3A_n">n</code></td>
<td>
<p>The number of rows (observations) in the design matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please see <code><a href="#topic+SLOPE">SLOPE()</a></code> for detailed information regarding the parameters in
this function, in particular the section <em>Regularization Sequences</em>.
</p>
<p>Note that these sequences are automatically scaled (unless a value for
the <code>alpha</code> parameter is manually supplied) when using <code><a href="#topic+SLOPE">SLOPE()</a></code>. In this
function, nu such scaling is attempted.
</p>


<h3>Value</h3>

<p>A vector of length <code>n_lambda</code> with regularization weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLOPE">SLOPE()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># compute different penalization sequences
bh &lt;- regularizationWeights(100, q = 0.2, type = "bh")

gaussian &lt;- regularizationWeights(
  100,
  q = 0.2,
  n = 300,
  type = "gaussian"
)

oscar &lt;- regularizationWeights(
  100,
  theta1 = 1.284,
  theta2 = 0.0182,
  type = "oscar"
)

lasso &lt;- regularizationWeights(100, type = "lasso") * mean(oscar)

# Plot a comparison between these sequences
plot(bh, type = "l", ylab = expression(lambda))
lines(gaussian, col = "dark orange")
lines(oscar, col = "navy")
lines(lasso, col = "red3")

legend(
  "topright",
  legend = c("BH", "Gaussian", "OSCAR", "lasso"),
  col = c("black", "dark orange", "navy", "red3"),
  lty = 1
)
</code></pre>

<hr>
<h2 id='score'>Compute one of several loss metrics on a new data set</h2><span id='topic+score'></span><span id='topic+score.GaussianSLOPE'></span><span id='topic+score.BinomialSLOPE'></span><span id='topic+score.MultinomialSLOPE'></span><span id='topic+score.PoissonSLOPE'></span>

<h3>Description</h3>

<p>This function is a unified interface to return various types of loss for a
model fit with <code><a href="#topic+SLOPE">SLOPE()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score(object, x, y, measure)

## S3 method for class 'GaussianSLOPE'
score(object, x, y, measure = c("mse", "mae"))

## S3 method for class 'BinomialSLOPE'
score(object, x, y, measure = c("mse", "mae", "deviance", "misclass", "auc"))

## S3 method for class 'MultinomialSLOPE'
score(object, x, y, measure = c("mse", "mae", "deviance", "misclass"))

## S3 method for class 'PoissonSLOPE'
score(object, x, y, measure = c("mse", "mae"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score_+3A_object">object</code></td>
<td>
<p>an object of class <code>"SLOPE"</code></p>
</td></tr>
<tr><td><code id="score_+3A_x">x</code></td>
<td>
<p>feature matrix</p>
</td></tr>
<tr><td><code id="score_+3A_y">y</code></td>
<td>
<p>response</p>
</td></tr>
<tr><td><code id="score_+3A_measure">measure</code></td>
<td>
<p>type of target measure. <code>"mse"</code> returns mean squared error.
<code>"mae"</code> returns mean absolute error, <code>"misclass"</code> returns
misclassification rate, and <code>"auc"</code> returns area under the ROC curve.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The measure along the regularization path depending on the
value in <code>measure</code>.#'
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLOPE">SLOPE()</a></code>, <code><a href="#topic+predict.SLOPE">predict.SLOPE()</a></code>
</p>
<p>Other SLOPE-methods: 
<code><a href="#topic+coef.SLOPE">coef.SLOPE</a>()</code>,
<code><a href="#topic+deviance.SLOPE">deviance.SLOPE</a>()</code>,
<code><a href="#topic+plot.SLOPE">plot.SLOPE</a>()</code>,
<code><a href="#topic+predict.SLOPE">predict.SLOPE</a>()</code>,
<code><a href="#topic+print.SLOPE">print.SLOPE</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- subset(infert, select = c("induced", "age", "pooled.stratum"))
y &lt;- infert$case

fit &lt;- SLOPE(x, y, family = "binomial")
score(fit, x, y, measure = "auc")
</code></pre>

<hr>
<h2 id='setupDiagnostics'>Setup a data.frame of diagnostics</h2><span id='topic+setupDiagnostics'></span>

<h3>Description</h3>

<p>Setup a data.frame of diagnostics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setupDiagnostics(res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setupDiagnostics_+3A_res">res</code></td>
<td>
<p>the result from calling the C++ routine used to fit a model
in SLOPE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame
</p>

<hr>
<h2 id='SLOPE'>Sorted L-One Penalized Estimation</h2><span id='topic+SLOPE'></span>

<h3>Description</h3>

<p>Fit a generalized linear model regularized with the
sorted L1 norm, which applies a
non-increasing regularization sequence to the
coefficient vector (<code class="reqn">\beta</code>) after having sorted it
in decreasing order according  to its absolute values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLOPE(
  x,
  y,
  family = c("gaussian", "binomial", "multinomial", "poisson"),
  intercept = TRUE,
  center = !inherits(x, "sparseMatrix"),
  scale = c("l2", "l1", "sd", "none"),
  alpha = c("path", "estimate"),
  lambda = c("bh", "gaussian", "oscar", "lasso"),
  alpha_min_ratio = if (NROW(x) &lt; NCOL(x)) 0.01 else 1e-04,
  path_length = if (alpha[1] == "estimate") 1 else 20,
  q = 0.1 * min(1, NROW(x)/NCOL(x)),
  theta1 = 1,
  theta2 = 0.5,
  prox_method = c("stack", "pava"),
  screen = TRUE,
  screen_alg = c("strong", "previous"),
  tol_dev_change = 1e-05,
  tol_dev_ratio = 0.995,
  max_variables = NROW(x),
  solver = c("fista", "admm"),
  max_passes = 1e+06,
  tol_abs = 1e-05,
  tol_rel = 1e-04,
  tol_rel_gap = 1e-05,
  tol_infeas = 0.001,
  tol_rel_coef_change = 0.001,
  diagnostics = FALSE,
  verbosity = 0,
  sigma,
  n_sigma,
  lambda_min_ratio
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SLOPE_+3A_x">x</code></td>
<td>
<p>the design matrix, which can be either a dense
matrix of the standard <em>matrix</em> class, or a sparse matrix
inheriting from <a href="Matrix.html#topic+sparseMatrix">Matrix::sparseMatrix</a>. Data frames will
be converted to matrices internally.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_y">y</code></td>
<td>
<p>the response, which for <code>family = "gaussian"</code> must be numeric; for
<code>family = "binomial"</code> or <code>family = "multinomial"</code>, it can be a factor.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_family">family</code></td>
<td>
<p>model family (objective); see <strong>Families</strong> for details.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_intercept">intercept</code></td>
<td>
<p>whether to fit an intercept</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_center">center</code></td>
<td>
<p>whether to center predictors or not by their mean. Defaults
to <code>TRUE</code> if <code>x</code> is dense and <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_scale">scale</code></td>
<td>
<p>type of scaling to apply to predictors.
</p>

<ul>
<li> <p><code>"l1"</code> scales predictors to have L1 norms of one.
</p>
</li>
<li> <p><code>"l2"</code> scales predictors to have L2 norms of one.#'
</p>
</li>
<li> <p><code>"sd"</code> scales predictors to have a population standard deviation one.
</p>
</li>
<li> <p><code>"none"</code> applies no scaling.
</p>
</li></ul>
</td></tr>
<tr><td><code id="SLOPE_+3A_alpha">alpha</code></td>
<td>
<p>scale for regularization path: either a decreasing numeric
vector (possibly of length 1) or a character vector; in the latter case,
the choices are:
</p>

<ul>
<li> <p><code>"path"</code>, which computes a regularization sequence
where the first value corresponds to the intercept-only (null) model and
the last to the almost-saturated model, and
</p>
</li>
<li> <p><code>"estimate"</code>, which estimates a <em>single</em> <code>alpha</code>
using Algorithm 5 in Bogdan et al. (2015).
</p>
</li></ul>

<p>When a value is manually entered for <code>alpha</code>, it will be scaled based
on the type of standardization that is applied to <code>x</code>. For <code>scale = "l2"</code>,
<code>alpha</code> will be scaled by <code class="reqn">\sqrt n</code>. For <code>scale = "sd"</code> or <code>"none"</code>,
alpha will be scaled by <code class="reqn">n</code>, and for <code>scale = "l1"</code> no scaling is
applied. Note, however, that the <code>alpha</code> that is returned in the
resulting value is the <strong>unstandardized</strong> alpha.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_lambda">lambda</code></td>
<td>
<p>either a character vector indicating the method used
to construct the lambda path or a numeric non-decreasing
vector with length equal to the number
of coefficients in the model; see section <strong>Regularization sequences</strong>
for details.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_alpha_min_ratio">alpha_min_ratio</code></td>
<td>
<p>smallest value for <code>lambda</code> as a fraction of
<code>lambda_max</code>; used in the selection of <code>alpha</code> when <code>alpha = "path"</code>.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_path_length">path_length</code></td>
<td>
<p>length of regularization path; note that the path
returned may still be shorter due to the early termination criteria
given by <code>tol_dev_change</code>, <code>tol_dev_ratio</code>, and <code>max_variables</code>.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_q">q</code></td>
<td>
<p>parameter controlling the shape of the lambda sequence, with
usage varying depending on the type of path used and has no effect
is a custom <code>lambda</code> sequence is used. Must be greater than <code>1e-6</code> and
smaller than 1.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_theta1">theta1</code></td>
<td>
<p>parameter controlling the shape of the lambda sequence
when <code>lambda == "OSCAR"</code>. This parameter basically sets the intercept
for the lambda sequence and is equivalent to <code class="reqn">\lambda_1</code> in the
original OSCAR formulation.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_theta2">theta2</code></td>
<td>
<p>parameter controlling the shape of the lambda sequence
when <code>lambda == "OSCAR"</code>. This parameter basically sets the slope
for the lambda sequence and is equivalent to <code class="reqn">\lambda_2</code> in the
original OSCAR formulation.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_prox_method">prox_method</code></td>
<td>
<p>method for calculating the proximal operator for
the Sorted L1 Norm (the SLOPE penalty). Please see <code><a href="#topic+sortedL1Prox">sortedL1Prox()</a></code> for
more information.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_screen">screen</code></td>
<td>
<p>whether to use predictor screening rules (rules that allow
some predictors to be discarded prior to fitting), which improve speed
greatly when the number of predictors is larger than the number
of observations.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_screen_alg">screen_alg</code></td>
<td>
<p>what type of screening algorithm to use.
</p>

<ul>
<li> <p><code>"strong"</code> uses the set from the strong screening rule and check
against the full set
</p>
</li>
<li> <p><code>"previous"</code> first fits with the previous active set, then checks
against the strong set, and finally against the full set if there are
no violations in the strong set
</p>
</li></ul>
</td></tr>
<tr><td><code id="SLOPE_+3A_tol_dev_change">tol_dev_change</code></td>
<td>
<p>the regularization path is stopped if the
fractional change in deviance falls below this value; note that this is
automatically set to 0 if a alpha is manually entered</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_tol_dev_ratio">tol_dev_ratio</code></td>
<td>
<p>the regularization path is stopped if the
deviance ratio <code class="reqn">1 - \mathrm{deviance}/\mathrm{(null-deviance)}
  </code> is above this threshold</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_max_variables">max_variables</code></td>
<td>
<p>criterion for stopping the path in terms of the
maximum number of unique, nonzero coefficients in absolute value in model.
For the multinomial family, this value will be multiplied internally with
the number of levels of the response minus one.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_solver">solver</code></td>
<td>
<p>type of solver use, either <code>"fista"</code> or <code>"admm"</code>;
all families currently support FISTA but only <code>family = "gaussian"</code>
supports ADMM.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_max_passes">max_passes</code></td>
<td>
<p>maximum number of passes (outer iterations) for solver</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_tol_abs">tol_abs</code></td>
<td>
<p>absolute tolerance criterion for ADMM solver</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_tol_rel">tol_rel</code></td>
<td>
<p>relative tolerance criterion for ADMM solver</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_tol_rel_gap">tol_rel_gap</code></td>
<td>
<p>stopping criterion for the duality gap; used only with
FISTA solver.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_tol_infeas">tol_infeas</code></td>
<td>
<p>stopping criterion for the level of infeasibility; used
with FISTA solver and KKT checks in screening algorithm.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_tol_rel_coef_change">tol_rel_coef_change</code></td>
<td>
<p>relative tolerance criterion for change
in coefficients between iterations, which is reached when
the maximum absolute change in any coefficient divided by the maximum
absolute coefficient size is less than this value.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_diagnostics">diagnostics</code></td>
<td>
<p>whether to save diagnostics from the solver
(timings and other values depending on type of solver)</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_verbosity">verbosity</code></td>
<td>
<p>level of verbosity for displaying output from the
program. Setting this to 1 displays basic information on the path level,
2 a little bit more information on the path level, and 3 displays
information from the solver.</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_sigma">sigma</code></td>
<td>
<p>deprecated; please use <code>alpha</code> instead</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_n_sigma">n_sigma</code></td>
<td>
<p>deprecated; please use <code>path_length</code> instead</p>
</td></tr>
<tr><td><code id="SLOPE_+3A_lambda_min_ratio">lambda_min_ratio</code></td>
<td>
<p>deprecated; please use <code>alpha_min_ratio</code> instead</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SLOPE()</code> solves the convex minimization problem
</p>
<p style="text-align: center;"><code class="reqn">
  f(\beta) + \alpha \sum_{i=j}^p \lambda_j |\beta|_{(j)},
</code>
</p>

<p>where <code class="reqn">f(\beta)</code> is a smooth and convex function and
the second part is the sorted L1-norm.
In ordinary least-squares regression,
<code class="reqn">f(\beta)</code> is simply the squared norm of the least-squares residuals.
See section <strong>Families</strong> for specifics regarding the various types of
<code class="reqn">f(\beta)</code> (model families) that are allowed in <code>SLOPE()</code>.
</p>
<p>By default, <code>SLOPE()</code> fits a path of models, each corresponding to
a separate regularization sequence, starting from
the null (intercept-only) model to an almost completely unregularized
model. These regularization sequences are parameterized using
<code class="reqn">\lambda</code> and <code class="reqn">\alpha</code>, with only <code class="reqn">\alpha</code> varying along the
path. The length of the path can be manually, but will terminate
prematurely depending on
arguments <code>tol_dev_change</code>, <code>tol_dev_ratio</code>, and <code>max_variables</code>.
This means that unless these arguments are modified, the path is not
guaranteed to be of length <code>path_length</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"SLOPE"</code> with the following slots:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>

<p>a three-dimensional array of the coefficients from the
model fit, including the intercept if it was fit.
There is one row for each coefficient, one column
for each target (dependent variable), and
one slice for each penalty.
</p>
</td></tr>
<tr><td><code>nonzeros</code></td>
<td>

<p>a three-dimensional logical array indicating whether a
coefficient was zero or not
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>the lambda vector that when multiplied by a value in <code>alpha</code>
gives the penalty vector at that point along the regularization
path
</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>

<p>vector giving the (unstandardized) scaling of the lambda sequence
</p>
</td></tr>
<tr><td><code>class_names</code></td>
<td>

<p>a character vector giving the names of the classes for binomial and
multinomial families
</p>
</td></tr>
<tr><td><code>passes</code></td>
<td>
<p>the number of passes the solver took at each step on the path</p>
</td></tr>
<tr><td><code>violations</code></td>
<td>

<p>the number of violations of the screening rule at each step on the path;
only available if <code>diagnostics = TRUE</code> in the call to <code><a href="#topic+SLOPE">SLOPE()</a></code>.
</p>
</td></tr>
<tr><td><code>active_sets</code></td>
<td>

<p>a list where each element indicates the indices of the
coefficients that were active at that point in the regularization path
</p>
</td></tr>
<tr><td><code>unique</code></td>
<td>

<p>the number of unique predictors (in absolute value)
</p>
</td></tr>
<tr><td><code>deviance_ratio</code></td>
<td>

<p>the deviance ratio (as a fraction of 1)
</p>
</td></tr>
<tr><td><code>null_deviance</code></td>
<td>

<p>the deviance of the null (intercept-only) model
</p>
</td></tr>
<tr><td><code>family</code></td>
<td>

<p>the name of the family used in the model fit
</p>
</td></tr>
<tr><td><code>diagnostics</code></td>
<td>

<p>a <code>data.frame</code> of objective values for the primal and dual problems, as
well as a measure of the infeasibility, time, and iteration; only
available if <code>diagnostics = TRUE</code> in the call to <code><a href="#topic+SLOPE">SLOPE()</a></code>.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call used for fitting the model</p>
</td></tr>
</table>


<h3>Families</h3>

<p><strong>Gaussian</strong>
</p>
<p>The Gaussian model (Ordinary Least Squares) minimizes the following
objective:
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{2} \Vert y - X\beta\Vert_2^2
</code>
</p>

<p><strong>Binomial</strong>
</p>
<p>The binomial model (logistic regression) has the following objective:
</p>
<p style="text-align: center;"><code class="reqn">
  \sum_{i=1}^n \log\left(1+ \exp\left(
    - y_i \left(x_i^T\beta + \beta_0 \right) \right) \right)
</code>
</p>

<p>with <code class="reqn">y \in \{-1, 1\}</code>.
</p>
<p><strong>Poisson</strong>
</p>
<p>In poisson regression, we use the following objective:
</p>
<p style="text-align: center;"><code class="reqn">
  -\sum_{i=1}^n \left(y_i\left(
    x_i^T\beta + \beta_0\right) - \exp\left(x_i^T\beta + \beta_0
  \right)\right)
</code>
</p>

<p><strong>Multinomial</strong>
</p>
<p>In multinomial regression, we minimize the full-rank objective
</p>
<p style="text-align: center;"><code class="reqn">
  -\sum_{i=1}^n\left(
    \sum_{k=1}^{m-1} y_{ik}(x_i^T\beta_k + \beta_{0,k})
    - \log\sum_{k=1}^{m-1} \exp\big(x_i^T\beta_k + \beta_{0,k}\big)
  \right)
</code>
</p>

<p>with <code class="reqn">y_{ik}</code> being the element in a <code class="reqn">n</code> by <code class="reqn">(m-1)</code> matrix, where
<code class="reqn">m</code> is the number of classes in the response.
</p>


<h3>Regularization Sequences</h3>

<p>There are multiple ways of specifying the <code>lambda</code> sequence
in <code>SLOPE()</code>. It is, first of all, possible to select the sequence manually
by
using a non-increasing
numeric vector, possibly of length one, as argument instead of a character.
The greater the differences are between
consecutive values along the sequence, the more clustering behavior
will the model exhibit. Note, also, that the scale of the <code class="reqn">\lambda</code>
vector makes no difference if <code>alpha = NULL</code>, since <code>alpha</code> will be
selected automatically to ensure that the model is completely sparse at the
beginning and almost unregularized at the end. If, however, both
<code>alpha</code> and <code>lambda</code> are manually specified, then the scales of both do
matter, so make sure to choose them wisely.
</p>
<p>Instead of choosing the sequence manually, one of the following
automatically generated sequences may be chosen.
</p>
<p><strong>BH (Benjamini&ndash;Hochberg)</strong>
</p>
<p>If <code>lambda = "bh"</code>, the sequence used is that referred to
as <code class="reqn">\lambda^{(\mathrm{BH})}</code> by Bogdan et al, which sets
<code class="reqn">\lambda</code> according to
</p>
<p style="text-align: center;"><code class="reqn">
  \lambda_i = \Phi^{-1}(1 - iq/(2p)),
</code>
</p>

<p>for <code class="reqn">i=1,\dots,p</code>, where <code class="reqn">\Phi^{-1}</code> is the quantile
function for the standard normal distribution and <code class="reqn">q</code> is a parameter
that can be set by the user in the call to <code>SLOPE()</code>.
</p>
<p><strong>Gaussian</strong>
</p>
<p>This penalty sequence is related to BH, such that
</p>
<p style="text-align: center;"><code class="reqn">
  \lambda_i = \lambda^{(\mathrm{BH})}_i
  \sqrt{1 + w(i-1)\cdot \mathrm{cumsum}(\lambda^2)_i},
</code>
</p>

<p>for <code class="reqn">i=1,\dots,p</code>, where <code class="reqn">w(k) = 1/(n-k-1)</code>. We let
<code class="reqn">\lambda_1 = \lambda^{(\mathrm{BH})}_1</code> and
adjust the sequence to make sure that it's non-increasing.
Note that if <code class="reqn">p</code> is large relative
to <code class="reqn">n</code>, this option will result in a constant sequence, which is
usually not what you would want.
</p>
<p><strong>OSCAR</strong>
</p>
<p>This sequence comes from Bondell and Reich and is a linear non-increasing
sequence, such that
</p>
<p style="text-align: center;"><code class="reqn">
  \lambda_i = \theta_1 + (p - i)\theta_2.
</code>
</p>

<p>for <code class="reqn">i = 1,\dots,p</code>. We use the parametrization from Zhong and Kwok
(2021) but use <code class="reqn">\theta_1</code> and <code class="reqn">\theta_2</code> instead of <code class="reqn">\lambda_1</code>
and <code class="reqn">\lambda_2</code> to avoid confusion and abuse of notation.
</p>
<p><strong>lasso</strong>
</p>
<p>SLOPE is exactly equivalent to the
lasso when the sequence of regularization weights is constant, i.e.
</p>
<p style="text-align: center;"><code class="reqn">
  \lambda_i = 1
</code>
</p>

<p>for <code class="reqn">i = 1,\dots,p</code>. Here, again, we stress that the fact that
all <code class="reqn">\lambda</code> are equal to one does not matter as long as
<code>alpha == NULL</code> since we scale the vector automatically.
Note that this option is only here for academic interest and
to highlight the fact that SLOPE is
a generalization of the lasso. There are more efficient packages, such as
<strong>glmnet</strong> and <strong>biglasso</strong>, for fitting the lasso.
</p>


<h3>Solvers</h3>

<p>There are currently two solvers available for SLOPE: FISTA (Beck and
Teboulle 2009) and ADMM (Boyd et al. 2008). FISTA is available for
families but ADMM is currently only available for <code>family = "gaussian"</code>.
</p>


<h3>References</h3>

<p>Bogdan, M., van den Berg, E., Sabatti, C., Su, W., &amp; Cand√®s, E. J. (2015).
SLOPE &ndash; adaptive variable selection via convex optimization. The Annals of
Applied Statistics, 9(3), 1103‚Äì1140. doi: <a href="https://doi.org/10/gfgwzt">10/gfgwzt</a>
</p>
<p>Bondell, H. D., &amp; Reich, B. J. (2008). Simultaneous Regression Shrinkage,
Variable Selection, and Supervised Clustering of Predictors with OSCAR.
Biometrics, 64(1), 115‚Äì123. JSTOR.
doi: <a href="https://doi.org/10.1111/j.1541-0420.2007.00843.x">10.1111/j.1541-0420.2007.00843.x</a>
</p>
<p>Boyd, S., Parikh, N., Chu, E., Peleato, B., &amp; Eckstein, J. (2010).
Distributed Optimization and Statistical Learning via the Alternating
Direction Method of Multipliers. Foundations and Trends¬Æ in Machine Learning,
3(1), 1‚Äì122. doi: <a href="https://doi.org/10.1561/2200000016">10.1561/2200000016</a>
</p>
<p>Beck, A., &amp; Teboulle, M. (2009). A Fast Iterative Shrinkage-Thresholding
Algorithm for Linear Inverse Problems. SIAM Journal on Imaging Sciences,
2(1), 183‚Äì202. doi: <a href="https://doi.org/10.1137/080716542">10.1137/080716542</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.SLOPE">plot.SLOPE()</a></code>, <code><a href="#topic+plotDiagnostics">plotDiagnostics()</a></code>, <code><a href="#topic+score">score()</a></code>, <code><a href="#topic+predict.SLOPE">predict.SLOPE()</a></code>,
<code><a href="#topic+trainSLOPE">trainSLOPE()</a></code>, <code><a href="#topic+coef.SLOPE">coef.SLOPE()</a></code>, <code><a href="#topic+print.SLOPE">print.SLOPE()</a></code>, <code><a href="#topic+print.SLOPE">print.SLOPE()</a></code>,
<code><a href="#topic+deviance.SLOPE">deviance.SLOPE()</a></code>, <code><a href="#topic+sortedL1Prox">sortedL1Prox()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Gaussian response, default lambda sequence
fit &lt;- SLOPE(bodyfat$x, bodyfat$y)

# Poisson response, OSCAR-type lambda sequence
fit &lt;- SLOPE(
  abalone$x,
  abalone$y,
  family = "poisson",
  lambda = "oscar",
  theta1 = 1,
  theta2 = 0.9
)

# Multinomial response, custom alpha and lambda
m &lt;- length(unique(wine$y)) - 1
p &lt;- ncol(wine$x)

alpha &lt;- 0.005
lambda &lt;- exp(seq(log(2), log(1.8), length.out = p * m))

fit &lt;- SLOPE(
  wine$x,
  wine$y,
  family = "multinomial",
  lambda = lambda,
  alpha = alpha
)
</code></pre>

<hr>
<h2 id='SLOPE-package'>SLOPE: Sorted L1 Penalized Estimation</h2><span id='topic+SLOPE-package'></span><span id='topic+_PACKAGE'></span>

<h3>Description</h3>

<p>Efficient implementations for Sorted L-One Penalized Estimation (SLOPE): generalized linear models regularized with the sorted L1-norm (Bogdan et al. (2015) &lt;doi:10/gfgwzt&gt;). Supported models include ordinary least-squares regression, binomial regression, multinomial regression, and Poisson regression. Both dense and sparse predictor matrices are supported. In addition, the package features predictor screening rules that enable fast and efficient solutions to high-dimensional problems.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Johan Larsson <a href="mailto:johan.larsson@stat.lu.se">johan.larsson@stat.lu.se</a> (<a href="https://orcid.org/0000-0002-4029-5945">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Jonas Wallin <a href="mailto:jonas.wallin@stat.lu.se">jonas.wallin@stat.lu.se</a> (<a href="https://orcid.org/0000-0003-0381-6593">ORCID</a>)
</p>
</li>
<li><p> Malgorzata Bogdan
</p>
</li>
<li><p> Ewout van den Berg
</p>
</li>
<li><p> Chiara Sabatti
</p>
</li>
<li><p> Emmanuel Candes
</p>
</li>
<li><p> Evan Patterson
</p>
</li>
<li><p> Weijie Su
</p>
</li>
<li><p> Jakub Ka≈Ça
</p>
</li>
<li><p> Krystyna Grzesiak
</p>
</li>
<li><p> Michal Burdukiewicz (<a href="https://orcid.org/0000-0001-8926-582X">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Jerome Friedman (code adapted from 'glmnet') [contributor]
</p>
</li>
<li><p> Trevor Hastie (code adapted from 'glmnet') [contributor]
</p>
</li>
<li><p> Rob Tibshirani (code adapted from 'glmnet') [contributor]
</p>
</li>
<li><p> Balasubramanian Narasimhan (code adapted from 'glmnet') [contributor]
</p>
</li>
<li><p> Noah Simon (code adapted from 'glmnet') [contributor]
</p>
</li>
<li><p> Junyang Qian (code adapted from 'glmnet') [contributor]
</p>
</li>
<li><p> Akarsh Goyal [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://jolars.github.io/SLOPE/">https://jolars.github.io/SLOPE/</a>
</p>
</li>
<li> <p><a href="https://github.com/jolars/SLOPE">https://github.com/jolars/SLOPE</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/jolars/SLOPE/issues">https://github.com/jolars/SLOPE/issues</a>
</p>
</li></ul>


<hr>
<h2 id='sortedL1Prox'>Sorted L1 Proximal Operator</h2><span id='topic+sortedL1Prox'></span>

<h3>Description</h3>

<p>The proximal operator for the Sorted L1 Norm, which is the penalty function
in SLOPE. It solves the problem
</p>
<p style="text-align: center;"><code class="reqn">
  \arg\,\min_x
    \Big(J(x, \lambda) + \frac{1}{2} ||x - v||_2^2\Big)
</code>
</p>

<p>where <code class="reqn">J(x, \lambda)</code> is the Sorted L1 Norm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sortedL1Prox(x, lambda, method = c("stack", "pava"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sortedL1Prox_+3A_x">x</code></td>
<td>
<p>A vector. In SLOPE, this is the vector of coefficients.</p>
</td></tr>
<tr><td><code id="sortedL1Prox_+3A_lambda">lambda</code></td>
<td>
<p>A non-negative and decreasing sequence
of weights for the Sorted L1 Norm. Needs to be the same length as
<code>x</code>.</p>
</td></tr>
<tr><td><code id="sortedL1Prox_+3A_method">method</code></td>
<td>
<p>Method used in the prox. <code>"stack"</code> is a stack-based algorithm
(Algorithm 4 in Bogdan et al.). <code>"pava"</code> is the PAVA algorithm used
in isotonic regression (also Algorithm 3 in Bogdan et al.).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An evaluation of the proximal operator at <code>x</code> and <code>lambda</code>.
</p>


<h3>Source</h3>

<p>M. Bogdan, E. van den Berg, Chiara Sabatti, Weijie Su, and Emmanuel J.
Cand√®s, ‚ÄúSLOPE ‚Äì adaptive variable selection via convex optimization,‚Äù Ann
Appl Stat, vol. 9, no. 3, pp. 1103‚Äì1140, 2015, doi: 10.1214/15-AOAS842.
</p>

<hr>
<h2 id='student'>Student performance</h2><span id='topic+student'></span>

<h3>Description</h3>

<p>A data set of the attributes of 382 students in secondary education
collected from two schools. The goal is to predict the
grade in math and Portugese at the end of the third period. See the
cited sources for additional information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>student
</code></pre>


<h3>Format</h3>

<p>382 observations from 13 variables represented as a list consisting
of a binary factor response matrix <code>y</code> with two responses: <code>portugese</code> and
<code>math</code> for the final scores in period three for the respective subjects.
The list also contains <code>x</code>: a sparse feature matrix of class
'dgCMatrix' with the following variables:
</p>

<dl>
<dt>school_ms</dt><dd><p>student's primary school, 1 for Mousinho da Silveira and 0
for Gabriel Pereira</p>
</dd>
<dt>sex</dt><dd><p>sex of student, 1 for male</p>
</dd>
<dt>age</dt><dd><p>age of student</p>
</dd>
<dt>urban</dt><dd><p>urban (1) or rural (0) home address</p>
</dd>
<dt>large_family</dt><dd><p>whether the family size is larger than 3</p>
</dd>
<dt>cohabitation</dt><dd><p>whether parents live together</p>
</dd>
<dt>Medu</dt><dd><p>mother's level of education (ordered)</p>
</dd>
<dt>Fedu</dt><dd><p>fathers's level of education (ordered)</p>
</dd>
<dt>Mjob_health</dt><dd><p>whether the mother was employed in health care</p>
</dd>
<dt>Mjob_other</dt><dd><p>whether the mother was employed as something other than
the specified job roles</p>
</dd>
<dt>Mjob_services</dt><dd><p>whether the mother was employed in the service sector</p>
</dd>
<dt>Mjob_teacher</dt><dd><p>whether the mother was employed as a teacher</p>
</dd>
<dt>Fjob_health</dt><dd><p>whether the father was employed in health care</p>
</dd>
<dt>Fjob_other</dt><dd><p>whether the father was employed as something other than
the specified job roles</p>
</dd>
<dt>Fjob_services</dt><dd><p>whether the father was employed in the service sector</p>
</dd>
<dt>Fjob_teacher</dt><dd><p>whether the father was employed as a teacher</p>
</dd>
<dt>reason_home</dt><dd><p>school chosen for being close to home</p>
</dd>
<dt>reason_other</dt><dd><p>school chosen for another reason</p>
</dd>
<dt>reason_rep</dt><dd><p>school chosen for its reputation</p>
</dd>
<dt>nursery</dt><dd><p>whether the student attended nursery school</p>
</dd>
<dt>internet</dt><dd><p>Pwhether the student has internet access at home</p>
</dd>
</dl>



<h3>Preprocessing</h3>

<p>All of the grade-specific predictors were dropped from the data set.
(Note that it is not clear from the source why some of these predictors are
specific to each grade, such as which parent is the student's guardian.)
The categorical variables were dummy-coded. Only the final grades (G3)
were kept as dependent variables, whilst the
first and second period grades were dropped.
</p>


<h3>Source</h3>

<p>P. Cortez and A. Silva. Using Data Mining to Predict Secondary School
Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th
FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto,
Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.
<a href="http://www3.dsi.uminho.pt/pcortez/student.pdf">http://www3.dsi.uminho.pt/pcortez/student.pdf</a>
</p>
<p>Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository
<a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>. Irvine, CA: University of California,
School of Information and Computer Science.
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+abalone">abalone</a></code>,
<code><a href="#topic+bodyfat">bodyfat</a></code>,
<code><a href="#topic+heart">heart</a></code>,
<code><a href="#topic+wine">wine</a></code>
</p>

<hr>
<h2 id='trainSLOPE'>Train a SLOPE model</h2><span id='topic+trainSLOPE'></span>

<h3>Description</h3>

<p>This function trains a model fit by <code><a href="#topic+SLOPE">SLOPE()</a></code> by tuning its parameters
through cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trainSLOPE(
  x,
  y,
  q = 0.2,
  number = 10,
  repeats = 1,
  measure = c("mse", "mae", "deviance", "misclass", "auc"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trainSLOPE_+3A_x">x</code></td>
<td>
<p>the design matrix, which can be either a dense
matrix of the standard <em>matrix</em> class, or a sparse matrix
inheriting from <a href="Matrix.html#topic+sparseMatrix">Matrix::sparseMatrix</a>. Data frames will
be converted to matrices internally.</p>
</td></tr>
<tr><td><code id="trainSLOPE_+3A_y">y</code></td>
<td>
<p>the response, which for <code>family = "gaussian"</code> must be numeric; for
<code>family = "binomial"</code> or <code>family = "multinomial"</code>, it can be a factor.</p>
</td></tr>
<tr><td><code id="trainSLOPE_+3A_q">q</code></td>
<td>
<p>parameter controlling the shape of the lambda sequence, with
usage varying depending on the type of path used and has no effect
is a custom <code>lambda</code> sequence is used. Must be greater than <code>1e-6</code> and
smaller than 1.</p>
</td></tr>
<tr><td><code id="trainSLOPE_+3A_number">number</code></td>
<td>
<p>number of folds (cross-validation)</p>
</td></tr>
<tr><td><code id="trainSLOPE_+3A_repeats">repeats</code></td>
<td>
<p>number of repeats for each fold (for repeated <em>k</em>-fold cross
validation)</p>
</td></tr>
<tr><td><code id="trainSLOPE_+3A_measure">measure</code></td>
<td>
<p>measure to try to optimize; note that you may
supply <em>multiple</em> values here and that, by default,
all the possible measures for the given model will be used.</p>
</td></tr>
<tr><td><code id="trainSLOPE_+3A_...">...</code></td>
<td>
<p>other arguments to pass on to <code><a href="#topic+SLOPE">SLOPE()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that by default this method matches all of the available metrics
for the given model family against those provided in the argument
<code>measure</code>. Collecting these measures is not particularly demanding
computationally so it is almost always best to leave this argument
as it is and then choose which argument to focus on in the call
to <code><a href="#topic+plot.TrainedSLOPE">plot.TrainedSLOPE()</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"TrainedSLOPE"</code>, with the following slots:
</p>
<table>
<tr><td><code>summary</code></td>
<td>
<p>a summary of the results with means, standard errors,
and 0.95 confidence levels</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the raw data from the model training</p>
</td></tr>
<tr><td><code>optima</code></td>
<td>
<p>a <code>data.frame</code> of the best (mean)
values for the different metrics and their corresponding parameter values</p>
</td></tr>
<tr><td><code>measure</code></td>
<td>
<p>a <code>data.frame</code> listing the used metrics and their labels</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the model fit to the entire data set</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call</p>
</td></tr>
</table>


<h3>Parallel operation</h3>

<p>This function uses the <strong>foreach</strong> package to enable parallel
operation. To enable this, simply register a parallel backend
using, for instance, <code>doParallel::registerDoParallel()</code> from the
<strong>doParallel</strong> package before running this function.
</p>


<h3>See Also</h3>

<p><code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code>, <code><a href="#topic+plot.TrainedSLOPE">plot.TrainedSLOPE()</a></code>
</p>
<p>Other model-tuning: 
<code><a href="#topic+caretSLOPE">caretSLOPE</a>()</code>,
<code><a href="#topic+plot.TrainedSLOPE">plot.TrainedSLOPE</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 8-fold cross-validation repeated 5 times
tune &lt;- trainSLOPE(subset(mtcars, select = c("mpg", "drat", "wt")),
  mtcars$hp,
  q = c(0.1, 0.2),
  number = 8,
  repeats = 5,
  measure = "mse"
)
</code></pre>

<hr>
<h2 id='wine'>Wine cultivars</h2><span id='topic+wine'></span>

<h3>Description</h3>

<p>A data set of results from chemical analysis of wines grown in Italy
from three different cultivars.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wine
</code></pre>


<h3>Format</h3>

<p>178 observations from 13 variables represented as a list consisting
of a categorical response vector <code>y</code>
with three levels: <em>A</em>, <em>B</em>, and <em>C</em> representing different
cultivars of wine as well as <code>x</code>: a sparse feature matrix of class
'dgCMatrix' with the following variables:
</p>

<dl>
<dt>alcohol</dt><dd><p>alcoholic content</p>
</dd>
<dt>malic</dt><dd><p>malic acid</p>
</dd>
<dt>ash</dt><dd><p>ash</p>
</dd>
<dt>alcalinity</dt><dd><p>alcalinity of ash</p>
</dd>
<dt>magnesium</dt><dd><p>magnemium</p>
</dd>
<dt>phenols</dt><dd><p>total phenols</p>
</dd>
<dt>flavanoids</dt><dd><p>flavanoids</p>
</dd>
<dt>nonflavanoids</dt><dd><p>nonflavanoid phenols</p>
</dd>
<dt>proanthocyanins</dt><dd><p>proanthocyanins</p>
</dd>
<dt>color</dt><dd><p>color intensity</p>
</dd>
<dt>hue</dt><dd><p>hue</p>
</dd>
<dt>dilution</dt><dd><p>OD280/OD315 of diluted wines</p>
</dd>
<dt>proline</dt><dd><p>proline</p>
</dd>
</dl>



<h3>Source</h3>

<p>Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository
<a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>. Irvine, CA: University of California,
School of Information and Computer Science.
</p>
<p><a href="https://raw.githubusercontent.com/hadley/rminds/master/1-data/wine.csv">https://raw.githubusercontent.com/hadley/rminds/master/1-data/wine.csv</a>
</p>
<p><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#wine">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#wine</a>
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+abalone">abalone</a></code>,
<code><a href="#topic+bodyfat">bodyfat</a></code>,
<code><a href="#topic+heart">heart</a></code>,
<code><a href="#topic+student">student</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
