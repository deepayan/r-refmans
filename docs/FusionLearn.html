<!DOCTYPE html><html><head><title>Help for package FusionLearn</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FusionLearn}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#fusionbase'>
<p>Fusion learning method for continuous responses</p></a></li>
<li><a href='#fusionbinary'>
<p>Fusion learning algorithm for binary responses</p></a></li>
<li><a href='#FusionLearn-package'>
<p>Fusion Learning</p></a></li>
<li><a href='#fusionmixed'>
<p>Fusion learning algorithm for mixed data</p></a></li>
<li><a href='#mockgene'>
<p>Mock Gene Data</p></a></li>
<li><a href='#stockindex'>
<p>Finance Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fusion Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Xin Gao, Yuan Zhong, and Raymond J. Carroll 	      </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yuan Zhong &lt;aqua.zhong@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The fusion learning method uses a model selection algorithm to learn from multiple data sets across different experimental platforms through group penalization. The responses of interest may include a mix of discrete and continuous variables. The responses may share the same set of predictors, however, the models and parameters differ across different platforms. Integrating information from different data sets can enhance the power of model selection. Package is based on Xin Gao, Raymond J. Carroll (2017) &lt;<a href="https://arxiv.org/abs/1610.00667v1">arXiv:1610.00667v1</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, MASS, ggplot2, mvtnorm</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-24 21:57:20 UTC; adamzhong</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-24 22:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='fusionbase'>
Fusion learning method for continuous responses
</h2><span id='topic+fusionbase'></span><span id='topic+fusionbase.fit'></span>

<h3>Description</h3>

<p><code>fusionbase</code> conducts the group penalization to multiple linear models with a specified penalty value. <code>fusionbase.fit</code> can be used to search the best candidate model based on the pseudo Bayesian information criterion with a sequence of penalty values. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fusionbase(x, y, lambda, N, p, m, beta=0.1, thresh=0.05, 
           maxiter=30, methods="scad",Complete=TRUE)

fusionbase.fit(x, y, lambda, N, p, m, beta=0.1, thresh=0.05, 
               maxiter=30, methods="scad", Complete=TRUE, depen ="IND", a=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fusionbase_+3A_x">x</code></td>
<td>

<p>List. Listing matrices of the predictors from different platforms. 
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_y">y</code></td>
<td>

<p>List. A list of continuous responses vectors from different platforms following the same order as in <code>x</code>.
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_lambda">lambda</code></td>
<td>

<p>Numeric or vector. For <code>fusionbase</code>, lambda is a numeric value for the penalty; for <code>fusionbase.fit</code>, lambda is a vector with a list of penalty values. 
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_n">N</code></td>
<td>

<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each data set. If a vector is provided, then the elements are the sample sizes for all the platforms.
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_p">p</code></td>
<td>

<p>Numeric. The number of predictors.
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_m">m</code></td>
<td>

<p>Numeric. The number of platforms.
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_beta">beta</code></td>
<td>

<p>Numeric or Matrix. An initial value for the estimated parameters with dimensions nvars x nplatforms. The defaul value is 0.1.
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_thresh">thresh</code></td>
<td>

<p>Numeric. The stopping criteria. The default value is 0.05.  
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_maxiter">maxiter</code></td>
<td>

<p>Numeric. Maximum number of iterations. The default value is 30.
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_methods">methods</code></td>
<td>

<p>Character (&quot;lass&quot; or &quot;scad&quot;). <code>lass</code>: LASSO; <code>scad</code>: SCAD.
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_complete">Complete</code></td>
<td>

<p>Logic input. If <code>Complete == TRUE</code>, the predictors <code class="reqn">M_1</code>,...,<code class="reqn">M_p</code> are measured in all platforms. If <code>Compelte == FALSE</code>, in some platforms, not all of the predictors <code class="reqn">\{M_1,M_2,...,M_p\}</code> are measured. The values of the corresponding estimated coefficients for the missing predictors will be <code>NA</code>.
</p>
</td></tr>  
<tr><td><code id="fusionbase_+3A_depen">depen</code></td>
<td>

<p>Character. Input only for function <code>fusionbase.fit</code>. &quot;IND&quot; means the observations across different platforms are independent; &quot;CORR&quot; means the observations are correlated, and the sample sizes should be equal for different platforms. 
</p>
</td></tr>
<tr><td><code id="fusionbase_+3A_a">a</code></td>
<td>

<p>Numeric. Input only for function <code>fusionbase.fit</code>. The free multiplicative constant used in <code class="reqn">\gamma_n</code>. The default value is 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basic fusion learning function to learn from multiple linear models with continuous responses. More details regarding the model assumptions and the algorithm can be found in <code><a href="#topic+FusionLearn">FusionLearn</a></code>.
</p>


<h3>Value</h3>

<p><code>fusionbase</code> returns a list that has components:
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>A matrix (nvars x nplatforms) containing estimated coefficients of each linear model. If some data sets do not have the complete set of predictors, the corresponding coefficients are output as <code>NA</code>.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>Penalty function LASSO or SCAD.
</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>

<p>The numeric value shows the difference in the estimates between the successive updates upon convergence. 
</p>
</td></tr>
<tr><td><code>iteration</code></td>
<td>

<p>The numeric value shows the number of iterations upon convergence.
</p>
</td></tr>
</table>
<p><code>fusionbase.fit</code> provides the results in a table:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>

<p>The sequence of penalty values.
</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>

<p>The pseudolikelihood Bayesian information criterion evaluated at the sequence of the penalty values.
</p>
</td></tr>
<tr><td><code>-2Loglkh</code></td>
<td>

<p>Minus twice the pseudo loglikelihood of the chosen model.
</p>
</td></tr>
<tr><td><code>Est_df</code></td>
<td>

<p>The estimated degrees of freedom quantifying the model complexity.
</p>
</td></tr>
</table>
<p><code>fusionbase.fit</code> also returns a model selection plot showing the results above. 
</p>


<h3>Note</h3>

<p>The range of the penalty values should be carefully chosen. For some penalty values, the resulting models may have singular information matrix or the fitting of the glm cannot converge.
</p>


<h3>Author(s)</h3>

<p>Xin Gao, Yuan Zhong, and Raymond J. Carroll
</p>


<h3>References</h3>

<p>Gao, X and Carroll, R. J. (2017) Data integration with high dimensionality. Biometrika, 104, 2, pp. 251-272
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##analysis of the stock index data
#Responses contain indices "VIX","GSPC", and "DJI" 
y &lt;- list(stockindexVIX[,1],stockindexGSPC[,1],stockindexDJI[,1]) 

#Predictors include 46 stocks
x &lt;- list(stockindexVIX[,2:47],stockindexGSPC[,2:47],stockindexDJI[,2:47])  

##Implementing the model selection algorithm based on the psuedolikelihood 
##information criteria  
model &lt;- fusionbase.fit(x,y,seq(0.03,5,length.out = 10),232,46,3,depen="CORR")
lambda &lt;- model[which.min(model[,2]),1]
result &lt;- fusionbase(x,y,lambda,232,46,3)

##Identify the significant predictors for the three indices
id &lt;- which(result$beta[,1]!=0)+1
colnames(stockindexVIX)[id]
</code></pre>

<hr>
<h2 id='fusionbinary'>
Fusion learning algorithm for binary responses
</h2><span id='topic+fusionbinary'></span><span id='topic+fusionbinary.fit'></span>

<h3>Description</h3>

<p><code>fusionbinary</code> conducts the group penalization with a specified penalty value learning from multiple generalized linear models with binary responses. <code>fusionbinary.fit</code> can be used to search the best candidate model based on the pseudo Bayesian information criterion with a sequence of penalty values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fusionbinary(x, y, lambda, N, p, m, beta=0.1, thresh=0.1, 
             maxiter=100, methods="scad", link="logit", Complete=TRUE)

fusionbinary.fit(x, y, lambda, N, p, m, beta=0.1, thresh=0.1, 
                 maxiter=100, methods="scad", link="logit", Complete=TRUE, 
                 depen ="IND", a=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fusionbinary_+3A_x">x</code></td>
<td>

<p>List. Listing matrices of the predictors from different platforms. 
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_y">y</code></td>
<td>

<p>List. A list of binary responses vectors from different platforms following the same order as in <code>x</code>.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_lambda">lambda</code></td>
<td>

<p>Numeric or vector. For <code>fusionbinary</code>, lambda is a numeric value for the penalty; for <code>fusionbinary.fit</code>, lambda is a vector with a list of penalty values.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_n">N</code></td>
<td>

<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each data set. If a vector is provided, then the elements are the sample sizes for all the platforms.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_p">p</code></td>
<td>

<p>Numeric. The number of predictors.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_m">m</code></td>
<td>

<p>Numeric. The number of platforms.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_beta">beta</code></td>
<td>

<p>Numeric. An initial value for the estimated parameters with dimensions nvars x nplatforms.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_thresh">thresh</code></td>
<td>

<p>Numeric. The stopping criteria. The default value is 0.1.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_maxiter">maxiter</code></td>
<td>

<p>Numeric. Maximum number of iterations. The default value is 100.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_methods">methods</code></td>
<td>

<p>Character (&quot;lass&quot; or &quot;scad&quot;). <code>lass</code>: LASSO; <code>scad</code>: SCAD.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_link">link</code></td>
<td>

<p>Character (&quot;logit&quot; or &quot;probit&quot;). Link functions: logistic or probit.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_complete">Complete</code></td>
<td>

<p>Logic input. If <code>Complete == TRUE</code>, the predictors <code class="reqn">M_1</code>,...,<code class="reqn">M_p</code> are measured in all platforms. If <code>Compelte == FALSE</code>, in some platforms, not all of the predictors <code class="reqn">\{M_1,M_2,...,M_p\}</code> are measured. The values of the corresponding estimated coefficients for the missing predictors will be <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_depen">depen</code></td>
<td>

<p>Character. Input only for function <code>fusionbinary.fit</code>. &quot;IND&quot; means the observations across different platforms are independent; &quot;CORR&quot; means the observations are correlated, and the sample sizes should be equal for different platforms. 
</p>
</td></tr>
<tr><td><code id="fusionbinary_+3A_a">a</code></td>
<td>

<p>Numeric. Input only for function <code>fusionbinary.fit</code>. The free multiplicative constant used in <code class="reqn">\gamma_n</code>. The default value is 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generalized fusion learning function to learn from multiple models with binary responses. More details regarding the algorithm can be found in <code><a href="#topic+FusionLearn">FusionLearn</a></code>.
</p>


<h3>Value</h3>

<p><code>fusionbinary</code> returns a list that has components:
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>A matrix (nvars x nplatforms) containing estimated coefficients of each linear model. If some data sets do not have the complete set of predictors, the corresponding coefficients are output as <code>NA</code>.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>Penalty function LASSO or SCAD.
</p>
</td></tr>
<tr><td><code>link</code></td>
<td>

<p>The link function used in the estimation.
</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>

<p>The numeric value shows the difference in the estimates between the successive updates upon convergence. 
</p>
</td></tr>
<tr><td><code>iteration</code></td>
<td>

<p>The numeric value shows the number of iterations upon convergence.
</p>
</td></tr>
</table>
<p><code>fusionbinary.fit</code> provides the results in a table:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>

<p>The sequence of penalty values.
</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>

<p>The pseudolikelihood Bayesian information criterion evaluated at the sequence of the penalty values.
</p>
</td></tr>
<tr><td><code>-2Loglkh</code></td>
<td>

<p>Minus twice the pseudo loglikelihood of the chosen model.
</p>
</td></tr>
<tr><td><code>Est_df</code></td>
<td>

<p>The estimated degrees of freedom quantifying the model complexity.
</p>
</td></tr>
</table>
<p><code>fusionbinary.fit</code> also returns a model selection plot showing the results above. 
</p>


<h3>Note</h3>

<p>The range of the penalty values should be carefully chosen. For some penalty values, the resulting models may have singular information matrix or the fitting of the glm cannot converge.
</p>


<h3>Author(s)</h3>

<p>Xin Gao, Yuan Zhong, and Raymond J. Carroll
</p>


<h3>References</h3>

<p>Gao, X and Carroll, R. J. (2017) Data integration with high dimensionality. Biometrika, 104, 2, pp. 251-272
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Analysis of the gene data 
y = list(mockgene1[,2],mockgene2[,2])           ## responses "status"
x = list(mockgene1[,3:502],mockgene2[,3:502])   ## 500 predictors 


##Implementing fusion learning algorithm 
result &lt;- fusionbinary(x,y,0.3,N=c(98,286),500,2) 
id &lt;- which(result$beta[,1]!=0)+2
genename &lt;- colnames(mockgene1)[id]

</code></pre>

<hr>
<h2 id='FusionLearn-package'>
Fusion Learning 
</h2><span id='topic+FusionLearn'></span>

<h3>Description</h3>

<p><code>FusionLearn</code> package implements a new learning algorithm to integrate information from different experimental platforms. The algorithm applies the grouped penalization method in the pseudolikelihood setting. 
</p>


<h3>Details</h3>

<p>In the context of fusion learning, there are <code class="reqn">k</code> different data sets from <code class="reqn">k</code> different experimental platforms. The data from each platform can be modeled by a different generalized linear model. Assume the same set of predictors <code class="reqn">\{M_1,M_2,...,M_j,...,M_p \}</code> are measured across <code class="reqn">k</code> different experimental platforms.
</p>

<table>
<tr>
 <td style="text-align: left;">
Platforms </td><td style="text-align: left;">  Formula </td><td style="text-align: center;"> <code class="reqn">M_1</code> </td><td style="text-align: center;"> <code class="reqn">M_2</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">M_j</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">M_p</code> </td>
</tr>
<tr>
 <td style="text-align: left;">           
1 </td><td style="text-align: left;"> <code class="reqn">y_1: g_1(\mu_1) \sim</code> </td><td style="text-align: center;"> <code class="reqn">x_{11}\beta_{11}+</code> </td><td style="text-align: center;"> <code class="reqn">x_{12}\beta_{12}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code>  </td><td style="text-align: center;"> <code class="reqn">x_{1j}\beta_{1j}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">x_{1p}\beta_{1p}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
2 </td><td style="text-align: left;"> <code class="reqn">y_2: g_2(\mu_2) \sim</code> </td><td style="text-align: center;"> <code class="reqn">x_{21}\beta_{21}+</code> </td><td style="text-align: center;"> <code class="reqn">x_{22}\beta_{22}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">x_{2j}\beta_{2j}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code>  </td><td style="text-align: center;"> <code class="reqn">x_{2p}\beta_{2p}</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;">  ... </td><td style="text-align: center;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
k </td><td style="text-align: left;"> <code class="reqn">y_k: g_k(\mu_k) \sim</code> </td><td style="text-align: center;"> <code class="reqn">x_{k1}\beta_{k1}+</code> </td><td style="text-align: center;"> <code class="reqn">x_{k2}\beta_{k2}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">x_{kj}\beta_{kj}+</code> </td><td style="text-align: center;"> <code class="reqn">\dots</code> </td><td style="text-align: center;"> <code class="reqn">x_{kp}\beta_{kp}</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Here <code class="reqn">x_{kj}</code> represents the observation of the predictor <code class="reqn">M_j</code> on the <code class="reqn">k</code>th platform, and <code class="reqn">\beta^{(j)}</code> denotes the vector of regression coefficients for the predictor <code class="reqn">M_j</code>. 
</p>

<table>
<tr>
 <td style="text-align: left;">
Platforms </td><td style="text-align: left;"> <code class="reqn">\bold{M_j}</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code class="reqn">\bold{\beta^{(j)}}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
1 </td><td style="text-align: left;"> <code class="reqn">x_{1j}</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code class="reqn">\beta_{1j}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
2 </td><td style="text-align: left;"> <code class="reqn">x_{2j}</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code class="reqn">\beta_{2j}</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;"> ... </td><td style="text-align: left;"> </td><td style="text-align: left;"> ... </td>
</tr>
<tr>
 <td style="text-align: left;">
k </td><td style="text-align: left;"> <code class="reqn">x_{kj}</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code class="reqn">\beta_{kj}</code>
</td>
</tr>

</table>

<p>Consider the following examples.
</p>
<p><em>Example 1.</em> Suppose <code class="reqn">k</code> different types of experiments are conducted to study the genetic mechanism of a disease. The predictors in this research are different facets of individual genes, such as mRNA expression, protein expression, RNAseq expression and so on. The goal is to select the genes which affect the disease, while the genes are assessed in a number of ways through different measurement processes across <code class="reqn">k</code> experimental platforms.
</p>
<p><em>Example 2.</em> The predictive models for three different financial indices are simultaneously built from a panel of stock index predictors. In this case, the predictor values across different models are the same, but the regression coefficients are different.
</p>
<p>In the conventional approach, the model for each of the <code class="reqn">k</code> platforms is analyzed separately. <code>FusionLearn</code> algorithm selects significant predictors through learning from multiple models. The overall objective is to minimize the function: 
</p>
<p style="text-align: center;"><code class="reqn">Q(\beta)=l_I(\beta)- n \sum_{j=1}^{p} \Omega_{\lambda_n} ||\beta^{(j)}||,</code>
</p>

<p>with <code class="reqn">p</code> being the numbers of predictors, <code class="reqn">\Omega_{\lambda_n}</code> being the penalty functions, and <code class="reqn">||\beta^{(j)}|| = (\sum_{i=1}^{k}\beta_{ij}^2)^{1/2}</code> denoting the <code class="reqn">L_2</code>-norm of the coefficients of the predictor <code class="reqn">M_j</code>. 
</p>
<p>The user can specify the penalty function <code class="reqn">\Omega_{\lambda_n}</code> and the penalty values <code class="reqn">\lambda_n</code>. This package also contains functions to provide the pseudolikelihood Bayesian information criterion:
</p>
<p style="text-align: center;"><code class="reqn"> pseu-BIC(s) = -2l_I(\hat{\beta}_I;Y) + d_s^{*} \gamma_n </code>
</p>

<p>with <code class="reqn">-2l_I(\hat{\beta}_I; Y)</code> denoting the pseudo loglikelihood, <code class="reqn">d_s^{*}</code> measuring the model complexity and <code class="reqn">\gamma_n</code> being the penalty on the model complexity. 
</p>
<p>The basic function <code><a href="#topic+fusionbase">fusionbase</a></code> deals with continuous responses. The function <code><a href="#topic+fusionbinary">fusionbinary</a></code> is applied to binary responses, and the function <code><a href="#topic+fusionmixed">fusionmixed</a></code> is applied to a mix of continuous and binary responses.
</p>


<h3>Note</h3>

<p>Here we provide two examples to illustrate the data structures. Assume <code class="reqn">X_I</code> and <code class="reqn">X_{II}</code> represent two sets of the predictors from 2 experimental platforms. 
</p>
<p><em>Example 1</em>. If the observations from <code class="reqn">X_I</code> and <code class="reqn">X_{II}</code> are independent, the number of observations can be different. The order of the predictors <code class="reqn">\{M_1, M_2, M_3, M_4\}</code> in <code class="reqn">X_I</code> matches with the predictors in <code class="reqn">X_{II}</code>. If <code class="reqn">X_{II}</code> does not include the predictor <code class="reqn">M_3</code>, then the <code class="reqn">M_3</code> in <code class="reqn">X_{II}</code> needs to be filled with <code>NA</code>.    
</p>

<table>
<tr>
 <td style="text-align: left;">
     </td><td style="text-align: right;">    <code class="reqn">M_1</code> </td><td style="text-align: right;"> <code class="reqn">M_2</code> </td><td style="text-align: right;"> <code class="reqn">M_3</code> </td><td style="text-align: right;"> <code class="reqn">M_4</code> </td><td style="text-align: left;">
     </td><td style="text-align: right;">    <code class="reqn">M_1</code> </td><td style="text-align: right;"> <code class="reqn">M_2</code> </td><td style="text-align: right;"> <code class="reqn">M_3</code> </td><td style="text-align: right;"> <code class="reqn">M_4</code> </td>
</tr>
<tr>
 <td style="text-align: left;"> 
<code class="reqn">X_I = </code> </td><td style="text-align: right;"> 0.1  </td><td style="text-align: right;">     0.3   </td><td style="text-align: right;">   0.5     </td><td style="text-align: right;">   20      </td><td style="text-align: left;">
<code class="reqn">X_{II} = </code> </td><td style="text-align: right;"> 100  </td><td style="text-align: right;">     8   </td><td style="text-align: right;">  <code>NA</code> </td><td style="text-align: right;">     100      </td>
</tr>
<tr>
 <td style="text-align: left;">
             </td><td style="text-align: right;"> 0.3  </td><td style="text-align: right;">     0.1   </td><td style="text-align: right;">   0.5     </td><td style="text-align: right;">   7       </td><td style="text-align: left;">
             </td><td style="text-align: right;"> 30  </td><td style="text-align: right;">      1   </td><td style="text-align: right;">   <code>NA</code> </td><td style="text-align: right;">     2     </td>
</tr>
<tr>
 <td style="text-align: left;">
             </td><td style="text-align: right;"> 0.1  </td><td style="text-align: right;">     0.9   </td><td style="text-align: right;">     1     </td><td style="text-align: right;">   0       </td><td style="text-align: left;">
             </td><td style="text-align: right;"> 43  </td><td style="text-align: right;">     19   </td><td style="text-align: right;">  <code>NA</code>   </td><td style="text-align: right;">   -3       </td>
</tr>
<tr>
 <td style="text-align: left;">
             </td><td style="text-align: right;"> -0.3  </td><td style="text-align: right;">    1.2   </td><td style="text-align: right;">     2     </td><td style="text-align: right;">     40  </td>
</tr>

</table>

<p><em>Example 2</em>. If the observations from <code class="reqn">X_I</code> and <code class="reqn">X_{II}</code> are correlated, the number of observations must be the same. The <code class="reqn">i</code>th row in <code class="reqn">X_I</code> is correlatd with the <code class="reqn">i</code>th row in <code class="reqn">X_{II}</code>. The predictors of <code class="reqn">X_I</code> and <code class="reqn">X_{II}</code> should be matched in order. The predictors which are not measured need to be filled with <code>NA</code>.
</p>

<table>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: right;"> <code class="reqn">M_1</code> </td><td style="text-align: right;"> <code class="reqn">M_2</code> </td><td style="text-align: right;"> <code class="reqn">M_3</code> </td><td style="text-align: right;"> <code class="reqn">M_4</code> </td><td style="text-align: left;">
     </td><td style="text-align: right;"> <code class="reqn">M_1</code> </td><td style="text-align: right;"> <code class="reqn">M_2</code> </td><td style="text-align: right;"> <code class="reqn">M_3</code> </td><td style="text-align: right;"> <code class="reqn">M_4</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code class="reqn">X_I = </code> </td><td style="text-align: right;"> 0.1  </td><td style="text-align: right;">     0.3   </td><td style="text-align: right;">   0.5     </td><td style="text-align: right;">   20      </td><td style="text-align: left;">
<code class="reqn">X_{II} = </code> </td><td style="text-align: right;"> 0.3  </td><td style="text-align: right;">     0.8   </td><td style="text-align: right;">  <code>NA</code> </td><td style="text-align: right;">     100      </td>
</tr>
<tr>
 <td style="text-align: left;">
      </td><td style="text-align: right;"> 0.3  </td><td style="text-align: right;">     0.1   </td><td style="text-align: right;">   0.5     </td><td style="text-align: right;">   70       </td><td style="text-align: left;">
      </td><td style="text-align: right;"> 0.2  </td><td style="text-align: right;">      1   </td><td style="text-align: right;">   <code>NA</code> </td><td style="text-align: right;">    20     </td>
</tr>
<tr>
 <td style="text-align: left;">
       </td><td style="text-align: right;"> -0.1  </td><td style="text-align: right;">     0.9   </td><td style="text-align: right;">     1     </td><td style="text-align: right;">   0       </td><td style="text-align: left;">
             </td><td style="text-align: right;">  0.43  </td><td style="text-align: right;">   1.9   </td><td style="text-align: right;">  <code>NA</code>   </td><td style="text-align: right;">   -30  </td>
</tr>
<tr>
 <td style="text-align: left;">
             </td><td style="text-align: right;"> -0.3  </td><td style="text-align: right;">    1.2   </td><td style="text-align: right;">     2     </td><td style="text-align: right;">     40   </td><td style="text-align: left;">
             </td><td style="text-align: right;">  -0.4  </td><td style="text-align: right;">   -2   </td><td style="text-align: right;">    <code>NA</code> </td><td style="text-align: right;">   40</td>
</tr>

</table>

<p>In functions <code>fusionbase.fit</code>, <code>fusionbinary.fit</code>, and <code>fusionmixed.fit</code>, the option <code>depen</code> is used to specify whether observations from different platforms are correlated or independent. 
</p>


<h3>Author(s)</h3>

<p>Xin Gao, Yuan Zhong and Raymond J Carroll
</p>
<p>Maintainer: Yuan Zhong &lt;aqua.zhong@gmail.com&gt;
</p>


<h3>References</h3>

<p>Gao, X and Carroll, R. J. (2017) Data integration with high dimensionality. Biometrika, 104, 2, pp. 251-272
</p>

<hr>
<h2 id='fusionmixed'>
Fusion learning algorithm for mixed data
</h2><span id='topic+fusionmixed'></span><span id='topic+fusionmixed.fit'></span>

<h3>Description</h3>

<p><code>fusionmixed</code> conducts the group penalization with a specified penalty value learning from multiple generalized linear models with mixed continuous and binary responses. <code>fusionmixed.fit</code> can be used to search the best candidate model based on the pseudo Bayesian information criterion with a sequence of penalty values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fusionmixed(x, y, lambda, N, p, m1, m2, beta=0.1, thresh=0.1, 
            maxiter=100, methods="scad", link="logit", Complete=TRUE)

fusionmixed.fit(x, y, lambda, N, p, m1, m2, beta=0.1, thresh=0.1, 
                maxiter=100, methods="scad",link="logit", Complete=TRUE, 
                depen ="IND", a=1)
</code></pre>


<h3>Arguments</h3>

  
<table>
<tr><td><code id="fusionmixed_+3A_x">x</code></td>
<td>

<p>List. Listing matrices of the predictors from different platforms. The first m1 data sets in the list are the ones of continuous responses, and the following m2 data sets are the ones of binary responses.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_y">y</code></td>
<td>

<p>List. A list of the responses vectors from different platforms following the same order as in <code>x</code>. The values <code>m1</code> and <code>m2</code> must be specified.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_lambda">lambda</code></td>
<td>

<p>Numeric or vector.  For <code>fusionmixed</code>, lambda is a numeric value for the penalty; for <code>fusionmixed.fit</code>, lambda is a vector with a list of penalty values.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_n">N</code></td>
<td>

<p>Numeric or vector. If only one numeric value is provided, equal sample size will be assumed for each data set. If a vector is provided, then the elements are the sample sizes for all the platforms.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_p">p</code></td>
<td>

<p>Numeric. The number of predictors.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_m1">m1</code></td>
<td>

<p>Numeric. Number of platforms whose response variables are continuous.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_m2">m2</code></td>
<td>

<p>Numeric. Number of platforms whose response variables are binary.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_beta">beta</code></td>
<td>

<p>Numeric. An initial value for the estimated parameters with dimensions nvars x nplatforms. The default value is 0.1.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_thresh">thresh</code></td>
<td>

<p>Numeric. The stopping criteria. The default value is 0.1.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_maxiter">maxiter</code></td>
<td>

<p>Numeric. Maximum number of iterations. The default value is 100.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_methods">methods</code></td>
<td>

<p>Character (&quot;lass&quot; or &quot;scad&quot;). <code>lass</code>: LASSO; <code>scad</code>: SCAD.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_link">link</code></td>
<td>

<p>Character (&quot;logit&quot; or &quot;probit&quot;). Link functions: logistic or probit.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_complete">Complete</code></td>
<td>

<p>Logic input. If <code>Complete == TRUE</code>, the predictors <code class="reqn">M_1</code>,...,<code class="reqn">M_p</code> are measured in all platforms. If <code>Compelte == FALSE</code>, in some platforms, not all of the predictors <code class="reqn">\{M_1,M_2,...,M_p\}</code> are measured. The values of the corresponding estimated coefficients for the missing predictors will be <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_depen">depen</code></td>
<td>

<p>Character. Input only for function <code>fusionmixed.fit</code>. &quot;IND&quot; means the observations across different platforms are independent; &quot;CORR&quot; means the observations are correlated, and the sample sizes should be equal for different platforms. 
</p>
</td></tr>
<tr><td><code id="fusionmixed_+3A_a">a</code></td>
<td>

<p>Numeric. Input only for function <code>fusionmixed.fit</code>. The free multiplicative constant used in <code class="reqn">\gamma_n</code>. The default value is 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fusionmixed</code> is designed for a more complex data structure by aggregating information from continuous and binary responses. More details regarding the algorithm can be found in <code><a href="#topic+FusionLearn">FusionLearn</a></code>.
</p>


<h3>Value</h3>

<p><code>fusionmixed</code> returns a list that has components:
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>A matrix (nvars x nplatforms) containing estimated coefficients of each linear model. If some data sets do not have the complete set of predictors, the corresponding coefficients are output as <code>NA</code>.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>Penalty function LASSO or SCAD.
</p>
</td></tr>
<tr><td><code>link</code></td>
<td>

<p>The link function used in the estimation.
</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>

<p>The numeric value shows the difference in the estimates between the successive updates upon convergence. 
</p>
</td></tr>
<tr><td><code>iteration</code></td>
<td>

<p>The numeric value shows the number of iterations upon convergence.
</p>
</td></tr>
</table>
<p><code>fusionmixed.fit</code> provides the results in a table:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>

<p>The sequence of penalty values.
</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>

<p>The pseudolikelihood Bayesian information criterion evaluated at the sequence of the penalty values.
</p>
</td></tr>
<tr><td><code>-2Loglkh</code></td>
<td>

<p>Minus twice the pseudo loglikelihood of the chosen model.
</p>
</td></tr>
<tr><td><code>Est_df</code></td>
<td>

<p>The estimated degrees of freedom quantifying the model complexity.
</p>
</td></tr>
</table>
<p><code>fusionmixed.fit</code> also returns a model selection plot showing the results above. 
</p>


<h3>Note</h3>

<p>The range of the penalty values should be carefully chosen. For some penalty values, the resulting models may have singular information matrix or the fitting of the glm cannot converge.
</p>


<h3>Author(s)</h3>

<p>Xin Gao, Yuan Zhong, and Raymond J. Carroll
</p>


<h3>References</h3>

<p>Gao, X and Carroll, R. J. (2017) Data integration with high dimensionality. Biometrika, 104, 2, pp. 251-272
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fusionbase">fusionbase</a></code>,<code><a href="#topic+fusionbinary">fusionbinary</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Analysis of the index data

#Responses contain indices "VIX","GSPC", and "DJI",  
#"DJI" is dichotomized into "increasing" or "decreasing"
y &lt;- list(stockindexVIX[,1],stockindexGSPC[,1],stockindexDJI[,1]&gt;0)

#Predictors include 46 stocks
x &lt;- list(stockindexVIX[,2:47],stockindexGSPC[,2:47],stockindexDJI[,2:47])  
##Implementing the model selection based on psuedolikelihood 
##information criteria
model &lt;- fusionmixed.fit(x,y,seq(0.03,5,length.out = 10),232,46,2,1,depen="CORR")
lambda &lt;- model[which.min(model[,2]),1]  
result &lt;- fusionmixed(x,y,lambda,232,46,2,1)

##Identify the significant predictors for three indices
id &lt;- which(result$beta[,1]!=0)+1
colnames(stockindexVIX)[id]


</code></pre>

<hr>
<h2 id='mockgene'>
Mock Gene Data
</h2><span id='topic+mockgene1'></span><span id='topic+mockgene2'></span>

<h3>Description</h3>

<p>This dataset is a mock version of two different microarray experiments on breast cancer cells.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("mockgene1")
data("mockgene2")</code></pre>


<h3>Format</h3>

<p>The first data &quot;mockgene1&quot; contains 98 subjects, and the second data &quot;mockgene2&quot; contains 286 subjects.
</p>
<p>The first column for each data is ID number.
</p>
<p>The second column is subjects' status. If the status is the estrogen-receptor-positive, <code class="reqn">y=1</code>; if the status is estrogen-receptor-negative, <code class="reqn">y=0</code>.
Other columns record the gene expression values.
</p>


<h3>Details</h3>

<p>This is an example to implement the <code>FusionLearn</code> algorithm for binary responses. In this case, the two experiments followed different protocols, and the two sets of gene expression profiles are different. The objective is to select a suitable subset gene predictors for the disease analysis based on both experiments. 
</p>


<h3>Source</h3>

<p>This data is a mock version of the original data. The original gene data contain over 20,000 profile expressions, and more details can be found on <a href="https://www.ncbi.nlm.nih.gov/">https://www.ncbi.nlm.nih.gov/</a> with series numbers GSE2034 and GSE22093.
</p>

<hr>
<h2 id='stockindex'>
Finance Data
</h2><span id='topic+stockindexVIX'></span><span id='topic+stockindexGSPC'></span><span id='topic+stockindexDJI'></span><span id='topic+validVIX'></span><span id='topic+validGSPC'></span><span id='topic+validDJI'></span>

<h3>Description</h3>

<p>This is a dataset containing the log return on three financial market indices and 46 stocks between 2013 and 2015. The responses are the financial indices, &quot;VIX&quot;, &quot;SP500&quot;, and &quot;DJI&quot;, and the predictors are 46 stocks from the market. The data are given in three-day gap from 700 trading days. We also provide the validation datasets of three indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("stockindexVIX")
data("stockindexGSPC")
data("stockindexDJI")
data("validVIX")
data("validGSPC")
data("validDJI")
</code></pre>


<h3>Details</h3>

<p>This example is used to demonstrate the use of the functions <code><a href="#topic+fusionbase">fusionbase</a></code> and <code><a href="#topic+fusionmixed">fusionmixed</a></code>. This dataset has correlated responses and the same predictors values for three models.
</p>


<h3>Source</h3>

<p>This data is available on Yahoo Finance. 
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
