<!DOCTYPE html><html><head><title>Help for package ELYP</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ELYP}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BJfindL2'><p>Find the Wilks Confidence Interval Lower Bound for Betafun from the 2 dimensional Buckley-James Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#BJfindU2'><p>Find the Wilks Confidence Interval Upper Bound for Betafun from the 2 dimensional Buckley-James Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#CoxEL'><p>Compute Empirical Likelihood and Partial Likelihood of Cox model for Testing the beta and Baseline Jointly.</p></a></li>
<li><a href='#CoxFindL2'><p>Find the Wilks Confidence Interval Lower Bound for Efun based on the Empirical Likelihood Ratio Function CoxEL</p></a></li>
<li><a href='#CoxFindL3'><p>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#CoxFindU2'><p>Find the Wilks Confidence Interval Upper Bound for Efun from the Empirical Likelihood Ratio Function CoxEL( ).</p></a></li>
<li><a href='#CoxFindU3'><p>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#ELrange'><p>Find the Ractangular parameter region where EL is Only 4 below the Maximum Value.</p></a></li>
<li><a href='#ELYP-internal'><p>Internal ELYP functions</p></a></li>
<li><a href='#findL2d'><p>Find the Wilks Confidence Interval Lower Bound from the Given 2-d Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#findL3'><p>Find the Wilks Confidence Interval Lower Bound from the Given Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#findL4'><p>Find the Wilks Confidence Interval Lower Bound from the Given Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#findU2d'><p>Find the Wilks Confidence Interval Upper Bound from the Given 2-d Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#findU3'><p>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#findU32'><p>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#findU4'><p>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</p></a></li>
<li><a href='#fitYP3'><p> Compute Baseline Hazard for the Given Data, Given Parameters: beta1, beta2, lam, and fun.</p>
Also, Given the Baseline, Compute the empirical likelihood value.</a></li>
<li><a href='#fitYP4'><p> Compute Alpha and Baseline Hazard for the Given Data, Given Parameters beta1, beta2.</p>
Also, compute the empirical likelihood value.</a></li>
<li><a href='#fitYP41'><p> Compute the Baseline Hazard for the Given Data, given Parameters beta1, beta2.</p>
Also, compute the empirical likelihood value.</a></li>
<li><a href='#GastricCancer'><p>Gastric Cancer Data</p></a></li>
<li><a href='#myLLfun'><p> Compute Baseline Hazard for the Given Data and Parameters beta1, beta2, lam.</p>
Also Compute the empirical likelihood value.</a></li>
<li><a href='#myLLfun2'><p> Compute Baseline Hazard for the Given Data and Parameters beta1, beta2, alpha, lam.</p>
Also Compute the empirical likelihood value.</a></li>
<li><a href='#Pfun'><p> The Hazard Ratio in YP Model as a Function of beta1 beta2 and Mulam.</p></a></li>
<li><a href='#Pfun2'><p>The Hazard Ratio in YP Model as a Function of beta1, beta2, a, X, and Mulam.</p></a></li>
<li><a href='#simuDataYP'><p> Generate random times that follow the YP model with the Given Parameters th1, th2, and alphaX.</p></a></li>
<li><a href='#smallcell'><p>Smallcell Lung Cancer Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Maintainer:</td>
<td>Mai Zhou &lt;mai@ms.uky.edu&gt;</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7-5</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, survival</td>
</tr>
<tr>
<td>Author:</td>
<td>Mai Zhou</td>
</tr>
<tr>
<td>Description:</td>
<td>Empirical likelihood ratio tests for the Yang and Prentice (short/long term hazards ratio) models. 
             Empirical likelihood tests within a Cox model, for parameters defined via 
			 both baseline hazard function and regression parameters.</td>
</tr>
<tr>
<td>Title:</td>
<td>Empirical Likelihood Analysis for the Cox Model and
Yang-Prentice (2005) Model</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.ms.uky.edu/~mai/EmpLik.html">http://www.ms.uky.edu/~mai/EmpLik.html</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-08-19 04:24:27 UTC; mai</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-08-19 05:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='BJfindL2'>Find the Wilks Confidence Interval Lower Bound for Betafun from the 2 dimensional Buckley-James Empirical Likelihood Ratio Function</h2><span id='topic+BJfindL2'></span>

<h3>Description</h3>

<p>This function uses simple search to find the lower level (default 95%) 1 parameter Wilks confidence limits based on the Buckley-James empirical likelihood test function for two dimensional beta's. Betafun determines the 1 parameter we are finding the lower bound.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BJfindL2(NPmle, ConfInt, LLRfn, Betafun, dataMat, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BJfindL2_+3A_npmle">NPmle</code></td>
<td>
<p>a 2-d vector: the NPMLEs: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="BJfindL2_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 2. Approx. length of the 2 conf. intervals for beta1 and beta2.</p>
</td></tr>
<tr><td><code id="BJfindL2_+3A_llrfn">LLRfn</code></td>
<td>
<p>a function that returns -2LLR value.</p>
</td></tr> 
<tr><td><code id="BJfindL2_+3A_betafun">Betafun</code></td>
<td>
<p>a function that takes the input of 2 parameter values (beta1,beta2) and 
returns a parameter that we wish to find the confidence Interval lower Value. </p>
</td></tr>
<tr><td><code id="BJfindL2_+3A_datamat">dataMat</code></td>
<td>
<p>matrix of covariates</p>
</td></tr>
<tr><td><code id="BJfindL2_+3A_level">level</code></td>
<td>
<p>confidence level. Use chi-square(df=1), but calibration possible.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the 2 parameters, finding the -2LLR values, until we find those Betafun
which the -2 log likelihood Ratio value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Lower</code></td>
<td>
<p>the lower confidence bound.</p>
</td></tr>
<tr><td><code>minParameterNloglik</code></td>
<td>
<p>Final values of the 2 parameters, and the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. and Li, G. (2006). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See the Rd file of BJfindU2 for example.
</code></pre>

<hr>
<h2 id='BJfindU2'>Find the Wilks Confidence Interval Upper Bound for Betafun from the 2 dimensional Buckley-James Empirical Likelihood Ratio Function</h2><span id='topic+BJfindU2'></span>

<h3>Description</h3>

<p>This function uses simple search to find the upper level (default 95%) 1 parameter Wilks confidence limits based on the Buckley-James empirical likelihood test function for two dimensional beta's. The confidece interval is for the 1 parameter, determined by Betafun.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BJfindU2(NPmle, ConfInt, LLRfn, Betafun, dataMat, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BJfindU2_+3A_npmle">NPmle</code></td>
<td>
<p>a 2-d vector: the NPMLEs: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="BJfindU2_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 2. Approx. length of the 2 conf. intervals for beta1 and beta2. May use the SD from bj(). </p>
</td></tr>
<tr><td><code id="BJfindU2_+3A_llrfn">LLRfn</code></td>
<td>
<p>a function that returns the -2LLR.</p>
</td></tr> 
<tr><td><code id="BJfindU2_+3A_betafun">Betafun</code></td>
<td>
<p>a function that takes the input of 2 parameter values (beta1, beta2) and 
returns a parameter that we wish to find its confidence Interval Lower Value. </p>
</td></tr>
<tr><td><code id="BJfindU2_+3A_datamat">dataMat</code></td>
<td>
<p>matrix of covariates</p>
</td></tr>
<tr><td><code id="BJfindU2_+3A_level">level</code></td>
<td>
<p>confidence level.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the 2 parameters, until we find the max of Betafun, provided
the -2 log likelihood value is &lt;= 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Upper</code></td>
<td>
<p>the upper confidence bound.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 2 parameters, and the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2005). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
# The Stanford Heart Transplant Data: with 152 cases.
# Needs bjtest( ) function from emplik package to run.

## BJloglik &lt;- function(para, dataMat) {
##            yvec &lt;- dataMat[,1]
##            dvec &lt;- dataMat[,2]
##            x &lt;- dataMat[,3:4]
## temp &lt;- bjtest(y=log10(yvec), d=dvec, x=x, beta=para)
## return(temp)
## }

## BJ2fun &lt;- function (b1, b2) {
##    return(b2)
## }

## We first use bj() from Design library to find NPmle and
## the conservative SD of beta1 and beta2

## BJfindU2(NPmle=c(3.52696077,-0.01989555), 
##      ConfInt=c(0.3,0.0066), LLRfn=BJloglik, 
##      Betafun=BJ2fun, 
##      dataMat=cbind(stanford5$time, stanford5$status, 
##      rep(1,152),stanford5$age))
##
# This will take (~ 1 min.) to run.
</code></pre>

<hr>
<h2 id='CoxEL'>Compute Empirical Likelihood and Partial Likelihood of Cox model for Testing the beta and Baseline Jointly. </h2><span id='topic+CoxEL'></span>

<h3>Description</h3>

<p>This function compute empirical likelihood and partial likelihood for the purpose of 
testing (jointly) the beta (the regression parameter) and a baseline hazard feature, 
which is defined by lam and fun.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoxEL(y, d, Z, beta, lam, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoxEL_+3A_y">y</code></td>
<td>
<p>a vector containing the survival times</p>
</td></tr>
<tr><td><code id="CoxEL_+3A_d">d</code></td>
<td>
<p>censoring status: 1 - uncensored; 0 - censored.</p>
</td></tr>
<tr><td><code id="CoxEL_+3A_z">Z</code></td>
<td>
<p>a matrix of covariates, size nxk; Z=(Z_1i, ..., Z_ki)</p>
</td></tr>
<tr><td><code id="CoxEL_+3A_beta">beta</code></td>
<td>
<p>a vector =(beta1, ... betak)</p>
</td></tr>
<tr><td><code id="CoxEL_+3A_lam">lam</code></td>
<td>
<p>a scalar, used in the constraint of baseline: int f(t)dH(t)= Mulam. It is sometime called the tilting amount.</p>
</td></tr>
<tr><td><code id="CoxEL_+3A_fun">fun</code></td>
<td>
<p>a function in the int f(t)dH(t). Together with lam, it defines the feature of the baseline hazard H(t).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function compute the likelihood when we impose both restriction on beta and on baseline. The restriction on beta is simply by setting beta equal to the given value in the CoxEL input. The restriction on the baseline is via a finite dimensional feature. 
</p>
<p>lam controls the amount of tilting for the baseline, in the direction of the feature defined by
int f(t) dH(t). When lam = 0 means no tilting. 
</p>


<h3>Value</h3>

<p>It returns a list containing:
(1)logEmpLik: log empirical likelihood value; 
(2)logPlik: log partial likelihood value; 
(3)Hazw: the constrained baseline estimator (the jumps);
(4)mu: the value of the constraint, int f(t)dH(t)= Mulam i.e., the feature value.
</p>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2016). Empirical Likelihood Method in Survival Analysis.
Zhou, M. (2005). 
Cox model with restriction on the baseline hazard. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## censored regression with one right censored observation.
## we check the estimation equation, with the MLE inside myfun7. 
y &lt;- c(3, 5.3, 6.4, 9.1, 14.1, 15.4, 18.1, 15.3, 14, 5.8, 7.3, 14.4)
x &lt;- c(1, 1.5, 2,   3,   4,    5,    6,    5,    4,  1,   2,   4.5)
d &lt;- c(1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0)
</code></pre>

<hr>
<h2 id='CoxFindL2'>Find the Wilks Confidence Interval Lower Bound for Efun based on the Empirical Likelihood Ratio Function CoxEL</h2><span id='topic+CoxFindL2'></span>

<h3>Description</h3>

<p>This function uses simple search to find the lower level (default 95%) Wilks confidence limits based on the CoxEL( ) likelihood function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoxFindL2(BetaMLE, StepSize, Hfun, Efun, y, d, Z, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoxFindL2_+3A_betamle">BetaMLE</code></td>
<td>
<p>a scalar: the NPMLEs: beta1 hat.</p>
</td></tr>
<tr><td><code id="CoxFindL2_+3A_stepsize">StepSize</code></td>
<td>
<p>a vector of length 2. Approximate length of the 2 confidence intervals: beta1, and lambda.</p>
</td></tr>
<tr><td><code id="CoxFindL2_+3A_hfun">Hfun</code></td>
<td>
<p>a function that defines the baseline feature: int f(t)dH(t)= mu or sometimes called Mulam.</p>
</td></tr> 
<tr><td><code id="CoxFindL2_+3A_efun">Efun</code></td>
<td>
<p>a function that takes the input of 2 parameter values (beta1 and Mulam) and 
returns a parameter that we wish to find the confidence interval lower value. The two input variables must be named beta and theta.</p>
</td></tr>
<tr><td><code id="CoxFindL2_+3A_y">y</code></td>
<td>
<p>the censored survival times. </p>
</td></tr>
<tr><td><code id="CoxFindL2_+3A_d">d</code></td>
<td>
<p>vector of 0, and 1, censoring indicator</p>
</td></tr>
<tr><td><code id="CoxFindL2_+3A_z">Z</code></td>
<td>
<p>matrix of covariates</p>
</td></tr>
<tr><td><code id="CoxFindL2_+3A_level">level</code></td>
<td>
<p>confidence level. Using chi-square(df=1), but calibration possible.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Lower</code></td>
<td>
<p>the lower confidence bound.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 3 parameters, and the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## We find 95% lower limit of theta= \Lambda_0(300) exp(\beta)
## where \Lambda and \beta are inside a Cox model.
## First we define a function (Hfun) = I[t &lt;= 300], so that
## the baseline feature is \Lambda_0(300). The second function
## we need to define is (Efun) = what we called theta above.

data(smallcell)
myHfun &lt;- function(t){as.numeric(t &lt;= 300)}
myEfun &lt;- function(beta, theta){theta*exp(beta)}

myy &lt;- smallcell$survival
myd &lt;- smallcell$indicator
myZ &lt;- smallcell$arm

CoxFindL2(BetaMLE=0.5337653, StepSize=c(0.1, 3), 
          Hfun=myHfun, Efun=myEfun, y=myy, d=myd, Z=myZ)
</code></pre>

<hr>
<h2 id='CoxFindL3'>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</h2><span id='topic+CoxFindL3'></span>

<h3>Description</h3>

<p>This program uses simple search to find the Lower 95% (or other)Wilks confidence limits based on the log likelihood function (CoxEL) supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoxFindL3(BetaMLE, StepSize, Hfun, Efun, y, d, Z, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoxFindL3_+3A_betamle">BetaMLE</code></td>
<td>
<p>a vector containing the two NPMLEs: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="CoxFindL3_+3A_stepsize">StepSize</code></td>
<td>
<p>a vector of length 3. Approximate length of the 3 confidence intervals: beta1, beta2 and lambda.</p>
</td></tr>
<tr><td><code id="CoxFindL3_+3A_hfun">Hfun</code></td>
<td>
<p>a function that used to defines the baseline feature, mu.</p>
</td></tr> 
<tr><td><code id="CoxFindL3_+3A_efun">Efun</code></td>
<td>
<p>a function that takes the input of 3 parameter values (beta1, beta2 and Mulam) and 
returns a parameter that we wish to find the confidence Interval Lower Value. The input variables must be called beta and theta. beta: in the form of a 2-d vector (i.e., the beta1, beta2) and theta: (=Mulam)</p>
</td></tr>
<tr><td><code id="CoxFindL3_+3A_y">y</code></td>
<td>
<p>a vector of censored survival time.</p>
</td></tr>
<tr><td><code id="CoxFindL3_+3A_d">d</code></td>
<td>
<p>a vector of 0 and 1, censoring indicator</p>
</td></tr>
<tr><td><code id="CoxFindL3_+3A_z">Z</code></td>
<td>
<p>covariates of the Cox model.</p>
</td></tr>
<tr><td><code id="CoxFindL3_+3A_level">level</code></td>
<td>
<p>confidence level</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter (defined by Efun), try to go to lower and lower values of the 
parameter until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Lower</code></td>
<td>
<p>the lower confidence bound.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 4 parameters, and  the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Here Mulam is the value of int g(t) d H(t) = Mulam
## For example g(t) = I[ t &lt;= 2.0 ]; look inside myLLfun(). 

data(GastricCancer)

# The following will take about 0.5 min to run.
# findU3(NPmle=c(1.816674, -1.002082), ConfInt=c(1.2, 0.5, 10),   
#         LogLikfn=myLLfun, Pfun=Pfun, dataMat=GastricCancer)

</code></pre>

<hr>
<h2 id='CoxFindU2'>Find the Wilks Confidence Interval Upper Bound for Efun from the Empirical Likelihood Ratio Function CoxEL( ).</h2><span id='topic+CoxFindU2'></span>

<h3>Description</h3>

<p>This function uses simple search to find the upper 95% Wilks confidence limits based on the log likelihood function supplied.
This is a sister function to CoxFindL2().</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoxFindU2(BetaMLE, StepSize, Hfun, Efun, y, d, Z, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoxFindU2_+3A_betamle">BetaMLE</code></td>
<td>
<p>a scalar: the NPMLE beta1 hat.</p>
</td></tr>
<tr><td><code id="CoxFindU2_+3A_stepsize">StepSize</code></td>
<td>
<p>a vector of length 2. Approximate length of the 2 confidence intervals: beta1, and lambda. It is the initial search step size.</p>
</td></tr>
<tr><td><code id="CoxFindU2_+3A_hfun">Hfun</code></td>
<td>
<p>a function that defines the baseline feature: mu=int f(t) dH(t).</p>
</td></tr> 
<tr><td><code id="CoxFindU2_+3A_efun">Efun</code></td>
<td>
<p>a function that takes the input of 2 parameter values (beta1, and Mulam) and 
returns a parameter that we wish to find the confidence Interval Upper Value. The two input variables must be called beta and theta.</p>
</td></tr>
<tr><td><code id="CoxFindU2_+3A_y">y</code></td>
<td>
<p>a vector of censored survival times. </p>
</td></tr>
<tr><td><code id="CoxFindU2_+3A_d">d</code></td>
<td>
<p>a vector of 0 and 1, censoring indicator.</p>
</td></tr>
<tr><td><code id="CoxFindU2_+3A_z">Z</code></td>
<td>
<p>covariates for the Cox model</p>
</td></tr>
<tr><td><code id="CoxFindU2_+3A_level">level</code></td>
<td>
<p>Confidence Level. Use chi-square(df=1), but calibration possible.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Upper</code></td>
<td>
<p>the upper confidence bound.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 4 parameters, and  the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See example in CoxFindL2.
## Here Mulam is the value of int g(t) d H(t) = Mulam
## For example g(t) = I[ t &lt;= 2.0 ]; look inside myLLfun(). 
</code></pre>

<hr>
<h2 id='CoxFindU3'>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</h2><span id='topic+CoxFindU3'></span>

<h3>Description</h3>

<p>This program uses simple search to find the upper 95% Wilks confidence limits based on the log likelihood function supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoxFindU3(BetaMLE, StepSize, Hfun, Efun, y, d, Z, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoxFindU3_+3A_betamle">BetaMLE</code></td>
<td>
<p>a vector containing the two NPMLEs: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="CoxFindU3_+3A_stepsize">StepSize</code></td>
<td>
<p>a vector of length 3. Approximate length of the 3 confidence intervals: beta1, beta2 and lambda.</p>
</td></tr>
<tr><td><code id="CoxFindU3_+3A_hfun">Hfun</code></td>
<td>
<p>a function that defines the baseline feature: mu.</p>
</td></tr> 
<tr><td><code id="CoxFindU3_+3A_efun">Efun</code></td>
<td>
<p>a function that takes the input of 3 parameter values (beta1, beta2 and Mulam) and 
returns a parameter that we wish to find the confidence Interval Upper Value. The input variables must be in the form: beta = c(beta1, beta2) and theta = Mulam.</p>
</td></tr>
<tr><td><code id="CoxFindU3_+3A_y">y</code></td>
<td>
<p>a matrix. </p>
</td></tr>
<tr><td><code id="CoxFindU3_+3A_d">d</code></td>
<td>
<p>a vector of 0 and 1</p>
</td></tr>
<tr><td><code id="CoxFindU3_+3A_z">Z</code></td>
<td>
<p>covariates</p>
</td></tr>
<tr><td><code id="CoxFindU3_+3A_level">level</code></td>
<td>
<p>confidence level using chi-square(df=1), but calibration possible.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Upper</code></td>
<td>
<p>the upper confidence bound.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 4 parameters (beta1, beta2, Mulam, lam), and  the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Here Mulam is the value of int g(t) d H(t) = Mulam
## For example g(t) = I[ t &lt;= 2.0 ]; look inside myLLfun(). 

data(GastricCancer)

# The following will take about 0.5 min to run.
# findU3(NPmle=c(1.816674, -1.002082), ConfInt=c(1.2, 0.5, 10),   
#        LogLikfn=myLLfun, Pfun=Pfun, dataMat=GastricCancer)

</code></pre>

<hr>
<h2 id='ELrange'>Find the Ractangular parameter region where EL is Only 4 below the Maximum Value. </h2><span id='topic+ELrange'></span>

<h3>Description</h3>

<p>This function compute the hazard ratio, given beta1 beta2 a X and Mulam = int g(t) dH(t).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ELrange(mle, loglik, step, DataMat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ELrange_+3A_mle">mle</code></td>
<td>
<p>The NPMLE of the parameters value. </p>
</td></tr>
<tr><td><code id="ELrange_+3A_loglik">loglik</code></td>
<td>
<p>a function. Takes 2 inputs: mle and DataMat. output one scalar = loglik value.</p>
</td></tr>
<tr><td><code id="ELrange_+3A_step">step</code></td>
<td>
<p>a vector, same length as mle. The initial search step.</p>
</td></tr>
<tr><td><code id="ELrange_+3A_datamat">DataMat</code></td>
<td>
<p>The data matrix, to be used by loglik( ).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Say something.
</p>


<h3>Value</h3>

<p>A list with Step [a vector] and TempV [a matrix]
</p>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## censored regression with one right censored observation.
## we check the estimation equation, with the MLE inside myfun7. 
y &lt;- c(3, 5.3, 6.4, 9.1, 14.1, 15.4, 18.1, 15.3, 14, 5.8, 7.3, 14.4)
x &lt;- c(1, 1.5, 2,   3,   4,    5,    6,    5,    4,  1,   2,   4.5)
d &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)
</code></pre>

<hr>
<h2 id='ELYP-internal'>Internal ELYP functions</h2><span id='topic+cumsumsurv'></span><span id='topic+Haz3'></span><span id='topic+Haz4'></span><span id='topic+YP3'></span><span id='topic+YP4'></span><span id='topic+YP41'></span><span id='topic+ELcomp'></span><span id='topic+rYP'></span><span id='topic+myffitYP3'></span><span id='topic+myffitYP4'></span><span id='topic+myffitYP41'></span><span id='topic+myffitYP411'></span><span id='topic+myffitYP412'></span>

<h3>Description</h3>

<p> Internal ELYP functions </p>


<h3>Usage</h3>

<pre><code class='language-R'>cumsumsurv(x)
Haz3(d, S, gam, lam, fvec)
Haz4(d, S, gam)
YP3(y, d, Z, b1, b2, k, lam, fun)
YP4(y, d, Z, b1, b2, k)
YP41(y, d, Z, b1, b2, k)
ELcomp(Haz, Sur, gam)
rYP(th1, th2, n, aX)
myffitYP3(x, myY, myd, myZ)
myffitYP4(x, myY, myd, myZ)
myffitYP41(x, myY, myd, myZ)
myffitYP411(x1, myY, myd, myZ, beta2)
myffitYP412(x2, myY, myd, myZ, beta1)
</code></pre>


<h3>Details</h3>

<p>These are not intended to be called by the user. They compute the baseline hazard function inside a YP model.
</p>
<p><code>cumsumsurv</code> is a faster version of rev(cumsum(rev(x))).
</p>
<p><code>Haz3</code> is used in <code>YP3</code>.
</p>
<p><code>Haz4</code> is used by <code>fitYP4</code>.
</p>
<p><code>YP3</code> is used by <code>fitYP3</code>.
</p>
<p><code>YP4</code> is used bu <code>fitYP4</code>.
</p>
<p><code>YP41</code> is used by <code>fitYP41</code>.
</p>
<p><code>ELcomp</code> is used for computation of the Log Empirical Likelihood value. Used by <code>fitYP3</code>.
</p>
<p><code>rYP</code> is used only by simuDataYP.
</p>
<p><code>myffitYP***</code> are for using the optim( ) function, to find
NPmle etc.
</p>

<hr>
<h2 id='findL2d'>Find the Wilks Confidence Interval Lower Bound from the Given 2-d Empirical Likelihood Ratio Function</h2><span id='topic+findL2d'></span>

<h3>Description</h3>

<p>This function is a sister function to findU2d( ). It uses simple search algorithm to find the lower 95% Wilks confidence
limits based on the log likelihood function supplied. The likelihood have two parameters: beta1, beta2 and
the the confidence interval is for a 1-d parameter defined by Pfun(beta1, beta2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findL2d(NPmle, ConfInt, LogLikfn, Pfun, dataMat, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findL2d_+3A_npmle">NPmle</code></td>
<td>
<p>a vector containing the two NPMLE: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="findL2d_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 2. These are APPROXIMATE length of confidence intervals, as initial guess.</p>
</td></tr>
<tr><td><code id="findL2d_+3A_loglikfn">LogLikfn</code></td>
<td>
<p>a function that takes input of beta=(beta1, beta2) and dataMat, and output the log likelihood value.</p>
</td></tr> 
<tr><td><code id="findL2d_+3A_pfun">Pfun</code></td>
<td>
<p>A function of 2 variables: beta1 and beta2. Must be able to take a vector input. Example: Pfun(x1, x2)= x1. </p>
</td></tr>
<tr><td><code id="findL2d_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix of data. for the function LogLikfn.</p>
</td></tr>
<tr><td><code id="findL2d_+3A_level">level</code></td>
<td>
<p>Confidence level. Default to 3.84 (95 percent).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Lower</code></td>
<td>
<p>the lower confidence bound for Pfun.</p>
</td></tr>
<tr><td><code>minParameterNloglik</code></td>
<td>
<p>Final values of the 2 parameters, and the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example with tied observations
x &lt;- c(1, 1.5, 2, 3, 4, 5, 6, 5, 4, 1, 2, 4.5)
d &lt;- c(1,   1, 0, 1, 0, 1, 1, 1, 1, 0, 0,   1)
</code></pre>

<hr>
<h2 id='findL3'>Find the Wilks Confidence Interval Lower Bound from the Given Empirical Likelihood Ratio Function</h2><span id='topic+findL3'></span>

<h3>Description</h3>

<p>This program is the sister program to the findU3( ). 
It uses simple search to find the lower 95% Wilks confidence
limits based on the log likelihood function supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findL3(NPmle, ConfInt, LogLikfn, Pfun, level=3.84, dataMat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findL3_+3A_npmle">NPmle</code></td>
<td>
<p>a vector containing the two NPMLE: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="findL3_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 3. </p>
</td></tr>
<tr><td><code id="findL3_+3A_loglikfn">LogLikfn</code></td>
<td>
<p>a function that compute the loglikelihood. Typically this has three parameters: beta1, beta2 and lam, in a Yang-Prentice model context.</p>
</td></tr> 
<tr><td><code id="findL3_+3A_pfun">Pfun</code></td>
<td>
<p>a function that takes the input of 3 parameter values (beta1,beta2 and Mulam) and 
returns a parameter that we wish to find the confidence Interval of (here only the Lower Value). </p>
</td></tr>
<tr><td><code id="findL3_+3A_level">level</code></td>
<td>
<p>confidence level. Default to 3.84 for 95 percent.</p>
</td></tr>
<tr><td><code id="findL3_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The empirical likelihood for Y-P model has parameters: beta1, beta2 and a baseline. The baseline is converted to a 1-d parameter feature via Hfun, and then amount controled by lam.
</p>
<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Lower</code></td>
<td>
<p>the lower confidence bound.</p>
</td></tr>
<tr><td><code>minParameterNloglik</code></td>
<td>
<p>Final values of the 4 parameters, and  the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Here Mulam is the value of int g(t) d H(t) = Mulam
## For example g(t) = I[ t &lt;= 2.0 ]; look inside myLLfun(). 

Pfun &lt;- function(b1, b2, Mulam) {
alpha &lt;- exp(-Mulam)
TrtCon &lt;- 1/(alpha*exp(-b1) + (1-alpha)*exp(-b2))
return(TrtCon)
}

data(GastricCancer)

# The following will take about 10 sec. to run on i7 CPU.
# findL3(NPmle=c(1.816674, -1.002082), ConfInt=c(1.2, 0.5, 10),   
#           LogLikfn=myLLfun, Pfun=Pfun, dataMat=GastricCancer)

</code></pre>

<hr>
<h2 id='findL4'>Find the Wilks Confidence Interval Lower Bound from the Given Empirical Likelihood Ratio Function</h2><span id='topic+findL4'></span>

<h3>Description</h3>

<p>This program uses simple search to find the upper 95% Wilks confidence limits based on the log likelihood function supplied.
Caution: it takes about 1 min. to run on a data set of 90 obs. [GastricCancer]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findL4(NPmle, ConfInt, LogLikfn2, Pfun, dataMat, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findL4_+3A_npmle">NPmle</code></td>
<td>
<p>a vector containing the three NPMLEs: beta1 hat, beta2 hat and alpha hat. from a Y-P model.</p>
</td></tr>
<tr><td><code id="findL4_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 4. Approx. length of the 4 conf. intervals: beta1, beta2, alpha and lambda.</p>
</td></tr>
<tr><td><code id="findL4_+3A_loglikfn2">LogLikfn2</code></td>
<td>
<p>a function that compute the empirical likelihood of the Y-P model. given the parameters beta1, beta2, alpha, and lam.</p>
</td></tr> 
<tr><td><code id="findL4_+3A_pfun">Pfun</code></td>
<td>
<p>a function that takes the input of 3 parameter values (beta1,beta2 and Mulam) and 
returns a parameter that we wish to find the confidence Interval Lower Value. </p>
</td></tr>
<tr><td><code id="findL4_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix. </p>
</td></tr>
<tr><td><code id="findL4_+3A_level">level</code></td>
<td>
<p>The significance level. Default to 3.84; corresponds to a 95 percent confidence interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Lower</code></td>
<td>
<p>the lower confidence bound.</p>
</td></tr>
<tr><td><code>minParameterNloglik</code></td>
<td>
<p>Final values of the 4 parameters, and the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Here Mulam is the value of int g(t) d H(t) = Mulam
## For example g(t) = I[ t &lt;= 2.0 ]; look inside myLLfun(). 

data(GastricCancer)

# The following will take about 0.5 min to run.
# findU3(NPmle=c(1.816674, -1.002082), ConfInt=c(1.2, 0.5, 10),   
#           LogLikfn=myLLfun, Pfun=Pfun, dataMat=GastricCancer)

</code></pre>

<hr>
<h2 id='findU2d'>Find the Wilks Confidence Interval Upper Bound from the Given 2-d Empirical Likelihood Ratio Function</h2><span id='topic+findU2d'></span>

<h3>Description</h3>

<p>This program uses simple search algorithm to find the upper 95% Wilks confidence
limits based on the log likelihood function supplied. The likelihood have two parameters beta1, beta2 and
the the confidence interval is for a 1-d parameter =Pfun(beta1,beta2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findU2d(NPmle, ConfInt, LogLikfn, Pfun, dataMat, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findU2d_+3A_npmle">NPmle</code></td>
<td>
<p>a vector containing the two NPMLE: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="findU2d_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 2. These are APPROXIMATE length of confidence intervals, as initial guess.</p>
</td></tr>
<tr><td><code id="findU2d_+3A_loglikfn">LogLikfn</code></td>
<td>
<p>a function that takes the input of beta and dataMat and output the logliklihood value.</p>
</td></tr> 
<tr><td><code id="findU2d_+3A_pfun">Pfun</code></td>
<td>
<p>A function of 2 variables: beta1 and beta2. Must be able to take vector input. output one value: The statistic you try to find the 
confidence interval of. Example: Pfun(x1, x2)= x1. </p>
</td></tr>
<tr><td><code id="findU2d_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix of data. for the function LogLikfn.</p>
</td></tr>
<tr><td><code id="findU2d_+3A_level">level</code></td>
<td>
<p>Confidence level. Default to 3.84 (95 percent).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently). 
</p>
<p>This problem may also be solved by the 
nuisance parameter/profiling technique.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Upper</code></td>
<td>
<p>the upper confidence bound for Pfun.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 2 parameters, and the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example with tied observations
x &lt;- c(1, 1.5, 2, 3, 4, 5, 6, 5, 4, 1, 2, 4.5)
d &lt;- c(1,   1, 0, 1, 0, 1, 1, 1, 1, 0, 0,   1)
</code></pre>

<hr>
<h2 id='findU3'>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</h2><span id='topic+findU3'></span>

<h3>Description</h3>

<p>This program uses simple search to find the upper 95% Wilks confidence limits based on the log likelihood function supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findU3(NPmle, ConfInt, LogLikfn, Pfun, level=3.84, dataMat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findU3_+3A_npmle">NPmle</code></td>
<td>
<p>a vector containing the two NPMLEs: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="findU3_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 3. Approximate length of the 3 confidence intervals: beta1, beta2 and lambda. They are used as initial search steps.</p>
</td></tr>
<tr><td><code id="findU3_+3A_loglikfn">LogLikfn</code></td>
<td>
<p>a function that takes input of beta1, beta2 lam, dataMat, and output the log likelihood value.</p>
</td></tr> 
<tr><td><code id="findU3_+3A_pfun">Pfun</code></td>
<td>
<p>a function that takes the input of 3 parameter values (beta1,beta2 and Mulam) and 
returns a parameter that we wish to find the confidence Interval Upper Value. </p>
</td></tr>
<tr><td><code id="findU3_+3A_level">level</code></td>
<td>
<p>confidence level, default to 3.84 for 95 percent.</p>
</td></tr>
<tr><td><code id="findU3_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix. for the loglik computation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Upper</code></td>
<td>
<p>the upper confidence bound.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 4 parameters, and  the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Here Mulam is the value of int g(t) d H(t) = Mulam
## For example g(t) = I[ t &lt;= 2.0 ]; look inside myLLfun(). 

data(GastricCancer)

# The following will take about 10 sec. to run on an i7-4690 CPU.
# findU3(NPmle=c(1.816674, -1.002082), ConfInt=c(1.2, 0.5, 10),   
#          LogLikfn=myLLfun, Pfun=Pfun, dataMat=GastricCancer)

</code></pre>

<hr>
<h2 id='findU32'>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</h2><span id='topic+findU32'></span>

<h3>Description</h3>

<p>This program uses simple search to find the upper 95% Wilks confidence limits based on the log likelihood function supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findU32(NPmle, ConfInt, LogLikfn, Pfun, dataMat, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findU32_+3A_npmle">NPmle</code></td>
<td>
<p>a vector containing the two NPMLEs: beta1 hat and beta2 hat.</p>
</td></tr>
<tr><td><code id="findU32_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 3. Approximate length of the 3 confidence intervals: beta1, beta2 and lambda. They are used as initial search step size.</p>
</td></tr>
<tr><td><code id="findU32_+3A_loglikfn">LogLikfn</code></td>
<td>
<p>a function that computes the loglikelihood.</p>
</td></tr> 
<tr><td><code id="findU32_+3A_pfun">Pfun</code></td>
<td>
<p>a function that takes the input of 3 parameter values (beta1, beta2 and Mulam) and 
returns a parameter that we wish to find the confidence Interval Upper Value. </p>
</td></tr>
<tr><td><code id="findU32_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix. </p>
</td></tr>
<tr><td><code id="findU32_+3A_level">level</code></td>
<td>
<p>Significance level. Default to 3.84 (95 percent).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a sister function to findU3( ). A bit faster. Use about
half the time compared to findU3().
</p>
<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Upper</code></td>
<td>
<p>the upper confidence bound.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 4 parameters, and  the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Here Mulam is the value of int g(t) d H(t) = Mulam
## For example g(t) = I[ t &lt;= 2.0 ]; look inside myLLfun(). 

data(GastricCancer)

# The following will take about 0.5 min to run.
# findU32(NPmle=c(1.816674, -1.002082), ConfInt=c(1.2, 0.5, 10),   
#            LogLikfn=myLLfun, Pfun=Pfun, dataMat=GastricCancer)

</code></pre>

<hr>
<h2 id='findU4'>Find the Wilks Confidence Interval Upper Bound from the Given Empirical Likelihood Ratio Function</h2><span id='topic+findU4'></span>

<h3>Description</h3>

<p>This program uses simple search to find the upper 95% Wilks confidence limits based on the log likelihood function supplied.
Caution: it take about 3 min. to run on a data set of 90 obs. [GastricCancer]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findU4(NPmle, ConfInt, LogLikfn2, Pfun, dataMat, level=3.84)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findU4_+3A_npmle">NPmle</code></td>
<td>
<p>a vector containing the three NPMLEs: beta1 hat, beta2 hat and alpha hat.</p>
</td></tr>
<tr><td><code id="findU4_+3A_confint">ConfInt</code></td>
<td>
<p>a vector of length 4. Approximate length of the 4 confidence intervals: beta1, beta2, alpha and lambda. They are the initial search step.</p>
</td></tr>
<tr><td><code id="findU4_+3A_loglikfn2">LogLikfn2</code></td>
<td>
<p>a function that computes the loglikelihood.</p>
</td></tr> 
<tr><td><code id="findU4_+3A_pfun">Pfun</code></td>
<td>
<p>a function that takes the input of 3 parameter values (beta1, beta2 and Mulam) and 
returns a parameter that we wish to find the confidence Interval Upper Value. </p>
</td></tr>
<tr><td><code id="findU4_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix. </p>
</td></tr>
<tr><td><code id="findU4_+3A_level">level</code></td>
<td>
<p>The significance level. Default to 3.84.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically we repeatedly testing the value of the parameter, until we find those
which the -2 log likelihood value is equal to 3.84 (or other level, if set differently).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Upper</code></td>
<td>
<p>the upper confidence bound.</p>
</td></tr>
<tr><td><code>maxParameterNloglik</code></td>
<td>
<p>Final values of the 4 parameters, and  the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>JCGS</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Here Mulam is the value of int g(t) d H(t) = Mulam
## For example g(t) = I[ t &lt;= 2.0 ]; look inside myLLfun(). 

data(GastricCancer)

# The following will take about 0.5 min to run.
# findU3(NPmle=c(1.816674, -1.002082), ConfInt=c(1.2, 0.5, 10),   
#           LogLikfn=myLLfun, Pfun=Pfun, dataMat=GastricCancer)

</code></pre>

<hr>
<h2 id='fitYP3'> Compute Baseline Hazard for the Given Data, Given Parameters: beta1, beta2, lam, and fun. 
Also, Given the Baseline, Compute the empirical likelihood value. </h2><span id='topic+fitYP3'></span>

<h3>Description</h3>

<p>This function fits the baseline for given beta1 beta2 and lam; and then compute the empirical likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitYP3(Y, d, Z, beta1, beta2, lam, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitYP3_+3A_y">Y</code></td>
<td>
<p>a vector containing the observed survival times.</p>
</td></tr>
<tr><td><code id="fitYP3_+3A_d">d</code></td>
<td>
<p>a vector containing the censoring indicators, 1-uncensored; 0-right censored.</p>
</td></tr>
<tr><td><code id="fitYP3_+3A_z">Z</code></td>
<td>
<p>a matrix of covariates (Xi and Zi)...</p>
</td></tr>
<tr><td><code id="fitYP3_+3A_beta1">beta1</code></td>
<td>
<p>a vector = (alpha, beta1). </p>
</td></tr> 
<tr><td><code id="fitYP3_+3A_beta2">beta2</code></td>
<td>
<p>a vector = (alpha, beta2). </p>
</td></tr>
<tr><td><code id="fitYP3_+3A_lam">lam</code></td>
<td>
<p>a scalar. tilting parameter for the baseline. When lam=0, then there is no tilting.</p>
</td></tr>
<tr><td><code id="fitYP3_+3A_fun">fun</code></td>
<td>
<p>a function. It determine what feature of the baseline lam tilts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the log empirical likelihood. The parameters are given: beta1, beta2 and lam. 
</p>
<p>What baseline feature the lam corresponds to is determined by the fun(t), as in int f(t) dH(t). This integral value for the lam is also in the output as Mulam.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>LogEmpLik</code></td>
<td>
<p>this is actually the log empirical likelihood value.</p>
</td></tr>
<tr><td><code>Mulam</code></td>
<td>
<p> The value of int f(t) d H(t) for corresponding lam. This is also called a baseline feature.</p>
</td></tr>
<tr><td><code>BaseHazw</code></td>
<td>
<p> The baseline hazard jumps.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## censored regression with one right censored observation.
## we check the estimation equation, with the MLE inside myfun7. 
y &lt;- c(3, 5.3, 6.4, 9.1, 14.1, 15.4, 18.1, 15.3, 14, 5.8, 7.3, 14.4)
x &lt;- c(1, 1.5, 2,   3,   4,    5,    6,    5,    4,  1,   2,   4.5)
d &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)
</code></pre>

<hr>
<h2 id='fitYP4'> Compute Alpha and Baseline Hazard for the Given Data, Given Parameters beta1, beta2. 
Also, compute the empirical likelihood value. </h2><span id='topic+fitYP4'></span>

<h3>Description</h3>

<p>This function finds the NPMLE of alpha and baseline, for the given beta1 and beta2. and then compute the empirical likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitYP4(Y, d, Z, beta1=1, beta2=-1, maxiter=60)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitYP4_+3A_y">Y</code></td>
<td>
<p>a vector containing the observed survival times.</p>
</td></tr>
<tr><td><code id="fitYP4_+3A_d">d</code></td>
<td>
<p>a vector containing the censoring indicators, 1-uncensored; 0-right censored.</p>
</td></tr>
<tr><td><code id="fitYP4_+3A_z">Z</code></td>
<td>
<p>a vector of ...</p>
</td></tr>
<tr><td><code id="fitYP4_+3A_beta1">beta1</code></td>
<td>
<p>a scalar. short term</p>
</td></tr> 
<tr><td><code id="fitYP4_+3A_beta2">beta2</code></td>
<td>
<p>a scalar. long term</p>
</td></tr>
<tr><td><code id="fitYP4_+3A_maxiter">maxiter</code></td>
<td>
<p>an integer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Difference to the function <code>fitYP3</code>: there is no constraint on the baseline. So, there is no lam input.
</p>
<p>On the other hand, it try to find the NPMLE of alpha, via cox model iteration. So, it will output alpha hat. 
</p>


<h3>Value</h3>

<p>A list with the following components (may be I should also return the baseline Surv?):
</p>
<table>
<tr><td><code>EmpLik</code></td>
<td>
<p>this is actually the log empirical likelihood value.</p>
</td></tr>
<tr><td><code>BaselineH</code></td>
<td>
<p> The baseline hazard estimate.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p> The regression coefficient estimate, that is proportional hazard.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## censored regression with one right censored observation.
## we check the estimation equation, with the MLE inside myfun7. 
y &lt;- c(3, 5.3, 6.4, 9.1, 14.1, 15.4, 18.1, 15.3, 14, 5.8, 7.3, 14.4)
x &lt;- c(1, 1.5, 2,   3,   4,    5,    6,    5,    4,  1,   2,   4.5)
d &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)
</code></pre>

<hr>
<h2 id='fitYP41'> Compute the Baseline Hazard for the Given Data, given Parameters beta1, beta2. 
Also, compute the empirical likelihood value. </h2><span id='topic+fitYP41'></span>

<h3>Description</h3>

<p>This function finds the NPMLE of baseline, for the given beta1 and beta2, and then compute the empirical likelihood. The model used is the simple YP model, without alpha.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitYP41(Y, d, Z, beta1=1, beta2=-1, maxiter=60)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitYP41_+3A_y">Y</code></td>
<td>
<p>a vector containing the observed survival times.</p>
</td></tr>
<tr><td><code id="fitYP41_+3A_d">d</code></td>
<td>
<p>a vector containing the censoring indicators, 1-uncensored; 0-right censored.</p>
</td></tr>
<tr><td><code id="fitYP41_+3A_z">Z</code></td>
<td>
<p>a vector of covariates ...</p>
</td></tr>
<tr><td><code id="fitYP41_+3A_beta1">beta1</code></td>
<td>
<p>a scalar. short term</p>
</td></tr> 
<tr><td><code id="fitYP41_+3A_beta2">beta2</code></td>
<td>
<p>a scalar. long term</p>
</td></tr>
<tr><td><code id="fitYP41_+3A_maxiter">maxiter</code></td>
<td>
<p>an integer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to the function <code>fitYP4</code> except using a simple YP model (without alpha).
</p>


<h3>Value</h3>

<p>A list with the following components (may be I should also return the baseline?):
</p>
<table>
<tr><td><code>EmpLik</code></td>
<td>
<p>this is actually the log empirical likelihood value.</p>
</td></tr>
<tr><td><code>BaselineH</code></td>
<td>
<p> The baseline hazard estimate.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## find NPMLE of beta1 and beta2 in the simple YP model.
data(GastricCancer)
optim(par=c(1.5,-1.5), fn= myffitYP41, 
                       myY=GastricCancer[1,], 
					   myd=GastricCancer[2,], 
					   myZ=GastricCancer[4,])
</code></pre>

<hr>
<h2 id='GastricCancer'>Gastric Cancer Data</h2><span id='topic+GastricCancer'></span>

<h3>Description</h3>

<p>There are 90 observations on 4 variables.
Times is the survival times in years.
Status is the censoring status. 
ax is the covariate that satisfy proportional hazards assumptions. 
zo is the covariate that indicating the two treatments, which we suppose follow the Y-P model.
For more details please see the reference below.
</p>
<p>Data are from 
Ying, Z., Jung, SH, and Wei, LJ (1995). 
Median regression analysis with censored data.
Journal of the American Statistical Association,
90, 178-184.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(GastricCancer)</code></pre>


<h3>Format</h3>

<p>A data frame containing 90 observations on 4 variables:
</p>

<table>
<tr>
 <td style="text-align: right;">
        [,1] </td><td style="text-align: left;"> "times"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,2] </td><td style="text-align: left;"> "status"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,3] </td><td style="text-align: left;"> "ax"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,4] </td><td style="text-align: left;"> "zo"</td>
</tr>

</table>



<h3>References</h3>

<p>Ying, Z., Jung, SH, and Wei, LJ
(1995). Median regression analysis with censored data.
Journal of the American Statistical Association, 90, 178-184.
</p>

<hr>
<h2 id='myLLfun'> Compute Baseline Hazard for the Given Data and Parameters beta1, beta2, lam. 
Also Compute the empirical likelihood value. </h2><span id='topic+myLLfun'></span>

<h3>Description</h3>

<p>This function is similar to <code>fitYP3</code>. Just streamline input and output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>myLLfun(mle, dataMat, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="myLLfun_+3A_mle">mle</code></td>
<td>
<p>a vector of length 3, containing the parameter values: beta1, beta2 and lam. They do not have to be the MLE.</p>
</td></tr>
<tr><td><code id="myLLfun_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix of 4 by n. But the 4th row do not matter, since alpha=0 here always.</p>
</td></tr>
<tr><td><code id="myLLfun_+3A_fun">fun</code></td>
<td>
<p>a function, used in the definition of int f(t)dH(t)= Mulam.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We assume a Y-P model. and with the given parameters (in the input mle) we compute the baseline hazard and compute the (parameter constrained) empirical likelihood value.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Mulam</code></td>
<td>
<p> The value of int f(t) d H(t) for corresponding lam. Notice lam, beta1, beta2 determine the baseline H(t). </p>
</td></tr>
<tr><td><code>Loglik</code></td>
<td>
<p>The log empirical likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## censored regression with one right censored observation.
## we check the estimation equation, with the MLE inside myfun7. 
y &lt;- c(3, 5.3, 6.4, 9.1, 14.1, 15.4, 18.1, 15.3, 14, 5.8, 7.3, 14.4)
x &lt;- c(1, 1.5, 2,   3,   4,    5,    6,    5,    4,  1,   2,   4.5)
d &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)
</code></pre>

<hr>
<h2 id='myLLfun2'> Compute Baseline Hazard for the Given Data and Parameters beta1, beta2, alpha, lam. 
Also Compute the empirical likelihood value. </h2><span id='topic+myLLfun2'></span>

<h3>Description</h3>

<p>This function is similar to <code>fitYP3</code>. Just streamline input and output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>myLLfun2(mle, dataMat, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="myLLfun2_+3A_mle">mle</code></td>
<td>
<p>a vector of length 4, containing the parameter values beta1, beta2, alpha, and lam. They do not have to be MLE.</p>
</td></tr>
<tr><td><code id="myLLfun2_+3A_datamat">dataMat</code></td>
<td>
<p>a matrix of 4 by n. They are (Y d X Z).</p>
</td></tr>
<tr><td><code id="myLLfun2_+3A_fun">fun</code></td>
<td>
<p>a function, used in define the int f(t)dH(t)= Mulam.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We assume a Y-P model. 
Say something.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Mulam</code></td>
<td>
<p> The value of int f(t) d H(t) for corresponding lam. Notice lam, beta1, beta2 determine the baseline H(t). </p>
</td></tr>
<tr><td><code>Loglik</code></td>
<td>
<p>The log empirical likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## censored regression with one right censored observation.
## we check the estimation equation, with the MLE inside myfun7. 
y &lt;- c(3, 5.3, 6.4, 9.1, 14.1, 15.4, 18.1, 15.3, 14, 5.8, 7.3, 14.4)
x &lt;- c(1, 1.5, 2,   3,   4,    5,    6,    5,    4,  1,   2,   4.5)
d &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)
</code></pre>

<hr>
<h2 id='Pfun'> The Hazard Ratio in YP Model as a Function of beta1 beta2 and Mulam. </h2><span id='topic+Pfun'></span>

<h3>Description</h3>

<p>This function compute the hazard ratio, given beta1 beta2 and Mulam = int g(t) dH(t) .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pfun(b1, b2, Mulam)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pfun_+3A_b1">b1</code></td>
<td>
<p>a scalar, the parameter value.</p>
</td></tr>
<tr><td><code id="Pfun_+3A_b2">b2</code></td>
<td>
<p>a scalar, parameter.</p>
</td></tr>
<tr><td><code id="Pfun_+3A_mulam">Mulam</code></td>
<td>
<p> It is int f(t)dH(t)= Mulam.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Say something.
</p>


<h3>Value</h3>

<p>A scalar which is the hazard ratio.
</p>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## censored regression with one right censored observation.
## we check the estimation equation, with the MLE inside myfun7. 
y &lt;- c(3, 5.3, 6.4, 9.1, 14.1, 15.4, 18.1, 15.3, 14, 5.8, 7.3, 14.4)
x &lt;- c(1, 1.5, 2,   3,   4,    5,    6,    5,    4,  1,   2,   4.5)
d &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)
</code></pre>

<hr>
<h2 id='Pfun2'>The Hazard Ratio in YP Model as a Function of beta1, beta2, a, X, and Mulam. </h2><span id='topic+Pfun2'></span>

<h3>Description</h3>

<p>This function compute the hazard ratio based on a Yang-Prentice model, given beta1, beta2, a, X and Mulam = int g(t) dH(t).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pfun2(b1, b2, a, X, Mulam)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pfun2_+3A_b1">b1</code></td>
<td>
<p>parameter value. = short term hazard ratio</p>
</td></tr>
<tr><td><code id="Pfun2_+3A_b2">b2</code></td>
<td>
<p>parameter: long term hazard ratio.</p>
</td></tr>
<tr><td><code id="Pfun2_+3A_a">a</code></td>
<td>
<p>parameter</p>
</td></tr>
<tr><td><code id="Pfun2_+3A_x">X</code></td>
<td>
<p>covariate</p>
</td></tr>
<tr><td><code id="Pfun2_+3A_mulam">Mulam</code></td>
<td>
<p> it is int f(t)dH(t)= Mulam.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The flexibility also rest on the definition of Mulam: it can
using any f(t) function. If we use indicator I[ t &lt;= t0 ] then
Mulam is just the baseline cumulative hazard funtion at t0. Where do you define the Mulam? (in fitYP3....)
</p>


<h3>Value</h3>

<p>A scalar which is the hazard ratio.
</p>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Zhou, M. (2002). 
Computing censored empirical likelihood ratio 
by EM algorithm. 
<em>Tech Report, Univ. of Kentucky, Dept of Statistics</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## censored regression with one right censored observation.
## we check the estimation equation, with the MLE inside myfun7. 
y &lt;- c(3, 5.3, 6.4, 9.1, 14.1, 15.4, 18.1, 15.3, 14, 5.8, 7.3, 14.4)
x &lt;- c(1, 1.5, 2,   3,   4,    5,    6,    5,    4,  1,   2,   4.5)
d &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)
</code></pre>

<hr>
<h2 id='simuDataYP'> Generate random times that follow the YP model with the Given Parameters th1, th2, and alphaX. </h2><span id='topic+simuDataYP'></span>

<h3>Description</h3>

<p>This function is for simulations. It generates data from Yang-Prentice model with given/known parameters and may be 
used later to see
how well some estimation procedure works on them. th1 = exp(beta1), th2 = exp(beta2), alphaX = $a' X$.
There is always a covariate Z that indicates the two samples, and the hazards of the two treatments follows the
Yang&ndash;Prentice model. The baseline hazard of sample one (where Z=0) is taken to be exponential.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simuDataYP(n1, n2, th1, th2, cens, alphaX)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simuDataYP_+3A_n1">n1</code></td>
<td>
<p>sample size of first arm.</p>
</td></tr>
<tr><td><code id="simuDataYP_+3A_n2">n2</code></td>
<td>
<p>sample size of second arm.</p>
</td></tr>
<tr><td><code id="simuDataYP_+3A_th1">th1</code></td>
<td>
<p>the parameter of th1=exp(beta1). Short term.</p>
</td></tr>
<tr><td><code id="simuDataYP_+3A_th2">th2</code></td>
<td>
<p>the parameter of th2=exp(beta2). Long term. </p>
</td></tr>
<tr><td><code id="simuDataYP_+3A_cens">cens</code></td>
<td>
<p>logical, Either TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="simuDataYP_+3A_alphax">alphaX</code></td>
<td>
<p>a vector of length n1+n2. It is the inner product of alpha and covariates X....the part that is proportional hazards. 
This way, alpha can be p dimensional, However alpha times X is always a vector of length n1+n2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The hazard of the generated survival times, Y, have hazard function that is proportional to exp( alphaX ).
</p>
<p>The hazard of arm 1 is constant, just exp( alphaX ).
The hazard of arm 2 is given as
exp(alphaX) / [ 1/th1 S_0(t) +  1/th2 F_0(t) ]
</p>
<p>where S_0 and F_0 are survival function and CDF of a standard exponential random variable. 
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>Y</code></td>
<td>
<p> The survival times, possibly right censored. </p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The censoring status.</p>
</td></tr>
<tr><td><code>Zmat</code></td>
<td>
<p>the covariates used in generating random times.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Mai Zhou </p>


<h3>References</h3>

<p>Yang and Prientice. (2005). Semiparametric analysis of short term/long term hazard ratios with two sample survival data.
<em>Biometrika</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data and covariates.
X &lt;- -99:100/50        ## the covariate for alpha, 200 long
temp &lt;- simuDataYP(n1=100, n2=100, th1=exp(1), th2=exp(-1), cens=TRUE, alphaX = -0.5*X)
## this generate a sample of censored data with n=200. beta1=1, beta2=-1, alpha= -0.5.
## and the design matrix or covariance matrix is 
Zmat &lt;- cbind(X, temp$Zmat)
</code></pre>

<hr>
<h2 id='smallcell'>Smallcell Lung Cancer Data</h2><span id='topic+smallcell'></span>

<h3>Description</h3>

<p>There are 121 observations on 4 variables.
Arm is the indication of two treatments.
Entry is the age of the patient at entry.
Survival is the survival time and 
indicator is the censoring indicator (right censoring).
For more details please see the reference below.
</p>
<p>Data are from 
Ying, Z., Jung, SH, and Wei, LJ (1995). 
Median regression analysis with censored data.
Journal of the American Statistical Association,
90, 178-184.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(smallcell)</code></pre>


<h3>Format</h3>

<p>A data frame containing 121 observations on 4 variables:
</p>

<table>
<tr>
 <td style="text-align: right;">
        [,1] </td><td style="text-align: left;"> "arm"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,2] </td><td style="text-align: left;"> "entry"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,3] </td><td style="text-align: left;"> "survival"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,4] </td><td style="text-align: left;"> "indicator"</td>
</tr>

</table>



<h3>References</h3>

<p>Ying, Z., Jung, SH, and Wei, LJ
(1995). Median regression analysis with censored data.
Journal of the American Statistical Association, 90, 178-184.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
