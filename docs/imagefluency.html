<!DOCTYPE html><html lang="en"><head><title>Help for package imagefluency</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {imagefluency}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#imagefluency-package'><p>imagefluency: Image Statistics Based on Processing Fluency</p></a></li>
<li><a href='#.check_input'><p>.check_input</p></a></li>
<li><a href='#.compl'><p>.compl</p></a></li>
<li><a href='#.contr'><p>.contr</p></a></li>
<li><a href='#.selfsim'><p>.selfsim</p></a></li>
<li><a href='#.shift_axis'><p>.shift_axis</p></a></li>
<li><a href='#.sym'><p>.sym</p></a></li>
<li><a href='#.sym_mirror'><p>.sym_mirror</p></a></li>
<li><a href='#.typ'><p>.typ</p></a></li>
<li><a href='#img_complexity'><p>Image complexity</p></a></li>
<li><a href='#img_contrast'><p>Image contrast</p></a></li>
<li><a href='#img_read'><p>Read bitmap image (bmp, jpg, png, tiff)</p></a></li>
<li><a href='#img_self_similarity'><p>Image self-similarity</p></a></li>
<li><a href='#img_simplicity'><p>Image simplicity</p></a></li>
<li><a href='#img_symmetry'><p>Image symmetry</p></a></li>
<li><a href='#img_typicality'><p>Typicality of images relative to each other</p></a></li>
<li><a href='#rgb2gray'><p>RGB to Gray Conversion</p></a></li>
<li><a href='#rotate90'><p>Matrix or Array Rotation by 90 Degrees</p></a></li>
<li><a href='#run_imagefluency'><p>Run imagefluency app</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Image Statistics Based on Processing Fluency</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Get image statistics based on processing fluency theory. The
    functions provide scores for several basic aesthetic principles that
    facilitate fluent cognitive processing of images: contrast,
    complexity / simplicity, self-similarity, symmetry, and typicality.
    See Mayer &amp; Landwehr (2018) &lt;<a href="https://doi.org/10.1037%2Faca0000187">doi:10.1037/aca0000187</a>&gt; and Mayer &amp; Landwehr
    (2018) &lt;<a href="https://doi.org/10.31219%2Fosf.io%2Fgtbhw">doi:10.31219/osf.io/gtbhw</a>&gt; for the theoretical background of the methods.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://imagefluency.com">https://imagefluency.com</a>, <a href="https://github.com/stm/imagefluency/">https://github.com/stm/imagefluency/</a>,
<a href="https://doi.org/10.5281/zenodo.5614665">https://doi.org/10.5281/zenodo.5614665</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/stm/imagefluency/issues/">https://github.com/stm/imagefluency/issues/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>R.utils, readbitmap, pracma, magick, OpenImageR</td>
</tr>
<tr>
<td>Suggests:</td>
<td>grid, ggplot2, scales, shiny, testthat, mockery, knitr,
rmarkdown, furrr, future, pbmcapply, tictoc, dplyr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Collate:</td>
<td>'utils.R' 'complexity.R' 'contrast.R' 'imagefluency-package.R'
'imagefluencyApp.R' 'self-similarity.R' 'simplicity.R'
'symmetry.R' 'typicality.R'</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-20 18:38:36 UTC; stefan</td>
</tr>
<tr>
<td>Author:</td>
<td>Stefan Mayer <a href="https://orcid.org/0000-0003-0034-7090"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Stefan Mayer &lt;stefan@mayer-de.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-22 14:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='imagefluency-package'>imagefluency: Image Statistics Based on Processing Fluency</h2><span id='topic+imagefluency'></span><span id='topic+imagefluency-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Get image statistics based on processing fluency theory. The functions provide scores for several basic aesthetic principles that facilitate fluent cognitive processing of images: contrast, complexity / simplicity, self-similarity, symmetry, and typicality. See Mayer &amp; Landwehr (2018) doi: <a href="https://doi.org/10.1037/aca0000187">10.1037/aca0000187</a> and Mayer &amp; Landwehr (2018) doi: <a href="https://doi.org/10.31219/osf.io/gtbhw">10.31219/osf.io/gtbhw</a> for the theoretical background of the methods.
</p>


<h3>Details</h3>

<p><em>The main functions are:</em>
</p>

<ul>
<li> <p><code><a href="#topic+img_contrast">img_contrast</a></code> to get the visual contrast of an
image
</p>
</li>
<li> <p><code><a href="#topic+img_complexity">img_complexity</a></code> to get the visual complexity of
an image (equals 1 minus image simplicity)
</p>
</li>
<li> <p><code><a href="#topic+img_self_similarity">img_self_similarity</a></code> to get the visual
self-similarity of an image
</p>
</li>
<li> <p><code><a href="#topic+img_simplicity">img_simplicity</a></code> to get the visual simplicity
of an image (equals 1 minus image complexity)
</p>
</li>
<li> <p><code><a href="#topic+img_symmetry">img_symmetry</a></code> to get the vertical and
horizontal symmetry of an image
</p>
</li>
<li> <p><code><a href="#topic+img_typicality">img_typicality</a></code> to get the visual typicality
of a list of images relative to each other
</p>
</li></ul>

<p><em>Other helpful functions are:</em>
</p>

<ul>
<li> <p><code><a href="#topic+img_read">img_read</a></code> wrapper function
to read images using <code><a href="readbitmap.html#topic+read.bitmap">readbitmap::read.bitmap</a></code>
</p>
</li>
<li> <p><code><a href="#topic+run_imagefluency">run_imagefluency</a></code> to launch a Shiny app
for an interactive demo of the main functions
</p>
</li>
<li> <p><code><a href="#topic+rgb2gray">rgb2gray</a></code> to convert images from
RGB into grayscale
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Stefan Mayer <a href="mailto:stefan@mayer-de.com">stefan@mayer-de.com</a> (<a href="https://orcid.org/0000-0003-0034-7090">ORCID</a>)
</p>


<h3>References</h3>

<p>Mayer, S. &amp; Landwehr, J, R. (2018). Quantifying Visual Aesthetics
Based on Processing Fluency Theory: Four Algorithmic Measures for
Antecedents of Aesthetic Preferences. <em>Psychology of Aesthetics,
Creativity, and the Arts</em>, <em>12</em>(4), 399&ndash;431.
doi: <a href="https://doi.org/10.1037/aca0000187">10.1037/aca0000187</a>
</p>
<p>Mayer, S. &amp; Landwehr, J. R. (2018). Objective measures of design
typicality. <em>Design Studies</em>, <em>54</em>, 146&ndash;161.
doi: <a href="https://doi.org/10.31219/osf.io/gtbhw">10.31219/osf.io/gtbhw</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://imagefluency.com">https://imagefluency.com</a>
</p>
</li>
<li> <p><a href="https://github.com/stm/imagefluency/">https://github.com/stm/imagefluency/</a>
</p>
</li>
<li> <p>doi: <a href="https://doi.org/10.5281/zenodo.5614665">10.5281/zenodo.5614665</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/stm/imagefluency/issues/">https://github.com/stm/imagefluency/issues/</a>
</p>
</li></ul>


<hr>
<h2 id='.check_input'>.check_input</h2><span id='topic+.check_input'></span>

<h3>Description</h3>

<p><code>.check_input</code> is a helper function of the
<code>rquantae</code> package that checks whether the input is
a matrix of numeric or integer values. Error message are
thrown if that is not the case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.check_input(img, f_call = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".check_input_+3A_img">img</code></td>
<td>
<p>An object that needs to checked.</p>
</td></tr>
<tr><td><code id=".check_input_+3A_f_call">f_call</code></td>
<td>
<p>The name of the function inside which the
<code>.check_input</code> is called.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An error message if the check fails.
</p>

<hr>
<h2 id='.compl'>.compl</h2><span id='topic+.compl'></span>

<h3>Description</h3>

<p>Returns the complexity of an image array / matrix or path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.compl(img, algorithm, rotate)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".compl_+3A_img">img</code></td>
<td>
<p>An array or matrix of numeric values or integer values, or the file path to the image.</p>
</td></tr>
<tr><td><code id=".compl_+3A_algorithm">algorithm</code></td>
<td>
<p>character. Which compression algorithm to use.</p>
</td></tr>
<tr><td><code id=".compl_+3A_rotate">rotate</code></td>
<td>
<p>logical. Image rotation by 90 degrees?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value (ratio compressed/uncompressed file size).
</p>

<hr>
<h2 id='.contr'>.contr</h2><span id='topic+.contr'></span>

<h3>Description</h3>

<p>Returns the RMS contrast of an image matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.contr(img)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".contr_+3A_img">img</code></td>
<td>
<p>A matrix of numeric values or integer values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value (RMS contrast)
</p>

<hr>
<h2 id='.selfsim'>.selfsim</h2><span id='topic+.selfsim'></span>

<h3>Description</h3>

<p>Returns the self-similarity of an image matrix as the degree to which the slope of the log-log power spectrum falls with power according to the value of 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.selfsim(img, full, raw, logplot)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".selfsim_+3A_img">img</code></td>
<td>
<p>A matrix of numeric values or integer values, preferably
by square size.</p>
</td></tr>
<tr><td><code id=".selfsim_+3A_full">full</code></td>
<td>
<p>logical. Should the full frequency range be used for
interpolation?</p>
</td></tr>
<tr><td><code id=".selfsim_+3A_raw">raw</code></td>
<td>
<p>logical. Should the raw value of the regression slope be returned?</p>
</td></tr>
<tr><td><code id=".selfsim_+3A_logplot">logplot</code></td>
<td>
<p>logical. Should the log-log power spectrum of the image be
plotted?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value (self-similarity)
</p>

<hr>
<h2 id='.shift_axis'>.shift_axis</h2><span id='topic+.shift_axis'></span>

<h3>Description</h3>

<p>.shift_axis shifts the mirror axis by xrange and returns
the symmetries at each axis position by calling the
.sym_mirror function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.shift_axis(img, imgW, xrange)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".shift_axis_+3A_img">img</code></td>
<td>
<p>A matrix of numeric values or integer values.</p>
</td></tr>
<tr><td><code id=".shift_axis_+3A_imgw">imgW</code></td>
<td>
<p>Image width (numeric).</p>
</td></tr>
<tr><td><code id=".shift_axis_+3A_xrange">xrange</code></td>
<td>
<p>Shift range (numeric vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of mirror symmetry values
</p>

<hr>
<h2 id='.sym'>.sym</h2><span id='topic+.sym'></span>

<h3>Description</h3>

<p>Calculates the mirror symmetry of an
image by correlating image halves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.sym(img, color, per_channel = TRUE, shift_range = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".sym_+3A_img">img</code></td>
<td>
<p>A matrix of numeric values or integer values.</p>
</td></tr>
<tr><td><code id=".sym_+3A_color">color</code></td>
<td>
<p>logical. Color image?</p>
</td></tr>
<tr><td><code id=".sym_+3A_per_channel">per_channel</code></td>
<td>
<p>logical. Channel-wise maximum symmetry?</p>
</td></tr>
<tr><td><code id=".sym_+3A_shift_range">shift_range</code></td>
<td>
<p>numeric. Percentage of axis shift.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>one numeric value as the symmetry
</p>

<hr>
<h2 id='.sym_mirror'>.sym_mirror</h2><span id='topic+.sym_mirror'></span>

<h3>Description</h3>

<p>sym_mirror returns the mirror symmetry of a grayscale
image matrix. To this end, the left and right image
halves are correlated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.sym_mirror(img)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".sym_mirror_+3A_img">img</code></td>
<td>
<p>A matrix of numeric values or integer values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value between 0 and 1
</p>

<hr>
<h2 id='.typ'>.typ</h2><span id='topic+.typ'></span>

<h3>Description</h3>

<p>Returns the typicality of a list of images as the correlation with the mean image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.typ(imglist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".typ_+3A_imglist">imglist</code></td>
<td>
<p>A list of matrices with numeric values or
integer values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value (RMS contrast)
</p>

<hr>
<h2 id='img_complexity'>Image complexity</h2><span id='topic+img_complexity'></span>

<h3>Description</h3>

<p><code>img_complexity</code> returns the complexity of an image via image
compression. Higher values indicate higher image complexity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_complexity(imgfile, algorithm = "zip", rotate = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="img_complexity_+3A_imgfile">imgfile</code></td>
<td>
<p>Either a character string containing the path to the image
file (or URL) or an an image in form of a matrix (grayscale image) or array
(color image) of numeric values representing the pre-loaded image (e.g. by
using <code><a href="#topic+img_read">img_read</a>()</code>).</p>
</td></tr>
<tr><td><code id="img_complexity_+3A_algorithm">algorithm</code></td>
<td>
<p>Character string that specifies which image compression
algorithm to use. Currently implemented are <code>zip</code> with deflate
compression (default), <code>jpg</code>, <code>gif</code>, and <code>png</code>.</p>
</td></tr>
<tr><td><code id="img_complexity_+3A_rotate">rotate</code></td>
<td>
<p>logical. Should the compressed file size of the rotated image
also be computed? (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the visual complexity of an image. Visual
complexity is calculated as ratio between the compressed and uncompressed
image file size. Preferably, the original image is an uncompressed image
file.
</p>
<p>The function takes the file path of an image file (or URL) or a pre-loaded
image as input argument (<code>imgfile</code>) and returns the ratio of the
compressed divided by the uncompressed image file size. Values can range
between almost 0 (virtually completely compressed image, thus extremely
simple image) and 1 (no compression possible, thus extremely complex
image).
</p>
<p>You can choose between different image compression algorithms. Currently
implemented are <code>zip</code> with deflate compression (default), <code>jpg</code>,
<code>gif</code>, and <code>png</code>. See Mayer &amp; Landwehr (2018) for a discussion of
different image compression algorithms for measuring visual complexity.
</p>
<p>As most compression algorithms do not depict horizontal and vertical
redundancies equally, the function includes an optional <code>rotate</code>
parameter (default: <code>FALSE</code>). Setting this parameter to <code>TRUE</code>
has the following effects: first, the image is rotated by 90 degrees.
Second, a compressed version of the rotated image is created. Finally,
the overall compressed image's file size is computed as the minimum of
the original image's file size and the file size of the rotated image.
</p>
<p>As <code>R</code>'s built-in <code>bmp</code> device creates (a) indexed instead of
True Color images and (b) creates files with different file sizes depending
on the operating system, the function relies on the <code>magick</code> package
to write (and read) images.
</p>


<h3>Value</h3>

<p>a numeric value: the ratio of the compressed divided by the
uncompressed image file size
</p>


<h3>References</h3>

<p>Donderi, D. C. (2006). Visual complexity: A Review.
<em>Psychological Bulletin</em>, <em>132</em>, 73&ndash;97.
doi: <a href="https://doi.org/10.1037/0033-2909.132.1.73">10.1037/0033-2909.132.1.73</a>
</p>
<p>Forsythe, A., Nadal, M., Sheehy, N., Cela-Conde, C. J., &amp; Sawey,
M. (2011). Predicting Beauty: Fractal Dimension and Visual Complexity in
Art. <em>British Journal of Psychology</em>, <em>102</em>, 49&ndash;70.
doi: <a href="https://doi.org/10.1348/000712610X498958">10.1348/000712610X498958</a>
</p>
<p>Mayer, S. &amp; Landwehr, J, R. (2018). Quantifying Visual Aesthetics
Based on Processing Fluency Theory: Four Algorithmic Measures for
Antecedents of Aesthetic Preferences. <em>Psychology of Aesthetics,
Creativity, and the Arts</em>, <em>12</em>(4), 399&ndash;431.
doi: <a href="https://doi.org/10.1037/aca0000187">10.1037/aca0000187</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+img_read">img_read</a></code>, <code><a href="#topic+img_contrast">img_contrast</a></code>,
<code><a href="#topic+img_self_similarity">img_self_similarity</a></code>, <code><a href="#topic+img_simplicity">img_simplicity</a></code>,
<code><a href="#topic+img_symmetry">img_symmetry</a></code>, <code><a href="#topic+img_typicality">img_typicality</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example image with high complexity: trees
trees &lt;- img_read(system.file("example_images", "trees.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(trees)
#
# get complexity
img_complexity(trees)


# Example image with low complexity: sky
sky &lt;- img_read(system.file("example_images", "sky.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(sky)
#
# get complexity
img_complexity(sky)

</code></pre>

<hr>
<h2 id='img_contrast'>Image contrast</h2><span id='topic+img_contrast'></span>

<h3>Description</h3>

<p><code>img_contrast</code> returns the RMS contrast of an image <code>img</code>. A higher
value indicates higher contrast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_contrast(img)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="img_contrast_+3A_img">img</code></td>
<td>
<p>An image in form of a matrix or array of numeric values. Use e.g.
<code><a href="#topic+img_read">img_read</a>()</code> to read an image file into <code>R</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the RMS contrast of an image <code>img</code>. The
RMS contrast is defined as the standard deviation of the normalized pixel
intensity values. A higher value indicates higher contrast. The image is
automatically normalized if necessary (i.e., normalization into range [0,
1]).
</p>
<p>For color images, the weighted average between each color channel's values
is computed.
</p>


<h3>Value</h3>

<p>a numeric value (RMS contrast)
</p>


<h3>References</h3>

<p>Peli, E. (1990). Contrast in complex images. <em>Journal of the
Optical Society of America A</em>, <em>7</em>, 2032&ndash;2040.
doi: <a href="https://doi.org/10.1364/JOSAA.7.002032">10.1364/JOSAA.7.002032</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+img_read">img_read</a></code>, <code><a href="#topic+img_complexity">img_complexity</a></code>,
<code><a href="#topic+img_self_similarity">img_self_similarity</a></code>, <code><a href="#topic+img_simplicity">img_simplicity</a></code>,
<code><a href="#topic+img_symmetry">img_symmetry</a></code>, <code><a href="#topic+img_typicality">img_typicality</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example image with relatively high contrast: berries
berries &lt;- img_read(system.file("example_images", "berries.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(berries)
#
# get contrast
img_contrast(berries)

# Example image with relatively low contrast: bike
bike &lt;- img_read(system.file("example_images", "bike.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(bike)
#
# get contrast
img_contrast(bike)

</code></pre>

<hr>
<h2 id='img_read'>Read bitmap image (bmp, jpg, png, tiff)</h2><span id='topic+img_read'></span>

<h3>Description</h3>

<p>Wrapper for readbitmap's <code><a href="readbitmap.html#topic+read.bitmap">read.bitmap</a></code> function. The
function currently allows reading in images in <code>bmp</code>, <code>jpg</code> /
<code>jpeg</code>, <code>png</code>, or <code>tif</code> / <code>tiff</code> format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_read(path, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="img_read_+3A_path">path</code></td>
<td>
<p>Path to the image file.</p>
</td></tr>
<tr><td><code id="img_read_+3A_...">...</code></td>
<td>
<p>Additional parameters that are passed to
<code><a href="readbitmap.html#topic+read.bitmap">read.bitmap</a></code> and the underlying image reader
packages.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see the <code><a href="readbitmap.html#topic+read.bitmap">read.bitmap</a></code>
documentation.
</p>


<h3>Value</h3>

<p>Objects returned by <code><a href="bmp.html#topic+read.bmp">read.bmp</a></code>,
<code><a href="jpeg.html#topic+readJPEG">readJPEG</a></code>, <code><a href="png.html#topic+readPNG">readPNG</a></code>, or
<code><a href="tiff.html#topic+readTIFF">readTIFF</a></code>. See their documentation for details.
</p>


<h3>See Also</h3>

<p><code><a href="readbitmap.html#topic+read.bitmap">read.bitmap</a></code>, <code><a href="bmp.html#topic+read.bmp">read.bmp</a></code>,
<code><a href="jpeg.html#topic+readJPEG">readJPEG</a></code>, <code><a href="png.html#topic+readPNG">readPNG</a></code>,
<code><a href="tiff.html#topic+readTIFF">readTIFF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example image with high vertical symmetry: rails
rails &lt;- img_read(system.file("example_images", "rails.jpg", package = "imagefluency"))
</code></pre>

<hr>
<h2 id='img_self_similarity'>Image self-similarity</h2><span id='topic+img_self_similarity'></span>

<h3>Description</h3>

<p><code>img_self_similarity</code> returns the self-similarity of an image (i.e., the
degree to which the log-log power spectrum of the image falls with a slope of
-2). Higher values indicate higher image self-similarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_self_similarity(img, full = FALSE, logplot = FALSE, raw = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="img_self_similarity_+3A_img">img</code></td>
<td>
<p>An image in form of a matrix or array of numeric values,
preferably by square size. If the input is not square, bilinear resizing to
a square size is performed using the
<code><a href="OpenImageR.html#topic+resizeImage">OpenImageR</a></code> package. Use e.g.
<code><a href="#topic+img_read">img_read</a>()</code> to read an image file into <code>R</code>.</p>
</td></tr>
<tr><td><code id="img_self_similarity_+3A_full">full</code></td>
<td>
<p>logical. Should the full frequency range be used for
interpolation? (default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="img_self_similarity_+3A_logplot">logplot</code></td>
<td>
<p>logical. Should the log-log power spectrum of the image be
plotted? (default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="img_self_similarity_+3A_raw">raw</code></td>
<td>
<p>logical. Should the raw value of the regression slope be returned?
(default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function takes a (square) array or matrix of numeric or integer
values representing an image as input and returns the self-similarity of
the image. Self-similarity is computed via the slope of the log-log power
spectrum using OLS. A slope near <code>-2</code> indicates fractal-like
properties (see Redies et al., 2007; Simoncelli &amp; Olshausen, 2001). Thus,
value for self-similarity that is return by the function calculated as
<code>self-similarity = abs(slope + 2) * (-1)</code>. That is, the measure
reaches its maximum value of 0 for a slope of -2, and any deviation from -2
results in negative values that are more negative the higher the deviation
from -2. For color images, the weighted average between each color channel's
values is computed (cf. Mayer &amp; Landwehr 2018).
</p>
<p>Per default, only the frequency range betwen 10 and 256 cycles per image is
used for interpolation. Computation for the full range can be set via the
parameter <code>full = TRUE</code>.
</p>
<p>If <code>logplot</code> is set to <code>TRUE</code> then a log-log plot of the power
spectrum is additionally shown. If the package <code>ggplot2</code> is installed
the plot includes the slope of the OLS regression. Note that this option is
currently implemented for grayscale images.
</p>
<p>It is possible to get the raw regression slope (instead of the transformed
value which indicates self-similarity) by using the option <code>raw =
  TRUE</code>.
</p>
<p>For color images, the weighed average between each color channel's values
is computed.
</p>


<h3>Value</h3>

<p>a numeric value (self-similarity)
</p>


<h3>Note</h3>

<p>The function inspired by Matlab's sfPlot (by Diederick C. Niehorster).
</p>


<h3>References</h3>

<p>Mayer, S. &amp; Landwehr, J, R. (2018). Quantifying Visual Aesthetics
Based on Processing Fluency Theory: Four Algorithmic Measures for
Antecedents of Aesthetic Preferences. <em>Psychology of Aesthetics,
Creativity, and the Arts</em>, <em>12</em>(4), 399&ndash;431.
doi: <a href="https://doi.org/10.1037/aca0000187">10.1037/aca0000187</a>
</p>
<p>Redies, C., Hasenstein, J., &amp; Denzler, J. (2007). Fractal-like
image statistics in visual art: Similarity to natural scenes. <em>Spatial
Vision</em>, <em>21</em>, 137&ndash;148.
doi: <a href="https://doi.org/10.1163/156856807782753921">10.1163/156856807782753921</a>
</p>
<p>Simoncelli, E. P., &amp; Olshausen, B. A. (2001). Natural image
statistics and neural representation. <em>Annual Review of Neuroscience</em>,
<em>24</em>, 1193&ndash;1216.
doi: <a href="https://doi.org/10.1146/annurev.neuro.24.1.1193">10.1146/annurev.neuro.24.1.1193</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+img_read">img_read</a></code>, <code><a href="#topic+img_contrast">img_contrast</a></code>,
<code><a href="#topic+img_complexity">img_complexity</a></code>, <code><a href="#topic+img_simplicity">img_simplicity</a></code>,
<code><a href="#topic+img_symmetry">img_symmetry</a></code>, <code><a href="#topic+img_typicality">img_typicality</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example image with high self-similarity: romanesco
romanesco &lt;- img_read(system.file("example_images", "romanesco.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(romanesco)
#
# get self-similarity
img_self_similarity(romanesco)

# Example image with low self-similarity: office
office &lt;- img_read(system.file("example_images", "office.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(office)
#
# get self-similarity
img_self_similarity(office)

</code></pre>

<hr>
<h2 id='img_simplicity'>Image simplicity</h2><span id='topic+img_simplicity'></span>

<h3>Description</h3>

<p><code>img_simplicity</code> returns the simplicity of an image as 1 minus the
complexity of the image. Higher values indicated higher image simplicity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_simplicity(imgfile, algorithm = "zip", rotate = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="img_simplicity_+3A_imgfile">imgfile</code></td>
<td>
<p>Either a character string containing the path to the image
file (or URL) or an an image in form of a matrix (grayscale image) or array
(color image) of numeric values representing the pre-loaded image (e.g. by
using <code><a href="#topic+img_read">img_read</a>()</code>).</p>
</td></tr>
<tr><td><code id="img_simplicity_+3A_algorithm">algorithm</code></td>
<td>
<p>Character string that specifies which image compression
algorithm to use. Currently implemented are <code>zip</code> with deflate
compression, <code>jpg</code>, <code>gif</code>, and <code>png</code>.</p>
</td></tr>
<tr><td><code id="img_simplicity_+3A_rotate">rotate</code></td>
<td>
<p>logical. Should the compressed file size of the rotated image
also be computed? (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Image simplicity is calculated as 1 minus the ratio between the
compressed and uncompressed file size (i.e., the compression rate). Values
can range between 0 (no compression possible, thus extremely complex image)
and almost 1 (virtually completely compressed image, thus extremly simple
image). Different compression algorithms are implemented. For details, see
<code><a href="#topic+img_complexity">img_complexity</a></code>.
</p>


<h3>Value</h3>

<p>a numeric value: 1 minus the ratio of compressed divided by
uncompressed file size (i.e., the compression rate)
</p>


<h3>References</h3>

<p>Donderi, D. C. (2006). Visual complexity: A Review.
<em>Psychological Bulletin</em>, <em>132</em>, 73&ndash;97.
doi: <a href="https://doi.org/10.1037/0033-2909.132.1.73">10.1037/0033-2909.132.1.73</a>
</p>
<p>Forsythe, A., Nadal, M., Sheehy, N., Cela-Conde, C. J., &amp; Sawey,
M. (2011). Predicting Beauty: Fractal Dimension and Visual Complexity in
Art. <em>British Journal of Psychology</em>, <em>102</em>, 49&ndash;70.
doi: <a href="https://doi.org/10.1348/000712610X498958">10.1348/000712610X498958</a>
</p>
<p>Mayer, S. &amp; Landwehr, J, R. (2018). Quantifying Visual Aesthetics
Based on Processing Fluency Theory: Four Algorithmic Measures for
Antecedents of Aesthetic Preferences. <em>Psychology of Aesthetics,
Creativity, and the Arts</em>, <em>12</em>(4), 399&ndash;431.
doi: <a href="https://doi.org/10.1037/aca0000187">10.1037/aca0000187</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+img_read">img_read</a></code>, <code><a href="#topic+img_complexity">img_complexity</a></code>,
<code><a href="#topic+img_contrast">img_contrast</a></code>, <code><a href="#topic+img_self_similarity">img_self_similarity</a></code>,
<code><a href="#topic+img_symmetry">img_symmetry</a></code>, <code><a href="#topic+img_typicality">img_typicality</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example image with low simplicity: trees
trees &lt;- img_read(system.file("example_images", "trees.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(trees)
#
# get simplicity
img_simplicity(trees)

# Example image with high simplicity: sky
sky &lt;- img_read(system.file("example_images", "sky.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(sky)
#
# get simplicity
img_simplicity(sky)

</code></pre>

<hr>
<h2 id='img_symmetry'>Image symmetry</h2><span id='topic+img_symmetry'></span>

<h3>Description</h3>

<p><code>img_symmetry</code> returns the vertical and horizontal mirror symmetry of an
image. Higher values indicate higher image symmetry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_symmetry(img, vertical = TRUE, horizontal = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="img_symmetry_+3A_img">img</code></td>
<td>
<p>An image in form of a matrix or array of numeric values. Use e.g.
<code><a href="#topic+img_read">img_read</a>()</code> to read an image file into <code>R</code>.</p>
</td></tr>
<tr><td><code id="img_symmetry_+3A_vertical">vertical</code></td>
<td>
<p>logical. Should the vertical symmetry be computed? (default:
TRUE)</p>
</td></tr>
<tr><td><code id="img_symmetry_+3A_horizontal">horizontal</code></td>
<td>
<p>logical. Should the horizontal symmetry be computed?
(default: TRUE)</p>
</td></tr>
<tr><td><code id="img_symmetry_+3A_...">...</code></td>
<td>
<p>Further options: <code>shift_range</code> to shift the mirror axis,
<code>per_channel</code> to switch between a maximal per channel vs. per image
symmetry (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the vertical and horizontal mirror symmetry of
an image <code>img</code>. Symmetry values can range between 0 (not symmetrical)
and 1 (fully symmetrical). If <code>vertical</code> or <code>horizontal</code> is set
to <code>FALSE</code> then vertical or horizontal symmetry is not computed,
respectively.
</p>
<p>As the perceptual mirror axis is not necessarily exactly in the middle of a
picture, the function estimates in a first step several symmetry values
with different positions for the mirror axis. To this end, the mirror axis
is automatically shifted up to 5% (default) of the image width to the left
and to the right (in the case of vertical symmetry; analogously for
horizontal symmetry). In the second step, the overall symmetry score is
computed as the maximum of the symmetry scores given the different mirror
axes. See Mayer &amp; Landwehr (2018) for details.
</p>
<p>Advanced users can change the shift range with the optional parameter
<code>shift_range</code>, which takes a numeric decimal as input. The default
<code>shift_range = 0.05</code> (i.e., 5%).
</p>
<p>For color images, the default is that first a maximal symmetry score (as
explained above) is obtained per color channel (parameter <code>per_channel
  = TRUE</code>). Subsequently, a weighted average between each color channel's
maximal score is computed as the image's overall symmetry. Advanced users
can reverse this order by setting <code>per_channel = FALSE</code>. This results
in first computing the weighted averages for each position of the mirror
axis separately, and afterwards finding the maximal overall symmetry score.
</p>


<h3>Value</h3>

<p>a named vector of numeric values (vertical and horizontal symmetry)
</p>


<h3>References</h3>

<p>Mayer, S. &amp; Landwehr, J, R. (2018). Quantifying Visual Aesthetics
Based on Processing Fluency Theory: Four Algorithmic Measures for
Antecedents of Aesthetic Preferences. <em>Psychology of Aesthetics,
Creativity, and the Arts</em>, <em>12</em>(4), 399&ndash;431.
doi: <a href="https://doi.org/10.1037/aca0000187">10.1037/aca0000187</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+img_read">img_read</a></code>, <code><a href="#topic+img_complexity">img_complexity</a></code>,
<code><a href="#topic+img_contrast">img_contrast</a></code>, <code><a href="#topic+img_self_similarity">img_self_similarity</a></code>
<code><a href="#topic+img_simplicity">img_simplicity</a></code>, <code><a href="#topic+img_typicality">img_typicality</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example image with high vertical symmetry: rails
rails &lt;- img_read(system.file("example_images", "rails.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(rails)
#
# get symmetry
img_symmetry(rails)

# Example image with low vertical symmetry: bridge
bridge &lt;- img_read(system.file("example_images", "bridge.jpg", package = "imagefluency"))
#
# display image
grid::grid.raster(bridge)
#
# get symmetry
img_symmetry(bridge)

</code></pre>

<hr>
<h2 id='img_typicality'>Typicality of images relative to each other</h2><span id='topic+img_typicality'></span>

<h3>Description</h3>

<p><code>img_typicality</code> returns the visual typicality of a list of images
relative to each other. Higher values indicate larger typicality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_typicality(imglist, rescale = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="img_typicality_+3A_imglist">imglist</code></td>
<td>
<p>A <em>list</em> of arrays or matrices with numeric values. Use
e.g. <code><a href="#topic+img_read">img_read</a>()</code> to read image files into <code>R</code> (see
example).</p>
</td></tr>
<tr><td><code id="img_typicality_+3A_rescale">rescale</code></td>
<td>
<p>numeric. Rescales the images prior to computing the typicality
scores (per default no rescaling is performed). Rescaling is performed by
<code>OpenImageR</code>'s <code><a href="OpenImageR.html#topic+resizeImage">resizeImage</a></code> function
(bilinear rescaling)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the visual typicality of a <em>list</em> of image
arrays or matrices <code>imglist</code> relative to each other. Values can range
between -1 (inversely typical) over 0 (not typical) to 1 (perfectly typical).
That is, higher absolute values indicate a larger typicality.
</p>
<p>The typicality score is computed as the correlation of a particular image
with the average representation of all images, i.e. the mean of all images.
For color images, the weighted average between each color channel's values
is computed. If the images have different dimensions they are automatically
resized to the smallest height and width.
</p>
<p>Rescaling of the images prior to computing the typicality scores can be
specified with the optional rescaling parameter (must be a numeric value).
Most users won't need any rescaling and can use the default (<code>rescale
  = NULL</code>). See Mayer &amp; Landwehr (2018) for more details.
</p>


<h3>Value</h3>

<p>a named matrix of numeric values (typicality scores)
</p>


<h3>References</h3>

<p>Mayer, S. &amp; Landwehr, J. R. (2018). Objective measures of design
typicality. <em>Design Studies</em>, <em>54</em>, 146&ndash;161.
doi: <a href="https://doi.org/10.1016/j.destud.2017.09.004">10.1016/j.destud.2017.09.004</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+img_read">img_read</a></code>, <code><a href="#topic+img_contrast">img_contrast</a></code>,
<code><a href="#topic+img_complexity">img_complexity</a></code>, <code><a href="#topic+img_self_similarity">img_self_similarity</a></code>
<code><a href="#topic+img_simplicity">img_simplicity</a></code>, <code><a href="#topic+img_symmetry">img_symmetry</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example images depicting valleys: valley_green, valley_white
# Example image depicting fireworks: fireworks
valley_green &lt;- img_read(
    system.file("example_images", "valley_green.jpg", package = "imagefluency")
  )
valley_white &lt;- img_read(
    system.file("example_images", "valley_white.jpg", package = "imagefluency")
  )
fireworks &lt;- img_read(
    system.file("example_images", "fireworks.jpg", package = "imagefluency")
  )
#
# display images
grid::grid.raster(valley_green)
grid::grid.raster(valley_white)
grid::grid.raster(fireworks)

# create image set as list
imglist &lt;- list(fireworks, valley_green, valley_white)

# get typicality
img_typicality(imglist)

</code></pre>

<hr>
<h2 id='rgb2gray'>RGB to Gray Conversion</h2><span id='topic+rgb2gray'></span>

<h3>Description</h3>

<p><code>rgb2gray</code> transforms colors from RGB space
(red/green/blue) into an matrix of grayscale values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgb2gray(img)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgb2gray_+3A_img">img</code></td>
<td>
<p>3-dimensional array of numeric or integer
values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function takes a 3-dimensional array of
numeric or integer values as input (<code>img</code>) and
returns a matrix of grayscale values as output. The
grayscale values are computed as <code>GRAY = 0.2989 *
  RED + 0.5870 * GREEN + 0.1140 * BLUE</code>. If the array has
a fourth dimension (i.e., alpha channel), the fourth
dimension is ignored.
</p>


<h3>Value</h3>

<p>A matrix of grayscale values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct a sample RGB image as array of random integers
imgRed &lt;- matrix(runif(100, min = 0, max = 255), 10, 10)
imgGreen &lt;- matrix(runif(100, min = 0, max = 255), 10, 10)
imgBlue &lt;- matrix(runif(100, min = 0, max = 255), 10, 10)
imgColor &lt;- array(c(imgRed, imgGreen, imgBlue), dim = c(10, 10, 3))

# convert to gray
img &lt;- rgb2gray(imgColor)
</code></pre>

<hr>
<h2 id='rotate90'>Matrix or Array Rotation by 90 Degrees</h2><span id='topic+rotate90'></span>

<h3>Description</h3>

<p>Matrix or Array Rotation by 90 Degrees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rotate90(img, direction = "positive")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rotate90_+3A_img">img</code></td>
<td>
<p>an array or a matrix</p>
</td></tr>
<tr><td><code id="rotate90_+3A_direction">direction</code></td>
<td>
<p>The direction of rotation by 90 degrees.
The value can be <code>"positive"</code> (default) or
<code>"negative"</code>. Aliases are
<code>"counterclockwise"</code> and <code>"clockwise"</code>,
respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function takes an array or matrix as input
object (<code>img</code>) and returns the object rotated by
90 degrees. Per default, the rotation is done in the
mathematically positive direction (i.e.,
counterclockwise). Clockwise rotation (i.e.,
mathematically negative) can be specified by passing
the value <code>"negative"</code> to the <code>direction</code>
argument.
</p>


<h3>Value</h3>

<p>an array or a matrix (rotated by 90 degrees)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># sample matrix
img &lt;- matrix(1:6, ncol = 2)
img

rotate90(img) # counterclockwise
rotate90(img, direction = "negative") # clockwise
</code></pre>

<hr>
<h2 id='run_imagefluency'>Run imagefluency app</h2><span id='topic+run_imagefluency'></span>

<h3>Description</h3>

<p>Launches a Shiny app that shows a demo of what can be done with
the <code>imagefluency</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_imagefluency()
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Only run this example in interactive R sessions
if (interactive()) {
  run_imagefluency()
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
