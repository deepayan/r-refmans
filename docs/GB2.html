<!DOCTYPE html><html><head><title>Help for package GB2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GB2}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Compound'>
<p>Compound Distribution based on the Generalized Beta Distribution of the Second Kind</p></a></li>
<li><a href='#CompoundAuxDensPlot'>
<p>Comparison of the compound GB2 and kernel densities by group</p></a></li>
<li><a href='#CompoundAuxFit'>
<p>Fitting the Compound Distribution based on the GB2 by the Method of Pseudo Maximum Likelihood Estimation using Auxiliary Information</p></a></li>
<li><a href='#CompoundAuxVarest'>
<p>Variance Estimation under the Compound GB2 Distribution Using Auxiliary Information</p></a></li>
<li><a href='#CompoundDensPlot'>
<p>Comparison of the GB2, compound GB2 and kernel densities</p></a></li>
<li><a href='#CompoundFit'>
<p>Fitting the Compound Distribution based on the GB2 by the Method of Maximum Likelihood Estimation</p></a></li>
<li><a href='#CompoundIndicators'><p>Indicators of Poverty and Social Exclusion under the Compound Distribution based on the GB2</p></a></li>
<li><a href='#CompoundMoments'>
<p>Moments of the Compound Distribution based on the GB2</p></a></li>
<li><a href='#CompoundQuantiles'>
<p>Quantiles and random generation of the Compound Distribution based on the GB2</p></a></li>
<li><a href='#CompoundVarest'>
<p>Variance Estimation of the Compound GB2 Distribution</p></a></li>
<li><a href='#Contindic'>
<p>Sensitivity Analysis of Laeken Indicators on GB2 Parameters</p></a></li>
<li><a href='#Contprof'>
<p>Contour Plot of the Profile Log-likelihood of the GB2 Distribution</p></a></li>
<li><a href='#Fisk'>
<p>Parameters of the Fisk Distribution</p></a></li>
<li><a href='#gb2'><p>The Generalized Beta Distribution of the Second Kind</p></a></li>
<li><a href='#Gini'>
<p>Computation of the Gini Coefficient for the GB2 Distribution and its Particular Cases.</p></a></li>
<li><a href='#Indicators'><p>Monetary Laeken Indicators under the GB2</p></a></li>
<li><a href='#LogDensity'>
<p>Log Density of the GB2 Distribution</p></a></li>
<li><a href='#LogLikelihood'>
<p>Full Log-likelihood of the GB2 Distribution</p></a></li>
<li><a href='#MLfitGB2'>
<p>Fitting the GB2 by the Method of Maximum Likelihood Estimation and Comparison of the Fitted Indicators with the Empirical Indicators</p></a></li>
<li><a href='#MLfullGB2'>
<p>Maximum Likelihood Estimation of the GB2 Based on the Full Log-likelihood</p></a></li>
<li><a href='#MLprofGB2'>
<p>Maximum Likelihood Estimation of the GB2 Based on the Profile Log-likelihood</p></a></li>
<li><a href='#Moments'>
<p>Moments and Other Properties of a GB2 Random Variable</p></a></li>
<li><a href='#NonlinearFit'>
<p>Fitting the GB2 by Minimizing the Distance Between a Set of Empirical Indicators and Their GB2 Expressions</p></a></li>
<li><a href='#PlotsML'>
<p>Cumulative Distribution Plot and Kernel Density Plot for the Fitted GB2</p></a></li>
<li><a href='#ProfLogLikelihood'>
<p>Profile Log-likelihood of the GB2 Distribution</p></a></li>
<li><a href='#RobustWeights'>
<p>Robustification of the sampling weights</p></a></li>
<li><a href='#Thomae'><p>Maximum Excess Representation of a Generalized Hypergeometric Function Using Thomae's Theorem</p></a></li>
<li><a href='#Varest'>
<p>Variance Estimation of the Parameters of the GB2 Distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-05-01</td>
</tr>
<tr>
<td>Title:</td>
<td>Generalized Beta Distribution of the Second Kind: Properties,
Likelihood, Estimation</td>
</tr>
<tr>
<td>Author:</td>
<td>Monique Graf &lt;monique.p.n.graf@bluewin.ch&gt;, Desislava Nedyalkova &lt;desislava.nedyalkova@gmail.com&gt;.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Desislava Nedyalkova &lt;desislava.nedyalkova@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cubature, hypergeo, laeken, numDeriv, stats, survey</td>
</tr>
<tr>
<td>Suggests:</td>
<td>simFrame</td>
</tr>
<tr>
<td>Description:</td>
<td>Package GB2 explores the Generalized Beta distribution of the second kind. Density, cumulative distribution function, quantiles and moments of the distributions are given. Functions for the full log-likelihood, the profile log-likelihood and the scores are provided. Formulas for various indicators of inequality and poverty under the GB2 are implemented. The GB2 is fitted by the methods of maximum pseudo-likelihood estimation using the full and profile log-likelihood, and non-linear least squares estimation of the model parameters. Various plots for the visualization and analysis of the results are provided. Variance estimation of the parameters is provided for the method of maximum pseudo-likelihood estimation. A mixture distribution based on the compounding property of the GB2 is presented (denoted as "compound" in the documentation). This mixture distribution is based on the discretization of the distribution of the underlying random scale parameter. The discretization can be left or right tail. Density, cumulative distribution function, moments and quantiles for the mixture distribution are provided. The compound mixture distribution is fitted using the method of maximum pseudo-likelihood estimation. The fit can also incorporate the use of auxiliary information. In this new version of the package, the mixture case is complemented with new functions for variance estimation by linearization and comparative density plots. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-22 05:38:15 UTC; hornik</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-22 05:53:16 UTC</td>
</tr>
</table>
<hr>
<h2 id='Compound'>
Compound Distribution based on the Generalized Beta Distribution of the Second Kind
</h2><span id='topic+Compound'></span><span id='topic+fg.cgb2'></span><span id='topic+dl.cgb2'></span><span id='topic+pl.cgb2'></span><span id='topic+dcgb2'></span><span id='topic+pcgb2'></span><span id='topic+prcgb2'></span>

<h3>Description</h3>

<p>Mixture distribution based on the compounding property of the GB2, in short &quot;compound GB2&quot;. Decomposition of the GB2 distribution with respect to the left and right tail of the distribution. Calculation of the component densities and cumulative distribution functions. 
Calculation of the compound density function and the compound cumulative distribution function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fg.cgb2(x, shape1, scale, shape2, shape3, pl0, decomp="r")
dl.cgb2(x, shape1, scale, shape2, shape3, pl0, decomp="r") 
pl.cgb2(y, shape1, scale, shape2, shape3, pl0, decomp="r", tol=1e-05)
dcgb2(x, shape1, scale, shape2, shape3, pl0, pl, decomp="r")
pcgb2(y, shape1, scale, shape2, shape3, pl0, pl, decomp="r")
prcgb2(y1, y2, shape1, scale, shape2, shape3, pl0, pl, decomp="r", tol=1e-08, 
debug=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Compound_+3A_x">x</code></td>
<td>
<p>numeric; can be a vector. The value(s) at which the compound density and the component densities are calculated, <code>x</code> is positive.</p>
</td></tr>
<tr><td><code id="Compound_+3A_y">y</code></td>
<td>
<p>numeric; can be a vector. The value(s) at which the compound distribution function and the component distribution functions are calculated.</p>
</td></tr>
<tr><td><code id="Compound_+3A_y1">y1</code>, <code id="Compound_+3A_y2">y2</code></td>
<td>
<p>numeric values.</p>
</td></tr>
<tr><td><code id="Compound_+3A_shape1">shape1</code>, <code id="Compound_+3A_scale">scale</code>, <code id="Compound_+3A_shape2">shape2</code>, <code id="Compound_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the GB2 distribution.</p>
</td></tr>
<tr><td><code id="Compound_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="Compound_+3A_pl">pl</code></td>
<td>
<p>numeric; a vector of fitted proportions. Sums to one. If <code>pl</code> is equal to <code>pl0</code>, we obtain the GB2 distribution.</p>
</td></tr>
<tr><td><code id="Compound_+3A_decomp">decomp</code></td>
<td>
<p>string; specifying if the decomposition of the GB2 is done with respect to the right tail (&quot;r&quot;) or the left tail (&quot;l&quot;) of the distribution.
By default, <code>decomp</code> = &quot;r&quot; - right tail decomposition.</p>
</td></tr>
<tr><td><code id="Compound_+3A_debug">debug</code></td>
<td>
<p>logical; By default, <code>debug = FALSE</code>.</p>
</td></tr>
<tr><td><code id="Compound_+3A_tol">tol</code></td>
<td>
<p>numeric; tolerance with default 0, meaning to iterate until additional terms do not change the partial sum.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of components <code class="reqn">L</code> is given by the length of the vector <code>pl0</code>. In our examples <code class="reqn">L=3</code>. Let <code class="reqn">N</code> denote the length of the vector <code>x</code>. Function <code>fg.cgb2</code> calculates the <code class="reqn">L</code> gamma factors which multiply the GB2 density in order to obtain the component density <code class="reqn">f_\ell</code>. These component densities are calculated using the function <code>dl.cgb2</code>. Function <code>pl.cgb2</code> calculates the corresponding <code class="reqn">L</code> cumulative component distribution functions. Function <code>dcgb2</code> calculates the resulting compound density function. Function <code>pcgb2</code> calculates the compound cumulative distribution function for a vector of values <code>y</code> and function <code>prcgb2</code>, given  2 arguments <code>y1</code> and <code>y2</code>, calculates the probability <code class="reqn">P(min(y1,y2) &lt; Y &lt; max(y1,y2))</code>, where the random variable <code class="reqn">Y</code> follows a compound GB2 distribution.
</p>


<h3>Value</h3>

<p><code>fg.cgb2</code> returns a matrix of size <code class="reqn">N \times L</code> of the Gamma factors, <code>dl.cgb2</code> returns a matrix of size <code class="reqn">N \times L</code> of component densities, <code>pl.cgb2</code> returns a matrix containing the <code class="reqn">L</code> component cdfs, <code>dcgb2</code> returns a matrix of size <code class="reqn">N \times 1</code> of the GB2 compound density function, <code>pcgb2</code> returns a matrix of size <code class="reqn">N \times 1</code> of the GB2 compound distribution function and <code>prcgb2</code> returns a probability between 0 and 1.  
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>References</h3>

<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#\dontrun{

#\library{cubature}

# GB2 parameters
af &lt;- 5
bf &lt;- 20000
pf &lt;- 0.45 
qf &lt;- 0.75

p0 &lt;- rep(1/3,3)
p1 &lt;- c(0.37,0.43,0.2)

# a vector of values
x &lt;- rep(20000*seq(1,2,length.out=9))

#Gamma components
fg.cgb2(20000,af,bf,pf,qf,p0)
fg.cgb2(Inf,af,bf,pf,qf,p0,"l")

#Component densities
dl.cgb2(x,af,bf,pf,qf,p0)
dl.cgb2(20000,af,bf,pf,qf,p0,"l")

#Component cdf
pl.cgb2(25000,af,bf,pf,qf,p0)

#Compound cdf
pcgb2(x,af,bf,pf,qf,p0,p1)
prcgb2(37000,38000,af,bf,pf,qf,p0,p1,"l")
#}
</code></pre>

<hr>
<h2 id='CompoundAuxDensPlot'>
Comparison of the compound GB2 and kernel densities by group
</h2><span id='topic+CompoundAuxDensPlot'></span><span id='topic+dplot.cavgb2'></span>

<h3>Description</h3>

<p>Function <code>dplot.cavgb2</code> produces a plot in which the compound and kernel (Epanechnikov) densities are plotted by group. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dplot.cavgb2(group, x, shape1, scale, shape2, shape3, pl0, pl, w=rep(1,length(x)), 
xmax = max(x)*(2/3), ymax=2e-05, decomp="r", choicecol=1:length(levels(group)), 
xlab="") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundAuxDensPlot_+3A_group">group</code></td>
<td>
<p>numeric; a factor variable giving the group membership of each sampled unit.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_x">x</code></td>
<td>
<p>numeric; can be a vector. The value(s) at which the density is calculated, used for the kernel estimate only. <code>x</code> is positive. </p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_shape1">shape1</code>, <code id="CompoundAuxDensPlot_+3A_scale">scale</code>, <code id="CompoundAuxDensPlot_+3A_shape2">shape2</code>, <code id="CompoundAuxDensPlot_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the GB2 distribution. On the plot they are denotes as <code>a</code>, <code>b</code>, <code>p</code>, <code>q</code> and <code>pl0</code> respectively.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_pl">pl</code></td>
<td>
<p>numeric; a vector of fitted proportions (output of <code><a href="#topic+pkl.cavgb2">pkl.cavgb2</a></code>). Sums to one. If <code>pl</code> is equal to <code>pl0</code>, we obtain the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_w">w</code></td>
<td>
<p>numeric; weights.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_xmax">xmax</code></td>
<td>
<p>numeric; scale on the horizontal axis. By default is equal to <code class="reqn">max(x)*(2/3)</code>.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_ymax">ymax</code></td>
<td>
<p>numeric; scale on the vertical axis. By default is equal to 2e-05.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_decomp">decomp</code></td>
<td>
<p>string; specifying if the decomposition of the GB2 is done with respect to the right tail (&quot;r&quot;) or the left tail (&quot;l&quot;) of the distribution. By default, <code>decomp</code> = &quot;r&quot; - right tail decomposition.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_choicecol">choicecol</code></td>
<td>
<p>numeric vector of length the number of groups; defines the color with which the density curves will be plotted for each group.</p>
</td></tr>
<tr><td><code id="CompoundAuxDensPlot_+3A_xlab">xlab</code></td>
<td>
<p>string; label for <code class="reqn">x</code>. The default is &quot; &quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The legend is placed interactively.  
</p>


<h3>Value</h3>

<p><code>dplot.cavgb2</code> plots a graph with two curves - the GB2 density, the compound GB2 per group and the corresponding kernel estimate.  
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>

<hr>
<h2 id='CompoundAuxFit'>
Fitting the Compound Distribution based on the GB2 by the Method of Pseudo Maximum Likelihood Estimation using Auxiliary Information
</h2><span id='topic+CompoundAuxFit'></span><span id='topic+pkl.cavgb2'></span><span id='topic+lambda0.cavgb2'></span><span id='topic+logl.cavgb2'></span><span id='topic+scores.cavgb2'></span><span id='topic+ml.cavgb2'></span>

<h3>Description</h3>

<p>Calculates the log-likelihood, the score functions of the log-likelihood and fits the compound distribution based on the GB2 and using auxiliary information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pkl.cavgb2(z, lambda)
lambda0.cavgb2(pl0, z, w=rep(1, dim(z)[1]))
logl.cavgb2(fac, z, lambda, w=rep(1, dim(fac)[1]))
scores.cavgb2(fac, z, lambda, w=rep(1, dim(fac)[1]))
ml.cavgb2(fac, z, lambda0, w = rep(1, dim(fac)[1]), maxiter = 100, fnscale=length(w)) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundAuxFit_+3A_z">z</code></td>
<td>
<p>numeric; a matrix of auxiliary variables.</p>
</td></tr>
<tr><td><code id="CompoundAuxFit_+3A_lambda">lambda</code></td>
<td>
<p>numeric; a matrix of parameters.</p>
</td></tr>
<tr><td><code id="CompoundAuxFit_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundAuxFit_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights of length the number of rows of the matrix <code>fac</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="CompoundAuxFit_+3A_fac">fac</code></td>
<td>
<p>numeric; a matrix of Gamma factors.</p>
</td></tr>
<tr><td><code id="CompoundAuxFit_+3A_lambda0">lambda0</code></td>
<td>
<p>numeric; a matrix of initial parameters.</p>
</td></tr>
<tr><td><code id="CompoundAuxFit_+3A_maxiter">maxiter</code></td>
<td>
<p>numeric; maximum number of iterations to perform. By default <code>maxiter</code> = 100.</p>
</td></tr>
<tr><td><code id="CompoundAuxFit_+3A_fnscale">fnscale</code></td>
<td>
<p>numeric; parameter of the <code><a href="stats.html#topic+optim">optim</a></code> function. By default <code>fnscale</code> is equal to the lenth of the vector of weights (value of <code>fnscale</code> in 
the preceding version of the package). Permits to solve some convergence problems (see <code><a href="stats.html#topic+optim">optim</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We model the probabilities <code class="reqn">p_\ell</code> with auxiliary variables. Let <code class="reqn">z_k</code> denote the vector of auxiliary information for unit <code class="reqn">k</code>. This auxiliary information modifies the probabilities <code class="reqn">p_\ell</code> at the unit level. Denote by <code class="reqn">p_{k,\ell}</code> the weight of the density <code class="reqn">f_\ell</code> for unit <code class="reqn">k</code>. For <code class="reqn">\ell=1,...,L-1</code>, we pose a linear model for the log-ratio <code class="reqn">v_{k,\ell}</code>:
</p>
<p style="text-align: center;"><code class="reqn">\log(p_{k,\ell}/p_{k,L}) = v_{k,\ell} =\sum_{i=1}^I \lambda_{\ell i} z_{k i}= \mathbf{z}_k^{T} \boldsymbol{\lambda_{\ell}}.</code>
</p>
 
<p>Function <code>pkl.cavgb2</code> calculates the <code class="reqn">p_{k,\ell}</code>. Function <code>lambda0.cavgb2</code> calculates the initial values <code class="reqn">\lambda_{\ell i}</code>, <code class="reqn">i= 1, ..., I</code>, <code class="reqn">\ell = 1, ..., L-1</code> . Let </p>
<p style="text-align: center;"><code class="reqn">\bar{z}_{i}=\sum_k w_k z_{ki}/\sum_k w_k</code>
</p>
<p> be the mean value of the <code class="reqn">i</code>-th explanatory variable. 
Writing </p>
<p style="text-align: center;"><code class="reqn">\log(\hat{p}^{(0)}_\ell / \hat{p}^{(0)}_L)=v^{(0)}_\ell = \sum_{i=1}^I \lambda^{(0)}_{\ell i} \bar{z}_{i},</code>
</p>
<p> we can choose <code class="reqn">\lambda^{(0)}_{\ell i}= v^{(0)}_\ell / (I \bar{z}_{i}).</code> Analogically to the ordinary fit of the compound distribution based on the GB2 <code><a href="#topic+CompoundFit">CompoundFit</a></code>, we express the log-likelihood as a weighted mean of <code class="reqn">log(f) = log(\sum(p_{k,\ell} f_\ell(x_k))</code>, evaluated at the data points, where <code class="reqn">f</code> is the GB2 compound density.
The scores are obtained as the weighted sums of the first derivatives of the log-likelihood, with respect to the parameters <code class="reqn">\lambda_\ell, \ \ell=1, ..., L-1</code>, evaluated at the data points. 
Function <code>ml.cavgb2</code> performs maximum likelihood estimation through the general-purpose optimization function <code>optim</code> from package <code>stats</code>. 
The considered method of optimization is &quot;BFGS&quot; (<code><a href="stats.html#topic+optim">optim</a></code>). Once we have the fitted parameters <code class="reqn">\hat{\lambda}</code> we can deduce the fitted parameters <code class="reqn">\hat{v{k\ell}}</code> and 
<code class="reqn">\hat{p_{k\ell}}</code> in function of <code class="reqn">\bar{z}</code> and <code class="reqn">\hat{\lambda}_{\ell}</code>.
</p>


<h3>Value</h3>

<p><code>pkl.cavgb2</code> returns a matrix of probabilities. <code>lambda0.cavgb2</code> returns a matrix of size <code class="reqn">I \times L-1</code>. 
<code>logl.cavgb2</code> returns the value of the pseudo log-likelihood. 
<code>scores.cavgb2</code> returns the weighted sum of the scores of the log-likelihood.
<code>ml.cavgb2</code> returns a list containing two objects - the vector of fitted coefficients <code class="reqn">\hat{\lambda_\ell}</code> and the output of the &quot;BFGS&quot; fit.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

library(simFrame)
data(eusilcP)

# Stratified cluster sampling
set.seed(12345)
srss &lt;- SampleControl(design = "region", grouping = "hid", size = c(200*3, 1095*3, 1390*3,
 425*3, 820*3, 990*3, 400*3, 450*3, 230*3), k = 1)

# Draw a sample
s1 &lt;- draw(eusilcP,srss)
#names(s1)

# Creation of auxiliary variables
ind &lt;- order(s1[["hid"]])
ss1 &lt;- data.frame(hid=s1[["hid"]], region=s1[["region"]], hsize=s1[["hsize"]], 
peqInc=s1[["eqIncome"]], age=s1[["age"]], pw=s1[[".weight"]])[ind,]
ss1[["child"]] &lt;- as.numeric((ss1[["age"]]&lt;=14))
ss1[["adult"]] &lt;- as.numeric((ss1[["age"]]&gt;=20))
sa &lt;- aggregate(ss1[,c("child","adult")],list(ss1[["hid"]]),sum)
names(sa)[1] &lt;- "hid"
sa[["children"]] &lt;- as.numeric((sa[["child"]]&gt;0))
sa[["single_a"]] &lt;- as.numeric((sa[["adult"]]==1))
sa[["sa.ch"]] &lt;- sa[["single_a"]]*sa[["children"]]
sa[["ma.ch"]] &lt;- (1-sa[["single_a"]])*sa[["children"]]
sa[["nochild"]] &lt;- 1-sa[["children"]]

# New data set
ns &lt;- merge(ss1[,c("hid","region","hsize","peqInc","pw")], 
sa[,c("hid","nochild","sa.ch","ma.ch")], by="hid")

# Ordering the data set
ns &lt;- ns[!is.na(ns$peqInc),]
index &lt;- order(ns$peqInc)
ns &lt;- ns[index,]

# 	Truncate at 0
ns &lt;- ns[ns$peqInc&gt;0,]
# income
peqInc &lt;- ns$peqInc
# weights
pw &lt;- ns$pw             

# Adding the weight adjustment
c1 &lt;- 0.1                                
pwa &lt;- robwts(peqInc,pw,c1,0.001)[[1]]        
corr &lt;- mean(pw)/mean(pwa)              
pwa &lt;- pwa*corr  

ns &lt;- data.frame(ns, aw=pwa) 

# Empirical indicators with original weights
emp.ind &lt;- c(main.emp(peqInc, pw),
              main.emp(peqInc[ns[["nochild"]]==1], pw[ns[["nochild"]]==1]),
              main.emp(peqInc[ns[["sa.ch"]]==1], pw[ns[["sa.ch"]]==1]),
              main.emp(peqInc[ns[["ma.ch"]]==1], pw[ns[["ma.ch"]]==1]))

# Matrix of auxiliary variables
z &lt;- ns[,c("nochild","sa.ch","ma.ch")]
#unique(z)
z &lt;- as.matrix(z)

# global GB2 fit, ML profile log-likelihood
gl.fit &lt;- profml.gb2(peqInc,pwa)$opt1
agl.fit &lt;- gl.fit$par[1]
bgl.fit &lt;- gl.fit$par[2]
pgl.fit &lt;- prof.gb2(peqInc,agl.fit,bgl.fit,pwa)[3]
qgl.fit &lt;- prof.gb2(peqInc,agl.fit,bgl.fit,pwa)[4]

# Likelihood and convergence
proflikgl &lt;- -gl.fit$value
convgl &lt;- gl.fit$convergence

# Fitted GB2 parameters and indicators
profgb2.par &lt;- c(agl.fit, bgl.fit, pgl.fit, qgl.fit)
profgb2.ind &lt;- main.gb2(0.6, agl.fit, bgl.fit, pgl.fit, qgl.fit)

# Initial lambda and pl
pl0 &lt;- c(0.2,0.6,0.2)
lambda0 &lt;- lambda0.cavgb2(pl0, z, pwa)

# left decomposition
decomp &lt;- "l"
facgl &lt;- fg.cgb2(peqInc, agl.fit, bgl.fit, pgl.fit, qgl.fit, pl0 ,decomp)
fitcml &lt;- ml.cavgb2(facgl, z, lambda0, pwa, maxiter=500) 
fitcml
convcl &lt;- fitcml[[2]]$convergence
convcl
lambdafitl &lt;- fitcml[[1]]
pglfitl &lt;-  pkl.cavgb2(diag(rep(1,3),lambdafitl)
row.names(pglfitl) &lt;- colnames(z)

## End(Not run)
</code></pre>

<hr>
<h2 id='CompoundAuxVarest'>
Variance Estimation under the Compound GB2 Distribution Using Auxiliary Information
</h2><span id='topic+CompoundAuxVarest'></span><span id='topic+scoreU.cavgb2'></span><span id='topic+scorez.cavgb2'></span><span id='topic+varscore.cavgb2'></span><span id='topic+desvar.cavgb2'></span><span id='topic+hess.cavgb2'></span><span id='topic+vepar.cavgb2'></span><span id='topic+veind.cavgb2'></span>

<h3>Description</h3>

<p>Calculation of variance estimates of the parameters of the compound GB2 distribution and of the estimated compound GB2 indicators under a complex survey design (see package <code><a href="MASS.html#topic+survey">survey</a></code>).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreU.cavgb2(fac, z, lambda) 
scorez.cavgb2(U,z)
varscore.cavgb2(SC, w=rep(1,dim(SC)[1]))
desvar.cavgb2(data=data, SC=SC, ids=NULL, probs=NULL, strata = NULL, variables = NULL,
fpc=NULL, nest = FALSE, check.strata = !nest, weights=NULL, pps=FALSE, 
variance=c("HT","YG"))
hess.cavgb2(U, P, z, w=rep(1, dim(z)[1]))
vepar.cavgb2(ml, Vsc, hess)
veind.cavgb2(group, vepar, shape1, scale, shape2, shape3, pl0, P, decomp="r")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundAuxVarest_+3A_fac">fac</code></td>
<td>
<p>numeric; a matrix of Gamma factors.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_z">z</code></td>
<td>
<p>numeric; a matrix of auxiliary variables.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_lambda">lambda</code></td>
<td>
<p>numeric; a matrix of parameters.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_u">U</code></td>
<td>
<p>numeric; a matrix of scores <code class="reqn">U_{k,\ell}</code> (output of the <code>scoreU.cavgb2</code> function).</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_sc">SC</code></td>
<td>
<p>numeric; scores, output of <code>scorez.cavgb2</code>.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_w">w</code></td>
<td>
<p>numeric; vector of extrapolation weights. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_data">data</code></td>
<td>
<p>dataset containing the design information per unit</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_ids">ids</code>, <code id="CompoundAuxVarest_+3A_probs">probs</code>, <code id="CompoundAuxVarest_+3A_strata">strata</code>, <code id="CompoundAuxVarest_+3A_variables">variables</code>, <code id="CompoundAuxVarest_+3A_fpc">fpc</code>, <code id="CompoundAuxVarest_+3A_nest">nest</code>, <code id="CompoundAuxVarest_+3A_check.strata">check.strata</code>, <code id="CompoundAuxVarest_+3A_weights">weights</code>, <code id="CompoundAuxVarest_+3A_pps">pps</code>, <code id="CompoundAuxVarest_+3A_variance">variance</code></td>
<td>
<p>parameters of <code><a href="survey.html#topic+svydesign">svydesign</a></code>.</p>
</td></tr>

<tr><td><code id="CompoundAuxVarest_+3A_p">P</code></td>
<td>
<p>numeric; matrix of mixture probabilities (output of <code>pkl.cavgb2</code>).</p>
</td></tr>

<tr><td><code id="CompoundAuxVarest_+3A_ml">ml</code></td>
<td>
<p>numeric; estimated values of the vector of v's. Output of the <code>ml.cavgb2</code> function (the second element in the list).</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_vsc">Vsc</code></td>
<td>
<p>numeric; 4 by 4 matrix. Variance of the scores <code>SC</code>, computed in <code>varscore.cavgb2</code> or with the design information in <code><a href="#topic+desvar.cavgb2">desvar.cavgb2</a></code>.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_hess">hess</code></td>
<td>
<p>numeric; Hessian (bread) for the sandwich variance estimate (output of <code>hess.cavgb2</code>).</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_group">group</code></td>
<td>
<p>numeric; a factor variable of the same length as the sample size giving the group membership in the special case when the auxiliary information defines group membership.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_vepar">vepar</code></td>
<td>
<p>numeric; output of <code>vepar.cavgb2</code>.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_shape1">shape1</code>, <code id="CompoundAuxVarest_+3A_scale">scale</code>, <code id="CompoundAuxVarest_+3A_shape2">shape2</code>, <code id="CompoundAuxVarest_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundAuxVarest_+3A_decomp">decomp</code></td>
<td>
<p>string; specifying if the decomposition of the GB2 is done with respect to the right tail (&quot;r&quot;) or the left tail (&quot;l&quot;) of the distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">N \times L</code> matrix of fitted mixture probabilities <code>P</code><code class="reqn">=(p_{k,\ell})</code> depends on the <code class="reqn">N \times I</code> matrix <code>z</code> of auxiliary variables. 
<code>P</code> has as many distinct rows as there are distinct rows in <code>z</code>. The <code class="reqn">N \times L</code> matrix  of gamma factors <code>fac</code><code class="reqn">=F</code>, output of <code>fg.cgb2</code> depends on the vector of initial 
probabilities <code class="reqn">p_{0,\ell}</code> only. The <code class="reqn">N \times (L-1)</code> matrix of scores <code>U</code> is defined as </p>
<p style="text-align: center;"><code class="reqn">U(k,\ell)=p_{k,\ell} \left( \frac{F(k,\ell)}{\sum_{j=1}^L p_{k,j}\, F(k,j)} - 1\right).</code>
</p>
 
<p>The linearized scores are the columns of a <code class="reqn">N \times I(L-1)</code> matrix </p>
<p style="text-align: center;"><code class="reqn">SC(k,\,I(\ell-1)+i)= U(k,\ell) \,  z(k,i).</code>
</p>
 
<p>Function <code>varscore.cavgb2</code> calculates the middle term of the sandwich variance estimator, that is the <code class="reqn">(I(L-1) \times I(L-1))</code> estimated variance-covariance matrix of the <code class="reqn">I(L-1)</code>
weighted sums of  the columns of <code class="reqn">SC</code>, without design information. 
<code>desvar.cavgb2</code> calculates the design-based variance-covariance matrix of the <code class="reqn">I(L-1)</code> weighted sums of the columns of <code class="reqn">SC</code>, invoking <code>svydesign</code> and <code>svytotal</code> of package <code><a href="MASS.html#topic+survey">survey</a></code>. 
<code>hess.cavgb2</code> calculates the Hessian (<code class="reqn">I(L-1) \times I(L-1)</code> matrix of second derivatives of the pseudo-log-likelihood with respect to the parameters). It should be negative definite. 
If not, the maximum likelihood estimates are spurious. <code>vepar.cavgb2</code> calculates the sandwich variance estimate of the vectorized matrix of parameters <code>lambda</code>.
<code>veind.cavgb2</code> calculates estimates, std error, covariance and correlation matrices of the indicators under the compound GB2 with auxiliary variables in the particular 
case where the unique combinations of the auxiliary variables define a small number of groups. Group membership is specified by the vector <code>group</code> of length <code class="reqn">N</code>.
</p>


<h3>Value</h3>

<p><code>scoreU.cavgb2</code> returns a <code class="reqn">N \times (L-1)</code> matrix of scores <code>U</code>. 
<code>scorez.cavgb2</code> returns a <code class="reqn">N \times I(L-1)</code> matrix whose columns are the linearized scores <code>SC</code>. 
<code>varscore.cavgb2</code> returns the variance-covariance estimate of the weighted sums of scores <code>SC</code>, given by weighted cross products. 
<code>desvar.cavgb2</code> returns a list of two elements. The first is the output of svytotal and the second is the design-based variance-covariance matrix of the 
weighted sums of the scores SC. 
<code>hess.cavgb2</code> returns the matrix of second derivatives of the likelihood with respect to the parameters (bread for the sandwich variance estimate). 
<code>vepar.cavgb2</code> returns a list of five elements - [[&quot;type&quot;]] with value &quot;parameter&quot;, [[&quot;estimate&quot;]] estimated parameters, [[&quot;stderr&quot;]] corresponding standard errors, [[&quot;Vcov&quot;]] variance -covariance matrix and [[&quot;Vcor&quot;]] - correlation matrix. 
<code>veind.cavgb2</code> returns a list of five elements: [[&quot;type&quot;]] with value &quot;indicator&quot;, followed by a list with as many arguments as <code>length(levels(group))</code>. Each argument is itself a list with 5
arguments: [[&quot;group&quot;]] group name, [[&quot;estimate&quot;]] estimated indicators under the compound GB2, [[&quot;stderr&quot;]] corresponding standard errors, [[&quot;Vcov&quot;]] variance -covariance matrix and [[&quot;Vcor&quot;]] - correlation matrix.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>References</h3>

<p>Davison, A. (2003),
<em>Statistical Models</em>.
Cambridge University Press.
</p>
<p>Freedman, D. A. (2006),
On The So-Called &quot;Huber Sandwich Estimator&quot; and &quot;Robust Standard Errors&quot;.
<em>The American Statistician</em>, <b>60</b>, 299&ndash;302.
</p>
<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>
<p>Pfeffermann, D. and Sverchkov, M. Yu. (2003),
Fitting Generalized Linear Models under Informative Sampling.
In, Skinner, C.J. and Chambers, R.L. (eds.). 
<em>Analysis of Survey Data</em>, chapter 12, 175&ndash;195.
Wiley, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example (following of example in CompoundAuxFit)

# Scores U 
U &lt;- scoreU.cavgb2(facgl, z, lambdafitl)

# Scores multiplied by z
SC &lt;- scorez.cavgb2(U,z)

# Naive variance estimate of sum of scores
(Vsc &lt;- varscore.cavgb2(SC,w=pwa))

# Design based variance of sum of scores
(desv &lt;- desvar.cavgb2(data=ns,SC=SC,id=~hid,strata=~region,weights=~pwa))

# Hessian
hess &lt;- hess.cavgb2(U,pglfitl,z,w=pwa) 

# 1. Sandwich variance-covariance matrix estimate of parameters using Vsc:
Param1 &lt;- vepar.cavgb2(fitcml,Vsc, hess)
Param1

# 2. Sandwich variance-covariance matrix estimate of parameters using 
# the design variance:
Param2 &lt;- vepar.cavgb2(fitcml,desv$Vtheta, hess)
Param2 

# 3. Indicators and conditional variances : takes a long time!
(Indic &lt;- veind.cavgb2(group,Param2 ,agl.fit,bgl.fit,pgl.fit,qgl.fit, 
                       pl0, pglfitl, decomp="l") )

## End(Not run)
</code></pre>

<hr>
<h2 id='CompoundDensPlot'>
Comparison of the GB2, compound GB2 and kernel densities
</h2><span id='topic+CompoundDensPlot'></span><span id='topic+dplot.cgb2'></span>

<h3>Description</h3>

<p>Function <code>dplot.cgb2</code> produces a plot in which the three densities are plotted. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dplot.cgb2(x,shape1, scale, shape2, shape3, pl0, pl, w=rep(1,length(x)), decomp="r", 
xmax = max(x)*(2/3), choicecol=1:3, kernel="epanechnikov", adjust=1, title=NULL,
ylim=NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundDensPlot_+3A_x">x</code></td>
<td>
<p>numeric; can be a vector. The value(s) at which the density is calculated, used for the kernel estimate only. <code>x</code> is positive. </p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_shape1">shape1</code>, <code id="CompoundDensPlot_+3A_scale">scale</code>, <code id="CompoundDensPlot_+3A_shape2">shape2</code>, <code id="CompoundDensPlot_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the GB2 distribution. On the plot they are denotes as <code>a</code>, codeb, <code>p</code>, <code>q</code> and <code>pl0</code> respectively.</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_pl">pl</code></td>
<td>
<p>numeric; a vector of mixture probabilities (output of <code><a href="#topic+ml.cgb2">ml.cgb2</a></code>). Sums to one. If <code>pl</code> is equal to <code>pl0</code>, we obtain the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_w">w</code></td>
<td>
<p>numeric; weights.</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_decomp">decomp</code></td>
<td>
<p>string; specifying if the decomposition of the GB2 is done with respect to the right tail (&quot;r&quot;) or the left tail (&quot;l&quot;) of the distribution. By default, <code>decomp</code> = &quot;r&quot; - right tail decomposition.</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_xmax">xmax</code></td>
<td>
<p>numeric; maximum <code>x</code> value to be plotted.</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_choicecol">choicecol</code></td>
<td>
<p>numeric vector of length 3; defines the color with which the density curves will be plotted.</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_adjust">adjust</code></td>
<td>
<p>numeric; graphical parameter of the generic function <code><a href="stats.html#topic+density">density</a></code>.</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_title">title</code></td>
<td>
<p>string; title of the plot. By default is equall to NULL (no title).</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_ylim">ylim</code></td>
<td>
<p>string; scaling of parameters. By default is equall to NULL (automatic scaling).</p>
</td></tr>
<tr><td><code id="CompoundDensPlot_+3A_kernel">kernel</code></td>
<td>
<p>string; the kernel used for the kernel density estimate. The default value is  &quot;Epanechnikov&quot; (see <code><a href="stats.html#topic+plot.density">plot.density</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The legend is placed interactively.  
</p>


<h3>Value</h3>

<p><code>dplot.cgb2</code> plots a graph with three curves - the GB2 density, the compound GB2 density and the corresponding kernel estimate  
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>

<hr>
<h2 id='CompoundFit'>
Fitting the Compound Distribution based on the GB2 by the Method of Maximum Likelihood Estimation
</h2><span id='topic+CompoundFit'></span><span id='topic+vofp.cgb2'></span><span id='topic+pofv.cgb2'></span><span id='topic+logl.cgb2'></span><span id='topic+scores.cgb2'></span><span id='topic+ml.cgb2'></span>

<h3>Description</h3>

<p>Calculates the log-likelihood, the score functions of the log-likelihood, the weighted mean of scores, and fits the parameters of the Compound Distribution based on the GB2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vofp.cgb2(pl)
pofv.cgb2(vl)
logl.cgb2(fac, pl, w=rep(1, dim(fac)[1]))
scores.cgb2(fac, pl, w=rep(1, dim(fac)[1]))
ml.cgb2(fac, pl0, w=rep(1, dim(fac)[1]), maxiter=100, fnscale=length(w)) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundFit_+3A_pl0">pl0</code></td>
<td>
<p>numeric; vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundFit_+3A_pl">pl</code></td>
<td>
<p>numeric; vector of fitted proportions. Sums to one. If <code>pl</code> is equal to <code>pl0</code>, we obtain the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundFit_+3A_fac">fac</code></td>
<td>
<p>numeric; matrix of Gamma factors (output of <code>fac.cgb2</code>.</p>
</td></tr>
<tr><td><code id="CompoundFit_+3A_vl">vl</code></td>
<td>
<p>numeric; vector of parameters. Its length is equal to the length of <code>pl</code> - 1.</p>
</td></tr>
<tr><td><code id="CompoundFit_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights of length the number of rows of the matrix <code>fac</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="CompoundFit_+3A_maxiter">maxiter</code></td>
<td>
<p>numeric; maximum number of iterations to perform. By default <code>maxiter</code> = 100.</p>
</td></tr>
<tr><td><code id="CompoundFit_+3A_fnscale">fnscale</code></td>
<td>
<p>numeric; an overall scaling parameter used in the function <code><a href="stats.html#topic+optim">optim</a></code>. By default it is equal to the length of the vector of weights <code>w</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are only <code class="reqn">L-1</code> parameters to estimate, because the probabilities <code class="reqn">p_\ell</code> sum to 1 (L is the dimension of the vector of probailities <code class="reqn">p_\ell</code>). Knowing this, we change the parameters <code class="reqn">p_\ell</code> to <code class="reqn">v_\ell=log(p_\ell/p_L), \ \ell= 1, ..., L-1</code>. This calculation is done through the function <code>vofp.cgb2</code>. <code>pofv.cgb2</code> calculates the <code class="reqn">p_\ell</code> in function of the given <code class="reqn">v_\ell</code>.
We express the log-likelihood as a weighted mean of <code class="reqn">log(f) = log(\sum(p_\ell f_\ell)</code>, evaluated at the data points, where <code class="reqn">f</code> is the GB2 compound density. If the weights are not available, then we suppose that <code>w</code> <code class="reqn">= 1</code>. Analogically, the scores are obtained as weighted sums of the first derivatives of the log-likelihood, with respect to the parameters <code class="reqn">v_\ell, \ \ell=1, ..., L-1</code>, evaluated at the data points.  Function <code>ml.cgb2</code> performs maximum likelihood estimation through the general-purpose optimization function <code>optim</code> from package <code>stats</code>. The considered method of optimization is BFGS.
</p>


<h3>Value</h3>

<p><code>vofp.cgb2</code> returns a vector of length <code class="reqn">L-1</code>, where <code class="reqn">L</code> is the length of the vector <code class="reqn">p_\ell</code>. 
<code>pofv.cgb2</code> returns a vector of length <code class="reqn">\ell</code>. 
<code>logl.cgb2</code> returns the value of the pseudo log-likelihood. 
<code>scores.cgb2</code> returns a vector of the weighted mean of the scores of length <code class="reqn">L-1</code>. 
<code>ml.cgb2</code> returns a list containing two objects - the vector of fitted proportions <code class="reqn">\hat{p_\ell}</code> and the output of the BFGS fit.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# GB2 parameters:
a &lt;- 4
b &lt;- 1950
p &lt;- 0.8
q &lt;- 0.6

# Proportions defining the component densities:
pl0 &lt;- rep(1/3,3)

# Mixture probabilities
pl &lt;- c(0.1,0.8,0.1)

# Random generation:
n &lt;- 10000
set.seed(12345)
x &lt;- rcgb2(n,a,b,p,q,pl0,pl,decomp="l")

# Factors in component densities
fac &lt;- fg.cgb2(x,a,b,p,q, pl0,decomp="l")

# Estimate the mixture probabilities:
estim &lt;- ml.cgb2(fac,pl0)

# estimated mixture probabilities:
estim[[1]]
#[1] 0.09724319 0.78415797 0.11859883

## End(Not run)
</code></pre>

<hr>
<h2 id='CompoundIndicators'>Indicators of Poverty and Social Exclusion under the Compound Distribution based on the GB2
</h2><span id='topic+CompoundIndicators'></span><span id='topic+arpt.cgb2'></span><span id='topic+arpr.cgb2'></span><span id='topic+rmpg.cgb2'></span><span id='topic+qsr.cgb2'></span><span id='topic+main.cgb2'></span>

<h3>Description</h3>

<p>Functions to calculate four primary social welfare indicators under the compound GB2 distribution, i.e. the at-risk-of-poverty threshold,
the at-risk-of-poverty rate, the relative median at-risk-of-poverty gap, and the income quintile share ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arpt.cgb2(prop, shape1, scale, shape2, shape3, pl0, pl, decomp="r")
arpr.cgb2(prop, shape1, shape2, shape3, pl0, pl, decomp="r")
rmpg.cgb2(arpr, shape1, shape2, shape3, pl0, pl, decomp="r")
qsr.cgb2(shape1, shape2, shape3, pl0, pl, decomp="r")
main.cgb2(prop, shape1, scale, shape2, shape3, pl0, pl, decomp="r")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundIndicators_+3A_prop">prop</code></td>
<td>
<p>numeric; proportion (in general is set to 0.6).</p>
</td></tr>
<tr><td><code id="CompoundIndicators_+3A_arpr">arpr</code></td>
<td>
<p>numeric; the value of the at-risk-of-poverty rate.</p>
</td></tr>
<tr><td><code id="CompoundIndicators_+3A_shape1">shape1</code>, <code id="CompoundIndicators_+3A_scale">scale</code>, <code id="CompoundIndicators_+3A_shape2">shape2</code>, <code id="CompoundIndicators_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundIndicators_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundIndicators_+3A_pl">pl</code></td>
<td>
<p>numeric; a vector of mixture probabilities. Sums to one. If <code class="reqn">pl=pl0</code> we obtain the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundIndicators_+3A_decomp">decomp</code></td>
<td>
<p>string; specifying if the decomposition of the GB2 is done with respect to the right tail (&quot;r&quot;) or the left tail (&quot;l&quot;) of the distribution.
By default, <code>decomp</code> = &quot;r&quot; - right tail decomposition.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The four indicators are described in details in the case of the GB2. The difference here is that we need to give an initial vector of proportions, fitted proportions and define for which decomposition (left or right) the indicators should be calculated.
</p>


<h3>Value</h3>

<p><code>arpt.cgb2</code> gives the ARPT, <code>arpr.cgb2</code> the ARPR, <code>rmpg.cgb2</code> the RMPG, <code>qsr.cgb2</code> gives the QSR and <code>main.cgb2</code> calculates
the median, the mean, the ARPR, the RMPG and the QSR under the compound GB2.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>


<h3>See Also</h3>

<p><code>arpr.gb2</code> for details on the welfare indicators under the GB2.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># GB2 parameters
a &lt;- 3.9
b &lt;- 18873
p &lt;- 0.97
q &lt;- 1.03

# Proportions defining the component densities
p0 &lt;- rep(1/3,3)

# Mixture probabilities
pl &lt;- c(0.39,0.26,0.35)

# for the right discretization
arpt &lt;- arpt.cgb2(0.6, a, b, p, q, p0, pl)
arpr &lt;- arpr.cgb2(0.6, a, p, q, p0, pl)
rmpg &lt;- rmpg.cgb2(arpr, a, p, q, p0, pl)
qsr &lt;- qsr.cgb2(a, p, q, p0, pl)

# for the left discretization
arptleft &lt;- arpt.cgb2(0.6, a, b, p, q, p0, pl, "l")
</code></pre>

<hr>
<h2 id='CompoundMoments'>
Moments of the Compound Distribution based on the GB2
</h2><span id='topic+mkl.cgb2'></span><span id='topic+moment.cgb2'></span><span id='topic+incompl.cgb2'></span>

<h3>Description</h3>

<p>These functions calculate the moment of order <code>k</code> and incomplete moment of order <code>k</code> of a GB2 compound random variable <code class="reqn">X</code> as well as the moment of order <code>k</code> for each component density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mkl.cgb2(k, shape1, scale, shape2, shape3, pl0, decomp="r")
moment.cgb2(k, shape1, scale, shape2 ,shape3, pl0, pl, decomp="r")
incompl.cgb2(x, k, shape1, scale, shape2, shape3, pl0, pl, decomp="r")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundMoments_+3A_x">x</code></td>
<td>
<p>numeric; vector of quantiles.</p>
</td></tr>
<tr><td><code id="CompoundMoments_+3A_k">k</code></td>
<td>
<p>numeric; order of the moment.</p>
</td></tr>
<tr><td><code id="CompoundMoments_+3A_shape1">shape1</code>, <code id="CompoundMoments_+3A_scale">scale</code>, <code id="CompoundMoments_+3A_shape2">shape2</code>, <code id="CompoundMoments_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundMoments_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundMoments_+3A_pl">pl</code></td>
<td>
<p>numeric; a vector of mixture probabilities. Sums to one. If <code class="reqn">pl=pl0</code> we obtain the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundMoments_+3A_decomp">decomp</code></td>
<td>
<p>string; specifying if the decomposition of the GB2 is done with respect to the right tail (&quot;r&quot;) or the left tail (&quot;l&quot;) of the distribution.
By default, <code>decomp</code> = &quot;r&quot; - right tail decomposition.</p>
</td></tr>
</table>


<h3>Value</h3>

 
<p><code>mkl.cgb2</code> returns a vector of the moments of the component densities, <code>moment.cgb2</code> returns the moment of order <code>k</code> and <code>incompl.cgb2</code> - the incomplete moment of order <code>k</code>.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#\dontrun{

#\library{cubature}

# GB2 parameters
af &lt;- 5
bf &lt;- 20000
pf &lt;- 0.45 
qf &lt;- 0.75

p0 &lt;- rep(1/3,3)
p1 &lt;- c(0.37,0.43,0.2)

# moments for the component densities
mkl.cgb2(1,af,bf,pf,qf,p0)
mkl.cgb2(-1,af,bf,pf,qf,p0,"l")

#Moment of order k
moment.cgb2(0.5,af,bf,pf,qf,p0,p1)
moment.cgb2(0.5,af,bf,pf,qf,p0,p1,"l")

#Incomplete moment of order k
incompl.cgb2(20000,1,af,bf,pf,qf,p0,p1)
incompl.cgb2(20000,1,af,bf,pf,qf,p0,p1,"l")
#}
</code></pre>

<hr>
<h2 id='CompoundQuantiles'>
Quantiles and random generation of the Compound Distribution based on the GB2
</h2><span id='topic+CompoundQuantiles'></span><span id='topic+qcgb2'></span><span id='topic+rcgb2'></span>

<h3>Description</h3>

<p>Calculation of the quantiles of a compound GB2 random variable. Random generation of compound GB2 variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qcgb2(prob, shape1, scale, shape2, shape3, pl0, pl, decomp="r", tol=1e-08, ff=1.5, 
debug=FALSE, maxiter=50)
rcgb2(n, shape1, scale, shape2, shape3, pl0, pl, decomp="r", tol=1e-02, maxiter=100,
debug = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundQuantiles_+3A_prob">prob</code></td>
<td>
<p>numeric; vector of probabilities between 0 and 1.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_shape1">shape1</code>, <code id="CompoundQuantiles_+3A_scale">scale</code>, <code id="CompoundQuantiles_+3A_shape2">shape2</code>, <code id="CompoundQuantiles_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_n">n</code></td>
<td>
<p>numeric; number of observations. If <code>length(n) &gt; 1</code>, the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_pl">pl</code></td>
<td>
<p>numeric; a vector of mixture probabilities. Sums to one. If <code class="reqn">pl=pl0</code> we obtain the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_decomp">decomp</code></td>
<td>
<p>string; specifying if the decomposition of the GB2 is done with respect to the right tail (&quot;r&quot;) or the left tail (&quot;l&quot;) of the distribution.
By default, <code>decomp</code> = &quot;r&quot; - right tail decomposition.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_ff">ff</code></td>
<td>
<p>numeric; a tuning parameter.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_debug">debug</code></td>
<td>
<p>logical; By default, <code>debug = FALSE</code>.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_maxiter">maxiter</code></td>
<td>
<p>numeric; maximum number of iterations to perform.</p>
</td></tr>
<tr><td><code id="CompoundQuantiles_+3A_tol">tol</code></td>
<td>
<p>numeric; tolerance with default 0, meaning to iterate until additional terms do not change the partial sum.</p>
</td></tr>
</table>


<h3>Value</h3>

 
<p><code>qcgb2</code> returns a vector of quantiles and <code>rcgb2</code> return a vector of size <code>n</code> of GB2 compound random deviates.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>References</h3>

<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#\dontrun{

#\library{cubature}

# GB2 parameters
af &lt;- 5
bf &lt;- 20000
pf &lt;- 0.45 
qf &lt;- 0.75

p0 &lt;- rep(1/3,3)
p1 &lt;- c(0.37,0.43,0.2)

#Quantiles

qcgb2(0.5,af,bf,pf,qf,p0,p1)
qcgb2(1,af,bf,pf,qf,p0,p1)
qcgb2(c(0.5,0.8),af,bf,pf,qf,p0,p1)

#Random generation
rcgb2(10,af,bf,pf,qf,p0,p1)

#}
</code></pre>

<hr>
<h2 id='CompoundVarest'>
Variance Estimation of the Compound GB2 Distribution
</h2><span id='topic+CompoundVarest'></span><span id='topic+scoreU.cgb2'></span><span id='topic+varscore.cgb2'></span><span id='topic+desvar.cgb2'></span><span id='topic+hess.cgb2'></span><span id='topic+vepar.cgb2'></span><span id='topic+derivind.cgb2'></span><span id='topic+veind.cgb2'></span>

<h3>Description</h3>

<p>Calculation of variance estimates of the parameters of the compound GB2 distribution and of the estimated compound GB2 indicators under cluster sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreU.cgb2(fac, pl)
varscore.cgb2(U, w=rep(1,dim(U)[1]))
desvar.cgb2(data=data, U=U, ids=NULL, probs=NULL, strata = NULL, variables = NULL, 
fpc=NULL, nest = FALSE, check.strata = !nest, weights=NULL, pps=FALSE, 
variance=c("HT","YG"))
hess.cgb2(U, pl, w=rep(1,dim(U)[1]))
vepar.cgb2(ml, Vsc, hess)
derivind.cgb2(shape1, scale, shape2, shape3, pl0, pl, prop=0.6, decomp="r")
veind.cgb2(Vpar, shape1, scale, shape2, shape3, pl0, pl, decomp="r")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompoundVarest_+3A_fac">fac</code></td>
<td>
<p>numeric; matrix of Gamma factors (output of <code>fac.cgb2</code>.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_pl">pl</code></td>
<td>
<p>numeric; a vector of fitted mixture probabilities. Sums to one. If <code>pl</code> is equal to <code>pl0</code>, we obtain the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_u">U</code></td>
<td>
<p>numeric; vector of scores. Output of the <code>scoreU.cgb2</code> function.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_w">w</code></td>
<td>
<p>numeric; vector of some extrapolation weights. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_data">data</code></td>
<td>
<p>dataset containing the design information per unit.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_ids">ids</code>, <code id="CompoundVarest_+3A_probs">probs</code>, <code id="CompoundVarest_+3A_strata">strata</code>, <code id="CompoundVarest_+3A_variables">variables</code>, <code id="CompoundVarest_+3A_fpc">fpc</code>, <code id="CompoundVarest_+3A_nest">nest</code>, <code id="CompoundVarest_+3A_check.strata">check.strata</code>, <code id="CompoundVarest_+3A_weights">weights</code>, <code id="CompoundVarest_+3A_pps">pps</code>, <code id="CompoundVarest_+3A_variance">variance</code></td>
<td>
<p>parameters of <code><a href="survey.html#topic+svydesign">svydesign</a></code>.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_ml">ml</code></td>
<td>
<p>numeric; output of the <code>ml.cgb2</code> function. A list with two components. First component: estimated mixture probabilities. Second component: list containing the output of <code>optim</code>.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_vsc">Vsc</code></td>
<td>
<p>numeric; 4 by 4 matrix.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_hess">hess</code></td>
<td>
<p>numeric; Hessian (bread) for the sandwich variance estimate.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_shape1">shape1</code>, <code id="CompoundVarest_+3A_scale">scale</code>, <code id="CompoundVarest_+3A_shape2">shape2</code>, <code id="CompoundVarest_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the GB2 distribution.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_pl0">pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_prop">prop</code></td>
<td>
<p>numeric; proportion (in general is set to 0.6).</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_decomp">decomp</code></td>
<td>
<p>string; specifying if the decomposition of the GB2 is done with respect to the right tail (&quot;r&quot;) or the left tail (&quot;l&quot;) of the distribution.</p>
</td></tr>
<tr><td><code id="CompoundVarest_+3A_vpar">Vpar</code></td>
<td>
<p>numeric; 4 by 4 matrix. Output of the function <code>vepar.cgb2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>scoreU.cgb2</code> calculates the <code class="reqn">N \times (L-1)</code> matrix of scores <code>U</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">U(k,\ell)=p_{\ell} \left( \frac{F(k,\ell)}{\sum_{j=1}^L p_{j}\, F(k,j)} - 1\right),</code>
</p>
<p> where <code class="reqn">p_\ell, \ell=1,..,L</code> is the vector of fitted mixture probabilities and <code class="reqn">F</code> is the <code class="reqn">N \times L</code>
matrix of gamma factors, output of <code>fg.cgb2</code>.
The linearized scores are the columns of <code>U</code>. They serve to compute the linearization approximation of the covariance matrix of the parameters <code class="reqn">v_\ell=\log(p_\ell/p_L), 
\ell=1,...,L-1</code>. Function <code>varscore.cgb2</code> calculates the middle term of the sandwich variance estimator, that is the <code class="reqn">((L-1) \times (L-1))</code> 
estimated variance-covariance matrix of the <code class="reqn">(L-1)</code> weighted sums of  the columns of <code>U</code>,  without design information. 
<code>desvar.cgb2</code> calculates the design-based variance-covariance matrix of the <code class="reqn">(L-1)</code> weighted sums of the columns of <code>U</code>, invoking <code>svydesign</code>
and <code>svytotal</code> of package <code><a href="MASS.html#topic+survey">survey</a></code>. <code>hess.cgb2</code> calculates the Hessian (<code class="reqn">(L-1) \times (L-1))</code> matrix of second derivatives of the pseudo-log-likelihood with 
respect to the parameters <code class="reqn">v_\ell</code>). It should be negative definite. If not, the maximum likelihood estimates are spurious. 
<code>vepar.cgb2</code> calculates the sandwich covariance matrix estimate of the vector of parameters <code>v</code>.
<code>veind.cgb2</code> calculates estimates, standard error, covariance and correlation matrices of the indicators under the compound GB2.
</p>


<h3>Value</h3>

<p><code>scoreU.cgb2</code> returns a <code class="reqn">N \times (L-1)</code> matrix of scores &lt;codeU.
<code>varscore.cgb2</code> returns the variance-covariance estimate of the  weighted sums of scores <code>U</code>, given by weighted cross products.
<code>desvar.cgb2</code> returns a list of two elements. The first is the output of svytotal and the second is the design-based variance-covariance matrix of the weighted sums of the scores. 
<code>hess.cgb2</code> returns the matrix of second derivatives of the likelihood with respect to the parameters (bread for the sandwich variance estimate). 
<code>vepar.cgb2</code> returns a list of five elements - [[&quot;type&quot;]] with value &quot;parameter&quot;, [[&quot;estimate&quot;]] estimated parameters, [[&quot;stderr&quot;]] corresponding standard errors, 
[[&quot;Vcov&quot;]] variance -covariance matrix and [[&quot;Vcor&quot;]] - correlation matrix.
<code>veind.cgb2</code> returns a list of five elements: [[&quot;type&quot;]] with value &quot;indicator&quot;, 
[[&quot;estimate&quot;]] estimated indicators under the compound GB2, [[&quot;stderr&quot;]] corresponding standard errors, [[&quot;Vcov&quot;]] variance -covariance matrix and [[&quot;Vcor&quot;]] - correlation matrix.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>References</h3>

<p>Davison, A. (2003),
<em>Statistical Models</em>.
Cambridge University Press.
</p>
<p>Freedman, D. A. (2006),
On The So-Called &quot;Huber Sandwich Estimator&quot; and &quot;Robust Standard Errors&quot;.
<em>The American Statistician</em>, <b>60</b>, 299&ndash;302.
</p>
<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>
<p>Pfeffermann, D. and Sverchkov, M. Yu. (2003),
Fitting Generalized Linear Models under Informative Sampling.
In, Skinner, C.J. and Chambers, R.L. (eds.). 
<em>Analysis of Survey Data</em>, chapter 12, 175&ndash;195.
Wiley, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example (following of example in CompoundFit)

# Estimated mixture probabilities:
(pl.hat &lt;- estim[[1]])

# scores per unit
U &lt;- scoreU.cgb2(fac, pl.hat)  

# Conditional variances given a,b,p,q:

# 1. Variance of sum of scores:
(Vsc &lt;- t(U) 
(Vsc &lt;- varscore.cgb2(U))        

# 2. sandwich variance-covariance matrix estimate of (v_1,v_2):
(hess &lt;-  hess.cgb2(U,pl.hat))
(Parameters &lt;- vepar.cgb2(estim, Vsc, hess))

# 3. Theoretical indicators  (with mixture prob pl)
decomp &lt;- "r"
(theoretical &lt;- main.cgb2( 0.6,a,b,p,q,pl0, pl,decomp=decomp))

# Estimated indicators and conditional variances : takes a long time!
(Indic &lt;- veind.cgb2(Parameters,a,b,p,q, pl0, pl.hat, decomp="r") )


## End(Not run)
</code></pre>

<hr>
<h2 id='Contindic'>
Sensitivity Analysis of Laeken Indicators on GB2 Parameters
</h2><span id='topic+Contindic'></span><span id='topic+contindic.gb2'></span>

<h3>Description</h3>

<p>Produces a contour plot of an indicator for a given <code>shape1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contindic.gb2(resol, shape1, shape21, shape22, shape31, shape32, fn, title, table=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contindic_+3A_resol">resol</code></td>
<td>
<p>numeric; number of grid points horizontally and vertically.</p>
</td></tr>
<tr><td><code id="Contindic_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter, first shape parameter of the GB2 distribution.</p>
</td></tr> 
<tr><td><code id="Contindic_+3A_shape21">shape21</code>, <code id="Contindic_+3A_shape22">shape22</code>, <code id="Contindic_+3A_shape31">shape31</code>, <code id="Contindic_+3A_shape32">shape32</code></td>
<td>
<p>numeric; limits on the positive parameters of the Beta distribution.</p>
</td></tr>
<tr><td><code id="Contindic_+3A_fn">fn</code></td>
<td>
<p>string; the name of the function to be used for the calculation of the values to be plotted.</p>
</td></tr>
<tr><td><code id="Contindic_+3A_title">title</code></td>
<td>
<p>string; title of the plot.</p>
</td></tr>
<tr><td><code id="Contindic_+3A_table">table</code></td>
<td>
<p>boolean; if <code>TRUE</code>, a table containing the values of the function <code>fn</code> at the different grid points is printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An indicator is defined as a function of three parameters. The shape parameter, <code>shape1</code>, is held fixed. The shape parameters <code>shape2</code> and <code>shape3</code> vary between <code>shape21</code> and <code>shape22</code>, and <code>shape31</code> and <code>shape32</code>, respectively.
</p>


<h3>Value</h3>

<p>A contour plot of a given indicator for a fixed value of the shape parameter <code>shape1</code>.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+contour">contour</a></code> (package <code>graphics</code>) for more details on contour plots.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>par(mfrow=c(2,2))
shape21 &lt;- 0.3
shape31 &lt;- 0.36
shape22 &lt;- 1.5
shape32 &lt;- 1.5
shape11 &lt;- 2.7
shape12 &lt;- 9.2
resol &lt;- 11
rangea &lt;- round(seq(shape11, shape12 ,length.out=4),digits=1)
arpr &lt;- function(shape1, shape2, shape3) 100*arpr.gb2(0.6, shape1, shape2, shape3)
fonc &lt;- "arpr"
for (shape1 in rangea){
contindic.gb2(resol, shape1, shape21, shape22, shape31, shape32, arpr, "At-risk-of-poverty rate", 
table=TRUE)
}
</code></pre>

<hr>
<h2 id='Contprof'>
Contour Plot of the Profile Log-likelihood of the GB2 Distribution
</h2><span id='topic+Contprof'></span><span id='topic+contprof.gb2'></span>

<h3>Description</h3>

<p>Produces a contour plot of the profile log-likelihood, which is a function of two parameters only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contprof.gb2(z, w=rep(1,length(z)), resol, low=0.1, high=20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contprof_+3A_z">z</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="Contprof_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>z</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="Contprof_+3A_resol">resol</code></td>
<td>
<p>numeric; number of grid points horizontally and vertically. For better graph quality, we recommend a value of 100.</p>
</td></tr>
<tr><td><code id="Contprof_+3A_low">low</code>, <code id="Contprof_+3A_high">high</code></td>
<td>
<p>numeric; lower and upper factors for scale.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The matrix containing the values to be plotted (NAs are allowed) is of size <code>resol</code> <code class="reqn">\times</code> <code>resol</code>.  
The locations of the grid lines at which the values of the profile log-likelihood are measured are equally-spaced values between <code>low</code> and <code>high</code> 
multiplied by the initial parameters.
</p>


<h3>Value</h3>

<p>A contour plot of the profile log-likelihood. The initial Fisk estimate is added as point &quot;F&quot;.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fisk">fisk</a></code> for the Fisk estimate, <code><a href="#topic+ProfLogLikelihood">ProfLogLikelihood</a></code> for the profile log-likelihood and <code><a href="graphics.html#topic+contour">contour</a></code> (package <code>graphics</code>) for more details on contour plots.
</p>

<hr>
<h2 id='Fisk'>
Parameters of the Fisk Distribution
</h2><span id='topic+Fisk'></span><span id='topic+fisk'></span><span id='topic+fiskh'></span>

<h3>Description</h3>

<p>Calculation of the parameters <code class="reqn">a</code> and <code class="reqn">b</code> of the Fisk distribution, which is a GB2 distribution with <code class="reqn">p = q = 1</code>. If <code class="reqn">m</code> and <code class="reqn">v</code> denote, respectively, the mean and variance of <code class="reqn">log(z)</code>, 
then <code class="reqn">\hat{a} = \pi/\sqrt{3*v}</code> and <code class="reqn">\hat{b} = \exp(m)</code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fisk(z, w=rep(1, length(z)))
fiskh(z, w=rep(1, length(z)), hs=rep(1, length(z)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fisk_+3A_z">z</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="Fisk_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>z</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="Fisk_+3A_hs">hs</code></td>
<td>
<p>numeric; vector of household sizes. Must have the same length as <code>z</code>. By default <code>hs</code> is a vector of 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>fisk</code> first calculates the mean and variance of <code class="reqn">log(z)</code> and next the values of <code class="reqn">a</code> and <code class="reqn">b</code> under the Fisk distribution.  
Function <code>fiskh</code> first calculates the mean and variance of <code class="reqn">log(z)</code>, assuming a sample of households, and next the values of <code class="reqn">a</code> and <code class="reqn">b</code> under the Fisk distribution. 
</p>


<h3>Value</h3>

<p><code>fisk</code> and <code>fiskh</code> return vectors of length 4 containing the estimated parameters <code class="reqn">a</code>, eqnb, as well as <code class="reqn">p=1</code> and <code class="reqn">q=1</code>. 
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code> for the general-purpose optimization
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(laeken)
data(eusilc)

# Income
inc &lt;- as.vector(eusilc$eqIncome)

# Weights
w &lt;- eusilc$rb050

#Fisk parameters
fpar &lt;- fisk(inc, w)
</code></pre>

<hr>
<h2 id='gb2'>The Generalized Beta Distribution of the Second Kind</h2><span id='topic+gb2'></span><span id='topic+dgb2'></span><span id='topic+pgb2'></span><span id='topic+qgb2'></span><span id='topic+rgb2'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random generation for the Generalized beta distribution of the second kind with parameters <code>a</code>, <code>b</code>, <code>p</code> and <code>q</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgb2(x, shape1, scale, shape2, shape3)
pgb2(x, shape1, scale, shape2, shape3)
qgb2(prob, shape1, scale, shape2, shape3)
rgb2(n, shape1, scale, shape2, shape3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gb2_+3A_x">x</code></td>
<td>
<p>numeric; vector of quantiles.</p>
</td></tr>
<tr><td><code id="gb2_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="gb2_+3A_scale">scale</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="gb2_+3A_shape2">shape2</code>, <code id="gb2_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
<tr><td><code id="gb2_+3A_prob">prob</code></td>
<td>
<p>numeric; vector of probabilities.</p>
</td></tr>
<tr><td><code id="gb2_+3A_n">n</code></td>
<td>
<p>numeric; number of observations. If <code>length(n) &gt; 1</code>, the length
is taken to be the number required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Generalized Beta distribution of the second kind with parameters <code>shape1</code> <code class="reqn">= a</code>, <code>scale</code> <code class="reqn">= b</code>,  <code>shape2</code> <code class="reqn">= p</code> and <code>shape3</code> <code class="reqn">= q</code> has density
</p>
<p style="text-align: center;"><code class="reqn">f(x)=\frac{a(x/b)^{ap-1}}{bB(p,q)(1+(x/b)^{a})^{p+q}}</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">p &gt; 0</code> and <code class="reqn">q &gt; 0</code>, where  <code class="reqn">B(p,q)</code> is the Beta function (<code><a href="base.html#topic+beta">beta</a></code>). If <code>Z</code> follows a Beta distribution with parameters <code class="reqn">p</code> and <code class="reqn">q</code> and 
</p>
<p style="text-align: center;"><code class="reqn">y = \frac{z}{1-z},</code>
</p>
<p> then </p>
<p style="text-align: center;"><code class="reqn">x = b * y^{1/a}</code>
</p>
<p> follows the GB2 distribution.
</p>


<h3>Value</h3>

<p><code>dgb2</code> gives the density, <code>pgb2</code> the distribution
function, <code>qgb2</code> the quantile function, and <code>rgb2</code>
generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Monique Graf</p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003) 
<em>Statistical Size Distributions in Economics and Actuarial Sciences</em>, chapter 6.
Wiley, Ney York.
</p>
<p>McDonald, J. B. (1984)
Some generalized functions for the size distribution of income. 
<em>Econometrica</em>, <b>52</b>, 647&ndash;663.
</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+beta">beta</a></code> for the Beta function and  <code><a href="stats.html#topic+dbeta">dbeta</a></code> for the Beta distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- 3.9
b &lt;- 18873
p &lt;- 0.97
q &lt;- 1.03
x &lt;- qgb2(0.6, a, b, p, q)
y &lt;- dgb2(x, a, b, p, q)
</code></pre>

<hr>
<h2 id='Gini'>
Computation of the Gini Coefficient for the GB2 Distribution and its Particular Cases.
</h2><span id='topic+Gini'></span><span id='topic+gini.gb2'></span><span id='topic+gini.b2'></span><span id='topic+gini.dag'></span><span id='topic+gini.sm'></span>

<h3>Description</h3>

<p>Computes the Gini coefficient for the GB2 distribution using the function <code><a href="#topic+gb2.gini">gb2.gini</a></code>. 
Computes the Gini coefficient for the Beta Distribution of the Second Kind, Dagum and Singh-Maddala distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gini.gb2(shape1, shape2, shape3)
gini.b2(shape2, shape3)
gini.dag(shape1, shape2)
gini.sm(shape1, shape3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gini_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="Gini_+3A_shape2">shape2</code>, <code id="Gini_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Gini coefficient.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003) 
<em>Statistical Size Distributions in Economics and Actuarial Sciences</em>, chapter 6.
Wiley, Ney York.
</p>
<p>McDonald, J. B. (1984)
Some generalized functions for the size distribution of income. 
<em>Econometrica</em>, <b>52</b>, 647&ndash;663.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gb2.gini">gb2.gini</a></code>
</p>

<hr>
<h2 id='Indicators'>Monetary Laeken Indicators under the GB2
</h2><span id='topic+Indicators'></span><span id='topic+arpt.gb2'></span><span id='topic+arpr.gb2'></span><span id='topic+rmpg.gb2'></span><span id='topic+qsr.gb2'></span><span id='topic+main.gb2'></span><span id='topic+main2.gb2'></span>

<h3>Description</h3>

<p>Functions to calculate four primary social welfare indicators under the GB2, i.e. the at-risk-of-poverty threshold,
the at-risk-of-poverty rate, the relative median at-risk-of-poverty gap, and the income quintile share ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arpt.gb2(prop, shape1, scale, shape2, shape3)
arpr.gb2(prop, shape1, shape2, shape3)
rmpg.gb2(arpr, shape1, shape2, shape3)
qsr.gb2(shape1, shape2, shape3)
main.gb2(prop, shape1, scale, shape2, shape3)
main2.gb2(prop, shape1, scale, shape12, shape13)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Indicators_+3A_prop">prop</code></td>
<td>
<p>numeric; proportion (in general is set to 0.6).</p>
</td></tr>
<tr><td><code id="Indicators_+3A_arpr">arpr</code></td>
<td>
<p>numeric; the value of the at-risk-of-poverty rate.</p>
</td></tr>
<tr><td><code id="Indicators_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="Indicators_+3A_scale">scale</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="Indicators_+3A_shape2">shape2</code>, <code id="Indicators_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
<tr><td><code id="Indicators_+3A_shape12">shape12</code></td>
<td>
<p>numeric; the product of the two parameters <code>shape1</code> and <code>shape2</code>.</p>
</td></tr>
<tr><td><code id="Indicators_+3A_shape13">shape13</code></td>
<td>
<p>numeric; the product of the two parameters <code>shape1</code> and <code>shape3</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In June 2006, the  Social Protection Committee, which is a group of officials of the European Commisiion, adopts a set of common indicators for the social protection and social inclusion process.
It consists of a portfolio of 14 overarching indicators (+11 context indicators) meant to reflect the overarching objectives (a) &quot;social cohesion&quot; and (b) &quot;interaction with the Lisbon strategy for growth and jobs (launched in 2000) objectives&quot;;
and of three strand portfolios for social inclusion, pensions, and health and long-term care.
</p>
<p>The at-risk-of-poverty threshold (or ARPT) is defined as 60% of the median national equivalized income. 
</p>
<p>The at-risk-of-poverty rate (or ARPR) is defined as the share of persons with an equivalised disposable income below the ARPT.
</p>
<p>The relative median at-risk-of-poverty gap (or RMPG) is defined as the difference between the median equivalised income of persons
below the ARPT and the ARPT itself, expressed as a percentage of the ARPT.
</p>
<p>The income quintile share ratio (or QSR) is defined as the ratio of total income received by the 20% of the country's
population with the highest income (top quintile) to that received by the 20% of the country's population with the lowest
income (lowest quintile).
</p>
<p>Let <code class="reqn">x_{0.5}</code> be the median of a GB2 with parameters <code>shape1</code> <code class="reqn">= a</code>, <code>scale</code> <code class="reqn">= b</code>,  <code>shape2</code> <code class="reqn">= p</code> and <code>shape3</code> <code class="reqn">= q</code>. Then, 
</p>
<p style="text-align: center;"><code class="reqn">ARPT(a,b,p,q)=0.6 x_{0.5}</code>
</p>

<p>The ARPR being scale-free, <code class="reqn">b</code> can be chosen arbitrarily and can be fixed to 1.
</p>
<p>The QSR is calculated with the help of the incomplete moments of order 1.
</p>
<p><code>main.gb2</code> and <code>main2.gb2</code> return a vector containing the following set of GB2 indicators: the median, the mean, the ARPR, the RMPG, the QSR and the Gini coefficient.  
The only difference is in the input parameters.
</p>


<h3>Value</h3>

<p><code>arpt.gb2</code> gives the ARPT, <code>arpr.gb2</code> the ARPR, <code>rmpg.gb2</code> the RMPG, and <code>qsr.gb2</code>
calculates the QSR. <code>main.gb2</code> returns a vector containing the median of the distribution, the mean of the distribution, the ARPR, the RMPG, the QSR and the Gini coefficient. 
<code>main2.gb2</code> produces the same output as <code>main.gb2</code>.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p><a href="https://ec.europa.eu/social/main.jsp?langId=en&amp;catId=750">https://ec.europa.eu/social/main.jsp?langId=en&amp;catId=750</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qgb2">qgb2</a></code>, <code><a href="#topic+incompl.gb2">incompl.gb2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- 3.9
b &lt;- 18873
p &lt;- 0.97
q &lt;- 1.03
ap &lt;- a*p
aq &lt;- a*q

arpt &lt;- arpt.gb2(0.6, a, b, p, q)
arpr &lt;- arpr.gb2(0.6, a, p, q)
rmpg &lt;- rmpg.gb2(arpr, a, p, q)
qsr &lt;- qsr.gb2(a, p, q)

ind1 &lt;- main.gb2(0.6, a, b, p, q)
ind2 &lt;- main2.gb2(0.6, a, b, ap, aq)
</code></pre>

<hr>
<h2 id='LogDensity'>
Log Density of the GB2 Distribution
</h2><span id='topic+LogDensity'></span><span id='topic+logf.gb2'></span><span id='topic+dlogf.gb2'></span><span id='topic+d2logf.gb2'></span>

<h3>Description</h3>

<p>Calculates the log density of the GB2 distribution for a single value or a vector of values. 
Calculates the first- and second-order partial derivatives of the log density evaluated at a single value.</p>


<h3>Usage</h3>

<pre><code class='language-R'>logf.gb2(x, shape1, scale, shape2, shape3)
dlogf.gb2(xi, shape1, scale, shape2, shape3)
d2logf.gb2(xi, shape1, scale, shape2, shape3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LogDensity_+3A_xi">xi</code></td>
<td>
<p>numeric; a data value.</p>
</td></tr>
<tr><td><code id="LogDensity_+3A_x">x</code></td>
<td>
<p>numeric; a vector of data values.</p>
</td></tr>
<tr><td><code id="LogDensity_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="LogDensity_+3A_scale">scale</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="LogDensity_+3A_shape2">shape2</code>, <code id="LogDensity_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We calculate <code class="reqn">log(f(x, \theta))</code>, where <code class="reqn">f</code> is the GB2 density with parameters <code>shape1</code> <code class="reqn">= a</code>, <code>scale</code> <code class="reqn">= b</code>, 
<code>shape2</code> <code class="reqn">= p</code> and <code>shape3</code> <code class="reqn">= q</code>, <code class="reqn">\theta</code> is the parameter vector. We calculate the first- and second-order partial derivatives of <code class="reqn">log(f(x, \theta))</code> with 
respect to the parameter vector <code class="reqn">\theta</code>.
</p>


<h3>Value</h3>

<p>Depending on the input <code>logf.gb2</code> gives the log density for a single value or a vector of values. <code>dlogf.gb2</code> gives the vector of the four first-order partial derivatives of the log density and 
<code>d2logf.gb2</code> gives the <code class="reqn">4 \times 4</code> matrix of second-order partial derivatives of the log density.
</p>


<h3>Author(s)</h3>

<p>Desislava Nedyalkova
</p>


<h3>References</h3>

<p>Brazauskas, V. (2002)
Fisher information matrix for the Feller-Pareto distribution.
<em>Statistics &amp; Probability Letters</em>, <b>59</b>, 159&ndash;167.
</p>

<hr>
<h2 id='LogLikelihood'>
Full Log-likelihood of the GB2 Distribution
</h2><span id='topic+LogLikelihood'></span><span id='topic+loglp.gb2'></span><span id='topic+loglh.gb2'></span><span id='topic+scoresp.gb2'></span><span id='topic+scoresh.gb2'></span><span id='topic+info.gb2'></span>

<h3>Description</h3>

<p>Calculates the log-likelihood, the score functions of the log-likelihood and the Fisher information matrix based on all four parameters of the GB2 distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglp.gb2(x, shape1, scale, shape2, shape3, w=rep(1, length(x)))
loglh.gb2(x, shape1, scale, shape2, shape3, w=rep(1, length(x)), hs=rep(1, length(x)))
scoresp.gb2(x, shape1, scale, shape2, shape3, w=rep(1, length(x)))
scoresh.gb2(x, shape1, scale, shape2, shape3, w=rep(1, length(x)), hs=rep(1, length(x)))
info.gb2(shape1, scale, shape2, shape3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LogLikelihood_+3A_x">x</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="LogLikelihood_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="LogLikelihood_+3A_scale">scale</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="LogLikelihood_+3A_shape2">shape2</code>, <code id="LogLikelihood_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
<tr><td><code id="LogLikelihood_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>x</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="LogLikelihood_+3A_hs">hs</code></td>
<td>
<p>numeric; vector of household sizes. Must have the same length as <code>x</code>. By default <code>hs</code> is a vector of 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We express the log-likelihood as a weighted mean of <code class="reqn">log(f)</code>, evaluated at the data points, where <code class="reqn">f</code> is the GB2 density with parameters <code>shape1</code> <code class="reqn">= a</code>, <code>scale</code> <code class="reqn">= b</code>, 
<code>shape2</code> <code class="reqn">= p</code> and <code>shape3</code> <code class="reqn">= q</code>.  If the weights are not available, then we suppose that <code>w</code> <code class="reqn">= 1</code>. <code>loglp.gb2</code> calculates the log-likelihood in the case where the data is a sample of persons and 
<code>loglh.gb2</code> is adapted for a sample of households.  Idem for the scores, which are obtained as weighted sums of the first derivatives of <code class="reqn">log(f)</code> with respect to the GB2 parameters, evaluated at the data points.  
The Fisher information matrix of the GB2 was obtained by Brazauskas (2002) and is expressed in terms of the second derivatives of the log-likelihood with respect to the GB2 parameters.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Brazauskas, V. (2002)
Fisher information matrix for the Feller-Pareto distribution.
<em>Statistics &amp; Probability Letters</em>, <b>59</b>, 159&ndash;167.
</p>
<p>Kleiber, C. and Kotz, S. (2003) 
<em>Statistical Size Distributions in Economics and Actuarial Sciences</em>, chapter 6.
Wiley, Ney York.
</p>

<hr>
<h2 id='MLfitGB2'>
Fitting the GB2 by the Method of Maximum Likelihood Estimation and Comparison of the Fitted Indicators with the Empirical Indicators
</h2><span id='topic+MLfitGB2'></span><span id='topic+main.emp'></span><span id='topic+mlfit.gb2'></span>

<h3>Description</h3>

<p>The function <code>mlfit.gb2</code> makes a call to <code>ml.gb2</code> and <code>profml.gb2</code>. Estimates of the GB2 parameters are calculated using maximum likelihood estimation based on the full and profile log-likelihoods. Empirical estimates of the set of primary indicators of poverty and social inclusion are calculated using the function <code>main.emp</code> (see package <code>laeken</code>) and these estimates
are compared with the indicators calculated with the GB2 fitted parameters using the function <code><a href="#topic+main.gb2">main.gb2</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>main.emp(z, w=rep(1, length(z)))
mlfit.gb2(z, w=rep(1, length(z))) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLfitGB2_+3A_z">z</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="MLfitGB2_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>z</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr></table>


<h3>Value</h3>

<p>A list containing three different objects. The first is a data frame with the values of the fitted parameters for the full log-likelihood and the profile log-likelihood, 
the values of the two likelihoods, the values of the GB2 estimates of the indicators and the values of the empirical estimates of the indicators. The second and third objects are, respectively,
the fit using the full log-likelihood and the fit using the profile log-likelihood.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code> , <code><a href="#topic+ml.gb2">ml.gb2</a></code>, <code><a href="#topic+profml.gb2">profml.gb2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># An example of using the function mlfit.gb2
# See also the examples of ml.gb2 and mlprof.gb2

## Not run: 
library(laeken)
data(eusilc)

# Income
inc &lt;- as.vector(eusilc$eqIncome)

# Weights
w &lt;- eusilc$rb050

# Data set
d &lt;- data.frame(inc, w)
d &lt;- d[!is.na(d$inc),]

# Truncate at 0
inc &lt;- d$inc[d$inc &gt; 0]
w   &lt;- d$w[d$inc &gt; 0]

# ML fit
m1 &lt;- mlfit.gb2(inc,w)

# GB2 fitted parameters and indicators through maximum likelihood estimation
m1[[1]]
# The fit using the full log-likelihood
m1[[2]]
# The fit using the profile log-likelihood
m1[[3]]

# ML fit, when no weights are avalable 
m2 &lt;- mlfit.gb2(inc)
# Results
m2[[1]]

## End(Not run)
</code></pre>

<hr>
<h2 id='MLfullGB2'>
Maximum Likelihood Estimation of the GB2 Based on the Full Log-likelihood
</h2><span id='topic+MLfullGB2'></span><span id='topic+ml.gb2'></span><span id='topic+mlh.gb2'></span>

<h3>Description</h3>

<p>Performs maximum pseudo-likelihood estimation through the general-purpose optimisation function <code>optim</code> from package <code>stats</code>. Two methods of optimization are considered: BFGS and L-BFGS-B 
(see <code>optim</code> documentation for more details). Initial values of the parameters to be optimized over (<code class="reqn">a</code>, <code class="reqn">b</code>, 
<code class="reqn">p</code> and <code class="reqn">q</code>) are given from the Fisk distribution and <code class="reqn">p=q=1</code>. The function to be maximized by <code>optim</code> is the negative of the full log-likelihood and the gradient is equal to the 
negative of the scores, respectively for the case of a sample of persons and a sample of households. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ml.gb2(z, w=rep(1, length(z)), method=1, hess=FALSE) 
mlh.gb2(z, w=rep(1, length(z)), hs=rep(1, length(z)), method=1, hess = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLfullGB2_+3A_z">z</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="MLfullGB2_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>z</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="MLfullGB2_+3A_hs">hs</code></td>
<td>
<p>numeric; vector of household sizes. Must have the same length as <code>z</code>. By default <code>hs</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="MLfullGB2_+3A_method">method</code></td>
<td>
<p>numeric; the method to be used by <code>optim</code>. By default, codemethod = 1 and the used method is BFGS. If <code>method = </code>2, method L-BFGS-B is used.</p>
</td></tr>
<tr><td><code id="MLfullGB2_+3A_hess">hess</code></td>
<td>
<p>logical; By default, <code>hess = FALSE</code>, the hessian matrix is not calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>ml.gb2</code> performs maximum likelihood estimation through the general-purpose optimization function <code>optim</code> from package <code>stats</code>,
based on the full log-likelihood calculated in a sample of persons. Function <code>mlh.gb2</code> performs maximum likelihood estimation through the general-purpose optimization function <code>optim</code> 
from package <code>stats</code>, based on the full log-likelihood calculated in a sample of households.
</p>


<h3>Value</h3>

 
<p><code>ml.gb2</code> and <code>mlh.gb2</code> return a list with 1 argument: <code>opt1</code> for the output of the BFGS fit or <code>opt2</code> for the output of the L-BFGS fit. Further values are given by the values of <code>optim</code>.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code> for the general-purpose optimization and <code><a href="#topic+fisk">fisk</a></code> for the Fisk distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(laeken)
data(eusilc)

# Income
inc &lt;- as.vector(eusilc$eqIncome)

# Weights
w &lt;- eusilc$rb050

# Data set
d &lt;- data.frame(inc, w)
d &lt;- d[!is.na(d$inc),]
   
# Truncate at 0
inc &lt;- d$inc[d$inc &gt; 0]
w   &lt;- d$w[d$inc &gt; 0]

# Fit using the full log-likelihood
fitf &lt;- ml.gb2(inc, w)

# Fitted GB2 parameters
af &lt;- fitf$par[1]
bf &lt;- fitf$par[2]
pf &lt;- fitf$par[3]
qf &lt;- fitf$par[4]

# Likelihood
flik &lt;- fitf$value

# If we want to compare the indicators

# GB2 indicators
indicf &lt;- round(main.gb2(0.6,af,bf,pf,qf), digits=3)
# Empirical indicators
indice &lt;- round(main.emp(inc,w), digits=3)

# Plots
plotsML.gb2(inc,af,bf,pf,qf,w)

## End(Not run)
</code></pre>

<hr>
<h2 id='MLprofGB2'>
Maximum Likelihood Estimation of the GB2 Based on the Profile Log-likelihood
</h2><span id='topic+MLprofGB2'></span><span id='topic+profml.gb2'></span>

<h3>Description</h3>

<p><code>profml.gb2</code> performs maximum likelihood estimation based on the profile log-likelihood through the general-purpose optimisation function <code>optim</code> from package <code>stats</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>profml.gb2(z, w=rep(1, length(z)), method=1, hess = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLprofGB2_+3A_z">z</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="MLprofGB2_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>z</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="MLprofGB2_+3A_method">method</code></td>
<td>
<p>numeric; the method to be used by <code>optim</code>. By default, codemethod = 1 and the used method is BFGS. If <code>method = </code>2, method L-BFGS-B is used.</p>
</td></tr>
<tr><td><code id="MLprofGB2_+3A_hess">hess</code></td>
<td>
<p>logical; By default, <code>hess = FALSE</code>, the hessian matrix is not calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two methods are considered: BFGS and L-BFGS-B (see <code>optim</code> documentation for more details). Initial values of the parameters to be optimized over (<code class="reqn">a</code> and <code class="reqn">b</code>) 
are given from the Fisk distribution.  The function to be maximized by <code>optim</code> is the negative of the profile log-likelihood (<code><a href="#topic+proflogl.gb2">proflogl.gb2</a></code>) 
and the gradient is equal to the negative of the scores (<code><a href="#topic+profscores.gb2">profscores.gb2</a></code>).
</p>


<h3>Value</h3>

<p>A list with 1 argument: <code>opt1</code> for the output of the BFGS fit or <code>opt2</code> for the output of the L-BFGS fit. Further values are given by the values of <code>optim</code>.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code> for the general-purpose optimization, <code>link{ml.gb2}</code> for the fit using the full log-likelihood and <code><a href="#topic+fisk">fisk</a></code> for the Fisk distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(laeken)
data(eusilc)

# Income
inc &lt;- as.vector(eusilc$eqIncome)

# Weights
w &lt;- eusilc$rb050

# Data set
d &lt;- data.frame(inc,w)
d &lt;- d[!is.na(d$inc),]
   
# Truncate at 0
inc &lt;- d$inc[d$inc &gt; 0]
w   &lt;- d$w[d$inc &gt; 0]

# Fit using the profile log-likelihood
fitp &lt;- profml.gb2(inc, w)$opt1

# Fitted GB2 parameters
ap &lt;- fitp$par[1]
bp &lt;- fitp$par[2]
pp &lt;- prof.gb2(inc, ap, bp, w)[3]
qp &lt;- prof.gb2(inc, ap, bp, w)[4]

# Profile log-likelihood
proflik &lt;- fitp$value

# If we want to compare the indicators
## Not run: 
# GB2 indicators
indicp &lt;- round(main.gb2(0.6,ap,bp,pp,qp), digits=3)
# Empirical indicators
indice &lt;- round(main.emp(inc,w), digits=3)

## End(Not run)

# Plots
## Not run: plotsML.gb2(inc,ap,bp,pp,qp,w)
</code></pre>

<hr>
<h2 id='Moments'>
Moments and Other Properties of a GB2 Random Variable
</h2><span id='topic+Moments'></span><span id='topic+moment.gb2'></span><span id='topic+incompl.gb2'></span><span id='topic+el.gb2'></span><span id='topic+vl.gb2'></span><span id='topic+sl.gb2'></span><span id='topic+kl.gb2'></span>

<h3>Description</h3>

<p>These functions calculate the moments of order <code>k</code> and incomplete moments of order <code>k</code> of a GB2 random variable <code class="reqn">X</code> as well as the expectation,
the variance, the kurtosis and the skewness of <code class="reqn">log(X)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moment.gb2(k, shape1, scale, shape2, shape3)
incompl.gb2(x, k, shape1, scale, shape2, shape3)
el.gb2(shape1, scale, shape2, shape3)
vl.gb2(shape1, shape2, shape3)
sl.gb2(shape2, shape3)
kl.gb2(shape2, shape3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Moments_+3A_x">x</code></td>
<td>
<p>numeric; vector of quantiles.</p>
</td></tr>
<tr><td><code id="Moments_+3A_k">k</code></td>
<td>
<p>numeric; order of the moment.</p>
</td></tr>
<tr><td><code id="Moments_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="Moments_+3A_scale">scale</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="Moments_+3A_shape2">shape2</code>, <code id="Moments_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">X</code> be a random variable following a GB2 distribution with parameters <code>shape1</code> <code class="reqn">= a</code>, <code>scale</code> <code class="reqn">= b</code>,  <code>shape2</code> <code class="reqn">= p</code> and <code>shape3</code> <code class="reqn">= q</code>. 
Moments and incomplete moments of <code class="reqn">X</code> exist only for <code class="reqn">-ap \le k \le aq</code>. Moments are given by
</p>
<p style="text-align: center;"><code class="reqn">E(X^k) = {b}^{k} \frac{\Gamma (p+k/a) \Gamma (q-k/a)}{\Gamma (p) \Gamma (q)}</code>
</p>
 
<p>This expression, when considered a function of <code>k</code>, can be viewed as the moment-generating function of <code class="reqn">Y=log(X)</code>. Thus, it is useful to compute the moments of <code class="reqn">log(X)</code>, 
which are needed for deriving, for instance, the Fisher information matrix of the GB2 distribution. Moments of <code class="reqn">log(X)</code> exist for all <code>k</code>.
</p>


<h3>Value</h3>

<p><code>moment.gb2</code> gives the moment of order <code>k</code>, 
<code>incompl.gb2</code> gives the incomplete moment of order <code>k</code>,
<code>El.gb2</code> gives the expectation of <code class="reqn">log(X)</code>, 
<code>vl.gb2</code> gives the variance of <code class="reqn">log(X)</code>, 
<code>sl.gb2</code> gives the skewness of <code class="reqn">log(X)</code>, 
<code>kl.gb2</code> gives the kurtosis of <code class="reqn">log(X)</code>.
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003) 
<em>Statistical Size Distributions in Economics and Actuarial Sciences</em>, chapter 6.
Wiley, Ney York.
</p>


<h3>See Also</h3>

 
<p><code><a href="base.html#topic+gamma">gamma</a></code> for the Gamma function and related functions (<code>digamma</code>, <code>trigamma</code> and <code>psigamma</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- 3.9
b &lt;- 18873
p &lt;- 0.97
q &lt;- 1.03
k &lt;- 2
x &lt;- qgb2(0.6, a, b, p, q)
moment.gb2(k, a, b, p, q)
incompl.gb2(x, k, a, b, p, q)
vl.gb2(a, p, q)
kl.gb2(p, q)
</code></pre>

<hr>
<h2 id='NonlinearFit'>
Fitting the GB2 by Minimizing the Distance Between a Set of Empirical Indicators and Their GB2 Expressions
</h2><span id='topic+NonlinearFit'></span><span id='topic+nlsfit.gb2'></span>

<h3>Description</h3>

<p>Fitting the parameters of the GB2 distribution by optimizing the squared weighted distance between a set of empirical indicators, i.e. the median, the ARPR, the RMPG, the QSR and the Gini coefficient,
and the GB2 indicators using nonlinear least squares (function <code>nls</code> from package <code>stats</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlsfit.gb2(med, ei4, par0=c(1/ei4[4],med,1,1), cva=1, bound1=par0[1]*max(0.2,1-2*cva), 
bound2=par0[1]*min(2,1+2*cva), ei4w=1/ei4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NonlinearFit_+3A_med">med</code></td>
<td>
<p>numeric; the empirical median.</p>
</td></tr>
<tr><td><code id="NonlinearFit_+3A_ei4">ei4</code></td>
<td>
<p>numeric; the values of the empirical indicators.</p>
</td></tr>
<tr><td><code id="NonlinearFit_+3A_par0">par0</code></td>
<td>
<p>numeric; vector of initial values for the GB2 parameters <code class="reqn">a, b, p</code> and <code class="reqn">q</code>. The default is to take <code class="reqn">a</code> equal to the inverse of the empirical Gini coefficient, <code class="reqn">b</code> equal to the empirical median and <code class="reqn">p = q = 1</code>.</p>
</td></tr>
<tr><td><code id="NonlinearFit_+3A_cva">cva</code></td>
<td>
<p>numeric; the coefficient of variation of the ML estimate of the parameter <code class="reqn">a</code>. The default value is 1.</p>
</td></tr>
<tr><td><code id="NonlinearFit_+3A_bound1">bound1</code>, <code id="NonlinearFit_+3A_bound2">bound2</code></td>
<td>
<p>numeric; the lower and upper bounds for the parameter <code class="reqn">a</code> in the algorithm. The default values are <code class="reqn">0.2*a_{0}</code> and <code class="reqn">2*a_{0}</code>, where <code class="reqn">a_{0}</code> is the initial value of the parameter <code class="reqn">a</code>.</p>
</td></tr>
<tr><td><code id="NonlinearFit_+3A_ei4w">ei4w</code></td>
<td>
<p>numeric; vector of weights of to be passed to the <code>nls</code> function. The default values are the inverse of the empirical indicators.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We consider the following set of indicators <code class="reqn">A = (median, ARPR, RMPG, QSR, Gini)</code> and their corresponding GB2 expressions <code class="reqn">A_{GB2}</code>. We fit the parameters of the GB2 in two consecutive steps. In the first step, we use the set of indicators, excluding the median, and their corresponding expressions in function of <code class="reqn">a</code>, <code class="reqn">ap</code> and <code class="reqn">aq</code>. The bounds for <code class="reqn">a</code> are defined in function of the coefficient of variation of the fitted parameter <code class="reqn">\hat(a)</code>. The nonlinear model that is passed to <code>nls</code> is given by:
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^4 c_i (A_{empir,i}-A_{GB2,i}(a,ap,aq))^2,</code>
</p>
<p> where the weights <code class="reqn">c_i</code> take the differing scales into account and are given by the vector <code>ei4w</code>. 
<code class="reqn">ap</code> and <code class="reqn">aq</code> are bounded so that the constraints for the existence of the moments of the GB2 distribution and the excess for calculating the Gini coefficient are fulfilled, 
i.e. <code class="reqn">ap \ge 1</code> and <code class="reqn">aq \ge 2</code>.  In the second step, only the the parameter <code class="reqn">b</code> is estimated, optimizing the weighted square difference between the empirical median and the GB2 median in function of the already obtained NLS parameters <code class="reqn">a, p</code> and <code class="reqn">q</code>. 
</p>


<h3>Value</h3>

<p><code>nlsfit.gb2</code> returns a list of three values: the fitted GB2 parameters, the first fitted object and the second fitted object.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nls">nls</a></code>, <code><a href="#topic+Thomae">Thomae</a></code>, <code><a href="#topic+moment.gb2">moment.gb2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Takes long time to run, as it makes a call to the function ml.gb2

## Not run: 
library(laeken)
data(eusilc)

# Personal income
inc &lt;- as.vector(eusilc$eqIncome)

# Sampling weights
w &lt;- eusilc$rb050

# Data set
d &lt;- data.frame(inc, w)
d &lt;- d[!is.na(d$inc),]
   
# Truncate at 0
d &lt;- d[d$inc &gt; 0,]
inc &lt;- d$inc
w   &lt;- d$w

# ML fit, full log-likelihood
fitf &lt;- ml.gb2(inc, w)$opt1

# Estimated parameters
af &lt;- fitf$par[1]
bf &lt;- fitf$par[2]
pf &lt;- fitf$par[3]
qf &lt;- fitf$par[4]

gb2.par &lt;- c(af, bf, pf, qf)

# Empirical indicators
indicEMP  &lt;- main.emp(inc, w)
indicEMP &lt;- c(indicEMP[1],indicEMP[3:6])
indicE &lt;- round(indicEMP, digits=3)

# Nonlinear fit
nn &lt;- nlsfit.gb2(indicEMP[1,3:6],indicEMP[3:6])
an &lt;- nn[[1]][1]
bn &lt;- nn[[1]][2]
pn &lt;- nn[[1]][3]
qn &lt;- nn[[1]][4]

# GB2 indicators
indicNLS &lt;- c(main.gb2(0.6, an, bn, pn, qn)[1], main.gb2(0.6, an, bn, pn, qn)[3:6])
indicML &lt;- c(main.gb2(0.6, af, bf, pf, qf)[1], main.gb2(0.6, af, bf, pf, qf)[3:6])
indicN &lt;- round(indicNLS, digits=3)
indicM &lt;- round(indicML, digits=3)

# Likelihoods
nlik &lt;- loglp.gb2(inc, an, bn, pn, qn, w)
mlik &lt;- loglp.gb2(inc, af, bf, pf, qf, w)

# Results
type=c("Emp. est", "NLS", "ML full")
results &lt;- data.frame(type=type,
        median=c(indicE[1], indicN[1], indicM[1]),
        ARPR=c(indicE[2], indicN[2], indicM[2]),
        RMPG=c(indicE[3], indicN[3], indicM[3]),
        QSR =c(indicE[4], indicN[4], indicM[4]),
        GINI=c(indicE[5], indicN[5], indicM[5]),
        likelihood=c(NA, nlik, mlik),
        a=c(NA, an, af), b=c(NA, bn, bf) ,p=c(NA, pn, pf), q=c(NA, qn, qf))


## End(Not run)
</code></pre>

<hr>
<h2 id='PlotsML'>
Cumulative Distribution Plot and Kernel Density Plot for the Fitted GB2
</h2><span id='topic+PlotsML'></span><span id='topic+plotsML.gb2'></span><span id='topic+saveplot'></span>

<h3>Description</h3>

<p>Function <code>plotsML.gb2</code> produces two plots. The first is a plot of the empirical cumulative distribution function versus the fitted cumulative distibution function.  
The second is a plot of the kernel density versus the fitted GB2 density.  Function <code>saveplot</code> saves locally the produced plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotsML.gb2(z, shape1, scale, shape2, shape3, w=rep(1,length(z))) 
saveplot(name, pathout)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotsML_+3A_z">z</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="PlotsML_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>z</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="PlotsML_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="PlotsML_+3A_scale">scale</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="PlotsML_+3A_shape2">shape2</code>, <code id="PlotsML_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
<tr><td><code id="PlotsML_+3A_name">name</code></td>
<td>
<p>string; the name of the plot.</p>
</td></tr>
<tr><td><code id="PlotsML_+3A_pathout">pathout</code></td>
<td>
<p>string; the path of the folder or device where the plot will be saved.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The used kernel is &quot;Epanechnikov&quot; (see <code><a href="base.html#topic+plot">plot</a></code>).  
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>

<hr>
<h2 id='ProfLogLikelihood'>
Profile Log-likelihood of the GB2 Distribution
</h2><span id='topic+ProfLogLikelihood'></span><span id='topic+prof.gb2'></span><span id='topic+proflogl.gb2'></span><span id='topic+profscores.gb2'></span>

<h3>Description</h3>

<p>Expression of the parameters <code>shape2</code> <code class="reqn">=p</code> and <code>shape3</code> <code class="reqn">=q</code>  of the GB2 distribution as functions of <code>shape1</code> <code class="reqn">=a</code> and <code>scale</code> <code class="reqn">=b</code>, 
profile log-likelihood of the GB2 distribution, scores of the profile log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prof.gb2(x, shape1, scale, w=rep(1, length(x)))
proflogl.gb2(x, shape1, scale, w=rep(1, length(x)))
profscores.gb2(x, shape1, scale, w=rep(1, length(x)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ProfLogLikelihood_+3A_x">x</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="ProfLogLikelihood_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="ProfLogLikelihood_+3A_scale">scale</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="ProfLogLikelihood_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>x</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using the full log-likelihood equations for the GB2 distribution, the parameters <code class="reqn">p</code> and <code class="reqn">q</code> can be estimated as functions of <code class="reqn">a</code> and <code class="reqn">b</code>.  These functions are plugged into the log-likelihood expression,
which becomes a function of <code class="reqn">a</code> and <code class="reqn">b</code> only. This is obtained by reparametrizing the GB2, i.e. we set <code class="reqn">r=\frac{p}{p+q}</code> and <code class="reqn">s=p+q</code>.  More details can be found in Graf (2009).
</p>


<h3>Value</h3>

<p><code>prof</code> returns a vector containing the values of <code class="reqn">r</code>, <code class="reqn">s</code>, <code class="reqn">p</code>, <code class="reqn">q</code> as well as two other parameters used in the calculation of the profile log-likelihood and its first derivatives.
<code>proflogl.gb2</code> returns the value of the profile log-likelihood and <code>profscores.gb2</code> returns the vector of the first derivatives of the profile log-likelihhod with respect to <code class="reqn">a</code> and <code class="reqn">b</code>.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>References</h3>

<p>Graf, M. (2009)
The Log-Likelihood of the Generalized Beta Distribution of the Second Kind.
<em>working paper</em>, SFSO.
</p>

<hr>
<h2 id='RobustWeights'>
Robustification of the sampling weights
</h2><span id='topic+RobustWeights'></span><span id='topic+robwts'></span>

<h3>Description</h3>

<p>Calculation of a Huber-type correction factor by which the vector of weights is multiplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robwts(x, w=rep(1,length(x)), c=0.01, alpha=0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RobustWeights_+3A_x">x</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="RobustWeights_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>x</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="RobustWeights_+3A_c">c</code></td>
<td>
<p>numeric; a constant which can take different values, e.g. 0.01,0.02. By default <code class="reqn">c=0.1</code>.</p>
</td></tr>
<tr><td><code id="RobustWeights_+3A_alpha">alpha</code></td>
<td>
<p>numeric; a probability in the interval <code class="reqn">(0,1)</code>. By default <code class="reqn">alpha=0.001</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">x</code> denotes the observed value and <code class="reqn">x_{\alpha}</code> the <code class="reqn">\alpha</code>-th qiantile of the Fisk distribution, then we define our scale as:
</p>
<p style="text-align: center;"><code class="reqn">d = \displaystyle \frac{x_{1-\alpha}}{b} - \frac{x_{\alpha}}{b}</code>
</p>
<p>. Next, the correction factor is calculated as follows:
</p>
<p style="text-align: center;"><code class="reqn">corr = \max\left\{c, \min\left(1,\displaystyle \frac{d}{|b/x-1|},\frac{d}{|x/b-1|}\right)\right\}</code>
</p>



<h3>Value</h3>

<p><code>robwts</code> returns a list of two elements: the vector of correction factors by which the weights are multiplied and the vector of corrected (robustified) weights. 
</p>


<h3>Author(s)</h3>

<p>Monique Graf
</p>


<h3>References</h3>

<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>

<hr>
<h2 id='Thomae'>Maximum Excess Representation of a Generalized Hypergeometric Function Using Thomae's Theorem</h2><span id='topic+ULg'></span><span id='topic+combiopt'></span><span id='topic+Thomae'></span><span id='topic+gb2.gini'></span>

<h3>Description</h3>

<p>Defines Thomae's arguments from the upper (<code>U</code>) and lower (<code>L</code>) parameters of a <code class="reqn">_{3}F_{2}(U,L;1)</code>. Computes the optimal combination leading to the maximum excess. 
Computes the optimal combination of Thomae's arguments and calculates the optimal representation of the <code class="reqn">_{3}F_{2}(U,L;1)</code> using the <code>genhypergeo_series</code> function from package <code>hypergeo</code>. 
Computes the Gini coefficient for the GB2 distribution, using Thomae's theorem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ULg(U, L)
combiopt(g)
Thomae(U, L, lB, tol, maxiter, debug)
gb2.gini(shape1, shape2, shape3, tol=1e-08, maxiter=10000, debug=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Thomae_+3A_u">U</code></td>
<td>
<p>numeric; vector of length 3 giving the upper arguments of the generalized hypergeometric function <code class="reqn">_{3}F_{2}</code>.</p>
</td></tr>
<tr><td><code id="Thomae_+3A_l">L</code></td>
<td>
<p>numeric; vector of length 2 giving the lower arguments of the generalized hypergeometric function <code class="reqn">_{3}F_{2}</code>.</p>
</td></tr>
<tr><td><code id="Thomae_+3A_g">g</code></td>
<td>
<p>numeric; vector of Thomae's permuting arguments.</p>
</td></tr>
<tr><td><code id="Thomae_+3A_lb">lB</code></td>
<td>
<p>numeric; ratio of beta functions (a common factor in the expression of the Gini coefficient under the GB2).</p>
</td></tr>
<tr><td><code id="Thomae_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="Thomae_+3A_shape2">shape2</code>, <code id="Thomae_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
<tr><td><code id="Thomae_+3A_tol">tol</code></td>
<td>
<p>numeric; tolerance with default 0, meaning to iterate until additional terms do not change the partial sum.</p>
</td></tr>
<tr><td><code id="Thomae_+3A_maxiter">maxiter</code></td>
<td>
<p>numeric; maximum number of iterations to perform.</p>
</td></tr>
<tr><td><code id="Thomae_+3A_debug">debug</code></td>
<td>
<p>boolean; if <code>TRUE</code>, returns the list of changes to the partial sum.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal use only. More details can be found in Graf (2009). 
</p>


<h3>Value</h3>

<p><code>ULg</code> returns a list containing Thomae's arguments and the excess, <code>combiopt</code> gives the optimal combination of Thomae's arguments, 
<code>Thomae</code> returns the optimal representation of the <code class="reqn">_{3}F_{2}(U,L;1)</code>, <code>gb2.gini</code> returns the value of the Gini coefficient under the GB2.
</p>


<h3>Author(s)</h3>

<p>Monique Graf</p>


<h3>References</h3>

<p>Graf, M. (2009)
An Efficient Algorithm for the Computation of the Gini coefficient of the Generalized Beta Distribution of the Second Kind. 
<em>ASA Proceedings of the Joint Statistical Meetings</em>, 4835&ndash;4843.
American Statistical Association (Alexandria, VA). 
</p>
<p>McDonald, J. B. (1984)
Some generalized functions for the size distribution of income. 
<em>Econometrica</em>, <b>52</b>, 647&ndash;663.
</p>


<h3>See Also</h3>

<p><code><a href="hypergeo.html#topic+genhypergeo_series">genhypergeo_series</a></code>, <code><a href="#topic+gini.gb2">gini.gb2</a></code>
</p>

<hr>
<h2 id='Varest'>
Variance Estimation of the Parameters of the GB2 Distribution
</h2><span id='topic+Varest'></span><span id='topic+varscore.gb2'></span><span id='topic+vepar.gb2'></span><span id='topic+derivind.gb2'></span><span id='topic+veind.gb2'></span>

<h3>Description</h3>

<p>Calculation of variance estimates of the estimated GB2 parameters and the estimated GB2 indicators under cluster sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varscore.gb2(x, shape1, scale, shape2, shape3, w=rep(1,length(x)), hs=rep(1,length(x)))
vepar.gb2(x, Vsc, shape1, scale, shape2, shape3, w=rep(1,length(x)), hs=rep(1,length(x)))
derivind.gb2(shape1, scale, shape2, shape3)
veind.gb2(Vpar, shape1, scale, shape2, shape3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Varest_+3A_x">x</code></td>
<td>
<p>numeric; vector of data values.</p>
</td></tr>
<tr><td><code id="Varest_+3A_vsc">Vsc</code></td>
<td>
<p>numeric; 4 by 4 matrix.</p>
</td></tr>
<tr><td><code id="Varest_+3A_shape1">shape1</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="Varest_+3A_scale">scale</code></td>
<td>
<p>numeric; positive parameter.</p>
</td></tr>
<tr><td><code id="Varest_+3A_shape2">shape2</code>, <code id="Varest_+3A_shape3">shape3</code></td>
<td>
<p>numeric; positive parameters of the Beta distribution.</p>
</td></tr>
<tr><td><code id="Varest_+3A_w">w</code></td>
<td>
<p>numeric; vector of weights. Must have the same length as <code>x</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="Varest_+3A_hs">hs</code></td>
<td>
<p>numeric; vector of household sizes. Must have the same length as <code>x</code>. By default <code>w</code> is a vector of 1.</p>
</td></tr>
<tr><td><code id="Varest_+3A_vpar">Vpar</code></td>
<td>
<p>numeric; 4 by 4 matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Knowing the first and second derivatives of <code class="reqn">log(f)</code>, and using the sandwich variance estimator (see Freedman (2006)), the calculation of the variance estimates of the GB2
parameters is straightforward. <code>Vsc</code> is a square matrix of size the number of parameters, e.g. the estimated design variance-covariance matrix of the estimated parameters. We know that the GB2 estimates of the Laeken indicators are functions of the GB2 parameters. In this case, the variance estimates of the fitted indicators are obtained 
using the delta method. The function <code>veind.gb2</code> uses <code>Vpar</code>, the sandwich variance estimator of the vector of parameters, in order to obtain the sandwich variance estimator of the indicators. More details can be found in Graf and Nedyalkova (2011).
</p>


<h3>Value</h3>

<p><code>varscore.gb2</code> calculates the middle term of the sandwich variance estimator under simple random cluster sampling. <code>vepar.gb2</code> returns a list of two elements: 
the estimated variance-covariance matrix of the estimated GB2 parameters and the second-order partial derivative of the pseudo log-likelihood function.
The function <code>veind.gb2</code> returns the estimated variance-covariance matrix of the estimated GB2 indicators.  <code>derivind.gb2</code> calculates the numerical derivatives of the GB2 indicators and is for internal use only. 
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>References</h3>

<p>Davison, A. (2003),
<em>Statistical Models</em>.
Cambridge University Press.
</p>
<p>Freedman, D. A. (2006),
On The So-Called &quot;Huber Sandwich Estimator&quot; and &quot;Robust Standard Errors&quot;.
<em>The American Statistician</em>, <b>60</b>, 299&ndash;302.
</p>
<p>Graf, M., Nedyalkova, D., Muennich, R., Seger, J. and Zins, S. (2011)
AMELI Deliverable 2.1: Parametric Estimation of Income Distributions and
Indicators of Poverty and Social Exclusion.
<em>Technical report</em>, AMELI-Project.
</p>
<p>Pfeffermann, D. and Sverchkov, M. Yu. (2003),
Fitting Generalized Linear Models under Informative Sampling.
In, Skinner, C.J. and Chambers, R.L. (eds.). 
<em>Analysis of Survey Data</em>, chapter 12, 175&ndash;195.
Wiley, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># An example of variance estimation of the GB2 parameters,
# using the dataset "eusilcP" from the R package simFrame.
# Takes long time to run

## Not run: 
library(survey)
library(simFrame)
data(eusilcP)

# Draw a sample from eusilcP
# 1-stage simple random cluster sampling of size 6000 (cluster = household)
# directly,
#s &lt;- draw(eusilcP[, c("hid", "hsize", "eqIncome")], grouping = "hid", size = 6000)

# or setting up 250 samples, and drawing the first one.
# This sample setup can be used for running a simulation.
set.seed(12345)
scs &lt;- setup(eusilcP, grouping = "hid", size = 6000, k = 250)
s &lt;- draw(eusilcP[, c("region", "hid", "hsize", "eqIncome")], scs, i=1)

# The number of observations (persons) in eusilcP (58654 persons)
\dontrun{N &lt;- dim(eusilcP)[1]} 
# The number of households in eusilcP (25000 households)
Nh &lt;- length(unique(eusilcP$hid)) 

# Survey design corresponding to the drawn sample
sdo = svydesign(id=~hid, fpc=rep(Nh,nrow(s)), data=s)
\dontrun{summary(sdo)}

# Truncated sample (truncate at 0)
s &lt;- s[!is.na(s$eqIncome),] 
str &lt;- s[s$eqIncome &gt; 0, ]
eqInc &lt;- str$eqIncome
w &lt;- str$.weight            

# Designs for the truncated sample
sdotr &lt;- subset(sdo, eqIncome &gt;0)
sddtr = svydesign(id=~hid, strata=~region, fpc=NULL, weights=~.weight, data=str)
\dontrun{summary(sdotr)}
\dontrun{summary(sddtr)}

# Fit by maximum likelihood
fit &lt;- ml.gb2(eqInc,w)$opt1
af &lt;- fit$par[1]
bf &lt;- fit$par[2]
pf &lt;- fit$par[3]
qf &lt;- fit$par[4]
mlik &lt;- -fit$value

# Estimated parameters and indicators, empirical indicators 
gb2.par &lt;- round(c(af, bf, pf, qf), digits=3)
emp.ind &lt;- main.emp(eqInc, w)
gb2.ind &lt;- main.gb2(0.6, af, bf, pf, qf)

# Scores
scores &lt;- matrix(nrow=length(eqInc), ncol=4)
for (i in 1:length(eqInc)){
scores[i,] &lt;- dlogf.gb2(eqInc[i], af, bf, pf, qf)
}

# Data on households only
sh &lt;- unique(str)
heqInc &lt;- sh$eqIncome
hw &lt;- sh$.weight
hhs &lt;- sh$hsize 
hs &lt;- as.numeric(as.vector(hhs))  

# Variance of the scores
VSC &lt;- varscore.gb2(heqInc, af, bf, pf, qf, hw, hs)

# Variance of the scores using the explicit designs, and package survey
DV1 &lt;- vcov(svytotal(~scores[,1]+scores[,2]+scores[,3]+scores[,4], design=sdotr))
DV2 &lt;- vcov(svytotal(~scores[,1]+scores[,2]+scores[,3]+scores[,4], design=sddtr))

# Estimated variance-covariance matrix of the parameters af, bf, pf and qf 
VCMP &lt;- vepar.gb2(heqInc, VSC, af, bf, pf, qf, hw, hs)[[1]]
DVCMP1 &lt;- vepar.gb2(heqInc, DV1, af, bf, pf, qf, hw, hs)[[1]]
DVCMP2 &lt;- vepar.gb2(heqInc, DV2, af, bf, pf, qf, hw, hs)[[1]]

\dontrun{diag(DVCMP1)/diag(VCMP)}
\dontrun{diag(DVCMP2)/diag(VCMP)}
\dontrun{diag(DV1)/diag(VSC)}
\dontrun{diag(DV2)/diag(VSC)}

# Standard errors of af, bf, pf and qf
se.par &lt;- sqrt(diag(VCMP))
sed1.par &lt;- sqrt(diag(DVCMP1))
sed2.par &lt;- sqrt(diag(DVCMP2))

# Estimated variance-covariance matrix of the indicators (VCMI)
VCMI &lt;- veind.gb2(VCMP, af, bf, pf, qf) 
DVCMI1 &lt;- veind.gb2(DVCMP1, af, bf, pf, qf)
DVCMI2 &lt;- veind.gb2(DVCMP2, af, bf, pf, qf)

# Standard errors and confidence intervals
varest.ind &lt;- diag(VCMI)
se.ind &lt;- sqrt(varest.ind)
lci.ind &lt;- gb2.ind - 1.96*se.ind
uci.ind &lt;- gb2.ind + 1.96*se.ind
inCI &lt;- as.numeric(lci.ind &lt;= emp.ind &amp; emp.ind &lt;= uci.ind)

# under the sampling design sdotr

varestd1.ind &lt;- diag(DVCMI1)
sed1.ind &lt;- sqrt(varestd1.ind)
lcid1.ind &lt;- gb2.ind - 1.96*sed1.ind
ucid1.ind &lt;- gb2.ind + 1.96*sed1.ind
inCId1 &lt;- as.numeric(lcid1.ind &lt;= emp.ind &amp; emp.ind &lt;= ucid1.ind)

#under the sampling design sddtr

varestd2.ind &lt;- diag(DVCMI2)
sed2.ind &lt;- sqrt(varestd2.ind)
lcid2.ind &lt;- gb2.ind - 1.96*sed2.ind
ucid2.ind &lt;- gb2.ind + 1.96*sed2.ind
inCId2 &lt;- as.numeric(lcid2.ind &lt;= emp.ind &amp; emp.ind &lt;= ucid2.ind)

#coefficients of variation .par (parameters), .ind (indicators)
cv.par &lt;- se.par/gb2.par
names(cv.par) &lt;- c("am","bm","pm","qm")
cvd1.par &lt;- sed1.par/gb2.par
names(cvd1.par) &lt;- c("am","bm","pm","qm")
cvd2.par &lt;- sed2.par/gb2.par
names(cvd2.par) &lt;- c("am","bm","pm","qm")

cv.ind &lt;- se.ind/gb2.ind
cvd1.ind &lt;- sed1.ind/gb2.ind
cvd2.ind &lt;- sed2.ind/gb2.ind


#results 
res &lt;- data.frame(am = af, bm = bf, pm = pf, qm = qf, lik = mlik,
  median = gb2.ind[[1]], mean = gb2.ind[[2]], ARPR = gb2.ind[[3]], 
    RMPG = gb2.ind[[4]], QSR = gb2.ind[[5]], Gini = gb2.ind[[6]],
  emedian = emp.ind[[1]], emean = emp.ind[[2]], eARPR = emp.ind[[3]], 
    eRMPG = emp.ind[[4]], eQSR = emp.ind[[5]], eGini = emp.ind[[6]],
  cva = cv.par[1], cvb = cv.par[2], cvp= cv.par[3], cvq = cv.par[4],
  cvd1a = cvd1.par[1], cvd1b = cvd1.par[2], cvd1p= cvd1.par[3], cvd1q = cvd1.par[4],
  cvd2a = cvd2.par[1], cvd2b = cvd2.par[2], cvd2p= cvd2.par[3], cvd2q = cvd2.par[4],
  cvmed = cv.ind[[1]], cvmean = cv.ind[[2]], cvARPR = cv.ind[[3]], 
  cvRMPG = cv.ind[[4]], cvQSR = cv.ind[[5]], cvGini = cv.ind[[6]],
  cvd1med = cvd1.ind[[1]], cvd1mean = cvd1.ind[[2]], cvd1ARPR = cvd1.ind[[3]], 
  cvd1RMPG = cvd1.ind[[4]], cvd1QSR = cvd1.ind[[5]], cvd1Gini = cvd1.ind[[6]],
  cvd2med = cvd2.ind[[1]], cvd2mean = cvd2.ind[[2]], cvd2ARPR = cvd2.ind[[3]], 
  cvd2RMPG = cvd2.ind[[4]], cvd2QSR = cvd2.ind[[5]], cvd2Gini = cvd2.ind[[6]])

  res &lt;- list(parameters = data.frame(am = af, bm = bf, pm = pf, qm = qf, lik = mlik),
              cv.parameters.naive = cv.par,
              cv.parameters.design1 = cvd1.par,
              cv.parameters.design2 = cvd2.par,
		  GB2.indicators = gb2.ind,
              emp.indicators = emp.ind,
              cv.indicators.naive = cv.ind,
              cv.indicators.design1 = cvd1.ind,
              cv.indicators.design2 = cvd2.ind)
res
\dontrun{inCI}

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
