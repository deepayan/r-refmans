<!DOCTYPE html><html><head><title>Help for package riAFTBART</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {riAFTBART}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cal_PEHE'><p>Calculate the PEHE</p></a></li>
<li><a href='#cal_surv_prob'><p>Calculate the survival probability from a fitted riAFT-BART model</p></a></li>
<li><a href='#dat_sim'><p>Simulate data with multiple treatments and clustered survival outcomes</p></a></li>
<li><a href='#intree'><p>Interpreting Tree Ensembles with inTrees</p></a></li>
<li><a href='#plot_gps'><p>Plot the propensity score by treatment</p></a></li>
<li><a href='#plot.riAFTBART_estimate'><p>Plot the trace plots for the parameters from a fitted riAFT-BART model</p></a></li>
<li><a href='#plot.riAFTBART_survProb'><p>Plot the fitted survival curves from riAFT-BART model</p></a></li>
<li><a href='#riAFTBART'><p>A flexible approach for causal inference with multiple treatments and clustered survival outcomes</p></a></li>
<li><a href='#riAFTBART_fit'><p>Fit a random effect accelerated failure time BART model</p></a></li>
<li><a href='#sa'><p>Flexible Monte Carlo sensitivity analysis for unmeasured confounding</p></a></li>
<li><a href='#var_select'><p>Perform Variable Selection using Three Threshold-based Procedures</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Flexible Approach for Causal Inference with Multiple
Treatments and Clustered Survival Outcomes</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Random-intercept accelerated failure time (AFT) model utilizing Bayesian additive regression trees (BART) for drawing causal inferences about multiple treatments while accounting for the multilevel survival data structure. It also includes an interpretable sensitivity analysis approach to evaluate how the drawn causal conclusions might be altered in response to the potential magnitude of departure from the no unmeasured confounding assumption.This package implements the methods described by Hu et al. (2022) &lt;<a href="https://doi.org/10.1002%2Fsim.9548">doi:10.1002/sim.9548</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>MCMCpack, msm, dbarts, magrittr, foreach, doParallel, dplyr,
BART, stringr, tidyr, survival, cowplot, ggplot2, twang, nnet,
RRF, randomForest</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-29 21:05:30 UTC; drake</td>
</tr>
<tr>
<td>Author:</td>
<td>Liangyuan Hu [aut],
  Jiayi Ji [aut],
  Fengrui Zhang [cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fengrui Zhang &lt;fz174@sph.rutgers.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-29 23:20:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='cal_PEHE'>Calculate the PEHE</h2><span id='topic+cal_PEHE'></span>

<h3>Description</h3>

<p>This function calculates the PEHE based on the survival probability from a fitted ri-AFTBART model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cal_PEHE(object, metric, time, LP, lambda, eta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cal_PEHE_+3A_object">object</code></td>
<td>
<p>An object from cal_survprob() function.</p>
</td></tr>
<tr><td><code id="cal_PEHE_+3A_metric">metric</code></td>
<td>
<p>A character string representing the metric to be calculated for PEHE. Only <code>"survival"</code> is allowed.</p>
</td></tr>
<tr><td><code id="cal_PEHE_+3A_time">time</code></td>
<td>
<p>A numeric value representing the time point used to calculate PEHE.</p>
</td></tr>
<tr><td><code id="cal_PEHE_+3A_lp">LP</code></td>
<td>
<p>A numeric vector corresponding to the true linear predictors for each treatment from the simulated data.</p>
</td></tr>
<tr><td><code id="cal_PEHE_+3A_lambda">lambda</code></td>
<td>
<p>A numeric value representing the true follow up time for from the simulated data.</p>
</td></tr>
<tr><td><code id="cal_PEHE_+3A_eta">eta</code></td>
<td>
<p>A numeric value to induce proportional/non-proportional hazards assumption from the simulated data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following three components:
</p>
<table>
<tr><td><code>true:</code></td>
<td>
<p>A numeric vector representing the true survival or rmst for each individual.</p>
</td></tr>
<tr><td><code>predicted:</code></td>
<td>
<p>A numeric vector representing the predicted survival or rmst for each individual.</p>
</td></tr>
<tr><td><code>pehe:</code></td>
<td>
<p>A numeric vector representing the calculated pehe.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(riAFTBART)
lp_w_all &lt;-
  c(".4*x1 + .1*x2  - .1*x4 + .1*x5",    #' w = 1
    ".2 * x1 + .2 * x2  - .2 * x4 - .3 * x5")  #' w = 2
nlp_w_all &lt;-
  c("-.5*x1*x4  - .1*x2*x5", #' w = 1
    "-.3*x1*x4 + .2*x2*x5")#' w = 2
lp_y_all &lt;- rep(".2*x1 + .3*x2 - .1*x3 - .1*x4 - .2*x5", 3)
nlp_y_all &lt;- rep(".7*x1*x1  - .1*x2*x3", 3)
X_all &lt;- c(
  "rnorm(10, 0, 0.5)",#' x1
  "rbeta(10, 2, .4)",   #' x2
  "runif(10, 0, 0.5)",#' x3
  "rweibull(10,1,2)",  #' x4
  "rbinom(10, 1, .4)"#' x5
)
set.seed(111111)
data &lt;- dat_sim(
  nK = 2,
  K = 5,
  n_trt = 3,
  X = X_all,
  eta = 2,
  lp_y = lp_y_all,
  nlp_y  = nlp_y_all,
  align = FALSE,
  lp_w = lp_w_all,
  nlp_w = nlp_w_all,
  lambda = c(1000,2000,3000),
  delta = c(0.5,0.5),
  psi = 1,
  sigma_w = 1,
  sigma_y = 2,
  censor_rate = 0.1
)
data$LP_true[,1]
data$lambda
data$eta
res &lt;- riAFTBART_fit(M.burnin = 10, M.keep = 10, M.thin = 1, status = data$delta,
                      y.train = data$Tobs, trt.train = data$w, trt.test = 1,
                      x.train = data$covariates,
                      x.test = data$covariates,
                      cluster.id = data$cluster)
res_cal_surv_prob &lt;- cal_surv_prob(object = res,
time.points = 1:max(data$Tobs),
test.only = TRUE,
cluster.id = data$cluster)

res_cal_PEHE_survival &lt;- cal_PEHE(object = res_cal_surv_prob,
                         metric = "survival", time = 40,
                         LP = data$LP_true[,1], lambda = data$lambda[1],
                         eta = data$eta)

res_cal_PEHE_rmst &lt;- cal_PEHE(object = res_cal_surv_prob,
                                  metric = "rmst",
                                  time = 40,
                                  LP = data$LP_true[,1],
                                  lambda = data$lambda[1],
                                  eta = data$eta)
                                  
</code></pre>

<hr>
<h2 id='cal_surv_prob'>Calculate the survival probability from a fitted riAFT-BART model</h2><span id='topic+cal_surv_prob'></span>

<h3>Description</h3>

<p>This function calculates the individual survival probability from a fitted riAFT-BART model at desired values of times
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cal_surv_prob(
  object,
  time.points,
  test.only = FALSE,
  train.only = FALSE,
  cluster.id
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cal_surv_prob_+3A_object">object</code></td>
<td>
<p>A fitted object from riAFTBART_estimate() function.</p>
</td></tr>
<tr><td><code id="cal_surv_prob_+3A_time.points">time.points</code></td>
<td>
<p>A numeric vector representing the points at which the survival probability is computed.</p>
</td></tr>
<tr><td><code id="cal_surv_prob_+3A_test.only">test.only</code></td>
<td>
<p>A logical indicating whether or not only data from the test set should be computed. The default is FALSE.</p>
</td></tr>
<tr><td><code id="cal_surv_prob_+3A_train.only">train.only</code></td>
<td>
<p>A logical indicating whether or not only data from the training set should be computed. The default is FALSE.</p>
</td></tr>
<tr><td><code id="cal_surv_prob_+3A_cluster.id">cluster.id</code></td>
<td>
<p>A vector of integers representing the cluster id. The cluster id should be an integer and start from 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following two components
</p>
<table>
<tr><td><code>Surv:</code></td>
<td>
<p>A matrix of survival probabilities for each individual.</p>
</td></tr>
<tr><td><code>time.points:</code></td>
<td>
<p>The time point entered.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(riAFTBART)
set.seed(20181223)
n = 50      # number of clusters
k = 50      # cluster size
N = n*k     # total sample size
cluster.id = rep(1:n, each=k)
tau.error = 0.8
b = stats::rnorm(n, 0, tau.error)
alpha = 2
beta1 = 1
beta2 = -1
sig.error = 0.5
censoring.rate = 0.02
x1 = stats::rnorm(N,0.5,1)
x2 = stats::rnorm(N,1.5,0.5)
trt.train = sample(c(1,2,3), N, prob = c(0.4,0.3,0.2), replace = TRUE)
trt.test = sample(c(1,2,3), N, prob = c(0.3,0.4,0.2), replace = TRUE)
error = stats::rnorm(N,0,sig.error)
logtime = alpha + beta1*x1 + beta2*x2 + b[cluster.id] + error
y = exp(logtime)
C = rexp(N, rate=censoring.rate) # censoring times
Y = pmin(y,C)
status = as.numeric(y&lt;=C)
res &lt;- riAFTBART_fit(M.burnin = 50, M.keep = 50, M.thin = 1, status = status,
                      y.train = Y, trt.train = trt.train, trt.test = trt.test,
                      x.train = cbind(x1,x2),
                      x.test = cbind(x1,x2),
                      cluster.id = cluster.id)

surv_prob_res &lt;- cal_surv_prob(object = res, time.points = sort(exp(logtime)),
test.only = TRUE, cluster.id = cluster.id)

</code></pre>

<hr>
<h2 id='dat_sim'>Simulate data with multiple treatments and clustered survival outcomes</h2><span id='topic+dat_sim'></span>

<h3>Description</h3>

<p>This function simulate data with multiple treatments and clustered survival outcomes. Users can adjust the following 11 design factors: (1) The number of clusters, (2) the sample size in each cluster, (3) ratio of units across treatment groups, (4) whether the treatment assignment model and the outcome generating model are linear or nonlinear, (5) whether the covariates that best predict the treatment also predict the outcome well, (6) whether the response surfaces are parallel across treatment groups, (7) degree of covariate overlap, (8) Whether the proportional hazards assumption is satisfied, (9) mean follow up time for each treatment group, (10) censoring proportion and (11) Standard deviation for the cluster effect in the treatment assignment and outcome generating model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dat_sim(
  nK,
  K,
  n_trt,
  X,
  lp_y,
  nlp_y,
  align = TRUE,
  eta,
  lambda,
  delta,
  psi,
  lp_w,
  nlp_w,
  sigma_w,
  sigma_y,
  censor_rate
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dat_sim_+3A_nk">nK</code></td>
<td>
<p>A numeric value indicating the number of clusters.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_k">K</code></td>
<td>
<p>A numeric value indicating the sample size in each cluster.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_n_trt">n_trt</code></td>
<td>
<p>A numeric value indicating the number of treatments.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_x">X</code></td>
<td>
<p>A vector of characters representing covariates, with each covariate being generated from the standard probability <code><a href="stats.html#topic+Distributions">distributions</a></code> in the <code><a href="stats.html#topic+stats-package">stats</a></code> package.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_lp_y">lp_y</code></td>
<td>
<p>A vector of characters of length <code>n_trt</code>, representing the linear effects in the outcome generating model.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_nlp_y">nlp_y</code></td>
<td>
<p>A vector of characters of length <code>n_trt</code>, representing the nonlinear effects in the outcome generating model.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_align">align</code></td>
<td>
<p>A logical indicating whether the predictors in the treatment assignment model are the same as the predictors for the outcome generating model. The default is <code>TRUE</code>. If the argument is set to <code>FALSE</code>, users need to specify additional two arguments <code>lp_w</code> and <code>nlp_w</code>.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_eta">eta</code></td>
<td>
<p>A numeric value to induce proportional hazards assumption or a character including linear combination of Xs to induce nonproportional hazards assumption.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_lambda">lambda</code></td>
<td>
<p>A numeric vector of length <code>n_trt</code> inducing different follow up time across treatment groups.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_delta">delta</code></td>
<td>
<p>A numeric vector of length <code>n_trt</code>-1 inducing different ratio of units across treatment groups.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_psi">psi</code></td>
<td>
<p>A numeric value for the parameter governing the sparsity of covariate overlap.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_lp_w">lp_w</code></td>
<td>
<p>A vector of characters of length <code>n_trt</code> - 1, representing the treatment assignment model.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_nlp_w">nlp_w</code></td>
<td>
<p>A vector of characters of length <code>n_trt</code> - 1, representing the treatment assignment model.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_sigma_w">sigma_w</code></td>
<td>
<p>A numeric value representing the standard deviation for the cluster effect in the treatment assignment model.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_sigma_y">sigma_y</code></td>
<td>
<p>A numeric value representing the standard deviation for the cluster effect in the outcome generating model.</p>
</td></tr>
<tr><td><code id="dat_sim_+3A_censor_rate">censor_rate</code></td>
<td>
<p>A numeric value for the rate parameter governing the proportion of censoring.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with 7 elements for simulated data. It contains
</p>
<table>
<tr><td><code>covariates:</code></td>
<td>
<p>X matrix</p>
</td></tr>
<tr><td><code>w:</code></td>
<td>
<p>treatment indicators</p>
</td></tr>
<tr><td><code>Tobs:</code></td>
<td>
<p>observed follow up time for the simulated right censored data</p>
</td></tr>
<tr><td><code>status:</code></td>
<td>
<p>the censoring indicator</p>
</td></tr>
<tr><td><code>cluster:</code></td>
<td>
<p>the clustering indicator</p>
</td></tr>
<tr><td><code>censor_prop:</code></td>
<td>
<p>the censoring proportion</p>
</td></tr>
<tr><td><code>T_mean:</code></td>
<td>
<p>mean observed follow up time</p>
</td></tr>
<tr><td><code>ratio_of_units:</code></td>
<td>
<p>the proportions of units in each treatment group</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(riAFTBART)
lp_w_all &lt;-
  c(".4*x1 + .1*x2  - .1*x4 + .1*x5",    # w = 1
    ".2 * x1 + .2 * x2  - .2 * x4 - .3 * x5")  # w = 2
nlp_w_all &lt;-
  c("-.5*x1*x4  - .1*x2*x5", # w = 1
    "-.3*x1*x4 + .2*x2*x5")# w = 2
lp_y_all &lt;- rep(".2*x1 + .3*x2 - .1*x3 - .1*x4 - .2*x5", 3)
nlp_y_all &lt;- rep(".7*x1*x1  - .1*x2*x3", 3)
X_all &lt;- c(
  "rnorm(1000, 0, 0.5)",# x1
  "rbeta(1000, 2, .4)",   # x2
  "runif(1000, 0, 0.5)",# x3
  "rweibull(1000,1,2)",  # x4
  "rbinom(1000, 1, .4)"# x5
)
set.seed(111111)
data &lt;- dat_sim(
  nK = 20,
  K = 50,
  n_trt = 3,
  X = X_all,
  eta = 2,
  lp_y = lp_y_all,
  nlp_y  = nlp_y_all,
  align = FALSE,
  lp_w = lp_w_all,
  nlp_w = nlp_w_all,
  lambda = c(1000,2000,3000),
  delta = c(0.5,0.5),
  psi = 1,
  sigma_w = 1,
  sigma_y = 2,
  censor_rate = 0.1
)
</code></pre>

<hr>
<h2 id='intree'>Interpreting Tree Ensembles with inTrees</h2><span id='topic+intree'></span>

<h3>Description</h3>

<p>The inTrees (interpretable trees) framework that extracts, measures, prunes and selects rules from a tree ensemble. All the codes we use are from the inTrees github repository to act as a work around method since package inTrees was removed from the CRAN repository.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intree(X, Y, ntree, typeDecay = 2, digits, n_rule)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intree_+3A_x">X</code></td>
<td>
<p>A matrix indicating the predictor variables.</p>
</td></tr>
<tr><td><code id="intree_+3A_y">Y</code></td>
<td>
<p>A response vector. If a factor, classification is assumed, otherwise regression is assumed.</p>
</td></tr>
<tr><td><code id="intree_+3A_ntree">ntree</code></td>
<td>
<p>Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets predicted at least a few times.</p>
</td></tr>
<tr><td><code id="intree_+3A_typedecay">typeDecay</code></td>
<td>
<p>An integer of 1 or 2. 1 representing relative error and 2 representing error. The default is set to 2.</p>
</td></tr>
<tr><td><code id="intree_+3A_digits">digits</code></td>
<td>
<p>An integer indicating the digits for rounding in Intrees.</p>
</td></tr>
<tr><td><code id="intree_+3A_n_rule">n_rule</code></td>
<td>
<p>An integer indicating the minimum number of rules to consider in Intrees.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix including a set of relevant and non-redundant rules, and their metrics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- within(iris,rm("Species")); Y &lt;- iris[,"Species"]
intree_result &lt;- intree(X, Y, ntree=100, digits = 3, n_rule = 2000)


</code></pre>

<hr>
<h2 id='plot_gps'>Plot the propensity score by treatment</h2><span id='topic+plot_gps'></span>

<h3>Description</h3>

<p>This function estimates the propensity score for each treatment group and then plot the propensity score by each treatment to check covariate overlap.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_gps(trt, X, cluster.id, method = "Multinomial")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_gps_+3A_trt">trt</code></td>
<td>
<p>A numeric vector representing the treatment groups.</p>
</td></tr>
<tr><td><code id="plot_gps_+3A_x">X</code></td>
<td>
<p>A dataframe or matrix, including all the covariates but not treatments, with  rows corresponding to observations and columns to variables.</p>
</td></tr>
<tr><td><code id="plot_gps_+3A_cluster.id">cluster.id</code></td>
<td>
<p>A vector of integers representing the clustering id. The cluster id should be an integer and start from 1.</p>
</td></tr>
<tr><td><code id="plot_gps_+3A_method">method</code></td>
<td>
<p>A character indicating how to estimate the propensity score. The default is &quot;Multinomial&quot;, which uses multinomial regression to estimate the propensity score.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(riAFTBART)
set.seed(20181223)
n = 5       # number of clusters
k = 50      # cluster size
N = n*k     # total sample size
cluster.id = rep(1:n, each=k)
tau.error = 0.8
b = stats::rnorm(n, 0, tau.error)
alpha = 2
beta1 = 1
beta2 = -1
sig.error = 0.5
censoring.rate = 0.02
x1 = stats::rnorm(N,0.5,1)
x2 = stats::rnorm(N,1.5,0.5)
trt.train = sample(c(1,2,3), N, prob = c(0.4,0.3,0.2), replace = TRUE)
plot_gps(trt = trt.train, X = cbind(x1, x2), cluster.id = cluster.id)
</code></pre>

<hr>
<h2 id='plot.riAFTBART_estimate'>Plot the trace plots for the parameters from a fitted riAFT-BART model</h2><span id='topic+plot.riAFTBART_estimate'></span>

<h3>Description</h3>

<p>This function creates the trace plots for the parameters from a fitted riAFT-BART model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'riAFTBART_estimate'
plot(x, focus = "sigma", id = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.riAFTBART_estimate_+3A_x">x</code></td>
<td>
<p>A fitted object of from riAFTBART_fit function.</p>
</td></tr>
<tr><td><code id="plot.riAFTBART_estimate_+3A_focus">focus</code></td>
<td>
<p>A character specifying which parameter to plot.</p>
</td></tr>
<tr><td><code id="plot.riAFTBART_estimate_+3A_id">id</code></td>
<td>
<p>A numeric vector indicating the subject or cluster index to plot, when the object to plot is random intercepts or predicted log survival time.</p>
</td></tr>
<tr><td><code id="plot.riAFTBART_estimate_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(riAFTBART)
set.seed(20181223)
n = 5       # number of clusters
k = 50      # cluster size
N = n*k     # total sample size
cluster.id = rep(1:n, each=k)
tau.error = 0.8
b = stats::rnorm(n, 0, tau.error)
alpha = 2
beta1 = 1
beta2 = -1
sig.error = 0.5
censoring.rate = 0.02
x1 = stats::rnorm(N,0.5,1)
x2 = stats::rnorm(N,1.5,0.5)
trt.train = sample(c(1,2,3), N, prob = c(0.4,0.3,0.2), replace = TRUE)
trt.test = sample(c(1,2,3), N, prob = c(0.3,0.4,0.2), replace = TRUE)
error = stats::rnorm(N,0,sig.error)
logtime = alpha + beta1*x1 + beta2*x2 + b[cluster.id] + error
y = exp(logtime)
C = rexp(N, rate=censoring.rate) # censoring times
Y = pmin(y,C)
status = as.numeric(y&lt;=C)
res &lt;- riAFTBART_fit(M.burnin = 10, M.keep = 10, M.thin = 1, status = status,
                      y.train = Y, trt.train = trt.train, trt.test = trt.test,
                      x.train = cbind(x1,x2),
                      x.test = cbind(x1,x2),
                      cluster.id = cluster.id)
plot(x = res, focus = "sigma")

</code></pre>

<hr>
<h2 id='plot.riAFTBART_survProb'>Plot the fitted survival curves from riAFT-BART model</h2><span id='topic+plot.riAFTBART_survProb'></span>

<h3>Description</h3>

<p>This function plot the mean/individual survival curves from a fitted riAFT-BART model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'riAFTBART_survProb'
plot(x, test.only = FALSE, train.only = TRUE, id = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.riAFTBART_survProb_+3A_x">x</code></td>
<td>
<p>An object from cal_surv_prob() function.</p>
</td></tr>
<tr><td><code id="plot.riAFTBART_survProb_+3A_test.only">test.only</code></td>
<td>
<p>A logical indicating whether or not only data from the test set should be computed. The default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.riAFTBART_survProb_+3A_train.only">train.only</code></td>
<td>
<p>A logical indicating whether or not only data from the training set should be computed. The default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.riAFTBART_survProb_+3A_id">id</code></td>
<td>
<p>A vector representing the IDs for the individual survival curves to plot. The default is NULL and the mean survival curves will be plotted.</p>
</td></tr>
<tr><td><code id="plot.riAFTBART_survProb_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(riAFTBART)
set.seed(20181223)
n = 5       # number of clusters
k = 50      # cluster size
N = n*k     # total sample size
cluster.id = rep(1:n, each=k)
tau.error = 0.8
b = stats::rnorm(n, 0, tau.error)
alpha = 2
beta1 = 1
beta2 = -1
sig.error = 0.5
censoring.rate = 0.02
x1 = stats::rnorm(N,0.5,1)
x2 = stats::rnorm(N,1.5,0.5)
trt.train = sample(c(1,2,3), N, prob = c(0.4,0.3,0.2), replace = TRUE)
trt.test = sample(c(1,2,3), N, prob = c(0.3,0.4,0.2), replace = TRUE)
error = stats::rnorm(N,0,sig.error)
logtime = alpha + beta1*x1 + beta2*x2 + b[cluster.id] + error
y = exp(logtime)
C = rexp(N, rate=censoring.rate) # censoring times
Y = pmin(y,C)
status = as.numeric(y&lt;=C)
res &lt;- riAFTBART_fit(M.burnin = 10, M.keep = 10, M.thin = 1, status = status,
                      y.train = Y, trt.train = trt.train, trt.test = trt.test,
                      x.train = cbind(x1,x2),
                      x.test = cbind(x1,x2),
                      cluster.id = cluster.id)
surv_prob_res &lt;- cal_surv_prob(object = res, time.points = sort(exp(logtime)),
test.only = TRUE, cluster.id = cluster.id)
plot(x = surv_prob_res, test.only = TRUE, train.only = FALSE)

</code></pre>

<hr>
<h2 id='riAFTBART'>A flexible approach for causal inference with multiple treatments and clustered survival outcomes</h2><span id='topic+riAFTBART'></span>

<h3>Description</h3>

<p>This function implements the random effect accelerated failure time BART (riAFT-BART) for causal inference with multiple treatments and clustered survival outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riAFTBART(
  M.burnin,
  M.keep,
  M.thin = 1,
  status,
  y,
  x,
  trt,
  cluster.id,
  verbose = FALSE,
  estimand = "ATE",
  reference_trt = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riAFTBART_+3A_m.burnin">M.burnin</code></td>
<td>
<p>A numeric value indicating the number of MCMC iterations to be treated as burn in.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_m.keep">M.keep</code></td>
<td>
<p>A numeric value indicating the number of MCMC posterior draws after burn in.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_m.thin">M.thin</code></td>
<td>
<p>A numeric value indicating the thinning parameter.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_status">status</code></td>
<td>
<p>A vector of event indicators: status = 1 indicates that the event was observed while status = 0 indicates the observation was right-censored.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_y">y</code></td>
<td>
<p>A vector of follow-up times.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_x">x</code></td>
<td>
<p>A dataframe or matrix, including all the covariates but not treatments with rows corresponding to observations and columns to variables.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_trt">trt</code></td>
<td>
<p>A numeric vector representing the treatment groups.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_cluster.id">cluster.id</code></td>
<td>
<p>A vector of integers representing the clustering id. The cluster id should be an integer and start from 1.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_verbose">verbose</code></td>
<td>
<p>A logical indicating whether to show the progress bar for riAFT-BART. The default is FALSE</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_estimand">estimand</code></td>
<td>
<p>A character string representing the type of causal estimand. Only <code>"ATT"</code> or <code>"ATE"</code> is allowed. When the <code>estimand = "ATT"</code>, users also need to specify the reference treatment group by setting the <code>reference_trt</code> argument.</p>
</td></tr>
<tr><td><code id="riAFTBART_+3A_reference_trt">reference_trt</code></td>
<td>
<p>A numeric value indicating reference treatment group for ATT effect.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of causal estimands in terms of log T between different treatment groups.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(riAFTBART)
set.seed(20181223)
n = 5       # number of clusters
k = 50      # cluster size
N = n*k     # total sample size
cluster.id = rep(1:n, each=k)
tau.error = 0.8
b = stats::rnorm(n, 0, tau.error)
alpha = 2
beta1 = 1
beta2 = -1
sig.error = 0.5
censoring.rate = 0.02
x1 = stats::rnorm(N,0.5,1)
x2 = stats::rnorm(N,1.5,0.5)
trt.train = sample(c(1,2,3), N, prob = c(0.4,0.3,0.2), replace = TRUE)
trt.test = sample(c(1,2,3), N, prob = c(0.3,0.4,0.2), replace = TRUE)
error = stats::rnorm(N,0,sig.error)
logtime = alpha + beta1*x1 + beta2*x2 + b[cluster.id] + error
y = exp(logtime)
C = rexp(N, rate=censoring.rate) # censoring times
Y = pmin(y,C)
status = as.numeric(y&lt;=C)
res_ate &lt;- riAFTBART(M.burnin = 10, M.keep = 10, M.thin = 1, status = status,
                      y = Y, trt = trt.train,
                      x = cbind(x1,x2),
                      cluster.id = cluster.id, estimand = "ATE")

</code></pre>

<hr>
<h2 id='riAFTBART_fit'>Fit a random effect accelerated failure time BART model</h2><span id='topic+riAFTBART_fit'></span>

<h3>Description</h3>

<p>This function implements the random effect accelerated failure time BART (riAFT-BART) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riAFTBART_fit(
  M.burnin,
  M.keep,
  M.thin = 1,
  status,
  y.train,
  x.train,
  trt.train,
  x.test,
  trt.test,
  cluster.id,
  verbose = FALSE,
  SA = FALSE,
  prior_c_function_used = NULL,
  gps = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riAFTBART_fit_+3A_m.burnin">M.burnin</code></td>
<td>
<p>A numeric value indicating the number of MCMC iterations to be treated as burn in.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_m.keep">M.keep</code></td>
<td>
<p>A numeric value indicating the number of MCMC posterior draws after burn in.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_m.thin">M.thin</code></td>
<td>
<p>A numeric value indicating the thinning parameter.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_status">status</code></td>
<td>
<p>A vector of event indicators: status = 1 indicates that the event was observed while status = 0 indicates the observation was right-censored.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_y.train">y.train</code></td>
<td>
<p>A vector of follow-up times.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_x.train">x.train</code></td>
<td>
<p>A dataframe or matrix, including all the covariates but not treatments for training data, with rows corresponding to observations and columns to variables.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_trt.train">trt.train</code></td>
<td>
<p>A numeric vector representing the treatment groups for the training data. If there's no treatment indicator, then set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_x.test">x.test</code></td>
<td>
<p>A dataframe or matrix, including all the covariates but not treatments for testing data, with  rows corresponding to observations and columns to variables.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_trt.test">trt.test</code></td>
<td>
<p>A numeric vector representing the treatment groups for the testing data. If there's no treatment indicator, then set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_cluster.id">cluster.id</code></td>
<td>
<p>A vector of integers representing the clustering id. The cluster id should be an integer and start from 1.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_verbose">verbose</code></td>
<td>
<p>A logical indicating whether to show the progress bar. The default is FALSE</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_sa">SA</code></td>
<td>
<p>A logical indicating whether to conduct sensitivity analysis. The default is FALSE.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_prior_c_function_used">prior_c_function_used</code></td>
<td>
<p>Prior confounding functions used for SA, which is inherited from the sa function. The default is NULL.</p>
</td></tr>
<tr><td><code id="riAFTBART_fit_+3A_gps">gps</code></td>
<td>
<p>Generalized propensity score, which is inherited from the sa function. The default is NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>b:</code></td>
<td>
<p>A matrix including samples from the posterior of the random effects.</p>
</td></tr>
<tr><td><code>tree:</code></td>
<td>
<p>A matrix with M.keep rows and nrow(x.train) columns represnting the predicted log survival time for x.train.</p>
</td></tr>
<tr><td><code>tree.pred:</code></td>
<td>
<p>A matrix with M.keep rows and nrow(x.test) columns represnting the predicted log survival time for x.test.</p>
</td></tr>
<tr><td><code>tau:</code></td>
<td>
<p>A vector representing the posterior samples of tau, the standard deviation of the random effects.</p>
</td></tr>
<tr><td><code>sigma:</code></td>
<td>
<p>A vector representing the posterior samples of sigma, the residual/error standard deviation.</p>
</td></tr>
<tr><td><code>vip:</code></td>
<td>
<p>A matrix with M.keep rows and ncol(x.train) columns represnting the variable inclusion proportions for each variable.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(riAFTBART)
set.seed(20181223)
n = 5       # number of clusters
k = 50      # cluster size
N = n*k     # total sample size
cluster.id = rep(1:n, each=k)
tau.error = 0.8
b = stats::rnorm(n, 0, tau.error)
alpha = 2
beta1 = 1
beta2 = -1
sig.error = 0.5
censoring.rate = 0.02
x1 = stats::rnorm(N,0.5,1)
x2 = stats::rnorm(N,1.5,0.5)
trt.train = sample(c(1,2,3), N, prob = c(0.4,0.3,0.2), replace = TRUE)
trt.test = sample(c(1,2,3), N, prob = c(0.3,0.4,0.2), replace = TRUE)
error = stats::rnorm(N,0,sig.error)
logtime = alpha + beta1*x1 + beta2*x2 + b[cluster.id] + error
y = exp(logtime)
C = rexp(N, rate=censoring.rate) # censoring times
Y = pmin(y,C)
status = as.numeric(y&lt;=C)
res &lt;- riAFTBART_fit(M.burnin = 10, M.keep = 10, M.thin = 1, status = status,
                      y.train = Y, trt.train = trt.train, trt.test = trt.test,
                      x.train = cbind(x1,x2),
                      x.test = cbind(x1,x2),
                      cluster.id = cluster.id)

</code></pre>

<hr>
<h2 id='sa'>Flexible Monte Carlo sensitivity analysis for unmeasured confounding</h2><span id='topic+sa'></span>

<h3>Description</h3>

<p>This function implements the flexible sensitivity analysis approach for unmeasured confounding with multiple treatments from multilevel survival data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sa(
  M.burnin,
  M.keep,
  M.thin = 1,
  status,
  y.train,
  x.train,
  trt.train,
  x.test,
  trt.test,
  cluster.id,
  verbose = FALSE,
  formula = NULL,
  prior_c_function,
  Q1,
  Q2 = NULL,
  nCores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sa_+3A_m.burnin">M.burnin</code></td>
<td>
<p>A numeric value indicating the number of MCMC iterations to be treated as burn in.</p>
</td></tr>
<tr><td><code id="sa_+3A_m.keep">M.keep</code></td>
<td>
<p>A numeric value indicating the number of MCMC posterior draws after burn in.</p>
</td></tr>
<tr><td><code id="sa_+3A_m.thin">M.thin</code></td>
<td>
<p>A numeric value indicating the thinning parameter.</p>
</td></tr>
<tr><td><code id="sa_+3A_status">status</code></td>
<td>
<p>A vector of event indicators: status = 1 indicates that the event was observed while status = 0 indicates the observation was right-censored.</p>
</td></tr>
<tr><td><code id="sa_+3A_y.train">y.train</code></td>
<td>
<p>A vector of follow-up times.</p>
</td></tr>
<tr><td><code id="sa_+3A_x.train">x.train</code></td>
<td>
<p>A dataframe or matrix, including all the covariates but not treatments for training data, with rows corresponding to observations and columns to variables.</p>
</td></tr>
<tr><td><code id="sa_+3A_trt.train">trt.train</code></td>
<td>
<p>A numeric vector representing the treatment groups for the training data.</p>
</td></tr>
<tr><td><code id="sa_+3A_x.test">x.test</code></td>
<td>
<p>A dataframe, including all the covariates but not treatments for testing data, with rows corresponding to observations and columns to variables.</p>
</td></tr>
<tr><td><code id="sa_+3A_trt.test">trt.test</code></td>
<td>
<p>A numeric vector representing the treatment groups for the testing data.</p>
</td></tr>
<tr><td><code id="sa_+3A_cluster.id">cluster.id</code></td>
<td>
<p>A vector of integers representing the clustering id.</p>
</td></tr>
<tr><td><code id="sa_+3A_verbose">verbose</code></td>
<td>
<p>A logical indicating whether to show the progress bar. The default is FALSE</p>
</td></tr>
<tr><td><code id="sa_+3A_formula">formula</code></td>
<td>
<p>A <code><a href="stats.html#topic+formula">formula</a></code> object for the analysis. The default is to use all terms specified in <code>x.train</code>.</p>
</td></tr>
<tr><td><code id="sa_+3A_prior_c_function">prior_c_function</code></td>
<td>
<p>1) A vector of characters indicating the prior distributions for the confounding functions. Each character contains the random number generation code from the standard probability <code><a href="stats.html#topic+Distributions">distributions</a></code> in the <code><a href="stats.html#topic+stats-package">stats</a></code> package. 2) A vector of characters including the grid specifications for the confounding functions. It should be used when users want to formulate the  confounding  functions as scalar values. 3) A matrix indicating the point mass prior for the confounding functions</p>
</td></tr>
<tr><td><code id="sa_+3A_q1">Q1</code></td>
<td>
<p>A numeric value indicating the number of draws of the GPS from the posterior predictive distribution</p>
</td></tr>
<tr><td><code id="sa_+3A_q2">Q2</code></td>
<td>
<p>A numeric value indicating the number of draws from the prior distributions of the confounding functions</p>
</td></tr>
<tr><td><code id="sa_+3A_ncores">nCores</code></td>
<td>
<p>A numeric value indicating number of cores to use for parallel computing.</p>
</td></tr>
<tr><td><code id="sa_+3A_...">...</code></td>
<td>
<p>Other parameters that can be passed to BART functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>result_riAFTBART:</code></td>
<td>
<p>Corrected log survival time for the test data from the riAFT-BART model.</p>
</td></tr>
<tr><td><code>c_functions:</code></td>
<td>
<p>The confounding functions sampled from the specified distribution used in the analysis.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(20181223)
n = 5       # number of clusters
k = 50      # cluster size
N = n*k     # total sample size
cluster.id = rep(1:n, each=k)
tau.error = 0.8
b = rnorm(n, 0, tau.error)
alpha = 2
beta1 = 1
beta2 = -1
beta3 = -2
sig.error = 0.5
censoring.rate = 0.02
x1 = rnorm(N,0.5,1)
x2 = rnorm(N,1.5,0.5)
trt.train = sample(c(1,2,3), N, prob = c(0.4,0.3,0.2), replace = TRUE)
trt.test = sample(c(1,2,3), N, prob = c(0.3,0.4,0.2), replace = TRUE)
error = rnorm(N,0,sig.error)
logtime = alpha + beta1*x1 + beta2*x2 + b[cluster.id] + error
y = exp(logtime)
C = rexp(N, rate=censoring.rate) # censoring times
Y = pmin(y,C)
status = as.numeric(y&lt;=C)
res_sa &lt;- sa(M.burnin = 10, M.keep = 10, M.thin = 1, status = status,
             y.train = Y,trt.train = trt.train,trt.test = trt.test,
             x.train = cbind(x1,x2),
             x.test = cbind(x1,x2),
             cluster.id = cluster.id, verbose = F,prior_c_function = c(
               "runif(-0.6, 0)",# c(1,2)
               "runif(0, 0.6)",# c(2,1)
               "runif(-0.6, 0)", # c(2,3)
               "seq(-0.6, 0, by = 0.3)", # c(1,3)
               "seq(0, 0.6, by = 0.3)", # c(3,1)
              "runif(0, 0.6)" # c(3,2)
            ),Q1 = 1, nCores = 1)
 
</code></pre>

<hr>
<h2 id='var_select'>Perform Variable Selection using Three Threshold-based Procedures</h2><span id='topic+var_select'></span>

<h3>Description</h3>

<p>Performs variable selection with ri-AFTBART using the three thresholding methods introduced in Bleich et al. (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_select(
  M.burnin,
  M.keep,
  M.thin = 1,
  status,
  y.train,
  x.train,
  trt.train,
  x.test,
  trt.test,
  cluster.id,
  verbose = FALSE,
  n_permuate,
  alpha = 0.1,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_select_+3A_m.burnin">M.burnin</code></td>
<td>
<p>A numeric value indicating the number of MCMC iterations to be treated as burn in.</p>
</td></tr>
<tr><td><code id="var_select_+3A_m.keep">M.keep</code></td>
<td>
<p>A numeric value indicating the number of MCMC posterior draws after burn in.</p>
</td></tr>
<tr><td><code id="var_select_+3A_m.thin">M.thin</code></td>
<td>
<p>A numeric value indicating the thinning parameter.</p>
</td></tr>
<tr><td><code id="var_select_+3A_status">status</code></td>
<td>
<p>A vector of event indicators: status = 1 indicates that the event was observed while status = 0 indicates the observation was right-censored.</p>
</td></tr>
<tr><td><code id="var_select_+3A_y.train">y.train</code></td>
<td>
<p>A vector of follow-up times.</p>
</td></tr>
<tr><td><code id="var_select_+3A_x.train">x.train</code></td>
<td>
<p>A dataframe or matrix, including all the covariates but not treatments for training data, with rows corresponding to observations and columns to variables.</p>
</td></tr>
<tr><td><code id="var_select_+3A_trt.train">trt.train</code></td>
<td>
<p>A numeric vector representing the treatment groups for the training data.</p>
</td></tr>
<tr><td><code id="var_select_+3A_x.test">x.test</code></td>
<td>
<p>A dataframe or matrix, including all the covariates but not treatments for testing data, with  rows corresponding to observations and columns to variables.</p>
</td></tr>
<tr><td><code id="var_select_+3A_trt.test">trt.test</code></td>
<td>
<p>A numeric vector representing the treatment groups for the testing data.</p>
</td></tr>
<tr><td><code id="var_select_+3A_cluster.id">cluster.id</code></td>
<td>
<p>A vector of integers representing the clustering id. The cluster id should be an integer and start from 1.</p>
</td></tr>
<tr><td><code id="var_select_+3A_verbose">verbose</code></td>
<td>
<p>A logical indicating whether to show the progress bar. The default is FALSE.</p>
</td></tr>
<tr><td><code id="var_select_+3A_n_permuate">n_permuate</code></td>
<td>
<p>Number of permutations of the event time together with the censoring indicator to generate the null permutation distribution.</p>
</td></tr>
<tr><td><code id="var_select_+3A_alpha">alpha</code></td>
<td>
<p>Cut-off level for the thresholds.</p>
</td></tr>
<tr><td><code id="var_select_+3A_seed">seed</code></td>
<td>
<p>An optional integer value to set the random seed for reproducibility. Default is NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>var_local_selected:</code></td>
<td>
<p>A character vector including all the variables selected using Local procedure.</p>
</td></tr>
<tr><td><code>var_max_selected:</code></td>
<td>
<p>A character vector including all the variables selected using Global Max procedure.</p>
</td></tr>
<tr><td><code>var_global_se_selected:</code></td>
<td>
<p>A character vector including all the variables selected using Global SE procedure.</p>
</td></tr>
<tr><td><code>vip_perm:</code></td>
<td>
<p>The permutation distribution for the variable inclusion proportions generated by permuting the event time together with the censoring indicator.</p>
</td></tr>
<tr><td><code>vip_obs:</code></td>
<td>
<p>The variable inclusion proportions for the actual data.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(20181223)
n = 2
k = 50
N = n*k
cluster.id = rep(1:n, each=k)
tau.error = 0.8
b = rnorm(n, 0, tau.error)
alpha = 2
beta1 = 1
beta2 = -1
beta3 = -2
sig.error = 0.5
censoring.rate = 0.02
x1 = rnorm(N,0.5,1)
x2 = rnorm(N,1.5,0.5)
error = rnorm(N,0,sig.error)
logtime = alpha + beta1*x1 + beta2*x2 + b[cluster.id] + error
y = exp(logtime)
C = rexp(N, rate=censoring.rate)
Y = pmin(y,C)
status = as.numeric(y&lt;=C)
trt.train = sample(c(1,2,3), N, prob = c(0.4,0.3,0.2), replace = TRUE)
trt.test = sample(c(1,2,3), N, prob = c(0.3,0.4,0.2), replace = TRUE)
res &lt;- var_select(M.burnin = 10, M.keep = 10, M.thin = 1, status = status,
                      y.train = Y, trt.train = trt.train, trt.test = trt.test,
                      x.train = cbind(x1,x2),
                      x.test = cbind(x1,x2),
                      cluster.id = cluster.id,
                      n_permuate = 4,alpha = 0.1,seed = 20181223)
                      
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
