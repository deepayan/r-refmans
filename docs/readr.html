<!DOCTYPE html><html><head><title>Help for package readr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {readr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.col_spec'><p>Generate a column specification</p></a></li>
<li><a href='#callback'><p>Callback classes</p></a></li>
<li><a href='#clipboard'><p>Returns values from the clipboard</p></a></li>
<li><a href='#col_skip'><p>Skip a column</p></a></li>
<li><a href='#cols'><p>Create column specification</p></a></li>
<li><a href='#cols_condense'><p>Examine the column specifications for a data frame</p></a></li>
<li><a href='#count_fields'><p>Count the number of fields in each line of a file</p></a></li>
<li><a href='#datasource'><p>Create a source object.</p></a></li>
<li><a href='#date_names'><p>Create or retrieve date names</p></a></li>
<li><a href='#edition_get'><p>Retrieve the currently active edition</p></a></li>
<li><a href='#format_delim'><p>Convert a data frame to a delimited string</p></a></li>
<li><a href='#guess_encoding'><p>Guess encoding of file</p></a></li>
<li><a href='#locale'><p>Create locales</p></a></li>
<li><a href='#melt_delim'><p>Return melted data for each token in a delimited file (including csv &amp; tsv)</p></a></li>
<li><a href='#melt_delim_chunked'><p>Melt a delimited file by chunks</p></a></li>
<li><a href='#melt_fwf'><p>Return melted data for each token in a fixed width file</p></a></li>
<li><a href='#melt_table'><p>Return melted data for each token in a whitespace-separated file</p></a></li>
<li><a href='#output_column'><p>Preprocess column for output</p></a></li>
<li><a href='#parse_atomic'><p>Parse logicals, integers, and reals</p></a></li>
<li><a href='#parse_datetime'><p>Parse date/times</p></a></li>
<li><a href='#parse_factor'><p>Parse factors</p></a></li>
<li><a href='#parse_guess'><p>Parse using the &quot;best&quot; type</p></a></li>
<li><a href='#parse_number'><p>Parse numbers, flexibly</p></a></li>
<li><a href='#parse_vector'><p>Parse a character vector.</p></a></li>
<li><a href='#problems'><p>Retrieve parsing problems</p></a></li>
<li><a href='#read_builtin'><p>Read built-in object from package</p></a></li>
<li><a href='#read_delim'><p>Read a delimited file (including CSV and TSV) into a tibble</p></a></li>
<li><a href='#read_delim_chunked'><p>Read a delimited file by chunks</p></a></li>
<li><a href='#read_file'><p>Read/write a complete file</p></a></li>
<li><a href='#read_fwf'><p>Read a fixed width file into a tibble</p></a></li>
<li><a href='#read_lines'><p>Read/write lines to/from a file</p></a></li>
<li><a href='#read_lines_chunked'><p>Read lines from a file or string by chunk.</p></a></li>
<li><a href='#read_log'><p>Read common/combined log file into a tibble</p></a></li>
<li><a href='#read_rds'><p>Read/write RDS files.</p></a></li>
<li><a href='#read_table'><p>Read whitespace-separated columns into a tibble</p></a></li>
<li><a href='#read_table2'><p>Read whitespace-separated columns into a tibble</p></a></li>
<li><a href='#readr_example'><p>Get path to readr example</p></a></li>
<li><a href='#readr_threads'><p>Determine how many threads readr should use when processing</p></a></li>
<li><a href='#readr-package'><p>readr: Read Rectangular Text Data</p></a></li>
<li><a href='#should_read_lazy'><p>Determine whether to read a file lazily</p></a></li>
<li><a href='#should_show_types'><p>Determine whether column types should be shown</p></a></li>
<li><a href='#show_progress'><p>Determine whether progress bars should be shown</p></a></li>
<li><a href='#spec_delim'><p>Generate a column specification</p></a></li>
<li><a href='#tokenize'><p>Tokenize a file/string.</p></a></li>
<li><a href='#Tokenizers'><p>Tokenizers.</p></a></li>
<li><a href='#type_convert'><p>Re-convert character columns in existing data frame</p></a></li>
<li><a href='#with_edition'><p>Temporarily change the active readr edition</p></a></li>
<li><a href='#write_delim'><p>Write a data frame to a delimited file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Read Rectangular Text Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.5</td>
</tr>
<tr>
<td>Description:</td>
<td>The goal of 'readr' is to provide a fast and friendly way to
    read rectangular data (like 'csv', 'tsv', and 'fwf').  It is designed
    to flexibly parse many types of data found in the wild, while still
    cleanly failing when data unexpectedly changes.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://readr.tidyverse.org">https://readr.tidyverse.org</a>, <a href="https://github.com/tidyverse/readr">https://github.com/tidyverse/readr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tidyverse/readr/issues">https://github.com/tidyverse/readr/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cli (&ge; 3.2.0), clipr, crayon, hms (&ge; 0.4.1), lifecycle (&ge;
0.2.0), methods, R6, rlang, tibble, utils, vroom (&ge; 1.6.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, curl, datasets, knitr, rmarkdown, spelling, stringi,
testthat (&ge; 3.2.0), tzdb (&ge; 0.1.1), waldo, withr, xml2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>cpp11, tzdb (&ge; 0.1.1)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>tidyverse, tidyverse/tidytemplate</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>false</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-10 21:03:49 UTC; jenny</td>
</tr>
<tr>
<td>Author:</td>
<td>Hadley Wickham [aut],
  Jim Hester [aut],
  Romain Francois [ctb],
  Jennifer Bryan <a href="https://orcid.org/0000-0002-6983-2759"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Shelby Bearrows [ctb],
  Posit Software, PBC [cph, fnd],
  https://github.com/mandreyel/ [cph] (mio library),
  Jukka Jylänki [ctb, cph] (grisu3 implementation),
  Mikkel Jørgensen [ctb, cph] (grisu3 implementation)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jennifer Bryan &lt;jenny@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-10 23:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.col_spec'>Generate a column specification</h2><span id='topic+as.col_spec'></span>

<h3>Description</h3>

<p>This is most useful for generating a specification using the short form
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.col_spec(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.col_spec_+3A_x">x</code></td>
<td>
<p>Input object</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>as.col_spec("cccnnn")
</code></pre>

<hr>
<h2 id='callback'>Callback classes</h2><span id='topic+callback'></span><span id='topic+ChunkCallback'></span><span id='topic+SideEffectChunkCallback'></span><span id='topic+DataFrameCallback'></span><span id='topic+ListCallback'></span><span id='topic+AccumulateCallback'></span>

<h3>Description</h3>

<p>These classes are used to define callback behaviors.
</p>


<h3>Details</h3>


<dl>
<dt>ChunkCallback</dt><dd><p>Callback interface definition, all callback functions should inherit from this class.</p>
</dd>
<dt>SideEffectChunkCallback</dt><dd><p>Callback function that is used only for side effects, no results are returned.</p>
</dd>
<dt>DataFrameCallback</dt><dd><p>Callback function that combines each result together at the end.</p>
</dd>
<dt>AccumulateCallBack</dt><dd>
<p>Callback function that accumulates a single result. Requires the parameter <code>acc</code> to specify
the initial value of the accumulator.  The parameter <code>acc</code> is <code>NULL</code> by default.
</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other chunked: 
<code><a href="#topic+melt_delim_chunked">melt_delim_chunked</a>()</code>,
<code><a href="#topic+read_delim_chunked">read_delim_chunked</a>()</code>,
<code><a href="#topic+read_lines_chunked">read_lines_chunked</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## If given a regular function it is converted to a SideEffectChunkCallback

# view structure of each chunk
read_lines_chunked(readr_example("mtcars.csv"), str, chunk_size = 5)

# Print starting line of each chunk
f &lt;- function(x, pos) print(pos)
read_lines_chunked(readr_example("mtcars.csv"), SideEffectChunkCallback$new(f), chunk_size = 5)

# If combined results are desired you can use the DataFrameCallback

# Cars with 3 gears
f &lt;- function(x, pos) subset(x, gear == 3)
read_csv_chunked(readr_example("mtcars.csv"), DataFrameCallback$new(f), chunk_size = 5)

# The ListCallback can be used for more flexible output
f &lt;- function(x, pos) x$mpg[x$hp &gt; 100]
read_csv_chunked(readr_example("mtcars.csv"), ListCallback$new(f), chunk_size = 5)

# The AccumulateCallback accumulates results from each chunk
f &lt;- function(x, pos, acc) sum(x$mpg) + acc
read_csv_chunked(readr_example("mtcars.csv"), AccumulateCallback$new(f, acc = 0), chunk_size = 5)
</code></pre>

<hr>
<h2 id='clipboard'>Returns values from the clipboard</h2><span id='topic+clipboard'></span>

<h3>Description</h3>

<p>This is useful in the <code><a href="#topic+read_delim">read_delim()</a></code> functions to read from the clipboard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clipboard()
</code></pre>


<h3>See Also</h3>

<p>read_delim
</p>

<hr>
<h2 id='col_skip'>Skip a column</h2><span id='topic+col_skip'></span>

<h3>Description</h3>

<p>Use this function to ignore a column when reading in a file.
To skip all columns not otherwise specified, use <code><a href="#topic+cols_only">cols_only()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>col_skip()
</code></pre>


<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+cols_condense">cols_condense</a>()</code>,
<code><a href="#topic+cols">cols</a>()</code>,
<code><a href="#topic+parse_datetime">parse_datetime</a>()</code>,
<code><a href="#topic+parse_factor">parse_factor</a>()</code>,
<code><a href="#topic+parse_guess">parse_guess</a>()</code>,
<code><a href="#topic+parse_logical">parse_logical</a>()</code>,
<code><a href="#topic+parse_number">parse_number</a>()</code>,
<code><a href="#topic+parse_vector">parse_vector</a>()</code>
</p>

<hr>
<h2 id='cols'>Create column specification</h2><span id='topic+cols'></span><span id='topic+cols_only'></span>

<h3>Description</h3>

<p><code>cols()</code> includes all columns in the input data, guessing the column types
as the default. <code>cols_only()</code> includes only the columns you explicitly
specify, skipping the rest. In general you can substitute <code>list()</code> for
<code>cols()</code> without changing the behavior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cols(..., .default = col_guess())

cols_only(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cols_+3A_...">...</code></td>
<td>
<p>Either column objects created by <code style="white-space: pre;">&#8288;col_*()&#8288;</code>, or their abbreviated
character names (as described in the <code>col_types</code> argument of
<code><a href="#topic+read_delim">read_delim()</a></code>). If you're only overriding a few columns, it's
best to refer to columns by name. If not named, the column types must match
the column names exactly.</p>
</td></tr>
<tr><td><code id="cols_+3A_.default">.default</code></td>
<td>
<p>Any named columns not explicitly overridden in <code>...</code>
will be read with this column type.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The available specifications are: (with string abbreviations in brackets)
</p>

<ul>
<li> <p><code>col_logical()</code> [l], containing only <code>T</code>, <code>F</code>, <code>TRUE</code> or <code>FALSE</code>.
</p>
</li>
<li> <p><code>col_integer()</code> [i], integers.
</p>
</li>
<li> <p><code>col_double()</code> [d], doubles.
</p>
</li>
<li> <p><code>col_character()</code> [c], everything else.
</p>
</li>
<li> <p><code>col_factor(levels, ordered)</code> [f], a fixed set of values.
</p>
</li>
<li> <p><code>col_date(format = "")</code> [D]: with the locale's <code>date_format</code>.
</p>
</li>
<li> <p><code>col_time(format = "")</code> [t]: with the locale's <code>time_format</code>.
</p>
</li>
<li> <p><code>col_datetime(format = "")</code> [T]: ISO8601 date times
</p>
</li>
<li> <p><code>col_number()</code> [n], numbers containing the <code>grouping_mark</code>
</p>
</li>
<li> <p><code>col_skip()</code> [_, -], don't import this column.
</p>
</li>
<li> <p><code>col_guess()</code> [?], parse using the &quot;best&quot; type based on the input.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+col_skip">col_skip</a>()</code>,
<code><a href="#topic+cols_condense">cols_condense</a>()</code>,
<code><a href="#topic+parse_datetime">parse_datetime</a>()</code>,
<code><a href="#topic+parse_factor">parse_factor</a>()</code>,
<code><a href="#topic+parse_guess">parse_guess</a>()</code>,
<code><a href="#topic+parse_logical">parse_logical</a>()</code>,
<code><a href="#topic+parse_number">parse_number</a>()</code>,
<code><a href="#topic+parse_vector">parse_vector</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cols(a = col_integer())
cols_only(a = col_integer())

# You can also use the standard abbreviations
cols(a = "i")
cols(a = "i", b = "d", c = "_")

# You can also use multiple sets of column definitions by combining
# them like so:

t1 &lt;- cols(
  column_one = col_integer(),
  column_two = col_number()
)

t2 &lt;- cols(
  column_three = col_character()
)

t3 &lt;- t1
t3$cols &lt;- c(t1$cols, t2$cols)
t3
</code></pre>

<hr>
<h2 id='cols_condense'>Examine the column specifications for a data frame</h2><span id='topic+cols_condense'></span><span id='topic+spec'></span>

<h3>Description</h3>

<p><code>cols_condense()</code> takes a spec object and condenses its definition by setting
the default column type to the most frequent type and only listing columns
with a different type.
</p>
<p><code>spec()</code> extracts the full column specification from a tibble
created by readr.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cols_condense(x)

spec(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cols_condense_+3A_x">x</code></td>
<td>
<p>The data frame object to extract from</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A col_spec object.
</p>


<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+col_skip">col_skip</a>()</code>,
<code><a href="#topic+cols">cols</a>()</code>,
<code><a href="#topic+parse_datetime">parse_datetime</a>()</code>,
<code><a href="#topic+parse_factor">parse_factor</a>()</code>,
<code><a href="#topic+parse_guess">parse_guess</a>()</code>,
<code><a href="#topic+parse_logical">parse_logical</a>()</code>,
<code><a href="#topic+parse_number">parse_number</a>()</code>,
<code><a href="#topic+parse_vector">parse_vector</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- read_csv(readr_example("mtcars.csv"))
s &lt;- spec(df)
s

cols_condense(s)
</code></pre>

<hr>
<h2 id='count_fields'>Count the number of fields in each line of a file</h2><span id='topic+count_fields'></span>

<h3>Description</h3>

<p>This is useful for diagnosing problems with functions that fail
to parse correctly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_fields(file, tokenizer, skip = 0, n_max = -1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="count_fields_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="count_fields_+3A_tokenizer">tokenizer</code></td>
<td>
<p>A tokenizer that specifies how to break the <code>file</code>
up into fields, e.g., <code><a href="#topic+tokenizer_csv">tokenizer_csv()</a></code>,
<code><a href="#topic+tokenizer_fwf">tokenizer_fwf()</a></code></p>
</td></tr>
<tr><td><code id="count_fields_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr><td><code id="count_fields_+3A_n_max">n_max</code></td>
<td>
<p>Optionally, maximum number of rows to count fields for.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>count_fields(readr_example("mtcars.csv"), tokenizer_csv())
</code></pre>

<hr>
<h2 id='datasource'>Create a source object.</h2><span id='topic+datasource'></span>

<h3>Description</h3>

<p>Create a source object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>datasource(
  file,
  skip = 0,
  skip_empty_rows = FALSE,
  comment = "",
  skip_quote = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="datasource_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="datasource_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Literal csv
datasource("a,b,c\n1,2,3")
datasource(charToRaw("a,b,c\n1,2,3"))

# Strings
datasource(readr_example("mtcars.csv"))
datasource(readr_example("mtcars.csv.bz2"))
datasource(readr_example("mtcars.csv.zip"))
## Not run: 
datasource("https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv")

## End(Not run)

# Connection
con &lt;- rawConnection(charToRaw("abc\n123"))
datasource(con)
close(con)
</code></pre>

<hr>
<h2 id='date_names'>Create or retrieve date names</h2><span id='topic+date_names'></span><span id='topic+date_names_lang'></span><span id='topic+date_names_langs'></span>

<h3>Description</h3>

<p>When parsing dates, you often need to know how weekdays of the week and
months are represented as text. This pair of functions allows you to either
create your own, or retrieve from a standard list. The standard list is
derived from ICU (<code style="white-space: pre;">&#8288;http://site.icu-project.org&#8288;</code>) via the stringi package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>date_names(mon, mon_ab = mon, day, day_ab = day, am_pm = c("AM", "PM"))

date_names_lang(language)

date_names_langs()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="date_names_+3A_mon">mon</code>, <code id="date_names_+3A_mon_ab">mon_ab</code></td>
<td>
<p>Full and abbreviated month names.</p>
</td></tr>
<tr><td><code id="date_names_+3A_day">day</code>, <code id="date_names_+3A_day_ab">day_ab</code></td>
<td>
<p>Full and abbreviated week day names. Starts with Sunday.</p>
</td></tr>
<tr><td><code id="date_names_+3A_am_pm">am_pm</code></td>
<td>
<p>Names used for AM and PM.</p>
</td></tr>
<tr><td><code id="date_names_+3A_language">language</code></td>
<td>
<p>A BCP 47 locale, made up of a language and a region,
e.g. <code>"en"</code> for American English. See <code>date_names_langs()</code>
for a complete list of available locales.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>date_names_lang("en")
date_names_lang("ko")
date_names_lang("fr")
</code></pre>

<hr>
<h2 id='edition_get'>Retrieve the currently active edition</h2><span id='topic+edition_get'></span>

<h3>Description</h3>

<p>Retrieve the currently active edition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edition_get()
</code></pre>


<h3>Value</h3>

<p>An integer corresponding to the currently active edition.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>edition_get()
</code></pre>

<hr>
<h2 id='format_delim'>Convert a data frame to a delimited string</h2><span id='topic+format_delim'></span><span id='topic+format_csv'></span><span id='topic+format_csv2'></span><span id='topic+format_tsv'></span>

<h3>Description</h3>

<p>These functions are equivalent to <code><a href="#topic+write_csv">write_csv()</a></code> etc., but instead
of writing to disk, they return a string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_delim(
  x,
  delim,
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  quote_escape = deprecated()
)

format_csv(
  x,
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  quote_escape = deprecated()
)

format_csv2(
  x,
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  quote_escape = deprecated()
)

format_tsv(
  x,
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  quote_escape = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_delim_+3A_x">x</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="format_delim_+3A_delim">delim</code></td>
<td>
<p>Delimiter used to separate values. Defaults to <code>" "</code> for <code>write_delim()</code>, <code>","</code> for <code>write_excel_csv()</code> and
<code>";"</code> for <code>write_excel_csv2()</code>. Must be a single character.</p>
</td></tr>
<tr><td><code id="format_delim_+3A_na">na</code></td>
<td>
<p>String used for missing values. Defaults to NA. Missing values
will never be quoted; strings with the same value as <code>na</code> will
always be quoted.</p>
</td></tr>
<tr><td><code id="format_delim_+3A_append">append</code></td>
<td>
<p>If <code>FALSE</code>, will overwrite existing file. If <code>TRUE</code>,
will append to existing file. In both cases, if the file does not exist a new
file is created.</p>
</td></tr>
<tr><td><code id="format_delim_+3A_col_names">col_names</code></td>
<td>
<p>If <code>FALSE</code>, column names will not be included at the top of the file. If <code>TRUE</code>,
column names will be included. If not specified, <code>col_names</code> will take the opposite value given to <code>append</code>.</p>
</td></tr>
<tr><td><code id="format_delim_+3A_quote">quote</code></td>
<td>
<p>How to handle fields which contain characters that need to be
quoted.
</p>

<ul>
<li> <p><code>needed</code> - Values are only quoted if needed: if they contain a delimiter,
quote, or newline.
</p>
</li>
<li> <p><code>all</code> - Quote all fields.
</p>
</li>
<li> <p><code>none</code> - Never quote fields.
</p>
</li></ul>
</td></tr>
<tr><td><code id="format_delim_+3A_escape">escape</code></td>
<td>
<p>The type of escape to use when quotes are in the data.
</p>

<ul>
<li> <p><code>double</code> - quotes are escaped by doubling them.
</p>
</li>
<li> <p><code>backslash</code> - quotes are escaped by a preceding backslash.
</p>
</li>
<li> <p><code>none</code> - quotes are not escaped.
</p>
</li></ul>
</td></tr>
<tr><td><code id="format_delim_+3A_eol">eol</code></td>
<td>
<p>The end of line character to use. Most commonly either <code>"\n"</code> for
Unix style newlines, or <code>"\r\n"</code> for Windows style newlines.</p>
</td></tr>
<tr><td><code id="format_delim_+3A_quote_escape">quote_escape</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Use the <code>escape</code>
argument instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string.
</p>


<h3>Output</h3>

<p>Factors are coerced to character. Doubles are formatted to a decimal string
using the grisu3 algorithm. <code>POSIXct</code> values are formatted as ISO8601 with a
UTC timezone <em>Note: <code>POSIXct</code> objects in local or non-UTC timezones will be
converted to UTC time before writing.</em>
</p>
<p>All columns are encoded as UTF-8. <code>write_excel_csv()</code> and <code>write_excel_csv2()</code> also include a
<a href="https://en.wikipedia.org/wiki/Byte_order_mark">UTF-8 Byte order mark</a>
which indicates to Excel the csv is UTF-8 encoded.
</p>
<p><code>write_excel_csv2()</code> and <code>write_csv2</code> were created to allow users with
different locale settings to save .csv files using their default settings
(e.g. <code style="white-space: pre;">&#8288;;&#8288;</code> as the column separator and <code style="white-space: pre;">&#8288;,&#8288;</code> as the decimal separator).
This is common in some European countries.
</p>
<p>Values are only quoted if they contain a comma, quote or newline.
</p>
<p>The <code style="white-space: pre;">&#8288;write_*()&#8288;</code> functions will automatically compress outputs if an appropriate extension is given.
Three extensions are currently supported: <code>.gz</code> for gzip compression, <code>.bz2</code> for bzip2 compression and
<code>.xz</code> for lzma compression.  See the examples for more information.
</p>


<h3>References</h3>

<p>Florian Loitsch, Printing Floating-Point Numbers Quickly and
Accurately with Integers, PLDI '10,
<a href="http://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf">http://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># format_()* functions are useful for testing and reprexes
cat(format_csv(mtcars))
cat(format_tsv(mtcars))
cat(format_delim(mtcars, ";"))

# Specifying missing values
df &lt;- data.frame(x = c(1, NA, 3))
format_csv(df, na = "missing")

# Quotes are automatically added as needed
df &lt;- data.frame(x = c("a ", '"', ",", "\n"))
cat(format_csv(df))
</code></pre>

<hr>
<h2 id='guess_encoding'>Guess encoding of file</h2><span id='topic+guess_encoding'></span>

<h3>Description</h3>

<p>Uses <code><a href="stringi.html#topic+stri_enc_detect">stringi::stri_enc_detect()</a></code>: see the documentation there
for caveats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>guess_encoding(file, n_max = 10000, threshold = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="guess_encoding_+3A_file">file</code></td>
<td>
<p>A character string specifying an input as specified in
<code><a href="#topic+datasource">datasource()</a></code>, a raw vector, or a list of raw vectors.</p>
</td></tr>
<tr><td><code id="guess_encoding_+3A_n_max">n_max</code></td>
<td>
<p>Number of lines to read. If <code>n_max</code> is -1, all lines in
file will be read.</p>
</td></tr>
<tr><td><code id="guess_encoding_+3A_threshold">threshold</code></td>
<td>
<p>Only report guesses above this threshold of certainty.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble
</p>


<h3>Examples</h3>

<pre><code class='language-R'>guess_encoding(readr_example("mtcars.csv"))
guess_encoding(read_lines_raw(readr_example("mtcars.csv")))
guess_encoding(read_file_raw(readr_example("mtcars.csv")))

guess_encoding("a\n\u00b5\u00b5")
</code></pre>

<hr>
<h2 id='locale'>Create locales</h2><span id='topic+locale'></span><span id='topic+default_locale'></span>

<h3>Description</h3>

<p>A locale object tries to capture all the defaults that can vary between
countries. You set the locale in once, and the details are automatically
passed on down to the columns parsers. The defaults have been chosen to
match R (i.e. US English) as closely as possible. See
<code>vignette("locales")</code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>locale(
  date_names = "en",
  date_format = "%AD",
  time_format = "%AT",
  decimal_mark = ".",
  grouping_mark = ",",
  tz = "UTC",
  encoding = "UTF-8",
  asciify = FALSE
)

default_locale()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="locale_+3A_date_names">date_names</code></td>
<td>
<p>Character representations of day and month names. Either
the language code as string (passed on to <code><a href="#topic+date_names_lang">date_names_lang()</a></code>)
or an object created by <code><a href="#topic+date_names">date_names()</a></code>.</p>
</td></tr>
<tr><td><code id="locale_+3A_date_format">date_format</code>, <code id="locale_+3A_time_format">time_format</code></td>
<td>
<p>Default date and time formats.</p>
</td></tr>
<tr><td><code id="locale_+3A_decimal_mark">decimal_mark</code>, <code id="locale_+3A_grouping_mark">grouping_mark</code></td>
<td>
<p>Symbols used to indicate the decimal
place, and to chunk larger numbers. Decimal mark can only be <code style="white-space: pre;">&#8288;,&#8288;</code> or
<code>.</code>.</p>
</td></tr>
<tr><td><code id="locale_+3A_tz">tz</code></td>
<td>
<p>Default tz. This is used both for input (if the time zone isn't
present in individual strings), and for output (to control the default
display). The default is to use &quot;UTC&quot;, a time zone that does not use
daylight savings time (DST) and hence is typically most useful for data.
The absence of time zones makes it approximately 50x faster to generate
UTC times than any other time zone.
</p>
<p>Use <code>""</code> to use the system default time zone, but beware that this
will not be reproducible across systems.
</p>
<p>For a complete list of possible time zones, see <code><a href="base.html#topic+OlsonNames">OlsonNames()</a></code>.
Americans, note that &quot;EST&quot; is a Canadian time zone that does not have
DST. It is <em>not</em> Eastern Standard Time. It's better to use
&quot;US/Eastern&quot;, &quot;US/Central&quot; etc.</p>
</td></tr>
<tr><td><code id="locale_+3A_encoding">encoding</code></td>
<td>
<p>Default encoding. This only affects how the file is
read - readr always converts the output to UTF-8.</p>
</td></tr>
<tr><td><code id="locale_+3A_asciify">asciify</code></td>
<td>
<p>Should diacritics be stripped from date names and converted to
ASCII? This is useful if you're dealing with ASCII data where the correct
spellings have been lost. Requires the <span class="pkg">stringi</span> package.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>locale()
locale("fr")

# South American locale
locale("es", decimal_mark = ",")
</code></pre>

<hr>
<h2 id='melt_delim'>Return melted data for each token in a delimited file (including csv &amp; tsv)</h2><span id='topic+melt_delim'></span><span id='topic+melt_csv'></span><span id='topic+melt_csv2'></span><span id='topic+melt_tsv'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#superseded"><img src="../help/figures/lifecycle-superseded.svg" alt='[Superseded]' /></a>
This function has been superseded in readr and moved to <a href="https://r-lib.github.io/meltr/">the meltr package</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>melt_delim(
  file,
  delim,
  quote = "\"",
  escape_backslash = FALSE,
  escape_double = TRUE,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  comment = "",
  trim_ws = FALSE,
  skip = 0,
  n_max = Inf,
  progress = show_progress(),
  skip_empty_rows = FALSE
)

melt_csv(
  file,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  progress = show_progress(),
  skip_empty_rows = FALSE
)

melt_csv2(
  file,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  progress = show_progress(),
  skip_empty_rows = FALSE
)

melt_tsv(
  file,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  progress = show_progress(),
  skip_empty_rows = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="melt_delim_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_delim">delim</code></td>
<td>
<p>Single character used to separate fields within a record.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_quote">quote</code></td>
<td>
<p>Single character used to quote strings.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_escape_backslash">escape_backslash</code></td>
<td>
<p>Does the file use backslashes to escape special
characters? This is more general than <code>escape_double</code> as backslashes
can be used to escape the delimiter character, the quote character, or
to add special characters like <code style="white-space: pre;">&#8288;\\n&#8288;</code>.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_escape_double">escape_double</code></td>
<td>
<p>Does the file escape quotes by doubling them?
i.e. If this option is <code>TRUE</code>, the value <code style="white-space: pre;">&#8288;""""&#8288;</code> represents
a single quote, <code style="white-space: pre;">&#8288;\"&#8288;</code>.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_quoted_na">quoted_na</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Should missing values
inside quotes be treated as missing values (the default) or strings. This
parameter is soft deprecated as of readr 2.0.0.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data. If <code>comment</code> is
supplied any commented lines are ignored <em>after</em> skipping.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of lines to read.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="melt_delim_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For certain non-rectangular data formats, it can be useful to parse the data
into a melted format where each row represents a single token.
</p>
<p><code>melt_csv()</code> and <code>melt_tsv()</code> are special cases of the general
<code>melt_delim()</code>. They're useful for reading the most common types of
flat file data, comma separated values and tab separated values,
respectively. <code>melt_csv2()</code> uses <code style="white-space: pre;">&#8288;;&#8288;</code> for the field separator and <code style="white-space: pre;">&#8288;,&#8288;</code> for the
decimal point. This is common in some European countries.
</p>


<h3>Value</h3>

<p>A <code><a href="tibble.html#topic+tibble">tibble()</a></code> of four columns:
</p>

<ul>
<li> <p><code>row</code>, the row that the token comes from in the original file
</p>
</li>
<li> <p><code>col</code>, the column that the token comes from in the original file
</p>
</li>
<li> <p><code>data_type</code>, the data type of the token, e.g. <code>"integer"</code>, <code>"character"</code>,
<code>"date"</code>, guessed in a similar way to the <code>guess_parser()</code> function.
</p>
</li>
<li> <p><code>value</code>, the token itself as a character string, unchanged from its
representation in the original file.
</p>
</li></ul>

<p>If there are parsing problems, a warning tells you
how many, and you can retrieve the details with <code><a href="#topic+problems">problems()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_delim">read_delim()</a></code> for the conventional way to read rectangular data
from delimited files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Input sources -------------------------------------------------------------
# Read from a path
melt_csv(readr_example("mtcars.csv"))
melt_csv(readr_example("mtcars.csv.zip"))
melt_csv(readr_example("mtcars.csv.bz2"))
## Not run: 
melt_csv("https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv")

## End(Not run)

# Or directly from a string (must contain a newline)
melt_csv("x,y\n1,2\n3,4")

# To import empty cells as 'empty' rather than `NA`
melt_csv("x,y\n,NA,\"\",''", na = "NA")

# File types ----------------------------------------------------------------
melt_csv("a,b\n1.0,2.0")
melt_csv2("a;b\n1,0;2,0")
melt_tsv("a\tb\n1.0\t2.0")
melt_delim("a|b\n1.0|2.0", delim = "|")
</code></pre>

<hr>
<h2 id='melt_delim_chunked'>Melt a delimited file by chunks</h2><span id='topic+melt_delim_chunked'></span><span id='topic+melt_csv_chunked'></span><span id='topic+melt_csv2_chunked'></span><span id='topic+melt_tsv_chunked'></span>

<h3>Description</h3>

<p>For certain non-rectangular data formats, it can be useful to parse the data
into a melted format where each row represents a single token.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>melt_delim_chunked(
  file,
  callback,
  chunk_size = 10000,
  delim,
  quote = "\"",
  escape_backslash = FALSE,
  escape_double = TRUE,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  comment = "",
  trim_ws = FALSE,
  skip = 0,
  progress = show_progress(),
  skip_empty_rows = FALSE
)

melt_csv_chunked(
  file,
  callback,
  chunk_size = 10000,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  progress = show_progress(),
  skip_empty_rows = FALSE
)

melt_csv2_chunked(
  file,
  callback,
  chunk_size = 10000,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  progress = show_progress(),
  skip_empty_rows = FALSE
)

melt_tsv_chunked(
  file,
  callback,
  chunk_size = 10000,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  progress = show_progress(),
  skip_empty_rows = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="melt_delim_chunked_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_callback">callback</code></td>
<td>
<p>A callback function to call on each chunk</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_chunk_size">chunk_size</code></td>
<td>
<p>The number of rows to include in each chunk</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_delim">delim</code></td>
<td>
<p>Single character used to separate fields within a record.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_quote">quote</code></td>
<td>
<p>Single character used to quote strings.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_escape_backslash">escape_backslash</code></td>
<td>
<p>Does the file use backslashes to escape special
characters? This is more general than <code>escape_double</code> as backslashes
can be used to escape the delimiter character, the quote character, or
to add special characters like <code style="white-space: pre;">&#8288;\\n&#8288;</code>.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_escape_double">escape_double</code></td>
<td>
<p>Does the file escape quotes by doubling them?
i.e. If this option is <code>TRUE</code>, the value <code style="white-space: pre;">&#8288;""""&#8288;</code> represents
a single quote, <code style="white-space: pre;">&#8288;\"&#8288;</code>.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_quoted_na">quoted_na</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Should missing values
inside quotes be treated as missing values (the default) or strings. This
parameter is soft deprecated as of readr 2.0.0.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data. If <code>comment</code> is
supplied any commented lines are ignored <em>after</em> skipping.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="melt_delim_chunked_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>melt_delim_chunked()</code> and the specialisations <code>melt_csv_chunked()</code>,
<code>melt_csv2_chunked()</code> and <code>melt_tsv_chunked()</code> read files by a chunk of rows
at a time, executing a given function on one chunk before reading the next.
</p>


<h3>See Also</h3>

<p>Other chunked: 
<code><a href="#topic+callback">callback</a></code>,
<code><a href="#topic+read_delim_chunked">read_delim_chunked</a>()</code>,
<code><a href="#topic+read_lines_chunked">read_lines_chunked</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Cars with 3 gears
f &lt;- function(x, pos) subset(x, data_type == "integer")
melt_csv_chunked(readr_example("mtcars.csv"), DataFrameCallback$new(f), chunk_size = 5)
</code></pre>

<hr>
<h2 id='melt_fwf'>Return melted data for each token in a fixed width file</h2><span id='topic+melt_fwf'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#superseded"><img src="../help/figures/lifecycle-superseded.svg" alt='[Superseded]' /></a>
This function has been superseded in readr and moved to <a href="https://r-lib.github.io/meltr/">the meltr package</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>melt_fwf(
  file,
  col_positions,
  locale = default_locale(),
  na = c("", "NA"),
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  progress = show_progress(),
  skip_empty_rows = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="melt_fwf_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_col_positions">col_positions</code></td>
<td>
<p>Column positions, as created by <code><a href="#topic+fwf_empty">fwf_empty()</a></code>,
<code><a href="#topic+fwf_widths">fwf_widths()</a></code> or <code><a href="#topic+fwf_positions">fwf_positions()</a></code>. To read in only selected fields,
use <code><a href="#topic+fwf_positions">fwf_positions()</a></code>. If the width of the last column is variable (a
ragged fwf file), supply the last end position as NA.</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of lines to read.</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="melt_fwf_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For certain non-rectangular data formats, it can be useful to parse the data
into a melted format where each row represents a single token.
</p>
<p><code>melt_fwf()</code> parses each token of a fixed width file into a single row, but
it still requires that each field is in the same in every row of the
source file.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+melt_table">melt_table()</a></code> to melt fixed width files where each
column is separated by whitespace, and <code><a href="#topic+read_fwf">read_fwf()</a></code> for the conventional
way to read rectangular data from fixed width files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fwf_sample &lt;- readr_example("fwf-sample.txt")
cat(read_lines(fwf_sample))

# You can specify column positions in several ways:
# 1. Guess based on position of empty columns
melt_fwf(fwf_sample, fwf_empty(fwf_sample, col_names = c("first", "last", "state", "ssn")))
# 2. A vector of field widths
melt_fwf(fwf_sample, fwf_widths(c(20, 10, 12), c("name", "state", "ssn")))
# 3. Paired vectors of start and end positions
melt_fwf(fwf_sample, fwf_positions(c(1, 30), c(10, 42), c("name", "ssn")))
# 4. Named arguments with start and end positions
melt_fwf(fwf_sample, fwf_cols(name = c(1, 10), ssn = c(30, 42)))
# 5. Named arguments with column widths
melt_fwf(fwf_sample, fwf_cols(name = 20, state = 10, ssn = 12))
</code></pre>

<hr>
<h2 id='melt_table'>Return melted data for each token in a whitespace-separated file</h2><span id='topic+melt_table'></span><span id='topic+melt_table2'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#superseded"><img src="../help/figures/lifecycle-superseded.svg" alt='[Superseded]' /></a>
This function has been superseded in readr and moved to <a href="https://r-lib.github.io/meltr/">the meltr package</a>.
</p>
<p>For certain non-rectangular data formats, it can be useful to parse the data
into a melted format where each row represents a single token.
</p>
<p><code>melt_table()</code> and <code>melt_table2()</code> are designed to read the type of textual
data where each column is separated by one (or more) columns of space.
</p>
<p><code>melt_table2()</code> allows any number of whitespace characters between columns,
and the lines can be of different lengths.
</p>
<p><code>melt_table()</code> is more strict, each line must be the same length,
and each field is in the same position in every line. It first finds empty
columns and then parses like a fixed width file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>melt_table(
  file,
  locale = default_locale(),
  na = "NA",
  skip = 0,
  n_max = Inf,
  guess_max = min(n_max, 1000),
  progress = show_progress(),
  comment = "",
  skip_empty_rows = FALSE
)

melt_table2(
  file,
  locale = default_locale(),
  na = "NA",
  skip = 0,
  n_max = Inf,
  progress = show_progress(),
  comment = "",
  skip_empty_rows = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="melt_table_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="melt_table_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="melt_table_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="melt_table_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr><td><code id="melt_table_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of lines to read.</p>
</td></tr>
<tr><td><code id="melt_table_+3A_guess_max">guess_max</code></td>
<td>
<p>Maximum number of lines to use for guessing column types.
Will never use more than the number of lines read.
See <code>vignette("column-types", package = "readr")</code> for more details.</p>
</td></tr>
<tr><td><code id="melt_table_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="melt_table_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="melt_table_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+melt_fwf">melt_fwf()</a></code> to melt fixed width files where each column
is not separated by whitespace. <code>melt_fwf()</code> is also useful for reading
tabular data with non-standard formatting.  <code><a href="#topic+read_table">read_table()</a></code> is the
conventional way to read tabular data from whitespace-separated files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fwf &lt;- readr_example("fwf-sample.txt")
writeLines(read_lines(fwf))
melt_table(fwf)

ws &lt;- readr_example("whitespace-sample.txt")
writeLines(read_lines(ws))
melt_table2(ws)
</code></pre>

<hr>
<h2 id='output_column'>Preprocess column for output</h2><span id='topic+output_column'></span>

<h3>Description</h3>

<p>This is a generic function that applied to each column before it is saved
to disk. It provides a hook for S3 classes that need special handling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>output_column(x, name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="output_column_+3A_x">x</code></td>
<td>
<p>A vector</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Most columns are not altered, but POSIXct are converted to ISO8601.
x &lt;- parse_datetime("2016-01-01")
str(output_column(x))
</code></pre>

<hr>
<h2 id='parse_atomic'>Parse logicals, integers, and reals</h2><span id='topic+parse_logical'></span><span id='topic+parse_integer'></span><span id='topic+parse_double'></span><span id='topic+parse_character'></span><span id='topic+col_logical'></span><span id='topic+col_integer'></span><span id='topic+col_double'></span><span id='topic+col_character'></span>

<h3>Description</h3>

<p>Use <code style="white-space: pre;">&#8288;parse_*()&#8288;</code> if you have a character vector you want to parse. Use
<code style="white-space: pre;">&#8288;col_*()&#8288;</code> in conjunction with a <code style="white-space: pre;">&#8288;read_*()&#8288;</code> function to parse the
values as they're read in.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_logical(x, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)

parse_integer(x, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)

parse_double(x, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)

parse_character(x, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)

col_logical()

col_integer()

col_double()

col_character()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_atomic_+3A_x">x</code></td>
<td>
<p>Character vector of values to parse.</p>
</td></tr>
<tr><td><code id="parse_atomic_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="parse_atomic_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="parse_atomic_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+col_skip">col_skip</a>()</code>,
<code><a href="#topic+cols_condense">cols_condense</a>()</code>,
<code><a href="#topic+cols">cols</a>()</code>,
<code><a href="#topic+parse_datetime">parse_datetime</a>()</code>,
<code><a href="#topic+parse_factor">parse_factor</a>()</code>,
<code><a href="#topic+parse_guess">parse_guess</a>()</code>,
<code><a href="#topic+parse_number">parse_number</a>()</code>,
<code><a href="#topic+parse_vector">parse_vector</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>parse_integer(c("1", "2", "3"))
parse_double(c("1", "2", "3.123"))
parse_number("$1,123,456.00")

# Use locale to override default decimal and grouping marks
es_MX &lt;- locale("es", decimal_mark = ",")
parse_number("$1.123.456,00", locale = es_MX)

# Invalid values are replaced with missing values with a warning.
x &lt;- c("1", "2", "3", "-")
parse_double(x)
# Or flag values as missing
parse_double(x, na = "-")
</code></pre>

<hr>
<h2 id='parse_datetime'>Parse date/times</h2><span id='topic+parse_datetime'></span><span id='topic+parse_date'></span><span id='topic+parse_time'></span><span id='topic+col_datetime'></span><span id='topic+col_date'></span><span id='topic+col_time'></span>

<h3>Description</h3>

<p>Parse date/times
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_datetime(
  x,
  format = "",
  na = c("", "NA"),
  locale = default_locale(),
  trim_ws = TRUE
)

parse_date(
  x,
  format = "",
  na = c("", "NA"),
  locale = default_locale(),
  trim_ws = TRUE
)

parse_time(
  x,
  format = "",
  na = c("", "NA"),
  locale = default_locale(),
  trim_ws = TRUE
)

col_datetime(format = "")

col_date(format = "")

col_time(format = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_datetime_+3A_x">x</code></td>
<td>
<p>A character vector of dates to parse.</p>
</td></tr>
<tr><td><code id="parse_datetime_+3A_format">format</code></td>
<td>
<p>A format specification, as described below. If set to &quot;&quot;,
date times are parsed as ISO8601, dates and times used the date and
time formats specified in the <code><a href="#topic+locale">locale()</a></code>.
</p>
<p>Unlike <code><a href="base.html#topic+strptime">strptime()</a></code>, the format specification must match
the complete string.</p>
</td></tr>
<tr><td><code id="parse_datetime_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="parse_datetime_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="parse_datetime_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+POSIXct">POSIXct()</a></code> vector with <code>tzone</code> attribute set to
<code>tz</code>. Elements that could not be parsed (or did not generate valid
dates) will be set to <code>NA</code>, and a warning message will inform
you of the total number of failures.
</p>


<h3>Format specification</h3>

<p><code>readr</code> uses a format specification similar to <code><a href="base.html#topic+strptime">strptime()</a></code>.
There are three types of element:
</p>

<ol>
<li><p> Date components are specified with &quot;%&quot; followed by a letter. For example
&quot;%Y&quot; matches a 4 digit year, &quot;%m&quot;, matches a 2 digit month and &quot;%d&quot; matches
a 2 digit day. Month and day default to <code>1</code>, (i.e. Jan 1st) if not present,
for example if only a year is given.
</p>
</li>
<li><p> Whitespace is any sequence of zero or more whitespace characters.
</p>
</li>
<li><p> Any other character is matched exactly.
</p>
</li></ol>

<p><code>parse_datetime()</code> recognises the following format specifications:
</p>

<ul>
<li><p> Year: &quot;%Y&quot; (4 digits). &quot;%y&quot; (2 digits); 00-69 -&gt; 2000-2069, 70-99 -&gt;
1970-1999.
</p>
</li>
<li><p> Month: &quot;%m&quot; (2 digits), &quot;%b&quot; (abbreviated name in current locale), &quot;%B&quot;
(full name in current locale).
</p>
</li>
<li><p> Day: &quot;%d&quot; (2 digits), &quot;%e&quot; (optional leading space), &quot;%a&quot; (abbreviated
name in current locale).
</p>
</li>
<li><p> Hour: &quot;%H&quot; or &quot;%I&quot; or &quot;%h&quot;, use I (and not H) with AM/PM, use h (and not H)
if your times represent durations longer than one day.
</p>
</li>
<li><p> Minutes: &quot;%M&quot;
</p>
</li>
<li><p> Seconds: &quot;%S&quot; (integer seconds), &quot;%OS&quot; (partial seconds)
</p>
</li>
<li><p> Time zone: &quot;%Z&quot; (as name, e.g. &quot;America/Chicago&quot;), &quot;%z&quot; (as offset from
UTC, e.g. &quot;+0800&quot;)
</p>
</li>
<li><p> AM/PM indicator: &quot;%p&quot;.
</p>
</li>
<li><p> Non-digits: &quot;%.&quot; skips one non-digit character, &quot;%+&quot; skips one or more
non-digit characters, &quot;%*&quot; skips any number of non-digits characters.
</p>
</li>
<li><p> Automatic parsers: &quot;%AD&quot; parses with a flexible YMD parser, &quot;%AT&quot; parses
with a flexible HMS parser.
</p>
</li>
<li><p> Time since the Unix epoch: &quot;%s&quot; decimal seconds since the Unix epoch.
</p>
</li>
<li><p> Shortcuts: &quot;%D&quot; = &quot;%m/%d/%y&quot;, &quot;%F&quot; = &quot;%Y-%m-%d&quot;, &quot;%R&quot; = &quot;%H:%M&quot;, &quot;%T&quot; =
&quot;%H:%M:%S&quot;, &quot;%x&quot; = &quot;%y/%m/%d&quot;.
</p>
</li></ul>



<h3>ISO8601 support</h3>

<p>Currently, readr does not support all of ISO8601. Missing features:
</p>

<ul>
<li><p> Week &amp; weekday specifications, e.g. &quot;2013-W05&quot;, &quot;2013-W05-10&quot;.
</p>
</li>
<li><p> Ordinal dates, e.g. &quot;2013-095&quot;.
</p>
</li>
<li><p> Using commas instead of a period for decimal separator.
</p>
</li></ul>

<p>The parser is also a little laxer than ISO8601:
</p>

<ul>
<li><p> Dates and times can be separated with a space, not just T.
</p>
</li>
<li><p> Mostly correct specifications like &quot;2009-05-19 14:&quot; and &quot;200912-01&quot; work.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+col_skip">col_skip</a>()</code>,
<code><a href="#topic+cols_condense">cols_condense</a>()</code>,
<code><a href="#topic+cols">cols</a>()</code>,
<code><a href="#topic+parse_factor">parse_factor</a>()</code>,
<code><a href="#topic+parse_guess">parse_guess</a>()</code>,
<code><a href="#topic+parse_logical">parse_logical</a>()</code>,
<code><a href="#topic+parse_number">parse_number</a>()</code>,
<code><a href="#topic+parse_vector">parse_vector</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Format strings --------------------------------------------------------
parse_datetime("01/02/2010", "%d/%m/%Y")
parse_datetime("01/02/2010", "%m/%d/%Y")
# Handle any separator
parse_datetime("01/02/2010", "%m%.%d%.%Y")

# Dates look the same, but internally they use the number of days since
# 1970-01-01 instead of the number of seconds. This avoids a whole lot
# of troubles related to time zones, so use if you can.
parse_date("01/02/2010", "%d/%m/%Y")
parse_date("01/02/2010", "%m/%d/%Y")

# You can parse timezones from strings (as listed in OlsonNames())
parse_datetime("2010/01/01 12:00 US/Central", "%Y/%m/%d %H:%M %Z")
# Or from offsets
parse_datetime("2010/01/01 12:00 -0600", "%Y/%m/%d %H:%M %z")

# Use the locale parameter to control the default time zone
# (but note UTC is considerably faster than other options)
parse_datetime("2010/01/01 12:00", "%Y/%m/%d %H:%M",
  locale = locale(tz = "US/Central")
)
parse_datetime("2010/01/01 12:00", "%Y/%m/%d %H:%M",
  locale = locale(tz = "US/Eastern")
)

# Unlike strptime, the format specification must match the complete
# string (ignoring leading and trailing whitespace). This avoids common
# errors:
strptime("01/02/2010", "%d/%m/%y")
parse_datetime("01/02/2010", "%d/%m/%y")

# Failures -------------------------------------------------------------
parse_datetime("01/01/2010", "%d/%m/%Y")
parse_datetime(c("01/ab/2010", "32/01/2010"), "%d/%m/%Y")

# Locales --------------------------------------------------------------
# By default, readr expects English date/times, but that's easy to change'
parse_datetime("1 janvier 2015", "%d %B %Y", locale = locale("fr"))
parse_datetime("1 enero 2015", "%d %B %Y", locale = locale("es"))

# ISO8601 --------------------------------------------------------------
# With separators
parse_datetime("1979-10-14")
parse_datetime("1979-10-14T10")
parse_datetime("1979-10-14T10:11")
parse_datetime("1979-10-14T10:11:12")
parse_datetime("1979-10-14T10:11:12.12345")

# Without separators
parse_datetime("19791014")
parse_datetime("19791014T101112")

# Time zones
us_central &lt;- locale(tz = "US/Central")
parse_datetime("1979-10-14T1010", locale = us_central)
parse_datetime("1979-10-14T1010-0500", locale = us_central)
parse_datetime("1979-10-14T1010Z", locale = us_central)
# Your current time zone
parse_datetime("1979-10-14T1010", locale = locale(tz = ""))
</code></pre>

<hr>
<h2 id='parse_factor'>Parse factors</h2><span id='topic+parse_factor'></span><span id='topic+col_factor'></span>

<h3>Description</h3>

<p><code>parse_factor()</code> is similar to <code><a href="base.html#topic+factor">factor()</a></code>, but generates a warning if
<code>levels</code> have been specified and some elements of <code>x</code> are not found in those
<code>levels</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_factor(
  x,
  levels = NULL,
  ordered = FALSE,
  na = c("", "NA"),
  locale = default_locale(),
  include_na = TRUE,
  trim_ws = TRUE
)

col_factor(levels = NULL, ordered = FALSE, include_na = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_factor_+3A_x">x</code></td>
<td>
<p>Character vector of values to parse.</p>
</td></tr>
<tr><td><code id="parse_factor_+3A_levels">levels</code></td>
<td>
<p>Character vector of the allowed levels. When <code>levels = NULL</code>
(the default), <code>levels</code> are discovered from the unique values of <code>x</code>, in
the order in which they appear in <code>x</code>.</p>
</td></tr>
<tr><td><code id="parse_factor_+3A_ordered">ordered</code></td>
<td>
<p>Is it an ordered factor?</p>
</td></tr>
<tr><td><code id="parse_factor_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="parse_factor_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="parse_factor_+3A_include_na">include_na</code></td>
<td>
<p>If <code>TRUE</code> and <code>x</code> contains at least one <code>NA</code>, then <code>NA</code>
is included in the levels of the constructed factor.</p>
</td></tr>
<tr><td><code id="parse_factor_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+col_skip">col_skip</a>()</code>,
<code><a href="#topic+cols_condense">cols_condense</a>()</code>,
<code><a href="#topic+cols">cols</a>()</code>,
<code><a href="#topic+parse_datetime">parse_datetime</a>()</code>,
<code><a href="#topic+parse_guess">parse_guess</a>()</code>,
<code><a href="#topic+parse_logical">parse_logical</a>()</code>,
<code><a href="#topic+parse_number">parse_number</a>()</code>,
<code><a href="#topic+parse_vector">parse_vector</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># discover the levels from the data
parse_factor(c("a", "b"))
parse_factor(c("a", "b", "-99"))
parse_factor(c("a", "b", "-99"), na = c("", "NA", "-99"))
parse_factor(c("a", "b", "-99"), na = c("", "NA", "-99"), include_na = FALSE)

# provide the levels explicitly
parse_factor(c("a", "b"), levels = letters[1:5])

x &lt;- c("cat", "dog", "caw")
animals &lt;- c("cat", "dog", "cow")

# base::factor() silently converts elements that do not match any levels to
# NA
factor(x, levels = animals)

# parse_factor() generates same factor as base::factor() but throws a warning
# and reports problems
parse_factor(x, levels = animals)
</code></pre>

<hr>
<h2 id='parse_guess'>Parse using the &quot;best&quot; type</h2><span id='topic+parse_guess'></span><span id='topic+col_guess'></span><span id='topic+guess_parser'></span>

<h3>Description</h3>

<p><code>parse_guess()</code> returns the parser vector; <code>guess_parser()</code>
returns the name of the parser. These functions use a number of heuristics
to determine which type of vector is &quot;best&quot;. Generally they try to err of
the side of safety, as it's straightforward to override the parsing choice
if needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_guess(
  x,
  na = c("", "NA"),
  locale = default_locale(),
  trim_ws = TRUE,
  guess_integer = FALSE
)

col_guess()

guess_parser(
  x,
  locale = default_locale(),
  guess_integer = FALSE,
  na = c("", "NA")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_guess_+3A_x">x</code></td>
<td>
<p>Character vector of values to parse.</p>
</td></tr>
<tr><td><code id="parse_guess_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="parse_guess_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="parse_guess_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="parse_guess_+3A_guess_integer">guess_integer</code></td>
<td>
<p>If <code>TRUE</code>, guess integer types for whole numbers, if
<code>FALSE</code> guess numeric type for all numbers.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+col_skip">col_skip</a>()</code>,
<code><a href="#topic+cols_condense">cols_condense</a>()</code>,
<code><a href="#topic+cols">cols</a>()</code>,
<code><a href="#topic+parse_datetime">parse_datetime</a>()</code>,
<code><a href="#topic+parse_factor">parse_factor</a>()</code>,
<code><a href="#topic+parse_logical">parse_logical</a>()</code>,
<code><a href="#topic+parse_number">parse_number</a>()</code>,
<code><a href="#topic+parse_vector">parse_vector</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Logical vectors
parse_guess(c("FALSE", "TRUE", "F", "T"))

# Integers and doubles
parse_guess(c("1", "2", "3"))
parse_guess(c("1.6", "2.6", "3.4"))

# Numbers containing grouping mark
guess_parser("1,234,566")
parse_guess("1,234,566")

# ISO 8601 date times
guess_parser(c("2010-10-10"))
parse_guess(c("2010-10-10"))
</code></pre>

<hr>
<h2 id='parse_number'>Parse numbers, flexibly</h2><span id='topic+parse_number'></span><span id='topic+col_number'></span>

<h3>Description</h3>

<p>This parses the first number it finds, dropping any non-numeric characters
before the first number and all characters after the first number. The
grouping mark specified by the locale is ignored inside the number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_number(x, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)

col_number()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_number_+3A_x">x</code></td>
<td>
<p>Character vector of values to parse.</p>
</td></tr>
<tr><td><code id="parse_number_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="parse_number_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="parse_number_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector (double) of parsed numbers.
</p>


<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+col_skip">col_skip</a>()</code>,
<code><a href="#topic+cols_condense">cols_condense</a>()</code>,
<code><a href="#topic+cols">cols</a>()</code>,
<code><a href="#topic+parse_datetime">parse_datetime</a>()</code>,
<code><a href="#topic+parse_factor">parse_factor</a>()</code>,
<code><a href="#topic+parse_guess">parse_guess</a>()</code>,
<code><a href="#topic+parse_logical">parse_logical</a>()</code>,
<code><a href="#topic+parse_vector">parse_vector</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## These all return 1000
parse_number("$1,000") ## leading `$` and grouping character `,` ignored
parse_number("euro1,000") ## leading non-numeric euro ignored
parse_number("t1000t1000") ## only parses first number found

parse_number("1,234.56")
## explicit locale specifying European grouping and decimal marks
parse_number("1.234,56", locale = locale(decimal_mark = ",", grouping_mark = "."))
## SI/ISO 31-0 standard spaces for number grouping
parse_number("1 234.56", locale = locale(decimal_mark = ".", grouping_mark = " "))

## Specifying strings for NAs
parse_number(c("1", "2", "3", "NA"))
parse_number(c("1", "2", "3", "NA", "Nothing"), na = c("NA", "Nothing"))
</code></pre>

<hr>
<h2 id='parse_vector'>Parse a character vector.</h2><span id='topic+parse_vector'></span>

<h3>Description</h3>

<p>Parse a character vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_vector(
  x,
  collector,
  na = c("", "NA"),
  locale = default_locale(),
  trim_ws = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_vector_+3A_x">x</code></td>
<td>
<p>Character vector of elements to parse.</p>
</td></tr>
<tr><td><code id="parse_vector_+3A_collector">collector</code></td>
<td>
<p>Column specification.</p>
</td></tr>
<tr><td><code id="parse_vector_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="parse_vector_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="parse_vector_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other parsers: 
<code><a href="#topic+col_skip">col_skip</a>()</code>,
<code><a href="#topic+cols_condense">cols_condense</a>()</code>,
<code><a href="#topic+cols">cols</a>()</code>,
<code><a href="#topic+parse_datetime">parse_datetime</a>()</code>,
<code><a href="#topic+parse_factor">parse_factor</a>()</code>,
<code><a href="#topic+parse_guess">parse_guess</a>()</code>,
<code><a href="#topic+parse_logical">parse_logical</a>()</code>,
<code><a href="#topic+parse_number">parse_number</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("1", "2", "3", "NA")
parse_vector(x, col_integer())
parse_vector(x, col_double())
</code></pre>

<hr>
<h2 id='problems'>Retrieve parsing problems</h2><span id='topic+problems'></span><span id='topic+stop_for_problems'></span>

<h3>Description</h3>

<p>Readr functions will only throw an error if parsing fails in an unrecoverable
way. However, there are lots of potential problems that you might want to
know about - these are stored in the <code>problems</code> attribute of the
output, which you can easily access with this function.
<code>stop_for_problems()</code> will throw an error if there are any parsing
problems: this is useful for automated scripts where you want to throw
an error as soon as you encounter a problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>problems(x = .Last.value)

stop_for_problems(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="problems_+3A_x">x</code></td>
<td>
<p>A data frame (from <code style="white-space: pre;">&#8288;read_*()&#8288;</code>) or a vector (from <code style="white-space: pre;">&#8288;parse_*()&#8288;</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with one row for each problem and four columns:
</p>
<table>
<tr><td><code>row</code>, <code>col</code></td>
<td>
<p>Row and column of problem</p>
</td></tr>
<tr><td><code>expected</code></td>
<td>
<p>What readr expected to find</p>
</td></tr>
<tr><td><code>actual</code></td>
<td>
<p>What it actually got</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- parse_integer(c("1X", "blah", "3"))
problems(x)

y &lt;- parse_integer(c("1", "2", "3"))
problems(y)
</code></pre>

<hr>
<h2 id='read_builtin'>Read built-in object from package</h2><span id='topic+read_builtin'></span>

<h3>Description</h3>

<p>Consistent wrapper around <code><a href="utils.html#topic+data">data()</a></code> that forces the promise. This is also a
stronger parallel to loading data from a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_builtin(x, package = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_builtin_+3A_x">x</code></td>
<td>
<p>Name (character string) of data set to read.</p>
</td></tr>
<tr><td><code id="read_builtin_+3A_package">package</code></td>
<td>
<p>Name of package from which to find data set. By default, all
attached packages are searched and then the 'data' subdirectory (if present)
of the current working directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the built-in class of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>read_builtin("mtcars", "datasets")
</code></pre>

<hr>
<h2 id='read_delim'>Read a delimited file (including CSV and TSV) into a tibble</h2><span id='topic+read_delim'></span><span id='topic+read_csv'></span><span id='topic+read_csv2'></span><span id='topic+read_tsv'></span>

<h3>Description</h3>

<p><code>read_csv()</code> and <code>read_tsv()</code> are special cases of the more general
<code>read_delim()</code>. They're useful for reading the most common types of
flat file data, comma separated values and tab separated values,
respectively. <code>read_csv2()</code> uses <code style="white-space: pre;">&#8288;;&#8288;</code> for the field separator and <code style="white-space: pre;">&#8288;,&#8288;</code> for the
decimal point. This format is common in some European countries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_delim(
  file,
  delim = NULL,
  quote = "\"",
  escape_backslash = FALSE,
  escape_double = TRUE,
  col_names = TRUE,
  col_types = NULL,
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  comment = "",
  trim_ws = FALSE,
  skip = 0,
  n_max = Inf,
  guess_max = min(1000, n_max),
  name_repair = "unique",
  num_threads = readr_threads(),
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)

read_csv(
  file,
  col_names = TRUE,
  col_types = NULL,
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  guess_max = min(1000, n_max),
  name_repair = "unique",
  num_threads = readr_threads(),
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)

read_csv2(
  file,
  col_names = TRUE,
  col_types = NULL,
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  guess_max = min(1000, n_max),
  progress = show_progress(),
  name_repair = "unique",
  num_threads = readr_threads(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)

read_tsv(
  file,
  col_names = TRUE,
  col_types = NULL,
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  guess_max = min(1000, n_max),
  progress = show_progress(),
  name_repair = "unique",
  num_threads = readr_threads(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_delim_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_delim">delim</code></td>
<td>
<p>Single character used to separate fields within a record.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_quote">quote</code></td>
<td>
<p>Single character used to quote strings.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_escape_backslash">escape_backslash</code></td>
<td>
<p>Does the file use backslashes to escape special
characters? This is more general than <code>escape_double</code> as backslashes
can be used to escape the delimiter character, the quote character, or
to add special characters like <code style="white-space: pre;">&#8288;\\n&#8288;</code>.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_escape_double">escape_double</code></td>
<td>
<p>Does the file escape quotes by doubling them?
i.e. If this option is <code>TRUE</code>, the value <code style="white-space: pre;">&#8288;""""&#8288;</code> represents
a single quote, <code style="white-space: pre;">&#8288;\"&#8288;</code>.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_col_names">col_names</code></td>
<td>
<p>Either <code>TRUE</code>, <code>FALSE</code> or a character vector
of column names.
</p>
<p>If <code>TRUE</code>, the first row of the input will be used as the column
names, and will not be included in the data frame. If <code>FALSE</code>, column
names will be generated automatically: X1, X2, X3 etc.
</p>
<p>If <code>col_names</code> is a character vector, the values will be used as the
names of the columns, and the first row of the input will be read into
the first row of the output data frame.
</p>
<p>Missing (<code>NA</code>) column names will generate a warning, and be filled
in with dummy names <code>...1</code>, <code>...2</code> etc. Duplicate column names
will generate a warning and be made unique, see <code>name_repair</code> to control
how this is done.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_col_types">col_types</code></td>
<td>
<p>One of <code>NULL</code>, a <code><a href="#topic+cols">cols()</a></code> specification, or
a string. See <code>vignette("readr")</code> for more details.
</p>
<p>If <code>NULL</code>, all column types will be inferred from <code>guess_max</code> rows of the
input, interspersed throughout the file. This is convenient (and fast),
but not robust. If the guessed types are wrong, you'll need to increase
<code>guess_max</code> or supply the correct types yourself.
</p>
<p>Column specifications created by <code><a href="base.html#topic+list">list()</a></code> or <code><a href="#topic+cols">cols()</a></code> must contain
one column specification for each column. If you only want to read a
subset of the columns, use <code><a href="#topic+cols_only">cols_only()</a></code>.
</p>
<p>Alternatively, you can use a compact string representation where each
character represents one column:
</p>

<ul>
<li><p> c = character
</p>
</li>
<li><p> i = integer
</p>
</li>
<li><p> n = number
</p>
</li>
<li><p> d = double
</p>
</li>
<li><p> l = logical
</p>
</li>
<li><p> f = factor
</p>
</li>
<li><p> D = date
</p>
</li>
<li><p> T = date time
</p>
</li>
<li><p> t = time
</p>
</li>
<li><p> ? = guess
</p>
</li>
<li><p> _ or - = skip
</p>
</li></ul>

<p>By default, reading a file without a column specification will print a
message showing what <code>readr</code> guessed they were. To remove this message,
set <code>show_col_types = FALSE</code> or set <code>options(readr.show_col_types = FALSE)</code>.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_col_select">col_select</code></td>
<td>
<p>Columns to include in the results. You can use the same
mini-language as <code>dplyr::select()</code> to refer to the columns by name. Use
<code>c()</code> to use more than one selection expression. Although this
usage is less common, <code>col_select</code> also accepts a numeric column index. See
<code><a href="tidyselect.html#topic+language">?tidyselect::language</a></code> for full details on the
selection language.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_id">id</code></td>
<td>
<p>The name of a column in which to store the file path. This is
useful when reading multiple input files and there is data in the file
paths, such as the data collection date. If <code>NULL</code> (the default) no extra
column is created.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_quoted_na">quoted_na</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Should missing values
inside quotes be treated as missing values (the default) or strings. This
parameter is soft deprecated as of readr 2.0.0.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="read_delim_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data. If <code>comment</code> is
supplied any commented lines are ignored <em>after</em> skipping.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of lines to read.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_guess_max">guess_max</code></td>
<td>
<p>Maximum number of lines to use for guessing column types.
Will never use more than the number of lines read.
See <code>vignette("column-types", package = "readr")</code> for more details.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_name_repair">name_repair</code></td>
<td>
<p>Handling of column names. The default behaviour is to
ensure column names are <code>"unique"</code>. Various repair strategies are
supported:
</p>

<ul>
<li> <p><code>"minimal"</code>: No name repair or checks, beyond basic existence of names.
</p>
</li>
<li> <p><code>"unique"</code> (default value): Make sure names are unique and not empty.
</p>
</li>
<li> <p><code>"check_unique"</code>: No name repair, but check they are <code>unique</code>.
</p>
</li>
<li> <p><code>"unique_quiet"</code>: Repair with the <code>unique</code> strategy, quietly.
</p>
</li>
<li> <p><code>"universal"</code>: Make the names <code>unique</code> and syntactic.
</p>
</li>
<li> <p><code>"universal_quiet"</code>: Repair with the <code>universal</code> strategy, quietly.
</p>
</li>
<li><p> A function: Apply custom name repair (e.g., <code>name_repair = make.names</code>
for names in the style of base R).
</p>
</li>
<li><p> A purrr-style anonymous function, see <code><a href="rlang.html#topic+as_function">rlang::as_function()</a></code>.
</p>
</li></ul>

<p>This argument is passed on as <code>repair</code> to <code><a href="vctrs.html#topic+vec_as_names">vctrs::vec_as_names()</a></code>.
See there for more details on these terms and the strategies used
to enforce them.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_num_threads">num_threads</code></td>
<td>
<p>The number of processing threads to use for initial
parsing and lazy reading of data. If your data contains newlines within
fields the parser should automatically detect this and fall back to using
one thread only. However if you know your file has newlines within quoted
fields it is safest to set <code>num_threads = 1</code> explicitly.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_show_col_types">show_col_types</code></td>
<td>
<p>If <code>FALSE</code>, do not show the guessed column types. If
<code>TRUE</code> always show the column types, even if they are supplied. If <code>NULL</code>
(the default) only show the column types if they are not explicitly supplied
by the <code>col_types</code> argument.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
<tr><td><code id="read_delim_+3A_lazy">lazy</code></td>
<td>
<p>Read values lazily? By default, this is <code>FALSE</code>, because there
are special considerations when reading a file lazily that have tripped up
some users. Specifically, things get tricky when reading and then writing
back into the same file. But, in general, lazy reading (<code>lazy = TRUE</code>) has
many benefits, especially for interactive use and when your downstream work
only involves a subset of the rows or columns.
</p>
<p>Learn more in <code><a href="#topic+should_read_lazy">should_read_lazy()</a></code> and in the documentation for the
<code>altrep</code> argument of <code><a href="vroom.html#topic+vroom">vroom::vroom()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="tibble.html#topic+tibble">tibble()</a></code>. If there are parsing problems, a warning will alert you.
You can retrieve the full details by calling <code><a href="#topic+problems">problems()</a></code> on your dataset.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Input sources -------------------------------------------------------------
# Read from a path
read_csv(readr_example("mtcars.csv"))
read_csv(readr_example("mtcars.csv.zip"))
read_csv(readr_example("mtcars.csv.bz2"))
## Not run: 
# Including remote paths
read_csv("https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv")

## End(Not run)

# Read from multiple file paths at once
continents &lt;- c("africa", "americas", "asia", "europe", "oceania")
filepaths &lt;- vapply(
  paste0("mini-gapminder-", continents, ".csv"),
  FUN = readr_example,
  FUN.VALUE = character(1)
)
read_csv(filepaths, id = "file")

# Or directly from a string with `I()`
read_csv(I("x,y\n1,2\n3,4"))

# Column selection-----------------------------------------------------------
# Pass column names or indexes directly to select them
read_csv(readr_example("chickens.csv"), col_select = c(chicken, eggs_laid))
read_csv(readr_example("chickens.csv"), col_select = c(1, 3:4))

# Or use the selection helpers
read_csv(
  readr_example("chickens.csv"),
  col_select = c(starts_with("c"), last_col())
)

# You can also rename specific columns
read_csv(
  readr_example("chickens.csv"),
  col_select = c(egg_yield = eggs_laid, everything())
)

# Column types --------------------------------------------------------------
# By default, readr guesses the columns types, looking at `guess_max` rows.
# You can override with a compact specification:
read_csv(I("x,y\n1,2\n3,4"), col_types = "dc")

# Or with a list of column types:
read_csv(I("x,y\n1,2\n3,4"), col_types = list(col_double(), col_character()))

# If there are parsing problems, you get a warning, and can extract
# more details with problems()
y &lt;- read_csv(I("x\n1\n2\nb"), col_types = list(col_double()))
y
problems(y)

# Column names --------------------------------------------------------------
# By default, readr duplicate name repair is noisy
read_csv(I("x,x\n1,2\n3,4"))

# Same default repair strategy, but quiet
read_csv(I("x,x\n1,2\n3,4"), name_repair = "unique_quiet")

# There's also a global option that controls verbosity of name repair
withr::with_options(
  list(rlib_name_repair_verbosity = "quiet"),
  read_csv(I("x,x\n1,2\n3,4"))
)

# Or use "minimal" to turn off name repair
read_csv(I("x,x\n1,2\n3,4"), name_repair = "minimal")

# File types ----------------------------------------------------------------
read_csv(I("a,b\n1.0,2.0"))
read_csv2(I("a;b\n1,0;2,0"))
read_tsv(I("a\tb\n1.0\t2.0"))
read_delim(I("a|b\n1.0|2.0"), delim = "|")
</code></pre>

<hr>
<h2 id='read_delim_chunked'>Read a delimited file by chunks</h2><span id='topic+read_delim_chunked'></span><span id='topic+read_csv_chunked'></span><span id='topic+read_csv2_chunked'></span><span id='topic+read_tsv_chunked'></span>

<h3>Description</h3>

<p>Read a delimited file by chunks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_delim_chunked(
  file,
  callback,
  delim = NULL,
  chunk_size = 10000,
  quote = "\"",
  escape_backslash = FALSE,
  escape_double = TRUE,
  col_names = TRUE,
  col_types = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  comment = "",
  trim_ws = FALSE,
  skip = 0,
  guess_max = chunk_size,
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE
)

read_csv_chunked(
  file,
  callback,
  chunk_size = 10000,
  col_names = TRUE,
  col_types = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  guess_max = chunk_size,
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE
)

read_csv2_chunked(
  file,
  callback,
  chunk_size = 10000,
  col_names = TRUE,
  col_types = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  guess_max = chunk_size,
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE
)

read_tsv_chunked(
  file,
  callback,
  chunk_size = 10000,
  col_names = TRUE,
  col_types = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  guess_max = chunk_size,
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_delim_chunked_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_callback">callback</code></td>
<td>
<p>A callback function to call on each chunk</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_delim">delim</code></td>
<td>
<p>Single character used to separate fields within a record.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_chunk_size">chunk_size</code></td>
<td>
<p>The number of rows to include in each chunk</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_quote">quote</code></td>
<td>
<p>Single character used to quote strings.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_escape_backslash">escape_backslash</code></td>
<td>
<p>Does the file use backslashes to escape special
characters? This is more general than <code>escape_double</code> as backslashes
can be used to escape the delimiter character, the quote character, or
to add special characters like <code style="white-space: pre;">&#8288;\\n&#8288;</code>.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_escape_double">escape_double</code></td>
<td>
<p>Does the file escape quotes by doubling them?
i.e. If this option is <code>TRUE</code>, the value <code style="white-space: pre;">&#8288;""""&#8288;</code> represents
a single quote, <code style="white-space: pre;">&#8288;\"&#8288;</code>.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_col_names">col_names</code></td>
<td>
<p>Either <code>TRUE</code>, <code>FALSE</code> or a character vector
of column names.
</p>
<p>If <code>TRUE</code>, the first row of the input will be used as the column
names, and will not be included in the data frame. If <code>FALSE</code>, column
names will be generated automatically: X1, X2, X3 etc.
</p>
<p>If <code>col_names</code> is a character vector, the values will be used as the
names of the columns, and the first row of the input will be read into
the first row of the output data frame.
</p>
<p>Missing (<code>NA</code>) column names will generate a warning, and be filled
in with dummy names <code>...1</code>, <code>...2</code> etc. Duplicate column names
will generate a warning and be made unique, see <code>name_repair</code> to control
how this is done.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_col_types">col_types</code></td>
<td>
<p>One of <code>NULL</code>, a <code><a href="#topic+cols">cols()</a></code> specification, or
a string. See <code>vignette("readr")</code> for more details.
</p>
<p>If <code>NULL</code>, all column types will be inferred from <code>guess_max</code> rows of the
input, interspersed throughout the file. This is convenient (and fast),
but not robust. If the guessed types are wrong, you'll need to increase
<code>guess_max</code> or supply the correct types yourself.
</p>
<p>Column specifications created by <code><a href="base.html#topic+list">list()</a></code> or <code><a href="#topic+cols">cols()</a></code> must contain
one column specification for each column. If you only want to read a
subset of the columns, use <code><a href="#topic+cols_only">cols_only()</a></code>.
</p>
<p>Alternatively, you can use a compact string representation where each
character represents one column:
</p>

<ul>
<li><p> c = character
</p>
</li>
<li><p> i = integer
</p>
</li>
<li><p> n = number
</p>
</li>
<li><p> d = double
</p>
</li>
<li><p> l = logical
</p>
</li>
<li><p> f = factor
</p>
</li>
<li><p> D = date
</p>
</li>
<li><p> T = date time
</p>
</li>
<li><p> t = time
</p>
</li>
<li><p> ? = guess
</p>
</li>
<li><p> _ or - = skip
</p>
</li></ul>

<p>By default, reading a file without a column specification will print a
message showing what <code>readr</code> guessed they were. To remove this message,
set <code>show_col_types = FALSE</code> or set <code>options(readr.show_col_types = FALSE)</code>.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_quoted_na">quoted_na</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Should missing values
inside quotes be treated as missing values (the default) or strings. This
parameter is soft deprecated as of readr 2.0.0.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data. If <code>comment</code> is
supplied any commented lines are ignored <em>after</em> skipping.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_guess_max">guess_max</code></td>
<td>
<p>Maximum number of lines to use for guessing column types.
Will never use more than the number of lines read.
See <code>vignette("column-types", package = "readr")</code> for more details.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_show_col_types">show_col_types</code></td>
<td>
<p>If <code>FALSE</code>, do not show the guessed column types. If
<code>TRUE</code> always show the column types, even if they are supplied. If <code>NULL</code>
(the default) only show the column types if they are not explicitly supplied
by the <code>col_types</code> argument.</p>
</td></tr>
<tr><td><code id="read_delim_chunked_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of lines in <code>file</code> can exceed the maximum integer value in R (~2 billion).
</p>


<h3>See Also</h3>

<p>Other chunked: 
<code><a href="#topic+callback">callback</a></code>,
<code><a href="#topic+melt_delim_chunked">melt_delim_chunked</a>()</code>,
<code><a href="#topic+read_lines_chunked">read_lines_chunked</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Cars with 3 gears
f &lt;- function(x, pos) subset(x, gear == 3)
read_csv_chunked(readr_example("mtcars.csv"), DataFrameCallback$new(f), chunk_size = 5)
</code></pre>

<hr>
<h2 id='read_file'>Read/write a complete file</h2><span id='topic+read_file'></span><span id='topic+read_file_raw'></span><span id='topic+write_file'></span>

<h3>Description</h3>

<p><code>read_file()</code> reads a complete file into a single object: either a
character vector of length one, or a raw vector. <code>write_file()</code> takes a
single string, or a raw vector, and writes it exactly as is.  Raw vectors
are useful when dealing with binary data, or if you have text data with
unknown encoding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_file(file, locale = default_locale())

read_file_raw(file)

write_file(x, file, append = FALSE, path = deprecated())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_file_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="read_file_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="read_file_+3A_x">x</code></td>
<td>
<p>A single string, or a raw vector to write to disk.</p>
</td></tr>
<tr><td><code id="read_file_+3A_append">append</code></td>
<td>
<p>If <code>FALSE</code>, will overwrite existing file. If <code>TRUE</code>,
will append to existing file. In both cases, if the file does not exist a new
file is created.</p>
</td></tr>
<tr><td><code id="read_file_+3A_path">path</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Use the <code>file</code> argument
instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>read_file</code>: A length 1 character vector.
<code>read_lines_raw</code>: A raw vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>read_file(file.path(R.home("doc"), "AUTHORS"))
read_file_raw(file.path(R.home("doc"), "AUTHORS"))

tmp &lt;- tempfile()

x &lt;- format_csv(mtcars[1:6, ])
write_file(x, tmp)
identical(x, read_file(tmp))

read_lines(I(x))
</code></pre>

<hr>
<h2 id='read_fwf'>Read a fixed width file into a tibble</h2><span id='topic+read_fwf'></span><span id='topic+fwf_empty'></span><span id='topic+fwf_widths'></span><span id='topic+fwf_positions'></span><span id='topic+fwf_cols'></span>

<h3>Description</h3>

<p>A fixed width file can be a very compact representation of numeric data.
It's also very fast to parse, because every field is in the same place in
every line. Unfortunately, it's painful to parse because you need to
describe the length of every field. Readr aims to make it as easy as possible
by providing a number of different ways to describe the field structure.
</p>

<ul>
<li> <p><code><a href="#topic+fwf_empty">fwf_empty()</a></code> - Guesses based on the positions of empty columns.
</p>
</li>
<li> <p><code><a href="#topic+fwf_widths">fwf_widths()</a></code> - Supply the widths of the columns.
</p>
</li>
<li> <p><code><a href="#topic+fwf_positions">fwf_positions()</a></code> - Supply paired vectors of start and end positions.
</p>
</li>
<li> <p><code><a href="#topic+fwf_cols">fwf_cols()</a></code> - Supply named arguments of paired start and end positions or column widths.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>read_fwf(
  file,
  col_positions = fwf_empty(file, skip, n = guess_max),
  col_types = NULL,
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  guess_max = min(n_max, 1000),
  progress = show_progress(),
  name_repair = "unique",
  num_threads = readr_threads(),
  show_col_types = should_show_types(),
  lazy = should_read_lazy(),
  skip_empty_rows = TRUE
)

fwf_empty(
  file,
  skip = 0,
  skip_empty_rows = FALSE,
  col_names = NULL,
  comment = "",
  n = 100L
)

fwf_widths(widths, col_names = NULL)

fwf_positions(start, end = NULL, col_names = NULL)

fwf_cols(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_fwf_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_col_positions">col_positions</code></td>
<td>
<p>Column positions, as created by <code><a href="#topic+fwf_empty">fwf_empty()</a></code>,
<code><a href="#topic+fwf_widths">fwf_widths()</a></code> or <code><a href="#topic+fwf_positions">fwf_positions()</a></code>. To read in only selected fields,
use <code><a href="#topic+fwf_positions">fwf_positions()</a></code>. If the width of the last column is variable (a
ragged fwf file), supply the last end position as NA.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_col_types">col_types</code></td>
<td>
<p>One of <code>NULL</code>, a <code><a href="#topic+cols">cols()</a></code> specification, or
a string. See <code>vignette("readr")</code> for more details.
</p>
<p>If <code>NULL</code>, all column types will be inferred from <code>guess_max</code> rows of the
input, interspersed throughout the file. This is convenient (and fast),
but not robust. If the guessed types are wrong, you'll need to increase
<code>guess_max</code> or supply the correct types yourself.
</p>
<p>Column specifications created by <code><a href="base.html#topic+list">list()</a></code> or <code><a href="#topic+cols">cols()</a></code> must contain
one column specification for each column. If you only want to read a
subset of the columns, use <code><a href="#topic+cols_only">cols_only()</a></code>.
</p>
<p>Alternatively, you can use a compact string representation where each
character represents one column:
</p>

<ul>
<li><p> c = character
</p>
</li>
<li><p> i = integer
</p>
</li>
<li><p> n = number
</p>
</li>
<li><p> d = double
</p>
</li>
<li><p> l = logical
</p>
</li>
<li><p> f = factor
</p>
</li>
<li><p> D = date
</p>
</li>
<li><p> T = date time
</p>
</li>
<li><p> t = time
</p>
</li>
<li><p> ? = guess
</p>
</li>
<li><p> _ or - = skip
</p>
</li></ul>

<p>By default, reading a file without a column specification will print a
message showing what <code>readr</code> guessed they were. To remove this message,
set <code>show_col_types = FALSE</code> or set <code>options(readr.show_col_types = FALSE)</code>.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_col_select">col_select</code></td>
<td>
<p>Columns to include in the results. You can use the same
mini-language as <code>dplyr::select()</code> to refer to the columns by name. Use
<code>c()</code> to use more than one selection expression. Although this
usage is less common, <code>col_select</code> also accepts a numeric column index. See
<code><a href="tidyselect.html#topic+language">?tidyselect::language</a></code> for full details on the
selection language.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_id">id</code></td>
<td>
<p>The name of a column in which to store the file path. This is
useful when reading multiple input files and there is data in the file
paths, such as the data collection date. If <code>NULL</code> (the default) no extra
column is created.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of lines to read.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_guess_max">guess_max</code></td>
<td>
<p>Maximum number of lines to use for guessing column types.
Will never use more than the number of lines read.
See <code>vignette("column-types", package = "readr")</code> for more details.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_name_repair">name_repair</code></td>
<td>
<p>Handling of column names. The default behaviour is to
ensure column names are <code>"unique"</code>. Various repair strategies are
supported:
</p>

<ul>
<li> <p><code>"minimal"</code>: No name repair or checks, beyond basic existence of names.
</p>
</li>
<li> <p><code>"unique"</code> (default value): Make sure names are unique and not empty.
</p>
</li>
<li> <p><code>"check_unique"</code>: No name repair, but check they are <code>unique</code>.
</p>
</li>
<li> <p><code>"unique_quiet"</code>: Repair with the <code>unique</code> strategy, quietly.
</p>
</li>
<li> <p><code>"universal"</code>: Make the names <code>unique</code> and syntactic.
</p>
</li>
<li> <p><code>"universal_quiet"</code>: Repair with the <code>universal</code> strategy, quietly.
</p>
</li>
<li><p> A function: Apply custom name repair (e.g., <code>name_repair = make.names</code>
for names in the style of base R).
</p>
</li>
<li><p> A purrr-style anonymous function, see <code><a href="rlang.html#topic+as_function">rlang::as_function()</a></code>.
</p>
</li></ul>

<p>This argument is passed on as <code>repair</code> to <code><a href="vctrs.html#topic+vec_as_names">vctrs::vec_as_names()</a></code>.
See there for more details on these terms and the strategies used
to enforce them.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_num_threads">num_threads</code></td>
<td>
<p>The number of processing threads to use for initial
parsing and lazy reading of data. If your data contains newlines within
fields the parser should automatically detect this and fall back to using
one thread only. However if you know your file has newlines within quoted
fields it is safest to set <code>num_threads = 1</code> explicitly.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_show_col_types">show_col_types</code></td>
<td>
<p>If <code>FALSE</code>, do not show the guessed column types. If
<code>TRUE</code> always show the column types, even if they are supplied. If <code>NULL</code>
(the default) only show the column types if they are not explicitly supplied
by the <code>col_types</code> argument.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_lazy">lazy</code></td>
<td>
<p>Read values lazily? By default, this is <code>FALSE</code>, because there
are special considerations when reading a file lazily that have tripped up
some users. Specifically, things get tricky when reading and then writing
back into the same file. But, in general, lazy reading (<code>lazy = TRUE</code>) has
many benefits, especially for interactive use and when your downstream work
only involves a subset of the rows or columns.
</p>
<p>Learn more in <code><a href="#topic+should_read_lazy">should_read_lazy()</a></code> and in the documentation for the
<code>altrep</code> argument of <code><a href="vroom.html#topic+vroom">vroom::vroom()</a></code>.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_col_names">col_names</code></td>
<td>
<p>Either NULL, or a character vector column names.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_n">n</code></td>
<td>
<p>Number of lines the tokenizer will read to determine file structure. By default
it is set to 100.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_widths">widths</code></td>
<td>
<p>Width of each field. Use NA as width of last field when
reading a ragged fwf file.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_start">start</code>, <code id="read_fwf_+3A_end">end</code></td>
<td>
<p>Starting and ending (inclusive) positions of each field.
Use NA as last end field when reading a ragged fwf file.</p>
</td></tr>
<tr><td><code id="read_fwf_+3A_...">...</code></td>
<td>
<p>If the first element is a data frame,
then it must have all numeric columns and either one or two rows.
The column names are the variable names. The column values are the
variable widths if a length one vector, and if length two, variable start and end
positions. The elements of <code>...</code> are used to construct a data frame
with or or two rows as above.</p>
</td></tr>
</table>


<h3>Second edition changes</h3>

<p>Comments are no longer looked for anywhere in the file.
They are now only ignored at the start of a line.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_table">read_table()</a></code> to read fixed width files where each
column is separated by whitespace.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fwf_sample &lt;- readr_example("fwf-sample.txt")
writeLines(read_lines(fwf_sample))

# You can specify column positions in several ways:
# 1. Guess based on position of empty columns
read_fwf(fwf_sample, fwf_empty(fwf_sample, col_names = c("first", "last", "state", "ssn")))
# 2. A vector of field widths
read_fwf(fwf_sample, fwf_widths(c(20, 10, 12), c("name", "state", "ssn")))
# 3. Paired vectors of start and end positions
read_fwf(fwf_sample, fwf_positions(c(1, 30), c(20, 42), c("name", "ssn")))
# 4. Named arguments with start and end positions
read_fwf(fwf_sample, fwf_cols(name = c(1, 20), ssn = c(30, 42)))
# 5. Named arguments with column widths
read_fwf(fwf_sample, fwf_cols(name = 20, state = 10, ssn = 12))
</code></pre>

<hr>
<h2 id='read_lines'>Read/write lines to/from a file</h2><span id='topic+read_lines'></span><span id='topic+read_lines_raw'></span><span id='topic+write_lines'></span>

<h3>Description</h3>

<p><code>read_lines()</code> reads up to <code>n_max</code> lines from a file. New lines are
not included in the output. <code>read_lines_raw()</code> produces a list of raw
vectors, and is useful for handling data with unknown encoding.
<code>write_lines()</code> takes a character vector or list of raw vectors, appending a
new line after each entry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_lines(
  file,
  skip = 0,
  skip_empty_rows = FALSE,
  n_max = Inf,
  locale = default_locale(),
  na = character(),
  lazy = should_read_lazy(),
  num_threads = readr_threads(),
  progress = show_progress()
)

read_lines_raw(
  file,
  skip = 0,
  n_max = -1L,
  num_threads = readr_threads(),
  progress = show_progress()
)

write_lines(
  x,
  file,
  sep = "\n",
  na = "NA",
  append = FALSE,
  num_threads = readr_threads(),
  path = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_lines_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_n_max">n_max</code></td>
<td>
<p>Number of lines to read. If <code>n_max</code> is -1, all lines in
file will be read.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_lazy">lazy</code></td>
<td>
<p>Read values lazily? By default, this is <code>FALSE</code>, because there
are special considerations when reading a file lazily that have tripped up
some users. Specifically, things get tricky when reading and then writing
back into the same file. But, in general, lazy reading (<code>lazy = TRUE</code>) has
many benefits, especially for interactive use and when your downstream work
only involves a subset of the rows or columns.
</p>
<p>Learn more in <code><a href="#topic+should_read_lazy">should_read_lazy()</a></code> and in the documentation for the
<code>altrep</code> argument of <code><a href="vroom.html#topic+vroom">vroom::vroom()</a></code>.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_num_threads">num_threads</code></td>
<td>
<p>The number of processing threads to use for initial
parsing and lazy reading of data. If your data contains newlines within
fields the parser should automatically detect this and fall back to using
one thread only. However if you know your file has newlines within quoted
fields it is safest to set <code>num_threads = 1</code> explicitly.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_x">x</code></td>
<td>
<p>A character vector or list of raw vectors to write to disk.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_sep">sep</code></td>
<td>
<p>The line separator. Defaults to <code style="white-space: pre;">&#8288;\\n&#8288;</code>, commonly used on POSIX
systems like macOS and linux. For native windows (CRLF) separators use
<code style="white-space: pre;">&#8288;\\r\\n&#8288;</code>.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_append">append</code></td>
<td>
<p>If <code>FALSE</code>, will overwrite existing file. If <code>TRUE</code>,
will append to existing file. In both cases, if the file does not exist a new
file is created.</p>
</td></tr>
<tr><td><code id="read_lines_+3A_path">path</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Use the <code>file</code> argument
instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>read_lines()</code>: A character vector with one element for each line.
<code>read_lines_raw()</code>: A list containing a raw vector for each line.
</p>
<p><code>write_lines()</code> returns <code>x</code>, invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>read_lines(file.path(R.home("doc"), "AUTHORS"), n_max = 10)
read_lines_raw(file.path(R.home("doc"), "AUTHORS"), n_max = 10)

tmp &lt;- tempfile()

write_lines(rownames(mtcars), tmp)
read_lines(tmp, lazy = FALSE)
read_file(tmp) # note trailing \n

write_lines(airquality$Ozone, tmp, na = "-1")
read_lines(tmp)
</code></pre>

<hr>
<h2 id='read_lines_chunked'>Read lines from a file or string by chunk.</h2><span id='topic+read_lines_chunked'></span><span id='topic+read_lines_raw_chunked'></span>

<h3>Description</h3>

<p>Read lines from a file or string by chunk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_lines_chunked(
  file,
  callback,
  chunk_size = 10000,
  skip = 0,
  locale = default_locale(),
  na = character(),
  progress = show_progress()
)

read_lines_raw_chunked(
  file,
  callback,
  chunk_size = 10000,
  skip = 0,
  progress = show_progress()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_lines_chunked_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="read_lines_chunked_+3A_callback">callback</code></td>
<td>
<p>A callback function to call on each chunk</p>
</td></tr>
<tr><td><code id="read_lines_chunked_+3A_chunk_size">chunk_size</code></td>
<td>
<p>The number of rows to include in each chunk</p>
</td></tr>
<tr><td><code id="read_lines_chunked_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr><td><code id="read_lines_chunked_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="read_lines_chunked_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="read_lines_chunked_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other chunked: 
<code><a href="#topic+callback">callback</a></code>,
<code><a href="#topic+melt_delim_chunked">melt_delim_chunked</a>()</code>,
<code><a href="#topic+read_delim_chunked">read_delim_chunked</a>()</code>
</p>

<hr>
<h2 id='read_log'>Read common/combined log file into a tibble</h2><span id='topic+read_log'></span>

<h3>Description</h3>

<p>This is a fairly standard format for log files - it uses both quotes
and square brackets for quoting, and there may be literal quotes embedded
in a quoted string. The dash, &quot;-&quot;, is used for missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_log(
  file,
  col_names = FALSE,
  col_types = NULL,
  trim_ws = TRUE,
  skip = 0,
  n_max = Inf,
  show_col_types = should_show_types(),
  progress = show_progress()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_log_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="read_log_+3A_col_names">col_names</code></td>
<td>
<p>Either <code>TRUE</code>, <code>FALSE</code> or a character vector
of column names.
</p>
<p>If <code>TRUE</code>, the first row of the input will be used as the column
names, and will not be included in the data frame. If <code>FALSE</code>, column
names will be generated automatically: X1, X2, X3 etc.
</p>
<p>If <code>col_names</code> is a character vector, the values will be used as the
names of the columns, and the first row of the input will be read into
the first row of the output data frame.
</p>
<p>Missing (<code>NA</code>) column names will generate a warning, and be filled
in with dummy names <code>...1</code>, <code>...2</code> etc. Duplicate column names
will generate a warning and be made unique, see <code>name_repair</code> to control
how this is done.</p>
</td></tr>
<tr><td><code id="read_log_+3A_col_types">col_types</code></td>
<td>
<p>One of <code>NULL</code>, a <code><a href="#topic+cols">cols()</a></code> specification, or
a string. See <code>vignette("readr")</code> for more details.
</p>
<p>If <code>NULL</code>, all column types will be inferred from <code>guess_max</code> rows of the
input, interspersed throughout the file. This is convenient (and fast),
but not robust. If the guessed types are wrong, you'll need to increase
<code>guess_max</code> or supply the correct types yourself.
</p>
<p>Column specifications created by <code><a href="base.html#topic+list">list()</a></code> or <code><a href="#topic+cols">cols()</a></code> must contain
one column specification for each column. If you only want to read a
subset of the columns, use <code><a href="#topic+cols_only">cols_only()</a></code>.
</p>
<p>Alternatively, you can use a compact string representation where each
character represents one column:
</p>

<ul>
<li><p> c = character
</p>
</li>
<li><p> i = integer
</p>
</li>
<li><p> n = number
</p>
</li>
<li><p> d = double
</p>
</li>
<li><p> l = logical
</p>
</li>
<li><p> f = factor
</p>
</li>
<li><p> D = date
</p>
</li>
<li><p> T = date time
</p>
</li>
<li><p> t = time
</p>
</li>
<li><p> ? = guess
</p>
</li>
<li><p> _ or - = skip
</p>
</li></ul>

<p>By default, reading a file without a column specification will print a
message showing what <code>readr</code> guessed they were. To remove this message,
set <code>show_col_types = FALSE</code> or set <code>options(readr.show_col_types = FALSE)</code>.</p>
</td></tr>
<tr><td><code id="read_log_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="read_log_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data. If <code>comment</code> is
supplied any commented lines are ignored <em>after</em> skipping.</p>
</td></tr>
<tr><td><code id="read_log_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of lines to read.</p>
</td></tr>
<tr><td><code id="read_log_+3A_show_col_types">show_col_types</code></td>
<td>
<p>If <code>FALSE</code>, do not show the guessed column types. If
<code>TRUE</code> always show the column types, even if they are supplied. If <code>NULL</code>
(the default) only show the column types if they are not explicitly supplied
by the <code>col_types</code> argument.</p>
</td></tr>
<tr><td><code id="read_log_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>read_log(readr_example("example.log"))
</code></pre>

<hr>
<h2 id='read_rds'>Read/write RDS files.</h2><span id='topic+read_rds'></span><span id='topic+write_rds'></span>

<h3>Description</h3>

<p>Consistent wrapper around <code><a href="base.html#topic+saveRDS">saveRDS()</a></code> and <code><a href="base.html#topic+readRDS">readRDS()</a></code>.
<code>write_rds()</code> does not compress by default as space is generally cheaper
than time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_rds(file, refhook = NULL)

write_rds(
  x,
  file,
  compress = c("none", "gz", "bz2", "xz"),
  version = 2,
  refhook = NULL,
  text = FALSE,
  path = deprecated(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_rds_+3A_file">file</code></td>
<td>
<p>The file path to read from/write to.</p>
</td></tr>
<tr><td><code id="read_rds_+3A_refhook">refhook</code></td>
<td>
<p>A function to handle reference objects.</p>
</td></tr>
<tr><td><code id="read_rds_+3A_x">x</code></td>
<td>
<p>R object to write to serialise.</p>
</td></tr>
<tr><td><code id="read_rds_+3A_compress">compress</code></td>
<td>
<p>Compression method to use: &quot;none&quot;, &quot;gz&quot; ,&quot;bz&quot;, or &quot;xz&quot;.</p>
</td></tr>
<tr><td><code id="read_rds_+3A_version">version</code></td>
<td>
<p>Serialization format version to be used. The default value is 2
as it's compatible for R versions prior to 3.5.0. See <code><a href="base.html#topic+readRDS">base::saveRDS()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="read_rds_+3A_text">text</code></td>
<td>
<p>If <code>TRUE</code> a text representation is used, otherwise a binary representation is used.</p>
</td></tr>
<tr><td><code id="read_rds_+3A_path">path</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Use the <code>file</code> argument
instead.</p>
</td></tr>
<tr><td><code id="read_rds_+3A_...">...</code></td>
<td>
<p>Additional arguments to connection function. For example, control
the space-time trade-off of different compression methods with
<code>compression</code>. See <code><a href="base.html#topic+connections">connections()</a></code> for more details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>write_rds()</code> returns <code>x</code>, invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>temp &lt;- tempfile()
write_rds(mtcars, temp)
read_rds(temp)
## Not run: 
write_rds(mtcars, "compressed_mtc.rds", "xz", compression = 9L)

## End(Not run)
</code></pre>

<hr>
<h2 id='read_table'>Read whitespace-separated columns into a tibble</h2><span id='topic+read_table'></span>

<h3>Description</h3>

<p><code>read_table()</code> is designed to read the type of textual
data where each column is separated by one (or more) columns of space.
</p>
<p><code>read_table()</code> is like <code><a href="utils.html#topic+read.table">read.table()</a></code>, it allows any number of whitespace
characters between columns, and the lines can be of different lengths.
</p>
<p><code>spec_table()</code> returns the column specifications rather than a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_table(
  file,
  col_names = TRUE,
  col_types = NULL,
  locale = default_locale(),
  na = "NA",
  skip = 0,
  n_max = Inf,
  guess_max = min(n_max, 1000),
  progress = show_progress(),
  comment = "",
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_table_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="read_table_+3A_col_names">col_names</code></td>
<td>
<p>Either <code>TRUE</code>, <code>FALSE</code> or a character vector
of column names.
</p>
<p>If <code>TRUE</code>, the first row of the input will be used as the column
names, and will not be included in the data frame. If <code>FALSE</code>, column
names will be generated automatically: X1, X2, X3 etc.
</p>
<p>If <code>col_names</code> is a character vector, the values will be used as the
names of the columns, and the first row of the input will be read into
the first row of the output data frame.
</p>
<p>Missing (<code>NA</code>) column names will generate a warning, and be filled
in with dummy names <code>...1</code>, <code>...2</code> etc. Duplicate column names
will generate a warning and be made unique, see <code>name_repair</code> to control
how this is done.</p>
</td></tr>
<tr><td><code id="read_table_+3A_col_types">col_types</code></td>
<td>
<p>One of <code>NULL</code>, a <code><a href="#topic+cols">cols()</a></code> specification, or
a string. See <code>vignette("readr")</code> for more details.
</p>
<p>If <code>NULL</code>, all column types will be inferred from <code>guess_max</code> rows of the
input, interspersed throughout the file. This is convenient (and fast),
but not robust. If the guessed types are wrong, you'll need to increase
<code>guess_max</code> or supply the correct types yourself.
</p>
<p>Column specifications created by <code><a href="base.html#topic+list">list()</a></code> or <code><a href="#topic+cols">cols()</a></code> must contain
one column specification for each column. If you only want to read a
subset of the columns, use <code><a href="#topic+cols_only">cols_only()</a></code>.
</p>
<p>Alternatively, you can use a compact string representation where each
character represents one column:
</p>

<ul>
<li><p> c = character
</p>
</li>
<li><p> i = integer
</p>
</li>
<li><p> n = number
</p>
</li>
<li><p> d = double
</p>
</li>
<li><p> l = logical
</p>
</li>
<li><p> f = factor
</p>
</li>
<li><p> D = date
</p>
</li>
<li><p> T = date time
</p>
</li>
<li><p> t = time
</p>
</li>
<li><p> ? = guess
</p>
</li>
<li><p> _ or - = skip
</p>
</li></ul>

<p>By default, reading a file without a column specification will print a
message showing what <code>readr</code> guessed they were. To remove this message,
set <code>show_col_types = FALSE</code> or set <code>options(readr.show_col_types = FALSE)</code>.</p>
</td></tr>
<tr><td><code id="read_table_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="read_table_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="read_table_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr><td><code id="read_table_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of lines to read.</p>
</td></tr>
<tr><td><code id="read_table_+3A_guess_max">guess_max</code></td>
<td>
<p>Maximum number of lines to use for guessing column types.
Will never use more than the number of lines read.
See <code>vignette("column-types", package = "readr")</code> for more details.</p>
</td></tr>
<tr><td><code id="read_table_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="read_table_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="read_table_+3A_show_col_types">show_col_types</code></td>
<td>
<p>If <code>FALSE</code>, do not show the guessed column types. If
<code>TRUE</code> always show the column types, even if they are supplied. If <code>NULL</code>
(the default) only show the column types if they are not explicitly supplied
by the <code>col_types</code> argument.</p>
</td></tr>
<tr><td><code id="read_table_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+read_fwf">read_fwf()</a></code> to read fixed width files where each column
is not separated by whitespace. <code>read_fwf()</code> is also useful for reading
tabular data with non-standard formatting.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ws &lt;- readr_example("whitespace-sample.txt")
writeLines(read_lines(ws))
read_table(ws)
</code></pre>

<hr>
<h2 id='read_table2'>Read whitespace-separated columns into a tibble</h2><span id='topic+read_table2'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p>This function is deprecated because we renamed it to <code><a href="#topic+read_table">read_table()</a></code> and
removed the old <code>read_table</code> function, which was too strict for most cases
and was analogous to just using <code>read_fwf()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_table2(
  file,
  col_names = TRUE,
  col_types = NULL,
  locale = default_locale(),
  na = "NA",
  skip = 0,
  n_max = Inf,
  guess_max = min(n_max, 1000),
  progress = show_progress(),
  comment = "",
  skip_empty_rows = TRUE
)
</code></pre>

<hr>
<h2 id='readr_example'>Get path to readr example</h2><span id='topic+readr_example'></span>

<h3>Description</h3>

<p>readr comes bundled with a number of sample files in its <code>inst/extdata</code>
directory. This function make them easy to access
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readr_example(file = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readr_example_+3A_file">file</code></td>
<td>
<p>Name of file. If <code>NULL</code>, the example files will be listed.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>readr_example()
readr_example("challenge.csv")
</code></pre>

<hr>
<h2 id='readr_threads'>Determine how many threads readr should use when processing</h2><span id='topic+readr_threads'></span>

<h3>Description</h3>

<p>The number of threads returned can be set by
</p>

<ul>
<li><p> The global option <code>readr.num_threads</code>
</p>
</li>
<li><p> The environment variable <code>VROOM_THREADS</code>
</p>
</li>
<li><p> The value of <code><a href="parallel.html#topic+detectCores">parallel::detectCores()</a></code>
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>readr_threads()
</code></pre>

<hr>
<h2 id='readr-package'>readr: Read Rectangular Text Data</h2><span id='topic+readr'></span><span id='topic+readr-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>The goal of 'readr' is to provide a fast and friendly way to read rectangular data (like 'csv', 'tsv', and 'fwf'). It is designed to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jennifer Bryan <a href="mailto:jenny@posit.co">jenny@posit.co</a> (<a href="https://orcid.org/0000-0002-6983-2759">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Hadley Wickham <a href="mailto:hadley@posit.co">hadley@posit.co</a>
</p>
</li>
<li><p> Jim Hester
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Romain Francois [contributor]
</p>
</li>
<li><p> Shelby Bearrows [contributor]
</p>
</li>
<li><p> Posit Software, PBC [copyright holder, funder]
</p>
</li>
<li><p> https://github.com/mandreyel/ (mio library) [copyright holder]
</p>
</li>
<li><p> Jukka Jylänki (grisu3 implementation) [contributor, copyright holder]
</p>
</li>
<li><p> Mikkel Jørgensen (grisu3 implementation) [contributor, copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://readr.tidyverse.org">https://readr.tidyverse.org</a>
</p>
</li>
<li> <p><a href="https://github.com/tidyverse/readr">https://github.com/tidyverse/readr</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tidyverse/readr/issues">https://github.com/tidyverse/readr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='should_read_lazy'>Determine whether to read a file lazily</h2><span id='topic+should_read_lazy'></span>

<h3>Description</h3>

<p>This function consults the option <code>readr.read_lazy</code> to figure out whether to
do lazy reading or not. If the option is unset, the default is <code>FALSE</code>,
meaning readr will read files eagerly, not lazily. If you want to use this
option to express a preference for lazy reading, do this:
</p>
<div class="sourceCode"><pre>options(readr.read_lazy = TRUE)
</pre></div>
<p>Typically, one would use the option to control lazy reading at the session,
file, or user level. The <code>lazy</code> argument of functions like <code><a href="#topic+read_csv">read_csv()</a></code> can
be used to control laziness in an individual call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>should_read_lazy()
</code></pre>


<h3>See Also</h3>

<p>The blog post <a href="https://www.tidyverse.org/blog/2021/11/readr-2-1-0-lazy/">&quot;Eager vs lazy reading in readr 2.1.0&quot;</a> explains
the benefits (and downsides) of lazy reading.
</p>

<hr>
<h2 id='should_show_types'>Determine whether column types should be shown</h2><span id='topic+should_show_types'></span>

<h3>Description</h3>

<p>Wrapper around <code>getOption("readr.show_col_types")</code> that implements some fall
back logic if the option is unset. This returns:
</p>

<ul>
<li> <p><code>TRUE</code> if the option is set to <code>TRUE</code>
</p>
</li>
<li> <p><code>FALSE</code> if the option is set to <code>FALSE</code>
</p>
</li>
<li> <p><code>FALSE</code> if the option is unset and we appear to be running tests
</p>
</li>
<li> <p><code>NULL</code> otherwise, in which case the caller determines whether to show
column types based on context, e.g. whether <code>show_col_types</code> or actual
<code>col_types</code> were explicitly specified
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>should_show_types()
</code></pre>

<hr>
<h2 id='show_progress'>Determine whether progress bars should be shown</h2><span id='topic+show_progress'></span>

<h3>Description</h3>

<p>By default, readr shows progress bars. However, progress reporting is
suppressed if any of the following conditions hold:
</p>

<ul>
<li><p> The bar is explicitly disabled by setting
<code>options(readr.show_progress = FALSE)</code>.
</p>
</li>
<li><p> The code is run in a non-interactive session, as determined by
<code><a href="rlang.html#topic+is_interactive">rlang::is_interactive()</a></code>.
</p>
</li>
<li><p> The code is run in an RStudio notebook chunk, as determined by
<code>getOption("rstudio.notebook.executing")</code>.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>show_progress()
</code></pre>

<hr>
<h2 id='spec_delim'>Generate a column specification</h2><span id='topic+spec_delim'></span><span id='topic+spec_csv'></span><span id='topic+spec_csv2'></span><span id='topic+spec_tsv'></span><span id='topic+spec_table'></span>

<h3>Description</h3>

<p>When printed, only the first 20 columns are printed by default. To override,
set <code>options(readr.num_columns)</code> can be used to modify this (a value of 0
turns off printing).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spec_delim(
  file,
  delim = NULL,
  quote = "\"",
  escape_backslash = FALSE,
  escape_double = TRUE,
  col_names = TRUE,
  col_types = list(),
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  comment = "",
  trim_ws = FALSE,
  skip = 0,
  n_max = 0,
  guess_max = 1000,
  name_repair = "unique",
  num_threads = readr_threads(),
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)

spec_csv(
  file,
  col_names = TRUE,
  col_types = list(),
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = 0,
  guess_max = 1000,
  name_repair = "unique",
  num_threads = readr_threads(),
  progress = show_progress(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)

spec_csv2(
  file,
  col_names = TRUE,
  col_types = list(),
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = 0,
  guess_max = 1000,
  progress = show_progress(),
  name_repair = "unique",
  num_threads = readr_threads(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)

spec_tsv(
  file,
  col_names = TRUE,
  col_types = list(),
  col_select = NULL,
  id = NULL,
  locale = default_locale(),
  na = c("", "NA"),
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = 0,
  guess_max = 1000,
  progress = show_progress(),
  name_repair = "unique",
  num_threads = readr_threads(),
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE,
  lazy = should_read_lazy()
)

spec_table(
  file,
  col_names = TRUE,
  col_types = list(),
  locale = default_locale(),
  na = "NA",
  skip = 0,
  n_max = 0,
  guess_max = 1000,
  progress = show_progress(),
  comment = "",
  show_col_types = should_show_types(),
  skip_empty_rows = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spec_delim_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_delim">delim</code></td>
<td>
<p>Single character used to separate fields within a record.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_quote">quote</code></td>
<td>
<p>Single character used to quote strings.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_escape_backslash">escape_backslash</code></td>
<td>
<p>Does the file use backslashes to escape special
characters? This is more general than <code>escape_double</code> as backslashes
can be used to escape the delimiter character, the quote character, or
to add special characters like <code style="white-space: pre;">&#8288;\\n&#8288;</code>.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_escape_double">escape_double</code></td>
<td>
<p>Does the file escape quotes by doubling them?
i.e. If this option is <code>TRUE</code>, the value <code style="white-space: pre;">&#8288;""""&#8288;</code> represents
a single quote, <code style="white-space: pre;">&#8288;\"&#8288;</code>.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_col_names">col_names</code></td>
<td>
<p>Either <code>TRUE</code>, <code>FALSE</code> or a character vector
of column names.
</p>
<p>If <code>TRUE</code>, the first row of the input will be used as the column
names, and will not be included in the data frame. If <code>FALSE</code>, column
names will be generated automatically: X1, X2, X3 etc.
</p>
<p>If <code>col_names</code> is a character vector, the values will be used as the
names of the columns, and the first row of the input will be read into
the first row of the output data frame.
</p>
<p>Missing (<code>NA</code>) column names will generate a warning, and be filled
in with dummy names <code>...1</code>, <code>...2</code> etc. Duplicate column names
will generate a warning and be made unique, see <code>name_repair</code> to control
how this is done.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_col_types">col_types</code></td>
<td>
<p>One of <code>NULL</code>, a <code><a href="#topic+cols">cols()</a></code> specification, or
a string. See <code>vignette("readr")</code> for more details.
</p>
<p>If <code>NULL</code>, all column types will be inferred from <code>guess_max</code> rows of the
input, interspersed throughout the file. This is convenient (and fast),
but not robust. If the guessed types are wrong, you'll need to increase
<code>guess_max</code> or supply the correct types yourself.
</p>
<p>Column specifications created by <code><a href="base.html#topic+list">list()</a></code> or <code><a href="#topic+cols">cols()</a></code> must contain
one column specification for each column. If you only want to read a
subset of the columns, use <code><a href="#topic+cols_only">cols_only()</a></code>.
</p>
<p>Alternatively, you can use a compact string representation where each
character represents one column:
</p>

<ul>
<li><p> c = character
</p>
</li>
<li><p> i = integer
</p>
</li>
<li><p> n = number
</p>
</li>
<li><p> d = double
</p>
</li>
<li><p> l = logical
</p>
</li>
<li><p> f = factor
</p>
</li>
<li><p> D = date
</p>
</li>
<li><p> T = date time
</p>
</li>
<li><p> t = time
</p>
</li>
<li><p> ? = guess
</p>
</li>
<li><p> _ or - = skip
</p>
</li></ul>

<p>By default, reading a file without a column specification will print a
message showing what <code>readr</code> guessed they were. To remove this message,
set <code>show_col_types = FALSE</code> or set <code>options(readr.show_col_types = FALSE)</code>.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_col_select">col_select</code></td>
<td>
<p>Columns to include in the results. You can use the same
mini-language as <code>dplyr::select()</code> to refer to the columns by name. Use
<code>c()</code> to use more than one selection expression. Although this
usage is less common, <code>col_select</code> also accepts a numeric column index. See
<code><a href="tidyselect.html#topic+language">?tidyselect::language</a></code> for full details on the
selection language.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_id">id</code></td>
<td>
<p>The name of a column in which to store the file path. This is
useful when reading multiple input files and there is data in the file
paths, such as the data collection date. If <code>NULL</code> (the default) no extra
column is created.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_quoted_na">quoted_na</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Should missing values
inside quotes be treated as missing values (the default) or strings. This
parameter is soft deprecated as of readr 2.0.0.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data. If <code>comment</code> is
supplied any commented lines are ignored <em>after</em> skipping.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of lines to read.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_guess_max">guess_max</code></td>
<td>
<p>Maximum number of lines to use for guessing column types.
Will never use more than the number of lines read.
See <code>vignette("column-types", package = "readr")</code> for more details.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_name_repair">name_repair</code></td>
<td>
<p>Handling of column names. The default behaviour is to
ensure column names are <code>"unique"</code>. Various repair strategies are
supported:
</p>

<ul>
<li> <p><code>"minimal"</code>: No name repair or checks, beyond basic existence of names.
</p>
</li>
<li> <p><code>"unique"</code> (default value): Make sure names are unique and not empty.
</p>
</li>
<li> <p><code>"check_unique"</code>: No name repair, but check they are <code>unique</code>.
</p>
</li>
<li> <p><code>"unique_quiet"</code>: Repair with the <code>unique</code> strategy, quietly.
</p>
</li>
<li> <p><code>"universal"</code>: Make the names <code>unique</code> and syntactic.
</p>
</li>
<li> <p><code>"universal_quiet"</code>: Repair with the <code>universal</code> strategy, quietly.
</p>
</li>
<li><p> A function: Apply custom name repair (e.g., <code>name_repair = make.names</code>
for names in the style of base R).
</p>
</li>
<li><p> A purrr-style anonymous function, see <code><a href="rlang.html#topic+as_function">rlang::as_function()</a></code>.
</p>
</li></ul>

<p>This argument is passed on as <code>repair</code> to <code><a href="vctrs.html#topic+vec_as_names">vctrs::vec_as_names()</a></code>.
See there for more details on these terms and the strategies used
to enforce them.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_num_threads">num_threads</code></td>
<td>
<p>The number of processing threads to use for initial
parsing and lazy reading of data. If your data contains newlines within
fields the parser should automatically detect this and fall back to using
one thread only. However if you know your file has newlines within quoted
fields it is safest to set <code>num_threads = 1</code> explicitly.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The automatic
progress bar can be disabled by setting option <code>readr.show_progress</code> to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_show_col_types">show_col_types</code></td>
<td>
<p>If <code>FALSE</code>, do not show the guessed column types. If
<code>TRUE</code> always show the column types, even if they are supplied. If <code>NULL</code>
(the default) only show the column types if they are not explicitly supplied
by the <code>col_types</code> argument.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
<tr><td><code id="spec_delim_+3A_lazy">lazy</code></td>
<td>
<p>Read values lazily? By default, this is <code>FALSE</code>, because there
are special considerations when reading a file lazily that have tripped up
some users. Specifically, things get tricky when reading and then writing
back into the same file. But, in general, lazy reading (<code>lazy = TRUE</code>) has
many benefits, especially for interactive use and when your downstream work
only involves a subset of the rows or columns.
</p>
<p>Learn more in <code><a href="#topic+should_read_lazy">should_read_lazy()</a></code> and in the documentation for the
<code>altrep</code> argument of <code><a href="vroom.html#topic+vroom">vroom::vroom()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>col_spec</code> generated for the file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Input sources -------------------------------------------------------------
# Retrieve specs from a path
spec_csv(system.file("extdata/mtcars.csv", package = "readr"))
spec_csv(system.file("extdata/mtcars.csv.zip", package = "readr"))

# Or directly from a string (must contain a newline)
spec_csv(I("x,y\n1,2\n3,4"))

# Column types --------------------------------------------------------------
# By default, readr guesses the columns types, looking at 1000 rows
# throughout the file.
# You can specify the number of rows used with guess_max.
spec_csv(system.file("extdata/mtcars.csv", package = "readr"), guess_max = 20)
</code></pre>

<hr>
<h2 id='tokenize'>Tokenize a file/string.</h2><span id='topic+tokenize'></span>

<h3>Description</h3>

<p>Turns input into a character vector. Usually the tokenization is done purely
in C++, and never exposed to R (because that requires a copy). This function
is useful for testing, or when a file doesn't parse correctly and you want
to see the underlying tokens.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenize(file, tokenizer = tokenizer_csv(), skip = 0, n_max = -1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokenize_+3A_file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">&#8288;http://&#8288;</code>,
<code style="white-space: pre;">&#8288;https://&#8288;</code>, <code style="white-space: pre;">&#8288;ftp://&#8288;</code>, or <code style="white-space: pre;">&#8288;ftps://&#8288;</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="#topic+clipboard">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr><td><code id="tokenize_+3A_tokenizer">tokenizer</code></td>
<td>
<p>A tokenizer specification.</p>
</td></tr>
<tr><td><code id="tokenize_+3A_skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr><td><code id="tokenize_+3A_n_max">n_max</code></td>
<td>
<p>Optionally, maximum number of rows to tokenize.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>tokenize("1,2\n3,4,5\n\n6")

# Only tokenize first two lines
tokenize("1,2\n3,4,5\n\n6", n = 2)
</code></pre>

<hr>
<h2 id='Tokenizers'>Tokenizers.</h2><span id='topic+Tokenizers'></span><span id='topic+tokenizer_delim'></span><span id='topic+tokenizer_csv'></span><span id='topic+tokenizer_tsv'></span><span id='topic+tokenizer_line'></span><span id='topic+tokenizer_log'></span><span id='topic+tokenizer_fwf'></span><span id='topic+tokenizer_ws'></span>

<h3>Description</h3>

<p>Explicitly create tokenizer objects. Usually you will not call these
function, but will instead use one of the use friendly wrappers like
<code><a href="#topic+read_csv">read_csv()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenizer_delim(
  delim,
  quote = "\"",
  na = "NA",
  quoted_na = TRUE,
  comment = "",
  trim_ws = TRUE,
  escape_double = TRUE,
  escape_backslash = FALSE,
  skip_empty_rows = TRUE
)

tokenizer_csv(
  na = "NA",
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip_empty_rows = TRUE
)

tokenizer_tsv(
  na = "NA",
  quoted_na = TRUE,
  quote = "\"",
  comment = "",
  trim_ws = TRUE,
  skip_empty_rows = TRUE
)

tokenizer_line(na = character(), skip_empty_rows = TRUE)

tokenizer_log(trim_ws)

tokenizer_fwf(
  begin,
  end,
  na = "NA",
  comment = "",
  trim_ws = TRUE,
  skip_empty_rows = TRUE
)

tokenizer_ws(na = "NA", comment = "", skip_empty_rows = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tokenizers_+3A_delim">delim</code></td>
<td>
<p>Single character used to separate fields within a record.</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_quote">quote</code></td>
<td>
<p>Single character used to quote strings.</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_quoted_na">quoted_na</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Should missing values
inside quotes be treated as missing values (the default) or strings. This
parameter is soft deprecated as of readr 2.0.0.</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_comment">comment</code></td>
<td>
<p>A string used to identify comments. Any text after the
comment characters will be silently ignored.</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_escape_double">escape_double</code></td>
<td>
<p>Does the file escape quotes by doubling them?
i.e. If this option is <code>TRUE</code>, the value <code style="white-space: pre;">&#8288;""""&#8288;</code> represents
a single quote, <code style="white-space: pre;">&#8288;\"&#8288;</code>.</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_escape_backslash">escape_backslash</code></td>
<td>
<p>Does the file use backslashes to escape special
characters? This is more general than <code>escape_double</code> as backslashes
can be used to escape the delimiter character, the quote character, or
to add special characters like <code style="white-space: pre;">&#8288;\\n&#8288;</code>.</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_skip_empty_rows">skip_empty_rows</code></td>
<td>
<p>Should blank rows be ignored altogether? i.e. If this
option is <code>TRUE</code> then blank rows will not be represented at all.  If it is
<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>
</td></tr>
<tr><td><code id="Tokenizers_+3A_begin">begin</code>, <code id="Tokenizers_+3A_end">end</code></td>
<td>
<p>Begin and end offsets for each file. These are C++
offsets so the first column is column zero, and the ranges are
[begin, end) (i.e inclusive-exclusive).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>tokenizer_csv()
</code></pre>

<hr>
<h2 id='type_convert'>Re-convert character columns in existing data frame</h2><span id='topic+type_convert'></span>

<h3>Description</h3>

<p>This is useful if you need to do some manual munging - you can read the
columns in as character, clean it up with (e.g.) regular expressions and
then let readr take another stab at parsing it. The name is a homage to
the base <code><a href="utils.html#topic+type.convert">utils::type.convert()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>type_convert(
  df,
  col_types = NULL,
  na = c("", "NA"),
  trim_ws = TRUE,
  locale = default_locale(),
  guess_integer = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="type_convert_+3A_df">df</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="type_convert_+3A_col_types">col_types</code></td>
<td>
<p>One of <code>NULL</code>, a <code><a href="#topic+cols">cols()</a></code> specification, or
a string. See <code>vignette("readr")</code> for more details.
</p>
<p>If <code>NULL</code>, column types will be imputed using all rows.</p>
</td></tr>
<tr><td><code id="type_convert_+3A_na">na</code></td>
<td>
<p>Character vector of strings to interpret as missing values. Set this
option to <code>character()</code> to indicate no missing values.</p>
</td></tr>
<tr><td><code id="type_convert_+3A_trim_ws">trim_ws</code></td>
<td>
<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from
each field before parsing it?</p>
</td></tr>
<tr><td><code id="type_convert_+3A_locale">locale</code></td>
<td>
<p>The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
<code><a href="#topic+locale">locale()</a></code> to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.</p>
</td></tr>
<tr><td><code id="type_convert_+3A_guess_integer">guess_integer</code></td>
<td>
<p>If <code>TRUE</code>, guess integer types for whole numbers, if
<code>FALSE</code> guess numeric type for all numbers.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>type_convert()</code> removes a 'spec' attribute,
because it likely modifies the column data types.
(see <code><a href="#topic+spec">spec()</a></code> for more information about column specifications).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  x = as.character(runif(10)),
  y = as.character(sample(10)),
  stringsAsFactors = FALSE
)
str(df)
str(type_convert(df))

df &lt;- data.frame(x = c("NA", "10"), stringsAsFactors = FALSE)
str(type_convert(df))

# Type convert can be used to infer types from an entire dataset

# first read the data as character
data &lt;- read_csv(readr_example("mtcars.csv"),
  col_types = list(.default = col_character())
)
str(data)
# Then convert it with type_convert
type_convert(data)
</code></pre>

<hr>
<h2 id='with_edition'>Temporarily change the active readr edition</h2><span id='topic+with_edition'></span><span id='topic+local_edition'></span>

<h3>Description</h3>

<p><code>with_edition()</code> allows you to change the active edition of readr for a given
block of code. <code>local_edition()</code> allows you to change the active edition of
readr until the end of the current function or file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>with_edition(edition, code)

local_edition(edition, env = parent.frame())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="with_edition_+3A_edition">edition</code></td>
<td>
<p>Should be a single integer, such as <code>1</code> or <code>2</code>.</p>
</td></tr>
<tr><td><code id="with_edition_+3A_code">code</code></td>
<td>
<p>Code to run with the changed edition.</p>
</td></tr>
<tr><td><code id="with_edition_+3A_env">env</code></td>
<td>
<p>Environment that controls scope of changes. For expert use only.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>with_edition(1, edition_get())
with_edition(2, edition_get())

# readr 1e and 2e behave differently when input rows have different number
# number of fields
with_edition(1, read_csv("1,2\n3,4,5", col_names = c("X", "Y", "Z")))
with_edition(2, read_csv("1,2\n3,4,5", col_names = c("X", "Y", "Z")))

# local_edition() applies in a specific scope, for example, inside a function
read_csv_1e &lt;- function(...) {
  local_edition(1)
  read_csv(...)
}
read_csv("1,2\n3,4,5", col_names = c("X", "Y", "Z"))      # 2e behaviour
read_csv_1e("1,2\n3,4,5", col_names = c("X", "Y", "Z"))   # 1e behaviour
read_csv("1,2\n3,4,5", col_names = c("X", "Y", "Z"))      # 2e behaviour
</code></pre>

<hr>
<h2 id='write_delim'>Write a data frame to a delimited file</h2><span id='topic+write_delim'></span><span id='topic+write_csv'></span><span id='topic+write_csv2'></span><span id='topic+write_excel_csv'></span><span id='topic+write_excel_csv2'></span><span id='topic+write_tsv'></span>

<h3>Description</h3>

<p>The <code style="white-space: pre;">&#8288;write_*()&#8288;</code> family of functions are an improvement to analogous function such
as <code><a href="utils.html#topic+write.csv">write.csv()</a></code> because they are approximately twice as fast. Unlike <code><a href="utils.html#topic+write.csv">write.csv()</a></code>,
these functions do not include row names as a column in the written file.
A generic function, <code>output_column()</code>, is applied to each variable
to coerce columns to suitable output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_delim(
  x,
  file,
  delim = " ",
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  num_threads = readr_threads(),
  progress = show_progress(),
  path = deprecated(),
  quote_escape = deprecated()
)

write_csv(
  x,
  file,
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  num_threads = readr_threads(),
  progress = show_progress(),
  path = deprecated(),
  quote_escape = deprecated()
)

write_csv2(
  x,
  file,
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  num_threads = readr_threads(),
  progress = show_progress(),
  path = deprecated(),
  quote_escape = deprecated()
)

write_excel_csv(
  x,
  file,
  na = "NA",
  append = FALSE,
  col_names = !append,
  delim = ",",
  quote = "all",
  escape = c("double", "backslash", "none"),
  eol = "\n",
  num_threads = readr_threads(),
  progress = show_progress(),
  path = deprecated(),
  quote_escape = deprecated()
)

write_excel_csv2(
  x,
  file,
  na = "NA",
  append = FALSE,
  col_names = !append,
  delim = ";",
  quote = "all",
  escape = c("double", "backslash", "none"),
  eol = "\n",
  num_threads = readr_threads(),
  progress = show_progress(),
  path = deprecated(),
  quote_escape = deprecated()
)

write_tsv(
  x,
  file,
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = "none",
  escape = c("double", "backslash", "none"),
  eol = "\n",
  num_threads = readr_threads(),
  progress = show_progress(),
  path = deprecated(),
  quote_escape = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_delim_+3A_x">x</code></td>
<td>
<p>A data frame or tibble to write to disk.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_file">file</code></td>
<td>
<p>File or connection to write to.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_delim">delim</code></td>
<td>
<p>Delimiter used to separate values. Defaults to <code>" "</code> for <code>write_delim()</code>, <code>","</code> for <code>write_excel_csv()</code> and
<code>";"</code> for <code>write_excel_csv2()</code>. Must be a single character.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_na">na</code></td>
<td>
<p>String used for missing values. Defaults to NA. Missing values
will never be quoted; strings with the same value as <code>na</code> will
always be quoted.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_append">append</code></td>
<td>
<p>If <code>FALSE</code>, will overwrite existing file. If <code>TRUE</code>,
will append to existing file. In both cases, if the file does not exist a new
file is created.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_col_names">col_names</code></td>
<td>
<p>If <code>FALSE</code>, column names will not be included at the top of the file. If <code>TRUE</code>,
column names will be included. If not specified, <code>col_names</code> will take the opposite value given to <code>append</code>.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_quote">quote</code></td>
<td>
<p>How to handle fields which contain characters that need to be
quoted.
</p>

<ul>
<li> <p><code>needed</code> - Values are only quoted if needed: if they contain a delimiter,
quote, or newline.
</p>
</li>
<li> <p><code>all</code> - Quote all fields.
</p>
</li>
<li> <p><code>none</code> - Never quote fields.
</p>
</li></ul>
</td></tr>
<tr><td><code id="write_delim_+3A_escape">escape</code></td>
<td>
<p>The type of escape to use when quotes are in the data.
</p>

<ul>
<li> <p><code>double</code> - quotes are escaped by doubling them.
</p>
</li>
<li> <p><code>backslash</code> - quotes are escaped by a preceding backslash.
</p>
</li>
<li> <p><code>none</code> - quotes are not escaped.
</p>
</li></ul>
</td></tr>
<tr><td><code id="write_delim_+3A_eol">eol</code></td>
<td>
<p>The end of line character to use. Most commonly either <code>"\n"</code> for
Unix style newlines, or <code>"\r\n"</code> for Windows style newlines.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_num_threads">num_threads</code></td>
<td>
<p>Number of threads to use when reading and materializing
vectors. If your data contains newlines within fields the parser will
automatically be forced to use a single thread only.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_progress">progress</code></td>
<td>
<p>Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The display
is updated every 50,000 values and will only display if estimated reading
time is 5 seconds or more. The automatic progress bar can be disabled by
setting option <code>readr.show_progress</code> to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_path">path</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Use the <code>file</code> argument
instead.</p>
</td></tr>
<tr><td><code id="write_delim_+3A_quote_escape">quote_escape</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Use the <code>escape</code>
argument instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code style="white-space: pre;">&#8288;write_*()&#8288;</code> returns the input <code>x</code> invisibly.
</p>


<h3>Output</h3>

<p>Factors are coerced to character. Doubles are formatted to a decimal string
using the grisu3 algorithm. <code>POSIXct</code> values are formatted as ISO8601 with a
UTC timezone <em>Note: <code>POSIXct</code> objects in local or non-UTC timezones will be
converted to UTC time before writing.</em>
</p>
<p>All columns are encoded as UTF-8. <code>write_excel_csv()</code> and <code>write_excel_csv2()</code> also include a
<a href="https://en.wikipedia.org/wiki/Byte_order_mark">UTF-8 Byte order mark</a>
which indicates to Excel the csv is UTF-8 encoded.
</p>
<p><code>write_excel_csv2()</code> and <code>write_csv2</code> were created to allow users with
different locale settings to save .csv files using their default settings
(e.g. <code style="white-space: pre;">&#8288;;&#8288;</code> as the column separator and <code style="white-space: pre;">&#8288;,&#8288;</code> as the decimal separator).
This is common in some European countries.
</p>
<p>Values are only quoted if they contain a comma, quote or newline.
</p>
<p>The <code style="white-space: pre;">&#8288;write_*()&#8288;</code> functions will automatically compress outputs if an appropriate extension is given.
Three extensions are currently supported: <code>.gz</code> for gzip compression, <code>.bz2</code> for bzip2 compression and
<code>.xz</code> for lzma compression.  See the examples for more information.
</p>


<h3>References</h3>

<p>Florian Loitsch, Printing Floating-Point Numbers Quickly and
Accurately with Integers, PLDI '10,
<a href="http://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf">http://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# If only a file name is specified, write_()* will write
# the file to the current working directory.
write_csv(mtcars, "mtcars.csv")
write_tsv(mtcars, "mtcars.tsv")

# If you add an extension to the file name, write_()* will
# automatically compress the output.
write_tsv(mtcars, "mtcars.tsv.gz")
write_tsv(mtcars, "mtcars.tsv.bz2")
write_tsv(mtcars, "mtcars.tsv.xz")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
