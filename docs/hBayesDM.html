<!DOCTYPE html><html><head><title>Help for package hBayesDM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hBayesDM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#alt_delta'><p>Rescorla-Wagner (Delta) Model</p></a></li>
<li><a href='#alt_gamma'><p>Rescorla-Wagner (Gamma) Model</p></a></li>
<li><a href='#bandit2arm_delta'><p>Rescorla-Wagner (Delta) Model</p></a></li>
<li><a href='#bandit4arm_2par_lapse'><p>3 Parameter Model, without C (choice perseveration), R (reward sensitivity), and P (punishment sensitivity). But with xi (noise)</p></a></li>
<li><a href='#bandit4arm_4par'><p>4 Parameter Model, without C (choice perseveration)</p></a></li>
<li><a href='#bandit4arm_lapse'><p>5 Parameter Model, without C (choice perseveration) but with xi (noise)</p></a></li>
<li><a href='#bandit4arm_lapse_decay'><p>5 Parameter Model, without C (choice perseveration) but with xi (noise). Added decay rate (Niv et al., 2015, J. Neuro).</p></a></li>
<li><a href='#bandit4arm_singleA_lapse'><p>4 Parameter Model, without C (choice perseveration) but with xi (noise). Single learning rate both for R and P.</p></a></li>
<li><a href='#bandit4arm2_kalman_filter'><p>Kalman Filter</p></a></li>
<li><a href='#banditNarm_2par_lapse'><p>3 Parameter Model, without C (choice perseveration), R (reward sensitivity), and P (punishment sensitivity). But with xi (noise)</p></a></li>
<li><a href='#banditNarm_4par'><p>4 Parameter Model, without C (choice perseveration)</p></a></li>
<li><a href='#banditNarm_delta'><p>Rescorla-Wagner (Delta) Model</p></a></li>
<li><a href='#banditNarm_kalman_filter'><p>Kalman Filter</p></a></li>
<li><a href='#banditNarm_lapse'><p>5 Parameter Model, without C (choice perseveration) but with xi (noise)</p></a></li>
<li><a href='#banditNarm_lapse_decay'><p>5 Parameter Model, without C (choice perseveration) but with xi (noise). Added decay rate (Niv et al., 2015, J. Neuro).</p></a></li>
<li><a href='#banditNarm_singleA_lapse'><p>4 Parameter Model, without C (choice perseveration) but with xi (noise). Single learning rate both for R and P.</p></a></li>
<li><a href='#bart_ewmv'><p>Exponential-Weight Mean-Variance Model</p></a></li>
<li><a href='#bart_par4'><p>Re-parameterized version of BART model with 4 parameters</p></a></li>
<li><a href='#cgt_cm'><p>Cumulative Model</p></a></li>
<li><a href='#choiceRT_ddm'><p>Drift Diffusion Model</p></a></li>
<li><a href='#choiceRT_ddm_single'><p>Drift Diffusion Model</p></a></li>
<li><a href='#choiceRT_lba'><p>Choice Reaction Time task, linear ballistic accumulator modeling</p></a></li>
<li><a href='#choiceRT_lba_single'><p>Choice Reaction Time task, linear ballistic accumulator modeling</p></a></li>
<li><a href='#cra_exp'><p>Exponential Subjective Value Model</p></a></li>
<li><a href='#cra_linear'><p>Linear Subjective Value Model</p></a></li>
<li><a href='#dbdm_prob_weight'><p>Probability Weight Function</p></a></li>
<li><a href='#dd_cs'><p>Constant-Sensitivity (CS) Model</p></a></li>
<li><a href='#dd_cs_single'><p>Constant-Sensitivity (CS) Model</p></a></li>
<li><a href='#dd_exp'><p>Exponential Model</p></a></li>
<li><a href='#dd_hyperbolic'><p>Hyperbolic Model</p></a></li>
<li><a href='#dd_hyperbolic_single'><p>Hyperbolic Model</p></a></li>
<li><a href='#estimate_mode'><p>Function to estimate mode of MCMC samples</p></a></li>
<li><a href='#extract_ic'><p>Extract Model Comparison Estimates</p></a></li>
<li><a href='#gng_m1'><p>RW + noise</p></a></li>
<li><a href='#gng_m2'><p>RW + noise + bias</p></a></li>
<li><a href='#gng_m3'><p>RW + noise + bias + pi</p></a></li>
<li><a href='#gng_m4'><p>RW (rew/pun) + noise + bias + pi</p></a></li>
<li><a href='#hBayesDM_model'><p>hBayesDM Model Base Function</p></a></li>
<li><a href='#hBayesDM-package'><p>Hierarchical Bayesian Modeling of Decision-Making Tasks</p></a></li>
<li><a href='#HDIofMCMC'><p>Compute Highest-Density Interval</p></a></li>
<li><a href='#igt_orl'><p>Outcome-Representation Learning Model</p></a></li>
<li><a href='#igt_pvl_decay'><p>Prospect Valence Learning (PVL) Decay-RI</p></a></li>
<li><a href='#igt_pvl_delta'><p>Prospect Valence Learning (PVL) Delta</p></a></li>
<li><a href='#igt_vpp'><p>Value-Plus-Perseverance</p></a></li>
<li><a href='#multiplot'><p>Function to plot multiple figures</p></a></li>
<li><a href='#peer_ocu'><p>Other-Conferred Utility (OCU) Model</p></a></li>
<li><a href='#plot.hBayesDM'><p>General Purpose Plotting for hBayesDM. This function plots hyper parameters.</p></a></li>
<li><a href='#plotDist'><p>Plots the histogram of MCMC samples.</p></a></li>
<li><a href='#plotHDI'><p>Plots highest density interval (HDI) from (MCMC) samples and prints HDI in the R console.</p>
HDI is indicated by a red line.
Based on John Kruschke's codes.</a></li>
<li><a href='#plotInd'><p>Plots individual posterior distributions, using the stan_plot function of the rstan package</p></a></li>
<li><a href='#printFit'><p>Print model-fits (mean LOOIC or WAIC values in addition to Akaike weights) of hBayesDM Models</p></a></li>
<li><a href='#prl_ewa'><p>Experience-Weighted Attraction Model</p></a></li>
<li><a href='#prl_fictitious'><p>Fictitious Update Model</p></a></li>
<li><a href='#prl_fictitious_multipleB'><p>Fictitious Update Model</p></a></li>
<li><a href='#prl_fictitious_rp'><p>Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE)</p></a></li>
<li><a href='#prl_fictitious_rp_woa'><p>Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE), without alpha (indecision point)</p></a></li>
<li><a href='#prl_fictitious_woa'><p>Fictitious Update Model, without alpha (indecision point)</p></a></li>
<li><a href='#prl_rp'><p>Reward-Punishment Model</p></a></li>
<li><a href='#prl_rp_multipleB'><p>Reward-Punishment Model</p></a></li>
<li><a href='#pst_gainloss_Q'><p>Gain-Loss Q Learning Model</p></a></li>
<li><a href='#pst_Q'><p>Q Learning Model</p></a></li>
<li><a href='#pstRT_ddm'><p>Drift Diffusion Model</p></a></li>
<li><a href='#pstRT_rlddm1'><p>Reinforcement Learning Drift Diffusion Model 1</p></a></li>
<li><a href='#pstRT_rlddm6'><p>Reinforcement Learning Drift Diffusion Model 6</p></a></li>
<li><a href='#ra_noLA'><p>Prospect Theory, without loss aversion (LA) parameter</p></a></li>
<li><a href='#ra_noRA'><p>Prospect Theory, without risk aversion (RA) parameter</p></a></li>
<li><a href='#ra_prospect'><p>Prospect Theory</p></a></li>
<li><a href='#rdt_happiness'><p>Happiness Computational Model</p></a></li>
<li><a href='#rhat'><p>Function for extracting Rhat values from an hBayesDM object</p></a></li>
<li><a href='#task2AFC_sdt'><p>Signal detection theory model</p></a></li>
<li><a href='#ts_par4'><p>Hybrid Model, with 4 parameters</p></a></li>
<li><a href='#ts_par6'><p>Hybrid Model, with 6 parameters</p></a></li>
<li><a href='#ts_par7'><p>Hybrid Model, with 7 parameters (original model)</p></a></li>
<li><a href='#ug_bayes'><p>Ideal Observer Model</p></a></li>
<li><a href='#ug_delta'><p>Rescorla-Wagner (Delta) Model</p></a></li>
<li><a href='#wcs_sql'><p>Sequential Learning Model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Hierarchical Bayesian Modeling of Decision-Making Tasks</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-09-13</td>
</tr>
<tr>
<td>Author:</td>
<td>Woo-Young Ahn [aut, cre],
  Nate Haines [aut],
  Lei Zhang [aut],
  Harhim Park [ctb],
  Jaeyeong Yang [ctb],
  Jethro Lee [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Woo-Young Ahn &lt;wooyoung.ahn@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Fit an array of decision-making tasks with computational models in
    a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of
    various computational models with a single line of coding
    (Ahn et al., 2017) &lt;<a href="https://doi.org/10.1162%2FCPSY_a_00002">doi:10.1162/CPSY_a_00002</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0), Rcpp (&ge; 0.12.0), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>rstan (&ge; 2.18.1), loo (&ge; 2.0), grid, parallel, ggplot2,
data.table</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH (&ge; 1.66.0), Rcpp (&ge; 0.12.0), RcppEigen (&ge; 0.3.3.3.0),
rstan (&ge; 2.18.1), StanHeaders (&ge; 2.18.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/CCS-Lab/hBayesDM">https://github.com/CCS-Lab/hBayesDM</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/CCS-Lab/hBayesDM/issues">https://github.com/CCS-Lab/hBayesDM/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make</td>
</tr>
<tr>
<td>Collate:</td>
<td>'HDIofMCMC.R' 'preprocess_funcs.R' 'stanmodels.R' 'settings.R'
'hBayesDM_model.R' 'alt_delta.R' 'alt_gamma.R'
'bandit2arm_delta.R' 'bandit4arm2_kalman_filter.R'
'bandit4arm_2par_lapse.R' 'bandit4arm_4par.R'
'bandit4arm_lapse.R' 'bandit4arm_lapse_decay.R'
'bandit4arm_singleA_lapse.R' 'banditNarm_2par_lapse.R'
'banditNarm_4par.R' 'banditNarm_delta.R'
'banditNarm_kalman_filter.R' 'banditNarm_lapse.R'
'banditNarm_lapse_decay.R' 'banditNarm_singleA_lapse.R'
'bart_ewmv.R' 'bart_par4.R' 'cgt_cm.R' 'choiceRT_ddm.R'
'choiceRT_ddm_single.R' 'choiceRT_lba.R'
'choiceRT_lba_single.R' 'cra_exp.R' 'cra_linear.R'
'dbdm_prob_weight.R' 'dd_cs.R' 'dd_cs_single.R' 'dd_exp.R'
'dd_hyperbolic.R' 'dd_hyperbolic_single.R' 'estimate_mode.R'
'extract_ic.R' 'gng_m1.R' 'gng_m2.R' 'gng_m3.R' 'gng_m4.R'
'hBayesDM.R' 'igt_orl.R' 'igt_pvl_decay.R' 'igt_pvl_delta.R'
'igt_vpp.R' 'multiplot.R' 'peer_ocu.R' 'plot.hBayesDM.R'
'plotDist.R' 'plotHDI.R' 'plotInd.R' 'printFit.R' 'prl_ewa.R'
'prl_fictitious.R' 'prl_fictitious_multipleB.R'
'prl_fictitious_rp.R' 'prl_fictitious_rp_woa.R'
'prl_fictitious_woa.R' 'prl_rp.R' 'prl_rp_multipleB.R'
'pstRT_ddm.R' 'pstRT_rlddm1.R' 'pstRT_rlddm6.R' 'pst_Q.R'
'pst_gainloss_Q.R' 'ra_noLA.R' 'ra_noRA.R' 'ra_prospect.R'
'rdt_happiness.R' 'rhat.R' 'task2AFC_sdt.R' 'ts_par4.R'
'ts_par6.R' 'ts_par7.R' 'ug_bayes.R' 'ug_delta.R' 'wcs_sql.R'
'zzz.R'</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-09-23 07:42:58 UTC; hoyoung</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-09-23 08:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='alt_delta'>Rescorla-Wagner (Delta) Model</h2><span id='topic+alt_delta'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Aversive Learning Task using Rescorla-Wagner (Delta) Model.
It has the following parameters: <code>A</code> (learning rate), <code>beta</code> (inverse temperature), <code>gamma</code> (risk preference).
</p>

<ul>
<li> <p><strong>Task</strong>: Aversive Learning Task (Browning et al., 2015)
</p>
</li>
<li> <p><strong>Model</strong>: Rescorla-Wagner (Delta) Model 
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>alt_delta(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alt_delta_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;, &quot;bluePunish&quot;, &quot;orangePunish&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="alt_delta_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Aversive Learning Task, there should be 5 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;, &quot;bluePunish&quot;, &quot;orangePunish&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial (blue == 1, orange == 2).</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of the given trial (punishment == 1, and non-punishment == 0).</p>
</dd>
<dt>bluePunish</dt><dd><p>Floating point value representing the magnitude of punishment for blue on that trial (e.g., 10, 97)</p>
</dd>
<dt>orangePunish</dt><dd><p>Floating point value representing the magnitude of punishment for orange on that trial (e.g., 23, 45)</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://github.com/lilihub">Lili Zhang</a> &lt;<a href="mailto:lili.zhang27@mail.dcu.ie">lili.zhang27@mail.dcu.ie</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;alt_delta&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Browning, M., Behrens, T. E., Jocham, G., O'reilly, J. X., &amp; Bishop, S. J. (2015). Anxious individuals have difficulty learning the causal statistics of aversive environments. Nature neuroscience, 18(4), 590.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- alt_delta(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- alt_delta(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='alt_gamma'>Rescorla-Wagner (Gamma) Model</h2><span id='topic+alt_gamma'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Aversive Learning Task using Rescorla-Wagner (Gamma) Model.
It has the following parameters: <code>A</code> (learning rate), <code>beta</code> (inverse temperature), <code>gamma</code> (risk preference).
</p>

<ul>
<li> <p><strong>Task</strong>: Aversive Learning Task (Browning et al., 2015)
</p>
</li>
<li> <p><strong>Model</strong>: Rescorla-Wagner (Gamma) Model 
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>alt_gamma(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alt_gamma_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;, &quot;bluePunish&quot;, &quot;orangePunish&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="alt_gamma_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Aversive Learning Task, there should be 5 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;, &quot;bluePunish&quot;, &quot;orangePunish&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial (blue == 1, orange == 2).</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of the given trial (punishment == 1, and non-punishment == 0).</p>
</dd>
<dt>bluePunish</dt><dd><p>Floating point value representing the magnitude of punishment for blue on that trial (e.g., 10, 97)</p>
</dd>
<dt>orangePunish</dt><dd><p>Floating point value representing the magnitude of punishment for orange on that trial (e.g., 23, 45)</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://github.com/lilihub">Lili Zhang</a> &lt;<a href="mailto:lili.zhang27@mail.dcu.ie">lili.zhang27@mail.dcu.ie</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;alt_gamma&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Browning, M., Behrens, T. E., Jocham, G., O'reilly, J. X., &amp; Bishop, S. J. (2015). Anxious individuals have difficulty learning the causal statistics of aversive environments. Nature neuroscience, 18(4), 590.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- alt_gamma(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- alt_gamma(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bandit2arm_delta'>Rescorla-Wagner (Delta) Model</h2><span id='topic+bandit2arm_delta'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the 2-Armed Bandit Task using Rescorla-Wagner (Delta) Model.
It has the following parameters: <code>A</code> (learning rate), <code>tau</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: 2-Armed Bandit Task (Erev et al., 2010; Hertwig et al., 2004)
</p>
</li>
<li> <p><strong>Model</strong>: Rescorla-Wagner (Delta) Model 
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bandit2arm_delta(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandit2arm_delta_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit2arm_delta_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the 2-Armed Bandit Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of the given trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bandit2arm_delta&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Erev, I., Ert, E., Roth, A. E., Haruvy, E., Herzog, S. M., Hau, R., et al. (2010). A choice prediction competition: Choices from experience and from description. Journal of Behavioral Decision Making, 23(1), 15-47. https://doi.org/10.1002/bdm.683
</p>
<p>Hertwig, R., Barron, G., Weber, E. U., &amp; Erev, I. (2004). Decisions From Experience and the Effect of Rare Events in Risky Choice. Psychological Science, 15(8), 534-539. https://doi.org/10.1111/j.0956-7976.2004.00715.x
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bandit2arm_delta(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bandit2arm_delta(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bandit4arm_2par_lapse'>3 Parameter Model, without C (choice perseveration), R (reward sensitivity), and P (punishment sensitivity). But with xi (noise)</h2><span id='topic+bandit4arm_2par_lapse'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the 4-Armed Bandit Task using 3 Parameter Model, without C (choice perseveration), R (reward sensitivity), and P (punishment sensitivity). But with xi (noise).
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>xi</code> (noise).
</p>

<ul>
<li> <p><strong>Task</strong>: 4-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 3 Parameter Model, without C (choice perseveration), R (reward sensitivity), and P (punishment sensitivity). But with xi (noise) (Aylward et al., 2018)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bandit4arm_2par_lapse(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandit4arm_2par_lapse_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_2par_lapse_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the 4-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, or 4.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bandit4arm_2par_lapse&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Aylward, Valton, Ahn, Bond, Dayan, Roiser, &amp; Robinson (2018) Altered decision-making under uncertainty in unmedicated mood and anxiety disorders. PsyArxiv. 10.31234/osf.io/k5b8m
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bandit4arm_2par_lapse(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bandit4arm_2par_lapse(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bandit4arm_4par'>4 Parameter Model, without C (choice perseveration)</h2><span id='topic+bandit4arm_4par'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the 4-Armed Bandit Task using 4 Parameter Model, without C (choice perseveration).
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>R</code> (reward sensitivity), <code>P</code> (punishment sensitivity).
</p>

<ul>
<li> <p><strong>Task</strong>: 4-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 4 Parameter Model, without C (choice perseveration) (Seymour et al., 2012)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bandit4arm_4par(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandit4arm_4par_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_4par_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the 4-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, or 4.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bandit4arm_4par&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Seymour, Daw, Roiser, Dayan, &amp; Dolan (2012). Serotonin Selectively Modulates Reward Value in Human Decision-Making. J Neuro, 32(17), 5833-5842.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bandit4arm_4par(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bandit4arm_4par(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bandit4arm_lapse'>5 Parameter Model, without C (choice perseveration) but with xi (noise)</h2><span id='topic+bandit4arm_lapse'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the 4-Armed Bandit Task using 5 Parameter Model, without C (choice perseveration) but with xi (noise).
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>R</code> (reward sensitivity), <code>P</code> (punishment sensitivity), <code>xi</code> (noise).
</p>

<ul>
<li> <p><strong>Task</strong>: 4-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 5 Parameter Model, without C (choice perseveration) but with xi (noise) (Seymour et al., 2012)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bandit4arm_lapse(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandit4arm_lapse_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the 4-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, or 4.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bandit4arm_lapse&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Seymour, Daw, Roiser, Dayan, &amp; Dolan (2012). Serotonin Selectively Modulates Reward Value in Human Decision-Making. J Neuro, 32(17), 5833-5842.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bandit4arm_lapse(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bandit4arm_lapse(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bandit4arm_lapse_decay'>5 Parameter Model, without C (choice perseveration) but with xi (noise). Added decay rate (Niv et al., 2015, J. Neuro).</h2><span id='topic+bandit4arm_lapse_decay'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the 4-Armed Bandit Task using 5 Parameter Model, without C (choice perseveration) but with xi (noise). Added decay rate (Niv et al., 2015, J. Neuro)..
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>R</code> (reward sensitivity), <code>P</code> (punishment sensitivity), <code>xi</code> (noise), <code>d</code> (decay rate).
</p>

<ul>
<li> <p><strong>Task</strong>: 4-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 5 Parameter Model, without C (choice perseveration) but with xi (noise). Added decay rate (Niv et al., 2015, J. Neuro). (Aylward et al., 2018)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bandit4arm_lapse_decay(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandit4arm_lapse_decay_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_lapse_decay_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the 4-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, or 4.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bandit4arm_lapse_decay&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Aylward, Valton, Ahn, Bond, Dayan, Roiser, &amp; Robinson (2018) Altered decision-making under uncertainty in unmedicated mood and anxiety disorders. PsyArxiv. 10.31234/osf.io/k5b8m
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bandit4arm_lapse_decay(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bandit4arm_lapse_decay(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bandit4arm_singleA_lapse'>4 Parameter Model, without C (choice perseveration) but with xi (noise). Single learning rate both for R and P.</h2><span id='topic+bandit4arm_singleA_lapse'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the 4-Armed Bandit Task using 4 Parameter Model, without C (choice perseveration) but with xi (noise). Single learning rate both for R and P..
It has the following parameters: <code>A</code> (learning rate), <code>R</code> (reward sensitivity), <code>P</code> (punishment sensitivity), <code>xi</code> (noise).
</p>

<ul>
<li> <p><strong>Task</strong>: 4-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 4 Parameter Model, without C (choice perseveration) but with xi (noise). Single learning rate both for R and P. (Aylward et al., 2018)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bandit4arm_singleA_lapse(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm_singleA_lapse_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the 4-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, or 4.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bandit4arm_singleA_lapse&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Aylward, Valton, Ahn, Bond, Dayan, Roiser, &amp; Robinson (2018) Altered decision-making under uncertainty in unmedicated mood and anxiety disorders. PsyArxiv. 10.31234/osf.io/k5b8m
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bandit4arm_singleA_lapse(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bandit4arm_singleA_lapse(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bandit4arm2_kalman_filter'>Kalman Filter</h2><span id='topic+bandit4arm2_kalman_filter'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the 4-Armed Bandit Task (modified) using Kalman Filter.
It has the following parameters: <code>lambda</code> (decay factor), <code>theta</code> (decay center), <code>beta</code> (inverse softmax temperature), <code>mu0</code> (anticipated initial mean of all 4 options), <code>s0</code> (anticipated initial sd (uncertainty factor) of all 4 options), <code>sD</code> (sd of diffusion noise).
</p>

<ul>
<li> <p><strong>Task</strong>: 4-Armed Bandit Task (modified) 
</p>
</li>
<li> <p><strong>Model</strong>: Kalman Filter (Daw et al., 2006)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bandit4arm2_kalman_filter(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bandit4arm2_kalman_filter_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the 4-Armed Bandit Task (modified), there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, or 4.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of the given trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/yoonseo-zoh/">Yoonseo Zoh</a> &lt;<a href="mailto:zohyos7@gmail.com">zohyos7@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bandit4arm2_kalman_filter&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Daw, N. D., O'Doherty, J. P., Dayan, P., Seymour, B., &amp; Dolan, R. J. (2006). Cortical substrates for exploratory decisions in humans. Nature, 441(7095), 876-879.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bandit4arm2_kalman_filter(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bandit4arm2_kalman_filter(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='banditNarm_2par_lapse'>3 Parameter Model, without C (choice perseveration), R (reward sensitivity), and P (punishment sensitivity). But with xi (noise)</h2><span id='topic+banditNarm_2par_lapse'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the N-Armed Bandit Task using 3 Parameter Model, without C (choice perseveration), R (reward sensitivity), and P (punishment sensitivity). But with xi (noise).
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>xi</code> (noise).
</p>

<ul>
<li> <p><strong>Task</strong>: N-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 3 Parameter Model, without C (choice perseveration), R (reward sensitivity), and P (punishment sensitivity). But with xi (noise) (Aylward et al., 2018)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>banditNarm_2par_lapse(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="banditNarm_2par_lapse_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_2par_lapse_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>Narm</dt><dd><p>Number of arms used in Multi-armed Bandit Task If not given, the number of unique choice will be used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the N-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, ... N.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://github.com/cheoljun95">Cheol Jun Cho</a> &lt;<a href="mailto:cjfwndnsl@gmail.com">cjfwndnsl@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;banditNarm_2par_lapse&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Aylward, Valton, Ahn, Bond, Dayan, Roiser, &amp; Robinson (2018) Altered decision-making under uncertainty in unmedicated mood and anxiety disorders. PsyArxiv. 10.31234/osf.io/k5b8m
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- banditNarm_2par_lapse(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- banditNarm_2par_lapse(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='banditNarm_4par'>4 Parameter Model, without C (choice perseveration)</h2><span id='topic+banditNarm_4par'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the N-Armed Bandit Task using 4 Parameter Model, without C (choice perseveration).
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>R</code> (reward sensitivity), <code>P</code> (punishment sensitivity).
</p>

<ul>
<li> <p><strong>Task</strong>: N-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 4 Parameter Model, without C (choice perseveration) (Seymour et al., 2012)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>banditNarm_4par(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="banditNarm_4par_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_4par_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>Narm</dt><dd><p>Number of arms used in Multi-armed Bandit Task If not given, the number of unique choice will be used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the N-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, ... N.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://github.com/cheoljun95">Cheol Jun Cho</a> &lt;<a href="mailto:cjfwndnsl@gmail.com">cjfwndnsl@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;banditNarm_4par&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Seymour, Daw, Roiser, Dayan, &amp; Dolan (2012). Serotonin Selectively Modulates Reward Value in Human Decision-Making. J Neuro, 32(17), 5833-5842.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- banditNarm_4par(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- banditNarm_4par(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='banditNarm_delta'>Rescorla-Wagner (Delta) Model</h2><span id='topic+banditNarm_delta'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the N-Armed Bandit Task using Rescorla-Wagner (Delta) Model.
It has the following parameters: <code>A</code> (learning rate), <code>tau</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: N-Armed Bandit Task (Erev et al., 2010; Hertwig et al., 2004)
</p>
</li>
<li> <p><strong>Model</strong>: Rescorla-Wagner (Delta) Model 
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>banditNarm_delta(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="banditNarm_delta_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_delta_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>Narm</dt><dd><p>Number of arms used in Multi-armed Bandit Task If not given, the number of unique choice will be used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the N-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, ... N.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://github.com/cheoljun95">Cheol Jun Cho</a> &lt;<a href="mailto:cjfwndnsl@gmail.com">cjfwndnsl@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;banditNarm_delta&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Erev, I., Ert, E., Roth, A. E., Haruvy, E., Herzog, S. M., Hau, R., et al. (2010). A choice prediction competition: Choices from experience and from description. Journal of Behavioral Decision Making, 23(1), 15-47. https://doi.org/10.1002/bdm.683
</p>
<p>Hertwig, R., Barron, G., Weber, E. U., &amp; Erev, I. (2004). Decisions From Experience and the Effect of Rare Events in Risky Choice. Psychological Science, 15(8), 534-539. https://doi.org/10.1111/j.0956-7976.2004.00715.x
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- banditNarm_delta(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- banditNarm_delta(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='banditNarm_kalman_filter'>Kalman Filter</h2><span id='topic+banditNarm_kalman_filter'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the N-Armed Bandit Task (modified) using Kalman Filter.
It has the following parameters: <code>lambda</code> (decay factor), <code>theta</code> (decay center), <code>beta</code> (inverse softmax temperature), <code>mu0</code> (anticipated initial mean of all 4 options), <code>s0</code> (anticipated initial sd (uncertainty factor) of all 4 options), <code>sD</code> (sd of diffusion noise).
</p>

<ul>
<li> <p><strong>Task</strong>: N-Armed Bandit Task (modified) 
</p>
</li>
<li> <p><strong>Model</strong>: Kalman Filter (Daw et al., 2006)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>banditNarm_kalman_filter(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="banditNarm_kalman_filter_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_kalman_filter_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>Narm</dt><dd><p>Number of arms used in Multi-armed Bandit Task If not given, the number of unique choice will be used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the N-Armed Bandit Task (modified), there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, ... N.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/yoonseo-zoh/">Yoonseo Zoh</a> &lt;<a href="mailto:zohyos7@gmail.com">zohyos7@gmail.com</a>&gt;, <a href="https://github.com/cheoljun95">Cheol Jun Cho</a> &lt;<a href="mailto:cjfwndnsl@gmail.com">cjfwndnsl@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;banditNarm_kalman_filter&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Daw, N. D., O'Doherty, J. P., Dayan, P., Seymour, B., &amp; Dolan, R. J. (2006). Cortical substrates for exploratory decisions in humans. Nature, 441(7095), 876-879.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- banditNarm_kalman_filter(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- banditNarm_kalman_filter(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='banditNarm_lapse'>5 Parameter Model, without C (choice perseveration) but with xi (noise)</h2><span id='topic+banditNarm_lapse'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the N-Armed Bandit Task using 5 Parameter Model, without C (choice perseveration) but with xi (noise).
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>R</code> (reward sensitivity), <code>P</code> (punishment sensitivity), <code>xi</code> (noise).
</p>

<ul>
<li> <p><strong>Task</strong>: N-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 5 Parameter Model, without C (choice perseveration) but with xi (noise) (Seymour et al., 2012)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>banditNarm_lapse(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="banditNarm_lapse_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>Narm</dt><dd><p>Number of arms used in Multi-armed Bandit Task If not given, the number of unique choice will be used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the N-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, ... N.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://github.com/cheoljun95">Cheol Jun Cho</a> &lt;<a href="mailto:cjfwndnsl@gmail.com">cjfwndnsl@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;banditNarm_lapse&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Seymour, Daw, Roiser, Dayan, &amp; Dolan (2012). Serotonin Selectively Modulates Reward Value in Human Decision-Making. J Neuro, 32(17), 5833-5842.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- banditNarm_lapse(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- banditNarm_lapse(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='banditNarm_lapse_decay'>5 Parameter Model, without C (choice perseveration) but with xi (noise). Added decay rate (Niv et al., 2015, J. Neuro).</h2><span id='topic+banditNarm_lapse_decay'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the N-Armed Bandit Task using 5 Parameter Model, without C (choice perseveration) but with xi (noise). Added decay rate (Niv et al., 2015, J. Neuro)..
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>R</code> (reward sensitivity), <code>P</code> (punishment sensitivity), <code>xi</code> (noise), <code>d</code> (decay rate).
</p>

<ul>
<li> <p><strong>Task</strong>: N-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 5 Parameter Model, without C (choice perseveration) but with xi (noise). Added decay rate (Niv et al., 2015, J. Neuro). (Aylward et al., 2018)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>banditNarm_lapse_decay(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="banditNarm_lapse_decay_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_lapse_decay_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>Narm</dt><dd><p>Number of arms used in Multi-armed Bandit Task If not given, the number of unique choice will be used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the N-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, ... N.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://github.com/cheoljun95">Cheol Jun Cho</a> &lt;<a href="mailto:cjfwndnsl@gmail.com">cjfwndnsl@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;banditNarm_lapse_decay&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Aylward, Valton, Ahn, Bond, Dayan, Roiser, &amp; Robinson (2018) Altered decision-making under uncertainty in unmedicated mood and anxiety disorders. PsyArxiv. 10.31234/osf.io/k5b8m
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- banditNarm_lapse_decay(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- banditNarm_lapse_decay(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='banditNarm_singleA_lapse'>4 Parameter Model, without C (choice perseveration) but with xi (noise). Single learning rate both for R and P.</h2><span id='topic+banditNarm_singleA_lapse'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the N-Armed Bandit Task using 4 Parameter Model, without C (choice perseveration) but with xi (noise). Single learning rate both for R and P..
It has the following parameters: <code>A</code> (learning rate), <code>R</code> (reward sensitivity), <code>P</code> (punishment sensitivity), <code>xi</code> (noise).
</p>

<ul>
<li> <p><strong>Task</strong>: N-Armed Bandit Task 
</p>
</li>
<li> <p><strong>Model</strong>: 4 Parameter Model, without C (choice perseveration) but with xi (noise). Single learning rate both for R and P. (Aylward et al., 2018)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>banditNarm_singleA_lapse(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="banditNarm_singleA_lapse_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="banditNarm_singleA_lapse_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>Narm</dt><dd><p>Number of arms used in Multi-armed Bandit Task If not given, the number of unique choice will be used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the N-Armed Bandit Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial: 1, 2, 3, ... N.</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on the given trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on the given trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://github.com/cheoljun95">Cheol Jun Cho</a> &lt;<a href="mailto:cjfwndnsl@gmail.com">cjfwndnsl@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;banditNarm_singleA_lapse&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Aylward, Valton, Ahn, Bond, Dayan, Roiser, &amp; Robinson (2018) Altered decision-making under uncertainty in unmedicated mood and anxiety disorders. PsyArxiv. 10.31234/osf.io/k5b8m
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- banditNarm_singleA_lapse(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- banditNarm_singleA_lapse(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bart_ewmv'>Exponential-Weight Mean-Variance Model</h2><span id='topic+bart_ewmv'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Balloon Analogue Risk Task using Exponential-Weight Mean-Variance Model.
It has the following parameters: <code>phi</code> (prior belief of burst), <code>eta</code> (updating exponent), <code>rho</code> (risk preference), <code>tau</code> (inverse temperature), <code>lambda</code> (loss aversion).
</p>

<ul>
<li> <p><strong>Task</strong>: Balloon Analogue Risk Task 
</p>
</li>
<li> <p><strong>Model</strong>: Exponential-Weight Mean-Variance Model (Park et al., 2020)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bart_ewmv(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bart_ewmv_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;pumps&quot;, &quot;explosion&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bart_ewmv_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Balloon Analogue Risk Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;pumps&quot;, &quot;explosion&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>pumps</dt><dd><p>The number of pumps.</p>
</dd>
<dt>explosion</dt><dd><p>0: intact, 1: burst</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bart_ewmv&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Park, H., Yang, J., Vassileva, J., &amp; Ahn, W. (2020). The Exponential-Weight Mean-Variance Model: A novel computational model for the Balloon Analogue Risk Task. https://doi.org/10.31234/osf.io/sdzj4
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bart_ewmv(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bart_ewmv(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='bart_par4'>Re-parameterized version of BART model with 4 parameters</h2><span id='topic+bart_par4'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Balloon Analogue Risk Task using Re-parameterized version of BART model with 4 parameters.
It has the following parameters: <code>phi</code> (prior belief of balloon not bursting), <code>eta</code> (updating rate), <code>gam</code> (risk-taking parameter), <code>tau</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Balloon Analogue Risk Task 
</p>
</li>
<li> <p><strong>Model</strong>: Re-parameterized version of BART model with 4 parameters (van Ravenzwaaij et al., 2011)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bart_par4(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bart_par4_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;pumps&quot;, &quot;explosion&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="bart_par4_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Balloon Analogue Risk Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;pumps&quot;, &quot;explosion&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>pumps</dt><dd><p>The number of pumps.</p>
</dd>
<dt>explosion</dt><dd><p>0: intact, 1: burst</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/ayoung-lee/">Ayoung Lee</a> &lt;<a href="mailto:aylee2008@naver.com">aylee2008@naver.com</a>&gt;, <a href="https://ccs-lab.github.io/team/jeongbin-oh/">Jeongbin Oh</a> &lt;<a href="mailto:ows0104@gmail.com">ows0104@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/jiyoon-lee/">Jiyoon Lee</a> &lt;<a href="mailto:nicole.lee2001@gmail.com">nicole.lee2001@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/junha-jang/">Junha Jang</a> &lt;<a href="mailto:andy627robo@naver.com">andy627robo@naver.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;bart_par4&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>van Ravenzwaaij, D., Dutilh, G., &amp; Wagenmakers, E. J. (2011). Cognitive model decomposition of the BART: Assessment and application. Journal of Mathematical Psychology, 55(1), 94-105.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- bart_par4(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- bart_par4(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='cgt_cm'>Cumulative Model</h2><span id='topic+cgt_cm'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Cambridge Gambling Task using Cumulative Model.
It has the following parameters: <code>alpha</code> (probability distortion), <code>c</code> (color bias), <code>rho</code> (relative loss sensitivity), <code>beta</code> (discounting rate), <code>gamma</code> (choice sensitivity).
</p>

<ul>
<li> <p><strong>Task</strong>: Cambridge Gambling Task (Rogers et al., 1999)
</p>
</li>
<li> <p><strong>Model</strong>: Cumulative Model 
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>cgt_cm(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cgt_cm_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;gamble_type&quot;, &quot;percentage_staked&quot;, &quot;trial_initial_points&quot;, &quot;assessment_stage&quot;, &quot;red_chosen&quot;, &quot;n_red_boxes&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;y_hat_col&quot;, &quot;y_hat_bet&quot;, &quot;bet_utils&quot;.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
Not available for this model.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cgt_cm_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Cambridge Gambling Task, there should be 7 columns of data with the
labels &quot;subjID&quot;, &quot;gamble_type&quot;, &quot;percentage_staked&quot;, &quot;trial_initial_points&quot;, &quot;assessment_stage&quot;, &quot;red_chosen&quot;, &quot;n_red_boxes&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>gamble_type</dt><dd><p>Integer value representng whether the bets on the current trial were presented in descending (0) or ascending (1) order.</p>
</dd>
<dt>percentage_staked</dt><dd><p>Integer value representing the bet percentage (not proportion) selected on the current trial: 5, 25, 50, 75, or 95.</p>
</dd>
<dt>trial_initial_points</dt><dd><p>Floating point value representing the number of points that the subject has at the start of the current trial (e.g., 100, 150, etc.).</p>
</dd>
<dt>assessment_stage</dt><dd><p>Integer value representing whether the current trial is a practice trial (0) or a test trial (1). Only test trials are used for model fitting.</p>
</dd>
<dt>red_chosen</dt><dd><p>Integer value representing whether the red color was chosen (1) versus the blue color (0).</p>
</dd>
<dt>n_red_boxes</dt><dd><p>Integer value representing the number of red boxes shown on the current trial: 1, 2, 3,..., or 9.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/nate-haines/">Nathaniel Haines</a> &lt;<a href="mailto:haines.175@osu.edu">haines.175@osu.edu</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;cgt_cm&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Rogers, R. D., Everitt, B. J., Baldacchino, A., Blackshaw, A. J., Swainson, R., Wynne, K., Baker, N. B., Hunter, J., Carthy, T., London, M., Deakin, J. F. W., Sahakian, B. J., Robbins, T. W. (1999). Dissociable deficits in the decision-making cognition of chronic amphetamine abusers, opiate abusers, patients with focal damage to prefrontal cortex, and tryptophan-depleted normal volunteers: evidence for monoaminergic mechanisms. Neuropsychopharmacology, 20, 322–339.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- cgt_cm(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- cgt_cm(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='choiceRT_ddm'>Drift Diffusion Model</h2><span id='topic+choiceRT_ddm'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Choice Reaction Time Task using Drift Diffusion Model.
It has the following parameters: <code>alpha</code> (boundary separation), <code>beta</code> (bias), <code>delta</code> (drift rate), <code>tau</code> (non-decision time).
</p>

<ul>
<li> <p><strong>Task</strong>: Choice Reaction Time Task 
</p>
</li>
<li> <p><strong>Model</strong>: Drift Diffusion Model (Ratcliff, 1978)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>choiceRT_ddm(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choiceRT_ddm_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;RT&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
Not available for this model.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>RTbound</dt><dd><p>Floating point value representing the lower bound (i.e., minimum allowed) reaction time. Defaults to 0.1 (100 milliseconds).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Choice Reaction Time Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;RT&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Choice made for the current trial, coded as 1/2 to indicate lower/upper boundary or left/right choices (e.g., 1 1 1 2 1 2).</p>
</dd>
<dt>RT</dt><dd><p>Choice reaction time for the current trial, in **seconds** (e.g., 0.435 0.383 0.314 0.309, etc.).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;choiceRT_ddm&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ratcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85(2), 59-108. https://doi.org/10.1037/0033-295X.85.2.59
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- choiceRT_ddm(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- choiceRT_ddm(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='choiceRT_ddm_single'>Drift Diffusion Model</h2><span id='topic+choiceRT_ddm_single'></span>

<h3>Description</h3>

<p>Individual Bayesian Modeling of the Choice Reaction Time Task using Drift Diffusion Model.
It has the following parameters: <code>alpha</code> (boundary separation), <code>beta</code> (bias), <code>delta</code> (drift rate), <code>tau</code> (non-decision time).
</p>

<ul>
<li> <p><strong>Task</strong>: Choice Reaction Time Task 
</p>
</li>
<li> <p><strong>Model</strong>: Drift Diffusion Model (Ratcliff, 1978)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>choiceRT_ddm_single(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choiceRT_ddm_single_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;RT&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
Not available for this model.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_ddm_single_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>RTbound</dt><dd><p>Floating point value representing the lower bound (i.e., minimum allowed) reaction time. Defaults to 0.1 (100 milliseconds).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Choice Reaction Time Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;RT&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Choice made for the current trial, coded as 1/2 to indicate lower/upper boundary or left/right choices (e.g., 1 1 1 2 1 2).</p>
</dd>
<dt>RT</dt><dd><p>Choice reaction time for the current trial, in **seconds** (e.g., 0.435 0.383 0.314 0.309, etc.).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;choiceRT_ddm_single&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ratcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85(2), 59-108. https://doi.org/10.1037/0033-295X.85.2.59
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- choiceRT_ddm_single(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- choiceRT_ddm_single(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='choiceRT_lba'>Choice Reaction Time task, linear ballistic accumulator modeling</h2><span id='topic+choiceRT_lba'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of choice/reaction time data with the following parameters: &quot;d&quot; (boundary), &quot;A&quot; (upper boundary of starting point), &quot;v&quot; (drift rate), &quot;tau&quot; (non-decision time).
The model published in Annis, J., Miller, B. J., &amp; Palmeri, T. J. (2016). Bayesian inference with Stan: A tutorial on adding custom distributions. Behavior research methods, 1-24.
</p>
<p><strong>MODEL:</strong>
Brown and Heathcote LBA model - multiple subjects. Note that this implementation estimates a different drift rate
for each condition-choice pair. For example, if the task involves deciding between two stimuli on each trial, and
there are two different conditions throughout the task (e.g. speed versus accuracy), a total of 4 (2 stimuli by 2 conditions)
drift rates will be estimated. For details on implementation, see Annis et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choiceRT_lba(
  data = "choose",
  niter = 3000,
  nwarmup = 1000,
  nchain = 2,
  ncore = 2,
  nthin = 1,
  inits = "random",
  indPars = "mean",
  saveDir = NULL,
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choiceRT_lba_+3A_data">data</code></td>
<td>
<p>A .txt file containing the data to be modeled. Data columns should be labelled as follows: &quot;subjID&quot;, &quot;choice&quot;, &quot;RT&quot;, and &quot;condition&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_nchain">nchain</code></td>
<td>
<p>Number of chains to be run.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_ncore">ncore</code></td>
<td>
<p>Integer value specifying how many CPUs to run the MCMC sampling on. Defaults to 1.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution. Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is high.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated. Options are &quot;fixed&quot; or &quot;random&quot; or your own initial values.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_savedir">saveDir</code></td>
<td>
<p>Path to directory where .RData file of model output (<code>modelData</code>) can be saved. Leave blank if not interested.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Exporting model-based regressors? TRUE or FALSE. Currently not available for this model.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file size). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point number representing the target acceptance probability of a new sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps that the MCMC sampler can take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name of the file, including the file extension
(e.g. &quot;.txt&quot;), that contains the behavioral data for the subject of interest for the current analysis.
The file should be a <strong>tab-delimited</strong> text (.txt) file whose rows represent trial-by-trial observations and columns
represent variables. For choice/reaction time tasks, there should be four columns of data
with the labels &quot;subjID&quot;, &quot;choice&quot;, &quot;RT&quot;, and &quot;condition&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labelled correctly and contain the information below:
</p>

<dl>
<dt><code>"subjID"</code></dt><dd><p>A unique identifier for each subject within data-set to be analyzed.</p>
</dd>
<dt><code>"choice"</code></dt><dd><p>An integer representing the choice made on the current trial. (e.g., 1 1 3 2 1 2).</p>
</dd>
<dt><code>"RT"</code></dt><dd><p>A floating number the choice reaction time in <strong>seconds</strong>. (e.g., 0.435 0.383 0.314 0.309, etc.).</p>
</dd>
<dt><code>"condition"</code></dt><dd><p>An integer representing the condition of the current trail (e.g., 1 2 3 4).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The data.txt file may contain other columns of data (e.g. &quot;Reaction_Time&quot;, &quot;trial_number&quot;, etc.), but only the data with the column
names listed above will be used for analysis/modeling. As long as the columns above are present and labelled correctly,
there is no need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored upon the
beginning of each chain. For those familiar with Bayesian methods, this value is equivalent to a burn-in sample.
Due to the nature of MCMC sampling, initial values (where the sampling chain begins) can have a heavy influence
on the generated posterior distributions. The <strong>nwarmup</strong> argument can be set to a high number in order to curb the
effects that initial values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling sequences) should be
used to draw samples from the posterior distribution. Since the posteriors are generated from a sampling
process, it is good practice to run multiple chains to ensure that a representative posterior is attained. When
sampling is completed, the multiple chains may be checked for convergence with the <code>plot(myModel, type = "trace")</code>
command. The chains should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC samples being chosen
to generate the posterior distributions. By default, <strong>nthin</strong> is equal to 1, hence every sample is used to
generate the posterior.
</p>
<p><strong>Contol Parameters:</strong> adapt_delta, stepsize, and max_treedepth are advanced options that give the user more control
over Stan's MCMC sampler. The Stan creators recommend that only advanced users change the default values, as alterations
can profoundly change the sampler's behavior. Refer to Hoffman &amp; Gelman (2014, Journal of Machine Learning Research) for
more information on the functioning of the sampler control parameters. One can also refer to section 58.2 of the
<a href="https://mc-stan.org/users/documentation/">Stan User's Manual</a> for a less technical description of these arguments.
</p>


<h3>Value</h3>

<p><code>modelData</code>  A class <code>'hBayesDM'</code> object with the following components:
</p>

<dl>
<dt><code>model</code></dt><dd><p>Character string with the name of the model (<code>"choiceRT_lba"</code>).</p>
</dd>
<dt><code>allIndPars</code></dt><dd><p><code>'data.frame'</code> containing the summarized parameter
values (as specified by <code>'indPars'</code>) for each subject.</p>
</dd>
<dt><code>parVals</code></dt><dd><p>A <code>'list'</code> where each element contains posterior samples
over different model parameters. </p>
</dd>
<dt><code>fit</code></dt><dd><p>A class <code>'stanfit'</code> object containing the fitted model.</p>
</dd>
<dt><code>rawdata</code></dt><dd><p><code>"data.frame"</code> containing the raw data used to fit the model, as specified by the user.</p>
</dd>
</dl>



<h3>References</h3>

<p>Brown, S. D., &amp; Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation.
Cognitive Psychology, 57(3), 153-178. http://doi.org/10.1016/j.cogpsych.2007.12.002
</p>
<p>Annis, J., Miller, B. J., &amp; Palmeri, T. J. (2016). Bayesian inference with Stan: A tutorial on adding custom distributions.
Behavior research methods, 1-24.
</p>
<p>Hoffman, M. D., &amp; Gelman, A. (2014). The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. The
Journal of Machine Learning Research, 15(1), 1593-1623.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM: <a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model and store results in "output"
output &lt;- choiceRT_lba(data = "example", niter = 2000, nwarmup = 1000, nchain = 3, ncore = 3)

# Visually check convergence of the sampling chains (should like like 'hairy caterpillars')
plot(output, type = 'trace')

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='choiceRT_lba_single'>Choice Reaction Time task, linear ballistic accumulator modeling</h2><span id='topic+choiceRT_lba_single'></span>

<h3>Description</h3>

<p>Individual Bayesian Modeling of choice/reaction time data with the following parameters: &quot;d&quot; (boundary), &quot;A&quot; (upper boundary of starting point), &quot;v&quot; (drift rate), &quot;tau&quot; (non-decision time).
The model published in Annis, J., Miller, B. J., &amp; Palmeri, T. J. (2016). Bayesian inference with Stan: A tutorial on adding custom distributions. Behavior research methods, 1-24.
</p>
<p><strong>MODEL:</strong>
Brown and Heathcote LBA model - single subject. Note that this implementation estimates a different drift rate
for each condition-choice pair. For example, if the task involves deciding between two stimuli on each trial, and
there are two different conditions throughout the task (e.g. speed versus accuracy), a total of 4 (2 stimuli by 2 conditions)
drift rates will be estimated. For details on implementation, see Annis et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choiceRT_lba_single(
  data = "choose",
  niter = 3000,
  nwarmup = 1000,
  nchain = 2,
  ncore = 2,
  nthin = 1,
  inits = "random",
  indPars = "mean",
  saveDir = NULL,
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choiceRT_lba_single_+3A_data">data</code></td>
<td>
<p>A .txt file containing the data to be modeled. Data columns should be labelled as follows: &quot;subjID&quot;, &quot;choice&quot;, &quot;RT&quot;, and &quot;condition&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_nchain">nchain</code></td>
<td>
<p>Number of chains to be run.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_ncore">ncore</code></td>
<td>
<p>Integer value specifying how many CPUs to run the MCMC sampling on. Defaults to 1.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution. Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is high.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated. Options are &quot;fixed&quot; or &quot;random&quot; or your own initial values.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_savedir">saveDir</code></td>
<td>
<p>Path to directory where .RData file of model output (<code>modelData</code>) can be saved. Leave blank if not interested.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Exporting model-based regressors? TRUE or FALSE. Currently not available for this model.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file size). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point number representing the target acceptance probability of a new sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="choiceRT_lba_single_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps that the MCMC sampler can take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name of the file, including the file extension
(e.g. &quot;.txt&quot;), that contains the behavioral data of all subjects of interest for the current analysis.
The file should be a <strong>tab-delimited</strong> text (.txt) file whose rows represent trial-by-trial observations and columns
represent variables. For choice/reaction time tasks, there should be four columns of data
with the labels &quot;choice&quot;, &quot;RT&quot;, and &quot;condition&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labelled correctly and contain the information below:
</p>

<dl>
<dt><code>"subjID"</code></dt><dd><p>A unique identifier for each subject within data-set to be analyzed.</p>
</dd>
<dt><code>"choice"</code></dt><dd><p>An integer representing the choice made on the current trial. (e.g., 1 1 3 2 1 2).</p>
</dd>
<dt><code>"RT"</code></dt><dd><p>A floating number the choice reaction time in <strong>seconds</strong>. (e.g., 0.435 0.383 0.314 0.309, etc.).</p>
</dd>
<dt><code>"condition"</code></dt><dd><p>An integer representing the condition of the current trail (e.g., 1 2 3 4).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The data.txt file may contain other columns of data (e.g. &quot;Reaction_Time&quot;, &quot;trial_number&quot;, etc.), but only the data with the column
names listed above will be used for analysis/modeling. As long as the columns above are present and labelled correctly,
there is no need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored upon the
beginning of each chain. For those familiar with Bayesian methods, this value is equivalent to a burn-in sample.
Due to the nature of MCMC sampling, initial values (where the sampling chain begins) can have a heavy influence
on the generated posterior distributions. The <strong>nwarmup</strong> argument can be set to a high number in order to curb the
effects that initial values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling sequences) should be
used to draw samples from the posterior distribution. Since the posteriors are generated from a sampling
process, it is good practice to run multiple chains to ensure that a representative posterior is attained. When
sampling is completed, the multiple chains may be checked for convergence with the <code>plot(myModel, type = "trace")</code>
command. The chains should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC samples being chosen
to generate the posterior distributions. By default, <strong>nthin</strong> is equal to 1, hence every sample is used to
generate the posterior.
</p>
<p><strong>Contol Parameters:</strong> adapt_delta, stepsize, and max_treedepth are advanced options that give the user more control
over Stan's MCMC sampler. The Stan creators recommend that only advanced users change the default values, as alterations
can profoundly change the sampler's behavior. Refer to Hoffman &amp; Gelman (2014, Journal of Machine Learning Research) for
more information on the functioning of the sampler control parameters. One can also refer to section 58.2 of the
<a href="https://mc-stan.org/users/documentation/">Stan User's Manual</a> for a less technical description of these arguments.
</p>


<h3>Value</h3>

<p><code>modelData</code>  A class <code>'hBayesDM'</code> object with the following components:
</p>

<dl>
<dt><code>model</code></dt><dd><p>Character string with the name of the model (<code>"choiceRT_lba_single"</code>).</p>
</dd>
<dt><code>allIndPars</code></dt><dd><p><code>'data.frame'</code> containing the summarized parameter
values (as specified by <code>'indPars'</code>) for each subject.</p>
</dd>
<dt><code>parVals</code></dt><dd><p>A <code>'list'</code> where each element contains posterior samples
over different model parameters. </p>
</dd>
<dt><code>fit</code></dt><dd><p>A class <code>'stanfit'</code> object containing the fitted model.</p>
</dd>
<dt><code>rawdata</code></dt><dd><p><code>"data.frame"</code> containing the raw data used to fit the model, as specified by the user.</p>
</dd>
</dl>



<h3>References</h3>

<p>Brown, S. D., &amp; Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation.
Cognitive Psychology, 57(3), 153-178. http://doi.org/10.1016/j.cogpsych.2007.12.002
</p>
<p>Annis, J., Miller, B. J., &amp; Palmeri, T. J. (2016). Bayesian inference with Stan: A tutorial on adding custom distributions.
Behavior research methods, 1-24.
</p>
<p>Hoffman, M. D., &amp; Gelman, A. (2014). The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. The
Journal of Machine Learning Research, 15(1), 1593-1623.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM: <a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model and store results in "output"
output &lt;- choiceRT_lba_single(data = "example", niter = 2000, nwarmup = 1000, nchain = 3, ncore = 3)

# Visually check convergence of the sampling chains (should like like 'hairy caterpillars')
plot(output, type = 'trace')

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='cra_exp'>Exponential Subjective Value Model</h2><span id='topic+cra_exp'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Choice Under Risk and Ambiguity Task using Exponential Subjective Value Model.
It has the following parameters: <code>alpha</code> (risk attitude), <code>beta</code> (ambiguity attitude), <code>gamma</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Choice Under Risk and Ambiguity Task 
</p>
</li>
<li> <p><strong>Model</strong>: Exponential Subjective Value Model (Hsu et al., 2005)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>cra_exp(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cra_exp_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;prob&quot;, &quot;ambig&quot;, &quot;reward_var&quot;, &quot;reward_fix&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;sv&quot;, &quot;sv_fix&quot;, &quot;sv_var&quot;, &quot;p_var&quot;.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cra_exp_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Choice Under Risk and Ambiguity Task, there should be 6 columns of data with the
labels &quot;subjID&quot;, &quot;prob&quot;, &quot;ambig&quot;, &quot;reward_var&quot;, &quot;reward_fix&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>prob</dt><dd><p>Objective probability of the variable lottery.</p>
</dd>
<dt>ambig</dt><dd><p>Ambiguity level of the variable lottery (0 for risky lottery; greater than 0 for ambiguous lottery).</p>
</dd>
<dt>reward_var</dt><dd><p>Amount of reward in variable lottery. Assumed to be greater than zero.</p>
</dd>
<dt>reward_fix</dt><dd><p>Amount of reward in fixed lottery. Assumed to be greater than zero.</p>
</dd>
<dt>choice</dt><dd><p>If the variable lottery was selected, choice == 1; otherwise choice == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;cra_exp&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Hsu, M., Bhatt, M., Adolphs, R., Tranel, D., &amp; Camerer, C. F. (2005). Neural systems responding to degrees of uncertainty in human decision-making. Science, 310(5754), 1680-1683. https://doi.org/10.1126/science.1115327
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- cra_exp(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- cra_exp(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='cra_linear'>Linear Subjective Value Model</h2><span id='topic+cra_linear'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Choice Under Risk and Ambiguity Task using Linear Subjective Value Model.
It has the following parameters: <code>alpha</code> (risk attitude), <code>beta</code> (ambiguity attitude), <code>gamma</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Choice Under Risk and Ambiguity Task 
</p>
</li>
<li> <p><strong>Model</strong>: Linear Subjective Value Model (Levy et al., 2010)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>cra_linear(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cra_linear_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;prob&quot;, &quot;ambig&quot;, &quot;reward_var&quot;, &quot;reward_fix&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;sv&quot;, &quot;sv_fix&quot;, &quot;sv_var&quot;, &quot;p_var&quot;.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="cra_linear_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Choice Under Risk and Ambiguity Task, there should be 6 columns of data with the
labels &quot;subjID&quot;, &quot;prob&quot;, &quot;ambig&quot;, &quot;reward_var&quot;, &quot;reward_fix&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>prob</dt><dd><p>Objective probability of the variable lottery.</p>
</dd>
<dt>ambig</dt><dd><p>Ambiguity level of the variable lottery (0 for risky lottery; greater than 0 for ambiguous lottery).</p>
</dd>
<dt>reward_var</dt><dd><p>Amount of reward in variable lottery. Assumed to be greater than zero.</p>
</dd>
<dt>reward_fix</dt><dd><p>Amount of reward in fixed lottery. Assumed to be greater than zero.</p>
</dd>
<dt>choice</dt><dd><p>If the variable lottery was selected, choice == 1; otherwise choice == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;cra_linear&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Levy, I., Snell, J., Nelson, A. J., Rustichini, A., &amp; Glimcher, P. W. (2010). Neural representation of subjective value under risk and ambiguity. Journal of Neurophysiology, 103(2), 1036-1047.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- cra_linear(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- cra_linear(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='dbdm_prob_weight'>Probability Weight Function</h2><span id='topic+dbdm_prob_weight'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Description Based Decison Making Task using Probability Weight Function.
It has the following parameters: <code>tau</code> (probability weight function), <code>rho</code> (subject utility function), <code>lambda</code> (loss aversion parameter), <code>beta</code> (inverse softmax temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Description Based Decison Making Task 
</p>
</li>
<li> <p><strong>Model</strong>: Probability Weight Function (Erev et al., 2010; Hertwig et al., 2004; Jessup et al., 2008)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>dbdm_prob_weight(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbdm_prob_weight_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;opt1hprob&quot;, &quot;opt2hprob&quot;, &quot;opt1hval&quot;, &quot;opt1lval&quot;, &quot;opt2hval&quot;, &quot;opt2lval&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dbdm_prob_weight_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Description Based Decison Making Task, there should be 8 columns of data with the
labels &quot;subjID&quot;, &quot;opt1hprob&quot;, &quot;opt2hprob&quot;, &quot;opt1hval&quot;, &quot;opt1lval&quot;, &quot;opt2hval&quot;, &quot;opt2lval&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>opt1hprob</dt><dd><p>Possiblity of getting higher value of outcome(opt1hval) when choosing option 1.</p>
</dd>
<dt>opt2hprob</dt><dd><p>Possiblity of getting higher value of outcome(opt2hval) when choosing option 2.</p>
</dd>
<dt>opt1hval</dt><dd><p>Possible (with opt1hprob probability) outcome of option 1.</p>
</dd>
<dt>opt1lval</dt><dd><p>Possible (with (1 - opt1hprob) probability) outcome of option 1.</p>
</dd>
<dt>opt2hval</dt><dd><p>Possible (with opt2hprob probability) outcome of option 2.</p>
</dd>
<dt>opt2lval</dt><dd><p>Possible (with (1 - opt2hprob) probability) outcome of option 2.</p>
</dd>
<dt>choice</dt><dd><p>If option 1 was selected, choice == 1; else if option 2 was selected, choice == 2.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/yoonseo-zoh/">Yoonseo Zoh</a> &lt;<a href="mailto:zohyos7@gmail.com">zohyos7@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;dbdm_prob_weight&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Erev, I., Ert, E., Roth, A. E., Haruvy, E., Herzog, S. M., Hau, R., ... &amp; Lebiere, C. (2010). A choice prediction competition: Choices from experience and from description. Journal of Behavioral Decision Making, 23(1), 15-47.
</p>
<p>Hertwig, R., Barron, G., Weber, E. U., &amp; Erev, I. (2004). Decisions from experience and the effect of rare events in risky choice. Psychological science, 15(8), 534-539.
</p>
<p>Jessup, R. K., Bishara, A. J., &amp; Busemeyer, J. R. (2008). Feedback produces divergence from prospect theory in descriptive choice. Psychological Science, 19(10), 1015-1022.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- dbdm_prob_weight(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- dbdm_prob_weight(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='dd_cs'>Constant-Sensitivity (CS) Model</h2><span id='topic+dd_cs'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Delay Discounting Task using Constant-Sensitivity (CS) Model.
It has the following parameters: <code>r</code> (exponential discounting rate), <code>s</code> (impatience), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Delay Discounting Task 
</p>
</li>
<li> <p><strong>Model</strong>: Constant-Sensitivity (CS) Model (Ebert et al., 2007)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>dd_cs(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dd_cs_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_cs_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Delay Discounting Task, there should be 6 columns of data with the
labels &quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>delay_later</dt><dd><p>An integer representing the delayed days for the later option (e.g. 1, 6, 28).</p>
</dd>
<dt>amount_later</dt><dd><p>A floating point number representing the amount for the later option (e.g. 10.5, 13.4, 30.9).</p>
</dd>
<dt>delay_sooner</dt><dd><p>An integer representing the delayed days for the sooner option (e.g. 0).</p>
</dd>
<dt>amount_sooner</dt><dd><p>A floating point number representing the amount for the sooner option (e.g. 10).</p>
</dd>
<dt>choice</dt><dd><p>If amount_later was selected, choice == 1; else if amount_sooner was selected, choice == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;dd_cs&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ebert, J. E. J., &amp; Prelec, D. (2007). The Fragility of Time: Time-Insensitivity and Valuation of the Near and Far Future. Management Science. https://doi.org/10.1287/mnsc.1060.0671
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- dd_cs(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- dd_cs(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='dd_cs_single'>Constant-Sensitivity (CS) Model</h2><span id='topic+dd_cs_single'></span>

<h3>Description</h3>

<p>Individual Bayesian Modeling of the Delay Discounting Task using Constant-Sensitivity (CS) Model.
It has the following parameters: <code>r</code> (exponential discounting rate), <code>s</code> (impatience), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Delay Discounting Task 
</p>
</li>
<li> <p><strong>Model</strong>: Constant-Sensitivity (CS) Model (Ebert et al., 2007)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>dd_cs_single(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dd_cs_single_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_cs_single_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Delay Discounting Task, there should be 6 columns of data with the
labels &quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>delay_later</dt><dd><p>An integer representing the delayed days for the later option (e.g. 1, 6, 28).</p>
</dd>
<dt>amount_later</dt><dd><p>A floating point number representing the amount for the later option (e.g. 10.5, 13.4, 30.9).</p>
</dd>
<dt>delay_sooner</dt><dd><p>An integer representing the delayed days for the sooner option (e.g. 0).</p>
</dd>
<dt>amount_sooner</dt><dd><p>A floating point number representing the amount for the sooner option (e.g. 10).</p>
</dd>
<dt>choice</dt><dd><p>If amount_later was selected, choice == 1; else if amount_sooner was selected, choice == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;dd_cs_single&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ebert, J. E. J., &amp; Prelec, D. (2007). The Fragility of Time: Time-Insensitivity and Valuation of the Near and Far Future. Management Science. https://doi.org/10.1287/mnsc.1060.0671
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- dd_cs_single(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- dd_cs_single(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='dd_exp'>Exponential Model</h2><span id='topic+dd_exp'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Delay Discounting Task using Exponential Model.
It has the following parameters: <code>r</code> (exponential discounting rate), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Delay Discounting Task 
</p>
</li>
<li> <p><strong>Model</strong>: Exponential Model (Samuelson, 1937)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>dd_exp(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dd_exp_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_exp_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Delay Discounting Task, there should be 6 columns of data with the
labels &quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>delay_later</dt><dd><p>An integer representing the delayed days for the later option (e.g. 1, 6, 28).</p>
</dd>
<dt>amount_later</dt><dd><p>A floating point number representing the amount for the later option (e.g. 10.5, 13.4, 30.9).</p>
</dd>
<dt>delay_sooner</dt><dd><p>An integer representing the delayed days for the sooner option (e.g. 0).</p>
</dd>
<dt>amount_sooner</dt><dd><p>A floating point number representing the amount for the sooner option (e.g. 10).</p>
</dd>
<dt>choice</dt><dd><p>If amount_later was selected, choice == 1; else if amount_sooner was selected, choice == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;dd_exp&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Samuelson, P. A. (1937). A Note on Measurement of Utility. The Review of Economic Studies, 4(2), 155. https://doi.org/10.2307/2967612
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- dd_exp(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- dd_exp(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='dd_hyperbolic'>Hyperbolic Model</h2><span id='topic+dd_hyperbolic'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Delay Discounting Task using Hyperbolic Model.
It has the following parameters: <code>k</code> (discounting rate), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Delay Discounting Task 
</p>
</li>
<li> <p><strong>Model</strong>: Hyperbolic Model (Mazur, 1987)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>dd_hyperbolic(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dd_hyperbolic_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Delay Discounting Task, there should be 6 columns of data with the
labels &quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>delay_later</dt><dd><p>An integer representing the delayed days for the later option (e.g. 1, 6, 28).</p>
</dd>
<dt>amount_later</dt><dd><p>A floating point number representing the amount for the later option (e.g. 10.5, 13.4, 30.9).</p>
</dd>
<dt>delay_sooner</dt><dd><p>An integer representing the delayed days for the sooner option (e.g. 0).</p>
</dd>
<dt>amount_sooner</dt><dd><p>A floating point number representing the amount for the sooner option (e.g. 10).</p>
</dd>
<dt>choice</dt><dd><p>If amount_later was selected, choice == 1; else if amount_sooner was selected, choice == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;dd_hyperbolic&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Mazur, J. E. (1987). An adjustment procedure for studying delayed reinforcement.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- dd_hyperbolic(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- dd_hyperbolic(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='dd_hyperbolic_single'>Hyperbolic Model</h2><span id='topic+dd_hyperbolic_single'></span>

<h3>Description</h3>

<p>Individual Bayesian Modeling of the Delay Discounting Task using Hyperbolic Model.
It has the following parameters: <code>k</code> (discounting rate), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Delay Discounting Task 
</p>
</li>
<li> <p><strong>Model</strong>: Hyperbolic Model (Mazur, 1987)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>dd_hyperbolic_single(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dd_hyperbolic_single_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="dd_hyperbolic_single_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Delay Discounting Task, there should be 6 columns of data with the
labels &quot;subjID&quot;, &quot;delay_later&quot;, &quot;amount_later&quot;, &quot;delay_sooner&quot;, &quot;amount_sooner&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>delay_later</dt><dd><p>An integer representing the delayed days for the later option (e.g. 1, 6, 28).</p>
</dd>
<dt>amount_later</dt><dd><p>A floating point number representing the amount for the later option (e.g. 10.5, 13.4, 30.9).</p>
</dd>
<dt>delay_sooner</dt><dd><p>An integer representing the delayed days for the sooner option (e.g. 0).</p>
</dd>
<dt>amount_sooner</dt><dd><p>A floating point number representing the amount for the sooner option (e.g. 10).</p>
</dd>
<dt>choice</dt><dd><p>If amount_later was selected, choice == 1; else if amount_sooner was selected, choice == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;dd_hyperbolic_single&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Mazur, J. E. (1987). An adjustment procedure for studying delayed reinforcement.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- dd_hyperbolic_single(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- dd_hyperbolic_single(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='estimate_mode'>Function to estimate mode of MCMC samples</h2><span id='topic+estimate_mode'></span>

<h3>Description</h3>

<p>Based on codes from 'http://stackoverflow.com/questions/2547402/is-there-a-built-in-function-for-finding-the-mode'
see the comment by Rasmus Baath
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_mode(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_mode_+3A_x">x</code></td>
<td>
<p>MCMC samples or some numeric or array values.</p>
</td></tr>
</table>

<hr>
<h2 id='extract_ic'>Extract Model Comparison Estimates</h2><span id='topic+extract_ic'></span>

<h3>Description</h3>

<p>Extract Model Comparison Estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_ic(model_data = NULL, ic = "looic", ncore = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_ic_+3A_model_data">model_data</code></td>
<td>
<p>Object returned by <code>'hBayesDM'</code> model function</p>
</td></tr>
<tr><td><code id="extract_ic_+3A_ic">ic</code></td>
<td>
<p>Information Criterion. 'looic', 'waic', or 'both'</p>
</td></tr>
<tr><td><code id="extract_ic_+3A_ncore">ncore</code></td>
<td>
<p>Number of cores to use when computing LOOIC</p>
</td></tr>
</table>


<h3>Value</h3>

<p>IC Leave-One-Out and/or Watanabe-Akaike information criterion estimates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(hBayesDM)
output = bandit2arm_delta("example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 1)
# To show the LOOIC model fit estimates (a detailed report; c)
extract_ic(output)
# To show the WAIC model fit estimates
extract_ic(output, ic = "waic")

## End(Not run)

</code></pre>

<hr>
<h2 id='gng_m1'>RW + noise</h2><span id='topic+gng_m1'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Orthogonalized Go/Nogo Task using RW + noise.
It has the following parameters: <code>xi</code> (noise), <code>ep</code> (learning rate), <code>rho</code> (effective size).
</p>

<ul>
<li> <p><strong>Task</strong>: Orthogonalized Go/Nogo Task 
</p>
</li>
<li> <p><strong>Model</strong>: RW + noise (Guitart-Masip et al., 2012)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>gng_m1(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gng_m1_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;cue&quot;, &quot;keyPressed&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;Qgo&quot;, &quot;Qnogo&quot;, &quot;Wgo&quot;, &quot;Wnogo&quot;.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m1_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Orthogonalized Go/Nogo Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;cue&quot;, &quot;keyPressed&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>cue</dt><dd><p>Nominal integer representing the cue shown for that trial: 1, 2, 3, or 4.</p>
</dd>
<dt>keyPressed</dt><dd><p>Binary value representing the subject's response for that trial (where Press == 1; No press == 0).</p>
</dd>
<dt>outcome</dt><dd><p>Ternary value representing the outcome of that trial (where Positive feedback == 1; Neutral feedback == 0; Negative feedback == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;gng_m1&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Guitart-Masip, M., Huys, Q. J. M., Fuentemilla, L., Dayan, P., Duzel, E., &amp; Dolan, R. J. (2012). Go and no-go learning in reward and punishment: Interactions between affect and effect. Neuroimage, 62(1), 154-166. https://doi.org/10.1016/j.neuroimage.2012.04.024
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- gng_m1(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- gng_m1(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='gng_m2'>RW + noise + bias</h2><span id='topic+gng_m2'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Orthogonalized Go/Nogo Task using RW + noise + bias.
It has the following parameters: <code>xi</code> (noise), <code>ep</code> (learning rate), <code>b</code> (action bias), <code>rho</code> (effective size).
</p>

<ul>
<li> <p><strong>Task</strong>: Orthogonalized Go/Nogo Task 
</p>
</li>
<li> <p><strong>Model</strong>: RW + noise + bias (Guitart-Masip et al., 2012)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>gng_m2(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gng_m2_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;cue&quot;, &quot;keyPressed&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;Qgo&quot;, &quot;Qnogo&quot;, &quot;Wgo&quot;, &quot;Wnogo&quot;.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m2_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Orthogonalized Go/Nogo Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;cue&quot;, &quot;keyPressed&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>cue</dt><dd><p>Nominal integer representing the cue shown for that trial: 1, 2, 3, or 4.</p>
</dd>
<dt>keyPressed</dt><dd><p>Binary value representing the subject's response for that trial (where Press == 1; No press == 0).</p>
</dd>
<dt>outcome</dt><dd><p>Ternary value representing the outcome of that trial (where Positive feedback == 1; Neutral feedback == 0; Negative feedback == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;gng_m2&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Guitart-Masip, M., Huys, Q. J. M., Fuentemilla, L., Dayan, P., Duzel, E., &amp; Dolan, R. J. (2012). Go and no-go learning in reward and punishment: Interactions between affect and effect. Neuroimage, 62(1), 154-166. https://doi.org/10.1016/j.neuroimage.2012.04.024
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- gng_m2(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- gng_m2(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='gng_m3'>RW + noise + bias + pi</h2><span id='topic+gng_m3'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Orthogonalized Go/Nogo Task using RW + noise + bias + pi.
It has the following parameters: <code>xi</code> (noise), <code>ep</code> (learning rate), <code>b</code> (action bias), <code>pi</code> (Pavlovian bias), <code>rho</code> (effective size).
</p>

<ul>
<li> <p><strong>Task</strong>: Orthogonalized Go/Nogo Task 
</p>
</li>
<li> <p><strong>Model</strong>: RW + noise + bias + pi (Guitart-Masip et al., 2012)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>gng_m3(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gng_m3_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;cue&quot;, &quot;keyPressed&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;Qgo&quot;, &quot;Qnogo&quot;, &quot;Wgo&quot;, &quot;Wnogo&quot;, &quot;SV&quot;.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m3_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Orthogonalized Go/Nogo Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;cue&quot;, &quot;keyPressed&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>cue</dt><dd><p>Nominal integer representing the cue shown for that trial: 1, 2, 3, or 4.</p>
</dd>
<dt>keyPressed</dt><dd><p>Binary value representing the subject's response for that trial (where Press == 1; No press == 0).</p>
</dd>
<dt>outcome</dt><dd><p>Ternary value representing the outcome of that trial (where Positive feedback == 1; Neutral feedback == 0; Negative feedback == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;gng_m3&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Guitart-Masip, M., Huys, Q. J. M., Fuentemilla, L., Dayan, P., Duzel, E., &amp; Dolan, R. J. (2012). Go and no-go learning in reward and punishment: Interactions between affect and effect. Neuroimage, 62(1), 154-166. https://doi.org/10.1016/j.neuroimage.2012.04.024
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- gng_m3(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- gng_m3(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='gng_m4'>RW (rew/pun) + noise + bias + pi</h2><span id='topic+gng_m4'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Orthogonalized Go/Nogo Task using RW (rew/pun) + noise + bias + pi.
It has the following parameters: <code>xi</code> (noise), <code>ep</code> (learning rate), <code>b</code> (action bias), <code>pi</code> (Pavlovian bias), <code>rhoRew</code> (reward sensitivity), <code>rhoPun</code> (punishment sensitivity).
</p>

<ul>
<li> <p><strong>Task</strong>: Orthogonalized Go/Nogo Task 
</p>
</li>
<li> <p><strong>Model</strong>: RW (rew/pun) + noise + bias + pi (Cavanagh et al., 2013)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>gng_m4(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gng_m4_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;cue&quot;, &quot;keyPressed&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;Qgo&quot;, &quot;Qnogo&quot;, &quot;Wgo&quot;, &quot;Wnogo&quot;, &quot;SV&quot;.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="gng_m4_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Orthogonalized Go/Nogo Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;cue&quot;, &quot;keyPressed&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>cue</dt><dd><p>Nominal integer representing the cue shown for that trial: 1, 2, 3, or 4.</p>
</dd>
<dt>keyPressed</dt><dd><p>Binary value representing the subject's response for that trial (where Press == 1; No press == 0).</p>
</dd>
<dt>outcome</dt><dd><p>Ternary value representing the outcome of that trial (where Positive feedback == 1; Neutral feedback == 0; Negative feedback == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;gng_m4&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Cavanagh, J. F., Eisenberg, I., Guitart-Masip, M., Huys, Q., &amp; Frank, M. J. (2013). Frontal Theta Overrides Pavlovian Learning Biases. Journal of Neuroscience, 33(19), 8541-8548. https://doi.org/10.1523/JNEUROSCI.5754-12.2013
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- gng_m4(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- gng_m4(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='hBayesDM_model'>hBayesDM Model Base Function</h2><span id='topic+hBayesDM_model'></span>

<h3>Description</h3>

<p>The base function from which all hBayesDM model functions are created.
</p>
<p>Contributor: <a href="https://ccs-lab.github.io/team/jethro-lee/">Jethro Lee</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hBayesDM_model(
  task_name,
  model_name,
  model_type = "",
  data_columns,
  parameters,
  regressors = NULL,
  postpreds = "y_pred",
  stanmodel_arg = NULL,
  preprocess_func
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hBayesDM_model_+3A_task_name">task_name</code></td>
<td>
<p>Character value for name of task. E.g. <code>"gng"</code>.</p>
</td></tr>
<tr><td><code id="hBayesDM_model_+3A_model_name">model_name</code></td>
<td>
<p>Character value for name of model. E.g. <code>"m1"</code>.</p>
</td></tr>
<tr><td><code id="hBayesDM_model_+3A_model_type">model_type</code></td>
<td>
<p>Character value for modeling type: <code>""</code> OR <code>"single"</code> OR
<code>"multipleB"</code>.</p>
</td></tr>
<tr><td><code id="hBayesDM_model_+3A_data_columns">data_columns</code></td>
<td>
<p>Character vector of necessary column names for the data. E.g.
<code>c("subjID", "cue", "keyPressed", "outcome")</code>.</p>
</td></tr>
<tr><td><code id="hBayesDM_model_+3A_parameters">parameters</code></td>
<td>
<p>List of parameters, with information about their lower bound, plausible value,
upper bound. E.g. <code>list("xi" = c(0, 0.1, 1), "ep" = c(0, 0.2, 1), "rho" = c(0, exp(2),
Inf))</code>.</p>
</td></tr>
<tr><td><code id="hBayesDM_model_+3A_regressors">regressors</code></td>
<td>
<p>List of regressors, with information about their extracted dimensions. E.g.
<code>list("Qgo" = 2, "Qnogo" = 2, "Wgo" = 2, "Wnogo" = 2)</code>. OR if model-based regressors are
not available for this model, <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="hBayesDM_model_+3A_postpreds">postpreds</code></td>
<td>
<p>Character vector of name(s) for the trial-level posterior predictive
simulations. Default is <code>"y_pred"</code>. OR if posterior predictions are not yet available for
this model, <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="hBayesDM_model_+3A_stanmodel_arg">stanmodel_arg</code></td>
<td>
<p>Leave as <code>NULL</code> (default) for completed models. Else should either be a
character value (specifying the name of a Stan file) OR a <code>stanmodel</code> object (returned as
a result of running <code><a href="rstan.html#topic+stan_model">stan_model</a></code>).</p>
</td></tr>
<tr><td><code id="hBayesDM_model_+3A_preprocess_func">preprocess_func</code></td>
<td>
<p>Function to preprocess the raw data before it gets passed to Stan. Takes
(at least) two arguments: a data.table object <code>raw_data</code> and a list object
<code>general_info</code>. Possible to include additional argument(s) to use during preprocessing.
Should return a list object <code>data_list</code>, which will then directly be passed to Stan.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>task_name</strong>: Typically same task models share the same data column requirements.
</p>
<p><strong>model_name</strong>: Typically different models are distinguished by their different list of
parameters.
</p>
<p><strong>model_type</strong> is one of the following three:
</p>

<dl>
<dt><code>""</code></dt><dd><p>Modeling of multiple subjects. (Default hierarchical Bayesian analysis.)</p>
</dd>
<dt><code>"single"</code></dt><dd><p>Modeling of a single subject.</p>
</dd>
<dt><code>"multipleB"</code></dt><dd><p>Modeling of multiple subjects, where multiple blocks exist within
each subject.</p>
</dd>
</dl>

<p><strong>data_columns</strong> must be the entirety of necessary data columns used at some point in the R
or Stan code. I.e. <code>"subjID"</code> must always be included. In the case of 'multipleB' type
models, <code>"block"</code> should also be included as well.
</p>
<p><strong>parameters</strong> is a list object, whose keys are the parameters of this model. Each parameter
key must be assigned a numeric vector holding 3 elements: the parameter's lower bound,
plausible value, and upper bound.
</p>
<p><strong>regressors</strong> is a list object, whose keys are the model-based regressors of this model.
Each regressor key must be assigned a numeric value indicating the number of dimensions its
data will be extracted as. If model-based regressors are not available for this model, this
argument should just be <code>NULL</code>.
</p>
<p><strong>postpreds</strong> defaults to <code>"y_pred"</code>, but any other character vector holding
appropriate names is possible (c.f. Two-Step Task models). If posterior predictions are not yet
available for this model, this argument should just be <code>NULL</code>.
</p>
<p><strong>stanmodel_arg</strong> can be used by developers, during the developmental stage of creating a
new model function. If this argument is passed a character value, the Stan file with the
corresponding name will be used for model fitting. If this argument is passed a
<code>stanmodel</code> object, that <code>stanmodel</code> object will be used for model fitting. When
creation of the model function is complete, this argument should just be left as <code>NULL</code>.
</p>
<p><strong>preprocess_func</strong> is the part of the code that is specific to the model, and is thus
written in the specific model R file.<br />
Arguments for this function are:
</p>

<dl>
<dt><code>raw_data</code></dt><dd><p>A data.table that holds the raw user data, which was read by using
<code><a href="data.table.html#topic+fread">fread</a></code>.</p>
</dd>
<dt><code>general_info</code></dt><dd><p>A list that holds the general informations about the raw data, i.e.
<code>subjs</code>, <code>n_subj</code>, <code>t_subjs</code>, <code>t_max</code>, <code>b_subjs</code>, <code>b_max</code>.</p>
</dd>
<dt><code>...</code></dt><dd><p>Optional additional argument(s) that specific model functions may want to
include. Examples of such additional arguments currently being used in hBayesDM models are:
<code>RTbound</code> (choiceRT_ddm models), <code>payscale</code> (igt models), and <code>trans_prob</code> (ts
models).</p>
</dd>
</dl>

<p>Return value for this function should be:
</p>

<dl>
<dt><code>data_list</code></dt><dd><p>A list with appropriately named keys (as required by the model Stan
file), holding the fully preprocessed user data.</p>
</dd>
</dl>

<p>NOTE: Syntax for data.table slightly differs from that of data.frame. If you want to use
<code>raw_data</code> as a data.frame when writing the <code>preprocess_func</code>, simply begin with the
line: <code>raw_data &lt;- as.data.frame(raw_data)</code>.<br />
NOTE: Because of allowing case &amp; underscore insensitive column names in user data,
<code>raw_data</code> columns must now be referenced by their lowercase non-underscored versions,
e.g. <code>"subjid"</code>, within the code of the preprocess function.<br />
</p>


<h3>Value</h3>

<p>A specific hBayesDM model function.
</p>

<hr>
<h2 id='hBayesDM-package'>Hierarchical Bayesian Modeling of Decision-Making Tasks</h2><span id='topic+hBayesDM-package'></span><span id='topic+hBayesDM'></span>

<h3>Description</h3>

<p>Fit an array of decision-making tasks with computational models in a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of various computational models with a single line of coding.
Bolded tasks, followed by their respective models, are itemized below.
</p>

<dl>
<dt><strong>Bandit</strong></dt><dd><p>2-Armed Bandit (Rescorla-Wagner (delta)) &mdash; <a href="#topic+bandit2arm_delta">bandit2arm_delta</a> <br />
4-Armed Bandit with fictive updating + reward/punishment sensitvity (Rescorla-Wagner (delta)) &mdash; <a href="#topic+bandit4arm_4par">bandit4arm_4par</a> <br />
4-Armed Bandit with fictive updating + reward/punishment sensitvity + lapse (Rescorla-Wagner (delta)) &mdash; <a href="#topic+bandit4arm_lapse">bandit4arm_lapse</a></p>
</dd>
<dt><strong>Bandit2</strong></dt><dd><p>Kalman filter &mdash; <a href="#topic+bandit4arm2_kalman_filter">bandit4arm2_kalman_filter</a></p>
</dd>
<dt><strong>Cambridge Gambling Task</strong></dt><dd><p>Cumulative Model &mdash; <a href="#topic+cgt_cm">cgt_cm</a></p>
</dd>
<dt><strong>Choice RT</strong></dt><dd><p>Drift Diffusion Model &mdash; <a href="#topic+choiceRT_ddm">choiceRT_ddm</a> <br />
Drift Diffusion Model for a single subject &mdash; <a href="#topic+choiceRT_ddm_single">choiceRT_ddm_single</a> <br />
Linear Ballistic Accumulator (LBA) model &mdash; <a href="#topic+choiceRT_lba">choiceRT_lba</a> <br />
Linear Ballistic Accumulator (LBA) model for a single subject &mdash; <a href="#topic+choiceRT_lba_single">choiceRT_lba_single</a></p>
</dd>
<dt><strong>Choice under Risk and Ambiguity</strong></dt><dd><p>Exponential model &mdash; <a href="#topic+cra_exp">cra_exp</a> <br />
Linear model &mdash; <a href="#topic+cra_linear">cra_linear</a></p>
</dd>
<dt><strong>Description-Based Decision Making</strong></dt><dd><p>probability weight function &mdash; <a href="#topic+dbdm_prob_weight">dbdm_prob_weight</a></p>
</dd>
<dt><strong>Delay Discounting</strong></dt><dd><p>Constant Sensitivity &mdash; <a href="#topic+dd_cs">dd_cs</a> <br />
Constant Sensitivity for a single subject &mdash; <a href="#topic+dd_cs_single">dd_cs_single</a> <br />
Exponential &mdash; <a href="#topic+dd_exp">dd_exp</a> <br />
Hyperbolic &mdash; <a href="#topic+dd_hyperbolic">dd_hyperbolic</a> <br />
Hyperbolic for a single subject &mdash; <a href="#topic+dd_hyperbolic_single">dd_hyperbolic_single</a></p>
</dd>
<dt><strong>Orthogonalized Go/Nogo</strong></dt><dd><p>RW + Noise &mdash; <a href="#topic+gng_m1">gng_m1</a> <br />
RW + Noise + Bias &mdash; <a href="#topic+gng_m2">gng_m2</a> <br />
RW + Noise + Bias + Pavlovian Bias &mdash; <a href="#topic+gng_m3">gng_m3</a> <br />
RW(modified) + Noise + Bias + Pavlovian Bias &mdash; <a href="#topic+gng_m4">gng_m4</a></p>
</dd>
<dt><strong>Iowa Gambling</strong></dt><dd><p>Outcome-Representation Learning &mdash; <a href="#topic+igt_orl">igt_orl</a> <br />
Prospect Valence Learning-DecayRI &mdash; <a href="#topic+igt_pvl_decay">igt_pvl_decay</a> <br />
Prospect Valence Learning-Delta &mdash; <a href="#topic+igt_pvl_delta">igt_pvl_delta</a> <br />
Value-Plus_Perseverance &mdash; <a href="#topic+igt_vpp">igt_vpp</a></p>
</dd>
<dt><strong>Peer influence task</strong></dt><dd><p>OCU model &mdash; <a href="#topic+peer_ocu">peer_ocu</a></p>
</dd>
<dt><strong>Probabilistic Reversal Learning</strong></dt><dd><p>Experience-Weighted Attraction &mdash; <a href="#topic+prl_ewa">prl_ewa</a> <br />
Fictitious Update &mdash; <a href="#topic+prl_fictitious">prl_fictitious</a> <br />
Fictitious Update w/o alpha (indecision point) &mdash; <a href="#topic+prl_fictitious_woa">prl_fictitious_woa</a> <br />
Fictitious Update and multiple blocks per subject &mdash; <a href="#topic+prl_fictitious_multipleB">prl_fictitious_multipleB</a> <br />
Reward-Punishment &mdash; <a href="#topic+prl_rp">prl_rp</a> <br />
Reward-Punishment and multiple blocks per subject &mdash; <a href="#topic+prl_rp_multipleB">prl_rp_multipleB</a> <br />
Fictitious Update with separate learning for Reward-Punishment &mdash; <a href="#topic+prl_fictitious_rp">prl_fictitious_rp</a> <br />
Fictitious Update with separate learning for Reward-Punishment w/o alpha (indecision point) &mdash; <a href="#topic+prl_fictitious_rp_woa">prl_fictitious_rp_woa</a></p>
</dd>
<dt><strong>Probabilistic Selection Task</strong></dt><dd><p>Q-learning with two learning rates &mdash; <a href="#topic+pst_gainloss_Q">pst_gainloss_Q</a></p>
</dd>
<dt><strong>Risk Aversion</strong></dt><dd><p>Prospect Theory (PT) &mdash; <a href="#topic+ra_prospect">ra_prospect</a> <br />
PT without a loss aversion parameter &mdash; <a href="#topic+ra_noLA">ra_noLA</a> <br />
PT without a risk aversion parameter &mdash; <a href="#topic+ra_noRA">ra_noRA</a></p>
</dd>
<dt><strong>Risky Decision Task</strong></dt><dd><p>Happiness model &mdash; <a href="#topic+rdt_happiness">rdt_happiness</a></p>
</dd>
<dt><strong>Two-Step task</strong></dt><dd><p>Full model (7 parameters) &mdash; <a href="#topic+ts_par7">ts_par7</a> <br />
6 parameter model (without eligibility trace, lambda) &mdash; <a href="#topic+ts_par6">ts_par6</a> <br />
4 parameter model &mdash; <a href="#topic+ts_par4">ts_par4</a></p>
</dd>
<dt><strong>Ultimatum Game</strong></dt><dd><p>Ideal Bayesian Observer &mdash; <a href="#topic+ug_bayes">ug_bayes</a> <br />
Rescorla-Wagner (delta) &mdash; <a href="#topic+ug_delta">ug_delta</a></p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Woo-Young Ahn <a href="mailto:wahn55@snu.ac.kr">wahn55@snu.ac.kr</a>
</p>
<p>Nathaniel Haines <a href="mailto:haines.175@osu.edu">haines.175@osu.edu</a>
</p>
<p>Lei Zhang <a href="mailto:bnuzhanglei2008@gmail.com">bnuzhanglei2008@gmail.com</a>
</p>


<h3>References</h3>

<p>Please cite as:
Ahn, W.-Y., Haines, N., &amp; Zhang, L. (2017). Revealing neuro-computational mechanisms of reinforcement learning and decision-making with the hBayesDM package. <em>Computational Psychiatry</em>. 1, 24-57. https://doi.org/10.1162/CPSY_a_00002
</p>


<h3>See Also</h3>

<p>For tutorials and further readings, visit : <a href="http://rpubs.com/CCSL/hBayesDM">http://rpubs.com/CCSL/hBayesDM</a>.
</p>

<hr>
<h2 id='HDIofMCMC'>Compute Highest-Density Interval</h2><span id='topic+HDIofMCMC'></span>

<h3>Description</h3>

<p>Computes the highest density interval from a sample of representative values,
estimated as shortest credible interval.
Based on John Kruschke's codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HDIofMCMC(sampleVec, credMass = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HDIofMCMC_+3A_samplevec">sampleVec</code></td>
<td>
<p>A vector of representative values from a probability distribution (e.g., MCMC samples).</p>
</td></tr>
<tr><td><code id="HDIofMCMC_+3A_credmass">credMass</code></td>
<td>
<p>A scalar between 0 and 1, indicating the mass within the credible interval that is to be estimated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the limits of the HDI
</p>

<hr>
<h2 id='igt_orl'>Outcome-Representation Learning Model</h2><span id='topic+igt_orl'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Iowa Gambling Task using Outcome-Representation Learning Model.
It has the following parameters: <code>Arew</code> (reward learning rate), <code>Apun</code> (punishment learning rate), <code>K</code> (perseverance decay), <code>betaF</code> (outcome frequency weight), <code>betaP</code> (perseverance weight).
</p>

<ul>
<li> <p><strong>Task</strong>: Iowa Gambling Task (Ahn et al., 2008)
</p>
</li>
<li> <p><strong>Model</strong>: Outcome-Representation Learning Model (Haines et al., 2018)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>igt_orl(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="igt_orl_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_orl_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>payscale</dt><dd><p>Raw payoffs within data are divided by this number. Used for scaling data. Defaults to 100.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Iowa Gambling Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer indicating which deck was chosen on that trial (where A==1, B==2, C==3, and D==4).</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on that trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on that trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/nate-haines/">Nate Haines</a> &lt;<a href="mailto:haines.175@osu.edu">haines.175@osu.edu</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;igt_orl&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ahn, W. Y., Busemeyer, J. R., &amp; Wagenmakers, E. J. (2008). Comparison of decision learning models using the generalization criterion method. Cognitive Science, 32(8), 1376-1402. https://doi.org/10.1080/03640210802352992
</p>
<p>Haines, N., Vassileva, J., &amp; Ahn, W.-Y. (2018). The Outcome-Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task. Cognitive Science. https://doi.org/10.1111/cogs.12688
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- igt_orl(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- igt_orl(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='igt_pvl_decay'>Prospect Valence Learning (PVL) Decay-RI</h2><span id='topic+igt_pvl_decay'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Iowa Gambling Task using Prospect Valence Learning (PVL) Decay-RI.
It has the following parameters: <code>A</code> (decay rate), <code>alpha</code> (outcome sensitivity), <code>cons</code> (response consistency), <code>lambda</code> (loss aversion).
</p>

<ul>
<li> <p><strong>Task</strong>: Iowa Gambling Task (Ahn et al., 2008)
</p>
</li>
<li> <p><strong>Model</strong>: Prospect Valence Learning (PVL) Decay-RI (Ahn et al., 2014)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>igt_pvl_decay(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="igt_pvl_decay_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_pvl_decay_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>payscale</dt><dd><p>Raw payoffs within data are divided by this number. Used for scaling data. Defaults to 100.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Iowa Gambling Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer indicating which deck was chosen on that trial (where A==1, B==2, C==3, and D==4).</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on that trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on that trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;igt_pvl_decay&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ahn, W. Y., Busemeyer, J. R., &amp; Wagenmakers, E. J. (2008). Comparison of decision learning models using the generalization criterion method. Cognitive Science, 32(8), 1376-1402. https://doi.org/10.1080/03640210802352992
</p>
<p>Ahn, W.-Y., Vasilev, G., Lee, S.-H., Busemeyer, J. R., Kruschke, J. K., Bechara, A., &amp; Vassileva, J. (2014). Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users. Frontiers in Psychology, 5, 1376. https://doi.org/10.3389/fpsyg.2014.00849
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- igt_pvl_decay(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- igt_pvl_decay(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='igt_pvl_delta'>Prospect Valence Learning (PVL) Delta</h2><span id='topic+igt_pvl_delta'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Iowa Gambling Task using Prospect Valence Learning (PVL) Delta.
It has the following parameters: <code>A</code> (learning rate), <code>alpha</code> (outcome sensitivity), <code>cons</code> (response consistency), <code>lambda</code> (loss aversion).
</p>

<ul>
<li> <p><strong>Task</strong>: Iowa Gambling Task (Ahn et al., 2008)
</p>
</li>
<li> <p><strong>Model</strong>: Prospect Valence Learning (PVL) Delta (Ahn et al., 2008)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>igt_pvl_delta(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="igt_pvl_delta_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_pvl_delta_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>payscale</dt><dd><p>Raw payoffs within data are divided by this number. Used for scaling data. Defaults to 100.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Iowa Gambling Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer indicating which deck was chosen on that trial (where A==1, B==2, C==3, and D==4).</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on that trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on that trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;igt_pvl_delta&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ahn, W. Y., Busemeyer, J. R., &amp; Wagenmakers, E. J. (2008). Comparison of decision learning models using the generalization criterion method. Cognitive Science, 32(8), 1376-1402. https://doi.org/10.1080/03640210802352992
</p>
<p>Ahn, W. Y., Busemeyer, J. R., &amp; Wagenmakers, E. J. (2008). Comparison of decision learning models using the generalization criterion method. Cognitive Science, 32(8), 1376-1402. https://doi.org/10.1080/03640210802352992
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- igt_pvl_delta(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- igt_pvl_delta(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='igt_vpp'>Value-Plus-Perseverance</h2><span id='topic+igt_vpp'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Iowa Gambling Task using Value-Plus-Perseverance.
It has the following parameters: <code>A</code> (learning rate), <code>alpha</code> (outcome sensitivity), <code>cons</code> (response consistency), <code>lambda</code> (loss aversion), <code>epP</code> (gain impact), <code>epN</code> (loss impact), <code>K</code> (decay rate), <code>w</code> (RL weight).
</p>

<ul>
<li> <p><strong>Task</strong>: Iowa Gambling Task (Ahn et al., 2008)
</p>
</li>
<li> <p><strong>Model</strong>: Value-Plus-Perseverance (Worthy et al., 2013)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>igt_vpp(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="igt_vpp_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="igt_vpp_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>payscale</dt><dd><p>Raw payoffs within data are divided by this number. Used for scaling data. Defaults to 100.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Iowa Gambling Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;gain&quot;, &quot;loss&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer indicating which deck was chosen on that trial (where A==1, B==2, C==3, and D==4).</p>
</dd>
<dt>gain</dt><dd><p>Floating point value representing the amount of currency won on that trial (e.g. 50, 100).</p>
</dd>
<dt>loss</dt><dd><p>Floating point value representing the amount of currency lost on that trial (e.g. 0, -50).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;igt_vpp&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ahn, W. Y., Busemeyer, J. R., &amp; Wagenmakers, E. J. (2008). Comparison of decision learning models using the generalization criterion method. Cognitive Science, 32(8), 1376-1402. https://doi.org/10.1080/03640210802352992
</p>
<p>Worthy, D. A., &amp; Todd Maddox, W. (2013). A comparison model of reinforcement-learning and win-stay-lose-shift decision-making processes: A tribute to W.K. Estes. Journal of Mathematical Psychology, 59, 41-49. https://doi.org/10.1016/j.jmp.2013.10.001
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- igt_vpp(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- igt_vpp(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='multiplot'>Function to plot multiple figures</h2><span id='topic+multiplot'></span>

<h3>Description</h3>

<p>Plots multiple figures
Based on codes from 'http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiplot(..., plots = NULL, cols = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiplot_+3A_...">...</code></td>
<td>
<p>Plot objects</p>
</td></tr>
<tr><td><code id="multiplot_+3A_plots">plots</code></td>
<td>
<p>List containing plot objects</p>
</td></tr>
<tr><td><code id="multiplot_+3A_cols">cols</code></td>
<td>
<p>Number of columns within the multi-figure plot</p>
</td></tr>
</table>

<hr>
<h2 id='peer_ocu'>Other-Conferred Utility (OCU) Model</h2><span id='topic+peer_ocu'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Peer Influence Task using Other-Conferred Utility (OCU) Model.
It has the following parameters: <code>rho</code> (risk preference), <code>tau</code> (inverse temperature), <code>ocu</code> (other-conferred utility).
</p>

<ul>
<li> <p><strong>Task</strong>: Peer Influence Task (Chung et al., 2015)
</p>
</li>
<li> <p><strong>Model</strong>: Other-Conferred Utility (OCU) Model 
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>peer_ocu(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="peer_ocu_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;condition&quot;, &quot;p_gamble&quot;, &quot;safe_Hpayoff&quot;, &quot;safe_Lpayoff&quot;, &quot;risky_Hpayoff&quot;, &quot;risky_Lpayoff&quot;, &quot;choice&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="peer_ocu_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Peer Influence Task, there should be 8 columns of data with the
labels &quot;subjID&quot;, &quot;condition&quot;, &quot;p_gamble&quot;, &quot;safe_Hpayoff&quot;, &quot;safe_Lpayoff&quot;, &quot;risky_Hpayoff&quot;, &quot;risky_Lpayoff&quot;, &quot;choice&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>condition</dt><dd><p>0: solo, 1: info (safe/safe), 2: info (mix), 3: info (risky/risky).</p>
</dd>
<dt>p_gamble</dt><dd><p>Probability of receiving a high payoff (same for both options).</p>
</dd>
<dt>safe_Hpayoff</dt><dd><p>High payoff of the safe option.</p>
</dd>
<dt>safe_Lpayoff</dt><dd><p>Low payoff of the safe option.</p>
</dd>
<dt>risky_Hpayoff</dt><dd><p>High payoff of the risky option.</p>
</dd>
<dt>risky_Lpayoff</dt><dd><p>Low payoff of the risky option.</p>
</dd>
<dt>choice</dt><dd><p>Which option was chosen? 0: safe, 1: risky.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;peer_ocu&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chung, D., Christopoulos, G. I., King-Casas, B., Ball, S. B., &amp; Chiu, P. H. (2015). Social signals of safety and risk confer utility and have asymmetric effects on observers' choices. Nature Neuroscience, 18(6), 912-916.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- peer_ocu(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- peer_ocu(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.hBayesDM'>General Purpose Plotting for hBayesDM. This function plots hyper parameters.</h2><span id='topic+plot.hBayesDM'></span>

<h3>Description</h3>

<p>General Purpose Plotting for hBayesDM. This function plots hyper parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hBayesDM'
plot(
  x = NULL,
  type = "dist",
  ncols = NULL,
  fontSize = NULL,
  binSize = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hBayesDM_+3A_x">x</code></td>
<td>
<p>Model output of class hBayesDM</p>
</td></tr>
<tr><td><code id="plot.hBayesDM_+3A_type">type</code></td>
<td>
<p>Character value that specifies the plot type. Options are: &quot;dist&quot;, &quot;trace&quot;, or &quot;simple&quot;. Defaults to &quot;dist&quot;.</p>
</td></tr>
<tr><td><code id="plot.hBayesDM_+3A_ncols">ncols</code></td>
<td>
<p>Integer value specifying how many plots there should be per row. Defaults to the number of parameters.</p>
</td></tr>
<tr><td><code id="plot.hBayesDM_+3A_fontsize">fontSize</code></td>
<td>
<p>Integer value specifying the size of the font used for plotting. Defaults to 10.</p>
</td></tr>
<tr><td><code id="plot.hBayesDM_+3A_binsize">binSize</code></td>
<td>
<p>Integer value specifying how wide the bars on the histogram should be. Defaults to 30.</p>
</td></tr>
<tr><td><code id="plot.hBayesDM_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed on</p>
</td></tr>
</table>

<hr>
<h2 id='plotDist'>Plots the histogram of MCMC samples.</h2><span id='topic+plotDist'></span>

<h3>Description</h3>

<p>Plots the histogram of MCMC samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDist(
  sample = NULL,
  Title = NULL,
  xLab = "Value",
  yLab = "Density",
  xLim = NULL,
  fontSize = NULL,
  binSize = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDist_+3A_sample">sample</code></td>
<td>
<p>MCMC samples</p>
</td></tr>
<tr><td><code id="plotDist_+3A_title">Title</code></td>
<td>
<p>Character value containing the main title for the plot</p>
</td></tr>
<tr><td><code id="plotDist_+3A_xlab">xLab</code></td>
<td>
<p>Character value containing the x label</p>
</td></tr>
<tr><td><code id="plotDist_+3A_ylab">yLab</code></td>
<td>
<p>Character value containing the y label</p>
</td></tr>
<tr><td><code id="plotDist_+3A_xlim">xLim</code></td>
<td>
<p>Vector containing the lower and upper x-bounds of the plot</p>
</td></tr>
<tr><td><code id="plotDist_+3A_fontsize">fontSize</code></td>
<td>
<p>Size of the font to use for plotting. Defaults to 10</p>
</td></tr>
<tr><td><code id="plotDist_+3A_binsize">binSize</code></td>
<td>
<p>Size of the bins for creating the histogram. Defaults to 30</p>
</td></tr>
<tr><td><code id="plotDist_+3A_...">...</code></td>
<td>
<p>Arguments that can be additionally supplied to geom_histogram</p>
</td></tr>
</table>


<h3>Value</h3>

<p>h1 Plot object
</p>

<hr>
<h2 id='plotHDI'>Plots highest density interval (HDI) from (MCMC) samples and prints HDI in the R console.
HDI is indicated by a red line.
Based on John Kruschke's codes.</h2><span id='topic+plotHDI'></span>

<h3>Description</h3>

<p>Plots highest density interval (HDI) from (MCMC) samples and prints HDI in the R console.
HDI is indicated by a red line.
Based on John Kruschke's codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotHDI(
  sample = NULL,
  credMass = 0.95,
  Title = NULL,
  xLab = "Value",
  yLab = "Density",
  fontSize = NULL,
  binSize = 30,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotHDI_+3A_sample">sample</code></td>
<td>
<p>MCMC samples</p>
</td></tr>
<tr><td><code id="plotHDI_+3A_credmass">credMass</code></td>
<td>
<p>A scalar between 0 and 1, indicating the mass within the credible interval that is to be estimated.</p>
</td></tr>
<tr><td><code id="plotHDI_+3A_title">Title</code></td>
<td>
<p>Character value containing the main title for the plot</p>
</td></tr>
<tr><td><code id="plotHDI_+3A_xlab">xLab</code></td>
<td>
<p>Character value containing the x label</p>
</td></tr>
<tr><td><code id="plotHDI_+3A_ylab">yLab</code></td>
<td>
<p>Character value containing the y label</p>
</td></tr>
<tr><td><code id="plotHDI_+3A_fontsize">fontSize</code></td>
<td>
<p>Integer value specifying the font size to be used for the plot labels</p>
</td></tr>
<tr><td><code id="plotHDI_+3A_binsize">binSize</code></td>
<td>
<p>Integer value specifyin ghow wide the bars on the histogram should be. Defaults to 30.</p>
</td></tr>
<tr><td><code id="plotHDI_+3A_...">...</code></td>
<td>
<p>Arguments that can be additionally supplied to geom_histogram</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the limits of the HDI
</p>

<hr>
<h2 id='plotInd'>Plots individual posterior distributions, using the stan_plot function of the rstan package</h2><span id='topic+plotInd'></span>

<h3>Description</h3>

<p>Plots individual posterior distributions, using the stan_plot function of the rstan package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotInd(obj = NULL, pars, show_density = T, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotInd_+3A_obj">obj</code></td>
<td>
<p>An output of the hBayesDM. Its class should be 'hBayesDM'.</p>
</td></tr>
<tr><td><code id="plotInd_+3A_pars">pars</code></td>
<td>
<p>(from stan_plot's help file) Character vector of parameter names. If unspecified, show all user-defined parameters or the first 10 (if there are more than 10)</p>
</td></tr>
<tr><td><code id="plotInd_+3A_show_density">show_density</code></td>
<td>
<p>T(rue) or F(alse). Show the density (T) or not (F)?</p>
</td></tr>
<tr><td><code id="plotInd_+3A_...">...</code></td>
<td>
<p>(from stan_plot's help file) Optional additional named arguments passed to stan_plot, which will be passed to geoms. See stan_plot's help file.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run a model
output &lt;- dd_hyperbolic("example", 2000, 1000, 3, 3)

# Plot the hyper parameters ('k' and 'beta')
plot(output)

# Plot individual 'k' (discounting rate) parameters
plotInd(output, "k")

# Plot individual 'beta' (inverse temperature) parameters
plotInd(output, "beta")

# Plot individual 'beta' parameters but don't show density
plotInd(output, "beta", show_density = F)

## End(Not run)
</code></pre>

<hr>
<h2 id='printFit'>Print model-fits (mean LOOIC or WAIC values in addition to Akaike weights) of hBayesDM Models</h2><span id='topic+printFit'></span>

<h3>Description</h3>

<p>Print model-fits (mean LOOIC or WAIC values in addition to Akaike weights) of hBayesDM Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>printFit(..., ic = "looic", ncore = 2, roundTo = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="printFit_+3A_...">...</code></td>
<td>
<p>Model objects output by hBayesDM functions (e.g. output1, output2, etc.)</p>
</td></tr>
<tr><td><code id="printFit_+3A_ic">ic</code></td>
<td>
<p>Which model comparison information criterion to use? 'looic', 'waic', or 'both</p>
</td></tr>
<tr><td><code id="printFit_+3A_ncore">ncore</code></td>
<td>
<p>Number of corse to use when computing LOOIC</p>
</td></tr>
<tr><td><code id="printFit_+3A_roundto">roundTo</code></td>
<td>
<p>Number of digits to the right of the decimal point in the output</p>
</td></tr>
</table>


<h3>Value</h3>

<p>modelTable A table with relevant model comparison data. LOOIC and WAIC weights are computed as Akaike weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run two models and store results in "output1" and "output2"
output1 &lt;- dd_hyperbolic("example", 2000, 1000, 3, 3)

output2 &lt;- dd_exp("example", 2000, 1000, 3, 3)

# Show the LOOIC model fit estimates
printFit(output1, output2)

# To show the WAIC model fit estimates
printFit(output1, output2, ic = "waic")

# To show both LOOIC and WAIC
printFit(output1, output2, ic = "both")

## End(Not run)
</code></pre>

<hr>
<h2 id='prl_ewa'>Experience-Weighted Attraction Model</h2><span id='topic+prl_ewa'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Reversal Learning Task using Experience-Weighted Attraction Model.
It has the following parameters: <code>phi</code> (1 - learning rate), <code>rho</code> (experience decay factor), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Reversal Learning Task 
</p>
</li>
<li> <p><strong>Model</strong>: Experience-Weighted Attraction Model (Ouden et al., 2013)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prl_ewa(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prl_ewa_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;ev_c&quot;, &quot;ev_nc&quot;, &quot;ew_c&quot;, &quot;ew_nc&quot;.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_ewa_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Reversal Learning Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on that trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of that trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang (for model-based regressors)</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park (for model-based regressors)</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;prl_ewa&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ouden, den, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M., Hoogman, M., et al. (2013). Dissociable Effects of Dopamine and Serotonin on Reversal Learning. Neuron, 80(4), 1090-1100. https://doi.org/10.1016/j.neuron.2013.08.030
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- prl_ewa(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- prl_ewa(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='prl_fictitious'>Fictitious Update Model</h2><span id='topic+prl_fictitious'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Reversal Learning Task using Fictitious Update Model.
It has the following parameters: <code>eta</code> (learning rate), <code>alpha</code> (indecision point), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Reversal Learning Task 
</p>
</li>
<li> <p><strong>Model</strong>: Fictitious Update Model (Glascher et al., 2009)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prl_fictitious(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prl_fictitious_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;ev_c&quot;, &quot;ev_nc&quot;, &quot;pe_c&quot;, &quot;pe_nc&quot;, &quot;dv&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Reversal Learning Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on that trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of that trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang (for model-based regressors)</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park (for model-based regressors)</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;prl_fictitious&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Glascher, J., Hampton, A. N., &amp; O'Doherty, J. P. (2009). Determining a Role for Ventromedial Prefrontal Cortex in Encoding Action-Based Value Signals During Reward-Related Decision Making. Cerebral Cortex, 19(2), 483-495. https://doi.org/10.1093/cercor/bhn098
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- prl_fictitious(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- prl_fictitious(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='prl_fictitious_multipleB'>Fictitious Update Model</h2><span id='topic+prl_fictitious_multipleB'></span>

<h3>Description</h3>

<p>Multiple-Block Hierarchical Bayesian Modeling of the Probabilistic Reversal Learning Task using Fictitious Update Model.
It has the following parameters: <code>eta</code> (learning rate), <code>alpha</code> (indecision point), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Reversal Learning Task 
</p>
</li>
<li> <p><strong>Model</strong>: Fictitious Update Model (Glascher et al., 2009)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prl_fictitious_multipleB(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prl_fictitious_multipleB_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;block&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;ev_c&quot;, &quot;ev_nc&quot;, &quot;pe_c&quot;, &quot;pe_nc&quot;, &quot;dv&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_multipleB_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Reversal Learning Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;block&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>block</dt><dd><p>A unique identifier for each of the multiple blocks within each subject.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on that trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of that trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang (for model-based regressors)</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park (for model-based regressors)</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;prl_fictitious_multipleB&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Glascher, J., Hampton, A. N., &amp; O'Doherty, J. P. (2009). Determining a Role for Ventromedial Prefrontal Cortex in Encoding Action-Based Value Signals During Reward-Related Decision Making. Cerebral Cortex, 19(2), 483-495. https://doi.org/10.1093/cercor/bhn098
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- prl_fictitious_multipleB(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- prl_fictitious_multipleB(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='prl_fictitious_rp'>Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE)</h2><span id='topic+prl_fictitious_rp'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Reversal Learning Task using Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE).
It has the following parameters: <code>eta_pos</code> (learning rate, +PE), <code>eta_neg</code> (learning rate, -PE), <code>alpha</code> (indecision point), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Reversal Learning Task 
</p>
</li>
<li> <p><strong>Model</strong>: Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE) (Glascher et al., 2009; Ouden et al., 2013)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prl_fictitious_rp(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prl_fictitious_rp_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;ev_c&quot;, &quot;ev_nc&quot;, &quot;pe_c&quot;, &quot;pe_nc&quot;, &quot;dv&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Reversal Learning Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on that trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of that trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang (for model-based regressors)</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park (for model-based regressors)</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;prl_fictitious_rp&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Glascher, J., Hampton, A. N., &amp; O'Doherty, J. P. (2009). Determining a Role for Ventromedial Prefrontal Cortex in Encoding Action-Based Value Signals During Reward-Related Decision Making. Cerebral Cortex, 19(2), 483-495. https://doi.org/10.1093/cercor/bhn098
</p>
<p>Ouden, den, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M., Hoogman, M., et al. (2013). Dissociable Effects of Dopamine and Serotonin on Reversal Learning. Neuron, 80(4), 1090-1100. https://doi.org/10.1016/j.neuron.2013.08.030
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- prl_fictitious_rp(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- prl_fictitious_rp(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='prl_fictitious_rp_woa'>Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE), without alpha (indecision point)</h2><span id='topic+prl_fictitious_rp_woa'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Reversal Learning Task using Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE), without alpha (indecision point).
It has the following parameters: <code>eta_pos</code> (learning rate, +PE), <code>eta_neg</code> (learning rate, -PE), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Reversal Learning Task 
</p>
</li>
<li> <p><strong>Model</strong>: Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE), without alpha (indecision point) (Glascher et al., 2009; Ouden et al., 2013)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prl_fictitious_rp_woa(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prl_fictitious_rp_woa_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;ev_c&quot;, &quot;ev_nc&quot;, &quot;pe_c&quot;, &quot;pe_nc&quot;, &quot;dv&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_rp_woa_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Reversal Learning Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on that trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of that trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang (for model-based regressors)</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park (for model-based regressors)</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;prl_fictitious_rp_woa&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Glascher, J., Hampton, A. N., &amp; O'Doherty, J. P. (2009). Determining a Role for Ventromedial Prefrontal Cortex in Encoding Action-Based Value Signals During Reward-Related Decision Making. Cerebral Cortex, 19(2), 483-495. https://doi.org/10.1093/cercor/bhn098
</p>
<p>Ouden, den, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M., Hoogman, M., et al. (2013). Dissociable Effects of Dopamine and Serotonin on Reversal Learning. Neuron, 80(4), 1090-1100. https://doi.org/10.1016/j.neuron.2013.08.030
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- prl_fictitious_rp_woa(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- prl_fictitious_rp_woa(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='prl_fictitious_woa'>Fictitious Update Model, without alpha (indecision point)</h2><span id='topic+prl_fictitious_woa'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Reversal Learning Task using Fictitious Update Model, without alpha (indecision point).
It has the following parameters: <code>eta</code> (learning rate), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Reversal Learning Task 
</p>
</li>
<li> <p><strong>Model</strong>: Fictitious Update Model, without alpha (indecision point) (Glascher et al., 2009)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prl_fictitious_woa(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prl_fictitious_woa_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;ev_c&quot;, &quot;ev_nc&quot;, &quot;pe_c&quot;, &quot;pe_nc&quot;, &quot;dv&quot;.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_fictitious_woa_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Reversal Learning Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on that trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of that trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang (for model-based regressors)</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park (for model-based regressors)</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;prl_fictitious_woa&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Glascher, J., Hampton, A. N., &amp; O'Doherty, J. P. (2009). Determining a Role for Ventromedial Prefrontal Cortex in Encoding Action-Based Value Signals During Reward-Related Decision Making. Cerebral Cortex, 19(2), 483-495. https://doi.org/10.1093/cercor/bhn098
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- prl_fictitious_woa(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- prl_fictitious_woa(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='prl_rp'>Reward-Punishment Model</h2><span id='topic+prl_rp'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Reversal Learning Task using Reward-Punishment Model.
It has the following parameters: <code>Apun</code> (punishment learning rate), <code>Arew</code> (reward learning rate), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Reversal Learning Task 
</p>
</li>
<li> <p><strong>Model</strong>: Reward-Punishment Model (Ouden et al., 2013)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prl_rp(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prl_rp_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;ev_c&quot;, &quot;ev_nc&quot;, &quot;pe&quot;.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_rp_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Reversal Learning Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on that trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of that trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang (for model-based regressors)</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park (for model-based regressors)</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;prl_rp&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ouden, den, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M., Hoogman, M., et al. (2013). Dissociable Effects of Dopamine and Serotonin on Reversal Learning. Neuron, 80(4), 1090-1100. https://doi.org/10.1016/j.neuron.2013.08.030
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- prl_rp(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- prl_rp(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='prl_rp_multipleB'>Reward-Punishment Model</h2><span id='topic+prl_rp_multipleB'></span>

<h3>Description</h3>

<p>Multiple-Block Hierarchical Bayesian Modeling of the Probabilistic Reversal Learning Task using Reward-Punishment Model.
It has the following parameters: <code>Apun</code> (punishment learning rate), <code>Arew</code> (reward learning rate), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Reversal Learning Task 
</p>
</li>
<li> <p><strong>Model</strong>: Reward-Punishment Model (Ouden et al., 2013)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prl_rp_multipleB(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prl_rp_multipleB_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;block&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;ev_c&quot;, &quot;ev_nc&quot;, &quot;pe&quot;.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="prl_rp_multipleB_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Reversal Learning Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;block&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>block</dt><dd><p>A unique identifier for each of the multiple blocks within each subject.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on that trial: 1 or 2.</p>
</dd>
<dt>outcome</dt><dd><p>Integer value representing the outcome of that trial (where reward == 1, and loss == -1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang (for model-based regressors)</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;, <a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park (for model-based regressors)</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;prl_rp_multipleB&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ouden, den, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M., Hoogman, M., et al. (2013). Dissociable Effects of Dopamine and Serotonin on Reversal Learning. Neuron, 80(4), 1090-1100. https://doi.org/10.1016/j.neuron.2013.08.030
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- prl_rp_multipleB(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- prl_rp_multipleB(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='pst_gainloss_Q'>Gain-Loss Q Learning Model</h2><span id='topic+pst_gainloss_Q'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Selection Task using Gain-Loss Q Learning Model.
It has the following parameters: <code>alpha_pos</code> (learning rate for positive feedbacks), <code>alpha_neg</code> (learning rate for negative feedbacks), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Selection Task 
</p>
</li>
<li> <p><strong>Model</strong>: Gain-Loss Q Learning Model (Frank et al., 2007)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>pst_gainloss_Q(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pst_gainloss_Q_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;type&quot;, &quot;choice&quot;, &quot;reward&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pst_gainloss_Q_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Selection Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;type&quot;, &quot;choice&quot;, &quot;reward&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>type</dt><dd><p>Two-digit number indicating which pair of stimuli were presented for that trial, e.g. 12, 34, or 56. The digit on the left (tens-digit) indicates the presented stimulus for option1, while the digit on the right (ones-digit) indicates that for option2. Code for each stimulus type (1~6) is defined as for 80% (type 1), 20% (type 2), 70% (type 3), 30% (type 4), 60% (type 5), 40% (type 6). The modeling will still work even if different probabilities are used for the stimuli; however, the total number of stimuli should be less than or equal to 6.</p>
</dd>
<dt>choice</dt><dd><p>Whether the subject chose the left option (option1) out of the given two options (i.e. if option1 was chosen, 1; if option2 was chosen, 0).</p>
</dd>
<dt>reward</dt><dd><p>Amount of reward earned as a result of the trial.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/jaeyeong-yang/">Jaeyeong Yang</a> &lt;<a href="mailto:jaeyeong.yang1125@gmail.com">jaeyeong.yang1125@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;pst_gainloss_Q&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Frank, M. J., Moustafa, A. A., Haughey, H. M., Curran, T., &amp; Hutchison, K. E. (2007). Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning. Proceedings of the National Academy of Sciences, 104(41), 16311-16316.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- pst_gainloss_Q(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- pst_gainloss_Q(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='pst_Q'>Q Learning Model</h2><span id='topic+pst_Q'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Selection Task using Q Learning Model.
It has the following parameters: <code>alpha</code> (learning rate), <code>beta</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Selection Task 
</p>
</li>
<li> <p><strong>Model</strong>: Q Learning Model (Frank et al., 2007)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>pst_Q(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pst_Q_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;type&quot;, &quot;choice&quot;, &quot;reward&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pst_Q_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Selection Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;type&quot;, &quot;choice&quot;, &quot;reward&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>type</dt><dd><p>Two-digit number indicating which pair of stimuli were presented for that trial, e.g. 12, 34, or 56. The digit on the left (tens-digit) indicates the presented stimulus for option1, while the digit on the right (ones-digit) indicates that for option2. Code for each stimulus type (1~6) is defined as for 80% (type 1), 20% (type 2), 70% (type 3), 30% (type 4), 60% (type 5), 40% (type 6). The modeling will still work even if different probabilities are used for the stimuli; however, the total number of stimuli should be less than or equal to 6.</p>
</dd>
<dt>choice</dt><dd><p>Whether the subject chose the left option (option1) out of the given two options (i.e. if option1 was chosen, 1; if option2 was chosen, 0).</p>
</dd>
<dt>reward</dt><dd><p>Amount of reward earned as a result of the trial.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://david-munoztord.com/">David Munoz Tord</a> &lt;<a href="mailto:david.munoztord@unige.ch">david.munoztord@unige.ch</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;pst_Q&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Frank, M. J., Moustafa, A. A., Haughey, H. M., Curran, T., &amp; Hutchison, K. E. (2007). Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning. Proceedings of the National Academy of Sciences, 104(41), 16311-16316.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- pst_Q(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- pst_Q(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='pstRT_ddm'>Drift Diffusion Model</h2><span id='topic+pstRT_ddm'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Selection Task (with RT data) using Drift Diffusion Model.
It has the following parameters: <code>a</code> (boundary separation), <code>tau</code> (non-decision time), <code>d1</code> (drift rate scaling), <code>d2</code> (drift rate scaling), <code>d3</code> (drift rate scaling).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Selection Task (with RT data) (Frank et al., 2007; Frank et al., 2004)
</p>
</li>
<li> <p><strong>Model</strong>: Drift Diffusion Model (Pedersen et al., 2017)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>pstRT_ddm(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pstRT_ddm_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;cond&quot;, &quot;choice&quot;, &quot;RT&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;choice_os&quot;, &quot;RT_os&quot;</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_ddm_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>RTbound</dt><dd><p>Floating point value representing the lower bound (i.e., minimum allowed) reaction time. Defaults to 0.1 (100 milliseconds).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Selection Task (with RT data), there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;cond&quot;, &quot;choice&quot;, &quot;RT&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>cond</dt><dd><p>Integer value representing the task condition of the given trial (AB == 1, CD == 2, EF == 3).</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial (1 or 2).</p>
</dd>
<dt>RT</dt><dd><p>Float value representing the time taken for the response on the given trial.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://hydoh.github.io/">Hoyoung Doh</a> &lt;<a href="mailto:hoyoung.doh@gmail.com">hoyoung.doh@gmail.com</a>&gt;, <a href="https://medicine.yale.edu/lab/goldfarb/profile/sanghoon_kang/">Sanghoon Kang</a> &lt;<a href="mailto:sanghoon.kang@yale.edu">sanghoon.kang@yale.edu</a>&gt;, <a href="https://jihyuncindyhur.github.io/">Jihyun K. Hur</a> &lt;<a href="mailto:jihyun.hur@yale.edu">jihyun.hur@yale.edu</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;pstRT_ddm&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Frank, M. J., Santamaria, A., O'Reilly, R. C., &amp; Willcutt, E. (2007). Testing computational models of dopamine and noradrenaline dysfunction in attention deficit/hyperactivity disorder. Neuropsychopharmacology, 32(7), 1583-1599.
</p>
<p>Frank, M. J., Seeberger, L. C., &amp; O'reilly, R. C. (2004). By carrot or by stick: cognitive reinforcement learning in parkinsonism. Science, 306(5703), 1940-1943.
</p>
<p>Pedersen, M. L., Frank, M. J., &amp; Biele, G. (2017). The drift diffusion model as the choice rule in reinforcement learning. Psychonomic bulletin &amp; review, 24(4), 1234-1251.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- pstRT_ddm(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- pstRT_ddm(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='pstRT_rlddm1'>Reinforcement Learning Drift Diffusion Model 1</h2><span id='topic+pstRT_rlddm1'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Selection Task (with RT data) using Reinforcement Learning Drift Diffusion Model 1.
It has the following parameters: <code>a</code> (boundary separation), <code>tau</code> (non-decision time), <code>v</code> (drift rate scaling), <code>alpha</code> (learning rate).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Selection Task (with RT data) (Frank et al., 2007; Frank et al., 2004)
</p>
</li>
<li> <p><strong>Model</strong>: Reinforcement Learning Drift Diffusion Model 1 (Pedersen et al., 2017)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>pstRT_rlddm1(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pstRT_rlddm1_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;cond&quot;, &quot;prob&quot;, &quot;choice&quot;, &quot;RT&quot;, &quot;feedback&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;Q1&quot;, &quot;Q2&quot;.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;choice_os&quot;, &quot;RT_os&quot;, &quot;choice_sm&quot;, &quot;RT_sm&quot;, &quot;fd_sm&quot;</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm1_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>RTbound</dt><dd><p>Floating point value representing the lower bound (i.e., minimum allowed) reaction time. Defaults to 0.1 (100 milliseconds).</p>
</dd>
<dt>initQ</dt><dd><p>Floating point value representing the model's initial value of any choice.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Selection Task (with RT data), there should be 6 columns of data with the
labels &quot;subjID&quot;, &quot;cond&quot;, &quot;prob&quot;, &quot;choice&quot;, &quot;RT&quot;, &quot;feedback&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>cond</dt><dd><p>Integer value representing the task condition of the given trial (AB == 1, CD == 2, EF == 3).</p>
</dd>
<dt>prob</dt><dd><p>Float value representing the probability that a correct response (1) is rewarded in the current task condition.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial (1 or 2).</p>
</dd>
<dt>RT</dt><dd><p>Float value representing the time taken for the response on the given trial.</p>
</dd>
<dt>feedback</dt><dd><p>Integer value representing the outcome of the given trial (where 'correct' == 1, and 'incorrect' == 0).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://hydoh.github.io/">Hoyoung Doh</a> &lt;<a href="mailto:hoyoung.doh@gmail.com">hoyoung.doh@gmail.com</a>&gt;, <a href="https://medicine.yale.edu/lab/goldfarb/profile/sanghoon_kang/">Sanghoon Kang</a> &lt;<a href="mailto:sanghoon.kang@yale.edu">sanghoon.kang@yale.edu</a>&gt;, <a href="https://jihyuncindyhur.github.io/">Jihyun K. Hur</a> &lt;<a href="mailto:jihyun.hur@yale.edu">jihyun.hur@yale.edu</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;pstRT_rlddm1&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Frank, M. J., Santamaria, A., O'Reilly, R. C., &amp; Willcutt, E. (2007). Testing computational models of dopamine and noradrenaline dysfunction in attention deficit/hyperactivity disorder. Neuropsychopharmacology, 32(7), 1583-1599.
</p>
<p>Frank, M. J., Seeberger, L. C., &amp; O'reilly, R. C. (2004). By carrot or by stick: cognitive reinforcement learning in parkinsonism. Science, 306(5703), 1940-1943.
</p>
<p>Pedersen, M. L., Frank, M. J., &amp; Biele, G. (2017). The drift diffusion model as the choice rule in reinforcement learning. Psychonomic bulletin &amp; review, 24(4), 1234-1251.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- pstRT_rlddm1(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- pstRT_rlddm1(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='pstRT_rlddm6'>Reinforcement Learning Drift Diffusion Model 6</h2><span id='topic+pstRT_rlddm6'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Probabilistic Selection Task (with RT data) using Reinforcement Learning Drift Diffusion Model 6.
It has the following parameters: <code>a</code> (boundary separation), <code>bp</code> (boundary separation power), <code>tau</code> (non-decision time), <code>v</code> (drift rate scaling), <code>alpha_pos</code> (learning rate for positive prediction error), <code>alpha_neg</code> (learning rate for negative prediction error).
</p>

<ul>
<li> <p><strong>Task</strong>: Probabilistic Selection Task (with RT data) (Frank et al., 2007; Frank et al., 2004)
</p>
</li>
<li> <p><strong>Model</strong>: Reinforcement Learning Drift Diffusion Model 6 (Pedersen et al., 2017)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>pstRT_rlddm6(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pstRT_rlddm6_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;iter&quot;, &quot;cond&quot;, &quot;prob&quot;, &quot;choice&quot;, &quot;RT&quot;, &quot;feedback&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
For this model they are: &quot;Q1&quot;, &quot;Q2&quot;.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;choice_os&quot;, &quot;RT_os&quot;, &quot;choice_sm&quot;, &quot;RT_sm&quot;, &quot;fd_sm&quot;</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="pstRT_rlddm6_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>RTbound</dt><dd><p>Floating point value representing the lower bound (i.e., minimum allowed) reaction time. Defaults to 0.1 (100 milliseconds).</p>
</dd>
<dt>initQ</dt><dd><p>Floating point value representing the model's initial value of any choice.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Probabilistic Selection Task (with RT data), there should be 7 columns of data with the
labels &quot;subjID&quot;, &quot;iter&quot;, &quot;cond&quot;, &quot;prob&quot;, &quot;choice&quot;, &quot;RT&quot;, &quot;feedback&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>iter</dt><dd><p>Integer value representing the trial number for each task condition.</p>
</dd>
<dt>cond</dt><dd><p>Integer value representing the task condition of the given trial (AB == 1, CD == 2, EF == 3).</p>
</dd>
<dt>prob</dt><dd><p>Float value representing the probability that a correct response (1) is rewarded in the current task condition.</p>
</dd>
<dt>choice</dt><dd><p>Integer value representing the option chosen on the given trial (1 or 2).</p>
</dd>
<dt>RT</dt><dd><p>Float value representing the time taken for the response on the given trial.</p>
</dd>
<dt>feedback</dt><dd><p>Integer value representing the outcome of the given trial (where 'correct' == 1, and 'incorrect' == 0).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://hydoh.github.io/">Hoyoung Doh</a> &lt;<a href="mailto:hoyoung.doh@gmail.com">hoyoung.doh@gmail.com</a>&gt;, <a href="https://medicine.yale.edu/lab/goldfarb/profile/sanghoon_kang/">Sanghoon Kang</a> &lt;<a href="mailto:sanghoon.kang@yale.edu">sanghoon.kang@yale.edu</a>&gt;, <a href="https://jihyuncindyhur.github.io/">Jihyun K. Hur</a> &lt;<a href="mailto:jihyun.hur@yale.edu">jihyun.hur@yale.edu</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;pstRT_rlddm6&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Frank, M. J., Santamaria, A., O'Reilly, R. C., &amp; Willcutt, E. (2007). Testing computational models of dopamine and noradrenaline dysfunction in attention deficit/hyperactivity disorder. Neuropsychopharmacology, 32(7), 1583-1599.
</p>
<p>Frank, M. J., Seeberger, L. C., &amp; O'reilly, R. C. (2004). By carrot or by stick: cognitive reinforcement learning in parkinsonism. Science, 306(5703), 1940-1943.
</p>
<p>Pedersen, M. L., Frank, M. J., &amp; Biele, G. (2017). The drift diffusion model as the choice rule in reinforcement learning. Psychonomic bulletin &amp; review, 24(4), 1234-1251.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- pstRT_rlddm6(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- pstRT_rlddm6(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='ra_noLA'>Prospect Theory, without loss aversion (LA) parameter</h2><span id='topic+ra_noLA'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Risk Aversion Task using Prospect Theory, without loss aversion (LA) parameter.
It has the following parameters: <code>rho</code> (risk aversion), <code>tau</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Risk Aversion Task 
</p>
</li>
<li> <p><strong>Model</strong>: Prospect Theory, without loss aversion (LA) parameter (Sokol-Hessner et al., 2009)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ra_noLA(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ra_noLA_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;gain&quot;, &quot;loss&quot;, &quot;cert&quot;, &quot;gamble&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_noLA_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Risk Aversion Task, there should be 5 columns of data with the
labels &quot;subjID&quot;, &quot;gain&quot;, &quot;loss&quot;, &quot;cert&quot;, &quot;gamble&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>gain</dt><dd><p>Possible (50%) gain outcome of a risky option (e.g. 9).</p>
</dd>
<dt>loss</dt><dd><p>Possible (50%) loss outcome of a risky option (e.g. 5, or -5).</p>
</dd>
<dt>cert</dt><dd><p>Guaranteed amount of a safe option. &quot;cert&quot; is assumed to be zero or greater than zero.</p>
</dd>
<dt>gamble</dt><dd><p>If gamble was taken, gamble == 1; else gamble == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;ra_noLA&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Sokol-Hessner, P., Hsu, M., Curley, N. G., Delgado, M. R., Camerer, C. F., Phelps, E. A., &amp; Smith, E. E. (2009). Thinking like a Trader Selectively Reduces Individuals' Loss Aversion. Proceedings of the National Academy of Sciences of the United States of America, 106(13), 5035-5040. https://www.pnas.org/content/106/13/5035
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- ra_noLA(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- ra_noLA(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='ra_noRA'>Prospect Theory, without risk aversion (RA) parameter</h2><span id='topic+ra_noRA'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Risk Aversion Task using Prospect Theory, without risk aversion (RA) parameter.
It has the following parameters: <code>lambda</code> (loss aversion), <code>tau</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Risk Aversion Task 
</p>
</li>
<li> <p><strong>Model</strong>: Prospect Theory, without risk aversion (RA) parameter (Sokol-Hessner et al., 2009)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ra_noRA(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ra_noRA_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;gain&quot;, &quot;loss&quot;, &quot;cert&quot;, &quot;gamble&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_noRA_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Risk Aversion Task, there should be 5 columns of data with the
labels &quot;subjID&quot;, &quot;gain&quot;, &quot;loss&quot;, &quot;cert&quot;, &quot;gamble&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>gain</dt><dd><p>Possible (50%) gain outcome of a risky option (e.g. 9).</p>
</dd>
<dt>loss</dt><dd><p>Possible (50%) loss outcome of a risky option (e.g. 5, or -5).</p>
</dd>
<dt>cert</dt><dd><p>Guaranteed amount of a safe option. &quot;cert&quot; is assumed to be zero or greater than zero.</p>
</dd>
<dt>gamble</dt><dd><p>If gamble was taken, gamble == 1; else gamble == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;ra_noRA&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Sokol-Hessner, P., Hsu, M., Curley, N. G., Delgado, M. R., Camerer, C. F., Phelps, E. A., &amp; Smith, E. E. (2009). Thinking like a Trader Selectively Reduces Individuals' Loss Aversion. Proceedings of the National Academy of Sciences of the United States of America, 106(13), 5035-5040. https://www.pnas.org/content/106/13/5035
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- ra_noRA(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- ra_noRA(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='ra_prospect'>Prospect Theory</h2><span id='topic+ra_prospect'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Risk Aversion Task using Prospect Theory.
It has the following parameters: <code>rho</code> (risk aversion), <code>lambda</code> (loss aversion), <code>tau</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Risk Aversion Task 
</p>
</li>
<li> <p><strong>Model</strong>: Prospect Theory (Sokol-Hessner et al., 2009)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ra_prospect(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ra_prospect_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;gain&quot;, &quot;loss&quot;, &quot;cert&quot;, &quot;gamble&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ra_prospect_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Risk Aversion Task, there should be 5 columns of data with the
labels &quot;subjID&quot;, &quot;gain&quot;, &quot;loss&quot;, &quot;cert&quot;, &quot;gamble&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>gain</dt><dd><p>Possible (50%) gain outcome of a risky option (e.g. 9).</p>
</dd>
<dt>loss</dt><dd><p>Possible (50%) loss outcome of a risky option (e.g. 5, or -5).</p>
</dd>
<dt>cert</dt><dd><p>Guaranteed amount of a safe option. &quot;cert&quot; is assumed to be zero or greater than zero.</p>
</dd>
<dt>gamble</dt><dd><p>If gamble was taken, gamble == 1; else gamble == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;ra_prospect&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Sokol-Hessner, P., Hsu, M., Curley, N. G., Delgado, M. R., Camerer, C. F., Phelps, E. A., &amp; Smith, E. E. (2009). Thinking like a Trader Selectively Reduces Individuals' Loss Aversion. Proceedings of the National Academy of Sciences of the United States of America, 106(13), 5035-5040. https://www.pnas.org/content/106/13/5035
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- ra_prospect(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- ra_prospect(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='rdt_happiness'>Happiness Computational Model</h2><span id='topic+rdt_happiness'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Risky Decision Task using Happiness Computational Model.
It has the following parameters: <code>w0</code> (baseline), <code>w1</code> (weight of certain rewards), <code>w2</code> (weight of expected values), <code>w3</code> (weight of reward prediction errors), <code>gam</code> (forgetting factor), <code>sig</code> (standard deviation of error).
</p>

<ul>
<li> <p><strong>Task</strong>: Risky Decision Task 
</p>
</li>
<li> <p><strong>Model</strong>: Happiness Computational Model (Rutledge et al., 2014)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>rdt_happiness(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rdt_happiness_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;gain&quot;, &quot;loss&quot;, &quot;cert&quot;, &quot;type&quot;, &quot;gamble&quot;, &quot;outcome&quot;, &quot;happy&quot;, &quot;RT_happy&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="rdt_happiness_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Risky Decision Task, there should be 9 columns of data with the
labels &quot;subjID&quot;, &quot;gain&quot;, &quot;loss&quot;, &quot;cert&quot;, &quot;type&quot;, &quot;gamble&quot;, &quot;outcome&quot;, &quot;happy&quot;, &quot;RT_happy&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>gain</dt><dd><p>Possible (50%) gain outcome of a risky option (e.g. 9).</p>
</dd>
<dt>loss</dt><dd><p>Possible (50%) loss outcome of a risky option (e.g. 5, or -5).</p>
</dd>
<dt>cert</dt><dd><p>Guaranteed amount of a safe option.</p>
</dd>
<dt>type</dt><dd><p>loss == -1, mixed == 0, gain == 1</p>
</dd>
<dt>gamble</dt><dd><p>If gamble was taken, gamble == 1; else gamble == 0.</p>
</dd>
<dt>outcome</dt><dd><p>Result of the trial.</p>
</dd>
<dt>happy</dt><dd><p>Happiness score.</p>
</dd>
<dt>RT_happy</dt><dd><p>Reaction time for answering the happiness score.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;rdt_happiness&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Rutledge, R. B., Skandali, N., Dayan, P., &amp; Dolan, R. J. (2014). A computational and neural model of momentary subjective well-being. Proceedings of the National Academy of Sciences, 111(33), 12252-12257.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- rdt_happiness(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- rdt_happiness(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='rhat'>Function for extracting Rhat values from an hBayesDM object</h2><span id='topic+rhat'></span>

<h3>Description</h3>

<p>A convenience function for extracting Rhat values from an hBayesDM object. Can also
check if all Rhat values are less than or equal to a specified value.
If variational inference was used, an error message will be displayed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhat(fit = NULL, less = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rhat_+3A_fit">fit</code></td>
<td>
<p>Model output of class <code>hBayesDM</code></p>
</td></tr>
<tr><td><code id="rhat_+3A_less">less</code></td>
<td>
<p>A numeric value specifying how to check Rhat values. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>'less'</code> is specified, then <code>rhat(fit, less)</code> will return <code>TRUE</code> if all Rhat values are
less than or equal to <code>'less'</code>. If any values are greater than <code>'less'</code>, <code>rhat(fit, less)</code> will
return <code>FALSE</code>. If <code>'less'</code> is left unspecified (NULL), <code>rhat(fit)</code> will return a <code>data.frame</code> object
containing all Rhat values.
</p>

<hr>
<h2 id='task2AFC_sdt'>Signal detection theory model</h2><span id='topic+task2AFC_sdt'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the 2-alternative forced choice task using Signal detection theory model.
It has the following parameters: <code>d</code> (discriminability), <code>c</code> (decision bias (criteria)).
</p>

<ul>
<li> <p><strong>Task</strong>: 2-alternative forced choice task 
</p>
</li>
<li> <p><strong>Model</strong>: Signal detection theory model 
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>task2AFC_sdt(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="task2AFC_sdt_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;stimulus&quot;, &quot;response&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="task2AFC_sdt_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the 2-alternative forced choice task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;stimulus&quot;, &quot;response&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>stimulus</dt><dd><p>Types of Stimuli (Should be 1 or 0. 1 for Signal and 0 for Noise)</p>
</dd>
<dt>response</dt><dd><p>Types of Responses (It should be same format as the stimulus field. Should be 1 or 0)</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://heesunpark26.github.io/">Heesun Park</a> &lt;<a href="mailto:heesunpark26@gmail.com">heesunpark26@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;task2AFC_sdt&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- task2AFC_sdt(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- task2AFC_sdt(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='ts_par4'>Hybrid Model, with 4 parameters</h2><span id='topic+ts_par4'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Two-Step Task using Hybrid Model, with 4 parameters.
It has the following parameters: <code>a</code> (learning rate for both stages 1 &amp; 2), <code>beta</code> (inverse temperature for both stages 1 &amp; 2), <code>pi</code> (perseverance), <code>w</code> (model-based weight).
</p>

<ul>
<li> <p><strong>Task</strong>: Two-Step Task (Daw et al., 2011)
</p>
</li>
<li> <p><strong>Model</strong>: Hybrid Model, with 4 parameters (Daw et al., 2011; Wunderlich et al., 2012)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ts_par4(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ts_par4_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;level1_choice&quot;, &quot;level2_choice&quot;, &quot;reward&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred_step1&quot;, &quot;y_pred_step2&quot;</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par4_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>trans_prob</dt><dd><p>Common state transition probability from Stage (Level) 1 to Stage (Level) 2. Defaults to 0.7.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Two-Step Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;level1_choice&quot;, &quot;level2_choice&quot;, &quot;reward&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>level1_choice</dt><dd><p>Choice made for Level (Stage) 1 (1: stimulus 1, 2: stimulus 2).</p>
</dd>
<dt>level2_choice</dt><dd><p>Choice made for Level (Stage) 2 (1: stimulus 3, 2: stimulus 4, 3: stimulus 5, 4: stimulus 6).<br />        Note that, in our notation, choosing stimulus 1 in Level 1 leads to stimulus 3 &amp; 4 in Level 2 with a common (0.7 by default) transition. Similarly, choosing stimulus 2 in Level 1 leads to stimulus 5 &amp; 6 in Level 2 with a common (0.7 by default) transition. To change this default transition probability, set the function argument 'trans_prob' to your preferred value.</p>
</dd>
<dt>reward</dt><dd><p>Reward after Level 2 (0 or 1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;ts_par4&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Daw, N. D., Gershman, S. J., Seymour, B., Ben Seymour, Dayan, P., &amp; Dolan, R. J. (2011). Model-Based Influences on Humans' Choices and Striatal Prediction Errors. Neuron, 69(6), 1204-1215. https://doi.org/10.1016/j.neuron.2011.02.027
</p>
<p>Daw, N. D., Gershman, S. J., Seymour, B., Ben Seymour, Dayan, P., &amp; Dolan, R. J. (2011). Model-Based Influences on Humans' Choices and Striatal Prediction Errors. Neuron, 69(6), 1204-1215. https://doi.org/10.1016/j.neuron.2011.02.027
</p>
<p>Wunderlich, K., Smittenaar, P., &amp; Dolan, R. J. (2012). Dopamine enhances model-based over model-free choice behavior. Neuron, 75(3), 418-424.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- ts_par4(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- ts_par4(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='ts_par6'>Hybrid Model, with 6 parameters</h2><span id='topic+ts_par6'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Two-Step Task using Hybrid Model, with 6 parameters.
It has the following parameters: <code>a1</code> (learning rate in stage 1), <code>beta1</code> (inverse temperature in stage 1), <code>a2</code> (learning rate in stage 2), <code>beta2</code> (inverse temperature in stage 2), <code>pi</code> (perseverance), <code>w</code> (model-based weight).
</p>

<ul>
<li> <p><strong>Task</strong>: Two-Step Task (Daw et al., 2011)
</p>
</li>
<li> <p><strong>Model</strong>: Hybrid Model, with 6 parameters (Daw et al., 2011)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ts_par6(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ts_par6_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;level1_choice&quot;, &quot;level2_choice&quot;, &quot;reward&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred_step1&quot;, &quot;y_pred_step2&quot;</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par6_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>trans_prob</dt><dd><p>Common state transition probability from Stage (Level) 1 to Stage (Level) 2. Defaults to 0.7.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Two-Step Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;level1_choice&quot;, &quot;level2_choice&quot;, &quot;reward&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>level1_choice</dt><dd><p>Choice made for Level (Stage) 1 (1: stimulus 1, 2: stimulus 2).</p>
</dd>
<dt>level2_choice</dt><dd><p>Choice made for Level (Stage) 2 (1: stimulus 3, 2: stimulus 4, 3: stimulus 5, 4: stimulus 6).<br />        Note that, in our notation, choosing stimulus 1 in Level 1 leads to stimulus 3 &amp; 4 in Level 2 with a common (0.7 by default) transition. Similarly, choosing stimulus 2 in Level 1 leads to stimulus 5 &amp; 6 in Level 2 with a common (0.7 by default) transition. To change this default transition probability, set the function argument 'trans_prob' to your preferred value.</p>
</dd>
<dt>reward</dt><dd><p>Reward after Level 2 (0 or 1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;ts_par6&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Daw, N. D., Gershman, S. J., Seymour, B., Ben Seymour, Dayan, P., &amp; Dolan, R. J. (2011). Model-Based Influences on Humans' Choices and Striatal Prediction Errors. Neuron, 69(6), 1204-1215. https://doi.org/10.1016/j.neuron.2011.02.027
</p>
<p>Daw, N. D., Gershman, S. J., Seymour, B., Ben Seymour, Dayan, P., &amp; Dolan, R. J. (2011). Model-Based Influences on Humans' Choices and Striatal Prediction Errors. Neuron, 69(6), 1204-1215. https://doi.org/10.1016/j.neuron.2011.02.027
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- ts_par6(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- ts_par6(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='ts_par7'>Hybrid Model, with 7 parameters (original model)</h2><span id='topic+ts_par7'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Two-Step Task using Hybrid Model, with 7 parameters (original model).
It has the following parameters: <code>a1</code> (learning rate in stage 1), <code>beta1</code> (inverse temperature in stage 1), <code>a2</code> (learning rate in stage 2), <code>beta2</code> (inverse temperature in stage 2), <code>pi</code> (perseverance), <code>w</code> (model-based weight), <code>lambda</code> (eligibility trace).
</p>

<ul>
<li> <p><strong>Task</strong>: Two-Step Task (Daw et al., 2011)
</p>
</li>
<li> <p><strong>Model</strong>: Hybrid Model, with 7 parameters (original model) (Daw et al., 2011)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ts_par7(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ts_par7_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;level1_choice&quot;, &quot;level2_choice&quot;, &quot;reward&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred_step1&quot;, &quot;y_pred_step2&quot;</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ts_par7_+3A_...">...</code></td>
<td>
<p>For this model, it's possible to set <strong>model-specific argument(s)</strong> as follows: 
</p>

<dl>
<dt>trans_prob</dt><dd><p>Common state transition probability from Stage (Level) 1 to Stage (Level) 2. Defaults to 0.7.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Two-Step Task, there should be 4 columns of data with the
labels &quot;subjID&quot;, &quot;level1_choice&quot;, &quot;level2_choice&quot;, &quot;reward&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>level1_choice</dt><dd><p>Choice made for Level (Stage) 1 (1: stimulus 1, 2: stimulus 2).</p>
</dd>
<dt>level2_choice</dt><dd><p>Choice made for Level (Stage) 2 (1: stimulus 3, 2: stimulus 4, 3: stimulus 5, 4: stimulus 6).<br />        Note that, in our notation, choosing stimulus 1 in Level 1 leads to stimulus 3 &amp; 4 in Level 2 with a common (0.7 by default) transition. Similarly, choosing stimulus 2 in Level 1 leads to stimulus 5 &amp; 6 in Level 2 with a common (0.7 by default) transition. To change this default transition probability, set the function argument 'trans_prob' to your preferred value.</p>
</dd>
<dt>reward</dt><dd><p>Reward after Level 2 (0 or 1).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/harhim-park/">Harhim Park</a> &lt;<a href="mailto:hrpark12@gmail.com">hrpark12@gmail.com</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;ts_par7&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Daw, N. D., Gershman, S. J., Seymour, B., Ben Seymour, Dayan, P., &amp; Dolan, R. J. (2011). Model-Based Influences on Humans' Choices and Striatal Prediction Errors. Neuron, 69(6), 1204-1215. https://doi.org/10.1016/j.neuron.2011.02.027
</p>
<p>Daw, N. D., Gershman, S. J., Seymour, B., Ben Seymour, Dayan, P., &amp; Dolan, R. J. (2011). Model-Based Influences on Humans' Choices and Striatal Prediction Errors. Neuron, 69(6), 1204-1215. https://doi.org/10.1016/j.neuron.2011.02.027
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- ts_par7(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- ts_par7(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='ug_bayes'>Ideal Observer Model</h2><span id='topic+ug_bayes'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Norm-Training Ultimatum Game using Ideal Observer Model.
It has the following parameters: <code>alpha</code> (envy), <code>beta</code> (guilt), <code>tau</code> (inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Norm-Training Ultimatum Game 
</p>
</li>
<li> <p><strong>Model</strong>: Ideal Observer Model (Xiang et al., 2013)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ug_bayes(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ug_bayes_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;offer&quot;, &quot;accept&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ug_bayes_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Norm-Training Ultimatum Game, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;offer&quot;, &quot;accept&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>offer</dt><dd><p>Floating point value representing the offer made in that trial (e.g. 4, 10, 11).</p>
</dd>
<dt>accept</dt><dd><p>1 or 0, indicating whether the offer was accepted in that trial (where accepted == 1, rejected == 0).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;ug_bayes&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Xiang, T., Lohrenz, T., &amp; Montague, P. R. (2013). Computational Substrates of Norms and Their Violations during Social Exchange. Journal of Neuroscience, 33(3), 1099-1108. https://doi.org/10.1523/JNEUROSCI.1642-12.2013
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- ug_bayes(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- ug_bayes(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='ug_delta'>Rescorla-Wagner (Delta) Model</h2><span id='topic+ug_delta'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Norm-Training Ultimatum Game using Rescorla-Wagner (Delta) Model.
It has the following parameters: <code>alpha</code> (envy), <code>tau</code> (inverse temperature), <code>ep</code> (norm adaptation rate).
</p>

<ul>
<li> <p><strong>Task</strong>: Norm-Training Ultimatum Game 
</p>
</li>
<li> <p><strong>Model</strong>: Rescorla-Wagner (Delta) Model (Gu et al., 2015)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ug_delta(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ug_delta_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;offer&quot;, &quot;accept&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="ug_delta_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Norm-Training Ultimatum Game, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;offer&quot;, &quot;accept&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>offer</dt><dd><p>Floating point value representing the offer made in that trial (e.g. 4, 10, 11).</p>
</dd>
<dt>accept</dt><dd><p>1 or 0, indicating whether the offer was accepted in that trial (where accepted == 1, rejected == 0).</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;ug_delta&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Gu, X., Wang, X., Hula, A., Wang, S., Xu, S., Lohrenz, T. M., et al. (2015). Necessary, Yet Dissociable Contributions of the Insular and Ventromedial Prefrontal Cortices to Norm Adaptation: Computational and Lesion Evidence in Humans. Journal of Neuroscience, 35(2), 467-473. https://doi.org/10.1523/JNEUROSCI.2906-14.2015
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- ug_delta(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- ug_delta(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

<hr>
<h2 id='wcs_sql'>Sequential Learning Model</h2><span id='topic+wcs_sql'></span>

<h3>Description</h3>

<p>Hierarchical Bayesian Modeling of the Wisconsin Card Sorting Task using Sequential Learning Model.
It has the following parameters: <code>r</code> (reward sensitivity), <code>p</code> (punishment sensitivity), <code>d</code> (decision consistency or inverse temperature).
</p>

<ul>
<li> <p><strong>Task</strong>: Wisconsin Card Sorting Task 
</p>
</li>
<li> <p><strong>Model</strong>: Sequential Learning Model (Bishara et al., 2010)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>wcs_sql(
  data = NULL,
  niter = 4000,
  nwarmup = 1000,
  nchain = 4,
  ncore = 1,
  nthin = 1,
  inits = "vb",
  indPars = "mean",
  modelRegressor = FALSE,
  vb = FALSE,
  inc_postpred = FALSE,
  adapt_delta = 0.95,
  stepsize = 1,
  max_treedepth = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wcs_sql_+3A_data">data</code></td>
<td>
<p>Data to be modeled. It should be given as a data.frame object,
a filepath for a tab-seperated txt file, <code>"example"</code> to use example data, or
<code>"choose"</code> to choose data with an interactive window.
Columns in the dataset must include:
&quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. See <b>Details</b> below for more information.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_niter">niter</code></td>
<td>
<p>Number of iterations, including warm-up. Defaults to 4000.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_nwarmup">nwarmup</code></td>
<td>
<p>Number of iterations used for warm-up only. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_nchain">nchain</code></td>
<td>
<p>Number of Markov chains to run. Defaults to 4.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_ncore">ncore</code></td>
<td>
<p>Number of CPUs to be used for running. Defaults to 1.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_nthin">nthin</code></td>
<td>
<p>Every <code>i == nthin</code> sample will be used to generate the posterior distribution.
Defaults to 1. A higher number can be used when auto-correlation within the MCMC sampling is
high.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_inits">inits</code></td>
<td>
<p>Character value specifying how the initial values should be generated.
Possible options are &quot;vb&quot; (default), &quot;fixed&quot;, &quot;random&quot;, or your own initial values.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_indpars">indPars</code></td>
<td>
<p>Character value specifying how to summarize individual parameters. Current options
are: &quot;mean&quot;, &quot;median&quot;, or &quot;mode&quot;.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_modelregressor">modelRegressor</code></td>
<td>
<p>Whether to export model-based regressors (<code>TRUE</code> or <code>FALSE</code>).
Not available for this model.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_vb">vb</code></td>
<td>
<p>Use variational inference to approximately draw from a posterior distribution. Defaults
to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_inc_postpred">inc_postpred</code></td>
<td>
<p>Include trial-level posterior predictive simulations in model output (may greatly increase file
size). Defaults to <code>FALSE</code>.
If set to <code>TRUE</code>, it includes: &quot;y_pred&quot;</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_adapt_delta">adapt_delta</code></td>
<td>
<p>Floating point value representing the target acceptance probability of a new
sample in the MCMC chain. Must be between 0 and 1. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_stepsize">stepsize</code></td>
<td>
<p>Integer value specifying the size of each leapfrog step that the MCMC sampler can
take on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_max_treedepth">max_treedepth</code></td>
<td>
<p>Integer value specifying how many leapfrog steps the MCMC sampler can take
on each new iteration. See <b>Details</b> below.</p>
</td></tr>
<tr><td><code id="wcs_sql_+3A_...">...</code></td>
<td>
<p>For this model, there is no model-specific argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section describes some of the function arguments in greater detail.
</p>
<p><strong>data</strong> should be assigned a character value specifying the full path and name (including
extension information, e.g. &quot;.txt&quot;) of the file that contains the behavioral data-set of all
subjects of interest for the current analysis. The file should be a <strong>tab-delimited</strong> text
file, whose rows represent trial-by-trial observations and columns represent variables.<br />
For the Wisconsin Card Sorting Task, there should be 3 columns of data with the
labels &quot;subjID&quot;, &quot;choice&quot;, &quot;outcome&quot;. It is not necessary for the columns to be in this particular order,
however it is necessary that they be labeled correctly and contain the information below:
</p>

<dl>
<dt>subjID</dt><dd><p>A unique identifier for each subject in the data-set.</p>
</dd>
<dt>choice</dt><dd><p>Integer value indicating which deck was chosen on that trial: 1, 2, 3, or 4.</p>
</dd>
<dt>outcome</dt><dd><p>1 or 0, indicating the outcome of that trial: correct == 1, wrong == 0.</p>
</dd>
</dl>

<p><strong>*</strong>Note: The file may contain other columns of data (e.g. &quot;ReactionTime&quot;, &quot;trial_number&quot;,
etc.), but only the data within the column names listed above will be used during the modeling.
As long as the necessary columns mentioned above are present and labeled correctly, there is no
need to remove other miscellaneous data columns.
</p>
<p><strong>nwarmup</strong> is a numerical value that specifies how many MCMC samples should not be stored
upon the beginning of each chain. For those familiar with Bayesian methods, this is equivalent
to burn-in samples. Due to the nature of the MCMC algorithm, initial values (i.e. where the
sampling chains begin) can have a heavy influence on the generated posterior distributions. The
<code>nwarmup</code> argument can be set to a high number in order to curb the effects that initial
values have on the resulting posteriors.
</p>
<p><strong>nchain</strong> is a numerical value that specifies how many chains (i.e. independent sampling
sequences) should be used to draw samples from the posterior distribution. Since the posteriors
are generated from a sampling process, it is good practice to run multiple chains to ensure
that a reasonably representative posterior is attained. When the sampling is complete, it is
possible to check the multiple chains for convergence by running the following line of code:
<code>plot(output, type = "trace")</code>. The trace-plot should resemble a &quot;furry caterpillar&quot;.
</p>
<p><strong>nthin</strong> is a numerical value that specifies the &quot;skipping&quot; behavior of the MCMC sampler,
using only every <code>i == nthin</code> samples to generate posterior distributions. By default,
<code>nthin</code> is equal to 1, meaning that every sample is used to generate the posterior.
</p>
<p><strong>Control Parameters:</strong> <code>adapt_delta</code>, <code>stepsize</code>, and <code>max_treedepth</code> are
advanced options that give the user more control over Stan's MCMC sampler. It is recommended
that only advanced users change the default values, as alterations can profoundly change the
sampler's behavior. Refer to 'The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo (Hoffman &amp; Gelman, 2014, Journal of Machine Learning Research)' for
more information on the sampler control parameters. One can also refer to 'Section 34.2. HMC
Algorithm Parameters' of the <a href="https://mc-stan.org/users/documentation/">Stan User's Guide
and Reference Manual</a>, or to the help page for <code><a href="rstan.html#topic+stan">stan</a></code> for a less technical
description of these arguments.
</p>


<h4>Contributors</h4>

<p><a href="https://ccs-lab.github.io/team/dayeong-min/">Dayeong Min</a> &lt;<a href="mailto:mindy2801@snu.ac.kr">mindy2801@snu.ac.kr</a>&gt;</p>



<h3>Value</h3>

<p>A class &quot;hBayesDM&quot; object <code>modelData</code> with the following components:
</p>

<dl>
<dt>model</dt><dd><p>Character value that is the name of the model (\code&quot;wcs_sql&quot;).</p>
</dd>
<dt>allIndPars</dt><dd><p>Data.frame containing the summarized parameter values (as specified by
<code>indPars</code>) for each subject.</p>
</dd>
<dt>parVals</dt><dd><p>List object containing the posterior samples over different parameters.</p>
</dd>
<dt>fit</dt><dd><p>A class <code><a href="rstan.html#topic+stanfit">stanfit</a></code> object that contains the fitted Stan
model.</p>
</dd>
<dt>rawdata</dt><dd><p>Data.frame containing the raw data used to fit the model, as specified by
the user.</p>
</dd>
<dt>modelRegressor</dt><dd><p>List object containing the extracted model-based regressors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bishara, A. J., Kruschke, J. K., Stout, J. C., Bechara, A., McCabe, D. P., &amp; Busemeyer, J. R. (2010). Sequential learning models for the Wisconsin card sort task: Assessing processes in substance dependent individuals. Journal of Mathematical Psychology, 54(1), 5-13.
</p>


<h3>See Also</h3>

<p>We refer users to our in-depth tutorial for an example of using hBayesDM:
<a href="https://rpubs.com/CCSL/hBayesDM">https://rpubs.com/CCSL/hBayesDM</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run the model with a given data.frame as df
output &lt;- wcs_sql(
  data = df, niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Run the model with example data
output &lt;- wcs_sql(
  data = "example", niter = 2000, nwarmup = 1000, nchain = 4, ncore = 4)

# Visually check convergence of the sampling chains (should look like 'hairy caterpillars')
plot(output, type = "trace")

# Check Rhat values (all Rhat values should be less than or equal to 1.1)
rhat(output)

# Plot the posterior distributions of the hyper-parameters (distributions should be unimodal)
plot(output)

# Show the WAIC and LOOIC model fit estimates
printFit(output)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
