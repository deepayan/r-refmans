<!DOCTYPE html><html><head><title>Help for package BayesTreePrior</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BayesTreePrior}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BayesTreePrior'><p>Simulation of the tree prior.</p></a></li>
<li><a href='#BayesTreePriorNotOrthogonal'><p>Simulation of the tree prior in the general case (Case #4).</p></a></li>
<li><a href='#BayesTreePriorOrthogonal'><p>Simulation of the tree prior in the case where we have one single variable (Case #3).</p></a></li>
<li><a href='#BayesTreePriorOrthogonalInf'><p>Simulation of the tree prior in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) (Case #2).</p></a></li>
<li><a href='#E_alpha'><p>Expected value of the number of bottom nodes in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) and <code class="reqn">\beta=0</code> (Case #1).</p></a></li>
<li><a href='#GetListUniqueSplits'><p>Unique splits that leads to children with more than <code class="reqn">minpart</code> nodes.</p></a></li>
<li><a href='#NumBotMaxDepth'><p>Number of bottom nodes and depth in the case where we have one single variable (Case #3).</p></a></li>
<li><a href='#NumBotMaxDepth_inf'><p>Number of bottom nodes and depth in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) (Case #2).</p></a></li>
<li><a href='#NumBotMaxDepthX'><p>Number of bottom nodes and depth in the general case (Case #4).</p></a></li>
<li><a href='#p_split'><p>Probability of split of the tree prior.</p></a></li>
<li><a href='#Var_alpha'><p>Variance of the number of bottom nodes in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) and <code class="reqn">\beta=0</code> (Case #1).</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Bayesian Tree Prior Simulation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-06-27</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexia Jolicoeur-Martineau &lt;alexia.jolicoeur-martineau@mail.mcgill.ca&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexia Jolicoeur-Martineau &lt;alexia.jolicoeur-martineau@mail.mcgill.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a way to simulate from the prior distribution of Bayesian trees by Chipman et al. (1998) &lt;<a href="https://doi.org/10.2307%2F2669832">doi:10.2307/2669832</a>&gt;. The prior distribution of Bayesian trees is highly dependent on the design matrix X, therefore using the suggested hyperparameters by Chipman et al. (1998) &lt;<a href="https://doi.org/10.2307%2F2669832">doi:10.2307/2669832</a>&gt; is not recommended and could lead to unexpected prior distribution. This work is part of my master thesis (expected 2016).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>tgp, BayesTree, bartMachine, MASS</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-06-27 17:38:55 UTC; Emiaz</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-07-04 20:28:58</td>
</tr>
</table>
<hr>
<h2 id='BayesTreePrior'>Simulation of the tree prior.</h2><span id='topic+BayesTreePrior'></span>

<h3>Description</h3>

<p>This is the main function to use for simulating from the prior. There are 4 cases : 
</p>

<ul>
<li><p>Case #1: Unrealistic case where we assume that the number of variables and possible splits are infinite (therefore <code class="reqn">P(T)</code> is not dependent on the design matrix X) and <code class="reqn">\beta=0</code>
</p>
</li>
<li><p>Case #2: Unrealistic case where we assume that the number of variables and possible splits are infinite (therefore <code class="reqn">P(T)</code> is not dependent on the design matrix X)
</p>
</li>
<li><p>Case #3: One variable with a finite number of observations (Seems to be equivalent to the multiple variables case when all variables are continuous)
</p>
</li>
<li><p>Case #4: General case
</p>
</li></ul>

<p>Case #1 will be used if no design matrix X or number of observations is given and <code class="reqn">\beta = 0</code>. Case #2 will be used if no design matrix X or number of observations is given and <code class="reqn">\beta \neq 0</code>. Case #3 will be used if no design matrix X is given but the number of observations is given. Case #4 will be used if the design matrix X is given. Note that case #4 is always slower, so if all your variables are continuous, it would be advisable to enter the number of uniques observations rather than the design matrix X, to be able to use case #3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesTreePrior(alpha, beta, X = NULL, n_obs = NULL, n_iter = 500,
  minpart = 1, package = NULL, pvars = NULL, MIA = FALSE,
  missingdummy = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BayesTreePrior_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_beta">beta</code></td>
<td>
<p>power parameter of the tree prior, <code class="reqn">\beta \geq 0</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_x">X</code></td>
<td>
<p>data.frame of the design matrix (Required for case #4).</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_n_obs">n_obs</code></td>
<td>
<p>number of unique observations, <code class="reqn">n_{obs}&gt;1</code> (Required for case #3).</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_n_iter">n_iter</code></td>
<td>
<p>number of trees to generate, <code class="reqn">n_{iter}&gt;0</code> (Used for case #2, #3 or #4).</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_minpart">minpart</code></td>
<td>
<p>the minimum number of observations required in one of the child to be able to split, <code class="reqn">minpart&gt;0</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_package">package</code></td>
<td>
<p>a optional string that can take the following values : &quot;BayesTree&quot;, &quot;tgp&quot; or &quot;bartMachine&quot;. It forces the algorithm to use the default paramameters used by the package specified (<code class="reqn">minpart=5</code> for BayesTree, <code class="reqn">minpart = max(c(10,dim(X)[2]+1))</code> for tgp and <code class="reqn">minpart=1</code> for bartMachine).</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_pvars">pvars</code></td>
<td>
<p>vector of probabilities for the choices of variables to split (Will automatically be normalized so that the sum equal to 1). It must be twice as large as the number of variables when <code class="reqn">missingdummy</code> is TRUE.</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_mia">MIA</code></td>
<td>
<p>set to TRUE if you want Missing Incorporated in Attributes (MIA) imputation to be used.</p>
</td></tr>
<tr><td><code id="BayesTreePrior_+3A_missingdummy">missingdummy</code></td>
<td>
<p>set to TRUE if you want the NAs to be dummy coded.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>In case #1, it returns a list containing, in the following order: the expectation and the variance of the number of bottom nodes. In cases #2, #3 or #4, it returns a list containing, in the following order: the mean number of bottom nodes, the standard deviation of the number of bottom nodes, the mean of the depth, the standard deviation of the depth and a data.frame of vectors <code class="reqn">(b_i,d_i)</code>, where <code class="reqn">b_i</code> is the number of bottom nodes and <code class="reqn">d_i</code> is the depth of the <code class="reqn">i</code>th generated tree (<code class="reqn">i=1, \ldots ,n_{iter}</code>).
</p>


<h3>References</h3>

<p>Chipman, H. A., George, E. I., &amp; McCulloch, R. E. (1998). <em>Bayesian CART model search.</em> Journal of the American Statistical Association, 93(443), 935-948.
</p>
<p>Gramacy, R. B. (2007). tgp: <em>an <span class="rlang"><b>R</b></span> package for Bayesian nonstationary, semiparametric nonlinear regression and design by treed Gaussian process models.</em> Journal of Statistical Software, 19(9), 6.
</p>
<p>Chipman, H. A., George, E. I., &amp; McCulloch, R. E. (2010). <em>BART: Bayesian additive regression trees.</em> The Annals of Applied Statistics, 266-298.
</p>
<p>Kapelner, A., &amp; Bleich, J. (2013). <em>bartMachine: A powerful tool for machine learning.</em> stat, 1050, 8.
</p>
<p>Twala, B. E. T. H., Jones, M. C., &amp; Hand, D. J. (2008). <em>Good methods for coping with missing data in decision trees.</em> Pattern Recognition Letters, 29(7), 950-956.
</p>
<p>Jolicoeur-Martineau, A. (expected 2016) <em>Etude d'une loi a priori pour les arbres binaires de regression</em> (<em>Study on the prior distribution of binary regression trees</em>) (Master thesis). UQAM university.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Case 1 : Unrealistic case where we assume that the number of var/obs is infinite and beta=0
results1 = BayesTreePrior(.45,0)
#Case 2 : Unrealistic case where we assume that the number of var/obs is infinite
results2 = BayesTreePrior(.95,.5)
#Case 3 : One variable with a finite number of observations
results3 = BayesTreePrior(.95,.5,n_obs=150)
if (requireNamespace("MASS", quietly = TRUE)) {
    #Case 4 : General case, without missing data
    x1 = MASS::mcycle$times
    x2= MASS::mcycle$accel
    X = cbind(x1, x2)
    results4_nomiss = BayesTreePrior(.95,.5, data.frame(X), minpart=5, package="tgp")
    #Case 4 : General case, with missing data
    x1[sample(1:length(x1), 20)] &lt;- NA
    x2[sample(1:length(x2), 20)] &lt;- NA
    X = cbind(x1, x2)
    results4_miss = BayesTreePrior(.95,.5, data.frame(X), minpart=5, package="tgp", 
    MIA=TRUE, missingdummy=TRUE)
}
</code></pre>

<hr>
<h2 id='BayesTreePriorNotOrthogonal'>Simulation of the tree prior in the general case (Case #4).</h2><span id='topic+BayesTreePriorNotOrthogonal'></span>

<h3>Description</h3>

<p>Generate <code class="reqn">n_{iter}</code> trees from the prior distribution in the general case (Case #4).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesTreePriorNotOrthogonal(alpha, beta, X, n_iter = 500, minpart = 1,
  pvars = NULL, MIA = FALSE, missingdummy = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BayesTreePriorNotOrthogonal_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorNotOrthogonal_+3A_beta">beta</code></td>
<td>
<p>power parameter of the tree prior, <code class="reqn">\beta \geq 0</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorNotOrthogonal_+3A_x">X</code></td>
<td>
<p>data.frame of the design matrix.</p>
</td></tr>
<tr><td><code id="BayesTreePriorNotOrthogonal_+3A_n_iter">n_iter</code></td>
<td>
<p>number of trees to generate, <code class="reqn">n_{iter}&gt;0</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorNotOrthogonal_+3A_minpart">minpart</code></td>
<td>
<p>the minimum number of observations required in one of the child to be able to split, <code class="reqn">minpart&gt;0</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorNotOrthogonal_+3A_pvars">pvars</code></td>
<td>
<p>vector of probabilities for the choices of variables to split (Will automatically be normalized so that the sum equal to 1). It must be twice as large as the number of variables when <code class="reqn">missingdummy</code> is TRUE.</p>
</td></tr>
<tr><td><code id="BayesTreePriorNotOrthogonal_+3A_mia">MIA</code></td>
<td>
<p>set to TRUE if you want Missing Incorporated in Attributes (MIA) imputation to be used.</p>
</td></tr>
<tr><td><code id="BayesTreePriorNotOrthogonal_+3A_missingdummy">missingdummy</code></td>
<td>
<p>set to TRUE if you have dummy coded the NAs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing, in the following order: the mean number of bottom nodes, the standard deviation of the number of bottom nodes, the mean of the depth, the standard deviation of the depth and a data.frame of vectors <code class="reqn">(b_i,d_i)</code>, where <code class="reqn">b_i</code> is the number of bottom nodes and <code class="reqn">d_i</code> is the depth of the <code class="reqn">i</code>th generated tree (<code class="reqn">i=1, \ldots ,n_{iter}</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BayesTreePriorOrthogonalInf">BayesTreePriorOrthogonalInf</a></code>, <code><a href="#topic+BayesTreePriorOrthogonal">BayesTreePriorOrthogonal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("MASS", quietly = TRUE)) {
    x1 = MASS::mcycle$times
    x1[sample(1:length(x1), 20)] &lt;- NA
    x2= MASS::mcycle$accel
    x2[sample(1:length(x2), 20)] &lt;- NA
    X = cbind(x1, x2)
    results1 = BayesTreePriorNotOrthogonal(.95,.5, data.frame(X), minpart=5)
    X_dummies = is.na(X) + 0
    results2 = BayesTreePriorNotOrthogonal(.95,.5, data.frame(cbind(X,X_dummies)), minpart=5, 
    MIA=TRUE, missingdummy=TRUE)
}
</code></pre>

<hr>
<h2 id='BayesTreePriorOrthogonal'>Simulation of the tree prior in the case where we have one single variable (Case #3).</h2><span id='topic+BayesTreePriorOrthogonal'></span>

<h3>Description</h3>

<p>Generate <code class="reqn">n_{iter}</code> trees from the prior distribution in the case where we have one variable with a finite number of observations (Case #3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesTreePriorOrthogonal(alpha, beta, n_obs, n_iter = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BayesTreePriorOrthogonal_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorOrthogonal_+3A_beta">beta</code></td>
<td>
<p>power parameter of the tree prior, <code class="reqn">beta \geq 0</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorOrthogonal_+3A_n_obs">n_obs</code></td>
<td>
<p>number of unique observations, <code class="reqn">n_{obs}&gt;1</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorOrthogonal_+3A_n_iter">n_iter</code></td>
<td>
<p>number of trees to generate, <code class="reqn">n_{iter}&gt;0</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing, in the following order: the mean number of bottom nodes, the standard deviation of the number of bottom nodes, the mean of the depth, the standard deviation of the depth and a data.frame of vectors <code class="reqn">(b_i,d_i)</code>, where <code class="reqn">b_i</code> is the number of bottom nodes and <code class="reqn">d_i</code> is the depth of the <code class="reqn">i</code>th generated tree (<code class="reqn">i=1, \ldots ,n_{iter}</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BayesTreePriorOrthogonalInf">BayesTreePriorOrthogonalInf</a></code>, <code><a href="#topic+BayesTreePriorNotOrthogonal">BayesTreePriorNotOrthogonal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>results1 = BayesTreePriorOrthogonal(.95,.5, 100)
results2 = BayesTreePriorOrthogonal(.95,.5, 250)
</code></pre>

<hr>
<h2 id='BayesTreePriorOrthogonalInf'>Simulation of the tree prior in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) (Case #2).</h2><span id='topic+BayesTreePriorOrthogonalInf'></span>

<h3>Description</h3>

<p>Generate <code class="reqn">n_{iter}</code> trees from the prior distribution in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) (Case #2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesTreePriorOrthogonalInf(alpha, beta, n_iter = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BayesTreePriorOrthogonalInf_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorOrthogonalInf_+3A_beta">beta</code></td>
<td>
<p>power parameter of the tree prior, <code class="reqn">beta \geq 0</code>.</p>
</td></tr>
<tr><td><code id="BayesTreePriorOrthogonalInf_+3A_n_iter">n_iter</code></td>
<td>
<p>number of trees to generate, <code class="reqn">n_{iter}&gt;0</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing, in the following order: the mean number of bottom nodes, the standard deviation of the number of bottom nodes, the mean of the depth, the standard deviation of the depth and a data.frame of vectors <code class="reqn">(b_i,d_i)</code>, where <code class="reqn">b_i</code> is the number of bottom nodes and <code class="reqn">d_i</code> is the depth of the <code class="reqn">i</code>th generated tree (<code class="reqn">i=1, \ldots ,n_{iter}</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BayesTreePriorOrthogonal">BayesTreePriorOrthogonal</a></code>, <code><a href="#topic+BayesTreePriorNotOrthogonal">BayesTreePriorNotOrthogonal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>results = BayesTreePriorOrthogonalInf(.95,.5)
</code></pre>

<hr>
<h2 id='E_alpha'>Expected value of the number of bottom nodes in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) and <code class="reqn">\beta=0</code> (Case #1).</h2><span id='topic+E_alpha'></span>

<h3>Description</h3>

<p>Expected value of the number of bottom nodes in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) and <code class="reqn">\beta=0</code> (Case #1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>E_alpha(alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="E_alpha_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">alpha \in [0,1)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the expected value of the number of bottom nodes.
</p>


<h3>References</h3>

<p>Jolicoeur-Martineau, A. (Currently in revision, expected 2016) <em>Etude d'une loi a priori pour les arbres binaires de regression</em> (<em>Study on the prior distribution of binary regression trees</em>) (Master thesis). UQAM university.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Var_alpha">Var_alpha</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>E_alpha(.30)
E_alpha(.45)
E_alpha(.499)
E_alpha(.75)
</code></pre>

<hr>
<h2 id='GetListUniqueSplits'>Unique splits that leads to children with more than <code class="reqn">minpart</code> nodes.</h2><span id='topic+GetListUniqueSplits'></span>

<h3>Description</h3>

<p>Unique splits that leads to children with more than <code class="reqn">minpart</code> nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetListUniqueSplits(x, minpart = 1, MIA = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetListUniqueSplits_+3A_x">x</code></td>
<td>
<p>vector containing the observations of a variable.</p>
</td></tr>
<tr><td><code id="GetListUniqueSplits_+3A_minpart">minpart</code></td>
<td>
<p>minimum number of observations in the children nodes.</p>
</td></tr>
<tr><td><code id="GetListUniqueSplits_+3A_mia">MIA</code></td>
<td>
<p>set to TRUE if you want Missing Incorporated in Attributes (MIA) imputation to be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code class="reqn">MIA</code> is TRUE and <code class="reqn">minpart&gt;1</code>, the possible splits could be different depending on whether we transfer the NAs to the left child or the right child; if this is the case then the function returns a list <code class="reqn">(v1,v2)</code>, where <code class="reqn">v1</code> is the vector containing the unique splits that leads to <code class="reqn">minpart</code> nodes when transferring the NAs to the left child and <code class="reqn">v2</code> is the vector containing the unique splits that leads to children with more than <code class="reqn">minpart</code> nodes when transferring the NAs to the left child. Otherwise, it returns the vector containing the unique splits that leads to children with more than <code class="reqn">minpart</code> nodes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>GetListUniqueSplits(c(1,4,7,3,0,2,2,3,4,7,7,7),minpart=1)
GetListUniqueSplits(c(1,4,7,3,0,2,2,3,4,7,7,7),minpart=3)
GetListUniqueSplits(c(1,4,7,3,0,2,2,3,4,7,7,7,NA,NA,NA),minpart=1, MIA=TRUE)
GetListUniqueSplits(c(1,4,7,3,0,2,2,3,4,7,7,7,NA,NA,NA),minpart=3, MIA=TRUE)
</code></pre>

<hr>
<h2 id='NumBotMaxDepth'>Number of bottom nodes and depth in the case where we have one single variable (Case #3).</h2><span id='topic+NumBotMaxDepth'></span>

<h3>Description</h3>

<p>Generate a tree and returns the number of bottom nodes and depth in the case where we have one variable with a finite number of observations (Case #3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NumBotMaxDepth(alpha, beta, x_size, depth = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NumBotMaxDepth_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepth_+3A_beta">beta</code></td>
<td>
<p>power parameter of the tree prior, <code class="reqn">beta \geq 0</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepth_+3A_x_size">x_size</code></td>
<td>
<p>number of possible splits, <code class="reqn">x_{size}&gt;0</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepth_+3A_depth">depth</code></td>
<td>
<p>depth of the current node, <code class="reqn">depth \geq 0</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector containing the number of bottom nodes and depth
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NumBotMaxDepth_inf">NumBotMaxDepth_inf</a></code>, <code><a href="#topic+NumBotMaxDepthX">NumBotMaxDepthX</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>NumBotMaxDepth(.95,.5,500)
</code></pre>

<hr>
<h2 id='NumBotMaxDepth_inf'>Number of bottom nodes and depth in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) (Case #2).</h2><span id='topic+NumBotMaxDepth_inf'></span>

<h3>Description</h3>

<p>Generate a tree and returns the number of bottom nodes and depth in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) (Case #2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NumBotMaxDepth_inf(alpha, beta, depth = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NumBotMaxDepth_inf_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepth_inf_+3A_beta">beta</code></td>
<td>
<p>power parameter of the tree prior, <code class="reqn">beta \geq 0</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepth_inf_+3A_depth">depth</code></td>
<td>
<p>depth of the current node, <code class="reqn">depth \geq 0</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector containing the number of bottom nodes and depth.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NumBotMaxDepth">NumBotMaxDepth</a></code>, <code><a href="#topic+NumBotMaxDepthX">NumBotMaxDepthX</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>NumBotMaxDepth_inf(.95,.5)
</code></pre>

<hr>
<h2 id='NumBotMaxDepthX'>Number of bottom nodes and depth in the general case (Case #4).</h2><span id='topic+NumBotMaxDepthX'></span>

<h3>Description</h3>

<p>Generate a tree and returns the number of bottom nodes and depth in the general case (Case #4).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NumBotMaxDepthX(alpha, beta, X, depth = 0, minpart = 1, pvars = NULL,
  MIA = FALSE, missingdummy = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NumBotMaxDepthX_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepthX_+3A_beta">beta</code></td>
<td>
<p>power parameter of the tree prior, <code class="reqn">beta \geq 0</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepthX_+3A_x">X</code></td>
<td>
<p>data.frame of the design matrix.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepthX_+3A_depth">depth</code></td>
<td>
<p>depth of the current node, <code class="reqn">depth \geq 0</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepthX_+3A_minpart">minpart</code></td>
<td>
<p>the minimum number of observations required in one of the child to be able to split, <code class="reqn">minpart&gt;0</code>.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepthX_+3A_pvars">pvars</code></td>
<td>
<p>vector of probabilities for the choices of variables to split (Will automatically be normalized so that the sum equal to 1). It must be twice as large as the number of variables when <code class="reqn">missingdummy</code> is TRUE.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepthX_+3A_mia">MIA</code></td>
<td>
<p>set to TRUE if you want Missing Incorporated in Attributes (MIA) imputation to be used.</p>
</td></tr>
<tr><td><code id="NumBotMaxDepthX_+3A_missingdummy">missingdummy</code></td>
<td>
<p>set to TRUE if you have dummy coded the NAs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector containing the number of bottom nodes and depth
</p>


<h3>References</h3>

<p>Twala, B. E. T. H., Jones, M. C., &amp; Hand, D. J. (2008). <em>Good methods for coping with missing data in decision trees.</em> Pattern Recognition Letters, 29(7), 950-956.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NumBotMaxDepth_inf">NumBotMaxDepth_inf</a></code>, <code><a href="#topic+NumBotMaxDepth">NumBotMaxDepth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("MASS", quietly = TRUE)) {
    x1 = MASS::mcycle$times
    x1[sample(1:length(x1), 20)] &lt;- NA
    x2= MASS::mcycle$accel
    x2[sample(1:length(x2), 20)] &lt;- NA
    X = cbind(x1, x2)
    results1 = NumBotMaxDepthX(.95,.5, data.frame(X), minpart=5)
    X_dummies = is.na(X) + 0
    results2 = NumBotMaxDepthX(.95,.5, data.frame(cbind(X,X_dummies)), minpart=5, MIA=TRUE, 
    missingdummy=TRUE)
}
</code></pre>

<hr>
<h2 id='p_split'>Probability of split of the tree prior.</h2><span id='topic+p_split'></span>

<h3>Description</h3>

<p>Probability of split of the tree prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p_split(alpha, beta, depth = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_split_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
<tr><td><code id="p_split_+3A_beta">beta</code></td>
<td>
<p>power parameter of the tree prior, <code class="reqn">\beta \geq 0</code>.</p>
</td></tr>
<tr><td><code id="p_split_+3A_depth">depth</code></td>
<td>
<p>depth of the current node, <code class="reqn">depth \geq 0</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the probability of split.
</p>


<h3>References</h3>

<p>Chipman, H. A., George, E. I. et McCulloch, R. E. (1998). Bayesian CART model search. Journal of the American Statistical Association, 93(443), 935-948.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p_split(.95,.5)
p_split(.95,.5,1)
p_split(.95,.5,2)
</code></pre>

<hr>
<h2 id='Var_alpha'>Variance of the number of bottom nodes in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) and <code class="reqn">\beta=0</code> (Case #1).</h2><span id='topic+Var_alpha'></span>

<h3>Description</h3>

<p>Variance of the number of bottom nodes in the unrealistic case where we assume that the number of variables and possible splits are infinite (therefore P(T) is not dependent on the design matrix X) and <code class="reqn">\beta=0</code> (Case #1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Var_alpha(alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Var_alpha_+3A_alpha">alpha</code></td>
<td>
<p>base parameter of the tree prior, <code class="reqn">\alpha \in [0,1)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the variance of the number of bottom nodes.
</p>


<h3>References</h3>

<p>Jolicoeur-Martineau, A. (Currently in revision, expected 2016) <em>Etude d'une loi a priori pour les arbres binaires de regression</em> (<em>Study on the prior distribution of binary regression trees</em>) (Master thesis). UQAM university.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+E_alpha">E_alpha</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Var_alpha(.30)
Var_alpha(.45)
Var_alpha(.499)
Var_alpha(.75)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
