<!DOCTYPE html><html><head><title>Help for package aws.comprehend</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {aws.comprehend}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aws.comprehend-package'><p>aws.comprehend</p></a></li>
<li><a href='#bind_and_index'><p>Bind and index a ResultList</p></a></li>
<li><a href='#comprehendHTTP'><p>Execute AWS Comprehend API Request</p></a></li>
<li><a href='#detect_entities'><p>Detect named entities in a source text</p></a></li>
<li><a href='#detect_language'><p>Detect language in a source text</p></a></li>
<li><a href='#detect_medical_entities'><p>Detect named entities in a source medical text</p></a></li>
<li><a href='#detect_medical_phi'><p>Detect Protected Health Information (PHI) in a source medical text</p></a></li>
<li><a href='#detect_phrases'><p>Detect key phrases</p></a></li>
<li><a href='#detect_sentiment'><p>Detect sentiment in a source text</p></a></li>
<li><a href='#detect_syntax'><p>Detect syntax in a source text</p></a></li>
<li><a href='#flatten'><p>Flatten embedded data.frames (1 level max)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Client for 'AWS Comprehend'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-03-10</td>
</tr>
<tr>
<td>Description:</td>
<td>Client for 'AWS Comprehend' <a href="https://aws.amazon.com/comprehend">https://aws.amazon.com/comprehend</a>, a cloud natural language processing service that can perform a number of quantitative text analyses, including language detection, sentiment analysis, and feature extraction.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/cloudyr/aws.comprehend">https://github.com/cloudyr/aws.comprehend</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/cloudyr/aws.comprehend/issues">https://github.com/cloudyr/aws.comprehend/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>httr, jsonlite, aws.signature (&ge; 0.3.4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 2.1.0)</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-03-18 13:30:25 UTC; asac</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas J. Leeper <a href="https://orcid.org/0000-0003-4097-6326"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Antoine Sachet [aut, cre],
  Dave Kincaid [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Antoine Sachet &lt;antoine.sac@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-03-18 14:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='aws.comprehend-package'>aws.comprehend</h2><span id='topic+aws.comprehend-package'></span><span id='topic+aws.comprehend'></span>

<h3>Description</h3>

<p>AWS Comprehend Client Package
</p>


<h3>Details</h3>

<p>Client for AWS Comprehend (<a href="https://aws.amazon.com/comprehend">https://aws.amazon.com/comprehend</a>0, a cloud natural language processing service that can perform a number of quantitative text analyses, including language detection, sentiment analysis, and feature extraction.
</p>


<h3>Author(s)</h3>

<p>Thomas J. Leeper &lt;thosjleeper@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+detect_language">detect_language</a></code>, <code><a href="#topic+detect_sentiment">detect_sentiment</a></code>, <code><a href="#topic+detect_entities">detect_entities</a></code>, <code><a href="#topic+detect_phrases">detect_phrases</a></code>
</p>

<hr>
<h2 id='bind_and_index'>Bind and index a ResultList</h2><span id='topic+bind_and_index'></span>

<h3>Description</h3>

<p>Turn a list of data.frames (of different lengths and potentially empty)
into a single indexed data.frame. Useful to process a ResultList from 'comprehendHTTP'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bind_and_index(index, df_list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bind_and_index_+3A_index">index</code></td>
<td>
<p>Vector of indices</p>
</td></tr>
<tr><td><code id="bind_and_index_+3A_df_list">df_list</code></td>
<td>
<p>List of data.frames to bind and index. Should NOT be a data.frame.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>'index' and 'df_list' should be the same length. An error is raised otherwise.
</p>
<p>bind_and_index(1:2, list(data.frame(col = &quot;a&quot;), data.frame(col = &quot;b&quot;)))
</p>
<p>bind_and_index(1:3, list(
data.frame(col = &quot;a&quot;),
data.frame(),
data.frame(c(&quot;b&quot;, &quot;c&quot;))))
</p>

<hr>
<h2 id='comprehendHTTP'>Execute AWS Comprehend API Request</h2><span id='topic+comprehendHTTP'></span>

<h3>Description</h3>

<p>This is the workhorse function to execute calls to the Comprehend API.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comprehendHTTP(
  action,
  query = list(),
  headers = list(),
  body = NULL,
  verbose = getOption("verbose", FALSE),
  region = Sys.getenv("AWS_DEFAULT_REGION", "us-east-1"),
  key = NULL,
  secret = NULL,
  session_token = NULL,
  service = c("comprehend", "comprehendmedical"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="comprehendHTTP_+3A_action">action</code></td>
<td>
<p>A character string specifying the API action to take</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_query">query</code></td>
<td>
<p>An optional named list containing query string parameters and their character values.</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_headers">headers</code></td>
<td>
<p>A list of headers to pass to the HTTP request.</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_body">body</code></td>
<td>
<p>A request body</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_verbose">verbose</code></td>
<td>
<p>A logical indicating whether to be verbose. Default is given by <code>options("verbose")</code>.</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_region">region</code></td>
<td>
<p>A character string containing the AWS region. If missing, defaults to &ldquo;us-east-1&rdquo;.</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_key">key</code></td>
<td>
<p>A character string containing an AWS Access Key ID. See <code><a href="aws.signature.html#topic+locate_credentials">locate_credentials</a></code>.</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_secret">secret</code></td>
<td>
<p>A character string containing an AWS Secret Access Key. See <code><a href="aws.signature.html#topic+locate_credentials">locate_credentials</a></code>.</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_session_token">session_token</code></td>
<td>
<p>A character string containing an AWS Session Token. See <code><a href="aws.signature.html#topic+locate_credentials">locate_credentials</a></code>.</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_service">service</code></td>
<td>
<p>the Comprehend service to use. Currently either 'comprehend' for the base service or 'comprehendmedical'
for the Comprehend Medical service.</p>
</td></tr>
<tr><td><code id="comprehendHTTP_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="httr.html#topic+GET">GET</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function constructs and signs an Polly API request and returns the results thereof, or relevant debugging information in the case of error.
</p>


<h3>Value</h3>

<p>If successful, a named list. Otherwise, a data structure of class &ldquo;aws-error&rdquo; containing any error message(s) from AWS and information about the request attempt.
</p>


<h3>Author(s)</h3>

<p>Thomas J. Leeper
</p>

<hr>
<h2 id='detect_entities'>Detect named entities in a source text</h2><span id='topic+detect_entities'></span>

<h3>Description</h3>

<p>Detect entities in a source text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_entities(text, language = "en", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect_entities_+3A_text">text</code></td>
<td>
<p>A character string containing a text to entities analyze, or a character vector to perform analysis separately for each element.</p>
</td></tr>
<tr><td><code id="detect_entities_+3A_language">language</code></td>
<td>
<p>A character string containing a two-letter language code. Currently &ldquo;en&rdquo; and &ldquo;es&rdquo; are supported.</p>
</td></tr>
<tr><td><code id="detect_entities_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+comprehendHTTP">comprehendHTTP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # simple example
  detect_entities("Amazon provides web services. Jeff is their leader.")
  
  txt &lt;-c("Amazon provides web services, like Google.",
          "Jeff is their leader.")
  detect_entities(txt)

## End(Not run)
</code></pre>

<hr>
<h2 id='detect_language'>Detect language in a source text</h2><span id='topic+detect_language'></span>

<h3>Description</h3>

<p>Detect language(s) in a source text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_language(text, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect_language_+3A_text">text</code></td>
<td>
<p>A character string containing a textual source, or a character vector to detect languages separately for each element.</p>
</td></tr>
<tr><td><code id="detect_language_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+comprehendHTTP">comprehendHTTP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of language probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # simple example
  detect_language("This is a test sentence in English")
  
  # two languages in a single text
  txt &lt;- "A: ¡Hola! ¿Como está, usted?\nB: Ça va bien. Merci. Et toi?"
  detect_language(txt)

  # "batch" mode
  detect_language(c("A: ¡Hola! ¿Como está, usted?",
                    "B: Ça va bien. Merci. Et toi?"))

## End(Not run)
</code></pre>

<hr>
<h2 id='detect_medical_entities'>Detect named entities in a source medical text</h2><span id='topic+detect_medical_entities'></span>

<h3>Description</h3>

<p>Detect entities in a source medical text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_medical_entities(text, language = "en", version = c("2", "1"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect_medical_entities_+3A_text">text</code></td>
<td>
<p>A character string containing a text to entities analyze, or a character vector to perform analysis separately for each element.</p>
</td></tr>
<tr><td><code id="detect_medical_entities_+3A_language">language</code></td>
<td>
<p>A character string containing a two-letter language code. Currently only &ldquo;en&rdquo; is supported.</p>
</td></tr>
<tr><td><code id="detect_medical_entities_+3A_version">version</code></td>
<td>
<p>A character string containing the version of the API that should be used. Currently only &quot;1&quot; or &quot;2&quot; are supported.</p>
</td></tr>
<tr><td><code id="detect_medical_entities_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+comprehendHTTP">comprehendHTTP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # simple example
  medical_detect_entities("Mrs. Smith comes in today complaining of shortness of breath.")
  
  txt &lt;-c("Mrs. Smith comes in today.",
          "She is complaining of shortnesss of breath.")
  medical_detect_entities(txt)

## End(Not run)
</code></pre>

<hr>
<h2 id='detect_medical_phi'>Detect Protected Health Information (PHI) in a source medical text</h2><span id='topic+detect_medical_phi'></span>

<h3>Description</h3>

<p>Detect Protected Health Information (PHI) in a source medical text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_medical_phi(text, language = "en", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect_medical_phi_+3A_text">text</code></td>
<td>
<p>A character string containing a text to entities analyze, or a character vector to perform analysis separately for each element.</p>
</td></tr>
<tr><td><code id="detect_medical_phi_+3A_language">language</code></td>
<td>
<p>A character string containing a two-letter language code. Currently only &ldquo;en&rdquo; is supported.</p>
</td></tr>
<tr><td><code id="detect_medical_phi_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+comprehendHTTP">comprehendHTTP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # simple example
  medical_detect_phi("Mrs. Smith comes in today complaining of shortness of breath.")
  
  txt &lt;-c("Mrs. Smith comes in today.",
          "She is complaining of shortnesss of breath.")
  medical_detect_phi(txt)

## End(Not run)
</code></pre>

<hr>
<h2 id='detect_phrases'>Detect key phrases</h2><span id='topic+detect_phrases'></span>

<h3>Description</h3>

<p>Detect key phrases in a source text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_phrases(text, language = "en", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect_phrases_+3A_text">text</code></td>
<td>
<p>A character string containing a text to analyze, or a character vector to perform analysis separately for each element.</p>
</td></tr>
<tr><td><code id="detect_phrases_+3A_language">language</code></td>
<td>
<p>A character string containing a two-letter language code. Currently &ldquo;en&rdquo; and &ldquo;es&rdquo; are supported.</p>
</td></tr>
<tr><td><code id="detect_phrases_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+comprehendHTTP">comprehendHTTP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # simple example
  detect_phrases("Amazon provides web services. Jeff is their leader.")
  
  txt &lt;-c("Amazon provides web services.",
          "Jeff is their leader.")
  detect_phrases(txt)

## End(Not run)
</code></pre>

<hr>
<h2 id='detect_sentiment'>Detect sentiment in a source text</h2><span id='topic+detect_sentiment'></span>

<h3>Description</h3>

<p>Detect sentiment in a source text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_sentiment(text, language = "en", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect_sentiment_+3A_text">text</code></td>
<td>
<p>A character string containing a text to sentiment analyze, or a character vector to perform analysis separately for each element.</p>
</td></tr>
<tr><td><code id="detect_sentiment_+3A_language">language</code></td>
<td>
<p>A character string containing a two-letter language code. Currently &ldquo;en&rdquo; and &ldquo;es&rdquo; are supported.</p>
</td></tr>
<tr><td><code id="detect_sentiment_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+comprehendHTTP">comprehendHTTP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # simple example
  detect_sentiment("I have never been happier. This is the best day ever.")

  txt &lt;-c("I have never been happier. This is the best day ever.",
          "I have always been happier. This is the worst day ever.")
  detect_sentiment(txt)

## End(Not run)
</code></pre>

<hr>
<h2 id='detect_syntax'>Detect syntax in a source text</h2><span id='topic+detect_syntax'></span>

<h3>Description</h3>

<p>Detect syntax in a source text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_syntax(text, language = "en", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect_syntax_+3A_text">text</code></td>
<td>
<p>A character string containing a text to syntax analyze, or a character vector to perform analysis separately for each element.</p>
</td></tr>
<tr><td><code id="detect_syntax_+3A_language">language</code></td>
<td>
<p>A character string containing a two-letter language code.</p>
</td></tr>
<tr><td><code id="detect_syntax_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+comprehendHTTP">comprehendHTTP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # simple example
  detect_syntax("The quick brown fox jumps over the lazy dog.")

  txt &lt;-c("The quick brown fox jumps over the lazy dog.",
          "I have never been happier!")
  detect_syntax(txt)

## End(Not run)
</code></pre>

<hr>
<h2 id='flatten'>Flatten embedded data.frames (1 level max)</h2><span id='topic+flatten'></span>

<h3>Description</h3>

<p>Flatten embedded data.frames (1 level max)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flatten(df)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flatten_+3A_df">df</code></td>
<td>
<p>data.frame to flatten</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
