<!DOCTYPE html><html><head><title>Help for package drape</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {drape}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#basis_poly'><p>Estimate the score function of the d'th covariate using a polynomial basis.</p></a></li>
<li><a href='#compare'><p>Generate simulation data and evaluate estimators, with sample splitting.</p></a></li>
<li><a href='#compare_evaluate'><p>Evaluate estimators by training nuisance functions on training set and evaluating them on test set.</p></a></li>
<li><a href='#compare_lm'><p>Generate simulation data and evaluate OLS estimator.</p></a></li>
<li><a href='#compare_partially_linear'><p>Generate simulation data and evaluate partially linear estimator.</p></a></li>
<li><a href='#compare_rothenhausler'><p>Generate simulation data and evaluate Rothenhausler estimator.</p></a></li>
<li><a href='#cv_resmooth'><p>K-fold cross-validation for resmoothing bandwidth.</p></a></li>
<li><a href='#cv_spline_score'><p>K-fold cross-validation for spline_score.</p></a></li>
<li><a href='#drape'><p>Estimate the doubly-robust average partial effect estimate of X on Y, in the presence of Z.</p></a></li>
<li><a href='#fit_lasso_poly'><p>Fit a lasso regression using quadratic polynomial basis, with interactions.</p></a></li>
<li><a href='#fit_xgboost'><p>Fit pre-tuned XGBoost regression for use in simulations.</p></a></li>
<li><a href='#MC_sums'><p>Compute sums of a Monte Carlo vector for use in resmoothing.</p></a></li>
<li><a href='#mixture_score'><p>Population score function for the symmetric mixture two Gaussian random variables.</p></a></li>
<li><a href='#new_X'><p>Generate a matrix of covariates for use in resmoothing, in which</p>
the d'th column of X is translated successively by the Kronecker
product of bw and MC_variates.</a></li>
<li><a href='#ng_pseudo_response'><p>Generate pseudo responses as in Ng 1994 to enable univariate score</p>
estimation by standard smoothing spline regression.</a></li>
<li><a href='#partially_linear'><p>Fit a doubly-robust partially linear regression using the DoubleML package</p>
and pre-tuned XGBoost regressions, for use in simulations.</a></li>
<li><a href='#resmooth'><p>Resmooth the predictions of a fitted model</p></a></li>
<li><a href='#rmixture'><p>Symmetric mixture two Gaussian random variables.</p></a></li>
<li><a href='#rothenhausler_basis'><p>Generate the modified quadratic basis of Rothenhausler and Yu.</p></a></li>
<li><a href='#rothenhausler_yu'><p>Estimate the average partial effect of using the debiased lasso method of Rothenhausler and Yu,</p>
using pre-tuned lasso penalties, for use in simulations.</a></li>
<li><a href='#simulate_data'><p>Generate simulation data.</p></a></li>
<li><a href='#sort_bin'><p>Sort and bin x within a specified tolerance, using hist().</p></a></li>
<li><a href='#spline_score'><p>Univariate score estimation via the smoothing spline method of Cox 1985</p>
and Ng 1994.</a></li>
<li><a href='#z_correlated_normal'><p>Generate n copies of Z ~ N_p(0,Sigma), where Sigma_jj = 1, Sigma_jk = corr for all j not equal to k.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Doubly Robust Average Partial Effects</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Doubly robust average partial effect estimation. This implementation contains methods for adding additional smoothness to plug-in regression procedures and for estimating score functions using smoothing splines. Details of the method can be found in Harvey Klyne and Rajen D. Shah (2023) &lt;<a href="https://arxiv.org/abs/2308.09207">arXiv:2308.09207</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/harveyklyne/drape/issues">https://github.com/harveyklyne/drape/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>DoubleML, glmnet, graphics, hdi, knitr, Matrix, mlr3,
paradox, partykit, rjson, rmarkdown, testthat (&ge; 3.0.0),
xgboost</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-17 00:36:38 UTC; Harvey</td>
</tr>
<tr>
<td>Author:</td>
<td>Harvey Klyne [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Harvey Klyne &lt;hklyne@g.harvard.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-18 13:30:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='basis_poly'>Estimate the score function of the d'th covariate using a polynomial basis.</h2><span id='topic+basis_poly'></span>

<h3>Description</h3>

<p>Computes the score function estimate when rho(X) is assumed to lie within the span
of the polynomial basis of X.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basis_poly(X, d, degree = 2, lambda = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="basis_poly_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
<tr><td><code id="basis_poly_+3A_d">d</code></td>
<td>
<p>integer index of covariate of interest.</p>
</td></tr>
<tr><td><code id="basis_poly_+3A_degree">degree</code></td>
<td>
<p>maximum degree of polynomial terms.</p>
</td></tr>
<tr><td><code id="basis_poly_+3A_lambda">lambda</code></td>
<td>
<p>optional scalar penalty, if &quot;NULL&quot; chosen via cross-validation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing the estimated score function &quot;rho&quot;, which takes
matrix input and yields a vector of score estimates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
X &lt;- matrix(stats::rnorm(200), ncol=4)
bs &lt;- basis_poly(X=X, d=1, degree=2)
bs$rho(X)
</code></pre>

<hr>
<h2 id='compare'>Generate simulation data and evaluate estimators, with sample splitting.</h2><span id='topic+compare'></span>

<h3>Description</h3>

<p>Generate simulation data and evaluate estimators, with sample splitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare(n, ex_setting, f_setting, nfold = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_+3A_n">n</code></td>
<td>
<p>integer number of samples. For &quot;401k&quot; ex_setting this is ignored
and the whole data set is used.</p>
</td></tr>
<tr><td><code id="compare_+3A_ex_setting">ex_setting</code></td>
<td>
<p>string &quot;normal&quot;, &quot;mixture2&quot;, &quot;mixture3&quot;,
&quot;logistic&quot;, &quot;t4&quot;, &quot;401k&quot;.</p>
</td></tr>
<tr><td><code id="compare_+3A_f_setting">f_setting</code></td>
<td>
<p>string &quot;plm&quot;, &quot;additive&quot;, &quot;interaction&quot;.</p>
</td></tr>
<tr><td><code id="compare_+3A_nfold">nfold</code></td>
<td>
<p>integer number of cross-validation folds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing estimates, standard error estimates, and sample theta (for debugging).
</p>

<hr>
<h2 id='compare_evaluate'>Evaluate estimators by training nuisance functions on training set and evaluating them on test set.</h2><span id='topic+compare_evaluate'></span>

<h3>Description</h3>

<p>Evaluate estimators by training nuisance functions on training set and evaluating them on test set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_evaluate(train, test, ex_setting, f_setting, regression, sm_bw_out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_evaluate_+3A_train">train</code></td>
<td>
<p>list containing vector of responses y and matrix of predictors X = (x,z).</p>
</td></tr>
<tr><td><code id="compare_evaluate_+3A_test">test</code></td>
<td>
<p>list containing vector of responses y and matrix of predictors X = (x,z).</p>
</td></tr>
<tr><td><code id="compare_evaluate_+3A_ex_setting">ex_setting</code></td>
<td>
<p>string &quot;normal&quot;, &quot;mixture2&quot;, &quot;mixture3&quot;,
&quot;logistic&quot;, &quot;t4&quot;, &quot;401k&quot;.</p>
</td></tr>
<tr><td><code id="compare_evaluate_+3A_f_setting">f_setting</code></td>
<td>
<p>string &quot;plm&quot;, &quot;additive&quot;, &quot;interaction&quot;.</p>
</td></tr>
<tr><td><code id="compare_evaluate_+3A_regression">regression</code></td>
<td>
<p>Optional fitted regression.</p>
</td></tr>
<tr><td><code id="compare_evaluate_+3A_sm_bw_out">sm_bw_out</code></td>
<td>
<p>Output of cv_resmooth.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing f, df, and score estimates evaluated on the test set.
</p>

<hr>
<h2 id='compare_lm'>Generate simulation data and evaluate OLS estimator.</h2><span id='topic+compare_lm'></span>

<h3>Description</h3>

<p>Generate simulation data and evaluate OLS estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_lm(n, ex_setting, f_setting)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_lm_+3A_n">n</code></td>
<td>
<p>integer number of samples. For &quot;401k&quot; ex_setting this is ignored
and the whole data set is used.</p>
</td></tr>
<tr><td><code id="compare_lm_+3A_ex_setting">ex_setting</code></td>
<td>
<p>string &quot;normal&quot;, &quot;mixture2&quot;, &quot;mixture3&quot;,
&quot;logistic&quot;, &quot;t4&quot;, &quot;401k&quot;.</p>
</td></tr>
<tr><td><code id="compare_lm_+3A_f_setting">f_setting</code></td>
<td>
<p>string &quot;plm&quot;, &quot;additive&quot;, &quot;interaction&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing estimate, standard error estimate, and sample theta (for debugging).
</p>

<hr>
<h2 id='compare_partially_linear'>Generate simulation data and evaluate partially linear estimator.</h2><span id='topic+compare_partially_linear'></span>

<h3>Description</h3>

<p>Generate simulation data and evaluate partially linear estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_partially_linear(n, ex_setting, f_setting)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_partially_linear_+3A_n">n</code></td>
<td>
<p>integer number of samples. For &quot;401k&quot; ex_setting this is ignored
and the whole data set is used.</p>
</td></tr>
<tr><td><code id="compare_partially_linear_+3A_ex_setting">ex_setting</code></td>
<td>
<p>string &quot;normal&quot;, &quot;mixture2&quot;, &quot;mixture3&quot;,
&quot;logistic&quot;, &quot;t4&quot;, &quot;401k&quot;.</p>
</td></tr>
<tr><td><code id="compare_partially_linear_+3A_f_setting">f_setting</code></td>
<td>
<p>string &quot;plm&quot;, &quot;additive&quot;, &quot;interaction&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing estimate, standard error estimate, and sample theta (for debugging).
</p>

<hr>
<h2 id='compare_rothenhausler'>Generate simulation data and evaluate Rothenhausler estimator.</h2><span id='topic+compare_rothenhausler'></span>

<h3>Description</h3>

<p>Generate simulation data and evaluate Rothenhausler estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_rothenhausler(n, ex_setting, f_setting)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_rothenhausler_+3A_n">n</code></td>
<td>
<p>integer number of samples. For &quot;401k&quot; ex_setting this is ignored
and the whole data set is used.</p>
</td></tr>
<tr><td><code id="compare_rothenhausler_+3A_ex_setting">ex_setting</code></td>
<td>
<p>string &quot;normal&quot;, &quot;mixture2&quot;, &quot;mixture3&quot;,
&quot;logistic&quot;, &quot;t4&quot;, &quot;401k&quot;.</p>
</td></tr>
<tr><td><code id="compare_rothenhausler_+3A_f_setting">f_setting</code></td>
<td>
<p>string &quot;plm&quot;, &quot;additive&quot;, &quot;interaction&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing estimate, standard error estimate, and sample theta (for debugging).
</p>

<hr>
<h2 id='cv_resmooth'>K-fold cross-validation for resmoothing bandwidth.</h2><span id='topic+cv_resmooth'></span>

<h3>Description</h3>

<p>Picks the largest resmoothing bandwidth achieving a cross-validation score within some specified tolerance of the original regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_resmooth(
  X,
  y,
  d = 1,
  regression,
  tol = 2,
  prefit = FALSE,
  foldid = NULL,
  bw = exp(seq(-5, 2, 0.2))/(2 * sqrt(3)) * stats::sd(X[, d]),
  nfolds = 5L,
  n_points = 101,
  sd_trim = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_resmooth_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_y">y</code></td>
<td>
<p>vector of responses.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_d">d</code></td>
<td>
<p>integer index of covariate to be smoothed along.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_regression">regression</code></td>
<td>
<p>If prefit = FALSE this is a function which takes input data of the form (X,y),
and returns a prediction function. This prediction function
itself accepts matrix input same width as X,
and returns a vector of y-predictions,
and optionally a vector of derivative predictions.
If prefit = TRUE then this is a list of length nfolds with each entry containing a component &quot;fit&quot; consisting
of a prediction function taking matrix input and returning a vector.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_tol">tol</code></td>
<td>
<p>vector of tolerances controlling the degree of permissible cross-validation error increase.
Larger values lead to a larger amount of smoothing being selected.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_prefit">prefit</code></td>
<td>
<p>boolean signifying if the regressions are already fit to the training data for each fold.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_foldid">foldid</code></td>
<td>
<p>optional vector with components in 1:nfolds indicating the folds in which
each observation fell. Overwrites nfolds.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_bw">bw</code></td>
<td>
<p>vector of bandwidths for the Gaussian resmoothing kernel.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_nfolds">nfolds</code></td>
<td>
<p>integer number of cross-validation folds.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_n_points">n_points</code></td>
<td>
<p>integer number of gridpoints to be used for convolution.</p>
</td></tr>
<tr><td><code id="cv_resmooth_+3A_sd_trim">sd_trim</code></td>
<td>
<p>float number of standard deviations at which to trim the
Gaussian distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list. Vector &quot;bw&quot; of bandwidths used. Vectors &quot;cv&quot; of
cross-validation scores and numeric &quot;cv_unsm&quot; for the cross-validation
without any smoothing. Vector &quot;bw_opt_inds&quot; for the indices of the selected bandwidths
under various tolerances. Vector &quot;bw_opt&quot; for the corresponding bandwidths.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(stats::rnorm(200), ncol=2)
y &lt;- X[,1] + sin(X[,2]) + 0.5 * stats::rnorm(nrow(X))
reg &lt;- function(X,y){
    df &lt;- data.frame(y,X)
    colnames(df) &lt;- c("y", "X1", "X2")
    lm1 &lt;- stats::lm(y~X1+sin(X2), data=df)
    fit &lt;- function(newX){
        newdf = data.frame(newX)
        colnames(newdf) &lt;- c("X1", "X2")
        return(as.vector(stats::predict(lm1, newdata=newdf)))}
    return(list("fit"=fit))
}
cv_resmooth(X=X, y=y, d=2, regression=reg, tol = c(0.5, 1, 2))
</code></pre>

<hr>
<h2 id='cv_spline_score'>K-fold cross-validation for spline_score.</h2><span id='topic+cv_spline_score'></span>

<h3>Description</h3>

<p>K-fold cross-validation for spline_score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_spline_score(x, df = 2:15, nfolds = 5L, tol = 0.001, nmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_spline_score_+3A_x">x</code></td>
<td>
<p>vector of datapoints</p>
</td></tr>
<tr><td><code id="cv_spline_score_+3A_df">df</code></td>
<td>
<p>vector of smoothing parameters for the
non-parametric score estimator, corresponding to the
effective degrees of freedom for a smoothing spline.</p>
</td></tr>
<tr><td><code id="cv_spline_score_+3A_nfolds">nfolds</code></td>
<td>
<p>integer number of cross-validation folds.</p>
</td></tr>
<tr><td><code id="cv_spline_score_+3A_tol">tol</code></td>
<td>
<p>numeric tolerance, minimum distance between neighbouring points,
to avoid singularities.</p>
</td></tr>
<tr><td><code id="cv_spline_score_+3A_nmax">nmax</code></td>
<td>
<p>if specified, overrides tol as maximal number of unique points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of 5 elements: df vector, cv vector of corresponding
cross-validation scores, se vector of standard error estimates,
df_min cross-validation minimiser, df_1se largest smoothing
parameter within CV score within one standard error of df_min.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
x &lt;- stats::rt(100, df=4)
cv_spline_score(x)

x &lt;- stats::rlogis(500)
cvspl &lt;- cv_spline_score(x)
cvspl$df_min
</code></pre>

<hr>
<h2 id='drape'>Estimate the doubly-robust average partial effect estimate of X on Y, in the presence of Z.</h2><span id='topic+drape'></span>

<h3>Description</h3>

<p>Estimate the doubly-robust average partial effect estimate of X on Y, in the presence of Z.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drape(
  y,
  x,
  z,
  response_regression,
  predictor_regression,
  resmooth_bw = NULL,
  spline_df = NULL,
  nfolds = 5L,
  foldid = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drape_+3A_y">y</code></td>
<td>
<p>vector of responses.</p>
</td></tr>
<tr><td><code id="drape_+3A_x">x</code></td>
<td>
<p>vector of the predictor of interest.</p>
</td></tr>
<tr><td><code id="drape_+3A_z">z</code></td>
<td>
<p>matrix of additional predictors.</p>
</td></tr>
<tr><td><code id="drape_+3A_response_regression">response_regression</code></td>
<td>
<p>function which takes input data of the form
(X,y), where X=cbind(x,z), and returns a prediction function f:X -&gt; y and optionally a
similar derivative estimation function (in this case no resmoothing is done).</p>
</td></tr>
<tr><td><code id="drape_+3A_predictor_regression">predictor_regression</code></td>
<td>
<p>function which takes input data of the form
(z,x), and returns a prediction function m:z -&gt; x.</p>
</td></tr>
<tr><td><code id="drape_+3A_resmooth_bw">resmooth_bw</code></td>
<td>
<p>optional numeric to be used as resmoothing bandwidth,
otherwise chosen via cross-validation. Only used if
response_regression doesn't predict derivatives.</p>
</td></tr>
<tr><td><code id="drape_+3A_spline_df">spline_df</code></td>
<td>
<p>optional double, a smoothing parameter for the
unconditional spline score estimator, corresponding to the effective degrees
of freedom for a smoothing spline. If NULL, chosen via
cross-validation.</p>
</td></tr>
<tr><td><code id="drape_+3A_nfolds">nfolds</code></td>
<td>
<p>integer, number of sample-splits. If set to
one, then all data is used for both training and evaluation.</p>
</td></tr>
<tr><td><code id="drape_+3A_foldid">foldid</code></td>
<td>
<p>optional vector with components in 1:nfolds indicating the folds in which
each observation fell. Overwrites nfolds.</p>
</td></tr>
<tr><td><code id="drape_+3A_verbose">verbose</code></td>
<td>
<p>boolean controlling level of information outputted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing the average partial effect estimate and the
corresponding standard error estimate. If verbose=TRUE, additionally contains
variables used in computations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
data &lt;- simulate_data(200, "normal", "plm")
response_regression &lt;- function(X,y){
    df &lt;- data.frame(y,X)
    colnames(df) &lt;- c("y", paste0("X", 1:10))
    lm1 &lt;- stats::lm(y~X1+sin(X2), data=df)
    fit &lt;- function(newX){
        newdf &lt;- data.frame(newX)
        colnames(newdf) &lt;- paste0("X", 1:10)
        return(as.vector(stats::predict(lm1, newdata=newdf)))}
    return(list("fit"=fit))
}
predictor_regression &lt;- function(z,x){
    df &lt;- data.frame(x,z)
    colnames(df) &lt;- c("x", paste0("Z", 1:9))
    lm1 &lt;- stats::lm(x~Z1+Z2, data=df)
    fit &lt;- function(newz){
        newdf &lt;- data.frame(newz)
        colnames(newdf) &lt;- paste0("Z", 1:9)
        return(as.vector(stats::predict(lm1, newdata=newdf)))}
    return(list("fit"=fit))
}
drape(data$y, data$x, data$z, response_regression, predictor_regression, nfolds=2)
</code></pre>

<hr>
<h2 id='fit_lasso_poly'>Fit a lasso regression using quadratic polynomial basis, with interactions.</h2><span id='topic+fit_lasso_poly'></span>

<h3>Description</h3>

<p>Compute regression function and derivative estimates based
on polynomial basis lasso with penalty parameter chosen by
cross validation (CV).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_lasso_poly(X, y, degree, lambda = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_lasso_poly_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
<tr><td><code id="fit_lasso_poly_+3A_y">y</code></td>
<td>
<p>vector of responses.</p>
</td></tr>
<tr><td><code id="fit_lasso_poly_+3A_degree">degree</code></td>
<td>
<p>maximum degree of polynomial terms.</p>
</td></tr>
<tr><td><code id="fit_lasso_poly_+3A_lambda">lambda</code></td>
<td>
<p>optional scalar tuning parameter, if &quot;NULL&quot; chosen via
cross-validation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing: A function &quot;fit&quot; which takes matrix input of the
same width as X, and returns a vector of y-predictions. A
scalar &quot;lambda&quot; the tuning parameter.
</p>

<hr>
<h2 id='fit_xgboost'>Fit pre-tuned XGBoost regression for use in simulations.</h2><span id='topic+fit_xgboost'></span>

<h3>Description</h3>

<p>Fit pre-tuned XGBoost regression for use in simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_xgboost(X, y, params, derivative = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_xgboost_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
<tr><td><code id="fit_xgboost_+3A_y">y</code></td>
<td>
<p>vector of responses.</p>
</td></tr>
<tr><td><code id="fit_xgboost_+3A_params">params</code></td>
<td>
<p>XGBoost hyperparameters.</p>
</td></tr>
<tr><td><code id="fit_xgboost_+3A_derivative">derivative</code></td>
<td>
<p>logical determining if numerical difference derivative
estimate (wrt the first predictor) should also be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing a function &quot;fit&quot; which takes matrix input of the
same width as X, and returns a vector of predictions. Optionally the list
also contains a function &quot;deriv_fit&quot; for numerical difference derivative
estimates.
</p>

<hr>
<h2 id='MC_sums'>Compute sums of a Monte Carlo vector for use in resmoothing.</h2><span id='topic+MC_sums'></span>

<h3>Description</h3>

<p>Compute sums of a Monte Carlo vector for use in resmoothing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MC_sums(a, n, nMC, nbw)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MC_sums_+3A_a">a</code></td>
<td>
<p>vector of length (n x nMC x nbw).</p>
</td></tr>
<tr><td><code id="MC_sums_+3A_n">n</code></td>
<td>
<p>integer.</p>
</td></tr>
<tr><td><code id="MC_sums_+3A_nmc">nMC</code></td>
<td>
<p>integer.</p>
</td></tr>
<tr><td><code id="MC_sums_+3A_nbw">nbw</code></td>
<td>
<p>integer.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with nbw elements. The j'th element of which is
a vector of length n, the i'th element being the sum of the
(((j-1)n + (i-1)) x nMC + 1) to (((j-1)n + i) x nMC)
elements of a inclusive.
</p>

<hr>
<h2 id='mixture_score'>Population score function for the symmetric mixture two Gaussian random variables.</h2><span id='topic+mixture_score'></span>

<h3>Description</h3>

<p>Population score function for the symmetric mixture two Gaussian random variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixture_score(x, sd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixture_score_+3A_x">x</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="mixture_score_+3A_sd">sd</code></td>
<td>
<p>standard deviation of each Gaussian.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of length n
</p>

<hr>
<h2 id='new_X'>Generate a matrix of covariates for use in resmoothing, in which
the d'th column of X is translated successively by the Kronecker
product of bw and MC_variates.</h2><span id='topic+new_X'></span>

<h3>Description</h3>

<p>Generate a matrix of covariates for use in resmoothing, in which
the d'th column of X is translated successively by the Kronecker
product of bw and MC_variates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>new_X(X, d, MC_variates, bw)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="new_X_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
<tr><td><code id="new_X_+3A_d">d</code></td>
<td>
<p>integer index of covariate to be smoothed along.</p>
</td></tr>
<tr><td><code id="new_X_+3A_mc_variates">MC_variates</code></td>
<td>
<p>vector of standard Gaussian rvs.</p>
</td></tr>
<tr><td><code id="new_X_+3A_bw">bw</code></td>
<td>
<p>vector of bandwidths for the Gaussian kernel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix with ncol(X) columns and (nrow(X)length(MC_variates)
length(bw)) rows.
</p>

<hr>
<h2 id='ng_pseudo_response'>Generate pseudo responses as in Ng 1994 to enable univariate score
estimation by standard smoothing spline regression.</h2><span id='topic+ng_pseudo_response'></span>

<h3>Description</h3>

<p>Pseudo responses should be regarded as a computational tool, not
as an estimate of the score itself.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ng_pseudo_response(x, w = rep(1, length(x)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ng_pseudo_response_+3A_x">x</code></td>
<td>
<p>vector of covariates.</p>
</td></tr>
<tr><td><code id="ng_pseudo_response_+3A_w">w</code></td>
<td>
<p>vector of weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score estimates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(-3,3, length.out=50)
ng_pseudo_response(x)
</code></pre>

<hr>
<h2 id='partially_linear'>Fit a doubly-robust partially linear regression using the DoubleML package
and pre-tuned XGBoost regressions, for use in simulations.</h2><span id='topic+partially_linear'></span>

<h3>Description</h3>

<p>Fit a doubly-robust partially linear regression using the DoubleML package
and pre-tuned XGBoost regressions, for use in simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partially_linear(X, y, g_params, m_params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partially_linear_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
<tr><td><code id="partially_linear_+3A_y">y</code></td>
<td>
<p>vector of responses.</p>
</td></tr>
<tr><td><code id="partially_linear_+3A_g_params">g_params</code></td>
<td>
<p>XGBoost hyperparameters for partially linear regression of y on X.</p>
</td></tr>
<tr><td><code id="partially_linear_+3A_m_params">m_params</code></td>
<td>
<p>XGBoost hyperparameters for predictor regression of the first column of X on the others.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing the linear parameter estimate and the
corresponding standard error estimate.
</p>

<hr>
<h2 id='resmooth'>Resmooth the predictions of a fitted model</h2><span id='topic+resmooth'></span>

<h3>Description</h3>

<p>Smooth the predictions of a fitted model by convolving them
with a Gaussian kernel along the d'th covariate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resmooth(
  fit,
  X,
  d = 1,
  bw = exp(seq(-1, 1))/(2 * sqrt(3)) * stats::sd(X[, d]),
  n_points = 101,
  sd_trim = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resmooth_+3A_fit">fit</code></td>
<td>
<p>a prediction function taking matrix input and
returning a vector.</p>
</td></tr>
<tr><td><code id="resmooth_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
<tr><td><code id="resmooth_+3A_d">d</code></td>
<td>
<p>integer index of covariate to be smoothed along.</p>
</td></tr>
<tr><td><code id="resmooth_+3A_bw">bw</code></td>
<td>
<p>vector of bandwidths for the Gaussian kernel.</p>
</td></tr>
<tr><td><code id="resmooth_+3A_n_points">n_points</code></td>
<td>
<p>integer number of gridpoints to be used for convolution.</p>
</td></tr>
<tr><td><code id="resmooth_+3A_sd_trim">sd_trim</code></td>
<td>
<p>float number of standard deviations at which to trim the
Gaussian distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the following elements. A list &quot;pred&quot; of the same length
as &quot;bw&quot;. Each element is a vector of predictions which are smooth with
respect to the dth column of X, with smoothness corresponding to the
respective element of &quot;bw&quot;. A similar list &quot;deriv&quot; of corresponding
vectors of first derivatives. Vectors &quot;gridpoints&quot; and &quot;prob_weights&quot;
of equally spaced gridpoints and corresponding normal density weights.
Vector &quot;bw&quot; of bandwidths used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Single bandwidth
X &lt;- matrix(seq(-2,2,by=0.05))
fit &lt;- function(Y){1*(rowMeans(Y)&lt;0)}
sm &lt;- resmooth(fit=fit, X=X, d=1, bw=0.2)
sm$pred[[1]]

# Multiple bandwidths simultaneously
X &lt;- matrix(stats::rnorm(200), ncol=2)
y &lt;- X[,1] + sin(X[,2]) + 0.5 * stats::rnorm(nrow(X))
df &lt;- data.frame(y,X)
lm1 &lt;- stats::lm(y~X1+sin(X2), data=df)
fit &lt;- function(Y){as.vector(stats::predict(lm1, newdata=data.frame(Y)))}
resmooth(fit=fit, X=X, d=2)
</code></pre>

<hr>
<h2 id='rmixture'>Symmetric mixture two Gaussian random variables.</h2><span id='topic+rmixture'></span>

<h3>Description</h3>

<p>The resulting distribution is mean zero, variance one.
X ~ N(-sqrt(1-sd^2),sd^2) wp 0.5,
N(sqrt(1-sd^2),sd^2) wp 0.5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmixture(n, sd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmixture_+3A_n">n</code></td>
<td>
<p>number of observations.</p>
</td></tr>
<tr><td><code id="rmixture_+3A_sd">sd</code></td>
<td>
<p>standard deviation of each Gaussian.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of length n
</p>

<hr>
<h2 id='rothenhausler_basis'>Generate the modified quadratic basis of Rothenhausler and Yu.</h2><span id='topic+rothenhausler_basis'></span>

<h3>Description</h3>

<p>Generate the modified quadratic basis of Rothenhausler and Yu.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rothenhausler_basis(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rothenhausler_basis_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing the modified basis matrices for regression and derivative estimation.
</p>

<hr>
<h2 id='rothenhausler_yu'>Estimate the average partial effect of using the debiased lasso method of Rothenhausler and Yu,
using pre-tuned lasso penalties, for use in simulations.</h2><span id='topic+rothenhausler_yu'></span>

<h3>Description</h3>

<p>Estimate the average partial effect of using the debiased lasso method of Rothenhausler and Yu,
using pre-tuned lasso penalties, for use in simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rothenhausler_yu(X, y, f_lambda, m_lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rothenhausler_yu_+3A_x">X</code></td>
<td>
<p>matrix of covariates.</p>
</td></tr>
<tr><td><code id="rothenhausler_yu_+3A_y">y</code></td>
<td>
<p>vector of responses.</p>
</td></tr>
<tr><td><code id="rothenhausler_yu_+3A_f_lambda">f_lambda</code></td>
<td>
<p>lasso penalty for regression of y on X.</p>
</td></tr>
<tr><td><code id="rothenhausler_yu_+3A_m_lambda">m_lambda</code></td>
<td>
<p>lasso penalty for predictor regression of the first column of X on the others.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing the linear parameter estimate and the
corresponding standard error estimate.
</p>

<hr>
<h2 id='simulate_data'>Generate simulation data.</h2><span id='topic+simulate_data'></span>

<h3>Description</h3>

<p>If ex_setting = &quot;401k&quot; then 401k data set is used for (X,Z). Otherwise:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_data(n, ex_setting, f_setting)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_data_+3A_n">n</code></td>
<td>
<p>integer number of samples. For &quot;401k&quot; ex_setting this is ignored
and the whole data set is used.</p>
</td></tr>
<tr><td><code id="simulate_data_+3A_ex_setting">ex_setting</code></td>
<td>
<p>string &quot;normal&quot;, &quot;mixture2&quot;, &quot;mixture3&quot;,
&quot;logistic&quot;, &quot;t4&quot;, &quot;401k&quot;.</p>
</td></tr>
<tr><td><code id="simulate_data_+3A_f_setting">f_setting</code></td>
<td>
<p>string &quot;plm&quot;, &quot;additive&quot;, &quot;interaction&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Z ~ N_9(0,Sigma),
where Sigma_jj = 1, Sigma_jk = corr for all j not equal to k.
X = m(Z) + s(Z)*ex
where m and sigma are step functions of z_1 and z_3 respectively.
Y = f(X,Z) + N(0,1)
</p>


<h3>Value</h3>

<p>list containing y, x, z. Additionally contains the population
nuisance parameters evaluated on the data, and the sample version of
the average partial effect.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulate_data(100, "normal", "plm")
</code></pre>

<hr>
<h2 id='sort_bin'>Sort and bin x within a specified tolerance, using hist().</h2><span id='topic+sort_bin'></span>

<h3>Description</h3>

<p>Sort and bin x within a specified tolerance, using hist().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort_bin(x, tol = 1e-05, nmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort_bin_+3A_x">x</code></td>
<td>
<p>vector of covariates.</p>
</td></tr>
<tr><td><code id="sort_bin_+3A_tol">tol</code></td>
<td>
<p>numeric tolerance, minimum distance between neighbouring points,
to avoid singularities.</p>
</td></tr>
<tr><td><code id="sort_bin_+3A_nmax">nmax</code></td>
<td>
<p>if specified, overrides tol as maximal number of unique points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with three elements. x_sort is sorted and binned x,
w is a vector of weights corresponding to the frequency of each bin,
order is a vector specifying the ordering of x into the binned values
sort_x.
</p>

<hr>
<h2 id='spline_score'>Univariate score estimation via the smoothing spline method of Cox 1985
and Ng 1994.</h2><span id='topic+spline_score'></span>

<h3>Description</h3>

<p>Univariate score estimation via the smoothing spline method of Cox 1985
and Ng 1994.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spline_score(x, df = 5, tol = 0.001, nmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spline_score_+3A_x">x</code></td>
<td>
<p>vector of datapoints</p>
</td></tr>
<tr><td><code id="spline_score_+3A_df">df</code></td>
<td>
<p>vector of smoothing parameters for the
non-parametric score estimator, corresponding to the
effective degrees of freedom for a smoothing spline.</p>
</td></tr>
<tr><td><code id="spline_score_+3A_tol">tol</code></td>
<td>
<p>numeric tolerance, minimum distance between neighbouring points,
to avoid singularities.</p>
</td></tr>
<tr><td><code id="spline_score_+3A_nmax">nmax</code></td>
<td>
<p>if specified, overrides tol as maximal number of unique points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>score function &quot;rho&quot; and derivative &quot;drho&quot;, which take vector
input and yield a vector of score estimates corresponding to each df (in a
list if there are multiple df values). Also output the vector &quot;df&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Single bandwidth
x &lt;- stats::rlogis(100)
spl &lt;- spline_score(x, df=6)
spl$rho(x)
spl$drho(x)

# Multiple bandwidths simultaneously
x &lt;- stats::rt(n=100, df=4)
spl &lt;- spline_score(x, df=c(2,5,10))
spl$rho(x)
</code></pre>

<hr>
<h2 id='z_correlated_normal'>Generate n copies of Z ~ N_p(0,Sigma), where Sigma_jj = 1, Sigma_jk = corr for all j not equal to k.</h2><span id='topic+z_correlated_normal'></span>

<h3>Description</h3>

<p>Generate n copies of Z ~ N_p(0,Sigma), where Sigma_jj = 1, Sigma_jk = corr for all j not equal to k.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>z_correlated_normal(n, p, corr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="z_correlated_normal_+3A_n">n</code></td>
<td>
<p>integer number of samples.</p>
</td></tr>
<tr><td><code id="z_correlated_normal_+3A_p">p</code></td>
<td>
<p>integer number of dimensions.</p>
</td></tr>
<tr><td><code id="z_correlated_normal_+3A_corr">corr</code></td>
<td>
<p>float correlation in (-1,1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n by p matrix.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
