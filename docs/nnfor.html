<!DOCTYPE html><html lang="en"><head><title>Help for package nnfor</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nnfor}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#nnfor-package'><p>nnfor: Time Series Forecasting with Neural Networks</p></a></li>
<li><a href='#elm'><p>Extreme learning machines for time series forecasting</p></a></li>
<li><a href='#elm.fast'><p>ELM (fast) neural network.</p></a></li>
<li><a href='#elm.thief'><p>ELM network for THieF.</p></a></li>
<li><a href='#forecast.elm'><p>Forecast using ELM neural network.</p></a></li>
<li><a href='#forecast.mlp'><p>Forecast using MLP neural network.</p></a></li>
<li><a href='#linscale'><p>Apply minmax linear scaling to a vector.</p></a></li>
<li><a href='#mlp'><p>Multilayer Perceptron for time series forecasting</p></a></li>
<li><a href='#mlp.thief'><p>MLP network for THieF.</p></a></li>
<li><a href='#nnfor'><p>nnfor:Time Series Forecasting with Neural Networks</p></a></li>
<li><a href='#plot.elm'><p>Plot ELM network.</p></a></li>
<li><a href='#plot.mlp'><p>Plot MLP network.</p></a></li>
<li><a href='#predict.elm.fast'><p>Predictions for ELM (fast) network.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Time Series Forecasting with Neural Networks</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.9</td>
</tr>
<tr>
<td>Description:</td>
<td>Automatic time series modelling with neural networks. 
    Allows fully automatic, semi-manual or fully manual specification of networks. For details of the
	specification methodology see: (i) Crone and Kourentzes (2010) &lt;<a href="https://doi.org/10.1016%2Fj.neucom.2010.01.017">doi:10.1016/j.neucom.2010.01.017</a>&gt;;
	and (ii) Kourentzes et al. (2014) &lt;<a href="https://doi.org/10.1016%2Fj.eswa.2013.12.011">doi:10.1016/j.eswa.2013.12.011</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>generics</td>
</tr>
<tr>
<td>Imports:</td>
<td>forecast, glmnet, neuralnet, plotrix, MASS, tsutils, uroot,
methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>thief</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://kourentzes.com/forecasting/2019/01/16/tutorial-for-the-nnfor-r-package/">https://kourentzes.com/forecasting/2019/01/16/tutorial-for-the-nnfor-r-package/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/trnnick/nnfor/issues">https://github.com/trnnick/nnfor/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-14 23:23:37 UTC; Nikos</td>
</tr>
<tr>
<td>Author:</td>
<td>Nikolaos Kourentzes [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nikolaos Kourentzes &lt;nikolaos@kourentzes.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-15 00:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='nnfor-package'>nnfor: Time Series Forecasting with Neural Networks</h2><span id='topic+nnfor-package'></span><span id='topic+_PACKAGE'></span>

<h3>Description</h3>

<p>Automatic time series modelling with neural networks. Allows fully automatic, semi-manual or fully manual specification of networks. For details of the specification methodology see: (i) Crone and Kourentzes (2010) <a href="https://doi.org/10.1016/j.neucom.2010.01.017">doi:10.1016/j.neucom.2010.01.017</a>; and (ii) Kourentzes et al. (2014) <a href="https://doi.org/10.1016/j.eswa.2013.12.011">doi:10.1016/j.eswa.2013.12.011</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nikolaos Kourentzes <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://kourentzes.com/forecasting/2019/01/16/tutorial-for-the-nnfor-r-package/">https://kourentzes.com/forecasting/2019/01/16/tutorial-for-the-nnfor-r-package/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/trnnick/nnfor/issues">https://github.com/trnnick/nnfor/issues</a>
</p>
</li></ul>


<hr>
<h2 id='elm'>Extreme learning machines for time series forecasting</h2><span id='topic+elm'></span>

<h3>Description</h3>

<p>This function fits ELM neural networks for time series forecasting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elm(
  y,
  m = frequency(y),
  hd = NULL,
  type = c("lasso", "ridge", "step", "lm"),
  reps = 20,
  comb = c("median", "mean", "mode"),
  lags = NULL,
  keep = NULL,
  difforder = NULL,
  outplot = c(FALSE, TRUE),
  sel.lag = c(TRUE, FALSE),
  direct = c(FALSE, TRUE),
  allow.det.season = c(TRUE, FALSE),
  det.type = c("auto", "bin", "trg"),
  xreg = NULL,
  xreg.lags = NULL,
  xreg.keep = NULL,
  barebone = c(FALSE, TRUE),
  model = NULL,
  retrain = c(FALSE, TRUE)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elm_+3A_y">y</code></td>
<td>
<p>Input time series. Can be ts or msts object.</p>
</td></tr>
<tr><td><code id="elm_+3A_m">m</code></td>
<td>
<p>Frequency of the time series. By default it is picked up from y.</p>
</td></tr>
<tr><td><code id="elm_+3A_hd">hd</code></td>
<td>
<p>Number of hidden nodes. This can be a vector, where each number represents the number of hidden nodes of a different hidden layer. Use NULL to automatically specify.</p>
</td></tr>
<tr><td><code id="elm_+3A_type">type</code></td>
<td>
<p>Estimation type for output layer weights. Can be &quot;lasso&quot; (lasso with CV), &quot;ridge&quot; (ridge regression with CV), &quot;step&quot; (stepwise regression with AIC) or &quot;lm&quot; (linear regression).</p>
</td></tr>
<tr><td><code id="elm_+3A_reps">reps</code></td>
<td>
<p>Number of networks to train, the result is the ensemble forecast.</p>
</td></tr>
<tr><td><code id="elm_+3A_comb">comb</code></td>
<td>
<p>Combination operator for forecasts when reps &gt; 1. Can be &quot;median&quot;, &quot;mode&quot; (based on KDE estimation) and &quot;mean&quot;.</p>
</td></tr>
<tr><td><code id="elm_+3A_lags">lags</code></td>
<td>
<p>Lags of y to use as inputs. If none provided then 1:frequency(y) is used. Use 0 for no univariate lags.</p>
</td></tr>
<tr><td><code id="elm_+3A_keep">keep</code></td>
<td>
<p>Logical vector to force lags to stay in the model if sel.lag == TRUE. If NULL then it keep = rep(FALSE,length(lags)).</p>
</td></tr>
<tr><td><code id="elm_+3A_difforder">difforder</code></td>
<td>
<p>Vector including the differencing lags. For example c(1,12) will apply first and seasonal (12) differences. For no differencing use 0. For automatic selection use NULL.</p>
</td></tr>
<tr><td><code id="elm_+3A_outplot">outplot</code></td>
<td>
<p>Provide plot of model fit. Can be TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="elm_+3A_sel.lag">sel.lag</code></td>
<td>
<p>Automatically select lags. Can be TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="elm_+3A_direct">direct</code></td>
<td>
<p>Use direct input-output connections to model strictly linear effects. Can be TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="elm_+3A_allow.det.season">allow.det.season</code></td>
<td>
<p>Permit modelling seasonality with deterministic dummies.</p>
</td></tr>
<tr><td><code id="elm_+3A_det.type">det.type</code></td>
<td>
<p>Type of deterministic seasonality dummies to use. This can be &quot;bin&quot; for binary or &quot;trg&quot; for a sine-cosine pair. With &quot;auto&quot; if ony a single seasonality is used and periodicity is up to 12 then &quot;bin&quot; is used, otherwise &quot;trg&quot;.</p>
</td></tr>
<tr><td><code id="elm_+3A_xreg">xreg</code></td>
<td>
<p>Exogenous regressors. Each column is a different regressor and the sample size must be at least as long as the target in-sample set, but can be longer.</p>
</td></tr>
<tr><td><code id="elm_+3A_xreg.lags">xreg.lags</code></td>
<td>
<p>This is a list containing the lags for each exogenous variable. Each list is a numeric vector containing lags. If xreg has 3 columns then the xreg.lags list must contain three elements. If NULL then it is automatically specified.</p>
</td></tr>
<tr><td><code id="elm_+3A_xreg.keep">xreg.keep</code></td>
<td>
<p>List of logical vectors to force lags of xreg to stay in the model if sel.lag == TRUE. If NULL then all exogenous lags can be removed.</p>
</td></tr>
<tr><td><code id="elm_+3A_barebone">barebone</code></td>
<td>
<p>Use an alternative elm implementation (written in R) that is faster when the number of inputs is very high. Typically not needed.</p>
</td></tr>
<tr><td><code id="elm_+3A_model">model</code></td>
<td>
<p>A previously trained mlp object. If this is provided then the same model is fitted to y, without re-estimating any model parameters.</p>
</td></tr>
<tr><td><code id="elm_+3A_retrain">retrain</code></td>
<td>
<p>If a previous model is provided, retrain the network or not. If the network is retrained the size of the hidden layer is reset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return object of class <code>elm</code>. If barebone == TRUE then the object inherits a second class &quot;<code>elm.fast</code>&quot;.
The function <code>plot</code> produces a plot the network architecture.
<code>elm</code> contains:
</p>

<ul>
<li> <p><code>net</code> - ELM networks. If it is of class &quot;<code>elm.fast</code>&quot; then this is NULL.
</p>
</li>
<li> <p><code>hd</code> - Number of hidden nodes. If it is of class &quot;<code>elm.fast</code>&quot; this is a vector with a different number for each repetition.
</p>
</li>
<li> <p><code>W.in</code> - NULL unless it is of class &quot;<code>elm.fast</code>&quot;. Contains the input weights.
</p>
</li>
<li> <p><code>W</code> - Output layer weights for each repetition.
</p>
</li>
<li> <p><code>b</code> - Contains the output node bias for each training repetition.
</p>
</li>
<li> <p><code>W.dct</code> - Contains the direct connection weights if argument direct == TRUE. Otherwise is NULL.
</p>
</li>
<li> <p><code>lags</code> - Input lags used.
</p>
</li>
<li> <p><code>xreg.lags</code> - <code>xreg</code> lags used.
</p>
</li>
<li> <p><code>difforder</code> - Differencing used.
</p>
</li>
<li> <p><code>sdummy</code> - Use of deterministic seasonality.
</p>
</li>
<li> <p><code>ff</code> - Seasonal frequencies detected in data (taken from ts or msts object).
</p>
</li>
<li> <p><code>ff.det</code> - Seasonal frequencies coded using deterministic dummies.
</p>
</li>
<li> <p><code>det.type</code> - Type of determistic seasonality.
</p>
</li>
<li> <p><code>y</code> - Input time series.
</p>
</li>
<li> <p><code>minmax</code> - Scaling structure.
</p>
</li>
<li> <p><code>xreg.minmax</code> - Scaling structure for xreg variables.
</p>
</li>
<li> <p><code>comb</code> - Combination operator used.
</p>
</li>
<li> <p><code>type</code> - Estimation used for output layer weights.
</p>
</li>
<li> <p><code>direct</code> - Presence of direct input-output connections.
</p>
</li>
<li> <p><code>fitted</code> - Fitted values.
</p>
</li>
<li> <p><code>MSE</code> - In-sample Mean Squared Error.
</p>
</li></ul>



<h3>Note</h3>

<p>To use elm with Temporal Hierarchies (<a href="https://cran.r-project.org/package=thief">thief</a> package) see <code><a href="#topic+elm.thief">elm.thief</a></code>.
The elm function by default calls the <code>neuralnet</code> function. If barebone == TRUE then it uses an alternative implementation (<code>TStools:::elm.fast</code>) which is more appropriate when the number of inputs is several hundreds.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> For an introduction to neural networks see: Ord K., Fildes R., Kourentzes N. (2017) <a href="https://kourentzes.com/forecasting/2017/10/16/new-forecasting-book-principles-of-business-forecasting-2e/">Principles of Business Forecasting 2e</a>. <em>Wessex Press Publishing Co.</em>, Chapter 10.
</p>
</li>
<li><p> For combination operators see: Kourentzes N., Barrow B.K., Crone S.F. (2014) <a href="https://kourentzes.com/forecasting/2014/04/19/neural-network-ensemble-operators-for-time-series-forecasting/">Neural network ensemble operators for time series forecasting</a>. <em>Expert Systems with Applications</em>, <b>41</b>(<b>9</b>), 4235-4244.
</p>
</li>
<li><p> For variable selection see: Crone S.F., Kourentzes N. (2010) <a href="https://kourentzes.com/forecasting/2010/04/19/feature-selection-for-time-series-prediction-a-combined-filter-and-wrapper-approach-for-neural-networks/">Feature selection for time series prediction – A combined filter and wrapper approach for neural networks</a>. <em>Neurocomputing</em>, <b>73</b>(<b>10</b>), 1923-1936.
</p>
</li>
<li><p> For ELMs see: Huang G.B., Zhou H., Ding X. (2006) Extreme learning machine: theory and applications. <em>Neurocomputing</em>, <b>70</b>(<b>1</b>), 489-501.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+forecast.elm">forecast.elm</a></code>, <code><a href="#topic+elm.thief">elm.thief</a></code>, <code><a href="#topic+mlp">mlp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 fit &lt;- elm(AirPassengers)
 print(fit)
 plot(fit)
 frc &lt;- forecast(fit,h=36)
 plot(frc)

## End(Not run)

</code></pre>

<hr>
<h2 id='elm.fast'>ELM (fast) neural network.</h2><span id='topic+elm.fast'></span>

<h3>Description</h3>

<p>Fit ELM (fast) neural network. This is an ELM implementation that does not rely on neuralnets package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elm.fast(
  y,
  x,
  hd = NULL,
  type = c("lasso", "ridge", "step", "ls"),
  reps = 20,
  comb = c("median", "mean", "mode"),
  direct = c(FALSE, TRUE),
  linscale = c(TRUE, FALSE),
  output = c("linear", "logistic"),
  core = c("FALSE", "TRUE"),
  ortho = c(FALSE, TRUE)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elm.fast_+3A_y">y</code></td>
<td>
<p>Target variable.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_x">x</code></td>
<td>
<p>Explanatory variables. Each column is a variable.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_hd">hd</code></td>
<td>
<p>Starting number of hidden nodes (scalar). Use NULL to automatically specify.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_type">type</code></td>
<td>
<p>Estimation type for output layer weights. Can be &quot;lasso&quot; (lasso with CV), &quot;ridge&quot; (ridge regression with CV), &quot;step&quot; (stepwise regression with AIC) or &quot;lm&quot; (linear regression).</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_reps">reps</code></td>
<td>
<p>Number of networks to train.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_comb">comb</code></td>
<td>
<p>Combination operator for forecasts when reps &gt; 1. Can be &quot;median&quot;, &quot;mode&quot; (based on KDE estimation) and &quot;mean&quot;.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_direct">direct</code></td>
<td>
<p>Use direct input-output connections to model strictly linear effects. Can be TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_linscale">linscale</code></td>
<td>
<p>Scale inputs linearly between -0.8 to 0.8. If output == &quot;logistic&quot; then scaling is between 0 and 1.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_output">output</code></td>
<td>
<p>Type of output layer. It can be &quot;linear&quot; or &quot;logistic&quot;. If &quot;logistic&quot; then type must be set to &quot;lasso&quot;.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_core">core</code></td>
<td>
<p>If TRUE skips calculation of final fitted values and MSE. Called internally by <code>"elm"</code> function.</p>
</td></tr>
<tr><td><code id="elm.fast_+3A_ortho">ortho</code></td>
<td>
<p>If TRUE then the initial weights between the input and hidden layers are orthogonal (only when number of input variable &lt;= sample size).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;<code>elm.fast</code>&quot;.
The function <code>plot</code> produces a plot the network fit.
An object of class <code>"elm.fast"</code> is a list containing the following elements:
</p>

<ul>
<li> <p><code>hd</code> - Number of hidden nodes. This is a vector with a different number for each training repetition.
</p>
</li>
<li> <p><code>W.in</code> - Input weights for each training repetition.
</p>
</li>
<li> <p><code>W</code> - Output layer weights for each repetition.
</p>
</li>
<li> <p><code>b</code> - Output node bias for each training repetition.
</p>
</li>
<li> <p><code>W.dct</code> - Direct connection weights argument if direct == TRUE for each training repetition. Otherwuse NULL.
</p>
</li>
<li> <p><code>fitted.all</code> - Fitted values for each training repetition.
</p>
</li>
<li> <p><code>fitted</code> - Ensemble fitted values.
</p>
</li>
<li> <p><code>y</code> - Target variable.
</p>
</li>
<li> <p><code>type</code> - Estimation used for output layer weights.
</p>
</li>
<li> <p><code>comb</code> - Combination operator used.
</p>
</li>
<li> <p><code>direct</code> - Presence of direct input-output connections.
</p>
</li>
<li> <p><code>minmax</code> - If scaling is used this contains the scaling information for the target variable.
</p>
</li>
<li> <p><code>minmax.x</code> - If scaling is used this contains the scaling information for the input variables.
</p>
</li>
<li> <p><code>MSE</code> - In-sample Mean Squared Error.
</p>
</li></ul>



<h3>Note</h3>

<p>This implementation of ELM is more appropriate when the number of inputs is several hundreds. For time series modelling use <code><a href="#topic+elm">elm</a></code> instead.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> For combination operators see: Kourentzes N., Barrow B.K., Crone S.F. (2014) <a href="https://kourentzes.com/forecasting/2014/04/19/neural-network-ensemble-operators-for-time-series-forecasting/">Neural network ensemble operators for time series forecasting</a>. <em>Expert Systems with Applications</em>, <b>41</b>(<b>9</b>), 4235-4244.
</p>
</li>
<li><p> For ELMs see: Huang G.B., Zhou H., Ding X. (2006) Extreme learning machine: theory and applications. <em>Neurocomputing</em>, <b>70</b>(<b>1</b>), 489-501.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+elm">elm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 p &lt;- 2000
 n &lt;- 150
 X &lt;- matrix(rnorm(p*n),nrow=n)
 b &lt;- cbind(rnorm(p))
 Y &lt;- X %*% b
 fit &lt;- elm.fast(Y,X)
 print(fit)

## End(Not run)

</code></pre>

<hr>
<h2 id='elm.thief'>ELM network for THieF.</h2><span id='topic+elm.thief'></span>

<h3>Description</h3>

<p>Function for ELM forecasting with Temporal Hierarchies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elm.thief(y, h = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elm.thief_+3A_y">y</code></td>
<td>
<p>Input time series. Can be ts or msts object.</p>
</td></tr>
<tr><td><code id="elm.thief_+3A_h">h</code></td>
<td>
<p>Forecast horizon. If NULL then h is set to match frequency of time series.</p>
</td></tr>
<tr><td><code id="elm.thief_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+elm">elm</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of classes &quot;<code>forecast.net</code>&quot; and &quot;<code>forecast</code>&quot;.
The function <code>plot</code> produces a plot of the forecasts.
An object of class <code>"forecast.net"</code> is a list containing the following elements:
</p>

<ul>
<li> <p><code>method</code> - The name of the forecasting method as a character string.
</p>
</li>
<li> <p><code>mean</code> - Point forecasts as a time series.
</p>
</li>
<li> <p><code>all.mean</code> - An array h x reps of all ensemble members forecasts, where reps are the number of ensemble members.
</p>
</li>
<li> <p><code>x</code> - The original time series (either <code>fit</code> used to create the network.
</p>
</li>
<li> <p><code>fitted</code> - Fitted values. Any values not fitted for the initial period of the time series are imputted with NA.
</p>
</li>
<li> <p><code>residuals</code> - Residuals from the fitted network.
</p>
</li></ul>



<h3>Note</h3>

<p>This function is created to work with Temporal Hierarchied (<a href="https://cran.r-project.org/package=thief">thief</a> package). For conventional ELM networks use <code><a href="#topic+elm">elm</a></code>.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> For forecasting with temporal hierarchies see: Athanasopoulos G., Hyndman R.J., Kourentzes N., Petropoulos F. (2017) <a href="https://kourentzes.com/forecasting/2017/02/27/forecasting-with-temporal-hierarchies-3/">Forecasting with Temporal Hierarchies</a>. <em>European Journal of Operational research</em>, <b>262</b>(<b>1</b>), 60-74.
</p>
</li>
<li><p> For combination operators see: Kourentzes N., Barrow B.K., Crone S.F. (2014) <a href="https://kourentzes.com/forecasting/2014/04/19/neural-network-ensemble-operators-for-time-series-forecasting/">Neural network ensemble operators for time series forecasting</a>. <em>Expert Systems with Applications</em>, <b>41</b>(<b>9</b>), 4235-4244.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+elm">elm</a></code>, <code><a href="#topic+mlp.thief">mlp.thief</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(thief)
  frc &lt;- thief(AirPassengers,forecastfunction=elm.thief)
  plot(frc)

## End(Not run)

</code></pre>

<hr>
<h2 id='forecast.elm'>Forecast using ELM neural network.</h2><span id='topic+forecast.elm'></span>

<h3>Description</h3>

<p>Create forecasts using ELM neural networks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'elm'
forecast(object, h = NULL, y = NULL, xreg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forecast.elm_+3A_object">object</code></td>
<td>
<p>ELM network object, produced using <code><a href="#topic+elm">elm</a></code>.</p>
</td></tr>
<tr><td><code id="forecast.elm_+3A_h">h</code></td>
<td>
<p>Forecast horizon. If NULL then h is set to match frequency of time series.</p>
</td></tr>
<tr><td><code id="forecast.elm_+3A_y">y</code></td>
<td>
<p>Optionally forecast using different data than what the network was trained on. Expected to create havoc and do really bad things!</p>
</td></tr>
<tr><td><code id="forecast.elm_+3A_xreg">xreg</code></td>
<td>
<p>Exogenous regressors. Each column is a different regressor and the sample size must be at least as long as the target in-sample set plus the forecast horizon, but can be longer. Set it to NULL if no xreg inputs are used.</p>
</td></tr>
<tr><td><code id="forecast.elm_+3A_...">...</code></td>
<td>
<p>Unused argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of classes &quot;<code>forecast.net</code>&quot; and &quot;<code>forecast</code>&quot;.
The function <code>plot</code> produces a plot of the forecasts.
An object of class <code>"forecast.net"</code> is a list containing the following elements:
</p>

<ul>
<li> <p><code>method</code> - The name of the forecasting method as a character string.
</p>
</li>
<li> <p><code>mean</code> - Point forecasts as a time series.
</p>
</li>
<li> <p><code>all.mean</code> - An array h x reps of all ensemble members forecasts, where reps are the number of ensemble members.
</p>
</li>
<li> <p><code>x</code> - The original time series used to create the network.
</p>
</li>
<li> <p><code>fitted</code> - Fitted values.
</p>
</li>
<li> <p><code>residuals</code> - Residuals from the fitted network.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+elm">elm</a></code>, <code><a href="#topic+elm.thief">elm.thief</a></code>, <code><a href="#topic+mlp">mlp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 fit &lt;- elm(AirPassengers)
 plot(fit)
 frc &lt;- forecast(fit,h=36)
 plot(frc)

## End(Not run)

</code></pre>

<hr>
<h2 id='forecast.mlp'>Forecast using MLP neural network.</h2><span id='topic+forecast.mlp'></span>

<h3>Description</h3>

<p>Create forecasts using MLP neural networks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlp'
forecast(object, h = NULL, y = NULL, xreg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forecast.mlp_+3A_object">object</code></td>
<td>
<p>MLP network object, produced using <code><a href="#topic+mlp">mlp</a></code>.</p>
</td></tr>
<tr><td><code id="forecast.mlp_+3A_h">h</code></td>
<td>
<p>Forecast horizon. If NULL then h is set to match frequency of time series.</p>
</td></tr>
<tr><td><code id="forecast.mlp_+3A_y">y</code></td>
<td>
<p>Optionally forecast using different data than what the network was trained on. Expected to create havoc and do really bad things!</p>
</td></tr>
<tr><td><code id="forecast.mlp_+3A_xreg">xreg</code></td>
<td>
<p>Exogenous regressors. Each column is a different regressor and the sample size must be at least as long as the target in-sample set plus the forecast horizon, but can be longer. Set it to NULL if no xreg inputs are used.</p>
</td></tr>
<tr><td><code id="forecast.mlp_+3A_...">...</code></td>
<td>
<p>Unused argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of classes &quot;<code>forecast.net</code>&quot; and &quot;<code>forecast</code>&quot;.
The function <code>plot</code> produces a plot of the forecasts.
An object of class <code>"forecast.net"</code> is a list containing the following elements:
</p>

<ul>
<li> <p><code>method</code> - The name of the forecasting method as a character string.
</p>
</li>
<li> <p><code>mean</code> - Point forecasts as a time series.
</p>
</li>
<li> <p><code>all.mean</code> - An array h x reps of all ensemble members forecasts, where reps are the number of ensemble members.
</p>
</li>
<li> <p><code>x</code> - The original time series used to create the network.
</p>
</li>
<li> <p><code>fitted</code> - Fitted values.
</p>
</li>
<li> <p><code>residuals</code> - Residuals from the fitted network.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlp">mlp</a></code>, <code><a href="#topic+mlp.thief">mlp.thief</a></code>, <code><a href="#topic+elm">elm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 fit &lt;- mlp(AirPassengers)
 plot(fit)
 frc &lt;- forecast(fit,h=36)
 plot(frc)

## End(Not run)

</code></pre>

<hr>
<h2 id='linscale'>Apply minmax linear scaling to a vector.</h2><span id='topic+linscale'></span>

<h3>Description</h3>

<p>Apply minmax linear scaling to a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linscale(x, minmax = NULL, rev = c(FALSE, TRUE))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="linscale_+3A_x">x</code></td>
<td>
<p>Input vector.</p>
</td></tr>
<tr><td><code id="linscale_+3A_minmax">minmax</code></td>
<td>
<p>minmax must be a list with elements &quot;mn&quot;, &quot;mx&quot;, &quot;mn.orig&quot; and &quot;mx.orig&quot;, where &quot;mn&quot; and &quot;mx&quot; refer to the target min and max, and the remaining two refer to the current vector min and max. By default mn=-1 and mx=1. mn.orig and mx.orig can be missing, unless the scaling is reversed.</p>
</td></tr>
<tr><td><code id="linscale_+3A_rev">rev</code></td>
<td>
<p>Reverse scaling back to original: TRUE or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Outputs a list with elements:
</p>

<ul>
<li> <p><code>x</code> - Scaled vector.
</p>
</li>
<li> <p><code>minmax</code> - List with resulting mn, mx, mn.orig and mx.orig. Can be used as input to reverse scaling.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  y &lt;- rnorm(20)*100
  sc &lt;- linscale(y)
  x &lt;- sc$x
  print(c(min(y),max(y)))
  print(c(min(x),max(x)))
  sc.rev &lt;- linscale(x,minmax=sc$minmax,rev=TRUE)
  print(c(min(sc.rev$x),max(sc.rev$x)))

</code></pre>

<hr>
<h2 id='mlp'>Multilayer Perceptron for time series forecasting</h2><span id='topic+mlp'></span>

<h3>Description</h3>

<p>This function fits MLP neural networks for time series forecasting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlp(
  y,
  m = frequency(y),
  hd = NULL,
  reps = 20,
  comb = c("median", "mean", "mode"),
  lags = NULL,
  keep = NULL,
  difforder = NULL,
  outplot = c(FALSE, TRUE),
  sel.lag = c(TRUE, FALSE),
  allow.det.season = c(TRUE, FALSE),
  det.type = c("auto", "bin", "trg"),
  xreg = NULL,
  xreg.lags = NULL,
  xreg.keep = NULL,
  hd.auto.type = c("set", "valid", "cv", "elm"),
  hd.max = NULL,
  model = NULL,
  retrain = c(FALSE, TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlp_+3A_y">y</code></td>
<td>
<p>Input time series. Can be ts or msts object.</p>
</td></tr>
<tr><td><code id="mlp_+3A_m">m</code></td>
<td>
<p>Frequency of the time series. By default it is picked up from y.</p>
</td></tr>
<tr><td><code id="mlp_+3A_hd">hd</code></td>
<td>
<p>Number of hidden nodes. This can be a vector, where each number represents the number of hidden nodes of a different hidden layer.</p>
</td></tr>
<tr><td><code id="mlp_+3A_reps">reps</code></td>
<td>
<p>Number of networks to train, the result is the ensemble forecast.</p>
</td></tr>
<tr><td><code id="mlp_+3A_comb">comb</code></td>
<td>
<p>Combination operator for forecasts when reps &gt; 1. Can be &quot;median&quot;, &quot;mode&quot; (based on KDE estimation) and &quot;mean&quot;.</p>
</td></tr>
<tr><td><code id="mlp_+3A_lags">lags</code></td>
<td>
<p>Lags of y to use as inputs. If none provided then 1:frequency(y) is used. Use 0 for no univariate lags.</p>
</td></tr>
<tr><td><code id="mlp_+3A_keep">keep</code></td>
<td>
<p>Logical vector to force lags to stay in the model if sel.lag == TRUE. If NULL then it keep = rep(FALSE,length(lags)).</p>
</td></tr>
<tr><td><code id="mlp_+3A_difforder">difforder</code></td>
<td>
<p>Vector including the differencing lags. For example c(1,12) will apply first and seasonal (12) differences. For no differencing use 0. For automatic selection use NULL.</p>
</td></tr>
<tr><td><code id="mlp_+3A_outplot">outplot</code></td>
<td>
<p>Provide plot of model fit. Can be TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="mlp_+3A_sel.lag">sel.lag</code></td>
<td>
<p>Automatically select lags. Can be TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="mlp_+3A_allow.det.season">allow.det.season</code></td>
<td>
<p>Permit modelling seasonality with deterministic dummies.</p>
</td></tr>
<tr><td><code id="mlp_+3A_det.type">det.type</code></td>
<td>
<p>Type of deterministic seasonality dummies to use. This can be &quot;bin&quot; for binary or &quot;trg&quot; for a sine-cosine pair. With &quot;auto&quot; if ony a single seasonality is used and periodicity is up to 12 then &quot;bin&quot; is used, otherwise &quot;trg&quot;.</p>
</td></tr>
<tr><td><code id="mlp_+3A_xreg">xreg</code></td>
<td>
<p>Exogenous regressors. Each column is a different regressor and the sample size must be at least as long as the target in-sample set, but can be longer.</p>
</td></tr>
<tr><td><code id="mlp_+3A_xreg.lags">xreg.lags</code></td>
<td>
<p>This is a list containing the lags for each exogenous variable. Each list is a numeric vector containing lags. If xreg has 3 columns then the xreg.lags list must contain three elements. If NULL then it is automatically specified.</p>
</td></tr>
<tr><td><code id="mlp_+3A_xreg.keep">xreg.keep</code></td>
<td>
<p>List of logical vectors to force lags of xreg to stay in the model if sel.lag == TRUE. If NULL then all exogenous lags can be removed. The syntax for multiple xreg is the same as for xreg.lags.</p>
</td></tr>
<tr><td><code id="mlp_+3A_hd.auto.type">hd.auto.type</code></td>
<td>
<p>Used only if hd==NULL. &quot;set&quot; fixes hd=5. &quot;valid&quot; uses a 20% validation set (randomly) sampled to find the best number of hidden nodes. &quot;cv&quot; uses 5-fold cross-validation. &quot;elm&quot; uses ELM to estimate the number of hidden nodes (experimental).</p>
</td></tr>
<tr><td><code id="mlp_+3A_hd.max">hd.max</code></td>
<td>
<p>When hd.auto.type is set to either &quot;valid&quot; or &quot;cv&quot; then this argument can be used to set the maximum number of hidden nodes to evaluate, otherwise the maximum is set automatically.</p>
</td></tr>
<tr><td><code id="mlp_+3A_model">model</code></td>
<td>
<p>A previously trained mlp object. If this is provided then the same model is fitted to y, without re-estimating any model parameters.</p>
</td></tr>
<tr><td><code id="mlp_+3A_retrain">retrain</code></td>
<td>
<p>If a previous model is provided, retrain the network or not.</p>
</td></tr>
<tr><td><code id="mlp_+3A_...">...</code></td>
<td>
<p>Additional inputs for neuralnet function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return object of class <code>mlp</code>.
The function <code>plot</code> produces a plot the network architecture.
<code>mlp</code> contains:
</p>

<ul>
<li> <p><code>net</code> - MLP networks.
</p>
</li>
<li> <p><code>hd</code> - Number of hidden nodes.
</p>
</li>
<li> <p><code>lags</code> - Input lags used.
</p>
</li>
<li> <p><code>xreg.lags</code> - <code>xreg</code> lags used.
</p>
</li>
<li> <p><code>difforder</code> - Differencing used.
</p>
</li>
<li> <p><code>sdummy</code> - Use of deterministic seasonality.
</p>
</li>
<li> <p><code>ff</code> - Seasonal frequencies detected in data (taken from ts or msts object).
</p>
</li>
<li> <p><code>ff.det</code> - Seasonal frequencies coded using deterministic dummies.
</p>
</li>
<li> <p><code>det.type</code> - Type of determistic seasonality.
</p>
</li>
<li> <p><code>y</code> - Input time series.
</p>
</li>
<li> <p><code>minmax</code> - Scaling structure.
</p>
</li>
<li> <p><code>xreg.minmax</code> - Scaling structure for xreg variables.
</p>
</li>
<li> <p><code>comb</code> - Combination operator used.
</p>
</li>
<li> <p><code>fitted</code> - Fitted values.
</p>
</li>
<li> <p><code>MSE</code> - In-sample Mean Squared Error.
</p>
</li>
<li> <p><code>MSEH</code> - If <code>hd.auto.type</code> is set to either &quot;valid&quot; or &quot;cv&quot; an array of the MSE error for each network size is provided. Otherwise this is NULL.
</p>
</li></ul>



<h3>Note</h3>

<p>To use mlp with Temporal Hierarchies (<a href="https://cran.r-project.org/package=thief">thief</a> package) see <code><a href="#topic+mlp.thief">mlp.thief</a></code>.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> For an introduction to neural networks see: Ord K., Fildes R., Kourentzes N. (2017) <a href="https://kourentzes.com/forecasting/2017/10/16/new-forecasting-book-principles-of-business-forecasting-2e/">Principles of Business Forecasting 2e</a>. <em>Wessex Press Publishing Co.</em>, Chapter 10.
</p>
</li>
<li><p> For combination operators see: Kourentzes N., Barrow B.K., Crone S.F. (2014) <a href="https://kourentzes.com/forecasting/2014/04/19/neural-network-ensemble-operators-for-time-series-forecasting/">Neural network ensemble operators for time series forecasting</a>. <em>Expert Systems with Applications</em>, <b>41</b>(<b>9</b>), 4235-4244.
</p>
</li>
<li><p> For variable selection see: Crone S.F., Kourentzes N. (2010) <a href="https://kourentzes.com/forecasting/2010/04/19/feature-selection-for-time-series-prediction-a-combined-filter-and-wrapper-approach-for-neural-networks/">Feature selection for time series prediction – A combined filter and wrapper approach for neural networks</a>. <em>Neurocomputing</em>, <b>73</b>(<b>10</b>), 1923-1936.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+forecast.mlp">forecast.mlp</a></code>, <code><a href="#topic+mlp.thief">mlp.thief</a></code>, <code><a href="#topic+elm">elm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 fit &lt;- mlp(AirPassengers)
 print(fit)
 plot(fit)
 frc &lt;- forecast(fit,h=36)
 plot(frc)

## End(Not run)

</code></pre>

<hr>
<h2 id='mlp.thief'>MLP network for THieF.</h2><span id='topic+mlp.thief'></span>

<h3>Description</h3>

<p>Function for MLP forecasting with Temporal Hierarchies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlp.thief(y, h = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlp.thief_+3A_y">y</code></td>
<td>
<p>Input time series. Can be ts or msts object.</p>
</td></tr>
<tr><td><code id="mlp.thief_+3A_h">h</code></td>
<td>
<p>Forecast horizon. If NULL then h is set to match frequency of time series.</p>
</td></tr>
<tr><td><code id="mlp.thief_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+mlp">mlp</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of classes &quot;<code>forecast.net</code>&quot; and &quot;<code>forecast</code>&quot;.
The function <code>plot</code> produces a plot of the forecasts.
An object of class <code>"forecast.net"</code> is a list containing the following elements:
</p>

<ul>
<li> <p><code>method</code> - The name of the forecasting method as a character string.
</p>
</li>
<li> <p><code>mean</code> - Point forecasts as a time series.
</p>
</li>
<li> <p><code>all.mean</code> - An array h x reps of all ensemble members forecasts, where reps are the number of ensemble members.
</p>
</li>
<li> <p><code>x</code> - The original time series (either <code>fit</code> used to create the network.
</p>
</li>
<li> <p><code>fitted</code> - Fitted values. Any values not fitted for the initial period of the time series are imputted with NA.
</p>
</li>
<li> <p><code>residuals</code> - Residuals from the fitted network.
</p>
</li></ul>



<h3>Note</h3>

<p>This function is created to work with Temporal Hierarchied (<a href="https://cran.r-project.org/package=thief">thief</a> package). For conventional MLP networks use <code><a href="#topic+mlp">mlp</a></code>.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> For forecasting with temporal hierarchies see: Athanasopoulos G., Hyndman R.J., Kourentzes N., Petropoulos F. (2017) <a href="https://kourentzes.com/forecasting/2017/02/27/forecasting-with-temporal-hierarchies-3/">Forecasting with Temporal Hierarchies</a>. <em>European Journal of Operational research</em>, <b>262</b>(<b>1</b>), 60-74.
</p>
</li>
<li><p> For combination operators see: Kourentzes N., Barrow B.K., Crone S.F. (2014) <a href="https://kourentzes.com/forecasting/2014/04/19/neural-network-ensemble-operators-for-time-series-forecasting/">Neural network ensemble operators for time series forecasting</a>. <em>Expert Systems with Applications</em>, <b>41</b>(<b>9</b>), 4235-4244.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+mlp">mlp</a></code>, <code><a href="#topic+elm.thief">elm.thief</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(thief)
  frc &lt;- thief(AirPassengers,forecastfunction=mlp.thief)
  plot(frc)

## End(Not run)

</code></pre>

<hr>
<h2 id='nnfor'>nnfor:Time Series Forecasting with Neural Networks</h2><span id='topic+nnfor'></span>

<h3>Description</h3>

<p>The <span class="pkg">nnfor</span> package provides automatic time series modelling with neural networks. It facilitates fully automatic, semi-manual or fully manual specification of networks, using multilayer perceptrons (<code><a href="#topic+mlp">mlp</a></code>) and extreme learning machines (<code><a href="#topic+elm">elm</a></code>).
</p>


<h3>Note</h3>

<p>You can find a tutorial how to use the package <a href="https://kourentzes.com/forecasting/2019/01/16/tutorial-for-the-nnfor-r-package/">here</a>.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> For an introduction to neural networks see: Ord K., Fildes R., Kourentzes N. (2017) <a href="https://kourentzes.com/forecasting/2017/10/16/new-forecasting-book-principles-of-business-forecasting-2e/">Principles of Business Forecasting 2e</a>. <em>Wessex Press Publishing Co.</em>, Chapter 10.
</p>
</li>
<li><p> For ensemble combination operators see: Kourentzes N., Barrow B.K., Crone S.F. (2014) <a href="https://kourentzes.com/forecasting/2014/04/19/neural-network-ensemble-operators-for-time-series-forecasting/">Neural network ensemble operators for time series forecasting</a>. <em>Expert Systems with Applications</em>, <b>41</b>(<b>9</b>), 4235-4244.
</p>
</li>
<li><p> For variable selection see: Crone S.F., Kourentzes N. (2010) <a href="https://kourentzes.com/forecasting/2010/04/19/feature-selection-for-time-series-prediction-a-combined-filter-and-wrapper-approach-for-neural-networks/">Feature selection for time series prediction – A combined filter and wrapper approach for neural networks</a>. <em>Neurocomputing</em>, <b>73</b>(<b>10</b>), 1923-1936.
</p>
</li></ul>


<hr>
<h2 id='plot.elm'>Plot ELM network.</h2><span id='topic+plot.elm'></span>

<h3>Description</h3>

<p>Produces a plot of the ELM network architecture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'elm'
plot(x, r = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.elm_+3A_x">x</code></td>
<td>
<p>ELM network object, produced using <code><a href="#topic+elm">elm</a></code>.</p>
</td></tr>
<tr><td><code id="plot.elm_+3A_r">r</code></td>
<td>
<p>Ensemple member to plot.</p>
</td></tr>
<tr><td><code id="plot.elm_+3A_...">...</code></td>
<td>
<p>Unused argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None. Function produces a plot.
</p>


<h3>Note</h3>

<p>Neurons are coloured with <code>"lightgrey"</code>. Seasonal dummies are coloured with <code>"lightpink"</code> and xreg with <code>"lightblue"</code>.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+elm">elm</a></code>, <code><a href="#topic+mlp">mlp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 fit &lt;- elm(AirPassengers)
 print(fit)
 plot(fit)
 frc &lt;- forecast(fit,h=36)
 plot(frc)

## End(Not run)

</code></pre>

<hr>
<h2 id='plot.mlp'>Plot MLP network.</h2><span id='topic+plot.mlp'></span>

<h3>Description</h3>

<p>Produces a plot of the MLP network architecture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlp'
plot(x, r = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.mlp_+3A_x">x</code></td>
<td>
<p>MLP network object, produced using <code><a href="#topic+mlp">mlp</a></code>.</p>
</td></tr>
<tr><td><code id="plot.mlp_+3A_r">r</code></td>
<td>
<p>Ensemple member to plot.</p>
</td></tr>
<tr><td><code id="plot.mlp_+3A_...">...</code></td>
<td>
<p>Unused argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None. Function produces a plot.
</p>


<h3>Note</h3>

<p>Neurons are coloured with <code>"lightgrey"</code>. Seasonal dummies are coloured with <code>"lightpink"</code> and xreg with <code>"lightblue"</code>.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+elm">elm</a></code>, <code><a href="#topic+mlp">mlp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 fit &lt;- mlp(AirPassengers)
 print(fit)
 plot(fit)
 frc &lt;- forecast(fit,h=36)
 plot(frc)

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.elm.fast'>Predictions for ELM (fast) network.</h2><span id='topic+predict.elm.fast'></span>

<h3>Description</h3>

<p>Calculate predictions for ELM (fast) network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'elm.fast'
predict(object, newx, na.rm = c(FALSE, TRUE), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.elm.fast_+3A_object">object</code></td>
<td>
<p>ELM network object, produced using <code><a href="#topic+elm.fast">elm.fast</a></code>.</p>
</td></tr>
<tr><td><code id="predict.elm.fast_+3A_newx">newx</code></td>
<td>
<p>Explanatory variables. Each column is a variable.</p>
</td></tr>
<tr><td><code id="predict.elm.fast_+3A_na.rm">na.rm</code></td>
<td>
<p>If TRUE remove columns and object produces an ensemble forecast, then remove any members that give NA in their forecasts.</p>
</td></tr>
<tr><td><code id="predict.elm.fast_+3A_...">...</code></td>
<td>
<p>Unused argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with:
</p>

<ul>
<li> <p><code>Y.hat</code> - Ensemble prediction.
</p>
</li>
<li> <p><code>Y.all</code> - Predictions of each training repetition.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+elm.fast">elm.fast</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 p &lt;- 2000
 n &lt;- 150
 X &lt;- matrix(rnorm(p*n),nrow=n)
 b &lt;- cbind(rnorm(p))
 Y &lt;- X %*% b
 fit &lt;- elm.fast(Y,X)
 predict(fit,X)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
