<!DOCTYPE html><html><head><title>Help for package MFSIS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MFSIS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BcorSIS'><p>A Generic Sure Independence Screening Procedure</p></a></li>
<li><a href='#CAS'><p>Category-Adaptive Variable Screening for Ultra-High Dimensional Heterogeneous Categorical Data</p></a></li>
<li><a href='#CISIS'><p>Model-Free Feature screening Based on Concordance Index for Ultra-High Dimensional Categorical Data</p></a></li>
<li><a href='#Cor'><p>Parallel function</p>
This is a parallel function about the projection correlation.</a></li>
<li><a href='#CSIS'><p>Model-Free Feature screening Based on Concordance Index Statistic</p></a></li>
<li><a href='#DCSIS'><p>Feature Screening via Distance Correlation Learning</p></a></li>
<li><a href='#GendataAFT'><p>Generate simulation data (Survival data based on the accelerated failure time model)</p></a></li>
<li><a href='#GendataCox'><p>Generate simulation data (Survival data based on the Cox model)</p></a></li>
<li><a href='#GendataGP'><p>Generate simulation data (Complete data with group predictors)</p></a></li>
<li><a href='#GendataIM'><p>Generate simulation data (Complete data for intersection variables)</p></a></li>
<li><a href='#GendataLDA'><p>Generate simulation data (Categorial based on linear discriminant analysis model)</p></a></li>
<li><a href='#GendataLGM'><p>Generate simulation data (Binary category data based on logistic model)</p></a></li>
<li><a href='#GendataLM'><p>Generate simulation data (Complete data based on linear models)</p></a></li>
<li><a href='#GendataMRM'><p>Generate simulation data (Multivariate response models)</p></a></li>
<li><a href='#GendataPM'><p>Generate simulation data (Discrete response data based on poisson model)</p></a></li>
<li><a href='#GendataTM'><p>Generate simulation data (Complete data based on transformation model)</p></a></li>
<li><a href='#get_arccos'><p>Arccos function</p></a></li>
<li><a href='#Kfilter'><p>The Kolmogorov filter for variable screening</p></a></li>
<li><a href='#Kfilter_fused'><p>The fused kolmogorov filter: a nonparametric model-free screening method</p></a></li>
<li><a href='#Kfilter_single'><p>The Kolmogorov filter for variable screening in high-dimensional binary classification</p></a></li>
<li><a href='#MDCSIS'><p>Martingale Difference Correlation and Its Use in High-Dimensional Variable Screening</p></a></li>
<li><a href='#MFSIS'><p>Model-free feature screening procedures</p></a></li>
<li><a href='#MVSIS'><p>Model-Free Feature Screening for Ultrahigh Dimensional Discriminant Analysis</p></a></li>
<li><a href='#PCSIS'><p>Model-Free Feature Screening Based on the Projection Correlation</p></a></li>
<li><a href='#projection_corr'><p>Projection correlation function</p></a></li>
<li><a href='#PSIS'><p>Ultrahigh-Dimensional Multiclass Linear Discriminant Analysis by Pairwise Sure Independence Screening</p></a></li>
<li><a href='#req_py'><p>Detect Python Module</p></a></li>
<li><a href='#Simdata'><p>Generate simulation data (The unified class framework to generate simulation data)</p></a></li>
<li><a href='#SIRS'><p>Model-Free Feature Screening for Ultrahigh Dimensional Data</p></a></li>
<li><a href='#SIS'><p>Sure Independent Screening</p></a></li>
<li><a href='#WLS'><p>A Model-free Variable Screening Method Based on Leverage Score</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Model-Free Sure Independent Screening Procedures</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-30</td>
</tr>
<tr>
<td>Author:</td>
<td>Xuewei Cheng [aut, cre],
  Hong Wang [aut],
  Liping Zhu [aut],
  Wei Zhong [aut],
  Hanpu Zhou [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xuewei Cheng &lt;xwcheng@hunnu.edu.cn&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of popular screening methods that are commonly 
  employed in ultra-high and high dimensional data. Through this publicly 
  available package, we provide a unified framework to carry out model-free 
  screening procedures including 
  SIS (Fan and Lv (2008) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9868.2008.00674.x">doi:10.1111/j.1467-9868.2008.00674.x</a>&gt;), 
  SIRS(Zhu et al. (2011)&lt;<a href="https://doi.org/10.1198%2Fjasa.2011.tm10563">doi:10.1198/jasa.2011.tm10563</a>&gt;), 
  DC-SIS (Li et al. (2012) &lt;<a href="https://doi.org/10.1080%2F01621459.2012.695654">doi:10.1080/01621459.2012.695654</a>&gt;), 
  MDC-SIS(Shao and Zhang (2014) &lt;<a href="https://doi.org/10.1080%2F01621459.2014.887012">doi:10.1080/01621459.2014.887012</a>&gt;), 
  Bcor-SIS (Pan et al. (2019) &lt;<a href="https://doi.org/10.1080%2F01621459.2018.1462709">doi:10.1080/01621459.2018.1462709</a>&gt;), 
  PC-Screen (Liu et al. (2020) &lt;<a href="https://doi.org/10.1080%2F01621459.2020.1783274">doi:10.1080/01621459.2020.1783274</a>&gt;), 
  WLS (Zhong et al.(2021) &lt;<a href="https://doi.org/10.1080%2F01621459.2021.1918554">doi:10.1080/01621459.2021.1918554</a>&gt;), 
  Kfilter (Mai and Zou (2015) &lt;<a href="https://doi.org/10.1214%2F14-AOS1303">doi:10.1214/14-AOS1303</a>&gt;), 
  MVSIS (Cui et al. (2015) &lt;<a href="https://doi.org/10.1080%2F01621459.2014.920256">doi:10.1080/01621459.2014.920256</a>&gt;), 
  PSIS (Pan et al. (2016) &lt;<a href="https://doi.org/10.1080%2F01621459.2014.998760">doi:10.1080/01621459.2014.998760</a>&gt;), 
  CAS (Xie et al. (2020) &lt;<a href="https://doi.org/10.1080%2F01621459.2019.1573734">doi:10.1080/01621459.2019.1573734</a>&gt;), 
  CI-SIS (Cheng and Wang. (2023) &lt;<a href="https://doi.org/10.1016%2Fj.cmpb.2022.107269">doi:10.1016/j.cmpb.2022.107269</a>&gt;) and 
  CSIS (Cheng et al. (2023) &lt;<a href="https://doi.org/10.1007%2Fs00180-023-01399-5">doi:10.1007/s00180-023-01399-5</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Python (&gt;= 3.8.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>survival, MASS, Ball, reticulate, stats, crayon, cli, dr,
foreach, parallel, doParallel</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, utils, pkgdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-30 04:24:10 UTC; ChengXuewei</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-30 07:20:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='BcorSIS'>A Generic Sure Independence Screening Procedure</h2><span id='topic+BcorSIS'></span>

<h3>Description</h3>

<p>A generic nonparametric sure independence screening procedure,
called BCor-SIS, on the basis of a recently developed universal
dependence measure: Ball correlation.
We show that the proposed procedure has strong screening consistency even
when the dimensionality is an exponential order of the sample size
without imposing sub-exponential moment assumptions on the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BcorSIS(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BcorSIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="BcorSIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1. For survival models, Y should
be an object of class Surv, as provided by the function
Surv() in the package survival.</p>
</td></tr>
<tr><td><code id="BcorSIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by BcorSIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Pan, W., X. Wang, H. Zhang, H. Zhu, and J. Zhu (2020). Ball covariance: A generic measure of dependence in banach space. Journal of the American Statistical Association 115(529),307–317.
</p>
<p>Pan, W., X. Wang, W. Xiao, and H. Zhu (2019). A generic sure independence screening procedure. Journal of the American Statistical Association 114(526), 928–937.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Scenario 1  generate complete data
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A1 &lt;- BcorSIS(X, Y, n / log(n))
A1

## Scenario 2  generate survival data
library(survival)
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataCox(n, p, rho)
data &lt;- cbind(data[[1]], data[[2]], data[[3]])
colnames(data)[ncol(data)] &lt;- c("status")
colnames(data)[(ncol(data) - 1)] &lt;- c("time")
colnames(data)[(1:(ncol(data) - 2))] &lt;- c(paste0("X", 1:(ncol(data) - 2)))
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 2)]
Y &lt;- Surv(data[, (ncol(data) - 1)], data[, ncol(data)])
A2 &lt;- BcorSIS(X, Y, n / log(n))
A2
</code></pre>

<hr>
<h2 id='CAS'>Category-Adaptive Variable Screening for Ultra-High Dimensional Heterogeneous Categorical Data</h2><span id='topic+CAS'></span>

<h3>Description</h3>

<p>A category-adaptive screening procedure with high-dimensional heterogeneous data, which is to detect category-specific important covariates.
This proposal is a model-free approach without any specification of a regression model and an adaptive procedure
in the sense that the set of active variables is allowed to vary across different categories, thus making it more
flexible to accommodate heterogeneity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAS(X, Y, nsis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="CAS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="CAS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by CAS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Pan, R., Wang, H., and Li, R. (2016). Ultrahigh-dimensional multiclass linear discriminant analysis by pairwise sure independence screening. Journal of the American Statistical Association, 111(513):169–179.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLGM(n, p, rho)
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- CAS(X, Y, n / log(n))
A

</code></pre>

<hr>
<h2 id='CISIS'>Model-Free Feature screening Based on Concordance Index for Ultra-High Dimensional Categorical Data</h2><span id='topic+CISIS'></span>

<h3>Description</h3>

<p>The proposed method is based on the concordance index which measures concordance between random vectors.
A model-free and robust feature screening method for ultrahigh-dimensional categorical data.
The performance is quite robust in the presence of heavy-tailed distributions, extremely unbalance responses, and category-adaptive data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CISIS(X, Y, nsis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CISIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="CISIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="CISIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by CISIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Cheng X, Wang H. A generic model-free feature screening procedure for ultra-high dimensional data with categorical response[J]. Computer Methods and Programs in Biomedicine, 2023, 229: 107269.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLGM(n, p, rho)
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- CISIS(X, Y, n / log(n))
A

</code></pre>

<hr>
<h2 id='Cor'>Parallel function
This is a parallel function about the projection correlation.</h2><span id='topic+Cor'></span>

<h3>Description</h3>

<p>Parallel function
This is a parallel function about the projection correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cor(Xj, A_y, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cor_+3A_xj">Xj</code></td>
<td>
<p>Each column from design matrix of dimensions n * p</p>
</td></tr>
<tr><td><code id="Cor_+3A_a_y">A_y</code></td>
<td>
<p>The arccos value about Y</p>
</td></tr>
<tr><td><code id="Cor_+3A_n">n</code></td>
<td>
<p>The sample size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the projection correlation between Xj and A_y
</p>

<hr>
<h2 id='CSIS'>Model-Free Feature screening Based on Concordance Index Statistic</h2><span id='topic+CSIS'></span>

<h3>Description</h3>

<p>A model-free and data-adaptive feature screening method for
ultrahigh-dimensional data and even survival data. The proposed method is based
on the concordance index which measures concordance between random vectors even
if one of the vectors is a survival object Surv. This rank correlation based
method does not require specifying a regression model, and applies robustly to data
in the presence of censoring and heavy tails. It enjoys both sure screening and rank
consistency properties under weak assumptions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CSIS(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CSIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="CSIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1. For survival models,
Y should be an object of class Surv, as provided by the function
Surv() in the package survival.</p>
</td></tr>
<tr><td><code id="CSIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by CSIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Cheng X, Li G, Wang H. The concordance filter: an adaptive model-free feature screening procedure[J]. Computational Statistics, 2023: 1-24.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Scenario 1  generate complete data
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A1 &lt;- CSIS(X, Y, n / log(n))
A1

## Scenario 2  generate survival data
library(survival)
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataCox(n, p, rho)
data &lt;- cbind(data[[1]], data[[2]], data[[3]])
colnames(data)[ncol(data)] &lt;- c("status")
colnames(data)[(ncol(data) - 1)] &lt;- c("time")
colnames(data)[(1:(ncol(data) - 2))] &lt;- c(paste0("X", 1:(ncol(data) - 2)))
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 2)]
Y &lt;- Surv(data[, (ncol(data) - 1)], data[, ncol(data)])
A2 &lt;- CSIS(X, Y, n / log(n))
A2

</code></pre>

<hr>
<h2 id='DCSIS'>Feature Screening via Distance Correlation Learning</h2><span id='topic+DCSIS'></span>

<h3>Description</h3>

<p>A sure independence screening procedure based on the distance correlation (DC-SIS).
The DC-SIS can be implemented as easily as the sure independence screening (SIS) procedure based on the Pearson correlation proposed by Fan and Lv(2008).
DC-SIS can be used directly to screen grouped predictor variables and multivariate response variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DCSIS(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DCSIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="DCSIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="DCSIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by DCSIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Fan, J. and J. Lv (2008). Sure independence screening for ultrahigh dimensional feature space. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 70(5),849–911.
</p>
<p>Li, R., W. Zhong, and L. Zhu (2012). Feature screening via distance correlation learning. Journal of the American Statistical Association 107(499), 1129–1139.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- DCSIS(X, Y, n / log(n))
A

</code></pre>

<hr>
<h2 id='GendataAFT'>Generate simulation data (Survival data based on the accelerated failure time model)</h2><span id='topic+GendataAFT'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data based on the AFT model.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataAFT(
  n,
  p,
  rho,
  beta = c(rep(1, 5), rep(0, p - 5)),
  lambda = 0.1,
  error = "gaussian"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataAFT_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataAFT_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataAFT_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataAFT_+3A_beta">beta</code></td>
<td>
<p>A vector with length of n, which are the coefficients that you want to generate
about Linear model. The default is beta=(1,1,1,1,1,0,...,0)^T;</p>
</td></tr>
<tr><td><code id="GendataAFT_+3A_lambda">lambda</code></td>
<td>
<p>This parameter control the censoring rate in survival data.
The censored time is generated by exponential distribution with mean 1/lambda. The default
is lambda=0.1.</p>
</td></tr>
<tr><td><code id="GendataAFT_+3A_error">error</code></td>
<td>
<p>The distribution of error term.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Wei LJ (1992). “The accelerated failure time model: a useful alternative to the Cox regression model in survival analysis.” Statistics in medicine, 11(14-15), 1871–1879.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataAFT(n, p, rho)

</code></pre>

<hr>
<h2 id='GendataCox'>Generate simulation data (Survival data based on the Cox model)</h2><span id='topic+GendataCox'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data based on the Cox model.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataCox(n, p, rho, beta = c(rep(1, 5), rep(0, p - 5)), lambda = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataCox_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataCox_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataCox_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataCox_+3A_beta">beta</code></td>
<td>
<p>A vector with length of n, which are the coefficients that you want to generate
about Linear model. The default is beta=(1,1,1,1,1,0,...,0)^T;</p>
</td></tr>
<tr><td><code id="GendataCox_+3A_lambda">lambda</code></td>
<td>
<p>This parameter control the censoring rate in survival data.
The censored time is generated by exponential distribution with mean 1/lambda. The default
is lambda=0.1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Cox DR (1972). “Regression models and life-tables.” Journal of the Royal Statistical Society:Series B (Methodological), 34(2), 187–202.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataCox(n, p, rho)

</code></pre>

<hr>
<h2 id='GendataGP'>Generate simulation data (Complete data with group predictors)</h2><span id='topic+GendataGP'></span>

<h3>Description</h3>

<p>In many regression problems, some predictors may be naturally grouped.
The most common example that contains group variables is the multifactor
analysis of variance (ANOVA) problem, where each factor may have several
levels and can be expressed through a group of dummy variables.
This function helps you quickly generate simulation data with group predictors.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
This simulated example comes from Example 2 introduced by Li et al.(2012)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataGP(n, p, rho, error = c("gaussian", "t", "cauchy"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataGP_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataGP_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataGP_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataGP_+3A_error">error</code></td>
<td>
<p>The distribution of error term.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Li, R., W. Zhong, and L. Zhu (2012). Feature screening via distance correlation learning. Journal of the American Statistical Association 107(499), 1129–1139.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataGP(n, p, rho, "gaussian")

</code></pre>

<hr>
<h2 id='GendataIM'>Generate simulation data (Complete data for intersection variables)</h2><span id='topic+GendataIM'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data based on transformation model.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
This simulated example comes from Section 4.2 introduced by Pan et al.(2019)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataIM(n, p, rho, order = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataIM_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataIM_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataIM_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataIM_+3A_order">order</code></td>
<td>
<p>The number of interactive variables and the default is 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Pan, W., X. Wang, W. Xiao, and H. Zhu (2019). A generic sure independence screening procedure. Journal of the American Statistical Association 114(526), 928–937.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataIM(n, p, rho)

</code></pre>

<hr>
<h2 id='GendataLDA'>Generate simulation data (Categorial based on linear discriminant analysis model)</h2><span id='topic+GendataLDA'></span>

<h3>Description</h3>

<p>Simulates a dataset that can be used to filter out features for ultrahigh-dimensional discriminant analysis.
The simulation is based on the balanced scenarios in Example 3.1 of Cui et al.(2015).
The simulated dataset has p numerical X-predictors and a categorical Y-response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataLDA(
  n,
  p,
  R = 3,
  error = c("gaussian", "t", "cauchy"),
  style = c("balanced", "unbalanced")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataLDA_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataLDA_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataLDA_+3A_r">R</code></td>
<td>
<p>A positive integer, number of outcome categories for multinomial (categorical) outcome Y.</p>
</td></tr>
<tr><td><code id="GendataLDA_+3A_error">error</code></td>
<td>
<p>The distribution of error term, you can choose &quot;gaussian&quot; to generate a normal
distribution of error or you choose &quot;t&quot; to generate a t distribution of error with degree=2.
&quot;cauchy&quot; is represent the error term with cauchy distribution.</p>
</td></tr>
<tr><td><code id="GendataLDA_+3A_style">style</code></td>
<td>
<p>The balance among categories in categorial data .</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Cui, H., Li, R., &amp; Zhong, W. (2015). Model-free feature screening for ultrahigh dimensional discriminant analysis. Journal of the American Statistical Association, 110(510), 630-641.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
R &lt;- 3
data &lt;- GendataLDA(n, p, R, error = "gaussian", style = "balanced")
</code></pre>

<hr>
<h2 id='GendataLGM'>Generate simulation data (Binary category data based on logistic model)</h2><span id='topic+GendataLGM'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data based on logistic model.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataLGM(n, p, rho, beta = c(rep(1, 5), rep(0, p - 5)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataLGM_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataLGM_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataLGM_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataLGM_+3A_beta">beta</code></td>
<td>
<p>A vector with length of n, which are the coefficients that you want to generate
about Linear model. The default is beta=(1,1,1,1,1,0,...,0)^T;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLGM(n, p, rho)
</code></pre>

<hr>
<h2 id='GendataLM'>Generate simulation data (Complete data based on linear models)</h2><span id='topic+GendataLM'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data based on linear model.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataLM(
  n,
  p,
  rho,
  beta = c(rep(1, 5), rep(0, p - 5)),
  error = c("gaussian", "t", "cauchy")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataLM_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataLM_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataLM_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataLM_+3A_beta">beta</code></td>
<td>
<p>A vector with length of n, which are the coefficients that you want to generate
about Linear model. The default is beta=(1,1,1,1,1,0,...,0)^T;</p>
</td></tr>
<tr><td><code id="GendataLM_+3A_error">error</code></td>
<td>
<p>The distribution of error term.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
</code></pre>

<hr>
<h2 id='GendataMRM'>Generate simulation data (Multivariate response models)</h2><span id='topic+GendataMRM'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data based on transformation model.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
This simulated example comes from Example 3 introduced by Li et al.(2020)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataMRM(n, p, rho, type = c("a", "b"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataMRM_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataMRM_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataMRM_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataMRM_+3A_type">type</code></td>
<td>
<p>The type of multivariate response models, which use different mean and covariance
structure to generate data. Specially, type=&quot;a&quot; is following the Model 3.a and
type=&quot;b&quot; is following the Model 3.b by Li et al.(2020).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Liu, W., Y. Ke, J. Liu, and R. Li (2020). Model-free feature screening and FDR control with knockoff features. Journal of the American Statistical Association, 1–16.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataMRM(n, p, rho, type = "a")

</code></pre>

<hr>
<h2 id='GendataPM'>Generate simulation data (Discrete response data based on poisson model)</h2><span id='topic+GendataPM'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data based on poisson model.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
The simulated examples based on poisson model are significant popular
in the screening procedures, such as Model 1.f in Liu et al.(2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataPM(n, p, rho, beta = c(rep(1, 5), rep(0, p - 5)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataPM_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataPM_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataPM_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataPM_+3A_beta">beta</code></td>
<td>
<p>A vector with length of n, which are the coefficients that you want to generate
about Linear model. The default is beta=(1,1,1,1,1,0,...,0)^T;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Liu, W., Y. Ke, J. Liu, and R. Li (2020). Model-free feature screening and FDR control with knockoff features. Journal of the American Statistical Association, 1–16.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataPM(n, p, rho)

</code></pre>

<hr>
<h2 id='GendataTM'>Generate simulation data (Complete data based on transformation model)</h2><span id='topic+GendataTM'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data based on transformation model.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
This simulated example comes from Example 3.a introduced by Zhu et al.(2011)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GendataTM(
  n,
  p,
  rho,
  beta = c(rep(1, 5), rep(0, p - 5)),
  error = c("gaussian", "t", "cauchy")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GendataTM_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="GendataTM_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="GendataTM_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="GendataTM_+3A_beta">beta</code></td>
<td>
<p>A vector with length of n, which are the coefficients that you want to generate
about Linear model. The default is beta=(1,1,1,1,1,0,...,0)^T;</p>
</td></tr>
<tr><td><code id="GendataTM_+3A_error">error</code></td>
<td>
<p>The distribution of error term.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Zhu, L.-P., L. Li, R. Li, and L.-X. Zhu (2011). Model-free feature screening for ultrahigh-dimensional data. Journal of the American Statistical Association 106(496), 1464–1475.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataTM(n, p, rho, error = "gaussian")

</code></pre>

<hr>
<h2 id='get_arccos'>Arccos function</h2><span id='topic+get_arccos'></span>

<h3>Description</h3>

<p>This is a function to get a arccos value based on projection correlation from the Python language.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_arccos(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_arccos_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the arccos value
</p>

<hr>
<h2 id='Kfilter'>The Kolmogorov filter for variable screening</h2><span id='topic+Kfilter'></span>

<h3>Description</h3>

<p>A new model-free screening method called the fused Kolmogorov filter is proposed for high-dimensional data analysis.
This new method is fully nonparametric and can work with many types of covariates and response variables, including continuous,
discrete and categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kfilter(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kfilter_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="Kfilter_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="Kfilter_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by SIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Mai, Q., &amp; Zou, H. (2013). The Kolmogorov filter for variable screening in high-dimensional binary classification. Biometrika, 100(1), 229-234.
</p>
<p>Mai, Q., &amp; Zou, H. (2015). The fused Kolmogorov filter: A nonparametric model-free screening method. The Annals of Statistics, 43(4), 1471-1497.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n=100;
p=200;
rho=0.5;
data=GendataLM(n,p,rho,error="gaussian")
data=cbind(data[[1]],data[[2]])
colnames(data)[1:ncol(data)]=c(paste0("X",1:(ncol(data)-1)),"Y")
data=as.matrix(data)
X=data[,1:(ncol(data)-1)];
Y=data[,ncol(data)];
A=Kfilter(X,Y,n/log(n));A

</code></pre>

<hr>
<h2 id='Kfilter_fused'>The fused kolmogorov filter: a nonparametric model-free screening method</h2><span id='topic+Kfilter_fused'></span>

<h3>Description</h3>

<p>The fused kolmogorov filter: a nonparametric model-free screening method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kfilter_fused(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kfilter_fused_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="Kfilter_fused_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="Kfilter_fused_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by Kfilter_fused. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>References</h3>

<p>Mai, Q., &amp; Zou, H. (2015). The fused Kolmogorov filter: A nonparametric model-free screening method. The Annals of Statistics, 43(4), 1471-1497.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Scenario 1  generate discrete response data
n=100;
p=200;
R=5;
data=GendataLDA(n,p,R,error="gaussian",style="balanced")
data=cbind(data[[1]],data[[2]])
colnames(data)[1:ncol(data)]=c(paste0("X",1:(ncol(data)-1)),"Y")
data=as.matrix(data)
X=data[,1:(ncol(data)-1)];
Y=data[,ncol(data)];
A1=Kfilter_fused(X,Y,n/log(n));A1

##Scenario 2  generate continuous response data
n=50;
p=200;
rho=0.5;
data=GendataLM(n,p,rho,error="gaussian")
data=cbind(data[[1]],data[[2]])
colnames(data)[1:ncol(data)]=c(paste0("X",1:(ncol(data)-1)),"Y")
data=as.matrix(data)
X=data[,1:(ncol(data)-1)];
Y=data[,ncol(data)];
A2=Kfilter_fused(X,Y,n/log(n));A2

</code></pre>

<hr>
<h2 id='Kfilter_single'>The Kolmogorov filter for variable screening in high-dimensional binary classification</h2><span id='topic+Kfilter_single'></span>

<h3>Description</h3>

<p>The Kolmogorov filter for variable screening in high-dimensional binary classification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kfilter_single(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kfilter_single_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="Kfilter_single_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="Kfilter_single_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by Kfilter_single. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>References</h3>

<p>#' Mai, Q., &amp; Zou, H. (2013). The Kolmogorov filter for variable screening in high-dimensional binary classification. Biometrika, 100(1), 229-234.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=100;
p=200;
rho=0.5;
data=GendataLGM(n,p,rho)
data=cbind(data[[1]],data[[2]])
colnames(data)[1:ncol(data)]=c(paste0("X",1:(ncol(data)-1)),"Y")
data=as.matrix(data)
X=data[,1:(ncol(data)-1)];
Y=data[,ncol(data)];
A=Kfilter_single(X,Y,n/log(n));A

</code></pre>

<hr>
<h2 id='MDCSIS'>Martingale Difference Correlation and Its Use in High-Dimensional Variable Screening</h2><span id='topic+MDCSIS'></span>

<h3>Description</h3>

<p>A new metric, the so-called martingale difference correlation,
to measure the departure of conditional mean independence between a scalar response variable V and a vector predictor variable U.
Our metric is a natural extension of distance correlation proposed by Szekely, Rizzo, and Bahirov(2007),
which is used to measure the dependence between V and U. The martingale difference
correlation and its empirical counterpart inherit a number of desirable features of distance correlation and sample distance correlation,
such as algebraic simplicity and elegant theoretical properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MDCSIS(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MDCSIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="MDCSIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="MDCSIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by MDCSIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Szekely, G. J., M. L. Rizzo, and N. K. Bakirov (2007). Measuring and testing dependence by correlation of distances. The annals of statistics 35(6), 2769–2794.
</p>
<p>Shao, X. and J. Zhang (2014). Martingale difference correlation and its use in high-dimensional variable screening. Journal of the American Statistical Association 109(507),1302–1318.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- MDCSIS(X, Y, n / log(n))
A

</code></pre>

<hr>
<h2 id='MFSIS'>Model-free feature screening procedures</h2><span id='topic+MFSIS'></span>

<h3>Description</h3>

<p>Through this function, we provide a unified framework
to carry out model-free screening procedures including
SIS (Fan and Lv (2008) &lt;doi:10.1111/j.1467-9868.2008.00674.x&gt;),
SIRS(Zhu et al. (2011)&lt;doi:10.1198/jasa.2011.tm10563&gt;),
DC-SIS (Li et al. (2012) &lt;doi:10.1080/01621459.2012.695654&gt;),
MDC-SIS(Shao and Zhang (2014) &lt;doi:10.1080/01621459.2014.887012&gt;),
Bcor-SIS (Pan et al. (2019) &lt;doi:10.1080/01621459.2018.1462709&gt;),
PC-Screen (Liu et al. (2020) &lt;doi:10.1080/01621459.2020.1783274&gt;),
WLS (Zhong et al.(2021) &lt;doi:10.1080/01621459.2021.1918554&gt;),
Kfilter (Mai and Zou (2015) &lt;doi:10.1214/14-AOS1303&gt;),
MVSIS (Cui et al. (2015) &lt;doi:10.1080/01621459.2014.920256&gt;),
PSIS (Pan et al. (2016) &lt;doi:10.1080/01621459.2014.998760&gt;),
CAS (Xie et al. (2020) &lt;doi:101080/0162145920191573734&gt;),
CI-SIS (Cheng and Wang. (2022) &lt;doi:10.1016/j.cmpb.2022.107269&gt;)
and CSIS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MFSIS(
  X,
  Y,
  nsis = (dim(X)[1])/log(dim(X)[1]),
  method = c("SIS", "SIRS", "DCSIS", "MDCSIS", "CSIS", "PCSIS", "BcorSIS", "WLS",
    "MVSIS", "Kfilter")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MFSIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="MFSIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="MFSIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by the screening method. The default is n/log(n).</p>
</td></tr>
<tr><td><code id="MFSIS_+3A_method">method</code></td>
<td>
<p>The method that you choose to perform screening procedure.
method=c(&quot;SIS&quot;, &quot;SIRS&quot;, &quot;DCSIS&quot;, &quot;MDCSIS&quot;, &quot;CSIS&quot;, &quot;PCSIS&quot;, &quot;BcorSIS&quot;, &quot;WLS&quot;, &quot;MVSIS&quot;, &quot;Kfilter&quot;,&quot;PSIS&quot;,&quot;CAS&quot;,&quot;CISIS&quot;).
If you want to know more information about this method, please use command &quot;help(method)&quot; for detail information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- MFSIS(X, Y, n / log(n), method = "CSIS")
A

</code></pre>

<hr>
<h2 id='MVSIS'>Model-Free Feature Screening for Ultrahigh Dimensional Discriminant Analysis</h2><span id='topic+MVSIS'></span>

<h3>Description</h3>

<p>A marginal feature screening procedure based on empirical conditional distribution function.
The response variable is categorical in discriminant analysis.
This enables us to use the conditional distribution function to construct a new index for feature screening.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MVSIS(X, Y, nsis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MVSIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="MVSIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="MVSIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by MVSIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Cui, H., Li, R., &amp; Zhong, W. (2015). Model-free feature screening for ultrahigh dimensional discriminant analysis. Journal of the American Statistical Association, 110(510), 630-641.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLGM(n, p, rho)
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- MVSIS(X, Y, n / log(n))
A

</code></pre>

<hr>
<h2 id='PCSIS'>Model-Free Feature Screening Based on the Projection Correlation</h2><span id='topic+PCSIS'></span>

<h3>Description</h3>

<p>A model-free screening method is based on the projection correlation
which measures the dependence between two random vectors.
This projection correlation based method does not require specifying a
regression model, and applies to data in the presence of heavy tails
and multivariate responses. It enjoys both sure screening and
rank consistency properties under weak assumptions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PCSIS(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PCSIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="PCSIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="PCSIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by PCSIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Zhu, L., K. Xu, R. Li, and W. Zhong (2017). Projection correlation between two random vectors. Biometrika 104(4), 829–843.
</p>
<p>Liu, W., Y. Ke, J. Liu, and R. Li (2020). Model-free feature screening and FDR control with knockoff features. Journal of the American Statistical Association, 1–16.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# have_numpy=reticulate::py_module_available("numpy")
# if (have_numpy){
# req_py()
n=100;
p=200;
rho=0.5;
data=GendataLM(n,p,rho,error="gaussian")
data=cbind(data[[1]],data[[2]])
colnames(data)[1:ncol(data)]=c(paste0("X",1:(ncol(data)-1)),"Y")
data=as.matrix(data)
X=data[,1:(ncol(data)-1)];
Y=data[,ncol(data)];
# A=PCSIS(X,Y,n/log(n));A
# }else{
#    print('You should have the Python testing environment!')
#}

</code></pre>

<hr>
<h2 id='projection_corr'>Projection correlation function</h2><span id='topic+projection_corr'></span>

<h3>Description</h3>

<p>Projection correlation between X[,j] and Y from the Python language
</p>


<h3>Usage</h3>

<pre><code class='language-R'>projection_corr(A_x, A_y, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="projection_corr_+3A_a_x">A_x</code></td>
<td>
<p>The arccos value about X</p>
</td></tr>
<tr><td><code id="projection_corr_+3A_a_y">A_y</code></td>
<td>
<p>The arccos value about Y</p>
</td></tr>
<tr><td><code id="projection_corr_+3A_n">n</code></td>
<td>
<p>The sample size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the projection correlation
</p>

<hr>
<h2 id='PSIS'>Ultrahigh-Dimensional Multiclass Linear Discriminant Analysis by Pairwise Sure Independence Screening</h2><span id='topic+PSIS'></span>

<h3>Description</h3>

<p>A novel pairwise sure independence screening method for linear discriminant analysis with an
ultrahigh-dimensional predictor. This procedure is directly applicable to the situation with many classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PSIS(X, Y, nsis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PSIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="PSIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="PSIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by PSIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Pan, R., Wang, H., and Li, R. (2016). Ultrahigh-dimensional multiclass linear discriminant analysis by pairwise sure independence screening. Journal of the American Statistical Association, 111(513):169–179.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLGM(n, p, rho)
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- PSIS(X, Y, n / log(n))
A

</code></pre>

<hr>
<h2 id='req_py'>Detect Python Module</h2><span id='topic+req_py'></span>

<h3>Description</h3>

<p>A function to detect Python module.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>req_py()
</code></pre>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>

<hr>
<h2 id='Simdata'>Generate simulation data (The unified class framework to generate simulation data)</h2><span id='topic+Simdata'></span>

<h3>Description</h3>

<p>This function helps you quickly generate simulation data.
You just need to input the sample and dimension of the data
you want to generate and the covariance parameter rho.
The models is numerous.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Simdata(
  n,
  p,
  rho,
  beta = c(rep(1, 5), rep(0, p - 5)),
  error = c("gaussian", "t", "cauchy"),
  R = 3,
  style = c("balanced", "unbalanced"),
  lambda = 0.1,
  order = 2,
  type = c("a", "b"),
  model = c("linear", "nonlinear", "binomial", "poisson", "classification", "Cox",
    "interaction", "group", "multivariate", "AFT")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simdata_+3A_n">n</code></td>
<td>
<p>Number of subjects in the dataset to be simulated. It will also equal to the
number of rows in the dataset to be simulated, because it is assumed that each
row represents a different independent and identically distributed subject.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_p">p</code></td>
<td>
<p>Number of predictor variables (covariates) in the simulated dataset.
These covariates will be the features screened by model-free procedures.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_rho">rho</code></td>
<td>
<p>The correlation between adjacent covariates in the simulated matrix X.
The within-subject covariance matrix of X is assumed to has the same form as an
AR(1) auto-regressive covariance matrix, although this is not meant to imply
that the X covariates for each subject are in fact a time series. Instead, it is just
used as an example of a parsimonious but nontrivial covariance structure. If
rho is left at the default of zero, the X covariates will be independent and the
simulation will run faster.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_beta">beta</code></td>
<td>
<p>A vector with length of n, which are the coefficients that you want to generate
about chosen model. The default is beta=(1,1,1,1,1,0,...,0)^T.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_error">error</code></td>
<td>
<p>The distribution of error term.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_r">R</code></td>
<td>
<p>A positive integer, number of outcome categories for multinomial (categorical) outcome Y.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_style">style</code></td>
<td>
<p>Whether categories in categorial data are balanced or not.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_lambda">lambda</code></td>
<td>
<p>This parameter control the censoring rate in survival data.
The censored time is generated by exponential distribution with mean 1/lambda. The default
is lambda=0.1.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_order">order</code></td>
<td>
<p>The number of interactive variables and the default is 2.</p>
</td></tr>
<tr><td><code id="Simdata_+3A_type">type</code></td>
<td>
<p>The type of multivariate response models, which use different mean and covariance
structure to generate data. Specially, type=&quot;a&quot; is following the Model 3.a and
type=&quot;b&quot; is following the Model 3.b by Liu et al.(2020).</p>
</td></tr>
<tr><td><code id="Simdata_+3A_model">model</code></td>
<td>
<p>The model that you choose to generate simulation data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the list of your simulation data
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Liu, W., Y. Ke, J. Liu, and R. Li (2020). Model-free feature screening and FDR control with knockoff features. Journal of the American Statistical Association, 1–16.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- Simdata(n, p, rho, error = "gaussian", model = "linear")
</code></pre>

<hr>
<h2 id='SIRS'>Model-Free Feature Screening for Ultrahigh Dimensional Data</h2><span id='topic+SIRS'></span>

<h3>Description</h3>

<p>A novel feature screening procedure under a unified model framework,
which covers a wide variety of commonly used parametric and semi-parametric models.
This method does not require imposing a specific model structure on regression functions,
and thus is particularly appealing to ultrahigh-dimensional regressions, where there are a
huge number of candidate predictors but little information about the actual model forms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIRS(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SIRS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="SIRS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="SIRS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by SIRS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Zhu, L.-P., L. Li, R. Li, and L.-X. Zhu (2011). Model-free feature screening for ultrahigh-dimensional data. Journal of the American Statistical Association 106(496), 1464–1475.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- SIRS(X, Y, n / log(n))
A

</code></pre>

<hr>
<h2 id='SIS'>Sure Independent Screening</h2><span id='topic+SIS'></span>

<h3>Description</h3>

<p>To overcome challenges caused by ultra-high dimensionality,
Fan and Lv (2008) proposed a sure independence screening (SIS)
method, which aims to screen out the redundant features by
ranking their marginal Pearson correlations. The SIS method
is named after the SIS property, which states the selected subset
of features contains all the active ones with probability
approaching one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIS(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SIS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="SIS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="SIS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by SIS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Fan, J. and J. Lv (2008). Sure independence screening for ultrahigh dimensional feature space. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 70(5),849–911.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- SIS(X, Y, n / log(n))
A

</code></pre>

<hr>
<h2 id='WLS'>A Model-free Variable Screening Method Based on Leverage Score</h2><span id='topic+WLS'></span>

<h3>Description</h3>

<p>An innovative and effective sampling scheme based on leverage scores via singular value decompositions
has been proposed to select rows of a design matrix as a surrogate of the full data in linear regression.
Analogously, variable screening can be viewed as selecting rows of the design matrix. However, effective
variable selection along this line of thinking remains elusive. This method propose a
weighted leverage variable screening method by using both the left and right singular vectors of the design matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WLS(X, Y, nsis = (dim(X)[1])/log(dim(X)[1]))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WLS_+3A_x">X</code></td>
<td>
<p>The design matrix of dimensions n * p. Each row is an observation vector.</p>
</td></tr>
<tr><td><code id="WLS_+3A_y">Y</code></td>
<td>
<p>The response vector of dimension n * 1.</p>
</td></tr>
<tr><td><code id="WLS_+3A_nsis">nsis</code></td>
<td>
<p>Number of predictors recruited by WLS. The default is n/log(n).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the labels of first nsis largest active set of all predictors.
</p>


<h3>Author(s)</h3>

<p>Xuewei Cheng <a href="mailto:xwcheng@hunnu.edu.cn">xwcheng@hunnu.edu.cn</a>
</p>


<h3>References</h3>

<p>Zhong, W., Liu, Y., &amp; Zeng, P. (2021). A Model-free Variable Screening Method Based on Leverage Score. Journal of the American Statistical Association, (just-accepted), 1-36.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
p &lt;- 200
rho &lt;- 0.5
data &lt;- GendataLM(n, p, rho, error = "gaussian")
data &lt;- cbind(data[[1]], data[[2]])
colnames(data)[1:ncol(data)] &lt;- c(paste0("X", 1:(ncol(data) - 1)), "Y")
data &lt;- as.matrix(data)
X &lt;- data[, 1:(ncol(data) - 1)]
Y &lt;- data[, ncol(data)]
A &lt;- WLS(X, Y, n / log(n))
A

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
