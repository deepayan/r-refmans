<!DOCTYPE html><html><head><title>Help for package CovTools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CovTools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BCovTest1.mxPBF'><p>One-Sample Covariance Test using Maximum Pairwise Bayes Factor</p></a></li>
<li><a href='#BDiagTest1.mxPBF'><p>One-Sample Diagonality Test by Maximum Pairwise Bayes Factor</p></a></li>
<li><a href='#CovDist'><p>Compute Pairwise Distance for Symmetric Positive-Definite Matrices</p></a></li>
<li><a href='#CovEst.2003LW'><p>Covariance Estimation with Linear Shrinkage</p></a></li>
<li><a href='#CovEst.2010OAS'><p>Oracle Approximating Shrinkage Estimator</p></a></li>
<li><a href='#CovEst.2010RBLW'><p>Rao-Blackwell Ledoit-Wolf Estimator</p></a></li>
<li><a href='#CovEst.adaptive'><p>Covariance Estimation via Adaptive Thresholding</p></a></li>
<li><a href='#CovEst.hard'><p>Covariance Estimation via Hard Thresholding</p></a></li>
<li><a href='#CovEst.hardPD'><p>Covariance Estimation via Hard Thresholding under Positive-Definiteness Constraint</p></a></li>
<li><a href='#CovEst.nearPD'><p>Covariance Estimation via Nearest Positive-Definite Matrix Projection</p></a></li>
<li><a href='#CovEst.soft'><p>Covariance Estimation via Soft Thresholding</p></a></li>
<li><a href='#CovMean'><p>Estimate Mean Covariance Matrix</p></a></li>
<li><a href='#CovTest1.2013Cai'><p>One-Sample Covariance Test by Cai and Ma (2013)</p></a></li>
<li><a href='#CovTest1.2014Srivastava'><p>One-Sample Covariance Test by Srivastava, Yanagihara, and Kubokawa (2014)</p></a></li>
<li><a href='#CovTest2.2013Cai'><p>Two-Sample Covariance Test by Cai and Ma (2013)</p></a></li>
<li><a href='#DiagTest1.2011Cai'><p>One-Sample Diagonality Test by Cai and Jiang (2011)</p></a></li>
<li><a href='#DiagTest1.2015Lan'><p>One-Sample Diagonality Test by Lan et al. (2015)</p></a></li>
<li><a href='#package-CovTools'><p>A Collection of Geometric and Statistical Tools for Covariance (and Precision) Analysis</p></a></li>
<li><a href='#PreEst.2014An'><p>Banded Precision Matrix Estimation via Bandwidth Test</p></a></li>
<li><a href='#PreEst.2014Banerjee'><p>Bayesian Estimation of a Banded Precision Matrix (Banerjee 2014)</p></a></li>
<li><a href='#PreEst.2017Lee'><p>Bayesian Estimation of a Banded Precision Matrix (Lee 2017)</p></a></li>
<li><a href='#PreEst.glasso'><p>Precision Matrix Estimation via Graphical Lasso</p></a></li>
<li><a href='#samplecovs'><p>Generate Sample Covariances of 2 groups</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Tools for Covariance Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.4</td>
</tr>
<tr>
<td>Description:</td>
<td>Covariance is of universal prevalence across various disciplines within statistics.
    We provide a rich collection of geometric and inferential tools for convenient analysis of
    covariance structures, topics including distance measures, mean covariance estimator,
    covariance hypothesis test for one-sample and two-sample cases, and covariance estimation.
    For an introduction to covariance in multivariate statistical analysis,
    see Schervish (1987) &lt;<a href="https://doi.org/10.1214%2Fss%2F1177013111">doi:10.1214/ss/1177013111</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kisungyou/CovTools">https://github.com/kisungyou/CovTools</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.14.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, geigen, shapes, expm, mvtnorm, stats, Matrix,
doParallel, foreach, parallel, pracma, Rdpack, utils, SHT</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-08-13 16:35:54 UTC; kisung</td>
</tr>
<tr>
<td>Author:</td>
<td>Kyoungjae Lee [aut],
  Lizhen Lin [ctb],
  Kisung You <a href="https://orcid.org/0000-0002-8584-459X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kisung You &lt;kisungyou@outlook.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-08-13 23:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BCovTest1.mxPBF'>One-Sample Covariance Test using Maximum Pairwise Bayes Factor</h2><span id='topic+BCovTest1.mxPBF'></span>

<h3>Description</h3>

<p>It performs Bayesian version of 1-sample test for Covariance where the null hypothesis is
</p>
<p style="text-align: center;"><code class="reqn">H_0 : \Sigma_n = \Sigma_0</code>
</p>

<p>where <code class="reqn">\Sigma_n</code> is the covariance of data model and <code class="reqn">\Sigma_0</code> is a
hypothesized covariance. Denote <code class="reqn">X_i</code> be the <code class="reqn">i</code>-th column of data matrix.
Under the maximum pairwise Bayes Factor framework, we have following hypothesis,
</p>
<p style="text-align: center;"><code class="reqn">H_0: a_{ij}=0~\mathrm{ and }~\tau_{ij}=1 \quad \mathrm{versus. } \quad  H_1: \mathrm{ not }~ H_0.</code>
</p>

<p>The model is
</p>
<p style="text-align: center;"><code class="reqn">X_i | X_j \sim N_n( a_{ij}X_j, \tau_{ij}^2 I_n )</code>
</p>

<p>and the prior is set, under <code class="reqn">H_1</code>,  as
</p>
<p style="text-align: center;"><code class="reqn"> a_{ij}|\tau_{ij}^2 \sim N(0, \tau_{ij}^2/(\gamma*||X_j||^2))</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_{ij}^2 \sim IG(a0, b0).</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>BCovTest1.mxPBF(data, Sigma0 = diag(ncol(data)), a0 = 2, b0 = 2, gamma = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BCovTest1.mxPBF_+3A_data">data</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="BCovTest1.mxPBF_+3A_sigma0">Sigma0</code></td>
<td>
<p>a <code class="reqn">(p\times p)</code> given covariance matrix.</p>
</td></tr>
<tr><td><code id="BCovTest1.mxPBF_+3A_a0">a0</code></td>
<td>
<p>shape parameter for inverse-gamma prior.</p>
</td></tr>
<tr><td><code id="BCovTest1.mxPBF_+3A_b0">b0</code></td>
<td>
<p>scale parameter for inverse-gamma prior.</p>
</td></tr>
<tr><td><code id="BCovTest1.mxPBF_+3A_gamma">gamma</code></td>
<td>
<p>non-negative number. See the equation above.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>log.BF.mat</dt><dd><p>a <code class="reqn">(p\times p)</code> matrix of pairwise log Bayes factors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Lee K, Lin L, Dunson D (2018).
&ldquo;Maximum Pairwise Bayes Factors for Covariance Structure Testing.&rdquo;
<em>arXiv preprint</em>.
<a href="https://arxiv.org/abs/1809.03105">https://arxiv.org/abs/1809.03105</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## generate data from multivariate normal with trivial covariance.
pdim = 10
data = matrix(rnorm(100*pdim), nrow=100)

## run mxPBF-based test
out1 = BCovTest1.mxPBF(data)
out2 = BCovTest1.mxPBF(data, a0=5.0, b0=5.0) # change some params

## visualize two Bayes Factor matrices
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
image(exp(out1$log.BF.mat)[,pdim:1], main="default")
image(exp(out2$log.BF.mat)[,pdim:1], main="a0=b0=5.0")
par(opar)

## End(Not run)

</code></pre>

<hr>
<h2 id='BDiagTest1.mxPBF'>One-Sample Diagonality Test by Maximum Pairwise Bayes Factor</h2><span id='topic+BDiagTest1.mxPBF'></span>

<h3>Description</h3>

<p>One-sample diagonality test can be stated with the null hypothesis
</p>
<p style="text-align: center;"><code class="reqn">H_0 : \sigma_{ij} = 0~\mathrm{for any}~i \neq j</code>
</p>

<p>and alternative hypothesis <code class="reqn">H_1 : ~\mathrm{not}~H_0</code>
with <code class="reqn">\Sigma_n = (\sigma_{ij})</code>. Let <code class="reqn">X_i</code> be the <code class="reqn">i</code>-th column of data matrix. Under the maximum pairwise bayes factor framework, we have following hypothesis,
</p>
<p style="text-align: center;"><code class="reqn">H_0: a_{ij}=0\quad \mathrm{versus. } \quad  H_1: \mathrm{ not }~ H_0.</code>
</p>

<p>The model is
</p>
<p style="text-align: center;"><code class="reqn">X_i | X_j \sim N_n( a_{ij}X_j, \tau_{ij}^2 I_n ).</code>
</p>

<p>Under <code class="reqn">H_0</code>, the prior is set as
</p>
<p style="text-align: center;"><code class="reqn">\tau_{ij}^2 \sim IG(a0, b0)</code>
</p>
<p> and under <code class="reqn">H_1</code>, priors are
</p>
<p style="text-align: center;"><code class="reqn"> a_{ij}|\tau_{ij}^2 \sim N(0, \tau_{ij}^2/(\gamma*||X_j||^2))</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_{ij}^2 \sim IG(a0, b0).</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>BDiagTest1.mxPBF(data, a0 = 2, b0 = 2, gamma = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BDiagTest1.mxPBF_+3A_data">data</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="BDiagTest1.mxPBF_+3A_a0">a0</code></td>
<td>
<p>shape parameter for inverse-gamma prior.</p>
</td></tr>
<tr><td><code id="BDiagTest1.mxPBF_+3A_b0">b0</code></td>
<td>
<p>scale parameter for inverse-gamma prior.</p>
</td></tr>
<tr><td><code id="BDiagTest1.mxPBF_+3A_gamma">gamma</code></td>
<td>
<p>non-negative number. See the equation above.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>log.BF.mat</dt><dd> <p><code class="reqn">(p\times p)</code> matrix of pairwise log Bayes factors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Lee K, Lin L, Dunson D (2018).
&ldquo;Maximum Pairwise Bayes Factors for Covariance Structure Testing.&rdquo;
<em>arXiv preprint</em>.
<a href="https://arxiv.org/abs/1809.03105">https://arxiv.org/abs/1809.03105</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## generate data from multivariate normal with trivial covariance.
pdim = 10
data = matrix(rnorm(100*pdim), nrow=100)

## run test
## run mxPBF-based test
out1 = BDiagTest1.mxPBF(data)
out2 = BDiagTest1.mxPBF(data, a0=5.0, b0=5.0) # change some params

## visualize two Bayes Factor matrices
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
image(exp(out1$log.BF.mat)[,pdim:1], main="default")
image(exp(out2$log.BF.mat)[,pdim:1], main="a0=b0=5.0")
par(opar)

## End(Not run)

</code></pre>

<hr>
<h2 id='CovDist'>Compute Pairwise Distance for Symmetric Positive-Definite Matrices</h2><span id='topic+CovDist'></span>

<h3>Description</h3>

<p>For a given 3-dimensional array where symmetric positive definite (SPD) matrices are stacked slice
by slice, it computes pairwise distance using various popular measures. Some of measures
are <em>metric</em> as they suffice 3 conditions in mathematical context; nonnegative definiteness,
symmetry, and triangle inequalities. Other non-metric measures represent <em>dissimilarities</em> between
two SPD objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovDist(
  A,
  method = c("AIRM", "Bhattacharyya", "Cholesky", "Euclidean", "Hellinger", "JBLD",
    "KLDM", "LERM", "Procrustes.SS", "Procrustes.Full", "PowerEuclidean",
    "RootEuclidean"),
  power = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovDist_+3A_a">A</code></td>
<td>
<p>a <code class="reqn">(p\times p\times N)</code> 3d array of <code class="reqn">N</code> SPD matrices.</p>
</td></tr>
<tr><td><code id="CovDist_+3A_method">method</code></td>
<td>
<p>the type of distance measures to be used; <code>"AIRM"</code> for Affine Invariant
Riemannian Metric, <code>"Bhattacharyya"</code> for Bhattacharyya distance based on normal model,
<code>"Cholesky"</code> for Cholesky difference in Frobenius norm,
<code>"Euclidean"</code> for naive Frobenius norm as distance,
<code>"Hellinger"</code> for Hellinger distance based on normal model,
<code>"JBLD"</code> for Jensen-Bregman Log Determinant Distance,
<code>"KLDM"</code> for symmetrized Kullback-Leibler Distance Measure,
<code>"LERM"</code> for Log Euclidean Riemannian Metric,
<code>"Procrustes.SS"</code> for Procrustes Size and Shape measure,
<code>"Procrustes.Full"</code> for Procrustes analysis with scale,
<code>"PowerEuclidean"</code> for weighted eigenvalues by some exponent, and
<code>"RootEuclidean"</code> for matrix square root.</p>
</td></tr>
<tr><td><code id="CovDist_+3A_power">power</code></td>
<td>
<p>a non-zero number for PowerEuclidean distance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code class="reqn">(N\times N)</code> symmetric matrix of pairwise distances.
</p>


<h3>References</h3>

<p>Arsigny V, Fillard P, Pennec X, Ayache N (2006).
&ldquo;Log-Euclidean metrics for fast and simple calculus on diffusion tensors.&rdquo;
<em>Magnetic Resonance in Medicine</em>, <b>56</b>(2), 411&ndash;421.
ISSN 0740-3194, 1522-2594.
</p>
<p>Dryden IL, Koloydenko A, Zhou D (2009).
&ldquo;Non-Euclidean statistics for covariance matrices, with applications to diffusion tensor imaging.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>3</b>(3), 1102&ndash;1123.
ISSN 1932-6157.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate 100 SPD matrices of size (5-by-5)
samples = samplecovs(100,5)

## get pairwise distance for "AIRM"
distAIRM = CovDist(samples, method="AIRM")

## dimension reduction using MDS
ss = cmdscale(distAIRM)

## visualize
opar &lt;- par(no.readonly=TRUE)
plot(ss[,1],ss[,2],main="2d projection")
par(opar)

</code></pre>

<hr>
<h2 id='CovEst.2003LW'>Covariance Estimation with Linear Shrinkage</h2><span id='topic+CovEst.2003LW'></span>

<h3>Description</h3>

<p>Ledoit and Wolf (2003, 2004) proposed a linear shrinkage strategy to estimate covariance matrix
with an application to portfolio optimization. An optimal covariance is written as a convex combination as follows,
</p>
<p style="text-align: center;"><code class="reqn">\hat{\Sigma} = \delta \hat{F} + (1-\delta) \hat{S}</code>
</p>

<p>where <code class="reqn">\delta \in (0,1)</code> a control parameter/weight, <code class="reqn">\hat{S}</code> an empirical covariance matrix, and <code class="reqn">\hat{F}</code> a <em>target</em> matrix.
Although authors used <code class="reqn">F</code> a highly structured estimator, we also enabled an arbitrary target matrix to be used as long as it's symmetric
and positive definite of corresponding size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovEst.2003LW(X, target = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovEst.2003LW_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="CovEst.2003LW_+3A_target">target</code></td>
<td>
<p>target matrix <code class="reqn">F</code>. If <code>target=NULL</code>, <em>constant correlation model</em> estimator is used. If <code>target</code> is specified as a qualified matrix, it is used instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>S</dt><dd><p>a <code class="reqn">(p\times p)</code> covariance matrix estimate.</p>
</dd>
<dt>delta</dt><dd><p>an estimate for convex combination weight according to the relevant theory.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ledoit O, Wolf M (2003).
&ldquo;Improved estimation of the covariance matrix of stock returns with an application to portfolio selection.&rdquo;
<em>Journal of Empirical Finance</em>, <b>10</b>(5), 603&ndash;621.
ISSN 09275398.
</p>
<p>Ledoit O, Wolf M (2004).
&ldquo;A well-conditioned estimator for large-dimensional covariance matrices.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>88</b>(2), 365&ndash;411.
ISSN 0047259X.
</p>
<p>Ledoit O, Wolf M (2004).
&ldquo;Honey, I Shrunk the Sample Covariance Matrix.&rdquo;
<em>The Journal of Portfolio Management</em>, <b>30</b>(4), 110&ndash;119.
ISSN 0095-4918.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## CRAN-purpose small computation
# set a seed for reproducibility
set.seed(11)

#  small data with identity covariance
pdim      &lt;- 5
dat.small &lt;- matrix(rnorm(20*pdim), ncol=pdim)

#  run the code with highly structured estimator
out.small &lt;- CovEst.2003LW(dat.small)

#  visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
image(diag(5)[,pdim:1], main="true cov")
image(cov(dat.small)[,pdim:1], main="sample cov")
image(out.small$S[,pdim:1], main="estimated cov")
par(opar)

## Not run: 
## want to see how delta is determined according to
#  the number of observations we have.
nsamples = seq(from=5, to=200, by=5)
nnsample = length(nsamples)

#  we will record two values; delta and norm difference
vec.delta = rep(0, nnsample)
vec.normd = rep(0, nnsample)
for (i in 1:nnsample){
  dat.norun &lt;- matrix(rnorm(nsamples[i]*pdim), ncol=pdim) # sample in R^5
  out.norun &lt;- CovEst.2003LW(dat.norun)                   # run with default

  vec.delta[i] = out.norun$delta
  vec.normd[i] = norm(out.norun$S - diag(pdim),"f")       # Frobenius norm
}

# let's visualize the results
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2))
plot(nsamples, vec.delta, lwd=2, type="b", col="red", main="estimated deltas")
plot(nsamples, vec.normd, lwd=2, type="b", col="blue",main="Frobenius error")
par(opar)

## End(Not run)

</code></pre>

<hr>
<h2 id='CovEst.2010OAS'>Oracle Approximating Shrinkage Estimator</h2><span id='topic+CovEst.2010OAS'></span>

<h3>Description</h3>

<p>Authors propose to estimate covariance matrix by iteratively approximating the shrinkage with
</p>
<p style="text-align: center;"><code class="reqn">\hat{\Sigma} = \rho \hat{F} + (1-\rho) \hat{S}</code>
</p>

<p>where <code class="reqn">\rho \in (0,1)</code> a control parameter/weight, <code class="reqn">\hat{S}</code> an empirical covariance matrix, and <code class="reqn">\hat{F}</code> a <em>target</em> matrix.
It is proposed to use a structured estimate <code class="reqn">\hat{F} = \textrm{Tr} (\hat{S}/p) \cdot I_{p\times p}</code> where <code class="reqn">I_{p\times p}</code> is an identity matrix of dimension <code class="reqn">p</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovEst.2010OAS(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovEst.2010OAS_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>S</dt><dd><p>a <code class="reqn">(p\times p)</code> covariance matrix estimate.</p>
</dd>
<dt>rho</dt><dd><p>an estimate for convex combination weight.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chen Y, Wiesel A, Eldar YC, Hero AO (2010).
&ldquo;Shrinkage Algorithms for MMSE Covariance Estimation.&rdquo;
<em>IEEE Transactions on Signal Processing</em>, <b>58</b>(10), 5016&ndash;5029.
ISSN 1053-587X, 1941-0476.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## CRAN-purpose small computation
# set a seed for reproducibility
set.seed(11)

#  small data with identity covariance
pdim      &lt;- 5
dat.small &lt;- matrix(rnorm(10*pdim), ncol=pdim)

#  run the code
out.small &lt;- CovEst.2010OAS(dat.small)

#  visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
image(diag(pdim)[,pdim:1],     main="true cov")
image(cov(dat.small)[,pdim:1], main="sample cov")
image(out.small$S[,pdim:1],    main="estimated cov")
par(opar)

## Not run: 
## want to see how delta is determined according to
#  the number of observations we have.
nsamples = seq(from=5, to=200, by=5)
nnsample = length(nsamples)

#  we will record two values; rho and norm difference
vec.rho   = rep(0, nnsample)
vec.normd = rep(0, nnsample)
for (i in 1:nnsample){
  dat.norun &lt;- matrix(rnorm(nsamples[i]*pdim), ncol=pdim) # sample in R^5
  out.norun &lt;- CovEst.2010OAS(dat.norun)                  # run with default

  vec.rho[i]   = out.norun$rho
  vec.normd[i] = norm(out.norun$S - diag(pdim),"f")       # Frobenius norm
}

# let's visualize the results
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2))
plot(nsamples, vec.rho,   lwd=2, type="b", col="red", main="estimated rhos")
plot(nsamples, vec.normd, lwd=2, type="b", col="blue",main="Frobenius error")
par(opar)

## End(Not run)

</code></pre>

<hr>
<h2 id='CovEst.2010RBLW'>Rao-Blackwell Ledoit-Wolf Estimator</h2><span id='topic+CovEst.2010RBLW'></span>

<h3>Description</h3>

<p>Authors propose to estimate covariance matrix by minimizing mean squared error with the following formula,
</p>
<p style="text-align: center;"><code class="reqn">\hat{\Sigma} = \rho \hat{F} + (1-\rho) \hat{S}</code>
</p>

<p>where <code class="reqn">\rho \in (0,1)</code> a control parameter/weight, <code class="reqn">\hat{S}</code> an empirical covariance matrix, and <code class="reqn">\hat{F}</code> a <em>target</em> matrix.
It is proposed to use a structured estimate <code class="reqn">\hat{F} = \textrm{Tr} (\hat{S}/p) \cdot I_{p\times p}</code> where <code class="reqn">I_{p\times p}</code> is an identity matrix of dimension <code class="reqn">p</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovEst.2010RBLW(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovEst.2010RBLW_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>S</dt><dd><p>a <code class="reqn">(p\times p)</code> covariance matrix estimate.</p>
</dd>
<dt>rho</dt><dd><p>an estimate for convex combination weight.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chen Y, Wiesel A, Eldar YC, Hero AO (2010).
&ldquo;Shrinkage Algorithms for MMSE Covariance Estimation.&rdquo;
<em>IEEE Transactions on Signal Processing</em>, <b>58</b>(10), 5016&ndash;5029.
ISSN 1053-587X, 1941-0476.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## CRAN-purpose small computation
# set a seed for reproducibility
set.seed(11)

#  small data with identity covariance
pdim      &lt;- 10
dat.small &lt;- matrix(rnorm(5*pdim), ncol=pdim)

#  run the code
out.small &lt;- CovEst.2010RBLW(dat.small)

#  visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
image(diag(pdim)[,pdim:1],     main="true cov")
image(cov(dat.small)[,pdim:1], main="sample cov")
image(out.small$S[,pdim:1],    main="estimated cov")
par(opar)

## Not run: 
## want to see how delta is determined according to
#  the number of observations we have.
nsamples = seq(from=5, to=200, by=5)
nnsample = length(nsamples)

#  we will record two values; rho and norm difference
vec.rho   = rep(0, nnsample)
vec.normd = rep(0, nnsample)
for (i in 1:nnsample){
  dat.norun &lt;- matrix(rnorm(nsamples[i]*pdim), ncol=pdim) # sample in R^5
  out.norun &lt;- CovEst.2010RBLW(dat.norun)                 # run with default

  vec.rho[i]   = out.norun$rho
  vec.normd[i] = norm(out.norun$S - diag(5),"f")          # Frobenius norm
}

# let's visualize the results
opar &lt;- par(mfrow=c(1,2))
plot(nsamples, vec.rho,   lwd=2, type="b", col="red", main="estimated rhos")
plot(nsamples, vec.normd, lwd=2, type="b", col="blue",main="Frobenius error")
par(opar)

## End(Not run)

</code></pre>

<hr>
<h2 id='CovEst.adaptive'>Covariance Estimation via Adaptive Thresholding</h2><span id='topic+CovEst.adaptive'></span>

<h3>Description</h3>

<p>Cai and Liu (2011) proposed an adaptive variant of Bickel and Levina (2008) - <code><a href="#topic+CovEst.hard">CovEst.hard</a></code>. The idea of <em>adaptive thresholding</em> is
to apply thresholding technique on correlation matrix in that it becomes <em>adaptive</em> in terms of each variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovEst.adaptive(X, thr = 0.5, nCV = 10, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovEst.adaptive_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="CovEst.adaptive_+3A_thr">thr</code></td>
<td>
<p>user-defined threshold value. If it is a vector of regularization values, it automatically selects one that minimizes cross validation risk.</p>
</td></tr>
<tr><td><code id="CovEst.adaptive_+3A_ncv">nCV</code></td>
<td>
<p>the number of repetitions for 2-fold random cross validations for each threshold value.</p>
</td></tr>
<tr><td><code id="CovEst.adaptive_+3A_parallel">parallel</code></td>
<td>
<p>a logical; <code>TRUE</code> to use half of available cores, <code>FALSE</code> to do every computation sequentially.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>S</dt><dd><p>a <code class="reqn">(p\times p)</code> covariance matrix estimate.</p>
</dd>
<dt>CV</dt><dd><p>a dataframe containing vector of tested threshold values(<code>thr</code>) and corresponding cross validation scores(<code>CVscore</code>).</p>
</dd>
</dl>



<h3>References</h3>

<p>Cai T, Liu W (2011).
&ldquo;Adaptive Thresholding for Sparse Covariance Matrix Estimation.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>106</b>(494), 672&ndash;684.
ISSN 0162-1459, 1537-274X.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data from multivariate normal with Identity covariance.
pdim &lt;- 5
data &lt;- matrix(rnorm(10*pdim), ncol=pdim)

## apply 4 different schemes
#  mthr is a vector of regularization parameters to be tested
mthr &lt;- seq(from=0.01,to=0.99,length.out=10)

out1 &lt;- CovEst.adaptive(data, thr=0.1)  # threshold value 0.1
out2 &lt;- CovEst.adaptive(data, thr=0.5)  # threshold value 0.5
out3 &lt;- CovEst.adaptive(data, thr=0.1)  # threshold value 0.9
out4 &lt;- CovEst.adaptive(data, thr=mthr) # automatic threshold checking

## visualize 4 estimated matrices
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
image(out1$S[,pdim:1], col=gray((0:100)/100), main="thr=0.1")
image(out2$S[,pdim:1], col=gray((0:100)/100), main="thr=0.5")
image(out3$S[,pdim:1], col=gray((0:100)/100), main="thr=0.9")
image(out4$S[,pdim:1], col=gray((0:100)/100), main="automatic")
par(opar)

</code></pre>

<hr>
<h2 id='CovEst.hard'>Covariance Estimation via Hard Thresholding</h2><span id='topic+CovEst.hard'></span>

<h3>Description</h3>

<p>Bickel and Levina (2008) proposed a sparse covariance estimation technique to apply thresholding on off-diagonal elements of
the sample covariance matrix. The entry of sample covariance matrix <code class="reqn">S_{i,j}=0</code> if <code class="reqn">|S_{i,j}|&lt;=\tau</code> where <code class="reqn">\tau</code> is
a thresholding value (<code>thr</code>). If <code>thr</code> is rather a vector of regularization parameters, it applies
cross-validation scheme to select an optimal value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovEst.hard(X, thr = sqrt(log(ncol(X))/nrow(X)), nCV = 10, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovEst.hard_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="CovEst.hard_+3A_thr">thr</code></td>
<td>
<p>user-defined threshold value. If it is a vector of regularization values, it automatically selects one that minimizes cross validation risk.</p>
</td></tr>
<tr><td><code id="CovEst.hard_+3A_ncv">nCV</code></td>
<td>
<p>the number of repetitions for 2-fold random cross validations for each threshold value.</p>
</td></tr>
<tr><td><code id="CovEst.hard_+3A_parallel">parallel</code></td>
<td>
<p>a logical; <code>TRUE</code> to use half of available cores, <code>FALSE</code> to do every computation sequentially.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>S</dt><dd><p>a <code class="reqn">(p\times p)</code> covariance matrix estimate.</p>
</dd>
<dt>CV</dt><dd><p>a dataframe containing vector of tested threshold values(<code>thr</code>) and corresponding cross validation scores(<code>CVscore</code>).</p>
</dd>
</dl>



<h3>References</h3>

<p>Bickel PJ, Levina E (2008).
&ldquo;Covariance regularization by thresholding.&rdquo;
<em>The Annals of Statistics</em>, <b>36</b>(6), 2577&ndash;2604.
ISSN 0090-5364.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data from multivariate normal with Identity covariance.
pdim &lt;- 5
data &lt;- matrix(rnorm(10*pdim), ncol=pdim)

## apply 4 different schemes
#  mthr is a vector of regularization parameters to be tested
mthr &lt;- exp(seq(from=log(0.1),to=log(10),length.out=10))

out1 &lt;- CovEst.hard(data, thr=0.1)  # threshold value 0.1
out2 &lt;- CovEst.hard(data, thr=1)    # threshold value 1
out3 &lt;- CovEst.hard(data, thr=10)   # threshold value 10
out4 &lt;- CovEst.hard(data, thr=mthr) # automatic threshold checking

## visualize 4 estimated matrices
gcol &lt;- gray((0:100)/100)
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
image(out1$S[,pdim:1], col=gcol, main="thr=0.1")
image(out2$S[,pdim:1], col=gcol, main="thr=1")
image(out3$S[,pdim:1], col=gcol, main="thr=10")
image(out4$S[,pdim:1], col=gcol, main="automatic")
par(opar)

</code></pre>

<hr>
<h2 id='CovEst.hardPD'>Covariance Estimation via Hard Thresholding under Positive-Definiteness Constraint</h2><span id='topic+CovEst.hardPD'></span>

<h3>Description</h3>

<p>Sparse covariance estimation does not necessarily guarantee positive definiteness of an estimated
covariance matrix. Fan et al. (2013) proposed to solve this issue by taking an iterative procedure to
take an incremental decrease of threshold value until positive definiteness is preserved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovEst.hardPD(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovEst.hardPD_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>S</dt><dd><p>a <code class="reqn">(p\times p)</code> covariance matrix estimate.</p>
</dd>
<dt>optC</dt><dd><p>an optimal threshold value <code class="reqn">C_{min}</code> that guarantees positive definiteness after thresholding.</p>
</dd>
</dl>



<h3>References</h3>

<p>Fan J, Liao Y, Mincheva M (2013).
&ldquo;Large covariance estimation by thresholding principal orthogonal complements.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>(4), 603&ndash;680.
ISSN 13697412.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data from multivariate normal with Identity covariance.
pdim &lt;- 5
data &lt;- matrix(rnorm(10*pdim), ncol=pdim)

## apply 4 different schemes
out1 &lt;- CovEst.hard(data, thr=0.1)  # threshold value 0.1
out2 &lt;- CovEst.hard(data, thr=1)    # threshold value 1
out3 &lt;- CovEst.hard(data, thr=10)   # threshold value 10
out4 &lt;- CovEst.hardPD(data) # automatic threshold checking

## visualize 4 estimated matrices
mmessage &lt;- paste("hardPD::optimal thr=",sprintf("%.2f",out4$optC),sep="")
gcol     &lt;- gray((0:100)/100)
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
image(out1$S[,pdim:1], col=gcol, main="thr=0.1")
image(out2$S[,pdim:1], col=gcol, main="thr=1")
image(out3$S[,pdim:1], col=gcol, main="thr=10")
image(out4$S[,pdim:1], col=gcol, main=mmessage)
par(opar)

</code></pre>

<hr>
<h2 id='CovEst.nearPD'>Covariance Estimation via Nearest Positive-Definite Matrix Projection</h2><span id='topic+CovEst.nearPD'></span>

<h3>Description</h3>

<p>Qi and Sun (2006) proposed an algorithm for computing the positive correlation matrix
with Positive Definiteness and transforming it back in order to estimate covariance matrix.
This algorithm does not depend on any parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovEst.nearPD(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovEst.nearPD_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>S</dt><dd><p>a <code class="reqn">(p\times p)</code> covariance matrix estimate.</p>
</dd>
</dl>



<h3>References</h3>

<p>Qi H, Sun D (2006).
&ldquo;A Quadratically Convergent Newton Method for Computing the Nearest Correlation Matrix.&rdquo;
<em>SIAM Journal on Matrix Analysis and Applications</em>, <b>28</b>(2), 360&ndash;385.
ISSN 0895-4798, 1095-7162.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data from multivariate normal with Identity covariance.
pdim &lt;- 5
data &lt;- matrix(rnorm(10*pdim), ncol=pdim)

## compare against sample covariance
out1 &lt;- cov(data)
out2 &lt;- CovEst.nearPD(data) # apply nearPD

## visualize 2 estimated matrices
gcol &lt;- gray((0:100)/100)
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
image(out1[,pdim:1],   col=gcol, main="sample covariance")
image(out2$S[,pdim:1], col=gcol, main="SPD Projection")
par(opar)

</code></pre>

<hr>
<h2 id='CovEst.soft'>Covariance Estimation via Soft Thresholding</h2><span id='topic+CovEst.soft'></span>

<h3>Description</h3>

<p>Soft Thresholding method for covariance estimation takes off-diagonal elements <code class="reqn">z</code> of sample covariance matrix and applies
</p>
<p style="text-align: center;"><code class="reqn">h_{\tau}(z) = \textrm{sgn}(z)(|z|-\tau)_{+}</code>
</p>

<p>where <code class="reqn">\textrm{sgn}(z)</code> is a sign of the value <code class="reqn">z</code>, and <code class="reqn">(x)_+ = \textrm{max}(x,0)</code>. If <code>thr</code> is rather a vector of regularization parameters, it applies
cross-validation scheme to select an optimal value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovEst.soft(X, thr = 0.5, nCV = 10, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovEst.soft_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="CovEst.soft_+3A_thr">thr</code></td>
<td>
<p>user-defined threshold value. If it is a vector of regularization values, it automatically selects one that minimizes cross validation risk.</p>
</td></tr>
<tr><td><code id="CovEst.soft_+3A_ncv">nCV</code></td>
<td>
<p>the number of repetitions for 2-fold random cross validations for each threshold value.</p>
</td></tr>
<tr><td><code id="CovEst.soft_+3A_parallel">parallel</code></td>
<td>
<p>a logical; <code>TRUE</code> to use half of available cores, <code>FALSE</code> to do every computation sequentially.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>S</dt><dd><p>a <code class="reqn">(p\times p)</code> covariance matrix estimate.</p>
</dd>
<dt>CV</dt><dd><p>a dataframe containing vector of tested threshold values(<code>thr</code>) and corresponding cross validation scores(<code>CVscore</code>).</p>
</dd>
</dl>



<h3>References</h3>

<p>Antoniadis A, Fan J (2001).
&ldquo;Regularization of Wavelet Approximations.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>96</b>(455), 939&ndash;967.
ISSN 0162-1459, 1537-274X.
</p>
<p>Donoho DL, Johnstone IM, Kerkyacharian G, Picard D (1995).
&ldquo;Wavelet Shrinkage: Asymptopia?&rdquo;
<em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <b>57</b>(2), 301&ndash;369.
ISSN 00359246.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data from multivariate normal with Identity covariance.
pdim &lt;- 5
data &lt;- matrix(rnorm(10*pdim), ncol=pdim)

## apply 4 different schemes
#  mthr is a vector of regularization parameters to be tested
mthr &lt;- exp(seq(from=log(0.1),to=log(10),length.out=10))

out1 &lt;- CovEst.soft(data, thr=0.1)  # threshold value 0.1
out2 &lt;- CovEst.soft(data, thr=1)    # threshold value 1
out3 &lt;- CovEst.soft(data, thr=10)   # threshold value 10
out4 &lt;- CovEst.soft(data, thr=mthr) # automatic threshold checking

## visualize 4 estimated matrices
gcol &lt;- gray((0:100)/100)
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
image(out1$S[,pdim:1], col=gcol, main="thr=0.1")
image(out2$S[,pdim:1], col=gcol, main="thr=1")
image(out3$S[,pdim:1], col=gcol, main="thr=10")
image(out4$S[,pdim:1], col=gcol, main="automatic")
par(opar)

</code></pre>

<hr>
<h2 id='CovMean'>Estimate Mean Covariance Matrix</h2><span id='topic+CovMean'></span>

<h3>Description</h3>

<p>For a given 3-dimensional array where symmetric positive definite (SPD) matrices are stacked slice
by slice, it estimates Frechet mean on an open cone of SPD matrices under corresponding metric/distance
measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovMean(
  A,
  method = c("AIRM", "Cholesky", "Euclidean", "LERM", "Procrustes.SS",
    "Procrustes.Full", "PowerEuclidean", "RootEuclidean"),
  power = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovMean_+3A_a">A</code></td>
<td>
<p>a <code class="reqn">(p\times p\times N)</code> 3d array of <code class="reqn">N</code> SPD matrices.</p>
</td></tr>
<tr><td><code id="CovMean_+3A_method">method</code></td>
<td>
<p>the type of distance measures to be used; <code>"AIRM"</code> for Affine Invariant
Riemannian Metric,
<code>"Cholesky"</code> for Cholesky difference in Frobenius norm,
<code>"Euclidean"</code> for naive Frobenius norm as distance,
<code>"LERM"</code> for Log Euclidean Riemannian Metric,
<code>"Procrustes.SS"</code> for Procrustes Size and Shape measure,
<code>"Procrustes.Full"</code> for Procrustes analysis with scale,
<code>"PowerEuclidean"</code> for weighted eigenvalues by some exponent, and
<code>"RootEuclidean"</code> for matrix square root.</p>
</td></tr>
<tr><td><code id="CovMean_+3A_power">power</code></td>
<td>
<p>a non-zero number for PowerEuclidean distance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code class="reqn">(p\times p)</code> mean covariance matrix estimated.
</p>


<h3>References</h3>

<p>Dryden IL, Koloydenko A, Zhou D (2009).
&ldquo;Non-Euclidean statistics for covariance matrices, with applications to diffusion tensor imaging.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>3</b>(3), 1102&ndash;1123.
ISSN 1932-6157.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## generate 100 sample covariances of size (5-by-5).
pdim    = 5
samples = samplecovs(100,pdim)

## compute mean of first 50 sample covariances from data under Normal(0,Identity).
mLERM = CovMean(samples[,,1:50], method="LERM")
mAIRM = CovMean(samples[,,1:50], method="AIRM")
mChol = CovMean(samples[,,1:50], method="Cholesky")
mRoot = CovMean(samples[,,1:50], method="RootEuclidean")

## visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
image(mLERM[,pdim:1], main="LERM mean")
image(mAIRM[,pdim:1], main="AIRM mean")
image(mChol[,pdim:1], main="Cholesky mean")
image(mRoot[,pdim:1], main="RootEuclidean mean")
par(opar)

## End(Not run)

</code></pre>

<hr>
<h2 id='CovTest1.2013Cai'>One-Sample Covariance Test by Cai and Ma (2013)</h2><span id='topic+CovTest1.2013Cai'></span>

<h3>Description</h3>

<p>Given data, it performs 1-sample test for Covariance where
the null hypothesis is
</p>
<p style="text-align: center;"><code class="reqn">H_0 : \Sigma_n = \Sigma_0</code>
</p>

<p>where <code class="reqn">\Sigma_n</code> is the covariance of data model and <code class="reqn">\Sigma_0</code> is a
hypothesized covariance based on a procedure proposed by Cai and Ma (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovTest1.2013Cai(data, Sigma0 = diag(ncol(data)), alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovTest1.2013Cai_+3A_data">data</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="CovTest1.2013Cai_+3A_sigma0">Sigma0</code></td>
<td>
<p>a <code class="reqn">(p\times p)</code> given covariance matrix.</p>
</td></tr>
<tr><td><code id="CovTest1.2013Cai_+3A_alpha">alpha</code></td>
<td>
<p>level of significance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic value.</p>
</dd>
<dt>threshold</dt><dd><p>rejection criterion to be compared against test statistic.</p>
</dd>
<dt>reject</dt><dd><p>a logical; <code>TRUE</code> to reject null hypothesis, <code>FALSE</code> otherwise.</p>
</dd>
</dl>



<h3>References</h3>

<p>Cai TT, Ma Z (2013).
&ldquo;Optimal hypothesis testing for high dimensional covariance matrices.&rdquo;
<em>Bernoulli</em>, <b>19</b>(5B), 2359&ndash;2388.
ISSN 1350-7265.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## generate data from multivariate normal with trivial covariance.
pdim = 5
data = matrix(rnorm(10*pdim), ncol=pdim)

## run the test
CovTest1.2013Cai(data)

## End(Not run)

</code></pre>

<hr>
<h2 id='CovTest1.2014Srivastava'>One-Sample Covariance Test by Srivastava, Yanagihara, and Kubokawa (2014)</h2><span id='topic+CovTest1.2014Srivastava'></span>

<h3>Description</h3>

<p>Given data, it performs 1-sample test for Covariance where
the null hypothesis is
</p>
<p style="text-align: center;"><code class="reqn">H_0 : \Sigma_n = \Sigma_0</code>
</p>

<p>where <code class="reqn">\Sigma_n</code> is the covariance of data model and <code class="reqn">\Sigma_0</code> is a
hypothesized covariance based on a procedure proposed by Srivastava, Yanagihara, and Kubokawa (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovTest1.2014Srivastava(data, Sigma0 = diag(ncol(data)), alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovTest1.2014Srivastava_+3A_data">data</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="CovTest1.2014Srivastava_+3A_sigma0">Sigma0</code></td>
<td>
<p>a <code class="reqn">(p\times p)</code> given covariance matrix.</p>
</td></tr>
<tr><td><code id="CovTest1.2014Srivastava_+3A_alpha">alpha</code></td>
<td>
<p>level of significance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic value.</p>
</dd>
<dt>threshold</dt><dd><p>rejection criterion to be compared against test statistic.</p>
</dd>
<dt>reject</dt><dd><p>a logical; <code>TRUE</code> to reject null hypothesis, <code>FALSE</code> otherwise.</p>
</dd>
</dl>



<h3>References</h3>

<p>Srivastava MS, Yanagihara H, Kubokawa T (2014).
&ldquo;Tests for covariance matrices in high dimension with less sample size.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>130</b>, 289&ndash;309.
ISSN 0047259X.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## generate data from multivariate normal with trivial covariance.
pdim = 5
data = matrix(rnorm(10*pdim), ncol=pdim)

## run the test
CovTest1.2014Srivastava(data)

## End(Not run)

</code></pre>

<hr>
<h2 id='CovTest2.2013Cai'>Two-Sample Covariance Test by Cai and Ma (2013)</h2><span id='topic+CovTest2.2013Cai'></span>

<h3>Description</h3>

<p>Given two sets of data, it performs 2-sample test for equality of covariance matrices where
the null hypothesis is
</p>
<p style="text-align: center;"><code class="reqn">H_0 : \Sigma_1 = \Sigma_2</code>
</p>

<p>where <code class="reqn">\Sigma_1</code> and <code class="reqn">\Sigma_2</code> represent true (unknown) covariance
for each dataset based on a procedure proposed by Cai and Ma (2013).
If <code>statistic</code> <code class="reqn">&gt;</code> <code>threshold</code>, it rejects null hypothesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovTest2.2013Cai(X, Y, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CovTest2.2013Cai_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(m\times p)</code>  matrix where each row is an observation from the first dataset.</p>
</td></tr>
<tr><td><code id="CovTest2.2013Cai_+3A_y">Y</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> matrix where each row is an observation from the second dataset.</p>
</td></tr>
<tr><td><code id="CovTest2.2013Cai_+3A_alpha">alpha</code></td>
<td>
<p>level of significance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic value.</p>
</dd>
<dt>threshold</dt><dd><p>rejection criterion to be compared against test statistic.</p>
</dd>
<dt>reject</dt><dd><p>a logical; <code>TRUE</code> to reject null hypothesis, <code>FALSE</code> otherwise.</p>
</dd>
</dl>



<h3>References</h3>

<p>Cai TT, Ma Z (2013).
&ldquo;Optimal hypothesis testing for high dimensional covariance matrices.&rdquo;
<em>Bernoulli</em>, <b>19</b>(5B), 2359&ndash;2388.
ISSN 1350-7265.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate 2 datasets from multivariate normal with identical covariance.
pdim  = 5
data1 = matrix(rnorm(100*pdim), ncol=pdim)
data2 = matrix(rnorm(150*pdim), ncol=pdim)

## run test
CovTest2.2013Cai(data1, data2)

</code></pre>

<hr>
<h2 id='DiagTest1.2011Cai'>One-Sample Diagonality Test by Cai and Jiang (2011)</h2><span id='topic+DiagTest1.2011Cai'></span>

<h3>Description</h3>

<p>Given data, it performs 1-sample test for diagonal entries of a Covariance matrix where
the null hypothesis is
</p>
<p style="text-align: center;"><code class="reqn">H_0 : \sigma_{ij} = 0~\mathrm{for any}~i \neq j</code>
</p>

<p>and alternative hypothesis is <code class="reqn">H_1 : ~\mathrm{not}~H_0</code>
with <code class="reqn">\Sigma_n = (\sigma_{ij})</code> based on a procedure proposed by Cai and Jiang (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DiagTest1.2011Cai(data, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DiagTest1.2011Cai_+3A_data">data</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="DiagTest1.2011Cai_+3A_alpha">alpha</code></td>
<td>
<p>level of significance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic value.</p>
</dd>
<dt>threshold</dt><dd><p>rejection criterion to be compared against test statistic.</p>
</dd>
<dt>reject</dt><dd><p>a logical; <code>TRUE</code> to reject null hypothesis, <code>FALSE</code> otherwise.</p>
</dd>
</dl>



<h3>References</h3>

<p>Cai TT, Jiang T (2011).
&ldquo;Limiting laws of coherence of random matrices with applications to testing covariance structure and construction of compressed sensing matrices.&rdquo;
<em>The Annals of Statistics</em>, <b>39</b>(3), 1496&ndash;1525.
ISSN 0090-5364.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## generate data from multivariate normal with trivial covariance.
pdim = 5
data = matrix(rnorm(100*pdim), ncol=pdim)

## run test with different alpha values
DiagTest1.2011Cai(data, alpha=0.01)
DiagTest1.2011Cai(data, alpha=0.05)
DiagTest1.2011Cai(data, alpha=0.10)

## End(Not run)

</code></pre>

<hr>
<h2 id='DiagTest1.2015Lan'>One-Sample Diagonality Test by Lan et al. (2015)</h2><span id='topic+DiagTest1.2015Lan'></span>

<h3>Description</h3>

<p>Given data, it performs 1-sample test for diagonal entries of a Covariance matrix where
the null hypothesis is
</p>
<p style="text-align: center;"><code class="reqn">H_0 : \sigma_{ij} = 0~\mathrm{for any}~i \neq j</code>
</p>

<p>and alternative hypothesis is <code class="reqn">H_1 : ~\mathrm{not}~H_0</code>
with <code class="reqn">\Sigma_n = (\sigma_{ij})</code> based on a procedure proposed by Lan et al. (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DiagTest1.2015Lan(data, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DiagTest1.2015Lan_+3A_data">data</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="DiagTest1.2015Lan_+3A_alpha">alpha</code></td>
<td>
<p>level of significance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic value.</p>
</dd>
<dt>threshold</dt><dd><p>rejection criterion to be compared against test statistic.</p>
</dd>
<dt>reject</dt><dd><p>a logical; <code>TRUE</code> to reject null hypothesis, <code>FALSE</code> otherwise.</p>
</dd>
</dl>



<h3>References</h3>

<p>Lan W, Luo R, Tsai C, Wang H, Yang Y (2015).
&ldquo;Testing the Diagonality of a Large Covariance Matrix in a Regression Setting.&rdquo;
<em>Journal of Business \&amp; Economic Statistics</em>, <b>33</b>(1), 76&ndash;86.
ISSN 0735-0015, 1537-2707.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## generate data from multivariate normal with trivial covariance.
pdim = 5
data = matrix(rnorm(100*pdim), ncol=pdim)

## run test with different alpha values
DiagTest1.2015Lan(data, alpha=0.01)
DiagTest1.2015Lan(data, alpha=0.05)
DiagTest1.2015Lan(data, alpha=0.10)

## End(Not run)

</code></pre>

<hr>
<h2 id='package-CovTools'>A Collection of Geometric and Statistical Tools for Covariance (and Precision) Analysis</h2><span id='topic+package-CovTools'></span>

<h3>Description</h3>

<p>Covariance is of universal prevalence across various disciplines within statistics.
<span class="pkg">CovTools</span> package aims at providing a rich collection of geometric and statistical tools
for a variety of inferences on covariance structures as well as its inverse called precision matrix.
See the sections below for a comprehensive list of functions provided from the package.
</p>


<h3>Geometric Methods</h3>

<p>From inference on manifolds perspective, we have following functions,
</p>

<table>
<tr>
 <td style="text-align: center;">
<em>name of a function</em> </td><td style="text-align: center;"> <em>description</em> </td>
</tr>
<tr>
 <td style="text-align: center;">
<code><a href="#topic+CovDist">CovDist</a></code> </td><td style="text-align: center;"> compute pairwise distance of covariance matrices </td>
</tr>
<tr>
 <td style="text-align: center;">
<code><a href="#topic+CovMean">CovMean</a></code> </td><td style="text-align: center;"> compute mean covariance matrix
</td>
</tr>

</table>


<hr>
<h2 id='PreEst.2014An'>Banded Precision Matrix Estimation via Bandwidth Test</h2><span id='topic+PreEst.2014An'></span>

<h3>Description</h3>

<p><code>PreEst.2014An</code> returns an estimator of the banded precision matrix using the modified Cholesky decomposition.
It uses the estimator defined in Bickel and Levina (2008). The bandwidth is determined by the bandwidth test
suggested by An, Guo and Liu (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PreEst.2014An(
  X,
  upperK = floor(ncol(X)/2),
  algorithm = c("Bonferroni", "Holm"),
  alpha = 0.01
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PreEst.2014An_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="PreEst.2014An_+3A_upperk">upperK</code></td>
<td>
<p>upper bound of bandwidth <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="PreEst.2014An_+3A_algorithm">algorithm</code></td>
<td>
<p>bandwidth test algorithm to be used.</p>
</td></tr>
<tr><td><code id="PreEst.2014An_+3A_alpha">alpha</code></td>
<td>
<p>significance level for the bandwidth test.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>C</dt><dd><p>a <code class="reqn">(p\times p)</code> estimated banded precision matrix.</p>
</dd>
<dt>optk</dt><dd><p>an estimated optimal bandwidth acquired from the test procedure.</p>
</dd>
</dl>



<h3>References</h3>

<p>An B, Guo J, Liu Y (2014).
&ldquo;Hypothesis testing for band size detection of high-dimensional banded precision matrices.&rdquo;
<em>Biometrika</em>, <b>101</b>(2), 477&ndash;483.
ISSN 0006-3444, 1464-3510.
</p>
<p>Bickel PJ, Levina E (2008).
&ldquo;Regularized estimation of large covariance matrices.&rdquo;
<em>The Annals of Statistics</em>, <b>36</b>(1), 199&ndash;227.
ISSN 0090-5364.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## parameter setting
p = 200; n = 100
k0 = 5; A0min=0.1; A0max=0.2; D0min=2; D0max=5

set.seed(123)
A0 = matrix(0, p,p)
for(i in 2:p){
  term1 = runif(n=min(k0,i-1),min=A0min, max=A0max)
  term2 = sample(c(1,-1),size=min(k0,i-1),replace=TRUE)
  vals  = term1*term2
  vals  = vals[ order(abs(vals)) ]
  A0[i, max(1, i-k0):(i-1)] = vals
}

D0 = diag(runif(n = p, min = D0min, max = D0max))
Omega0 = t(diag(p) - A0)%*%diag(1/diag(D0))%*%(diag(p) - A0)

## data generation (based on AR representation)
## it is same with generating n random samples from N_p(0, Omega0^{-1})
X = matrix(0, nrow=n, ncol=p)
X[,1] = rnorm(n, sd = sqrt(D0[1,1]))
for(j in 2:p){
  mean.vec.j = X[, 1:(j-1)]%*%as.matrix(A0[j, 1:(j-1)])
  X[,j] = rnorm(n, mean = mean.vec.j, sd = sqrt(D0[j,j]))
}

## banded estimation using two different schemes
Omega1 &lt;- PreEst.2014An(X, upperK=20, algorithm="Bonferroni")
Omega2 &lt;- PreEst.2014An(X, upperK=20, algorithm="Holm")

## visualize true and estimated precision matrices
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
image(Omega0[,p:1],   main="Original Precision")
image(Omega1$C[,p:1], main="banded3::Bonferroni")
image(Omega2$C[,p:1], main="banded3::Holm")
par(opar)

## End(Not run)

</code></pre>

<hr>
<h2 id='PreEst.2014Banerjee'>Bayesian Estimation of a Banded Precision Matrix (Banerjee 2014)</h2><span id='topic+PreEst.2014Banerjee'></span>

<h3>Description</h3>

<p><code>PreEst.2014Banerjee</code> returns a Bayes estimator of the banded precision matrix using G-Wishart prior.
Stein’s loss or squared error loss function is used depending on the “loss” argument in the function.
The bandwidth is set at the mode of marginal posterior for the bandwidth parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PreEst.2014Banerjee(
  X,
  upperK = floor(ncol(X)/2),
  delta = 10,
  logpi = function(k) {     -k^4 },
  loss = c("Stein", "Squared")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PreEst.2014Banerjee_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="PreEst.2014Banerjee_+3A_upperk">upperK</code></td>
<td>
<p>upper bound of bandwidth <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="PreEst.2014Banerjee_+3A_delta">delta</code></td>
<td>
<p>hyperparameter for G-Wishart prior. Default value is 10. It has to be larger than 2.</p>
</td></tr>
<tr><td><code id="PreEst.2014Banerjee_+3A_logpi">logpi</code></td>
<td>
<p>log of prior distribution for bandwidth <code class="reqn">k</code>. Default is a function proportional to <code class="reqn">-k^4</code>.</p>
</td></tr>
<tr><td><code id="PreEst.2014Banerjee_+3A_loss">loss</code></td>
<td>
<p>type of loss; either <code>"Stein"</code> or <code>"Squared"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>C</dt><dd><p>a <code class="reqn">(p\times p)</code> MAP estimate for precision matrix.</p>
</dd>
</dl>



<h3>References</h3>

<p>Banerjee S, Ghosal S (2014).
&ldquo;Posterior convergence rates for estimating large precision matrices using graphical models.&rdquo;
<em>Electronic Journal of Statistics</em>, <b>8</b>(2), 2111&ndash;2137.
ISSN 1935-7524.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data from multivariate normal with Identity precision.
pdim = 10
data = matrix(rnorm(50*pdim), ncol=pdim)

## compare different K
out1 &lt;- PreEst.2014Banerjee(data, upperK=1)
out2 &lt;- PreEst.2014Banerjee(data, upperK=3)
out3 &lt;- PreEst.2014Banerjee(data, upperK=5)

## visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
image(diag(pdim)[,pdim:1],main="Original Precision")
image(out1$C[,pdim:1], main="banded1::upperK=1")
image(out2$C[,pdim:1], main="banded1::upperK=3")
image(out3$C[,pdim:1], main="banded1::upperK=5")
par(opar)

</code></pre>

<hr>
<h2 id='PreEst.2017Lee'>Bayesian Estimation of a Banded Precision Matrix (Lee 2017)</h2><span id='topic+PreEst.2017Lee'></span>

<h3>Description</h3>

<p><code>PreEst.2017Lee</code> returns a Bayes estimator of the banded precision matrix,
which is defined in subsection 3.3 of Lee and Lee (2017), using the k-BC prior.
The bandwidth is set at the mode of marginal posterior for the bandwidth parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PreEst.2017Lee(X, upperK = floor(ncol(X)/2), logpi = function(k) {
    -k^4
})
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PreEst.2017Lee_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="PreEst.2017Lee_+3A_upperk">upperK</code></td>
<td>
<p>upper bound of bandwidth <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="PreEst.2017Lee_+3A_logpi">logpi</code></td>
<td>
<p>log of prior distribution for bandwidth <code class="reqn">k</code>. Default is a function proportional to <code class="reqn">-k^4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>C</dt><dd><p>a <code class="reqn">(p\times p)</code> MAP estimate for precision matrix.</p>
</dd>
</dl>



<h3>References</h3>

<p>Lee K, Lee J (2017).
&ldquo;Estimating Large Precision Matrices via Modified Cholesky Decomposition.&rdquo;
<em>ArXiv e-prints</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data from multivariate normal with Identity precision.
pdim = 5
data = matrix(rnorm(100*pdim), ncol=pdim)

## compare different K
out1 &lt;- PreEst.2017Lee(data, upperK=1)
out2 &lt;- PreEst.2017Lee(data, upperK=3)
out3 &lt;- PreEst.2017Lee(data, upperK=5)

## visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
image(diag(pdim)[,pdim:1], main="Original Precision")
image(out1$C[,pdim:1],     main="banded2::upperK=1")
image(out2$C[,pdim:1],     main="banded2::upperK=3")
image(out3$C[,pdim:1],     main="banded2::upperK=5")
par(opar)

</code></pre>

<hr>
<h2 id='PreEst.glasso'>Precision Matrix Estimation via Graphical Lasso</h2><span id='topic+PreEst.glasso'></span>

<h3>Description</h3>

<p>Given a sample covariance matrix <code class="reqn">S</code>, graphical lasso aims at estimating sparse precision matrix <code class="reqn">X</code> - inverse
of covariance. It solves a following optimization problem,
</p>
<p style="text-align: center;"><code class="reqn">\textrm{max}_X
\log\textrm{det}X - &lt;S,X&gt; - \lambda \|X \|_1 \textrm{ such that } X \succ 0</code>
</p>

<p>where <code class="reqn">\lambda</code> a regularization parameter, <code class="reqn">&lt;S,X&gt;=tr(S^T X)</code> , <code class="reqn">\|X\|_1 = \sum X_{ij}</code> and <code class="reqn">X\succ 0</code> indicates positive definiteness. We provide three
modes of computations, <code>'fixed'</code>,<code>'confidence'</code>, or <code>'BIC'</code> with respect to <code class="reqn">\lambda</code>. Please see the section below for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PreEst.glasso(X, method = list(type = "fixed", param = 1), parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PreEst.glasso_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">(n\times p)</code> data matrix where each row is an observation.</p>
</td></tr>
<tr><td><code id="PreEst.glasso_+3A_method">method</code></td>
<td>
<p>a list containing following parameters, </p>

<dl>
<dt>type</dt><dd><p>one of <code>'fixed'</code>,<code>'confidence'</code>, or <code>'BIC'</code>.</p>
</dd>
<dt>param</dt><dd><p>either a numeric value or vector of values.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="PreEst.glasso_+3A_parallel">parallel</code></td>
<td>
<p>a logical; <code>TRUE</code> for using half the cores available, <code>FALSE</code> otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>C</dt><dd><p>a <code class="reqn">(p\times p)</code> estimated precision matrix.</p>
</dd>
<dt>BIC</dt><dd><p>a dataframe containing <code class="reqn">\lambda</code> values and corresponding BIC scores with <code>type='BIC'</code> method.</p>
</dd>
</dl>



<h3>regularization parameters</h3>

<p>We currently provide three options for solving the problem, <code>'fixed'</code>,<code>'confidence'</code>, or <code>'BIC'</code> with respect to <code class="reqn">\lambda</code>.
When the method type is <code>'fixed'</code>, the parameter should be a single numeric value as a user-defined <code class="reqn">\lambda</code> value. Likewise,
method type of <code>'confidence'</code> requires a singule numeric value in <code class="reqn">(0,1)</code>, where the value is set heuristically
according to
</p>
<p style="text-align: center;"><code class="reqn">
\rho = \frac{t_{n-2}(\gamma) \max S_{ii}S_{jj}}{\sqrt{n-2+ t_{n-2}^2(\gamma)}}
</code>
</p>

<p>for a given confidence level <code class="reqn">\gamma \in (0,1)</code> as proposed by Banerjee et al. (2006).
Finally, <code>'BIC'</code> type requires a vector of <code class="reqn">\lambda</code> values and opts for a lambda value with the lowest BIC values
as proposed by Yuan and Lin (2007).
</p>


<h3>References</h3>

<p>Banerjee O, Ghaoui LE, d'Aspremont A, Natsoulis G (2006).
&ldquo;Convex optimization techniques for fitting sparse Gaussian graphical models.&rdquo;
In <em>Proceedings of the 23rd international conference on Machine learning</em>, 89&ndash;96.
ISBN 978-1-59593-383-6.
</p>
<p>Yuan M, Lin Y (2007).
&ldquo;Model Selection and Estimation in the Gaussian Graphical Model.&rdquo;
<em>Biometrika</em>, <b>94</b>(1), 19&ndash;35.
ISSN 00063444.
</p>
<p>Friedman J, Hastie T, Tibshirani R (2008).
&ldquo;Sparse inverse covariance estimation with the graphical lasso.&rdquo;
<em>Biostatistics</em>, <b>9</b>(3), 432&ndash;441.
ISSN 1465-4644, 1468-4357.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## generate data from multivariate normal with Identity precision.
pdim = 10
data = matrix(rnorm(100*pdim), ncol=pdim)

## prepare input arguments for diefferent scenarios
lbdvec &lt;- c(0.01,0.1,1,10,100)              # a vector of regularization parameters
list1 &lt;- list(type="fixed",param=1.0)       # single regularization parameter case
list2 &lt;- list(type="confidence",param=0.95) # single confidence level case
list3 &lt;- list(type="BIC",param=lbdvec)      # multiple regularizers with BIC selection

## compute with different scenarios
out1 &lt;- PreEst.glasso(data, method=list1)
out2 &lt;- PreEst.glasso(data, method=list2)
out3 &lt;- PreEst.glasso(data, method=list3)

## visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
image(diag(pdim)[,pdim:1], main="Original Precision")
image(out1$C[,pdim:1],     main="glasso::lambda=1.0")
image(out2$C[,pdim:1],     main="glasso::Confidence=0.95")
image(out3$C[,pdim:1],     main="glasso::BIC selection")
par(opar)


</code></pre>

<hr>
<h2 id='samplecovs'>Generate Sample Covariances of 2 groups</h2><span id='topic+samplecovs'></span>

<h3>Description</h3>

<p>For visualization purpose, <code>samplecovs</code> generates a 3d array
of stacked sample covariances where - in 3rd dimension, the first half
are sample covariances of samples generated independently from
normal distribution with identity covariance, where the latter half
consists of samples covariances from dense random population covariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>samplecovs(ncopy, size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="samplecovs_+3A_ncopy">ncopy</code></td>
<td>
<p>the total number of sample covariances to be generated.</p>
</td></tr>
<tr><td><code id="samplecovs_+3A_size">size</code></td>
<td>
<p>dimension <code class="reqn">p</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code class="reqn">(p\times p\times ncopy)</code> array of strictly positive definite sample covariances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate total of 20 samples covariances of size 5-by-5.
samples &lt;- samplecovs(20,5)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
