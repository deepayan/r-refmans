<!DOCTYPE html><html><head><title>Help for package countSTAR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {countSTAR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#a_j'><p>Inverse rounding function</p></a></li>
<li><a href='#bam_star'><p>Fit Bayesian Additive STAR Model with MCMC</p></a></li>
<li><a href='#bart_star'><p>MCMC Algorithm for BART-STAR</p></a></li>
<li><a href='#bart_star_ispline'><p>MCMC sampler for BART-STAR with a monotone spline model</p>
for the transformation</a></li>
<li><a href='#blm_star'><p>STAR Bayesian Linear Regression</p></a></li>
<li><a href='#blm_star_bnpgibbs'><p>Gibbs sampler for STAR linear regression with BNP transformation</p></a></li>
<li><a href='#blm_star_exact'><p>Monte Carlo sampler for STAR linear regression with a g-prior</p></a></li>
<li><a href='#BrentMethod'><p>Brent's method for optimization</p></a></li>
<li><a href='#computeTimeRemaining'><p>Estimate the remaining time in the MCMC based on previous samples</p></a></li>
<li><a href='#confint.lmstar'><p>Compute asymptotic confidence intervals for STAR linear regression</p></a></li>
<li><a href='#credBands'><p>Compute Simultaneous Credible Bands</p></a></li>
<li><a href='#ergMean'><p>Compute the ergodic (running) mean.</p></a></li>
<li><a href='#expectation_gRcpp'><p>Estimate the mean for a STAR process</p></a></li>
<li><a href='#expectation_identity'><p>Estimate the mean for a STAR process</p></a></li>
<li><a href='#expectation_log'><p>Estimate the mean for a STAR process</p></a></li>
<li><a href='#expectation_sqrt'><p>Estimate the mean for a STAR process</p></a></li>
<li><a href='#expectation2_gRcpp'><p>Compute E(Y^2) for a STAR process</p></a></li>
<li><a href='#g_bc'><p>Box-Cox transformation</p></a></li>
<li><a href='#g_bnp'><p>Bayesian bootstrap-based transformation</p></a></li>
<li><a href='#g_cdf'><p>Cumulative distribution function (CDF)-based transformation</p></a></li>
<li><a href='#g_inv_approx'><p>Approximate inverse transformation</p></a></li>
<li><a href='#g_inv_bc'><p>Inverse Box-Cox transformation</p></a></li>
<li><a href='#gbm_star'><p>Fitting STAR Gradient Boosting Machines via EM algorithm</p></a></li>
<li><a href='#genEM_star'><p>Generalized EM estimation for STAR</p></a></li>
<li><a href='#genMCMC_star'><p>Generalized MCMC Algorithm for STAR</p></a></li>
<li><a href='#genMCMC_star_ispline'><p>MCMC sampler for STAR with a monotone spline model</p>
for the transformation</a></li>
<li><a href='#getEffSize'><p>Summarize of effective sample size</p></a></li>
<li><a href='#init_bam_orthog'><p>Initialize the parameters for an additive model</p></a></li>
<li><a href='#init_bam_thin'><p>Initialize the parameters for an additive model</p></a></li>
<li><a href='#init_lm_gprior'><p>Initialize linear regression parameters assuming a g-prior</p></a></li>
<li><a href='#init_lm_hs'><p>Initialize linear regression parameters assuming a horseshoe prior</p></a></li>
<li><a href='#init_lm_ridge'><p>Initialize linear regression parameters assuming a ridge prior</p></a></li>
<li><a href='#init_params_mean'><p>Initialize the parameters for a simple mean-only model</p></a></li>
<li><a href='#interval_gRcpp'><p>Estimate confidence intervals/bands for a STAR process</p></a></li>
<li><a href='#invlogit'><p>Compute the inverse log-odds</p></a></li>
<li><a href='#lm_star'><p>Fitting frequentist STAR linear model via EM algorithm</p></a></li>
<li><a href='#logit'><p>Compute the log-odds</p></a></li>
<li><a href='#logLikePointRcpp'><p>Compute the pointwise log-likelihood for STAR</p></a></li>
<li><a href='#logLikeRcpp'><p>Compute the log-likelihood for STAR</p></a></li>
<li><a href='#plot_coef'><p>Plot the estimated regression coefficients and credible intervals</p></a></li>
<li><a href='#plot_fitted'><p>Plot the fitted values and the data</p></a></li>
<li><a href='#plot_pmf'><p>Plot the empirical and model-based probability mass functions</p></a></li>
<li><a href='#pmaxRcpp'><p>pmax() in Rcpp</p></a></li>
<li><a href='#pminRcpp'><p>pmin() in Rcpp</p></a></li>
<li><a href='#predict.lmstar'><p>Predict method for response in STAR linear model</p></a></li>
<li><a href='#pvals'><p>Compute coefficient p-values for STAR linear regression using likelihood ratio test</p></a></li>
<li><a href='#randomForest_star'><p>Fit Random Forest STAR with EM algorithm</p></a></li>
<li><a href='#roaches'><p>Data on the efficacy of a pest management system at reducing the number of</p>
roaches in urban apartments.</a></li>
<li><a href='#round_floor'><p>Rounding function</p></a></li>
<li><a href='#rtruncnormRcpp'><p>Sample from a truncated normal distribution</p></a></li>
<li><a href='#sample_bam_orthog'><p>Sample the parameters for an additive model</p></a></li>
<li><a href='#sample_bam_thin'><p>Sample the parameters for an additive model</p></a></li>
<li><a href='#sample_lm_gprior'><p>Sample the linear regression parameters assuming a g-prior</p></a></li>
<li><a href='#sample_lm_hs'><p>Sample linear regression parameters assuming horseshoe prior</p></a></li>
<li><a href='#sample_lm_ridge'><p>Sample linear regression parameters assuming a ridge prior</p></a></li>
<li><a href='#sample_params_mean'><p>Sample the parameters for a simple mean-only model</p></a></li>
<li><a href='#sampleFastGaussian'><p>Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al.</p></a></li>
<li><a href='#simBaS'><p>Compute Simultaneous Band Scores (SimBaS)</p></a></li>
<li><a href='#simulate_nb_friedman'><p>Simulate count data from Friedman's nonlinear regression</p></a></li>
<li><a href='#simulate_nb_lm'><p>Simulate count data from a linear regression</p></a></li>
<li><a href='#spline_star'><p>Estimation for Bayesian STAR spline regression</p></a></li>
<li><a href='#spline_star_exact'><p>Monte Carlo predictive sampler for spline regression</p></a></li>
<li><a href='#splineBasis'><p>Initialize and reparametrize a spline basis matrix</p></a></li>
<li><a href='#truncnorm_mom'><p>Compute the first and second moment of a truncated normal</p></a></li>
<li><a href='#uni.slice'><p>Univariate Slice Sampler from Neal (2008)</p></a></li>
<li><a href='#update_struct'><p>Update parameters for warpDLM model with trend DLM</p></a></li>
<li><a href='#warpDLM'><p>Posterior Inference for warpDLM model with latent structural DLM</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Flexible Modeling of Count Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>For Bayesian and classical inference and prediction with count-valued data,
    Simultaneous Transformation and Rounding (STAR) Models provide a flexible, interpretable,
    and easy-to-use approach. STAR models the observed count data using a rounded 
    continuous data model and incorporates a transformation for greater flexibility.
    Implicitly, STAR formalizes the commonly-applied yet incoherent procedure of 
    (i) transforming count-valued data and subsequently 
    (ii) modeling the transformed data using Gaussian models. 
    STAR is well-defined for count-valued data, which is reflected in predictive accuracy, 
    and is designed to account for zero-inflation, bounded or censored data, and over- or underdispersion. 
    Importantly, STAR is easy to combine with existing MCMC or point estimation
    methods for continuous data, which allows seamless adaptation of continuous data
    models (such as linear regressions, additive models, BART, random forests,
    and gradient boosting machines) for count-valued data. The package also includes several
    methods for modeling count time series data, namely via warped Dynamic Linear Models. 
    For more details and background on these methodologies, see the works of 
    Kowal and Canale (2020) &lt;<a href="https://doi.org/10.1214%2F20-EJS1707">doi:10.1214/20-EJS1707</a>&gt;, 
    Kowal and Wu (2022) &lt;<a href="https://doi.org/10.1111%2Fbiom.13617">doi:10.1111/biom.13617</a>&gt;, 
    King and Kowal (2022) &lt;<a href="https://doi.org/10.48550/arXiv.2110.14790">doi:10.48550/arXiv.2110.14790</a>&gt;, and 
    Kowal and Wu (2023) &lt;<a href="https://doi.org/10.48550/arXiv.2110.12316">doi:10.48550/arXiv.2110.12316</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, coda, dbarts, FastGP, gbm, graphics, Matrix,
spikeSlabGAM, splines2, randomForest, Rcpp, TruncatedNormal,
truncdist, KFAS</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, bayesplot, mgcv</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bking124.github.io/countSTAR/">https://bking124.github.io/countSTAR/</a>
<a href="https://github.com/bking124/countSTAR">https://github.com/bking124/countSTAR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bking124/countSTAR/issues">https://github.com/bking124/countSTAR/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-29 21:33:30 UTC; brian</td>
</tr>
<tr>
<td>Author:</td>
<td>Brian King [aut, cre],
  Dan Kowal [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brian King &lt;brianking387@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-30 18:30:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='a_j'>Inverse rounding function</h2><span id='topic+a_j'></span>

<h3>Description</h3>

<p>Define the intervals associated with <code>y = j</code> based on the flooring function.
The function returns <code>-Inf</code> for <code>j = 0</code> (or smaller) and <code>Inf</code> for
any <code>j &gt;= y_max + 1</code>, where <code>y_max</code> is a known upper bound on the data <code>y</code>
(if specified).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>a_j(j, y_max = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="a_j_+3A_j">j</code></td>
<td>
<p>the integer-valued input(s)</p>
</td></tr>
<tr><td><code id="a_j_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The (lower) interval endpoint(s) associated with <code>j</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Standard cases:
a_j(1)
a_j(20)

# Boundary cases:
a_j(0)
a_j(20, y_max = 15)

</code></pre>

<hr>
<h2 id='bam_star'>Fit Bayesian Additive STAR Model with MCMC</h2><span id='topic+bam_star'></span>

<h3>Description</h3>

<p>Run the MCMC algorithm for a STAR Bayesian additive model
The transformation can be known (e.g., log or sqrt) or unknown
(Box-Cox or estimated nonparametrically) for greater flexibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bam_star(
  y,
  X_lin,
  X_nonlin,
  splinetype = "orthogonal",
  transformation = "np",
  y_max = Inf,
  nsave = 5000,
  nburn = 5000,
  nskip = 2,
  save_y_hat = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bam_star_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="bam_star_+3A_x_lin">X_lin</code></td>
<td>
<p><code>n x pL</code> matrix of predictors to be modelled as linear</p>
</td></tr>
<tr><td><code id="bam_star_+3A_x_nonlin">X_nonlin</code></td>
<td>
<p><code>n x pNL</code> matrix of predictors to be modelled as nonlinear</p>
</td></tr>
<tr><td><code id="bam_star_+3A_splinetype">splinetype</code></td>
<td>
<p>Type of spline to use for modelling the nonlinear predictors;
must be either &quot;orthogonal&quot; (orthogonalized splines&ndash;the default) or &quot;thinplate&quot;
(low-rank thin plate splines)</p>
</td></tr>
<tr><td><code id="bam_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li><p> &quot;box-cox&quot; (box-cox transformation with learned parameter)
</p>
</li>
<li><p> &quot;ispline&quot; (transformation is modeled as unknown, monotone function
using I-splines)
</p>
</li></ul>
</td></tr>
<tr><td><code id="bam_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="bam_star_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save</p>
</td></tr>
<tr><td><code id="bam_star_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="bam_star_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
<tr><td><code id="bam_star_+3A_save_y_hat">save_y_hat</code></td>
<td>
<p>logical; if TRUE, compute and save the posterior draws of
the expected counts, E(y), which may be slow to compute</p>
</td></tr>
<tr><td><code id="bam_star_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, print time remaining</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation.
</p>
<p>Posterior and predictive inference is obtained via a Gibbs sampler
that combines (i) a latent data augmentation step (like in probit regression)
and (ii) an existing sampler for a continuous data model.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt', as well as a version in which the Box-Cox parameter
is inferred within the MCMC sampler ('box-cox'). Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>. Third, the transformation can be
modeled as an unknown, monotone function using I-splines ('ispline'). The
Robust Adaptive Metropolis (RAM) sampler is used for drawing the parameter
of the transformation function.
</p>


<h3>Value</h3>

<p>a list with at least the following elements:
</p>

<ul>
<li> <p><code>coefficients</code>: the posterior mean of the coefficients
</p>
</li>
<li> <p><code>fitted.values</code>: the posterior mean of the conditional expectation of the counts <code>y</code>
</p>
</li>
<li> <p><code>post.coefficients</code>: posterior draws of the coefficients
</p>
</li>
<li> <p><code>post.fitted.values</code>: posterior draws of the conditional mean of the counts <code>y</code>
</p>
</li>
<li> <p><code>post.pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>post.lambda</code>: draws from the posterior distribution of <code>lambda</code>
</p>
</li>
<li> <p><code>post.sigma</code>: draws from the posterior distribution of <code>sigma</code>
</p>
</li>
<li> <p><code>post.log.like.point</code>: draws of the log-likelihood for each of the <code>n</code> observations
</p>
</li>
<li> <p><code>WAIC</code>: Widely-Applicable/Watanabe-Akaike Information Criterion
</p>
</li>
<li> <p><code>p_waic</code>: Effective number of parameters based on WAIC
</p>
</li></ul>

<p>In the case of <code>transformation="ispline"</code>, the list also contains
</p>

<ul>
<li> <p><code>post.g</code>: draws from the posterior distribution of the transformation <code>g</code>
</p>
</li>
<li> <p><code>post.sigma.gamma</code>: draws from the posterior distribution of <code>sigma.gamma</code>,
the prior standard deviation of the transformation g() coefficients
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate data with count-valued response y:
sim_dat = simulate_nb_friedman(n = 100, p = 5, seed=32)
y = sim_dat$y; X = sim_dat$X

# Linear and nonlinear components:
X_lin = as.matrix(X[,-(1:3)])
X_nonlin = as.matrix(X[,(1:3)])

# STAR: nonparametric transformation
fit &lt;- bam_star(y,X_lin, X_nonlin, nburn=1000, nskip=0)

# Posterior mean of each coefficient:
coef(fit)

# WAIC:
fit$WAIC

# MCMC diagnostics:
plot(as.ts(fit$post.coefficients[,1:3]))

# Posterior predictive check:
hist(apply(fit$post.pred, 1,
           function(x) mean(x==0)), main = 'Proportion of Zeros', xlab='');
abline(v = mean(y==0), lwd=4, col ='blue')


</code></pre>

<hr>
<h2 id='bart_star'>MCMC Algorithm for BART-STAR</h2><span id='topic+bart_star'></span>

<h3>Description</h3>

<p>Run the MCMC algorithm for a BART model for count-valued responses using STAR.
The transformation can be known (e.g., log or sqrt) or unknown
(Box-Cox or estimated nonparametrically) for greater flexibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bart_star(
  y,
  X,
  X_test = NULL,
  y_test = NULL,
  transformation = "np",
  y_max = Inf,
  n.trees = 200,
  sigest = NULL,
  sigdf = 3,
  sigquant = 0.9,
  k = 2,
  power = 2,
  base = 0.95,
  nsave = 5000,
  nburn = 5000,
  nskip = 2,
  save_y_hat = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bart_star_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="bart_star_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="bart_star_+3A_x_test">X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors for test data</p>
</td></tr>
<tr><td><code id="bart_star_+3A_y_test">y_test</code></td>
<td>
<p><code>n0 x 1</code> vector of the test data responses (used for
computing log-predictive scores)</p>
</td></tr>
<tr><td><code id="bart_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent process; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li><p> &quot;box-cox&quot; (box-cox transformation with learned parameter)
</p>
</li>
<li><p> &quot;ispline&quot; (transformation is modeled as unknown, monotone function
using I-splines)
</p>
</li></ul>
</td></tr>
<tr><td><code id="bart_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="bart_star_+3A_n.trees">n.trees</code></td>
<td>
<p>number of trees to use in BART; default is 200</p>
</td></tr>
<tr><td><code id="bart_star_+3A_sigest">sigest</code></td>
<td>
<p>positive numeric estimate of the residual standard deviation (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_+3A_sigdf">sigdf</code></td>
<td>
<p>degrees of freedom for error variance prior (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_+3A_sigquant">sigquant</code></td>
<td>
<p>quantile of the error variance prior that the rough estimate (sigest)
is placed at. The closer the quantile is to 1, the more aggressive the fit will be (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_+3A_k">k</code></td>
<td>
<p>the number of prior standard deviations E(Y|x) = f(x) is away from +/- 0.5.
The response is internally scaled to range from -0.5 to 0.5.
The bigger k is, the more conservative the fitting will be (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_+3A_power">power</code></td>
<td>
<p>power parameter for tree prior (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_+3A_base">base</code></td>
<td>
<p>base parameter for tree prior (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save</p>
</td></tr>
<tr><td><code id="bart_star_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="bart_star_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
<tr><td><code id="bart_star_+3A_save_y_hat">save_y_hat</code></td>
<td>
<p>logical; if TRUE, compute and save the posterior draws of
the expected counts, E(y), which may be slow to compute</p>
</td></tr>
<tr><td><code id="bart_star_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, print time remaining</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation. Here, the model in (1)
is a Bayesian additive regression tree (BART) model.
</p>
<p>Posterior and predictive inference is obtained via a Gibbs sampler
that combines (i) a latent data augmentation step (like in probit regression)
and (ii) an existing sampler for a continuous data model.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt', as well as a version in which the Box-Cox parameter
is inferred within the MCMC sampler ('box-cox'). Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>. Third, the transformation can be
modeled as an unknown, monotone function using I-splines ('ispline'). The
Robust Adaptive Metropolis (RAM) sampler is used for drawing the parameter
of the transformation function.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>post.pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>post.sigma</code>: draws from the posterior distribution of <code>sigma</code>
</p>
</li>
<li> <p><code>post.log.like.point</code>: draws of the log-likelihood for each of the <code>n</code> observations
</p>
</li>
<li> <p><code>WAIC</code>: Widely-Applicable/Watanabe-Akaike Information Criterion
</p>
</li>
<li> <p><code>p_waic</code>: Effective number of parameters based on WAIC
</p>
</li>
<li> <p><code>post.pred.test</code>: draws from the posterior predictive distribution at the test points <code>X_test</code>
(<code>NULL</code> if <code>X_test</code> is not given)
</p>
</li>
<li> <p><code>post.fitted.values.test</code>: posterior draws of the conditional mean at the test points <code>X_test</code>
(<code>NULL</code> if <code>X_test</code> is not given)
</p>
</li>
<li> <p><code>post.mu.test</code>: draws of the conditional mean of z_star at the test points <code>X_test</code>
(<code>NULL</code> if <code>X_test</code> is not given)
</p>
</li>
<li> <p><code>post.log.pred.test</code>: draws of the log-predictive distribution for each of the <code>n0</code> test cases
(<code>NULL</code> if <code>X_test</code> is not given)
</p>
</li>
<li> <p><code>fitted.values</code>: the posterior mean of the conditional expectation of the counts <code>y</code>
(<code>NULL</code> if <code>save_y_hat=FALSE</code>)
</p>
</li>
<li> <p><code>post.fitted.values</code>: posterior draws of the conditional mean of the counts <code>y</code>
(<code>NULL</code> if <code>save_y_hat=FALSE</code>)
</p>
</li></ul>

<p>In the case of <code>transformation="ispline"</code>, the list also contains
</p>

<ul>
<li> <p><code>post.g</code>: draws from the posterior distribution of the transformation <code>g</code>
</p>
</li>
<li> <p><code>post.sigma.gamma</code>: draws from the posterior distribution of <code>sigma.gamma</code>,
the prior standard deviation of the transformation g() coefficients
</p>
</li></ul>

<p>If <code>transformation="box-cox"</code>, then the list also contains
</p>

<ul>
<li> <p><code>post.lambda</code>: draws from the posterior distribution of <code>lambda</code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate data with count-valued response y:
sim_dat = simulate_nb_friedman(n = 100, p = 10)
y = sim_dat$y; X = sim_dat$X

# BART-STAR with log-transformation:
fit_log = bart_star(y = y, X = X, transformation = 'log',
                    save_y_hat = TRUE, nburn=1000, nskip=0)

# Fitted values
plot_fitted(y = sim_dat$Ey,
            post_y = fit_log$post.fitted.values,
            main = 'Fitted Values: BART-STAR-log')

# WAIC for BART-STAR-log:
fit_log$WAIC

# MCMC diagnostics:
plot(as.ts(fit_log$post.fitted.values[,1:10]))

# Posterior predictive check:
hist(apply(fit_log$post.pred, 1,
           function(x) mean(x==0)), main = 'Proportion of Zeros', xlab='');
abline(v = mean(y==0), lwd=4, col ='blue')

# BART-STAR with nonparametric transformation:
fit = bart_star(y = y, X = X,
                     transformation = 'np', save_y_hat = TRUE)

# Fitted values
plot_fitted(y = sim_dat$Ey,
            post_y = fit$post.fitted.values,
            main = 'Fitted Values: BART-STAR-np')

# WAIC for BART-STAR-np:
fit$WAIC

# MCMC diagnostics:
plot(as.ts(fit$post.fitted.values[,1:10]))

# Posterior predictive check:
hist(apply(fit$post.pred, 1,
           function(x) mean(x==0)), main = 'Proportion of Zeros', xlab='');
abline(v = mean(y==0), lwd=4, col ='blue')


</code></pre>

<hr>
<h2 id='bart_star_ispline'>MCMC sampler for BART-STAR with a monotone spline model
for the transformation</h2><span id='topic+bart_star_ispline'></span>

<h3>Description</h3>

<p>Run the MCMC algorithm for BART model for count-valued responses using STAR.
The transformation is modeled as an unknown, monotone function
using I-splines. The Robust Adaptive Metropolis (RAM) sampler
is used for drawing the parameter of the transformation function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bart_star_ispline(
  y,
  X,
  X_test = NULL,
  y_test = NULL,
  lambda_prior = 1/2,
  y_max = Inf,
  n.trees = 200,
  sigest = NULL,
  sigdf = 3,
  sigquant = 0.9,
  k = 2,
  power = 2,
  base = 0.95,
  nsave = 5000,
  nburn = 5000,
  nskip = 2,
  save_y_hat = FALSE,
  target_acc_rate = 0.3,
  adapt_rate = 0.75,
  stop_adapt_perc = 0.5,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bart_star_ispline_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_x_test">X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors for test data</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_y_test">y_test</code></td>
<td>
<p><code>n0 x 1</code> vector of the test data responses (used for
computing log-predictive scores)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_lambda_prior">lambda_prior</code></td>
<td>
<p>the prior mean for the transformation g() is the Box-Cox function with
parameter <code>lambda_prior</code></p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_n.trees">n.trees</code></td>
<td>
<p>number of trees to use in BART; default is 200</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_sigest">sigest</code></td>
<td>
<p>positive numeric estimate of the residual standard deviation (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_sigdf">sigdf</code></td>
<td>
<p>degrees of freedom for error variance prior (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_sigquant">sigquant</code></td>
<td>
<p>quantile of the error variance prior that the rough estimate (sigest)
is placed at. The closer the quantile is to 1, the more aggresive the fit will be (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_k">k</code></td>
<td>
<p>the number of prior standard deviations E(Y|x) = f(x) is away from +/- 0.5.
The response is internally scaled to range from -0.5 to 0.5.
The bigger k is, the more conservative the fitting will be (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_power">power</code></td>
<td>
<p>power parameter for tree prior (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_base">base</code></td>
<td>
<p>base parameter for tree prior (see ?bart)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_save_y_hat">save_y_hat</code></td>
<td>
<p>logical; if TRUE, compute and save the posterior draws of
the expected counts, E(y), which may be slow to compute</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_target_acc_rate">target_acc_rate</code></td>
<td>
<p>target acceptance rate (between zero and one)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_adapt_rate">adapt_rate</code></td>
<td>
<p>rate of adaptation in RAM sampler (between zero and one)</p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_stop_adapt_perc">stop_adapt_perc</code></td>
<td>
<p>stop adapting at the proposal covariance at <code>stop_adapt_perc*nburn</code></p>
</td></tr>
<tr><td><code id="bart_star_ispline_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, print time remaining</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>fitted.values</code>: the posterior mean of the conditional expectation of the counts <code>y</code>
</p>
</li>
<li> <p><code>post.fitted.values</code>: posterior draws of the conditional mean of the counts <code>y</code>
</p>
</li>
<li> <p><code>post.pred.test</code>: draws from the posterior predictive distribution at the test points <code>X_test</code>
</p>
</li>
<li> <p><code>post.fitted.values.test</code>: posterior draws of the conditional mean at the test points <code>X_test</code>
</p>
</li>
<li> <p><code>post.pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>post.sigma</code>: draws from the posterior distribution of <code>sigma</code>
</p>
</li>
<li> <p><code>post.mu.test</code>: draws of the conditional mean of z_star at the test points
</p>
</li>
<li> <p><code>post.log.like.point</code>: draws of the log-likelihood for each of the <code>n</code> observations
</p>
</li>
<li> <p><code>post.log.pred.test</code>: draws of the log-predictive distribution for each of the <code>n0</code> test cases
</p>
</li>
<li> <p><code>WAIC</code>: Widely-Applicable/Watanabe-Akaike Information Criterion
</p>
</li>
<li> <p><code>p_waic</code>: Effective number of parameters based on WAIC
</p>
</li>
<li> <p><code>post.g</code>: draws from the posterior distribution of the transformation <code>g</code>
</p>
</li>
<li> <p><code>post.sigma.gamma</code>: draws from the posterior distribution of <code>sigma.gamma</code>,
the prior standard deviation of the transformation <code>g</code> coefficients
</p>
</li></ul>


<hr>
<h2 id='blm_star'>STAR Bayesian Linear Regression</h2><span id='topic+blm_star'></span>

<h3>Description</h3>

<p>Posterior inference for STAR linear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blm_star(
  y,
  X,
  X_test = NULL,
  transformation = "np",
  y_max = Inf,
  prior = "gprior",
  use_MCMC = TRUE,
  nsave = 5000,
  nburn = 5000,
  nskip = 0,
  method_sigma = "mle",
  approx_Fz = FALSE,
  approx_Fy = FALSE,
  psi = NULL,
  compute_marg = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blm_star_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="blm_star_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="blm_star_+3A_x_test">X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors for test data</p>
</td></tr>
<tr><td><code id="blm_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent process; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li><p> &quot;box-cox&quot; (box-cox transformation with learned parameter)
</p>
</li>
<li><p> &quot;ispline&quot; (transformation is modeled as unknown, monotone function
using I-splines)
</p>
</li>
<li><p> &quot;bnp&quot; (Bayesian nonparametric transformation using the Bayesian bootstrap)
</p>
</li></ul>
</td></tr>
<tr><td><code id="blm_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="blm_star_+3A_prior">prior</code></td>
<td>
<p>prior to use for the latent linear regression; currently implemented options
are &quot;gprior&quot;, &quot;horseshoe&quot;, and &quot;ridge&quot;. Not all modeling options and transformations are
available with the latter two priors.</p>
</td></tr>
<tr><td><code id="blm_star_+3A_use_mcmc">use_MCMC</code></td>
<td>
<p>= TRUE,</p>
</td></tr>
<tr><td><code id="blm_star_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save (or MC samples to draw if use_MCMC=FALSE)</p>
</td></tr>
<tr><td><code id="blm_star_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="blm_star_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
<tr><td><code id="blm_star_+3A_method_sigma">method_sigma</code></td>
<td>
<p>method to estimate the latent data standard deviation in exact sampler;
must be one of
</p>

<ul>
<li><p> &quot;mle&quot; use the MLE from the STAR EM algorithm
</p>
</li>
<li><p> &quot;mmle&quot; use the marginal MLE (Note: slower!)
</p>
</li></ul>
</td></tr>
<tr><td><code id="blm_star_+3A_approx_fz">approx_Fz</code></td>
<td>
<p>logical; in BNP transformation, apply a (fast and stable)
normal approximation for the marginal CDF of the latent data</p>
</td></tr>
<tr><td><code id="blm_star_+3A_approx_fy">approx_Fy</code></td>
<td>
<p>logical; in BNP transformation, approximate
the marginal CDF of <code>y</code> using the empirical CDF</p>
</td></tr>
<tr><td><code id="blm_star_+3A_psi">psi</code></td>
<td>
<p>prior variance (g-prior)</p>
</td></tr>
<tr><td><code id="blm_star_+3A_compute_marg">compute_marg</code></td>
<td>
<p>logical; if TRUE, compute and return the
marginal likelihood (only available when using exact sampler, i.e. use_MCMC=FALSE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation. Here, the continuous
latent data model is a linear regression.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt', as well as a version in which the Box-Cox parameter
is inferred within the MCMC sampler ('box-cox'). Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>. The distribution-based
transformations approximately preserve the mean and variance of the count data <code>y</code>
on the latent data scale, which lends interpretability to the model parameters.
Lastly, the transformation can be modeled using the Bayesian bootstrap ('bnp'),
which is a Bayesian nonparametric model and incorporates the uncertainty
about the transformation into posterior and predictive inference.
</p>
<p>The Monte Carlo sampler (<code>use_MCMC=FALSE</code>) produces direct, discrete, and joint draws
from the posterior distribution and the posterior predictive distribution
of the linear regression model with a g-prior.
</p>


<h3>Value</h3>

<p>a list with at least the following elements:
</p>

<ul>
<li> <p><code>coefficients</code>: the posterior mean of the regression coefficients
</p>
</li>
<li> <p><code>post.beta</code>: posterior draws of the regression coefficients
</p>
</li>
<li> <p><code>post.pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>post.log.like.point</code>: draws of the log-likelihood for each of the <code>n</code> observations
</p>
</li>
<li> <p><code>WAIC</code>: Widely-Applicable/Watanabe-Akaike Information Criterion
</p>
</li>
<li> <p><code>p_waic</code>: Effective number of parameters based on WAIC
</p>
</li></ul>

<p>If test points are passed in, then the list will also have <code>post.predtest</code>,
which contains draws from the posterior predictive distribution at test points.
</p>
<p>Other elements may be present depending on the choice of prior, transformation,
and sampling approach.
</p>


<h3>Note</h3>

<p>The 'bnp' transformation (without the <code>Fy</code> approximation) is
slower than the other transformations because of the way
the <code>TruncatedNormal</code> sampler must be updated as the lower and upper
limits change (due to the sampling of <code>g</code>). Thus, computational
improvements are likely available.
</p>

<hr>
<h2 id='blm_star_bnpgibbs'>Gibbs sampler for STAR linear regression with BNP transformation</h2><span id='topic+blm_star_bnpgibbs'></span>

<h3>Description</h3>

<p>Compute MCMC samples from the posterior and predictive
distributions of a STAR linear regression model with a g-prior
and BNP transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blm_star_bnpgibbs(
  y,
  X,
  X_test = X,
  y_max = Inf,
  psi = NULL,
  approx_Fz = FALSE,
  approx_Fy = FALSE,
  nsave = 1000,
  nburn = 1000,
  nskip = 0,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blm_star_bnpgibbs_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_x_test">X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors for test data;
default is the observed covariates <code>X</code></p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_psi">psi</code></td>
<td>
<p>prior variance (g-prior)</p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_approx_fz">approx_Fz</code></td>
<td>
<p>logical; in BNP transformation, apply a (fast and stable)
normal approximation for the marginal CDF of the latent data</p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_approx_fy">approx_Fy</code></td>
<td>
<p>logical; in BNP transformation, approximate
the marginal CDF of <code>y</code> using the empirical CDF</p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save</p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="blm_star_bnpgibbs_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation. Here, the continuous
latent data model is a linear regression.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt'. Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>. The distribution-based
transformations approximately preserve the mean and variance of the count data <code>y</code>
on the latent data scale, which lends interpretability to the model parameters.
Lastly, the transformation can be modeled using the Bayesian bootstrap ('bnp'),
which is a Bayesian nonparametric model and incorporates the uncertainty
about the transformation into posterior and predictive inference.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>coefficients</code> the posterior mean of the regression coefficients
</p>
</li>
<li> <p><code>post_beta</code>: <code>nsave x p</code> samples from the posterior distribution
of the regression coefficients
</p>
</li>
<li> <p><code>post_ytilde</code>: <code>nsave x n0</code> samples
from the posterior predictive distribution at test points <code>X_test</code>
</p>
</li>
<li> <p><code>post_g</code>: <code>nsave</code> posterior samples of the transformation
evaluated at the unique <code>y</code> values (only applies for 'bnp' transformations)
</p>
</li></ul>


<hr>
<h2 id='blm_star_exact'>Monte Carlo sampler for STAR linear regression with a g-prior</h2><span id='topic+blm_star_exact'></span>

<h3>Description</h3>

<p>Compute direct Monte Carlo samples from the posterior and predictive
distributions of a STAR linear regression model with a g-prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blm_star_exact(
  y,
  X,
  X_test = X,
  transformation = "np",
  y_max = Inf,
  psi = NULL,
  method_sigma = "mle",
  approx_Fz = FALSE,
  approx_Fy = FALSE,
  nsave = 5000,
  compute_marg = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blm_star_exact_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_x_test">X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors for test data</p>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;bnp&quot; (Bayesian nonparametric transformation using the Bayesian bootstrap)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li></ul>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_psi">psi</code></td>
<td>
<p>prior variance (g-prior)</p>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_method_sigma">method_sigma</code></td>
<td>
<p>method to estimate the latent data standard deviation; must be one of
</p>

<ul>
<li><p> &quot;mle&quot; use the MLE from the STAR EM algorithm
</p>
</li>
<li><p> &quot;mmle&quot; use the marginal MLE (Note: slower!)
</p>
</li></ul>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_approx_fz">approx_Fz</code></td>
<td>
<p>logical; in BNP transformation, apply a (fast and stable)
normal approximation for the marginal CDF of the latent data</p>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_approx_fy">approx_Fy</code></td>
<td>
<p>logical; in BNP transformation, approximate
the marginal CDF of <code>y</code> using the empirical CDF</p>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_nsave">nsave</code></td>
<td>
<p>number of Monte Carlo simulations</p>
</td></tr>
<tr><td><code id="blm_star_exact_+3A_compute_marg">compute_marg</code></td>
<td>
<p>logical; if TRUE, compute and return the
marginal likelihood</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation. Here, the continuous
latent data model is a linear regression.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt'. Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>. The distribution-based
transformations approximately preserve the mean and variance of the count data <code>y</code>
on the latent data scale, which lends interpretability to the model parameters.
Lastly, the transformation can be modeled using the Bayesian bootstrap ('bnp'),
which is a Bayesian nonparametric model and incorporates the uncertainty
about the transformation into posterior and predictive inference.
</p>
<p>The Monte Carlo sampler produces direct, discrete, and joint draws
from the posterior distribution and the posterior predictive distribution
of the linear regression model with a g-prior.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>coefficients</code> the posterior mean of the regression coefficients
</p>
</li>
<li> <p><code>post.beta</code>: <code>nsave x p</code> samples from the posterior distribution
of the regression coefficients
</p>
</li>
<li> <p><code>post.pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>post.pred.test</code>: <code>nsave x n0</code> samples
from the posterior predictive distribution at test points <code>X_test</code>
(if given, otherwise NULL)
</p>
</li>
<li> <p><code>sigma</code>: The estimated latent data standard deviation
</p>
</li>
<li> <p><code>post.g</code>: <code>nsave</code> posterior samples of the transformation
evaluated at the unique <code>y</code> values (only applies for 'bnp' transformations)
</p>
</li>
<li> <p><code>marg.like</code>: the marginal likelihood (if requested; otherwise NULL)
</p>
</li></ul>



<h3>Note</h3>

<p>The 'bnp' transformation (without the <code>Fy</code> approximation) is
slower than the other transformations because of the way
the <code>TruncatedNormal</code> sampler must be updated as the lower and upper
limits change (due to the sampling of <code>g</code>). Thus, computational
improvements are likely available.
</p>

<hr>
<h2 id='BrentMethod'>Brent's method for optimization</h2><span id='topic+BrentMethod'></span>

<h3>Description</h3>

<p>Implementation for Brent's algorithm for minimizing a univariate function over an interval.
The code is based on a function in the <code>stsm</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BrentMethod(a = 0, b, fcn, tol = .Machine$double.eps^0.25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BrentMethod_+3A_a">a</code></td>
<td>
<p>lower limit for search</p>
</td></tr>
<tr><td><code id="BrentMethod_+3A_b">b</code></td>
<td>
<p>upper limit for search</p>
</td></tr>
<tr><td><code id="BrentMethod_+3A_fcn">fcn</code></td>
<td>
<p>function to minimize</p>
</td></tr>
<tr><td><code id="BrentMethod_+3A_tol">tol</code></td>
<td>
<p>tolerance level for convergence of the optimization procedure</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of containing the following elements:
</p>

<ul>
<li> <p><code>fx</code> the minimum value of the input function
</p>
</li>
<li> <p><code>x</code> the argument that minimizes the function
</p>
</li>
<li> <p><code>iter</code> number of iterations to converge
</p>
</li>
<li> <p><code>vx</code> a vector that stores the arguments until convergence
</p>
</li></ul>


<hr>
<h2 id='computeTimeRemaining'>Estimate the remaining time in the MCMC based on previous samples</h2><span id='topic+computeTimeRemaining'></span>

<h3>Description</h3>

<p>Estimate the remaining time in the MCMC based on previous samples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeTimeRemaining(nsi, timer0, nsims, nrep = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computeTimeRemaining_+3A_nsi">nsi</code></td>
<td>
<p>Current iteration</p>
</td></tr>
<tr><td><code id="computeTimeRemaining_+3A_timer0">timer0</code></td>
<td>
<p>Initial timer value, returned from <code>proc.time()[3]</code></p>
</td></tr>
<tr><td><code id="computeTimeRemaining_+3A_nsims">nsims</code></td>
<td>
<p>Total number of simulations</p>
</td></tr>
<tr><td><code id="computeTimeRemaining_+3A_nrep">nrep</code></td>
<td>
<p>Print the estimated time remaining every <code>nrep</code> iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Table of summary statistics using the function <code>summary</code>
</p>

<hr>
<h2 id='confint.lmstar'>Compute asymptotic confidence intervals for STAR linear regression</h2><span id='topic+confint.lmstar'></span>

<h3>Description</h3>

<p>For a linear regression model within the STAR framework,
compute (asymptotic) confidence intervals for a regression coefficient of interest.
Confidence intervals are computed by inverting the likelihood ratio test and
profiling the log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lmstar'
confint(object, parm, level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.lmstar_+3A_object">object</code></td>
<td>
<p>Object of class &quot;lmstar&quot; as output by <code><a href="#topic+lm_star">lm_star</a></code></p>
</td></tr>
<tr><td><code id="confint.lmstar_+3A_parm">parm</code></td>
<td>
<p>a specification of which parameters are to be given confidence intervals,
either a vector of numbers or a vector of names. If missing, all parameters are considered.</p>
</td></tr>
<tr><td><code id="confint.lmstar_+3A_level">level</code></td>
<td>
<p>confidence level; default is 0.95</p>
</td></tr>
<tr><td><code id="confint.lmstar_+3A_...">...</code></td>
<td>
<p>Ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix (or vector) with columns giving lower and upper confidence limits for each parameter.
These will be labelled as (1-level)/2 and 1 - (1-level)/2 in 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate data with count-valued response y:
sim_dat = simulate_nb_lm(n = 100, p = 2)
y = sim_dat$y; X = sim_dat$X

#Select a transformation:
transformation = 'np'

#Estimate model
fit = lm_star(y~X, transformation=transformation)

#Confidence interval for all parameters
confint(fit)

</code></pre>

<hr>
<h2 id='credBands'>Compute Simultaneous Credible Bands</h2><span id='topic+credBands'></span>

<h3>Description</h3>

<p>Compute (1-alpha)% credible BANDS for a function based on MCMC samples using Crainiceanu et al. (2007)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>credBands(sampFuns, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="credBands_+3A_sampfuns">sampFuns</code></td>
<td>
<p><code>Nsims x m</code> matrix of <code>Nsims</code> MCMC samples and <code>m</code> points along the curve</p>
</td></tr>
<tr><td><code id="credBands_+3A_alpha">alpha</code></td>
<td>
<p>confidence level</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>m x 2</code> matrix of credible bands; the first column is the lower band, the second is the upper band
</p>


<h3>Note</h3>

<p>The input needs not be curves: the simultaneous credible &quot;bands&quot; may be computed
for vectors. The resulting credible intervals will provide joint coverage at the (1-alpha)
level across all components of the vector.
</p>

<hr>
<h2 id='ergMean'>Compute the ergodic (running) mean.</h2><span id='topic+ergMean'></span>

<h3>Description</h3>

<p>Compute the ergodic (running) mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ergMean(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ergMean_+3A_x">x</code></td>
<td>
<p>vector for which to compute the running mean</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector <code>y</code> with each element defined by <code>y[i] = mean(x[1:i])</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compare:
ergMean(1:10)
mean(1:10)

# Running mean for iid N(5, 1) samples:
x = rnorm(n = 10^4, mean = 5, sd = 1)
plot(ergMean(x))
abline(h=5)

</code></pre>

<hr>
<h2 id='expectation_gRcpp'>Estimate the mean for a STAR process</h2><span id='topic+expectation_gRcpp'></span>

<h3>Description</h3>

<p>Estimate the conditional expectation for a STAR process
under a generic link function g.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation_gRcpp(g_a_j, g_a_jp1, mu, sigma, Jmax)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expectation_gRcpp_+3A_g_a_j">g_a_j</code></td>
<td>
<p><code>Jmax x 1</code> vector of g(a(j))</p>
</td></tr>
<tr><td><code id="expectation_gRcpp_+3A_g_a_jp1">g_a_jp1</code></td>
<td>
<p><code>Jmax x 1</code> vector of g(a(j + 1))</p>
</td></tr>
<tr><td><code id="expectation_gRcpp_+3A_mu">mu</code></td>
<td>
<p><code>m x 1</code> vector of conditional expectations</p>
</td></tr>
<tr><td><code id="expectation_gRcpp_+3A_sigma">sigma</code></td>
<td>
<p><code>m x 1</code> vector of conditional standard deviations</p>
</td></tr>
<tr><td><code id="expectation_gRcpp_+3A_jmax">Jmax</code></td>
<td>
<p><code>m x 1</code> vector of maximum integer values to consider</p>
</td></tr>
</table>


<h3>Value</h3>

<p>y_hat <code>m x 1</code> vector of conditional expectations
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='expectation_identity'>Estimate the mean for a STAR process</h2><span id='topic+expectation_identity'></span>

<h3>Description</h3>

<p>Estimate the conditional expectation for a STAR process
under the identity link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation_identity(a, Jmax, Mu, sigma_t, Offset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expectation_identity_+3A_a">a</code></td>
<td>
<p><code>Jmaxmax</code>-dimensional vector of STAR integers a_j</p>
</td></tr>
<tr><td><code id="expectation_identity_+3A_jmax">Jmax</code></td>
<td>
<p><code>T x m</code> matrix of maximum integer values to consider</p>
</td></tr>
<tr><td><code id="expectation_identity_+3A_mu">Mu</code></td>
<td>
<p><code>T x m</code> matrix of latent means</p>
</td></tr>
<tr><td><code id="expectation_identity_+3A_sigma_t">sigma_t</code></td>
<td>
<p><code>T</code>-dimensional vector of time-dependent latent error sd's</p>
</td></tr>
<tr><td><code id="expectation_identity_+3A_offset">Offset</code></td>
<td>
<p><code>T x m</code> matrix of offsets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Zhat <code>T x m</code> matrix of conditional expectations
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='expectation_log'>Estimate the mean for a STAR process</h2><span id='topic+expectation_log'></span>

<h3>Description</h3>

<p>Estimate the conditional expectation for a STAR process
under the log link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation_log(a, Jmax, Mu, sigma_t, Offset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expectation_log_+3A_a">a</code></td>
<td>
<p><code>Jmaxmax</code>-dimensional vector of STAR integers a_j</p>
</td></tr>
<tr><td><code id="expectation_log_+3A_jmax">Jmax</code></td>
<td>
<p><code>T x m</code> matrix of maximum integer values to consider</p>
</td></tr>
<tr><td><code id="expectation_log_+3A_mu">Mu</code></td>
<td>
<p><code>T x m</code> matrix of latent means</p>
</td></tr>
<tr><td><code id="expectation_log_+3A_sigma_t">sigma_t</code></td>
<td>
<p><code>T</code>-dimensional vector of time-dependent latent error sd's</p>
</td></tr>
<tr><td><code id="expectation_log_+3A_offset">Offset</code></td>
<td>
<p><code>T x m</code> matrix of offsets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Zhat <code>T x m</code> matrix of conditional expectations
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='expectation_sqrt'>Estimate the mean for a STAR process</h2><span id='topic+expectation_sqrt'></span>

<h3>Description</h3>

<p>Estimate the conditional expectation for a STAR process
under the square root link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation_sqrt(a, Jmax, Mu, sigma_t, Offset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expectation_sqrt_+3A_a">a</code></td>
<td>
<p><code>Jmaxmax</code>-dimensional vector of STAR integers a_j</p>
</td></tr>
<tr><td><code id="expectation_sqrt_+3A_jmax">Jmax</code></td>
<td>
<p><code>T x m</code> matrix of maximum integer values to consider</p>
</td></tr>
<tr><td><code id="expectation_sqrt_+3A_mu">Mu</code></td>
<td>
<p><code>T x m</code> matrix of latent means</p>
</td></tr>
<tr><td><code id="expectation_sqrt_+3A_sigma_t">sigma_t</code></td>
<td>
<p><code>T</code>-dimensional vector of time-dependent latent error sd's</p>
</td></tr>
<tr><td><code id="expectation_sqrt_+3A_offset">Offset</code></td>
<td>
<p><code>T x m</code> matrix of offsets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Zhat <code>T x m</code> matrix of conditional expectations
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='expectation2_gRcpp'>Compute E(Y^2) for a STAR process</h2><span id='topic+expectation2_gRcpp'></span>

<h3>Description</h3>

<p>Compute the conditional expectation of Y^2 for a STAR process Y
under a generic link function g.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation2_gRcpp(g_a_j, g_a_jp1, mu, sigma, Jmax)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expectation2_gRcpp_+3A_g_a_j">g_a_j</code></td>
<td>
<p><code>Jmax x 1</code> vector of g(a(j))</p>
</td></tr>
<tr><td><code id="expectation2_gRcpp_+3A_g_a_jp1">g_a_jp1</code></td>
<td>
<p><code>Jmax x 1</code> vector of g(a(j + 1))</p>
</td></tr>
<tr><td><code id="expectation2_gRcpp_+3A_mu">mu</code></td>
<td>
<p><code>m x 1</code> vector of conditional expectations</p>
</td></tr>
<tr><td><code id="expectation2_gRcpp_+3A_sigma">sigma</code></td>
<td>
<p><code>m x 1</code> vector of conditional standard deviations</p>
</td></tr>
<tr><td><code id="expectation2_gRcpp_+3A_jmax">Jmax</code></td>
<td>
<p><code>m x 1</code> vector of maximum integer values to consider</p>
</td></tr>
</table>


<h3>Value</h3>

<p>y2_hat <code>m x 1</code> vector of conditional expectations
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='g_bc'>Box-Cox transformation</h2><span id='topic+g_bc'></span>

<h3>Description</h3>

<p>Evaluate the Box-Cox transformation, which is a scaled power transformation
to preserve continuity in the index <code>lambda</code> at zero. Negative values are
permitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g_bc(t, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g_bc_+3A_t">t</code></td>
<td>
<p>argument(s) at which to evaluate the function</p>
</td></tr>
<tr><td><code id="g_bc_+3A_lambda">lambda</code></td>
<td>
<p>Box-Cox parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation(s) of the Box-Cox function at the given input(s) <code>t</code>.
</p>


<h3>Note</h3>

<p>Special cases include
the identity transformation (<code>lambda = 1</code>),
the square-root transformation (<code>lambda = 1/2</code>),
and the log transformation (<code>lambda = 0</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Log-transformation:
g_bc(1:5, lambda = 0); log(1:5)

# Square-root transformation: note the shift and scaling
g_bc(1:5, lambda = 1/2); sqrt(1:5)

</code></pre>

<hr>
<h2 id='g_bnp'>Bayesian bootstrap-based transformation</h2><span id='topic+g_bnp'></span>

<h3>Description</h3>

<p>Compute one posterior draw from the smoothed transformation
implied by (separate) Bayesian bootstrap models for the CDFs
of <code>y</code> and <code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g_bnp(
  y,
  xtSigmax = rep(0, length(y)),
  zgrid = NULL,
  sigma_epsilon = 1,
  approx_Fz = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g_bnp_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="g_bnp_+3A_xtsigmax">xtSigmax</code></td>
<td>
<p><code>n x 1</code> vector of <code>t(X_i) Sigma_theta X_i</code>,
where <code>Sigma_theta</code> is the prior variance</p>
</td></tr>
<tr><td><code id="g_bnp_+3A_zgrid">zgrid</code></td>
<td>
<p>optional vector of grid points for evaluating the CDF
of z (<code>Fz</code>)</p>
</td></tr>
<tr><td><code id="g_bnp_+3A_sigma_epsilon">sigma_epsilon</code></td>
<td>
<p>latent standard deviation</p>
</td></tr>
<tr><td><code id="g_bnp_+3A_approx_fz">approx_Fz</code></td>
<td>
<p>logical; if TRUE, use a normal approximation for <code>Fz</code>,
the marginal CDF of the latent z, which is faster and more stable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A smooth monotone function which can be used for evaluations of the transformation
at each posterior draw.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Sample some data:
y = rpois(n = 200, lambda = 5)
# Compute 200 draws of g on a grid:
t = seq(0, max(y), length.out = 100) # grid
g_post = t(sapply(1:500, function(s) g_bnp(y, approx_Fz = TRUE)(t)))
# Plot together:
plot(t, t, ylim = range(g_post), type='n', ylab = 'g(t)',  main = 'Bayesian bootstrap posterior: g')
apply(g_post, 1, function(g) lines(t, g, col='gray'))
# And the posterior mean of g:
lines(t, colMeans(g_post), lwd=3)

</code></pre>

<hr>
<h2 id='g_cdf'>Cumulative distribution function (CDF)-based transformation</h2><span id='topic+g_cdf'></span>

<h3>Description</h3>

<p>Compute a CDF-based transformation using the observed count data.
The CDF can be estimated nonparametrically or parametrically based on the
Poisson or Negative Binomial distributions. In the parametric case,
the parameters are determined based on the moments of <code>y</code>.
Note that this is a fixed quantity and does not come with uncertainty quantification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g_cdf(y, distribution = "np")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g_cdf_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="g_cdf_+3A_distribution">distribution</code></td>
<td>
<p>the distribution used for the CDF; must be one of
</p>

<ul>
<li><p> &quot;np&quot; (empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (moment-matched marginal Negative Binomial CDF)
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A smooth monotone function which can be used for evaluations of the transformation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Sample some data:
y = rpois(n = 500, lambda = 5)

# Empirical CDF version:
g_np = g_cdf(y, distribution = 'np')

# Poisson version:
g_pois = g_cdf(y, distribution = 'pois')

# Negative binomial version:
g_negbin = g_cdf(y, distribution = 'neg-bin')

# Plot together:
t = 1:max(y) # grid
plot(t, g_np(t), type='l')
lines(t, g_pois(t), lty = 2)
lines(t, g_negbin(t), lty = 3)

</code></pre>

<hr>
<h2 id='g_inv_approx'>Approximate inverse transformation</h2><span id='topic+g_inv_approx'></span>

<h3>Description</h3>

<p>Compute the inverse function of a transformation <code>g</code> based on a grid search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g_inv_approx(g, t_grid)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g_inv_approx_+3A_g">g</code></td>
<td>
<p>the transformation function</p>
</td></tr>
<tr><td><code id="g_inv_approx_+3A_t_grid">t_grid</code></td>
<td>
<p>grid of arguments at which to evaluate the transformation function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function which can be used for evaluations of the
(approximate) inverse transformation function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Sample some data:
y = rpois(n = 500, lambda = 5)

# Empirical CDF transformation:
g_np = g_cdf(y, distribution = 'np')

# Grid for approximation:
t_grid = seq(1, max(y), length.out = 100)

# Approximate inverse:
g_inv = g_inv_approx(g = g_np, t_grid = t_grid)

# Check the approximation:
plot(t_grid, g_inv(g_np(t_grid)), type='p')
lines(t_grid, t_grid)

</code></pre>

<hr>
<h2 id='g_inv_bc'>Inverse Box-Cox transformation</h2><span id='topic+g_inv_bc'></span>

<h3>Description</h3>

<p>Evaluate the inverse Box-Cox transformation. Negative values are permitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g_inv_bc(s, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g_inv_bc_+3A_s">s</code></td>
<td>
<p>argument(s) at which to evaluate the function</p>
</td></tr>
<tr><td><code id="g_inv_bc_+3A_lambda">lambda</code></td>
<td>
<p>Box-Cox parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation(s) of the inverse Box-Cox function at the given input(s) <code>s</code>.
</p>


<h3>Note</h3>

<p>Special cases include
the identity transformation (<code>lambda = 1</code>),
the square-root transformation (<code>lambda = 1/2</code>),
and the log transformation (<code>lambda = 0</code>).
</p>
<p>#' @examples
# (Inverse) log-transformation:
g_inv_bc(1:5, lambda = 0); exp(1:5)
</p>
<p># (Inverse) square-root transformation: note the shift and scaling
g_inv_bc(1:5, lambda = 1/2); (1:5)^2
</p>

<hr>
<h2 id='gbm_star'>Fitting STAR Gradient Boosting Machines via EM algorithm</h2><span id='topic+gbm_star'></span>

<h3>Description</h3>

<p>Compute the MLEs and log-likelihood for the Gradient Boosting Machines (GBM) STAR model.
The STAR model requires a *transformation* and an *estimation function* for the conditional mean
given observed data. The transformation can be known (e.g., log or sqrt) or unknown
(Box-Cox or estimated nonparametrically) for greater flexibility.
The estimator in this case is a GBM.
Standard function calls including <code><a href="stats.html#topic+fitted">fitted</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code> apply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbm_star(
  y,
  X,
  X.test = NULL,
  transformation = "np",
  y_max = Inf,
  sd_init = 10,
  tol = 10^-10,
  max_iters = 1000,
  n.trees = 100,
  interaction.depth = 1,
  shrinkage = 0.1,
  bag.fraction = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gbm_star_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_x.test">X.test</code></td>
<td>
<p><code>m x p</code> matrix of out-of-sample predictors</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li><p> &quot;box-cox&quot; (box-cox transformation with learned parameter)
</p>
</li></ul>
</td></tr>
<tr><td><code id="gbm_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="gbm_star_+3A_sd_init">sd_init</code></td>
<td>
<p>add random noise for EM algorithm initialization scaled by <code>sd_init</code>
times the Gaussian MLE standard deviation; default is 10</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_tol">tol</code></td>
<td>
<p>tolerance for stopping the EM algorithm; default is 10^-10;</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_max_iters">max_iters</code></td>
<td>
<p>maximum number of EM iterations before stopping; default is 1000</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_n.trees">n.trees</code></td>
<td>
<p>Integer specifying the total number of trees to fit.
This is equivalent to the number of iterations and the number of basis functions in the additive expansion.
Default is 100.</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>Integer specifying the maximum depth of each tree
(i.e., the highest level of variable interactions allowed).
A value of 1 implies an additive model, a value of 2 implies a model with up to 2-way interactions, etc.
Default is 1.</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_shrinkage">shrinkage</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the expansion.
Also known as the learning rate or step-size reduction; 0.001 to 0.1 usually work, but a smaller learning rate typically requires more trees.
Default is 0.1.</p>
</td></tr>
<tr><td><code id="gbm_star_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly selected to propose the next tree in the expansion.
This introduces randomnesses into the model fit. If bag.fraction &lt; 1 then running the same model twice will result in similar but different fits.
Default is 1 (for a deterministic prediction).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation. The Gaussian model in
this case is a GBM.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>fitted.values</code>: the fitted values at the MLEs (training)
</p>
</li>
<li> <p><code>fitted.values.test</code>: the fitted values at the MLEs (testing)
</p>
</li>
<li> <p><code>g.hat</code> a function containing the (known or estimated) transformation
</p>
</li>
<li> <p><code>sigma.hat</code> the MLE of the standard deviation
</p>
</li>
<li> <p><code>mu.hat</code> the MLE of the conditional mean (on the transformed scale)
</p>
</li>
<li> <p><code>z.hat</code> the estimated latent data (on the transformed scale) at the MLEs
</p>
</li>
<li> <p><code>residuals</code> the Dunn-Smyth residuals (randomized)
</p>
</li>
<li> <p><code>residuals_rep</code> the Dunn-Smyth residuals (randomized) for 10 replicates
</p>
</li>
<li> <p><code>logLik</code> the log-likelihood at the MLEs
</p>
</li>
<li> <p><code>logLik0</code> the log-likelihood at the MLEs for the *unrounded* initialization
</p>
</li>
<li> <p><code>lambda</code> the Box-Cox nonlinear parameter
</p>
</li>
<li> <p><code>gbmObj</code>: the object returned by gbm() at the MLEs
</p>
</li>
<li><p> and other parameters that
(1) track the parameters across EM iterations and
(2) record the model specifications
</p>
</li></ul>



<h3>Note</h3>

<p>Infinite latent data values may occur when the transformed
Gaussian model is highly inadequate. In that case, the function returns
the *indices* of the data points with infinite latent values, which are
significant outliers under the model. Deletion of these indices and
re-running the model is one option, but care must be taken to ensure
that (i) it is appropriate to treat these observations as outliers and
(ii) the model is adequate for the remaining data points.
</p>


<h3>References</h3>

<p>Kowal, D. R., &amp; Wu, B. (2021).
Semiparametric count data regression for selfreported mental health.
<em>Biometrics</em>. <a href="https://doi.org/10.1111/biom.13617">doi:10.1111/biom.13617</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data with count-valued response y:
sim_dat = simulate_nb_friedman(n = 100, p = 10)
y = sim_dat$y; X = sim_dat$X

# EM algorithm for STAR (using the log-link)
fit_em = gbm_star(y = y, X = X,
                 transformation = 'log')

# Evaluate convergence:
plot(fit_em$logLik_all, type='l', main = 'GBM-STAR-log', xlab = 'Iteration', ylab = 'log-lik')

# Fitted values:
y_hat = fitted(fit_em)
plot(y_hat, y);

# Residuals:
plot(residuals(fit_em))
qqnorm(residuals(fit_em)); qqline(residuals(fit_em))

# Log-likelihood at MLEs:
fit_em$logLik

</code></pre>

<hr>
<h2 id='genEM_star'>Generalized EM estimation for STAR</h2><span id='topic+genEM_star'></span>

<h3>Description</h3>

<p>Compute MLEs and log-likelihood for a generalized STAR model. The STAR model requires
a *transformation* and an *estimation function* for the conditional mean
given observed data. The transformation can be known (e.g., log or sqrt) or unknown
(Box-Cox or estimated nonparametrically) for greater flexibility.
The estimator can be any least squares estimator, including nonlinear models.
Standard function calls including
<code>coefficients()</code>, <code>fitted()</code>, and <code>residuals()</code> apply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genEM_star(
  y,
  estimator,
  transformation = "np",
  y_max = Inf,
  sd_init = 10,
  tol = 10^-10,
  max_iters = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genEM_star_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="genEM_star_+3A_estimator">estimator</code></td>
<td>
<p>a function that inputs data <code>y</code> and outputs a list with two elements:
</p>

<ol>
<li><p> The fitted values <code>fitted.values</code>
</p>
</li>
<li><p> The parameter estimates <code>coefficients</code>
</p>
</li></ol>
</td></tr>
<tr><td><code id="genEM_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li><p> &quot;box-cox&quot; (box-cox transformation with learned parameter)
</p>
</li></ul>
</td></tr>
<tr><td><code id="genEM_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="genEM_star_+3A_sd_init">sd_init</code></td>
<td>
<p>add random noise for EM algorithm initialization scaled by <code>sd_init</code>
times the Gaussian MLE standard deviation; default is 10</p>
</td></tr>
<tr><td><code id="genEM_star_+3A_tol">tol</code></td>
<td>
<p>tolerance for stopping the EM algorithm; default is 10^-10;</p>
</td></tr>
<tr><td><code id="genEM_star_+3A_max_iters">max_iters</code></td>
<td>
<p>maximum number of EM iterations before stopping; default is 1000</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation.
</p>
<p>The expectation-maximization (EM) algorithm is used to produce
maximum likelihood estimators (MLEs) for the parameters defined in the
<code>estimator</code> function, such as linear regression coefficients,
which define the Gaussian model for the continuous latent data.
Fitted values (point predictions), residuals, and log-likelihood values
are also available. Inference for the estimators proceeds via classical maximum likelihood.
Initialization of the EM algorithm can be randomized to monitor convergence.
However, the log-likelihood is concave for all transformations (except 'box-cox'),
so global convergence is guaranteed.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt', as well as a version in which the Box-Cox parameter
is estimated within the EM algorithm ('box-cox'). Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>coefficients</code> the MLEs of the coefficients
</p>
</li>
<li> <p><code>fitted.values</code> the fitted values at the MLEs
</p>
</li>
<li> <p><code>g.hat</code> a function containing the (known or estimated) transformation
</p>
</li>
<li> <p><code>sigma.hat</code> the MLE of the standard deviation
</p>
</li>
<li> <p><code>mu.hat</code> the MLE of the conditional mean (on the transformed scale)
</p>
</li>
<li> <p><code>z.hat</code> the estimated latent data (on the transformed scale) at the MLEs
</p>
</li>
<li> <p><code>residuals</code> the Dunn-Smyth residuals (randomized)
</p>
</li>
<li> <p><code>residuals_rep</code> the Dunn-Smyth residuals (randomized) for 10 replicates
</p>
</li>
<li> <p><code>logLik</code> the log-likelihood at the MLEs
</p>
</li>
<li> <p><code>logLik0</code> the log-likelihood at the MLEs for the *unrounded* initialization
</p>
</li>
<li> <p><code>lambda</code> the Box-Cox nonlinear parameter
</p>
</li>
<li><p> and other parameters that
(1) track the parameters across EM iterations and
(2) record the model specifications
</p>
</li></ul>



<h3>Note</h3>

<p>Infinite latent data values may occur when the transformed
Gaussian model is highly inadequate. In that case, the function returns
the *indices* of the data points with infinite latent values, which are
significant outliers under the model. Deletion of these indices and
re-running the model is one option, but care must be taken to ensure
that (i) it is appropriate to treat these observations as outliers and
(ii) the model is adequate for the remaining data points.
</p>


<h3>References</h3>

<p>Kowal, D. R., &amp; Wu, B. (2021).
Semiparametric count data regression for selfreported mental health.
<em>Biometrics</em>. <a href="https://doi.org/10.1111/biom.13617">doi:10.1111/biom.13617</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data with count-valued response y:
sim_dat = simulate_nb_friedman(n = 100, p = 5)
y = sim_dat$y; X = sim_dat$X

# Select a transformation:
transformation = 'np'

# Example using GAM as underlying estimator (for illustration purposes only)
if(require("mgcv")){
  fit_em = genEM_star(y = y,
                      estimator = function(y) gam(y ~ s(X1)+s(X2),
                      data=data.frame(y,X)),
                      transformation = transformation)
}

# Fitted coefficients:
coef(fit_em)

# Fitted values:
y_hat = fitted(fit_em)
plot(y_hat, y);

# Log-likelihood at MLEs:
fit_em$logLik

</code></pre>

<hr>
<h2 id='genMCMC_star'>Generalized MCMC Algorithm for STAR</h2><span id='topic+genMCMC_star'></span>

<h3>Description</h3>

<p>Run the MCMC algorithm for STAR given
</p>

<ol>
<li><p> a function to initialize model parameters; and
</p>
</li>
<li><p> a function to sample (i.e., update) model parameters.
</p>
</li></ol>

<p>The transformation can be known (e.g., log or sqrt) or unknown
(Box-Cox or estimated nonparametrically) for greater flexibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genMCMC_star(
  y,
  sample_params,
  init_params,
  transformation = "np",
  y_max = Inf,
  nsave = 5000,
  nburn = 5000,
  nskip = 0,
  save_y_hat = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genMCMC_star_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_sample_params">sample_params</code></td>
<td>
<p>a function that inputs data <code>y</code> and a named list <code>params</code> containing
</p>

<ol>
<li> <p><code>mu</code>: the <code>n x 1</code> vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>

<p>and outputs an updated list <code>params</code> of samples from the full conditional posterior
distribution of <code>coefficients</code> and <code>sigma</code> (and updates <code>mu</code>)</p>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_init_params">init_params</code></td>
<td>
<p>an initializing function that inputs data <code>y</code>
and initializes the named list <code>params</code> of <code>mu</code>, <code>sigma</code>, and <code>coefficients</code></p>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li><p> &quot;box-cox&quot; (box-cox transformation with learned parameter)
</p>
</li></ul>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save</p>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_save_y_hat">save_y_hat</code></td>
<td>
<p>logical; if TRUE, compute and save the posterior draws of
the expected counts, E(y), which may be slow to compute</p>
</td></tr>
<tr><td><code id="genMCMC_star_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, print time remaining</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation.
</p>
<p>Posterior and predictive inference is obtained via a Gibbs sampler
that combines (i) a latent data augmentation step (like in probit regression)
and (ii) an existing sampler for a continuous data model.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt', as well as a version in which the Box-Cox parameter
is inferred within the MCMC sampler ('box-cox'). Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>.
</p>


<h3>Value</h3>

<p>a list with at least the following elements:
</p>

<ul>
<li> <p><code>post.pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>post.sigma</code>: draws from the posterior distribution of <code>sigma</code>
</p>
</li>
<li> <p><code>post.log.like.point</code>: draws of the log-likelihood for each of the <code>n</code> observations
</p>
</li>
<li> <p><code>WAIC</code>: Widely-Applicable/Watanabe-Akaike Information Criterion
</p>
</li>
<li> <p><code>p_waic</code>: Effective number of parameters based on WAIC
</p>
</li>
<li> <p><code>post.lambda</code>: draws from the posterior distribution of <code>lambda</code>
(NULL unless <code>transformation='box-cox'</code>)
</p>
</li>
<li> <p><code>fitted.values</code>: the posterior mean of the conditional expectation of the counts <code>y</code>
(<code>NULL</code> if <code>save_y_hat=FALSE</code>)
</p>
</li>
<li> <p><code>post.fitted.values</code>: posterior draws of the conditional mean of the counts <code>y</code>
(<code>NULL</code> if <code>save_y_hat=FALSE</code>)
</p>
</li></ul>

<p>If the coefficients list from <code>init_params</code> and <code>sample_params</code> contains a named element <code>beta</code>,
e.g. for linear regression, then the function output contains
</p>

<ul>
<li> <p><code>coefficients</code>: the posterior mean of the beta coefficients
</p>
</li>
<li> <p><code>post.beta</code>: draws from the posterior distribution of <code>beta</code>
</p>
</li>
<li> <p><code>post.othercoefs</code>: draws from the posterior distribution of any other sampled coefficients, e.g. variance terms
</p>
</li></ul>

<p>If no <code>beta</code> exists in the parameter coefficients, then the output list just contains
</p>

<ul>
<li> <p><code>coefficients</code>: the posterior mean of all coefficients
</p>
</li>
<li> <p><code>post.beta</code>: draws from the posterior distribution of all coefficients
</p>
</li></ul>

<p>Additionally, if <code>init_params</code> and <code>sample_params</code> have output <code>mu_test</code>, then the sampler will output
<code>post.predtest</code>, which contains draws from the posterior predictive distribution at test points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data with count-valued response y:
sim_dat = simulate_nb_lm(n = 100, p = 5)
y = sim_dat$y; X = sim_dat$X

# STAR: log-transformation:
fit_log = genMCMC_star(y = y,
                         sample_params = function(y, params) sample_lm_gprior(y, X, params),
                         init_params = function(y) init_lm_gprior(y, X),
                         transformation = 'log')
# Posterior mean of each coefficient:
coef(fit_log)

# WAIC for STAR-log:
fit_log$WAIC

# MCMC diagnostics:
plot(as.ts(fit_log$post.beta[,1:3]))

# Posterior predictive check:
hist(apply(fit_log$post.pred, 1,
           function(x) mean(x==0)), main = 'Proportion of Zeros', xlab='');
abline(v = mean(y==0), lwd=4, col ='blue')

</code></pre>

<hr>
<h2 id='genMCMC_star_ispline'>MCMC sampler for STAR with a monotone spline model
for the transformation</h2><span id='topic+genMCMC_star_ispline'></span>

<h3>Description</h3>

<p>Run the MCMC algorithm for STAR given
</p>

<ol>
<li><p> a function to initialize model parameters; and
</p>
</li>
<li><p> a function to sample (i.e., update) model parameters.
</p>
</li></ol>

<p>The transformation is modeled as an unknown, monotone function
using I-splines. The Robust Adaptive Metropolis (RAM) sampler
is used for drawing the parameter of the transformation function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genMCMC_star_ispline(
  y,
  sample_params,
  init_params,
  lambda_prior = 1/2,
  y_max = Inf,
  nsave = 5000,
  nburn = 5000,
  nskip = 0,
  save_y_hat = FALSE,
  target_acc_rate = 0.3,
  adapt_rate = 0.75,
  stop_adapt_perc = 0.5,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genMCMC_star_ispline_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_sample_params">sample_params</code></td>
<td>
<p>a function that inputs data <code>y</code> and a named list
<code>params</code> containing at least
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>

<p>and optionally a fourth element <code>mu_test</code> which contains the vector of conditional means
at test points. The output is an updated list <code>params</code> of samples from the full conditional posterior
distribution of <code>coefficients</code> and <code>sigma</code> (along with updates of <code>mu</code> and <code>mu_test</code> if applicable)</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_init_params">init_params</code></td>
<td>
<p>an initializing function that inputs data <code>y</code>
and initializes the named list <code>params</code> of <code>mu</code>, <code>sigma</code>, <code>coefficients</code> and <code>mu_test</code> (if desired)</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_lambda_prior">lambda_prior</code></td>
<td>
<p>the prior mean for the transformation g() is the Box-Cox function with
parameter <code>lambda_prior</code></p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_save_y_hat">save_y_hat</code></td>
<td>
<p>logical; if TRUE, compute and save the posterior draws of
the expected counts, E(y), which may be slow to compute</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_target_acc_rate">target_acc_rate</code></td>
<td>
<p>target acceptance rate (between zero and one)</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_adapt_rate">adapt_rate</code></td>
<td>
<p>rate of adaptation in RAM sampler (between zero and one)</p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_stop_adapt_perc">stop_adapt_perc</code></td>
<td>
<p>stop adapting at the proposal covariance at <code>stop_adapt_perc*nburn</code></p>
</td></tr>
<tr><td><code id="genMCMC_star_ispline_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, print time remaining</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the coefficients list from <code>init_params</code> and <code>sample_params</code> contains a named element <code>beta</code>,
e.g. for linear regression, then the function output contains
</p>

<ul>
<li> <p><code>coefficients</code>: the posterior mean of the beta coefficients
</p>
</li>
<li> <p><code>post.beta</code>: draws from the posterior distribution of <code>beta</code>
</p>
</li>
<li> <p><code>post.othercoefs</code>: draws from the posterior distribution of any other sampled coefficients, e.g. variance terms
</p>
</li></ul>

<p>If no <code>beta</code> exists in the parameter coefficients, then the output list just contains
</p>

<ul>
<li> <p><code>coefficients</code>: the posterior mean of all coefficients
</p>
</li>
<li> <p><code>post.beta</code>: draws from the posterior distribution of all coefficients
</p>
</li></ul>

<p>Additionally, if <code>init_params</code> and <code>sample_params</code> have output <code>mu_test</code>, then the sampler will output
<code>post.predtest</code>, which contains draws from the posterior predictive distribution at test points.
</p>


<h3>Value</h3>

<p>A list with at least the following elements:
</p>

<ul>
<li> <p><code>post.pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>post.sigma</code>: draws from the posterior distribution of <code>sigma</code>
</p>
</li>
<li> <p><code>post.log.like.point</code>: draws of the log-likelihood for each of the <code>n</code> observations
</p>
</li>
<li> <p><code>WAIC</code>: Widely-Applicable/Watanabe-Akaike Information Criterion
</p>
</li>
<li> <p><code>p_waic</code>: Effective number of parameters based on WAIC
</p>
</li>
<li> <p><code>post.g</code>: draws from the posterior distribution of the transformation <code>g</code>
</p>
</li>
<li> <p><code>post.sigma.gamma</code>: draws from the posterior distribution of <code>sigma.gamma</code>,
the prior standard deviation of the transformation g() coefficients
</p>
</li>
<li> <p><code>fitted.values</code>: the posterior mean of the conditional expectation of the counts <code>y</code>
(<code>NULL</code> if <code>save_y_hat=FALSE</code>)
</p>
</li>
<li> <p><code>post.fitted.values</code>: posterior draws of the conditional mean of the counts <code>y</code>
(<code>NULL</code> if <code>save_y_hat=FALSE</code>)
</p>
</li></ul>

<p>along with other elements depending on the nature of the initialization and sampling functions. See details for more info.
</p>

<hr>
<h2 id='getEffSize'>Summarize of effective sample size</h2><span id='topic+getEffSize'></span>

<h3>Description</h3>

<p>Compute the summary statistics for the effective sample size (ESS) across
posterior samples for possibly many variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEffSize(postX)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getEffSize_+3A_postx">postX</code></td>
<td>
<p>An array of arbitrary dimension <code>(nsims x ... x ...)</code>, where <code>nsims</code> is the number of posterior samples</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Table of summary statistics using the function <code>summary()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ESS for iid simulations:
rand_iid = rnorm(n = 10^4)
getEffSize(rand_iid)

# ESS for several AR(1) simulations with coefficients 0.1, 0.2,...,0.9:
rand_ar1 = sapply(seq(0.1, 0.9, by = 0.1), function(x) arima.sim(n = 10^4, list(ar = x)))
getEffSize(rand_ar1)

</code></pre>

<hr>
<h2 id='init_bam_orthog'>Initialize the parameters for an additive model</h2><span id='topic+init_bam_orthog'></span>

<h3>Description</h3>

<p>Initialize the parameters for an additive model, which may contain
both linear and nonlinear predictors. The nonlinear terms are modeled
using orthogonalized splines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_bam_orthog(y, X_lin, X_nonlin, B_all = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_bam_orthog_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="init_bam_orthog_+3A_x_lin">X_lin</code></td>
<td>
<p><code>n x pL</code> matrix of predictors to be modelled as linear</p>
</td></tr>
<tr><td><code id="init_bam_orthog_+3A_x_nonlin">X_nonlin</code></td>
<td>
<p><code>n x pNL</code> matrix of predictors to be modelled as nonlinear</p>
</td></tr>
<tr><td><code id="init_bam_orthog_+3A_b_all">B_all</code></td>
<td>
<p>optional <code>pNL</code>-dimensional list of <code>n x L[j]</code> dimensional
basis matrices for each nonlinear term j=1,...,pNL; if NULL, compute internally</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list <code>params</code> containing
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>



<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta_lin</code>: the <code>p x 1</code> linear coefficients, including the linear terms from <code>X_nonlin</code>
</p>
</li>
<li> <p><code>f_j</code>: the <code>n x pNL</code> matrix of fitted values for each nonlinear function
</p>
</li>
<li> <p><code>theta_j</code>: the <code>pNL</code>-dimensional of nonlinear basis coefficients
</p>
</li>
<li> <p><code>sigma_beta</code>: <code>p x 1</code> vector of linear regression coefficient standard deviations
</p>
</li>
<li> <p><code>sigma_theta_j</code>: <code>pNL x 1</code> vector of nonlinear coefficient standard deviations
</p>
</li></ul>


<hr>
<h2 id='init_bam_thin'>Initialize the parameters for an additive model</h2><span id='topic+init_bam_thin'></span>

<h3>Description</h3>

<p>Initialize the parameters for an additive model, which may contain
both linear and nonlinear predictors. The nonlinear terms are modeled
using low-rank thin plate splines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_bam_thin(y, X_lin, X_nonlin, B_all = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_bam_thin_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="init_bam_thin_+3A_x_lin">X_lin</code></td>
<td>
<p><code>n x pL</code> matrix of predictors to be modelled as linear</p>
</td></tr>
<tr><td><code id="init_bam_thin_+3A_x_nonlin">X_nonlin</code></td>
<td>
<p><code>n x pNL</code> matrix of predictors to be modelled as nonlinear</p>
</td></tr>
<tr><td><code id="init_bam_thin_+3A_b_all">B_all</code></td>
<td>
<p>optional <code>pNL</code>-dimensional list of <code>n x L[j]</code> dimensional
basis matrices for each nonlinear term j=1,...,pNL; if NULL, compute internally</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list <code>params</code> containing
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>



<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta_lin</code>: the <code>p x 1</code> linear coefficients, including the linear terms from <code>X_nonlin</code>
</p>
</li>
<li> <p><code>f_j</code>: the <code>n x pNL</code> matrix of fitted values for each nonlinear function
</p>
</li>
<li> <p><code>theta_j</code>: the <code>pNL</code>-dimensional of nonlinear basis coefficients
</p>
</li>
<li> <p><code>sigma_beta</code>: <code>p x 1</code> vector of linear regression coefficient standard deviations
</p>
</li>
<li> <p><code>sigma_theta_j</code>: <code>pNL x 1</code> vector of nonlinear coefficient standard deviations
</p>
</li></ul>


<hr>
<h2 id='init_lm_gprior'>Initialize linear regression parameters assuming a g-prior</h2><span id='topic+init_lm_gprior'></span>

<h3>Description</h3>

<p>Initialize the parameters for a linear regression model assuming a
g-prior for the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_lm_gprior(y, X, X_test = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_lm_gprior_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="init_lm_gprior_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="init_lm_gprior_+3A_x_test">X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors at test points (default is NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list <code>params</code> containing at least
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>

<p>Additionally, if X_test is not NULL, then the list includes an element
<code>mu_test</code>, the vector of conditional means at the test points
</p>


<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta</code>: the <code>p x 1</code> vector of regression coefficients
components of <code>beta</code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Simulate data for illustration:
sim_dat = simulate_nb_lm(n = 100, p = 5)
y = sim_dat$y; X = sim_dat$X

# Initialize:
params = init_lm_gprior(y = y, X = X)
names(params)
names(params$coefficients)

</code></pre>

<hr>
<h2 id='init_lm_hs'>Initialize linear regression parameters assuming a horseshoe prior</h2><span id='topic+init_lm_hs'></span>

<h3>Description</h3>

<p>Initialize the parameters for a linear regression model assuming a
horseshoe prior for the (non-intercept) coefficients. The number of predictors
<code>p</code> may exceed the number of observations <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_lm_hs(y, X, X_test = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_lm_hs_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="init_lm_hs_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="init_lm_hs_+3A_x_test">X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors at test points (default is NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list <code>params</code> containing at least
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>

<p>Additionally, if X_test is not NULL, then the list includes an element
<code>mu_test</code>, the vector of conditional means at the test points
</p>


<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta</code>: the <code>p x 1</code> vector of regression coefficients
</p>
</li>
<li> <p><code>sigma_beta</code>: the <code>p x 1</code> vector of regression coefficient standard deviations
(local scale parameters)
</p>
</li>
<li> <p><code>xi_sigma_beta</code>: the <code>p x 1</code> vector of parameter-expansion variables for <code>sigma_beta</code>
</p>
</li>
<li> <p><code>lambda_beta</code>: the global scale parameter
</p>
</li>
<li> <p><code>xi_lambda_beta</code>: the parameter-expansion variable for <code>lambda_beta</code>
components of <code>beta</code>
</p>
</li></ul>


<hr>
<h2 id='init_lm_ridge'>Initialize linear regression parameters assuming a ridge prior</h2><span id='topic+init_lm_ridge'></span>

<h3>Description</h3>

<p>Initialize the parameters for a linear regression model assuming a
ridge prior for the (non-intercept) coefficients. The number of predictors
<code>p</code> may exceed the number of observations <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_lm_ridge(y, X, X_test = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_lm_ridge_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="init_lm_ridge_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="init_lm_ridge_+3A_x_test">X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors at test points (default is NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list <code>params</code> containing at least
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>

<p>Additionally, if X_test is not NULL, then the list includes an element
<code>mu_test</code>, the vector of conditional means at the test points
</p>


<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta</code>: the <code>p x 1</code> vector of regression coefficients
</p>
</li>
<li> <p><code>sigma_beta</code>: the prior standard deviation for the (non-intercept)
components of <code>beta</code>
</p>
</li></ul>


<hr>
<h2 id='init_params_mean'>Initialize the parameters for a simple mean-only model</h2><span id='topic+init_params_mean'></span>

<h3>Description</h3>

<p>Initialize the parameters for the model y ~ N(mu0, sigma^2)
with a flat prior on mu0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_params_mean(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_params_mean_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list <code>params</code> containing
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>



<h3>Note</h3>

<p>The only parameter in <code>coefficients</code> is <code>mu0</code>.
Although redundant here, this parametrization is useful in other functions.
</p>

<hr>
<h2 id='interval_gRcpp'>Estimate confidence intervals/bands for a STAR process</h2><span id='topic+interval_gRcpp'></span>

<h3>Description</h3>

<p>Compute confidence intervals/bands for the expected value of the count-valued STAR process <code>y</code>
based on intervals/bands for the Gaussian process <code>mu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interval_gRcpp(g_a_j, g_a_jp1, L_mu, U_mu, sigma, Jmax)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interval_gRcpp_+3A_g_a_j">g_a_j</code></td>
<td>
<p><code>Jmax x 1</code> vector of g(a(j))</p>
</td></tr>
<tr><td><code id="interval_gRcpp_+3A_g_a_jp1">g_a_jp1</code></td>
<td>
<p><code>Jmax x 1</code> vector of g(a(j + 1))</p>
</td></tr>
<tr><td><code id="interval_gRcpp_+3A_l_mu">L_mu</code></td>
<td>
<p><code>m x 1</code> vector of lower intervals for <code>mu</code></p>
</td></tr>
<tr><td><code id="interval_gRcpp_+3A_u_mu">U_mu</code></td>
<td>
<p><code>m x 1</code> vector of upper intervals for <code>mu</code></p>
</td></tr>
<tr><td><code id="interval_gRcpp_+3A_sigma">sigma</code></td>
<td>
<p><code>m x 1</code> vector of conditional standard deviations</p>
</td></tr>
<tr><td><code id="interval_gRcpp_+3A_jmax">Jmax</code></td>
<td>
<p><code>m x 1</code> vector of maximum integer values to consider</p>
</td></tr>
</table>


<h3>Value</h3>

<p>LU_y <code>m x 2</code> vector of intervals for <code>y</code>.
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='invlogit'>Compute the inverse log-odds</h2><span id='topic+invlogit'></span>

<h3>Description</h3>

<p>Compute the inverse log-odds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invlogit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invlogit_+3A_x">x</code></td>
<td>
<p>scalar or vector for which to compute the (componentwise) inverse log-odds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A scalar or vector of values in (0,1)
</p>

<hr>
<h2 id='lm_star'>Fitting frequentist STAR linear model via EM algorithm</h2><span id='topic+lm_star'></span>

<h3>Description</h3>

<p>Compute the MLEs and log-likelihood for the STAR linear model.
The regression coefficients are estimated using least squares within
an EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lm_star(
  formula,
  data = NULL,
  transformation = "np",
  y_max = Inf,
  sd_init = 10,
  tol = 10^-10,
  max_iters = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lm_star_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;<code><a href="stats.html#topic+formula">formula</a></code>&quot; (see <code><a href="stats.html#topic+lm">lm</a></code> for details on model specification)</p>
</td></tr>
<tr><td><code id="lm_star_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object coercible by as.data.frame to a data frame)
containing the variables in the model; like <code><a href="stats.html#topic+lm">lm</a></code>, if not found in data,
the variables are taken from <code>environment(formula)</code></p>
</td></tr>
<tr><td><code id="lm_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li><p> &quot;box-cox&quot; (box-cox transformation with learned parameter)
</p>
</li></ul>
</td></tr>
<tr><td><code id="lm_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="lm_star_+3A_sd_init">sd_init</code></td>
<td>
<p>add random noise for EM algorithm initialization scaled by <code>sd_init</code>
times the Gaussian MLE standard deviation; default is 10</p>
</td></tr>
<tr><td><code id="lm_star_+3A_tol">tol</code></td>
<td>
<p>tolerance for stopping the EM algorithm; default is 10^-10;</p>
</td></tr>
<tr><td><code id="lm_star_+3A_max_iters">max_iters</code></td>
<td>
<p>maximum number of EM iterations before stopping; default is 1000</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard function calls including
<code><a href="stats.html#topic+coefficients">coefficients</a></code>, <code><a href="stats.html#topic+fitted">fitted</a></code>, and <code><a href="stats.html#topic+residuals">residuals</a></code> apply. Fitted values are the expectation
at the MLEs, and as such are not necessarily count-valued.
</p>


<h3>Value</h3>

<p>an object of <code>class</code> &quot;lmstar&quot;, which is a list with the following elements:
</p>

<ul>
<li> <p><code>coefficients</code> the MLEs of the coefficients
</p>
</li>
<li> <p><code>fitted.values</code> the fitted values at the MLEs
</p>
</li>
<li> <p><code>g.hat</code> a function containing the (known or estimated) transformation
</p>
</li>
<li> <p><code>ginv.hat</code> a function containing the inverse of the transformation
</p>
</li>
<li> <p><code>sigma.hat</code> the MLE of the standard deviation
</p>
</li>
<li> <p><code>mu.hat</code> the MLE of the conditional mean (on the transformed scale)
</p>
</li>
<li> <p><code>z.hat</code> the estimated latent data (on the transformed scale) at the MLEs
</p>
</li>
<li> <p><code>residuals</code> the Dunn-Smyth residuals (randomized)
</p>
</li>
<li> <p><code>residuals_rep</code> the Dunn-Smyth residuals (randomized) for 10 replicates
</p>
</li>
<li> <p><code>logLik</code> the log-likelihood at the MLEs
</p>
</li>
<li> <p><code>logLik0</code> the log-likelihood at the MLEs for the *unrounded* initialization
</p>
</li>
<li> <p><code>lambda</code> the Box-Cox nonlinear parameter
</p>
</li>
<li><p> and other parameters that
(1) track the parameters across EM iterations and
(2) record the model specifications
</p>
</li></ul>



<h3>Note</h3>

<p>Infinite latent data values may occur when the transformed
Gaussian model is highly inadequate. In that case, the function returns
the *indices* of the data points with infinite latent values, which are
significant outliers under the model. Deletion of these indices and
re-running the model is one option, but care must be taken to ensure
that (i) it is appropriate to treat these observations as outliers and
(ii) the model is adequate for the remaining data points.
</p>


<h3>References</h3>

<p>Kowal, D. R., &amp; Wu, B. (2021).
Semiparametric count data regression for selfreported mental health.
<em>Biometrics</em>. <a href="https://doi.org/10.1111/biom.13617">doi:10.1111/biom.13617</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data with count-valued response y:
sim_dat = simulate_nb_lm(n = 100, p = 3)
y = sim_dat$y; X = sim_dat$X

# Fit model
fit_em = lm_star(y~X)

# Fitted coefficients:
coef(fit_em)
# Fitted values:
y_hat = fitted(fit_em)
plot(y_hat, y);

# Residuals:
plot(residuals(fit_em))
qqnorm(residuals(fit_em)); qqline(residuals(fit_em))
</code></pre>

<hr>
<h2 id='logit'>Compute the log-odds</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>Compute the log-odds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit_+3A_x">x</code></td>
<td>
<p>scalar or vector in (0,1) for which to compute the (componentwise) log-odds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A scalar or vector of log-odds
</p>

<hr>
<h2 id='logLikePointRcpp'>Compute the pointwise log-likelihood for STAR</h2><span id='topic+logLikePointRcpp'></span>

<h3>Description</h3>

<p>Compute the pointwise log-likelihood for a STAR model. The code here assumes
that the transformed real-valued process (z_star) has conditionally independent
components with means <code>mu</code> and standard deviations <code>sigma</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLikePointRcpp(g_a_j, g_a_jp1, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLikePointRcpp_+3A_g_a_j">g_a_j</code></td>
<td>
<p><code>m x 1</code> vector of g(a(j))</p>
</td></tr>
<tr><td><code id="logLikePointRcpp_+3A_g_a_jp1">g_a_jp1</code></td>
<td>
<p><code>m x 1</code> vector of g(a(j + 1))</p>
</td></tr>
<tr><td><code id="logLikePointRcpp_+3A_mu">mu</code></td>
<td>
<p><code>m x 1</code> vector of conditional expectations</p>
</td></tr>
<tr><td><code id="logLikePointRcpp_+3A_sigma">sigma</code></td>
<td>
<p><code>m x 1</code> vector of conditional standard deviations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>loglike <code>m x 1</code> log-likelihood value
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='logLikeRcpp'>Compute the log-likelihood for STAR</h2><span id='topic+logLikeRcpp'></span>

<h3>Description</h3>

<p>Compute the log-likelihood for a STAR model. The code here assumes
that the transformed real-valued process (z_star) has conditionally independent
components with means <code>mu</code> and standard deviations <code>sigma</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLikeRcpp(g_a_j, g_a_jp1, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLikeRcpp_+3A_g_a_j">g_a_j</code></td>
<td>
<p><code>m x 1</code> vector of g(a(j))</p>
</td></tr>
<tr><td><code id="logLikeRcpp_+3A_g_a_jp1">g_a_jp1</code></td>
<td>
<p><code>m x 1</code> vector of g(a(j + 1))</p>
</td></tr>
<tr><td><code id="logLikeRcpp_+3A_mu">mu</code></td>
<td>
<p><code>m x 1</code> vector of conditional expectations</p>
</td></tr>
<tr><td><code id="logLikeRcpp_+3A_sigma">sigma</code></td>
<td>
<p><code>m x 1</code> vector of conditional standard deviations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>loglike scalar log-likelihood value
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='plot_coef'>Plot the estimated regression coefficients and credible intervals</h2><span id='topic+plot_coef'></span>

<h3>Description</h3>

<p>Plot the estimated regression coefficients and credible intervals
for the linear effects in up to two models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_coef(
  post_coefficients_1,
  post_coefficients_2 = NULL,
  alpha = 0.05,
  labels = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_coef_+3A_post_coefficients_1">post_coefficients_1</code></td>
<td>
<p><code>Nsims x p</code> matrix of simulations from the posterior
distribution of the <code>p</code> coefficients, where <code>Nsims</code> is the number of simulations</p>
</td></tr>
<tr><td><code id="plot_coef_+3A_post_coefficients_2">post_coefficients_2</code></td>
<td>
<p><code>Nsims x p</code> matrix of simulations from the posterior
distribution of the <code>p</code> coefficients from another model</p>
</td></tr>
<tr><td><code id="plot_coef_+3A_alpha">alpha</code></td>
<td>
<p>confidence level for the credible intervals</p>
</td></tr>
<tr><td><code id="plot_coef_+3A_labels">labels</code></td>
<td>
<p><code>p</code> dimensional string of labels for the coefficient names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of regression coefficients and credible intervals for 1-2 models
</p>

<hr>
<h2 id='plot_fitted'>Plot the fitted values and the data</h2><span id='topic+plot_fitted'></span>

<h3>Description</h3>

<p>Plot the fitted values, plus pointwise credible intervals, against the
data. For simulations, one may use the true values in place of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_fitted(y, post_y, y_hat = NULL, alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_fitted_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="plot_fitted_+3A_post_y">post_y</code></td>
<td>
<p><code>Nsims x n</code> matrix of simulated fitted values, where <code>Nsims</code> is the
number of simulations</p>
</td></tr>
<tr><td><code id="plot_fitted_+3A_y_hat">y_hat</code></td>
<td>
<p><code>n x 1</code> vector of fitted values; if NULL, use the pointwise sample mean <code>colMeans(post_y)</code></p>
</td></tr>
<tr><td><code id="plot_fitted_+3A_alpha">alpha</code></td>
<td>
<p>confidence level for the credible intervals</p>
</td></tr>
<tr><td><code id="plot_fitted_+3A_...">...</code></td>
<td>
<p>other arguments for plotting</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot with the fitted values and the credible intervals against the data
</p>

<hr>
<h2 id='plot_pmf'>Plot the empirical and model-based probability mass functions</h2><span id='topic+plot_pmf'></span>

<h3>Description</h3>

<p>Plot the empirical probability mass function, i.e., the proportion of
data values <code>y</code> that equal <code>j</code> for each <code>j=0,1,...</code>,
together with the model-based estimate of the probability mass function
based on the posterior predictive distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pmf(y, post.pred, error.bars = FALSE, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_pmf_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="plot_pmf_+3A_post.pred">post.pred</code></td>
<td>
<p><code>nsave</code> draws from the posterior predictive distribution of <code>y</code></p>
</td></tr>
<tr><td><code id="plot_pmf_+3A_error.bars">error.bars</code></td>
<td>
<p>logical; if TRUE, include errors bars on the model-based PMF</p>
</td></tr>
<tr><td><code id="plot_pmf_+3A_alpha">alpha</code></td>
<td>
<p>confidence level for the credible intervals</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the empirical PMF of y along with a PMF estimate from the model posterior
predictive distribution
</p>

<hr>
<h2 id='pmaxRcpp'>pmax() in Rcpp</h2><span id='topic+pmaxRcpp'></span>

<h3>Description</h3>

<p>Compute the pointwise max for two vectors of equal length
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmaxRcpp(v1, v2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmaxRcpp_+3A_v1">v1</code></td>
<td>
<p><code>m x 1</code> vector</p>
</td></tr>
<tr><td><code id="pmaxRcpp_+3A_v2">v2</code></td>
<td>
<p><code>m x 1</code> vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vm <code>m x 1</code> vector of pointwise maxima
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='pminRcpp'>pmin() in Rcpp</h2><span id='topic+pminRcpp'></span>

<h3>Description</h3>

<p>Compute the pointwise min for two vectors of equal length
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pminRcpp(v1, v2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pminRcpp_+3A_v1">v1</code></td>
<td>
<p><code>m x 1</code> vector</p>
</td></tr>
<tr><td><code id="pminRcpp_+3A_v2">v2</code></td>
<td>
<p><code>m x 1</code> vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vm <code>m x 1</code> vector of pointwise minima
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='predict.lmstar'>Predict method for response in STAR linear model</h2><span id='topic+predict.lmstar'></span>

<h3>Description</h3>

<p>Outputs predicted values based on an lmstar fit and optionally prediction intervals based
on the the (plug-in) predictive distribution for the STAR linear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lmstar'
predict(object, newdata = NULL, interval = FALSE, level = 0.95, N = 1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.lmstar_+3A_object">object</code></td>
<td>
<p>Object of class &quot;lmstar&quot; as output by <code><a href="#topic+lm_star">lm_star</a></code></p>
</td></tr>
<tr><td><code id="predict.lmstar_+3A_newdata">newdata</code></td>
<td>
<p>An optional matrix/data frame  in which to look for variables with which to predict.
If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="predict.lmstar_+3A_interval">interval</code></td>
<td>
<p>logical; whether or not to include prediction intervals (default FALSE)</p>
</td></tr>
<tr><td><code id="predict.lmstar_+3A_level">level</code></td>
<td>
<p>Level for prediction intervals</p>
</td></tr>
<tr><td><code id="predict.lmstar_+3A_n">N</code></td>
<td>
<p>number of Monte Carlo samples from the posterior predictive distribution
used to approximate intervals; default is 1000</p>
</td></tr>
<tr><td><code id="predict.lmstar_+3A_...">...</code></td>
<td>
<p>Ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If interval=TRUE, then <code>predict.lmstar</code> uses a Monte Carlo approach to estimating the (plug-in)
predictive distribution for the STAR linear model. The algorithm iteratively samples
(i) the latent data given the observed data, (ii) the latent predictive data given the latent data from (i),
and (iii) (inverse) transforms and rounds the latent predictive data to obtain a
draw from the integer-valued predictive distribution.
</p>
<p>The appropriate quantiles of these Monte Carlo draws are computed and reported as the prediction interval.
</p>


<h3>Value</h3>

<p>Either a a vector of predictions (if interval=FALSE) or a matrix of predictions and
bounds with column names fit, lwr, and upr
</p>


<h3>Note</h3>

<p>The &ldquo;plug-in&quot; predictive distribution is a crude approximation. Better
approaches are available using the Bayesian models, e.g. <code><a href="#topic+blm_star">blm_star</a></code>, which provide samples
from the posterior predictive distribution.
</p>
<p>For highly skewed responses, prediction intervals especially at lower levels may
not include the predicted value itself, since the mean is often much larger than the median.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data with count-valued response y:
x = seq(0, 1, length.out = 100)
y = rpois(n = length(x), lambda = exp(1.5 + 5*(x -.5)^2))

# Estimate model--assume a quadratic effect (better for illustration purposes)
fit = lm_star(y~x+I(x^2), transformation = 'sqrt')

#Compute the predictive draws for the test points (same as observed points here)
#Also compute intervals using plug-in predictive distribution
y_pred = predict(fit, interval=TRUE)

# Plot the results
plot(x, y, ylim = range(y, y_pred), main = 'STAR: Predictions and 95% PI')
lines(x,y_pred[,"fit"], col='black', type='s', lwd=4)
lines(x, y_pred[,"lwr"], col='darkgray', type='s', lwd=4)
lines(x, y_pred[,"upr"], col='darkgray', type='s', lwd=4)

</code></pre>

<hr>
<h2 id='pvals'>Compute coefficient p-values for STAR linear regression using likelihood ratio test</h2><span id='topic+pvals'></span>

<h3>Description</h3>

<p>For a linear regression model within the STAR framework,
compute p-values for regression coefficients using a likelihood ratio test.
It also computes a p-value for excluding all predictors, akin to a (partial)
F test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvals(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvals_+3A_object">object</code></td>
<td>
<p>Object of class &quot;lmstar&quot; as output by <code><a href="#topic+lm_star">lm_star</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of p+1 p-values, one for each predictor as well as the joint
p-value excluding all predictors
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data with count-valued response y:
sim_dat = simulate_nb_lm(n = 100, p = 2)
y = sim_dat$y; X = sim_dat$X

# Select a transformation:
transformation = 'np'

#Estimate model
fit = lm_star(y~X, transformation = transformation)

#Compute p-values
pvals(fit)

</code></pre>

<hr>
<h2 id='randomForest_star'>Fit Random Forest STAR with EM algorithm</h2><span id='topic+randomForest_star'></span>

<h3>Description</h3>

<p>Compute the MLEs and log-likelihood for the Random Forest STAR model.
The STAR model requires a *transformation* and an *estimation function* for the conditional mean
given observed data. The transformation can be known (e.g., log or sqrt) or unknown
(Box-Cox or estimated nonparametrically) for greater flexibility.
The estimator in this case is a random forest.
Standard function calls including <code><a href="stats.html#topic+fitted">fitted</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code> apply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randomForest_star(
  y,
  X,
  X.test = NULL,
  transformation = "np",
  y_max = Inf,
  sd_init = 10,
  tol = 10^-10,
  max_iters = 1000,
  ntree = 500,
  mtry = max(floor(ncol(X)/3), 1),
  nodesize = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randomForest_star_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_x.test">X.test</code></td>
<td>
<p><code>m x p</code> matrix of out-of-sample predictors</p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li><p> &quot;box-cox&quot; (box-cox transformation with learned parameter)
</p>
</li></ul>
</td></tr>
<tr><td><code id="randomForest_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_sd_init">sd_init</code></td>
<td>
<p>add random noise for EM algorithm initialization scaled by <code>sd_init</code>
times the Gaussian MLE standard deviation; default is 10</p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_tol">tol</code></td>
<td>
<p>tolerance for stopping the EM algorithm; default is 10^-10;</p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_max_iters">max_iters</code></td>
<td>
<p>maximum number of EM iterations before stopping; default is 1000</p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_ntree">ntree</code></td>
<td>
<p>Number of trees to grow.
This should not be set to too small a number, to ensure that every input row gets predicted at least a few times.
Default is 500.</p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_mtry">mtry</code></td>
<td>
<p>Number of variables randomly sampled as candidates at each split.
Default is p/3.</p>
</td></tr>
<tr><td><code id="randomForest_star_+3A_nodesize">nodesize</code></td>
<td>
<p>Minimum size of terminal nodes. Setting this number larger causes smaller trees to be grown (and thus take less time).
Default is 5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation.
</p>
<p>The expectation-maximization (EM) algorithm is used to produce
maximum likelihood estimators (MLEs) for the parameters defined in the
The fitted values are computed using out-of-bag samples. As a result,
the log-likelihood is based on out-of-bag prediction, and it is similarly
straightforward to compute out-of-bag squared and absolute errors.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>fitted.values</code>: the fitted values at the MLEs based on out-of-bag samples (training)
</p>
</li>
<li> <p><code>fitted.values.test</code>: the fitted values at the MLEs (testing)
</p>
</li>
<li> <p><code>g.hat</code> a function containing the (known or estimated) transformation
</p>
</li>
<li> <p><code>sigma.hat</code> the MLE of the standard deviation
</p>
</li>
<li> <p><code>mu.hat</code> the MLE of the conditional mean (on the transformed scale)
</p>
</li>
<li> <p><code>z.hat</code> the estimated latent data (on the transformed scale) at the MLEs
</p>
</li>
<li> <p><code>residuals</code> the Dunn-Smyth residuals (randomized)
</p>
</li>
<li> <p><code>residuals_rep</code> the Dunn-Smyth residuals (randomized) for 10 replicates
</p>
</li>
<li> <p><code>logLik</code> the log-likelihood at the MLEs
</p>
</li>
<li> <p><code>logLik0</code> the log-likelihood at the MLEs for the *unrounded* initialization
</p>
</li>
<li> <p><code>lambda</code> the Box-Cox nonlinear parameter
</p>
</li>
<li> <p><code>rfObj</code>: the object returned by randomForest() at the MLEs
</p>
</li>
<li><p> and other parameters that
(1) track the parameters across EM iterations and
(2) record the model specifications
</p>
</li></ul>



<h3>Note</h3>

<p>Since the random forest produces random predictions, the EM algorithm
will never converge exactly.
</p>
<p>Infinite latent data values may occur when the transformed
Gaussian model is highly inadequate. In that case, the function returns
the *indices* of the data points with infinite latent values, which are
significant outliers under the model. Deletion of these indices and
re-running the model is one option, but care must be taken to ensure
that (i) it is appropriate to treat these observations as outliers and
(ii) the model is adequate for the remaining data points.
</p>


<h3>References</h3>

<p>Kowal, D. R., &amp; Wu, B. (2021).
Semiparametric count data regression for selfreported mental health.
<em>Biometrics</em>. <a href="https://doi.org/10.1111/biom.13617">doi:10.1111/biom.13617</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate data with count-valued response y:
sim_dat = simulate_nb_friedman(n = 100, p = 10)
y = sim_dat$y; X = sim_dat$X

# EM algorithm for STAR (using the log-link)
fit_em = randomForest_star(y = y, X = X,
                 transformation = 'log',
                 max_iters = 100)

# Fitted values (out-of-bag)
y_hat = fitted(fit_em)
plot(y_hat, y);

# Residuals:
plot(residuals(fit_em))
qqnorm(residuals(fit_em)); qqline(residuals(fit_em))

# Log-likelihood at MLEs (out-of-bag):
fit_em$logLik


</code></pre>

<hr>
<h2 id='roaches'>Data on the efficacy of a pest management system at reducing the number of
roaches in urban apartments.</h2><span id='topic+roaches'></span>

<h3>Description</h3>

<p>Data on the efficacy of a pest management system at reducing the number of
roaches in urban apartments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roaches
</code></pre>


<h3>Format</h3>

<p>## 'roaches'
A data frame with 262 obs. of 6 variables:
</p>

<dl>
<dt>y</dt><dd><p>Number of roaches caught</p>
</dd>
<dt>roach1</dt><dd><p>Pretreatment number of roaches</p>
</dd>
<dt>treatment</dt><dd><p>Treatment indicator</p>
</dd>
<dt>senior</dt><dd><p> Indicator for only elderly residents in building</p>
</dd>
<dt>exposure2</dt><dd><p>Number of days for which the roach traps were used</p>
</dd>
</dl>



<h3>Source</h3>

<p>Gelman and Hill (2007); package 'rstanarm'
</p>

<hr>
<h2 id='round_floor'>Rounding function</h2><span id='topic+round_floor'></span>

<h3>Description</h3>

<p>Define the rounding operator associated with the floor function. The function
also returns zero whenever the input is negative and caps the value at <code>y_max</code>,
where <code>y_max</code> is a known upper bound on the data <code>y</code> (if specified).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>round_floor(z, y_max = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="round_floor_+3A_z">z</code></td>
<td>
<p>the real-valued input(s)</p>
</td></tr>
<tr><td><code id="round_floor_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The count-valued output(s) from the rounding function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Floor function:
round_floor(1.5)
round_floor(0.5)

# Special treatmeant of negative numbers:
round_floor(-1)

</code></pre>

<hr>
<h2 id='rtruncnormRcpp'>Sample from a truncated normal distribution</h2><span id='topic+rtruncnormRcpp'></span>

<h3>Description</h3>

<p>Sample from a truncated normal distribution. Samples are drawn
componentwise, so each component of the vector is allowed its own
mean, standard deviation, and upper and lower limits. The components
are assumed to be independent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rtruncnormRcpp(y_lower, y_upper, mu, sigma, u_rand)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rtruncnormRcpp_+3A_y_lower">y_lower</code></td>
<td>
<p><code>m x 1</code> vector of lower endpoints</p>
</td></tr>
<tr><td><code id="rtruncnormRcpp_+3A_y_upper">y_upper</code></td>
<td>
<p><code>m x 1</code> vector of upper endpoints</p>
</td></tr>
<tr><td><code id="rtruncnormRcpp_+3A_mu">mu</code></td>
<td>
<p><code>m x 1</code> vector of conditional expectations</p>
</td></tr>
<tr><td><code id="rtruncnormRcpp_+3A_sigma">sigma</code></td>
<td>
<p><code>m x 1</code> vector of conditional standard deviations</p>
</td></tr>
<tr><td><code id="rtruncnormRcpp_+3A_u_rand">u_rand</code></td>
<td>
<p><code>m x 1</code> vector of uniform random variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>z_star <code>m x 1</code> draw from the truncated normal distribution
</p>


<h3>Note</h3>

<p>This function uses <code>Rcpp</code> for computational efficiency.
</p>

<hr>
<h2 id='sample_bam_orthog'>Sample the parameters for an additive model</h2><span id='topic+sample_bam_orthog'></span>

<h3>Description</h3>

<p>Sample the parameters for an additive model, which may contain
both linear and nonlinear predictors. The nonlinear terms are modeled
using orthogonalized splines. The sampler draws the linear terms
jointly and then samples each vector of nonlinear coefficients using
Bayesian backfitting (i.e., conditional on all other nonlinear and linear terms).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_bam_orthog(
  y,
  X_lin,
  X_nonlin,
  params,
  A = 10^4,
  B_all = NULL,
  diagBtB_all = NULL,
  XtX = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_bam_orthog_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="sample_bam_orthog_+3A_x_lin">X_lin</code></td>
<td>
<p><code>n x pL</code> matrix of predictors to be modelled as linear</p>
</td></tr>
<tr><td><code id="sample_bam_orthog_+3A_x_nonlin">X_nonlin</code></td>
<td>
<p><code>n x pNL</code> matrix of predictors to be modelled as nonlinear</p>
</td></tr>
<tr><td><code id="sample_bam_orthog_+3A_params">params</code></td>
<td>
<p>the named list of parameters containing
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>
</td></tr>
<tr><td><code id="sample_bam_orthog_+3A_a">A</code></td>
<td>
<p>the prior scale for <code>sigma_beta</code>, which we assume follows a Uniform(0, A) prior.</p>
</td></tr>
<tr><td><code id="sample_bam_orthog_+3A_b_all">B_all</code></td>
<td>
<p>optional <code>pNL</code>-dimensional list of <code>n x L[j]</code> dimensional
basis matrices for each nonlinear term j=1,...,pNL; if NULL, compute internally</p>
</td></tr>
<tr><td><code id="sample_bam_orthog_+3A_diagbtb_all">diagBtB_all</code></td>
<td>
<p>optional <code>pNL</code>-dimensional list of <code>diag(crossprod(B_all[[j]]))</code>;
if NULL, compute internally</p>
</td></tr>
<tr><td><code id="sample_bam_orthog_+3A_xtx">XtX</code></td>
<td>
<p>optional <code>p x p</code> matrix of <code>crossprod(X)</code> (one-time cost);
if NULL, compute internally</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated named list <code>params</code> with draws from the full conditional distributions
of <code>sigma</code> and <code>coefficients</code> (and updated <code>mu</code>).
</p>


<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta_lin</code>: the <code>p x 1</code> linear coefficients, including the linear terms from <code>X_nonlin</code>
</p>
</li>
<li> <p><code>f_j</code>: the <code>n x pNL</code> matrix of fitted values for each nonlinear function
</p>
</li>
<li> <p><code>theta_j</code>: the <code>pNL</code>-dimensional of nonlinear basis coefficients
</p>
</li>
<li> <p><code>sigma_beta</code>: <code>p x 1</code> vector of linear regression coefficient standard deviations
</p>
</li>
<li> <p><code>sigma_theta_j</code>: <code>pNL x 1</code> vector of nonlinear coefficient standard deviations
</p>
</li></ul>


<hr>
<h2 id='sample_bam_thin'>Sample the parameters for an additive model</h2><span id='topic+sample_bam_thin'></span>

<h3>Description</h3>

<p>Sample the parameters for an additive model, which may contain
both linear and nonlinear predictors. The nonlinear terms are modeled
using low-rank thin plate splines. The sampler draws the linear terms
jointly and then samples each vector of nonlinear coefficients using
Bayesian backfitting (i.e., conditional on all other nonlinear and linear terms).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_bam_thin(
  y,
  X_lin,
  X_nonlin,
  params,
  A = 10^4,
  B_all = NULL,
  BtB_all = NULL,
  XtX = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_bam_thin_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="sample_bam_thin_+3A_x_lin">X_lin</code></td>
<td>
<p><code>n x pL</code> matrix of predictors to be modelled as linear</p>
</td></tr>
<tr><td><code id="sample_bam_thin_+3A_x_nonlin">X_nonlin</code></td>
<td>
<p><code>n x pNL</code> matrix of predictors to be modelled as nonlinear</p>
</td></tr>
<tr><td><code id="sample_bam_thin_+3A_params">params</code></td>
<td>
<p>the named list of parameters containing
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>
</td></tr>
<tr><td><code id="sample_bam_thin_+3A_a">A</code></td>
<td>
<p>the prior scale for <code>sigma_beta</code>, which we assume follows a Uniform(0, A) prior.</p>
</td></tr>
<tr><td><code id="sample_bam_thin_+3A_b_all">B_all</code></td>
<td>
<p>optional <code>pNL</code>-dimensional list of <code>n x L[j]</code> dimensional
basis matrices for each nonlinear term j=1,...,pNL; if NULL, compute internally</p>
</td></tr>
<tr><td><code id="sample_bam_thin_+3A_btb_all">BtB_all</code></td>
<td>
<p>optional <code>pNL</code>-dimensional list of <code>crossprod(B_all[[j]])</code>;
if NULL, compute internally</p>
</td></tr>
<tr><td><code id="sample_bam_thin_+3A_xtx">XtX</code></td>
<td>
<p>optional <code>p x p</code> matrix of <code>crossprod(X)</code> (one-time cost);
if NULL, compute internally</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated named list <code>params</code> with draws from the full conditional distributions
of <code>sigma</code> and <code>coefficients</code> (and updated <code>mu</code>).
</p>


<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta_lin</code>: the <code>p x 1</code> linear coefficients, including the linear terms from <code>X_nonlin</code>
</p>
</li>
<li> <p><code>f_j</code>: the <code>n x pNL</code> matrix of fitted values for each nonlinear function
</p>
</li>
<li> <p><code>theta_j</code>: the <code>pNL</code>-dimensional of nonlinear basis coefficients
</p>
</li>
<li> <p><code>sigma_beta</code>: <code>p x 1</code> vector of linear regression coefficient standard deviations
</p>
</li>
<li> <p><code>sigma_theta_j</code>: <code>pNL x 1</code> vector of nonlinear coefficient standard deviations
</p>
</li></ul>


<hr>
<h2 id='sample_lm_gprior'>Sample the linear regression parameters assuming a g-prior</h2><span id='topic+sample_lm_gprior'></span>

<h3>Description</h3>

<p>Sample the parameters for a linear regression model assuming a
g-prior for the  coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_lm_gprior(y, X, params, psi = NULL, XtX = NULL, X_test = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_lm_gprior_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="sample_lm_gprior_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="sample_lm_gprior_+3A_params">params</code></td>
<td>
<p>the named list of parameters containing
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>
</td></tr>
<tr><td><code id="sample_lm_gprior_+3A_psi">psi</code></td>
<td>
<p>the prior variance for the g-prior</p>
</td></tr>
<tr><td><code id="sample_lm_gprior_+3A_xtx">XtX</code></td>
<td>
<p>the <code>p x p</code> matrix of <code>crossprod(X)</code> (one-time cost);
if NULL, compute within the function</p>
</td></tr>
<tr><td><code id="sample_lm_gprior_+3A_x_test">X_test</code></td>
<td>
<p>matrix of predictors at test points (default is NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated named list <code>params</code> with draws from the full conditional distributions
of <code>sigma</code> and <code>coefficients</code> (along with updated <code>mu</code> and <code>mu_test</code> if applicable).
</p>


<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta</code>: the <code>p x 1</code> vector of regression coefficients
components of <code>beta</code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Simulate data for illustration:
sim_dat = simulate_nb_lm(n = 100, p = 5)
y = sim_dat$y; X = sim_dat$X
# Initialize:
params = init_lm_gprior(y = y, X = X)
# Sample:
params = sample_lm_gprior(y = y, X = X, params = params)
names(params)
names(params$coefficients)

</code></pre>

<hr>
<h2 id='sample_lm_hs'>Sample linear regression parameters assuming horseshoe prior</h2><span id='topic+sample_lm_hs'></span>

<h3>Description</h3>

<p>Sample the parameters for a linear regression model assuming a
horseshoe prior for the (non-intercept) coefficients. The number of predictors
<code>p</code> may exceed the number of observations <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_lm_hs(y, X, params, XtX = NULL, X_test = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_lm_hs_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="sample_lm_hs_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="sample_lm_hs_+3A_params">params</code></td>
<td>
<p>the named list of parameters containing
</p>

<ol>
<li> <p><code>mu</code> <code>n x 1</code> vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code> the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code> a named list of parameters that determine <code>mu</code>
</p>
</li></ol>
</td></tr>
<tr><td><code id="sample_lm_hs_+3A_xtx">XtX</code></td>
<td>
<p>the <code>p x p</code> matrix of <code>crossprod(X)</code> (one-time cost);
if NULL, compute within the function</p>
</td></tr>
<tr><td><code id="sample_lm_hs_+3A_x_test">X_test</code></td>
<td>
<p>matrix of predictors at test points (default is NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated named list <code>params</code> with draws from the full conditional distributions
of <code>sigma</code> and <code>coefficients</code> (along with updated <code>mu</code> and <code>mu_test</code> if applicable).
</p>


<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta</code> the <code>p x 1</code> vector of regression coefficients
</p>
</li>
<li> <p><code>sigma_beta</code> <code>p x 1</code> vector of regression coefficient standard deviations
(local scale parameters)
</p>
</li>
<li> <p><code>xi_sigma_beta</code> <code>p x 1</code> vector of parameter-expansion variables for <code>sigma_beta</code>
</p>
</li>
<li> <p><code>lambda_beta</code> the global scale parameter
</p>
</li>
<li> <p><code>xi_lambda_beta</code> parameter-expansion variable for <code>lambda_beta</code>
components of <code>beta</code>
</p>
</li></ul>


<hr>
<h2 id='sample_lm_ridge'>Sample linear regression parameters assuming a ridge prior</h2><span id='topic+sample_lm_ridge'></span>

<h3>Description</h3>

<p>Sample the parameters for a linear regression model assuming a
ridge prior for the (non-intercept) coefficients. The number of predictors
<code>p</code> may exceed the number of observations <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_lm_ridge(y, X, params, A = 10^4, XtX = NULL, X_test = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_lm_ridge_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="sample_lm_ridge_+3A_x">X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td></tr>
<tr><td><code id="sample_lm_ridge_+3A_params">params</code></td>
<td>
<p>the named list of parameters containing
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>
</td></tr>
<tr><td><code id="sample_lm_ridge_+3A_a">A</code></td>
<td>
<p>the prior scale for <code>sigma_beta</code>, which we assume follows a Uniform(0, A) prior.</p>
</td></tr>
<tr><td><code id="sample_lm_ridge_+3A_xtx">XtX</code></td>
<td>
<p>the <code>p x p</code> matrix of <code>crossprod(X)</code> (one-time cost);
if NULL, compute within the function</p>
</td></tr>
<tr><td><code id="sample_lm_ridge_+3A_x_test">X_test</code></td>
<td>
<p>matrix of predictors at test points (default is NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated named list <code>params</code> with draws from the full conditional distributions
of <code>sigma</code> and <code>coefficients</code> (along with updated <code>mu</code> and <code>mu_test</code> if applicable).
</p>


<h3>Note</h3>

<p>The parameters in <code>coefficients</code> are:
</p>

<ul>
<li> <p><code>beta</code>: the <code>p x 1</code> vector of regression coefficients
</p>
</li>
<li> <p><code>sigma_beta</code>: the prior standard deviation for the (non-intercept)
components of <code>beta</code>
</p>
</li></ul>


<hr>
<h2 id='sample_params_mean'>Sample the parameters for a simple mean-only model</h2><span id='topic+sample_params_mean'></span>

<h3>Description</h3>

<p>Sample the parameters for the model y ~ N(mu0, sigma^2)
with a flat prior on mu0 and sigma ~ Unif(0, A).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_params_mean(y, params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_params_mean_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of data</p>
</td></tr>
<tr><td><code id="sample_params_mean_+3A_params">params</code></td>
<td>
<p>the named list of parameters containing
</p>

<ol>
<li> <p><code>mu</code>: vector of conditional means (fitted values)
</p>
</li>
<li> <p><code>sigma</code>: the conditional standard deviation
</p>
</li>
<li> <p><code>coefficients</code>: a named list of parameters that determine <code>mu</code>
</p>
</li></ol>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated named list <code>params</code> with draws from the full conditional distributions
of <code>sigma</code> and <code>coefficients</code> (and updated <code>mu</code>).
</p>


<h3>Note</h3>

<p>The only parameter in <code>coefficients</code> is <code>mu0</code>.
Although redundant here, this parametrization is useful in other functions.
</p>

<hr>
<h2 id='sampleFastGaussian'>Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al.</h2><span id='topic+sampleFastGaussian'></span>

<h3>Description</h3>

<p>Sample from N(mu, Sigma) where Sigma = solve(crossprod(Phi) + solve(D))
and mu = Sigma*crossprod(Phi, alpha):
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleFastGaussian(Phi, Ddiag, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleFastGaussian_+3A_phi">Phi</code></td>
<td>
<p><code>n x p</code> matrix (of predictors)</p>
</td></tr>
<tr><td><code id="sampleFastGaussian_+3A_ddiag">Ddiag</code></td>
<td>
<p><code>p x 1</code> vector of diagonal components (of prior variance)</p>
</td></tr>
<tr><td><code id="sampleFastGaussian_+3A_alpha">alpha</code></td>
<td>
<p><code>n x 1</code> vector (of data, scaled by variance)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Draw from N(mu, Sigma), which is <code>p x 1</code>, and is computed in <code>O(n^2*p)</code>
</p>


<h3>Note</h3>

<p>Assumes D is diagonal, but extensions are available
</p>

<hr>
<h2 id='simBaS'>Compute Simultaneous Band Scores (SimBaS)</h2><span id='topic+simBaS'></span>

<h3>Description</h3>

<p>Compute simultaneous band scores (SimBaS) from Meyer et al. (2015, Biometrics).
SimBaS uses MC(MC) simulations of a function of interest to compute the minimum
alpha such that the joint credible bands at the alpha level do not include zero.
This quantity is computed for each grid point (or observation point) in the domain
of the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simBaS(sampFuns)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simBaS_+3A_sampfuns">sampFuns</code></td>
<td>
<p><code>Nsims x m</code> matrix of <code>Nsims</code> MCMC samples and <code>m</code> points along the curve</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>m x 1</code> vector of simBaS
</p>


<h3>Note</h3>

<p>The input needs not be curves: the simBaS may be computed
for vectors to achieve a multiplicity adjustment.
</p>
<p>The minimum of the returned value, <code>PsimBaS_t</code>,
over the domain <code>t</code> is the Global Bayesian P-Value (GBPV) for testing
whether the function is zero everywhere.
</p>

<hr>
<h2 id='simulate_nb_friedman'>Simulate count data from Friedman's nonlinear regression</h2><span id='topic+simulate_nb_friedman'></span>

<h3>Description</h3>

<p>Simulate data from a negative-binomial distribution with nonlinear mean function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_nb_friedman(
  n = 100,
  p = 10,
  r_nb = 1,
  b_int = log(1.5),
  b_sig = log(5),
  sigma_true = sqrt(2 * log(1)),
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_nb_friedman_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="simulate_nb_friedman_+3A_p">p</code></td>
<td>
<p>number of predictors</p>
</td></tr>
<tr><td><code id="simulate_nb_friedman_+3A_r_nb">r_nb</code></td>
<td>
<p>the dispersion parameter of the Negative Binomial dispersion;
smaller values imply greater overdispersion, while larger values approximate the Poisson distribution.</p>
</td></tr>
<tr><td><code id="simulate_nb_friedman_+3A_b_int">b_int</code></td>
<td>
<p>intercept; default is log(1.5).</p>
</td></tr>
<tr><td><code id="simulate_nb_friedman_+3A_b_sig">b_sig</code></td>
<td>
<p>regression coefficients for true signals; default is log(5.0).</p>
</td></tr>
<tr><td><code id="simulate_nb_friedman_+3A_sigma_true">sigma_true</code></td>
<td>
<p>standard deviation of the Gaussian innovation; default is zero.</p>
</td></tr>
<tr><td><code id="simulate_nb_friedman_+3A_seed">seed</code></td>
<td>
<p>optional integer to set the seed for reproducible simulation; default is NULL
which results in a different dataset after each run</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-expected counts are modeled using the Friedman (1991) nonlinear function
with interactions, possibly
with additional Gaussian noise (on the log-scale). We assume that half of the predictors
are associated with the response, i.e., true signals. For sufficiently large dispersion
parameter <code>r_nb</code>, the distribution will approximate a Poisson distribution.
Here, the predictor variables are simulated from independent uniform distributions.
</p>


<h3>Value</h3>

<p>A named list with the simulated count response <code>y</code>, the simulated design matrix <code>X</code>,
and the true expected counts <code>Ey</code>.
</p>


<h3>Note</h3>

<p>Specifying <code>sigma_true = sqrt(2*log(1 + a))</code> implies that the expected counts are
inflated by <code>100*a</code>% (relative to <code>exp(X*beta)</code>), in addition to providing additional
overdispersion.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate and plot the count data:
sim_dat = simulate_nb_friedman(n = 100, p = 10);
plot(sim_dat$y)
</code></pre>

<hr>
<h2 id='simulate_nb_lm'>Simulate count data from a linear regression</h2><span id='topic+simulate_nb_lm'></span>

<h3>Description</h3>

<p>Simulate data from a negative-binomial distribution with linear mean function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_nb_lm(
  n = 100,
  p = 10,
  r_nb = 1,
  b_int = log(1.5),
  b_sig = log(2),
  sigma_true = sqrt(2 * log(1)),
  ar1 = 0,
  intercept = FALSE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_nb_lm_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="simulate_nb_lm_+3A_p">p</code></td>
<td>
<p>number of predictors (including the intercept)</p>
</td></tr>
<tr><td><code id="simulate_nb_lm_+3A_r_nb">r_nb</code></td>
<td>
<p>the dispersion parameter of the Negative Binomial dispersion;
smaller values imply greater overdispersion, while larger values approximate the Poisson distribution.</p>
</td></tr>
<tr><td><code id="simulate_nb_lm_+3A_b_int">b_int</code></td>
<td>
<p>intercept; default is log(1.5), which implies the expected count is 1.5
when all predictors are zero</p>
</td></tr>
<tr><td><code id="simulate_nb_lm_+3A_b_sig">b_sig</code></td>
<td>
<p>regression coefficients for true signals; default is log(2.0), which implies a
twofold increase in the expected counts for a one unit increase in x</p>
</td></tr>
<tr><td><code id="simulate_nb_lm_+3A_sigma_true">sigma_true</code></td>
<td>
<p>standard deviation of the Gaussian innovation; default is zero.</p>
</td></tr>
<tr><td><code id="simulate_nb_lm_+3A_ar1">ar1</code></td>
<td>
<p>the autoregressive coefficient among the columns of the X matrix; default is zero.</p>
</td></tr>
<tr><td><code id="simulate_nb_lm_+3A_intercept">intercept</code></td>
<td>
<p>a Boolean indicating whether an intercept column should be included
in the returned design matrix; default is FALSE</p>
</td></tr>
<tr><td><code id="simulate_nb_lm_+3A_seed">seed</code></td>
<td>
<p>optional integer to set the seed for reproducible simulation; default is NULL
which results in a different dataset after each run</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-expected counts are modeled as a linear function of covariates, possibly
with additional Gaussian noise (on the log-scale). We assume that half of the predictors
are associated with the response, i.e., true signals. For sufficiently large dispersion
parameter <code>r_nb</code>, the distribution will approximate a Poisson distribution.
Here, the predictor variables are simulated from independent standard normal distributions.
</p>


<h3>Value</h3>

<p>A named list with the simulated count response <code>y</code>, the simulated design matrix <code>X</code>
(possibly including the intercept), the true expected counts <code>Ey</code>,
and the true regression coefficients <code>beta_true</code>.
</p>


<h3>Note</h3>

<p>Specifying <code>sigma_true = sqrt(2*log(1 + a))</code> implies that the expected counts are
inflated by <code>100*a</code>% (relative to <code>exp(X*beta)</code>), in addition to providing additional
overdispersion.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate and plot the count data:
sim_dat = simulate_nb_lm(n = 100, p = 10);
plot(sim_dat$y)

</code></pre>

<hr>
<h2 id='spline_star'>Estimation for Bayesian STAR spline regression</h2><span id='topic+spline_star'></span>

<h3>Description</h3>

<p>Compute samples from the predictive
distributions of a STAR spline regression model using either a Gibbs sampling approach
or exact Monte Carlo sampling (default is Gibbs sampling which scales better for large n)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spline_star(
  y,
  tau = NULL,
  transformation = "np",
  y_max = Inf,
  psi = NULL,
  approx_Fz = FALSE,
  approx_Fy = FALSE,
  nsave = 1000,
  use_MCMC = TRUE,
  nburn = 1000,
  nskip = 0,
  verbose = TRUE,
  method_sigma = "mle"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spline_star_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="spline_star_+3A_tau">tau</code></td>
<td>
<p><code>n x 1</code> vector of observation points; if NULL, assume equally-spaced on [0,1]</p>
</td></tr>
<tr><td><code id="spline_star_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;bnp&quot; (Bayesian nonparametric transformation using the Bayesian bootstrap)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li></ul>
</td></tr>
<tr><td><code id="spline_star_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="spline_star_+3A_psi">psi</code></td>
<td>
<p>prior variance (1/smoothing parameter); if NULL, update in MCMC</p>
</td></tr>
<tr><td><code id="spline_star_+3A_approx_fz">approx_Fz</code></td>
<td>
<p>logical; in BNP transformation, apply a (fast and stable)
normal approximation for the marginal CDF of the latent data</p>
</td></tr>
<tr><td><code id="spline_star_+3A_approx_fy">approx_Fy</code></td>
<td>
<p>logical; in BNP transformation, approximate
the marginal CDF of <code>y</code> using the empirical CDF</p>
</td></tr>
<tr><td><code id="spline_star_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save (or number of Monte Carlo simulations)</p>
</td></tr>
<tr><td><code id="spline_star_+3A_use_mcmc">use_MCMC</code></td>
<td>
<p>logical; whether to run Gibbs sampler or Monte Carlo (default is TRUE)</p>
</td></tr>
<tr><td><code id="spline_star_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="spline_star_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
<tr><td><code id="spline_star_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, print time remaining</p>
</td></tr>
<tr><td><code id="spline_star_+3A_method_sigma">method_sigma</code></td>
<td>
<p>method to estimate the latent data standard deviation (only applicable if <code>use_MCMC=FALSE</code>);
must be one of
</p>

<ul>
<li><p> &quot;mle&quot; use the MLE from the STAR EM algorithm (default)
</p>
</li>
<li><p> &quot;mmle&quot; use the marginal MLE (Note: slower!)
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation. Here, the continuous
latent data model is a spline regression.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt'. Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>. The distribution-based
transformations approximately preserve the mean and variance of the count data <code>y</code>
on the latent data scale, which lends interpretability to the model parameters.
Lastly, the transformation can be modeled using the Bayesian bootstrap ('bnp'),
which is a Bayesian nonparametric model and incorporates the uncertainty
about the transformation into posterior and predictive inference.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>post_ytilde</code>: <code>nsave x n</code> samples
from the posterior predictive distribution at the observation points <code>tau</code>
</p>
</li>
<li> <p><code>marg_like</code>: the marginal likelihood (only if <code>use_MCMC=FALSE</code>; otherwise NULL)
</p>
</li></ul>



<h3>Note</h3>

<p>For the 'bnp' transformation (without the <code>Fy</code> approximation),
there are numerical stability issues when <code>psi</code> is modeled as unknown.
In this case, it is better to fix <code>psi</code> at some positive number.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate some data:
n = 100
tau = seq(0,1, length.out = n)
y = round_floor(exp(1 + rnorm(n)/4 + poly(tau, 4)%*%rnorm(n=4, sd = 4:1)))

# Sample from the predictive distribution of a STAR spline model:
fit = spline_star(y = y, tau = tau)

# Compute 90% prediction intervals:
pi_y = t(apply(fit$post_ytilde, 2, quantile, c(0.05, .95)))

# Plot the results: intervals, median, and smoothed mean
plot(tau, y, ylim = range(pi_y, y))
polygon(c(tau, rev(tau)),c(pi_y[,2], rev(pi_y[,1])),col='gray', border=NA)
lines(tau, apply(fit$post_ytilde, 2, median), lwd=5, col ='black')
lines(tau, smooth.spline(tau, apply(fit$post_ytilde, 2, mean))$y, lwd=5, col='blue')
lines(tau, y, type='p')

</code></pre>

<hr>
<h2 id='spline_star_exact'>Monte Carlo predictive sampler for spline regression</h2><span id='topic+spline_star_exact'></span>

<h3>Description</h3>

<p>Compute direct Monte Carlo samples from the posterior predictive
distribution of a STAR spline regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spline_star_exact(
  y,
  tau = NULL,
  transformation = "np",
  y_max = Inf,
  psi = 1000,
  method_sigma = "mle",
  approx_Fz = FALSE,
  approx_Fy = FALSE,
  nsave = 1000,
  compute_marg = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spline_star_exact_+3A_y">y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_tau">tau</code></td>
<td>
<p><code>n x 1</code> vector of observation points; if NULL, assume equally-spaced on [0,1]</p>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent data; must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;bnp&quot; (Bayesian nonparametric transformation using the Bayesian bootstrap)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li></ul>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_psi">psi</code></td>
<td>
<p>prior variance (1/smoothing parameter)</p>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_method_sigma">method_sigma</code></td>
<td>
<p>method to estimate the latent data standard deviation; must be one of
</p>

<ul>
<li><p> &quot;mle&quot; use the MLE from the STAR EM algorithm
</p>
</li>
<li><p> &quot;mmle&quot; use the marginal MLE (Note: slower!)
</p>
</li></ul>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_approx_fz">approx_Fz</code></td>
<td>
<p>logical; in BNP transformation, apply a (fast and stable)
normal approximation for the marginal CDF of the latent data</p>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_approx_fy">approx_Fy</code></td>
<td>
<p>logical; in BNP transformation, approximate
the marginal CDF of <code>y</code> using the empirical CDF</p>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_nsave">nsave</code></td>
<td>
<p>number of Monte Carlo simulations</p>
</td></tr>
<tr><td><code id="spline_star_exact_+3A_compute_marg">compute_marg</code></td>
<td>
<p>logical; if TRUE, compute and return the
marginal likelihood</p>
</td></tr>
</table>


<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation. Here, the continuous
latent data model is a spline regression.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt'. Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>. The distribution-based
transformations approximately preserve the mean and variance of the count data <code>y</code>
on the latent data scale, which lends interpretability to the model parameters.
Lastly, the transformation can be modeled using the Bayesian bootstrap ('bnp'),
which is a Bayesian nonparametric model and incorporates the uncertainty
about the transformation into posterior and predictive inference.
</p>
<p>The Monte Carlo sampler produces direct, discrete, and joint draws
from the posterior predictive distribution of the spline regression model
at the observed tau points.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>

<ul>
<li> <p><code>post_ytilde</code>: <code>nsave x n</code> samples
from the posterior predictive distribution at the observation points <code>tau</code>
</p>
</li>
<li> <p><code>marg_like</code>: the marginal likelihood (if requested; otherwise NULL)
</p>
</li></ul>


<hr>
<h2 id='splineBasis'>Initialize and reparametrize a spline basis matrix</h2><span id='topic+splineBasis'></span>

<h3>Description</h3>

<p>Following Wand and Ormerod (2008), compute a low-rank thin plate spline
basis which is diagonalized such that the prior variance for the nonlinear component
is a scalar times a diagonal matrix. Knot locations are determined by quantiles
and the penalty is the integrated squared second derivative.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splineBasis(tau, sumToZero = TRUE, rescale01 = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splineBasis_+3A_tau">tau</code></td>
<td>
<p><code>m x 1</code> vector of observed points</p>
</td></tr>
<tr><td><code id="splineBasis_+3A_sumtozero">sumToZero</code></td>
<td>
<p>logical; if TRUE, enforce a sum-to-zero constraint (useful for additive models)</p>
</td></tr>
<tr><td><code id="splineBasis_+3A_rescale01">rescale01</code></td>
<td>
<p>logical; if TRUE, rescale <code>tau</code> to the interval [0,1] prior to computing
basis and penalty matrices</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>B_nl</code>: the nonlinear component of the spline basis matrix
</p>


<h3>Note</h3>

<p>To form the full spline basis matrix, compute <code>cbind(1, tau, B_nl)</code>.
The sum-to-zero constraint implicitly assumes that the linear term is
centered and scaled, i.e., <code>scale(tau)</code>.
</p>

<hr>
<h2 id='truncnorm_mom'>Compute the first and second moment of a truncated normal</h2><span id='topic+truncnorm_mom'></span>

<h3>Description</h3>

<p>Given lower and upper endpoints and the mean and standard deviation
of a (non-truncated) normal distribution, compute the first and second
moment of the truncated normal distribution. All inputs may be scalars
or vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>truncnorm_mom(a, b, mu, sig)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="truncnorm_mom_+3A_a">a</code></td>
<td>
<p>lower endpoint</p>
</td></tr>
<tr><td><code id="truncnorm_mom_+3A_b">b</code></td>
<td>
<p>upper endpoint</p>
</td></tr>
<tr><td><code id="truncnorm_mom_+3A_mu">mu</code></td>
<td>
<p>expected value of the non-truncated normal distribution</p>
</td></tr>
<tr><td><code id="truncnorm_mom_+3A_sig">sig</code></td>
<td>
<p>standard deviation of the non-truncated normal distribution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the first moment <code>m1</code> and the second moment <code>m2</code>
</p>

<hr>
<h2 id='uni.slice'>Univariate Slice Sampler from Neal (2008)</h2><span id='topic+uni.slice'></span>

<h3>Description</h3>

<p>Compute a draw from a univariate distribution using the code provided by
Radford M. Neal. The documentation below is also reproduced from Neal (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uni.slice(x0, g, w = 1, m = Inf, lower = -Inf, upper = +Inf, gx0 = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uni.slice_+3A_x0">x0</code></td>
<td>
<p>Initial point</p>
</td></tr>
<tr><td><code id="uni.slice_+3A_g">g</code></td>
<td>
<p>Function returning the log of the probability density (plus constant)</p>
</td></tr>
<tr><td><code id="uni.slice_+3A_w">w</code></td>
<td>
<p>Size of the steps for creating interval (default 1)</p>
</td></tr>
<tr><td><code id="uni.slice_+3A_m">m</code></td>
<td>
<p>Limit on steps (default infinite)</p>
</td></tr>
<tr><td><code id="uni.slice_+3A_lower">lower</code></td>
<td>
<p>Lower bound on support of the distribution (default -Inf)</p>
</td></tr>
<tr><td><code id="uni.slice_+3A_upper">upper</code></td>
<td>
<p>Upper bound on support of the distribution (default +Inf)</p>
</td></tr>
<tr><td><code id="uni.slice_+3A_gx0">gx0</code></td>
<td>
<p>Value of g(x0), if known (default is not known)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The point sampled, with its log density attached as an attribute.
</p>


<h3>Note</h3>

<p>The log density function may return -Inf for points outside the support
of the distribution.  If a lower and/or upper bound is specified for the
support, the log density function will not be called outside such limits.
</p>

<hr>
<h2 id='update_struct'>Update parameters for warpDLM model with trend DLM</h2><span id='topic+update_struct'></span>

<h3>Description</h3>

<p>This function serves to update the warpDLM variance parameters
when the underlying DLM is a structural model (i.e. local level
or local linear trend). It assumes a Unif(0,A=10^4) prior on all
standard deviations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_struct(fit, z_star, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_struct_+3A_fit">fit</code></td>
<td>
<p>the KFAS model object describing the DLM</p>
</td></tr>
<tr><td><code id="update_struct_+3A_z_star">z_star</code></td>
<td>
<p>the latest draw of z*</p>
</td></tr>
<tr><td><code id="update_struct_+3A_theta">theta</code></td>
<td>
<p>the latest draw of the latent state(s) theta</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A KFAS model object (of class SSModel) updated with the newly
sampled variance parameters
</p>

<hr>
<h2 id='warpDLM'>Posterior Inference for warpDLM model with latent structural DLM</h2><span id='topic+warpDLM'></span>

<h3>Description</h3>

<p>This function outputs posterior quantities and forecasts from a univariate
warpDLM model. Currently two latent DLM specifications are supported:
local level and the local linear trend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>warpDLM(
  y,
  type = c("level", "trend"),
  transformation = c("np", "identity", "log", "sqrt", "pois", "neg-bin"),
  y_max = Inf,
  R0 = 10,
  nsave = 5000,
  nburn = 5000,
  nskip = 1,
  n.ahead = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="warpDLM_+3A_y">y</code></td>
<td>
<p>the count-valued time series</p>
</td></tr>
<tr><td><code id="warpDLM_+3A_type">type</code></td>
<td>
<p>the type of latent DLM (must be either level or trend)</p>
</td></tr>
<tr><td><code id="warpDLM_+3A_transformation">transformation</code></td>
<td>
<p>transformation to use for the latent process (default is np);
must be one of
</p>

<ul>
<li><p> &quot;identity&quot; (identity transformation)
</p>
</li>
<li><p> &quot;log&quot; (log transformation)
</p>
</li>
<li><p> &quot;sqrt&quot; (square root transformation)
</p>
</li>
<li><p> &quot;np&quot; (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li><p> &quot;pois&quot; (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li><p> &quot;neg-bin&quot; (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li></ul>
</td></tr>
<tr><td><code id="warpDLM_+3A_y_max">y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td></tr>
<tr><td><code id="warpDLM_+3A_r0">R0</code></td>
<td>
<p>the variance for the initial state theta_0; default is 10</p>
</td></tr>
<tr><td><code id="warpDLM_+3A_nsave">nsave</code></td>
<td>
<p>number of MCMC iterations to save</p>
</td></tr>
<tr><td><code id="warpDLM_+3A_nburn">nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td></tr>
<tr><td><code id="warpDLM_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td></tr>
<tr><td><code id="warpDLM_+3A_n.ahead">n.ahead</code></td>
<td>
<p>number of steps to forecast ahead</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>

<ul>
<li> <p><code>V_post</code>: posterior draws of the observation variance
</p>
</li>
<li> <p><code>W_post</code>: posterior draws of the state update variance(s)
</p>
</li>
<li> <p><code>fc_post</code>: draws from the forecast distribution (of length n.ahead)
</p>
</li>
<li> <p><code>post_pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>g_func</code>: transformation function
</p>
</li>
<li> <p><code>g_inv_func</code>: inverse transformation function
</p>
</li>
<li> <p><code>KFAS_mod</code>: the final KFAS model representing the latent DLM
</p>
</li></ul>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
