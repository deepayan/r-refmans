<!DOCTYPE html><html lang="en-GB"><head><title>Help for package scoringutils</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {scoringutils}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#scoringutils-package'><p>scoringutils: Utilities for Scoring and Assessing Predictions</p></a></li>
<li><a href='#add_relative_skill'><p>Add relative skill scores based on pairwise comparisons</p></a></li>
<li><a href='#ae_median_quantile'><p>Absolute error of the median (quantile-based version)</p></a></li>
<li><a href='#ae_median_sample'><p>Absolute error of the median (sample-based version)</p></a></li>
<li><a href='#apply_metrics'><p>Apply a list of functions to a data table of forecasts</p></a></li>
<li><a href='#as_forecast_binary'><p>Create a <code>forecast</code> object for binary forecasts</p></a></li>
<li><a href='#as_forecast_doc_template'><p>General information on creating a <code>forecast</code> object</p></a></li>
<li><a href='#as_forecast_generic'><p>Common functionality for <code style="white-space: pre;">&#8288;as_forecast_&lt;type&gt;&#8288;</code> functions</p></a></li>
<li><a href='#as_forecast_nominal'><p>Create a <code>forecast</code> object for nominal forecasts</p></a></li>
<li><a href='#as_forecast_ordinal'><p>Create a <code>forecast</code> object for ordinal forecasts</p></a></li>
<li><a href='#as_forecast_point'><p>Create a <code>forecast</code> object for point forecasts</p></a></li>
<li><a href='#as_forecast_quantile'><p>Create a <code>forecast</code> object for quantile-based forecasts</p></a></li>
<li><a href='#as_forecast_sample'><p>Create a <code>forecast</code> object for sample-based forecasts</p></a></li>
<li><a href='#as_scores'><p>Create an object of class <code>scores</code> from data</p></a></li>
<li><a href='#assert_dims_ok_point'><p>Assert Inputs Have Matching Dimensions</p></a></li>
<li><a href='#assert_forecast_generic'><p>Validation common to all forecast types</p></a></li>
<li><a href='#assert_forecast_type'><p>Assert that forecast type is as expected</p></a></li>
<li><a href='#assert_forecast.forecast_binary'><p>Assert that input is a forecast object and passes validations</p></a></li>
<li><a href='#assert_input_binary'><p>Assert that inputs are correct for binary forecast</p></a></li>
<li><a href='#assert_input_categorical'><p>Assert that inputs are correct for categorical forecasts</p></a></li>
<li><a href='#assert_input_interval'><p>Assert that inputs are correct for interval-based forecast</p></a></li>
<li><a href='#assert_input_nominal'><p>Assert that inputs are correct for nominal forecasts</p></a></li>
<li><a href='#assert_input_ordinal'><p>Assert that inputs are correct for ordinal forecasts</p></a></li>
<li><a href='#assert_input_point'><p>Assert that inputs are correct for point forecast</p></a></li>
<li><a href='#assert_input_quantile'><p>Assert that inputs are correct for quantile-based forecast</p></a></li>
<li><a href='#assert_input_sample'><p>Assert that inputs are correct for sample-based forecast</p></a></li>
<li><a href='#assert_scores'><p>Validate an object of class <code>scores</code></p></a></li>
<li><a href='#bias_quantile'><p>Determines bias of quantile forecasts</p></a></li>
<li><a href='#bias_quantile_single_vector'><p>Compute bias for a single vector of quantile predictions</p></a></li>
<li><a href='#bias_sample'><p>Determine bias of forecasts</p></a></li>
<li><a href='#check_columns_present'><p>Check column names are present in a data.frame</p></a></li>
<li><a href='#check_dims_ok_point'><p>Check Inputs Have Matching Dimensions</p></a></li>
<li><a href='#check_duplicates'><p>Check that there are no duplicate forecasts</p></a></li>
<li><a href='#check_input_binary'><p>Check that inputs are correct for binary forecast</p></a></li>
<li><a href='#check_input_interval'><p>Check that inputs are correct for interval-based forecast</p></a></li>
<li><a href='#check_input_point'><p>Check that inputs are correct for point forecast</p></a></li>
<li><a href='#check_input_quantile'><p>Check that inputs are correct for quantile-based forecast</p></a></li>
<li><a href='#check_input_sample'><p>Check that inputs are correct for sample-based forecast</p></a></li>
<li><a href='#check_number_per_forecast'><p>Check that all forecasts have the same number of rows</p></a></li>
<li><a href='#check_numeric_vector'><p>Check whether an input is an atomic vector of mode 'numeric'</p></a></li>
<li><a href='#check_try'><p>Helper function to convert assert statements into checks</p></a></li>
<li><a href='#clean_forecast'><p>Clean forecast object</p></a></li>
<li><a href='#compare_forecasts'><p>Compare a subset of common forecasts</p></a></li>
<li><a href='#crps_sample'><p>(Continuous) ranked probability score</p></a></li>
<li><a href='#document_assert_functions'><p>Documentation template for assert functions</p></a></li>
<li><a href='#document_check_functions'><p>Documentation template for check functions</p></a></li>
<li><a href='#document_test_functions'><p>Documentation template for test functions</p></a></li>
<li><a href='#dss_sample'><p>Dawid-Sebastiani score</p></a></li>
<li><a href='#ensure_data.table'><p>Ensure that an object is a <code>data.table</code></p></a></li>
<li><a href='#example_binary'><p>Binary forecast example data</p></a></li>
<li><a href='#example_nominal'><p>Nominal example data</p></a></li>
<li><a href='#example_ordinal'><p>Ordinal example data</p></a></li>
<li><a href='#example_point'><p>Point forecast example data</p></a></li>
<li><a href='#example_quantile'><p>Quantile example data</p></a></li>
<li><a href='#example_sample_continuous'><p>Continuous forecast example data</p></a></li>
<li><a href='#example_sample_discrete'><p>Discrete forecast example data</p></a></li>
<li><a href='#forecast_types'><p>Documentation template for forecast types</p></a></li>
<li><a href='#geometric_mean'><p>Calculate geometric mean</p></a></li>
<li><a href='#get_correlations'><p>Calculate correlation between metrics</p></a></li>
<li><a href='#get_coverage'><p>Get quantile and interval coverage values for quantile-based forecasts</p></a></li>
<li><a href='#get_duplicate_forecasts'><p>Find duplicate forecasts</p></a></li>
<li><a href='#get_forecast_counts'><p>Count number of available forecasts</p></a></li>
<li><a href='#get_forecast_type'><p>Get forecast type from forecast object</p></a></li>
<li><a href='#get_forecast_unit'><p>Get unit of a single forecast</p></a></li>
<li><a href='#get_metrics'><p>Get metrics</p></a></li>
<li><a href='#get_metrics.forecast_binary'><p>Get default metrics for binary forecasts</p></a></li>
<li><a href='#get_metrics.forecast_nominal'><p>Get default metrics for nominal forecasts</p></a></li>
<li><a href='#get_metrics.forecast_ordinal'><p>Get default metrics for nominal forecasts</p></a></li>
<li><a href='#get_metrics.forecast_point'><p>Get default metrics for point forecasts</p></a></li>
<li><a href='#get_metrics.forecast_quantile'><p>Get default metrics for quantile-based forecasts</p></a></li>
<li><a href='#get_metrics.forecast_sample'><p>Get default metrics for sample-based forecasts</p></a></li>
<li><a href='#get_metrics.scores'><p>Get names of the metrics that were used for scoring</p></a></li>
<li><a href='#get_pairwise_comparisons'><p>Obtain pairwise comparisons between models</p></a></li>
<li><a href='#get_pit_histogram.forecast_quantile'><p>Probability integral transformation histogram</p></a></li>
<li><a href='#get_protected_columns'><p>Get protected columns from data</p></a></li>
<li><a href='#get_range_from_quantile'><p>Get interval range belonging to a quantile</p></a></li>
<li><a href='#get_type'><p>Get type of a vector or matrix of observed values or predictions</p></a></li>
<li><a href='#illustration-input-metric-binary-point'><p>Illustration of required inputs for binary and point forecasts</p></a></li>
<li><a href='#illustration-input-metric-nominal'><p>Illustration of required inputs for nominal forecasts</p></a></li>
<li><a href='#illustration-input-metric-ordinal'><p>Illustration of required inputs for ordinal forecasts</p></a></li>
<li><a href='#illustration-input-metric-quantile'><p>Illustration of required inputs for quantile-based forecasts</p></a></li>
<li><a href='#illustration-input-metric-sample'><p>Illustration of required inputs for sample-based forecasts</p></a></li>
<li><a href='#interpolate_median'><p>Helper function to interpolate the median prediction if it is not available</p></a></li>
<li><a href='#interval_coverage'><p>Interval coverage (for quantile-based forecasts)</p></a></li>
<li><a href='#interval_score'><p>Interval score</p></a></li>
<li><a href='#is_forecast_binary'><p>Test whether an object is a forecast object</p></a></li>
<li><a href='#log_shift'><p>Log transformation with an additive shift</p></a></li>
<li><a href='#logs_categorical'><p>Log score for categorical outcomes</p></a></li>
<li><a href='#logs_sample'><p>Logarithmic score (sample-based version)</p></a></li>
<li><a href='#mad_sample'><p>Determine dispersion of a probabilistic forecast</p></a></li>
<li><a href='#new_forecast'><p>Class constructor for <code>forecast</code> objects</p></a></li>
<li><a href='#new_scores'><p>Construct an object of class <code>scores</code></p></a></li>
<li><a href='#pairwise_comparison_one_group'><p>Do pairwise comparison for one set of forecasts</p></a></li>
<li><a href='#permutation_test'><p>Simple permutation test</p></a></li>
<li><a href='#pit_histogram_sample'><p>Probability integral transformation for counts</p></a></li>
<li><a href='#plot_correlations'><p>Plot correlation between metrics</p></a></li>
<li><a href='#plot_forecast_counts'><p>Visualise the number of available forecasts</p></a></li>
<li><a href='#plot_heatmap'><p>Create a heatmap of a scoring metric</p></a></li>
<li><a href='#plot_interval_coverage'><p>Plot interval coverage</p></a></li>
<li><a href='#plot_pairwise_comparisons'><p>Plot heatmap of pairwise comparisons</p></a></li>
<li><a href='#plot_quantile_coverage'><p>Plot quantile coverage</p></a></li>
<li><a href='#plot_wis'><p>Plot contributions to the weighted interval score</p></a></li>
<li><a href='#print.forecast'><p>Print information about a forecast object</p></a></li>
<li><a href='#quantile_score'><p>Quantile score</p></a></li>
<li><a href='#quantile_to_interval'><p>Transform from a quantile format to an interval format</p></a></li>
<li><a href='#rps_ordinal'><p>Ranked Probability Score for ordinal outcomes</p></a></li>
<li><a href='#run_safely'><p>Run a function safely</p></a></li>
<li><a href='#sample_to_interval_long'><p>Change data from a sample-based format to a long interval range format</p></a></li>
<li><a href='#score.forecast_binary'><p>Evaluate forecasts</p></a></li>
<li><a href='#scoring-functions-binary'><p>Metrics for binary outcomes</p></a></li>
<li><a href='#se_mean_sample'><p>Squared error of the mean (sample-based version)</p></a></li>
<li><a href='#select_metrics'><p>Select metrics from a list of functions</p></a></li>
<li><a href='#set_forecast_unit'><p>Set unit of a single forecast manually</p></a></li>
<li><a href='#summarise_scores'><p>Summarise scores as produced by <code>score()</code></p></a></li>
<li><a href='#test_columns_not_present'><p>Test whether column names are NOT present in a data.frame</p></a></li>
<li><a href='#test_columns_present'><p>Test whether all column names are present in a data.frame</p></a></li>
<li><a href='#theme_scoringutils'><p>Scoringutils ggplot2 theme</p></a></li>
<li><a href='#transform_forecasts'><p>Transform forecasts and observed values</p></a></li>
<li><a href='#validate_metrics'><p>Validate metrics</p></a></li>
<li><a href='#wis'><p>Weighted interval score (WIS)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Utilities for Scoring and Assessing Predictions</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.0</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Facilitate the evaluation of forecasts in a convenient
    framework based on data.table. It allows user to to check their forecasts
    and diagnose issues, to visualise forecasts and missing data, to transform
    data before scoring, to handle missing forecasts, to aggregate scores, and
    to visualise the results of the evaluation. The package mostly focuses on
    the evaluation of probabilistic forecasts and allows evaluating several
    different forecast types and input formats. Find more information about the
    package in the Vignettes as well as in the accompanying paper,
    &lt;<a href="https://doi.org/10.48550%2FarXiv.2205.07090">doi:10.48550/arXiv.2205.07090</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>checkmate, cli, data.table (&ge; 1.16.0), ggplot2 (&ge; 3.4.0),
methods, Metrics, purrr, scoringRules, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggdist, kableExtra, knitr, magrittr, rmarkdown, testthat (&ge;
3.1.9), vdiffr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>r-lib/pkgdown, amirmasoudabdol/preferably</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://doi.org/10.48550/arXiv.2205.07090">https://doi.org/10.48550/arXiv.2205.07090</a>,
<a href="https://epiforecasts.io/scoringutils/">https://epiforecasts.io/scoringutils/</a>,
<a href="https://github.com/epiforecasts/scoringutils">https://github.com/epiforecasts/scoringutils</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/epiforecasts/scoringutils/issues">https://github.com/epiforecasts/scoringutils/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-03 17:54:23 UTC; nikos</td>
</tr>
<tr>
<td>Author:</td>
<td>Nikos Bosse <a href="https://orcid.org/0000-0002-7750-5280"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Sam Abbott <a href="https://orcid.org/0000-0001-8057-8037"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Hugo Gruson <a href="https://orcid.org/0000-0002-4094-1476"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Johannes Bracher <a href="https://orcid.org/0000-0002-3777-1410"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Toshiaki Asakura <a href="https://orcid.org/0000-0001-8838-785X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  James Mba Azam <a href="https://orcid.org/0000-0001-5782-7330"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Sebastian Funk [aut],
  Michael Chirico <a href="https://orcid.org/0000-0003-0787-087X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nikos Bosse &lt;nikosbosse@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-03 18:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='scoringutils-package'>scoringutils: Utilities for Scoring and Assessing Predictions</h2><span id='topic+scoringutils'></span><span id='topic+scoringutils-package'></span>

<h3>Description</h3>

<p>Facilitate the evaluation of forecasts in a convenient framework based on data.table. It allows user to to check their forecasts and diagnose issues, to visualise forecasts and missing data, to transform data before scoring, to handle missing forecasts, to aggregate scores, and to visualise the results of the evaluation. The package mostly focuses on the evaluation of probabilistic forecasts and allows evaluating several different forecast types and input formats. Find more information about the package in the Vignettes as well as in the accompanying paper, <a href="https://doi.org/10.48550/arXiv.2205.07090">doi:10.48550/arXiv.2205.07090</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a> (<a href="https://orcid.org/0000-0002-7750-5280">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Sam Abbott <a href="mailto:contact@samabbott.co.uk">contact@samabbott.co.uk</a> (<a href="https://orcid.org/0000-0001-8057-8037">ORCID</a>)
</p>
</li>
<li><p> Hugo Gruson <a href="mailto:hugo.gruson+R@normalesup.org">hugo.gruson+R@normalesup.org</a> (<a href="https://orcid.org/0000-0002-4094-1476">ORCID</a>)
</p>
</li>
<li><p> Sebastian Funk <a href="mailto:sebastian.funk@lshtm.ac.uk">sebastian.funk@lshtm.ac.uk</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Johannes Bracher <a href="mailto:johannes.bracher@kit.edu">johannes.bracher@kit.edu</a> (<a href="https://orcid.org/0000-0002-3777-1410">ORCID</a>) [contributor]
</p>
</li>
<li><p> Toshiaki Asakura <a href="mailto:toshiaki.asa9ra@gmail.com">toshiaki.asa9ra@gmail.com</a> (<a href="https://orcid.org/0000-0001-8838-785X">ORCID</a>) [contributor]
</p>
</li>
<li><p> James Mba Azam <a href="mailto:james.azam@lshtm.ac.uk">james.azam@lshtm.ac.uk</a> (<a href="https://orcid.org/0000-0001-5782-7330">ORCID</a>) [contributor]
</p>
</li>
<li><p> Michael Chirico <a href="mailto:michaelchirico4@gmail.com">michaelchirico4@gmail.com</a> (<a href="https://orcid.org/0000-0003-0787-087X">ORCID</a>) [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://doi.org/10.48550/arXiv.2205.07090">doi:10.48550/arXiv.2205.07090</a>
</p>
</li>
<li> <p><a href="https://epiforecasts.io/scoringutils/">https://epiforecasts.io/scoringutils/</a>
</p>
</li>
<li> <p><a href="https://github.com/epiforecasts/scoringutils">https://github.com/epiforecasts/scoringutils</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/epiforecasts/scoringutils/issues">https://github.com/epiforecasts/scoringutils/issues</a>
</p>
</li></ul>


<hr>
<h2 id='add_relative_skill'>Add relative skill scores based on pairwise comparisons</h2><span id='topic+add_relative_skill'></span>

<h3>Description</h3>

<p>Adds a columns with relative skills computed by running
pairwise comparisons on the scores.
For more information on
the computation of relative skill, see <code><a href="#topic+get_pairwise_comparisons">get_pairwise_comparisons()</a></code>.
Relative skill will be calculated for the aggregation level specified in
<code>by</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_relative_skill(
  scores,
  compare = "model",
  by = NULL,
  metric = intersect(c("wis", "crps", "brier_score"), names(scores)),
  baseline = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_relative_skill_+3A_scores">scores</code></td>
<td>
<p>An object of class <code>scores</code> (a data.table with
scores and an additional attribute <code>metrics</code> as produced by <code><a href="#topic+score">score()</a></code>).</p>
</td></tr>
<tr><td><code id="add_relative_skill_+3A_compare">compare</code></td>
<td>
<p>Character vector with a single colum name that defines the
elements for the pairwise comparison. For example, if this is set to
&quot;model&quot; (the default), then elements of the &quot;model&quot; column will be
compared.</p>
</td></tr>
<tr><td><code id="add_relative_skill_+3A_by">by</code></td>
<td>
<p>Character vector with column names that define further grouping
levels for the pairwise comparisons. By default this is <code>NULL</code> and there
will be one relative skill score per distinct entry of the column selected
in <code>compare</code>. If further columns are given here, for example, <code>by = "location"</code> with <code>compare = "model"</code>, then one separate relative skill
score is calculated for every model in every location.</p>
</td></tr>
<tr><td><code id="add_relative_skill_+3A_metric">metric</code></td>
<td>
<p>A string with the name of the metric for which
a relative skill shall be computed. By default this is either &quot;crps&quot;,
&quot;wis&quot; or &quot;brier_score&quot; if any of these are available.</p>
</td></tr>
<tr><td><code id="add_relative_skill_+3A_baseline">baseline</code></td>
<td>
<p>A string with the name of a model. If a baseline is
given, then a scaled relative skill with respect to the baseline will be
returned. By default (<code>NULL</code>), relative skill will not be scaled with
respect to a baseline model.</p>
</td></tr>
</table>

<hr>
<h2 id='ae_median_quantile'>Absolute error of the median (quantile-based version)</h2><span id='topic+ae_median_quantile'></span>

<h3>Description</h3>

<p>Compute the absolute error of the median calculated as
</p>
<p style="text-align: center;"><code class="reqn">
  |\text{observed} - \text{median prediction}|
</code>
</p>

<p>The median prediction is the predicted value for which quantile_level == 0.5.
The function requires 0.5 to be among the quantile levels in <code>quantile_level</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ae_median_quantile(observed, predicted, quantile_level)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ae_median_quantile_+3A_observed">observed</code></td>
<td>
<p>Numeric vector of size n with the observed values.</p>
</td></tr>
<tr><td><code id="ae_median_quantile_+3A_predicted">predicted</code></td>
<td>
<p>Numeric nxN matrix of predictive
quantiles, n (number of rows) being the number of forecasts (corresponding
to the number of observed values) and N
(number of columns) the number of quantiles per forecast.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.</p>
</td></tr>
<tr><td><code id="ae_median_quantile_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Vector of of size N with the quantile levels
for which predictions were made.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector of length N with the absolute error of the median.
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-quantile.png" style="width:750px;max-width:100%;" alt="metrics-quantile.png" />
</div><p>
Overview of required input format for quantile-based forecasts


</p>


<h3>See Also</h3>

<p><code><a href="#topic+ae_median_sample">ae_median_sample()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- rnorm(30, mean = 1:30)
predicted_values &lt;- replicate(3, rnorm(30, mean = 1:30))
ae_median_quantile(
  observed, predicted_values, quantile_level = c(0.2, 0.5, 0.8)
)
</code></pre>

<hr>
<h2 id='ae_median_sample'>Absolute error of the median (sample-based version)</h2><span id='topic+ae_median_sample'></span>

<h3>Description</h3>

<p>Absolute error of the median calculated as
</p>
<p style="text-align: center;"><code class="reqn">
  |\text{observed} - \text{median prediction}|
</code>
</p>

<p>where the median prediction is calculated as the median of the predictive
samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ae_median_sample(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ae_median_sample_+3A_observed">observed</code></td>
<td>
<p>A vector with observed values of size n</p>
</td></tr>
<tr><td><code id="ae_median_sample_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive samples, n (number of rows) being
the number of data points and N (number of columns) the number of Monte
Carlo samples. Alternatively, <code>predicted</code> can just be a vector of size n.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector of length n with the absolute errors of the median.
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>


<h3>See Also</h3>

<p><code><a href="#topic+ae_median_quantile">ae_median_quantile()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- rnorm(30, mean = 1:30)
predicted_values &lt;- matrix(rnorm(30, mean = 1:30))
ae_median_sample(observed, predicted_values)
</code></pre>

<hr>
<h2 id='apply_metrics'>Apply a list of functions to a data table of forecasts</h2><span id='topic+apply_metrics'></span>

<h3>Description</h3>

<p>This helper function applies scoring rules (stored as a list of
functions) to a data table of forecasts. <code>apply_metrics</code> is used within
<code>score()</code> to apply all scoring rules to the data.
Scoring rules are wrapped in <code><a href="#topic+run_safely">run_safely()</a></code> to catch errors and to make
sure that only arguments are passed to the scoring rule that are actually
accepted by it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply_metrics(forecast, metrics, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="apply_metrics_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
<tr><td><code id="apply_metrics_+3A_metrics">metrics</code></td>
<td>
<p>A named list of scoring functions. Names will be used as
column names in the output. See <code><a href="#topic+get_metrics">get_metrics()</a></code> for more information on the
default metrics used. See the <em>Customising metrics</em> section below for
information on how to pass custom arguments to scoring functions.</p>
</td></tr>
<tr><td><code id="apply_metrics_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the scoring rules. Note that
this is currently not used, as all calls to <code>apply_scores</code> currently
avoid passing arguments via <code>...</code> and instead expect that the metrics
directly be modified using <code><a href="purrr.html#topic+partial">purrr::partial()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data table with the forecasts and the calculated metrics.
</p>

<hr>
<h2 id='as_forecast_binary'>Create a <code>forecast</code> object for binary forecasts</h2><span id='topic+as_forecast_binary'></span><span id='topic+as_forecast_binary.default'></span>

<h3>Description</h3>

<p>Process and validate a data.frame (or similar) or similar with forecasts
and observations. If the input passes all input checks, those functions will
be converted to a <code>forecast</code> object. A forecast object is a <code>data.table</code> with
a class <code>forecast</code> and an additional class that depends on the forecast type.
</p>
<p>The arguments <code>observed</code>, <code>predicted</code>, etc. make it possible to rename
existing columns of the input data to match the required columns for a
forecast object. Using the argument <code>forecast_unit</code>, you can specify
the columns that uniquely identify a single forecast (and thereby removing
other, unneeded columns. See section &quot;Forecast Unit&quot; below for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_forecast_binary(data, ...)

## Default S3 method:
as_forecast_binary(
  data,
  forecast_unit = NULL,
  observed = NULL,
  predicted = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_forecast_binary_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="as_forecast_binary_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
<tr><td><code id="as_forecast_binary_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="as_forecast_binary_+3A_observed">observed</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
observed values. This column will be renamed to &quot;observed&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_binary_+3A_predicted">predicted</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
predicted values. This column will be renamed to &quot;predicted&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>forecast</code> object of class <code>forecast_binary</code>
</p>


<h3>Required input</h3>

<p>The input needs to be a data.frame or similar with the following columns:
</p>

<ul>
<li> <p><code>observed</code>: <code>factor</code> with exactly two levels representing the observed
values. The highest factor level is assumed to be the reference level.
This means that corresponding value in <code>predicted</code> represent the
probability that the observed value is equal to the highest factor level.
</p>
</li>
<li> <p><code>predicted</code>: <code>numeric</code> with predicted probabilities, representing
the probability that the corresponding value in <code>observed</code> is equal to
the highest available factor level.
</p>
</li></ul>

<p>For convenience, we recommend an additional column <code>model</code> holding the name
of the forecaster or model that produced a prediction, but this is not
strictly necessary.
</p>
<p>See the <a href="#topic+example_binary">example_binary</a> data set for an example.
</p>


<h3>Forecast unit</h3>

<p>In order to score forecasts, <code>scoringutils</code> needs to know which of the rows
of the data belong together and jointly form a single forecasts. This is
easy e.g. for point forecast, where there is one row per forecast. For
quantile or sample-based forecasts, however, there are multiple rows that
belong to a single forecast.
</p>
<p>The <em>forecast unit</em> or <em>unit of a single forecast</em> is then described by the
combination of columns that uniquely identify a single forecast.
For example, we could have forecasts made by different models in various
locations at different time points, each for several weeks into the future.
The forecast unit could then be described as
<code>forecast_unit = c("model", "location", "forecast_date", "forecast_horizon")</code>.
<code>scoringutils</code> automatically tries to determine the unit of a single
forecast. It uses all existing columns for this, which means that no columns
must be present that are unrelated to the forecast unit. As a very simplistic
example, if you had an additional row, &quot;even&quot;, that is one if the row number
is even and zero otherwise, then this would mess up scoring as <code>scoringutils</code>
then thinks that this column was relevant in defining the forecast unit.
</p>
<p>In order to avoid issues, we recommend setting the forecast unit explicitly,
using the <code>forecast_unit</code> argument. This will simply drop unneeded columns,
while making sure that all necessary, 'protected columns' like &quot;predicted&quot;
or &quot;observed&quot; are retained.
</p>


<h3>See Also</h3>

<p>Other functions to create forecast objects: 
<code><a href="#topic+as_forecast_nominal">as_forecast_nominal</a>()</code>,
<code><a href="#topic+as_forecast_ordinal">as_forecast_ordinal</a>()</code>,
<code><a href="#topic+as_forecast_point">as_forecast_point</a>()</code>,
<code><a href="#topic+as_forecast_quantile">as_forecast_quantile</a>()</code>,
<code><a href="#topic+as_forecast_sample">as_forecast_sample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as_forecast_binary(
  example_binary,
  predicted = "predicted",
  forecast_unit = c("model", "target_type", "target_end_date",
                    "horizon", "location")
)
</code></pre>

<hr>
<h2 id='as_forecast_doc_template'>General information on creating a <code>forecast</code> object</h2><span id='topic+as_forecast_doc_template'></span>

<h3>Description</h3>

<p>Process and validate a data.frame (or similar) or similar with forecasts
and observations. If the input passes all input checks, those functions will
be converted to a <code>forecast</code> object. A forecast object is a <code>data.table</code> with
a class <code>forecast</code> and an additional class that depends on the forecast type.
</p>
<p>The arguments <code>observed</code>, <code>predicted</code>, etc. make it possible to rename
existing columns of the input data to match the required columns for a
forecast object. Using the argument <code>forecast_unit</code>, you can specify
the columns that uniquely identify a single forecast (and thereby removing
other, unneeded columns. See section &quot;Forecast Unit&quot; below for details).
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_forecast_doc_template_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="as_forecast_doc_template_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="as_forecast_doc_template_+3A_observed">observed</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
observed values. This column will be renamed to &quot;observed&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_doc_template_+3A_predicted">predicted</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
predicted values. This column will be renamed to &quot;predicted&quot;.</p>
</td></tr>
</table>


<h3>Forecast unit</h3>

<p>In order to score forecasts, <code>scoringutils</code> needs to know which of the rows
of the data belong together and jointly form a single forecasts. This is
easy e.g. for point forecast, where there is one row per forecast. For
quantile or sample-based forecasts, however, there are multiple rows that
belong to a single forecast.
</p>
<p>The <em>forecast unit</em> or <em>unit of a single forecast</em> is then described by the
combination of columns that uniquely identify a single forecast.
For example, we could have forecasts made by different models in various
locations at different time points, each for several weeks into the future.
The forecast unit could then be described as
<code>forecast_unit = c("model", "location", "forecast_date", "forecast_horizon")</code>.
<code>scoringutils</code> automatically tries to determine the unit of a single
forecast. It uses all existing columns for this, which means that no columns
must be present that are unrelated to the forecast unit. As a very simplistic
example, if you had an additional row, &quot;even&quot;, that is one if the row number
is even and zero otherwise, then this would mess up scoring as <code>scoringutils</code>
then thinks that this column was relevant in defining the forecast unit.
</p>
<p>In order to avoid issues, we recommend setting the forecast unit explicitly,
using the <code>forecast_unit</code> argument. This will simply drop unneeded columns,
while making sure that all necessary, 'protected columns' like &quot;predicted&quot;
or &quot;observed&quot; are retained.
</p>

<hr>
<h2 id='as_forecast_generic'>Common functionality for <code style="white-space: pre;">&#8288;as_forecast_&lt;type&gt;&#8288;</code> functions</h2><span id='topic+as_forecast_generic'></span>

<h3>Description</h3>

<p>Common functionality for <code style="white-space: pre;">&#8288;as_forecast_&lt;type&gt;&#8288;</code> functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_forecast_generic(data, forecast_unit = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_forecast_generic_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="as_forecast_generic_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="as_forecast_generic_+3A_...">...</code></td>
<td>
<p>Named arguments that are used to rename columns. The names of the
arguments are the names of the columns that should be renamed. The values
are the new names.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function splits out part of the functionality of
<code style="white-space: pre;">&#8288;as_forecast_&lt;type&gt;&#8288;</code> that is the same for all <code style="white-space: pre;">&#8288;as_forecast_&lt;type&gt;&#8288;</code> functions.
It renames the required columns, where appropriate, and sets the forecast
unit.
</p>

<hr>
<h2 id='as_forecast_nominal'>Create a <code>forecast</code> object for nominal forecasts</h2><span id='topic+as_forecast_nominal'></span><span id='topic+as_forecast_nominal.default'></span>

<h3>Description</h3>

<p>Process and validate a data.frame (or similar) or similar with forecasts
and observations. If the input passes all input checks, those functions will
be converted to a <code>forecast</code> object. A forecast object is a <code>data.table</code> with
a class <code>forecast</code> and an additional class that depends on the forecast type.
</p>
<p>The arguments <code>observed</code>, <code>predicted</code>, etc. make it possible to rename
existing columns of the input data to match the required columns for a
forecast object. Using the argument <code>forecast_unit</code>, you can specify
the columns that uniquely identify a single forecast (and thereby removing
other, unneeded columns. See section &quot;Forecast Unit&quot; below for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_forecast_nominal(data, ...)

## Default S3 method:
as_forecast_nominal(
  data,
  forecast_unit = NULL,
  observed = NULL,
  predicted = NULL,
  predicted_label = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_forecast_nominal_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="as_forecast_nominal_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
<tr><td><code id="as_forecast_nominal_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="as_forecast_nominal_+3A_observed">observed</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
observed values. This column will be renamed to &quot;observed&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_nominal_+3A_predicted">predicted</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
predicted values. This column will be renamed to &quot;predicted&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_nominal_+3A_predicted_label">predicted_label</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that denotes
the outcome to which a predicted probability corresponds to.
This column will be renamed to &quot;predicted_label&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Nominal forecasts are a form of categorical forecasts and represent a
generalisation of binary forecasts to multiple outcomes. The possible
outcomes that the observed values can assume are not ordered.
</p>


<h3>Value</h3>

<p>A <code>forecast</code> object of class <code>forecast_nominal</code>
</p>


<h3>Required input</h3>

<p>The input needs to be a data.frame or similar for the default method
with the following columns:
</p>

<ul>
<li> <p><code>observed</code>: Column with observed values of type <code>factor</code> with N levels,
where N is the number of possible outcomes.
The levels of the factor represent the possible outcomes that
the observed values can assume.
</p>
</li>
<li> <p><code>predicted</code>: <code>numeric</code> column with predicted probabilities. The values
represent the probability that the observed value is equal to the factor
level denoted in <code>predicted_label</code>. Note that forecasts must be complete,
i.e. there must be a probability assigned to every possible outcome and
those probabilities must sum to one.
</p>
</li>
<li> <p><code>predicted_label</code>: <code>factor</code> with N levels, denoting the outcome that the
probabilities in <code>predicted</code> correspond to.
</p>
</li></ul>

<p>For convenience, we recommend an additional column <code>model</code> holding the name
of the forecaster or model that produced a prediction, but this is not
strictly necessary.
</p>
<p>See the <a href="#topic+example_nominal">example_nominal</a> data set for an example.
</p>


<h3>Forecast unit</h3>

<p>In order to score forecasts, <code>scoringutils</code> needs to know which of the rows
of the data belong together and jointly form a single forecasts. This is
easy e.g. for point forecast, where there is one row per forecast. For
quantile or sample-based forecasts, however, there are multiple rows that
belong to a single forecast.
</p>
<p>The <em>forecast unit</em> or <em>unit of a single forecast</em> is then described by the
combination of columns that uniquely identify a single forecast.
For example, we could have forecasts made by different models in various
locations at different time points, each for several weeks into the future.
The forecast unit could then be described as
<code>forecast_unit = c("model", "location", "forecast_date", "forecast_horizon")</code>.
<code>scoringutils</code> automatically tries to determine the unit of a single
forecast. It uses all existing columns for this, which means that no columns
must be present that are unrelated to the forecast unit. As a very simplistic
example, if you had an additional row, &quot;even&quot;, that is one if the row number
is even and zero otherwise, then this would mess up scoring as <code>scoringutils</code>
then thinks that this column was relevant in defining the forecast unit.
</p>
<p>In order to avoid issues, we recommend setting the forecast unit explicitly,
using the <code>forecast_unit</code> argument. This will simply drop unneeded columns,
while making sure that all necessary, 'protected columns' like &quot;predicted&quot;
or &quot;observed&quot; are retained.
</p>


<h3>See Also</h3>

<p>Other functions to create forecast objects: 
<code><a href="#topic+as_forecast_binary">as_forecast_binary</a>()</code>,
<code><a href="#topic+as_forecast_ordinal">as_forecast_ordinal</a>()</code>,
<code><a href="#topic+as_forecast_point">as_forecast_point</a>()</code>,
<code><a href="#topic+as_forecast_quantile">as_forecast_quantile</a>()</code>,
<code><a href="#topic+as_forecast_sample">as_forecast_sample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as_forecast_nominal(
  na.omit(example_nominal),
  predicted = "predicted",
  forecast_unit = c("model", "target_type", "target_end_date",
                    "horizon", "location")
)
</code></pre>

<hr>
<h2 id='as_forecast_ordinal'>Create a <code>forecast</code> object for ordinal forecasts</h2><span id='topic+as_forecast_ordinal'></span><span id='topic+as_forecast_ordinal.default'></span>

<h3>Description</h3>

<p>Process and validate a data.frame (or similar) or similar with forecasts
and observations. If the input passes all input checks, those functions will
be converted to a <code>forecast</code> object. A forecast object is a <code>data.table</code> with
a class <code>forecast</code> and an additional class that depends on the forecast type.
</p>
<p>The arguments <code>observed</code>, <code>predicted</code>, etc. make it possible to rename
existing columns of the input data to match the required columns for a
forecast object. Using the argument <code>forecast_unit</code>, you can specify
the columns that uniquely identify a single forecast (and thereby removing
other, unneeded columns. See section &quot;Forecast Unit&quot; below for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_forecast_ordinal(data, ...)

## Default S3 method:
as_forecast_ordinal(
  data,
  forecast_unit = NULL,
  observed = NULL,
  predicted = NULL,
  predicted_label = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_forecast_ordinal_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="as_forecast_ordinal_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
<tr><td><code id="as_forecast_ordinal_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="as_forecast_ordinal_+3A_observed">observed</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
observed values. This column will be renamed to &quot;observed&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_ordinal_+3A_predicted">predicted</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
predicted values. This column will be renamed to &quot;predicted&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_ordinal_+3A_predicted_label">predicted_label</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that denotes
the outcome to which a predicted probability corresponds to.
This column will be renamed to &quot;predicted_label&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ordinal forecasts are a form of categorical forecasts and represent a
generalisation of binary forecasts to multiple outcomes. The possible
outcomes that the observed values can assume are ordered.
</p>


<h3>Value</h3>

<p>A <code>forecast</code> object of class <code>forecast_ordinal</code>
</p>


<h3>Required input</h3>

<p>The input needs to be a data.frame or similar for the default method
with the following columns:
</p>

<ul>
<li> <p><code>observed</code>: Column with observed values of type <code>factor</code> with N ordered
levels, where N is the number of possible outcomes.
The levels of the factor represent the possible outcomes that
the observed values can assume.
</p>
</li>
<li> <p><code>predicted</code>: <code>numeric</code> column with predicted probabilities. The values
represent the probability that the observed value is equal to the factor
level denoted in <code>predicted_label</code>. Note that forecasts must be complete,
i.e. there must be a probability assigned to every possible outcome and
those probabilities must sum to one.
</p>
</li>
<li> <p><code>predicted_label</code>: <code>factor</code> with N levels, denoting the outcome that the
probabilities in <code>predicted</code> correspond to.
</p>
</li></ul>

<p>For convenience, we recommend an additional column <code>model</code> holding the name
of the forecaster or model that produced a prediction, but this is not
strictly necessary.
</p>
<p>See the <a href="#topic+example_ordinal">example_ordinal</a> data set for an example.
</p>


<h3>Forecast unit</h3>

<p>In order to score forecasts, <code>scoringutils</code> needs to know which of the rows
of the data belong together and jointly form a single forecasts. This is
easy e.g. for point forecast, where there is one row per forecast. For
quantile or sample-based forecasts, however, there are multiple rows that
belong to a single forecast.
</p>
<p>The <em>forecast unit</em> or <em>unit of a single forecast</em> is then described by the
combination of columns that uniquely identify a single forecast.
For example, we could have forecasts made by different models in various
locations at different time points, each for several weeks into the future.
The forecast unit could then be described as
<code>forecast_unit = c("model", "location", "forecast_date", "forecast_horizon")</code>.
<code>scoringutils</code> automatically tries to determine the unit of a single
forecast. It uses all existing columns for this, which means that no columns
must be present that are unrelated to the forecast unit. As a very simplistic
example, if you had an additional row, &quot;even&quot;, that is one if the row number
is even and zero otherwise, then this would mess up scoring as <code>scoringutils</code>
then thinks that this column was relevant in defining the forecast unit.
</p>
<p>In order to avoid issues, we recommend setting the forecast unit explicitly,
using the <code>forecast_unit</code> argument. This will simply drop unneeded columns,
while making sure that all necessary, 'protected columns' like &quot;predicted&quot;
or &quot;observed&quot; are retained.
</p>


<h3>See Also</h3>

<p>Other functions to create forecast objects: 
<code><a href="#topic+as_forecast_binary">as_forecast_binary</a>()</code>,
<code><a href="#topic+as_forecast_nominal">as_forecast_nominal</a>()</code>,
<code><a href="#topic+as_forecast_point">as_forecast_point</a>()</code>,
<code><a href="#topic+as_forecast_quantile">as_forecast_quantile</a>()</code>,
<code><a href="#topic+as_forecast_sample">as_forecast_sample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as_forecast_ordinal(
  na.omit(example_ordinal),
  predicted = "predicted",
  forecast_unit = c("model", "target_type", "target_end_date",
                    "horizon", "location")
)
</code></pre>

<hr>
<h2 id='as_forecast_point'>Create a <code>forecast</code> object for point forecasts</h2><span id='topic+as_forecast_point'></span><span id='topic+as_forecast_point.default'></span><span id='topic+as_forecast_point.forecast_quantile'></span>

<h3>Description</h3>

<p>When converting a <code>forecast_quantile</code> object into a <code>forecast_point</code> object,
the 0.5 quantile is extracted and returned as the point forecast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_forecast_point(data, ...)

## Default S3 method:
as_forecast_point(
  data,
  forecast_unit = NULL,
  observed = NULL,
  predicted = NULL,
  ...
)

## S3 method for class 'forecast_quantile'
as_forecast_point(data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_forecast_point_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="as_forecast_point_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
<tr><td><code id="as_forecast_point_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="as_forecast_point_+3A_observed">observed</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
observed values. This column will be renamed to &quot;observed&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_point_+3A_predicted">predicted</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
predicted values. This column will be renamed to &quot;predicted&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>forecast</code> object of class <code>forecast_point</code>
</p>


<h3>Required input</h3>

<p>The input needs to be a data.frame or similar for the default method
with the following columns:
</p>

<ul>
<li> <p><code>observed</code>: Column of type <code>numeric</code> with observed values.
</p>
</li>
<li> <p><code>predicted</code>: Column of type <code>numeric</code> with predicted values.
</p>
</li></ul>

<p>For convenience, we recommend an additional column <code>model</code> holding the name
of the forecaster or model that produced a prediction, but this is not
strictly necessary.
</p>
<p>See the <a href="#topic+example_point">example_point</a> data set for an example.
</p>


<h3>See Also</h3>

<p>Other functions to create forecast objects: 
<code><a href="#topic+as_forecast_binary">as_forecast_binary</a>()</code>,
<code><a href="#topic+as_forecast_nominal">as_forecast_nominal</a>()</code>,
<code><a href="#topic+as_forecast_ordinal">as_forecast_ordinal</a>()</code>,
<code><a href="#topic+as_forecast_quantile">as_forecast_quantile</a>()</code>,
<code><a href="#topic+as_forecast_sample">as_forecast_sample</a>()</code>
</p>

<hr>
<h2 id='as_forecast_quantile'>Create a <code>forecast</code> object for quantile-based forecasts</h2><span id='topic+as_forecast_quantile'></span><span id='topic+as_forecast_quantile.default'></span><span id='topic+as_forecast_quantile.forecast_sample'></span>

<h3>Description</h3>

<p>Process and validate a data.frame (or similar) or similar with forecasts
and observations. If the input passes all input checks, those functions will
be converted to a <code>forecast</code> object. A forecast object is a <code>data.table</code> with
a class <code>forecast</code> and an additional class that depends on the forecast type.
</p>
<p>The arguments <code>observed</code>, <code>predicted</code>, etc. make it possible to rename
existing columns of the input data to match the required columns for a
forecast object. Using the argument <code>forecast_unit</code>, you can specify
the columns that uniquely identify a single forecast (and thereby removing
other, unneeded columns. See section &quot;Forecast Unit&quot; below for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_forecast_quantile(data, ...)

## Default S3 method:
as_forecast_quantile(
  data,
  forecast_unit = NULL,
  observed = NULL,
  predicted = NULL,
  quantile_level = NULL,
  ...
)

## S3 method for class 'forecast_sample'
as_forecast_quantile(
  data,
  probs = c(0.05, 0.25, 0.5, 0.75, 0.95),
  type = 7,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_forecast_quantile_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="as_forecast_quantile_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
<tr><td><code id="as_forecast_quantile_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="as_forecast_quantile_+3A_observed">observed</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
observed values. This column will be renamed to &quot;observed&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_quantile_+3A_predicted">predicted</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
predicted values. This column will be renamed to &quot;predicted&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_quantile_+3A_quantile_level">quantile_level</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains
the quantile level of the predicted values. This column will be renamed to
&quot;quantile_level&quot;. Only applicable to quantile-based forecasts.</p>
</td></tr>
<tr><td><code id="as_forecast_quantile_+3A_probs">probs</code></td>
<td>
<p>A numeric vector of quantile levels for which
quantiles will be computed. Corresponds to the <code>probs</code> argument in
<code><a href="stats.html#topic+quantile">quantile()</a></code>.</p>
</td></tr>
<tr><td><code id="as_forecast_quantile_+3A_type">type</code></td>
<td>
<p>Type argument passed down to the quantile function. For more
information, see <code><a href="stats.html#topic+quantile">quantile()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>forecast</code> object of class <code>forecast_quantile</code>
</p>


<h3>Required input</h3>

<p>The input needs to be a data.frame or similar for the default method
with the following columns:
</p>

<ul>
<li> <p><code>observed</code>: Column of type <code>numeric</code> with observed values.
</p>
</li>
<li> <p><code>predicted</code>: Column of type <code>numeric</code> with predicted values. Predicted
values represent quantiles of the predictive distribution.
</p>
</li>
<li> <p><code>quantile_level</code>: Column of type <code>numeric</code>, denoting the quantile level of
the corresponding predicted value.
Quantile levels must be between 0 and 1.
</p>
</li></ul>

<p>For convenience, we recommend an additional column <code>model</code> holding the name
of the forecaster or model that produced a prediction, but this is not
strictly necessary.
</p>
<p>See the <a href="#topic+example_quantile">example_quantile</a> data set for an example.
</p>


<h3>Converting from <code>forecast_sample</code> to <code>forecast_quantile</code></h3>

<p>When creating a <code>forecast_quantile</code> object from a <code>forecast_sample</code> object,
the quantiles are estimated by computing empircal quantiles from the samples
via <code><a href="stats.html#topic+quantile">quantile()</a></code>. Note that empirical quantiles are a biased estimator for
the true quantiles in particular in the tails of the distribution and
when the number of available samples is low.
</p>


<h3>Forecast unit</h3>

<p>In order to score forecasts, <code>scoringutils</code> needs to know which of the rows
of the data belong together and jointly form a single forecasts. This is
easy e.g. for point forecast, where there is one row per forecast. For
quantile or sample-based forecasts, however, there are multiple rows that
belong to a single forecast.
</p>
<p>The <em>forecast unit</em> or <em>unit of a single forecast</em> is then described by the
combination of columns that uniquely identify a single forecast.
For example, we could have forecasts made by different models in various
locations at different time points, each for several weeks into the future.
The forecast unit could then be described as
<code>forecast_unit = c("model", "location", "forecast_date", "forecast_horizon")</code>.
<code>scoringutils</code> automatically tries to determine the unit of a single
forecast. It uses all existing columns for this, which means that no columns
must be present that are unrelated to the forecast unit. As a very simplistic
example, if you had an additional row, &quot;even&quot;, that is one if the row number
is even and zero otherwise, then this would mess up scoring as <code>scoringutils</code>
then thinks that this column was relevant in defining the forecast unit.
</p>
<p>In order to avoid issues, we recommend setting the forecast unit explicitly,
using the <code>forecast_unit</code> argument. This will simply drop unneeded columns,
while making sure that all necessary, 'protected columns' like &quot;predicted&quot;
or &quot;observed&quot; are retained.
</p>


<h3>See Also</h3>

<p>Other functions to create forecast objects: 
<code><a href="#topic+as_forecast_binary">as_forecast_binary</a>()</code>,
<code><a href="#topic+as_forecast_nominal">as_forecast_nominal</a>()</code>,
<code><a href="#topic+as_forecast_ordinal">as_forecast_ordinal</a>()</code>,
<code><a href="#topic+as_forecast_point">as_forecast_point</a>()</code>,
<code><a href="#topic+as_forecast_sample">as_forecast_sample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as_forecast_quantile(
  example_quantile,
  predicted = "predicted",
  forecast_unit = c("model", "target_type", "target_end_date",
                    "horizon", "location")
)
</code></pre>

<hr>
<h2 id='as_forecast_sample'>Create a <code>forecast</code> object for sample-based forecasts</h2><span id='topic+as_forecast_sample'></span><span id='topic+as_forecast_sample.default'></span>

<h3>Description</h3>

<p>Process and validate a data.frame (or similar) or similar with forecasts
and observations. If the input passes all input checks, those functions will
be converted to a <code>forecast</code> object. A forecast object is a <code>data.table</code> with
a class <code>forecast</code> and an additional class that depends on the forecast type.
</p>
<p>The arguments <code>observed</code>, <code>predicted</code>, etc. make it possible to rename
existing columns of the input data to match the required columns for a
forecast object. Using the argument <code>forecast_unit</code>, you can specify
the columns that uniquely identify a single forecast (and thereby removing
other, unneeded columns. See section &quot;Forecast Unit&quot; below for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_forecast_sample(data, ...)

## Default S3 method:
as_forecast_sample(
  data,
  forecast_unit = NULL,
  observed = NULL,
  predicted = NULL,
  sample_id = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_forecast_sample_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="as_forecast_sample_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
<tr><td><code id="as_forecast_sample_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="as_forecast_sample_+3A_observed">observed</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
observed values. This column will be renamed to &quot;observed&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_sample_+3A_predicted">predicted</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
predicted values. This column will be renamed to &quot;predicted&quot;.</p>
</td></tr>
<tr><td><code id="as_forecast_sample_+3A_sample_id">sample_id</code></td>
<td>
<p>(optional) Name of the column in <code>data</code> that contains the
sample id. This column will be renamed to &quot;sample_id&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>forecast</code> object of class <code>forecast_sample</code>
</p>


<h3>Required input</h3>

<p>The input needs to be a data.frame or similar for the default method
with the following columns:
</p>

<ul>
<li> <p><code>observed</code>: Column of type <code>numeric</code> with observed values.
</p>
</li>
<li> <p><code>predicted</code>: Column of type <code>numeric</code> with predicted values. Predicted
values represent random samples from the predictive distribution.
</p>
</li>
<li> <p><code>sample_id</code>: Column of any type with unique identifiers
(unique within a single forecast) for each sample.
</p>
</li></ul>

<p>For convenience, we recommend an additional column <code>model</code> holding the name
of the forecaster or model that produced a prediction, but this is not
strictly necessary.
</p>
<p>See the <a href="#topic+example_sample_continuous">example_sample_continuous</a> and <a href="#topic+example_sample_discrete">example_sample_discrete</a> data set
for an example
</p>


<h3>Forecast unit</h3>

<p>In order to score forecasts, <code>scoringutils</code> needs to know which of the rows
of the data belong together and jointly form a single forecasts. This is
easy e.g. for point forecast, where there is one row per forecast. For
quantile or sample-based forecasts, however, there are multiple rows that
belong to a single forecast.
</p>
<p>The <em>forecast unit</em> or <em>unit of a single forecast</em> is then described by the
combination of columns that uniquely identify a single forecast.
For example, we could have forecasts made by different models in various
locations at different time points, each for several weeks into the future.
The forecast unit could then be described as
<code>forecast_unit = c("model", "location", "forecast_date", "forecast_horizon")</code>.
<code>scoringutils</code> automatically tries to determine the unit of a single
forecast. It uses all existing columns for this, which means that no columns
must be present that are unrelated to the forecast unit. As a very simplistic
example, if you had an additional row, &quot;even&quot;, that is one if the row number
is even and zero otherwise, then this would mess up scoring as <code>scoringutils</code>
then thinks that this column was relevant in defining the forecast unit.
</p>
<p>In order to avoid issues, we recommend setting the forecast unit explicitly,
using the <code>forecast_unit</code> argument. This will simply drop unneeded columns,
while making sure that all necessary, 'protected columns' like &quot;predicted&quot;
or &quot;observed&quot; are retained.
</p>


<h3>See Also</h3>

<p>Other functions to create forecast objects: 
<code><a href="#topic+as_forecast_binary">as_forecast_binary</a>()</code>,
<code><a href="#topic+as_forecast_nominal">as_forecast_nominal</a>()</code>,
<code><a href="#topic+as_forecast_ordinal">as_forecast_ordinal</a>()</code>,
<code><a href="#topic+as_forecast_point">as_forecast_point</a>()</code>,
<code><a href="#topic+as_forecast_quantile">as_forecast_quantile</a>()</code>
</p>

<hr>
<h2 id='as_scores'>Create an object of class <code>scores</code> from data</h2><span id='topic+as_scores'></span>

<h3>Description</h3>

<p>This convenience function wraps <code><a href="#topic+new_scores">new_scores()</a></code> and validates
the <code>scores</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_scores(scores, metrics)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_scores_+3A_scores">scores</code></td>
<td>
<p>A data.table or similar with scores as produced by <code><a href="#topic+score">score()</a></code>.</p>
</td></tr>
<tr><td><code id="as_scores_+3A_metrics">metrics</code></td>
<td>
<p>A character vector with the names of the scores
(i.e. the names of the scoring rules used for scoring).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>scores</code>
</p>

<hr>
<h2 id='assert_dims_ok_point'>Assert Inputs Have Matching Dimensions</h2><span id='topic+assert_dims_ok_point'></span>

<h3>Description</h3>

<p>Function assesses whether input dimensions match. In the
following, n is the number of observations / forecasts. Scalar values may
be repeated to match the length of the other input.
Allowed options are therefore:
</p>

<ul>
<li> <p><code>observed</code> is vector of length 1 or length n
</p>
</li>
<li> <p><code>predicted</code> is:
</p>

<ul>
<li><p> a vector of of length 1 or length n
</p>
</li>
<li><p> a matrix with n rows and 1 column
</p>
</li></ul>

</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>assert_dims_ok_point(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_dims_ok_point_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a factor of length n with
exactly two levels, holding the observed values.
The highest factor level is assumed to be the reference level. This means
that <code>predicted</code> represents the probability that the observed value is
equal to the highest factor level.</p>
</td></tr>
<tr><td><code id="assert_dims_ok_point_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. <code>predicted</code> should be a vector of
length n, holding probabilities. Alternatively, <code>predicted</code> can be a matrix
of size n x 1. Values represent the probability that
the corresponding value in <code>observed</code> will be equal to the highest
available factor level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_forecast_generic'>Validation common to all forecast types</h2><span id='topic+assert_forecast_generic'></span>

<h3>Description</h3>

<p>The function runs input checks that apply to all input data, regardless of
forecast type. The function
</p>

<ul>
<li><p> asserts that the forecast is a data.table which has columns <code>observed</code> and
<code>predicted</code>
</p>
</li>
<li><p> checks the forecast type and forecast unit
</p>
</li>
<li><p> checks there are no duplicate forecasts
</p>
</li>
<li><p> if appropriate, checks the number of samples / quantiles is the same
for all forecasts.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>assert_forecast_generic(data, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_forecast_generic_+3A_data">data</code></td>
<td>
<p>A data.table with forecasts and observed values that should
be validated.</p>
</td></tr>
<tr><td><code id="assert_forecast_generic_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If <code>FALSE</code> (default is <code>TRUE</code>), no messages and
warnings will be created.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the input
</p>

<hr>
<h2 id='assert_forecast_type'>Assert that forecast type is as expected</h2><span id='topic+assert_forecast_type'></span>

<h3>Description</h3>

<p>Assert that forecast type is as expected
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_forecast_type(data, actual = get_forecast_type(data), desired = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_forecast_type_+3A_data">data</code></td>
<td>
<p>A forecast object.</p>
</td></tr>
<tr><td><code id="assert_forecast_type_+3A_actual">actual</code></td>
<td>
<p>The actual forecast type of the data</p>
</td></tr>
<tr><td><code id="assert_forecast_type_+3A_desired">desired</code></td>
<td>
<p>The desired forecast type of the data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_forecast.forecast_binary'>Assert that input is a forecast object and passes validations</h2><span id='topic+assert_forecast.forecast_binary'></span><span id='topic+assert_forecast.forecast_point'></span><span id='topic+assert_forecast.forecast_quantile'></span><span id='topic+assert_forecast.forecast_sample'></span><span id='topic+assert_forecast'></span><span id='topic+assert_forecast.default'></span>

<h3>Description</h3>

<p>Assert that an object is a forecast object (i.e. a <code>data.table</code> with a class
<code>forecast</code> and an additional class <code style="white-space: pre;">&#8288;forecast_&lt;type&gt;&#8288;</code> corresponding to the
forecast type).
</p>
<p>See the corresponding <code style="white-space: pre;">&#8288;assert_forecast_&lt;type&gt;&#8288;</code> functions for more details on
the required input formats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_binary'
assert_forecast(forecast, forecast_type = NULL, verbose = TRUE, ...)

## S3 method for class 'forecast_point'
assert_forecast(forecast, forecast_type = NULL, verbose = TRUE, ...)

## S3 method for class 'forecast_quantile'
assert_forecast(forecast, forecast_type = NULL, verbose = TRUE, ...)

## S3 method for class 'forecast_sample'
assert_forecast(forecast, forecast_type = NULL, verbose = TRUE, ...)

assert_forecast(forecast, forecast_type = NULL, verbose = TRUE, ...)

## Default S3 method:
assert_forecast(forecast, forecast_type = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_forecast.forecast_binary_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
<tr><td><code id="assert_forecast.forecast_binary_+3A_forecast_type">forecast_type</code></td>
<td>
<p>(optional) The forecast type you expect the forecasts
to have. If the forecast type as determined by <code>scoringutils</code> based on the
input does not match this, an error will be thrown. If <code>NULL</code> (the
default), the forecast type will be inferred from the data.</p>
</td></tr>
<tr><td><code id="assert_forecast.forecast_binary_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If <code>FALSE</code> (default is <code>TRUE</code>), no messages and
warnings will be created.</p>
</td></tr>
<tr><td><code id="assert_forecast.forecast_binary_+3A_...">...</code></td>
<td>
<p>Currently unused. You <em>cannot</em> pass additional arguments to scoring
functions via <code>...</code>. See the <em>Customising metrics</em> section below for
details on how to use <code><a href="purrr.html#topic+partial">purrr::partial()</a></code> to pass arguments to individual
metrics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns <code>NULL</code> invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>forecast &lt;- as_forecast_binary(example_binary)
assert_forecast(forecast)
</code></pre>

<hr>
<h2 id='assert_input_binary'>Assert that inputs are correct for binary forecast</h2><span id='topic+assert_input_binary'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring binary forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_input_binary(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_input_binary_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a factor of length n with
exactly two levels, holding the observed values.
The highest factor level is assumed to be the reference level. This means
that <code>predicted</code> represents the probability that the observed value is
equal to the highest factor level.</p>
</td></tr>
<tr><td><code id="assert_input_binary_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. <code>predicted</code> should be a vector of
length n, holding probabilities. Alternatively, <code>predicted</code> can be a matrix
of size n x 1. Values represent the probability that
the corresponding value in <code>observed</code> will be equal to the highest
available factor level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_input_categorical'>Assert that inputs are correct for categorical forecasts</h2><span id='topic+assert_input_categorical'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring categorical, i.e. either nominal or ordinal
forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_input_categorical(observed, predicted, predicted_label, ordered = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_input_categorical_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a factor of length n with
N levels holding the observed values. n is the number of observations and
N is the number of possible outcomes the observed values can assume.</p>
</td></tr>
<tr><td><code id="assert_input_categorical_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be nxN matrix of predicted
probabilities, n (number of rows) being the number of data points and N
(number of columns) the number of possible outcomes the observed values
can assume.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.
Values represent the probability that the corresponding value
in <code>observed</code> will be equal to the factor level referenced in
<code>predicted_label</code>.</p>
</td></tr>
<tr><td><code id="assert_input_categorical_+3A_predicted_label">predicted_label</code></td>
<td>
<p>Factor of length N with N levels, where N is the
number of possible outcomes the observed values can assume.</p>
</td></tr>
<tr><td><code id="assert_input_categorical_+3A_ordered">ordered</code></td>
<td>
<p>Value indicating whether factors have to be ordered or not.
Defaults to <code>NA</code>, which means that the check is not performed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_input_interval'>Assert that inputs are correct for interval-based forecast</h2><span id='topic+assert_input_interval'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring interval-based forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_input_interval(observed, lower, upper, interval_range)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_input_interval_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="assert_input_interval_+3A_lower">lower</code></td>
<td>
<p>Input to be checked. Should be a numeric vector of size n that
holds the predicted value for the lower bounds of the prediction intervals.</p>
</td></tr>
<tr><td><code id="assert_input_interval_+3A_upper">upper</code></td>
<td>
<p>Input to be checked. Should be a numeric vector of size n that
holds the predicted value for the upper bounds of the prediction intervals.</p>
</td></tr>
<tr><td><code id="assert_input_interval_+3A_interval_range">interval_range</code></td>
<td>
<p>Input to be checked. Should be a vector of size n that
denotes the interval range in percent. E.g. a value of 50 denotes a
(25%, 75%) prediction interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_input_nominal'>Assert that inputs are correct for nominal forecasts</h2><span id='topic+assert_input_nominal'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring nominal forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_input_nominal(observed, predicted, predicted_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_input_nominal_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be an unordered factor of length
n with N levels holding the observed values. n is the number of
observations and N is the number of possible outcomes the observed values
can assume.</p>
</td></tr>
<tr><td><code id="assert_input_nominal_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be nxN matrix of predicted
probabilities, n (number of rows) being the number of data points and N
(number of columns) the number of possible outcomes the observed values
can assume.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.
Values represent the probability that the corresponding value
in <code>observed</code> will be equal to the factor level referenced in
<code>predicted_label</code>.</p>
</td></tr>
<tr><td><code id="assert_input_nominal_+3A_predicted_label">predicted_label</code></td>
<td>
<p>Unordered factor of length N with N levels, where N
is the number of possible outcomes the observed values can assume.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_input_ordinal'>Assert that inputs are correct for ordinal forecasts</h2><span id='topic+assert_input_ordinal'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring ordinal forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_input_ordinal(observed, predicted, predicted_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_input_ordinal_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be an ordered factor of length n
with N levels holding the observed values. n is the number of observations
and N is the number of possible outcomes the observed values can assume.</p>
</td></tr>
<tr><td><code id="assert_input_ordinal_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be nxN matrix of predicted
probabilities, n (number of rows) being the number of data points and N
(number of columns) the number of possible outcomes the observed values
can assume.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.
Values represent the probability that the corresponding value
in <code>observed</code> will be equal to factor level referenced in <code>predicted_label</code>.</p>
</td></tr>
<tr><td><code id="assert_input_ordinal_+3A_predicted_label">predicted_label</code></td>
<td>
<p>Ordered factor of length N with N levels, where N is
the number of possible outcomes the observed values can assume.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_input_point'>Assert that inputs are correct for point forecast</h2><span id='topic+assert_input_point'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring point forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_input_point(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_input_point_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="assert_input_point_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
predicted values of size n.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_input_quantile'>Assert that inputs are correct for quantile-based forecast</h2><span id='topic+assert_input_quantile'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring quantile-based forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_input_quantile(
  observed,
  predicted,
  quantile_level,
  unique_quantile_levels = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_input_quantile_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="assert_input_quantile_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be nxN matrix of predictive
quantiles, n (number of rows) being the number of data points and N
(number of columns) the number of quantiles per forecast.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.</p>
</td></tr>
<tr><td><code id="assert_input_quantile_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Input to be checked. Should be a vector of size N that
denotes the quantile levels corresponding to the columns of the prediction
matrix.</p>
</td></tr>
<tr><td><code id="assert_input_quantile_+3A_unique_quantile_levels">unique_quantile_levels</code></td>
<td>
<p>Whether the quantile levels are required to be
unique (<code>TRUE</code>, the default) or not (<code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_input_sample'>Assert that inputs are correct for sample-based forecast</h2><span id='topic+assert_input_sample'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the requirements for
scoring sample-based forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_input_sample(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_input_sample_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="assert_input_sample_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be a numeric nxN matrix of
predictive samples, n (number of rows) being the number of data points and
N (number of columns) the number of samples per forecast.
If <code>observed</code> is just a single number, then predicted values can just be a
vector of size N.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='assert_scores'>Validate an object of class <code>scores</code></h2><span id='topic+assert_scores'></span>

<h3>Description</h3>

<p>This function validates an object of class <code>scores</code>, checking
that it has the correct class and that it has a <code>metrics</code> attribute.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_scores(scores)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assert_scores_+3A_scores">scores</code></td>
<td>
<p>A data.table or similar with scores as produced by <code><a href="#topic+score">score()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns <code>NULL</code> invisibly
</p>

<hr>
<h2 id='bias_quantile'>Determines bias of quantile forecasts</h2><span id='topic+bias_quantile'></span>

<h3>Description</h3>

<p>Determines bias from quantile forecasts. For an increasing number of
quantiles this measure converges against the sample based bias version
for integer and continuous forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bias_quantile(observed, predicted, quantile_level, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bias_quantile_+3A_observed">observed</code></td>
<td>
<p>Numeric vector of size n with the observed values.</p>
</td></tr>
<tr><td><code id="bias_quantile_+3A_predicted">predicted</code></td>
<td>
<p>Numeric nxN matrix of predictive
quantiles, n (number of rows) being the number of forecasts (corresponding
to the number of observed values) and N
(number of columns) the number of quantiles per forecast.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.</p>
</td></tr>
<tr><td><code id="bias_quantile_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Vector of of size N with the quantile levels
for which predictions were made. Note that if this does not contain the
median (0.5) then the median is imputed as being the mean of the two
innermost quantiles.</p>
</td></tr>
<tr><td><code id="bias_quantile_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For quantile forecasts, bias is measured as
</p>
<p style="text-align: center;"><code class="reqn">
B_t = (1 - 2 \cdot \max \{i | q_{t,i} \in Q_t \land q_{t,i} \leq x_t\})
 \mathbf{1}( x_t \leq q_{t, 0.5}) \\
+ (1 - 2 \cdot \min \{i | q_{t,i} \in Q_t \land q_{t,i} \geq x_t\})
 1( x_t \geq q_{t, 0.5}),</code>
</p>

<p>where <code class="reqn">Q_t</code> is the set of quantiles that form the predictive
distribution at time <code class="reqn">t</code> and <code class="reqn">x_t</code> is the observed value. For
consistency, we define <code class="reqn">Q_t</code> such that it always includes the element
<code class="reqn">q_{t, 0} = - \infty</code> and <code class="reqn">q_{t,1} = \infty</code>.
<code class="reqn">1()</code> is the indicator function that is <code class="reqn">1</code> if the
condition is satisfied and <code class="reqn">0</code> otherwise.
</p>
<p>In clearer terms, bias <code class="reqn">B_t</code> is:
</p>

<ul>
<li> <p><code class="reqn">1 - 2 \cdot</code> the maximum percentile rank for which the corresponding
quantile is still smaller than or equal to the observed value,
<em>if the observed value is smaller than the median of the predictive
distribution.</em>
</p>
</li>
<li> <p><code class="reqn">1 - 2 \cdot</code> the minimum percentile rank for which the corresponding
quantile is still larger than or equal to the observed value <em>if the observed
value is larger
than the median of the predictive distribution.</em>.
</p>
</li>
<li> <p><code class="reqn">0</code> <em>if the observed value is exactly the median</em> (both terms cancel
out)
</p>
</li></ul>

<p>Bias can assume values between -1 and 1 and is 0 ideally (i.e. unbiased).
</p>
<p>Note that if the given quantiles do not contain the median, the median is
imputed as a linear interpolation of the two innermost quantiles. If the
median is not available and cannot be imputed, an error will be thrown.
Note that in order to compute bias, quantiles must be non-decreasing with
increasing quantile levels.
</p>
<p>For a large enough number of quantiles, the
percentile rank will equal the proportion of predictive samples below the
observed value, and the bias metric coincides with the one for
continuous forecasts (see <code><a href="#topic+bias_sample">bias_sample()</a></code>).
</p>


<h3>Value</h3>

<p>scalar with the quantile bias for a single quantile prediction
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-quantile.png" style="width:750px;max-width:100%;" alt="metrics-quantile.png" />
</div><p>
Overview of required input format for quantile-based forecasts


</p>


<h3>Examples</h3>

<pre><code class='language-R'>predicted &lt;- matrix(c(1.5:23.5, 3.3:25.3), nrow = 2, byrow = TRUE)
quantile_level &lt;- c(0.01, 0.025, seq(0.05, 0.95, 0.05), 0.975, 0.99)
observed &lt;- c(15, 12.4)
bias_quantile(observed, predicted, quantile_level)
</code></pre>

<hr>
<h2 id='bias_quantile_single_vector'>Compute bias for a single vector of quantile predictions</h2><span id='topic+bias_quantile_single_vector'></span>

<h3>Description</h3>

<p>Internal function to compute bias for a single observed value,
a vector of predicted values and a vector of quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bias_quantile_single_vector(observed, predicted, quantile_level, na.rm)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bias_quantile_single_vector_+3A_observed">observed</code></td>
<td>
<p>Scalar with the observed value.</p>
</td></tr>
<tr><td><code id="bias_quantile_single_vector_+3A_predicted">predicted</code></td>
<td>
<p>Vector of length N (corresponding to the number of
quantiles) that holds predictions.</p>
</td></tr>
<tr><td><code id="bias_quantile_single_vector_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Vector of of size N with the quantile levels
for which predictions were made. Note that if this does not contain the
median (0.5) then the median is imputed as being the mean of the two
innermost quantiles.</p>
</td></tr>
<tr><td><code id="bias_quantile_single_vector_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>scalar with the quantile bias for a single quantile prediction
</p>

<hr>
<h2 id='bias_sample'>Determine bias of forecasts</h2><span id='topic+bias_sample'></span>

<h3>Description</h3>

<p>Determines bias from predictive Monte-Carlo samples. The function
automatically recognises whether forecasts are continuous or
integer valued and adapts the Bias function accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bias_sample(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bias_sample_+3A_observed">observed</code></td>
<td>
<p>A vector with observed values of size n</p>
</td></tr>
<tr><td><code id="bias_sample_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive samples, n (number of rows) being
the number of data points and N (number of columns) the number of Monte
Carlo samples. Alternatively, <code>predicted</code> can just be a vector of size n.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For continuous forecasts, Bias is measured as
</p>
<p style="text-align: center;"><code class="reqn">
B_t (P_t, x_t) = 1 - 2 * (P_t (x_t))
</code>
</p>

<p>where <code class="reqn">P_t</code> is the empirical cumulative distribution function of the
prediction for the observed value <code class="reqn">x_t</code>. Computationally, <code class="reqn">P_t (x_t)</code> is
just calculated as the fraction of predictive samples for <code class="reqn">x_t</code>
that are smaller than <code class="reqn">x_t</code>.
</p>
<p>For integer valued forecasts, Bias is measured as
</p>
<p style="text-align: center;"><code class="reqn">
B_t (P_t, x_t) = 1 - (P_t (x_t) + P_t (x_t + 1))
</code>
</p>

<p>to adjust for the integer nature of the forecasts.
</p>
<p>In both cases, Bias can assume values between
-1 and 1 and is 0 ideally.
</p>


<h3>Value</h3>

<p>Numeric vector of length n with the biases of the predictive samples with
respect to the observed values.
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>


<h3>References</h3>

<p>The integer valued Bias function is discussed in
Assessing the performance of real-time epidemic forecasts: A case study of
Ebola in the Western Area region of Sierra Leone, 2014-15 Funk S, Camacho A,
Kucharski AJ, Lowe R, Eggo RM, et al. (2019) Assessing the performance of
real-time epidemic forecasts: A case study of Ebola in the Western Area
region of Sierra Leone, 2014-15. PLOS Computational Biology 15(2): e1006785.
<a href="https://doi.org/10.1371/journal.pcbi.1006785">doi:10.1371/journal.pcbi.1006785</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## integer valued forecasts
observed &lt;- rpois(30, lambda = 1:30)
predicted &lt;- replicate(200, rpois(n = 30, lambda = 1:30))
bias_sample(observed, predicted)

## continuous forecasts
observed &lt;- rnorm(30, mean = 1:30)
predicted &lt;- replicate(200, rnorm(30, mean = 1:30))
bias_sample(observed, predicted)
</code></pre>

<hr>
<h2 id='check_columns_present'>Check column names are present in a data.frame</h2><span id='topic+check_columns_present'></span>

<h3>Description</h3>

<p>The functions loops over the column names and checks whether they are
present. If an issue is encountered, the function immediately stops
and returns a message with the first issue encountered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_columns_present(data, columns)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_columns_present_+3A_data">data</code></td>
<td>
<p>A data.frame or similar to be checked</p>
</td></tr>
<tr><td><code id="check_columns_present_+3A_columns">columns</code></td>
<td>
<p>A character vector of column names to check</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_dims_ok_point'>Check Inputs Have Matching Dimensions</h2><span id='topic+check_dims_ok_point'></span>

<h3>Description</h3>

<p>Function assesses whether input dimensions match. In the
following, n is the number of observations / forecasts. Scalar values may
be repeated to match the length of the other input.
Allowed options are therefore:
</p>

<ul>
<li> <p><code>observed</code> is vector of length 1 or length n
</p>
</li>
<li> <p><code>predicted</code> is:
</p>

<ul>
<li><p> a vector of of length 1 or length n
</p>
</li>
<li><p> a matrix with n rows and 1 column
</p>
</li></ul>

</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>check_dims_ok_point(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_dims_ok_point_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a factor of length n with
exactly two levels, holding the observed values.
The highest factor level is assumed to be the reference level. This means
that <code>predicted</code> represents the probability that the observed value is
equal to the highest factor level.</p>
</td></tr>
<tr><td><code id="check_dims_ok_point_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. <code>predicted</code> should be a vector of
length n, holding probabilities. Alternatively, <code>predicted</code> can be a matrix
of size n x 1. Values represent the probability that
the corresponding value in <code>observed</code> will be equal to the highest
available factor level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_duplicates'>Check that there are no duplicate forecasts</h2><span id='topic+check_duplicates'></span>

<h3>Description</h3>

<p>Runs <code><a href="#topic+get_duplicate_forecasts">get_duplicate_forecasts()</a></code> and returns a message if an issue is
encountered
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_duplicates(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_duplicates_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_input_binary'>Check that inputs are correct for binary forecast</h2><span id='topic+check_input_binary'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring binary forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_input_binary(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_input_binary_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a factor of length n with
exactly two levels, holding the observed values.
The highest factor level is assumed to be the reference level. This means
that <code>predicted</code> represents the probability that the observed value is
equal to the highest factor level.</p>
</td></tr>
<tr><td><code id="check_input_binary_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. <code>predicted</code> should be a vector of
length n, holding probabilities. Alternatively, <code>predicted</code> can be a matrix
of size n x 1. Values represent the probability that
the corresponding value in <code>observed</code> will be equal to the highest
available factor level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_input_interval'>Check that inputs are correct for interval-based forecast</h2><span id='topic+check_input_interval'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring interval-based forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_input_interval(observed, lower, upper, interval_range)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_input_interval_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="check_input_interval_+3A_lower">lower</code></td>
<td>
<p>Input to be checked. Should be a numeric vector of size n that
holds the predicted value for the lower bounds of the prediction intervals.</p>
</td></tr>
<tr><td><code id="check_input_interval_+3A_upper">upper</code></td>
<td>
<p>Input to be checked. Should be a numeric vector of size n that
holds the predicted value for the upper bounds of the prediction intervals.</p>
</td></tr>
<tr><td><code id="check_input_interval_+3A_interval_range">interval_range</code></td>
<td>
<p>Input to be checked. Should be a vector of size n that
denotes the interval range in percent. E.g. a value of 50 denotes a
(25%, 75%) prediction interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_input_point'>Check that inputs are correct for point forecast</h2><span id='topic+check_input_point'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring point forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_input_point(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_input_point_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="check_input_point_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
predicted values of size n.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_input_quantile'>Check that inputs are correct for quantile-based forecast</h2><span id='topic+check_input_quantile'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the
requirements for scoring quantile-based forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_input_quantile(observed, predicted, quantile_level)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_input_quantile_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="check_input_quantile_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be nxN matrix of predictive
quantiles, n (number of rows) being the number of data points and N
(number of columns) the number of quantiles per forecast.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.</p>
</td></tr>
<tr><td><code id="check_input_quantile_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Input to be checked. Should be a vector of size N that
denotes the quantile levels corresponding to the columns of the prediction
matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_input_sample'>Check that inputs are correct for sample-based forecast</h2><span id='topic+check_input_sample'></span>

<h3>Description</h3>

<p>Function assesses whether the inputs correspond to the requirements for
scoring sample-based forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_input_sample(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_input_sample_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="check_input_sample_+3A_predicted">predicted</code></td>
<td>
<p>Input to be checked. Should be a numeric nxN matrix of
predictive samples, n (number of rows) being the number of data points and
N (number of columns) the number of samples per forecast.
If <code>observed</code> is just a single number, then predicted values can just be a
vector of size N.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_number_per_forecast'>Check that all forecasts have the same number of rows</h2><span id='topic+check_number_per_forecast'></span>

<h3>Description</h3>

<p>Helper function that checks the number of rows (corresponding e.g to
quantiles or samples) per forecast.
If the number of quantiles or samples is the same for all forecasts, it
returns TRUE and a string with an error message otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_number_per_forecast(data, forecast_unit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_number_per_forecast_+3A_data">data</code></td>
<td>
<p>A data.frame or similar to be checked</p>
</td></tr>
<tr><td><code id="check_number_per_forecast_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>Character vector denoting the unit of a single forecast.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_numeric_vector'>Check whether an input is an atomic vector of mode 'numeric'</h2><span id='topic+check_numeric_vector'></span>

<h3>Description</h3>

<p>Helper function to check whether an input is a numeric vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_numeric_vector(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_numeric_vector_+3A_x">x</code></td>
<td>
<p>input to check</p>
</td></tr>
<tr><td><code id="check_numeric_vector_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="checkmate.html#topic+checkNumeric">checkmate::check_numeric</a></code>
</p>

<dl>
<dt><code>lower</code></dt><dd><p>[<code>numeric(1)</code>]<br />
Lower value all elements of <code>x</code> must be greater than or equal to.</p>
</dd>
<dt><code>upper</code></dt><dd><p>[<code>numeric(1)</code>]<br />
Upper value all elements of <code>x</code> must be lower than or equal to.</p>
</dd>
<dt><code>finite</code></dt><dd><p>[<code>logical(1)</code>]<br />
Check for only finite values? Default is <code>FALSE</code>.</p>
</dd>
<dt><code>any.missing</code></dt><dd><p>[<code>logical(1)</code>]<br />
Are vectors with missing values allowed? Default is <code>TRUE</code>.</p>
</dd>
<dt><code>all.missing</code></dt><dd><p>[<code>logical(1)</code>]<br />
Are vectors with no non-missing values allowed? Default is <code>TRUE</code>.
Note that empty vectors do not have non-missing values.</p>
</dd>
<dt><code>len</code></dt><dd><p>[<code>integer(1)</code>]<br />
Exact expected length of <code>x</code>.</p>
</dd>
<dt><code>min.len</code></dt><dd><p>[<code>integer(1)</code>]<br />
Minimal length of <code>x</code>.</p>
</dd>
<dt><code>max.len</code></dt><dd><p>[<code>integer(1)</code>]<br />
Maximal length of <code>x</code>.</p>
</dd>
<dt><code>unique</code></dt><dd><p>[<code>logical(1)</code>]<br />
Must all values be unique? Default is <code>FALSE</code>.</p>
</dd>
<dt><code>sorted</code></dt><dd><p>[<code>logical(1)</code>]<br />
Elements must be sorted in ascending order. Missing values are ignored.</p>
</dd>
<dt><code>names</code></dt><dd><p>[<code>character(1)</code>]<br />
Check for names. See <code><a href="checkmate.html#topic+checkNamed">checkNamed</a></code> for possible values.
Default is &ldquo;any&rdquo; which performs no check at all.
Note that you can use <code><a href="checkmate.html#topic+checkSubset">checkSubset</a></code> to check for a specific set of names.</p>
</dd>
<dt><code>typed.missing</code></dt><dd><p>[<code>logical(1)</code>]<br />
If set to <code>FALSE</code> (default), all types of missing values (<code>NA</code>, <code>NA_integer_</code>,
<code>NA_real_</code>, <code>NA_character_</code> or <code>NA_character_</code>) as well as empty vectors are allowed
while type-checking atomic input.
Set to <code>TRUE</code> to enable strict type checking.</p>
</dd>
<dt><code>null.ok</code></dt><dd><p>[<code>logical(1)</code>]<br />
If set to <code>TRUE</code>, <code>x</code> may also be <code>NULL</code>.
In this case only a type check of <code>x</code> is performed, all additional checks are disabled.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='check_try'>Helper function to convert assert statements into checks</h2><span id='topic+check_try'></span>

<h3>Description</h3>

<p>Tries to execute an expression. Internally, this is used to
see whether assertions fail when checking inputs (i.e. to convert an
<code style="white-space: pre;">&#8288;assert_*()&#8288;</code> statement into a check). If the expression fails, the error
message is returned. If the expression succeeds, <code>TRUE</code> is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_try(expr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_try_+3A_expr">expr</code></td>
<td>
<p>an expression to be evaluated</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='clean_forecast'>Clean forecast object</h2><span id='topic+clean_forecast'></span>

<h3>Description</h3>

<p>The function makes it possible to silently validate an object. In addition,
it can return a copy of the data and remove rows with missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_forecast(forecast, copy = FALSE, na.omit = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clean_forecast_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
<tr><td><code id="clean_forecast_+3A_copy">copy</code></td>
<td>
<p>Logical, default is <code>FALSE</code>. If <code>TRUE</code>, a copy of the input data
is created.</p>
</td></tr>
<tr><td><code id="clean_forecast_+3A_na.omit">na.omit</code></td>
<td>
<p>Logical, default is <code>FALSE</code>. If <code>TRUE</code>, rows with missing
values are removed.</p>
</td></tr>
</table>

<hr>
<h2 id='compare_forecasts'>Compare a subset of common forecasts</h2><span id='topic+compare_forecasts'></span>

<h3>Description</h3>

<p>This function compares two comparators based on the subset of forecasts for which
both comparators have made a prediction. It gets called
from <code><a href="#topic+pairwise_comparison_one_group">pairwise_comparison_one_group()</a></code>, which handles the
comparison of multiple comparators on a single set of forecasts (there are no
subsets of forecasts to be distinguished). <code><a href="#topic+pairwise_comparison_one_group">pairwise_comparison_one_group()</a></code>
in turn gets called from from <code><a href="#topic+get_pairwise_comparisons">get_pairwise_comparisons()</a></code> which can handle
pairwise comparisons for a set of forecasts with multiple subsets, e.g.
pairwise comparisons for one set of forecasts, but done separately for two
different forecast targets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_forecasts(
  scores,
  compare = "model",
  name_comparator1,
  name_comparator2,
  metric,
  one_sided = FALSE,
  test_type = c("non_parametric", "permutation"),
  n_permutations = 999
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_forecasts_+3A_scores">scores</code></td>
<td>
<p>An object of class <code>scores</code> (a data.table with
scores and an additional attribute <code>metrics</code> as produced by <code><a href="#topic+score">score()</a></code>).</p>
</td></tr>
<tr><td><code id="compare_forecasts_+3A_compare">compare</code></td>
<td>
<p>Character vector with a single colum name that defines the
elements for the pairwise comparison. For example, if this is set to
&quot;model&quot; (the default), then elements of the &quot;model&quot; column will be
compared.</p>
</td></tr>
<tr><td><code id="compare_forecasts_+3A_name_comparator1">name_comparator1</code></td>
<td>
<p>Character, name of the first comparator</p>
</td></tr>
<tr><td><code id="compare_forecasts_+3A_name_comparator2">name_comparator2</code></td>
<td>
<p>Character, name of the comparator to compare against</p>
</td></tr>
<tr><td><code id="compare_forecasts_+3A_metric">metric</code></td>
<td>
<p>A string with the name of the metric for which
a relative skill shall be computed. By default this is either &quot;crps&quot;,
&quot;wis&quot; or &quot;brier_score&quot; if any of these are available.</p>
</td></tr>
<tr><td><code id="compare_forecasts_+3A_one_sided">one_sided</code></td>
<td>
<p>Boolean, default is <code>FALSE</code>, whether two conduct a one-sided
instead of a two-sided test to determine significance in a pairwise
comparison.</p>
</td></tr>
<tr><td><code id="compare_forecasts_+3A_test_type">test_type</code></td>
<td>
<p>Character, either &quot;non_parametric&quot; (the default) or
&quot;permutation&quot;. This determines which kind of test shall be conducted to
determine p-values.</p>
</td></tr>
<tr><td><code id="compare_forecasts_+3A_n_permutations">n_permutations</code></td>
<td>
<p>Numeric, the number of permutations for a
permutation test. Default is 999.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with mean score ratios and p-values for the comparison
between two comparators
</p>


<h3>Author(s)</h3>

<p>Johannes Bracher, <a href="mailto:johannes.bracher@kit.edu">johannes.bracher@kit.edu</a>
</p>
<p>Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a>
</p>

<hr>
<h2 id='crps_sample'>(Continuous) ranked probability score</h2><span id='topic+crps_sample'></span><span id='topic+dispersion_sample'></span><span id='topic+overprediction_sample'></span><span id='topic+underprediction_sample'></span>

<h3>Description</h3>

<p>Wrapper around the <code><a href="scoringRules.html#topic+scores_sample_univ">crps_sample()</a></code>
function from the
<span class="pkg">scoringRules</span> package. Can be used for continuous as well as integer
valued forecasts
</p>
<p>The Continuous ranked probability score (CRPS) can be interpreted as the sum
of three components: overprediction,  underprediction and dispersion.
&quot;Dispersion&quot; is defined as the CRPS of the median forecast $m$. If an
observation $y$ is greater than $m$ then overpredictoin is defined as the
CRPS of the forecast for $y$ minus the dispersion component, and
underprediction is zero. If, on the other hand, $y&lt;m$ then underprediction
is defined as the CRPS of the forecast for $y$ minus the dispersion
component, and overprediction is zero.
</p>
<p>The overprediction, underprediction and dispersion components correspond to
those of the <code><a href="#topic+wis">wis()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_sample(observed, predicted, separate_results = FALSE, ...)

dispersion_sample(observed, predicted, ...)

overprediction_sample(observed, predicted, ...)

underprediction_sample(observed, predicted, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crps_sample_+3A_observed">observed</code></td>
<td>
<p>A vector with observed values of size n</p>
</td></tr>
<tr><td><code id="crps_sample_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive samples, n (number of rows) being
the number of data points and N (number of columns) the number of Monte
Carlo samples. Alternatively, <code>predicted</code> can just be a vector of size n.</p>
</td></tr>
<tr><td><code id="crps_sample_+3A_separate_results">separate_results</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default is <code>FALSE</code>), then the
separate parts of the CRPS (dispersion penalty, penalties for
over- and under-prediction) get returned as separate elements of a list.
If you want a <code>data.frame</code> instead, simply call <code><a href="base.html#topic+as.data.frame">as.data.frame()</a></code> on the
output.</p>
</td></tr>
<tr><td><code id="crps_sample_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to <code>crps_sample()</code> from functions
<code>overprediction_sample()</code>, <code>underprediction_sample()</code> and
<code>dispersion_sample()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with scores.
</p>
<p><code>dispersion_sample()</code>: a numeric vector with dispersion values (one per
observation).
</p>
<p><code>overprediction_quantile()</code>: a numeric vector with overprediction values
(one per observation).
</p>
<p><code>underprediction_quantile()</code>: a numeric vector with underprediction values (one per
observation).
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>


<h3>References</h3>

<p>Alexander Jordan, Fabian Krger, Sebastian Lerch, Evaluating Probabilistic
Forecasts with scoringRules, <a href="https://www.jstatsoft.org/article/view/v090i12">https://www.jstatsoft.org/article/view/v090i12</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- rpois(30, lambda = 1:30)
predicted &lt;- replicate(200, rpois(n = 30, lambda = 1:30))
crps_sample(observed, predicted)
</code></pre>

<hr>
<h2 id='document_assert_functions'>Documentation template for assert functions</h2><span id='topic+document_assert_functions'></span>

<h3>Description</h3>

<p>Documentation template for assert functions
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="document_assert_functions_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL invisibly if the assertion was successful and throws an
error otherwise.
</p>

<hr>
<h2 id='document_check_functions'>Documentation template for check functions</h2><span id='topic+document_check_functions'></span>

<h3>Description</h3>

<p>Documentation template for check functions
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="document_check_functions_+3A_data">data</code></td>
<td>
<p>A data.frame or similar to be checked</p>
</td></tr>
<tr><td><code id="document_check_functions_+3A_observed">observed</code></td>
<td>
<p>Input to be checked. Should be a numeric vector with the
observed values of size n.</p>
</td></tr>
<tr><td><code id="document_check_functions_+3A_columns">columns</code></td>
<td>
<p>A character vector of column names to check</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and a string with an
error message otherwise.
</p>

<hr>
<h2 id='document_test_functions'>Documentation template for test functions</h2><span id='topic+document_test_functions'></span>

<h3>Description</h3>

<p>Documentation template for test functions
</p>


<h3>Value</h3>

<p>Returns TRUE if the check was successful and FALSE otherwise
</p>

<hr>
<h2 id='dss_sample'>Dawid-Sebastiani score</h2><span id='topic+dss_sample'></span>

<h3>Description</h3>

<p>Wrapper around the <code><a href="scoringRules.html#topic+scores_sample_univ">dss_sample()</a></code>
function from the
<span class="pkg">scoringRules</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dss_sample(observed, predicted, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dss_sample_+3A_observed">observed</code></td>
<td>
<p>A vector with observed values of size n</p>
</td></tr>
<tr><td><code id="dss_sample_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive samples, n (number of rows) being
the number of data points and N (number of columns) the number of Monte
Carlo samples. Alternatively, <code>predicted</code> can just be a vector of size n.</p>
</td></tr>
<tr><td><code id="dss_sample_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to
<a href="scoringRules.html#topic+scores_sample_univ">dss_sample()</a> from the scoringRules package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with scores.
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>


<h3>References</h3>

<p>Alexander Jordan, Fabian Krger, Sebastian Lerch, Evaluating Probabilistic
Forecasts with scoringRules, <a href="https://www.jstatsoft.org/article/view/v090i12">https://www.jstatsoft.org/article/view/v090i12</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- rpois(30, lambda = 1:30)
predicted &lt;- replicate(200, rpois(n = 30, lambda = 1:30))
dss_sample(observed, predicted)
</code></pre>

<hr>
<h2 id='ensure_data.table'>Ensure that an object is a <code>data.table</code></h2><span id='topic+ensure_data.table'></span>

<h3>Description</h3>

<p>This function ensures that an object is a <code style="white-space: pre;">&#8288;data table&#8288;</code>.
If the object is not a data table, it is converted to one. If the object
is a data table, a copy of the object is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ensure_data.table(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ensure_data.table_+3A_data">data</code></td>
<td>
<p>An object to ensure is a data table.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table/a copy of an existing data.table.
</p>

<hr>
<h2 id='example_binary'>Binary forecast example data</h2><span id='topic+example_binary'></span>

<h3>Description</h3>

<p>A data set with binary predictions for COVID-19 cases and deaths constructed
from data submitted to the European Forecast Hub.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_binary
</code></pre>


<h3>Format</h3>

<p>An object of class <code>forecast_binary</code> (see <code><a href="#topic+as_forecast_binary">as_forecast_binary()</a></code>)
with the following columns:
</p>

<dl>
<dt>location</dt><dd><p>the country for which a prediction was made</p>
</dd>
<dt>location_name</dt><dd><p>name of the country for which a prediction was made</p>
</dd>
<dt>target_end_date</dt><dd><p>the date for which a prediction was made</p>
</dd>
<dt>target_type</dt><dd><p>the target to be predicted (cases or deaths)</p>
</dd>
<dt>observed</dt><dd><p>A factor with observed values</p>
</dd>
<dt>forecast_date</dt><dd><p>the date on which a prediction was made</p>
</dd>
<dt>model</dt><dd><p>name of the model that generated the forecasts</p>
</dd>
<dt>horizon</dt><dd><p>forecast horizon in weeks</p>
</dd>
<dt>predicted</dt><dd><p>predicted value</p>
</dd>
</dl>



<h3>Details</h3>

<p>Predictions in the data set were constructed based on the continuous example
data by looking at the number of samples below the mean prediction.
The outcome was constructed as whether or not the actually
observed value was below or above that mean prediction.
This should not be understood as sound statistical practice, but rather
as a practical way to create an example data set.
</p>
<p>The data was created using the script create-example-data.R in the inst/
folder (or the top level folder in a compiled package).
</p>


<h3>Source</h3>

<p><a href="https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/">https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/</a>
</p>

<hr>
<h2 id='example_nominal'>Nominal example data</h2><span id='topic+example_nominal'></span>

<h3>Description</h3>

<p>A data set with predictions for COVID-19 cases and deaths submitted to the
European Forecast Hub.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_nominal
</code></pre>


<h3>Format</h3>

<p>An object of class <code>forecast_nominal</code>
(see <code><a href="#topic+as_forecast_nominal">as_forecast_nominal()</a></code>) with the following columns:
</p>

<dl>
<dt>location</dt><dd><p>the country for which a prediction was made</p>
</dd>
<dt>target_end_date</dt><dd><p>the date for which a prediction was made</p>
</dd>
<dt>target_type</dt><dd><p>the target to be predicted (cases or deaths)</p>
</dd>
<dt>observed</dt><dd><p>Numeric: observed values</p>
</dd>
<dt>location_name</dt><dd><p>name of the country for which a prediction was made</p>
</dd>
<dt>forecast_date</dt><dd><p>the date on which a prediction was made</p>
</dd>
<dt>predicted_label</dt><dd><p>outcome that a probabilty corresponds to</p>
</dd>
<dt>predicted</dt><dd><p>predicted value</p>
</dd>
<dt>model</dt><dd><p>name of the model that generated the forecasts</p>
</dd>
<dt>horizon</dt><dd><p>forecast horizon in weeks</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data was created using the script create-example-data.R in the inst/
folder (or the top level folder in a compiled package).
</p>


<h3>Source</h3>

<p><a href="https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/">https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/</a>
</p>

<hr>
<h2 id='example_ordinal'>Ordinal example data</h2><span id='topic+example_ordinal'></span>

<h3>Description</h3>

<p>A data set with predictions for COVID-19 cases and deaths submitted to the
European Forecast Hub.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_ordinal
</code></pre>


<h3>Format</h3>

<p>An object of class <code>forecast_ordinal</code>
(see <code><a href="#topic+as_forecast_ordinal">as_forecast_ordinal()</a></code>) with the following columns:
</p>

<dl>
<dt>location</dt><dd><p>the country for which a prediction was made</p>
</dd>
<dt>target_end_date</dt><dd><p>the date for which a prediction was made</p>
</dd>
<dt>target_type</dt><dd><p>the target to be predicted (cases or deaths)</p>
</dd>
<dt>observed</dt><dd><p>Numeric: observed values</p>
</dd>
<dt>location_name</dt><dd><p>name of the country for which a prediction was made</p>
</dd>
<dt>forecast_date</dt><dd><p>the date on which a prediction was made</p>
</dd>
<dt>predicted_label</dt><dd><p>outcome that a probabilty corresponds to</p>
</dd>
<dt>predicted</dt><dd><p>predicted value</p>
</dd>
<dt>model</dt><dd><p>name of the model that generated the forecasts</p>
</dd>
<dt>horizon</dt><dd><p>forecast horizon in weeks</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data was created using the script create-example-data.R in the inst/
folder (or the top level folder in a compiled package).
</p>


<h3>Source</h3>

<p><a href="https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/">https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/</a>
</p>

<hr>
<h2 id='example_point'>Point forecast example data</h2><span id='topic+example_point'></span>

<h3>Description</h3>

<p>A data set with predictions for COVID-19 cases and deaths submitted to the
European Forecast Hub. This data set is like the quantile example data, only
that the median has been replaced by a point forecast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_point
</code></pre>


<h3>Format</h3>

<p>An object of class <code>forecast_point</code> (see <code><a href="#topic+as_forecast_point">as_forecast_point()</a></code>)
with the following columns:
</p>

<dl>
<dt>location</dt><dd><p>the country for which a prediction was made</p>
</dd>
<dt>target_end_date</dt><dd><p>the date for which a prediction was made</p>
</dd>
<dt>target_type</dt><dd><p>the target to be predicted (cases or deaths)</p>
</dd>
<dt>observed</dt><dd><p>observed values</p>
</dd>
<dt>location_name</dt><dd><p>name of the country for which a prediction was made</p>
</dd>
<dt>forecast_date</dt><dd><p>the date on which a prediction was made</p>
</dd>
<dt>predicted</dt><dd><p>predicted value</p>
</dd>
<dt>model</dt><dd><p>name of the model that generated the forecasts</p>
</dd>
<dt>horizon</dt><dd><p>forecast horizon in weeks</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data was created using the script create-example-data.R in the inst/
folder (or the top level folder in a compiled package).
</p>


<h3>Source</h3>

<p><a href="https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/">https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/</a>
</p>

<hr>
<h2 id='example_quantile'>Quantile example data</h2><span id='topic+example_quantile'></span>

<h3>Description</h3>

<p>A data set with predictions for COVID-19 cases and deaths submitted to the
European Forecast Hub.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_quantile
</code></pre>


<h3>Format</h3>

<p>An object of class <code>forecast_quantile</code>
(see <code><a href="#topic+as_forecast_quantile">as_forecast_quantile()</a></code>) with the following columns:
</p>

<dl>
<dt>location</dt><dd><p>the country for which a prediction was made</p>
</dd>
<dt>target_end_date</dt><dd><p>the date for which a prediction was made</p>
</dd>
<dt>target_type</dt><dd><p>the target to be predicted (cases or deaths)</p>
</dd>
<dt>observed</dt><dd><p>Numeric: observed values</p>
</dd>
<dt>location_name</dt><dd><p>name of the country for which a prediction was made</p>
</dd>
<dt>forecast_date</dt><dd><p>the date on which a prediction was made</p>
</dd>
<dt>quantile_level</dt><dd><p>quantile level of the corresponding prediction</p>
</dd>
<dt>predicted</dt><dd><p>predicted value</p>
</dd>
<dt>model</dt><dd><p>name of the model that generated the forecasts</p>
</dd>
<dt>horizon</dt><dd><p>forecast horizon in weeks</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data was created using the script create-example-data.R in the inst/
folder (or the top level folder in a compiled package).
</p>


<h3>Source</h3>

<p><a href="https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/">https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/</a>
</p>

<hr>
<h2 id='example_sample_continuous'>Continuous forecast example data</h2><span id='topic+example_sample_continuous'></span>

<h3>Description</h3>

<p>A data set with continuous predictions for COVID-19 cases and deaths
constructed from data submitted to the European Forecast Hub.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_sample_continuous
</code></pre>


<h3>Format</h3>

<p>An object of class <code>forecast_sample</code> (see <code><a href="#topic+as_forecast_sample">as_forecast_sample()</a></code>)
with the following columns:
</p>

<dl>
<dt>location</dt><dd><p>the country for which a prediction was made</p>
</dd>
<dt>target_end_date</dt><dd><p>the date for which a prediction was made</p>
</dd>
<dt>target_type</dt><dd><p>the target to be predicted (cases or deaths)</p>
</dd>
<dt>observed</dt><dd><p>observed values</p>
</dd>
<dt>location_name</dt><dd><p>name of the country for which a prediction was made</p>
</dd>
<dt>forecast_date</dt><dd><p>the date on which a prediction was made</p>
</dd>
<dt>model</dt><dd><p>name of the model that generated the forecasts</p>
</dd>
<dt>horizon</dt><dd><p>forecast horizon in weeks</p>
</dd>
<dt>predicted</dt><dd><p>predicted value</p>
</dd>
<dt>sample_id</dt><dd><p>id for the corresponding sample</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data was created using the script create-example-data.R in the inst/
folder (or the top level folder in a compiled package).
</p>


<h3>Source</h3>

<p><a href="https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/">https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/</a>
</p>

<hr>
<h2 id='example_sample_discrete'>Discrete forecast example data</h2><span id='topic+example_sample_discrete'></span>

<h3>Description</h3>

<p>A data set with integer predictions for COVID-19 cases and deaths
constructed from data submitted to the European Forecast Hub.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_sample_discrete
</code></pre>


<h3>Format</h3>

<p>An object of class <code>forecast_sample</code> (see <code><a href="#topic+as_forecast_sample">as_forecast_sample()</a></code>)
with the following columns:
</p>

<dl>
<dt>location</dt><dd><p>the country for which a prediction was made</p>
</dd>
<dt>target_end_date</dt><dd><p>the date for which a prediction was made</p>
</dd>
<dt>target_type</dt><dd><p>the target to be predicted (cases or deaths)</p>
</dd>
<dt>observed</dt><dd><p>observed values</p>
</dd>
<dt>location_name</dt><dd><p>name of the country for which a prediction was made</p>
</dd>
<dt>forecast_date</dt><dd><p>the date on which a prediction was made</p>
</dd>
<dt>model</dt><dd><p>name of the model that generated the forecasts</p>
</dd>
<dt>horizon</dt><dd><p>forecast horizon in weeks</p>
</dd>
<dt>predicted</dt><dd><p>predicted value</p>
</dd>
<dt>sample_id</dt><dd><p>id for the corresponding sample</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data was created using the script create-example-data.R in the inst/
folder (or the top level folder in a compiled package).
</p>


<h3>Source</h3>

<p><a href="https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/">https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/</a>
</p>

<hr>
<h2 id='forecast_types'>Documentation template for forecast types</h2><span id='topic+forecast_types'></span>

<h3>Description</h3>

<p>Documentation template for forecast types
</p>


<h3>Forecast unit</h3>

<p>In order to score forecasts, <code>scoringutils</code> needs to know which of the rows
of the data belong together and jointly form a single forecasts. This is
easy e.g. for point forecast, where there is one row per forecast. For
quantile or sample-based forecasts, however, there are multiple rows that
belong to a single forecast.
</p>
<p>The <em>forecast unit</em> or <em>unit of a single forecast</em> is then described by the
combination of columns that uniquely identify a single forecast.
For example, we could have forecasts made by different models in various
locations at different time points, each for several weeks into the future.
The forecast unit could then be described as
<code>forecast_unit = c("model", "location", "forecast_date", "forecast_horizon")</code>.
<code>scoringutils</code> automatically tries to determine the unit of a single
forecast. It uses all existing columns for this, which means that no columns
must be present that are unrelated to the forecast unit. As a very simplistic
example, if you had an additional row, &quot;even&quot;, that is one if the row number
is even and zero otherwise, then this would mess up scoring as <code>scoringutils</code>
then thinks that this column was relevant in defining the forecast unit.
</p>
<p>In order to avoid issues, we recommend setting the forecast unit explicitly,
using the <code>forecast_unit</code> argument. This will simply drop unneeded columns,
while making sure that all necessary, 'protected columns' like &quot;predicted&quot;
or &quot;observed&quot; are retained.
</p>

<hr>
<h2 id='geometric_mean'>Calculate geometric mean</h2><span id='topic+geometric_mean'></span>

<h3>Description</h3>

<p>Calculate geometric mean
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geometric_mean(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="geometric_mean_+3A_x">x</code></td>
<td>
<p>Numeric vector of values for which to calculate the geometric mean.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Used in <code><a href="#topic+get_pairwise_comparisons">get_pairwise_comparisons()</a></code>.
</p>


<h3>Value</h3>

<p>The geometric mean of the values in <code>x</code>. <code>NA</code> values are ignored.
</p>

<hr>
<h2 id='get_correlations'>Calculate correlation between metrics</h2><span id='topic+get_correlations'></span>

<h3>Description</h3>

<p>Calculate the correlation between different metrics for a data.frame of
scores as produced by <code><a href="#topic+score">score()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_correlations(scores, metrics = get_metrics.scores(scores), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_correlations_+3A_scores">scores</code></td>
<td>
<p>An object of class <code>scores</code> (a data.table with
scores and an additional attribute <code>metrics</code> as produced by <code><a href="#topic+score">score()</a></code>).</p>
</td></tr>
<tr><td><code id="get_correlations_+3A_metrics">metrics</code></td>
<td>
<p>A character vector with the metrics to show. If set to
<code>NULL</code> (default), all metrics present in <code>scores</code> will be shown.</p>
</td></tr>
<tr><td><code id="get_correlations_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass down to <code><a href="stats.html#topic+cor">cor()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>scores</code> (a data.table with an additional
attribute <code>metrics</code> holding the names of the scores) with correlations
between different metrics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr) # pipe operator

scores &lt;- example_quantile %&gt;%
 as_forecast_quantile() %&gt;%
 score()

get_correlations(scores)
</code></pre>

<hr>
<h2 id='get_coverage'>Get quantile and interval coverage values for quantile-based forecasts</h2><span id='topic+get_coverage'></span>

<h3>Description</h3>

<p>For a validated forecast object in a quantile-based format
(see <code><a href="#topic+as_forecast_quantile">as_forecast_quantile()</a></code> for more information), this function computes:
</p>

<ul>
<li><p> interval coverage of central prediction intervals
</p>
</li>
<li><p> quantile coverage for predictive quantiles
</p>
</li>
<li><p> the deviation between desired and actual coverage (both for interval and
quantile coverage)
</p>
</li></ul>

<p>Coverage values are computed for a specific level of grouping, as specified
in the <code>by</code> argument. By default, coverage values are computed per model.
</p>
<p><strong>Interval coverage</strong>
</p>
<p>Interval coverage for a given interval range is defined as the proportion of
observations that fall within the corresponding central prediction intervals.
Central prediction intervals are symmetric around the median and formed
by two quantiles that denote the lower and upper bound. For example, the 50%
central prediction interval is the interval between the 0.25 and 0.75
quantiles of the predictive distribution.
</p>
<p><strong>Quantile coverage</strong>
</p>
<p>Quantile coverage for a given quantile level is defined as the proportion of
observed values that are smaller than the corresponding predictive quantile.
For example, the 0.5 quantile coverage is the proportion of observed values
that are smaller than the 0.5 quantile of the predictive distribution.
Just as above, for a single observation and the quantile of a single
predictive distribution, the value will either be <code>TRUE</code> or <code>FALSE</code>.
</p>
<p><strong>Coverage deviation</strong>
</p>
<p>The coverage deviation is the difference between the desired coverage
(can be either interval or quantile coverage) and the
actual coverage. For example, if the desired coverage is 90% and the actual
coverage is 80%, the coverage deviation is -0.1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_coverage(forecast, by = "model")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_coverage_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
<tr><td><code id="get_coverage_+3A_by">by</code></td>
<td>
<p>character vector that denotes the level of grouping for which the
coverage values should be computed. By default (<code>"model"</code>), one coverage
value per model will be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with columns as specified in <code>by</code> and additional
columns for the coverage values described above
</p>
<p>a data.table with columns &quot;interval_coverage&quot;,
&quot;interval_coverage_deviation&quot;, &quot;quantile_coverage&quot;,
&quot;quantile_coverage_deviation&quot; and the columns specified in <code>by</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr) # pipe operator
example_quantile %&gt;%
  as_forecast_quantile() %&gt;%
  get_coverage(by = "model")
</code></pre>

<hr>
<h2 id='get_duplicate_forecasts'>Find duplicate forecasts</h2><span id='topic+get_duplicate_forecasts'></span>

<h3>Description</h3>

<p>Internal helper function to identify duplicate forecasts, i.e.
instances where there is more than one forecast for the same prediction
target.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_duplicate_forecasts(data, forecast_unit = NULL, counts = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_duplicate_forecasts_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="get_duplicate_forecasts_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>(optional) Name of the columns in <code>data</code> (after
any renaming of columns) that denote the unit of a
single forecast. See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for details.
If <code>NULL</code> (the default), all columns that are not required columns are
assumed to form the unit of a single forecast. If specified, all columns
that are not part of the forecast unit (or required columns) will be removed.</p>
</td></tr>
<tr><td><code id="get_duplicate_forecasts_+3A_counts">counts</code></td>
<td>
<p>Should the output show the number of duplicates per forecast
unit instead of the individual duplicated rows? Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with all rows for which a duplicate forecast was found
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example &lt;- rbind(example_quantile, example_quantile[1000:1010])
get_duplicate_forecasts(example)
</code></pre>

<hr>
<h2 id='get_forecast_counts'>Count number of available forecasts</h2><span id='topic+get_forecast_counts'></span>

<h3>Description</h3>

<p>Given a data set with forecasts, this function counts the number of
available forecasts.
The level of grouping can be specified using the <code>by</code> argument (e.g. to
count the number of forecasts per model, or the number of forecasts per
model and location).
This is useful to determine whether there are any missing forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_forecast_counts(
  forecast,
  by = get_forecast_unit(forecast),
  collapse = c("quantile_level", "sample_id")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_forecast_counts_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
<tr><td><code id="get_forecast_counts_+3A_by">by</code></td>
<td>
<p>character vector or <code>NULL</code> (the default) that denotes the
categories over which the number of forecasts should be counted.
By default this will be the unit of a single forecast (i.e.
all available columns (apart from a few &quot;protected&quot; columns such as
'predicted' and 'observed') plus &quot;quantile_level&quot; or &quot;sample_id&quot; where
present).</p>
</td></tr>
<tr><td><code id="get_forecast_counts_+3A_collapse">collapse</code></td>
<td>
<p>character vector (default: <code style="white-space: pre;">&#8288;c("quantile_level", "sample_id"&#8288;</code>)
with names of categories for which the number of rows should be collapsed
to one when counting. For example, a single forecast is usually represented
by a set of several quantiles or samples and collapsing these to one makes
sure that a single forecast only gets counted once. Setting
<code>collapse = c()</code> would mean that all quantiles / samples would be counted
as individual forecasts.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with columns as specified in <code>by</code> and an additional
column &quot;count&quot; with the number of forecasts.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(magrittr) # pipe operator
example_quantile %&gt;%
  as_forecast_quantile() %&gt;%
  get_forecast_counts(by = c("model", "target_type"))
</code></pre>

<hr>
<h2 id='get_forecast_type'>Get forecast type from forecast object</h2><span id='topic+get_forecast_type'></span>

<h3>Description</h3>

<p>Get forecast type from forecast object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_forecast_type(forecast)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_forecast_type_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character vector of length one with the forecast type.
</p>

<hr>
<h2 id='get_forecast_unit'>Get unit of a single forecast</h2><span id='topic+get_forecast_unit'></span>

<h3>Description</h3>

<p>Helper function to get the unit of a single forecast, i.e.
the column names that define where a single forecast was made for.
This just takes all columns that are available in the data and subtracts
the columns that are protected, i.e. those returned by
<code><a href="#topic+get_protected_columns">get_protected_columns()</a></code> as well as the names of the metrics that were
specified during scoring, if any.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_forecast_unit(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_forecast_unit_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector with the column names that define the unit of
a single forecast
</p>


<h3>Forecast unit</h3>

<p>In order to score forecasts, <code>scoringutils</code> needs to know which of the rows
of the data belong together and jointly form a single forecasts. This is
easy e.g. for point forecast, where there is one row per forecast. For
quantile or sample-based forecasts, however, there are multiple rows that
belong to a single forecast.
</p>
<p>The <em>forecast unit</em> or <em>unit of a single forecast</em> is then described by the
combination of columns that uniquely identify a single forecast.
For example, we could have forecasts made by different models in various
locations at different time points, each for several weeks into the future.
The forecast unit could then be described as
<code>forecast_unit = c("model", "location", "forecast_date", "forecast_horizon")</code>.
<code>scoringutils</code> automatically tries to determine the unit of a single
forecast. It uses all existing columns for this, which means that no columns
must be present that are unrelated to the forecast unit. As a very simplistic
example, if you had an additional row, &quot;even&quot;, that is one if the row number
is even and zero otherwise, then this would mess up scoring as <code>scoringutils</code>
then thinks that this column was relevant in defining the forecast unit.
</p>
<p>In order to avoid issues, we recommend setting the forecast unit explicitly,
using the <code>forecast_unit</code> argument. This will simply drop unneeded columns,
while making sure that all necessary, 'protected columns' like &quot;predicted&quot;
or &quot;observed&quot; are retained.
</p>

<hr>
<h2 id='get_metrics'>Get metrics</h2><span id='topic+get_metrics'></span>

<h3>Description</h3>

<p>Generic function to to obtain default metrics available for scoring or metrics
that were used for scoring.
</p>

<ul>
<li><p> If called on a <code>forecast</code> object it returns a list of functions that can be
used for scoring.
</p>
</li>
<li><p> If called on a <code>scores</code> object (see <code><a href="#topic+score">score()</a></code>), it returns a character vector
with the names of the metrics that were used for scoring.
</p>
</li></ul>

<p>See the documentation for the actual methods in the <code style="white-space: pre;">&#8288;See Also&#8288;</code> section below
for more details. Alternatively call <code style="white-space: pre;">&#8288;?get_metrics.&lt;forecast_type&gt;&#8288;</code> or
<code>?get_metrics.scores</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_metrics(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_metrics_+3A_x">x</code></td>
<td>
<p>A <code>forecast</code> or <code>scores</code> object.</p>
</td></tr>
<tr><td><code id="get_metrics_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the method.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other get_metrics functions: 
<code><a href="#topic+get_metrics.forecast_binary">get_metrics.forecast_binary</a>()</code>,
<code><a href="#topic+get_metrics.forecast_nominal">get_metrics.forecast_nominal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_ordinal">get_metrics.forecast_ordinal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_point">get_metrics.forecast_point</a>()</code>,
<code><a href="#topic+get_metrics.forecast_quantile">get_metrics.forecast_quantile</a>()</code>,
<code><a href="#topic+get_metrics.forecast_sample">get_metrics.forecast_sample</a>()</code>,
<code><a href="#topic+get_metrics.scores">get_metrics.scores</a>()</code>
</p>

<hr>
<h2 id='get_metrics.forecast_binary'>Get default metrics for binary forecasts</h2><span id='topic+get_metrics.forecast_binary'></span>

<h3>Description</h3>

<p>For binary forecasts, the default scoring rules are:
</p>

<ul>
<li><p> &quot;brier_score&quot; = <code><a href="#topic+brier_score">brier_score()</a></code>
</p>
</li>
<li><p> &quot;log_score&quot; = <code><a href="#topic+logs_binary">logs_binary()</a></code>
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_binary'
get_metrics(x, select = NULL, exclude = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_metrics.forecast_binary_+3A_x">x</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values, see <code><a href="#topic+as_forecast_binary">as_forecast_binary()</a></code>).</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_binary_+3A_select">select</code></td>
<td>
<p>A character vector of scoring rules to select from the list. If
<code>select</code> is <code>NULL</code> (the default), all possible scoring rules are returned.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_binary_+3A_exclude">exclude</code></td>
<td>
<p>A character vector of scoring rules to exclude from the list.
If <code>select</code> is not <code>NULL</code>, this argument is ignored.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_binary_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of scoring functions.
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-binary-point.png" style="width:750px;max-width:100%;" alt="metrics-binary-point.png" />
</div><p>
Overview of required input format for binary and point forecasts


</p>


<h3>See Also</h3>

<p>Other get_metrics functions: 
<code><a href="#topic+get_metrics">get_metrics</a>()</code>,
<code><a href="#topic+get_metrics.forecast_nominal">get_metrics.forecast_nominal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_ordinal">get_metrics.forecast_ordinal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_point">get_metrics.forecast_point</a>()</code>,
<code><a href="#topic+get_metrics.forecast_quantile">get_metrics.forecast_quantile</a>()</code>,
<code><a href="#topic+get_metrics.forecast_sample">get_metrics.forecast_sample</a>()</code>,
<code><a href="#topic+get_metrics.scores">get_metrics.scores</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_metrics(example_binary)
get_metrics(example_binary, select = "brier_score")
get_metrics(example_binary, exclude = "log_score")
</code></pre>

<hr>
<h2 id='get_metrics.forecast_nominal'>Get default metrics for nominal forecasts</h2><span id='topic+get_metrics.forecast_nominal'></span>

<h3>Description</h3>

<p>For nominal forecasts, the default scoring rule is:
</p>

<ul>
<li><p> &quot;log_score&quot; = <code><a href="#topic+logs_categorical">logs_categorical()</a></code>
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_nominal'
get_metrics(x, select = NULL, exclude = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_metrics.forecast_nominal_+3A_x">x</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values, see <code><a href="#topic+as_forecast_binary">as_forecast_binary()</a></code>).</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_nominal_+3A_select">select</code></td>
<td>
<p>A character vector of scoring rules to select from the list. If
<code>select</code> is <code>NULL</code> (the default), all possible scoring rules are returned.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_nominal_+3A_exclude">exclude</code></td>
<td>
<p>A character vector of scoring rules to exclude from the list.
If <code>select</code> is not <code>NULL</code>, this argument is ignored.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_nominal_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other get_metrics functions: 
<code><a href="#topic+get_metrics">get_metrics</a>()</code>,
<code><a href="#topic+get_metrics.forecast_binary">get_metrics.forecast_binary</a>()</code>,
<code><a href="#topic+get_metrics.forecast_ordinal">get_metrics.forecast_ordinal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_point">get_metrics.forecast_point</a>()</code>,
<code><a href="#topic+get_metrics.forecast_quantile">get_metrics.forecast_quantile</a>()</code>,
<code><a href="#topic+get_metrics.forecast_sample">get_metrics.forecast_sample</a>()</code>,
<code><a href="#topic+get_metrics.scores">get_metrics.scores</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_metrics(example_nominal)
</code></pre>

<hr>
<h2 id='get_metrics.forecast_ordinal'>Get default metrics for nominal forecasts</h2><span id='topic+get_metrics.forecast_ordinal'></span>

<h3>Description</h3>

<p>For ordinal forecasts, the default scoring rules are:
</p>

<ul>
<li><p> &quot;log_score&quot; = <code><a href="#topic+logs_categorical">logs_categorical()</a></code>
</p>
</li>
<li><p> &quot;rps&quot; = <code><a href="#topic+rps_ordinal">rps_ordinal()</a></code>
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_ordinal'
get_metrics(x, select = NULL, exclude = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_metrics.forecast_ordinal_+3A_x">x</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values, see <code><a href="#topic+as_forecast_binary">as_forecast_binary()</a></code>).</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_ordinal_+3A_select">select</code></td>
<td>
<p>A character vector of scoring rules to select from the list. If
<code>select</code> is <code>NULL</code> (the default), all possible scoring rules are returned.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_ordinal_+3A_exclude">exclude</code></td>
<td>
<p>A character vector of scoring rules to exclude from the list.
If <code>select</code> is not <code>NULL</code>, this argument is ignored.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_ordinal_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other get_metrics functions: 
<code><a href="#topic+get_metrics">get_metrics</a>()</code>,
<code><a href="#topic+get_metrics.forecast_binary">get_metrics.forecast_binary</a>()</code>,
<code><a href="#topic+get_metrics.forecast_nominal">get_metrics.forecast_nominal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_point">get_metrics.forecast_point</a>()</code>,
<code><a href="#topic+get_metrics.forecast_quantile">get_metrics.forecast_quantile</a>()</code>,
<code><a href="#topic+get_metrics.forecast_sample">get_metrics.forecast_sample</a>()</code>,
<code><a href="#topic+get_metrics.scores">get_metrics.scores</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_metrics(example_ordinal)
</code></pre>

<hr>
<h2 id='get_metrics.forecast_point'>Get default metrics for point forecasts</h2><span id='topic+get_metrics.forecast_point'></span>

<h3>Description</h3>

<p>For point forecasts, the default scoring rules are:
</p>

<ul>
<li><p> &quot;ae_point&quot; = <a href="Metrics.html#topic+ae">ae()</a>
</p>
</li>
<li><p> &quot;se_point&quot; = <a href="Metrics.html#topic+se">se()</a>
</p>
</li>
<li><p> &quot;ape&quot; = <a href="Metrics.html#topic+ape">ape()</a>
</p>
</li></ul>

<p>A note of caution: Every scoring rule for a point forecast
is implicitly minimised by a specific aspect of the predictive distribution
(see Gneiting, 2011).
</p>
<p>The mean squared error, for example, is only a meaningful scoring rule if
the forecaster actually reported the mean of their predictive distribution
as a point forecast. If the forecaster reported the median, then the mean
absolute error would be the appropriate scoring rule. If the scoring rule
and the predictive task do not align, the results will be misleading.
</p>
<p>Failure to respect this correspondence can lead to grossly misleading
results! Consider the example in the section below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_point'
get_metrics(x, select = NULL, exclude = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_metrics.forecast_point_+3A_x">x</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values, see <code><a href="#topic+as_forecast_binary">as_forecast_binary()</a></code>).</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_point_+3A_select">select</code></td>
<td>
<p>A character vector of scoring rules to select from the list. If
<code>select</code> is <code>NULL</code> (the default), all possible scoring rules are returned.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_point_+3A_exclude">exclude</code></td>
<td>
<p>A character vector of scoring rules to exclude from the list.
If <code>select</code> is not <code>NULL</code>, this argument is ignored.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_point_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-binary-point.png" style="width:750px;max-width:100%;" alt="metrics-binary-point.png" />
</div><p>
Overview of required input format for binary and point forecasts


</p>


<h3>References</h3>

<p>Making and Evaluating Point Forecasts, Gneiting, Tilmann, 2011,
Journal of the American Statistical Association.
</p>


<h3>See Also</h3>

<p>Other get_metrics functions: 
<code><a href="#topic+get_metrics">get_metrics</a>()</code>,
<code><a href="#topic+get_metrics.forecast_binary">get_metrics.forecast_binary</a>()</code>,
<code><a href="#topic+get_metrics.forecast_nominal">get_metrics.forecast_nominal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_ordinal">get_metrics.forecast_ordinal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_quantile">get_metrics.forecast_quantile</a>()</code>,
<code><a href="#topic+get_metrics.forecast_sample">get_metrics.forecast_sample</a>()</code>,
<code><a href="#topic+get_metrics.scores">get_metrics.scores</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_metrics(example_point, select = "ape")

library(magrittr)
set.seed(123)
n &lt;- 500
observed &lt;- rnorm(n, 5, 4)^2

predicted_mu &lt;- mean(observed)
predicted_not_mu &lt;- predicted_mu - rnorm(n, 10, 2)

df &lt;- data.frame(
  model = rep(c("perfect", "bad"), each = n),
  predicted = c(rep(predicted_mu, n), predicted_not_mu),
  observed = rep(observed, 2),
  id = rep(1:n, 2)
) %&gt;%
  as_forecast_point()
score(df) %&gt;%
  summarise_scores()
</code></pre>

<hr>
<h2 id='get_metrics.forecast_quantile'>Get default metrics for quantile-based forecasts</h2><span id='topic+get_metrics.forecast_quantile'></span>

<h3>Description</h3>

<p>For quantile-based forecasts, the default scoring rules are:
</p>

<ul>
<li><p> &quot;wis&quot; = <code><a href="#topic+wis">wis()</a></code>
</p>
</li>
<li><p> &quot;overprediction&quot; = <code><a href="#topic+overprediction_quantile">overprediction_quantile()</a></code>
</p>
</li>
<li><p> &quot;underprediction&quot; = <code><a href="#topic+underprediction_quantile">underprediction_quantile()</a></code>
</p>
</li>
<li><p> &quot;dispersion&quot; = <code><a href="#topic+dispersion_quantile">dispersion_quantile()</a></code>
</p>
</li>
<li><p> &quot;bias&quot; = <code><a href="#topic+bias_quantile">bias_quantile()</a></code>
</p>
</li>
<li><p> &quot;interval_coverage_50&quot; = <code><a href="#topic+interval_coverage">interval_coverage()</a></code>
</p>
</li>
<li><p> &quot;interval_coverage_90&quot; = purrr::partial(
interval_coverage, interval_range = 90
)
</p>
</li>
<li><p> &quot;ae_median&quot; = <code><a href="#topic+ae_median_quantile">ae_median_quantile()</a></code>
</p>
</li></ul>

<p>Note: The <code>interval_coverage_90</code> scoring rule is created by modifying
<code><a href="#topic+interval_coverage">interval_coverage()</a></code>, making use of the function <code><a href="purrr.html#topic+partial">purrr::partial()</a></code>.
This construct allows the function to deal with arbitrary arguments in <code>...</code>,
while making sure that only those that <code><a href="#topic+interval_coverage">interval_coverage()</a></code> can
accept get passed on to it. <code>interval_range = 90</code> is set in the function
definition, as passing an argument <code>interval_range = 90</code> to <code><a href="#topic+score">score()</a></code> would
mean it would also get passed to <code>interval_coverage_50</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_quantile'
get_metrics(x, select = NULL, exclude = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_metrics.forecast_quantile_+3A_x">x</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values, see <code><a href="#topic+as_forecast_binary">as_forecast_binary()</a></code>).</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_quantile_+3A_select">select</code></td>
<td>
<p>A character vector of scoring rules to select from the list. If
<code>select</code> is <code>NULL</code> (the default), all possible scoring rules are returned.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_quantile_+3A_exclude">exclude</code></td>
<td>
<p>A character vector of scoring rules to exclude from the list.
If <code>select</code> is not <code>NULL</code>, this argument is ignored.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_quantile_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-quantile.png" style="width:750px;max-width:100%;" alt="metrics-quantile.png" />
</div><p>
Overview of required input format for quantile-based forecasts


</p>


<h3>See Also</h3>

<p>Other get_metrics functions: 
<code><a href="#topic+get_metrics">get_metrics</a>()</code>,
<code><a href="#topic+get_metrics.forecast_binary">get_metrics.forecast_binary</a>()</code>,
<code><a href="#topic+get_metrics.forecast_nominal">get_metrics.forecast_nominal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_ordinal">get_metrics.forecast_ordinal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_point">get_metrics.forecast_point</a>()</code>,
<code><a href="#topic+get_metrics.forecast_sample">get_metrics.forecast_sample</a>()</code>,
<code><a href="#topic+get_metrics.scores">get_metrics.scores</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_metrics(example_quantile, select = "wis")
</code></pre>

<hr>
<h2 id='get_metrics.forecast_sample'>Get default metrics for sample-based forecasts</h2><span id='topic+get_metrics.forecast_sample'></span>

<h3>Description</h3>

<p>For sample-based forecasts, the default scoring rules are:
</p>

<ul>
<li><p> &quot;crps&quot; = <code><a href="#topic+crps_sample">crps_sample()</a></code>
</p>
</li>
<li><p> &quot;overprediction&quot; = <code><a href="#topic+overprediction_sample">overprediction_sample()</a></code>
</p>
</li>
<li><p> &quot;underprediction&quot; = <code><a href="#topic+underprediction_sample">underprediction_sample()</a></code>
</p>
</li>
<li><p> &quot;dispersion&quot; = <code><a href="#topic+dispersion_sample">dispersion_sample()</a></code>
</p>
</li>
<li><p> &quot;log_score&quot; = <code><a href="#topic+logs_sample">logs_sample()</a></code>
</p>
</li>
<li><p> &quot;dss&quot; = <code><a href="#topic+dss_sample">dss_sample()</a></code>
</p>
</li>
<li><p> &quot;mad&quot; = <code><a href="#topic+mad_sample">mad_sample()</a></code>
</p>
</li>
<li><p> &quot;bias&quot; = <code><a href="#topic+bias_sample">bias_sample()</a></code>
</p>
</li>
<li><p> &quot;ae_median&quot; = <code><a href="#topic+ae_median_sample">ae_median_sample()</a></code>
</p>
</li>
<li><p> &quot;se_mean&quot; = <code><a href="#topic+se_mean_sample">se_mean_sample()</a></code>
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_sample'
get_metrics(x, select = NULL, exclude = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_metrics.forecast_sample_+3A_x">x</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values, see <code><a href="#topic+as_forecast_binary">as_forecast_binary()</a></code>).</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_sample_+3A_select">select</code></td>
<td>
<p>A character vector of scoring rules to select from the list. If
<code>select</code> is <code>NULL</code> (the default), all possible scoring rules are returned.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_sample_+3A_exclude">exclude</code></td>
<td>
<p>A character vector of scoring rules to exclude from the list.
If <code>select</code> is not <code>NULL</code>, this argument is ignored.</p>
</td></tr>
<tr><td><code id="get_metrics.forecast_sample_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>


<h3>See Also</h3>

<p>Other get_metrics functions: 
<code><a href="#topic+get_metrics">get_metrics</a>()</code>,
<code><a href="#topic+get_metrics.forecast_binary">get_metrics.forecast_binary</a>()</code>,
<code><a href="#topic+get_metrics.forecast_nominal">get_metrics.forecast_nominal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_ordinal">get_metrics.forecast_ordinal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_point">get_metrics.forecast_point</a>()</code>,
<code><a href="#topic+get_metrics.forecast_quantile">get_metrics.forecast_quantile</a>()</code>,
<code><a href="#topic+get_metrics.scores">get_metrics.scores</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_metrics(example_sample_continuous, exclude = "mad")
</code></pre>

<hr>
<h2 id='get_metrics.scores'>Get names of the metrics that were used for scoring</h2><span id='topic+get_metrics.scores'></span>

<h3>Description</h3>

<p>When applying a scoring rule via <code><a href="#topic+score">score()</a></code>, the names of the scoring rules
become column names of the
resulting data.table. In addition, an attribute <code>metrics</code> will be
added to the output, holding the names of the scores as a vector.
</p>
<p>This is done so that functions like <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> or
<code><a href="#topic+summarise_scores">summarise_scores()</a></code> can still identify which columns are part of the
forecast unit and which hold a score.
</p>
<p><code>get_metrics()</code> accesses and returns the <code>metrics</code> attribute. If there is no
attribute, the function will return <code>NULL</code> (or, if <code>error = TRUE</code> will
produce an error instead). In addition, it checks the column names of the
input for consistency with the data stored in the <code>metrics</code> attribute.
</p>
<p><strong>Handling a missing or inconsistent <code>metrics</code> attribute</strong>:
</p>
<p>If the metrics attribute is missing or is not consistent with the column
names of the data.table, you can either
</p>

<ul>
<li><p> run <code><a href="#topic+score">score()</a></code> again, specifying names for the scoring rules manually, or
</p>
</li>
<li><p> add/update the attribute manually using
<code>attr(scores, "metrics") &lt;- c("names", "of", "your", "scores")</code> (the
order does not matter).
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'scores'
get_metrics(x, error = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_metrics.scores_+3A_x">x</code></td>
<td>
<p>A <code>scores</code> object, (a data.table with an attribute <code>metrics</code> as
produced by <code><a href="#topic+score">score()</a></code>).</p>
</td></tr>
<tr><td><code id="get_metrics.scores_+3A_error">error</code></td>
<td>
<p>Throw an error if there is no attribute called <code>metrics</code>?
Default is FALSE.</p>
</td></tr>
<tr><td><code id="get_metrics.scores_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character vector with the names of the scoring rules that were used
for scoring.
</p>


<h3>See Also</h3>

<p>Other get_metrics functions: 
<code><a href="#topic+get_metrics">get_metrics</a>()</code>,
<code><a href="#topic+get_metrics.forecast_binary">get_metrics.forecast_binary</a>()</code>,
<code><a href="#topic+get_metrics.forecast_nominal">get_metrics.forecast_nominal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_ordinal">get_metrics.forecast_ordinal</a>()</code>,
<code><a href="#topic+get_metrics.forecast_point">get_metrics.forecast_point</a>()</code>,
<code><a href="#topic+get_metrics.forecast_quantile">get_metrics.forecast_quantile</a>()</code>,
<code><a href="#topic+get_metrics.forecast_sample">get_metrics.forecast_sample</a>()</code>
</p>

<hr>
<h2 id='get_pairwise_comparisons'>Obtain pairwise comparisons between models</h2><span id='topic+get_pairwise_comparisons'></span>

<h3>Description</h3>

<p>Compare scores obtained by different models in a pairwise tournament. All
combinations of two models are compared against each other based on the
overlapping set of available forecasts common to both models.
</p>
<p>The input should be a <code>scores</code> object as produced by <code><a href="#topic+score">score()</a></code>. Note that
adding additional unrelated columns can unpredictably change results, as
all present columns are taken into account when determining the set of
overlapping forecasts between two models.
</p>
<p>The output of the pairwise comparisons is a set of mean score ratios,
relative skill scores and p-values.
</p>

<div style="text-align: left">
<p><img src="../help/figures/pairwise-illustration.png" style="width:750px;max-width:100%;" alt="pairwise-illustration.png" />
</div><p>
Illustration of the pairwise comparison process.
</p>


<p><em>Mean score ratios</em>
</p>
<p>For every pair of two models, a mean score ratio is computed. This is simply
the mean score of the first model divided by the mean score of the second.
Mean score ratios are computed based on the set of overlapping forecasts
between the two models. That means that only scores for those targets are
taken into account for which both models have submitted a forecast.
</p>
<p><em>(Scaled) Relative skill scores</em>
</p>
<p>The relative score of a model is the geometric mean of all mean score
ratios which involve that model.
If a baseline is provided, scaled relative skill scores will be calculated
as well. Scaled relative skill scores are simply the relative skill score of
a model divided by the relative skill score of the baseline model.
</p>
<p><em>p-values</em>
</p>
<p>In addition, the function computes p-values for the comparison between two
models (again based on the set of overlapping forecasts). P-values can be
computed in two ways: based on a nonparametric Wilcoxon signed-rank test
(internally using <code><a href="stats.html#topic+wilcox.test">wilcox.test()</a></code> with <code>paired = TRUE</code>) or based on a
permutation test. The permutation test is based on the difference in mean
scores between two models. The default null hypothesis is that the mean score
difference is zero (see <code><a href="#topic+permutation_test">permutation_test()</a></code>).
Adjusted p-values are computed by calling <code><a href="stats.html#topic+p.adjust">p.adjust()</a></code> on the raw p-values.
</p>
<p>The code for the pairwise comparisons is inspired by an implementation by
Johannes Bracher.
The implementation of the permutation test follows the function
<code>permutationTest</code> from the <code>surveillance</code> package by Michael Hhle,
Andrea Riebler and Michaela Paul.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pairwise_comparisons(
  scores,
  compare = "model",
  by = NULL,
  metric = intersect(c("wis", "crps", "brier_score"), names(scores)),
  baseline = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pairwise_comparisons_+3A_scores">scores</code></td>
<td>
<p>An object of class <code>scores</code> (a data.table with
scores and an additional attribute <code>metrics</code> as produced by <code><a href="#topic+score">score()</a></code>).</p>
</td></tr>
<tr><td><code id="get_pairwise_comparisons_+3A_compare">compare</code></td>
<td>
<p>Character vector with a single colum name that defines the
elements for the pairwise comparison. For example, if this is set to
&quot;model&quot; (the default), then elements of the &quot;model&quot; column will be
compared.</p>
</td></tr>
<tr><td><code id="get_pairwise_comparisons_+3A_by">by</code></td>
<td>
<p>Character vector with column names that define further grouping
levels for the pairwise comparisons. By default this is <code>NULL</code> and there
will be one relative skill score per distinct entry of the column selected
in <code>compare</code>. If further columns are given here, for example, <code>by = "location"</code> with <code>compare = "model"</code>, then one separate relative skill
score is calculated for every model in every location.</p>
</td></tr>
<tr><td><code id="get_pairwise_comparisons_+3A_metric">metric</code></td>
<td>
<p>A string with the name of the metric for which
a relative skill shall be computed. By default this is either &quot;crps&quot;,
&quot;wis&quot; or &quot;brier_score&quot; if any of these are available.</p>
</td></tr>
<tr><td><code id="get_pairwise_comparisons_+3A_baseline">baseline</code></td>
<td>
<p>A string with the name of a model. If a baseline is
given, then a scaled relative skill with respect to the baseline will be
returned. By default (<code>NULL</code>), relative skill will not be scaled with
respect to a baseline model.</p>
</td></tr>
<tr><td><code id="get_pairwise_comparisons_+3A_...">...</code></td>
<td>
<p>Additional arguments for the comparison between two models. See
<code><a href="#topic+compare_forecasts">compare_forecasts()</a></code> for more information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with the results of pairwise comparisons
containing the mean score ratios (<code>mean_scores_ratio</code>),
unadjusted (<code>pval</code>) and adjusted (<code>adj_pval</code>) p-values, and relative skill
values of each model (<code>..._relative_skill</code>). If a baseline model is given
then the scaled relative skill is reported as well
(<code>..._scaled_relative_skill</code>).
</p>


<h3>Author(s)</h3>

<p>Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a>
</p>
<p>Johannes Bracher, <a href="mailto:johannes.bracher@kit.edu">johannes.bracher@kit.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(magrittr) # pipe operator

scores &lt;- example_quantile %&gt;%
 as_forecast_quantile() %&gt;%
 score()

pairwise &lt;- get_pairwise_comparisons(scores, by = "target_type")
pairwise2 &lt;- get_pairwise_comparisons(
  scores, by = "target_type", baseline = "EuroCOVIDhub-baseline"
)

library(ggplot2)
plot_pairwise_comparisons(pairwise, type = "mean_scores_ratio") +
  facet_wrap(~target_type)
</code></pre>

<hr>
<h2 id='get_pit_histogram.forecast_quantile'>Probability integral transformation histogram</h2><span id='topic+get_pit_histogram.forecast_quantile'></span><span id='topic+get_pit_histogram.forecast_sample'></span><span id='topic+get_pit_histogram'></span><span id='topic+get_pit_histogram.default'></span>

<h3>Description</h3>

<p>Generate a Probability Integral Transformation (PIT) histogram for
validated forecast objects.
</p>
<p>See the examples for how to plot the result of this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_quantile'
get_pit_histogram(forecast, num_bins = NULL, breaks = NULL, by, ...)

## S3 method for class 'forecast_sample'
get_pit_histogram(
  forecast,
  num_bins = 10,
  breaks = NULL,
  by,
  integers = c("nonrandom", "random", "ignore"),
  n_replicates = NULL,
  ...
)

get_pit_histogram(forecast, num_bins, breaks, by, ...)

## Default S3 method:
get_pit_histogram(forecast, num_bins, breaks, by, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pit_histogram.forecast_quantile_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
<tr><td><code id="get_pit_histogram.forecast_quantile_+3A_num_bins">num_bins</code></td>
<td>
<p>The number of bins in the PIT histogram. For sample-based
forecasts, the default is 10 bins. For quantile-based forecasts, the
default is one bin for each available quantile.
You can control the number of bins by supplying a number. This is fine for
sample-based pit histograms, but may fail for quantile-based formats. In
this case it is preferred to supply explicit breaks points using the
<code>breaks</code> argument.</p>
</td></tr>
<tr><td><code id="get_pit_histogram.forecast_quantile_+3A_breaks">breaks</code></td>
<td>
<p>Numeric vector with the break points for the bins in the
PIT histogram. This is preferred when creating a PIT histogram based on
quantile-based data. Default is <code>NULL</code> and breaks will be determined by
<code>num_bins</code>. If <code>breaks</code> is used, <code>num_bins</code> will be ignored.
0 and 1 will always be added as left and right bounds, respectively.</p>
</td></tr>
<tr><td><code id="get_pit_histogram.forecast_quantile_+3A_by">by</code></td>
<td>
<p>Character vector with the columns according to which the
PIT values shall be grouped. If you e.g. have the columns 'model' and
'location' in the input data and want to have a PIT histogram for
every model and location, specify <code>by = c("model", "location")</code>.</p>
</td></tr>
<tr><td><code id="get_pit_histogram.forecast_quantile_+3A_...">...</code></td>
<td>
<p>Currently unused. You <em>cannot</em> pass additional arguments to scoring
functions via <code>...</code>. See the <em>Customising metrics</em> section below for
details on how to use <code><a href="purrr.html#topic+partial">purrr::partial()</a></code> to pass arguments to individual
metrics.</p>
</td></tr>
<tr><td><code id="get_pit_histogram.forecast_quantile_+3A_integers">integers</code></td>
<td>
<p>How to handle integer forecasts (count data). This is based
on methods described Czado et al. (2007). If &quot;nonrandom&quot; (default) the
function will use the non-randomised PIT method. If &quot;random&quot;, will use the
randomised PIT method. If &quot;ignore&quot;, will treat integer forecasts as if they
were continuous.</p>
</td></tr>
<tr><td><code id="get_pit_histogram.forecast_quantile_+3A_n_replicates">n_replicates</code></td>
<td>
<p>The number of draws for the randomised PIT for discrete
predictions. Will be ignored if forecasts are continuous or <code>integers</code> is
not set to <code>random</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with density values for each bin in the PIT histogram.
</p>


<h3>References</h3>

<p>Sebastian Funk, Anton Camacho, Adam J. Kucharski, Rachel Lowe,
Rosalind M. Eggo, W. John Edmunds (2019) Assessing the performance of
real-time epidemic forecasts: A case study of Ebola in the Western Area
region of Sierra Leone, 2014-15, <a href="https://doi.org/10.1371/journal.pcbi.1006785">doi:10.1371/journal.pcbi.1006785</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pit_histogram_sample">pit_histogram_sample()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("ggplot2")

result &lt;- get_pit_histogram(example_sample_continuous, by = "model")
ggplot(result,  aes(x = mid, y = density)) +
  geom_col() +
  facet_wrap(. ~ model) +
  labs(x = "Quantile", "Density")

# example with quantile data
result &lt;- get_pit_histogram(example_quantile, by = "model")
ggplot(result,  aes(x = mid, y = density)) +
  geom_col() +
  facet_wrap(. ~ model) +
  labs(x = "Quantile", "Density")
</code></pre>

<hr>
<h2 id='get_protected_columns'>Get protected columns from data</h2><span id='topic+get_protected_columns'></span>

<h3>Description</h3>

<p>Helper function to get the names of all columns in a data frame
that are protected columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_protected_columns(data = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_protected_columns_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector with the names of protected columns in the data.
If data is <code>NULL</code> (default) then it returns a list of all columns that are
protected in scoringutils.
</p>

<hr>
<h2 id='get_range_from_quantile'>Get interval range belonging to a quantile</h2><span id='topic+get_range_from_quantile'></span>

<h3>Description</h3>

<p>Every quantile can be thought of either as the lower or the
upper bound of a symmetric central prediction interval. This helper function
returns the range of the central prediction interval to which the quantile
belongs.
</p>
<p>Due to numeric instability that sometimes occurred in the past, ranges are
rounded to 10 decimal places. This is not a problem for the vast majority of
use cases, but it is something to be aware of.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_range_from_quantile(quantile_level)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_range_from_quantile_+3A_quantile_level">quantile_level</code></td>
<td>
<p>A numeric vector of quantile levels of size N.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector of interval ranges of size N
</p>

<hr>
<h2 id='get_type'>Get type of a vector or matrix of observed values or predictions</h2><span id='topic+get_type'></span>

<h3>Description</h3>

<p>Internal helper function to get the type of a vector (usually
of observed or predicted values). The function checks whether the input is
a factor, or else whether it is integer (or can be coerced to integer) or
whether it's continuous.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_type(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_type_+3A_x">x</code></td>
<td>
<p>Input the type should be determined for.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character vector of length one with either &quot;classification&quot;,
&quot;integer&quot;, or &quot;continuous&quot;.
</p>

<hr>
<h2 id='illustration-input-metric-binary-point'>Illustration of required inputs for binary and point forecasts</h2><span id='topic+illustration-input-metric-binary-point'></span>

<h3>Description</h3>

<p>Illustration of required inputs for binary and point forecasts
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-binary-point.png" style="width:750px;max-width:100%;" alt="metrics-binary-point.png" />
</div><p>
Overview of required input format for binary and point forecasts


</p>

<hr>
<h2 id='illustration-input-metric-nominal'>Illustration of required inputs for nominal forecasts</h2><span id='topic+illustration-input-metric-nominal'></span>

<h3>Description</h3>

<p>Illustration of required inputs for nominal forecasts
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-nominal.png" style="width:750px;max-width:100%;" alt="metrics-nominal.png" />
</div><p>
Overview of required input format for nominal forecasts


</p>

<hr>
<h2 id='illustration-input-metric-ordinal'>Illustration of required inputs for ordinal forecasts</h2><span id='topic+illustration-input-metric-ordinal'></span>

<h3>Description</h3>

<p>Illustration of required inputs for ordinal forecasts
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-ordinal.png" style="width:750px;max-width:100%;" alt="metrics-ordinal.png" />
</div><p>
Overview of required input format for ordinal forecasts


</p>

<hr>
<h2 id='illustration-input-metric-quantile'>Illustration of required inputs for quantile-based forecasts</h2><span id='topic+illustration-input-metric-quantile'></span>

<h3>Description</h3>

<p>Illustration of required inputs for quantile-based forecasts
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-quantile.png" style="width:750px;max-width:100%;" alt="metrics-quantile.png" />
</div><p>
Overview of required input format for quantile-based forecasts


</p>

<hr>
<h2 id='illustration-input-metric-sample'>Illustration of required inputs for sample-based forecasts</h2><span id='topic+illustration-input-metric-sample'></span>

<h3>Description</h3>

<p>Illustration of required inputs for sample-based forecasts
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>

<hr>
<h2 id='interpolate_median'>Helper function to interpolate the median prediction if it is not available</h2><span id='topic+interpolate_median'></span>

<h3>Description</h3>

<p>Internal function to interpolate the median prediction if it is not
available in the given quantile levels.
This is done using linear interpolation between the two innermost quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpolate_median(predicted, quantile_level)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpolate_median_+3A_predicted">predicted</code></td>
<td>
<p>Vector of length N (corresponding to the number of
quantiles) that holds predictions.</p>
</td></tr>
<tr><td><code id="interpolate_median_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Vector of of size N with the quantile levels
for which predictions were made. Note that if this does not contain the
median (0.5) then the median is imputed as being the mean of the two
innermost quantiles.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>scalar with the imputed median prediction
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-quantile.png" style="width:750px;max-width:100%;" alt="metrics-quantile.png" />
</div><p>
Overview of required input format for quantile-based forecasts


</p>

<hr>
<h2 id='interval_coverage'>Interval coverage (for quantile-based forecasts)</h2><span id='topic+interval_coverage'></span>

<h3>Description</h3>

<p>Check whether the observed value is within a given central
prediction interval. The prediction interval is defined by a lower and an
upper bound formed by a pair of predictive quantiles. For example, a 50%
prediction interval is formed by the 0.25 and 0.75 quantiles of the
predictive distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interval_coverage(observed, predicted, quantile_level, interval_range = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interval_coverage_+3A_observed">observed</code></td>
<td>
<p>Numeric vector of size n with the observed values.</p>
</td></tr>
<tr><td><code id="interval_coverage_+3A_predicted">predicted</code></td>
<td>
<p>Numeric nxN matrix of predictive
quantiles, n (number of rows) being the number of forecasts (corresponding
to the number of observed values) and N
(number of columns) the number of quantiles per forecast.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.</p>
</td></tr>
<tr><td><code id="interval_coverage_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Vector of of size N with the quantile levels
for which predictions were made.</p>
</td></tr>
<tr><td><code id="interval_coverage_+3A_interval_range">interval_range</code></td>
<td>
<p>A single number with the range of the prediction
interval in percent (e.g. 50 for a 50% prediction interval) for which you
want to compute interval coverage.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length n with elements either TRUE,
if the observed value is within the corresponding prediction interval, and
FALSE otherwise.
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-quantile.png" style="width:750px;max-width:100%;" alt="metrics-quantile.png" />
</div><p>
Overview of required input format for quantile-based forecasts


</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- c(1, -15, 22)
predicted &lt;- rbind(
  c(-1, 0, 1, 2, 3),
  c(-2, 1, 2, 2, 4),
   c(-2, 0, 3, 3, 4)
)
quantile_level &lt;- c(0.1, 0.25, 0.5, 0.75, 0.9)
interval_coverage(observed, predicted, quantile_level)
</code></pre>

<hr>
<h2 id='interval_score'>Interval score</h2><span id='topic+interval_score'></span>

<h3>Description</h3>

<p>Proper Scoring Rule to score quantile predictions, following Gneiting
and Raftery (2007). Smaller values are better.
</p>
<p>The score is computed as
</p>
<p style="text-align: center;"><code class="reqn">
\textrm{score} = (\textrm{upper} - \textrm{lower}) + \frac{2}{\alpha}(\textrm{lower}
 - \textrm{observed}) *
\mathbf{1}(\textrm{observed} &lt; \textrm{lower}) +
\frac{2}{\alpha}(\textrm{observed} - \textrm{upper}) *
\mathbf{1}(\textrm{observed} &gt; \textrm{upper})
</code>
</p>

<p>where <code class="reqn">\mathbf{1}()</code> is the indicator function and
indicates how much is outside the prediction interval.
<code class="reqn">\alpha</code> is the decimal value that indicates how much is outside
the prediction interval.
</p>
<p>To improve usability, the user is asked to provide an interval range in
percentage terms, i.e. interval_range = 90 (percent) for a 90 percent
prediction interval. Correspondingly, the user would have to provide the
5% and 95% quantiles (the corresponding alpha would then be 0.1).
No specific distribution is assumed, but the interval has to be symmetric
around the median (i.e you can't use the 0.1 quantile
as the lower bound and the 0.7 quantile as the upper bound).
Non-symmetric quantiles can be scored using the function <code><a href="#topic+quantile_score">quantile_score()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interval_score(
  observed,
  lower,
  upper,
  interval_range,
  weigh = TRUE,
  separate_results = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interval_score_+3A_observed">observed</code></td>
<td>
<p>A vector with observed values of size n</p>
</td></tr>
<tr><td><code id="interval_score_+3A_lower">lower</code></td>
<td>
<p>Vector of size n with the prediction for the lower quantile
of the given interval range.</p>
</td></tr>
<tr><td><code id="interval_score_+3A_upper">upper</code></td>
<td>
<p>Vector of size n with the prediction for the upper quantile
of the given interval range.</p>
</td></tr>
<tr><td><code id="interval_score_+3A_interval_range">interval_range</code></td>
<td>
<p>Numeric vector (either a single number or a vector of
size n) with the range of the prediction intervals. For example, if you're
forecasting the 0.05 and 0.95 quantile, the interval range would be 90.
The interval range corresponds to <code class="reqn">(100-\alpha)/100</code>, where
<code class="reqn">\alpha</code> is the decimal value that indicates how much is outside
the prediction interval (see e.g. Gneiting and Raftery (2007)).</p>
</td></tr>
<tr><td><code id="interval_score_+3A_weigh">weigh</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), weigh the score by
<code class="reqn">\alpha / 2</code>, so it can be averaged into an interval score that, in
the limit (for an increasing number of equally spaced quantiles/prediction
intervals), corresponds
to the CRPS. <code class="reqn">\alpha</code> is the value that corresponds to the
(<code class="reqn">\alpha/2</code>) or (<code class="reqn">1 - \alpha/2</code>), i.e. it is the decimal
value that represents how much is outside a central prediction interval
(E.g. for a 90 percent central prediction interval, alpha is 0.1).</p>
</td></tr>
<tr><td><code id="interval_score_+3A_separate_results">separate_results</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default is <code>FALSE</code>), then the
separate parts of the interval score (dispersion penalty, penalties for
over- and under-prediction get returned as separate elements of a list).
If you want a <code>data.frame</code> instead, simply call <code><a href="base.html#topic+as.data.frame">as.data.frame()</a></code> on the
output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with the scoring values, or a list with separate entries if
<code>separate_results</code> is <code>TRUE</code>.
</p>


<h3>References</h3>

<p>Strictly Proper Scoring Rules, Prediction,and Estimation,
Tilmann Gneiting and Adrian E. Raftery, 2007, Journal of the American
Statistical Association, Volume 102, 2007 - Issue 477
</p>
<p>Evaluating epidemic forecasts in an interval format,
Johannes Bracher, Evan L. Ray, Tilmann Gneiting and Nicholas G. Reich,
<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618">https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618</a> # nolint
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- rnorm(30, mean = 1:30)
interval_range &lt;- rep(90, 30)
alpha &lt;- (100 - interval_range) / 100
lower &lt;- qnorm(alpha / 2, rnorm(30, mean = 1:30))
upper &lt;- qnorm((1 - alpha / 2), rnorm(30, mean = 11:40))

scoringutils:::interval_score(
  observed = observed,
  lower = lower,
  upper = upper,
  interval_range = interval_range
)

# gives a warning, as the interval_range should likely be 50 instead of 0.5
scoringutils:::interval_score(
  observed = 4, upper = 8, lower = 2, interval_range = 0.5
)

# example with missing values and separate results
scoringutils:::interval_score(
  observed = c(observed, NA),
  lower = c(lower, NA),
  upper = c(NA, upper),
  separate_results = TRUE,
  interval_range = 90
)
</code></pre>

<hr>
<h2 id='is_forecast_binary'>Test whether an object is a forecast object</h2><span id='topic+is_forecast_binary'></span><span id='topic+is_forecast_nominal'></span><span id='topic+is_forecast_ordinal'></span><span id='topic+is_forecast_point'></span><span id='topic+is_forecast_quantile'></span><span id='topic+is_forecast_sample'></span><span id='topic+is_forecast'></span>

<h3>Description</h3>

<p>Test whether an object is a forecast object.
</p>
<p>You can test for a specific <code style="white-space: pre;">&#8288;forecast_&lt;type&gt;&#8288;</code> class using the appropriate
<code style="white-space: pre;">&#8288;is_forecast_&lt;type&gt;&#8288;</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_forecast_binary(x)

is_forecast_nominal(x)

is_forecast_ordinal(x)

is_forecast_point(x)

is_forecast_quantile(x)

is_forecast_sample(x)

is_forecast(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_forecast_binary_+3A_x">x</code></td>
<td>
<p>An R object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><em><code>is_forecast</code></em>: <code>TRUE</code> if the object is of class <code>forecast</code>,
<code>FALSE</code> otherwise.
</p>
<p><em><code style="white-space: pre;">&#8288;is_forecast_&lt;type&gt;*&#8288;</code></em>: <code>TRUE</code> if the object is of class <code style="white-space: pre;">&#8288;forecast_*&#8288;</code> in addition
to class <code>forecast</code>, <code>FALSE</code> otherwise.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>forecast_binary &lt;- as_forecast_binary(example_binary)
is_forecast(forecast_binary)
</code></pre>

<hr>
<h2 id='log_shift'>Log transformation with an additive shift</h2><span id='topic+log_shift'></span>

<h3>Description</h3>

<p>Function that shifts a value by some offset and then applies the
natural logarithm to it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_shift(x, offset = 0, base = exp(1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_shift_+3A_x">x</code></td>
<td>
<p>vector of input values to be transformed</p>
</td></tr>
<tr><td><code id="log_shift_+3A_offset">offset</code></td>
<td>
<p>Number to add to the input value before taking the natural
logarithm.</p>
</td></tr>
<tr><td><code id="log_shift_+3A_base">base</code></td>
<td>
<p>A positive number: the base with respect to which
logarithms are computed. Defaults to e = exp(1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output is computed as log(x + offset)
</p>


<h3>Value</h3>

<p>A numeric vector with transformed values
</p>


<h3>References</h3>

<p>Transformation of forecasts for evaluating predictive
performance in an epidemiological context
Nikos I. Bosse, Sam Abbott, Anne Cori, Edwin van Leeuwen, Johannes Bracher,
Sebastian Funk
medRxiv 2023.01.23.23284722
<a href="https://doi.org/10.1101/2023.01.23.23284722">doi:10.1101/2023.01.23.23284722</a>
<a href="https://www.medrxiv.org/content/10.1101/2023.01.23.23284722v1">https://www.medrxiv.org/content/10.1101/2023.01.23.23284722v1</a> # nolint
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr) # pipe operator
log_shift(1:10)
log_shift(0:9, offset = 1)

example_quantile[observed &gt; 0, ] %&gt;%
  as_forecast_quantile() %&gt;%
  transform_forecasts(fun = log_shift, offset = 1)
</code></pre>

<hr>
<h2 id='logs_categorical'>Log score for categorical outcomes</h2><span id='topic+logs_categorical'></span>

<h3>Description</h3>

<p><strong>Log score for categorical (nominal or ordinal) outcomes</strong>
</p>
<p>The Log Score is the negative logarithm of the probability
assigned to the observed value. It is a proper scoring rule. Small values
are better (best is zero, worst is infinity).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logs_categorical(observed, predicted, predicted_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logs_categorical_+3A_observed">observed</code></td>
<td>
<p>Factor of length n with N levels holding the
observed values.</p>
</td></tr>
<tr><td><code id="logs_categorical_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive probabilities, n (number of rows)
being the number of observations and N (number of columns) the number of
possible outcomes.</p>
</td></tr>
<tr><td><code id="logs_categorical_+3A_predicted_label">predicted_label</code></td>
<td>
<p>Factor of length N, denoting the outcome
that the probabilities in <code>predicted</code> correspond to.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of size n with log scores
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-nominal.png" style="width:750px;max-width:100%;" alt="metrics-nominal.png" />
</div><p>
Overview of required input format for nominal forecasts


</p>


<h3>See Also</h3>

<p>Other log score functions: 
<code><a href="#topic+logs_sample">logs_sample</a>()</code>,
<code><a href="#topic+scoring-functions-binary">scoring-functions-binary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>factor_levels &lt;- c("one", "two", "three")
predicted_label &lt;- factor(c("one", "two", "three"), levels = factor_levels)
observed &lt;- factor(c("one", "three", "two"), levels = factor_levels)
predicted &lt;- matrix(
  c(0.8, 0.1, 0.1,
    0.1, 0.2, 0.7,
    0.4, 0.4, 0.2),
  nrow = 3,
  byrow = TRUE
)
logs_categorical(observed, predicted, predicted_label)
</code></pre>

<hr>
<h2 id='logs_sample'>Logarithmic score (sample-based version)</h2><span id='topic+logs_sample'></span>

<h3>Description</h3>

<p>This function is a wrapper around the
<code><a href="scoringRules.html#topic+scores_sample_univ">logs_sample()</a></code> function from the
<span class="pkg">scoringRules</span> package.
</p>
<p>The log score is the negative logarithm of the predictive density evaluated
at the observed value.
</p>
<p>The function should be used to score continuous predictions only.
While the Log Score is in theory also applicable
to discrete forecasts, the problem lies in the implementation: The function
uses a kernel density estimation, which is not well defined with
integer-valued Monte Carlo Samples.
See the scoringRules package for more details and alternatives, e.g.
calculating scores for specific discrete probability distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logs_sample(observed, predicted, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logs_sample_+3A_observed">observed</code></td>
<td>
<p>A vector with observed values of size n</p>
</td></tr>
<tr><td><code id="logs_sample_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive samples, n (number of rows) being
the number of data points and N (number of columns) the number of Monte
Carlo samples. Alternatively, <code>predicted</code> can just be a vector of size n.</p>
</td></tr>
<tr><td><code id="logs_sample_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to
<a href="scoringRules.html#topic+scores_sample_univ">logs_sample()</a> from the scoringRules package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with scores.
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>


<h3>References</h3>

<p>Alexander Jordan, Fabian Krger, Sebastian Lerch, Evaluating Probabilistic
Forecasts with scoringRules, <a href="https://www.jstatsoft.org/article/view/v090i12">https://www.jstatsoft.org/article/view/v090i12</a>
</p>


<h3>See Also</h3>

<p>Other log score functions: 
<code><a href="#topic+logs_categorical">logs_categorical</a>()</code>,
<code><a href="#topic+scoring-functions-binary">scoring-functions-binary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- rpois(30, lambda = 1:30)
predicted &lt;- replicate(200, rpois(n = 30, lambda = 1:30))
logs_sample(observed, predicted)
</code></pre>

<hr>
<h2 id='mad_sample'>Determine dispersion of a probabilistic forecast</h2><span id='topic+mad_sample'></span>

<h3>Description</h3>

<p>Sharpness is the ability of the model to generate predictions within a
narrow range and dispersion is the lack thereof.
It is a data-independent measure, and is purely a feature
of the forecasts themselves.
</p>
<p>Dispersion of predictive samples corresponding to one single observed value is
measured as the normalised median of the absolute deviation from
the median of the predictive samples. For details, see <a href="stats.html#topic+mad">mad()</a>
and the explanations given in Funk et al. (2019)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mad_sample(observed = NULL, predicted, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mad_sample_+3A_observed">observed</code></td>
<td>
<p>Place holder, argument will be ignored and exists only for
consistency with other scoring functions. The output does not depend on
any observed values.</p>
</td></tr>
<tr><td><code id="mad_sample_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive samples, n (number of rows) being
the number of data points and N (number of columns) the number of Monte
Carlo samples. Alternatively, <code>predicted</code> can just be a vector of size n.</p>
</td></tr>
<tr><td><code id="mad_sample_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <a href="stats.html#topic+mad">mad()</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with dispersion values.
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>


<h3>References</h3>

<p>Funk S, Camacho A, Kucharski AJ, Lowe R, Eggo RM, Edmunds WJ (2019)
Assessing the performance of real-time epidemic forecasts: A case study of
Ebola in the Western Area region of Sierra Leone, 2014-15.
PLoS Comput Biol 15(2): e1006785. <a href="https://doi.org/10.1371/journal.pcbi.1006785">doi:10.1371/journal.pcbi.1006785</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>predicted &lt;- replicate(200, rpois(n = 30, lambda = 1:30))
mad_sample(predicted = predicted)
</code></pre>

<hr>
<h2 id='new_forecast'>Class constructor for <code>forecast</code> objects</h2><span id='topic+new_forecast'></span>

<h3>Description</h3>

<p>Construct a class based on a data.frame or similar. The constructor
</p>

<ul>
<li><p> coerces the data into a data.table
</p>
</li>
<li><p> assigns a class
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>new_forecast(data, classname)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="new_forecast_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="new_forecast_+3A_classname">classname</code></td>
<td>
<p>name of the class to be created</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class indicated by <code>classname</code>
</p>

<hr>
<h2 id='new_scores'>Construct an object of class <code>scores</code></h2><span id='topic+new_scores'></span>

<h3>Description</h3>

<p>This function creates an object of class <code>scores</code> based on a
data.table or similar.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>new_scores(scores, metrics, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="new_scores_+3A_scores">scores</code></td>
<td>
<p>A data.table or similar with scores as produced by <code><a href="#topic+score">score()</a></code>.</p>
</td></tr>
<tr><td><code id="new_scores_+3A_metrics">metrics</code></td>
<td>
<p>A character vector with the names of the scores
(i.e. the names of the scoring rules used for scoring).</p>
</td></tr>
<tr><td><code id="new_scores_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="data.table.html#topic+as.data.table">data.table::as.data.table()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>scores</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
df &lt;- data.frame(
  model = "A",
  wis = "0.1"
)
new_scores(df, "wis")

## End(Not run)
</code></pre>

<hr>
<h2 id='pairwise_comparison_one_group'>Do pairwise comparison for one set of forecasts</h2><span id='topic+pairwise_comparison_one_group'></span>

<h3>Description</h3>

<p>This function does the pairwise comparison for one set of forecasts, but
multiple models involved. It gets called from <code><a href="#topic+get_pairwise_comparisons">get_pairwise_comparisons()</a></code>.
<code><a href="#topic+get_pairwise_comparisons">get_pairwise_comparisons()</a></code> splits the data into arbitrary subgroups
specified by the user (e.g. if pairwise comparison should be done separately
for different forecast targets) and then the actual pairwise comparison for
that subgroup is managed from <code><a href="#topic+pairwise_comparison_one_group">pairwise_comparison_one_group()</a></code>. In order to
actually do the comparison between two models over a subset of common
forecasts it calls <code><a href="#topic+compare_forecasts">compare_forecasts()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise_comparison_one_group(
  scores,
  metric,
  baseline,
  compare = "model",
  by,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pairwise_comparison_one_group_+3A_scores">scores</code></td>
<td>
<p>An object of class <code>scores</code> (a data.table with
scores and an additional attribute <code>metrics</code> as produced by <code><a href="#topic+score">score()</a></code>).</p>
</td></tr>
<tr><td><code id="pairwise_comparison_one_group_+3A_metric">metric</code></td>
<td>
<p>A string with the name of the metric for which
a relative skill shall be computed. By default this is either &quot;crps&quot;,
&quot;wis&quot; or &quot;brier_score&quot; if any of these are available.</p>
</td></tr>
<tr><td><code id="pairwise_comparison_one_group_+3A_baseline">baseline</code></td>
<td>
<p>A string with the name of a model. If a baseline is
given, then a scaled relative skill with respect to the baseline will be
returned. By default (<code>NULL</code>), relative skill will not be scaled with
respect to a baseline model.</p>
</td></tr>
<tr><td><code id="pairwise_comparison_one_group_+3A_compare">compare</code></td>
<td>
<p>Character vector with a single colum name that defines the
elements for the pairwise comparison. For example, if this is set to
&quot;model&quot; (the default), then elements of the &quot;model&quot; column will be
compared.</p>
</td></tr>
<tr><td><code id="pairwise_comparison_one_group_+3A_by">by</code></td>
<td>
<p>Character vector with column names that define further grouping
levels for the pairwise comparisons. By default this is <code>NULL</code> and there
will be one relative skill score per distinct entry of the column selected
in <code>compare</code>. If further columns are given here, for example, <code>by = "location"</code> with <code>compare = "model"</code>, then one separate relative skill
score is calculated for every model in every location.</p>
</td></tr>
<tr><td><code id="pairwise_comparison_one_group_+3A_...">...</code></td>
<td>
<p>Additional arguments for the comparison between two models. See
<code><a href="#topic+compare_forecasts">compare_forecasts()</a></code> for more information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with the results of pairwise comparisons
containing the mean score ratios (<code>mean_scores_ratio</code>),
unadjusted (<code>pval</code>) and adjusted (<code>adj_pval</code>) p-values, and relative skill
values of each model (<code>..._relative_skill</code>). If a baseline model is given
then the scaled relative skill is reported as well
(<code>..._scaled_relative_skill</code>).
</p>

<hr>
<h2 id='permutation_test'>Simple permutation test</h2><span id='topic+permutation_test'></span>

<h3>Description</h3>

<p>The implementation of the permutation test follows the
function
<code>permutationTest</code> from the <code>surveillance</code> package by Michael Hhle,
Andrea Riebler and Michaela Paul.
The function compares two vectors of scores. It computes the mean of each
vector independently and then takes either the difference or the ratio of
the two. This observed difference or ratio is compared against the same
test statistic based on permutations of the original data.
</p>
<p>Used in <code><a href="#topic+get_pairwise_comparisons">get_pairwise_comparisons()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permutation_test(
  scores1,
  scores2,
  n_permutation = 999,
  one_sided = FALSE,
  comparison_mode = c("difference", "ratio")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="permutation_test_+3A_scores1">scores1</code></td>
<td>
<p>Vector of scores to compare against another vector of scores.</p>
</td></tr>
<tr><td><code id="permutation_test_+3A_scores2">scores2</code></td>
<td>
<p>A second vector of scores to compare against the first</p>
</td></tr>
<tr><td><code id="permutation_test_+3A_n_permutation">n_permutation</code></td>
<td>
<p>The number of replications to use for a permutation
test. More replications yield more exact results, but require more
computation.</p>
</td></tr>
<tr><td><code id="permutation_test_+3A_one_sided">one_sided</code></td>
<td>
<p>Whether or not to compute a one-sided test. Default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="permutation_test_+3A_comparison_mode">comparison_mode</code></td>
<td>
<p>How to compute the test statistic for the comparison
of the two scores. Should be either &quot;difference&quot; or &quot;ratio&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>p-value of the permutation test
</p>

<hr>
<h2 id='pit_histogram_sample'>Probability integral transformation for counts</h2><span id='topic+pit_histogram_sample'></span>

<h3>Description</h3>

<p>Uses a Probability integral transformation (PIT) (or a
randomised PIT for integer forecasts) to
assess the calibration of predictive Monte Carlo samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pit_histogram_sample(
  observed,
  predicted,
  quantiles,
  integers = c("nonrandom", "random", "ignore"),
  n_replicates = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pit_histogram_sample_+3A_observed">observed</code></td>
<td>
<p>A vector with observed values of size n</p>
</td></tr>
<tr><td><code id="pit_histogram_sample_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive samples, n (number of rows) being
the number of data points and N (number of columns) the number of Monte
Carlo samples. Alternatively, <code>predicted</code> can just be a vector of size n.</p>
</td></tr>
<tr><td><code id="pit_histogram_sample_+3A_quantiles">quantiles</code></td>
<td>
<p>A vector of quantiles between which to calculate the PIT.</p>
</td></tr>
<tr><td><code id="pit_histogram_sample_+3A_integers">integers</code></td>
<td>
<p>How to handle integer forecasts (count data). This is based
on methods described Czado et al. (2007). If &quot;nonrandom&quot; (default) the
function will use the non-randomised PIT method. If &quot;random&quot;, will use the
randomised PIT method. If &quot;ignore&quot;, will treat integer forecasts as if they
were continuous.</p>
</td></tr>
<tr><td><code id="pit_histogram_sample_+3A_n_replicates">n_replicates</code></td>
<td>
<p>The number of draws for the randomised PIT for discrete
predictions. Will be ignored if forecasts are continuous or <code>integers</code> is
not set to <code>random</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calibration or reliability of forecasts is the ability of a model to
correctly identify its own uncertainty in making predictions. In a model
with perfect calibration, the observed data at each time point look as if
they came from the predictive probability distribution at that time.
</p>
<p>Equivalently, one can inspect the probability integral transform of the
predictive distribution at time t,
</p>
<p style="text-align: center;"><code class="reqn">
u_t = F_t (x_t)
</code>
</p>

<p>where <code class="reqn">x_t</code> is the observed data point at time <code class="reqn">t \textrm{ in } t_1,
, t_n</code>, n being the number of forecasts, and <code class="reqn">F_t</code> is
the (continuous) predictive cumulative probability distribution at time t. If
the true probability distribution of outcomes at time t is <code class="reqn">G_t</code> then the
forecasts <code class="reqn">F_t</code> are said to be ideal if <code class="reqn">F_t = G_t</code> at all times t.
In that case, the probabilities <code class="reqn">u_t</code> are distributed uniformly.
</p>
<p>In the case of discrete nonnegative outcomes such as incidence counts,
the PIT is no longer uniform even when forecasts are ideal.
In that case two methods are available ase described by Czado et al. (2007).
</p>
<p>By default, a nonrandomised PIT is calculated using the conditional
cumulative distribution function
</p>
<p style="text-align: center;"><code class="reqn">
  F(u) =
  \begin{cases}
    0 &amp; \text{if } v &lt; P_t(k_t - 1) \\
    (v - P_t(k_t - 1)) / (P_t(k_t) - P_t(k_t - 1)) &amp; \text{if } P_t(k_t - 1) \leq v &lt; P_t(k_t) \\
    1 &amp; \text{if } v \geq P_t(k_t)
  \end{cases}
</code>
</p>

<p>where <code class="reqn">k_t</code> is the observed count, <code class="reqn">P_t(x)</code> is the predictive
cumulative probability of observing incidence <code class="reqn">k</code> at time <code class="reqn">t</code> and
<code class="reqn">P_t (-1) = 0</code> by definition.
Values of the PIT histogram are then created by averaging over the <code class="reqn">n</code>
predictions,
</p>
<p style="text-align: center;"><code class="reqn">
   \bar{F}(u) = \frac{i = 1}{n} \sum_{i=1}^{n} F^{(i)}(u)
</code>
</p>

<p>And calculating the value at each bin between quantile <code class="reqn">q_i</code> and quantile
<code class="reqn">q_{i + 1}</code> as
</p>
<p style="text-align: center;"><code class="reqn">
   \bar{F}(q_i) - \bar{F}(q_{i + 1})
</code>
</p>

<p>Alternatively, a randomised PIT can be used instead. In this case, the PIT is
</p>
<p style="text-align: center;"><code class="reqn">
  u_t = P_t(k_t) + v * (P_t(k_t) - P_t(k_t - 1))
</code>
</p>

<p>where <code class="reqn">v</code> is standard uniform and independent of <code class="reqn">k</code>. The values of
the PIT histogram are then calculated by binning the <code class="reqn">u_t</code> values as above.
</p>


<h3>Value</h3>

<p>A vector with PIT histogram densities for the bins corresponding
to the given quantiles.
</p>


<h3>References</h3>

<p>Claudia Czado, Tilmann Gneiting Leonhard Held (2009) Predictive model
assessment for count data. Biometrika, 96(4), 633-648.
Sebastian Funk, Anton Camacho, Adam J. Kucharski, Rachel Lowe,
Rosalind M. Eggo, W. John Edmunds (2019) Assessing the performance of
real-time epidemic forecasts: A case study of Ebola in the Western Area
region of Sierra Leone, 2014-15, <a href="https://doi.org/10.1371/journal.pcbi.1006785">doi:10.1371/journal.pcbi.1006785</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_pit_histogram">get_pit_histogram()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## continuous predictions
observed &lt;- rnorm(20, mean = 1:20)
predicted &lt;- replicate(100, rnorm(n = 20, mean = 1:20))
pit &lt;- pit_histogram_sample(observed, predicted, quantiles = seq(0, 1, 0.1))

## integer predictions
observed &lt;- rpois(20, lambda = 1:20)
predicted &lt;- replicate(100, rpois(n = 20, lambda = 1:20))
pit &lt;- pit_histogram_sample(observed, predicted, quantiles = seq(0, 1, 0.1))

## integer predictions, randomised PIT
observed &lt;- rpois(20, lambda = 1:20)
predicted &lt;- replicate(100, rpois(n = 20, lambda = 1:20))
pit &lt;- pit_histogram_sample(
  observed, predicted, quantiles = seq(0, 1, 0.1),
  integers = "random", n_replicates = 30
)
</code></pre>

<hr>
<h2 id='plot_correlations'>Plot correlation between metrics</h2><span id='topic+plot_correlations'></span>

<h3>Description</h3>

<p>Plots a heatmap of correlations between different metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_correlations(correlations, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_correlations_+3A_correlations">correlations</code></td>
<td>
<p>A data.table of correlations between scores as produced
by <code><a href="#topic+get_correlations">get_correlations()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_correlations_+3A_digits">digits</code></td>
<td>
<p>A number indicating how many decimal places the correlations
should be rounded to. By default (<code>digits = NULL</code>) no rounding takes place.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object showing a coloured matrix of correlations between metrics.
</p>
<p>A ggplot object with a visualisation of correlations between metrics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr) # pipe operator
scores &lt;- example_quantile %&gt;%
  as_forecast_quantile %&gt;%
  score()
correlations &lt;- scores %&gt;%
  summarise_scores() %&gt;%
  get_correlations()
plot_correlations(correlations, digits = 2)
</code></pre>

<hr>
<h2 id='plot_forecast_counts'>Visualise the number of available forecasts</h2><span id='topic+plot_forecast_counts'></span>

<h3>Description</h3>

<p>Visualise Where Forecasts Are Available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_forecast_counts(
  forecast_counts,
  x,
  y = "model",
  x_as_factor = TRUE,
  show_counts = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_forecast_counts_+3A_forecast_counts">forecast_counts</code></td>
<td>
<p>A data.table (or similar) with a column <code>count</code>
holding forecast counts, as produced by <code><a href="#topic+get_forecast_counts">get_forecast_counts()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_forecast_counts_+3A_x">x</code></td>
<td>
<p>Character vector of length one that denotes the name of the column
to appear on the x-axis of the plot.</p>
</td></tr>
<tr><td><code id="plot_forecast_counts_+3A_y">y</code></td>
<td>
<p>Character vector of length one that denotes the name of the column
to appear on the y-axis of the plot. Default is &quot;model&quot;.</p>
</td></tr>
<tr><td><code id="plot_forecast_counts_+3A_x_as_factor">x_as_factor</code></td>
<td>
<p>Logical (default is <code>TRUE</code>). Whether or not to convert
the variable on the x-axis to a factor. This has an effect e.g. if dates
are shown on the x-axis.</p>
</td></tr>
<tr><td><code id="plot_forecast_counts_+3A_show_counts">show_counts</code></td>
<td>
<p>Logical (default is <code>TRUE</code>) that indicates whether
or not to show the actual count numbers on the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object with a plot of forecast counts
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
library(magrittr) # pipe operator
forecast_counts &lt;- example_quantile %&gt;%
  as_forecast_quantile %&gt;%
  get_forecast_counts(by = c("model", "target_type", "target_end_date"))
plot_forecast_counts(
 forecast_counts, x = "target_end_date", show_counts = FALSE
) +
 facet_wrap("target_type")
</code></pre>

<hr>
<h2 id='plot_heatmap'>Create a heatmap of a scoring metric</h2><span id='topic+plot_heatmap'></span>

<h3>Description</h3>

<p>This function can be used to create a heatmap of one metric across different
groups, e.g. the interval score obtained by several forecasting models in
different locations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_heatmap(scores, y = "model", x, metric)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_heatmap_+3A_scores">scores</code></td>
<td>
<p>A data.frame of scores based on quantile forecasts as
produced by <code><a href="#topic+score">score()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_heatmap_+3A_y">y</code></td>
<td>
<p>The variable from the scores you want to show on the y-Axis. The
default for this is &quot;model&quot;</p>
</td></tr>
<tr><td><code id="plot_heatmap_+3A_x">x</code></td>
<td>
<p>The variable from the scores you want to show on the x-Axis. This
could be something like &quot;horizon&quot;, or &quot;location&quot;</p>
</td></tr>
<tr><td><code id="plot_heatmap_+3A_metric">metric</code></td>
<td>
<p>String, the metric that determines the value and colour shown
in the tiles of the heatmap.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object showing a heatmap of the desired metric
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr) # pipe operator
scores &lt;- example_quantile %&gt;%
  as_forecast_quantile %&gt;%
  score()
scores &lt;- summarise_scores(scores, by = c("model", "target_type"))
scores &lt;- summarise_scores(
  scores, by = c("model", "target_type"),
  fun = signif, digits = 2
)

plot_heatmap(scores, x = "target_type", metric = "bias")
</code></pre>

<hr>
<h2 id='plot_interval_coverage'>Plot interval coverage</h2><span id='topic+plot_interval_coverage'></span>

<h3>Description</h3>

<p>Plot interval coverage values (see <code><a href="#topic+get_coverage">get_coverage()</a></code> for more information).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_interval_coverage(coverage, colour = "model")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_interval_coverage_+3A_coverage">coverage</code></td>
<td>
<p>A data frame of coverage values as produced by
<code><a href="#topic+get_coverage">get_coverage()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_interval_coverage_+3A_colour">colour</code></td>
<td>
<p>According to which variable shall the graphs be coloured?
Default is &quot;model&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot object with a plot of interval coverage
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
example &lt;- as_forecast_quantile(example_quantile)
coverage &lt;- get_coverage(example, by = "model")
plot_interval_coverage(coverage)
</code></pre>

<hr>
<h2 id='plot_pairwise_comparisons'>Plot heatmap of pairwise comparisons</h2><span id='topic+plot_pairwise_comparisons'></span>

<h3>Description</h3>

<p>Creates a heatmap of the ratios or pvalues from a pairwise comparison
between models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pairwise_comparisons(
  comparison_result,
  type = c("mean_scores_ratio", "pval")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_pairwise_comparisons_+3A_comparison_result">comparison_result</code></td>
<td>
<p>A data.frame as produced by
<code><a href="#topic+get_pairwise_comparisons">get_pairwise_comparisons()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_pairwise_comparisons_+3A_type">type</code></td>
<td>
<p>Character vector of length one that is either
&quot;mean_scores_ratio&quot; or &quot;pval&quot;. This denotes whether to
visualise the ratio or the p-value of the pairwise comparison.
Default is &quot;mean_scores_ratio&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object with a heatmap of mean score ratios from pairwise
comparisons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
library(magrittr) # pipe operator
scores &lt;- example_quantile %&gt;%
  as_forecast_quantile %&gt;%
  score()
pairwise &lt;- get_pairwise_comparisons(scores, by = "target_type")
plot_pairwise_comparisons(pairwise, type = "mean_scores_ratio") +
  facet_wrap(~target_type)
</code></pre>

<hr>
<h2 id='plot_quantile_coverage'>Plot quantile coverage</h2><span id='topic+plot_quantile_coverage'></span>

<h3>Description</h3>

<p>Plot quantile coverage values (see <code><a href="#topic+get_coverage">get_coverage()</a></code> for more information).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_quantile_coverage(coverage, colour = "model")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_quantile_coverage_+3A_coverage">coverage</code></td>
<td>
<p>A data frame of coverage values as produced by
<code><a href="#topic+get_coverage">get_coverage()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_quantile_coverage_+3A_colour">colour</code></td>
<td>
<p>String, according to which variable shall the graphs be
coloured? Default is &quot;model&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object with a plot of interval coverage
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example &lt;- as_forecast_quantile(example_quantile)
coverage &lt;- get_coverage(example, by = "model")
plot_quantile_coverage(coverage)
</code></pre>

<hr>
<h2 id='plot_wis'>Plot contributions to the weighted interval score</h2><span id='topic+plot_wis'></span>

<h3>Description</h3>

<p>Visualise the components of the weighted interval score: penalties for
over-prediction, under-prediction and for high dispersion (lack of
sharpness).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_wis(scores, x = "model", relative_contributions = FALSE, flip = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_wis_+3A_scores">scores</code></td>
<td>
<p>A data.table of scores based on quantile forecasts as
produced by <code><a href="#topic+score">score()</a></code> and summarised using <code><a href="#topic+summarise_scores">summarise_scores()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_wis_+3A_x">x</code></td>
<td>
<p>The variable from the scores you want to show on the x-Axis.
Usually this will be &quot;model&quot;.</p>
</td></tr>
<tr><td><code id="plot_wis_+3A_relative_contributions">relative_contributions</code></td>
<td>
<p>Logical. Show relative contributions instead
of absolute contributions? Default is <code>FALSE</code> and this functionality is not
available yet.</p>
</td></tr>
<tr><td><code id="plot_wis_+3A_flip">flip</code></td>
<td>
<p>Boolean (default is <code>FALSE</code>), whether or not to flip the axes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object showing a contributions from the three components of
the weighted interval score.
</p>
<p>A ggplot object with a visualisation of the WIS decomposition
</p>


<h3>References</h3>

<p>Bracher J, Ray E, Gneiting T, Reich, N (2020) Evaluating epidemic forecasts
in an interval format. <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618">https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
library(magrittr) # pipe operator
scores &lt;- example_quantile %&gt;%
  as_forecast_quantile %&gt;%
  score()
scores &lt;- summarise_scores(scores, by = c("model", "target_type"))

plot_wis(scores,
  x = "model",
  relative_contributions = TRUE
) +
  facet_wrap(~target_type)
plot_wis(scores,
  x = "model",
  relative_contributions = FALSE
) +
  facet_wrap(~target_type, scales = "free_x")
</code></pre>

<hr>
<h2 id='print.forecast'>Print information about a forecast object</h2><span id='topic+print.forecast'></span>

<h3>Description</h3>

<p>This function prints information about a forecast object,
including &quot;Forecast type&quot;, &quot;Score columns&quot;,
&quot;Forecast unit&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.forecast_+3A_x">x</code></td>
<td>
<p>A forecast object</p>
</td></tr>
<tr><td><code id="print.forecast_+3A_...">...</code></td>
<td>
<p>Additional arguments for <code><a href="base.html#topic+print">print()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns <code>x</code> invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- as_forecast_quantile(example_quantile)
print(dat)
</code></pre>

<hr>
<h2 id='quantile_score'>Quantile score</h2><span id='topic+quantile_score'></span>

<h3>Description</h3>

<p>Proper Scoring Rule to score quantile predictions. Smaller values are better.
The quantile score is closely related to the interval score (see <code><a href="#topic+wis">wis()</a></code>) and
is the quantile equivalent that works with single quantiles instead of
central prediction intervals.
</p>
<p>The quantile score, also called pinball loss, for a single quantile
level <code class="reqn">\tau</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">
  \text{QS}_\tau(F, y) = 2 \cdot \{ \mathbf{1}(y \leq q_\tau) - \tau\} \cdot (q_\tau - y) =
  \begin{cases}
2 \cdot (1 - \tau) * q_\tau - y,       &amp; \text{if } y \leq q_\tau\\
2 \cdot \tau * |q_\tau - y|,           &amp; \text{if } y &gt; q_\tau,
\end{cases}
</code>
</p>

<p>with <code class="reqn">q_\tau</code> being the <code class="reqn">\tau</code>-quantile of the predictive
distribution <code class="reqn">F</code>, and <code class="reqn">\mathbf{1}(\cdot)</code> the indicator function.
</p>
<p>The weighted interval score for a single prediction interval can be obtained
as the average of the quantile scores for the lower and upper quantile of
that prediction interval:
</p>
<p style="text-align: center;"><code class="reqn">
  \text{WIS}_\alpha(F, y) = \frac{\text{QS}_{\alpha/2}(F, y)
  + \text{QS}_{1 - \alpha/2}(F, y)}{2}.
</code>
</p>

<p>See the SI of Bracher et al. (2021) for more details.
</p>
<p><code>quantile_score()</code> returns the average quantile score across the quantile
levels provided. For a set of quantile levels that form pairwise central
prediction intervals, the quantile score is equivalent to the interval score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_score(observed, predicted, quantile_level, weigh = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_score_+3A_observed">observed</code></td>
<td>
<p>Numeric vector of size n with the observed values.</p>
</td></tr>
<tr><td><code id="quantile_score_+3A_predicted">predicted</code></td>
<td>
<p>Numeric nxN matrix of predictive
quantiles, n (number of rows) being the number of forecasts (corresponding
to the number of observed values) and N
(number of columns) the number of quantiles per forecast.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.</p>
</td></tr>
<tr><td><code id="quantile_score_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Vector of of size N with the quantile levels
for which predictions were made.</p>
</td></tr>
<tr><td><code id="quantile_score_+3A_weigh">weigh</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), weigh the score by
<code class="reqn">\alpha / 2</code>, so it can be averaged into an interval score that, in
the limit (for an increasing number of equally spaced quantiles/prediction
intervals), corresponds
to the CRPS. <code class="reqn">\alpha</code> is the value that corresponds to the
(<code class="reqn">\alpha/2</code>) or (<code class="reqn">1 - \alpha/2</code>), i.e. it is the decimal
value that represents how much is outside a central prediction interval
(E.g. for a 90 percent central prediction interval, alpha is 0.1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector of length n with the quantile score. The scores are
averaged across quantile levels if multiple quantile levels are provided
(the result of calling <code>rowMeans()</code> on the matrix of quantile scores that
is computed based on the observed and predicted values).
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-quantile.png" style="width:750px;max-width:100%;" alt="metrics-quantile.png" />
</div><p>
Overview of required input format for quantile-based forecasts


</p>


<h3>References</h3>

<p>Strictly Proper Scoring Rules, Prediction,and Estimation,
Tilmann Gneiting and Adrian E. Raftery, 2007, Journal of the American
Statistical Association, Volume 102, 2007 - Issue 477
</p>
<p>Evaluating epidemic forecasts in an interval format,
Johannes Bracher, Evan L. Ray, Tilmann Gneiting and Nicholas G. Reich, 2021,
<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618">https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- rnorm(10, mean = 1:10)
alpha &lt;- 0.5

lower &lt;- qnorm(alpha / 2, observed)
upper &lt;- qnorm((1 - alpha / 2), observed)

qs_lower &lt;- quantile_score(observed,
  predicted = matrix(lower),
  quantile_level = alpha / 2
)
qs_upper &lt;- quantile_score(observed,
  predicted = matrix(upper),
  quantile_level = 1 - alpha / 2
)
interval_score &lt;- (qs_lower + qs_upper) / 2
interval_score2 &lt;- quantile_score(
  observed,
  predicted = cbind(lower, upper),
  quantile_level = c(alpha / 2, 1 - alpha / 2)
)

# this is the same as the following
wis(
  observed,
  predicted = cbind(lower, upper),
  quantile_level = c(alpha / 2, 1 - alpha / 2)
)
</code></pre>

<hr>
<h2 id='quantile_to_interval'>Transform from a quantile format to an interval format</h2><span id='topic+quantile_to_interval'></span><span id='topic+quantile_to_interval_dataframe'></span><span id='topic+quantile_to_interval_numeric'></span>

<h3>Description</h3>

<p>Internal helper function to transform from a quantile format to an interval
format (which is no longer a supported forecast format, but still used
internally. The function mimics an S3 generic, but is not actually an S3
generic, as we want the functions to be internal and not exported.)
</p>
<p><strong>Quantile format</strong>
In a quantile format, a prediction is characterised by one or multiple
predicted values and the corresponding quantile levels. For example, a
prediction in a quantile format could be represented by the 0.05, 0.25, 0.5,
0.75 and 0.95 quantiles of the predictive distribution.
</p>
<p><strong>Interval format</strong>
In the interval format, two quantiles are assumed to form a prediction
interval. Prediction intervals need to be symmetric around the median and
are characterised by a lower and an upper bound. The lower bound is defined
by the lower quantile and the upper bound is defined by the upper quantile.
A 90% prediction interval, for example, covers 90% of the probability mass
and is defined by the 5% and 95% quantiles. A forecast could therefore
be characterised by one or multiple prediction intervals, e.g. the lower
and upper bounds of the 50% and 90% prediction intervals (corresponding to
the 0.25 and 0.75 as well as the 0.05 and 0.095 quantiles).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_to_interval(...)

quantile_to_interval_dataframe(
  forecast,
  format = "long",
  keep_quantile_col = FALSE,
  ...
)

quantile_to_interval_numeric(observed, predicted, quantile_level, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_to_interval_+3A_...">...</code></td>
<td>
<p>Arguments</p>
</td></tr>
<tr><td><code id="quantile_to_interval_+3A_forecast">forecast</code></td>
<td>
<p>A data.table with forecasts in a quantile-based format (see
<code><a href="#topic+as_forecast_quantile">as_forecast_quantile()</a></code>).</p>
</td></tr>
<tr><td><code id="quantile_to_interval_+3A_format">format</code></td>
<td>
<p>The format of the output. Either &quot;long&quot; or &quot;wide&quot;. If &quot;long&quot;
(the default), there will be a column <code>boundary</code> (with values either
&quot;upper&quot; or &quot;lower&quot; and a column <code>interval_range</code> that contains the range of
the interval. If &quot;wide&quot;, there will be a column <code>interval_range</code> and two
columns <code>lower</code> and <code>upper</code> that contain the lower and upper bounds of the
prediction interval, respectively.</p>
</td></tr>
<tr><td><code id="quantile_to_interval_+3A_keep_quantile_col">keep_quantile_col</code></td>
<td>
<p>keep the <code>quantile_level</code> column in the final
output after transformation (default is FALSE). This only works if
<code>format = "long"</code>. If <code>format = "wide"</code>, the <code>quantile_level</code> column will
always be dropped.</p>
</td></tr>
<tr><td><code id="quantile_to_interval_+3A_observed">observed</code></td>
<td>
<p>Numeric vector of size n with the observed values.</p>
</td></tr>
<tr><td><code id="quantile_to_interval_+3A_predicted">predicted</code></td>
<td>
<p>Numeric nxN matrix of predictive
quantiles, n (number of rows) being the number of forecasts (corresponding
to the number of observed values) and N
(number of columns) the number of quantiles per forecast.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.</p>
</td></tr>
<tr><td><code id="quantile_to_interval_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Vector of of size N with the quantile levels
for which predictions were made.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with forecasts in an interval format.
</p>
<p><em>quantile_to_interval_dataframe</em>:
a data.table in an interval format (either &quot;long&quot; or &quot;wide&quot;), with or
without a <code>quantile_level</code> column. Rows will not be reordered.
</p>
<p><em>quantile_to_interval.numeric</em>:
a data.table in a wide interval format with columns <code>forecast_id</code>,
<code>observed</code>, <code>lower</code>, <code>upper</code>, and <code>interval_range</code>. The <code>forecast_id</code> column
is a unique identifier for each forecast. Rows will be reordered according to
<code>forecast_id</code> and <code>interval_range</code>.
</p>

<hr>
<h2 id='rps_ordinal'>Ranked Probability Score for ordinal outcomes</h2><span id='topic+rps_ordinal'></span>

<h3>Description</h3>

<p>The Ranked Probability Score (RPS) measures the difference between the predicted
and observed cumulative distribution functions. It is a proper scoring rule that
takes the ordering of categories into account. Small values are better
(best is zero, worst is N - 1 where N is the number of categories).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rps_ordinal(observed, predicted, predicted_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rps_ordinal_+3A_observed">observed</code></td>
<td>
<p>A factor of length n with N levels holding the observed
values.</p>
</td></tr>
<tr><td><code id="rps_ordinal_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive probabilities, n (number of rows)
being the number of observations and N (number of columns) the number of
possible outcomes.</p>
</td></tr>
<tr><td><code id="rps_ordinal_+3A_predicted_label">predicted_label</code></td>
<td>
<p>A factor of length N, denoting the outcome that the
probabilities in <code>predicted</code> correspond to.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of size n with ranked probability scores
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-nominal.png" style="width:750px;max-width:100%;" alt="metrics-nominal.png" />
</div><p>
Overview of required input format for nominal forecasts


</p>


<h3>Examples</h3>

<pre><code class='language-R'>factor_levels &lt;- c("one", "two", "three")
predicted_label &lt;- factor(factor_levels, levels = factor_levels, ordered = TRUE)
observed &lt;- factor(c("three", "three", "two"), levels = factor_levels, ordered = TRUE)
predicted &lt;- matrix(
  c(0.8, 0.1, 0.1,
    0.1, 0.2, 0.7,
    0.4, 0.4, 0.2),
  nrow = 3,
  byrow = TRUE
)
rps_ordinal(observed, predicted, predicted_label)
</code></pre>

<hr>
<h2 id='run_safely'>Run a function safely</h2><span id='topic+run_safely'></span>

<h3>Description</h3>

<p>This is a wrapper/helper function designed to run a function safely
when it is not completely clear what arguments could be passed to the
function.
</p>
<p>All named arguments in <code>...</code> that are not accepted by <code>fun</code> are removed.
All unnamed arguments are passed on to the function. In case <code>fun</code> errors,
the error will be converted to a warning and <code>run_safely</code> returns <code>NULL</code>.
</p>
<p><code>run_safely</code> can be useful when constructing functions to be used as
metrics in <code><a href="#topic+score">score()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_safely(..., fun, metric_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="run_safely_+3A_...">...</code></td>
<td>
<p>Arguments to pass to <code>fun</code>.</p>
</td></tr>
<tr><td><code id="run_safely_+3A_fun">fun</code></td>
<td>
<p>A function to execute.</p>
</td></tr>
<tr><td><code id="run_safely_+3A_metric_name">metric_name</code></td>
<td>
<p>A character string with the name of the metric. Used to
provide a more informative warning message in case <code>fun</code> errors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of <code>fun</code> or <code>NULL</code> if <code>fun</code> errors
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) {x}
scoringutils:::run_safely(2, fun = f, metric_name = "f")
scoringutils:::run_safely(2, y = 3, fun = f, metric_name = "f")
scoringutils:::run_safely(fun = f, metric_name = "f")
scoringutils:::run_safely(y = 3, fun = f, metric_name = "f")
</code></pre>

<hr>
<h2 id='sample_to_interval_long'>Change data from a sample-based format to a long interval range format</h2><span id='topic+sample_to_interval_long'></span>

<h3>Description</h3>

<p>Transform data from a format that is based on predictive samples to a format
based on interval ranges.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_to_interval_long(
  data,
  interval_range = c(0, 50, 90),
  type = 7,
  keep_quantile_col = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_to_interval_long_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="sample_to_interval_long_+3A_type">type</code></td>
<td>
<p>Type argument passed down to the quantile function. For more
information, see <code><a href="stats.html#topic+quantile">quantile()</a></code>.</p>
</td></tr>
<tr><td><code id="sample_to_interval_long_+3A_keep_quantile_col">keep_quantile_col</code></td>
<td>
<p>keep quantile_level column, default is TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table in a long interval interval range format
</p>

<hr>
<h2 id='score.forecast_binary'>Evaluate forecasts</h2><span id='topic+score.forecast_binary'></span><span id='topic+score.forecast_nominal'></span><span id='topic+score.forecast_ordinal'></span><span id='topic+score.forecast_point'></span><span id='topic+score.forecast_quantile'></span><span id='topic+score.forecast_sample'></span><span id='topic+score'></span>

<h3>Description</h3>

<p><code>score()</code> applies a selection of scoring metrics to a forecast
object.
<code>score()</code> is a generic that dispatches to different methods depending on the
class of the input data.
</p>
<p>See <code><a href="#topic+as_forecast_binary">as_forecast_binary()</a></code>, <code><a href="#topic+as_forecast_quantile">as_forecast_quantile()</a></code> etc. for information on
how to create a forecast object.
</p>
<p>See <code><a href="#topic+get_forecast_unit">get_forecast_unit()</a></code> for more information on the concept of a forecast
unit.
</p>
<p>For additional help and examples, check out the paper
<a href="https://arxiv.org/abs/2205.07090">Evaluating Forecasts with scoringutils in R</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forecast_binary'
score(forecast, metrics = get_metrics(forecast), ...)

## S3 method for class 'forecast_nominal'
score(forecast, metrics = get_metrics(forecast), ...)

## S3 method for class 'forecast_ordinal'
score(forecast, metrics = get_metrics(forecast), ...)

## S3 method for class 'forecast_point'
score(forecast, metrics = get_metrics(forecast), ...)

## S3 method for class 'forecast_quantile'
score(forecast, metrics = get_metrics(forecast), ...)

## S3 method for class 'forecast_sample'
score(forecast, metrics = get_metrics(forecast), ...)

score(forecast, metrics, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="score.forecast_binary_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
<tr><td><code id="score.forecast_binary_+3A_metrics">metrics</code></td>
<td>
<p>A named list of scoring functions. Names will be used as
column names in the output. See <code><a href="#topic+get_metrics">get_metrics()</a></code> for more information on the
default metrics used. See the <em>Customising metrics</em> section below for
information on how to pass custom arguments to scoring functions.</p>
</td></tr>
<tr><td><code id="score.forecast_binary_+3A_...">...</code></td>
<td>
<p>Currently unused. You <em>cannot</em> pass additional arguments to scoring
functions via <code>...</code>. See the <em>Customising metrics</em> section below for
details on how to use <code><a href="purrr.html#topic+partial">purrr::partial()</a></code> to pass arguments to individual
metrics.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Customising metrics</strong>
</p>
<p>If you want to pass arguments to a scoring function, you need change the
scoring function itself via e.g. <code><a href="purrr.html#topic+partial">purrr::partial()</a></code> and pass an updated list
of functions with your custom metric to the <code>metrics</code> argument in <code>score()</code>.
For example, to use <code><a href="#topic+interval_coverage">interval_coverage()</a></code> with <code>interval_range = 90</code>, you
would define a new function, e.g.
<code>interval_coverage_90 &lt;- purrr::partial(interval_coverage, interval_range = 90)</code>
and pass this new function to <code>metrics</code> in <code>score()</code>.
</p>
<p>Note that if you want to pass a variable as an argument, you can
unquote it with <code style="white-space: pre;">&#8288;!!&#8288;</code> to make sure the value is evaluated only once when the
function is created. Consider the following example:
</p>
<div class="sourceCode"><pre>custom_arg &lt;- "foo"
print1 &lt;- purrr::partial(print, x = custom_arg)
print2 &lt;- purrr::partial(print, x = !!custom_arg)

custom_arg &lt;- "bar"
print1() # prints 'bar'
print2() # prints 'foo'
</pre></div>


<h3>Value</h3>

<p>An object of class <code>scores</code>. This object is a data.table with
unsummarised scores (one score per forecast) and has an additional attribute
<code>metrics</code> with the names of the metrics used for scoring. See
<code><a href="#topic+summarise_scores">summarise_scores()</a></code>) for information on how to summarise
scores.
</p>


<h3>Author(s)</h3>

<p>Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a>
</p>


<h3>References</h3>

<p>Bosse NI, Gruson H, Cori A, van Leeuwen E, Funk S, Abbott S
(2022) Evaluating Forecasts with scoringutils in R.
<a href="https://doi.org/10.48550/arXiv.2205.07090">doi:10.48550/arXiv.2205.07090</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr) # pipe operator


validated &lt;- as_forecast_quantile(example_quantile)
score(validated) %&gt;%
  summarise_scores(by = c("model", "target_type"))

# set forecast unit manually (to avoid issues with scoringutils trying to
# determine the forecast unit automatically)
example_quantile %&gt;%
  as_forecast_quantile(
    forecast_unit = c(
      "location", "target_end_date", "target_type", "horizon", "model"
    )
  ) %&gt;%
  score()

# forecast formats with different metrics
## Not run: 
score(as_forecast_binary(example_binary))
score(as_forecast_quantile(example_quantile))
score(as_forecast_point(example_point))
score(as_forecast_sample(example_sample_discrete))
score(as_forecast_sample(example_sample_continuous))

## End(Not run)
</code></pre>

<hr>
<h2 id='scoring-functions-binary'>Metrics for binary outcomes</h2><span id='topic+scoring-functions-binary'></span><span id='topic+brier_score'></span><span id='topic+logs_binary'></span>

<h3>Description</h3>

<p><strong>Brier score</strong>
</p>
<p>The Brier Score is the mean squared error between the probabilistic
prediction and the observed outcome. The Brier score is a proper scoring
rule. Small values are better (best is 0, the worst is 1).
</p>
<p style="text-align: center;"><code class="reqn">
  \textrm{Brier\_Score} = (\textrm{prediction} - \textrm{outcome})^2,
</code>
</p>
<p> where <code class="reqn">\textrm{outcome} \in \{0, 1\}</code>, and
<code class="reqn">\textrm{prediction} \in [0, 1]</code> represents
the probability that the outcome is equal to 1.
</p>
<p><strong>Log score for binary outcomes</strong>
</p>
<p>The Log Score is the negative logarithm of the probability
assigned to the observed value. It is a proper scoring rule. Small values
are better (best is zero, worst is infinity).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brier_score(observed, predicted)

logs_binary(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scoring-functions-binary_+3A_observed">observed</code></td>
<td>
<p>A factor of length n with exactly two levels, holding
the observed values.
The highest factor level is assumed to be the reference level. This means
that <code>predicted</code> represents the probability that the observed value is
equal to the highest factor level.</p>
</td></tr>
<tr><td><code id="scoring-functions-binary_+3A_predicted">predicted</code></td>
<td>
<p>A numeric vector of length n, holding probabilities.
Values represent the probability that the corresponding outcome is equal to
the highest level of the factor <code>observed</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions require users to provide observed values as a factor in order
to distinguish its input from the input format required for scoring point
forecasts. Internally, however, factors will be converted to numeric values.
A factor <code style="white-space: pre;">&#8288;observed = factor(c(0, 1, 1, 0, 1)&#8288;</code> with two levels (<code>0</code> and <code>1</code>)
would internally be coerced to a numeric vector (in this case this would
result in the numeric vector <code>c(1, 2, 2, 1, 1)</code>). After subtracting 1, the
resulting vector (<code>c(0, 1, 1, 0)</code> in this case) is used for internal
calculations. All predictions are assumed represent the probability that the
outcome is equal of the last/highest factor level (in this case that the
outcome is equal to 1).
</p>
<p>You could alternatively also provide a vector like
<code>observed = factor(c("a", "b", "b", "a"))</code> (with two levels, <code>a</code> and <code>b</code>),
which would result in exactly the same internal representation. Probabilities
then represent the probability that the outcome is equal to &quot;b&quot;.
If you want your predictions to be probabilities that the outcome is &quot;a&quot;,
then you could of course make <code>observed</code> a factor with levels swapped, i.e.
<code>observed = factor(c("a", "b", "b", "a"), levels = c("b", "a"))</code>
</p>


<h3>Value</h3>

<p>A numeric vector of size n with the Brier scores
</p>
<p>A numeric vector of size n with log scores
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-binary-point.png" style="width:750px;max-width:100%;" alt="metrics-binary-point.png" />
</div><p>
Overview of required input format for binary and point forecasts


</p>


<h3>See Also</h3>

<p>Other log score functions: 
<code><a href="#topic+logs_categorical">logs_categorical</a>()</code>,
<code><a href="#topic+logs_sample">logs_sample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- factor(sample(c(0, 1), size = 30, replace = TRUE))
predicted &lt;- runif(n = 30, min = 0, max = 1)

brier_score(observed, predicted)
logs_binary(observed, predicted)
</code></pre>

<hr>
<h2 id='se_mean_sample'>Squared error of the mean (sample-based version)</h2><span id='topic+se_mean_sample'></span>

<h3>Description</h3>

<p>Squared error of the mean calculated as
</p>
<p style="text-align: center;"><code class="reqn">
  \textrm{mean}(\textrm{observed} - \textrm{mean prediction})^2
</code>
</p>

<p>The mean prediction is calculated as the mean of the predictive samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>se_mean_sample(observed, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="se_mean_sample_+3A_observed">observed</code></td>
<td>
<p>A vector with observed values of size n</p>
</td></tr>
<tr><td><code id="se_mean_sample_+3A_predicted">predicted</code></td>
<td>
<p>nxN matrix of predictive samples, n (number of rows) being
the number of data points and N (number of columns) the number of Monte
Carlo samples. Alternatively, <code>predicted</code> can just be a vector of size n.</p>
</td></tr>
</table>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-sample.png" style="width:750px;max-width:100%;" alt="metrics-sample.png" />
</div><p>
Overview of required input format for sample-based forecasts


</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- rnorm(30, mean = 1:30)
predicted_values &lt;- matrix(rnorm(30, mean = 1:30))
se_mean_sample(observed, predicted_values)
</code></pre>

<hr>
<h2 id='select_metrics'>Select metrics from a list of functions</h2><span id='topic+select_metrics'></span>

<h3>Description</h3>

<p>Helper function to return only the scoring rules selected by
the user from a list of possible functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_metrics(metrics, select = NULL, exclude = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_metrics_+3A_metrics">metrics</code></td>
<td>
<p>A list of scoring functions.</p>
</td></tr>
<tr><td><code id="select_metrics_+3A_select">select</code></td>
<td>
<p>A character vector of scoring rules to select from the list. If
<code>select</code> is <code>NULL</code> (the default), all possible scoring rules are returned.</p>
</td></tr>
<tr><td><code id="select_metrics_+3A_exclude">exclude</code></td>
<td>
<p>A character vector of scoring rules to exclude from the list.
If <code>select</code> is not <code>NULL</code>, this argument is ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of scoring functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>select_metrics(
  metrics = get_metrics(example_binary),
  select = "brier_score"
)
select_metrics(
  metrics = get_metrics(example_binary),
  exclude = "log_score"
)
</code></pre>

<hr>
<h2 id='set_forecast_unit'>Set unit of a single forecast manually</h2><span id='topic+set_forecast_unit'></span>

<h3>Description</h3>

<p>Helper function to set the unit of a single forecast (i.e. the
combination of columns that uniquely define a single forecast) manually.
This simple function keeps the columns specified in <code>forecast_unit</code> (plus
additional protected columns, e.g. for observed values, predictions or
quantile levels) and removes duplicate rows. <code>set_forecast_unit()</code> will
mainly be called when constructing a <code>forecast</code> object
via the <code>forecast_unit</code> argument in <code style="white-space: pre;">&#8288;as_forecast_&lt;type&gt;&#8288;</code>.
</p>
<p>If not done explicitly, <code>scoringutils</code> attempts to determine the unit
of a single forecast automatically by simply assuming that all column names
are relevant to determine the forecast unit. This may lead to unexpected
behaviour, so setting the forecast unit explicitly can help make the code
easier to debug and easier to read.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_forecast_unit(data, forecast_unit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_forecast_unit_+3A_data">data</code></td>
<td>
<p>A data.frame (or similar) with predicted and observed values.
See the details section of for additional information
on the required input format.</p>
</td></tr>
<tr><td><code id="set_forecast_unit_+3A_forecast_unit">forecast_unit</code></td>
<td>
<p>Character vector with the names of the columns that
uniquely identify a single forecast.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with only those columns kept that are relevant to
scoring or denote the unit of a single forecast as specified by the user.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr) # pipe operator
example_quantile %&gt;%
  scoringutils:::set_forecast_unit(
    c("location", "target_end_date", "target_type", "horizon", "model")
  )
</code></pre>

<hr>
<h2 id='summarise_scores'>Summarise scores as produced by <code><a href="#topic+score">score()</a></code></h2><span id='topic+summarise_scores'></span><span id='topic+summarize_scores'></span>

<h3>Description</h3>

<p>Summarise scores as produced by <code><a href="#topic+score">score()</a></code>.
</p>
<p><code>summarise_scores</code> relies on a way to identify the names of the scores and
distinguish them from columns that denote the unit of a single forecast.
Internally, this is done via a stored attribute, <code>metrics</code> that stores
the names of the scores. This means, however, that you need to be careful
with renaming scores after they have been produced by <code><a href="#topic+score">score()</a></code>. If you
do, you also have to manually update the attribute by calling
<code>attr(scores, "metrics") &lt;- new_names</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarise_scores(scores, by = "model", fun = mean, ...)

summarize_scores(scores, by = "model", fun = mean, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarise_scores_+3A_scores">scores</code></td>
<td>
<p>An object of class <code>scores</code> (a data.table with
scores and an additional attribute <code>metrics</code> as produced by <code><a href="#topic+score">score()</a></code>).</p>
</td></tr>
<tr><td><code id="summarise_scores_+3A_by">by</code></td>
<td>
<p>Character vector with column names to summarise scores by. Default
is &quot;model&quot;, i.e. scores are summarised by the &quot;model&quot; column.</p>
</td></tr>
<tr><td><code id="summarise_scores_+3A_fun">fun</code></td>
<td>
<p>A function used for summarising scores. Default is <code><a href="base.html#topic+mean">mean()</a></code>.</p>
</td></tr>
<tr><td><code id="summarise_scores_+3A_...">...</code></td>
<td>
<p>Additional parameters that can be passed to the summary function
provided to <code>fun</code>. For more information see the documentation of the
respective function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with summarised scores. Scores are summarised according
to the names of the columns of the original data specified in <code>by</code>
using the <code>fun</code> passed to <code>summarise_scores()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(magrittr) # pipe operator
scores &lt;- example_sample_continuous %&gt;%
 as_forecast_sample() %&gt;%
 score()

# get scores by model
summarise_scores(scores, by = "model")

# get scores by model and target type
summarise_scores(scores, by = c("model", "target_type"))

# get standard deviation
summarise_scores(scores, by = "model", fun = sd)

# round digits
summarise_scores(scores, by = "model") %&gt;%
  summarise_scores(fun = signif, digits = 2)
</code></pre>

<hr>
<h2 id='test_columns_not_present'>Test whether column names are NOT present in a data.frame</h2><span id='topic+test_columns_not_present'></span>

<h3>Description</h3>

<p>The function checks whether all column names are NOT present.
If none of the columns are present, the function returns TRUE. If one or
more columns are present, the function returns FALSE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_columns_not_present(data, columns)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_columns_not_present_+3A_data">data</code></td>
<td>
<p>A data.frame or similar to be checked</p>
</td></tr>
<tr><td><code id="test_columns_not_present_+3A_columns">columns</code></td>
<td>
<p>A character vector of column names to check</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if none of the columns are present and FALSE otherwise
</p>

<hr>
<h2 id='test_columns_present'>Test whether all column names are present in a data.frame</h2><span id='topic+test_columns_present'></span>

<h3>Description</h3>

<p>The function checks whether all column names are present. If
one or more columns are missing, the function returns FALSE. If all columns
are present, the function returns TRUE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_columns_present(data, columns)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_columns_present_+3A_data">data</code></td>
<td>
<p>A data.frame or similar to be checked</p>
</td></tr>
<tr><td><code id="test_columns_present_+3A_columns">columns</code></td>
<td>
<p>A character vector of column names to check</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns TRUE if all columns are present and FALSE otherwise
</p>

<hr>
<h2 id='theme_scoringutils'>Scoringutils ggplot2 theme</h2><span id='topic+theme_scoringutils'></span>

<h3>Description</h3>

<p>A theme for ggplot2 plots used in <code>scoringutils</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theme_scoringutils()
</code></pre>


<h3>Value</h3>

<p>A ggplot2 theme
</p>

<hr>
<h2 id='transform_forecasts'>Transform forecasts and observed values</h2><span id='topic+transform_forecasts'></span>

<h3>Description</h3>

<p>Function to transform forecasts and observed values before scoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_forecasts(
  forecast,
  fun = log_shift,
  append = TRUE,
  label = "log",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transform_forecasts_+3A_forecast">forecast</code></td>
<td>
<p>A forecast object (a validated data.table with predicted and
observed values).</p>
</td></tr>
<tr><td><code id="transform_forecasts_+3A_fun">fun</code></td>
<td>
<p>A function used to transform both observed values and predictions.
The default function is <code><a href="#topic+log_shift">log_shift()</a></code>, a custom function that is
essentially the same as <code><a href="base.html#topic+log">log()</a></code>, but has an additional arguments (<code>offset</code>)
that allows you add an offset before applying the logarithm. This is often
helpful as the natural log transformation is not defined at zero. A
common, and pragmatic solution, is to add a small offset to the data
before applying the log transformation. In our work we have often used an
offset of 1 but the precise value will depend on your application.</p>
</td></tr>
<tr><td><code id="transform_forecasts_+3A_append">append</code></td>
<td>
<p>Logical, defaults to <code>TRUE</code>. Whether or not to append a
transformed version of the data to the currently existing data (<code>TRUE</code>). If
selected, the data gets transformed and appended to the existing data,
making it possible to use the outcome directly in <code><a href="#topic+score">score()</a></code>. An additional
column, 'scale', gets created that denotes which rows or untransformed
('scale' has the value &quot;natural&quot;) and which have been transformed ('scale'
has the value passed to the argument <code>label</code>).</p>
</td></tr>
<tr><td><code id="transform_forecasts_+3A_label">label</code></td>
<td>
<p>A string for the newly created 'scale' column to denote the
newly transformed values. Only relevant if <code>append = TRUE</code>.</p>
</td></tr>
<tr><td><code id="transform_forecasts_+3A_...">...</code></td>
<td>
<p>Additional parameters to pass to the function you supplied. For
the default option of <code><a href="#topic+log_shift">log_shift()</a></code> this could be the <code>offset</code> argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are a few reasons, depending on the circumstances, for
why this might be desirable (check out the linked reference for more info).
In epidemiology, for example, it may be useful to log-transform incidence
counts before evaluating forecasts using scores such as the weighted interval
score (WIS) or the continuous ranked probability score (CRPS).
Log-transforming forecasts and observations changes the interpretation of
the score from a measure of absolute distance between forecast and
observation to a score that evaluates a forecast of the exponential growth
rate. Another motivation can be to apply a variance-stabilising
transformation or to standardise incidence counts by population.
</p>
<p>Note that if you want to apply a transformation, it is important to transform
the forecasts and observations and then apply the score. Applying a
transformation after the score risks losing propriety of the proper scoring
rule.
</p>


<h3>Value</h3>

<p>A forecast object with either a transformed version of the data, or
one with both the untransformed and the transformed data. includes the
original data as well as a transformation of the original data. There will
be one additional column, &lsquo;scale&rsquo;, present which will be set to &quot;natural&quot;
for the untransformed forecasts.
</p>


<h3>Author(s)</h3>

<p>Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a>
</p>


<h3>References</h3>

<p>Transformation of forecasts for evaluating predictive
performance in an epidemiological context
Nikos I. Bosse, Sam Abbott, Anne Cori, Edwin van Leeuwen, Johannes Bracher,
Sebastian Funk
medRxiv 2023.01.23.23284722
<a href="https://doi.org/10.1101/2023.01.23.23284722">doi:10.1101/2023.01.23.23284722</a>
<a href="https://www.medrxiv.org/content/10.1101/2023.01.23.23284722v1">https://www.medrxiv.org/content/10.1101/2023.01.23.23284722v1</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr) # pipe operator

# transform forecasts using the natural logarithm
# negative values need to be handled (here by replacing them with 0)
example_quantile %&gt;%
  .[, observed := ifelse(observed &lt; 0, 0, observed)] %&gt;%
  as_forecast_quantile() %&gt;%
# Here we use the default function log_shift() which is essentially the same
# as log(), but has an additional arguments (offset) that allows you add an
# offset before applying the logarithm.
  transform_forecasts(append = FALSE) %&gt;%
  head()

# alternatively, integrating the truncation in the transformation function:
example_quantile %&gt;%
  as_forecast_quantile() %&gt;%
 transform_forecasts(
   fun = function(x) {log_shift(pmax(0, x))}, append = FALSE
 ) %&gt;%
 head()

# specifying an offset for the log transformation removes the
# warning caused by zeros in the data
example_quantile %&gt;%
  as_forecast_quantile() %&gt;%
  .[, observed := ifelse(observed &lt; 0, 0, observed)] %&gt;%
  transform_forecasts(offset = 1, append = FALSE) %&gt;%
  head()

# adding square root transformed forecasts to the original ones
example_quantile %&gt;%
  .[, observed := ifelse(observed &lt; 0, 0, observed)] %&gt;%
  as_forecast_quantile() %&gt;%
  transform_forecasts(fun = sqrt, label = "sqrt") %&gt;%
  score() %&gt;%
  summarise_scores(by = c("model", "scale"))

# adding multiple transformations
example_quantile %&gt;%
  as_forecast_quantile() %&gt;%
  .[, observed := ifelse(observed &lt; 0, 0, observed)] %&gt;%
  transform_forecasts(fun = log_shift, offset = 1) %&gt;%
  transform_forecasts(fun = sqrt, label = "sqrt") %&gt;%
  head()
</code></pre>

<hr>
<h2 id='validate_metrics'>Validate metrics</h2><span id='topic+validate_metrics'></span>

<h3>Description</h3>

<p>This function validates whether the list of metrics is a list
of valid functions.
</p>
<p>The function is used in <code><a href="#topic+score">score()</a></code> to make sure that all metrics are valid
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_metrics(metrics)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate_metrics_+3A_metrics">metrics</code></td>
<td>
<p>A named list with metrics. Every element should be a scoring
function to be applied to the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of metrics, with those filtered out that are not
valid functions
</p>

<hr>
<h2 id='wis'>Weighted interval score (WIS)</h2><span id='topic+wis'></span><span id='topic+dispersion_quantile'></span><span id='topic+overprediction_quantile'></span><span id='topic+underprediction_quantile'></span>

<h3>Description</h3>

<p>The WIS is a proper scoring rule used to evaluate forecasts in an interval- /
quantile-based format. See Bracher et al. (2021). Smaller values are better.
</p>
<p>As the name suggest the score assumes that a forecast comes in the form of
one or multiple central prediction intervals. A prediction interval is
characterised by a lower and an upper bound formed by a pair of predictive
quantiles. For example, a 50% central prediction interval is formed by the
0.25 and 0.75 quantiles of the predictive distribution.
</p>
<p><strong>Interval score</strong>
</p>
<p>The interval score (IS) is the sum of three components:
overprediction, underprediction and dispersion. For a single prediction
interval only one of the components is non-zero. If for a single prediction
interval the observed value is below the lower bound, then the interval
score is equal to the absolute difference between the lower bound and the
observed value (&quot;underprediction&quot;). &quot;Overprediction&quot; is defined analogously.
If the observed value falls within the bounds of the prediction interval,
then the interval score is equal to the width of the prediction interval,
i.e. the difference between the upper and lower bound. For a single interval,
we therefore have:
</p>
<p style="text-align: center;"><code class="reqn">
\textrm{IS} = (\textrm{upper} - \textrm{lower}) + \frac{2}{\alpha}(\textrm{lower}
 - \textrm{observed}) *
\mathbf{1}(\textrm{observed} &lt; \textrm{lower}) +
\frac{2}{\alpha}(\textrm{observed} - \textrm{upper}) *
\mathbf{1}(\textrm{observed} &gt; \textrm{upper})
</code>
</p>

<p>where <code class="reqn">\mathbf{1}()</code> is the indicator function and
indicates how much is outside the prediction interval.
<code class="reqn">\alpha</code> is the decimal value that indicates how much is outside
the prediction interval. For a 90% prediction interval, for example,
<code class="reqn">\alpha</code> is equal to 0.1. No specific distribution is assumed,
but the interval formed by the quantiles has to be symmetric around the
median (i.e you can't use the 0.1 quantile as the lower bound and the 0.7
quantile as the upper bound).
Non-symmetric quantiles can be scored using the function <code><a href="#topic+quantile_score">quantile_score()</a></code>.
</p>
<p>For a set of <code class="reqn">k = 1, \dots, K</code> prediction intervals and the median
<code class="reqn">m</code>, we can compute a weighted interval score (WIS) as the sum of the
interval scores for individual intervals:
</p>
<p style="text-align: center;"><code class="reqn">
\text{WIS}_{\alpha_{\{0:K\}}}(F, y) = \frac{1}{K + 1/2}
\times \left(w_0 \times |y - m| + \sum_{k=1}^{K}
\left\{ w_k \times \text{IS}_{\alpha_k}(F, y) \right\}\right)
</code>
</p>

<p>The individual scores are usually weighted with
<code class="reqn">w_k = \frac{\alpha_k}{2}</code>. This weight ensures that
for an increasing number of equally spaced quantiles, the WIS
converges to the continuous ranked probability score (CRPS).
</p>
<p><strong>Quantile score</strong>
</p>
<p>In addition to the interval score, there also exists a quantile score (QS)
(see <code><a href="#topic+quantile_score">quantile_score()</a></code>), which is equal to the so-called pinball loss.
The quantile score can be computed for a single quantile (whereas the
interval score requires two quantiles that form an interval). However,
the intuitive decomposition into overprediction, underprediction and
dispersion does not exist for the quantile score.
</p>
<p><strong>Two versions of the weighted interval score</strong>
</p>
<p>There are two ways to conceptualise the weighted interval score across
several quantiles / prediction intervals and the median.
</p>
<p>In one view, you would treat the WIS as the average of quantile scores (and
the median as 0.5-quantile) (this is the default for <code>wis()</code>). In another
view, you would treat the WIS as the average of several interval scores +
the difference between the observed value and median forecast. The effect of
that is that in contrast to the first view, the median has twice as much
weight (because it is weighted like a prediction interval, rather than like
a single quantile). Both are valid ways to conceptualise the WIS and you
can control the behaviour with the <code>count_median_twice</code>-argument.
</p>
<p><strong>WIS components</strong>:
WIS components can be computed individually using the functions
<code>overprediction</code>, <code>underprediction</code>, and <code>dispersion.</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wis(
  observed,
  predicted,
  quantile_level,
  separate_results = FALSE,
  weigh = TRUE,
  count_median_twice = FALSE,
  na.rm = FALSE
)

dispersion_quantile(observed, predicted, quantile_level, ...)

overprediction_quantile(observed, predicted, quantile_level, ...)

underprediction_quantile(observed, predicted, quantile_level, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wis_+3A_observed">observed</code></td>
<td>
<p>Numeric vector of size n with the observed values.</p>
</td></tr>
<tr><td><code id="wis_+3A_predicted">predicted</code></td>
<td>
<p>Numeric nxN matrix of predictive
quantiles, n (number of rows) being the number of forecasts (corresponding
to the number of observed values) and N
(number of columns) the number of quantiles per forecast.
If <code>observed</code> is just a single number, then predicted can just be a
vector of size N.</p>
</td></tr>
<tr><td><code id="wis_+3A_quantile_level">quantile_level</code></td>
<td>
<p>Vector of of size N with the quantile levels
for which predictions were made.</p>
</td></tr>
<tr><td><code id="wis_+3A_separate_results">separate_results</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default is <code>FALSE</code>), then the
separate parts of the interval score (dispersion penalty, penalties for
over- and under-prediction get returned as separate elements of a list).
If you want a <code>data.frame</code> instead, simply call <code><a href="base.html#topic+as.data.frame">as.data.frame()</a></code> on the
output.</p>
</td></tr>
<tr><td><code id="wis_+3A_weigh">weigh</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), weigh the score by
<code class="reqn">\alpha / 2</code>, so it can be averaged into an interval score that, in
the limit (for an increasing number of equally spaced quantiles/prediction
intervals), corresponds
to the CRPS. <code class="reqn">\alpha</code> is the value that corresponds to the
(<code class="reqn">\alpha/2</code>) or (<code class="reqn">1 - \alpha/2</code>), i.e. it is the decimal
value that represents how much is outside a central prediction interval
(E.g. for a 90 percent central prediction interval, alpha is 0.1).</p>
</td></tr>
<tr><td><code id="wis_+3A_count_median_twice">count_median_twice</code></td>
<td>
<p>If TRUE, count the median twice in the score.</p>
</td></tr>
<tr><td><code id="wis_+3A_na.rm">na.rm</code></td>
<td>
<p>If TRUE, ignore NA values when computing the score.</p>
</td></tr>
<tr><td><code id="wis_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to <code>wis()</code> from functions
<code>overprediction_quantile()</code>, <code>underprediction_quantile()</code> and
<code>dispersion_quantile()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>wis()</code>: a numeric vector with WIS values of size n (one per observation),
or a list with separate entries if <code>separate_results</code> is <code>TRUE</code>.
</p>
<p><code>dispersion_quantile()</code>: a numeric vector with dispersion values (one per
observation).
</p>
<p><code>overprediction_quantile()</code>: a numeric vector with overprediction values
(one per observation).
</p>
<p><code>underprediction_quantile()</code>: a numeric vector with underprediction values
(one per observation)
</p>


<h3>Input format</h3>


<div style="text-align: left">
<p><img src="../help/figures/metrics-quantile.png" style="width:750px;max-width:100%;" alt="metrics-quantile.png" />
</div><p>
Overview of required input format for quantile-based forecasts


</p>


<h3>References</h3>

<p>Evaluating epidemic forecasts in an interval format,
Johannes Bracher, Evan L. Ray, Tilmann Gneiting and Nicholas G. Reich, 2021,
<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618">https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed &lt;- c(1, -15, 22)
predicted &lt;- rbind(
  c(-1, 0, 1, 2, 3),
  c(-2, 1, 2, 2, 4),
  c(-2, 0, 3, 3, 4)
)
quantile_level &lt;- c(0.1, 0.25, 0.5, 0.75, 0.9)
wis(observed, predicted, quantile_level)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
