<!DOCTYPE html><html><head><title>Help for package gecko</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gecko}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#clean'><p>Uniformize raster layers.</p></a></li>
<li><a href='#confusion.matrix'><p>Create a confusion matrix</p></a></li>
<li><a href='#create.east'><p>Create eastness layer.</p></a></li>
<li><a href='#create.lat'><p>Create latitude layer.</p></a></li>
<li><a href='#create.long'><p>Create longitude layer.</p></a></li>
<li><a href='#create.north'><p>Create northness layer.</p></a></li>
<li><a href='#distance'><p>Create distance layer.</p></a></li>
<li><a href='#gecko.data'><p>Example data packaged with gecko</p></a></li>
<li><a href='#gecko.getDir'><p>Read GIS directory.</p></a></li>
<li><a href='#gecko.setDir'><p>Setup GIS directory.</p></a></li>
<li><a href='#gecko.worldclim'><p>Download worldclim files.</p></a></li>
<li><a href='#move'><p>Move records to closest non-NA cell.</p></a></li>
<li><a href='#normalize'><p>Normalize raster.</p></a></li>
<li><a href='#outliers.detect'><p>Detect outliers in a set of geographical coordinates</p></a></li>
<li><a href='#outliers.visualize'><p>Visual detection of outliers.</p></a></li>
<li><a href='#performance.metrics'><p>Performance of model predictions</p></a></li>
<li><a href='#reduce'><p>Reduce dimensionality of raster layers.</p></a></li>
<li><a href='#spectre.area'><p>Get SPECTRE raster segments.</p></a></li>
<li><a href='#spectre.citations'><p>Get in text citations for SPECTRE layers</p></a></li>
<li><a href='#spectre.points'><p>Get SPECTRE data from points.</p></a></li>
<li><a href='#spectre.template'><p>Download the SPECTRE template.</p></a></li>
<li><a href='#spectrify'><p>Make a raster layer SPECTRE compatible</p></a></li>
<li><a href='#splitDataset'><p>Split a dataset for model training</p></a></li>
<li><a href='#stats'><p>Get a short summary of a given raster segment.</p></a></li>
<li><a href='#thin'><p>Spatial thinning of occurrence records.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Geographical Ecology and Conservation Knowledge Online</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>terra, sp, grDevices, graphics, stats, utils, geosphere,
methods, red, biomod2, kernlab</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/VascoBranco/gecko/issues">https://github.com/VascoBranco/gecko/issues</a></td>
</tr>
<tr>
<td>Author:</td>
<td>Vasco V. Branco <a href="https://orcid.org/0000-0001-7797-3183"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Pedro Cardoso <a href="https://orcid.org/0000-0001-8119-9960"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Luís Correia <a href="https://orcid.org/0000-0003-2439-1168"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Vasco V. Branco &lt;vasco.branco@helsinki.fi&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Includes a collection of geographical analysis functions aimed primarily at ecology and conservation science studies, allowing processing of both point and raster data. Future versions will integrate species threat datasets developed by the authors.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-23 11:05:28 UTC; witch-king-of-angmar</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-23 12:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='clean'>Uniformize raster layers.</h2><span id='topic+clean'></span>

<h3>Description</h3>

<p>Crop raster layers to minimum size possible and uniformize <code>NA</code> values across layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean(layers)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Excludes all marginal rows and columns with only <code>NA</code> values and change values to <code>NA</code> if they are <code>NA</code> in any of the layers.
</p>


<h3>Value</h3>

<p>SpatRaster. Same class as layers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>region = gecko.data("layers")
terra::plot(clean(region))
</code></pre>

<hr>
<h2 id='confusion.matrix'>Create a confusion matrix</h2><span id='topic+confusion.matrix'></span>

<h3>Description</h3>

<p>Create a confusion matrix for any multiclass set of predicted vs observed labels
in a classification problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion.matrix(actual, predicted)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusion.matrix_+3A_actual">actual</code></td>
<td>
<p>dataframe. Original labels.</p>
</td></tr>
<tr><td><code id="confusion.matrix_+3A_predicted">predicted</code></td>
<td>
<p>dataframe. Predicted labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame. Predicted labels (rows) x Observed labels (cols).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = c("FALSE", "TRUE", "FALSE", "TRUE", "TRUE")
y = c("TRUE", "TRUE", "TRUE", "TRUE", "TRUE")
confusion.matrix(x, y)
</code></pre>

<hr>
<h2 id='create.east'>Create eastness layer.</h2><span id='topic+create.east'></span>

<h3>Description</h3>

<p>Create a layer depicting eastness based on an elevation layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.east(layers)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.east_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. A layer of elevation (a digital elevation model - DEM). 
As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using elevation, aspect can be calculated. Yet, it is a circular variable (0 = 360) and has to be converted to northness and eastness to be useful for modelling.
</p>


<h3>Value</h3>

<p>SpatRaster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>region = gecko.data("layers")
terra::plot(create.east(region[[3]]))
</code></pre>

<hr>
<h2 id='create.lat'>Create latitude layer.</h2><span id='topic+create.lat'></span>

<h3>Description</h3>

<p>Create a layer depicting latitude based on any other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.lat(layers)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.lat_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using latitude (and longitude) in models may help limiting the extrapolation of the predicted area much beyond known areas.
</p>


<h3>Value</h3>

<p>SpatRaster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>region = gecko.data("layers")
terra::plot(create.lat(region[[1]]))
</code></pre>

<hr>
<h2 id='create.long'>Create longitude layer.</h2><span id='topic+create.long'></span>

<h3>Description</h3>

<p>Create a layer depicting longitude based on any other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.long(layers)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.long_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using longitude (and latitude) in models may help limiting the extrapolation of the predicted area much beyond known areas.
</p>


<h3>Value</h3>

<p>SpatRaster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>region = gecko.data("layers")
terra::plot(create.long(region))
</code></pre>

<hr>
<h2 id='create.north'>Create northness layer.</h2><span id='topic+create.north'></span>

<h3>Description</h3>

<p>Create a layer depicting northness based on an elevation layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.north(layers)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.north_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. A layer of elevation (a digital elevation model - DEM). 
As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using elevation, aspect can be calculated. Yet, it is a circular variable (0 = 360) and has to be converted to northness and eastness to be useful for modelling.
</p>


<h3>Value</h3>

<p>SpatRaster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>region = gecko.data("layers")
terra::plot(create.north(region[[3]]))
</code></pre>

<hr>
<h2 id='distance'>Create distance layer.</h2><span id='topic+distance'></span>

<h3>Description</h3>

<p>Creates a layer depicting distances to records using the minimum, average, distance to the minimum convex polygon or distance taking into account a cost surface.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distance(longlat, layers, type = "minimum")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distance_+3A_longlat">longlat</code></td>
<td>
<p>matrix. Matrix of longitude and latitude or eastness and northness (two columns in this order) of species occurrence records.</p>
</td></tr>
<tr><td><code id="distance_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>. To serve as model to create distance layer.</p>
</td></tr>
<tr><td><code id="distance_+3A_type">type</code></td>
<td>
<p>character. text string indicating whether the output should be the &quot;minimum&quot;, &quot;average&quot; or &quot;mcp&quot; distance to all records. &quot;mcp&quot; means the distance to the minimum convex polygon encompassing all records.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using distance to records in models may help limiting the extrapolation of the predicted area much beyond known areas.
</p>


<h3>Value</h3>

<p>SpatRaster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>userpar &lt;- par(no.readonly = TRUE) 
region = gecko.data("layers")
alt = region[[3]]
localities = gecko.data("records")
par(mfrow=c(3,2))
terra::plot(alt)
points(localities)
terra::plot(distance(localities, alt))
terra::plot(distance(localities, alt, type = "average"))
par(userpar)
</code></pre>

<hr>
<h2 id='gecko.data'>Example data packaged with gecko</h2><span id='topic+gecko.data'></span>

<h3>Description</h3>

<p>Load data included in the package. This includes <strong>records</strong>,
a matrix of longitude and latitude (two columns) occurrence records for
Hogna maderiana (Walckenaer, 1837); <strong>range</strong>, a SpatRaster object, as
defined by package terra, of the geographic range of Hogna maderiana
(Walckenaer, 1837); <strong>layers</strong>, a SpatRaster object with layers 
representing the average annual temperature, total annual precipitation,
altitude and landcover for Madeira Island
(Fick &amp; Hijmans 2017, Tuanmu &amp; Jetz 2014); <strong>threat</strong>, a layer of mean 
fire occurence in Madeira between 2006 and 2016; and <strong>worldborders</strong> is a
simplified version of the vector of world country borders created by
<a href="https://github.com/victorcazalis/RedList_countries">Victor Cazalis</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gecko.data(data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gecko.data_+3A_data">data</code></td>
<td>
<p>character. String of one of the data names mentioned in the description, e.g.: <code>"gecko.records"</code>.
If <code>NULL</code>, the example files will be listed.</p>
</td></tr>
</table>


<h3>Source</h3>

<p>This function is inspired by <code><a href="palmerpenguins.html#topic+path_to_file">palmerpanguins::path_to_file()</a></code>
which in turn is based on <code><a href="readxl.html#topic+readxl_example">readxl::readxl_example()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
gecko.data()
gecko.data("range")

## End(Not run)
</code></pre>

<hr>
<h2 id='gecko.getDir'>Read GIS directory.</h2><span id='topic+gecko.getDir'></span>

<h3>Description</h3>

<p>Read directory where GIS files are stored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gecko.getDir()
</code></pre>


<h3>Details</h3>

<p>Reads a txt file pointing to where the world GIS files are stored.
</p>

<hr>
<h2 id='gecko.setDir'>Setup GIS directory.</h2><span id='topic+gecko.setDir'></span>

<h3>Description</h3>

<p>Setup directory where GIS files are stored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gecko.setDir(gisPath = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gecko.setDir_+3A_gispath">gisPath</code></td>
<td>
<p>Path to the directory where the gis files are stored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Writes a txt file in the red directory allowing the package to always access the world GIS files directory.
</p>

<hr>
<h2 id='gecko.worldclim'>Download worldclim files.</h2><span id='topic+gecko.worldclim'></span>

<h3>Description</h3>

<p>Download the latest version of worldclim to your gecko work directory. 
If you have not yet setup a work directory, it will be be setup as if running 
<code><a href="#topic+gecko.setDir">gecko::gecko.setDir()</a></code> with <code>gisPath = NULL</code>.
This is a large dataset that is prone to fail by timeout if downloaded 
through R. Instead of using this function you can run gecko.setDir() (if you 
haven't yet) and download the files at 
https://geodata.ucdavis.edu/climate/worldclim/2_1/base/wc2.1_30s_bio.zip or 
https://geodata.ucdavis.edu/climate/worldclim/2_1/base/wc2.1_10m_bio.zip. 
Unzip their contents correspondingly to the folders &quot;./worldclim/1 km&quot; or 
&quot;./worldclim/10 km&quot; inside the folder returned by gecko.getDir().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gecko.worldclim(res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gecko.worldclim_+3A_res">res</code></td>
<td>
<p>character. Specifies the resolution of environmental data used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads a txt file pointing to where the world GIS files are stored.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
gecko.worldclim("10 km")

## End(Not run)
</code></pre>

<hr>
<h2 id='move'>Move records to closest non-NA cell.</h2><span id='topic+move'></span>

<h3>Description</h3>

<p>Identifies and moves presence records to cells with environmental values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>move(longlat, layers, buffer = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="move_+3A_longlat">longlat</code></td>
<td>
<p>matrix. Matrix of longitude and latitude or eastness and northness (two columns in this order) of species occurrence records.</p>
</td></tr>
<tr><td><code id="move_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>.</p>
</td></tr>
<tr><td><code id="move_+3A_buffer">buffer</code></td>
<td>
<p>numeric. Maximum distance in map units that a record will move. If 0 all <code>NA</code> records will be changed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Often records are in coastal or other areas for which no environmental data is available. This function moves such records to the closest cells with data so that no information is lost during modelling.
</p>


<h3>Value</h3>

<p>A matrix with new coordinate values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>region &lt;- terra::rast(matrix(c(rep(NA,100), rep(1,100), rep(NA,100)), ncol = 15))
presences &lt;- cbind(runif(100, 0, 0.55), runif(100, 0, 1))
terra::plot(region)
points(presences)
presences &lt;- move(presences, region)
terra::plot(region)
points(presences)
</code></pre>

<hr>
<h2 id='normalize'>Normalize raster.</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>Normalize a raster file according to one three methods, 'standard', 'range' or 'rank'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(layer, method = "standard", filepath = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize_+3A_layer">layer</code></td>
<td>
<p>SpatRaster. Object with a single layer as defined by package terra.</p>
</td></tr>
<tr><td><code id="normalize_+3A_method">method</code></td>
<td>
<p>character. Specifying <code>'standard'</code>, <code>'range'</code> or <code>'rank'</code>.</p>
</td></tr>
<tr><td><code id="normalize_+3A_filepath">filepath</code></td>
<td>
<p>character. Optional, specifies a path to the output file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The three options, &quot;standard&quot; standardizes data to a mean = 0 and sd = 1,
&quot;range&quot; standardizes to a range of 0 to 1, and &quot;rank&quot; similarly standardizes to
a range of 0 to 1 but does so after ranking all points.
</p>


<h3>Value</h3>

<p>A raster layer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
region = gecko.data("layers")[[1]]
ranked_region = normalize(region, method = "rank")

## End(Not run)
</code></pre>

<hr>
<h2 id='outliers.detect'>Detect outliers in a set of geographical coordinates</h2><span id='topic+outliers.detect'></span>

<h3>Description</h3>

<p>This function generates pseudo-abscences from an input data.frame
containing latitude and longitude coordinates by using environmental data and
then uses both presences and pseudo-absences to train a SVM model used to 
flag possible outliers for a given species.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outliers.detect(
  longlat,
  training = NULL,
  hi_res = TRUE,
  crop = FALSE,
  threshold = 0.05,
  method = "all"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outliers.detect_+3A_longlat">longlat</code></td>
<td>
<p>data.frame. With two columns containing latitude and longitude, describing
the locations of a species, which may contain outliers.</p>
</td></tr>
<tr><td><code id="outliers.detect_+3A_training">training</code></td>
<td>
<p>data.frame. With the same formatting as <code>longlat</code>, indicating only known
locations where a target species occurs. Used exclusively as training data for
method 'svm'.</p>
</td></tr>
<tr><td><code id="outliers.detect_+3A_hi_res">hi_res</code></td>
<td>
<p>logical. Specifies if 1 KM resolution environmental data should be used. 
If <code>FALSE</code> 10 KM resolution data is used instead.</p>
</td></tr>
<tr><td><code id="outliers.detect_+3A_crop">crop</code></td>
<td>
<p>logical. Indicates whether environmental data should be cropped to
an extent similar to what is given in <code>longlat</code> and <code>training</code>. Useful to avoid
large processing times of higher resolutions.</p>
</td></tr>
<tr><td><code id="outliers.detect_+3A_threshold">threshold</code></td>
<td>
<p>numeric. Value indicating the threshold for classifying 
outliers in methods <code>"geo"</code> and <code>"env"</code>. E.g.: under the default
of 0.05, points that are at an average distance greater than the 95
of the average distances of all points, will be classified as outliers.</p>
</td></tr>
<tr><td><code id="outliers.detect_+3A_method">method</code></td>
<td>
<p>A string specifying the outlier detection method. <code>"geo"</code> 
calculates the euclidean distance between point coordinates and classifies as
outliers those outside the 0
<code>"env"</code>
performs the same calculation but instead uses the environmental data extracted
from those points. <code>"svm"</code> will use the dataset given to <code>"longlat"</code> and it corresponding
extracted environmental data to train a support vector machine model that then
predicts outliers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Environmental data used is WorldClim and requires a long download, see
<code><a href="#topic+gecko.setDir">gecko::gecko.setDir()</a></code>
This function is heavily based on the methods described in Liu et al. (2017). 
There the authors describe SVM_pdSDM, a pseudo-SDM method similar to a 
two-class presence only SVM that is capable of using pseudo-absence points, 
implemented with the ksvm function in the R package kernlab. 
It is suggested that, for each set of <code>"n"</code> occurence 
records, <code>"2 * n"</code> pseudo-absences points are generated.
Whilst using it keep in mind works highlighting limitations such as such as
Meynard et al. (2019). See References section.
</p>


<h3>Value</h3>

<p>list if <code>method = "all"</code>, containing whether or not a given point
was classified as <code>TRUE</code> or <code>FALSE</code> along with the confusion matrix
for the training data. If <code>method = "geo"</code> or 
<code>method = "env"</code> a data.frame is returned.
</p>


<h3>References</h3>

<p>Liu, C., White, M. and Newell, G. (2017) ‘Detecting outliers in species distribution data’, Journal of Biogeography, 45(1), pp. 164–176. doi:10.1111/jbi.13122. <br />
<br />
Meynard, C.N., Kaplan, D.M. and Leroy, B. (2019) ‘Detecting outliers in species distribution data: Some caveats and clarifications on a virtual species study’, Journal of Biogeography, 46(9), pp. 2141–2144. doi:10.1111/jbi.13626. <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
new_occurences = gecko.data("records")
old_occurences = data.frame(X = runif(10, -17.1, -17.05), Y = runif(10, 32.73, 32.76))
outliers.detect(new_occurences, old_occurences)

## End(Not run)
</code></pre>

<hr>
<h2 id='outliers.visualize'>Visual detection of outliers.</h2><span id='topic+outliers.visualize'></span>

<h3>Description</h3>

<p>Draws plots of sites in geographical (longlat) and environmental (2-axis PCA) space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outliers.visualize(longlat, layers)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outliers.visualize_+3A_longlat">longlat</code></td>
<td>
<p>matrix. Matrix of longitude and latitude or eastness and northness (two columns in this order) of species occurrence records.</p>
</td></tr>
<tr><td><code id="outliers.visualize_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>. It can be any set of environmental layers thought to allow the identification of environmental outliers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Erroneous data sources or errors in transcriptions may introduce outliers that can be easily detected by looking at simple graphs of geographical or environmental space.
</p>


<h3>Value</h3>

<p>data.frame. Contains coordinate values and distance to centroid in pca. Two plots are drawn for visual inspection. The environmental plot includes row numbers for easy identification of possible outliers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>localities = gecko.data("records")
region = gecko.data("layers")
outliers.visualize(localities, region[[1:3]])
</code></pre>

<hr>
<h2 id='performance.metrics'>Performance of model predictions</h2><span id='topic+performance.metrics'></span>

<h3>Description</h3>

<p>Calculate the performance of a model through a comparison 
between predicted and observed labels. Available metrics are <code>accuracy</code>,
<code>F1</code> and <code>TSS</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performance.metrics(actual, predicted, metric)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="performance.metrics_+3A_actual">actual</code></td>
<td>
<p>dataframe. Same formatting as <code>y</code>, containg some sort of classification data.</p>
</td></tr>
<tr><td><code id="performance.metrics_+3A_predicted">predicted</code></td>
<td>
<p>dataframe. Same formatting as <code>x</code>, containg the predicted classifications of a model trained over the data in <code>x</code>.</p>
</td></tr>
<tr><td><code id="performance.metrics_+3A_metric">metric</code></td>
<td>
<p>character. String specifying the metric used, one of <code>accuracy</code>, <code>F1</code> and <code>TSS</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>The F-score or F-measure (F1)</strong> is: <br />
<br />
<code class="reqn">F1 = 2 \dfrac{Precision * Recall}{Precision + Recall}</code>, with <br />
<br />
<code class="reqn">Precision = \dfrac{True Positive}{True Positive + False Positive}</code> <br />
<br />
<code class="reqn">Recall = \dfrac{True Positive}{True Positive + False Negative}</code> <br />
<br />
<strong>Accuracy</strong> is: <br />
<br />
<code class="reqn">\dfrac{100 * (True Postives + True Negatives)}{True Postives + True Negatives + False Positives + False Negatives}</code>
<br />
<br />
<strong>The Pierce's skill score (PSS),  Bookmaker's Informedness (BM) or True Skill Statistic (TSS)</strong> is: <br />
<br />
<code class="reqn">TSS = TPR + TNR - 1</code>, <br />
with <code class="reqn">TPR</code> being the True Positive Rate, positives correctly labelled 
as such and <code class="reqn">TNR</code>, the True Negative Rate, the rate of negatives correctly
labelled, such that:<br />
<br />
<code class="reqn">TPR = \dfrac{True Positives}{True Positives + False Negatives}</code>
<br />
<code class="reqn">TNR = \dfrac{True Negatives}{True Negatives + False Positives}</code>
<br />
Take in consideration the fact that the F1 score is not a robust metric in datasets with class imbalances.
</p>


<h3>Value</h3>

<p>numeric.
</p>


<h3>References</h3>

<p>PSS:
Peirce, C. S. (1884). The numerical measure of the success of predictions. Science, 4, 453–454.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>observed = c("FALSE", "TRUE", "FALSE", "TRUE", "TRUE")
predicted = c("TRUE", "TRUE", "TRUE", "TRUE", "TRUE")
performance.metrics(observed, predicted, "TSS")
</code></pre>

<hr>
<h2 id='reduce'>Reduce dimensionality of raster layers.</h2><span id='topic+reduce'></span>

<h3>Description</h3>

<p>Reduce the number of layers by either performing a PCA on them or by eliminating highly correlated ones.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reduce(layers, method = "pca", n = NULL, thres = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reduce_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. As defined in package terra, see <code><a href="terra.html#topic+rast">terra::rast()</a></code>.</p>
</td></tr>
<tr><td><code id="reduce_+3A_method">method</code></td>
<td>
<p>character. Either Principal Components Analysis (&quot;pca&quot;, default) or Pearson's correlation (&quot;cor&quot;).</p>
</td></tr>
<tr><td><code id="reduce_+3A_n">n</code></td>
<td>
<p>numeric. Number of layers to reduce to.</p>
</td></tr>
<tr><td><code id="reduce_+3A_thres">thres</code></td>
<td>
<p>numeric. Value for pairwise Pearson's correlation above which one of the layers (randomly selected) is eliminated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using a large number of explanatory variables in models with few records may lead to overfitting. This function allows to avoid it as much as possible.
If both n and thres are given, n has priority. If method is not recognized and layers come from read function, only landcover is reduced by using only the dominating landuse of each cell.
</p>


<h3>Value</h3>

<p>SpatRaster.
</p>

<hr>
<h2 id='spectre.area'>Get SPECTRE raster segments.</h2><span id='topic+spectre.area'></span>

<h3>Description</h3>

<p>Downloads SPECTRE segments according to a bounding box selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectre.area(
  index,
  ext = c(-180, 180, -60, 90),
  normalize = FALSE,
  filepath = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spectre.area_+3A_index">index</code></td>
<td>
<p>numeric. A vector of integers specifying the layers. Refer to the list.</p>
</td></tr>
<tr><td><code id="spectre.area_+3A_ext">ext</code></td>
<td>
<p>numeric or SpatExtent. A vector of <code>xmin</code>, <code>xmax</code>, <code>ymin</code>, <code>ymax</code> or a <code>terra</code> 
spatial extent object (See <code><a href="terra.html#topic+ext">terra::ext()</a></code>). If no 
input is given, an extent of <code>xmin = -180, xmax = 180, ymin = -60, ymax = 90</code> is selected.</p>
</td></tr>
<tr><td><code id="spectre.area_+3A_normalize">normalize</code></td>
<td>
<p>character or logical. Either logical on whether data should be normalized 
for the given interval or a character specifying a type of normalization. Type
default to &quot;standard&quot;. Check <code><a href="#topic+normalize">gecko::normalize()</a></code>
for more info.</p>
</td></tr>
<tr><td><code id="spectre.area_+3A_filepath">filepath</code></td>
<td>
<p>character. An optional user defined path for the final output. If <code>NULL</code>, requested files are left in the current temp directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>SpatRaster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
regional_threats = spectre.area(3, terra::ext(-17.3,-16.6,32.6,32.9), normalize = FALSE)
terra::plot(regional_threats[[1]], main = "Human Density")

## End(Not run)
</code></pre>

<hr>
<h2 id='spectre.citations'>Get in text citations for SPECTRE layers</h2><span id='topic+spectre.citations'></span>

<h3>Description</h3>

<p>Generate in-text citations for a selection of SPECTRE layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectre.citations(index)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spectre.citations_+3A_index">index</code></td>
<td>
<p>numeric. A vector of integers specifying the layers. Refer to the Details section.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The current layers in SPECTRE are:
</p>

<ol>
<li> <p><strong>MINING_AREA</strong>. Mining density based on the number of known mining properties (pre-operational, operational, and closed) in a 50-cell radius (1x1 km cells).
</p>
</li>
<li> <p><strong>HAZARD_POTENTIAL</strong>. Number of significant hazards (earthquakes, volcanoes, landslides, floods, drought, cyclones) potentially affecting cells based on hazard frequency data.
</p>
</li>
<li> <p><strong>HUMAN_DENSITY</strong> Continuous metric of population density.
</p>
</li>
<li> <p><strong>BUILT_AREA</strong> Percentage metric indicating the built-up presence.
</p>
</li>
<li> <p><strong>ROAD_DENSITY</strong>. Continuous metric of road density.
</p>
</li>
<li> <p><strong>FOOTPRINT_PERC</strong>. Percentage metric indicating anthropogenic impacts on the environment.
</p>
</li>
<li> <p><strong>IMPACT_AREA</strong>. Classification of land into very low impact areas (1), low impact areas (2) and non-low impact areas (3).
</p>
</li>
<li> <p><strong>MODIF_AREA</strong>. Continuous 0-1 metric that reflects the proportion of a landscape that has been modified.
</p>
</li>
<li> <p><strong>HUMAN_BIOMES</strong>. Classification of land cover into different anthropogenic biomes of differing pressure such as dense settlements, villages and cropland.
</p>
</li>
<li> <p><strong>FIRE_OCCUR</strong>. Continuous metric of mean fire occurrence during the years of 2006 and 2016.
</p>
</li>
<li> <p><strong>CROP_PERC_UNI</strong>. Percentage metric indicating the proportion of cropland in each cell.
</p>
</li>
<li> <p><strong>CROP_PERC_IIASA</strong>. Percentage metric indicating the proportion of cropland in each cell.
</p>
</li>
<li> <p><strong>LIVESTOCK_MASS</strong>. Estimated total amount of livestock wet biomass based on global livestock head counts.
</p>
</li>
<li> <p><strong>FOREST_LOSS_PERC</strong>. Continuous -100 to 100 metric of forest tree cover loss between 2007 and 2017.
</p>
</li>
<li> <p><strong>FOREST_TREND</strong>. Classification metric of 0 (no loss) or a discrete value from 1 to 17, representing loss (a stand-replacement disturbance or change from a forest to non-forest state) detected primarily in the year 2001-2019, respectively.
</p>
</li>
<li> <p><strong>NPPCARBON_GRAM</strong>. Quantity of carbon needed to derive food and fiber products (HANPP).
</p>
</li>
<li> <p><strong>NPPCARBON_PERC</strong>. HANNP as a percentage of local Net Primary Productivity.
</p>
</li>
<li> <p><strong>LIGHT_MCDM2</strong>. Continuous simulated zenith radiance data.
</p>
</li>
<li> <p><strong>FERTILIZER_LGHA</strong>. Continuous metric of kilograms of fertilizer used per hectare.
</p>
</li>
<li> <p><strong>TEMP_TRENDS</strong>. Continuous metric of temperature trends, based on the linear regression coefficients of mean monthly temperature for the years of 1950 to 2019.
</p>
</li>
<li> <p><strong>TEMP_SIGNIF</strong>. Continuous metric of temperature trend significance, the temperature trends divided by its standard error.
</p>
</li>
<li> <p><strong>CLIM_EXTREME</strong>. Continuous metric calculated as whatever is the largest of the absolute of the trend coefficients of the months with the lowest or highest mean temperatures.
</p>
</li>
<li> <p><strong>CLIM_VELOCITY</strong>. Continuous metric of the velocity of climate change, the ratio between TEMP_TRENDS and a local spatial gradient in mean temperature calculated as the slope of a plane fitted to the values of a 3x3 cell neighbourhood centered on each pixel.
</p>
</li>
<li> <p><strong>ARIDITY_TREND</strong>. Continuous metric of aridity trends, based on the linear regression coefficients of aridity for the years of 1990 to 2019, i.e: MPET/(MPRE+1).
</p>
</li></ol>



<h3>Value</h3>

<p>list. Contains two elements, both characters: the first a single 
character containing the in-text citations, the second a character of 
length <code>x</code> with the bibliographic citations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sources = c(2,3)
out = spectre.citations(sources)
</code></pre>

<hr>
<h2 id='spectre.points'>Get SPECTRE data from points.</h2><span id='topic+spectre.points'></span>

<h3>Description</h3>

<p>Downloads SPECTRE layer data according to a selection of points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectre.points(index, points)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spectre.points_+3A_index">index</code></td>
<td>
<p>numeric. A vector of integers specifying the layers. Refer to the documentation of 
<code><a href="#topic+spectre.citations">gecko::spectre.citations()</a></code> for a list
of available layers.</p>
</td></tr>
<tr><td><code id="spectre.points_+3A_points">points</code></td>
<td>
<p>data.frame or matrix. Containing point data coordinates, organized in longitude, latitude (longlat).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame or matrix. Contains both the points given as well as 
their respective values for each layer specified.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
localities = gecko.data("records")
local_threats = spectre.points(c(2,3), localities)

## End(Not run)
</code></pre>

<hr>
<h2 id='spectre.template'>Download the SPECTRE template.</h2><span id='topic+spectre.template'></span>

<h3>Description</h3>

<p>Download the raster template for SPECTRE layers to your gecko work directory. 
If you have not yet setup a work directory, it will be be setup as if running 
<code><a href="#topic+gecko.setDir">gecko::gecko.setDir()</a></code> with <code>gisPath = NULL</code>.
This is a large dataset that is prone to fail by timeout if downloaded 
through R. Instead of using this function you can run gecko.setDir() (if you 
haven't yet) and download the file at 
https://github.com/VascoBranco/spectre.content/raw/main/spectre.template.zip.
Unzip its contents to a folder &quot;./spectretemplate&quot; inside the folder returned by gecko.getDir().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectre.template()
</code></pre>


<h3>Details</h3>

<p>Reads a txt file pointing to where the world GIS files are stored.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spectre.template()

## End(Not run)
</code></pre>

<hr>
<h2 id='spectrify'>Make a raster layer SPECTRE compatible</h2><span id='topic+spectrify'></span>

<h3>Description</h3>

<p>Transform a given raster object to the resolution, datum, 
projection and extent used in SPECTRE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectrify(layers, continuous = TRUE, filepath = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spectrify_+3A_layers">layers</code></td>
<td>
<p>SpatRaster. A raster object that you would like to be SPECTRE compatible.</p>
</td></tr>
<tr><td><code id="spectrify_+3A_continuous">continuous</code></td>
<td>
<p>logical. Whether the data present in <code>layers</code> is continuous. 
If <code>TRUE</code> bilinear interpolation will be used in the case of resampling and reprojection. 
if <code>FALSE</code> nearest neighbour will be used instead. 
See <code><a href="terra.html#topic+resample">terra::resample()</a></code> for more information on interpolation methods.</p>
</td></tr>
<tr><td><code id="spectrify_+3A_filepath">filepath</code></td>
<td>
<p>character. Optional file path to where the final raster layer 
should be saved, in the format &quot;folder/file.tif&quot;. If <code>filepath</code> is <code>NULL</code> 
your layer will be saved to your current working directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>SpatRaster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# For the sake of demonstration we will transform our raster layer "range".
distribution = gecko.data("range")
standard_dist = spectrify(distribution)
terra::plot(standard_dist)

## End(Not run)
</code></pre>

<hr>
<h2 id='splitDataset'>Split a dataset for model training</h2><span id='topic+splitDataset'></span>

<h3>Description</h3>

<p>Split a dataset for model training while keeping class representativity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitDataset(data, proportion)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitDataset_+3A_data">data</code></td>
<td>
<p>dataframe. Containg some sort of classification data. The last column
must contain the label data.</p>
</td></tr>
<tr><td><code id="splitDataset_+3A_proportion">proportion</code></td>
<td>
<p>numeric. A value between 0 a 1 determining the proportion of the dataset 
split between training and testing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list. First element is the train data, second element is the test data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Binary label case
my_data = data.frame(X = runif(20), Y = runif(20), Z = runif(20), Label =
c(rep("presence", 10), rep("outlier", 10)) )
splitDataset(my_data, 0.8)

# Multi label case
my_data = data.frame(X = runif(60), Y = runif(60), Z = runif(60), Label =
c(rep("A", 20), rep("B", 30), rep("C", 10)) )
splitDataset(my_data, 0.8)
</code></pre>

<hr>
<h2 id='stats'>Get a short summary of a given raster segment.</h2><span id='topic+stats'></span>

<h3>Description</h3>

<p>Return a set of descriptive statistics of the given layer,
either a specific one (minimum, q1, median, q3, maximum,
median absolute deviation (mad), mean, standard deviation (sd)) or all of them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stats(layer, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stats_+3A_layer">layer</code></td>
<td>
<p>SpatRaster. Raster object, as defined by package terra, with a single layer.</p>
</td></tr>
<tr><td><code id="stats_+3A_plot">plot</code></td>
<td>
<p>logical. If TRUE, a histogram of raster values is drawn.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame. If plot is TRUE, also outputs a histogram of the layer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>region = gecko.data("layers")
stats(region[[1]])
</code></pre>

<hr>
<h2 id='thin'>Spatial thinning of occurrence records.</h2><span id='topic+thin'></span>

<h3>Description</h3>

<p>Thinning of records with minimum distances either absolute or relative to the species range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thin(longlat, distance = 0.01, relative = TRUE, runs = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thin_+3A_longlat">longlat</code></td>
<td>
<p>matrix. Matrix of longitude and latitude or eastness and northness (two columns in this order) of species occurrence records.</p>
</td></tr>
<tr><td><code id="thin_+3A_distance">distance</code></td>
<td>
<p>numeric. Distance either in relative terms (proportion of maximum distance between any two records) or in raster units.</p>
</td></tr>
<tr><td><code id="thin_+3A_relative">relative</code></td>
<td>
<p>logical. If <code>TRUE</code>, represents the proportion of maximum distance between any two records. If <code>FALSE</code>, is in raster units.</p>
</td></tr>
<tr><td><code id="thin_+3A_runs">runs</code></td>
<td>
<p>numeric. Number of runs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Clumped distribution records due to ease of accessibility of sites, emphasis of sampling on certain areas in the past, etc. may bias species distribution models.
The algorithm used here eliminates records closer than a given distance to any other record. The choice of records to eliminate is random, so a number of runs are made and the one keeping more of the original records is chosen.
</p>


<h3>Value</h3>

<p>A matrix of species occurrence records separated by at least the given distance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>userpar &lt;- par(no.readonly = TRUE)
occ_points &lt;- matrix(sample(100), ncol = 2)
par(mfrow=c(1,2))
graphics::plot(occ_points)
occ_points &lt;- thin(occ_points, 0.1)
graphics::plot(occ_points)
par(userpar)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
