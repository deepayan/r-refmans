<!DOCTYPE html><html><head><title>Help for package hddplot</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hddplot}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#accTrainTest'><p>Two subsets of data each take in turn the role of test set</p></a></li>
<li><a href='#aovFbyrow'><p>calculate aov F-statistic for each row of a matrix</p></a></li>
<li><a href='#cvdisc'><p>Cross-validated accuracy, in linear discriminant calculations</p></a></li>
<li><a href='#cvscores'><p>For high-dimensional data with known groups, derive scores for plotting</p></a></li>
<li><a href='#defectiveCVdisc'><p>defective accuracy assessments from linear discriminant calculations</p></a></li>
<li><a href='#divideUp'><p>Partition data into mutiple nearly equal subsets</p></a></li>
<li><a href='#Golub'><p>Golub data (7129 rows by 72 columns), after normalization</p></a></li>
<li><a href='#golubInfo'><p>Classifying factors for the 72 columns of the Golub data set</p></a></li>
<li><a href='#orderFeatures'><p>Order features, based on their ability to discriminate</p></a></li>
<li><a href='#pcp'><p>convenience version of the singular value decomposition</p></a></li>
<li><a href='#plotTrainTest'><p>Plot predictions for both a I/II train/test split, and the reverse</p></a></li>
<li><a href='#qqthin'><p>a version of qqplot() that thins out points that overplot</p></a></li>
<li><a href='#scoreplot'><p>Plot discriminant function scores, with various identification</p></a></li>
<li><a href='#simulateScores'><p>Generate linear discriminant scores from random data, after selection</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Use Known Groups in High-Dimensional Data to Derive Scores for
Plots</td>
</tr>
<tr>
<td>Version:</td>
<td>0.59-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-13</td>
</tr>
<tr>
<td>Author:</td>
<td>John Maindonald</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>John Maindonald &lt;jhmaindonald@gmail.com&gt;</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Description:</td>
<td>Cross-validated linear discriminant calculations determine
  the optimum number of features. Test and training scores from
  successive cross-validation steps determine, via a principal
  components calculation, a low-dimensional global space onto which test
  scores are projected, in order to plot them. Further functions are
  included that are intended for didactic use. The  package implements,
  and extends, methods described in J.H. Maindonald and C.J. Burden (2005)
  <a href="https://journal.austms.org.au/V46/CTAC2004/Main/home.html">https://journal.austms.org.au/V46/CTAC2004/Main/home.html</a>.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/jhmaindonald/hddplot">https://github.com/jhmaindonald/hddplot</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>true</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, multtest</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr</td>
</tr>
<tr>
<td>ZipData:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-14 02:53:13 UTC; johnm1</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-14 04:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='accTrainTest'>Two subsets of data each take in turn the role of test set</h2><span id='topic+accTrainTest'></span>

<h3>Description</h3>

<p>A division of data is specified, for use of linear discriminant analysis,
into a training and test set. Feature selection and model fitting is
formed, first with I/II as training/test, then with II/I as training/test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accTrainTest(x = matrix(rnorm(1000), ncol=20), cl = factor(rep(1:3,c(7,9,4))),
 traintest = divideUp(cl, nset=2), nfeatures = NULL, print.acc = FALSE,
 print.progress=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accTrainTest_+3A_x">x</code></td>
<td>
<p>Matrix; rows are features, and columns are observations
('samples')</p>
</td></tr>
<tr><td><code id="accTrainTest_+3A_cl">cl</code></td>
<td>
<p>Factor that classifies columns into groups that will classify
the data for purposes of discriminant calculations</p>
</td></tr>
<tr><td><code id="accTrainTest_+3A_traintest">traintest</code></td>
<td>
<p>Values that specify a division of observations into
two groups. In the first pass (fold), one to be training and the other test,
with the roles then reversed in a second pass or fold.</p>
</td></tr>
<tr><td><code id="accTrainTest_+3A_nfeatures">nfeatures</code></td>
<td>
<p>integer: numbers of features for which calculations are
required</p>
</td></tr>
<tr><td><code id="accTrainTest_+3A_print.acc">print.acc</code></td>
<td>
<p>logical: should accuracies be printed?</p>
</td></tr>
<tr><td><code id="accTrainTest_+3A_print.progress">print.progress</code></td>
<td>
<p>logical: should progress by feature number be printed?</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>sub1.2</code></td>
<td>
<p>row numbers of features, by order of values of the group
separation measure, for the first subset (I) of the <code>x</code></p>
</td></tr>
<tr><td><code>acc1.2</code></td>
<td>
<p>accuracies, with I as training set and II as test</p>
</td></tr>
<tr><td><code>sub2.1</code></td>
<td>
<p>row numbers of features, by order of values of the group
separation measure, for the second subset (II) of the <code>x</code></p>
</td></tr>
<tr><td><code>acc2.1</code></td>
<td>
<p>accuracies, with II as training set and I as test</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(rnorm(1000), ncol=20)
cl &lt;- factor(rep(1:3, c(7,9,4)))
gp.id &lt;- divideUp(cl, nset=2)
accTrainTest(x=mat, cl=cl, traintest=gp.id,
             nfeatures=1:16, print.acc=TRUE, print.progress=TRUE)

## The function is currently defined as
function(x=matrix(rnorm(1000), ncol=20), cl = factor(rep(1:3, c(7,9,4))),
         traintest=divideUp(cl, nset=2), nfeatures=NULL, print.acc=FALSE){
    traintest &lt;- factor(traintest)
    train &lt;- traintest==levels(traintest)[1]
    testset &lt;- traintest==levels(traintest)[2]
    cl1 &lt;- cl[train]
    cl2 &lt;- cl[testset]
    ng1 &lt;- length(cl1)
    ng2 &lt;- length(cl2)
    maxg &lt;- max(c(ng1-length(unique(cl1))-2,
                  ng2-length(unique(cl2))-2))
    if(is.null(nfeatures)){
      max.features &lt;- maxg
      nfeatures &lt;- 1:max.features
    } else
    {
      if(max(nfeatures)&gt;maxg)nfeatures &lt;- nfeatures[nfeatures&lt;=maxg]
      max.features &lt;- max(nfeatures)
    }
    ord1 &lt;- orderFeatures(x, cl, subset=train)[1:max.features]
    ord2 &lt;- orderFeatures(x, cl, subset=testset)[1:max.features]
    ord &lt;- unique(c(ord1, ord2))
    sub1 &lt;- match(ord1, ord)
    sub2 &lt;- match(ord2, ord)
    df1 &lt;- data.frame(t(x[ord, train]))
    df2 &lt;- data.frame(t(x[ord, testset]))
    acc1 &lt;- acc2 &lt;- numeric(max(nfeatures))
    for(i in nfeatures){
      if(print.progress)cat(paste(i, ":", sep=""))
      df1.lda &lt;- lda(df1[, sub1[1:i], drop=FALSE], cl1)
      hat2 &lt;- predict(df1.lda, newdata=df2[, sub1[1:i], drop=FALSE])$class
      tab &lt;- table(hat2, cl2)
      acc1[i] &lt;- sum(tab[row(tab)==col(tab)])/sum(tab)
      df2.lda &lt;- lda(df2[, sub2[1:i], drop=FALSE], cl2)
      hat1 &lt;- predict(df2.lda, newdata=df1[, sub2[1:i], drop=FALSE])$class
      tab &lt;- table(hat1, cl1)
      acc2[i] &lt;- sum(tab[row(tab)==col(tab)])/sum(tab)
    }
    cat("\n")
    if(print.acc){
      print(round(acc1,2))
      print(round(acc2,2))
    }
    maxacc1 &lt;- max(acc1)
    maxacc2 &lt;- max(acc2)
    sub1 &lt;- match(maxacc1, acc1)
    sub2 &lt;- match(maxacc2, acc2)
    nextacc1 &lt;- max(acc1[acc1&lt;1])
    nextacc2 &lt;- max(acc1[acc1&lt;2])
    lower1 &lt;- maxacc1-sqrt(nextacc1*(1-nextacc1)/ng1)
    lower2 &lt;- maxacc2-sqrt(nextacc2*(1-nextacc2)/ng2)
    lsub1 &lt;- min((1:ng1)[acc1&gt;lower1])
    lsub2 &lt;- min((1:ng2)[acc2&gt;lower2])
    lower &lt;- c("Best accuracy, less 1SD  ",
               paste(paste(round(c(lower1, lower2),2), c(lsub1, lsub2),
                           sep=" ("), " features)   ", sep=""))
    best &lt;- c("Best accuracy",
              paste(paste(round(c(maxacc1, maxacc2),2), c(sub1, sub2),
                          sep=" ("), " features)", sep=""))
    acc.df &lt;- cbind(lower, best)
    dimnames(acc.df) &lt;- list(c("Training/test split",
                               "I (training) / II (test)    ",
                               "II (training) / I (test)    "),c("",""))
    print(acc.df, quote=FALSE)
    invisible(list(sub1.2=ord1, acc1.2=acc1, sub2.1=ord2, acc2.1=acc2))
  }
</code></pre>

<hr>
<h2 id='aovFbyrow'>calculate aov F-statistic for each row of a matrix</h2><span id='topic+aovFbyrow'></span>

<h3>Description</h3>

<p>Returns on aov F-statistic for each row of <code>x</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aovFbyrow(x=matrix(rnorm(1000), ncol=20), cl = factor(rep(1:3, c(7,9,4))))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aovFbyrow_+3A_x">x</code></td>
<td>
<p>features by observations matrix</p>
</td></tr>
<tr><td><code id="aovFbyrow_+3A_cl">cl</code></td>
<td>
<p>factor that classifies the values in each row</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This uses the functions <code>qr()</code> and <code>qr.qty()</code> for the main
part of the calculation, for handling the calculations efficently
</p>


<h3>Value</h3>

<p>one F-statistic for each row of <code>x</code>
</p>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+orderFeatures">orderFeatures</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(rnorm(1000), ncol=20)
cl &lt;- factor(rep(1:3, c(7,9,4)))
Fstats &lt;- aovFbyrow(x = mat, cl = cl)

## The function is currently defined as
aovFbyrow &lt;-
function(x=matrix(rnorm(1000), ncol=20),
         cl=factor(rep(1:3, c(7,9,4)))){
    y &lt;- t(x)
    qr.obj &lt;- qr(model.matrix(~cl))
    qty.obj &lt;- qr.qty(qr.obj,y)
    tab &lt;- table(factor(cl))
    dfb &lt;- length(tab)-1
    dfw &lt;- sum(tab)-dfb-1
    ms.between &lt;- apply(qty.obj[2:(dfb+1), , drop=FALSE]^2, 2, sum)/dfb
    ms.within &lt;- apply(qty.obj[-(1:(dfb+1)), , drop=FALSE]^2, 2, sum)/dfw
    Fstat &lt;- ms.between/ms.within
  }
</code></pre>

<hr>
<h2 id='cvdisc'>Cross-validated accuracy, in linear discriminant calculations</h2><span id='topic+cvdisc'></span>

<h3>Description</h3>

<p>Determine cross-validated accuracy, for each of a number of features in
a specified range, with feature selection repeated at each step of the
cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvdisc(x, cl, nfold = c(10,1), test = "f", nfeatures = 2, seed = 31,
       funda = lda, print.progress = TRUE, subset = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvdisc_+3A_x">x</code></td>
<td>
<p>Matrix; rows are features, and columns are observations
('samples')</p>
</td></tr>
<tr><td><code id="cvdisc_+3A_cl">cl</code></td>
<td>
<p>Factor that classifies columns into groups</p>
</td></tr>
<tr><td><code id="cvdisc_+3A_nfold">nfold</code></td>
<td>
<p>Number of folds for the cross-validation. Optionally, a second
number species the number of repeats of the cross-validation.
</p>
</td></tr>
<tr><td><code id="cvdisc_+3A_test">test</code></td>
<td>
<p>What statistic will be used to measure separation between
groups? Currently <code>"f"</code> is the only possibility.</p>
</td></tr>
<tr><td><code id="cvdisc_+3A_nfeatures">nfeatures</code></td>
<td>
<p>Specifies the different numbers of features (e.g., 1:10)
that will be tried, to determine cross-validation accuracy in each
instance</p>
</td></tr>
<tr><td><code id="cvdisc_+3A_seed">seed</code></td>
<td>
<p>This can be used to specify a starting value for the random
number generator, in order to make calculations repeatable</p>
</td></tr>
<tr><td><code id="cvdisc_+3A_funda">funda</code></td>
<td>
<p>Function that will be used for discrimination.  Currently
<code>lda</code> is the only option</p>
</td></tr>
<tr><td><code id="cvdisc_+3A_print.progress">print.progress</code></td>
<td>
<p>Set to <code>TRUE</code> (default) for printing out,
as calculations proceed, the number of the current fold</p>
</td></tr>
<tr><td><code id="cvdisc_+3A_subset">subset</code></td>
<td>
<p>Allows the use of a subset of the samples (observations)</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>folds</code></td>
<td>
<p>Each column gives, for one run of the cross-validation,
numbers that identify the <code>nfold</code> distinct folds of the
cross-validation</p>
</td></tr>
<tr><td><code>xUsed</code></td>
<td>
<p>returns the rows of <code>x</code> that were used,
in at least one fold</p>
</td></tr>
<tr><td><code>cl</code></td>
<td>
<p>Factor that classifies columns into groups</p>
</td></tr>
<tr><td><code>acc.cv</code></td>
<td>
<p>Cross-validated accuracy</p>
</td></tr>
<tr><td><code>genelist</code></td>
<td>
<p>Array: <code>max(nfeatures)</code> by number of folds by
number of repeats, identifying the features chosen at each repeat of
each fold.  (for <code>k</code> &lt; <code>max(nfeatures)</code> features, take the
initial <code>k</code> rows</p>
</td></tr>
<tr><td><code>Fmatrix</code></td>
<td>
<p>Array, with the same dimensions as <code>genelist</code>,
that gives the anova F-statistic when that feature is used on its own
to separate groups</p>
</td></tr>
<tr><td><code>nfeatures</code></td>
<td>
<p>Specifies the different numbers of features that were
tried, to determine cross-validation accuracy in each instance</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+cvscores">cvscores</a></code>, <code><a href="#topic+scoreplot">scoreplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use first 500 rows (expression values) of Golub, for demonstration.
data(Golub)
data(golubInfo)
attach(golubInfo)
miniG.BM &lt;- Golub[1:500, BM.PB=="BM"]  # 1st 500 rows only
cancer.BM &lt;- cancer[BM.PB=="BM"]
miniG.cv &lt;- cvdisc(miniG.BM, cl=cancer.BM, nfeatures=1:10,
                    nfold=c(3,1))
## Plot cross-validated accuracy, as a function of number of features
plot(miniG.cv$acc.cv, type="l")


## The function is currently defined as
function(x, cl, nfold=NULL, test="f",
           nfeatures=2, seed=31, funda=lda, print.progress=TRUE,
           subset=NULL){
    ## If nfold is not specified, use leave-one-out CV
    if(is.null(nfold))nfold &lt;- sum(!is.na(cl))
    ## Option to omit one or more points
    if(!is.null(subset)){cl[!is.na(cl)][!subset] &lt;- NA
                         nfold[1] &lt;- min(nfold[1], sum(!is.na(cl)))
                       }
    if(any(is.na(cl))){x &lt;- x[,!is.na(cl)]
                       cl &lt;- cl[!is.na(cl)]
                     }
    if(length(nfold)==1)nfold &lt;- c(nfold,1)
    cl &lt;- factor(cl)
    ngp &lt;- length(levels(cl))
    genes &lt;- rownames(x)
    nobs &lt;- dim(x)[2]
    if(is.null(genes)){
      genes &lt;- paste(1:dim(x)[1])
      print("Input rows (features) are not named. Names")
      print(paste(1,":", dim(x)[1], " will be assigned.", sep=""))
      rownames(x) &lt;- genes
    }
    require(MASS)
    if(!is.null(seed))set.seed(seed)
    Fcut &lt;- NULL
    maxgenes &lt;- max(nfeatures)
    ## Cross-validation calculations
    if(nfold[1]==nobs)foldids &lt;- matrix(sample(1:nfold[1]),ncol=1) else
    foldids &lt;- sapply(1:nfold[2], function(x)
                     divideUp(cl, nset=nfold[1]))
    genelist &lt;- array("", dim=c(nrow=maxgenes, ncol=nfold[1], nleaf=nfold[2]))
    Fmatrix &lt;- array(0, dim=c(nrow=maxgenes, ncol=nfold[1], nleaf=nfold[2]))
    testscores &lt;- NULL
    acc.cv &lt;- numeric(maxgenes)
    if(print.progress)
      cat("\n", "Preliminary per fold calculations","\n")
    for(k in 1:nfold[2])
      {
        foldk &lt;- foldids[,k]
    ufold &lt;- sort(unique(foldk))
    for(i in ufold){
      if(print.progress) cat(paste(i,":",sep=""))
      trainset &lt;- (1:nobs)[foldk!=i]
      cli &lt;- factor(cl[trainset])

      stat &lt;- aovFbyrow(x=x[, trainset], cl=cli)
      ordi &lt;- order(-abs(stat))[1:maxgenes]
      genelist[,i, k] &lt;- genes[ordi]
      Fmatrix[, i, k] &lt;- stat[ordi]
    }
  }
    ulist &lt;- unique(as.vector(genelist))
    df &lt;- data.frame(t(x[ulist, , drop=FALSE]))
    names(df) &lt;- ulist
#######################################################################
    if(print.progress)cat("\n", "Show each choice of number of features:","\n")
    for(ng in nfeatures){
      hat &lt;- cl
      if(print.progress)cat(paste(ng,":",sep=""))
    for(k in 1:nfold[2])
      {
        foldk &lt;- foldids[,k]
        ufold &lt;- sort(unique(foldk))
      for(i in ufold){
        testset &lt;- (1:nobs)[foldk==i]
        trainset &lt;- (1:nobs)[foldk!=i]
        ntest &lt;- length(testset)
        ntrain &lt;- nobs-ntest
        genes.i &lt;- genelist[1:ng, i, k]
        dfi &lt;- df[-testset, genes.i, drop=FALSE]
        newdfi &lt;- df[testset, genes.i, drop=FALSE]
        cli &lt;- cl[-testset]
        xy.xda &lt;- funda(cli~., data=dfi)
        subs &lt;- match(colnames(dfi), rownames(df))
        newpred.xda &lt;- predict(xy.xda, newdata=newdfi, method="debiased")
        hat[testset] &lt;- newpred.xda$class
      }
        tabk &lt;- table(hat,cl)
        if(k==1)tab &lt;- tabk else tab &lt;- tab+tabk
      }
      acc.cv[ng] &lt;- sum(tab[row(tab)==col(tab)])/sum(tab)
    }
    cat("\n")
    if(length(nfeatures)&gt;1&amp;all(diff(nfeatures)==1)){
      nobs &lt;- length(cl)
      ng1 &lt;- length(acc.cv)
      maxacc1 &lt;- max(acc.cv)
      sub1 &lt;- match(maxacc1, acc.cv)
      nextacc1 &lt;- max(acc.cv[acc.cv&lt;1])
      lower1 &lt;- maxacc1-sqrt(nextacc1*(1-nextacc1)/nobs)
      lsub1 &lt;- min((1:ng1)[acc.cv&gt;lower1])
      lower &lt;- c("Best accuracy, less 1SD  ",
                 paste(paste(round(c(lower1),2), c(lsub1),
                             sep=" ("), " features)   ", sep=""))
      best &lt;- c("Best accuracy",
                paste(paste(round(c(maxacc1),2), c(sub1),
                            sep=" ("), " features)", sep=""))
      acc.df &lt;- cbind(lower, best)
      dimnames(acc.df) &lt;- list(c("Accuracy",
                                 "(Cross-validation)"),c("",""))
      print(acc.df, quote=FALSE)
    }
    invisible(list(foldids=foldids, xUsed=df, cl=cl, acc.cv=acc.cv,
                   genelist=genelist, Fmatrix=Fmatrix, nfeatures=nfeatures))
  }
</code></pre>

<hr>
<h2 id='cvscores'>For high-dimensional data with known groups, derive scores for plotting</h2><span id='topic+cvscores'></span>

<h3>Description</h3>

<p>This is designed to used with the output from
<code>cvdisc</code>.  Test and training scores from successive
cross-validation steps determine, via a principal components
calculation, a low-dimensional global space onto which test scores are
projected, in order to plot them.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvscores(cvlist, nfeatures, ndisc = NULL, cl.other,
         x.other, keepcols = NULL, print.progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvscores_+3A_cvlist">cvlist</code></td>
<td>
<p>Output object from <code>cvdisc</code></p>
</td></tr>
<tr><td><code id="cvscores_+3A_nfeatures">nfeatures</code></td>
<td>
<p>Number of features to use</p>
</td></tr>
<tr><td><code id="cvscores_+3A_ndisc">ndisc</code></td>
<td>
<p>Dimension of space in which scores will be formed, at most
one less than the number of groups</p>
</td></tr>
<tr><td><code id="cvscores_+3A_cl.other">cl.other</code></td>
<td>
<p>Classifies additional observations that are to be
projected onto the same low-dimensional space</p>
</td></tr>
<tr><td><code id="cvscores_+3A_x.other">x.other</code></td>
<td>
<p>Matrix from which additional observations will be taken</p>
</td></tr>
<tr><td><code id="cvscores_+3A_keepcols">keepcols</code></td>
<td>
<p>Number of sets of principal component scores to use in
discriminant calculations and consequent evaluation of scores that will
determine the low-dimensional global space</p>
</td></tr>
<tr><td><code id="cvscores_+3A_print.progress">print.progress</code></td>
<td>
<p>Set to <code>TRUE</code> (default) for printing out,
as calculations proceed, the number of the current fold</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>scores</code></td>
<td>
<p>Scores that can be plotted</p>
</td></tr>
<tr><td><code>cl</code></td>
<td>
<p>Factor that was used to classify observations into groups</p>
</td></tr>
<tr><td><code>other.scores</code></td>
<td>
<p>Other scores, if any, for plotting</p>
</td></tr>
<tr><td><code>cl.other</code></td>
<td>
<p>Factor that was used to classify the 'other' data into groups</p>
</td></tr>
<tr><td><code>nfeatures</code></td>
<td>
<p>Number of features used</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The methodology used here has developed beyond that described in
Maindonald and Burden (2005)
</p>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>References</h3>

<p>J. H. Maindonald and C. J. Burden, 2005. Selection bias in plots of
microarray or other data that have been sampled from a high-dimensional space.
In R. May and A.J. Roberts, eds., <em>Proceedings of 12th
Computational Techniques and Applications Conference CTAC-2004</em>, volume 46,
pp. C59&ndash;C74.
</p>
<p><a href="https://journal.austms.org.au/V46/CTAC2004/Main/home.html">https://journal.austms.org.au/V46/CTAC2004/Main/home.html</a> [March 15, 2005]</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+cvdisc">cvdisc</a></code>, <code><a href="#topic+scoreplot">scoreplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use first 500 rows (expression values) of Golub, for demonstration.
data(Golub)
data(golubInfo)
attach(golubInfo)
miniG.BM &lt;- Golub[1:500, BM.PB=="BM"]  # 1st 500 rows only
cancer.BM &lt;- cancer[BM.PB=="BM"]
miniG.cv &lt;- cvdisc(miniG.BM, cl=cancer.BM, nfeatures=1:10,
                    nfold=c(3,1))
miniG.scores &lt;- cvscores(cvlist=miniG.cv, nfeatures=4,
                         cl.other=NULL)
detach(golubInfo)

## The function is currently defined as
function(cvlist, nfeatures, ndisc=NULL, cl.other, x.other,
           keepcols=NULL, print.progress=TRUE
           ){
    library(MASS)
    foldids &lt;- cvlist$foldids
    nfold &lt;- c(length(unique(foldids)), dim(foldids)[2])

    ugenes &lt;- unique(as.vector(cvlist$genelist[1:nfeatures, ,]))
    df &lt;- cvlist$xUsed[, ugenes]
    cl &lt;- cvlist$cl
    if(!length(cl)==dim(df)[1])
      stop(paste("length(cl) =", length(cl),"does not equal",
                 "dim(cvlist$df)[1] =", dim(df)[1]))
    levnames &lt;- levels(cl)
    if(is.null(ndisc))ndisc &lt;- length(levnames)-1
    ngp &lt;- length(levnames)
    nobs &lt;- dim(df)[1]
    allscores &lt;- array(0, dim=c(nrow=nobs, ncol=ndisc*nfold[1], nleaf=nfold[2]))
    if(!is.null(cl.other)){
      cl.other &lt;- factor(cl.other)
      if(is.null(dim(x.other)))stop("x.other must have dimension 2")
      if(!length(cl.other)==dim(x.other)[2])
        stop(paste("length(cl.other) =", length(cl.other),"does not equal",
                   "dim(x.other)[2] =", dim(x.other)[2]))
      df.other &lt;- data.frame(t(x.other[ugenes, ,drop=FALSE]))
      colnames(df.other) &lt;- ugenes
    }
    else other.scores &lt;- NULL
    for(k in 1:nfold[2]){
      foldk &lt;- foldids[,k]
      ufold &lt;- sort(unique(foldk))
      j &lt;- 0
      for(i in ufold){
        j &lt;- j+1
        if(print.progress)cat(paste(if(j&gt;1) ":" else "", i,sep=""))
        testi &lt;- (1:nobs)[foldk==i]
        traini &lt;- (1:nobs)[foldk!=i]
        ntest &lt;- length(testi)
        ntrain &lt;- nobs-ntest
        genes.i &lt;- cvlist$genelist[1:nfeatures, i, k]
        dfi &lt;- as.data.frame(df[-testi, genes.i, drop=FALSE])
        newdfi &lt;- as.data.frame(df[testi, genes.i, drop=FALSE])
        cli &lt;- cl[-testi]
        xy.xda &lt;- lda(cli~., data=dfi)
        allscores[, ((i-1)*ndisc)+(1:ndisc), k] &lt;-
          predict(xy.xda, newdata=df, dimen=ndisc)$x
      }
    }
    cat("\n")
    dim(allscores) &lt;- c(nobs, ndisc*prod(nfold))
    if(is.null(keepcols))keepcols &lt;- min(nfeatures, dim(allscores)[2])
    allscores.pcp &lt;- data.frame(pcp(allscores, varscores=FALSE)$g[, 1:keepcols])
    globals &lt;- predict(lda(cl ~ ., data=allscores.pcp))$x[,1:ndisc]
    fitscores &lt;- array(0, dim=c(nrow=nobs, ncol=ndisc, nleaf=nfold[2]))
    for(k in 1:nfold[2]){
      foldk &lt;- foldids[,k]
      ufold &lt;- sort(unique(foldk))
##      ntimes.genes &lt;- table(cvlist$genelist[1:nfeatures,,k])
      av &lt;- colMeans(df)
      j &lt;- 0
      for(i in ufold){
        j &lt;- j+1
        cat(paste(if (j&gt;1) ":" else "", i,sep=""))
        testi &lt;- (1:nobs)[foldk==i]
        traini &lt;- (1:nobs)[foldk!=i]
        genes.i &lt;- cvlist$genelist[1:nfeatures, i, k]
        dfi &lt;- data.frame(df[-testi, genes.i, drop=FALSE])
        newdfi &lt;- data.frame(df[testi, genes.i, drop=FALSE])
        cli &lt;- cl[-testi]
        traini.xda &lt;- lda(cli~., data=dfi)
        scorei &lt;- predict(traini.xda)$x[,1:ndisc]
        newpred.xda &lt;- predict(traini.xda, newdata=newdfi)
        scorei.out &lt;- newpred.xda$x[, 1:ndisc, drop=FALSE]
        scorei.all &lt;- globals[-testi, 1:ndisc]
        avcol &lt;- colMeans(scorei.all)
        scorei.all &lt;- sweep(scorei.all, 2, avcol,"-")
        avi &lt;- colMeans(scorei)
        scorei &lt;- sweep(scorei, 2, avi,"-")
        trans &lt;- qr.solve(scorei, scorei.all)
        scorei.out &lt;- sweep(scorei.out, 2, avi, "-")
        fitscores[testi, , k] &lt;- sweep(scorei.out%*%trans, 2, avcol, "+")
      }
    }
    fitscores &lt;- apply(fitscores, 1:2, mean)

    if(!is.null(cl.other)){
      Fmatrix &lt;- cvlist$Fmatrix
      ord &lt;- order(Fmatrix)[1:nfeatures]
      rowcol &lt;- cbind(as.vector(row(Fmatrix))[ord],as.vector(col(Fmatrix))[ord])
      ugenes &lt;- unique(as.vector(cvlist$genelist[rowcol]))
      df &lt;- cvlist$xUsed[, ugenes]
      xy.xda &lt;- lda(cl~., data=df)
      train.scores &lt;- predict(xy.xda, dimen=ndisc)$x
      other.scores &lt;- predict(xy.xda, newdata=df.other,
                              dimen=ndisc)$x
      avcol &lt;- colMeans(globals)
      all.scores &lt;- sweep(globals, 2, avcol,"-")
      av.train &lt;- colMeans(train.scores)
      train.scores &lt;- sweep(train.scores, 2, av.train, "-")
      trans &lt;- qr.solve(train.scores, all.scores)
      other.scores &lt;- sweep(other.scores%*%trans, 2, avcol, "+")
    }
    if(print.progress)cat("\n")
    invisible(list(scores=fitscores, cl=cl, other=other.scores,
                   cl.other=cl.other, nfeatures=nfeatures))
  }
</code></pre>

<hr>
<h2 id='defectiveCVdisc'>defective accuracy assessments from linear discriminant calculations</h2><span id='topic+defectiveCVdisc'></span>

<h3>Description</h3>

<p>Determine cross-validated accuracy, for each of a number of features in
a specified range, in each case with a set of features that have been
selected using the total data. The &quot;accuracy&quot; assessment are provided
only for comparative purposes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defectiveCVdisc(x, cl, nfold = NULL, FUN = aovFbyrow, nfeatures = 2, seed = 31,
         funda = lda, foldids = NULL, subset = NULL, print.progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="defectiveCVdisc_+3A_x">x</code></td>
<td>
<p>Matrix; rows are features, and columns are observations
('samples')</p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_cl">cl</code></td>
<td>
<p>Factor that classifies columns into groups</p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_nfold">nfold</code></td>
<td>
<p>Number of folds for the cross-validation. Optionally, a second
number species the number of repeats of the cross-validation</p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_fun">FUN</code></td>
<td>
<p>function used to calculate a measure, for each row, of
separation into groups</p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_nfeatures">nfeatures</code></td>
<td>
<p>Specifies the different numbers of features (e.g., 1:10)
that will be tried, to determine cross-validation accuracy in each
instance</p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_seed">seed</code></td>
<td>
<p>This can be used to specify a starting value for the random
number generator, in order to make calculations repeatable</p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_funda">funda</code></td>
<td>
<p>Function that will be used for discrimination.  Currently
<code>lda</code> is the only option</p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_foldids">foldids</code></td>
<td>
<p>Fold information, as output from <code>cvdisc()</code></p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_subset">subset</code></td>
<td>
<p>Allows the use of a subset of the samples (observations)</p>
</td></tr>
<tr><td><code id="defectiveCVdisc_+3A_print.progress">print.progress</code></td>
<td>
<p>Set to <code>TRUE</code> (default) for printing out,
as calculations proceed, the number of the current fold</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>acc.resub</code></td>
<td>
<p>resubstitution measure of 'accuracy'</p>
</td></tr>
<tr><td><code>acc.sel1</code></td>
<td>
<p>'accuracy' from cross-validation, with the initially
selected features</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvdisc">cvdisc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(rnorm(1000), ncol=20)
cl &lt;- factor(rep(1:3, c(7,9,4)))
badaccs &lt;- defectiveCVdisc(mat, cl, nfold=c(3,1), nfeatures=1:5)
## Note the list elements acc.resub and acc.sel1


## The function is currently defined as
function(x, cl, nfold=NULL, FUN=aovFbyrow,
           nfeatures=2, seed=31, funda=lda, foldids=NULL,
           subset=NULL, print.progress=TRUE){
    ## Option to omit one or more points
    if(!is.null(subset)) cl[!is.na(cl)][!subset] &lt;- NA
    if(any(is.na(cl))){x &lt;- x[,!is.na(cl)]
                       cl &lt;- cl[!is.na(cl)]
                     }
    nobs &lt;- dim(x)[2]
    ## Get fold information from foldids, if specified,
    ## else if nfold is not specified, use leave-one-out CV
    if(!is.null(foldids))
      nfold &lt;- c(length(unique(foldids)), dim(foldids)[2])
    if(is.null(nfold)&amp;is.null(foldids))nfold &lt;- sum(!is.na(cl))
    else if(nfold[1]==nobs)foldids &lt;- sample(1:nfold[1])
    else foldids &lt;- sapply(1:nfold[2], function(x)
                     divideUp(cl, nset=nfold[1]))
    if(length(nfold)==1)nfold &lt;- c(nfold,1)
    cl &lt;- factor(cl)
    ngp &lt;- length(levels(cl))
    genes &lt;- rownames(x)
     if(is.null(genes)){
      genes &lt;- paste(1:dim(x)[1])
      print("Input rows (features) are not named. Names")
      print(paste(1,":", dim(x)[1], " will be assigned.", sep=""))
      rownames(x) &lt;- genes
    }
    require(MASS)
    if(!is.null(seed))set.seed(seed)
    Fcut &lt;- NULL
    maxgenes &lt;- max(nfeatures)

    stat &lt;- FUN(x=x, cl)
    Fcut &lt;- list(F=sort(stat, decreasing=TRUE)[nfeatures],
                 df=c(ngp-1, nobs-ngp))
    ord &lt;- order(-abs(stat))[1:maxgenes]
    genes.ord &lt;- genes[ord]
    selectonce.df &lt;- data.frame(t(x[ord, , drop=FALSE]))
    acc.resub &lt;- acc.sel1 &lt;- numeric(maxgenes)
    if(nfold[1]==0)acc.sel1 &lt;- NULL

    for(ng in nfeatures){
      resub.xda &lt;- funda(cl~., data=selectonce.df[,1:ng,drop=FALSE])
      hat.rsb &lt;- predict(resub.xda)$class
      tab.rsb &lt;- table(hat.rsb, cl)
      acc.resub[ng] &lt;- sum(tab.rsb[row(tab.rsb)==col(tab.rsb)])/sum(tab.rsb)
      if(nfold[1]==0)next
      if(nfold[1]==nobs){
        hat.sel1 &lt;- funda(cl~., data=selectonce.df[,1:ng,drop=FALSE],
                          CV=TRUE)$class
        tab.one &lt;- table(hat.sel1, cl)
        acc.sel1[ng] &lt;- sum(tab.one[row(tab.one)==col(tab.one)])/sum(tab.one)
      } else
      {
      hat &lt;- cl
      if(print.progress)cat(paste(ng,":",sep=""))
      for(k in 1:nfold[2])
      {
        foldk &lt;- foldids[,k]
        ufold &lt;- sort(unique(foldk))
        for(i in ufold){
          testset &lt;- (1:nobs)[foldk==i]
          trainset &lt;- (1:nobs)[foldk!=i]
          dfi &lt;- selectonce.df[-testset, 1:ng, drop=FALSE]
          newdfi &lt;- selectonce.df[testset, 1:ng, drop=FALSE]
          cli &lt;- cl[-testset]
          xy.xda &lt;- funda(cli~., data=dfi)
          subs &lt;- match(colnames(dfi), rownames(df))
          newpred.xda &lt;- predict(xy.xda, newdata=newdfi, method="debiased")
          hat[testset] &lt;- newpred.xda$class
        }
        tabk &lt;- table(hat,cl)
        if(k==1)tab &lt;- tabk else tab &lt;- tab+tabk
      }
      acc.sel1[ng] &lt;- sum(tab[row(tab)==col(tab)])/sum(tab)
      }
    }
    if(print.progress)cat("\n")
    invisible(list(acc.resub=acc.resub, acc.sel1=acc.sel1, genes=genes.ord))
  }
</code></pre>

<hr>
<h2 id='divideUp'>Partition data into mutiple nearly equal subsets</h2><span id='topic+divideUp'></span>

<h3>Description</h3>

<p>Randomly partition data into nearly equal subsets. If
<code>balanced=TRUE</code> the requirement is imposed that the subsets
should as far as possible be balanced with respect to a classifying
factor.  The multiple sets are suitable for use for determining the
folds in a cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divideUp(cl, nset = 2, seed = NULL, balanced=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="divideUp_+3A_cl">cl</code></td>
<td>
<p>classifying factor</p>
</td></tr>
<tr><td><code id="divideUp_+3A_nset">nset</code></td>
<td>
<p>number of subsets into which to partition data</p>
</td></tr>
<tr><td><code id="divideUp_+3A_seed">seed</code></td>
<td>
<p>set the seed, if required, in order to obtain
reproducible results</p>
</td></tr>
<tr><td><code id="divideUp_+3A_balanced">balanced</code></td>
<td>
<p>logical: should subsets be as far as possible balanced
with respect to the classifying factor?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a set of indices that identify the <code>nset</code> subsets
</p>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>Examples</h3>

<pre><code class='language-R'>foldid &lt;- divideUp(cl=rep(1:3, c(17,14,8)), nset=10)
table(rep(1:3, c(17,14,8)), foldid)
foldid &lt;- divideUp(cl=rep(1:3, c(17,14,8)), nset=10,
       	    balanced=FALSE)
table(rep(1:3, c(17,14,8)), foldid)


## The function is currently defined as
function(cl = rep(1:3, c(7, 4, 8)), nset=2, seed=NULL, balanced=TRUE){
    if(!is.null(seed))set.seed(seed)
    if(balanced){
      ord &lt;- order(cl)
      ordcl &lt;- cl[ord]
      gp0 &lt;- rep(sample(1:nset), length.out=length(cl))
      gp &lt;- unlist(split(gp0,ordcl), function(x)sample(x))
      gp[ord] &lt;- gp
    } else
    gp &lt;- sample(rep(1:nset, length.out=length(cl)))
    as.vector(gp)
  }
</code></pre>

<hr>
<h2 id='Golub'>Golub data (7129 rows by 72 columns), after normalization</h2><span id='topic+Golub'></span>

<h3>Description</h3>

<p>These are a normalized version of the Golub leukemia data from the
<code>golubEsets</code> package, available from:
</p>
<p><a href="https://www.bioconductor.org/packages/release/data/experiment/">https://www.bioconductor.org/packages/release/data/experiment/</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Golub)</code></pre>


<h3>Format</h3>

<p>Numeric matrix: 7129 rows by 72 columns.
</p>


<h3>Details</h3>

<p>Data have been normalized and are supplied, here, as a matrix.
</p>


<h3>Source</h3>

<p>See the help page for the dataset <code>golubMerge</code>, in the
<code>golubEsets</code> package, for details of the source of the original
data.
</p>


<h3>References</h3>

<p>Molecular Classification of Cancer: Class Discovery and Class Prediction by 
Gene Expression Monitoring, Science, 531-537, 1999, T. R. Golub and 
D. K. Slonim and P. Tamayo and C. Huard and M. Gaasenbeek and J. P. Mesirov 
and H. Coller and M.L. Loh and J. R. Downing and M. A. Caligiuri and 
C. D. Bloomfield and E. S. Lander
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Golub)
## Select 20 rows from the data; show boxplots of variation across chips
boxplot(data.frame(t(Golub[sample(1:7129, 20), ]))) 
</code></pre>

<hr>
<h2 id='golubInfo'>Classifying factors for the 72 columns of the Golub data set</h2><span id='topic+golubInfo'></span>

<h3>Description</h3>

<p>Details are given of the classifying factors for the 72
columns of the Golub data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(golubInfo)</code></pre>


<h3>Format</h3>

<p>A data frame with 72 observations on the following 6 variables,
that identifies the samples (observations) in the data set <code>Golub</code>
</p>

<dl>
<dt><code>Samples</code></dt><dd><p>a numeric vector: sample number</p>
</dd>
<dt><code>BM.PB</code></dt><dd><p>a factor with levels <code>BM</code> (from bone marrow) 
<code>PB</code> (from peripheral blood)</p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>F</code> <code>M</code></p>
</dd>
<dt><code>Source</code></dt><dd><p>a factor with levels <code>CALGB</code> <code>CCG</code> <code>DFCI</code> <code>St-Jude</code>. These are the hospitals from which the sample came</p>
</dd>
<dt><code>tissue.mf</code></dt><dd><p>a factor with levels <code>BM:NA</code> <code>BM:f</code> <code>BM:m</code> <code>PB:NA</code> <code>PB:f</code> <code>PB:m</code>.  This factor identifies the
several combinations of <code>source</code> and <code>Gender</code></p>
</dd>
<dt><code>cancer</code></dt><dd><p>a factor with levels <code>allB</code> <code>allT</code> <code>aml</code>
There are two types of Acute Lymphoblastic Leukemia (<code>allB</code> and 
<code>allT</code>), plus Acute Myoblastic Leukemia (<code>aml</code>)
</p>
</dd>
</dl>



<h3>Source</h3>

<p>See the help page for the dataset <code>golubMerge</code>, in the
<code>golubEsets</code> package, for details of the source of the original
data.
</p>


<h3>References</h3>

<p>Molecular Classification of Cancer: Class Discovery and Class Prediction by 
Gene Expression Monitoring, Science, 531-537, 1999, T. R. Golub and 
D. K. Slonim and P. Tamayo and C. Huard and M. Gaasenbeek and J. P. Mesirov 
and H. Coller and M.L. Loh and J. R. Downing and M. A. Caligiuri and 
C. D. Bloomfield and E. S. Lander
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(golubInfo)
str(golubInfo)
</code></pre>

<hr>
<h2 id='orderFeatures'>Order features, based on their ability to discriminate</h2><span id='topic+orderFeatures'></span>

<h3>Description</h3>

<p> For each row of <code>data</code>, an F or (potentially) other
statistic is calculated, using the function <code>FUN</code>, that measures
the extent to which this variable separates the data into groups. This
statistic is then used to order the rows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> orderFeatures(x, cl, subset = NULL, FUN = aovFbyrow, values =
FALSE) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orderFeatures_+3A_x">x</code></td>
<td>
<p>Matrix; rows are features, and columns are observations 
('samples')</p>
</td></tr>
<tr><td><code id="orderFeatures_+3A_cl">cl</code></td>
<td>
<p>Factor that classifies columns into groups</p>
</td></tr>
<tr><td><code id="orderFeatures_+3A_subset">subset</code></td>
<td>
<p>allows specification of a subset of the columns of <code>data</code></p>
</td></tr>
<tr><td><code id="orderFeatures_+3A_fun">FUN</code></td>
<td>
<p>specifies the function used to measure separation between groups</p>
</td></tr>
<tr><td><code id="orderFeatures_+3A_values">values</code></td>
<td>
<p>if <code>TRUE</code>, F-values as well as the ordering are returned</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either (<code>values=FALSE</code>) a vector that orders the rows,
or (<code>values=TRUE</code>)
</p>
<table>
<tr><td><code>ord</code></td>
<td>
<p>a vector that orders the rows</p>
</td></tr>
<tr><td><code>stat</code></td>
<td>
<p>ordered values of the statistic</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(rnorm(1000), ncol=20)
cl &lt;- factor(rep(1:3, c(7,9,4)))
ord &lt;- orderFeatures(mat, cl)

## The function is currently defined as
function(x, cl, subset=NULL, FUN=aovFbyrow, values=FALSE){
    if(dim(x)[2]!=length(cl))stop(paste("Dimension 2 of x is",
                  dim(x)[2], "differs from the length of cl (=",
                  length(cl)))
    ## Ensure that cl is a factor &amp; has no redundant levels
    if(is.null(subset))
      cl &lt;- factor(cl)
    else
      cl &lt;- factor(cl[subset])
    if(is.null(subset))
      stat &lt;- FUN(x, cl)
    else
      stat &lt;- FUN(x[, subset], cl)
    ord &lt;- order(-abs(stat))
    if(!values)ord else(list(ord=ord, stat=stat[ord]))
  }
</code></pre>

<hr>
<h2 id='pcp'>convenience version of the singular value decomposition</h2><span id='topic+pcp'></span>

<h3>Description</h3>

<p>Packages results from an SVD on what can be either a cases by variables
(features) or variables by cases layout, for use in principal component
and related calculations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcp(x = datasets::USArrests, varscores = TRUE, cases = "rows", center = "vars",
    standardize = FALSE, scale.cases = 1, log = FALSE, sc = 1, reflect = c(1, 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcp_+3A_x">x</code></td>
<td>
<p>matrix on which SVD is to be performed</p>
</td></tr>
<tr><td><code id="pcp_+3A_varscores">varscores</code></td>
<td>
<p>logical; should scores be returned?</p>
</td></tr>
<tr><td><code id="pcp_+3A_cases">cases</code></td>
<td>
<p>specify either <code>"rows"</code> or <code>"columns"</code></p>
</td></tr>
<tr><td><code id="pcp_+3A_center">center</code></td>
<td>
<p>logical: if set to <code>"vars"</code>, then values of variables
will be centered</p>
</td></tr>
<tr><td><code id="pcp_+3A_standardize">standardize</code></td>
<td>
<p>logical: should values of variables be standardized to
zero mean and unit deviance.  Takes precedence over the setting of
<code>center</code></p>
</td></tr>
<tr><td><code id="pcp_+3A_scale.cases">scale.cases</code></td>
<td>
<p>set to a value in [0,1]. <code>scale.cases=0</code> gives
a pure rotation of the variables. <code>scale.cases=1</code> weights a/c the
singular values</p>
</td></tr>
<tr><td><code id="pcp_+3A_log">log</code></td>
<td>
<p>logical: should logarithms be taken, prior to the calculation?</p>
</td></tr>
<tr><td><code id="pcp_+3A_sc">sc</code></td>
<td>
<p>the variable scores are divided by <code class="reqn">sqrt{sc-1}</code>. By default,
<code>sc</code> = number of cases</p>
</td></tr>
<tr><td><code id="pcp_+3A_reflect">reflect</code></td>
<td>
<p>a vector of two elements, by default <code>c(1,1)</code>.
Use of -1 in one or both positions can be useful in reconciling results
with output from other software</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>g</code></td>
<td>
<p>case scores</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>variable scores</p>
</td></tr>
<tr><td><code>avv</code></td>
<td>
<p>variable means</p>
</td></tr>
<tr><td><code>sdev</code></td>
<td>
<p>singular values, divides by the square root of one less than
the number of cases</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+La.svd">La.svd</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>USArrests.svd &lt;- pcp(x = datasets::USArrests)

## The function is currently defined as
function(x=datasets::USArrests,
           varscores=TRUE,
           cases="rows",
           center="vars",
           standardize=FALSE,
           scale.cases=1,
           log=FALSE,
           sc=1,
           reflect=c(1,1))
{
  x &lt;- as.matrix(x)
  avv &lt;- 0
  sdv &lt;- 1
  casedim &lt;- 2-as.logical(cases=="rows")
  vardim &lt;- 3-casedim
  ## casedim=1 if rows are cases; otherwise casedim=2
  ## scale.cases=0 gives a pure rotation of the variables
  ## scale.cases=1 weights a/c the singular values
  ncases &lt;- dim(x)[casedim]
  nvar &lt;- dim(x)[vardim]
  if(is.null(sc))sc &lt;- dim(x)[casedim]-1
  if(log)x &lt;- log(x, base=2)
  if(standardize){
    avv &lt;- apply(x, vardim, mean)
    sdv &lt;- apply(x, vardim, sd)
    x &lt;- sweep(x, vardim, avv,"-")
    x &lt;- sweep(x, vardim, sdv,"/")
  }
  else if(as.logical(match("vars", center, nomatch=0))){
    avv &lt;- apply(x,vardim, mean)
    x &lt;- sweep(x, vardim, avv,"-")}

  svdx &lt;- La.svd(x, method = c("dgesdd"))
  h &lt;- NULL
  if(cases=="rows"){
    g &lt;- sweep(svdx$u, 2, svdx$d^scale.cases, "*")*sqrt(sc)
    if(varscores)
      h &lt;- t((svdx$d^(1-scale.cases)* svdx$vt ))/sqrt(sc)
  }
  else if(cases=="columns"){
    g &lt;- sweep(t(svdx$vt), 2, svdx$d^scale.cases, "*")*sqrt(sc)
    if(varscores)
      h &lt;- sweep(svdx$u, 2, svdx$d^(1-scale.cases),"*")/sqrt(sc)
  }
  invisible(list(g=g, rotation=h, av=avv, sdev=svdx$d/sqrt(ncases-1)))
  }
</code></pre>

<hr>
<h2 id='plotTrainTest'>Plot predictions for both a I/II train/test split, and the reverse</h2><span id='topic+plotTrainTest'></span>

<h3>Description</h3>

<p>A division of data is specified, for use of linear discriminant analysis,
into a training and test set. Feature selection and model fitting is
formed, first with I/II as training/test, then with II/I as training/test.
Two graphs are plotted &ndash; for the I (training) /II (test) scores, and for
the II/I scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotTrainTest(x, nfeatures, cl, traintest,
              titles = c("A: I/II (train with I, scores are for II)",
                         "B: II/I (train with II, scores are for I)"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotTrainTest_+3A_x">x</code></td>
<td>
<p>Matrix; rows are features, and columns are observations
('samples')</p>
</td></tr>
<tr><td><code id="plotTrainTest_+3A_nfeatures">nfeatures</code></td>
<td>
<p>integer: numbers of features for which calculations are
required</p>
</td></tr>
<tr><td><code id="plotTrainTest_+3A_cl">cl</code></td>
<td>
<p>Factor that classifies columns into groups that will classify
the data for purposes of discriminant calculations</p>
</td></tr>
<tr><td><code id="plotTrainTest_+3A_traintest">traintest</code></td>
<td>
<p>Values that specify a division of observations into
two groups. In the first pass (fold), one to be training and the other test,
with the roles then reversed in a second pass or fold.</p>
</td></tr>
<tr><td><code id="plotTrainTest_+3A_titles">titles</code></td>
<td>
<p>A character vector of length 2 giving titles for the two graphs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Two graphs are plotted.
</p>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(rnorm(1000), ncol=20)
cl &lt;- factor(rep(1:3, c(7,9,4)))
gp.id &lt;- divideUp(cl, nset=2)
plotTrainTest(x=mat, cl=cl, traintest=gp.id, nfeatures=c(2,3))



## The function is currently defined as
function(x, nfeatures, cl, traintest,
           titles=c("A: I/II (train with I, scores are for II)",
             "B: II/I (train with II, scores are for I)")){
    oldpar &lt;- par(mfrow=c(1,2), pty="s")
    on.exit(par(oldpar))
    if(length(nfeatures)==1)nfeatures &lt;- rep(nfeatures,2)
    traintest &lt;- factor(traintest)
    train &lt;- traintest==levels(traintest)[1]
    testset &lt;- traintest==levels(traintest)[2]
    cl1 &lt;- cl[train]
    cl2 &lt;- cl[testset]
    nf1 &lt;- nfeatures[1]
    ord1 &lt;- orderFeatures(x, cl, subset=train)
    df1 &lt;- data.frame(t(x[ord1[1:nf1], train]))
    df2 &lt;- data.frame(t(x[ord1[1:nf1], testset]))
    df1.lda &lt;- lda(df1, cl1)
    scores &lt;- predict(df1.lda, newdata=df2)$x
    scoreplot(scorelist=list(scores=scores, cl=cl2,
             nfeatures=nfeatures[1], other=NULL, cl.other=NULL),
           prefix.title="")
    mtext(side=3, line=2, titles[1], adj=0)
    nf2 &lt;- nfeatures[2]
    ord2 &lt;- orderFeatures(x, cl, subset=testset)
    df2 &lt;- data.frame(t(x[ord2[1:nf2], testset]))
    df1 &lt;- data.frame(t(x[ord2[1:nf2], train]))
    df2.lda &lt;- lda(df2, cl2)
    scores &lt;- predict(df2.lda, newdata=df1)$x
    scoreplot(scorelist=list(scores=scores, cl=cl1,
             nfeatures=nfeatures[2], other=NULL, cl.other=NULL),
           prefix.title="")
    mtext(side=3, line=2, titles[2], adj=0)
  }

</code></pre>

<hr>
<h2 id='qqthin'>a version of qqplot() that thins out points that overplot</h2><span id='topic+qqthin'></span>

<h3>Description</h3>

<p>QQ-plots with large numbers of points typically generate graphics files
that are unhelpfully large.  This function handles the problem by
removing points that are, for all practical purposes, redundant
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qqthin(x, y, ends = c(0.01, 0.99), eps = 0.001, xlab = deparse(substitute(x)),
       adj.xlab = NULL, ylab = deparse(substitute(y)), show.line = TRUE,
       print.thinning.details=TRUE, centerline = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qqthin_+3A_x">x</code></td>
<td>
<p>ordered values of <code>x</code> will be plotted on the x-axis</p>
</td></tr>
<tr><td><code id="qqthin_+3A_y">y</code></td>
<td>
<p>ordered values of <code>y</code> will be plotted on the y-axis</p>
</td></tr>
<tr><td><code id="qqthin_+3A_ends">ends</code></td>
<td>
<p>outside these cumulative proportions of numbers of points,
all points will be included in the graph</p>
</td></tr>
<tr><td><code id="qqthin_+3A_eps">eps</code></td>
<td>
<p>controls the extent of overplotting</p>
</td></tr>
<tr><td><code id="qqthin_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="qqthin_+3A_adj.xlab">adj.xlab</code></td>
<td>
<p>positioning of x-label</p>
</td></tr>
<tr><td><code id="qqthin_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="qqthin_+3A_show.line">show.line</code></td>
<td>
<p>logical; show the line y=x?</p>
</td></tr>
<tr><td><code id="qqthin_+3A_print.thinning.details">print.thinning.details</code></td>
<td>
<p>logical; print number of points after thinning?</p>
</td></tr>
<tr><td><code id="qqthin_+3A_centerline">centerline</code></td>
<td>
<p>logical; draw a line though the part of the graph where
some points have been omitted?</p>
</td></tr>
<tr><td><code id="qqthin_+3A_...">...</code></td>
<td>
<p>additional graphics parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Gives a qqplot. The number of points retained is returned invisibly.
</p>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>References</h3>

<p> ~put references to the literature/web site here ~ </p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(rnorm(1000), ncol=20)
cl &lt;- factor(rep(1:3, c(7,9,4)))
Fstats &lt;- aovFbyrow(x = mat, cl = cl)
qqthin(qf(ppoints(length(Fstats)), 2, 17), Fstats, eps=0.01)


## The function is currently defined as
function(x, y, ends=c(.01,.99), eps=0.001,
           xlab = deparse(substitute(x)), adj.xlab=NULL,
           ylab = deparse(substitute(y)), show.line=TRUE,
           print.thinning.details=TRUE,
           centerline=TRUE, ...){
    ## qqthin() is a substitute for qqplot(), that thins
    ## out plotted points from the region where they are
    ## dense.  Apart from the overlaid curve that shows
    ## the region where points have been thinned, it may
    ## be hard to distinguish the result of qqthin()
    ## from that of qqplot()
    xlab &lt;- xlab
    ylab &lt;- ylab
    x &lt;- sort(x)
    y &lt;- sort(y)
    dx&lt;-diff(x)
    epsdist &lt;- sqrt(diff(range(x))^2+diff(range(y))^2)*eps
    dx&lt;-0.5*(c(dx[1],dx)+c(dx,dx[length(dx)]))
    dy&lt;-diff(y)
    dy&lt;-0.5*(c(dy[1],dy)+c(dy,dy[length(dy)]))
    dpoints &lt;- epsdist/sqrt(dx^2+dy^2)
    ## dpoints is a local measure of the number of points
    ## per unit distance along the diagonal, with the unit
    ## set to approximately eps*(length of diagonal)
    dig&lt;-floor(dpoints)+1
    ## dig is, roughly, the number of points per unit distance.
    ## We wish to retain one point per unit distance.  For this
    ## retain points where cdig rounds to an integer. For such
    ## points, cdig has increased by approx 1, relative to the
    ## previous point that is retained.
    cdig&lt;-round(cumsum(1/dig))
    subs&lt;-match(unique(cdig), cdig)
    if(is.null(adj.xlab))
    plot(x[subs], y[subs], xlab=xlab, ylab=ylab)
    else {
      plot(x[subs], y[subs], xlab="", ylab=ylab)
      mtext(side=1, xlab, adj=adj.xlab, line=par()$mgp[1])
    }
    if(any(diff(subs)&gt;1)){
    n1 &lt;- min(subs[c(diff(subs),0)&gt;1])
    n2 &lt;- max(subs[c(0,diff(subs))&gt;1])
    ns1 &lt;- match(n1, subs)
    ns2 &lt;- match(n2, subs)
    if(print.thinning.details)
       print(paste("Graph retains", length(subs), "points."))
    if(centerline)
      lines(smooth.spline(x[subs[ns1:ns2]], y[subs[ns1:ns2]]),
            col="grey", lwd=2)
	    }
    if(show.line)abline(0, 1, col="red")
invisible(length(subs))
  }
</code></pre>

<hr>
<h2 id='scoreplot'>Plot discriminant function scores, with various identification</h2><span id='topic+scoreplot'></span>

<h3>Description</h3>

<p>There is provision for the plottting of two sets of scores on the same
graph, possibly with different classifying factors.  The function is
designed for use with output from <code>cvscores()</code> or from
<code>simulateScores()</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreplot(scorelist, plot.disc = 1:2, xlab = NULL, ylab = NULL, params = NULL,
          circle = NULL, cl.circle = NULL, circle.pos = c(1, 1), adj.circle = 1,
          adj.title = 0.5, join.legends = TRUE, prefix.title = "", cex.title = 1,
          ratio = 1, plot.folds = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scoreplot_+3A_scorelist">scorelist</code></td>
<td>
<p>list, with elements <code>scores</code> (a matrix of scores)
<code>cl</code> (a classifying factor), <code>other</code> (optional, a further sets
of scores), <code>cl.other</code> (a a classifying factor for <code>other</code>,
optional) and <code>nfeatures</code> (optional, used to label the graph)</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_plot.disc">plot.disc</code></td>
<td>
<p>choice of columns of <code>scorelist</code> to plot</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_params">params</code></td>
<td>
<p>List, with optional elements (lists) <code>points</code>,
<code>other</code>, <code>circle</code> and <code>legend</code>.  Allowed list elements
for <code>points</code> and <code>other</code> are <code>cex</code>, <code>lwd</code>, <code>pch</code>
and <code>col</code>. For <code>circle</code> they are <code>cex</code>, <code>lwd</code> and
<code>col</code>.  For <code>legend</code>, they are <code>cex</code> and <code>cex.other</code></p>
</td></tr>
<tr><td><code id="scoreplot_+3A_circle">circle</code></td>
<td>
<p>identifies points that are to be circled</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_cl.circle">cl.circle</code></td>
<td>
<p>different colors may be used for different
points, according to levels of <code>cl.circle</code></p>
</td></tr>
<tr><td><code id="scoreplot_+3A_circle.pos">circle.pos</code></td>
<td>
<p>This is a vector of length 2, that specifies where
to place the legend information for the circling of points.
Possibilities are <code>c(0,0)</code> (left, below), <code>c(1,1)</code> (right, above),
etc.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_adj.circle">adj.circle</code></td>
<td>
<p>controls positioning of circle legend</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_adj.title">adj.title</code></td>
<td>
<p>controls positioning of title</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_join.legends">join.legends</code></td>
<td>
<p>logical; should legends for <code>points</code> and
<code>other</code> be combined?</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_prefix.title">prefix.title</code></td>
<td>
<p>prefix, to place before title</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_cex.title">cex.title</code></td>
<td>
<p><code>cex</code> for title</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_ratio">ratio</code></td>
<td>
<p><code>y</code>-scale to <code>x</code>-scale ratio for graph</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_plot.folds">plot.folds</code></td>
<td>
<p>Plot individual fold information, comparing projected
training scores with their projections onto the global space.  This is
not at present implemented</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed to <code>eqscplot()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A graph is plotted.
</p>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+cvdisc">cvdisc</a></code>, <code><a href="#topic+cvscores">cvscores</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use first 500 rows (expression values) of Golub, for demonstration.
data(Golub)
data(golubInfo)
attach(golubInfo)
miniG.BM &lt;- Golub[1:500, BM.PB=="BM"]  # 1st 500 rows only
cancer.BM &lt;- cancer[BM.PB=="BM"]
miniG.cv &lt;- cvdisc(miniG.BM, cl=cancer.BM, nfeatures=1:10,
                    nfold=c(3,1))
miniG.scores &lt;- cvscores(cvlist=miniG.cv, nfeatures=4,
                         cl.other=NULL)
subsetB &lt;- (cancer=="allB") &amp; (tissue.mf %in% c("BM:f","BM:m","PB:m"))
tissue.mfB &lt;- tissue.mf[subsetB, drop=TRUE]
scoreplot(scorelist=miniG.scores, cl.circle=tissue.mfB,
       circle=tissue.mfB%in%c("BM:f","BM:m"),
       params=list(circle=list(col=c("cyan","gray"))),
       prefix="BM samples -")
detach(golubInfo)

## The function is currently defined as
  function(scorelist, plot.disc=1:2,
           xlab=NULL, ylab=NULL, params=NULL,
           circle=NULL, cl.circle=NULL, circle.pos=c(1,1),
           adj.circle=1,
           adj.title=0.5, join.legends=T, prefix.title="Golub data - ",
           cex.title=1.0, ratio=1, plot.folds=FALSE, ...){
    library(MASS)
    combine.params &lt;-
      function(params=list(circle=list(col=c("cyan","gray")))){
        default.params=list(points=list(cex=1, lwd=1.25, pch=1:8, col=1:8),
          other=list(cex=0.65, lwd=1.25, pch=13:9, col=c(6:8,5:1)),
          circle=list(cex=2, lwd=1, pch=1.75, col="gray40"),
          legend=list(cex=1, cex.other=1))
        nam &lt;- names(params)
        if(!is.null(nam))
          for(a in nam){
            nam2 &lt;- names(params[[a]])
            for(b in nam2)default.params[[a]][[b]] &lt;- params[[a]][[b]]
          }
        default.params
      }
    params &lt;- combine.params(params=params)
    cl &lt;- scorelist$cl
    cl.other &lt;- scorelist$cl.other
    if(!is.null(cl.other)) cl.other &lt;- factor(cl.other)
    nfeatures &lt;- scorelist$nfeatures
    if(length(plot.disc)==2){
      n1 &lt;- plot.disc[1]
      n2 &lt;- plot.disc[2]
      if(is.null(xlab))xlab &lt;- paste("Discriminant function", n1)
      if(is.null(ylab))ylab &lt;- paste("Discriminant function", n2)
    } else stop("plot.disc must be a vector of length 2")
    if(!is.factor(cl))cl &lt;- factor(cl)
    levnames &lt;- levels(cl)
    fitscores &lt;- scorelist$scores
    other.scores &lt;- scorelist$other
    ngp &lt;- length(levnames)
    n1lim &lt;- range(fitscores[,n1])
    n2lim &lt;- range(fitscores[,n2])
    if(!is.null(cl.other)){
      n1lim &lt;- range(c(n1lim, other.scores[,n1]))
      n2lim &lt;- range(c(n2lim, other.scores[,n2]))
      levnum &lt;- unclass(cl.other)
      levnames.other &lt;- levels(cl.other)
      intlev.other &lt;- unclass(cl.other)
      ngp.other &lt;- length(levels(cl.other))
    }
    n1 &lt;- plot.disc[1]; n2 &lt;- plot.disc[2]
    intlev &lt;- unclass(cl)
    oldpar &lt;- par(lwd=1)
    on.exit(par(oldpar))
    eqscplot(n1lim, n2lim, type="n",
             xlab=xlab, ylab=ylab, ratio=ratio, ...)
    with(params$points,
         points(fitscores[,n1], fitscores[,n2], col=col[intlev],
                pch=pch[intlev], cex=cex, lwd=lwd))
    if(!is.null(cl.other))
      with(params$other,
           points(other.scores[,n1], other.scores[,n2],
                  pch=pch[intlev.other],
                  col=col[intlev.other],
                  cex=cex, lwd=lwd))
    if(!is.null(cl.circle)){
      cl.circle &lt;- factor(cl.circle[circle])
      lev.circle &lt;- levels(cl.circle)
      with(params$circle,
           points(fitscores[circle, n1], fitscores[circle,n2], pch=pch,
                  cex=cex, col=col[unclass(cl.circle)], lwd=lwd))
    }
    par(xpd=TRUE)
    chw &lt;- par()$cxy[1]
    chh &lt;- par()$cxy[2]
    par(lwd=1.5)
    ypos &lt;- par()$usr[4]
    xmid &lt;- mean(par()$usr[1:2])
    top.pos &lt;- 0
    mtext(side=3, line=(top.pos+1), paste(prefix.title,
            nfeatures, "features"), cex=cex.title, adj=adj.title)
    ypos.legend &lt;- ypos+(top.pos-0.45)*chh*0.8

    if(join.legends&amp;!is.null(cl.other)){
      leg.info &lt;- legend(xmid, ypos.legend, xjust=0.5, yjust=0, plot=FALSE,
                         x.intersp=0.5, ncol=ngp, legend=levnames,
                         pt.lwd=params$points$lwd,
                         pt.cex=params$points$cex,
                         cex=params$legend$cex,
                         pch=params$points$pch)
      legother.info &lt;- legend(xmid, ypos.legend, xjust=0.5, yjust=0,
                              plot=FALSE, x.intersp=0.5,
                              ncol=ngp.other, legend=levnames.other,
                              pt.lwd=params$other$lwd,
                              pt.cex=params$other$cex,
                              cex=params$legend$cex.other,
                              pch=params$other$pch)
      leftoff &lt;- 0.5*legother.info$rect$w-0.5*chw
      rightoff &lt;- 0.5*leg.info$rect$w+0.5*chw
      ypos.other &lt;- ypos.legend
    }
    else {
      leftoff &lt;- 0
      rightoff &lt;- 0
      ypos.other &lt;- ypos+(top.pos-1.5)*chh*0.8
    }
    legend(xmid-leftoff, ypos.legend, xjust=0.5, yjust=0,
           bty="n", pch=params$points$pch,
           x.intersp=0.5, col=params$points$col, ncol=ngp,
           legend=levnames,
           pt.lwd=params$points$lwd,
           pt.cex=params$points$cex,
           cex=params$legend$cex)
    par(lwd=1)
    if(!is.null(cl.other))
      lego.info &lt;- legend(xmid+rightoff, ypos.other, xjust=0.5, yjust=0,
                          pch=params$other$pch, x.intersp=0.5,
                          col=params$other$col, ncol=ngp.other,
                          pt.lwd=params$other$lwd,
                          pt.cex=params$other$cex,
                          legend=levnames.other,
                          cex=params$legend$cex.other,
                          bty="n")
    if(!is.null(cl.other)&amp;join.legends)
      text(lego.info$rect$left+c(0.4*chw,lego.info$rect$w-0.25*chw),
           rep(ypos.other,2)+0.8*chh, labels=c("(",")"),
           cex=params$legend$cex,
           lwd=params$legend$lwd, bty="n")
    par(lwd=params$circle$lwd)
    if(!is.null(cl.circle))if(lev.circle[1]!=""){
      pch.circle &lt;- params$circle$pch
      xy &lt;- par()$usr[circle.pos+c(1,3)]
      legend(xy[1], xy[2],
             xjust=adj.circle[1], yjust=circle.pos[2], bty="n", x.intersp=0.5,
             pch=rep(pch.circle,length(lev.circle)), col=params$circle$col,
             ncol=1, legend=lev.circle, cex=0.85, pt.cex=1.5)
    }
    par(lwd=1, xpd=FALSE)
    if(plot.folds){
      mtext(side=1, line=1.25, "Discriminant function 1", outer=T)
      mtext(side=2, line=1.25, "Discriminant function 2", outer=T)
    }
  }
</code></pre>

<hr>
<h2 id='simulateScores'>Generate linear discriminant scores from random data, after selection</h2><span id='topic+simulateScores'></span>

<h3>Description</h3>

<p>Simulates the effect of generating scores from random data, possibly
with predicted scores calculates also for additional 'observations'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateScores(nrows = 7129, cl = rep(1:3, c(19, 10, 2)), x = NULL, cl.other = NULL,
               x.other = NULL, nfeatures = 15, dimen=2, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulateScores_+3A_nrows">nrows</code></td>
<td>
<p>number of rows of random data matrix</p>
</td></tr>
<tr><td><code id="simulateScores_+3A_cl">cl</code></td>
<td>
<p>classifying factor</p>
</td></tr>
<tr><td><code id="simulateScores_+3A_x">x</code></td>
<td>
<p>data matrix, by default randomly generated</p>
</td></tr>
<tr><td><code id="simulateScores_+3A_cl.other">cl.other</code></td>
<td>
<p>classifying factor for additional observations</p>
</td></tr>
<tr><td><code id="simulateScores_+3A_x.other">x.other</code></td>
<td>
<p>additional observations</p>
</td></tr>
<tr><td><code id="simulateScores_+3A_nfeatures">nfeatures</code></td>
<td>
<p>number of features to select (by default uses
aov F-statistic)</p>
</td></tr>
<tr><td><code id="simulateScores_+3A_dimen">dimen</code></td>
<td>
<p>number of sets of discriminant scores to retain (at most
one less than number of levels of <code>cl</code>)</p>
</td></tr>
<tr><td><code id="simulateScores_+3A_seed">seed</code></td>
<td>
<p>set, if required, so that calculations can be reproduced</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>scores</code></td>
<td>
<p>matrix of scores</p>
</td></tr>
<tr><td><code>cl</code></td>
<td>
<p>classifying factor</p>
</td></tr>
<tr><td><code>other</code></td>
<td>
<p>matrix of 'other' scores</p>
</td></tr>
<tr><td><code>cl.other</code></td>
<td>
<p>classifying factor for <code>scores.other</code></p>
</td></tr>
<tr><td><code>nfeatures</code></td>
<td>
<p>number of features used in generating the scores</p>
</td></tr>
</table>


<h3>Note</h3>

<p>NB: Prior to 0.53, this function made (wrongly) a random
selection of features.
</p>


<h3>Author(s)</h3>

<p>John Maindonald</p>


<h3>Examples</h3>

<pre><code class='language-R'>scorelist &lt;- simulateScores(nrows=500, cl=rep(1:3, c(19,10,2)))
plot(scorelist$scores, col=unclass(scorelist$cl), pch=16)


## The function is currently defined as
simulateScores &lt;-
  function (nrows = 7129, cl = rep(1:3, c(19, 10, 2)), x = NULL,
            cl.other = NULL, x.other = NULL, nfeatures = 15, dimen = 2,
            seed = NULL)
{
  if (!is.null(seed))
    set.seed(seed)
  m &lt;- length(cl)
  m.other &lt;- length(cl.other)
  if (is.null(x)) {
    x &lt;- matrix(rnorm(nrows * m), nrow = nrows)
    rownames(x) &lt;- paste(1:nrows)
  }
  else nrows &lt;- dim(x)[1]
  if (is.null(x.other)) {
    x.other &lt;- matrix(rnorm(nrows * m.other), nrow = nrows)
    rownames(x.other) &lt;- paste(1:nrows)
  }
  if (is.numeric(cl))
    cl &lt;- paste("Gp", cl, sep = "")
  if(!is.null(cl.other)){
    if (is.numeric(cl.other))
      cl.other &lt;- paste("Gp", cl.other, sep = "")
    cl.other &lt;- factor(cl.other)
  }
  cl &lt;- factor(cl)
  if (dimen &gt; length(levels(cl)) - 1)
    dimen &lt;- length(levels(cl)) - 1
  ordfeatures &lt;- orderFeatures(x, cl = cl, values = TRUE)
  stat &lt;- ordfeatures$stat[1:nfeatures]
  ord.use &lt;- ordfeatures$ord[1:nfeatures]
  xUse.ord &lt;- data.frame(t(x[ord.use, ]))
  xUseOther.ord &lt;- data.frame(t(x.other[ord.use, ]))
  ordUse.lda &lt;- lda(xUse.ord, grouping = cl)
  scores &lt;- predict(ordUse.lda, dimen = dimen)$x
  if(!is.null(cl.other))
    scores.other &lt;- predict(ordUse.lda, newdata = xUseOther.ord,
                            dimen = dimen)$x else
  scores.other &lt;- NULL
  invisible(list(scores = scores, cl = cl, other = scores.other,
                 cl.other = cl.other, nfeatures = nfeatures))
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
