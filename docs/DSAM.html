<!DOCTYPE html><html><head><title>Help for package DSAM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DSAM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#checkFull'><p>Check whether the sample set is full</p></a></li>
<li><a href='#dataSplit'><p>Main function of data splitting algorithm</p></a></li>
<li><a href='#DP.initialSample'><p>Initial sampling of DUPLEX</p></a></li>
<li><a href='#DP.reSample'><p>Repeat sampling of DUPLEX</p></a></li>
<li><a href='#DSAM_test_largeData'><p>large test dataset</p></a></li>
<li><a href='#DSAM_test_modData'><p>Moderate test dataset</p></a></li>
<li><a href='#DSAM_test_smallData'><p>Small test dataset</p></a></li>
<li><a href='#DUPLEX'><p>'DSAM' - DUPLEX algorithm</p></a></li>
<li><a href='#getAUC'><p>Get the AUC value between two datasets</p></a></li>
<li><a href='#getMax'><p>Get the maximum of the output column from the original data set</p></a></li>
<li><a href='#getMean'><p>Get the mean and  standard deviation of the output column from the original data set</p></a></li>
<li><a href='#getMin'><p>Get the minimum of the output column from the original data set</p></a></li>
<li><a href='#getSnen'><p>Get sampling number of each SOM neuron</p></a></li>
<li><a href='#MDUPLEX'><p>'DSAM' - MDUPLEX algorithm</p></a></li>
<li><a href='#par.default'><p>Default parameter list</p></a></li>
<li><a href='#remainUnsample'><p>Get the remain unsampled data after <code>SSsample</code></p></a></li>
<li><a href='#SBSS.P'><p>'DSAM' - SBSS.P algorithm</p></a></li>
<li><a href='#selectData'><p>Select specific split data</p></a></li>
<li><a href='#somCluster'><p>Self-organized map clustering</p></a></li>
<li><a href='#SOMPLEX'><p>'DSAM' - SOMPLEX algorithm</p></a></li>
<li><a href='#SS'><p>'DSAM' - SS algorithm</p></a></li>
<li><a href='#SSsample'><p>Core function of SS sampling</p></a></li>
<li><a href='#standardise'><p>Standardized data</p></a></li>
<li><a href='#TIMECON'><p>'DSAM' - Time-consecutive algorithm</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Data Splitting Algorithms for Model Developments</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Providing six different algorithms that can be used to split the 
    available data into training, test and validation subsets with similar distribution 
    for hydrological model developments. The dataSplit() function will help you divide 
    the data according to specific requirements, and you can refer to the par.default() 
    function to set the parameters for data splitting. The getAUC() function will help 
    you measure the similarity of distribution features between the data subsets.
    For more information about the data splitting algorithms, please refer to:
    Chen et al. (2022) &lt;<a href="https://doi.org/10.1016%2Fj.jhydrol.2022.128340">doi:10.1016/j.jhydrol.2022.128340</a>&gt;, 
    Zheng et al. (2022) &lt;<a href="https://doi.org/10.1029%2F2021WR031818">doi:10.1029/2021WR031818</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/lark-max/DSAM">https://github.com/lark-max/DSAM</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lark-max/DSAM/issues">https://github.com/lark-max/DSAM/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, kohonen, Matrix, pROC, stats, utils, xgboost</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-29 13:27:17 UTC; junyi</td>
</tr>
<tr>
<td>Author:</td>
<td>Feifei Zheng [aut, ths],
  Junyi Chen <a href="https://orcid.org/0009-0001-1978-6475"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Junyi Chen &lt;jun1chen@zju.edu.cn&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-29 14:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='checkFull'>Check whether the sample set is full</h2><span id='topic+checkFull'></span>

<h3>Description</h3>

<p>Built-in function: This function includes four arguments,
where the first one contains the information of the original dataset as well as the three subsets,
and the remaining three augments are the maximum sample sizes for the training, test and validation subsets respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkFull(split.info, num.train, num.test, num.valid)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkFull_+3A_split.info">split.info</code></td>
<td>
<p>List type, which contains the original data set, three sampling subsets, termination signal and other relevant sampling information.</p>
</td></tr>
<tr><td><code id="checkFull_+3A_num.train">num.train</code></td>
<td>
<p>The number of training data points specified by the user.</p>
</td></tr>
<tr><td><code id="checkFull_+3A_num.test">num.test</code></td>
<td>
<p>The number of test data points specified by the user.</p>
</td></tr>
<tr><td><code id="checkFull_+3A_num.valid">num.valid</code></td>
<td>
<p>The number of validation data points specified by the user.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with sampling information.
</p>

<hr>
<h2 id='dataSplit'>Main function of data splitting algorithm</h2><span id='topic+dataSplit'></span>

<h3>Description</h3>

<p>'DSAM' interface function: The user needs to provide a parameter list before data-splitting.
These parameters have default values, with details given in the <code><a href="#topic+par.default">par.default</a></code> function.
Conditioned on the parameter list, this function carries out the data-splitting based on the algorithm specified by the user.
The available algorithms include the traditional time-consecutive method (TIMECON), DUPLEX, MDUPLEX SOMPLEX, SBSS.P, SS.
The algorithm details can be found in Chen et al. (2022). Note that this package focuses on deals with the dataset with multiple inputs but one output,
where this output is used to enable the application of various data-splitting algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataSplit(data, control = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataSplit_+3A_data">data</code></td>
<td>
<p>The dataset should be matrix or Data.frame. The format should be as follows: Column one is a subscript vector used to mark each data point (each row is considered as a data point); Columns from 2 to N-1 are the input data, and Column N are the output data.</p>
</td></tr>
<tr><td><code id="dataSplit_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the <code><a href="#topic+par.default">par.default</a></code> function.</p>
</td></tr>
<tr><td><code id="dataSplit_+3A_...">...</code></td>
<td>
<p>A redundant argument list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the training, test and validation subsets. If the original data are required to be split into two subsets, the training and test subsets can be combined into a single calibration subset.
</p>


<h3>Author(s)</h3>

<p>Feifei Zheng <a href="mailto:feifeizheng@zju.edu.cn">feifeizheng@zju.edu.cn</a>
</p>
<p>Junyi Chen <a href="mailto:jun1chen@zju.edu.cn">jun1chen@zju.edu.cn</a>
</p>


<h3>References</h3>

<p>Chen, J., Zheng F., May R., Guo D., Gupta H., and Maier H. R.(2022).Improved data splitting methods for data-driven hydrological model development based on a large number of catchment samples, Journal of Hydrology, 613.
</p>
<p>Zheng, F., Chen J., Maier H. R., and Gupta H.(2022). Achieving Robust and Transferable Performance for Conservation‚ÄêBased Models of Dynamical Physical Systems, Water Resources Research, 58(5).
</p>
<p>Zheng, F., Chen, J., Ma, Y.,  Chen Q., Maier H. R., and Gupta H.(2023). A Robust Strategy to Account for Data Sampling Variability in the Development of Hydrological Models, Water Resources Research, 59(3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("DSAM_test_smallData")
res.sml = dataSplit(DSAM_test_smallData)

data("DSAM_test_modData")
res.mod = dataSplit(DSAM_test_modData, list(sel.alg = "SBSS.P"))

data("DSAM_test_largeData")
res.lag = dataSplit(DSAM_test_largeData, list(sel.alg = "SOMPLEX"))

</code></pre>

<hr>
<h2 id='DP.initialSample'>Initial sampling of DUPLEX</h2><span id='topic+DP.initialSample'></span>

<h3>Description</h3>

<p>Built-in function: The initial sampling function of DUPLEX algorithm, aimed to obtain the two data points with the farthest Euclidean distance from the original data set and assign them to the corresponding sampling subset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DP.initialSample(split.info, choice)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DP.initialSample_+3A_split.info">split.info</code></td>
<td>
<p>A list containing relevant sampling information such as the original dataset and three sample subsets.</p>
</td></tr>
<tr><td><code id="DP.initialSample_+3A_choice">choice</code></td>
<td>
<p>The variable must be one name of the three sample subsets contained in split.info, according to which the function assigns the current two data points to the specific sampling subset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the training, test and validation subsets. If the original data are required to be split into two subsets, the training and test subsets can be combined into a single calibration subset.
</p>

<hr>
<h2 id='DP.reSample'>Repeat sampling of DUPLEX</h2><span id='topic+DP.reSample'></span>

<h3>Description</h3>

<p>Built-in function: The cyclic sampling function of DUPLEX algorithm that takes the two data points farthest from the current sampling set and assigns them to the corresponding sampling subset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DP.reSample(split.info, choice)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DP.reSample_+3A_split.info">split.info</code></td>
<td>
<p>A list containing relevant sampling information such as the original dataset and three sample subsets.</p>
</td></tr>
<tr><td><code id="DP.reSample_+3A_choice">choice</code></td>
<td>
<p>The variable must be one name of the three sample subsets contained in split.info, according to which the function assigns the current two data points to the specific sampling subset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the training, test and validation subsets. If the original data are required to be split into two subsets, the training and test subsets can be combined into a single calibration subset.
</p>

<hr>
<h2 id='DSAM_test_largeData'>large test dataset</h2><span id='topic+DSAM_test_largeData'></span>

<h3>Description</h3>

<p>A large dataset containing the rainfall and runoff time series using for
testing data splitting algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DSAM_test_largeData
</code></pre>


<h3>Format</h3>

<p>A data frame with 3650 rows and 5 variables
</p>

<dl>
<dt>Idex</dt><dd><p>Data subscript that marks the position of each data point</p>
</dd>
<dt>I</dt><dd><p>input vectors</p>
</dd>
<dt>I.1</dt><dd><p>input vectors</p>
</dd>
<dt>I.2</dt><dd><p>input vectors</p>
</dd>
<dt>O</dt><dd><p>The output vector, usually the runoff</p>
</dd>
</dl>
<p>...

</p>

<hr>
<h2 id='DSAM_test_modData'>Moderate test dataset</h2><span id='topic+DSAM_test_modData'></span>

<h3>Description</h3>

<p>A moderate dataset containing the rainfall and runoff time series using for
testing data splitting algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DSAM_test_modData
</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 rows and 5 variables
</p>

<dl>
<dt>Idex</dt><dd><p>Data subscript that marks the position of each data point</p>
</dd>
<dt>I</dt><dd><p>input vectors</p>
</dd>
<dt>I.1</dt><dd><p>input vectors</p>
</dd>
<dt>I.2</dt><dd><p>input vectors</p>
</dd>
<dt>O</dt><dd><p>The output vector, usually the runoff</p>
</dd>
</dl>
<p>...

</p>

<hr>
<h2 id='DSAM_test_smallData'>Small test dataset</h2><span id='topic+DSAM_test_smallData'></span>

<h3>Description</h3>

<p>A small dataset containing the rainfall and runoff time series using for
testing data splitting algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DSAM_test_smallData
</code></pre>


<h3>Format</h3>

<p>A data frame with 200 rows and 5 variables
</p>

<dl>
<dt>Idex</dt><dd><p>Data subscript that marks the position of each data point</p>
</dd>
<dt>I</dt><dd><p>input vectors</p>
</dd>
<dt>I.1</dt><dd><p>input vectors</p>
</dd>
<dt>I.2</dt><dd><p>input vectors</p>
</dd>
<dt>O</dt><dd><p>The output vector, usually the runoff</p>
</dd>
</dl>
<p>...

</p>

<hr>
<h2 id='DUPLEX'>'DSAM' - DUPLEX algorithm</h2><span id='topic+DUPLEX'></span>

<h3>Description</h3>

<p>The deterministic DUPLEX algorithm, with details given in Chen et al. (2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DUPLEX(data, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DUPLEX_+3A_data">data</code></td>
<td>
<p>The dataset should be matrix or Data.frame. The format should be as follows: Column one is a subscript vector used to mark each data point (each row is considered as a data point); Columns from 2 to N-1 are the input data, and Column N are the output data.</p>
</td></tr>
<tr><td><code id="DUPLEX_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the <code><a href="#topic+par.default">par.default</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the training, test and validation subsets. If the original data are required to be split into two subsets, the training and test subsets can be combined into a single calibration subset.
</p>

<hr>
<h2 id='getAUC'>Get the AUC value between two datasets</h2><span id='topic+getAUC'></span>

<h3>Description</h3>

<p>This function calls <code>[kohonen]{xgboost}</code> to train the classifier, followed by calculating the similarity between the two given datasets. The return value is a AUC index, ranging between 0 and 1, where the AUC is closer to 0.5, the more similar the two data sets is.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAUC(data1, data2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getAUC_+3A_data1">data1</code></td>
<td>
<p>Dataset 1, the data type must be numeric, matrix or Data.frame.</p>
</td></tr>
<tr><td><code id="getAUC_+3A_data2">data2</code></td>
<td>
<p>Dataset 2, the data type must be numeric, matrix or Data.frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the AUC value.
</p>

<hr>
<h2 id='getMax'>Get the maximum of the output column from the original data set</h2><span id='topic+getMax'></span>

<h3>Description</h3>

<p>This function return the maximum of runoff(output columu) for users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMax(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getMax_+3A_data">data</code></td>
<td>
<p>The original data set, the data type must be numeric, matrix or Data.frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the maximum value of the output column.
</p>

<hr>
<h2 id='getMean'>Get the mean and  standard deviation of the output column from the original data set</h2><span id='topic+getMean'></span>

<h3>Description</h3>

<p>This function return the mean and  standard deviation of runoff(output columu) for users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMean(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getMean_+3A_data">data</code></td>
<td>
<p>The original data set, the data type must be numeric, matrix or Data.frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return a list with mean value and standard deviation.
</p>

<hr>
<h2 id='getMin'>Get the minimum of the output column from the original data set</h2><span id='topic+getMin'></span>

<h3>Description</h3>

<p>This function return the minimum of runoff(output columu) for users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMin(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getMin_+3A_data">data</code></td>
<td>
<p>The original data set, the data type must be numeric, matrix or Data.frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the minimum value of the output column.
</p>

<hr>
<h2 id='getSnen'>Get sampling number of each SOM neuron</h2><span id='topic+getSnen'></span>

<h3>Description</h3>

<p>Built-in function: Calculates the maximum number of samples of each subset in each neuron within the SOM network based on the sampling ratio specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSnen(som.info, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getSnen_+3A_som.info">som.info</code></td>
<td>
<p>The list contains information about the SOM network, including the total number of neurons, the number of rows, and the set of data points within each neuron.</p>
</td></tr>
<tr><td><code id="getSnen_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the par.default function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function return a list containing three vectors Tr,Ts and Vd, the length of which is the same as the number of neurons. Tr,Ts and Vd vectors record the specified amount of data that need be obtained for the Training, Test and Validation subset in each neuron respectively.
</p>

<hr>
<h2 id='MDUPLEX'>'DSAM' - MDUPLEX algorithm</h2><span id='topic+MDUPLEX'></span>

<h3>Description</h3>

<p>This is a modified MDUPLEX algorithm, which is also deterministic, with details given in Zheng et al. (2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MDUPLEX(data, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MDUPLEX_+3A_data">data</code></td>
<td>
<p>The dataset should be matrix or Data.frame. The format should be as follows: Column one is a subscript vector used to mark each data point (each row is considered as a data point); Columns from 2 to N-1 are the input data, and Column N are the output data.</p>
</td></tr>
<tr><td><code id="MDUPLEX_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the par.default function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the training, test and validation subsets. If the original data are required to be split into two subsets, the training and test subsets can be combined into a single calibration subset.
</p>


<h3>References</h3>

<p>Chen, J., Zheng F., May R., Guo D., Gupta H., and Maier H. R.(2022), Improved data splitting methods for data-driven hydrological model development based on a large number of catchment samples, Journal of Hydrology, 613.
</p>
<p>Zheng, F., Chen J., MaierH. R., and Gupta H.(2022), Achieving Robust and Transferable Performance for Conservation‚ÄêBased Models of Dynamical Physical Systems, Water Resources Research, 58(5).
</p>

<hr>
<h2 id='par.default'>Default parameter list</h2><span id='topic+par.default'></span>

<h3>Description</h3>

<p>The list of parameters needs to be set by the user, each with a default value.
</p>

<dl>
<dt>include.inp</dt><dd><p>Boolean variable that determines whether the input vectors should be included during the Euclidean distance calculation. The default is <code>TRUE</code>.  </p>
</dd>
<dt>seed</dt><dd><p>Random number seed. The default is <code>1000</code>.  </p>
</dd>
<dt>sel.alg</dt><dd><p>A string variable that represents the available data splitting algorithms including <code>"SOMPLEX"</code>, <code>"MDUPLEX"</code>, <code>"DUPLEX"</code>, <code>"SBSS.P"</code>, <code>"SS"</code> and <code>"TIMECON"</code>. The default is <code>"MDUPLEX"</code>.  </p>
</dd>
<dt>prop.Tr</dt><dd><p>The proportion of data allocated to the training subset, where the default is <code>0.6</code>.  </p>
</dd>
<dt>prop.Ts</dt><dd><p>The proportion of data allocated to the test subset, where the default is <code>0.2</code>.  </p>
</dd>
<dt>Train</dt><dd><p>A string variable representing the output file name for the training data subset. The default is <code>"Train.txt"</code>.  </p>
</dd>
<dt>Test</dt><dd><p>A string variable representing the output file name for the test data subset. The default is <code>"Test.txt"</code>.  </p>
</dd>
<dt>Validation</dt><dd><p>A string variable representing the output file name for the validation data subset. The default is <code>"Valid.txt"</code>.  </p>
</dd>
<dt>loc.calib</dt><dd><p>Vector type: When sel.alg = &quot;TIMECON&quot;, the program will select a continuous time-series data subset from the original data set, where the start and end positions are determined by this vector, with the first and the second value representing the start and end position in percentage of the original dataset. The default is <code>c(0,0.6)</code>, implying that the algorithm selects the first 60% of the data from the original dataset.  </p>
</dd>
<dt>writeFile</dt><dd><p>Boolean variable that determines whether the data subsets need to be output or not. The default is <code>FALSE</code>.  </p>
</dd>
<dt>showTrace</dt><dd><p>Boolean variable that determines the level of user feedback. The default is <code>FALSE</code>.   </p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>par.default()
</code></pre>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='remainUnsample'>Get the remain unsampled data after <code><a href="#topic+SSsample">SSsample</a></code></h2><span id='topic+remainUnsample'></span>

<h3>Description</h3>

<p>Built-in function: This function is used in the semi-deterministic SS algorithm, and it contains two parameters X and Y, both of which are in an increased order. All data points in X vector that have not appeared in Y vector will be recorded and returned by this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remainUnsample(X, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remainUnsample_+3A_x">X</code></td>
<td>
<p>A vector that needs to be sampled.</p>
</td></tr>
<tr><td><code id="remainUnsample_+3A_y">Y</code></td>
<td>
<p>A vector with data samples from X.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the remaining data that are not in Y.
</p>

<hr>
<h2 id='SBSS.P'>'DSAM' - SBSS.P algorithm</h2><span id='topic+SBSS.P'></span>

<h3>Description</h3>

<p>SBSS.P algorithm is a stochastic algorithm. It obtains data subsets through uniform sampling in each neuron after clustering through SOM neural network, with details given in May et al. (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SBSS.P(data, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SBSS.P_+3A_data">data</code></td>
<td>
<p>The dataset should be matrix or Data.frame. The format should be as follows: Column one is a subscript vector used to mark each data point (each row is considered as a data point); Columns from 2 to N-1 are the input data, and Column N are the output data.</p>
</td></tr>
<tr><td><code id="SBSS.P_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the par.default function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the training, test and validation subsets. If the original data are required to be split into two subsets, the training and test subsets can be combined into a single calibration subset.
</p>


<h3>References</h3>

<p>May, R. J., Maier H. R., and Dandy G. C.(2010), Data splitting for artificial neural networks using SOM-based stratified sampling, Neural Netw, 23(2), 283-294.
</p>

<hr>
<h2 id='selectData'>Select specific split data</h2><span id='topic+selectData'></span>

<h3>Description</h3>

<p>Built-in function: This function decides whether to process the input dataset according to the parameter <code>include.inp</code>. If TRUE, this function removes Column 1 of the input dataset; otherwise, it returns the Column N of the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectData(data, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectData_+3A_data">data</code></td>
<td>
<p>The dataset should be matrix or Data.frame. The format should be as follows: Column one is a subscript vector used to mark each data point (each row is considered as a data point); Columns from 2 to N-1 are the input data, and Column N are the output data.</p>
</td></tr>
<tr><td><code id="selectData_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the par.default function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix for subsequent calculations.
</p>

<hr>
<h2 id='somCluster'>Self-organized map clustering</h2><span id='topic+somCluster'></span>

<h3>Description</h3>

<p>Built-in function: This function performs clustering for a given dataset by calling the <code>[kohonen]{som}</code> function from a ‚Äúkohonen‚Äù package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>somCluster(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="somCluster_+3A_data">data</code></td>
<td>
<p>The dataset in matrix or data.frame, containing only input and output vectors, but with no subscript vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return a data list of clustering neurons in the SOM network.
</p>

<hr>
<h2 id='SOMPLEX'>'DSAM' - SOMPLEX algorithm</h2><span id='topic+SOMPLEX'></span>

<h3>Description</h3>

<p>SOMPLEX algorithm is a stochastic algorithm, with details given in Chen et al. (2022) and Zheng et al. (2023)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SOMPLEX(data, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SOMPLEX_+3A_data">data</code></td>
<td>
<p>The dataset should be matrix or Data.frame. The format should be as follows: Column one is a subscript vector used to mark each data point (each row is considered as a data point); Columns from 2 to N-1 are the input data, and Column N are the output data.</p>
</td></tr>
<tr><td><code id="SOMPLEX_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the <code><a href="#topic+par.default">par.default</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the training, test and validation subsets. If the original data are required to be split into two subsets, the training and test subsets can be combined into a single calibration subset.
</p>


<h3>References</h3>

<p>Chen, J., Zheng F., May R., Guo D., Gupta H., and Maier H. R.(2022), Improved data splitting methods for data-driven hydrological model development based on a large number of catchment samples, Journal of Hydrology, 613.
</p>

<hr>
<h2 id='SS'>'DSAM' - SS algorithm</h2><span id='topic+SS'></span>

<h3>Description</h3>

<p>The systematic stratified (SS) is a semi-deterministic method, with details given in Zheng et al. (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SS(data, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SS_+3A_data">data</code></td>
<td>
<p>The type of data set to be divided should be matrix or Data.frame, and the data format is as follows: The first column is a subscript vector, which is used to mark each data point (each row is regarded as a data point); Columns 2 through N-1 are the input vectors, and columns N (the last) are the output vectors.</p>
</td></tr>
<tr><td><code id="SS_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the <code><a href="#topic+par.default">par.default</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the training, test and validation subsets. If the original data are required to be split into two subsets, the training and test subsets can be combined into a single calibration subset.
</p>


<h3>References</h3>

<p>Zheng, F., Maier, H.R., Wu, W., Dandy, G.C., Gupta, H.V. and Zhang, T. (2018) On Lack of Robustness in Hydrological Model Development Due to Absence of Guidelines for Selecting Calibration and Evaluation Data: Demonstration for Data‚ÄêDriven Models. Water Resources Research 54(2), 1013-1030.
</p>

<hr>
<h2 id='SSsample'>Core function of SS sampling</h2><span id='topic+SSsample'></span>

<h3>Description</h3>

<p>Built-in function: This function performs the SS algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SSsample(index, prop)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SSsample_+3A_index">index</code></td>
<td>
<p>A subscript vector whose subscript corresponds to the output vector of the data point sorted in an ascending order.</p>
</td></tr>
<tr><td><code id="SSsample_+3A_prop">prop</code></td>
<td>
<p>The sampling ratio, with the value ranging between 0 and 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return a vector containing the subscript of the sampled data points.
</p>

<hr>
<h2 id='standardise'>Standardized data</h2><span id='topic+standardise'></span>

<h3>Description</h3>

<p>Built-in function: This function is used to standardize the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardise(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standardise_+3A_data">data</code></td>
<td>
<p>The dataset should be of type matrix or Data.frame and contain only the input and output vectors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return a matrix with normalized data.
</p>

<hr>
<h2 id='TIMECON'>'DSAM' - Time-consecutive algorithm</h2><span id='topic+TIMECON'></span>

<h3>Description</h3>

<p>This function selects a time-consecutive data from the original data set as the calibration (training and test) subset, and the remaining data is taken as the evaluation subset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TIMECON(data, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TIMECON_+3A_data">data</code></td>
<td>
<p>The dataset should be matrix or Data.frame. The format should be as follows: Column one is a subscript vector used to mark each data point (each row is considered as a data point); Columns from 2 to N-1 are the input data, and Column N are the output data.</p>
</td></tr>
<tr><td><code id="TIMECON_+3A_control">control</code></td>
<td>
<p>User-defined parameter list, where each parameter definition refers to the <code><a href="#topic+par.default">par.default</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the calibration and validation subsets.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
