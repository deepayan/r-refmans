<!DOCTYPE html><html><head><title>Help for package rfVarImpOOB</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rfVarImpOOB}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Accuracy'><p>computes accuracy of a vector</p></a></li>
<li><a href='#arabidopsis'><p>Arabidopsis thaliana</p></a></li>
<li><a href='#gini_index'><p>compute Gini impurity for binary values only</p></a></li>
<li><a href='#gini_process'><p>computes Gini index</p></a></li>
<li><a href='#GiniImportanceForest'><p>computes inbag and OOB Gini importance averaged over all trees in a forest</p></a></li>
<li><a href='#GiniImportanceTree'><p>computes Gini information gain for one tree from randomForest</p></a></li>
<li><a href='#InOutBags'><p>separates data into inbag and outbag</p></a></li>
<li><a href='#lpnorm'><p>Compute the Lp norm of a vector.</p></a></li>
<li><a href='#mlogloss'><p>computes log loss for multiclass problem</p></a></li>
<li><a href='#Mode'><p>computes the mode of an array</p></a></li>
<li><a href='#plotVI'><p>creates barplots for variable importances</p></a></li>
<li><a href='#plotVI2'><p>creates barplots for variable importances</p></a></li>
<li><a href='#preorder2'><p>recursive traversal of tree assigning row numbers of data for each node and leaf</p></a></li>
<li><a href='#rfTitanic'><p>fit a random forest model on the titanic data</p></a></li>
<li><a href='#splitBag'><p>splits the data from parent node into left and right children</p></a></li>
<li><a href='#titanic_train'><p>Titanic train data.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Unbiased Variable Importance for Random Forests</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-06-30</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.2), stats, randomForest</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, ggpubr, dplyr,titanic,magrittr,ranger</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr,rmarkdown</td>
</tr>
<tr>
<td>Author:</td>
<td>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes a novel variable importance for random forests: Impurity reduction importance scores for out-of-bag (OOB) data complementing the existing inbag Gini importance, see also &lt;<a href="https://doi.org/10.1080%2F03610926.2020.1764042">doi:10.1080/03610926.2020.1764042</a>&gt;. 
    The Gini impurities for inbag and OOB data are combined in three different ways, after which the information gain is computed at each split.
    This gain is aggregated for each split variable in a tree and averaged across trees.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-01 08:16:57 UTC; loecherm</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-01 14:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Accuracy'>computes accuracy of a vector </h2><span id='topic+Accuracy'></span>

<h3>Description</h3>

<p>Accuracy is defined as the proportion of correct labels</p>


<h3>Usage</h3>

<pre><code class='language-R'>Accuracy(y, yHat, dig = 8)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Accuracy_+3A_y">y</code></td>
<td>
<p>vector of categorical/nominal values</p>
</td></tr>
<tr><td><code id="Accuracy_+3A_yhat">yHat</code></td>
<td>
<p>prediction/estimate</p>
</td></tr>
<tr><td><code id="Accuracy_+3A_dig">dig</code></td>
<td>
<p>number of digits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Accuracy defined as proportion of values equal to majority  </p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>







Accuracy(c(rep(0,9),1), 1)


Accuracy(c(rep(0,9),1), 0)


</code></pre>

<hr>
<h2 id='arabidopsis'>Arabidopsis thaliana</h2><span id='topic+arabidopsis'></span>

<h3>Description</h3>

<p>RNA editing is the process whereby RNA is modified from
the sequence of the corresponding DNA template [1].
For instance, cytidine-to-uridine conversion (abbreviated
C-to-U conversion) is common in plant mitochondria.
The mechanisms of this conversion remain largely
unknown, although the role of neighboring nucleotides is
emphasized. Cummings and Myers [1] suggest to use
information from sequence regions flanking the sites of
interest to predict editing in Arabidopsis thaliana, Brassicanapus and Oryza sativa based on random forests. The Arabidopsis thaliana data of [1] can be loaded from the journal Web site.
</p>
<p>For each of the 876 observations, the
data set gives
</p>
<p>the response at the site of interest (binary: edited/not
edited) and as potential predictor variables
the 40 nucleotides at positions -20 to 20, relative to the
edited site (4 categories),
cp: the codon position (4 categories),
fe: the estimated folding energy (continuous) and
dfe: the difference in estimated folding energy between pre-
edited and edited sequences (continuous).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arabidopsis
</code></pre>


<h3>Format</h3>

<p>Data frame with columns
</p>

<dl>
<dt>edit</dt><dd><p>binary:the response at the site of interest</p>
</dd>
<dt>X.k</dt><dd><p>nucleotides at positions -k, relative to the edited site (4 categories)</p>
</dd>
<dt>Xk</dt><dd><p>nucleotides at positions k, relative to the edited site (4 categories)</p>
</dd>
<dt>cp</dt><dd><p> the codon position (4 categories),</p>
</dd>
<dt>fe</dt><dd><p>the estimated folding energy (continuous)</p>
</dd>
<dt>dfe</dt><dd><p>the difference in estimated folding energy between pre-
edited and edited sequences (continuous)</p>
</dd>
</dl>


<h3>Source</h3>

<p>[1] Cummings, Michael P, and Daniel S Myers. Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics, 2004, 7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>arabidopsis
</code></pre>

<hr>
<h2 id='gini_index'>compute Gini impurity for binary values only</h2><span id='topic+gini_index'></span>

<h3>Description</h3>

<p>simple function to compute simple or penalized Gini impurity
</p>
<p>The &quot;penalty&quot; compares the class probabilities <code>pHat</code> with a reference estimate <code>pEst</code> 
</p>
<p>which would typically serve as a prediction (e.g. in a tree node).</p>


<h3>Usage</h3>

<pre><code class='language-R'>gini_index(pHat, pEst = NULL, k = 2, kind = 1, w = 2)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gini_index_+3A_phat">pHat</code></td>
<td>
<p>probabilities from the current data,</p>
</td></tr>
<tr><td><code id="gini_index_+3A_pest">pEst</code></td>
<td>
<p>estimated class probabilities (typically from an earlier inbag estimation). Only pass if you intend to compute the &quot;validation-penalized Gini&quot;</p>
</td></tr>
<tr><td><code id="gini_index_+3A_k">k</code></td>
<td>
<p>exponent of penalty term: abs(pHat-pEst)^k</p>
</td></tr>
<tr><td><code id="gini_index_+3A_kind">kind</code></td>
<td>
<p>kind of penalty</p>
</td></tr>
<tr><td><code id="gini_index_+3A_w">w</code></td>
<td>
<p>weights, default is 2 if you pass just a single probability instead of the vector (p,1-p)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>simple or penalized Gini impurity</p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>

#Test binary case:





gini_index(0.5,0.5,kind=1)


gini_index(0.9,0.1,kind=1)


gini_index(0.1,0.9,kind=1)





gini_index(0.5,0.5,kind=2)


gini_index(0.9,0.1,kind=2)


gini_index(0.1,0.9,kind=2)








gini_index(0.5,0.5,kind=3)


gini_index(0.9,0.1,kind=3)


gini_index(0.1,0.9,kind=3)





</code></pre>

<hr>
<h2 id='gini_process'>computes Gini index </h2><span id='topic+gini_process'></span>

<h3>Description</h3>

<p>computes Gini index </p>


<h3>Usage</h3>

<pre><code class='language-R'>gini_process(classes, splitvar = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gini_process_+3A_classes">classes</code></td>
<td>
<p>vector of factors/categorical vars</p>
</td></tr>
<tr><td><code id="gini_process_+3A_splitvar">splitvar</code></td>
<td>
<p>split variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Gini index</p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>

#Test binary case:





#50/50split


gini_process(c(rep(0,10),rep(1,10)))#0.5 CORRECT !


#10/90split


gini_process(c(rep(0,1),rep(1,9)))#0.18= CORRECT ! 


#0/100split


gini_process(factor(c(rep(0,0),rep(1,10)), levels=c(0,1)))#0








#Test binary case:





#25/25/25/25 split


gini_process(factor(c(rep(0,5),rep(1,5),rep(2,5),


                      rep(3,5)), levels=c(0:3)))#0.75 = 4*0.25*0.75 CORRECT !


#10/10/10/70 split


gini_process(factor(c(rep(0,1),rep(1,1),rep(2,1),


                      rep(3,7)), levels=c(0:3)))#0.48 = 3*0.1*0.9+0.7*0.3  CORRECT !


#0/0/0/100 split


gini_process(factor(c(rep(0,0),rep(1,0),rep(2,0),


                      rep(3,20)), levels=c(0:3)))#0. CORRECT !





</code></pre>

<hr>
<h2 id='GiniImportanceForest'>computes inbag and OOB Gini importance averaged over all trees in a forest</h2><span id='topic+GiniImportanceForest'></span>

<h3>Description</h3>

<p>workhorse function of this package</p>


<h3>Usage</h3>

<pre><code class='language-R'>GiniImportanceForest(RF, data, ylabel = "Survived", zeroLeaf = TRUE, 


    agg = c("mean", "median", "none")[1], score = c("PMDI21", 


        "MDI", "MDA", "MIA")[1], Predictor = Mode, verbose = 0)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GiniImportanceForest_+3A_rf">RF</code></td>
<td>
<p>object returned by call to randomForest()</p>
</td></tr>
<tr><td><code id="GiniImportanceForest_+3A_data">data</code></td>
<td>
<p>data which was used to train the RF. NOTE: assumes setting of inbag=TRUE while training</p>
</td></tr>
<tr><td><code id="GiniImportanceForest_+3A_ylabel">ylabel</code></td>
<td>
<p>name of dependent variable</p>
</td></tr>
<tr><td><code id="GiniImportanceForest_+3A_zeroleaf">zeroLeaf</code></td>
<td>
<p>if TRUE discard the information gain due to splits resulting in n=1</p>
</td></tr>
<tr><td><code id="GiniImportanceForest_+3A_agg">agg</code></td>
<td>
<p>method of aggregating importance scores across trees. If &quot;none&quot; return the raw arrays (for debugging)</p>
</td></tr>
<tr><td><code id="GiniImportanceForest_+3A_score">score</code></td>
<td>
<p>scoring method:MDI=mean decrease impurity (Gini),MDA=mean decrease accuracy (permutation),MIA=mean increase accuracy</p>
</td></tr>
<tr><td><code id="GiniImportanceForest_+3A_predictor">Predictor</code></td>
<td>
<p>function to estimate node prediction, such as Mode or mean or median. Alternatively, pass an array of numbers as replacement for the yHat column of tree</p>
</td></tr>
<tr><td><code id="GiniImportanceForest_+3A_verbose">verbose</code></td>
<td>
<p>level of verbosity</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix with variable importance scores and their stdevs</p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>




data("titanic_train", package = "rfVarImpOOB",  envir = environment())


set.seed(123)


ranRows=sample(nrow(titanic_train), 300)


data=titanic_train[ranRows,]





RF = randomForest::randomForest(formula = Survived ~ Sex + Pclass + PassengerId,


                                data=data,


                                ntree=5,importance=TRUE,


                                mtry=3,keep.inbag=TRUE, 


                                nodesize = 20)


data$Survived = as.numeric(data$Survived)-1


VI_Titanic = GiniImportanceForest(RF, data,ylab="Survived")


</code></pre>

<hr>
<h2 id='GiniImportanceTree'>computes Gini information gain for one tree from randomForest</h2><span id='topic+GiniImportanceTree'></span>

<h3>Description</h3>

<p>computes importance scores for an individual tree. 
</p>
<p>These can be based on Gini impurity or Accuracy or logloss </p>


<h3>Usage</h3>

<pre><code class='language-R'>GiniImportanceTree(bag, RF, k, ylabel = "Survived", returnTree = FALSE, 


    zeroLeaf = TRUE, score = c("PMDI21", "MDI", "MDA", "MIA")[1], 


    Predictor = Mode, verbose = 0)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GiniImportanceTree_+3A_bag">bag</code></td>
<td>
<p>data to compute the Gini gain for</p>
</td></tr>
<tr><td><code id="GiniImportanceTree_+3A_rf">RF</code></td>
<td>
<p>object returned by call to randomForest()</p>
</td></tr>
<tr><td><code id="GiniImportanceTree_+3A_k">k</code></td>
<td>
<p>which tree</p>
</td></tr>
<tr><td><code id="GiniImportanceTree_+3A_ylabel">ylabel</code></td>
<td>
<p>name of dependent variable</p>
</td></tr>
<tr><td><code id="GiniImportanceTree_+3A_returntree">returnTree</code></td>
<td>
<p>if TRUE returns the tree data frame otherwise the aggregated Gini importance grouped by split variables</p>
</td></tr>
<tr><td><code id="GiniImportanceTree_+3A_zeroleaf">zeroLeaf</code></td>
<td>
<p>if TRUE discard the information gain due to splits resulting in n=1</p>
</td></tr>
<tr><td><code id="GiniImportanceTree_+3A_score">score</code></td>
<td>
<p>scoring method:PMDI=mean decrease penalized Gini impurity (note:the last digit is the exponent of the penalty!), 
</p>
<p>MDI=mean decrease impurity (Gini), MDA=mean decrease accuracy (permutation),
</p>
<p>MIA=mean increase accuracy</p>
</td></tr>
<tr><td><code id="GiniImportanceTree_+3A_predictor">Predictor</code></td>
<td>
<p>function to estimate node prediction, such as Mode or mean or median. Alternatively, pass an array of numbers as replacement for the yHat column of tree</p>
</td></tr>
<tr><td><code id="GiniImportanceTree_+3A_verbose">verbose</code></td>
<td>
<p>level of verbosity</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if returnTree==TRUE returns the tree data frame otherwise the aggregated Gini importance grouped by split variables</p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>




rfTit = rfTitanic(nRows = 500,nodesize=10)


rfTit$data$Survived = as.numeric(rfTit$data$Survived)-1


k=1


tmp &lt;- InOutBags(rfTit$RF, rfTit$data, k)


IndivTree =getTree(rfTit$RF,k)


#plot(as.party(tmp))#does not work


InTree = GiniImportanceTree(tmp$inbag,rfTit$RF,k,returnTree=TRUE)


OutTree = GiniImportanceTree(tmp$outbag,rfTit$RF,k,returnTree=TRUE)





</code></pre>

<hr>
<h2 id='InOutBags'>separates data into inbag and outbag</h2><span id='topic+InOutBags'></span>

<h3>Description</h3>

<p>convenience function to mitigate risk of improperly disentangling train/test
</p>
<p>NOTE: the original row names (too dangerous for repeated rows) are not kept but instead recorded in a separate column</p>


<h3>Usage</h3>

<pre><code class='language-R'>InOutBags(RF, data, k, inclRowNames = TRUE, NullRowNames = TRUE, 


    verbose = 0)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="InOutBags_+3A_rf">RF</code></td>
<td>
<p>object returned by call to randomForest()</p>
</td></tr>
<tr><td><code id="InOutBags_+3A_data">data</code></td>
<td>
<p>data which was used to train the RF. NOTE: assumes setting of inbag=TRUE while training</p>
</td></tr>
<tr><td><code id="InOutBags_+3A_k">k</code></td>
<td>
<p>tree number</p>
</td></tr>
<tr><td><code id="InOutBags_+3A_inclrownames">inclRowNames</code></td>
<td>
<p>create extra column of original row names</p>
</td></tr>
<tr><td><code id="InOutBags_+3A_nullrownames">NullRowNames</code></td>
<td>
<p>if TRUE set row names to NULL</p>
</td></tr>
<tr><td><code id="InOutBags_+3A_verbose">verbose</code></td>
<td>
<p>level of verbosity</p>
</td></tr>
</table>


<h3>Value</h3>

<p>inbag and outbag subsets of the original data</p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>

rfTit = rfTitanic(nRows = 200,nodesize=10, ntree = 5)





k=1


tmp &lt;- InOutBags(rfTit$RF, rfTit$data, k)





</code></pre>

<hr>
<h2 id='lpnorm'>Compute the Lp norm of a vector.</h2><span id='topic+lpnorm'></span>

<h3>Description</h3>

<p>Compute the Lp norm of a vector.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpnorm(x, p = 2)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpnorm_+3A_x">x</code></td>
<td>
<p>vector to compute the Lp norm of</p>
</td></tr>
<tr><td><code id="lpnorm_+3A_p">p</code></td>
<td>
<p>parameter of p norm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lp norm of a vector or NA</p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>

lpnorm(1:10)


lpnorm(matrix(1:25, 5, 5))


lpnorm(split(1:25, rep(1:5, each = 5)))





lpnorm(1:10, 1)


lpnorm(matrix(1:25, 5, 5), 1)


lpnorm(split(1:25, rep(1:5, each = 5)), 1)





lpnorm(rnorm(10), 0)


lpnorm(matrix(rnorm(25), 5, 5), 0)


lpnorm(split(rnorm(25), rep(1:5, each = 5)), 0)





lpnorm(-5:5, Inf)


lpnorm(matrix(-25:-1, 5, 5), Inf)


lpnorm(split(-25:-1, rep(1:5, each = 5)), Inf)


</code></pre>

<hr>
<h2 id='mlogloss'>computes log loss for multiclass problem</h2><span id='topic+mlogloss'></span>

<h3>Description</h3>

<p>computes log loss for multiclass problem</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlogloss(actual, pred_m, eps = 0.001)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlogloss_+3A_actual">actual</code></td>
<td>
<p>integer vector with truth labels, values range from 0 to n - 1 classes</p>
</td></tr>
<tr><td><code id="mlogloss_+3A_pred_m">pred_m</code></td>
<td>
<p>predicted probs: column 1 =&gt; label 0, column 2 =&gt; label 1 and so on</p>
</td></tr>
<tr><td><code id="mlogloss_+3A_eps">eps</code></td>
<td>
<p>numerical cutoff taken very high</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>




# require(nnet)


# set.seed(1)


# actual = as.integer(iris$Species) - 1


# fit = nnet(Species ~ ., data = iris, size = 2)


# pred = predict(fit, iris)#note this is a 3-column prediction matrix!


# 


# mlogloss(actual, pred) # 0.03967





#library(titanic)


#baseline prediction


#data(titanic_train, package="titanic")


yHat = mean(titanic_train$Survived)#0.383838


mlogloss(titanic_train$Survived,yHat)


#try factors


titanic_train$Survived = as.factor(titanic_train$Survived)


mlogloss(titanic_train$Survived,yHat)


</code></pre>

<hr>
<h2 id='Mode'>computes the mode of an array</h2><span id='topic+Mode'></span>

<h3>Description</h3>

<p>returns the mode of a vector</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mode(x)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mode_+3A_x">x</code></td>
<td>
<p>vector to find mode of</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>




Mode(rep(letters[1:3],1:3))


Mode(c(TRUE,TRUE,FALSE))


Mode(c(TRUE,TRUE,FALSE,FALSE))


</code></pre>

<hr>
<h2 id='plotVI'>creates barplots for variable importances</h2><span id='topic+plotVI'></span>

<h3>Description</h3>

<p>creates barplots for variable importances</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotVI(VIbench, order_by = "Gini_OOB", decreasing = TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotVI_+3A_vibench">VIbench</code></td>
<td>
<p>matrix with importance scores as returned by GiniImportanceForest</p>
</td></tr>
<tr><td><code id="plotVI_+3A_order_by">order_by</code></td>
<td>
<p>how to order</p>
</td></tr>
<tr><td><code id="plotVI_+3A_decreasing">decreasing</code></td>
<td>
<p>which direction to sort</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data("titanic_train", package = "rfVarImpOOB",  envir = environment())


set.seed(123)


ranRows=sample(nrow(titanic_train), 300)


data=titanic_train[ranRows,]





RF = randomForest::randomForest(formula = Survived ~ Sex + Pclass + PassengerId,


                                       data=data,


                                       ntree=5,importance=TRUE,


                                       mtry=3,keep.inbag=TRUE, 


                                       nodesize = 20)


data$Survived = as.numeric(data$Survived)-1


VI_Titanic = GiniImportanceForest(RF, data,ylab="Survived")


plotVI(VI_Titanic,decreasing = TRUE)





</code></pre>

<hr>
<h2 id='plotVI2'>creates barplots for variable importances</h2><span id='topic+plotVI2'></span>

<h3>Description</h3>

<p>creates barplots for variable importances including permutation scores</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotVI2(VIbench, decreasing = TRUE, with_MDA = TRUE, ordered_by = "inbag", 


    score = "Gini Importance", horizontal = TRUE, fill = "order", 


    labelSize = 10, nrow = 3)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotVI2_+3A_vibench">VIbench</code></td>
<td>
<p>matrix with importance scores as returned by GiniImportanceForest</p>
</td></tr>
<tr><td><code id="plotVI2_+3A_decreasing">decreasing</code></td>
<td>
<p>which direction to sort</p>
</td></tr>
<tr><td><code id="plotVI2_+3A_with_mda">with_MDA</code></td>
<td>
<p>also visualize mean decrease in accuracy (permutation importance)</p>
</td></tr>
<tr><td><code id="plotVI2_+3A_ordered_by">ordered_by</code></td>
<td>
<p>how to order</p>
</td></tr>
<tr><td><code id="plotVI2_+3A_score">score</code></td>
<td>
<p>type of importance score: Gini, MIA,..</p>
</td></tr>
<tr><td><code id="plotVI2_+3A_horizontal">horizontal</code></td>
<td>
<p>horizontal barplot instead of vertical ?</p>
</td></tr>
<tr><td><code id="plotVI2_+3A_fill">fill</code></td>
<td>
<p>fill style for barplots; use e.g. shQuote(&quot;blue&quot;) to pass color strings</p>
</td></tr>
<tr><td><code id="plotVI2_+3A_labelsize">labelSize</code></td>
<td>
<p>size of axis labels</p>
</td></tr>
<tr><td><code id="plotVI2_+3A_nrow">nrow</code></td>
<td>
<p>number of rows of ploztz arrangement</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data("titanic_train", package = "rfVarImpOOB",  envir = environment())


set.seed(123)


ranRows=sample(nrow(titanic_train), 300)


data=titanic_train[ranRows,]





RF = randomForest::randomForest(formula = Survived ~ Sex + Pclass + PassengerId,


                         data=data,


                    ntree=5,importance=TRUE,


                    mtry=3,keep.inbag=TRUE, 


                    nodesize = 20)


data$Survived = as.numeric(data$Survived)-1


VI_Titanic = GiniImportanceForest(RF, data,ylab="Survived")


plotVI2(VI_Titanic,decreasing = TRUE)





</code></pre>

<hr>
<h2 id='preorder2'>recursive traversal of tree assigning row numbers of data for each node and leaf</h2><span id='topic+preorder2'></span>

<h3>Description</h3>

<p>Recursive calling stops at leaf after which the function propagates back up the tree</p>


<h3>Usage</h3>

<pre><code class='language-R'>preorder2(treeRow, bag, tree, verbose = 0)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preorder2_+3A_treerow">treeRow</code></td>
<td>
<p>current row of tree dataframe to be</p>
</td></tr>
<tr><td><code id="preorder2_+3A_bag">bag</code></td>
<td>
<p>The data for the current row</p>
</td></tr>
<tr><td><code id="preorder2_+3A_tree">tree</code></td>
<td>
<p>tree (from randomForest::getTree to be traversed</p>
</td></tr>
<tr><td><code id="preorder2_+3A_verbose">verbose</code></td>
<td>
<p>level of verbosity</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tree with rownames in column node</p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("titanic_train", package = "rfVarImpOOB",  envir = environment())



set.seed(123)

ranRows=sample(nrow(titanic_train), 300)



RF = randomForest::randomForest(formula = Survived ~ Sex + Pclass + PassengerId,

                    data=titanic_train[ranRows,],

                    ntree=5,importance=TRUE,

                    mtry=3,keep.inbag=TRUE, 

                    nodesize = 1)

k=2

tree = randomForest::getTree(RF, k, labelVar = TRUE) 

tree$node=NA

attr(tree, "rflib") = "randomForest"
inbag = rep(rownames(RF$inbag),time=RF$inbag[,k])

#trainBag=titanic_train[inbag,]

trainBag=titanic_train[ranRows,][inbag,]

tree=preorder2(1,trainBag,tree)

</code></pre>

<hr>
<h2 id='rfTitanic'>fit a random forest model on the titanic data</h2><span id='topic+rfTitanic'></span>

<h3>Description</h3>

<p>convenience function to reduce overhead of repeatedly fitting RF to titanic data</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfTitanic(formel = Survived ~ Sex + Pclass + PassengerId, nRows = 500, 


    ntree = 10, mtry = 3, nodesize = 1)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rfTitanic_+3A_formel">formel</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="rfTitanic_+3A_nrows">nRows</code></td>
<td>
<p>subsample size</p>
</td></tr>
<tr><td><code id="rfTitanic_+3A_ntree">ntree</code></td>
<td>
<p>number of trees</p>
</td></tr>
<tr><td><code id="rfTitanic_+3A_mtry">mtry</code></td>
<td>
<p>mtry</p>
</td></tr>
<tr><td><code id="rfTitanic_+3A_nodesize">nodesize</code></td>
<td>
<p>nodesize</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>

rfTit = rfTitanic(nRows = 500,nodesize=10)


</code></pre>

<hr>
<h2 id='splitBag'>splits the data from parent node into left and right children</h2><span id='topic+splitBag'></span>

<h3>Description</h3>

<p>The function properly splits on factor levels</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitBag(treeRow, bag, tree)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitBag_+3A_treerow">treeRow</code></td>
<td>
<p>current row of tree dataframe to be</p>
</td></tr>
<tr><td><code id="splitBag_+3A_bag">bag</code></td>
<td>
<p>The data for the current row</p>
</td></tr>
<tr><td><code id="splitBag_+3A_tree">tree</code></td>
<td>
<p>tree (from randomForest::getTree)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with elements left_daughter, right_daughter</p>


<h3>Author(s)</h3>

<p>Markus Loecher &lt;Markus.Loecher@gmail.com&gt;</p>

<hr>
<h2 id='titanic_train'>Titanic train data.</h2><span id='topic+titanic_train'></span>

<h3>Description</h3>

<p>Titanic train data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>titanic_train
</code></pre>


<h3>Format</h3>

<p>Data frame with columns
</p>

<dl>
<dt>PassengerId</dt><dd><p>Passenger ID</p>
</dd>
<dt>Survived</dt><dd><p>Passenger Survival Indicator</p>
</dd>
<dt>Pclass</dt><dd><p>Passenger Class</p>
</dd>
<dt>Name</dt><dd><p>Name</p>
</dd>
<dt>Sex</dt><dd><p>Sex</p>
</dd>
<dt>Age</dt><dd><p>Age</p>
</dd>
<dt>SibSp</dt><dd><p>Number of Siblings/Spouses Aboard</p>
</dd>
<dt>Parch</dt><dd><p>Number of Parents/Children Aboard</p>
</dd>
<dt>Ticket</dt><dd><p>Ticket Number</p>
</dd>
<dt>Fare</dt><dd><p>Passenger Fare</p>
</dd>
<dt>Cabin</dt><dd><p>Cabin</p>
</dd>
<dt>Embarked</dt><dd><p>Port of Embarkation</p>
</dd>
</dl>


<h3>Source</h3>

<p>https://www.kaggle.com/c/titanic/data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>titanic_train
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
