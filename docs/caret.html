<!DOCTYPE html><html><head><title>Help for package caret</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {caret}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.matrix.confusionMatrix'><p>Confusion matrix as a table</p></a></li>
<li><a href='#avNNet'><p>Neural Networks Using Model Averaging</p></a></li>
<li><a href='#bag'><p>A General Framework For Bagging</p></a></li>
<li><a href='#bagEarth'><p>Bagged Earth</p></a></li>
<li><a href='#bagFDA'><p>Bagged FDA</p></a></li>
<li><a href='#BloodBrain'><p>Blood Brain Barrier Data</p></a></li>
<li><a href='#BoxCoxTrans'><p>Box-Cox and Exponential Transformations</p></a></li>
<li><a href='#calibration'><p>Probability Calibration Plot</p></a></li>
<li><a href='#caret-internal'><p>Internal Functions</p></a></li>
<li><a href='#caretSBF'><p>Selection By Filtering (SBF) Helper Functions</p></a></li>
<li><a href='#cars'><p>Kelly Blue Book resale data for 2005 model year GM cars</p></a></li>
<li><a href='#classDist'><p>Compute and predict the distances to class centroids</p></a></li>
<li><a href='#confusionMatrix'><p>Create a confusion matrix</p></a></li>
<li><a href='#confusionMatrix.train'><p>Estimate a Resampled Confusion Matrix</p></a></li>
<li><a href='#cox2'><p>COX-2 Activity Data</p></a></li>
<li><a href='#createDataPartition'><p>Data Splitting functions</p></a></li>
<li><a href='#defaultSummary'><p>Calculates performance across resamples</p></a></li>
<li><a href='#densityplot.rfe'><p>Lattice functions for plotting resampling results of recursive feature</p>
selection</a></li>
<li><a href='#dhfr'><p>Dihydrofolate Reductase Inhibitors Data</p></a></li>
<li><a href='#diff.resamples'><p>Inferential Assessments About Model Performance</p></a></li>
<li><a href='#dotPlot'><p>Create a dotplot of variable importance values</p></a></li>
<li><a href='#dotplot.diff.resamples'><p>Lattice Functions for Visualizing Resampling Differences</p></a></li>
<li><a href='#downSample'><p>Down- and Up-Sampling Imbalanced Data</p></a></li>
<li><a href='#dummyVars'><p>Create A Full Set of Dummy Variables</p></a></li>
<li><a href='#extractPrediction'><p>Extract predictions and class probabilities from train objects</p></a></li>
<li><a href='#featurePlot'><p>Wrapper for Lattice Plotting of Predictor Variables</p></a></li>
<li><a href='#filterVarImp'><p>Calculation of filter-based variable importance</p></a></li>
<li><a href='#findCorrelation'><p>Determine highly correlated variables</p></a></li>
<li><a href='#findLinearCombos'><p>Determine linear combinations in a matrix</p></a></li>
<li><a href='#format.bagEarth'><p>Format 'bagEarth' objects</p></a></li>
<li><a href='#gafs_initial'><p>Ancillary genetic algorithm functions</p></a></li>
<li><a href='#gafs.default'><p>Genetic algorithm feature selection</p></a></li>
<li><a href='#gafsControl'><p>Control parameters for GA and SA feature selection</p></a></li>
<li><a href='#GermanCredit'><p>German Credit Data</p></a></li>
<li><a href='#getSamplingInfo'><p>Get sampling info from a train model</p></a></li>
<li><a href='#ggplot.rfe'><p>Plot RFE Performance Profiles</p></a></li>
<li><a href='#ggplot.train'><p>Plot Method for the train Class</p></a></li>
<li><a href='#histogram.train'><p>Lattice functions for plotting resampling results</p></a></li>
<li><a href='#icr.formula'><p>Independent Component Regression</p></a></li>
<li><a href='#index2vec'><p>Convert indicies to a binary vector</p></a></li>
<li><a href='#knn3'><p>k-Nearest Neighbour Classification</p></a></li>
<li><a href='#knnreg'><p>k-Nearest Neighbour Regression</p></a></li>
<li><a href='#learning_curve_dat'><p>Create Data to Plot a Learning Curve</p></a></li>
<li><a href='#lift'><p>Lift Plot</p></a></li>
<li><a href='#maxDissim'><p>Maximum Dissimilarity Sampling</p></a></li>
<li><a href='#mdrr'><p>Multidrug Resistance Reversal (MDRR) Agent Data</p></a></li>
<li><a href='#modelLookup'><p>Tools for Models Available in <code>train</code></p></a></li>
<li><a href='#nearZeroVar'><p>Identification of near zero variance predictors</p></a></li>
<li><a href='#negPredValue'><p>Calculate sensitivity, specificity and predictive values</p></a></li>
<li><a href='#nullModel'><p>Fit a simple, non-informative model</p></a></li>
<li><a href='#oil'><p>Fatty acid composition of commercial oils</p></a></li>
<li><a href='#oneSE'><p>Selecting tuning Parameters</p></a></li>
<li><a href='#panel.lift2'><p>Lattice Panel Functions for Lift Plots</p></a></li>
<li><a href='#panel.needle'><p>Needle Plot Lattice Panel</p></a></li>
<li><a href='#pcaNNet'><p>Neural Networks with a Principal Component Step</p></a></li>
<li><a href='#pickSizeBest'><p>Backwards Feature Selection Helper Functions</p></a></li>
<li><a href='#plot.gafs'><p>Plot Method for the gafs and safs Classes</p></a></li>
<li><a href='#plot.varImp.train'><p>Plotting variable importance measures</p></a></li>
<li><a href='#plotClassProbs'><p>Plot Predicted Probabilities in Classification Models</p></a></li>
<li><a href='#plotObsVsPred'><p>Plot Observed versus Predicted Results in Regression and Classification</p>
Models</a></li>
<li><a href='#plsda'><p>Partial Least Squares and Sparse Partial Least Squares Discriminant Analysis</p></a></li>
<li><a href='#pottery'><p>Pottery from Pre-Classical Sites in Italy</p></a></li>
<li><a href='#prcomp.resamples'><p>Principal Components Analysis of Resampling Results</p></a></li>
<li><a href='#predict.bagEarth'><p>Predicted values based on bagged Earth and FDA models</p></a></li>
<li><a href='#predict.gafs'><p>Predict new samples</p></a></li>
<li><a href='#predict.knn3'><p>Predictions from k-Nearest Neighbors</p></a></li>
<li><a href='#predict.knnreg'><p>Predictions from k-Nearest Neighbors Regression Model</p></a></li>
<li><a href='#predictors'><p>List predictors used in the model</p></a></li>
<li><a href='#preProcess'><p>Pre-Processing of Predictors</p></a></li>
<li><a href='#print.confusionMatrix'><p>Print method for confusionMatrix</p></a></li>
<li><a href='#print.train'><p>Print Method for the train Class</p></a></li>
<li><a href='#recall'><p>Calculate recall, precision and F values</p></a></li>
<li><a href='#resampleHist'><p>Plot the resampling distribution of the model statistics</p></a></li>
<li><a href='#resamples'><p>Collation and Visualization of Resampling Results</p></a></li>
<li><a href='#resampleSummary'><p>Summary of resampled performance estimates</p></a></li>
<li><a href='#rfe'><p>Backwards Feature Selection</p></a></li>
<li><a href='#rfeControl'><p>Controlling the Feature Selection Algorithms</p></a></li>
<li><a href='#Sacramento'><p>Sacramento CA Home Prices</p></a></li>
<li><a href='#safs'><p>Simulated annealing feature selection</p></a></li>
<li><a href='#safs_initial'><p>Ancillary simulated annealing functions</p></a></li>
<li><a href='#sbf'><p>Selection By Filtering (SBF)</p></a></li>
<li><a href='#sbfControl'><p>Control Object for Selection By Filtering (SBF)</p></a></li>
<li><a href='#scat'><p>Morphometric Data on Scat</p></a></li>
<li><a href='#segmentationData'><p>Cell Body Segmentation</p></a></li>
<li><a href='#SLC14_1'><p>Simulation Functions</p></a></li>
<li><a href='#spatialSign'><p>Compute the multivariate spatial sign</p></a></li>
<li><a href='#summary.bagEarth'><p>Summarize a bagged earth or FDA fit</p></a></li>
<li><a href='#tecator'><p>Fat, Water and Protein Content of Meat Samples</p></a></li>
<li><a href='#thresholder'><p>Generate Data to Choose a Probability Threshold</p></a></li>
<li><a href='#train'><p>Fit Predictive Models over Different Tuning Parameters</p></a></li>
<li><a href='#train_model_list'><p>A List of Available Models in train</p></a></li>
<li><a href='#trainControl'><p>Control parameters for train</p></a></li>
<li><a href='#update.safs'><p>Update or Re-fit a SA or GA Model</p></a></li>
<li><a href='#update.train'><p>Update or Re-fit a Model</p></a></li>
<li><a href='#var_seq'><p>Sequences of Variables for Tuning</p></a></li>
<li><a href='#varImp'><p>Calculation of variable importance for regression and classification models</p></a></li>
<li><a href='#varImp.gafs'><p>Variable importances for GAs and SAs</p></a></li>
<li><a href='#xyplot.resamples'><p>Lattice Functions for Visualizing Resampling Results</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Classification and Regression Training</td>
</tr>
<tr>
<td>Version:</td>
<td>6.0-94</td>
</tr>
<tr>
<td>Description:</td>
<td>Misc functions for training and plotting classification and
    regression models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/topepo/caret/">https://github.com/topepo/caret/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/topepo/caret/issues">https://github.com/topepo/caret/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>ggplot2, lattice (&ge; 0.20), R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>e1071, foreach, grDevices, methods, ModelMetrics (&ge; 1.2.2.2),
nlme, plyr, pROC, recipes (&ge; 0.1.10), reshape2, stats, stats4,
utils, withr (&ge; 2.0.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>BradleyTerry2, covr, Cubist, dplyr, earth (&ge; 2.2-3),
ellipse, fastICA, gam (&ge; 1.15), ipred, kernlab, klaR, knitr,
MASS, Matrix, mda, mgcv, mlbench, MLmetrics, nnet, pamr, party
(&ge; 0.9-99992), pls, proxy, randomForest, RANN, rmarkdown,
rpart, spls, subselect, superpc, testthat (&ge; 0.9.1), themis
(&ge; 0.1.3)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-21 18:04:50 UTC; max</td>
</tr>
<tr>
<td>Author:</td>
<td>Max Kuhn <a href="https://orcid.org/0000-0003-2402-136X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Jed Wing [ctb],
  Steve Weston [ctb],
  Andre Williams [ctb],
  Chris Keefer [ctb],
  Allan Engelhardt [ctb],
  Tony Cooper [ctb],
  Zachary Mayer [ctb],
  Brenton Kenkel [ctb],
  R Core Team [ctb],
  Michael Benesty [ctb],
  Reynald Lescarbeau [ctb],
  Andrew Ziem [ctb],
  Luca Scrucca [ctb],
  Yuan Tang [ctb],
  Can Candan [ctb],
  Tyler Hunt [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Max Kuhn &lt;mxkuhn@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-21 19:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.matrix.confusionMatrix'>Confusion matrix as a table</h2><span id='topic+as.matrix.confusionMatrix'></span><span id='topic+as.table.confusionMatrix'></span>

<h3>Description</h3>

<p>Conversion functions for class <code>confusionMatrix</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'confusionMatrix'
as.matrix(x, what = "xtabs", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.confusionMatrix_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+confusionMatrix">confusionMatrix</a></code></p>
</td></tr>
<tr><td><code id="as.matrix.confusionMatrix_+3A_what">what</code></td>
<td>
<p>data to convert to matrix. Either <code>"xtabs"</code>, <code>"overall"</code> or  <code>"classes"</code></p>
</td></tr>
<tr><td><code id="as.matrix.confusionMatrix_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>as.table</code>, the cross-tabulations are saved. For <code>as.matrix</code>, the three object types are saved in matrix format.
</p>


<h3>Value</h3>

<p>A matrix or table
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################
## 2 class example

lvs &lt;- c("normal", "abnormal")
truth &lt;- factor(rep(lvs, times = c(86, 258)),
                levels = rev(lvs))
pred &lt;- factor(
               c(
                 rep(lvs, times = c(54, 32)),
                 rep(lvs, times = c(27, 231))),
               levels = rev(lvs))

xtab &lt;- table(pred, truth)

results &lt;- confusionMatrix(xtab)
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")

###################
## 3 class example

xtab &lt;- confusionMatrix(iris$Species, sample(iris$Species))
as.matrix(xtab)

</code></pre>

<hr>
<h2 id='avNNet'>Neural Networks Using Model Averaging</h2><span id='topic+avNNet'></span><span id='topic+avNNet.default'></span><span id='topic+predict.avNNet'></span><span id='topic+avNNet.formula'></span><span id='topic+print.avNNet'></span>

<h3>Description</h3>

<p>Aggregate several neural network models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>avNNet(x, ...)

## S3 method for class 'formula'
avNNet(
  formula,
  data,
  weights,
  ...,
  repeats = 5,
  bag = FALSE,
  allowParallel = TRUE,
  seeds = sample.int(1e+05, repeats),
  subset,
  na.action,
  contrasts = NULL
)

## Default S3 method:
avNNet(
  x,
  y,
  repeats = 5,
  bag = FALSE,
  allowParallel = TRUE,
  seeds = sample.int(1e+05, repeats),
  ...
)

## S3 method for class 'avNNet'
print(x, ...)

## S3 method for class 'avNNet'
predict(object, newdata, type = c("raw", "class", "prob"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="avNNet_+3A_x">x</code></td>
<td>
<p>matrix or data frame of <code>x</code> values for examples.</p>
</td></tr>
<tr><td><code id="avNNet_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="nnet.html#topic+nnet">nnet</a></code></p>
</td></tr>
<tr><td><code id="avNNet_+3A_formula">formula</code></td>
<td>
<p>A formula of the form <code>class ~ x1 + x2 + ...</code></p>
</td></tr>
<tr><td><code id="avNNet_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in  <code>formula</code> are preferentially to be taken.</p>
</td></tr>
<tr><td><code id="avNNet_+3A_weights">weights</code></td>
<td>
<p>(case) weights for each example - if missing defaults to 1.</p>
</td></tr>
<tr><td><code id="avNNet_+3A_repeats">repeats</code></td>
<td>
<p>the number of neural networks with different random number seeds</p>
</td></tr>
<tr><td><code id="avNNet_+3A_bag">bag</code></td>
<td>
<p>a logical for bagging for each repeat</p>
</td></tr>
<tr><td><code id="avNNet_+3A_allowparallel">allowParallel</code></td>
<td>
<p>if a parallel backend is loaded and available, should the function use it?</p>
</td></tr>
<tr><td><code id="avNNet_+3A_seeds">seeds</code></td>
<td>
<p>random number seeds that can be set prior to bagging (if done) and network creation. This helps maintain reproducibility when models are run in parallel.</p>
</td></tr>
<tr><td><code id="avNNet_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the training sample.  (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="avNNet_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if <code>NA</code>s are found.
The default action is for the procedure to fail.  An alternative is
<code>na.omit</code>, which leads to rejection of cases with missing values on
any required variable.  (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="avNNet_+3A_contrasts">contrasts</code></td>
<td>
<p>a list of contrasts to be used for some or all of
the  factors  appearing as variables in the model formula.</p>
</td></tr>
<tr><td><code id="avNNet_+3A_y">y</code></td>
<td>
<p>matrix or data frame of target values for examples.</p>
</td></tr>
<tr><td><code id="avNNet_+3A_object">object</code></td>
<td>
<p>an object of class <code>avNNet</code> as  returned by <code>avNNet</code>.</p>
</td></tr>
<tr><td><code id="avNNet_+3A_newdata">newdata</code></td>
<td>
<p>matrix or data frame of test examples. A vector is considered to be
a row vector comprising a single case.</p>
</td></tr>
<tr><td><code id="avNNet_+3A_type">type</code></td>
<td>
<p>Type of output, either: <code>raw</code> for the raw outputs, <code>code</code> for the predicted class or <code>prob</code> for the class probabilities.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following Ripley (1996), the same neural network model is fit using different random number seeds. All the resulting models are used for prediction. For regression, the output from each network are averaged. For classification, the model scores are first averaged, then translated to predicted classes. Bagging can also be used to create the models.
</p>
<p>If a parallel backend is registered, the <span class="pkg">foreach</span> package is used to train the networks in parallel.
</p>


<h3>Value</h3>

<p>For <code>avNNet</code>, an object of  <code>"avNNet"</code> or <code>"avNNet.formula"</code>. Items of interest in #' the output are:
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>a list of the models generated from  <code><a href="nnet.html#topic+nnet">nnet</a></code></p>
</td></tr>
<tr><td><code>repeats</code></td>
<td>
<p>an echo of the model input</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>if any predictors had only one distinct value, this is a character string of the #' remaining columns. Otherwise a value of <code>NULL</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>These are heavily based on the <code>nnet</code> code from Brian Ripley.
</p>


<h3>References</h3>

<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks.</em> Cambridge.
</p>


<h3>See Also</h3>

<p><code><a href="nnet.html#topic+nnet">nnet</a></code>,  <code><a href="#topic+preProcess">preProcess</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BloodBrain)
## Not run: 
modelFit &lt;- avNNet(bbbDescr, logBBB, size = 5, linout = TRUE, trace = FALSE)
modelFit

predict(modelFit, bbbDescr)

## End(Not run)
</code></pre>

<hr>
<h2 id='bag'>A General Framework For Bagging</h2><span id='topic+bag'></span><span id='topic+bag.default'></span><span id='topic+bagControl'></span><span id='topic+predict.bag'></span><span id='topic+ldaBag'></span><span id='topic+plsBag'></span><span id='topic+nbBag'></span><span id='topic+ctreeBag'></span><span id='topic+svmBag'></span><span id='topic+nnetBag'></span><span id='topic+print.bag'></span><span id='topic+summary.bag'></span><span id='topic+print.summary.bag'></span>

<h3>Description</h3>

<p><code>bag</code> provides a framework for bagging classification or regression models. The user can provide their own functions for model building, prediction and aggregation of predictions (see Details below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bag(x, ...)

bagControl(
  fit = NULL,
  predict = NULL,
  aggregate = NULL,
  downSample = FALSE,
  oob = TRUE,
  allowParallel = TRUE
)

## Default S3 method:
bag(x, y, B = 10, vars = ncol(x), bagControl = NULL, ...)

## S3 method for class 'bag'
predict(object, newdata = NULL, ...)

## S3 method for class 'bag'
print(x, ...)

## S3 method for class 'bag'
summary(object, ...)

## S3 method for class 'summary.bag'
print(x, digits = max(3, getOption("digits") - 3), ...)

ldaBag

plsBag

nbBag

ctreeBag

svmBag

nnetBag
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bag_+3A_x">x</code></td>
<td>
<p>a matrix or data frame of predictors</p>
</td></tr>
<tr><td><code id="bag_+3A_...">...</code></td>
<td>
<p>arguments to pass to the model function</p>
</td></tr>
<tr><td><code id="bag_+3A_fit">fit</code></td>
<td>
<p>a function that has arguments <code>x</code>, <code>y</code> and <code>...</code> and produces a model object #' that can later be used for prediction. Example functions are found in <code>ldaBag</code>, <code>plsBag</code>, #' <code>nbBag</code>, <code>svmBag</code> and <code>nnetBag</code>.</p>
</td></tr>
<tr><td><code id="bag_+3A_predict">predict</code></td>
<td>
<p>a function that generates predictions for each sub-model. The function should have #' arguments <code>object</code> and <code>x</code>. The output of the function can be any type of object (see the #' example below where posterior probabilities are generated. Example functions are found in <code>ldaBag</code>#' , <code>plsBag</code>, <code>nbBag</code>, <code>svmBag</code> and <code>nnetBag</code>.)</p>
</td></tr>
<tr><td><code id="bag_+3A_aggregate">aggregate</code></td>
<td>
<p>a function with arguments <code>x</code> and <code>type</code>. The function that takes the output #' of the <code>predict</code> function and reduces the bagged predictions to a single prediction per sample. #' the <code>type</code> argument can be used to switch between predicting classes or class probabilities for #' classification models. Example functions are found in <code>ldaBag</code>, <code>plsBag</code>, <code>nbBag</code>, #' <code>svmBag</code> and <code>nnetBag</code>.</p>
</td></tr>
<tr><td><code id="bag_+3A_downsample">downSample</code></td>
<td>
<p>logical: for classification, should the data set be randomly sampled so that each #' class has the same number of samples as the smallest class?</p>
</td></tr>
<tr><td><code id="bag_+3A_oob">oob</code></td>
<td>
<p>logical: should out-of-bag statistics be computed and the predictions retained?</p>
</td></tr>
<tr><td><code id="bag_+3A_allowparallel">allowParallel</code></td>
<td>
<p>a parallel backend is loaded and available, should the function use it?</p>
</td></tr>
<tr><td><code id="bag_+3A_y">y</code></td>
<td>
<p>a vector of outcomes</p>
</td></tr>
<tr><td><code id="bag_+3A_b">B</code></td>
<td>
<p>the number of bootstrap samples to train over.</p>
</td></tr>
<tr><td><code id="bag_+3A_vars">vars</code></td>
<td>
<p>an integer. If this argument is not <code>NULL</code>, a random sample of size <code>vars</code> is taken of the predictors in each bagging iteration. If <code>NULL</code>, all predictors are used.</p>
</td></tr>
<tr><td><code id="bag_+3A_bagcontrol">bagControl</code></td>
<td>
<p>a list of options.</p>
</td></tr>
<tr><td><code id="bag_+3A_object">object</code></td>
<td>
<p>an object of class <code>bag</code>.</p>
</td></tr>
<tr><td><code id="bag_+3A_newdata">newdata</code></td>
<td>
<p>a matrix or data frame of samples for prediction. Note that this argument must have a non-null value</p>
</td></tr>
<tr><td><code id="bag_+3A_digits">digits</code></td>
<td>
<p>minimal number of <em>significant digits</em>.</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 3.
</p>
<p>An object of class <code>list</code> of length 3.
</p>
<p>An object of class <code>list</code> of length 3.
</p>
<p>An object of class <code>list</code> of length 3.
</p>
<p>An object of class <code>list</code> of length 3.
</p>
<p>An object of class <code>list</code> of length 3.
</p>


<h3>Details</h3>

<p>The function is basically a framework where users can plug in any model in to assess
the effect of bagging. Examples functions can be found in <code>ldaBag</code>, <code>plsBag</code>
, <code>nbBag</code>, <code>svmBag</code> and <code>nnetBag</code>.
Each has elements <code>fit</code>, <code>pred</code> and <code>aggregate</code>.
</p>
<p>One note: when <code>vars</code> is not <code>NULL</code>, the sub-setting occurs prior to the <code>fit</code> and #' <code>predict</code> functions are called. In this way, the user probably does not need to account for the #' change in predictors in their functions.
</p>
<p>When using <code>bag</code> with <code><a href="#topic+train">train</a></code>, classification models should use <code>type = "prob"</code> #' inside of the <code>predict</code> function so that <code>predict.train(object, newdata, type = "prob")</code> will #' work.
</p>
<p>If a parallel backend is registered, the <span class="pkg">foreach</span> package is used to train the models in parallel.
</p>


<h3>Value</h3>

<p><code>bag</code> produces an object of class <code>bag</code> with elements
</p>
<table>
<tr><td><code>fits</code></td>
<td>
<p>a list with two sub-objects: the <code>fit</code> object has the actual model fit for that #' bagged samples and the <code>vars</code> object is either <code>NULL</code> or a vector of integers corresponding to which predictors were sampled for that model</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>a mirror of the arguments passed into <code>bagControl</code></p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>the number of bagging iterations</p>
</td></tr>
<tr><td><code>dims</code></td>
<td>
<p>the dimensions of the training set</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## A simple example of bagging conditional inference regression trees:
data(BloodBrain)

## treebag &lt;- bag(bbbDescr, logBBB, B = 10,
##                bagControl = bagControl(fit = ctreeBag$fit,
##                                        predict = ctreeBag$pred,
##                                        aggregate = ctreeBag$aggregate))




## An example of pooling posterior probabilities to generate class predictions
data(mdrr)

## remove some zero variance predictors and linear dependencies
mdrrDescr &lt;- mdrrDescr[, -nearZeroVar(mdrrDescr)]
mdrrDescr &lt;- mdrrDescr[, -findCorrelation(cor(mdrrDescr), .95)]

## basicLDA &lt;- train(mdrrDescr, mdrrClass, "lda")

## bagLDA2 &lt;- train(mdrrDescr, mdrrClass,
##                  "bag",
##                  B = 10,
##                  bagControl = bagControl(fit = ldaBag$fit,
##                                          predict = ldaBag$pred,
##                                          aggregate = ldaBag$aggregate),
##                  tuneGrid = data.frame(vars = c((1:10)*10 , ncol(mdrrDescr))))

</code></pre>

<hr>
<h2 id='bagEarth'>Bagged Earth</h2><span id='topic+bagEarth'></span><span id='topic+print.bagEarth'></span><span id='topic+bagEarth.default'></span><span id='topic+bagEarth.formula'></span>

<h3>Description</h3>

<p>A bagging wrapper for multivariate adaptive regression
splines (MARS) via the <code>earth</code> function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bagEarth(x, ...)

## Default S3 method:
bagEarth(x, y, weights = NULL, B = 50, summary = mean, keepX = TRUE, ...)

## S3 method for class 'formula'
bagEarth(
  formula,
  data = NULL,
  B = 50,
  summary = mean,
  keepX = TRUE,
  ...,
  subset,
  weights = NULL,
  na.action = na.omit
)

## S3 method for class 'bagEarth'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bagEarth_+3A_x">x</code></td>
<td>
<p>matrix or data frame of 'x' values for examples.</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_...">...</code></td>
<td>
<p>arguments passed to the <code>earth</code> function</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_y">y</code></td>
<td>
<p>matrix or data frame of numeric values outcomes.</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_weights">weights</code></td>
<td>
<p>(case) weights for each example - if missing defaults to 1.</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_b">B</code></td>
<td>
<p>the number of bootstrap samples</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_summary">summary</code></td>
<td>
<p>a function with a single argument specifying how the bagged predictions should be summarized</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_keepx">keepX</code></td>
<td>
<p>a logical: should the original training data be kept?</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_formula">formula</code></td>
<td>
<p>A formula of the form <code>y ~ x1 + x2 + ...</code></p>
</td></tr>
<tr><td><code id="bagEarth_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in  'formula' are
preferentially to be taken.</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the
training sample.  (NOTE: If given, this argument must be
named.)</p>
</td></tr>
<tr><td><code id="bagEarth_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if 'NA's are
found. The default action is for the procedure to fail.  An
alternative is na.omit, which leads to rejection of cases
with missing values on any required variable.  (NOTE: If
given, this argument must be named.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes a Earth model for each bootstap sample.
</p>


<h3>Value</h3>

<p>A list with elements
</p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>a list of <code>B</code> Earth fits</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>the number of bootstrap samples</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>either <code>NULL</code> or the value of <code>x</code>, depending on the
value of <code>keepX</code></p>
</td></tr>
<tr><td><code>oob</code></td>
<td>
<p>a matrix of performance estimates for each bootstrap sample</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Max Kuhn (<code>bagEarth.formula</code> is based on Ripley's <code>nnet.formula</code>)
</p>


<h3>References</h3>

<p>J. Friedman, &ldquo;Multivariate Adaptive Regression Splines&rdquo; (with
discussion) (1991).  Annals of Statistics, 19/1, 1-141.
</p>


<h3>See Also</h3>

<p><code><a href="earth.html#topic+earth">earth</a></code>, <code><a href="#topic+predict.bagEarth">predict.bagEarth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(mda)
library(earth)
data(trees)
fit1 &lt;- earth(x = trees[,-3], y = trees[,3])
set.seed(2189)
fit2 &lt;- bagEarth(x = trees[,-3], y = trees[,3], B = 10)

## End(Not run)

</code></pre>

<hr>
<h2 id='bagFDA'>Bagged FDA</h2><span id='topic+bagFDA'></span><span id='topic+print.bagFDA'></span><span id='topic+bagFDA.default'></span><span id='topic+bagFDA.formula'></span>

<h3>Description</h3>

<p>A bagging wrapper for flexible discriminant analysis (FDA) using multivariate adaptive regression splines (MARS) basis functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bagFDA(x, ...)

## Default S3 method:
bagFDA(x, y, weights = NULL, B = 50, keepX = TRUE, ...)

## S3 method for class 'formula'
bagFDA(
  formula,
  data = NULL,
  B = 50,
  keepX = TRUE,
  ...,
  subset,
  weights = NULL,
  na.action = na.omit
)

## S3 method for class 'bagFDA'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bagFDA_+3A_x">x</code></td>
<td>
<p>matrix or data frame of 'x' values for examples.</p>
</td></tr>
<tr><td><code id="bagFDA_+3A_...">...</code></td>
<td>
<p>arguments passed to the <code>mars</code> function</p>
</td></tr>
<tr><td><code id="bagFDA_+3A_y">y</code></td>
<td>
<p>matrix or data frame of numeric values outcomes.</p>
</td></tr>
<tr><td><code id="bagFDA_+3A_weights">weights</code></td>
<td>
<p>(case) weights for each example - if missing defaults to 1.</p>
</td></tr>
<tr><td><code id="bagFDA_+3A_b">B</code></td>
<td>
<p>the number of bootstrap samples</p>
</td></tr>
<tr><td><code id="bagFDA_+3A_keepx">keepX</code></td>
<td>
<p>a logical: should the original training data be kept?</p>
</td></tr>
<tr><td><code id="bagFDA_+3A_formula">formula</code></td>
<td>
<p>A formula of the form <code>y ~ x1 + x2 + ...</code></p>
</td></tr>
<tr><td><code id="bagFDA_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in  'formula' are
preferentially to be taken.</p>
</td></tr>
<tr><td><code id="bagFDA_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the
training sample.  (NOTE: If given, this argument must be
named.)</p>
</td></tr>
<tr><td><code id="bagFDA_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if 'NA's are
found. The default action is for the procedure to fail.  An
alternative is na.omit, which leads to rejection of cases
with missing values on any required variable.  (NOTE: If
given, this argument must be named.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes a FDA model for each bootstap sample.
</p>


<h3>Value</h3>

<p>A list with elements
</p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>a list of <code>B</code> FDA fits</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>the number of bootstrap samples</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>either <code>NULL</code> or the value of <code>x</code>, depending on the
value of <code>keepX</code></p>
</td></tr>
<tr><td><code>oob</code></td>
<td>
<p>a matrix of performance estimates for each bootstrap sample</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Max Kuhn (<code>bagFDA.formula</code> is based on Ripley's <code>nnet.formula</code>)
</p>


<h3>References</h3>

<p>J. Friedman, &ldquo;Multivariate Adaptive Regression Splines&rdquo; (with discussion) (1991).  Annals of Statistics, 19/1, 1-141.
</p>


<h3>See Also</h3>

<p><code><a href="mda.html#topic+fda">fda</a></code>, <code><a href="#topic+predict.bagFDA">predict.bagFDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mlbench)
library(earth)
data(Glass)

set.seed(36)
inTrain &lt;- sample(1:dim(Glass)[1], 150)

trainData &lt;- Glass[ inTrain, ]
testData  &lt;- Glass[-inTrain, ]


set.seed(3577)
baggedFit &lt;- bagFDA(Type ~ ., trainData)
confusionMatrix(data = predict(baggedFit, testData[, -10]),
                reference = testData[, 10])

</code></pre>

<hr>
<h2 id='BloodBrain'>Blood Brain Barrier Data</h2><span id='topic+BloodBrain'></span><span id='topic+bbbDescr'></span><span id='topic+logBBB'></span>

<h3>Description</h3>

<p>Mente and Lombardo (2005) develop models to predict the log
of the ratio of the concentration of a compound in the brain
and the concentration in blood. For each compound, they computed
three sets of molecular descriptors: MOE 2D, rule-of-five and
Charge Polar Surface Area (CPSA). In all, 134 descriptors were
calculated. Included in this package are 208 non-proprietary
literature compounds. The vector <code>logBBB</code> contains the concentration
ratio and the data fame <code>bbbDescr</code> contains the descriptor values.
</p>


<h3>Value</h3>

<table>
<tr><td><code>bbbDescr</code></td>
<td>
<p>data frame of chemical descriptors</p>
</td></tr> <tr><td><code>logBBB</code></td>
<td>
<p>vector of assay results</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Mente, S.R. and Lombardo, F. (2005). A recursive-partitioning model
for blood-brain barrier permeation, <em>Journal of Computer-Aided Molecular Design</em>,
Vol. 19, pg. 465-481.
</p>

<hr>
<h2 id='BoxCoxTrans'>Box-Cox and Exponential Transformations</h2><span id='topic+BoxCoxTrans'></span><span id='topic+BoxCoxTrans.default'></span><span id='topic+predict.BoxCoxTrans'></span><span id='topic+expoTrans.default'></span><span id='topic+expoTrans'></span><span id='topic+predict.expoTrans'></span><span id='topic+print.BoxCoxTrans'></span>

<h3>Description</h3>

<p>These classes can be used to estimate transformations and apply them to existing and future data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BoxCoxTrans(y, ...)

## Default S3 method:
BoxCoxTrans(
  y,
  x = rep(1, length(y)),
  fudge = 0.2,
  numUnique = 3,
  na.rm = FALSE,
  ...
)

## S3 method for class 'BoxCoxTrans'
print(x, newdata, digits = 3, ...)

## S3 method for class 'BoxCoxTrans'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BoxCoxTrans_+3A_y">y</code></td>
<td>
<p>a numeric vector of data to be transformed. For <code>BoxCoxTrans</code>, the data must be strictly positive.</p>
</td></tr>
<tr><td><code id="BoxCoxTrans_+3A_...">...</code></td>
<td>
<p>for <code>BoxCoxTrans</code>: options to pass to <code><a href="MASS.html#topic+boxcox">boxcox</a></code>. <code>plotit</code> should not be passed through. For <code>predict.BoxCoxTrans</code>, additional arguments are ignored.</p>
</td></tr>
<tr><td><code id="BoxCoxTrans_+3A_x">x</code></td>
<td>
<p>an optional dependent variable to be used in a linear model.</p>
</td></tr>
<tr><td><code id="BoxCoxTrans_+3A_fudge">fudge</code></td>
<td>
<p>a tolerance value: lambda values within +/-fudge will be coerced to 0 and within 1+/-fudge will be coerced to 1.</p>
</td></tr>
<tr><td><code id="BoxCoxTrans_+3A_numunique">numUnique</code></td>
<td>
<p>how many unique values should <code>y</code> have to estimate the transformation?</p>
</td></tr>
<tr><td><code id="BoxCoxTrans_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should be stripped from <code>y</code> and <code>x</code> before the computation proceeds.</p>
</td></tr>
<tr><td><code id="BoxCoxTrans_+3A_newdata">newdata</code></td>
<td>
<p>a numeric vector of values to transform.</p>
</td></tr>
<tr><td><code id="BoxCoxTrans_+3A_digits">digits</code></td>
<td>
<p>minimal number of <em>significant digits</em>.</p>
</td></tr>
<tr><td><code id="BoxCoxTrans_+3A_object">object</code></td>
<td>
<p>an object of class <code>BoxCoxTrans</code> or <code>expoTrans</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>BoxCoxTrans</code> function is basically a wrapper for the <code><a href="MASS.html#topic+boxcox">boxcox</a></code> function in the MASS library. It can be used to estimate the transformation and apply it to new data.
</p>
<p><code>expoTrans</code> estimates the exponential transformation of Manly (1976) but assumes a common mean for
the data. The transformation parameter is estimated by directly maximizing the likelihood.
</p>
<p>If <code>any(y &lt;= 0)</code> or  if <code>length(unique(y)) &lt; numUnique</code>, lambda is not estimated and no
transformation is applied.
</p>


<h3>Value</h3>

<p>Both functions returns a list of class of either <code>BoxCoxTrans</code> or <code>expoTrans</code> with
elements
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>estimated transformation value</p>
</td></tr>
<tr><td><code>fudge</code></td>
<td>
<p>value of <code>fudge</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of data points used to estimate lambda</p>
</td></tr>
<tr><td><code>summary</code></td>
<td>
<p>the results of <code>summary(y)</code></p>
</td></tr>
<tr><td><code>ratio</code></td>
<td>
<p><code>max(y)/min(y)</code></p>
</td></tr>
<tr><td><code>skewness</code></td>
<td>
<p>sample skewness statistic</p>
</td></tr>
</table>
<p><code>BoxCoxTrans</code> also returns: </p>
<table>
<tr><td><code>fudge</code></td>
<td>
<p>value of <code>fudge</code></p>
</td></tr>
</table>
<p>The <code>predict</code> functions returns numeric vectors of transformed values
</p>


<h3>Author(s)</h3>

<p>Max Author
</p>


<h3>References</h3>

<p>Box, G. E. P. and Cox, D. R. (1964) An analysis of transformations (with discussion). Journal of the Royal Statistical Society B, 26, 211-252.
Manly, B. L. (1976) Exponential data transformations. The Statistician, 25, 37 - 42.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+boxcox">boxcox</a></code>, <code><a href="#topic+preProcess">preProcess</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BloodBrain)

ratio &lt;- exp(logBBB)
bc &lt;- BoxCoxTrans(ratio)
bc

predict(bc, ratio[1:5])

ratio[5] &lt;- NA
bc2 &lt;- BoxCoxTrans(ratio, bbbDescr$tpsa, na.rm = TRUE)
bc2

manly &lt;- expoTrans(ratio)
manly

</code></pre>

<hr>
<h2 id='calibration'>Probability Calibration Plot</h2><span id='topic+calibration'></span><span id='topic+calibration.formula'></span><span id='topic+calibration.default'></span><span id='topic+xyplot.calibration'></span><span id='topic+ggplot.calibration'></span><span id='topic+panel.calibration'></span><span id='topic+print.calibration'></span>

<h3>Description</h3>

<p>For classification models, this function creates a 'calibration plot' that describes
how consistent model probabilities are with observed event rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibration(x, ...)

## Default S3 method:
calibration(x, ...)

## S3 method for class 'formula'
calibration(
  x,
  data = NULL,
  class = NULL,
  cuts = 11,
  subset = TRUE,
  lattice.options = NULL,
  ...
)

## S3 method for class 'calibration'
print(x, ...)

## S3 method for class 'calibration'
xyplot(x, data = NULL, ...)

## S3 method for class 'calibration'
ggplot(data, ..., bwidth = 2, dwidth = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibration_+3A_x">x</code></td>
<td>
<p>a <code>lattice</code> formula (see <code><a href="lattice.html#topic+xyplot">xyplot</a></code> for syntax) where the left
-hand side of the formula is a factor class variable of the observed outcome and the right-hand side
specifies one or model columns corresponding to a numeric ranking variable for a model (e.g. class
probabilities). The classification variable should have two levels.</p>
</td></tr>
<tr><td><code id="calibration_+3A_...">...</code></td>
<td>
<p>options to pass through to <code><a href="lattice.html#topic+xyplot">xyplot</a></code> or the panel function (not
used in <code>calibration.formula</code>).</p>
</td></tr>
<tr><td><code id="calibration_+3A_data">data</code></td>
<td>
<p>For <code>calibration.formula</code>, a data frame (or more precisely, anything that is a valid
<code>envir</code> argument in <code>eval</code>, e.g., a list or an environment) containing values for any
variables in the formula, as well as <code>groups</code> and <code>subset</code> if applicable. If not found in
<code>data</code>, or if <code>data</code> is unspecified, the variables are looked for in the environment of the
formula. This argument is not used for <code>xyplot.calibration</code>. For ggplot.calibration, <code>data</code>
should be an object of class &quot;<code>calibration</code>&quot;.&quot;</p>
</td></tr>
<tr><td><code id="calibration_+3A_class">class</code></td>
<td>
<p>a character string for the class of interest</p>
</td></tr>
<tr><td><code id="calibration_+3A_cuts">cuts</code></td>
<td>
<p>If a single number this indicates the number of splits of the data are used to create the
plot. By default, it uses as many cuts as there are rows in <code>data</code>. If a vector, these are the
actual cuts that will be used.</p>
</td></tr>
<tr><td><code id="calibration_+3A_subset">subset</code></td>
<td>
<p>An expression that evaluates to a logical or integer indexing vector. It is evaluated in
<code>data</code>. Only the resulting rows of <code>data</code> are used for the plot.</p>
</td></tr>
<tr><td><code id="calibration_+3A_lattice.options">lattice.options</code></td>
<td>
<p>A list that could be supplied to <code><a href="lattice.html#topic+lattice.options">lattice.options</a></code></p>
</td></tr>
<tr><td><code id="calibration_+3A_bwidth">bwidth</code>, <code id="calibration_+3A_dwidth">dwidth</code></td>
<td>
<p>a numeric value for the confidence interval bar width and dodge width, respectively.
In the latter case, a dodge is only used when multiple models are specified in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>calibration.formula</code> is used to process the data and <code>xyplot.calibration</code> is used to create the plot.
</p>
<p>To construct the calibration plot, the following steps are used for each model:
</p>

<ol>
<li><p> The data are split into <code>cuts - 1</code> roughly equal groups by their class probabilities
</p>
</li>
<li><p> the number of samples with true results equal to <code>class</code> are determined
</p>
</li>
<li><p> the event rate is determined for each bin</p>
</li></ol>

<p><code>xyplot.calibration</code> produces a plot of the observed event rate by the mid-point of the bins.
</p>
<p>This implementation uses the <span class="pkg">lattice</span> function <code><a href="lattice.html#topic+xyplot">xyplot</a></code>, so plot
elements can be changed via panel functions, <code><a href="lattice.html#topic+trellis.par.get">trellis.par.set</a></code> or
other means. <code>calibration</code> uses the panel function <code><a href="#topic+panel.calibration">panel.calibration</a></code> by default, but
it can be changed by passing that argument into <code>xyplot.calibration</code>.
</p>
<p>The following elements are set by default in the plot but can be changed by passing new values into
<code>xyplot.calibration</code>: <code>xlab = "Bin Midpoint"</code>, <code>ylab = "Observed Event Percentage"</code>,
<code>type = "o"</code>, <code>ylim = extendrange(c(0, 100))</code>,<code>xlim = extendrange(c(0, 100))</code> and
<code>panel = panel.calibration</code>
</p>
<p>For the <code>ggplot</code> method, confidence intervals on the estimated proportions (from
<code><a href="stats.html#topic+binom.test">binom.test</a></code>) are also shown.
</p>


<h3>Value</h3>

<p><code>calibration.formula</code> returns a list with elements:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>the data used for plotting</p>
</td></tr>
<tr><td><code>cuts</code></td>
<td>
<p>the number of cuts</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>the event class</p>
</td></tr>
<tr><td><code>probNames</code></td>
<td>
<p>the names of the model probabilities</p>
</td></tr>
</table>
<p><code>xyplot.calibration</code> returns a <span class="pkg">lattice</span> object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, some <span class="pkg">lattice</span> code and documentation by Deepayan Sarkar
</p>


<h3>See Also</h3>

<p><code><a href="lattice.html#topic+xyplot">xyplot</a></code>, <code><a href="lattice.html#topic+trellis.par.get">trellis.par.set</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(mdrr)
mdrrDescr &lt;- mdrrDescr[, -nearZeroVar(mdrrDescr)]
mdrrDescr &lt;- mdrrDescr[, -findCorrelation(cor(mdrrDescr), .5)]


inTrain &lt;- createDataPartition(mdrrClass)
trainX &lt;- mdrrDescr[inTrain[[1]], ]
trainY &lt;- mdrrClass[inTrain[[1]]]
testX &lt;- mdrrDescr[-inTrain[[1]], ]
testY &lt;- mdrrClass[-inTrain[[1]]]

library(MASS)

ldaFit &lt;- lda(trainX, trainY)
qdaFit &lt;- qda(trainX, trainY)

testProbs &lt;- data.frame(obs = testY,
                        lda = predict(ldaFit, testX)$posterior[,1],
                        qda = predict(qdaFit, testX)$posterior[,1])

calibration(obs ~ lda + qda, data = testProbs)

calPlotData &lt;- calibration(obs ~ lda + qda, data = testProbs)
calPlotData

xyplot(calPlotData, auto.key = list(columns = 2))

## End(Not run)

</code></pre>

<hr>
<h2 id='caret-internal'>Internal Functions</h2><span id='topic+caret-internal'></span><span id='topic+createModel'></span><span id='topic+resampleWrapper'></span><span id='topic+sortImp'></span><span id='topic+caretTheme'></span><span id='topic+progress'></span><span id='topic+hasTerms'></span><span id='topic+predictionFunction'></span><span id='topic+probFunction'></span><span id='topic+expandParameters'></span><span id='topic+flatTable'></span><span id='topic+MeanSD'></span><span id='topic+sbfIter'></span><span id='topic+gamFormula'></span><span id='topic+bagEarthStats'></span><span id='topic+cforestStats'></span><span id='topic+ipredStats'></span><span id='topic+rfStats'></span><span id='topic+well_numbered'></span><span id='topic+outcome_conversion'></span>

<h3>Description</h3>

<p>Internal functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createModel(
  x,
  y,
  wts,
  method,
  tuneValue,
  obsLevels,
  pp = NULL,
  last = FALSE,
  sampling = NULL,
  classProbs,
  ...
)

well_numbered(prefix, items)

gamFormula(data, smoother = "s", cut = 8, y = "y")

flatTable(pred, obs)

ipredStats(x)

rfStats(x)

cforestStats(x)

bagEarthStats(x)

outcome_conversion(x, lv)

predictionFunction(method, modelFit, newdata, preProc = NULL, param = NULL)

hasTerms(x)

probFunction(method, modelFit, newdata = NULL, preProc = NULL, param = NULL)

resampleWrapper(x, ind)

sbfIter(x, y, testX, testY, testPerf = NULL, sbfControl = sbfControl(), ...)

sortImp(object, top)

progress(x, names, iter, start = TRUE)

MeanSD(x, exclude = NULL)

expandParameters(fixed, seq)
</code></pre>


<h3>Author(s)</h3>

<p>Max Kuhn, but <code>caretTheme</code> uses an expanded grid of the &quot;Blues&quot; palette designed by Cynthia Brewer and Mark Harrower
</p>

<hr>
<h2 id='caretSBF'>Selection By Filtering (SBF) Helper Functions</h2><span id='topic+caretSBF'></span><span id='topic+lmSBF'></span><span id='topic+rfSBF'></span><span id='topic+treebagSBF'></span><span id='topic+ldaSBF'></span><span id='topic+nbSBF'></span><span id='topic+gamScores'></span><span id='topic+anovaScores'></span>

<h3>Description</h3>

<p>Ancillary functions for univariate feature selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>caretSBF

anovaScores(x, y)

gamScores(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="caretSBF_+3A_x">x</code></td>
<td>
<p>a matrix or data frame of numeric predictors</p>
</td></tr>
<tr><td><code id="caretSBF_+3A_y">y</code></td>
<td>
<p>a numeric or factor vector of outcomes</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 5.
</p>


<h3>Details</h3>

<p>More details on these functions can be found at
<a href="http://topepo.github.io/caret/feature-selection-using-univariate-filters.html">http://topepo.github.io/caret/feature-selection-using-univariate-filters.html</a>.
</p>
<p>This page documents the functions that are used in selection by filtering
(SBF). The functions described here are passed to the algorithm via the
<code>functions</code> argument of <code><a href="#topic+sbfControl">sbfControl</a></code>.
</p>
<p>See <code><a href="#topic+sbfControl">sbfControl</a></code> for details on how these functions should be
defined.
</p>
<p><code>anovaScores</code> and <code>gamScores</code> are two examples of univariate
filtering functions. <code>anovaScores</code> fits a simple linear model between a
single feature and the outcome, then the p-value for the whole model F-test
is returned. <code>gamScores</code> fits a generalized additive model between a
single predictor and the outcome using a smoothing spline basis function. A
p-value is generated using the whole model test from
<code><a href="gam.html#topic+summary.Gam">summary.Gam</a></code> and is returned.
</p>
<p>If a particular model fails for <code>lm</code> or <code>gam</code>, a p-value of 1 is
returned.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sbfControl">sbfControl</a></code>, <code><a href="#topic+sbf">sbf</a></code>,
<code><a href="gam.html#topic+summary.Gam">summary.Gam</a></code>
</p>

<hr>
<h2 id='cars'>Kelly Blue Book resale data for 2005 model year GM cars</h2><span id='topic+cars'></span>

<h3>Description</h3>

<p>Kuiper (2008) collected data on Kelly Blue Book resale data for 804 GM cars (2005 model year).
</p>


<h3>Value</h3>

<table>
<tr><td><code>cars</code></td>
<td>
<p>data frame of the suggested retail price (column <code>Price</code>) and various
characteristics of each car (columns <code>Mileage</code>, <code>Cylinder</code>, <code>Doors</code>, <code>Cruise</code>,
<code>Sound</code>, <code>Leather</code>, <code>Buick</code>, <code>Cadillac</code>, <code>Chevy</code>, <code>Pontiac</code>, <code>Saab</code>,
<code>Saturn</code>, <code>convertible</code>, <code>coupe</code>, <code>hatchback</code>, <code>sedan</code> and <code>wagon</code>)</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Kuiper, S. (2008). Introduction to Multiple Regression: How Much Is Your Car Worth?,
<em>Journal of Statistics Education</em>, Vol. 16
<a href="http://jse.amstat.org/jse_archive.htm#2008">http://jse.amstat.org/jse_archive.htm#2008</a>.
</p>

<hr>
<h2 id='classDist'>Compute and predict the distances to class centroids</h2><span id='topic+classDist'></span><span id='topic+classDist.default'></span><span id='topic+predict.classDist'></span>

<h3>Description</h3>

<p>This function computes the class centroids and covariance matrix for a training set for determining Mahalanobis distances of samples to each class centroid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classDist(x, ...)

## Default S3 method:
classDist(x, y, groups = 5, pca = FALSE, keep = NULL, ...)

## S3 method for class 'classDist'
predict(object, newdata, trans = log, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classDist_+3A_x">x</code></td>
<td>
<p>a matrix or data frame of predictor variables</p>
</td></tr>
<tr><td><code id="classDist_+3A_...">...</code></td>
<td>
<p>optional arguments to pass (not currently used)</p>
</td></tr>
<tr><td><code id="classDist_+3A_y">y</code></td>
<td>
<p>a numeric or factor vector of class labels</p>
</td></tr>
<tr><td><code id="classDist_+3A_groups">groups</code></td>
<td>
<p>an integer for the number of bins for splitting a numeric outcome</p>
</td></tr>
<tr><td><code id="classDist_+3A_pca">pca</code></td>
<td>
<p>a logical: should principal components analysis be  applied to the dataset prior to splitting the data by class?</p>
</td></tr>
<tr><td><code id="classDist_+3A_keep">keep</code></td>
<td>
<p>an integer for the number of PCA components that should by used to predict new samples (<code>NULL</code> uses all within a tolerance of <code>sqrt(.Machine$double.eps)</code>)</p>
</td></tr>
<tr><td><code id="classDist_+3A_object">object</code></td>
<td>
<p>an object of class <code>classDist</code></p>
</td></tr>
<tr><td><code id="classDist_+3A_newdata">newdata</code></td>
<td>
<p>a matrix or data frame. If <code>vars</code> was previously specified, these columns should be in <code>newdata</code></p>
</td></tr>
<tr><td><code id="classDist_+3A_trans">trans</code></td>
<td>
<p>an optional function that can be applied to each class distance. <code>trans = NULL</code> will not apply a function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For factor outcomes, the data are split into groups for each class
and the mean and covariance matrix are calculated. These are then
used to compute Mahalanobis distances to the class centers (using
<code>predict.classDist</code> The function will check for non-singular matrices.
</p>
<p>For numeric outcomes, the data are split into roughly equal sized
bins based on <code>groups</code>. Percentiles are used to split the data.
</p>


<h3>Value</h3>

<p>for <code>classDist</code>, an object of class <code>classDist</code> with
elements:
</p>
<table>
<tr><td><code>values</code></td>
<td>
<p>a list with elements for each class. Each element
contains a mean vector for the class centroid and the
inverse of the class covariance matrix</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>a character vector of class labels</p>
</td></tr>
<tr><td><code>pca</code></td>
<td>
<p>the results of <code><a href="stats.html#topic+prcomp">prcomp</a></code> when
<code>pca = TRUE</code></p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the number of variables</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>a vector of samples sizes per class</p>
</td></tr>
</table>
<p>For <code>predict.classDist</code>, a matrix with columns for each class.
The columns names are the names of the class with the prefix
<code>dist.</code>. In the case of numeric <code>y</code>, the class labels are
the percentiles. For example, of <code>groups = 9</code>, the variable names
would be <code>dist.11.11</code>, <code>dist.22.22</code>, etc.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Forina et al. CAIMAN brothers: A family of powerful classification and class modeling techniques. Chemometrics and Intelligent Laboratory Systems (2009) vol. 96 (2) pp. 239-245
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>trainSet &lt;- sample(1:150, 100)

distData &lt;- classDist(iris[trainSet, 1:4],
                      iris$Species[trainSet])

newDist &lt;- predict(distData,
                   iris[-trainSet, 1:4])

splom(newDist, groups = iris$Species[-trainSet])

</code></pre>

<hr>
<h2 id='confusionMatrix'>Create a confusion matrix</h2><span id='topic+confusionMatrix'></span><span id='topic+confusionMatrix.table'></span><span id='topic+confusionMatrix.default'></span><span id='topic+confusionMatrix.matrix'></span>

<h3>Description</h3>

<p>Calculates a cross-tabulation of observed and predicted classes with
associated statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusionMatrix(data, ...)

## Default S3 method:
confusionMatrix(
  data,
  reference,
  positive = NULL,
  dnn = c("Prediction", "Reference"),
  prevalence = NULL,
  mode = "sens_spec",
  ...
)

## S3 method for class 'matrix'
confusionMatrix(
  data,
  positive = NULL,
  prevalence = NULL,
  mode = "sens_spec",
  ...
)

## S3 method for class 'table'
confusionMatrix(
  data,
  positive = NULL,
  prevalence = NULL,
  mode = "sens_spec",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusionMatrix_+3A_data">data</code></td>
<td>
<p>a factor of predicted classes (for the default method) or an
object of class <code><a href="base.html#topic+table">table</a></code>.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_...">...</code></td>
<td>
<p>options to be passed to <code>table</code>. NOTE: do not include
<code>dnn</code> here</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_reference">reference</code></td>
<td>
<p>a factor of classes to be used as the true results</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_positive">positive</code></td>
<td>
<p>an optional character string for the factor level that
corresponds to a &quot;positive&quot; result (if that makes sense for your data). If
there are only two factor levels, the first level will be used as the
&quot;positive&quot; result. When <code>mode = "prec_recall"</code>, <code>positive</code> is the
same value used for <code>relevant</code> for functions <code><a href="#topic+precision">precision</a></code>,
<code><a href="#topic+recall">recall</a></code>, and <code><a href="#topic+F_meas.table">F_meas.table</a></code>.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_dnn">dnn</code></td>
<td>
<p>a character vector of dimnames for the table</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_prevalence">prevalence</code></td>
<td>
<p>a numeric value or matrix for the rate of the &quot;positive&quot;
class of the data. When <code>data</code> has two levels, <code>prevalence</code> should
be a single numeric value. Otherwise, it should be a vector of numeric
values with elements for each class. The vector should have names
corresponding to the classes.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_mode">mode</code></td>
<td>
<p>a single character string either &quot;sens_spec&quot;, &quot;prec_recall&quot;, or
&quot;everything&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions requires that the factors have exactly the same levels.
</p>
<p>For two class problems, the sensitivity, specificity, positive predictive
value and negative predictive value is calculated using the <code>positive</code>
argument. Also, the prevalence of the &quot;event&quot; is computed from the data
(unless passed in as an argument), the detection rate (the rate of true
events also predicted to be events) and the detection prevalence (the
prevalence of predicted events).
</p>
<p>Suppose a 2x2 table with notation
</p>

<table>
<tr>
 <td style="text-align: right;"> </td><td style="text-align: center;"> Reference </td><td style="text-align: center;"> </td>
</tr>
<tr>
 <td style="text-align: right;"> Predicted </td><td style="text-align: center;"> Event </td><td style="text-align: center;"> No Event
</td>
</tr>
<tr>
 <td style="text-align: right;"> Event </td><td style="text-align: center;"> A </td><td style="text-align: center;"> B </td>
</tr>
<tr>
 <td style="text-align: right;"> No Event </td><td style="text-align: center;"> C </td><td style="text-align: center;"> D </td>
</tr>
<tr>
 <td style="text-align: right;"> </td>
</tr>

</table>

<p>The formulas used here are: </p>
<p style="text-align: center;"><code class="reqn">Sensitivity = A/(A+C)</code>
</p>
 <p style="text-align: center;"><code class="reqn">Specificity =
D/(B+D)</code>
</p>
 <p style="text-align: center;"><code class="reqn">Prevalence = (A+C)/(A+B+C+D)</code>
</p>
 <p style="text-align: center;"><code class="reqn">PPV = (sensitivity *
prevalence)/((sensitivity*prevalence) + ((1-specificity)*(1-prevalence)))</code>
</p>

<p style="text-align: center;"><code class="reqn">NPV = (specificity * (1-prevalence))/(((1-sensitivity)*prevalence) +
((specificity)*(1-prevalence)))</code>
</p>
 <p style="text-align: center;"><code class="reqn">Detection Rate = A/(A+B+C+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">Detection Prevalence = (A+B)/(A+B+C+D)</code>
</p>
 <p style="text-align: center;"><code class="reqn">Balanced Accuracy =
(sensitivity+specificity)/2</code>
</p>

<p style="text-align: center;"><code class="reqn">Precision = A/(A+B)</code>
</p>
 <p style="text-align: center;"><code class="reqn">Recall = A/(A+C)</code>
</p>
 <p style="text-align: center;"><code class="reqn">F1 =
(1+beta^2)*precision*recall/((beta^2 * precision)+recall)</code>
</p>

<p>where <code>beta = 1</code> for this function.
</p>
<p>See the references for discussions of the first five formulas.
</p>
<p>For more than two classes, these results are calculated comparing each
factor level to the remaining levels (i.e. a &quot;one versus all&quot; approach).
</p>
<p>The overall accuracy and unweighted Kappa statistic are calculated. A
p-value from McNemar's test is also computed using
<code><a href="stats.html#topic+mcnemar.test">mcnemar.test</a></code> (which can produce <code>NA</code> values with
sparse tables).
</p>
<p>The overall accuracy rate is computed along with a 95 percent confidence
interval for this rate (using <code><a href="stats.html#topic+binom.test">binom.test</a></code>) and a
one-sided test to see if the accuracy is better than the &quot;no information
rate,&quot; which is taken to be the largest class percentage in the data.
</p>


<h3>Value</h3>

<p>a list with elements </p>
<table>
<tr><td><code>table</code></td>
<td>
<p>the results of <code>table</code> on
<code>data</code> and <code>reference</code></p>
</td></tr> <tr><td><code>positive</code></td>
<td>
<p>the positive result level</p>
</td></tr>
<tr><td><code>overall</code></td>
<td>
<p>a numeric vector with overall accuracy and Kappa statistic
values</p>
</td></tr> <tr><td><code>byClass</code></td>
<td>
<p>the sensitivity, specificity, positive predictive
value, negative predictive value, precision, recall, F1, prevalence,
detection rate, detection prevalence and balanced accuracy for each class.
For two class systems, this is calculated once using the <code>positive</code>
argument</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the reference and data factors have the same levels, but in the
incorrect order, the function will reorder them to the order of the data and
issue a warning.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Kuhn, M. (2008), &ldquo;Building predictive models in R using the
caret package, &rdquo; <em>Journal of Statistical Software</em>,
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>).
</p>
<p>Altman, D.G., Bland, J.M. (1994) &ldquo;Diagnostic tests 1: sensitivity and
specificity,&rdquo; <em>British Medical Journal</em>, vol 308, 1552.
</p>
<p>Altman, D.G., Bland, J.M. (1994) &ldquo;Diagnostic tests 2: predictive values,&rdquo;
<em>British Medical Journal</em>, vol 309, 102.
</p>
<p>Velez, D.R., et. al. (2008) &ldquo;A balanced accuracy function for epistasis
modeling in imbalanced datasets using multifactor dimensionality
reduction.,&rdquo; <em>Genetic Epidemiology</em>, vol 4, 306.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.table.confusionMatrix">as.table.confusionMatrix</a></code>,
<code><a href="#topic+as.matrix.confusionMatrix">as.matrix.confusionMatrix</a></code>, <code><a href="#topic+sensitivity">sensitivity</a></code>,
<code><a href="#topic+specificity">specificity</a></code>, <code><a href="#topic+posPredValue">posPredValue</a></code>,
<code><a href="#topic+negPredValue">negPredValue</a></code>, <code><a href="#topic+print.confusionMatrix">print.confusionMatrix</a></code>,
<code><a href="stats.html#topic+binom.test">binom.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
###################
## 2 class example

lvs &lt;- c("normal", "abnormal")
truth &lt;- factor(rep(lvs, times = c(86, 258)),
                levels = rev(lvs))
pred &lt;- factor(
               c(
                 rep(lvs, times = c(54, 32)),
                 rep(lvs, times = c(27, 231))),
               levels = rev(lvs))

xtab &lt;- table(pred, truth)

confusionMatrix(xtab)
confusionMatrix(pred, truth)
confusionMatrix(xtab, prevalence = 0.25)

###################
## 3 class example

confusionMatrix(iris$Species, sample(iris$Species))

newPrior &lt;- c(.05, .8, .15)
names(newPrior) &lt;- levels(iris$Species)

confusionMatrix(iris$Species, sample(iris$Species))


</code></pre>

<hr>
<h2 id='confusionMatrix.train'>Estimate a Resampled Confusion Matrix</h2><span id='topic+confusionMatrix.train'></span><span id='topic+confusionMatrix.rfe'></span><span id='topic+confusionMatrix.sbf'></span>

<h3>Description</h3>

<p>Using a <code><a href="#topic+train">train</a></code>, <code><a href="#topic+rfe">rfe</a></code>, <code><a href="#topic+sbf">sbf</a></code> object,
determine a confusion matrix based on the resampling procedure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'train'
confusionMatrix(
  data,
  norm = "overall",
  dnn = c("Prediction", "Reference"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusionMatrix.train_+3A_data">data</code></td>
<td>
<p>An object of class <code><a href="#topic+train">train</a></code>, <code><a href="#topic+rfe">rfe</a></code>,
<code><a href="#topic+sbf">sbf</a></code> that did not use out-of-bag resampling or leave-one-out
cross-validation.</p>
</td></tr>
<tr><td><code id="confusionMatrix.train_+3A_norm">norm</code></td>
<td>
<p>A character string indicating how the table entries should be
normalized. Valid values are &quot;none&quot;, &quot;overall&quot; or &quot;average&quot;.</p>
</td></tr>
<tr><td><code id="confusionMatrix.train_+3A_dnn">dnn</code></td>
<td>
<p>A character vector of dimnames for the table</p>
</td></tr>
<tr><td><code id="confusionMatrix.train_+3A_...">...</code></td>
<td>
<p>not used here</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code><a href="#topic+train">train</a></code> is used for tuning a model, it tracks the confusion
matrix cell entries for the hold-out samples. These can be aggregated and
used for diagnostic purposes. For <code><a href="#topic+train">train</a></code>, the matrix is
estimated for the final model tuning parameters determined by
<code><a href="#topic+train">train</a></code>. For <code><a href="#topic+rfe">rfe</a></code>, the matrix is associated with
the optimal number of variables.
</p>
<p>There are several ways to show the table entries. Using <code>norm = "none"</code>
will show the aggregated counts of samples on each of the cells (across all
resamples). For <code>norm = "average"</code>, the average number of cell counts
across resamples is computed (this can help evaluate how many holdout
samples there were on average). The default is <code>norm = "overall"</code>,
which is equivalento to <code>"average"</code> but in percentages.
</p>


<h3>Value</h3>

<p>a list of class <code>confusionMatrix.train</code>,
<code>confusionMatrix.rfe</code> or <code>confusionMatrix.sbf</code> with elements
</p>
<table>
<tr><td><code>table</code></td>
<td>
<p>the normalized matrix</p>
</td></tr> <tr><td><code>norm</code></td>
<td>
<p>an echo fo the call</p>
</td></tr>
<tr><td><code>text</code></td>
<td>
<p>a character string with details about the resampling procedure
(e.g. &quot;Bootstrapped (25 reps) Confusion Matrix&quot;</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusionMatrix">confusionMatrix</a></code>, <code><a href="#topic+train">train</a></code>,
<code><a href="#topic+rfe">rfe</a></code>, <code><a href="#topic+sbf">sbf</a></code>, <code><a href="#topic+trainControl">trainControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(iris)
TrainData &lt;- iris[,1:4]
TrainClasses &lt;- iris[,5]

knnFit &lt;- train(TrainData, TrainClasses,
                method = "knn",
                preProcess = c("center", "scale"),
                tuneLength = 10,
                trControl = trainControl(method = "cv"))
confusionMatrix(knnFit)
confusionMatrix(knnFit, "average")
confusionMatrix(knnFit, "none")


</code></pre>

<hr>
<h2 id='cox2'>COX-2 Activity Data</h2><span id='topic+cox2'></span><span id='topic+cox2Class'></span><span id='topic+cox2Descr'></span><span id='topic+cox2IC50'></span>

<h3>Description</h3>

<p>From Sutherland, O'Brien, and Weaver (2003): &quot;A set of 467 cyclooxygenase-2
(COX-2) inhibitors has been assembled from the published work of a single
research group, with in vitro activities against human recombinant enzyme
expressed as IC50 values ranging from 1 nM to &gt;100 uM (53 compounds have
indeterminate IC50 values).&quot;
</p>


<h3>Details</h3>

<p>The data are in the Supplemental Data file for the article.
</p>
<p>A set of 255 descriptors (MOE2D and QikProp) were generated. To classify the
data, we used a cutoff of $2^2.5$ to determine activity
</p>


<h3>Value</h3>

<table>
<tr><td><code>cox2Descr</code></td>
<td>
<p>the descriptors</p>
</td></tr> <tr><td><code>cox2IC50</code></td>
<td>
<p>the IC50 data used
to determine activity</p>
</td></tr>
<tr><td><code>cox2Class</code></td>
<td>
<p>the categorical outcome (&quot;Active&quot; or &quot;Inactive&quot;) based on
the $2^2.5$ cutoff</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Sutherland, J. J., O'Brien, L. A. and Weaver, D. F. (2003).
Spline-Fitting with a Genetic Algorithm: A Method for Developing
Classification Structure-Activity Relationships, <em>Journal of Chemical
Information and Computer Sciences</em>, Vol. 43, pg. 1906-1915.
</p>

<hr>
<h2 id='createDataPartition'>Data Splitting functions</h2><span id='topic+createDataPartition'></span><span id='topic+createResample'></span><span id='topic+createFolds'></span><span id='topic+createMultiFolds'></span><span id='topic+createTimeSlices'></span><span id='topic+groupKFold'></span>

<h3>Description</h3>

<p>A series of test/training partitions are created using
<code>createDataPartition</code> while <code>createResample</code> creates one or more
bootstrap samples. <code>createFolds</code> splits the data into <code>k</code> groups
while <code>createTimeSlices</code> creates cross-validation split for series data.
<code>groupKFold</code> splits the data based on a grouping factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createDataPartition(
  y,
  times = 1,
  p = 0.5,
  list = TRUE,
  groups = min(5, length(y))
)

createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)

createMultiFolds(y, k = 10, times = 5)

createTimeSlices(y, initialWindow, horizon = 1, fixedWindow = TRUE, skip = 0)

groupKFold(group, k = length(unique(group)))

createResample(y, times = 10, list = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createDataPartition_+3A_y">y</code></td>
<td>
<p>a vector of outcomes. For <code>createTimeSlices</code>, these should be
in chronological order.</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_times">times</code></td>
<td>
<p>the number of partitions to create</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_p">p</code></td>
<td>
<p>the percentage of data that goes to training</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_list">list</code></td>
<td>
<p>logical - should the results be in a list (<code>TRUE</code>) or a
matrix with the number of rows equal to <code>floor(p * length(y))</code> and
<code>times</code> columns.</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_groups">groups</code></td>
<td>
<p>for numeric <code>y</code>, the number of breaks in the quantiles
(see below)</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_k">k</code></td>
<td>
<p>an integer for the number of folds.</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_returntrain">returnTrain</code></td>
<td>
<p>a logical. When true, the values returned are the sample
positions corresponding to the data used during training. This argument
only works in conjunction with <code>list = TRUE</code></p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_initialwindow">initialWindow</code></td>
<td>
<p>The initial number of consecutive values in each
training set sample</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_horizon">horizon</code></td>
<td>
<p>the number of consecutive values in test set sample</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_fixedwindow">fixedWindow</code></td>
<td>
<p>logical, if <code>FALSE</code>, all training samples start at 1</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_skip">skip</code></td>
<td>
<p>integer, how many (if any) resamples to skip to thin the total
amount</p>
</td></tr>
<tr><td><code id="createDataPartition_+3A_group">group</code></td>
<td>
<p>a vector of groups whose length matches the number of rows in
the overall data set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For bootstrap samples, simple random sampling is used.
</p>
<p>For other data splitting, the random sampling is done within the levels of
<code>y</code> when <code>y</code> is a factor in an attempt to balance the class
distributions within the splits.
</p>
<p>For numeric <code>y</code>, the sample is split into groups sections based on
percentiles and sampling is done within these subgroups. For
<code>createDataPartition</code>, the number of percentiles is set via the
<code>groups</code> argument. For <code>createFolds</code> and <code>createMultiFolds</code>,
the number of groups is set dynamically based on the sample size and
<code>k</code>.  For smaller samples sizes, these two functions may not do
stratified splitting and, at most, will split the data into quartiles.
</p>
<p>Also, for <code>createDataPartition</code>, very small class sizes (&lt;= 3) the
classes may not show up in both the training and test data
</p>
<p>For multiple k-fold cross-validation, completely independent folds are
created.  The names of the list objects will denote the fold membership
using the pattern &quot;Foldi.Repj&quot; meaning the ith section (of k) of the jth
cross-validation set (of <code>times</code>). Note that this function calls
<code>createFolds</code> with <code>list = TRUE</code> and <code>returnTrain = TRUE</code>.
</p>
<p>Hyndman and Athanasopoulos (2013)) discuss rolling forecasting origin
techniques that move the training and test sets in time.
<code>createTimeSlices</code> can create the indices for this type of splitting.
</p>
<p>For Group k-fold cross-validation, the data are split such that no group
is contained in both the modeling and holdout sets. One or more group
could be left out, depending on the value of <code>k</code>.
</p>


<h3>Value</h3>

<p>A list or matrix of row position integers corresponding to the
training data. For <code>createTimeSlices</code> subsamples are named by the end
index of each training subsample.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, <code>createTimeSlices</code> by Tony Cooper
</p>


<h3>References</h3>

<p><a href="http://topepo.github.io/caret/data-splitting.html">http://topepo.github.io/caret/data-splitting.html</a>
</p>
<p>Hyndman and Athanasopoulos (2013), Forecasting: principles and practice.
<a href="https://otexts.com/fpp2/">https://otexts.com/fpp2/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(oil)
createDataPartition(oilType, 2)

x &lt;- rgamma(50, 3, .5)
inA &lt;- createDataPartition(x, list = FALSE)

plot(density(x[inA]))
rug(x[inA])

points(density(x[-inA]), type = "l", col = 4)
rug(x[-inA], col = 4)

createResample(oilType, 2)

createFolds(oilType, 10)
createFolds(oilType, 5, FALSE)

createFolds(rnorm(21))

createTimeSlices(1:9, 5, 1, fixedWindow = FALSE)
createTimeSlices(1:9, 5, 1, fixedWindow = TRUE)
createTimeSlices(1:9, 5, 3, fixedWindow = TRUE)
createTimeSlices(1:9, 5, 3, fixedWindow = FALSE)

createTimeSlices(1:15, 5, 3)
createTimeSlices(1:15, 5, 3, skip = 2)
createTimeSlices(1:15, 5, 3, skip = 3)

set.seed(131)
groups &lt;- sort(sample(letters[1:4], size = 20, replace = TRUE))
table(groups)
folds &lt;- groupKFold(groups)
lapply(folds, function(x, y) table(y[x]), y = groups)
</code></pre>

<hr>
<h2 id='defaultSummary'>Calculates performance across resamples</h2><span id='topic+defaultSummary'></span><span id='topic+postResample'></span><span id='topic+twoClassSummary'></span><span id='topic+prSummary'></span><span id='topic+getTrainPerf'></span><span id='topic+mnLogLoss'></span><span id='topic+R2'></span><span id='topic+RMSE'></span><span id='topic+multiClassSummary'></span><span id='topic+MAE'></span>

<h3>Description</h3>

<p>Given two numeric vectors of data, the mean squared error and
R-squared are calculated. For two factors, the overall agreement
rate and Kappa are determined.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defaultSummary(data, lev = NULL, model = NULL)

postResample(pred, obs)

twoClassSummary(data, lev = NULL, model = NULL)

mnLogLoss(data, lev = NULL, model = NULL)

multiClassSummary(data, lev = NULL, model = NULL)

prSummary(data, lev = NULL, model = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="defaultSummary_+3A_data">data</code></td>
<td>
<p>a data frame with columns <code>obs</code> and
<code>pred</code> for the observed and predicted outcomes. For metrics
that rely on class probabilities, such as
<code>twoClassSummary</code>, columns should also include predicted
probabilities for each class. See the <code>classProbs</code> argument
to <code><a href="#topic+trainControl">trainControl</a></code>.</p>
</td></tr>
<tr><td><code id="defaultSummary_+3A_lev">lev</code></td>
<td>
<p>a character vector of factors levels for the
response. In regression cases, this would be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="defaultSummary_+3A_model">model</code></td>
<td>
<p>a character string for the model name (as taken
from the <code>method</code> argument of <code><a href="#topic+train">train</a></code>.</p>
</td></tr>
<tr><td><code id="defaultSummary_+3A_pred">pred</code></td>
<td>
<p>A vector of numeric data (could be a factor)</p>
</td></tr>
<tr><td><code id="defaultSummary_+3A_obs">obs</code></td>
<td>
<p>A vector of numeric data (could be a factor)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>postResample</code> is meant to be used with <code>apply</code>
across a matrix. For numeric data the code checks to see if the
standard deviation of either vector is zero. If so, the
correlation between those samples is assigned a value of zero.
<code>NA</code> values are ignored everywhere.
</p>
<p>Note that many models have more predictors (or parameters) than
data points, so the typical mean squared error denominator (n -
p) does not apply. Root mean squared error is calculated using
<code>sqrt(mean((pred - obs)^2</code>. Also, <code class="reqn">R^2</code> is calculated
wither using as the square of the correlation between the
observed and predicted outcomes when <code>form = "corr"</code>. when
<code>form = "traditional"</code>, </p>
<p style="text-align: center;"><code class="reqn"> R^2 = 1-\frac{\sum (y_i -
 \hat{y}_i)^2}{\sum (y_i - \bar{y})^2} </code>
</p>
<p>. Mean absolute error
is calculated using <code>mean(abs(pred-obs))</code>.
</p>
<p><code>defaultSummary</code> is the default function to compute
performance metrics in <code><a href="#topic+train">train</a></code>. It is a wrapper
around <code>postResample</code>. The first argument is <code>data</code>,
which is <code>data.frame</code> with columns named <code>obs</code> and
<code>pred</code> for the observed and predicted outcome values
(either numeric data for regression or character values for
classification). The second argument is <code>lev</code>, a character
string that has the outcome factor levels or NULL for a
regression model. The third parameter is <code>model</code>, which can
be used if a summary metric is specific to a model function. If
other columns from the data are required to compute the summary
statistics, but should not be used in the model, the
<code>recipe</code> method for <code><a href="#topic+train">train</a></code> can be used.
</p>
<p><code>twoClassSummary</code> computes sensitivity, specificity and
the area under the ROC curve. <code>mnLogLoss</code> computes the
minus log-likelihood of the multinomial distribution (without
the constant term): </p>
<p style="text-align: center;"><code class="reqn"> -logLoss = \frac{-1}{n}\sum_{i=1}^n
 \sum_{j=1}^C y_{ij} \log(p_{ij}) </code>
</p>
<p> where the <code>y</code> values are
binary indicators for the classes and <code>p</code> are the predicted
class probabilities.
</p>
<p><code>prSummary</code> (for precision and recall) computes values for
the default 0.50 probability cutoff as well as the area under
the precision-recall curve across all cutoffs and is labelled as
<code>"AUC"</code> in the output. If assumes that the first level of
the factor variables corresponds to a relevant result but the
<code>lev</code> argument can be used to change this.
</p>
<p><code>multiClassSummary</code> computes some overall measures of for
performance (e.g. overall accuracy and the Kappa statistic) and
several averages of statistics calculated from &quot;one-versus-all&quot;
configurations. For example, if there are three classes, three
sets of sensitivity values are determined and the average is
reported with the name (&quot;Mean_Sensitivity&quot;). The same is true
for a number of statistics generated by
<code><a href="#topic+confusionMatrix">confusionMatrix</a></code>. With two classes, the basic
sensitivity is reported with the name &quot;Sensitivity&quot;.
</p>
<p>To use <code>twoClassSummary</code> and/or <code>mnLogLoss</code>, the
<code>classProbs</code> argument of <code><a href="#topic+trainControl">trainControl</a></code> should
be <code>TRUE</code>. <code>multiClassSummary</code> can be used without
class probabilities but some statistics (e.g. overall log loss
and the average of per-class area under the ROC curves) will not
be in the result set.
</p>
<p>Other functions can be used via the <code>summaryFunction</code>
argument of <code><a href="#topic+trainControl">trainControl</a></code>. Custom functions must
have the same arguments as<code>defaultSummary</code>.
</p>
<p>The function <code>getTrainPerf</code> returns a one row data frame
with the resampling results for the chosen model. The statistics
will have the prefix &quot;<code>Train</code>&quot; (i.e. &quot;<code>TrainROC</code>&quot;).
There is also a column called &quot;<code>method</code>&quot; that echoes the
argument of the call to <code><a href="#topic+trainControl">trainControl</a></code> of the same
name.
</p>


<h3>Value</h3>

<p>A vector of performance estimates.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, Zachary Mayer
</p>


<h3>References</h3>

<p>Kvalseth. Cautionary note about <code class="reqn">R^2</code>. American Statistician
(1985) vol. 39 (4) pp. 279-285
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trainControl">trainControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
predicted &lt;-  matrix(rnorm(50), ncol = 5)
observed &lt;- rnorm(10)
apply(predicted, 2, postResample, obs = observed)

classes &lt;- c("class1", "class2")
set.seed(1)
dat &lt;- data.frame(obs =  factor(sample(classes, 50, replace = TRUE)),
                  pred = factor(sample(classes, 50, replace = TRUE)),
                  class1 = runif(50))
dat$class2 &lt;- 1 - dat$class1

defaultSummary(dat, lev = classes)
twoClassSummary(dat, lev = classes)
prSummary(dat, lev = classes)
mnLogLoss(dat, lev = classes)

</code></pre>

<hr>
<h2 id='densityplot.rfe'>Lattice functions for plotting resampling results of recursive feature
selection</h2><span id='topic+densityplot.rfe'></span><span id='topic+xyplot.rfe'></span><span id='topic+stripplot.rfe'></span><span id='topic+histogram.rfe'></span>

<h3>Description</h3>

<p>A set of lattice functions are provided to plot the resampled performance
estimates (e.g. classification accuracy, RMSE) over different subset sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rfe'
densityplot(x, data = NULL, metric = x$metric, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densityplot.rfe_+3A_x">x</code></td>
<td>
<p>An object produced by <code><a href="#topic+rfe">rfe</a></code></p>
</td></tr>
<tr><td><code id="densityplot.rfe_+3A_data">data</code></td>
<td>
<p>This argument is not used</p>
</td></tr>
<tr><td><code id="densityplot.rfe_+3A_metric">metric</code></td>
<td>
<p>A character string specifying the single performance metric
that will be plotted</p>
</td></tr>
<tr><td><code id="densityplot.rfe_+3A_...">...</code></td>
<td>
<p>arguments to pass to either
<code><a href="lattice.html#topic+histogram">histogram</a></code>,
<code><a href="lattice.html#topic+histogram">densityplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code> or
<code><a href="lattice.html#topic+xyplot">stripplot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, only the resampling results for the optimal model are saved in
the <code>rfe</code> object. The function <code><a href="#topic+rfeControl">rfeControl</a></code> can be used to
save all the results using the <code>returnResamp</code> argument.
</p>
<p>If leave-one-out or out-of-bag resampling was specified, plots cannot be
produced (see the <code>method</code> argument of <code><a href="#topic+rfeControl">rfeControl</a></code>)
</p>


<h3>Value</h3>

<p>A lattice plot object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rfe">rfe</a></code>, <code><a href="#topic+rfeControl">rfeControl</a></code>,
<code><a href="lattice.html#topic+histogram">histogram</a></code>,
<code><a href="lattice.html#topic+histogram">densityplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="lattice.html#topic+xyplot">stripplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
library(mlbench)
n &lt;- 100
p &lt;- 40
sigma &lt;- 1
set.seed(1)
sim &lt;- mlbench.friedman1(n, sd = sigma)
x &lt;- cbind(sim$x,  matrix(rnorm(n * p), nrow = n))
y &lt;- sim$y
colnames(x) &lt;- paste("var", 1:ncol(x), sep = "")

normalization &lt;- preProcess(x)
x &lt;- predict(normalization, x)
x &lt;- as.data.frame(x, stringsAsFactors = TRUE)
subsets &lt;- c(10, 15, 20, 25)

ctrl &lt;- rfeControl(
                   functions = lmFuncs,
                   method = "cv",
                   verbose = FALSE,
                   returnResamp = "all")

lmProfile &lt;- rfe(x, y,
                 sizes = subsets,
                 rfeControl = ctrl)
xyplot(lmProfile)
stripplot(lmProfile)

histogram(lmProfile)
densityplot(lmProfile)

## End(Not run)

</code></pre>

<hr>
<h2 id='dhfr'>Dihydrofolate Reductase Inhibitors Data</h2><span id='topic+dhfr'></span>

<h3>Description</h3>

<p>Sutherland and Weaver (2004) discuss QSAR models for dihydrofolate reductase
(DHFR) inhibition. This data set contains values for 325 compounds. For each
compound, 228 molecular descriptors have been calculated. Additionally, each
samples is designated as &quot;active&quot; or &quot;inactive&quot;.
</p>


<h3>Details</h3>

<p>The data frame <code>dhfr</code> contains a column called <code>Y</code> with the
outcome classification. The remainder of the columns are molecular
descriptor values.
</p>


<h3>Value</h3>

<table>
<tr><td><code>dhfr</code></td>
<td>
<p>data frame of chemical descriptors and the activity
values</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Sutherland, J.J. and Weaver, D.F. (2004). Three-dimensional
quantitative structure-activity and structure-selectivity relationships of
dihydrofolate reductase inhibitors, <em>Journal of Computer-Aided
Molecular Design</em>, Vol. 18, pg. 309-331.
</p>

<hr>
<h2 id='diff.resamples'>Inferential Assessments About Model Performance</h2><span id='topic+diff.resamples'></span><span id='topic+summary.diff.resamples'></span><span id='topic+compare_models'></span>

<h3>Description</h3>

<p>Methods for making inferences about differences between models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'resamples'
diff(
  x,
  models = x$models,
  metric = x$metrics,
  test = t.test,
  confLevel = 0.95,
  adjustment = "bonferroni",
  ...
)

## S3 method for class 'diff.resamples'
summary(object, digits = max(3, getOption("digits") - 3), ...)

compare_models(a, b, metric = a$metric[1])
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diff.resamples_+3A_x">x</code></td>
<td>
<p>an object generated by <code>resamples</code></p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_models">models</code></td>
<td>
<p>a character string for which models to compare</p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_metric">metric</code></td>
<td>
<p>a character string for which metrics to compare</p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_test">test</code></td>
<td>
<p>a function to compute differences. The output of this function
should have scalar outputs called <code>estimate</code> and <code>p.value</code></p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_conflevel">confLevel</code></td>
<td>
<p>confidence level to use for
<code><a href="#topic+dotplot.diff.resamples">dotplot.diff.resamples</a></code>. See Details below.</p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_adjustment">adjustment</code></td>
<td>
<p>any p-value adjustment method to pass to
<code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.</p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_...">...</code></td>
<td>
<p>further arguments to pass to <code>test</code></p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_object">object</code></td>
<td>
<p>a object generated by <code>diff.resamples</code></p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_digits">digits</code></td>
<td>
<p>the number of significant differences to display when printing</p>
</td></tr>
<tr><td><code id="diff.resamples_+3A_a">a</code>, <code id="diff.resamples_+3A_b">b</code></td>
<td>
<p>two objects of class <code><a href="#topic+train">train</a></code>, <code><a href="#topic+sbf">sbf</a></code> or
<code><a href="#topic+rfe">rfe</a></code> with a common set of resampling indices in the
<code>control</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ideas and methods here are based on Hothorn et al. (2005) and Eugster et
al. (2008).
</p>
<p>For each metric, all pair-wise differences are computed and tested to assess
if the difference is equal to zero.
</p>
<p>When a Bonferroni correction is used, the confidence level is changed from
<code>confLevel</code> to <code>1-((1-confLevel)/p)</code> here <code>p</code> is the number
of pair-wise comparisons are being made. For other correction methods, no
such change is used.
</p>
<p><code>compare_models</code> is a shorthand function to compare two models using a
single metric. It returns the results of <code><a href="stats.html#topic+t.test">t.test</a></code> on the
differences.
</p>


<h3>Value</h3>

<p>An object of class <code>"diff.resamples"</code> with elements: </p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call</p>
</td></tr> <tr><td><code>difs</code></td>
<td>
<p>a list for each metric being compared. Each list
contains a matrix with differences in columns and resamples in rows </p>
</td></tr>
<tr><td><code>statistics</code></td>
<td>
<p>a list of results generated by <code>test</code></p>
</td></tr>
<tr><td><code>adjustment</code></td>
<td>
<p>the p-value adjustment used</p>
</td></tr> <tr><td><code>models</code></td>
<td>
<p>a character
string for which models were compared.</p>
</td></tr> <tr><td><code>metrics</code></td>
<td>
<p>a character string
of performance metrics that were used</p>
</td></tr>
</table>
<p>or...
</p>
<p>An object of class <code>"summary.diff.resamples"</code> with elements: </p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call</p>
</td></tr> <tr><td><code>table</code></td>
<td>
<p>a list of tables that show the differences and
p-values </p>
</td></tr>
</table>
<p>...or (for <code>compare_models</code>) an object of class <code>htest</code> resulting
from <code><a href="stats.html#topic+t.test">t.test</a></code>.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Hothorn et al. The design and analysis of benchmark experiments.
Journal of Computational and Graphical Statistics (2005) vol. 14 (3) pp.
675-699
</p>
<p>Eugster et al. Exploratory and inferential analysis of benchmark
experiments. Ludwigs-Maximilians-Universitat Munchen, Department of
Statistics, Tech. Rep (2008) vol. 30
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resamples">resamples</a></code>, <code><a href="#topic+dotplot.diff.resamples">dotplot.diff.resamples</a></code>,
<code><a href="#topic+densityplot.diff.resamples">densityplot.diff.resamples</a></code>,
<code><a href="#topic+bwplot.diff.resamples">bwplot.diff.resamples</a></code>, <code><a href="#topic+levelplot.diff.resamples">levelplot.diff.resamples</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#load(url("http://topepo.github.io/caret/exampleModels.RData"))

resamps &lt;- resamples(list(CART = rpartFit,
                          CondInfTree = ctreeFit,
                          MARS = earthFit))

difs &lt;- diff(resamps)

difs

summary(difs)

compare_models(rpartFit, ctreeFit)

## End(Not run)

</code></pre>

<hr>
<h2 id='dotPlot'>Create a dotplot of variable importance values</h2><span id='topic+dotPlot'></span>

<h3>Description</h3>

<p>A lattice <code><a href="lattice.html#topic+xyplot">dotplot</a></code> is created from an object of
class <code>varImp.train</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dotPlot(x, top = min(20, dim(x$importance)[1]), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dotPlot_+3A_x">x</code></td>
<td>
<p>an object of class <code>varImp.train</code></p>
</td></tr>
<tr><td><code id="dotPlot_+3A_top">top</code></td>
<td>
<p>the number of predictors to plot</p>
</td></tr>
<tr><td><code id="dotPlot_+3A_...">...</code></td>
<td>
<p>options passed to <code><a href="lattice.html#topic+xyplot">dotplot</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>trellis</code>.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varImp">varImp</a></code>, <code><a href="lattice.html#topic+xyplot">dotplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(iris)
TrainData &lt;- iris[,1:4]
TrainClasses &lt;- iris[,5]

knnFit &lt;- train(TrainData, TrainClasses, "knn")

knnImp &lt;- varImp(knnFit)

dotPlot(knnImp)


</code></pre>

<hr>
<h2 id='dotplot.diff.resamples'>Lattice Functions for Visualizing Resampling Differences</h2><span id='topic+dotplot.diff.resamples'></span><span id='topic+levelplot.diff.resamples'></span><span id='topic+densityplot.diff.resamples'></span><span id='topic+bwplot.diff.resamples'></span>

<h3>Description</h3>

<p>Lattice functions for visualizing resampling result differences between
models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'diff.resamples'
dotplot(x, data = NULL, metric = x$metric[1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dotplot.diff.resamples_+3A_x">x</code></td>
<td>
<p>an object generated by <code><a href="#topic+diff.resamples">diff.resamples</a></code></p>
</td></tr>
<tr><td><code id="dotplot.diff.resamples_+3A_data">data</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="dotplot.diff.resamples_+3A_metric">metric</code></td>
<td>
<p>a character string for which metrics to plot. Note:
<code>dotplot</code> and <code>levelplot</code> require exactly two models whereas the
other methods can plot more than two.</p>
</td></tr>
<tr><td><code id="dotplot.diff.resamples_+3A_...">...</code></td>
<td>
<p>further arguments to pass to either
<code><a href="lattice.html#topic+histogram">densityplot</a></code>,
<code><a href="lattice.html#topic+dotplot">dotplot</a></code> or
<code><a href="lattice.html#topic+levelplot">levelplot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>densityplot</code> and <code>bwplot</code> display univariate visualizations of
the resampling distributions. <code>levelplot</code> displays the matrix of
pair-wide comparisons. <code>dotplot</code> shows the differences along with their
associated confidence intervals.
</p>


<h3>Value</h3>

<p>a lattice object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resamples">resamples</a></code>, <code><a href="#topic+diff.resamples">diff.resamples</a></code>,
<code><a href="lattice.html#topic+bwplot">bwplot</a></code>,
<code><a href="lattice.html#topic+histogram">densityplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>, <code><a href="lattice.html#topic+splom">splom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#load(url("http://topepo.github.io/caret/exampleModels.RData"))

resamps &lt;- resamples(list(CART = rpartFit,
                          CondInfTree = ctreeFit,
                          MARS = earthFit))
difs &lt;- diff(resamps)

dotplot(difs)

densityplot(difs,
            metric = "RMSE",
            auto.key = TRUE,
            pch = "|")

bwplot(difs,
       metric = "RMSE")

levelplot(difs, what = "differences")


## End(Not run)

</code></pre>

<hr>
<h2 id='downSample'>Down- and Up-Sampling Imbalanced Data</h2><span id='topic+downSample'></span><span id='topic+upSample'></span>

<h3>Description</h3>

<p><code>downSample</code> will randomly sample a data set so that all classes have
the same frequency as the minority class. <code>upSample</code> samples with
replacement to make the class distributions equal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downSample(x, y, list = FALSE, yname = "Class")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downSample_+3A_x">x</code></td>
<td>
<p>a matrix or data frame of predictor variables</p>
</td></tr>
<tr><td><code id="downSample_+3A_y">y</code></td>
<td>
<p>a factor variable with the class memberships</p>
</td></tr>
<tr><td><code id="downSample_+3A_list">list</code></td>
<td>
<p>should the function return <code>list(x, y)</code> or bind <code>x</code>
and <code>y</code> together? If <code>FALSE</code>, the output will be coerced to a data
frame.</p>
</td></tr>
<tr><td><code id="downSample_+3A_yname">yname</code></td>
<td>
<p>if <code>list = FALSE</code>, a label for the class column</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simple random sampling is used to down-sample for the majority class(es).
Note that the minority class data are left intact and that the samples will
be re-ordered in the down-sampled version.
</p>
<p>For up-sampling, all the original data are left intact and additional
samples are added to the minority classes with replacement.
</p>


<h3>Value</h3>

<p>Either a data frame or a list with elements <code>x</code> and <code>y</code>.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## A ridiculous example...
data(oil)
table(oilType)
downSample(fattyAcids, oilType)

upSample(fattyAcids, oilType)


</code></pre>

<hr>
<h2 id='dummyVars'>Create A Full Set of Dummy Variables</h2><span id='topic+dummyVars'></span><span id='topic+dummyVars.default'></span><span id='topic+predict.dummyVars'></span><span id='topic+contr.dummy'></span><span id='topic+contr.ltfr'></span><span id='topic+class2ind'></span><span id='topic+print.dummyVars'></span>

<h3>Description</h3>

<p><code>dummyVars</code> creates a full set of dummy variables (i.e. less than full
rank parameterization)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dummyVars(formula, ...)

## Default S3 method:
dummyVars(formula, data, sep = ".", levelsOnly = FALSE, fullRank = FALSE, ...)

## S3 method for class 'dummyVars'
print(x, ...)

## S3 method for class 'dummyVars'
predict(object, newdata, na.action = na.pass, ...)

contr.ltfr(n, contrasts = TRUE, sparse = FALSE)

class2ind(x, drop2nd = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dummyVars_+3A_formula">formula</code></td>
<td>
<p>An appropriate R model formula, see References</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to other methods</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_data">data</code></td>
<td>
<p>A data frame with the predictors of interest</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_sep">sep</code></td>
<td>
<p>An optional separator between factor variable names and their
levels. Use <code>sep = NULL</code> for no separator (i.e. normal behavior of
<code><a href="stats.html#topic+model.matrix">model.matrix</a></code> as shown in the Details section)</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_levelsonly">levelsOnly</code></td>
<td>
<p>A logical; <code>TRUE</code> means to completely remove the
variable names from the column names</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_fullrank">fullRank</code></td>
<td>
<p>A logical; should a full rank or less than full rank
parameterization be used? If <code>TRUE</code>, factors are encoded to be
consistent with <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> and the resulting there
are no linear dependencies induced between the columns.</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_x">x</code></td>
<td>
<p>A factor vector.</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_object">object</code></td>
<td>
<p>An object of class <code>dummyVars</code></p>
</td></tr>
<tr><td><code id="dummyVars_+3A_newdata">newdata</code></td>
<td>
<p>A data frame with the required columns</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_na.action">na.action</code></td>
<td>
<p>A function determining what should be done with missing
values in <code>newdata</code>. The default is to predict <code>NA</code>.</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_n">n</code></td>
<td>
<p>A vector of levels for a factor, or the number of levels.</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_contrasts">contrasts</code></td>
<td>
<p>A logical indicating whether contrasts should be computed.</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_sparse">sparse</code></td>
<td>
<p>A logical indicating if the result should be sparse.</p>
</td></tr>
<tr><td><code id="dummyVars_+3A_drop2nd">drop2nd</code></td>
<td>
<p>A logical: if the factor has two levels, should a single binary vector be returned?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most of the <code><a href="stats.html#topic+contrasts">contrasts</a></code> functions in R produce full rank
parameterizations of the predictor data. For example,
<code><a href="stats.html#topic+contr.treatment">contr.treatment</a></code> creates a reference cell in the data
and defines dummy variables for all factor levels except those in the
reference cell. For example, if a factor with 5 levels is used in a model
formula alone, <code><a href="stats.html#topic+contr.treatment">contr.treatment</a></code> creates columns for the
intercept and all the factor levels except the first level of the factor.
For the data in the Example section below, this would produce:
</p>
<pre> (Intercept) dayTue dayWed dayThu dayFri daySat daySun
           1      0      0      0      0      0      0
           1      0      0      0      0      0      0
           1      0      0      0      0      0      0
           1      0      1      0      0      0      0
           1      0      1      0      0      0      0
           1      0      0      0      1      0      0
           1      0      0      0      0      1      0
           1      0      0      0      0      1      0
           1      0      0      0      1      0      0</pre>
<p>In some situations, there may be a need for dummy variables for all the
levels of the factor. For the same example:
</p>
<pre> dayMon dayTue dayWed dayThu dayFri daySat daySun
      1      0      0      0      0      0      0
      1      0      0      0      0      0      0
      1      0      0      0      0      0      0
      0      0      1      0      0      0      0
      0      0      1      0      0      0      0
      0      0      0      0      1      0      0
      0      0      0      0      0      1      0
      0      0      0      0      0      1      0
      0      0      0      0      1      0      0</pre>
<p>Given a formula and initial data set, the class <code>dummyVars</code> gathers all
the information needed to produce a full set of dummy variables for any data
set. It uses <code>contr.ltfr</code> as the base function to do this.
</p>
<p><code>class2ind</code> is most useful for converting a factor outcome vector to a
matrix (or vector) of dummy variables.
</p>


<h3>Value</h3>

<p>The output of <code>dummyVars</code> is a list of class 'dummyVars' with
elements </p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr> <tr><td><code>form</code></td>
<td>
<p>the model formula</p>
</td></tr>
<tr><td><code>vars</code></td>
<td>
<p>names of all the variables in the model</p>
</td></tr> <tr><td><code>facVars</code></td>
<td>
<p>names
of all the factor variables in the model</p>
</td></tr> <tr><td><code>lvls</code></td>
<td>
<p>levels of any factor
variables</p>
</td></tr> <tr><td><code>sep</code></td>
<td>
<p><code>NULL</code> or a character separator</p>
</td></tr> <tr><td><code>terms</code></td>
<td>
<p>the <code><a href="stats.html#topic+terms.formula">terms.formula</a></code> object</p>
</td></tr> <tr><td><code>levelsOnly</code></td>
<td>
<p>a
logical</p>
</td></tr>
</table>
<p>The <code>predict</code> function produces a data frame.
</p>
<p><code>class2ind</code> returns a matrix (or a vector if <code>drop2nd = TRUE</code>).
</p>
<p><code>contr.ltfr</code> generates a design matrix.
</p>


<h3>Author(s)</h3>

<p><code>contr.ltfr</code> is a small modification of
<code><a href="stats.html#topic+contr.treatment">contr.treatment</a></code> by Max Kuhn
</p>


<h3>References</h3>

<p><a href="https://cran.r-project.org/doc/manuals/R-intro.html#Formulae-for-statistical-models">https://cran.r-project.org/doc/manuals/R-intro.html#Formulae-for-statistical-models</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+model.matrix">model.matrix</a></code>, <code><a href="stats.html#topic+contrasts">contrasts</a></code>,
<code><a href="stats.html#topic+formula">formula</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>when &lt;- data.frame(time = c("afternoon", "night", "afternoon",
                            "morning", "morning", "morning",
                            "morning", "afternoon", "afternoon"),
                   day = c("Mon", "Mon", "Mon",
                           "Wed", "Wed", "Fri",
                           "Sat", "Sat", "Fri"),
                           stringsAsFactors = TRUE)

levels(when$time) &lt;- list(morning="morning",
                          afternoon="afternoon",
                          night="night")
levels(when$day) &lt;- list(Mon="Mon", Tue="Tue", Wed="Wed", Thu="Thu",
                         Fri="Fri", Sat="Sat", Sun="Sun")

## Default behavior:
model.matrix(~day, when)

mainEffects &lt;- dummyVars(~ day + time, data = when)
mainEffects
predict(mainEffects, when[1:3,])

when2 &lt;- when
when2[1, 1] &lt;- NA
predict(mainEffects, when2[1:3,])
predict(mainEffects, when2[1:3,], na.action = na.omit)


interactionModel &lt;- dummyVars(~ day + time + day:time,
                              data = when,
                              sep = ".")
predict(interactionModel, when[1:3,])

noNames &lt;- dummyVars(~ day + time + day:time,
                     data = when,
                     levelsOnly = TRUE)
predict(noNames, when)

head(class2ind(iris$Species))

two_levels &lt;- factor(rep(letters[1:2], each = 5))
class2ind(two_levels)
class2ind(two_levels, drop2nd = TRUE)
</code></pre>

<hr>
<h2 id='extractPrediction'>Extract predictions and class probabilities from train objects</h2><span id='topic+extractPrediction'></span><span id='topic+extractProb'></span><span id='topic+predict.train'></span><span id='topic+predict.list'></span>

<h3>Description</h3>

<p>These functions can be used for a single <code>train</code> object or to loop
through a number of <code>train</code> objects to calculate the training and test
data predictions and class probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractPrediction(
  models,
  testX = NULL,
  testY = NULL,
  unkX = NULL,
  unkOnly = !is.null(unkX) &amp; is.null(testX),
  verbose = FALSE
)

extractProb(
  models,
  testX = NULL,
  testY = NULL,
  unkX = NULL,
  unkOnly = !is.null(unkX) &amp; is.null(testX),
  verbose = FALSE
)

## S3 method for class 'train'
predict(object, newdata = NULL, type = "raw", na.action = na.omit, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractPrediction_+3A_models">models</code></td>
<td>
<p>a list of objects of the class <code>train</code>. The objects must
have been generated with <code>fitBest = FALSE</code> and <code>returnData =
TRUE</code>.</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_testx">testX</code></td>
<td>
<p>an optional set of data to predict</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_testy">testY</code></td>
<td>
<p>an optional outcome corresponding to the data given in
<code>testX</code></p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_unkx">unkX</code></td>
<td>
<p>another optional set of data to predict without known outcomes</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_unkonly">unkOnly</code></td>
<td>
<p>a logical to bypass training and test set predictions. This
is useful if speed is needed for unknown samples.</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_verbose">verbose</code></td>
<td>
<p>a logical for printing messages</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_object">object</code></td>
<td>
<p>For <code>predict.train</code>, an object of class
<code><a href="#topic+train">train</a></code>. For <code>predict.list</code>, a list of objects of class
<code><a href="#topic+train">train</a></code>.</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_newdata">newdata</code></td>
<td>
<p>an optional set of data to predict on. If <code>NULL</code>, then
the original training data are used but, if the <code>train</code> model used a
recipe, an error will occur.</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_type">type</code></td>
<td>
<p>either &quot;raw&quot; or &quot;prob&quot;, for the number/class predictions or
class probabilities, respectively. Class probabilities are not available for
all classification models</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_na.action">na.action</code></td>
<td>
<p>the method for handling missing data</p>
</td></tr>
<tr><td><code id="extractPrediction_+3A_...">...</code></td>
<td>
<p>only used for <code>sort</code> and <code>modelCor</code> and captures
arguments to pass to <code>sort</code> or <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are wrappers for the specific prediction functions in each
modeling package. In each case, the optimal tuning values given in the
<code>tuneValue</code> slot of the <code>finalModel</code> object are used to predict.
</p>
<p>To get simple predictions for a new data set, the <code>predict</code> function
can be used. Limits can be imposed on the range of predictions. See
<code><a href="#topic+trainControl">trainControl</a></code> for more information.
</p>
<p>To get predictions for a series of models at once, a list of
<code><a href="#topic+train">train</a></code> objects can be passes to the <code>predict</code> function and
a list of model predictions will be returned.
</p>
<p>The two extraction functions can be used to get the predictions and observed
outcomes at once for the training, test and/or unknown samples at once in a
single data frame (instead of a list of just the predictions). These objects
can then be passes to <code><a href="#topic+plotObsVsPred">plotObsVsPred</a></code> or
<code><a href="#topic+plotClassProbs">plotClassProbs</a></code>.
</p>


<h3>Value</h3>

<p>For <code>predict.train</code>, a vector of predictions if <code>type = "raw"</code> or
a data frame of class probabilities for <code>type = "prob"</code>. In the latter
case, there are columns for each class.
</p>
<p>For <code>predict.list</code>, a list results. Each element is produced by
<code>predict.train</code>.
</p>
<p>For <code>extractPrediction</code>, a data frame with columns: </p>
<table>
<tr><td><code>obs</code></td>
<td>
<p>the
observed training and test data</p>
</td></tr> <tr><td><code>pred</code></td>
<td>
<p>predicted values</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the type of model used to predict</p>
</td></tr> <tr><td><code>object</code></td>
<td>
<p>the names of
the objects within <code>models</code>. If <code>models</code> is an un-named list, the
values of <code>object</code> will be &quot;Object1&quot;, &quot;Object2&quot; and so on</p>
</td></tr>
<tr><td><code>dataType</code></td>
<td>
<p>&quot;Training&quot;, &quot;Test&quot; or &quot;Unknown&quot; depending on what was
specified</p>
</td></tr>
</table>
<p>For <code>extractProb</code>, a data frame. There is a column for each class
containing the probabilities. The remaining columns are the same as above
(although the <code>pred</code> column is the predicted class)
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Kuhn (2008), &ldquo;Building Predictive Models in R Using the caret&rdquo;
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotObsVsPred">plotObsVsPred</a></code>, <code><a href="#topic+plotClassProbs">plotClassProbs</a></code>,
<code><a href="#topic+trainControl">trainControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
   ## Not run: 

knnFit &lt;- train(Species ~ ., data = iris, method = "knn",
                trControl = trainControl(method = "cv"))

rdaFit &lt;- train(Species ~ ., data = iris, method = "rda",
                trControl = trainControl(method = "cv"))

predict(knnFit)
predict(knnFit, type = "prob")

bothModels &lt;- list(knn = knnFit,
                   tree = rdaFit)

predict(bothModels)

extractPrediction(bothModels, testX = iris[1:10, -5])
extractProb(bothModels, testX = iris[1:10, -5])
  
## End(Not run)

</code></pre>

<hr>
<h2 id='featurePlot'>Wrapper for Lattice Plotting of Predictor Variables</h2><span id='topic+featurePlot'></span>

<h3>Description</h3>

<p>A shortcut to produce lattice graphs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>featurePlot(
  x,
  y,
  plot = if (is.factor(y)) "strip" else "scatter",
  labels = c("Feature", ""),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="featurePlot_+3A_x">x</code></td>
<td>
<p>a matrix or data frame of continuous feature/probe/spectra data.</p>
</td></tr>
<tr><td><code id="featurePlot_+3A_y">y</code></td>
<td>
<p>a factor indicating class membership.</p>
</td></tr>
<tr><td><code id="featurePlot_+3A_plot">plot</code></td>
<td>
<p>the type of plot. For classification: <code>box</code>, <code>strip</code>,
<code>density</code>, <code>pairs</code> or <code>ellipse</code>.  For regression,
<code>pairs</code> or <code>scatter</code></p>
</td></tr>
<tr><td><code id="featurePlot_+3A_labels">labels</code></td>
<td>
<p>a bad attempt at pre-defined axis labels</p>
</td></tr>
<tr><td><code id="featurePlot_+3A_...">...</code></td>
<td>
<p>options passed to lattice calls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function &ldquo;stacks&rdquo; data to get it into a form compatible with lattice
and creates the plots
</p>


<h3>Value</h3>

<p>An object of class &ldquo;trellis&rdquo;. The &lsquo;update&rsquo; method can be used to
update components of the object and the &lsquo;print&rsquo; method (usually called by
default) will plot it on an appropriate plotting device.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(rnorm(50*5),ncol=5)
y &lt;- factor(rep(c("A", "B"),  25))

trellis.par.set(theme = col.whitebg(), warn = FALSE)
featurePlot(x, y, "ellipse")
featurePlot(x, y, "strip", jitter = TRUE)
featurePlot(x, y, "box")
featurePlot(x, y, "pairs")

</code></pre>

<hr>
<h2 id='filterVarImp'>Calculation of filter-based variable importance</h2><span id='topic+filterVarImp'></span>

<h3>Description</h3>

<p>Specific engines for variable importance on a model by model basis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterVarImp(x, y, nonpara = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filterVarImp_+3A_x">x</code></td>
<td>
<p>A matrix or data frame of predictor data</p>
</td></tr>
<tr><td><code id="filterVarImp_+3A_y">y</code></td>
<td>
<p>A vector (numeric or factor) of outcomes)</p>
</td></tr>
<tr><td><code id="filterVarImp_+3A_nonpara">nonpara</code></td>
<td>
<p>should nonparametric methods be used to assess the
relationship between the features and response</p>
</td></tr>
<tr><td><code id="filterVarImp_+3A_...">...</code></td>
<td>
<p>options to pass to either <code><a href="stats.html#topic+lm">lm</a></code> or
<code><a href="stats.html#topic+loess">loess</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The importance of each predictor is evaluated individually using a
&ldquo;filter&rdquo; approach.
</p>
<p>For classification, ROC curve analysis is conducted on each predictor. For
two class problems, a series of cutoffs is applied to the predictor data to
predict the class. The sensitivity and specificity are computed for each
cutoff and the ROC curve is computed. The trapezoidal rule is used to
compute the area under the ROC curve. This area is used as the measure of
variable importance. For multi-class outcomes, the problem is decomposed
into all pair-wise problems and the area under the curve is calculated for
each class pair (i.e class 1 vs. class 2, class 2 vs. class 3 etc.). For a
specific class, the maximum area under the curve across the relevant
pair-wise AUC's is used as the variable importance measure.
</p>
<p>For regression, the relationship between each predictor and the outcome is
evaluated. An argument, <code>nonpara</code>, is used to pick the model fitting
technique. When <code>nonpara = FALSE</code>, a linear model is fit and the
absolute value of the $t$-value for the slope of the predictor is used.
Otherwise, a loess smoother is fit between the outcome and the predictor.
The $R^2$ statistic is calculated for this model against the intercept only
null model.
</p>


<h3>Value</h3>

<p>A data frame with variable importances. Column names depend on the
problem type.  For regression, the data frame contains one column: &quot;Overall&quot;
for the importance values.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mdrr)
filterVarImp(mdrrDescr[, 1:5], mdrrClass)

data(BloodBrain)

filterVarImp(bbbDescr[, 1:5], logBBB, nonpara = FALSE)
apply(bbbDescr[, 1:5],
      2,
      function(x, y) summary(lm(y~x))$coefficients[2,3],
      y = logBBB)

filterVarImp(bbbDescr[, 1:5], logBBB, nonpara = TRUE)

</code></pre>

<hr>
<h2 id='findCorrelation'>Determine highly correlated variables</h2><span id='topic+findCorrelation'></span>

<h3>Description</h3>

<p>This function searches through a correlation matrix and returns a vector of
integers corresponding to columns to remove to reduce pair-wise
correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findCorrelation(
  x,
  cutoff = 0.9,
  verbose = FALSE,
  names = FALSE,
  exact = ncol(x) &lt; 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findCorrelation_+3A_x">x</code></td>
<td>
<p>A correlation matrix</p>
</td></tr>
<tr><td><code id="findCorrelation_+3A_cutoff">cutoff</code></td>
<td>
<p>A numeric value for the pair-wise absolute correlation cutoff</p>
</td></tr>
<tr><td><code id="findCorrelation_+3A_verbose">verbose</code></td>
<td>
<p>A boolean for printing the details</p>
</td></tr>
<tr><td><code id="findCorrelation_+3A_names">names</code></td>
<td>
<p>a logical; should the column names be returned (<code>TRUE</code>) or
the column index (<code>FALSE</code>)?</p>
</td></tr>
<tr><td><code id="findCorrelation_+3A_exact">exact</code></td>
<td>
<p>a logical; should the average correlations be recomputed at
each step? See Details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The absolute values of pair-wise correlations are considered. If two
variables have a high correlation, the function looks at the mean absolute
correlation of each variable and removes the variable with the largest mean
absolute correlation.
</p>
<p>Using <code>exact = TRUE</code> will cause the function to re-evaluate the average
correlations at each step while <code>exact = FALSE</code> uses all the
correlations regardless of whether they have been eliminated or not. The
exact calculations will remove a smaller number of predictors but can be
much slower when the problem dimensions are &quot;big&quot;.
</p>
<p>There are several function in the <span class="pkg">subselect</span> package
(<code><a href="subselect.html#topic+eleaps">leaps</a></code>,
<code><a href="subselect.html#topic+genetic">genetic</a></code>,
<code><a href="subselect.html#topic+anneal">anneal</a></code>) that can also be used to accomplish
the same goal but tend to retain more predictors.
</p>


<h3>Value</h3>

<p>A vector of indices denoting the columns to remove (when <code>names
= TRUE</code>) otherwise a vector of column names. If no correlations meet the
criteria, <code>integer(0)</code> is returned.
</p>


<h3>Author(s)</h3>

<p>Original R code by Dong Li, modified by Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="subselect.html#topic+eleaps">leaps</a></code>,
<code><a href="subselect.html#topic+genetic">genetic</a></code>,
<code><a href="subselect.html#topic+anneal">anneal</a></code>, <code><a href="#topic+findLinearCombos">findLinearCombos</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
R1 &lt;- structure(c(1, 0.86, 0.56, 0.32, 0.85, 0.86, 1, 0.01, 0.74, 0.32, 
                  0.56, 0.01, 1, 0.65, 0.91, 0.32, 0.74, 0.65, 1, 0.36,
                  0.85, 0.32, 0.91, 0.36, 1), 
                .Dim = c(5L, 5L))
colnames(R1) &lt;- rownames(R1) &lt;- paste0("x", 1:ncol(R1))
R1

findCorrelation(R1, cutoff = .6, exact = FALSE)
findCorrelation(R1, cutoff = .6, exact = TRUE)
findCorrelation(R1, cutoff = .6, exact = TRUE, names = FALSE)


R2 &lt;- diag(rep(1, 5))
R2[2, 3] &lt;- R2[3, 2] &lt;- .7
R2[5, 3] &lt;- R2[3, 5] &lt;- -.7
R2[4, 1] &lt;- R2[1, 4] &lt;- -.67

corrDF &lt;- expand.grid(row = 1:5, col = 1:5)
corrDF$correlation &lt;- as.vector(R2)
levelplot(correlation ~ row + col, corrDF)

findCorrelation(R2, cutoff = .65, verbose = TRUE)

findCorrelation(R2, cutoff = .99, verbose = TRUE)

</code></pre>

<hr>
<h2 id='findLinearCombos'>Determine linear combinations in a matrix</h2><span id='topic+findLinearCombos'></span>

<h3>Description</h3>

<p>Enumerate and resolve the linear combinations in a numeric matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findLinearCombos(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findLinearCombos_+3A_x">x</code></td>
<td>
<p>a numeric matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The QR decomposition is used to determine if the matrix is full rank and
then identify the sets of columns that are involved in the dependencies.
</p>
<p>To &quot;resolve&quot; them, columns are iteratively removed and the matrix rank is
rechecked.
</p>
<p>The <code><a href="subselect.html#topic+trim.matrix">trim.matrix</a></code> function in the
<span class="pkg">subselect</span> package can also be used to accomplish the same goal.
</p>


<h3>Value</h3>

<p>a list with elements: </p>
<table>
<tr><td><code>linearCombos</code></td>
<td>
<p>If there are linear
combinations, this will be a list with elements for each dependency that
contains vectors of column numbers. </p>
</td></tr> <tr><td><code>remove</code></td>
<td>
<p>a list of column
numbers that can be removed to counter the linear combinations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kirk Mettler and Jed Wing (<code>enumLC</code>) and Max Kuhn
(<code>findLinearCombos</code>)
</p>


<h3>See Also</h3>

<p><code><a href="subselect.html#topic+trim.matrix">trim.matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
testData1 &lt;- matrix(0, nrow=20, ncol=8)
testData1[,1] &lt;- 1
testData1[,2] &lt;- round(rnorm(20), 1)
testData1[,3] &lt;- round(rnorm(20), 1)
testData1[,4] &lt;- round(rnorm(20), 1)
testData1[,5] &lt;- 0.5 * testData1[,2] - 0.25 * testData1[,3] - 0.25 * testData1[,4]
testData1[1:4,6] &lt;- 1
testData1[5:10,7] &lt;- 1
testData1[11:20,8] &lt;- 1

findLinearCombos(testData1)

testData2 &lt;- matrix(0, nrow=6, ncol=6)
testData2[,1] &lt;- c(1, 1, 1, 1, 1, 1)
testData2[,2] &lt;- c(1, 1, 1, 0, 0, 0)
testData2[,3] &lt;- c(0, 0, 0, 1, 1, 1)
testData2[,4] &lt;- c(1, 0, 0, 1, 0, 0)
testData2[,5] &lt;- c(0, 1, 0, 0, 1, 0)
testData2[,6] &lt;- c(0, 0, 1, 0, 0, 1)

findLinearCombos(testData2)

</code></pre>

<hr>
<h2 id='format.bagEarth'>Format 'bagEarth' objects</h2><span id='topic+format.bagEarth'></span>

<h3>Description</h3>

<p>Return a string representing the &lsquo;bagEarth&rsquo; expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bagEarth'
format(x, file = "", cat = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format.bagEarth_+3A_x">x</code></td>
<td>
<p>An <code><a href="#topic+bagEarth">bagEarth</a></code> object.  This is the only required
argument.</p>
</td></tr>
<tr><td><code id="format.bagEarth_+3A_file">file</code></td>
<td>
<p>A connection, or a character string naming the file to print to.
If &quot;&quot; (the default), the output prints to the standard output connection.
See <code><a href="base.html#topic+cat">cat</a></code>.</p>
</td></tr>
<tr><td><code id="format.bagEarth_+3A_cat">cat</code></td>
<td>
<p>a logical; should the equation be printed?</p>
</td></tr>
<tr><td><code id="format.bagEarth_+3A_...">...</code></td>
<td>
<p>Arguments to <code><a href="earth.html#topic+format.earth">format.earth</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character representation of the bagged earth object.
</p>


<h3>See Also</h3>

<p><code><a href="earth.html#topic+earth">earth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
a &lt;- bagEarth(Volume ~ ., data = trees, B= 3)
format(a)

# yields:
# (
#   31.61075 
#   +  6.587273 * pmax(0,  Girth -   14.2) 
#   -  3.229363 * pmax(0,   14.2 -  Girth) 
#   - 0.3167140 * pmax(0,     79 - Height) 
#   +
#    22.80225 
#   +  5.309866 * pmax(0,  Girth -     12) 
#   -  2.378658 * pmax(0,     12 -  Girth) 
#   +  0.793045 * pmax(0, Height -     80) 
#   - 0.3411915 * pmax(0,     80 - Height) 
#   +
#    31.39772 
#   +   6.18193 * pmax(0,  Girth -   14.2) 
#   -  3.660456 * pmax(0,   14.2 -  Girth) 
#   + 0.6489774 * pmax(0, Height -     80) 
# )/3

</code></pre>

<hr>
<h2 id='gafs_initial'>Ancillary genetic algorithm functions</h2><span id='topic+gafs_initial'></span><span id='topic+gafs_lrSelection'></span><span id='topic+gafs_rwSelection'></span><span id='topic+gafs_tourSelection'></span><span id='topic+gafs_uCrossover'></span><span id='topic+gafs_spCrossover'></span><span id='topic+gafs_raMutation'></span><span id='topic+caretGA'></span><span id='topic+rfGA'></span><span id='topic+treebagGA'></span><span id='topic+gafs_nlrSelection'></span>

<h3>Description</h3>

<p>Built-in functions related to genetic algorithms
</p>
<p>These functions are used with the <code>functions</code> argument of the
<code><a href="#topic+gafsControl">gafsControl</a></code> function. More information on the details of these
functions are at <a href="http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html">http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html</a>.
</p>
<p>Most of the <code>gafs_*</code> functions are based on those from the GA package
by Luca Scrucca. These functions here are small re-writes to work outside of
the GA package.
</p>
<p>The objects <code>caretGA</code>, <code>rfGA</code> and <code>treebagGA</code> are example
lists that can be used with the <code>functions</code> argument of
<code><a href="#topic+gafsControl">gafsControl</a></code>.
</p>
<p>In the case of <code>caretGA</code>, the <code>...</code> structure of
<code><a href="#topic+gafs">gafs</a></code> passes through to the model fitting routine. As a
consequence, the <code><a href="#topic+train">train</a></code> function can easily be accessed by
passing important arguments belonging to <code><a href="#topic+train">train</a></code> to
<code><a href="#topic+gafs">gafs</a></code>. See the examples below. By default, using <code>caretGA</code>
will used the resampled performance estimates produced by
<code><a href="#topic+train">train</a></code> as the internal estimate of fitness.
</p>
<p>For <code>rfGA</code> and <code>treebagGA</code>, the <code>randomForest</code> and
<code>bagging</code> functions are used directly (i.e. <code><a href="#topic+train">train</a></code> is not
used). Arguments to either of these functions can also be passed to them
though the <code><a href="#topic+gafs">gafs</a></code> call (see examples below). For these two
functions, the internal fitness is estimated using the out-of-bag estimates
naturally produced by those functions. While faster, this limits the user to
accuracy or Kappa (for classification) and RMSE and R-squared (for
regression).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gafs_initial(vars, popSize, ...)

gafs_lrSelection(population, fitness, r = NULL, q = NULL, ...)

gafs_spCrossover(population, fitness, parents, ...)

gafs_raMutation(population, parent, ...)

gafs_nlrSelection(population, fitness, q = 0.25, ...)

gafs_rwSelection(population, fitness, ...)

gafs_tourSelection(population, fitness, k = 3, ...)

gafs_uCrossover(population, parents, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gafs_initial_+3A_vars">vars</code></td>
<td>
<p>number of possible predictors</p>
</td></tr>
<tr><td><code id="gafs_initial_+3A_popsize">popSize</code></td>
<td>
<p>the population size passed into <code><a href="#topic+gafs">gafs</a></code></p>
</td></tr>
<tr><td><code id="gafs_initial_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
<tr><td><code id="gafs_initial_+3A_population">population</code></td>
<td>
<p>a binary matrix of the current subsets with predictors in
columns and individuals in rows</p>
</td></tr>
<tr><td><code id="gafs_initial_+3A_fitness">fitness</code></td>
<td>
<p>a vector of fitness values</p>
</td></tr>
<tr><td><code id="gafs_initial_+3A_r">r</code>, <code id="gafs_initial_+3A_q">q</code>, <code id="gafs_initial_+3A_k">k</code></td>
<td>
<p>tuning parameters for the specific selection operator</p>
</td></tr>
<tr><td><code id="gafs_initial_+3A_parent">parent</code>, <code id="gafs_initial_+3A_parents">parents</code></td>
<td>
<p>integer(s) for which chromosomes are altered</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The return value depends on the function.
</p>


<h3>Author(s)</h3>

<p>Luca Scrucca, <code>gafs_initial</code>, <code>caretGA</code>, <code>rfGA</code> and
<code>treebagGA</code> by Max Kuhn
</p>


<h3>References</h3>

<p>Scrucca L (2013). GA: A Package for Genetic Algorithms in R.
Journal of Statistical Software, 53(4), 1-37.
</p>
<p><a href="https://cran.r-project.org/package=GA">https://cran.r-project.org/package=GA</a>
</p>
<p><a href="http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html">http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gafs">gafs</a></code>, <code><a href="#topic+gafsControl">gafsControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
pop &lt;- gafs_initial(vars = 10, popSize = 10)
pop

gafs_lrSelection(population = pop, fitness = 1:10)

gafs_spCrossover(population = pop, fitness = 1:10, parents = 1:2)


## Not run: 
## Hypothetical examples
lda_ga &lt;- gafs(x = predictors,
               y = classes,
               gafsControl = gafsControl(functions = caretGA),
               ## now pass arguments to `train`
               method = "lda",
               metric = "Accuracy"
               trControl = trainControl(method = "cv", classProbs = TRUE))

rf_ga &lt;- gafs(x = predictors,
              y = classes,
              gafsControl = gafsControl(functions = rfGA),
              ## these are arguments to `randomForest`
              ntree = 1000,
              importance = TRUE)
	
## End(Not run)


</code></pre>

<hr>
<h2 id='gafs.default'>Genetic algorithm feature selection</h2><span id='topic+gafs.default'></span><span id='topic+gafs'></span><span id='topic+gafs.recipe'></span>

<h3>Description</h3>

<p>Supervised feature selection using genetic algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
gafs(
  x,
  y,
  iters = 10,
  popSize = 50,
  pcrossover = 0.8,
  pmutation = 0.1,
  elite = 0,
  suggestions = NULL,
  differences = TRUE,
  gafsControl = gafsControl(),
  ...
)

## S3 method for class 'recipe'
gafs(
  x,
  data,
  iters = 10,
  popSize = 50,
  pcrossover = 0.8,
  pmutation = 0.1,
  elite = 0,
  suggestions = NULL,
  differences = TRUE,
  gafsControl = gafsControl(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gafs.default_+3A_x">x</code></td>
<td>
<p>An object where samples are in rows and features are in columns.
This could be a simple matrix, data frame or other type (e.g. sparse
matrix). For the recipes method, <code>x</code> is a recipe object. See Details below</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_y">y</code></td>
<td>
<p>a numeric or factor vector containing the outcome for each sample</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_iters">iters</code></td>
<td>
<p>number of search iterations</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_popsize">popSize</code></td>
<td>
<p>number of subsets evaluated at each iteration</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_pcrossover">pcrossover</code></td>
<td>
<p>the crossover probability</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_pmutation">pmutation</code></td>
<td>
<p>the mutation probability</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_elite">elite</code></td>
<td>
<p>the number of best subsets to survive at each generation</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_suggestions">suggestions</code></td>
<td>
<p>a binary matrix of subsets strings to be included in the
initial population. If provided the number of columns must match the number
of columns in <code>x</code></p>
</td></tr>
<tr><td><code id="gafs.default_+3A_differences">differences</code></td>
<td>
<p>a logical: should the difference in fitness values with
and without each predictor be calculated?</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_gafscontrol">gafsControl</code></td>
<td>
<p>a list of values that define how this function acts. See
<code><a href="#topic+gafsControl">gafsControl</a></code> and URL.</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to other methods</p>
</td></tr>
<tr><td><code id="gafs.default_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in
<code>formula</code> or <code>recipe</code> are preferentially to be taken.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+gafs">gafs</a></code> conducts a supervised binary search of the predictor
space using a genetic algorithm. See Mitchell (1996) and Scrucca (2013) for
more details on genetic algorithms.
</p>
<p>This function conducts the search of the feature space repeatedly within
resampling iterations. First, the training data are split be whatever
resampling method was specified in the control function. For example, if
10-fold cross-validation is selected, the entire genetic algorithm is
conducted 10 separate times. For the first fold, nine tenths of the data are
used in the search while the remaining tenth is used to estimate the
external performance since these data points were not used in the search.
</p>
<p>During the genetic algorithm, a measure of fitness is needed to guide the
search. This is the internal measure of performance. During the search, the
data that are available are the instances selected by the top-level
resampling (e.g. the nine tenths mentioned above). A common approach is to
conduct another resampling procedure. Another option is to use a holdout set
of samples to determine the internal estimate of performance (see the
holdout argument of the control function). While this is faster, it is more
likely to cause overfitting of the features and should only be used when a
large amount of training data are available. Yet another idea is to use a
penalized metric (such as the AIC statistic) but this may not exist for some
metrics (e.g. the area under the ROC curve).
</p>
<p>The internal estimates of performance will eventually overfit the subsets to
the data. However, since the external estimate is not used by the search, it
is able to make better assessments of overfitting. After resampling, this
function determines the optimal number of generations for the GA.
</p>
<p>Finally, the entire data set is used in the last execution of the genetic
algorithm search and the final model is built on the predictor subset that
is associated with the optimal number of generations determined by
resampling (although the update function can be used to manually set the
number of generations).
</p>
<p>This is an example of the output produced when <code>gafsControl(verbose =
TRUE)</code> is used:
</p>
<pre>
Fold2 1 0.715 (13)
Fold2 2 0.715-&gt;0.737 (13-&gt;17, 30.4%) *
Fold2 3 0.737-&gt;0.732 (17-&gt;14, 24.0%)
Fold2 4 0.737-&gt;0.769 (17-&gt;23, 25.0%) *
</pre>
<p>For the second resample (e.g. fold 2), the best subset across all
individuals tested in the first generation contained 13 predictors and was
associated with a fitness value of 0.715. The second generation produced a
better subset containing 17 samples with an associated fitness values of
0.737 (and improvement is symbolized by the <code>*</code>. The percentage listed
is the Jaccard similarity between the previous best individual (with 13
predictors) and the new best. The third generation did not produce a better
fitness value but the fourth generation did.
</p>
<p>The search algorithm can be parallelized in several places: </p>

<ol>
<li><p> each externally resampled GA can be run independently (controlled by
the <code>allowParallel</code> option of <code><a href="#topic+gafsControl">gafsControl</a></code>) </p>
</li>
<li><p> within a
GA, the fitness calculations at a particular generation can be run in
parallel over the current set of individuals (see the <code>genParallel</code>
option in <code><a href="#topic+gafsControl">gafsControl</a></code>) </p>
</li>
<li><p> if inner resampling is used,
these can be run in parallel (controls depend on the function used. See, for
example, <code><a href="#topic+trainControl">trainControl</a></code>) </p>
</li>
<li><p> any parallelization of the
individual model fits. This is also specific to the modeling function.  </p>
</li></ol>

<p>It is probably best to pick one of these areas for parallelization and the
first is likely to produces the largest decrease in run-time since it is the
least likely to incur multiple re-starting of the worker processes. Keep in
mind that if multiple levels of parallelization occur, this can effect the
number of workers and the amount of memory required exponentially.
</p>


<h3>Value</h3>

<p>an object of class <code>gafs</code>
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, Luca Scrucca (for GA internals)
</p>


<h3>References</h3>

<p>Kuhn M and Johnson K (2013), Applied Predictive Modeling,
Springer, Chapter 19 <a href="http://appliedpredictivemodeling.com">http://appliedpredictivemodeling.com</a>
</p>
<p>Scrucca L (2013). GA: A Package for Genetic Algorithms in R. Journal of
Statistical Software, 53(4), 1-37. <a href="https://www.jstatsoft.org/article/view/v053i04">https://www.jstatsoft.org/article/view/v053i04</a>
</p>
<p>Mitchell M (1996), An Introduction to Genetic Algorithms, MIT Press.
</p>
<p><a href="https://en.wikipedia.org/wiki/Jaccard_index">https://en.wikipedia.org/wiki/Jaccard_index</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gafsControl">gafsControl</a></code>, <code><a href="#topic+predict.gafs">predict.gafs</a></code>,
<code><a href="#topic+caretGA">caretGA</a></code>, <code><a href="#topic+rfGA">rfGA</a></code> <code><a href="#topic+treebagGA">treebagGA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(1)
train_data &lt;- twoClassSim(100, noiseVars = 10)
test_data  &lt;- twoClassSim(10,  noiseVars = 10)

## A short example
ctrl &lt;- gafsControl(functions = rfGA,
                    method = "cv",
                    number = 3)

rf_search &lt;- gafs(x = train_data[, -ncol(train_data)],
                  y = train_data$Class,
                  iters = 3,
                  gafsControl = ctrl)

rf_search
  
## End(Not run)

</code></pre>

<hr>
<h2 id='gafsControl'>Control parameters for GA and SA feature selection</h2><span id='topic+gafsControl'></span><span id='topic+safsControl'></span>

<h3>Description</h3>

<p>Control the computational nuances of the <code><a href="#topic+gafs">gafs</a></code> and
<code><a href="#topic+safs">safs</a></code> functions
</p>
<p>Many of these options are the same as those described for
<code><a href="#topic+trainControl">trainControl</a></code>. More extensive documentation and examples
can be found on the <span class="pkg">caret</span> website at
<a href="http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html#syntax">http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html#syntax</a> and
<a href="http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html#syntax">http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html#syntax</a>.
</p>
<p>The <code>functions</code> component contains the information about how the model
should be fit and summarized. It also contains the elements needed for the
GA and SA modules (e.g. cross-over, etc).
</p>
<p>The elements of <code>functions</code> that are the same for GAs and SAs are:
</p>

<ul>
<li> <p><code>fit</code>, with arguments <code>x</code>, <code>y</code>, <code>lev</code>,
<code>last</code>, and <code>...</code>, is used to fit the classification or regression
model
</p>
</li>
<li> <p><code>pred</code>, with arguments <code>object</code> and <code>x</code>, predicts
new samples
</p>
</li>
<li> <p><code>fitness_intern</code>, with arguments <code>object</code>,
<code>x</code>, <code>y</code>, <code>maximize</code>, and <code>p</code>, summarizes performance
for the internal estimates of fitness
</p>
</li>
<li> <p><code>fitness_extern</code>, with
arguments <code>data</code>, <code>lev</code>, and <code>model</code>, summarizes performance
using the externally held-out samples
</p>
</li>
<li> <p><code>selectIter</code>, with
arguments <code>x</code>, <code>metric</code>, and <code>maximize</code>, determines the best
search iteration for feature selection.
</p>
</li></ul>

<p>The elements of <code>functions</code> specific to genetic algorithms are:
</p>

<ul>
<li> <p><code>initial</code>, with arguments <code>vars</code>, <code>popSize</code>
and <code>...</code>, creates an initial population.
</p>
</li>
<li> <p><code>selection</code>, with
arguments <code>population</code>, <code>fitness</code>, <code>r</code>, <code>q</code>, and
<code>...</code>, conducts selection of individuals.
</p>
</li>
<li> <p><code>crossover</code>, with
arguments <code>population</code>, <code>fitness</code>, <code>parents</code> and <code>...</code>,
control genetic reproduction.
</p>
</li>
<li> <p><code>mutation</code>, with arguments
<code>population</code>, <code>parent</code> and <code>...</code>, adds mutations.
</p>
</li></ul>

<p>The elements of <code>functions</code> specific to simulated annealing are:
</p>

<ul>
<li> <p><code>initial</code>, with arguments <code>vars</code>, <code>prob</code>, and
<code>...</code>, creates the initial subset.
</p>
</li>
<li> <p><code>perturb</code>, with
arguments <code>x</code>, <code>vars</code>, and <code>number</code>, makes incremental
changes to the subsets.
</p>
</li>
<li> <p><code>prob</code>, with arguments <code>old</code>,
<code>new</code>, and <code>iteration</code>, computes the acceptance probabilities
</p>
</li></ul>

<p>The pages <a href="http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html">http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html</a> and
<a href="http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html">http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html</a> have more details about each of
these functions.
</p>
<p><code>holdout</code> can be used to hold out samples for computing the internal
fitness value. Note that this is independent of the external resampling
step. Suppose 10-fold CV is being used. Within a resampling iteration,
<code>holdout</code> can be used to sample an additional proportion of the 90%
resampled data to use for estimating fitness. This may not be a good idea
unless you have a very large training set and want to avoid an internal
resampling procedure to estimate fitness.
</p>
<p>The search algorithms can be parallelized in several places:
</p>

<ol>
<li><p> each externally resampled GA or SA can be run independently
(controlled by the <code>allowParallel</code> options)
</p>
</li>
<li><p> within a GA, the
fitness calculations at a particular generation can be run in parallel over
the current set of individuals (see the <code>genParallel</code>)
</p>
</li>
<li><p> if inner resampling is used, these can be run in parallel (controls depend on the
function used. See, for example, <code><a href="#topic+trainControl">trainControl</a></code>)
</p>
</li>
<li><p> any parallelization of the individual model fits. This is also specific to the modeling function.
</p>
</li></ol>

<p>It is probably best to pick one of these areas for parallelization and the
first is likely to produces the largest decrease in run-time since it is the
least likely to incur multiple re-starting of the worker processes. Keep in
mind that if multiple levels of parallelization occur, this can effect the
number of workers and the amount of memory required exponentially.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gafsControl(
  functions = NULL,
  method = "repeatedcv",
  metric = NULL,
  maximize = NULL,
  number = ifelse(grepl("cv", method), 10, 25),
  repeats = ifelse(grepl("cv", method), 1, 5),
  verbose = FALSE,
  returnResamp = "final",
  p = 0.75,
  index = NULL,
  indexOut = NULL,
  seeds = NULL,
  holdout = 0,
  genParallel = FALSE,
  allowParallel = TRUE
)

safsControl(
  functions = NULL,
  method = "repeatedcv",
  metric = NULL,
  maximize = NULL,
  number = ifelse(grepl("cv", method), 10, 25),
  repeats = ifelse(grepl("cv", method), 1, 5),
  verbose = FALSE,
  returnResamp = "final",
  p = 0.75,
  index = NULL,
  indexOut = NULL,
  seeds = NULL,
  holdout = 0,
  improve = Inf,
  allowParallel = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gafsControl_+3A_functions">functions</code></td>
<td>
<p>a list of functions for model fitting, prediction etc (see
Details below)</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_method">method</code></td>
<td>
<p>The resampling method: <code>boot</code>, <code>boot632</code>, <code>cv</code>,
<code>repeatedcv</code>, <code>LOOCV</code>, <code>LGOCV</code> (for repeated training/test
splits)</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_metric">metric</code></td>
<td>
<p>a two-element string that specifies what summary metric will
be used to select the optimal number of iterations from the external fitness
value and which metric should guide subset selection. If specified, this
vector should have names <code>"internal"</code> and <code>"external"</code>. See
<code><a href="#topic+gafs">gafs</a></code> and/or <code><a href="#topic+safs">safs</a></code> for explanations of the
difference.</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_maximize">maximize</code></td>
<td>
<p>a two-element logical: should the metrics be maximized or
minimized? Like the <code>metric</code> argument, this this vector should have
names <code>"internal"</code> and <code>"external"</code>.</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_number">number</code></td>
<td>
<p>Either the number of folds or number of resampling iterations</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_repeats">repeats</code></td>
<td>
<p>For repeated k-fold cross-validation only: the number of
complete sets of folds to compute</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_verbose">verbose</code></td>
<td>
<p>a logical for printing results</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_returnresamp">returnResamp</code></td>
<td>
<p>A character string indicating how much of the resampled
summary metrics should be saved. Values can be &ldquo;all&rdquo; or &ldquo;none&rdquo;</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_p">p</code></td>
<td>
<p>For leave-group out cross-validation: the training percentage</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_index">index</code></td>
<td>
<p>a list with elements for each resampling iteration. Each list
element is the sample rows used for training at that iteration.</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_indexout">indexOut</code></td>
<td>
<p>a list (the same length as <code>index</code>) that dictates which
sample are held-out for each resample. If <code>NULL</code>, then the unique set
of samples not contained in <code>index</code> is used.</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_seeds">seeds</code></td>
<td>
<p>a vector or integers that can be used to set the seed during
each search. The number of seeds must be equal to the number of resamples
plus one.</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_holdout">holdout</code></td>
<td>
<p>the proportion of data in [0, 1) to be held-back from
<code>x</code> and <code>y</code> to calculate the internal fitness values</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_genparallel">genParallel</code></td>
<td>
<p>if a parallel backend is loaded and available, should
<code><a href="#topic+gafs">gafs</a></code> use it tp parallelize the fitness calculations within a
generation within a resample?</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_allowparallel">allowParallel</code></td>
<td>
<p>if a parallel backend is loaded and available, should
the function use it?</p>
</td></tr>
<tr><td><code id="gafsControl_+3A_improve">improve</code></td>
<td>
<p>the number of iterations without improvement before
<code><a href="#topic+safs">safs</a></code> reverts back to the previous optimal subset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An echo of the parameters specified
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p><a href="http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html">http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html</a>,
<a href="http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html">http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+safs">safs</a></code>, <code><a href="#topic+safs">safs</a></code>, , <code><a href="#topic+caretGA">caretGA</a></code>,
<code><a href="#topic+rfGA">rfGA</a></code>, <code><a href="#topic+treebagGA">treebagGA</a></code>, <code><a href="#topic+caretSA">caretSA</a></code>,
<code><a href="#topic+rfSA">rfSA</a></code>, <code><a href="#topic+treebagSA">treebagSA</a></code>
</p>

<hr>
<h2 id='GermanCredit'>German Credit Data</h2><span id='topic+GermanCredit'></span>

<h3>Description</h3>

<p>Data from Dr. Hans Hofmann of the University of Hamburg.
</p>


<h3>Details</h3>

<p>These data have two classes for the credit worthiness: good or bad. There
are predictors related to attributes, such as: checking account status,
duration, credit history, purpose of the loan, amount of the loan, savings
accounts or bonds, employment duration, Installment rate in percentage of
disposable income, personal information, other debtors/guarantors, residence
duration, property, age, other installment plans, housing, number of
existing credits, job information, Number of people being liable to provide
maintenance for, telephone, and foreign worker status.
</p>
<p>Many of these predictors are discrete and have been expanded into several
0/1 indicator variables
</p>


<h3>Source</h3>

<p>UCI Machine Learning Repository
</p>

<hr>
<h2 id='getSamplingInfo'>Get sampling info from a train model</h2><span id='topic+getSamplingInfo'></span>

<h3>Description</h3>

<p>Placeholder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSamplingInfo(method = NULL, regex = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getSamplingInfo_+3A_method">method</code></td>
<td>
<p>Modeling method.</p>
</td></tr>
<tr><td><code id="getSamplingInfo_+3A_regex">regex</code></td>
<td>
<p>Whether to use regex matching.</p>
</td></tr>
<tr><td><code id="getSamplingInfo_+3A_...">...</code></td>
<td>
<p>additional arguments to passed to grepl.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Placeholder.
</p>


<h3>Value</h3>

<p>A list
</p>

<hr>
<h2 id='ggplot.rfe'>Plot RFE Performance Profiles</h2><span id='topic+ggplot.rfe'></span><span id='topic+plot.rfe'></span>

<h3>Description</h3>

<p>These functions plot the resampling results for the candidate subset sizes
evaluated during the recursive feature elimination (RFE) process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rfe'
ggplot(
  data = NULL,
  mapping = NULL,
  metric = data$metric[1],
  output = "layered",
  ...,
  environment = NULL
)

## S3 method for class 'rfe'
plot(x, metric = x$metric, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggplot.rfe_+3A_data">data</code></td>
<td>
<p>an object of class <code><a href="#topic+rfe">rfe</a></code>.</p>
</td></tr>
<tr><td><code id="ggplot.rfe_+3A_mapping">mapping</code>, <code id="ggplot.rfe_+3A_environment">environment</code></td>
<td>
<p>unused arguments to make consistent with
<span class="pkg">ggplot2</span> generic method</p>
</td></tr>
<tr><td><code id="ggplot.rfe_+3A_metric">metric</code></td>
<td>
<p>What measure of performance to plot. Examples of possible
values are &quot;RMSE&quot;, &quot;Rsquared&quot;, &quot;Accuracy&quot; or &quot;Kappa&quot;. Other values can be
used depending on what metrics have been calculated.</p>
</td></tr>
<tr><td><code id="ggplot.rfe_+3A_output">output</code></td>
<td>
<p>either &quot;data&quot;, &quot;ggplot&quot; or &quot;layered&quot;. The first returns a data
frame while the second returns a simple <code>ggplot</code> object with no layers.
The third value returns a plot with a set of layers.</p>
</td></tr>
<tr><td><code id="ggplot.rfe_+3A_...">...</code></td>
<td>
<p><code>plot</code> only: specifications to be passed to
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>. The function automatically sets some
arguments (e.g. axis labels) but passing in values here will over-ride the
defaults.</p>
</td></tr>
<tr><td><code id="ggplot.rfe_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+rfe">rfe</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These plots show the average performance versus the subset sizes.
</p>


<h3>Value</h3>

<p>a lattice or ggplot object
</p>


<h3>Note</h3>

<p>We using a recipe as an input, there may be some subset sizes that are
not well-replicated over resamples. The 'ggplot' method will only show
subset sizes where at least half of the resamples have associated results.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Kuhn (2008), &ldquo;Building Predictive Models in R Using the caret&rdquo;
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rfe">rfe</a></code>, <code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(BloodBrain)

x &lt;- scale(bbbDescr[,-nearZeroVar(bbbDescr)])
x &lt;- x[, -findCorrelation(cor(x), .8)]
x &lt;- as.data.frame(x, stringsAsFactors = TRUE)

set.seed(1)
lmProfile &lt;- rfe(x, logBBB,
                 sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65),
                 rfeControl = rfeControl(functions = lmFuncs,
                                         number = 200))
plot(lmProfile)
plot(lmProfile, metric = "Rsquared")
ggplot(lmProfile)

## End(Not run)
</code></pre>

<hr>
<h2 id='ggplot.train'>Plot Method for the train Class</h2><span id='topic+ggplot.train'></span><span id='topic+plot.train'></span>

<h3>Description</h3>

<p>This function takes the output of a <code><a href="#topic+train">train</a></code> object and creates a
line or level plot using the <span class="pkg">lattice</span> or <span class="pkg">ggplot2</span> libraries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'train'
ggplot(
  data = NULL,
  mapping = NULL,
  metric = data$metric[1],
  plotType = "scatter",
  output = "layered",
  nameInStrip = FALSE,
  highlight = FALSE,
  ...,
  environment = NULL
)

## S3 method for class 'train'
plot(
  x,
  plotType = "scatter",
  metric = x$metric[1],
  digits = getOption("digits") - 3,
  xTrans = NULL,
  nameInStrip = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggplot.train_+3A_data">data</code></td>
<td>
<p>an object of class <code><a href="#topic+train">train</a></code>.</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_mapping">mapping</code>, <code id="ggplot.train_+3A_environment">environment</code></td>
<td>
<p>unused arguments to make consistent with
<span class="pkg">ggplot2</span> generic method</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_metric">metric</code></td>
<td>
<p>What measure of performance to plot. Examples of possible
values are &quot;RMSE&quot;, &quot;Rsquared&quot;, &quot;Accuracy&quot; or &quot;Kappa&quot;. Other values can be
used depending on what metrics have been calculated.</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_plottype">plotType</code></td>
<td>
<p>a string describing the type of plot (<code>"scatter"</code>,
<code>"level"</code> or <code>"line"</code> (<code>plot</code> only))</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_output">output</code></td>
<td>
<p>either &quot;data&quot;, &quot;ggplot&quot; or &quot;layered&quot;. The first returns a data
frame while the second returns a simple <code>ggplot</code> object with no layers.
The third value returns a plot with a set of layers.</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_nameinstrip">nameInStrip</code></td>
<td>
<p>a logical: if there are more than 2 tuning parameters,
should the name and value be included in the panel title?</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_highlight">highlight</code></td>
<td>
<p>a logical: if <code>TRUE</code>, a diamond is placed around the
optimal parameter setting for models using grid search.</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_...">...</code></td>
<td>
<p><code>plot</code> only: specifications to be passed to
<code><a href="lattice.html#topic+levelplot">levelplot</a></code>, <code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="lattice.html#topic+xyplot">stripplot</a></code> (for line plots). The function
automatically sets some arguments (e.g. axis labels) but passing in values
here will over-ride the defaults</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+train">train</a></code>.</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_digits">digits</code></td>
<td>
<p>an integer specifying the number of significant digits used to
label the parameter value.</p>
</td></tr>
<tr><td><code id="ggplot.train_+3A_xtrans">xTrans</code></td>
<td>
<p>a function that will be used to scale the x-axis in scatter
plots.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are no tuning parameters, or none were varied, an error is
produced.
</p>
<p>If the model has one tuning parameter with multiple candidate values, a plot
is produced showing the profile of the results over the parameter. Also, a
plot can be produced if there are multiple tuning parameters but only one is
varied.
</p>
<p>If there are two tuning parameters with different values, a plot can be
produced where a different line is shown for each value of of the other
parameter. For three parameters, the same line plot is created within
conditioning panels/facets of the other parameter.
</p>
<p>Also, with two tuning parameters (with different values), a levelplot (i.e.
un-clustered heatmap) can be created. For more than two parameters, this
plot is created inside conditioning panels/facets.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Kuhn (2008), &ldquo;Building Predictive Models in R Using the caret&rdquo;
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>, <code><a href="lattice.html#topic+levelplot">levelplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>, <code><a href="lattice.html#topic+xyplot">stripplot</a></code>,
<code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
library(klaR)
rdaFit &lt;- train(Species ~ .,
                data = iris,
                method = "rda",
                control = trainControl(method = "cv"))
plot(rdaFit)
plot(rdaFit, plotType = "level")

ggplot(rdaFit) + theme_bw()


## End(Not run)

</code></pre>

<hr>
<h2 id='histogram.train'>Lattice functions for plotting resampling results</h2><span id='topic+histogram.train'></span><span id='topic+stripplot.train'></span><span id='topic+xyplot.train'></span><span id='topic+densityplot.train'></span>

<h3>Description</h3>

<p>A set of lattice functions are provided to plot the resampled performance
estimates (e.g. classification accuracy, RMSE) over tuning parameters (if
any).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'train'
histogram(x, data = NULL, metric = x$metric, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="histogram.train_+3A_x">x</code></td>
<td>
<p>An object produced by <code><a href="#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="histogram.train_+3A_data">data</code></td>
<td>
<p>This argument is not used</p>
</td></tr>
<tr><td><code id="histogram.train_+3A_metric">metric</code></td>
<td>
<p>A character string specifying the single performance metric
that will be plotted</p>
</td></tr>
<tr><td><code id="histogram.train_+3A_...">...</code></td>
<td>
<p>arguments to pass to either
<code><a href="lattice.html#topic+histogram">histogram</a></code>,
<code><a href="lattice.html#topic+histogram">densityplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code> or
<code><a href="lattice.html#topic+xyplot">stripplot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, only the resampling results for the optimal model are saved in
the <code>train</code> object. The function <code><a href="#topic+trainControl">trainControl</a></code> can be used
to save all the results (see the example below).
</p>
<p>If leave-one-out or out-of-bag resampling was specified, plots cannot be
produced (see the <code>method</code> argument of <code><a href="#topic+trainControl">trainControl</a></code>)
</p>
<p>For <code>xyplot</code> and <code>stripplot</code>, the tuning parameter with the most
unique values will be plotted on the x-axis. The remaining parameters (if
any) will be used as conditioning variables. For <code>densityplot</code> and
<code>histogram</code>, all tuning parameters are used for conditioning.
</p>
<p>Using <code>horizontal = FALSE</code> in <code>stripplot</code> works.
</p>


<h3>Value</h3>

<p>A lattice plot object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>, <code><a href="#topic+trainControl">trainControl</a></code>,
<code><a href="lattice.html#topic+histogram">histogram</a></code>,
<code><a href="lattice.html#topic+histogram">densityplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="lattice.html#topic+xyplot">stripplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

library(mlbench)
data(BostonHousing)

library(rpart)
rpartFit &lt;- train(medv ~ .,
                  data = BostonHousing,
                  "rpart", 
                  tuneLength = 9,
                  trControl = trainControl(
                    method = "boot", 
                    returnResamp = "all"))

densityplot(rpartFit,
            adjust = 1.25)

xyplot(rpartFit,
       metric = "Rsquared",
       type = c("p", "a"))

stripplot(rpartFit,
          horizontal = FALSE,
          jitter = TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='icr.formula'>Independent Component Regression</h2><span id='topic+icr.formula'></span><span id='topic+icr.default'></span><span id='topic+icr'></span><span id='topic+predict.icr'></span>

<h3>Description</h3>

<p>Fit a linear regression model using independent components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
icr(formula, data, weights, ..., subset, na.action, contrasts = NULL)

## Default S3 method:
icr(x, y, ...)

## S3 method for class 'icr'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icr.formula_+3A_formula">formula</code></td>
<td>
<p>A formula of the form <code>class ~ x1 + x2 + ...{}</code></p>
</td></tr>
<tr><td><code id="icr.formula_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in <code>formula</code> are
preferentially to be taken.</p>
</td></tr>
<tr><td><code id="icr.formula_+3A_weights">weights</code></td>
<td>
<p>(case) weights for each example - if missing defaults to 1.</p>
</td></tr>
<tr><td><code id="icr.formula_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="fastICA.html#topic+fastICA">fastICA</a></code></p>
</td></tr>
<tr><td><code id="icr.formula_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the
training sample.  (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="icr.formula_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if <code>NA</code>s
are found. The default action is for the procedure to fail.  An alternative
is na.omit, which leads to rejection of cases with missing values on any
required variable.  (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="icr.formula_+3A_contrasts">contrasts</code></td>
<td>
<p>a list of contrasts to be used for some or all of the
factors appearing as variables in the model formula.</p>
</td></tr>
<tr><td><code id="icr.formula_+3A_x">x</code></td>
<td>
<p>matrix or data frame of <code>x</code> values for examples.</p>
</td></tr>
<tr><td><code id="icr.formula_+3A_y">y</code></td>
<td>
<p>matrix or data frame of target values for examples.</p>
</td></tr>
<tr><td><code id="icr.formula_+3A_object">object</code></td>
<td>
<p>an object of class <code>icr</code> as returned by <code>icr</code>.</p>
</td></tr>
<tr><td><code id="icr.formula_+3A_newdata">newdata</code></td>
<td>
<p>matrix or data frame of test examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This produces a model analogous to Principal Components Regression (PCR) but
uses Independent Component Analysis (ICA) to produce the scores. The user
must specify a value of <code>n.comp</code> to pass to
<code><a href="fastICA.html#topic+fastICA">fastICA</a></code>.
</p>
<p>The function <code><a href="#topic+preProcess">preProcess</a></code> to produce the ICA scores for the
original data and for <code>newdata</code>.
</p>


<h3>Value</h3>

<p>For <code>icr</code>, a list with elements </p>
<table>
<tr><td><code>model</code></td>
<td>
<p>the results of
<code><a href="stats.html#topic+lm">lm</a></code> after the ICA transformation</p>
</td></tr> <tr><td><code>ica</code></td>
<td>
<p>pre-processing information</p>
</td></tr> <tr><td><code>n.comp</code></td>
<td>
<p>number of ICA components</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>column names of the original data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="fastICA.html#topic+fastICA">fastICA</a></code>, <code><a href="#topic+preProcess">preProcess</a></code>,
<code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BloodBrain)

icrFit &lt;- icr(bbbDescr, logBBB, n.comp = 5)

icrFit

predict(icrFit, bbbDescr[1:5,])
</code></pre>

<hr>
<h2 id='index2vec'>Convert indicies to a binary vector</h2><span id='topic+index2vec'></span>

<h3>Description</h3>

<p>The function performs the opposite of <code>which</code> converting a set of
integers to a binary vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>index2vec(x, vars, sign = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="index2vec_+3A_x">x</code></td>
<td>
<p>a vector of integers</p>
</td></tr>
<tr><td><code id="index2vec_+3A_vars">vars</code></td>
<td>
<p>the number of possible locations</p>
</td></tr>
<tr><td><code id="index2vec_+3A_sign">sign</code></td>
<td>
<p>a lgical; when true the data are encoded as -1/+1, and 0/1
otherwise</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
index2vec(x = 1:2, vars = 5)
index2vec(x = 1:2, vars = 5, sign = TRUE)

</code></pre>

<hr>
<h2 id='knn3'>k-Nearest Neighbour Classification</h2><span id='topic+knn3'></span><span id='topic+knn3.formula'></span><span id='topic+knn3.matrix'></span><span id='topic+knn3.data.frame'></span><span id='topic+knn3Train'></span><span id='topic+print.knn3'></span>

<h3>Description</h3>

<p>$k$-nearest neighbour classification that can return class votes for all
classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn3(x, ...)

## S3 method for class 'formula'
knn3(formula, data, subset, na.action, k = 5, ...)

## S3 method for class 'data.frame'
knn3(x, y, k = 5, ...)

## S3 method for class 'matrix'
knn3(x, y, k = 5, ...)

## S3 method for class 'knn3'
print(x, ...)

knn3Train(train, test, cl, k = 1, l = 0, prob = TRUE, use.all = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knn3_+3A_x">x</code></td>
<td>
<p>a matrix of training set predictors</p>
</td></tr>
<tr><td><code id="knn3_+3A_...">...</code></td>
<td>
<p>additional parameters to pass to <code>knn3Train</code>. However,
passing <code>prob = FALSE</code> will be over-ridden.</p>
</td></tr>
<tr><td><code id="knn3_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> is
the response variable and <code>rhs</code> a set of predictors.</p>
</td></tr>
<tr><td><code id="knn3_+3A_data">data</code></td>
<td>
<p>optional data frame containing the variables in the model
formula.</p>
</td></tr>
<tr><td><code id="knn3_+3A_subset">subset</code></td>
<td>
<p>optional vector specifying a subset of observations to be
used.</p>
</td></tr>
<tr><td><code id="knn3_+3A_na.action">na.action</code></td>
<td>
<p>function which indicates what should happen when the data
contain <code>NA</code>s.</p>
</td></tr>
<tr><td><code id="knn3_+3A_k">k</code></td>
<td>
<p>number of neighbours considered.</p>
</td></tr>
<tr><td><code id="knn3_+3A_y">y</code></td>
<td>
<p>a factor vector of training set classes</p>
</td></tr>
<tr><td><code id="knn3_+3A_train">train</code></td>
<td>
<p>matrix or data frame of training set cases.</p>
</td></tr>
<tr><td><code id="knn3_+3A_test">test</code></td>
<td>
<p>matrix or data frame of test set cases. A vector will be
interpreted as a row vector for a single case.</p>
</td></tr>
<tr><td><code id="knn3_+3A_cl">cl</code></td>
<td>
<p>factor of true classifications of training set</p>
</td></tr>
<tr><td><code id="knn3_+3A_l">l</code></td>
<td>
<p>minimum vote for definite decision, otherwise <code>doubt</code>. (More
precisely, less than <code>k-l</code> dissenting votes are allowed, even if
<code>k</code> is increased by ties.)</p>
</td></tr>
<tr><td><code id="knn3_+3A_prob">prob</code></td>
<td>
<p>If this is true, the proportion of the votes for each class are
returned as attribute <code>prob</code>.</p>
</td></tr>
<tr><td><code id="knn3_+3A_use.all">use.all</code></td>
<td>
<p>controls handling of ties. If true, all distances equal to
the <code>k</code>th largest are included. If false, a random selection of
distances equal to the <code>k</code>th is chosen to use exactly <code>k</code>
neighbours.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>knn3</code> is essentially the same code as <code><a href="ipred.html#topic+ipredknn">ipredknn</a></code>
and <code>knn3Train</code> is a copy of <code><a href="class.html#topic+knn">knn</a></code>. The underlying C
code from the <code>class</code> package has been modified to return the vote
percentages for each class (previously the percentage for the winning class
was returned).
</p>


<h3>Value</h3>

<p>An object of class <code>knn3</code>. See <code><a href="#topic+predict.knn3">predict.knn3</a></code>.
</p>


<h3>Author(s)</h3>

<p><code><a href="class.html#topic+knn">knn</a></code> by W. N. Venables and B. D. Ripley and
<code><a href="ipred.html#topic+ipredknn">ipredknn</a></code> by Torsten.Hothorn
&lt;Torsten.Hothorn@rzmail.uni-erlangen.de&gt;, modifications by Max Kuhn and
Andre Williams
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
irisFit1 &lt;- knn3(Species ~ ., iris)

irisFit2 &lt;- knn3(as.matrix(iris[, -5]), iris[,5])

data(iris3)
train &lt;- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])
test &lt;- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
cl &lt;- factor(c(rep("s",25), rep("c",25), rep("v",25)))
knn3Train(train, test, cl, k = 5, prob = TRUE)

</code></pre>

<hr>
<h2 id='knnreg'>k-Nearest Neighbour Regression</h2><span id='topic+knnreg'></span><span id='topic+knnregTrain'></span><span id='topic+knnreg.formula'></span><span id='topic+knnreg.default'></span><span id='topic+knnreg.matrix'></span><span id='topic+knnreg.data.frame'></span><span id='topic+print.knnreg'></span>

<h3>Description</h3>

<p>$k$-nearest neighbour regression that can return the average value for the
neighbours.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knnreg(x, ...)

## Default S3 method:
knnreg(x, ...)

## S3 method for class 'formula'
knnreg(formula, data, subset, na.action, k = 5, ...)

## S3 method for class 'matrix'
knnreg(x, y, k = 5, ...)

## S3 method for class 'data.frame'
knnreg(x, y, k = 5, ...)

## S3 method for class 'knnreg'
print(x, ...)

knnregTrain(train, test, y, k = 5, use.all = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knnreg_+3A_x">x</code></td>
<td>
<p>a matrix or data frame of training set predictors.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_...">...</code></td>
<td>
<p>additional parameters to pass to <code>knnregTrain</code>.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> is
the response variable and <code>rhs</code> a set of predictors.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_data">data</code></td>
<td>
<p>optional data frame containing the variables in the model
formula.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_subset">subset</code></td>
<td>
<p>optional vector specifying a subset of observations to be
used.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_na.action">na.action</code></td>
<td>
<p>function which indicates what should happen when the data
contain <code>NA</code>s.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_k">k</code></td>
<td>
<p>number of neighbours considered.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_y">y</code></td>
<td>
<p>a numeric vector of outcomes.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_train">train</code></td>
<td>
<p>matrix or data frame of training set cases.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_test">test</code></td>
<td>
<p>matrix or data frame of test set cases. A vector will be
interpreted as a row vector for a single case.</p>
</td></tr>
<tr><td><code id="knnreg_+3A_use.all">use.all</code></td>
<td>
<p>controls handling of ties. If true, all distances equal to
the <code>k</code>th largest are included. If false, a random selection of
distances equal to the <code>k</code>th is chosen to use exactly <code>k</code>
neighbours.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>knnreg</code> is similar to <code><a href="ipred.html#topic+ipredknn">ipredknn</a></code> and
<code>knnregTrain</code> is a modification of <code><a href="class.html#topic+knn">knn</a></code>. The
underlying C code from the <code>class</code> package has been modified to return
average outcome.
</p>


<h3>Value</h3>

<p>An object of class <code>knnreg</code>. See <code><a href="#topic+predict.knnreg">predict.knnreg</a></code>.
</p>


<h3>Author(s)</h3>

<p><code><a href="class.html#topic+knn">knn</a></code> by W. N. Venables and B. D. Ripley and
<code><a href="ipred.html#topic+ipredknn">ipredknn</a></code> by Torsten.Hothorn
&lt;Torsten.Hothorn@rzmail.uni-erlangen.de&gt;, modifications by Max Kuhn and
Chris Keefer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BloodBrain)

inTrain &lt;- createDataPartition(logBBB, p = .8)[[1]]

trainX &lt;- bbbDescr[inTrain,]
trainY &lt;- logBBB[inTrain]

testX &lt;- bbbDescr[-inTrain,]
testY &lt;- logBBB[-inTrain]

fit &lt;- knnreg(trainX, trainY, k = 3)

plot(testY, predict(fit, testX))

</code></pre>

<hr>
<h2 id='learning_curve_dat'>Create Data to Plot a Learning Curve</h2><span id='topic+learning_curve_dat'></span>

<h3>Description</h3>

<p>For a given model, this function fits several versions on different sizes of
the total training set and returns the results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learning_curve_dat(
  dat,
  outcome = NULL,
  proportion = (1:10)/10,
  test_prop = 0,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learning_curve_dat_+3A_dat">dat</code></td>
<td>
<p>the training data</p>
</td></tr>
<tr><td><code id="learning_curve_dat_+3A_outcome">outcome</code></td>
<td>
<p>a character string identifying the outcome column name</p>
</td></tr>
<tr><td><code id="learning_curve_dat_+3A_proportion">proportion</code></td>
<td>
<p>the incremental proportions of the training set that are
used to fit the model</p>
</td></tr>
<tr><td><code id="learning_curve_dat_+3A_test_prop">test_prop</code></td>
<td>
<p>an optional proportion of the data to be used to measure
performance.</p>
</td></tr>
<tr><td><code id="learning_curve_dat_+3A_verbose">verbose</code></td>
<td>
<p>a logical to print logs to the screen as models are fit</p>
</td></tr>
<tr><td><code id="learning_curve_dat_+3A_...">...</code></td>
<td>
<p>options to pass to <code><a href="#topic+train">train</a></code> to specify the model.
These should not include <code>x</code>, <code>y</code>, <code>formula</code>, or <code>data</code>.
If <code>trainControl</code> is used here, do not use <code>method = "none"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates a data set that can be used to plot how well the model
performs over different sized versions of the training set. For each data
set size, the performance metrics are determined and saved. If
<code>test_prop == 0</code>, the apparent measure of performance (i.e.
re-predicting the training set) and the resampled estimate of performance
are available. Otherwise, the test set results are also added.
</p>
<p>If the model being fit has tuning parameters, the results are based on the
optimal settings determined by <code><a href="#topic+train">train</a></code>.
</p>


<h3>Value</h3>

<p>a data frame with columns for each performance metric calculated by
<code><a href="#topic+train">train</a></code> as well as columns: </p>
<table>
<tr><td><code>Training_Size</code></td>
<td>
<p>the number of
data points used in the current model fit</p>
</td></tr> <tr><td><code>Data</code></td>
<td>
<p>which data were used
to calculate performance. Values are &quot;Resampling&quot;, &quot;Training&quot;, and
(optionally) &quot;Testing&quot;</p>
</td></tr></table>
<p> In the results, each data set size will have one row
for the apparent error rate, one row for the test set results (if used) and
as many rows as resamples (e.g. 10 rows if 10-fold CV is used).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(1412)
class_dat &lt;- twoClassSim(1000)

ctrl &lt;- trainControl(classProbs = TRUE,
                     summaryFunction = twoClassSummary)

set.seed(29510)
lda_data &lt;-
  learning_curve_dat(dat = class_dat,
                     outcome = "Class",
                     test_prop = 1/4,
                     ## `train` arguments:
                     method = "lda",
                     metric = "ROC",
                     trControl = ctrl)



ggplot(lda_data, aes(x = Training_Size, y = ROC, color = Data)) +
  geom_smooth(method = loess, span = .8) +
  theme_bw()
 
## End(Not run)

</code></pre>

<hr>
<h2 id='lift'>Lift Plot</h2><span id='topic+lift'></span><span id='topic+lift.formula'></span><span id='topic+lift.default'></span><span id='topic+xyplot.lift'></span><span id='topic+print.lift'></span><span id='topic+ggplot.lift'></span>

<h3>Description</h3>

<p>For classification models, this function creates a 'lift plot' that
describes how well a model ranks samples for one class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lift(x, ...)

## Default S3 method:
lift(x, ...)

## S3 method for class 'formula'
lift(
  x,
  data = NULL,
  class = NULL,
  subset = TRUE,
  lattice.options = NULL,
  cuts = NULL,
  labels = NULL,
  ...
)

## S3 method for class 'lift'
print(x, ...)

## S3 method for class 'lift'
xyplot(x, data = NULL, plot = "gain", values = NULL, ...)

## S3 method for class 'lift'
ggplot(
  data = NULL,
  mapping = NULL,
  plot = "gain",
  values = NULL,
  ...,
  environment = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lift_+3A_x">x</code></td>
<td>
<p>a <code>lattice</code> formula (see <code><a href="lattice.html#topic+xyplot">xyplot</a></code>
for syntax) where the left-hand side of the formula is a factor class
variable of the observed outcome and the right-hand side specifies one or
model columns corresponding to a numeric ranking variable for a model (e.g.
class probabilities). The classification variable should have two levels.</p>
</td></tr>
<tr><td><code id="lift_+3A_...">...</code></td>
<td>
<p>options to pass through to <code><a href="lattice.html#topic+xyplot">xyplot</a></code>
or the panel function (not used in <code>lift.formula</code>).</p>
</td></tr>
<tr><td><code id="lift_+3A_data">data</code></td>
<td>
<p>For <code>lift.formula</code>, a data frame (or more precisely,
anything that is a valid <code>envir</code> argument in <code>eval</code>, e.g., a list
or an environment) containing values for any variables in the formula, as
well as <code>groups</code> and <code>subset</code> if applicable. If not found in
<code>data</code>, or if <code>data</code> is unspecified, the variables are looked for
in the environment of the formula. This argument is not used for
<code>xyplot.lift</code> or <code>ggplot.lift</code>.</p>
</td></tr>
<tr><td><code id="lift_+3A_class">class</code></td>
<td>
<p>a character string for the class of interest</p>
</td></tr>
<tr><td><code id="lift_+3A_subset">subset</code></td>
<td>
<p>An expression that evaluates to a logical or integer indexing
vector. It is evaluated in <code>data</code>. Only the resulting rows of
<code>data</code> are used for the plot.</p>
</td></tr>
<tr><td><code id="lift_+3A_lattice.options">lattice.options</code></td>
<td>
<p>A list that could be supplied to
<code><a href="lattice.html#topic+lattice.options">lattice.options</a></code></p>
</td></tr>
<tr><td><code id="lift_+3A_cuts">cuts</code></td>
<td>
<p>If a single value is given, a sequence of values between 0 and 1
are created with length <code>cuts</code>. If a vector, these values are used as
the cuts. If <code>NULL</code>, each unique value of the model prediction is used.
This is helpful when the data set is large.</p>
</td></tr>
<tr><td><code id="lift_+3A_labels">labels</code></td>
<td>
<p>A named list of labels for keys. The list should have an
element for each term on the right-hand side of the formula and the names
should match the names of the models.</p>
</td></tr>
<tr><td><code id="lift_+3A_plot">plot</code></td>
<td>
<p>Either &quot;gain&quot; (the default) or &quot;lift&quot;. The former plots the
number of samples called events versus the event rate while the latter shows
the event cut-off versus the lift statistic.</p>
</td></tr>
<tr><td><code id="lift_+3A_values">values</code></td>
<td>
<p>A vector of numbers between 0 and 100 specifying reference
values for the percentage of samples found (i.e. the y-axis). Corresponding
points on the x-axis are found via interpolation and line segments are shown
to indicate how many samples must be tested before these percentages are
found. The lines use either the <code>plot.line</code> or <code>superpose.line</code>
component of the current lattice theme to draw the lines (depending on
whether groups were used. These values are only used when <code>type =
"gain"</code>.</p>
</td></tr>
<tr><td><code id="lift_+3A_mapping">mapping</code>, <code id="lift_+3A_environment">environment</code></td>
<td>
<p>Not used (required for <code>ggplot</code> consistency).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lift.formula</code> is used to process the data and <code>xyplot.lift</code> is
used to create the plot.
</p>
<p>To construct data for the the lift and gain plots, the following steps are
used for each model:
</p>
 <ol>
<li><p> The data are ordered by the numeric model prediction used
on the right-hand side of the model formula </p>
</li>
<li><p> Each unique value of the
score is treated as a cut point </p>
</li>
<li><p> The number of samples with true
results equal to <code>class</code> are determined </p>
</li>
<li><p> The lift is calculated as
the ratio of the percentage of samples in each split corresponding to
<code>class</code> over the same percentage in the entire data set</p>
</li></ol>
 <p><code>lift</code>
with <code>plot = "gain"</code> produces a plot of the cumulative lift values by
the percentage of samples evaluated while <code>plot = "lift"</code> shows the cut
point value versus the lift statistic.
</p>
<p>This implementation uses the <span class="pkg">lattice</span> function
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>, so plot elements can be changed via
panel functions, <code><a href="lattice.html#topic+trellis.par.get">trellis.par.set</a></code> or
other means. <code>lift</code> uses the panel function <code><a href="#topic+panel.lift2">panel.lift2</a></code>
by default, but it can be changes using
<code><a href="lattice.html#topic+update.trellis">update.trellis</a></code> (see the examples in
<code><a href="#topic+panel.lift2">panel.lift2</a></code>).
</p>
<p>The following elements are set by default in the plot but can be changed by
passing new values into <code>xyplot.lift</code>: <code>xlab = "% Samples
Tested"</code>, <code>ylab = "% Samples Found"</code>, <code>type = "S"</code>, <code>ylim =
extendrange(c(0, 100))</code> and <code>xlim = extendrange(c(0, 100))</code>.
</p>


<h3>Value</h3>

<p><code>lift.formula</code> returns a list with elements: </p>
<table>
<tr><td><code>data</code></td>
<td>
<p>the
data used for plotting</p>
</td></tr> <tr><td><code>cuts</code></td>
<td>
<p>the number of cuts</p>
</td></tr> <tr><td><code>class</code></td>
<td>
<p>the
event class</p>
</td></tr> <tr><td><code>probNames</code></td>
<td>
<p>the names of the model probabilities</p>
</td></tr>
<tr><td><code>pct</code></td>
<td>
<p>the baseline event rate</p>
</td></tr>
</table>
<p><code>xyplot.lift</code> returns a <span class="pkg">lattice</span> object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, some <span class="pkg">lattice</span> code and documentation by Deepayan
Sarkar
</p>


<h3>See Also</h3>

<p><code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="lattice.html#topic+trellis.par.get">trellis.par.set</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
simulated &lt;- data.frame(obs = factor(rep(letters[1:2], each = 100)),
                        perfect = sort(runif(200), decreasing = TRUE),
                        random = runif(200))

lift1 &lt;- lift(obs ~ random, data = simulated)
lift1
xyplot(lift1)

lift2 &lt;- lift(obs ~ random + perfect, data = simulated)
lift2
xyplot(lift2, auto.key = list(columns = 2))

xyplot(lift2, auto.key = list(columns = 2), value = c(10, 30))

xyplot(lift2, plot = "lift", auto.key = list(columns = 2))

</code></pre>

<hr>
<h2 id='maxDissim'>Maximum Dissimilarity Sampling</h2><span id='topic+maxDissim'></span><span id='topic+minDiss'></span><span id='topic+sumDiss'></span>

<h3>Description</h3>

<p>Functions to create a sub-sample by maximizing the dissimilarity between new
samples and the existing subset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxDissim(
  a,
  b,
  n = 2,
  obj = minDiss,
  useNames = FALSE,
  randomFrac = 1,
  verbose = FALSE,
  ...
)

minDiss(u)

sumDiss(u)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maxDissim_+3A_a">a</code></td>
<td>
<p>a matrix or data frame of samples to start</p>
</td></tr>
<tr><td><code id="maxDissim_+3A_b">b</code></td>
<td>
<p>a matrix or data frame of samples to sample from</p>
</td></tr>
<tr><td><code id="maxDissim_+3A_n">n</code></td>
<td>
<p>the size of the sub-sample</p>
</td></tr>
<tr><td><code id="maxDissim_+3A_obj">obj</code></td>
<td>
<p>an objective function to measure overall dissimilarity</p>
</td></tr>
<tr><td><code id="maxDissim_+3A_usenames">useNames</code></td>
<td>
<p>a logical: should the function return the row names (as
opposed ot the row index)</p>
</td></tr>
<tr><td><code id="maxDissim_+3A_randomfrac">randomFrac</code></td>
<td>
<p>a number in (0, 1] that can be used to sub-sample from the
remaining candidate values</p>
</td></tr>
<tr><td><code id="maxDissim_+3A_verbose">verbose</code></td>
<td>
<p>a logical; should each step be printed?</p>
</td></tr>
<tr><td><code id="maxDissim_+3A_...">...</code></td>
<td>
<p>optional arguments to pass to dist</p>
</td></tr>
<tr><td><code id="maxDissim_+3A_u">u</code></td>
<td>
<p>a vector of dissimilarities</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given an initial set of m samples and a larger pool of n samples, this
function iteratively adds points to the smaller set by finding with of the n
samples is most dissimilar to the initial set. The argument <code>obj</code>
measures the overall dissimilarity between the initial set and a candidate
point. For example, maximizing the minimum or the sum of the m
dissimilarities are two common approaches.
</p>
<p>This algorithm tends to select points on the edge of the data mainstream and
will reliably select outliers. To select more samples towards the interior
of the data set, set <code>randomFrac</code> to be small (see the examples below).
</p>


<h3>Value</h3>

<p>a vector of integers or row names (depending on <code>useNames</code>)
corresponding to the rows of <code>b</code> that comprise the sub-sample.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn <a href="mailto:max.kuhn@pfizer.com">max.kuhn@pfizer.com</a>
</p>


<h3>References</h3>

<p>Willett, P. (1999), &quot;Dissimilarity-Based Algorithms for
Selecting Structurally Diverse Sets of Compounds,&quot; <em>Journal of
Computational Biology</em>, 6, 447-457.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dist">dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

example &lt;- function(pct = 1, obj = minDiss, ...)
{
  tmp &lt;- matrix(rnorm(200 * 2), nrow = 200)

  ## start with 15 data points
  start &lt;- sample(1:dim(tmp)[1], 15)
  base &lt;- tmp[start,]
  pool &lt;- tmp[-start,]
  
  ## select 9 for addition
  newSamp &lt;- maxDissim(
                       base, pool, 
                       n = 9, 
                       randomFrac = pct, obj = obj, ...)
  
  allSamp &lt;- c(start, newSamp)
  
  plot(
       tmp[-newSamp,], 
       xlim = extendrange(tmp[,1]), ylim = extendrange(tmp[,2]), 
       col = "darkgrey", 
       xlab = "variable 1", ylab = "variable 2")
  points(base, pch = 16, cex = .7)
  
  for(i in seq(along = newSamp))
    points(
           pool[newSamp[i],1], 
           pool[newSamp[i],2], 
           pch = paste(i), col = "darkred") 
}

par(mfrow=c(2,2))

set.seed(414)
example(1, minDiss)
title("No Random Sampling, Min Score")

set.seed(414)
example(.1, minDiss)
title("10 Pct Random Sampling, Min Score")

set.seed(414)
example(1, sumDiss)
title("No Random Sampling, Sum Score")

set.seed(414)
example(.1, sumDiss)
title("10 Pct Random Sampling, Sum Score")

</code></pre>

<hr>
<h2 id='mdrr'>Multidrug Resistance Reversal (MDRR) Agent Data</h2><span id='topic+mdrr'></span><span id='topic+mdrrClass'></span><span id='topic+mdrrDescr'></span>

<h3>Description</h3>

<p>Svetnik et al. (2003) describe these data: &quot;Bakken and Jurs studied a set of
compounds originally discussed by Klopman et al., who were interested in
multidrug resistance reversal (MDRR) agents. The original response variable
is a ratio measuring the ability of a compound to reverse a leukemia cell's
resistance to adriamycin. However, the problem was treated as a
classification problem, and compounds with the ratio &gt;4.2 were considered
active, and those with the ratio &lt;= 2.0 were considered inactive. Compounds
with the ratio between these two cutoffs were called moderate and removed
from the data for twoclass classification, leaving a set of 528 compounds
(298 actives and 230 inactives). (Various other arrangements of these data
were examined by Bakken and Jurs, but we will focus on this particular one.)
We did not have access to the original descriptors, but we generated a set
of 342 descriptors of three different types that should be similar to the
original descriptors, using the DRAGON software.&quot;
</p>


<h3>Details</h3>

<p>The data and R code are in the Supplemental Data file for the article.
</p>


<h3>Value</h3>

<table>
<tr><td><code>mdrrDescr</code></td>
<td>
<p>the descriptors</p>
</td></tr> <tr><td><code>mdrrClass</code></td>
<td>
<p>the categorical
outcome (&quot;Active&quot; or &quot;Inactive&quot;)</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Svetnik, V., Liaw, A., Tong, C., Culberson, J. C., Sheridan, R. P.
Feuston, B. P (2003).  Random Forest: A Classification and Regression Tool
for Compound Classification and QSAR Modeling, <em>Journal of Chemical
Information and Computer Sciences</em>, Vol. 43, pg. 1947-1958.
</p>

<hr>
<h2 id='modelLookup'>Tools for Models Available in <code>train</code></h2><span id='topic+modelLookup'></span><span id='topic+getModelInfo'></span><span id='topic+checkInstall'></span>

<h3>Description</h3>

<p>These function show information about models and packages that are
accessible via <code><a href="#topic+train">train</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelLookup(model = NULL)

checkInstall(pkg)

getModelInfo(model = NULL, regex = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelLookup_+3A_model">model</code></td>
<td>
<p>a character string associated with the <code>method</code> argument
of <code><a href="#topic+train">train</a></code>. If no value is passed, all models are returned. For
<code>getModelInfo</code>, regular expressions can be used.</p>
</td></tr>
<tr><td><code id="modelLookup_+3A_pkg">pkg</code></td>
<td>
<p>a character string of package names.</p>
</td></tr>
<tr><td><code id="modelLookup_+3A_regex">regex</code></td>
<td>
<p>a logical: should a regular expressions be used? If
<code>FALSE</code>, a simple match is conducted against the whole name of the
model.</p>
</td></tr>
<tr><td><code id="modelLookup_+3A_...">...</code></td>
<td>
<p>options to pass to <code><a href="base.html#topic+grepl">grepl</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>modelLookup</code> is good for getting information related to the tuning
parameters for a model. <code>getModelInfo</code> will return all the functions
and metadata associated with a model. Both of these functions will only
search within the models bundled in this package.
</p>
<p><code>checkInstall</code> will check to see if packages are installed. If they are
not and the session is interactive, an option is given to install the
packages using <code><a href="utils.html#topic+install.packages">install.packages</a></code> using that functions
default arguments (the missing packages are listed if you would like to
install them with other options). If the session is not interactive, an
error is thrown.
</p>


<h3>Value</h3>

<p><code>modelLookup</code> produces a data frame with columns </p>
<table>
<tr><td><code>model</code></td>
<td>
<p>a character string for the model code</p>
</td></tr> <tr><td><code>parameter</code></td>
<td>
<p>the tuning
parameter name</p>
</td></tr> <tr><td><code>label</code></td>
<td>
<p>a tuning parameter label (used in plots)</p>
</td></tr>
<tr><td><code>forReg</code></td>
<td>
<p>a logical; can the model be used for regression?</p>
</td></tr>
<tr><td><code>forClass</code></td>
<td>
<p>a logical; can the model be used for classification?</p>
</td></tr>
<tr><td><code>probModel</code></td>
<td>
<p>a logical; does the model produce class probabilities?</p>
</td></tr>
</table>
<p><code>getModelInfo</code> returns a list containing one or more lists of the
standard model information.
</p>
<p><code>checkInstall</code> returns not value.
</p>


<h3>Note</h3>

<p>The column <code>seq</code> is no longer included in the output of
<code>modelLookup</code>.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>, <code><a href="utils.html#topic+install.packages">install.packages</a></code>,
<code><a href="base.html#topic+grepl">grepl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
modelLookup()
modelLookup("gbm")

getModelInfo("pls")
getModelInfo("^pls")
getModelInfo("pls", regex = FALSE)

checkInstall(getModelInfo("pls")$library)

## End(Not run)

</code></pre>

<hr>
<h2 id='nearZeroVar'>Identification of near zero variance predictors</h2><span id='topic+nearZeroVar'></span><span id='topic+nzv'></span><span id='topic+checkResamples'></span><span id='topic+checkConditionalX'></span>

<h3>Description</h3>

<p><code>nearZeroVar</code> diagnoses predictors that have one unique value (i.e. are
zero variance predictors) or predictors that are have both of the following
characteristics: they have very few unique values relative to the number of
samples and the ratio of the frequency of the most common value to the
frequency of the second most common value is large. <code>checkConditionalX</code>
looks at the distribution of the columns of <code>x</code> conditioned on the
levels of <code>y</code> and identifies columns of <code>x</code> that are sparse within
groups of <code>y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nearZeroVar(
  x,
  freqCut = 95/5,
  uniqueCut = 10,
  saveMetrics = FALSE,
  names = FALSE,
  foreach = FALSE,
  allowParallel = TRUE
)

checkConditionalX(x, y)

checkResamples(index, x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nearZeroVar_+3A_x">x</code></td>
<td>
<p>a numeric vector or matrix, or a data frame with all numeric data</p>
</td></tr>
<tr><td><code id="nearZeroVar_+3A_freqcut">freqCut</code></td>
<td>
<p>the cutoff for the ratio of the most common value to the
second most common value</p>
</td></tr>
<tr><td><code id="nearZeroVar_+3A_uniquecut">uniqueCut</code></td>
<td>
<p>the cutoff for the percentage of distinct values out of the
number of total samples</p>
</td></tr>
<tr><td><code id="nearZeroVar_+3A_savemetrics">saveMetrics</code></td>
<td>
<p>a logical. If false, the positions of the zero- or
near-zero predictors is returned. If true, a data frame with predictor
information is returned.</p>
</td></tr>
<tr><td><code id="nearZeroVar_+3A_names">names</code></td>
<td>
<p>a logical. If false, column indexes are returned. If true,
column names are returned.</p>
</td></tr>
<tr><td><code id="nearZeroVar_+3A_foreach">foreach</code></td>
<td>
<p>should the <span class="pkg">foreach</span> package be used for the
computations? If <code>TRUE</code>, less memory should be used.</p>
</td></tr>
<tr><td><code id="nearZeroVar_+3A_allowparallel">allowParallel</code></td>
<td>
<p>should the parallel processing via the <span class="pkg">foreach</span>
package be used for the computations? If <code>TRUE</code>, more memory will be
used but execution time should be shorter.</p>
</td></tr>
<tr><td><code id="nearZeroVar_+3A_y">y</code></td>
<td>
<p>a factor vector with at least two levels</p>
</td></tr>
<tr><td><code id="nearZeroVar_+3A_index">index</code></td>
<td>
<p>a list. Each element corresponds to the training set samples in
<code>x</code> for a given resample</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, an example of near zero variance predictor is one that, for
1000 samples, has two distinct values and 999 of them are a single value.
</p>
<p>To be flagged, first the frequency of the most prevalent value over the
second most frequent value (called the &ldquo;frequency ratio&rdquo;) must be above
<code>freqCut</code>. Secondly, the &ldquo;percent of unique values,&rdquo; the number of
unique values divided by the total number of samples (times 100), must also
be below <code>uniqueCut</code>.
</p>
<p>In the above example, the frequency ratio is 999 and the unique value
percentage is 0.0001.
</p>
<p>Checking the conditional distribution of <code>x</code> may be needed for some
models, such as naive Bayes where the conditional distributions should have
at least one data point within a class.
</p>
<p><code>nzv</code> is the original version of the function.
</p>


<h3>Value</h3>

<p>For <code>nearZeroVar</code>: if <code>saveMetrics = FALSE</code>, a vector of
integers corresponding to the column positions of the problematic
predictors. If <code>saveMetrics = TRUE</code>, a data frame with columns:
</p>
<table>
<tr><td><code>freqRatio</code></td>
<td>
<p>the ratio of frequencies for the most common value over
the second most common value</p>
</td></tr> <tr><td><code>percentUnique</code></td>
<td>
<p>the percentage of unique
data points out of the total number of data points</p>
</td></tr> <tr><td><code>zeroVar</code></td>
<td>
<p>a vector
of logicals for whether the predictor has only one distinct value</p>
</td></tr> <tr><td><code>nzv</code></td>
<td>
<p>a vector of logicals for whether the predictor is a near zero variance
predictor</p>
</td></tr>
</table>
<p>For <code>checkResamples</code> or <code>checkConditionalX</code>, a vector of column
indicators for predictors with empty conditional distributions in at least
one class of <code>y</code>.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, with speed improvements to nearZeroVar by Allan Engelhardt
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
nearZeroVar(iris[, -5], saveMetrics = TRUE)

data(BloodBrain)
nearZeroVar(bbbDescr)
nearZeroVar(bbbDescr, names = TRUE)


set.seed(1)
classes &lt;- factor(rep(letters[1:3], each = 30))
x &lt;- data.frame(x1 = rep(c(0, 1), 45),
                x2 = c(rep(0, 10), rep(1, 80)))

lapply(x, table, y = classes)
checkConditionalX(x, classes)

folds &lt;- createFolds(classes, k = 3, returnTrain = TRUE)
x$x3 &lt;- x$x1
x$x3[folds[[1]]] &lt;- 0

checkResamples(folds, x, classes)



</code></pre>

<hr>
<h2 id='negPredValue'>Calculate sensitivity, specificity and predictive values</h2><span id='topic+negPredValue'></span><span id='topic+negPredValue.default'></span><span id='topic+negPredValue.table'></span><span id='topic+negPredValue.matrix'></span><span id='topic+posPredValue'></span><span id='topic+posPredValue.default'></span><span id='topic+posPredValue.table'></span><span id='topic+posPredValue.matrix'></span><span id='topic+sensitivity'></span><span id='topic+sensitivity.default'></span><span id='topic+sensitivity.table'></span><span id='topic+sensitivity.matrix'></span><span id='topic+specificity'></span><span id='topic+specificity.default'></span><span id='topic+specificity.table'></span><span id='topic+specificity.matrix'></span>

<h3>Description</h3>

<p>These functions calculate the sensitivity, specificity or predictive values
of a measurement system compared to a reference results (the truth or a gold
standard). The measurement and &quot;truth&quot; data must have the same two possible
outcomes and one of the outcomes must be thought of as a &quot;positive&quot; results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>negPredValue(data, ...)

## Default S3 method:
negPredValue(
  data,
  reference,
  negative = levels(reference)[2],
  prevalence = NULL,
  ...
)

## S3 method for class 'table'
negPredValue(data, negative = rownames(data)[-1], prevalence = NULL, ...)

## S3 method for class 'matrix'
negPredValue(data, negative = rownames(data)[-1], prevalence = NULL, ...)

posPredValue(data, ...)

## Default S3 method:
posPredValue(
  data,
  reference,
  positive = levels(reference)[1],
  prevalence = NULL,
  ...
)

## S3 method for class 'table'
posPredValue(data, positive = rownames(data)[1], prevalence = NULL, ...)

## S3 method for class 'matrix'
posPredValue(data, positive = rownames(data)[1], prevalence = NULL, ...)

sensitivity(data, ...)

## Default S3 method:
sensitivity(
  data,
  reference,
  positive = levels(reference)[1],
  na.rm = TRUE,
  ...
)

## S3 method for class 'table'
sensitivity(data, positive = rownames(data)[1], ...)

## S3 method for class 'matrix'
sensitivity(data, positive = rownames(data)[1], ...)

specificity(data, ...)

## Default S3 method:
specificity(
  data,
  reference,
  negative = levels(reference)[-1],
  na.rm = TRUE,
  ...
)

## S3 method for class 'table'
specificity(data, negative = rownames(data)[-1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="negPredValue_+3A_data">data</code></td>
<td>
<p>for the default functions, a factor containing the discrete
measurements. For the <code>table</code> or <code>matrix</code> functions, a table or
matric object, respectively.</p>
</td></tr>
<tr><td><code id="negPredValue_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
<tr><td><code id="negPredValue_+3A_reference">reference</code></td>
<td>
<p>a factor containing the reference values</p>
</td></tr>
<tr><td><code id="negPredValue_+3A_negative">negative</code></td>
<td>
<p>a character string that defines the factor level
corresponding to the &quot;negative&quot; results</p>
</td></tr>
<tr><td><code id="negPredValue_+3A_prevalence">prevalence</code></td>
<td>
<p>a numeric value for the rate of the &quot;positive&quot; class of
the data</p>
</td></tr>
<tr><td><code id="negPredValue_+3A_positive">positive</code></td>
<td>
<p>a character string that defines the factor level
corresponding to the &quot;positive&quot; results</p>
</td></tr>
<tr><td><code id="negPredValue_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should be
stripped before the computation proceeds</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sensitivity is defined as the proportion of positive results out of the
number of samples which were actually positive. When there are no positive
results, sensitivity is not defined and a value of <code>NA</code> is returned.
Similarly, when there are no negative results, specificity is not defined
and a value of <code>NA</code> is returned. Similar statements are true for
predictive values.
</p>
<p>The positive predictive value is defined as the percent of predicted
positives that are actually positive while the negative predictive value is
defined as the percent of negative positives that are actually negative.
</p>
<p>Suppose a 2x2 table with notation
</p>

<table>
<tr>
 <td style="text-align: right;"> </td><td style="text-align: center;"> Reference </td><td style="text-align: center;"> </td>
</tr>
<tr>
 <td style="text-align: right;"> Predicted </td><td style="text-align: center;"> Event </td><td style="text-align: center;"> No Event
</td>
</tr>
<tr>
 <td style="text-align: right;"> Event </td><td style="text-align: center;"> A </td><td style="text-align: center;"> B </td>
</tr>
<tr>
 <td style="text-align: right;"> No Event </td><td style="text-align: center;"> C </td><td style="text-align: center;"> D </td>
</tr>
<tr>
 <td style="text-align: right;"> </td>
</tr>

</table>

<p>The formulas used here are: </p>
<p style="text-align: center;"><code class="reqn">Sensitivity = A/(A+C)</code>
</p>
 <p style="text-align: center;"><code class="reqn">Specificity =
D/(B+D)</code>
</p>
 <p style="text-align: center;"><code class="reqn">Prevalence = (A+C)/(A+B+C+D)</code>
</p>
 <p style="text-align: center;"><code class="reqn">PPV = (sensitivity *
Prevalence)/((sensitivity*Prevalence) + ((1-specificity)*(1-Prevalence)))</code>
</p>

<p style="text-align: center;"><code class="reqn">NPV = (specificity * (1-Prevalence))/(((1-sensitivity)*Prevalence) +
((specificity)*(1-Prevalence)))</code>
</p>

<p>See the references for discussions of the statistics.
</p>


<h3>Value</h3>

<p>A number between 0 and 1 (or NA).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Kuhn, M. (2008), &ldquo;Building predictive models in R using the
caret package, &rdquo; <em>Journal of Statistical Software</em>,
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>).
</p>
<p>Altman, D.G., Bland, J.M. (1994) &ldquo;Diagnostic tests 1: sensitivity and
specificity,&rdquo; <em>British Medical Journal</em>, vol 308, 1552.
</p>
<p>Altman, D.G., Bland, J.M. (1994) &ldquo;Diagnostic tests 2: predictive values,&rdquo;
<em>British Medical Journal</em>, vol 309, 102.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusionMatrix">confusionMatrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
###################
## 2 class example

lvs &lt;- c("normal", "abnormal")
truth &lt;- factor(rep(lvs, times = c(86, 258)),
                levels = rev(lvs))
pred &lt;- factor(
               c(
                 rep(lvs, times = c(54, 32)),
                 rep(lvs, times = c(27, 231))),
               levels = rev(lvs))

xtab &lt;- table(pred, truth)

sensitivity(pred, truth)
sensitivity(xtab)
posPredValue(pred, truth)
posPredValue(pred, truth, prevalence = 0.25)

specificity(pred, truth)
negPredValue(pred, truth)
negPredValue(xtab)
negPredValue(pred, truth, prevalence = 0.25)


prev &lt;- seq(0.001, .99, length = 20)
npvVals &lt;- ppvVals &lt;- prev  * NA
for(i in seq(along = prev))
  {
    ppvVals[i] &lt;- posPredValue(pred, truth, prevalence = prev[i])
    npvVals[i] &lt;- negPredValue(pred, truth, prevalence = prev[i])
  }

plot(prev, ppvVals,
     ylim = c(0, 1),
     type = "l",
     ylab = "",
     xlab = "Prevalence (i.e. prior)")
points(prev, npvVals, type = "l", col = "red")
abline(h=sensitivity(pred, truth), lty = 2)
abline(h=specificity(pred, truth), lty = 2, col = "red")
legend(.5, .5,
       c("ppv", "npv", "sens", "spec"),
       col = c("black", "red", "black", "red"),
       lty = c(1, 1, 2, 2))

###################
## 3 class example

library(MASS)

fit &lt;- lda(Species ~ ., data = iris)
model &lt;- predict(fit)$class

irisTabs &lt;- table(model, iris$Species)

## When passing factors, an error occurs with more
## than two levels
sensitivity(model, iris$Species)

## When passing a table, more than two levels can
## be used
sensitivity(irisTabs, "versicolor")
specificity(irisTabs, c("setosa", "virginica"))

## End(Not run)

</code></pre>

<hr>
<h2 id='nullModel'>Fit a simple, non-informative model</h2><span id='topic+nullModel'></span><span id='topic+nullModel.default'></span><span id='topic+predict.nullModel'></span>

<h3>Description</h3>

<p>Fit a single mean or largest class model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nullModel(x, ...)

## Default S3 method:
nullModel(x = NULL, y, ...)

## S3 method for class 'nullModel'
predict(object, newdata = NULL, type = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nullModel_+3A_x">x</code></td>
<td>
<p>An optional matrix or data frame of predictors. These values are
not used in the model fit</p>
</td></tr>
<tr><td><code id="nullModel_+3A_...">...</code></td>
<td>
<p>Optional arguments (not yet used)</p>
</td></tr>
<tr><td><code id="nullModel_+3A_y">y</code></td>
<td>
<p>A numeric vector (for regression) or factor (for classification) of
outcomes</p>
</td></tr>
<tr><td><code id="nullModel_+3A_object">object</code></td>
<td>
<p>An object of class <code>nullModel</code></p>
</td></tr>
<tr><td><code id="nullModel_+3A_newdata">newdata</code></td>
<td>
<p>A matrix or data frame of predictors (only used to determine
the number of predictions to return)</p>
</td></tr>
<tr><td><code id="nullModel_+3A_type">type</code></td>
<td>
<p>Either &quot;raw&quot; (for regression), &quot;class&quot; or &quot;prob&quot; (for
classification)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nullModel</code> emulates other model building functions, but returns the
simplest model possible given a training set: a single mean for numeric
outcomes and the most prevalent class for factor outcomes. When class
probabilities are requested, the percentage of the training set samples with
the most prevalent class is returned.
</p>


<h3>Value</h3>

<p>The output of <code>nullModel</code> is a list of class <code>nullModel</code>
with elements </p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr> <tr><td><code>value</code></td>
<td>
<p>the mean of
<code>y</code> or the most prevalent class</p>
</td></tr> <tr><td><code>levels</code></td>
<td>
<p>when <code>y</code> is a
factor, a vector of levels. <code>NULL</code> otherwise</p>
</td></tr> <tr><td><code>pct</code></td>
<td>
<p>when <code>y</code>
is a factor, a data frame with a column for each class (<code>NULL</code>
otherwise). The column for the most prevalent class has the proportion of
the training samples with that class (the other columns are zero). </p>
</td></tr> <tr><td><code>n</code></td>
<td>
<p>the number of elements in <code>y</code></p>
</td></tr>
</table>
<p><code>predict.nullModel</code> returns a either a factor or numeric vector
depending on the class of <code>y</code>. All predictions are always the same.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
outcome &lt;- factor(sample(letters[1:2],
                         size = 100,
                         prob = c(.1, .9),
                         replace = TRUE))
useless &lt;- nullModel(y = outcome)
useless
predict(useless, matrix(NA, nrow = 10))


</code></pre>

<hr>
<h2 id='oil'>Fatty acid composition of commercial oils</h2><span id='topic+oil'></span><span id='topic+oilType'></span><span id='topic+fattyAcids'></span>

<h3>Description</h3>

<p>Fatty acid concentrations of commercial oils were measured using gas
chromatography.  The data is used to predict the type of oil.  Note that
only the known oils are in the data set. Also, the authors state that there
are 95 samples of known oils. However, we count 96 in Table 1 (pgs.  33-35).
</p>


<h3>Value</h3>

<table>
<tr><td><code>fattyAcids</code></td>
<td>
<p>data frame of fatty acid compositions: Palmitic,
Stearic, Oleic, Linoleic, Linolenic, Eicosanoic and Eicosenoic. When values
fell below the lower limit of the assay (denoted as &lt;X in the paper), the
limit was used. </p>
</td></tr> <tr><td><code>oilType</code></td>
<td>
<p>factor of oil types: pumpkin (A), sunflower
(B), peanut (C), olive (D), soybean (E), rapeseed (F) and corn (G).</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Brodnjak-Voncina et al. (2005). Multivariate data analysis in
classification of vegetable oils characterized by the content of fatty
acids, <em>Chemometrics and Intelligent Laboratory Systems</em>, Vol.
75:31-45.
</p>

<hr>
<h2 id='oneSE'>Selecting tuning Parameters</h2><span id='topic+oneSE'></span><span id='topic+best'></span><span id='topic+tolerance'></span>

<h3>Description</h3>

<p>Various functions for setting tuning parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oneSE(x, metric, num, maximize)

tolerance(x, metric, tol = 1.5, maximize)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oneSE_+3A_x">x</code></td>
<td>
<p>a data frame of tuning parameters and model results, sorted from
least complex models to the mst complex</p>
</td></tr>
<tr><td><code id="oneSE_+3A_metric">metric</code></td>
<td>
<p>a string that specifies what summary metric will be used to
select the optimal model. By default, possible values are &quot;RMSE&quot; and
&quot;Rsquared&quot; for regression and &quot;Accuracy&quot; and &quot;Kappa&quot; for classification. If
custom performance metrics are used (via the <code>summaryFunction</code> argument
in <code><a href="#topic+trainControl">trainControl</a></code>, the value of <code>metric</code> should match one
of the arguments. If it does not, a warning is issued and the first metric
given by the <code>summaryFunction</code> is used.</p>
</td></tr>
<tr><td><code id="oneSE_+3A_num">num</code></td>
<td>
<p>the number of resamples (for <code>oneSE</code> only)</p>
</td></tr>
<tr><td><code id="oneSE_+3A_maximize">maximize</code></td>
<td>
<p>a logical: should the metric be maximized or minimized?</p>
</td></tr>
<tr><td><code id="oneSE_+3A_tol">tol</code></td>
<td>
<p>the acceptable percent tolerance (for <code>tolerance</code> only)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions can be used by <code><a href="#topic+train">train</a></code> to select the &quot;optimal&quot;
model from a series of models. Each requires the user to select a metric
that will be used to judge performance. For regression models, values of
<code>"RMSE"</code> and <code>"Rsquared"</code> are applicable. Classification models
use either <code>"Accuracy"</code> or <code>"Kappa"</code> (for unbalanced class
distributions.
</p>
<p>More details on these functions can be found at
<a href="http://topepo.github.io/caret/model-training-and-tuning.html#custom">http://topepo.github.io/caret/model-training-and-tuning.html#custom</a>.
</p>
<p>By default, <code><a href="#topic+train">train</a></code> uses <code>best</code>.
</p>
<p><code>best</code> simply chooses the tuning parameter associated with the largest
(or lowest for <code>"RMSE"</code>) performance.
</p>
<p><code>oneSE</code> is a rule in the spirit of the &quot;one standard error&quot; rule of
Breiman et al. (1984), who suggest that the tuning parameter associated with
the best performance may over fit. They suggest that the simplest model
within one standard error of the empirically optimal model is the better
choice. This assumes that the models can be easily ordered from simplest to
most complex (see the Details section below).
</p>
<p><code>tolerance</code> takes the simplest model that is within a percent tolerance
of the empirically optimal model. For example, if the largest Kappa value is
0.5 and a simpler model within 3 percent is acceptable, we score the other
models using <code>(x - 0.5)/0.5 * 100</code>. The simplest model whose score is
not less than 3 is chosen (in this case, a model with a Kappa value of 0.35
is acceptable).
</p>
<p>User-defined functions can also be used. The argument
<code>selectionFunction</code> in <code><a href="#topic+trainControl">trainControl</a></code> can be used to pass
the function directly or to pass the function by name.
</p>


<h3>Value</h3>

<p>a row index
</p>


<h3>Note</h3>

<p>In many cases, it is not very clear how to order the models on
simplicity. For simple trees and other models (such as PLS), this is
straightforward. However, for others it is not.
</p>
<p>For example, many of the boosting models used by <span class="pkg">caret</span> have parameters
for the number of boosting iterations and the tree complexity (others may
also have a learning rate parameter). In this implementation, we order
models on number of iterations, then tree depth. Clearly, this is arguable
(please email the author for suggestions though).
</p>
<p>For MARS models, they are orders on the degree of the features, then the
number of retained terms.
</p>
<p>RBF SVM models are ordered first by the cost parameter, then by the kernel
parameter while polynomial models are ordered first on polynomial degree,
then cost and scale.
</p>
<p>Neural networks are ordered by the number of hidden units and then the
amount of weight decay.
</p>
<p>k-nearest neighbor models are ordered from most neighbors to least (i.e.
smoothest to model jagged decision boundaries).
</p>
<p>Elastic net models are ordered first on the L1 penalty, then by the L2
penalty.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Breiman, Friedman, Olshen, and Stone. (1984)
<em>Classification and Regression Trees</em>. Wadsworth.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>, <code><a href="#topic+trainControl">trainControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# simulate a PLS regression model
test &lt;- data.frame(ncomp = 1:5,
                   RMSE = c(3, 1.1, 1.02, 1, 2),
                   RMSESD = .4)

best(test, "RMSE", maximize = FALSE)
oneSE(test, "RMSE", maximize = FALSE, num = 10)
tolerance(test, "RMSE", tol = 3, maximize = FALSE)

### usage example

data(BloodBrain)

marsGrid &lt;- data.frame(degree = 1, nprune = (1:10) * 3)

set.seed(1)
marsFit &lt;- train(bbbDescr, logBBB,
                 method = "earth",
                 tuneGrid = marsGrid,
                 trControl = trainControl(method = "cv",
                                          number = 10,
                                          selectionFunction = "tolerance"))

# around 18 terms should yield the smallest CV RMSE

## End(Not run)


</code></pre>

<hr>
<h2 id='panel.lift2'>Lattice Panel Functions for Lift Plots</h2><span id='topic+panel.lift2'></span><span id='topic+panel.lift'></span>

<h3>Description</h3>

<p>Two panel functions that be used in conjunction with <code><a href="#topic+lift">lift</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>panel.lift2(x, y, pct = 0, values = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="panel.lift2_+3A_x">x</code></td>
<td>
<p>the percentage of searched to be plotted in the scatterplot</p>
</td></tr>
<tr><td><code id="panel.lift2_+3A_y">y</code></td>
<td>
<p>the percentage of events found to be plotted in the scatterplot</p>
</td></tr>
<tr><td><code id="panel.lift2_+3A_pct">pct</code></td>
<td>
<p>the baseline percentage of true events in the data</p>
</td></tr>
<tr><td><code id="panel.lift2_+3A_values">values</code></td>
<td>
<p>A vector of numbers between 0 and 100 specifying reference
values for the percentage of samples found (i.e. the y-axis). Corresponding
points on the x-axis are found via interpolation and line segments are shown
to indicate how many samples must be tested before these percentages are
found. The lines use either the <code>plot.line</code> or <code>superpose.line</code>
component of the current lattice theme to draw the lines (depending on
whether groups were used</p>
</td></tr>
<tr><td><code id="panel.lift2_+3A_...">...</code></td>
<td>
<p>options to pass to
<code><a href="lattice.html#topic+panel.xyplot">panel.xyplot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>panel.lift</code> plots the data with a simple (black) 45 degree reference
line.
</p>
<p><code>panel.lift2</code> is the default for <code><a href="#topic+lift">lift</a></code> and plots the data
points with a shaded region encompassing the space between to the random
model and perfect model trajectories. The color of the region is determined
by the lattice <code>reference.line</code> information (see example below).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lift">lift</a></code>,
<code><a href="lattice.html#topic+panel.xyplot">panel.xyplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<a href="lattice.html#topic+trellis.par.get">trellis.par.set</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
simulated &lt;- data.frame(obs = factor(rep(letters[1:2], each = 100)),
                        perfect = sort(runif(200), decreasing = TRUE),
                        random = runif(200))

regionInfo &lt;- trellis.par.get("reference.line")
regionInfo$col &lt;- "lightblue"
trellis.par.set("reference.line", regionInfo)

lift2 &lt;- lift(obs ~ random + perfect, data = simulated)
lift2
xyplot(lift2, auto.key = list(columns = 2))

## use a different panel function
xyplot(lift2, panel = panel.lift)

</code></pre>

<hr>
<h2 id='panel.needle'>Needle Plot Lattice Panel</h2><span id='topic+panel.needle'></span>

<h3>Description</h3>

<p>A variation of <code>panel.dotplot</code> that plots horizontal lines from zero to
the data point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>panel.needle(
  x,
  y,
  horizontal = TRUE,
  pch = if (is.null(groups)) dot.symbol$pch else sup.symbol$pch,
  col = if (is.null(groups)) dot.symbol$col else sup.symbol$col,
  lty = dot.line$lty,
  lwd = dot.line$lwd,
  col.line = dot.line$col,
  levels.fos = NULL,
  groups = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="panel.needle_+3A_x">x</code>, <code id="panel.needle_+3A_y">y</code></td>
<td>
<p>variables to be plotted in the panel. Typically y is the 'factor'</p>
</td></tr>
<tr><td><code id="panel.needle_+3A_horizontal">horizontal</code></td>
<td>
<p>logical. If FALSE, the plot is &lsquo;transposed&rsquo; in the sense
that the behaviours of x and y are switched. x is now the &lsquo;factor&rsquo;.
Interpretation of other arguments change accordingly. See documentation of
<code>bwplot</code> for a fuller explanation.</p>
</td></tr>
<tr><td><code id="panel.needle_+3A_pch">pch</code>, <code id="panel.needle_+3A_col">col</code>, <code id="panel.needle_+3A_lty">lty</code>, <code id="panel.needle_+3A_lwd">lwd</code>, <code id="panel.needle_+3A_col.line">col.line</code></td>
<td>
<p>graphical parameters</p>
</td></tr>
<tr><td><code id="panel.needle_+3A_levels.fos">levels.fos</code></td>
<td>
<p>locations where reference lines will be drawn</p>
</td></tr>
<tr><td><code id="panel.needle_+3A_groups">groups</code></td>
<td>
<p>grouping variable (affects graphical parameters)</p>
</td></tr>
<tr><td><code id="panel.needle_+3A_...">...</code></td>
<td>
<p>extra parameters, passed to <code>panel.xyplot</code> which is
responsible for drawing the foreground points (<code>panel.dotplot</code> only
draws the background reference lines).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates (possibly grouped) needleplot of <code>x</code> against <code>y</code> or vice
versa
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, based on <code><a href="lattice.html#topic+panel.dotplot">panel.dotplot</a></code> by Deepayan
Sarkar
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+dotplot">dotplot</a></code>
</p>

<hr>
<h2 id='pcaNNet'>Neural Networks with a Principal Component Step</h2><span id='topic+pcaNNet'></span><span id='topic+pcaNNet.default'></span><span id='topic+predict.pcaNNet'></span><span id='topic+pcaNNet.formula'></span><span id='topic+print.pcaNNet'></span>

<h3>Description</h3>

<p>Run PCA on a dataset, then use it in a neural network model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcaNNet(x, ...)

## S3 method for class 'formula'
pcaNNet(
  formula,
  data,
  weights,
  ...,
  thresh = 0.99,
  subset,
  na.action,
  contrasts = NULL
)

## Default S3 method:
pcaNNet(x, y, thresh = 0.99, ...)

## S3 method for class 'pcaNNet'
print(x, ...)

## S3 method for class 'pcaNNet'
predict(object, newdata, type = c("raw", "class", "prob"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcaNNet_+3A_x">x</code></td>
<td>
<p>matrix or data frame of <code>x</code> values for examples.</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="nnet.html#topic+nnet">nnet</a></code>, such as
<code>size</code>, <code>decay</code>, etc.</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_formula">formula</code></td>
<td>
<p>A formula of the form <code>class ~ x1 + x2 + ...{}</code></p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in <code>formula</code> are
preferentially to be taken.</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_weights">weights</code></td>
<td>
<p>(case) weights for each example - if missing defaults to 1.</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_thresh">thresh</code></td>
<td>
<p>a threshold for the cumulative proportion of variance to
capture from the PCA analysis. For example, to retain enough PCA components
to capture 95 percent of variation, set <code>thresh = .95</code></p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the
training sample.  (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if <code>NA</code>s
are found. The default action is for the procedure to fail.  An alternative
is na.omit, which leads to rejection of cases with missing values on any
required variable.  (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_contrasts">contrasts</code></td>
<td>
<p>a list of contrasts to be used for some or all of the
factors appearing as variables in the model formula.</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_y">y</code></td>
<td>
<p>matrix or data frame of target values for examples.</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_object">object</code></td>
<td>
<p>an object of class <code>pcaNNet</code> as returned by
<code>pcaNNet</code>.</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_newdata">newdata</code></td>
<td>
<p>matrix or data frame of test examples. A vector is considered
to be a row vector comprising a single case.</p>
</td></tr>
<tr><td><code id="pcaNNet_+3A_type">type</code></td>
<td>
<p>Type of output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first will run principal component analysis on the data. The
cumulative percentage of variance is computed for each principal component.
The function uses the <code>thresh</code> argument to determine how many
components must be retained to capture this amount of variance in the
predictors.
</p>
<p>The principal components are then used in a neural network model.
</p>
<p>When predicting samples, the new data are similarly transformed using the
information from the PCA analysis on the training data and then predicted.
</p>
<p>Because the variance of each predictor is used in the PCA analysis, the code
does a quick check to make sure that each predictor has at least two
distinct values. If a predictor has one unique value, it is removed prior to
the analysis.
</p>


<h3>Value</h3>

<p>For <code>pcaNNet</code>, an object of <code>"pcaNNet"</code> or
<code>"pcaNNet.formula"</code>. Items of interest in the output are: </p>
<table>
<tr><td><code>pc</code></td>
<td>
<p>the output from <code><a href="#topic+preProcess">preProcess</a></code></p>
</td></tr> <tr><td><code>model</code></td>
<td>
<p>the model
generated from <code><a href="nnet.html#topic+nnet">nnet</a></code></p>
</td></tr> <tr><td><code>names</code></td>
<td>
<p>if any predictors had
only one distinct value, this is a character string of the remaining
columns. Otherwise a value of <code>NULL</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>These are heavily based on the <code>nnet</code> code from Brian Ripley.
</p>


<h3>References</h3>

<p>Ripley, B. D. (1996) <em>Pattern Recognition and Neural
Networks.</em> Cambridge.
</p>


<h3>See Also</h3>

<p><code><a href="nnet.html#topic+nnet">nnet</a></code>, <code><a href="#topic+preProcess">preProcess</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BloodBrain)
modelFit &lt;- pcaNNet(bbbDescr[, 1:10], logBBB, size = 5, linout = TRUE, trace = FALSE)
modelFit

predict(modelFit, bbbDescr[, 1:10])

</code></pre>

<hr>
<h2 id='pickSizeBest'>Backwards Feature Selection Helper Functions</h2><span id='topic+pickSizeBest'></span><span id='topic+pickSizeTolerance'></span><span id='topic+pickVars'></span><span id='topic+caretFuncs'></span><span id='topic+lmFuncs'></span><span id='topic+rfFuncs'></span><span id='topic+gamFuncs'></span><span id='topic+treebagFuncs'></span><span id='topic+ldaFuncs'></span><span id='topic+nbFuncs'></span><span id='topic+lrFuncs'></span>

<h3>Description</h3>

<p>Ancillary functions for backwards selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pickSizeBest(x, metric, maximize)

pickSizeTolerance(x, metric, tol = 1.5, maximize)

pickVars(y, size)

caretFuncs

ldaFuncs

treebagFuncs

gamFuncs

rfFuncs

lmFuncs

nbFuncs

lrFuncs
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pickSizeBest_+3A_x">x</code></td>
<td>
<p>a matrix or data frame with the performance metric of interest</p>
</td></tr>
<tr><td><code id="pickSizeBest_+3A_metric">metric</code></td>
<td>
<p>a character string with the name of the performance metric
that should be used to choose the appropriate number of variables</p>
</td></tr>
<tr><td><code id="pickSizeBest_+3A_maximize">maximize</code></td>
<td>
<p>a logical; should the metric be maximized?</p>
</td></tr>
<tr><td><code id="pickSizeBest_+3A_tol">tol</code></td>
<td>
<p>a scalar to denote the acceptable difference in optimal
performance (see Details below)</p>
</td></tr>
<tr><td><code id="pickSizeBest_+3A_y">y</code></td>
<td>
<p>a list of data frames with variables <code>Overall</code> and <code>var</code></p>
</td></tr>
<tr><td><code id="pickSizeBest_+3A_size">size</code></td>
<td>
<p>an integer for the number of variables to retain</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 6.
</p>
<p>An object of class <code>list</code> of length 6.
</p>
<p>An object of class <code>list</code> of length 6.
</p>
<p>An object of class <code>list</code> of length 6.
</p>
<p>An object of class <code>list</code> of length 6.
</p>
<p>An object of class <code>list</code> of length 6.
</p>
<p>An object of class <code>list</code> of length 6.
</p>
<p>An object of class <code>list</code> of length 6.
</p>


<h3>Details</h3>

<p>This page describes the functions that are used in backwards selection (aka
recursive feature elimination). The functions described here are passed to
the algorithm via the <code>functions</code> argument of <code><a href="#topic+rfeControl">rfeControl</a></code>.
</p>
<p>See <code><a href="#topic+rfeControl">rfeControl</a></code> for details on how these functions should be
defined.
</p>
<p>The 'pick' functions are used to find the appropriate subset size for
different situations. <code>pickBest</code> will find the position associated with
the numerically best value (see the <code>maximize</code> argument to help define
this).
</p>
<p><code>pickSizeTolerance</code> picks the lowest position (i.e. the smallest subset
size) that has no more of an X percent loss in performances. When
maximizing, it calculates (O-X)/O*100, where X is the set of performance
values and O is max(X). This is the percent loss. When X is to be minimized,
it uses (X-O)/O*100 (so that values greater than X have a positive &quot;loss&quot;).
The function finds the smallest subset size that has a percent loss less
than <code>tol</code>.
</p>
<p>Both of the 'pick' functions assume that the data are sorted from smallest
subset size to largest.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rfeControl">rfeControl</a></code>, <code><a href="#topic+rfe">rfe</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## For picking subset sizes:
## Minimize the RMSE
example &lt;- data.frame(RMSE = c(1.2, 1.1, 1.05, 1.01, 1.01, 1.03, 1.00),
                      Variables = 1:7)
## Percent Loss in performance (positive)
example$PctLoss &lt;- (example$RMSE - min(example$RMSE))/min(example$RMSE)*100

xyplot(RMSE ~ Variables, data= example)
xyplot(PctLoss ~ Variables, data= example)

absoluteBest &lt;- pickSizeBest(example, metric = "RMSE", maximize = FALSE)
within5Pct &lt;- pickSizeTolerance(example, metric = "RMSE", maximize = FALSE)

cat("numerically optimal:",
    example$RMSE[absoluteBest],
    "RMSE in position",
    absoluteBest, "\n")
cat("Accepting a 1.5 pct loss:",
    example$RMSE[within5Pct],
    "RMSE in position",
    within5Pct, "\n")

## Example where we would like to maximize
example2 &lt;- data.frame(Rsquared = c(0.4, 0.6, 0.94, 0.95, 0.95, 0.95, 0.95),
                      Variables = 1:7)
## Percent Loss in performance (positive)
example2$PctLoss &lt;- (max(example2$Rsquared) - example2$Rsquared)/max(example2$Rsquared)*100

xyplot(Rsquared ~ Variables, data= example2)
xyplot(PctLoss ~ Variables, data= example2)

absoluteBest2 &lt;- pickSizeBest(example2, metric = "Rsquared", maximize = TRUE)
within5Pct2 &lt;- pickSizeTolerance(example2, metric = "Rsquared", maximize = TRUE)

cat("numerically optimal:",
    example2$Rsquared[absoluteBest2],
    "R^2 in position",
    absoluteBest2, "\n")
cat("Accepting a 1.5 pct loss:",
    example2$Rsquared[within5Pct2],
    "R^2 in position",
    within5Pct2, "\n")

</code></pre>

<hr>
<h2 id='plot.gafs'>Plot Method for the gafs and safs Classes</h2><span id='topic+plot.gafs'></span><span id='topic+plot.safs'></span><span id='topic+ggplot.gafs'></span><span id='topic+ggplot.safs'></span>

<h3>Description</h3>

<p>Plot the performance values versus search iteration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gafs'
plot(
  x,
  metric = x$control$metric["external"],
  estimate = c("internal", "external"),
  output = "ggplot",
  ...
)

## S3 method for class 'gafs'
ggplot(data = NULL, mapping = NULL, ..., environment = NULL)

## S3 method for class 'safs'
ggplot(data = NULL, mapping = NULL, ..., environment = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gafs_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+gafs">gafs</a></code> or <code><a href="#topic+safs">safs</a></code></p>
</td></tr>
<tr><td><code id="plot.gafs_+3A_metric">metric</code></td>
<td>
<p>the measure of performance to plot (e.g. RMSE, accuracy, etc)</p>
</td></tr>
<tr><td><code id="plot.gafs_+3A_estimate">estimate</code></td>
<td>
<p>the type of estimate: either &quot;internal&quot; or &quot;external&quot;</p>
</td></tr>
<tr><td><code id="plot.gafs_+3A_output">output</code></td>
<td>
<p>either &quot;data&quot;, &quot;ggplot&quot; or &quot;lattice&quot;</p>
</td></tr>
<tr><td><code id="plot.gafs_+3A_...">...</code></td>
<td>
<p>For <code>plot</code> methods, these are options passed
to <code><a href="lattice.html#topic+xyplot">xyplot</a></code>. For <code>ggplot</code> methods,
they are not used.</p>
</td></tr>
<tr><td><code id="plot.gafs_+3A_data">data</code>, <code id="plot.gafs_+3A_mapping">mapping</code>, <code id="plot.gafs_+3A_environment">environment</code></td>
<td>
<p>kept for consistency with
<code>ggplot</code> and are not used here.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean (averaged over the resamples) is plotted against the search
iteration using a scatter plot.
</p>
<p>When <code>output = "data"</code>, the unaveraged data are returned with columns
for all the performance metrics and the resample indicator.
</p>


<h3>Value</h3>

<p>Either a data frame, ggplot object or lattice object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gafs">gafs</a></code>, <code><a href="#topic+safs">safs</a></code>,
<code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>, <code><a href="lattice.html#topic+xyplot">xyplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(1)
train_data &lt;- twoClassSim(100, noiseVars = 10)
test_data  &lt;- twoClassSim(10,  noiseVars = 10)

## A short example
ctrl &lt;- safsControl(functions = rfSA,
                    method = "cv",
                    number = 3)

rf_search &lt;- safs(x = train_data[, -ncol(train_data)],
                  y = train_data$Class,
                  iters = 50,
                  safsControl = ctrl)

plot(rf_search)
plot(rf_search,
	 output = "lattice",
	 auto.key = list(columns = 2))

plot_data &lt;- plot(rf_search, output = "data")
summary(plot_data)
    
## End(Not run)

</code></pre>

<hr>
<h2 id='plot.varImp.train'>Plotting variable importance measures</h2><span id='topic+plot.varImp.train'></span><span id='topic+ggplot.varImp.train'></span>

<h3>Description</h3>

<p>This function produces lattice and ggplot plots of objects with class
&quot;varImp.train&quot;. More info will be forthcoming.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varImp.train'
plot(x, top = dim(x$importance)[1], ...)

## S3 method for class 'varImp.train'
ggplot(
  data,
  mapping = NULL,
  top = dim(data$importance)[1],
  ...,
  environment = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.varImp.train_+3A_x">x</code>, <code id="plot.varImp.train_+3A_data">data</code></td>
<td>
<p>an object with class <code>varImp</code>.</p>
</td></tr>
<tr><td><code id="plot.varImp.train_+3A_top">top</code></td>
<td>
<p>a scalar numeric that specifies the number of variables to be
displayed (in order of importance)</p>
</td></tr>
<tr><td><code id="plot.varImp.train_+3A_...">...</code></td>
<td>
<p>arguments to pass to the lattice plot function
(<code><a href="lattice.html#topic+xyplot">dotplot</a></code> and <code><a href="#topic+panel.needle">panel.needle</a></code>)</p>
</td></tr>
<tr><td><code id="plot.varImp.train_+3A_mapping">mapping</code>, <code id="plot.varImp.train_+3A_environment">environment</code></td>
<td>
<p>unused arguments to make consistent with
<span class="pkg">ggplot2</span> generic method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For models where there is only one importance value, such a regression
models, a &quot;Pareto-type&quot; plot is produced where the variables are ranked by
their importance and a needle-plot is used to show the top variables.
Horizontal bar charts are used for <code>ggplot</code>.
</p>
<p>When there is more than one importance value per predictor, the same plot is
produced within conditioning panels for each class. The top predictors are
sorted by their average importance.
</p>


<h3>Value</h3>

<p>a lattice plot object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>

<hr>
<h2 id='plotClassProbs'>Plot Predicted Probabilities in Classification Models</h2><span id='topic+plotClassProbs'></span>

<h3>Description</h3>

<p>This function takes an object (preferably from the function
<code><a href="#topic+extractProb">extractProb</a></code>) and creates a lattice plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotClassProbs(object, plotType = "histogram", useObjects = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotClassProbs_+3A_object">object</code></td>
<td>
<p>an object (preferably from the function
<code><a href="#topic+extractProb">extractProb</a></code>. There should be columns for each level of the
class factor and columns named <code>obs</code>, <code>pred</code>, <code>model</code> (e.g.
&quot;rpart&quot;, &quot;nnet&quot; etc), <code>dataType</code> (e.g. &quot;Training&quot;, &quot;Test&quot; etc) and
optionally <code>objects</code> (for giving names to objects with the same model
type).</p>
</td></tr>
<tr><td><code id="plotClassProbs_+3A_plottype">plotType</code></td>
<td>
<p>either &quot;histogram&quot; or &quot;densityplot&quot;</p>
</td></tr>
<tr><td><code id="plotClassProbs_+3A_useobjects">useObjects</code></td>
<td>
<p>a logical; should the object name (if any) be used as a
conditioning variable?</p>
</td></tr>
<tr><td><code id="plotClassProbs_+3A_...">...</code></td>
<td>
<p>parameters to pass to <code><a href="lattice.html#topic+histogram">histogram</a></code> or
<code><a href="lattice.html#topic+densityplot">densityplot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the call to <code><a href="#topic+extractProb">extractProb</a></code> included test data, these data are
shown, but if unknowns were also included, these are not plotted
</p>


<h3>Value</h3>

<p>A lattice object. Note that the plot has to be printed to be
displayed (especially in a loop).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(mdrr)
set.seed(90)
inTrain &lt;- createDataPartition(mdrrClass, p = .5)[[1]]

trainData &lt;- mdrrDescr[inTrain,1:20]
testData &lt;- mdrrDescr[-inTrain,1:20]

trainY &lt;- mdrrClass[inTrain]
testY &lt;- mdrrClass[-inTrain]

ctrl &lt;- trainControl(method = "cv")

nbFit1 &lt;- train(trainData, trainY, "nb",
                trControl = ctrl,
                tuneGrid = data.frame(usekernel = TRUE, fL = 0))

nbFit2 &lt;- train(trainData, trainY, "nb",
                trControl = ctrl,
                tuneGrid = data.frame(usekernel = FALSE, fL = 0))


models &lt;- list(para = nbFit2, nonpara = nbFit1)

predProbs &lt;- extractProb(models, testX = testData,  testY = testY)

plotClassProbs(predProbs, useObjects = TRUE)
plotClassProbs(predProbs,
               subset = object == "para" &amp; dataType == "Test")
plotClassProbs(predProbs,
               useObjects = TRUE,
               plotType = "densityplot",
               auto.key = list(columns = 2))

## End(Not run)



</code></pre>

<hr>
<h2 id='plotObsVsPred'>Plot Observed versus Predicted Results in Regression and Classification
Models</h2><span id='topic+plotObsVsPred'></span>

<h3>Description</h3>

<p>This function takes an object (preferably from the function
<code><a href="#topic+extractPrediction">extractPrediction</a></code>) and creates a lattice plot. For numeric
outcomes, the observed and predicted data are plotted with a 45 degree
reference line and a smoothed fit. For factor outcomes, a dotplot plot is
produced with the accuracies for the different models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotObsVsPred(object, equalRanges = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotObsVsPred_+3A_object">object</code></td>
<td>
<p>an object (preferably from the function
<code><a href="#topic+extractPrediction">extractPrediction</a></code>. There should be columns named <code>obs</code>,
<code>pred</code>, <code>model</code> (e.g. &quot;rpart&quot;, &quot;nnet&quot; etc.)  and <code>dataType</code>
(e.g. &quot;Training&quot;, &quot;Test&quot; etc)</p>
</td></tr>
<tr><td><code id="plotObsVsPred_+3A_equalranges">equalRanges</code></td>
<td>
<p>a logical; should the x- and y-axis ranges be the same?</p>
</td></tr>
<tr><td><code id="plotObsVsPred_+3A_...">...</code></td>
<td>
<p>parameters to pass to <code><a href="lattice.html#topic+xyplot">xyplot</a></code> or
<code><a href="lattice.html#topic+xyplot">dotplot</a></code>, such as <code>auto.key</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the call to <code><a href="#topic+extractPrediction">extractPrediction</a></code> included test data, these
data are shown, but if unknowns were also included, they are not plotted
</p>


<h3>Value</h3>

<p>A lattice object. Note that the plot has to be printed to be
displayed (especially in a loop).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# regression example
data(BostonHousing)
rpartFit &lt;- train(BostonHousing[1:100, -c(4, 14)], 
                  BostonHousing$medv[1:100], 
                  "rpart", tuneLength = 9)
plsFit &lt;- train(BostonHousing[1:100, -c(4, 14)], 
                BostonHousing$medv[1:100], 
                "pls")

predVals &lt;- extractPrediction(list(rpartFit, plsFit), 
                              testX = BostonHousing[101:200, -c(4, 14)], 
                              testY = BostonHousing$medv[101:200], 
                              unkX = BostonHousing[201:300, -c(4, 14)])

plotObsVsPred(predVals)


#classification example
data(Satellite)
numSamples &lt;- dim(Satellite)[1]
set.seed(716)

varIndex &lt;- 1:numSamples

trainSamples &lt;- sample(varIndex, 150)

varIndex &lt;- (1:numSamples)[-trainSamples]
testSamples &lt;- sample(varIndex, 100)

varIndex &lt;- (1:numSamples)[-c(testSamples, trainSamples)]
unkSamples &lt;- sample(varIndex, 50)

trainX &lt;- Satellite[trainSamples, -37]
trainY &lt;- Satellite[trainSamples, 37]

testX &lt;- Satellite[testSamples, -37]
testY &lt;- Satellite[testSamples, 37]

unkX &lt;- Satellite[unkSamples, -37]

knnFit  &lt;- train(trainX, trainY, "knn")
rpartFit &lt;- train(trainX, trainY, "rpart")

predTargets &lt;- extractPrediction(list(knnFit, rpartFit), 
                                 testX = testX, 
                                 testY = testY, 
                                 unkX = unkX)

plotObsVsPred(predTargets)

## End(Not run)

</code></pre>

<hr>
<h2 id='plsda'>Partial Least Squares and Sparse Partial Least Squares Discriminant Analysis</h2><span id='topic+plsda'></span><span id='topic+plsda.default'></span><span id='topic+predict.plsda'></span><span id='topic+splsda.default'></span><span id='topic+predict.splsda'></span><span id='topic+splsda'></span>

<h3>Description</h3>

<p><code>plsda</code> is used to fit standard PLS models for classification while
<code>splsda</code> performs sparse PLS that embeds feature selection and
regularization for the same purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plsda(x, ...)

## S3 method for class 'plsda'
predict(object, newdata = NULL, ncomp = NULL, type = "class", ...)

## Default S3 method:
plsda(x, y, ncomp = 2, probMethod = "softmax", prior = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plsda_+3A_x">x</code></td>
<td>
<p>a matrix or data frame of predictors</p>
</td></tr>
<tr><td><code id="plsda_+3A_...">...</code></td>
<td>
<p>arguments to pass to <code><a href="pls.html#topic+mvr">plsr</a></code> or
<code><a href="spls.html#topic+spls">spls</a></code>. For <code>splsda</code>, this is the method for passing
tuning parameters specifications (e.g. <code>K</code>, <code>eta</code> or <code>kappa</code>)</p>
</td></tr>
<tr><td><code id="plsda_+3A_object">object</code></td>
<td>
<p>an object produced by <code>plsda</code></p>
</td></tr>
<tr><td><code id="plsda_+3A_newdata">newdata</code></td>
<td>
<p>a matrix or data frame of predictors</p>
</td></tr>
<tr><td><code id="plsda_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to include in the model. Predictions
can be made for models with values less than <code>ncomp</code>.</p>
</td></tr>
<tr><td><code id="plsda_+3A_type">type</code></td>
<td>
<p>either <code>"class"</code>, <code>"prob"</code> or <code>"raw"</code> to produce
the predicted class, class probabilities or the raw model scores,
respectively.</p>
</td></tr>
<tr><td><code id="plsda_+3A_y">y</code></td>
<td>
<p>a factor or indicator matrix for the discrete outcome. If a matrix,
the entries must be either 0 or 1 and rows must sum to one</p>
</td></tr>
<tr><td><code id="plsda_+3A_probmethod">probMethod</code></td>
<td>
<p>either &quot;softmax&quot; or &quot;Bayes&quot; (see Details)</p>
</td></tr>
<tr><td><code id="plsda_+3A_prior">prior</code></td>
<td>
<p>a vector or prior probabilities for the classes (only used for
<code>probeMethod = "Bayes"</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a factor is supplied, the appropriate indicator matrix is created.
</p>
<p>A multivariate PLS model is fit to the indicator matrix using the
<code><a href="pls.html#topic+mvr">plsr</a></code> or <code><a href="spls.html#topic+spls">spls</a></code> function.
</p>
<p>Two prediction methods can be used.
</p>
<p>The <b>softmax function</b> transforms the model predictions to
&quot;probability-like&quot; values (e.g. on [0, 1] and sum to 1). The class with the
largest class probability is the predicted class.
</p>
<p>Also, <b>Bayes rule</b> can be applied to the model predictions to form
posterior probabilities. Here, the model predictions for the training set
are used along with the training set outcomes to create conditional
distributions for each class. When new samples are predicted, the raw model
predictions are run through these conditional distributions to produce a
posterior probability for each class (along with the prior). This process is
repeated <code>ncomp</code> times for every possible PLS model. The
<code><a href="klaR.html#topic+NaiveBayes">NaiveBayes</a></code> function is used with <code>usekernel = TRUE</code>
for the posterior probability calculations.
</p>


<h3>Value</h3>

<p>For <code>plsda</code>, an object of class &quot;plsda&quot; and &quot;mvr&quot;. For
<code>splsda</code>, an object of class <code>splsda</code>.
</p>
<p>The predict methods produce either a vector, matrix or three-dimensional
array, depending on the values of <code>type</code> of <code>ncomp</code>. For example,
specifying more than one value of <code>ncomp</code> with <code>type = "class"</code>
with produce a three dimensional array but the default specification would
produce a factor vector.
</p>


<h3>See Also</h3>

<p><code><a href="pls.html#topic+mvr">plsr</a></code>, <code><a href="spls.html#topic+spls">spls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(mdrr)
set.seed(1)
inTrain &lt;- sample(seq(along = mdrrClass), 450)

nzv &lt;- nearZeroVar(mdrrDescr)
filteredDescr &lt;- mdrrDescr[, -nzv]

training &lt;- filteredDescr[inTrain,]
test &lt;- filteredDescr[-inTrain,]
trainMDRR &lt;- mdrrClass[inTrain]
testMDRR &lt;- mdrrClass[-inTrain]

preProcValues &lt;- preProcess(training)

trainDescr &lt;- predict(preProcValues, training)
testDescr &lt;- predict(preProcValues, test)

useBayes   &lt;- plsda(trainDescr, trainMDRR, ncomp = 5,
                    probMethod = "Bayes")
useSoftmax &lt;- plsda(trainDescr, trainMDRR, ncomp = 5)

confusionMatrix(predict(useBayes, testDescr),
                testMDRR)

confusionMatrix(predict(useSoftmax, testDescr),
                testMDRR)

histogram(~predict(useBayes, testDescr, type = "prob")[,"Active",]
          | testMDRR, xlab = "Active Prob", xlim = c(-.1,1.1))
histogram(~predict(useSoftmax, testDescr, type = "prob")[,"Active",]
          | testMDRR, xlab = "Active Prob", xlim = c(-.1,1.1))


## different sized objects are returned
length(predict(useBayes, testDescr))
dim(predict(useBayes, testDescr, ncomp = 1:3))
dim(predict(useBayes, testDescr, type = "prob"))
dim(predict(useBayes, testDescr, type = "prob", ncomp = 1:3))

## Using spls:
## (As of 11/09, the spls package now has a similar function with
## the same mane. To avoid conflicts, use caret:::splsda to
## get this version)

splsFit &lt;- caret:::splsda(trainDescr, trainMDRR,
                          K = 5, eta = .9,
                          probMethod = "Bayes")

confusionMatrix(caret:::predict.splsda(splsFit, testDescr),
                testMDRR)

## End(Not run)

</code></pre>

<hr>
<h2 id='pottery'>Pottery from Pre-Classical Sites in Italy</h2><span id='topic+pottery'></span><span id='topic+potteryClass'></span>

<h3>Description</h3>

<p>Measurements of 58 pottery samples.
</p>


<h3>Value</h3>

<table>
<tr><td><code>pottery</code></td>
<td>
<p>11 elemental composition measurements </p>
</td></tr>
<tr><td><code>potteryClass</code></td>
<td>
<p>factor of pottery type: black carbon containing bulks
(A) and clayey (B)</p>
</td></tr>
</table>


<h3>Source</h3>

<p>R. G. Brereton (2003). <em>Chemometrics: Data Analysis for the
Laboratory and Chemical Plant</em>, pg. 261.
</p>

<hr>
<h2 id='prcomp.resamples'>Principal Components Analysis of Resampling Results</h2><span id='topic+prcomp.resamples'></span><span id='topic+cluster.resamples'></span><span id='topic+cluster'></span><span id='topic+plot.prcomp.resamples'></span>

<h3>Description</h3>

<p>Performs a principal components analysis on an object of class
<code><a href="#topic+resamples">resamples</a></code> and returns the results as an object with classes
<code>prcomp.resamples</code> and <code>prcomp</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'resamples'
prcomp(x, metric = x$metrics[1], ...)

## S3 method for class 'prcomp.resamples'
plot(x, what = "scree", dims = max(2, ncol(x$rotation)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prcomp.resamples_+3A_x">x</code></td>
<td>
<p>For <code>prcomp</code>, an object of class <code><a href="#topic+resamples">resamples</a></code> and
for <code>plot.prcomp.resamples</code>, an object of class
<code>plot.prcomp.resamples</code></p>
</td></tr>
<tr><td><code id="prcomp.resamples_+3A_metric">metric</code></td>
<td>
<p>a performance metric that was estimated for every resample</p>
</td></tr>
<tr><td><code id="prcomp.resamples_+3A_...">...</code></td>
<td>
<p>For <code>prcomp.resamples</code>, options to pass to
<code><a href="stats.html#topic+prcomp">prcomp</a></code>, for <code>plot.prcomp.resamples</code>, options to
pass to Lattice objects (see Details below) and, for
<code>cluster.resamples</code>, options to pass to <code>hclust</code>.</p>
</td></tr>
<tr><td><code id="prcomp.resamples_+3A_what">what</code></td>
<td>
<p>the type of plot: <code>"scree"</code> produces a bar chart of
standard deviations, <code>"cumulative"</code> produces a bar chart of the
cumulative percent of variance, <code>"loadings"</code> produces a scatterplot
matrix of the loading values and <code>"components"</code> produces a scatterplot
matrix of the PCA components</p>
</td></tr>
<tr><td><code id="prcomp.resamples_+3A_dims">dims</code></td>
<td>
<p>The number of dimensions to plot when <code>what = "loadings"</code>
or <code>what = "components"</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The principal components analysis treats the models as variables and the
resamples are realizations of the variables. In this way, we can use PCA to
&quot;cluster&quot; the assays and look for similarities. Most of the methods for
<code><a href="stats.html#topic+prcomp">prcomp</a></code> can be used, although custom <code>print</code> and
<code>plot</code> methods are used.
</p>
<p>The plot method uses lattice graphics. When <code>what = "scree"</code> or
<code>what = "cumulative"</code>, <code><a href="lattice.html#topic+xyplot">barchart</a></code> is used.
When <code>what = "loadings"</code> or <code>what = "components"</code>, either
<code><a href="lattice.html#topic+xyplot">xyplot</a></code> or <code><a href="lattice.html#topic+splom">splom</a></code>
are used (the latter when <code>dims</code> &gt; 2). Options can be passed to these
methods using <code>...</code>.
</p>
<p>When <code>what = "loadings"</code> or <code>what = "components"</code>, the plots are
put on a common scale so that later components are less likely to be
over-interpreted. See Geladi et al. (2003) for examples of why this can be
important.
</p>
<p>For clustering, <code><a href="stats.html#topic+hclust">hclust</a></code> is used to determine clusters of
models based on the resampled performance values.
</p>


<h3>Value</h3>

<p>For <code>prcomp.resamples</code>, an object with classes
<code>prcomp.resamples</code> and <code>prcomp</code>. This object is the same as the
object produced by <code>prcomp</code>, but with additional elements: </p>
<table>
<tr><td><code>metric</code></td>
<td>
<p>the value for the <code>metric</code> argument</p>
</td></tr> <tr><td><code>call</code></td>
<td>
<p>the call</p>
</td></tr>
</table>
<p>For <code>plot.prcomp.resamples</code>, a Lattice object (see Details above)
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Geladi, P.; Manley, M.; and Lestander, T. (2003), &quot;Scatter
plotting in multivariate data analysis,&quot; J. Chemometrics, 17: 503-511
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resamples">resamples</a></code>, <code><a href="lattice.html#topic+xyplot">barchart</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>, <code><a href="lattice.html#topic+splom">splom</a></code>,
<code><a href="stats.html#topic+hclust">hclust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#load(url("http://topepo.github.io/caret/exampleModels.RData"))

resamps &lt;- resamples(list(CART = rpartFit,
                          CondInfTree = ctreeFit,
                          MARS = earthFit))
resampPCA &lt;- prcomp(resamps)

resampPCA

plot(resampPCA, what = "scree")

plot(resampPCA, what = "components")

plot(resampPCA, what = "components", dims = 2, auto.key = list(columns = 3))

clustered &lt;- cluster(resamps)
plot(clustered)


## End(Not run)
</code></pre>

<hr>
<h2 id='predict.bagEarth'>Predicted values based on bagged Earth and FDA models</h2><span id='topic+predict.bagEarth'></span><span id='topic+predict.bagFDA'></span>

<h3>Description</h3>

<p>Predicted values based on bagged Earth and FDA models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bagEarth'
predict(object, newdata = NULL, type = NULL, ...)

## S3 method for class 'bagFDA'
predict(object, newdata = NULL, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.bagEarth_+3A_object">object</code></td>
<td>
<p>Object of class inheriting from <code>bagEarth</code></p>
</td></tr>
<tr><td><code id="predict.bagEarth_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame or matrix in which to look for
variables with which to predict.  If omitted, the fitted values are used
(see note below).</p>
</td></tr>
<tr><td><code id="predict.bagEarth_+3A_type">type</code></td>
<td>
<p>The type of prediction. For bagged <code><a href="earth.html#topic+earth">earth</a></code>
regression model, <code>type = "response"</code> will produce a numeric vector of
the usual model predictions. <code><a href="earth.html#topic+earth">earth</a></code> also allows the user
to fit generalized linear models. In this case, <code>type = "response"</code>
produces the inverse link results as a vector. In the case of a binomial
generalized linear model, <code>type = "response"</code> produces a vector of
probabilities, <code>type = "class"</code> generates a factor vector and
<code>type = "prob"</code> produces a two-column matrix with probabilities for
both classes (averaged across the individual models). Similarly, for bagged
<code><a href="mda.html#topic+fda">fda</a></code> models, <code>type = "class"</code> generates a factor
vector and <code>type = "probs"</code> outputs a matrix of class probabilities.</p>
</td></tr>
<tr><td><code id="predict.bagEarth_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predictions (for regression or <code>type = "class"</code>)
or a data frame of class probabilities. By default, when the model
predicts a number, a vector of numeric predictions is returned. When
a classification model is used, the default prediction is a factor vector
of classes.
</p>


<h3>Note</h3>

<p>If the predictions for the original training set are needed, there are
two ways to calculate them. First, the original data set can be predicted by
each bagged earth model. Secondly, the predictions from each bootstrap
sample could be used (but are more likely to overfit). If the original call
to <code>bagEarth</code> or <code>bagFDA</code> had <code>keepX = TRUE</code>, the first
method is used, otherwise the values are calculated via the second method.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bagEarth">bagEarth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(trees)
## out of bag predictions vs just re-predicting the training set
set.seed(655)
fit1 &lt;- bagEarth(Volume ~ ., data = trees, keepX = TRUE)
set.seed(655)
fit2 &lt;- bagEarth(Volume ~ ., data = trees, keepX = FALSE)
hist(predict(fit1) - predict(fit2))

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.gafs'>Predict new samples</h2><span id='topic+predict.gafs'></span><span id='topic+predict.safs'></span>

<h3>Description</h3>

<p>Predict new samples using <code><a href="#topic+safs">safs</a></code> and <code><a href="#topic+gafs">gafs</a></code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gafs'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gafs_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+safs">safs</a></code> or <code><a href="#topic+gafs">gafs</a></code></p>
</td></tr>
<tr><td><code id="predict.gafs_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or matrix of predictors.</p>
</td></tr>
<tr><td><code id="predict.gafs_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only the predictors listed in <code>object$optVariables</code> are required.
</p>


<h3>Value</h3>

<p>The type of result depends on what was specified in
<code>object$control$functions$predict</code>.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+safs">safs</a></code>, <code><a href="#topic+gafs">gafs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

set.seed(1)
train_data &lt;- twoClassSim(100, noiseVars = 10)
test_data  &lt;- twoClassSim(10,  noiseVars = 10)

## A short example
ctrl &lt;- safsControl(functions = rfSA,
                    method = "cv",
                    number = 3)

rf_search &lt;- safs(x = train_data[, -ncol(train_data)],
                  y = train_data$Class,
                  iters = 3,
                  safsControl = ctrl)

rf_search

predict(rf_search, train_data)

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.knn3'>Predictions from k-Nearest Neighbors</h2><span id='topic+predict.knn3'></span>

<h3>Description</h3>

<p>Predict the class of a new observation based on k-NN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'knn3'
predict(object, newdata, type = c("prob", "class"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.knn3_+3A_object">object</code></td>
<td>
<p>object of class <code>knn3</code>.</p>
</td></tr>
<tr><td><code id="predict.knn3_+3A_newdata">newdata</code></td>
<td>
<p>a data frame of new observations.</p>
</td></tr>
<tr><td><code id="predict.knn3_+3A_type">type</code></td>
<td>
<p>return either the predicted class or the proportion of the votes
for the winning class.</p>
</td></tr>
<tr><td><code id="predict.knn3_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code><a href="stats.html#topic+predict">predict</a></code> for
class <code>knn3</code>. For the details see <code><a href="#topic+knn3">knn3</a></code>. This is
essentially a copy of <code><a href="ipred.html#topic+predict.ipredknn">predict.ipredknn</a></code>.
</p>


<h3>Value</h3>

<p>Either the predicted class or the proportion of the votes for each
class.
</p>


<h3>Author(s)</h3>

<p><code><a href="ipred.html#topic+predict.ipredknn">predict.ipredknn</a></code> by Torsten.Hothorn
&lt;Torsten.Hothorn@rzmail.uni-erlangen.de&gt;
</p>

<hr>
<h2 id='predict.knnreg'>Predictions from k-Nearest Neighbors Regression Model</h2><span id='topic+predict.knnreg'></span>

<h3>Description</h3>

<p>Predict the outcome of a new observation based on k-NN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'knnreg'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.knnreg_+3A_object">object</code></td>
<td>
<p>object of class <code>knnreg</code>.</p>
</td></tr>
<tr><td><code id="predict.knnreg_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or matrix of new observations.</p>
</td></tr>
<tr><td><code id="predict.knnreg_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code><a href="stats.html#topic+predict">predict</a></code> for
class <code>knnreg</code>. For the details see <code><a href="#topic+knnreg">knnreg</a></code>. This is
essentially a copy of <code><a href="ipred.html#topic+predict.ipredknn">predict.ipredknn</a></code>.
</p>


<h3>Value</h3>

<p>a numeric vector
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, Chris Keefer, adapted from <code><a href="class.html#topic+knn">knn</a></code> and
<code><a href="ipred.html#topic+predict.ipredknn">predict.ipredknn</a></code>
</p>

<hr>
<h2 id='predictors'>List predictors used in the model</h2><span id='topic+predictors'></span><span id='topic+predictors.formula'></span><span id='topic+predictors.terms'></span><span id='topic+predictors.train'></span><span id='topic+predictors.default'></span><span id='topic+predictors.list'></span><span id='topic+predictors.rfe'></span><span id='topic+predictors.sbf'></span>

<h3>Description</h3>

<p>This class uses a model fit to determine which predictors were used in the
final model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictors(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictors_+3A_x">x</code></td>
<td>
<p>a model object, list or terms</p>
</td></tr>
<tr><td><code id="predictors_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, <code><a href="party.html#topic+cforest">cforest</a></code>,
<code><a href="party.html#topic+ctree">ctree</a></code>, <code><a href="rpart.html#topic+rpart">rpart</a></code>,
<code><a href="ipred.html#topic+bagging">ipredbagg</a></code>, <code><a href="ipred.html#topic+bagging">bagging</a></code>,
<code><a href="earth.html#topic+earth">earth</a></code>, <code><a href="mda.html#topic+fda">fda</a></code>,
<code><a href="pamr.html#topic+pamr.train">pamr.train</a></code>, <code><a href="superpc.html#topic+superpc.train">superpc.train</a></code>,
<code><a href="#topic+bagEarth">bagEarth</a></code> and <code><a href="#topic+bagFDA">bagFDA</a></code>, an attempt was made to
report the predictors that were actually used in the final model.
</p>
<p>The <code>predictors</code> function can be called on the model object (as opposed
to the <code><a href="#topic+train">train</a></code>) object) and the package will try to find the
appropriate coed (if it exists).
</p>
<p>In cases where the predictors cannot be determined, <code>NA</code> is returned.
For example, <code><a href="nnet.html#topic+nnet">nnet</a></code> may return missing values from
<code>predictors</code>.
</p>


<h3>Value</h3>

<p>a character string of predictors or <code>NA</code>.
</p>

<hr>
<h2 id='preProcess'>Pre-Processing of Predictors</h2><span id='topic+preProcess'></span><span id='topic+preProcess.default'></span><span id='topic+predict.preProcess'></span>

<h3>Description</h3>

<p>Pre-processing transformation (centering, scaling etc.) can be estimated
from the training data and applied to any data set with the same variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preProcess(x, ...)

## Default S3 method:
preProcess(
  x,
  method = c("center", "scale"),
  thresh = 0.95,
  pcaComp = NULL,
  na.remove = TRUE,
  k = 5,
  knnSummary = mean,
  outcome = NULL,
  fudge = 0.2,
  numUnique = 3,
  verbose = FALSE,
  freqCut = 95/5,
  uniqueCut = 10,
  cutoff = 0.9,
  rangeBounds = c(0, 1),
  ...
)

## S3 method for class 'preProcess'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preProcess_+3A_x">x</code></td>
<td>
<p>a matrix or data frame. Non-numeric predictors are allowed but will
be ignored.</p>
</td></tr>
<tr><td><code id="preProcess_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="fastICA.html#topic+fastICA">fastICA</a></code>,
such as <code>n.comp</code></p>
</td></tr>
<tr><td><code id="preProcess_+3A_method">method</code></td>
<td>
<p>a character vector specifying the type of processing. Possible
values are &quot;BoxCox&quot;, &quot;YeoJohnson&quot;, &quot;expoTrans&quot;, &quot;center&quot;, &quot;scale&quot;, &quot;range&quot;,
&quot;knnImpute&quot;, &quot;bagImpute&quot;, &quot;medianImpute&quot;, &quot;pca&quot;, &quot;ica&quot;, &quot;spatialSign&quot;, &quot;corr&quot;, &quot;zv&quot;,
&quot;nzv&quot;, and &quot;conditionalX&quot; (see Details below)</p>
</td></tr>
<tr><td><code id="preProcess_+3A_thresh">thresh</code></td>
<td>
<p>a cutoff for the cumulative percent of variance to be retained
by PCA</p>
</td></tr>
<tr><td><code id="preProcess_+3A_pcacomp">pcaComp</code></td>
<td>
<p>the specific number of PCA components to keep. If specified,
this over-rides <code>thresh</code></p>
</td></tr>
<tr><td><code id="preProcess_+3A_na.remove">na.remove</code></td>
<td>
<p>a logical; should missing values be removed from the
calculations?</p>
</td></tr>
<tr><td><code id="preProcess_+3A_k">k</code></td>
<td>
<p>the number of nearest neighbors from the training set to use for
imputation</p>
</td></tr>
<tr><td><code id="preProcess_+3A_knnsummary">knnSummary</code></td>
<td>
<p>function to average the neighbor values per column during
imputation</p>
</td></tr>
<tr><td><code id="preProcess_+3A_outcome">outcome</code></td>
<td>
<p>a numeric or factor vector for the training set outcomes.
This can be used to help estimate the Box-Cox transformation of the
predictor variables (see Details below)</p>
</td></tr>
<tr><td><code id="preProcess_+3A_fudge">fudge</code></td>
<td>
<p>a tolerance value: Box-Cox transformation lambda values within
+/-fudge will be coerced to 0 and within 1+/-fudge will be coerced to 1.</p>
</td></tr>
<tr><td><code id="preProcess_+3A_numunique">numUnique</code></td>
<td>
<p>how many unique values should <code>y</code> have to estimate the
Box-Cox transformation?</p>
</td></tr>
<tr><td><code id="preProcess_+3A_verbose">verbose</code></td>
<td>
<p>a logical: prints a log as the computations proceed</p>
</td></tr>
<tr><td><code id="preProcess_+3A_freqcut">freqCut</code></td>
<td>
<p>the cutoff for the ratio of the most common value to the
second most common value. See <code><a href="#topic+nearZeroVar">nearZeroVar</a></code>.</p>
</td></tr>
<tr><td><code id="preProcess_+3A_uniquecut">uniqueCut</code></td>
<td>
<p>the cutoff for the percentage of distinct values out of
the number of total samples. See <code><a href="#topic+nearZeroVar">nearZeroVar</a></code>.</p>
</td></tr>
<tr><td><code id="preProcess_+3A_cutoff">cutoff</code></td>
<td>
<p>a numeric value for the pair-wise absolute correlation cutoff.
See <code><a href="#topic+findCorrelation">findCorrelation</a></code>.</p>
</td></tr>
<tr><td><code id="preProcess_+3A_rangebounds">rangeBounds</code></td>
<td>
<p>a two-element numeric vector specifying closed interval
for range transformation</p>
</td></tr>
<tr><td><code id="preProcess_+3A_object">object</code></td>
<td>
<p>an object of class <code>preProcess</code></p>
</td></tr>
<tr><td><code id="preProcess_+3A_newdata">newdata</code></td>
<td>
<p>a matrix or data frame of new data to be pre-processed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In all cases, transformations and operations are estimated using the data in
<code>x</code> and these operations are applied to new data using these values;
nothing is recomputed when using the <code>predict</code> function.
</p>
<p>The Box-Cox (<code>method = "BoxCox"</code>), Yeo-Johnson (<code>method =
"YeoJohnson"</code>), and exponential transformations (<code>method =
"expoTrans"</code>) have been &quot;repurposed&quot; here: they are being used to transform
the predictor variables. The Box-Cox transformation was developed for
transforming the response variable while another method, the Box-Tidwell
transformation, was created to estimate transformations of predictor data.
However, the Box-Cox method is simpler, more computationally efficient and
is equally effective for estimating power transformations. The Yeo-Johnson
transformation is similar to the Box-Cox model but can accommodate
predictors with zero and/or negative values (while the predictors values for
the Box-Cox transformation must be strictly positive). The exponential
transformation of Manly (1976) can also be used for positive or negative
data.
</p>
<p><code>method = "center"</code> subtracts the mean of the predictor's data (again
from the data in <code>x</code>) from the predictor values while <code>method =
"scale"</code> divides by the standard deviation.
</p>
<p>The &quot;range&quot; transformation scales the data to be within <code>rangeBounds</code>. If new
samples have values larger or smaller than those in the training set, values
will be outside of this range.
</p>
<p>Predictors that are not numeric are ignored in the calculations (including
methods &quot;zv'&quot; and &quot;nzv'&quot;).
</p>
<p><code>method = "zv"</code> identifies numeric predictor columns with a single
value (i.e. having zero variance) and excludes them from further
calculations. Similarly, <code>method = "nzv"</code> does the same by applying
<code><a href="#topic+nearZeroVar">nearZeroVar</a></code> exclude &quot;near zero-variance&quot; predictors. The options
<code>freqCut</code> and <code>uniqueCut</code> can be used to modify the filter.
</p>
<p><code>method = "corr"</code> seeks to filter out highly correlated predictors. See
<code><a href="#topic+findCorrelation">findCorrelation</a></code>.
</p>
<p>For classification, <code>method = "conditionalX"</code> examines the distribution
of each predictor conditional on the outcome. If there is only one unique
value within any class, the predictor is excluded from further calculations
(see <code><a href="#topic+checkConditionalX">checkConditionalX</a></code> for an example). When <code>outcome</code> is
not a factor, this calculation is not executed. This operation can be time
consuming when used within resampling via <code><a href="#topic+train">train</a></code>.
</p>
<p>The operations are applied in this order: zero-variance filter, near-zero
variance filter, correlation filter, Box-Cox/Yeo-Johnson/exponential transformation, centering,
scaling, range, imputation, PCA, ICA then spatial sign. This is a departure
from versions of <span class="pkg">caret</span> prior to version 4.76 (where imputation was
done first) and is not backwards compatible if bagging was used for
imputation.
</p>
<p>If PCA is requested but centering and scaling are not, the values will still
be centered and scaled. Similarly, when ICA is requested, the data are
automatically centered and scaled.
</p>
<p>k-nearest neighbor imputation is carried out by finding the k closest
samples (Euclidian distance) in the training set. Imputation via bagging
fits a bagged tree model for each predictor (as a function of all the
others). This method is simple, accurate and accepts missing values, but it
has much higher computational cost. Imputation via medians takes the median
of each predictor in the training set, and uses them to fill missing values.
This method is simple, fast, and accepts missing values, but treats each
predictor independently, and may be inaccurate.
</p>
<p>A warning is thrown if both PCA and ICA are requested. ICA, as implemented
by the <code><a href="fastICA.html#topic+fastICA">fastICA</a></code> package automatically does a PCA
decomposition prior to finding the ICA scores.
</p>
<p>The function will throw an error of any numeric variables in <code>x</code> has
less than two unique values unless either <code>method = "zv"</code> or
<code>method = "nzv"</code> are invoked.
</p>
<p>Non-numeric data will not be pre-processed and their values will be in the
data frame produced by the <code>predict</code> function. Note that when PCA or
ICA is used, the non-numeric columns may be in different positions when
predicted.
</p>


<h3>Value</h3>

<p><code>preProcess</code> results in a list with elements </p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the
function call</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a named list of operations and the variables
used for each </p>
</td></tr> <tr><td><code>dim</code></td>
<td>
<p>the dimensions of <code>x</code></p>
</td></tr> <tr><td><code>bc</code></td>
<td>
<p>Box-Cox
transformation values, see <code><a href="#topic+BoxCoxTrans">BoxCoxTrans</a></code></p>
</td></tr> <tr><td><code>mean</code></td>
<td>
<p>a vector
of means (if centering was requested)</p>
</td></tr> <tr><td><code>std</code></td>
<td>
<p>a vector of standard
deviations (if scaling or PCA was requested)</p>
</td></tr> <tr><td><code>rotation</code></td>
<td>
<p>a matrix of
eigenvectors if PCA was requested</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>the value of <code>method</code></p>
</td></tr>
<tr><td><code>thresh</code></td>
<td>
<p>the value of <code>thresh</code></p>
</td></tr> <tr><td><code>ranges</code></td>
<td>
<p>a matrix of min and
max values for each predictor when <code>method</code> includes &quot;range&quot; (and
<code>NULL</code> otherwise)</p>
</td></tr> <tr><td><code>numComp</code></td>
<td>
<p>the number of principal components
required of capture the specified amount of variance</p>
</td></tr> <tr><td><code>ica</code></td>
<td>
<p>contains
values for the <code>W</code> and <code>K</code> matrix of the decomposition</p>
</td></tr>
<tr><td><code>median</code></td>
<td>
<p>a vector of medians (if median imputation was requested)</p>
</td></tr>
</table>
<p><code>predict.preProcess</code> will produce a data frame.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, median imputation by Zachary Mayer
</p>


<h3>References</h3>

<p><a href="http://topepo.github.io/caret/pre-processing.html">http://topepo.github.io/caret/pre-processing.html</a>
</p>
<p>Kuhn and Johnson (2013), Applied Predictive Modeling, Springer, New York
(chapter 4)
</p>
<p>Kuhn (2008), Building predictive models in R using the caret
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>)
</p>
<p>Box, G. E. P. and Cox, D. R. (1964) An analysis of transformations (with
discussion). Journal of the Royal Statistical Society B, 26, 211-252.
</p>
<p>Box, G. E. P. and Tidwell, P. W. (1962) Transformation of the independent
variables. Technometrics 4, 531-550.
</p>
<p>Manly, B. L. (1976) Exponential data transformations. The Statistician, 25,
37 - 42.
</p>
<p>Yeo, I-K. and Johnson, R. (2000). A new family of power transformations to
improve normality or symmetry. Biometrika, 87, 954-959.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BoxCoxTrans">BoxCoxTrans</a></code>, <code><a href="#topic+expoTrans">expoTrans</a></code>
<code><a href="MASS.html#topic+boxcox">boxcox</a></code>, <code><a href="stats.html#topic+prcomp">prcomp</a></code>,
<code><a href="fastICA.html#topic+fastICA">fastICA</a></code>, <code><a href="#topic+spatialSign">spatialSign</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BloodBrain)
# one variable has one unique value
## Not run: 
preProc &lt;- preProcess(bbbDescr)

preProc  &lt;- preProcess(bbbDescr[1:100,-3])
training &lt;- predict(preProc, bbbDescr[1:100,-3])
test     &lt;- predict(preProc, bbbDescr[101:208,-3])

## End(Not run)

</code></pre>

<hr>
<h2 id='print.confusionMatrix'>Print method for confusionMatrix</h2><span id='topic+print.confusionMatrix'></span>

<h3>Description</h3>

<p>a print method for <code>confusionMatrix</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'confusionMatrix'
print(
  x,
  mode = x$mode,
  digits = max(3, getOption("digits") - 3),
  printStats = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.confusionMatrix_+3A_x">x</code></td>
<td>
<p>an object of class <code>confusionMatrix</code></p>
</td></tr>
<tr><td><code id="print.confusionMatrix_+3A_mode">mode</code></td>
<td>
<p>a single character string either &quot;sens_spec&quot;, &quot;prec_recall&quot;, or
&quot;everything&quot;</p>
</td></tr>
<tr><td><code id="print.confusionMatrix_+3A_digits">digits</code></td>
<td>
<p>number of significant digits when printed</p>
</td></tr>
<tr><td><code id="print.confusionMatrix_+3A_printstats">printStats</code></td>
<td>
<p>a logical: if <code>TRUE</code> then table statistics are also
printed</p>
</td></tr>
<tr><td><code id="print.confusionMatrix_+3A_...">...</code></td>
<td>
<p>optional arguments to pass to <code>print.table</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>x</code> is invisibly returned
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusionMatrix">confusionMatrix</a></code>
</p>

<hr>
<h2 id='print.train'>Print Method for the train Class</h2><span id='topic+print.train'></span>

<h3>Description</h3>

<p>Print the results of a <code><a href="#topic+train">train</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'train'
print(
  x,
  printCall = FALSE,
  details = FALSE,
  selectCol = FALSE,
  showSD = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.train_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+train">train</a></code>.</p>
</td></tr>
<tr><td><code id="print.train_+3A_printcall">printCall</code></td>
<td>
<p>a logical to print the call at the top of the output</p>
</td></tr>
<tr><td><code id="print.train_+3A_details">details</code></td>
<td>
<p>a logical to show print or summary methods for the final
model. In some cases (such as <code>gbm</code>, <code>knn</code>, <code>lvq</code>, naive
Bayes and bagged tree models), no information will be printed even if
<code>details = TRUE</code></p>
</td></tr>
<tr><td><code id="print.train_+3A_selectcol">selectCol</code></td>
<td>
<p>a logical whether to add a column with a star next to the
selected parameters</p>
</td></tr>
<tr><td><code id="print.train_+3A_showsd">showSD</code></td>
<td>
<p>a logical whether to show the standard deviation of the
resampling results within parentheses (e.g. &quot;4.24 (0.493)&quot;)</p>
</td></tr>
<tr><td><code id="print.train_+3A_...">...</code></td>
<td>
<p>options passed to <code><a href="base.html#topic+format">format</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The table of complexity parameters used, their resampled performance and a
flag for which rows are optimal.
</p>


<h3>Value</h3>

<p>A matrix with the complexity parameters and performance (invisibly).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(iris)
TrainData &lt;- iris[,1:4]
TrainClasses &lt;- iris[,5]

options(digits = 3)

library(klaR)
rdaFit &lt;- train(TrainData, TrainClasses, method = "rda",
                control = trainControl(method = "cv"))
rdaFit
print(rdaFit, showSD = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='recall'>Calculate recall, precision and F values</h2><span id='topic+recall'></span><span id='topic+recall.default'></span><span id='topic+recall.table'></span><span id='topic+precision'></span><span id='topic+precision.default'></span><span id='topic+precision.table'></span><span id='topic+precision.matrix'></span><span id='topic+F_meas'></span><span id='topic+F_meas.default'></span><span id='topic+F_meas.table'></span>

<h3>Description</h3>

<p>These functions calculate the recall, precision or F values of a measurement
system for finding/retrieving relevant documents compared to reference
results (the truth regarding relevance). The measurement and &quot;truth&quot; data
must have the same two possible outcomes and one of the outcomes must be
thought of as a &quot;relevant&quot; results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recall(data, ...)

## S3 method for class 'table'
recall(data, relevant = rownames(data)[1], ...)

## Default S3 method:
recall(data, reference, relevant = levels(reference)[1], na.rm = TRUE, ...)

precision(data, ...)

## Default S3 method:
precision(data, reference, relevant = levels(reference)[1], na.rm = TRUE, ...)

## S3 method for class 'table'
precision(data, relevant = rownames(data)[1], ...)

F_meas(data, ...)

## Default S3 method:
F_meas(
  data,
  reference,
  relevant = levels(reference)[1],
  beta = 1,
  na.rm = TRUE,
  ...
)

## S3 method for class 'table'
F_meas(data, relevant = rownames(data)[1], beta = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recall_+3A_data">data</code></td>
<td>
<p>for the default functions, a factor containing the discrete
measurements. For the <code>table</code> function, a table.</p>
</td></tr>
<tr><td><code id="recall_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
<tr><td><code id="recall_+3A_relevant">relevant</code></td>
<td>
<p>a character string that defines the factor level
corresponding to the &quot;relevant&quot; results</p>
</td></tr>
<tr><td><code id="recall_+3A_reference">reference</code></td>
<td>
<p>a factor containing the reference values (i.e. truth)</p>
</td></tr>
<tr><td><code id="recall_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should be
stripped before the computation proceeds</p>
</td></tr>
<tr><td><code id="recall_+3A_beta">beta</code></td>
<td>
<p>a numeric value used to weight precision and recall. A value of
1 is traditionally used and corresponds to the harmonic mean of the two
values but other values weight recall beta times more important than
precision.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The recall (aka sensitivity) is defined as the proportion of relevant
results out of the number of samples which were actually relevant. When
there are no relevant results, recall is not defined and a value of
<code>NA</code> is returned.
</p>
<p>The precision is percentage of predicted truly relevant results of the total
number of predicted relevant results and characterizes the &quot;purity in
retrieval performance&quot; (Buckland and Gey, 1994)
</p>
<p>The measure &quot;F&quot; is a combination of precision and recall (see below).
</p>
<p>Suppose a 2x2 table with notation
</p>

<table>
<tr>
 <td style="text-align: right;"> </td><td style="text-align: center;"> Reference </td><td style="text-align: center;"> </td>
</tr>
<tr>
 <td style="text-align: right;"> Predicted </td><td style="text-align: center;"> relevant </td><td style="text-align: center;">
Irrelevant </td>
</tr>
<tr>
 <td style="text-align: right;"> relevant </td><td style="text-align: center;"> A </td><td style="text-align: center;"> B </td>
</tr>
<tr>
 <td style="text-align: right;"> Irrelevant </td><td style="text-align: center;"> C </td><td style="text-align: center;"> D </td>
</tr>
<tr>
 <td style="text-align: right;"> </td>
</tr>

</table>

<p>The formulas used here are: </p>
<p style="text-align: center;"><code class="reqn">recall = A/(A+C)</code>
</p>
 <p style="text-align: center;"><code class="reqn">precision =
A/(A+B)</code>
</p>
 <p style="text-align: center;"><code class="reqn">F_i = (1+i^2)*prec*recall/((i^2 * precision)+recall)</code>
</p>

<p>See the references for discussions of the statistics.
</p>


<h3>Value</h3>

<p>A number between 0 and 1 (or NA).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Kuhn, M. (2008), &ldquo;Building predictive models in R using the
caret package, &rdquo; <em>Journal of Statistical Software</em>,
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>).
</p>
<p>Buckland, M., &amp; Gey, F. (1994). The relationship between Recall and
Precision. <em>Journal of the American Society for Information Science</em>,
45(1), 12-19.
</p>
<p>Powers, D. (2007). Evaluation: From Precision, Recall and F Factor to ROC,
Informedness, Markedness and Correlation. Technical Report SIE-07-001,
Flinders University
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusionMatrix">confusionMatrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
###################
## Data in Table 2 of Powers (2007)

lvs &lt;- c("Relevant", "Irrelevant")
tbl_2_1_pred &lt;- factor(rep(lvs, times = c(42, 58)), levels = lvs)
tbl_2_1_truth &lt;- factor(c(rep(lvs, times = c(30, 12)),
                          rep(lvs, times = c(30, 28))),
                        levels = lvs)
tbl_2_1 &lt;- table(tbl_2_1_pred, tbl_2_1_truth)

precision(tbl_2_1)
precision(data = tbl_2_1_pred, reference = tbl_2_1_truth, relevant = "Relevant")
recall(tbl_2_1)
recall(data = tbl_2_1_pred, reference = tbl_2_1_truth, relevant = "Relevant")


tbl_2_2_pred &lt;- factor(rep(lvs, times = c(76, 24)), levels = lvs)
tbl_2_2_truth &lt;- factor(c(rep(lvs, times = c(56, 20)),
                          rep(lvs, times = c(12, 12))),
                        levels = lvs)
tbl_2_2 &lt;- table(tbl_2_2_pred, tbl_2_2_truth)

precision(tbl_2_2)
precision(data = tbl_2_2_pred, reference = tbl_2_2_truth, relevant = "Relevant")
recall(tbl_2_2)
recall(data = tbl_2_2_pred, reference = tbl_2_2_truth, relevant = "Relevant")

</code></pre>

<hr>
<h2 id='resampleHist'>Plot the resampling distribution of the model statistics</h2><span id='topic+resampleHist'></span>

<h3>Description</h3>

<p>Create a lattice histogram or densityplot from the resampled outcomes from a
<code>train</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resampleHist(object, type = "density", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resampleHist_+3A_object">object</code></td>
<td>
<p>an object resulting form a call to <code><a href="#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="resampleHist_+3A_type">type</code></td>
<td>
<p>a character string. Either &quot;hist&quot; or &quot;density&quot;</p>
</td></tr>
<tr><td><code id="resampleHist_+3A_...">...</code></td>
<td>
<p>options to pass to histogram or densityplot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All the metrics from the object are plotted, but only for the final model.
For more comprehensive plots functions, see <code><a href="#topic+histogram.train">histogram.train</a></code>,
<code><a href="#topic+densityplot.train">densityplot.train</a></code>, <code><a href="#topic+xyplot.train">xyplot.train</a></code>,
<code><a href="#topic+stripplot.train">stripplot.train</a></code>.
</p>
<p>For the plot to be made, the <code>returnResamp</code> argument in
<code><a href="#topic+trainControl">trainControl</a></code> should be either &quot;final&quot; or &quot;all&quot;.
</p>


<h3>Value</h3>

<p>a object of class <code>trellis</code>
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>, <code><a href="lattice.html#topic+histogram">histogram</a></code>,
<code><a href="lattice.html#topic+histogram">densityplot</a></code>, <code><a href="#topic+histogram.train">histogram.train</a></code>,
<code><a href="#topic+densityplot.train">densityplot.train</a></code>, <code><a href="#topic+xyplot.train">xyplot.train</a></code>,
<code><a href="#topic+stripplot.train">stripplot.train</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
data(iris)
TrainData &lt;- iris[,1:4]
TrainClasses &lt;- iris[,5]

knnFit &lt;- train(TrainData, TrainClasses, "knn")

resampleHist(knnFit)

## End(Not run)

</code></pre>

<hr>
<h2 id='resamples'>Collation and Visualization of Resampling Results</h2><span id='topic+resamples'></span><span id='topic+resamples.default'></span><span id='topic+summary.resamples'></span><span id='topic+sort.resamples'></span><span id='topic+as.matrix.resamples'></span><span id='topic+as.data.frame.resamples'></span><span id='topic+modelCor'></span><span id='topic+print.resamples'></span>

<h3>Description</h3>

<p>These functions provide methods for collection, analyzing and visualizing a
set of resampling results from a common data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resamples(x, ...)

## Default S3 method:
resamples(x, modelNames = names(x), ...)

## S3 method for class 'resamples'
sort(x, decreasing = FALSE, metric = x$metric[1], FUN = mean, ...)

## S3 method for class 'resamples'
summary(object, metric = object$metrics, ...)

## S3 method for class 'resamples'
as.matrix(x, metric = x$metric[1], ...)

## S3 method for class 'resamples'
as.data.frame(x, row.names = NULL, optional = FALSE, metric = x$metric[1], ...)

modelCor(x, metric = x$metric[1], ...)

## S3 method for class 'resamples'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resamples_+3A_x">x</code></td>
<td>
<p>a list of two or more objects of class <code><a href="#topic+train">train</a></code>,
<code><a href="#topic+sbf">sbf</a></code> or <code><a href="#topic+rfe">rfe</a></code> with a common set of resampling
indices in the <code>control</code> object. For <code>sort.resamples</code>, it is an
object generated by <code>resamples</code>.</p>
</td></tr>
<tr><td><code id="resamples_+3A_...">...</code></td>
<td>
<p>only used for <code>sort</code> and <code>modelCor</code> and captures
arguments to pass to <code>sort</code> or <code>FUN</code>.</p>
</td></tr>
<tr><td><code id="resamples_+3A_modelnames">modelNames</code></td>
<td>
<p>an optional set of names to give to the resampling results</p>
</td></tr>
<tr><td><code id="resamples_+3A_decreasing">decreasing</code></td>
<td>
<p>logical. Should the sort be increasing or decreasing?</p>
</td></tr>
<tr><td><code id="resamples_+3A_metric">metric</code></td>
<td>
<p>a character string for the performance measure used to sort or
computing the between-model correlations</p>
</td></tr>
<tr><td><code id="resamples_+3A_fun">FUN</code></td>
<td>
<p>a function whose first argument is a vector and returns a scalar,
to be applied to each model's performance measure.</p>
</td></tr>
<tr><td><code id="resamples_+3A_object">object</code></td>
<td>
<p>an object generated by <code>resamples</code></p>
</td></tr>
<tr><td><code id="resamples_+3A_row.names">row.names</code>, <code id="resamples_+3A_optional">optional</code></td>
<td>
<p>not currently used but included for consistency
with <code>as.data.frame</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ideas and methods here are based on Hothorn et al. (2005) and Eugster et
al. (2008).
</p>
<p>The results from <code><a href="#topic+train">train</a></code> can have more than one performance
metric per resample. Each metric in the input object is saved.
</p>
<p><code>resamples</code> checks that the resampling results match; that is, the
indices in the object <code>trainObject$control$index</code> are the same. Also,
the argument <code><a href="#topic+trainControl">trainControl</a></code> <code>returnResamp</code> should have a
value of <code>"final"</code> for each model.
</p>
<p>The summary function computes summary statistics across each model/metric
combination.
</p>


<h3>Value</h3>

<p>For <code>resamples</code>: an object with class <code>"resamples"</code> with
elements </p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call</p>
</td></tr> <tr><td><code>values</code></td>
<td>
<p>a data frame of results where
rows correspond to resampled data sets and columns indicate the model and
metric</p>
</td></tr> <tr><td><code>models</code></td>
<td>
<p>a character string of model labels</p>
</td></tr> <tr><td><code>metrics</code></td>
<td>
<p>a
character string of performance metrics</p>
</td></tr> <tr><td><code>methods</code></td>
<td>
<p>a character string
of the <code><a href="#topic+train">train</a></code> <code>method</code> argument values for each model </p>
</td></tr>
</table>
<p>For <code>sort.resamples</code> a character string in the sorted order is
generated. <code>modelCor</code> returns a correlation matrix.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Hothorn et al. The design and analysis of benchmark experiments.
Journal of Computational and Graphical Statistics (2005) vol. 14 (3) pp.
675-699
</p>
<p>Eugster et al. Exploratory and inferential analysis of benchmark
experiments. Ludwigs-Maximilians-Universitat Munchen, Department of
Statistics, Tech. Rep (2008) vol. 30
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>, <code><a href="#topic+trainControl">trainControl</a></code>,
<code><a href="#topic+diff.resamples">diff.resamples</a></code>, <code><a href="#topic+xyplot.resamples">xyplot.resamples</a></code>,
<code><a href="#topic+densityplot.resamples">densityplot.resamples</a></code>, <code><a href="#topic+bwplot.resamples">bwplot.resamples</a></code>,
<code><a href="#topic+splom.resamples">splom.resamples</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(BloodBrain)
set.seed(1)

## tmp &lt;- createDataPartition(logBBB,
##                            p = .8,
##                            times = 100)

## rpartFit &lt;- train(bbbDescr, logBBB,
##                   "rpart",
##                   tuneLength = 16,
##                   trControl = trainControl(
##                     method = "LGOCV", index = tmp))

## ctreeFit &lt;- train(bbbDescr, logBBB,
##                   "ctree",
##                   trControl = trainControl(
##                     method = "LGOCV", index = tmp))

## earthFit &lt;- train(bbbDescr, logBBB,
##                   "earth",
##                   tuneLength = 20,
##                   trControl = trainControl(
##                     method = "LGOCV", index = tmp))

## or load pre-calculated results using:
## load(url("http://caret.r-forge.r-project.org/exampleModels.RData"))

## resamps &lt;- resamples(list(CART = rpartFit,
##                           CondInfTree = ctreeFit,
##                           MARS = earthFit))

## resamps
## summary(resamps)

</code></pre>

<hr>
<h2 id='resampleSummary'>Summary of resampled performance estimates</h2><span id='topic+resampleSummary'></span>

<h3>Description</h3>

<p>This function uses the out-of-bag predictions to calculate overall
performance metrics and returns the observed and predicted data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resampleSummary(obs, resampled, index = NULL, keepData = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resampleSummary_+3A_obs">obs</code></td>
<td>
<p>A vector (numeric or factor) of the outcome data</p>
</td></tr>
<tr><td><code id="resampleSummary_+3A_resampled">resampled</code></td>
<td>
<p>For bootstrapping, this is either a matrix (for numeric
outcomes) or a data frame (for factors). For cross-validation, a vector is
produced.</p>
</td></tr>
<tr><td><code id="resampleSummary_+3A_index">index</code></td>
<td>
<p>The list to index of samples in each cross-validation fold
(only used for cross-validation).</p>
</td></tr>
<tr><td><code id="resampleSummary_+3A_keepdata">keepData</code></td>
<td>
<p>A logical for returning the observed and predicted data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean and standard deviation of the values produced by
<code><a href="#topic+postResample">postResample</a></code> are calculated.
</p>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>metrics</code></td>
<td>
<p>A vector of values describing the
bootstrap distribution.</p>
</td></tr> <tr><td><code>data</code></td>
<td>
<p>A data frame or <code>NULL</code>. Columns
include <code>obs</code>, <code>pred</code> and <code>group</code> (for tracking
cross-validation folds or bootstrap samples)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+postResample">postResample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
resampleSummary(rnorm(10), matrix(rnorm(50), ncol = 5))

</code></pre>

<hr>
<h2 id='rfe'>Backwards Feature Selection</h2><span id='topic+rfe'></span><span id='topic+rfe.default'></span><span id='topic+rfeIter'></span><span id='topic+predict.rfe'></span><span id='topic+update.rfe'></span><span id='topic+rfe.formula'></span><span id='topic+rfe.recipe'></span>

<h3>Description</h3>

<p>A simple backwards selection, a.k.a. recursive feature elimination (RFE),
algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfe(x, ...)

## Default S3 method:
rfe(
  x,
  y,
  sizes = 2^(2:4),
  metric = ifelse(is.factor(y), "Accuracy", "RMSE"),
  maximize = ifelse(metric %in% c("RMSE", "MAE", "logLoss"), FALSE, TRUE),
  rfeControl = rfeControl(),
  ...
)

## S3 method for class 'formula'
rfe(form, data, ..., subset, na.action, contrasts = NULL)

rfeIter(
  x,
  y,
  testX,
  testY,
  sizes,
  rfeControl = rfeControl(),
  label = "",
  seeds = NA,
  ...
)

## S3 method for class 'rfe'
update(object, x, y, size, ...)

## S3 method for class 'recipe'
rfe(
  x,
  data,
  sizes = 2^(2:4),
  metric = NULL,
  maximize = NULL,
  rfeControl = rfeControl(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rfe_+3A_x">x</code></td>
<td>
<p>A matrix or data frame of predictors for model training. This
object must have unique column names. For the recipes method, <code>x</code>
is a recipe object.</p>
</td></tr>
<tr><td><code id="rfe_+3A_...">...</code></td>
<td>
<p>options to pass to the model fitting function (ignored in
<code>predict.rfe</code>)</p>
</td></tr>
<tr><td><code id="rfe_+3A_y">y</code></td>
<td>
<p>a vector of training set outcomes (either numeric or factor)</p>
</td></tr>
<tr><td><code id="rfe_+3A_sizes">sizes</code></td>
<td>
<p>a numeric vector of integers corresponding to the number of
features that should be retained</p>
</td></tr>
<tr><td><code id="rfe_+3A_metric">metric</code></td>
<td>
<p>a string that specifies what summary metric will be used to
select the optimal model. By default, possible values are &quot;RMSE&quot; and
&quot;Rsquared&quot; for regression and &quot;Accuracy&quot; and &quot;Kappa&quot; for classification. If
custom performance metrics are used (via the <code>functions</code> argument in
<code><a href="#topic+rfeControl">rfeControl</a></code>, the value of <code>metric</code> should match one of the
arguments.</p>
</td></tr>
<tr><td><code id="rfe_+3A_maximize">maximize</code></td>
<td>
<p>a logical: should the metric be maximized or minimized?</p>
</td></tr>
<tr><td><code id="rfe_+3A_rfecontrol">rfeControl</code></td>
<td>
<p>a list of options, including functions for fitting and
prediction. The web page
<a href="http://topepo.github.io/caret/recursive-feature-elimination.html#rfe">http://topepo.github.io/caret/recursive-feature-elimination.html#rfe</a> has more
details and examples related to this function.</p>
</td></tr>
<tr><td><code id="rfe_+3A_form">form</code></td>
<td>
<p>A formula of the form <code>y ~ x1 + x2 + ...</code></p>
</td></tr>
<tr><td><code id="rfe_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in
<code>formula</code> or <code>recipe</code> are preferentially to be taken.</p>
</td></tr>
<tr><td><code id="rfe_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used
in the training sample. (NOTE: If given, this argument must be
named.)</p>
</td></tr>
<tr><td><code id="rfe_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken
if NAs are found. The default action is for the procedure to
fail. An alternative is <code>na.omit</code>, which leads to rejection
of cases with missing values on any required variable. (NOTE: If
given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="rfe_+3A_contrasts">contrasts</code></td>
<td>
<p>A list of contrasts to be used for some or all
the factors appearing as variables in the model formula.</p>
</td></tr>
<tr><td><code id="rfe_+3A_testx">testX</code></td>
<td>
<p>a matrix or data frame of test set predictors. This must have
the same column names as <code>x</code></p>
</td></tr>
<tr><td><code id="rfe_+3A_testy">testY</code></td>
<td>
<p>a vector of test set outcomes</p>
</td></tr>
<tr><td><code id="rfe_+3A_label">label</code></td>
<td>
<p>an optional character string to be printed when in verbose
mode.</p>
</td></tr>
<tr><td><code id="rfe_+3A_seeds">seeds</code></td>
<td>
<p>an optional vector of integers for the size. The vector should
have length of <code>length(sizes)+1</code></p>
</td></tr>
<tr><td><code id="rfe_+3A_object">object</code></td>
<td>
<p>an object of class <code>rfe</code></p>
</td></tr>
<tr><td><code id="rfe_+3A_size">size</code></td>
<td>
<p>a single integers corresponding to the number of features that
should be retained in the updated model</p>
</td></tr>
</table>


<h3>Details</h3>

<p>More details on this function can be found at
<a href="http://topepo.github.io/caret/recursive-feature-elimination.html">http://topepo.github.io/caret/recursive-feature-elimination.html</a>.
</p>
<p>This function implements backwards selection of predictors based on
predictor importance ranking. The predictors are ranked and the less
important ones are sequentially eliminated prior to modeling. The goal is to
find a subset of predictors that can be used to produce an accurate model.
The web page <a href="http://topepo.github.io/caret/recursive-feature-elimination.html#rfe">http://topepo.github.io/caret/recursive-feature-elimination.html#rfe</a>
has more details and examples related to this function.
</p>
<p><code>rfe</code> can be used with &quot;explicit parallelism&quot;, where different
resamples (e.g. cross-validation group) can be split up and run on multiple
machines or processors. By default, <code>rfe</code> will use a single processor
on the host machine. As of version 4.99 of this package, the framework used
for parallel processing uses the <span class="pkg">foreach</span> package. To run the resamples
in parallel, the code for <code>rfe</code> does not change; prior to the call to
<code>rfe</code>, a parallel backend is registered with <span class="pkg">foreach</span> (see the
examples below).
</p>
<p><code>rfeIter</code> is the basic algorithm while <code>rfe</code> wraps these
operations inside of resampling. To avoid selection bias, it is better to
use the function <code>rfe</code> than <code>rfeIter</code>.
</p>
<p>When updating a model, if the entire set of resamples were not saved using
<code>rfeControl(returnResamp = "final")</code>, the existing resamples are
removed with a warning.
</p>


<h3>Value</h3>

<p>A list with elements </p>
<table>
<tr><td><code>finalVariables</code></td>
<td>
<p>a list of size
<code>length(sizes) + 1</code> containing the column names of the &ldquo;surviving&rdquo;
predictors at each stage of selection. The first element corresponds to all
the predictors (i.e. <code>size = ncol(x)</code>)</p>
</td></tr> <tr><td><code>pred</code></td>
<td>
<p>a data frame with
columns for the test set outcome, the predicted outcome and the subset
size.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>We using a recipe as an input, there may be some subset
sizes that are not well-replicated over resamples. 'rfe' method
will only consider subset sizes where at least half of the
resamples have associated results in the search for an optimal
subset size.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rfeControl">rfeControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(BloodBrain)

x &lt;- scale(bbbDescr[,-nearZeroVar(bbbDescr)])
x &lt;- x[, -findCorrelation(cor(x), .8)]
x &lt;- as.data.frame(x, stringsAsFactors = TRUE)

set.seed(1)
lmProfile &lt;- rfe(x, logBBB,
                 sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65),
                 rfeControl = rfeControl(functions = lmFuncs,
                                         number = 200))
set.seed(1)
lmProfile2 &lt;- rfe(x, logBBB,
                 sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65),
                 rfeControl = rfeControl(functions = lmFuncs,
                                         rerank = TRUE,
                                         number = 200))

xyplot(lmProfile$results$RMSE + lmProfile2$results$RMSE  ~
       lmProfile$results$Variables,
       type = c("g", "p", "l"),
       auto.key = TRUE)

rfProfile &lt;- rfe(x, logBBB,
                 sizes = c(2, 5, 10, 20),
                 rfeControl = rfeControl(functions = rfFuncs))

bagProfile &lt;- rfe(x, logBBB,
                  sizes = c(2, 5, 10, 20),
                  rfeControl = rfeControl(functions = treebagFuncs))

set.seed(1)
svmProfile &lt;- rfe(x, logBBB,
                  sizes = c(2, 5, 10, 20),
                  rfeControl = rfeControl(functions = caretFuncs,
                                          number = 200),
                  ## pass options to train()
                  method = "svmRadial")

## classification

data(mdrr)
mdrrDescr &lt;- mdrrDescr[,-nearZeroVar(mdrrDescr)]
mdrrDescr &lt;- mdrrDescr[, -findCorrelation(cor(mdrrDescr), .8)]

set.seed(1)
inTrain &lt;- createDataPartition(mdrrClass, p = .75, list = FALSE)[,1]

train &lt;- mdrrDescr[ inTrain, ]
test  &lt;- mdrrDescr[-inTrain, ]
trainClass &lt;- mdrrClass[ inTrain]
testClass  &lt;- mdrrClass[-inTrain]

set.seed(2)
ldaProfile &lt;- rfe(train, trainClass,
                  sizes = c(1:10, 15, 30),
                  rfeControl = rfeControl(functions = ldaFuncs, method = "cv"))
plot(ldaProfile, type = c("o", "g"))

postResample(predict(ldaProfile, test), testClass)


## End(Not run)

#######################################
## Parallel Processing Example via multicore

## Not run: 
library(doMC)

## Note: if the underlying model also uses foreach, the
## number of cores specified above will double (along with
## the memory requirements)
registerDoMC(cores = 2)

set.seed(1)
lmProfile &lt;- rfe(x, logBBB,
                 sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65),
                 rfeControl = rfeControl(functions = lmFuncs,
                                         number = 200))



## End(Not run)


</code></pre>

<hr>
<h2 id='rfeControl'>Controlling the Feature Selection Algorithms</h2><span id='topic+rfeControl'></span>

<h3>Description</h3>

<p>This function generates a control object that can be used to specify the
details of the feature selection algorithms used in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfeControl(
  functions = NULL,
  rerank = FALSE,
  method = "boot",
  saveDetails = FALSE,
  number = ifelse(method %in% c("cv", "repeatedcv"), 10, 25),
  repeats = ifelse(method %in% c("cv", "repeatedcv"), 1, number),
  verbose = FALSE,
  returnResamp = "final",
  p = 0.75,
  index = NULL,
  indexOut = NULL,
  timingSamps = 0,
  seeds = NA,
  allowParallel = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rfeControl_+3A_functions">functions</code></td>
<td>
<p>a list of functions for model fitting, prediction and
variable importance (see Details below)</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_rerank">rerank</code></td>
<td>
<p>a logical: should variable importance be re-calculated each
time features are removed?</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_method">method</code></td>
<td>
<p>The external resampling method: <code>boot</code>, <code>cv</code>,
<code>LOOCV</code> or <code>LGOCV</code> (for repeated training/test splits</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_savedetails">saveDetails</code></td>
<td>
<p>a logical to save the predictions and variable
importances from the selection process</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_number">number</code></td>
<td>
<p>Either the number of folds or number of resampling iterations</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_repeats">repeats</code></td>
<td>
<p>For repeated k-fold cross-validation only: the number of
complete sets of folds to compute</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_verbose">verbose</code></td>
<td>
<p>a logical to print a log for each external resampling
iteration</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_returnresamp">returnResamp</code></td>
<td>
<p>A character string indicating how much of the resampled
summary metrics should be saved. Values can be &ldquo;final&rdquo;, &ldquo;all&rdquo; or
&ldquo;none&rdquo;</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_p">p</code></td>
<td>
<p>For leave-group out cross-validation: the training percentage</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_index">index</code></td>
<td>
<p>a list with elements for each external resampling iteration.
Each list element is the sample rows used for training at that iteration.</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_indexout">indexOut</code></td>
<td>
<p>a list (the same length as <code>index</code>) that dictates which
sample are held-out for each resample. If <code>NULL</code>, then the unique set
of samples not contained in <code>index</code> is used.</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_timingsamps">timingSamps</code></td>
<td>
<p>the number of training set samples that will be used to
measure the time for predicting samples (zero indicates that the prediction
time should not be estimated).</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_seeds">seeds</code></td>
<td>
<p>an optional set of integers that will be used to set the seed
at each resampling iteration. This is useful when the models are run in
parallel. A value of <code>NA</code> will stop the seed from being set within the
worker processes while a value of <code>NULL</code> will set the seeds using a
random set of integers. Alternatively, a list can be used. The list should
have <code>B+1</code> elements where <code>B</code> is the number of resamples. The
first <code>B</code> elements of the list should be vectors of integers of length
<code>P</code> where <code>P</code> is the number of subsets being evaluated (including
the full set). The last element of the list only needs to be a single
integer (for the final model). See the Examples section below.</p>
</td></tr>
<tr><td><code id="rfeControl_+3A_allowparallel">allowParallel</code></td>
<td>
<p>if a parallel backend is loaded and available, should
the function use it?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>More details on this function can be found at
<a href="http://topepo.github.io/caret/recursive-feature-elimination.html#rfe">http://topepo.github.io/caret/recursive-feature-elimination.html#rfe</a>.
</p>
<p>Backwards selection requires function to be specified for some operations.
</p>
<p>The <code>fit</code> function builds the model based on the current data set. The
arguments for the function must be: </p>
 <ul>
<li><p><code>x</code> the current
training set of predictor data with the appropriate subset of variables
</p>
</li>
<li><p><code>y</code> the current outcome data (either a numeric or factor vector)
</p>
</li>
<li><p><code>first</code> a single logical value for whether the current predictor
set has all possible variables </p>
</li>
<li><p><code>last</code> similar to <code>first</code>, but
<code>TRUE</code> when the last model is fit with the final subset size and
predictors.  </p>
</li>
<li><p><code>...</code>optional arguments to pass to the fit function
in the call to <code>rfe</code> </p>
</li></ul>
<p> The function should return a model object that
can be used to generate predictions.
</p>
<p>The <code>pred</code> function returns a vector of predictions (numeric or
factors) from the current model. The arguments are: </p>

<ul>
<li><p><code>object</code> the model generated by the <code>fit</code> function
</p>
</li>
<li><p><code>x</code> the current set of predictor set for the held-back samples </p>
</li></ul>

<p>The <code>rank</code> function is used to return the predictors in the order of
the most important to the least important. Inputs are: </p>

<ul>
<li><p><code>object</code> the model generated by the <code>fit</code> function
</p>
</li>
<li><p><code>x</code> the current set of predictor set for the training samples
</p>
</li>
<li><p><code>y</code> the current training outcomes </p>
</li></ul>
<p> The function should return a
data frame with a column called <code>var</code> that has the current variable
names. The first row should be the most important predictor etc. Other
columns can be included in the output and will be returned in the final
<code>rfe</code> object.
</p>
<p>The <code>selectSize</code> function determines the optimal number of predictors
based on the resampling output. Inputs for the function are: </p>

<ul>
<li><p><code>x</code>a matrix with columns for the performance metrics and the
number of variables, called &quot;<code>Variables</code>&quot; </p>
</li>
<li><p><code>metric</code>a character
string of the performance measure to optimize (e.g. &quot;RMSE&quot;, &quot;Rsquared&quot;,
&quot;Accuracy&quot; or &quot;Kappa&quot;) </p>
</li>
<li><p><code>maximize</code>a single logical for whether the
metric should be maximized </p>
</li></ul>
<p> This function should return an integer
corresponding to the optimal subset size. <span class="pkg">caret</span> comes with two
examples functions for this purpose: <code><a href="#topic+pickSizeBest">pickSizeBest</a></code> and
<code><a href="#topic+pickSizeTolerance">pickSizeTolerance</a></code>.
</p>
<p>After the optimal subset size is determined, the <code>selectVar</code> function
will be used to calculate the best rankings for each variable across all the
resampling iterations. Inputs for the function are: </p>
 <ul>
<li><p><code>y</code>
a list of variables importance for each resampling iteration and each subset
size (generated by the user-defined <code>rank</code> function). In the example,
each each of the cross-validation groups the output of the <code>rank</code>
function is saved for each of the subset sizes (including the original
subset). If the rankings are not recomputed at each iteration, the values
will be the same within each cross-validation iteration.  </p>
</li>
<li><p><code>size</code>
the integer returned by the <code>selectSize</code> function </p>
</li></ul>
<p> This function
should return a character string of predictor names (of length <code>size</code>)
in the order of most important to least important
</p>
<p>Examples of these functions are included in the package:
<code><a href="#topic+lmFuncs">lmFuncs</a></code>, <code><a href="#topic+rfFuncs">rfFuncs</a></code>, <code><a href="#topic+treebagFuncs">treebagFuncs</a></code> and
<code><a href="#topic+nbFuncs">nbFuncs</a></code>.
</p>
<p>Model details about these functions, including examples, are at
<a href="http://topepo.github.io/caret/recursive-feature-elimination.html">http://topepo.github.io/caret/recursive-feature-elimination.html</a>. .
</p>


<h3>Value</h3>

<p>A list
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rfe">rfe</a></code>, <code><a href="#topic+lmFuncs">lmFuncs</a></code>, <code><a href="#topic+rfFuncs">rfFuncs</a></code>,
<code><a href="#topic+treebagFuncs">treebagFuncs</a></code>, <code><a href="#topic+nbFuncs">nbFuncs</a></code>,
<code><a href="#topic+pickSizeBest">pickSizeBest</a></code>, <code><a href="#topic+pickSizeTolerance">pickSizeTolerance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  ## Not run: 
subsetSizes &lt;- c(2, 4, 6, 8)
set.seed(123)
seeds &lt;- vector(mode = "list", length = 51)
for(i in 1:50) seeds[[i]] &lt;- sample.int(1000, length(subsetSizes) + 1)
seeds[[51]] &lt;- sample.int(1000, 1)

set.seed(1)
rfMod &lt;- rfe(bbbDescr, logBBB,
             sizes = subsetSizes,
             rfeControl = rfeControl(functions = rfFuncs,
                                     seeds = seeds,
                                     number = 50))
  
## End(Not run)

</code></pre>

<hr>
<h2 id='Sacramento'>Sacramento CA Home Prices</h2><span id='topic+Sacramento'></span>

<h3>Description</h3>

<p>This data frame contains house and sale price data for 932 homes in
Sacramento CA.  The original data were obtained from the website for the
SpatialKey software. From their website: &quot;The Sacramento real estate
transactions file is a list of 985 real estate transactions in the
Sacramento area reported over a five-day period, as reported by the
Sacramento Bee.&quot; Google was used to fill in missing/incorrect data.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Sacramento</code></td>
<td>
<p>a data frame with columns '<code>city</code>',
'<code>zip</code>', '<code>beds</code>', '<code>baths</code>', '<code>sqft</code>', '<code>type</code>',
'<code>price</code>', '<code>latitude</code>', and '<code>longitude</code>'</p>
</td></tr>
</table>


<h3>Source</h3>

<p>SpatialKey website:
<a href="https://support.spatialkey.com/spatialkey-sample-csv-data/">https://support.spatialkey.com/spatialkey-sample-csv-data/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Sacramento)

set.seed(955)
in_train &lt;- createDataPartition(log10(Sacramento$price), p = .8, list = FALSE)

training &lt;- Sacramento[ in_train,]
testing  &lt;- Sacramento[-in_train,]


</code></pre>

<hr>
<h2 id='safs'>Simulated annealing feature selection</h2><span id='topic+safs'></span><span id='topic+safs.default'></span><span id='topic+safs.recipe'></span>

<h3>Description</h3>

<p>Supervised feature selection using simulated annealing
</p>
<p><code><a href="#topic+safs">safs</a></code> conducts a supervised binary search of the predictor
space using simulated annealing (SA). See Kirkpatrick et al (1983) for more
information on this search algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>safs(x, ...)

## Default S3 method:
safs(x, y, iters = 10, differences = TRUE, safsControl = safsControl(), ...)

## S3 method for class 'recipe'
safs(x, data, iters = 10, differences = TRUE, safsControl = safsControl(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="safs_+3A_x">x</code></td>
<td>
<p>An object where samples are in rows and features are in columns.
This could be a simple matrix, data frame or other type (e.g. sparse
matrix). For the recipes method, <code>x</code> is a recipe object.  See Details below.</p>
</td></tr>
<tr><td><code id="safs_+3A_...">...</code></td>
<td>
<p>arguments passed to the classification or regression routine
specified in the function <code>safsControl$functions$fit</code></p>
</td></tr>
<tr><td><code id="safs_+3A_y">y</code></td>
<td>
<p>a numeric or factor vector containing the outcome for each sample.</p>
</td></tr>
<tr><td><code id="safs_+3A_iters">iters</code></td>
<td>
<p>number of search iterations</p>
</td></tr>
<tr><td><code id="safs_+3A_differences">differences</code></td>
<td>
<p>a logical: should the difference in fitness values with
and without each predictor be calculated?</p>
</td></tr>
<tr><td><code id="safs_+3A_safscontrol">safsControl</code></td>
<td>
<p>a list of values that define how this function acts. See
<code><a href="#topic+safsControl">safsControl</a></code> and URL.</p>
</td></tr>
<tr><td><code id="safs_+3A_data">data</code></td>
<td>
<p>an object of class <code><a href="#topic+rfe">rfe</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function conducts the search of the feature space repeatedly within
resampling iterations. First, the training data are split be whatever
resampling method was specified in the control function. For example, if
10-fold cross-validation is selected, the entire simulated annealing search
is conducted 10 separate times. For the first fold, nine tenths of the data
are used in the search while the remaining tenth is used to estimate the
external performance since these data points were not used in the search.
</p>
<p>During the search, a measure of fitness (i.e. SA energy value) is needed to
guide the search. This is the internal measure of performance. During the
search, the data that are available are the instances selected by the
top-level resampling (e.g. the nine tenths mentioned above). A common
approach is to conduct another resampling procedure. Another option is to
use a holdout set of samples to determine the internal estimate of
performance (see the holdout argument of the control function). While this
is faster, it is more likely to cause overfitting of the features and should
only be used when a large amount of training data are available. Yet another
idea is to use a penalized metric (such as the AIC statistic) but this may
not exist for some metrics (e.g. the area under the ROC curve).
</p>
<p>The internal estimates of performance will eventually overfit the subsets to
the data. However, since the external estimate is not used by the search, it
is able to make better assessments of overfitting. After resampling, this
function determines the optimal number of iterations for the SA.
</p>
<p>Finally, the entire data set is used in the last execution of the simulated
annealing algorithm search and the final model is built on the predictor
subset that is associated with the optimal number of iterations determined
by resampling (although the update function can be used to manually set the
number of iterations).
</p>
<p>This is an example of the output produced when <code>safsControl(verbose =
TRUE)</code> is used:
</p>
<pre>
Fold03 1 0.401 (11)
Fold03 2 0.401-&gt;0.410 (11+1, 91.7%) *
Fold03 3 0.410-&gt;0.396 (12+1, 92.3%) 0.969 A
Fold03 4 0.410-&gt;0.370 (12+2, 85.7%) 0.881
Fold03 5 0.410-&gt;0.399 (12+2, 85.7%) 0.954 A
Fold03 6 0.410-&gt;0.399 (12+1, 78.6%) 0.940 A
Fold03 7 0.410-&gt;0.428 (12+2, 73.3%) *
</pre>
<p>The text &quot;Fold03&quot; indicates that this search is for the third
cross-validation fold. The initial subset of 11 predictors had a fitness
value of 0.401. The next iteration added a single feature the the existing
best subset of 11 (as indicated by &quot;11+1&quot;) that increased the fitness value
to 0.410. This new solution, which has a Jaccard similarity value of 91.7%
to the current best solution, is automatically accepted. The third iteration
adds another feature to the current set of 12 but does not improve the
fitness. The acceptance probability for this difference is shown to be
95.6% and the &quot;A&quot; indicates that this new sub-optimal subset is accepted.
The fourth iteration does not show an increase and is not accepted. Note
that the Jaccard similarity value of 85.7% is the similarity to the current
best solution (from iteration 2) and the &quot;12+2&quot; indicates that there are two
additional features added from the current best that contains 12 predictors.
</p>
<p>The search algorithm can be parallelized in several places: </p>

<ol>
<li><p> each externally resampled SA can be run independently (controlled by
the <code>allowParallel</code> option of <code><a href="#topic+safsControl">safsControl</a></code>) </p>
</li>
<li><p> if inner
resampling is used, these can be run in parallel (controls depend on the
function used. See, for example, <code><a href="#topic+trainControl">trainControl</a></code>) </p>
</li>
<li>
<p>any parallelization of the individual model fits. This is also specific to
the modeling function.  </p>
</li></ol>

<p>It is probably best to pick one of these areas for parallelization and the
first is likely to produces the largest decrease in run-time since it is the
least likely to incur multiple re-starting of the worker processes. Keep in
mind that if multiple levels of parallelization occur, this can effect the
number of workers and the amount of memory required exponentially.
</p>


<h3>Value</h3>

<p>an object of class <code>safs</code>
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p><a href="http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html">http://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html</a>
</p>
<p><a href="http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html">http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html</a>
</p>
<p>Kuhn and Johnson (2013), Applied Predictive Modeling, Springer
</p>
<p>Kirkpatrick, S., Gelatt, C. D., and Vecchi, M. P. (1983). Optimization by
simulated annealing. Science, 220(4598), 671.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+safsControl">safsControl</a></code>, <code><a href="#topic+predict.safs">predict.safs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

set.seed(1)
train_data &lt;- twoClassSim(100, noiseVars = 10)
test_data  &lt;- twoClassSim(10,  noiseVars = 10)

## A short example
ctrl &lt;- safsControl(functions = rfSA,
                    method = "cv",
                    number = 3)

rf_search &lt;- safs(x = train_data[, -ncol(train_data)],
                  y = train_data$Class,
                  iters = 3,
                  safsControl = ctrl)

rf_search

## End(Not run)

</code></pre>

<hr>
<h2 id='safs_initial'>Ancillary simulated annealing functions</h2><span id='topic+safs_initial'></span><span id='topic+safs_perturb'></span><span id='topic+safs_prob'></span><span id='topic+caretSA'></span><span id='topic+rfSA'></span><span id='topic+treebagSA'></span>

<h3>Description</h3>

<p>Built-in functions related to simulated annealing
</p>
<p>These functions are used with the <code>functions</code> argument of the
<code><a href="#topic+safsControl">safsControl</a></code> function. More information on the details of these
functions are at <a href="http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html">http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html</a>.
</p>
<p>The <code>initial</code> function is used to create the first predictor subset.
The function <code>safs_initial</code> randomly selects 20% of the predictors.
Note that, instead of a function, <code><a href="#topic+safs">safs</a></code> can also accept a
vector of column numbers as the initial subset.
</p>
<p><code>safs_perturb</code> is an example of the operation that changes the subset
configuration at the start of each new iteration. By default, it will change
roughly 1% of the variables in the current subset.
</p>
<p>The <code>prob</code> function defines the acceptance probability at each
iteration, given the old and new fitness (i.e. energy values). It assumes
that smaller values are better. The default probability function computed
the percentage difference between the current and new fitness value and
using an exponential function to compute a probability: </p>
<pre> prob
= exp[(current-new)/current*iteration] </pre>


<h3>Usage</h3>

<pre><code class='language-R'>safs_initial(vars, prob = 0.2, ...)

safs_perturb(x, vars, number = floor(length(x) * 0.01) + 1)

safs_prob(old, new, iteration = 1)

caretSA

treebagSA

rfSA
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="safs_initial_+3A_vars">vars</code></td>
<td>
<p>the total number of possible predictor variables</p>
</td></tr>
<tr><td><code id="safs_initial_+3A_prob">prob</code></td>
<td>
<p>The probability that an individual predictor is included in the
initial predictor set</p>
</td></tr>
<tr><td><code id="safs_initial_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
<tr><td><code id="safs_initial_+3A_x">x</code></td>
<td>
<p>the integer index vector for the current subset</p>
</td></tr>
<tr><td><code id="safs_initial_+3A_number">number</code></td>
<td>
<p>the number of predictor variables to perturb</p>
</td></tr>
<tr><td><code id="safs_initial_+3A_old">old</code>, <code id="safs_initial_+3A_new">new</code></td>
<td>
<p>fitness values associated with the current and new subset</p>
</td></tr>
<tr><td><code id="safs_initial_+3A_iteration">iteration</code></td>
<td>
<p>the number of iterations overall or the number of
iterations since restart (if <code>improve</code> is used in
<code><a href="#topic+safsControl">safsControl</a></code>)</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 8.
</p>
<p>An object of class <code>list</code> of length 8.
</p>
<p>An object of class <code>list</code> of length 8.
</p>


<h3>Value</h3>

<p>The return value depends on the function. Note that the SA code
encodes the subsets as a vector of integers that are included in the subset
(which is different than the encoding used for GAs).
</p>
<p>The objects <code>caretSA</code>, <code>rfSA</code> and <code>treebagSA</code> are example
lists that can be used with the <code>functions</code> argument of
<code><a href="#topic+safsControl">safsControl</a></code>.
</p>
<p>In the case of <code>caretSA</code>, the <code>...</code> structure of
<code><a href="#topic+safs">safs</a></code> passes through to the model fitting routine. As a
consequence, the <code><a href="#topic+train">train</a></code> function can easily be accessed by
passing important arguments belonging to <code><a href="#topic+train">train</a></code> to
<code><a href="#topic+safs">safs</a></code>. See the examples below. By default, using <code>caretSA</code>
will used the resampled performance estimates produced by
<code><a href="#topic+train">train</a></code> as the internal estimate of fitness.
</p>
<p>For <code>rfSA</code> and <code>treebagSA</code>, the <code>randomForest</code> and
<code>bagging</code> functions are used directly (i.e. <code><a href="#topic+train">train</a></code> is not
used). Arguments to either of these functions can also be passed to them
though the <code><a href="#topic+safs">safs</a></code> call (see examples below). For these two
functions, the internal fitness is estimated using the out-of-bag estimates
naturally produced by those functions. While faster, this limits the user to
accuracy or Kappa (for classification) and RMSE and R-squared (for
regression).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p><a href="http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html">http://topepo.github.io/caret/feature-selection-using-simulated-annealing.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+safs">safs</a></code>, <code><a href="#topic+safsControl">safsControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
selected_vars &lt;- safs_initial(vars = 10 , prob = 0.2)
selected_vars

###

safs_perturb(selected_vars, vars = 10, number = 1)

###

safs_prob(old = .8, new = .9, iteration = 1)
safs_prob(old = .5, new = .6, iteration = 1)

grid &lt;- expand.grid(old = c(4, 3.5),
                    new = c(4.5, 4, 3.5) + 1,
                    iter = 1:40)
grid &lt;- subset(grid, old &lt; new)

grid$prob &lt;- apply(grid, 1,
                   function(x)
                     safs_prob(new = x["new"],
                               old= x["old"],
                               iteration = x["iter"]))

grid$Difference &lt;- factor(grid$new - grid$old)
grid$Group &lt;- factor(paste("Current Value", grid$old))

ggplot(grid, aes(x = iter, y = prob, color = Difference)) +
  geom_line() + facet_wrap(~Group) + theme_bw() +
  ylab("Probability") + xlab("Iteration")

## Not run: 
###
## Hypothetical examples
lda_sa &lt;- safs(x = predictors,
               y = classes,
               safsControl = safsControl(functions = caretSA),
               ## now pass arguments to `train`
               method = "lda",
               metric = "Accuracy"
               trControl = trainControl(method = "cv", classProbs = TRUE))

rf_sa &lt;- safs(x = predictors,
              y = classes,
              safsControl = safsControl(functions = rfSA),
              ## these are arguments to `randomForest`
              ntree = 1000,
              importance = TRUE)
	
## End(Not run)



</code></pre>

<hr>
<h2 id='sbf'>Selection By Filtering (SBF)</h2><span id='topic+sbf'></span><span id='topic+sbf.default'></span><span id='topic+sbf.formula'></span><span id='topic+predict.sbf'></span><span id='topic+sbf.recipe'></span>

<h3>Description</h3>

<p>Model fitting after applying univariate filters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sbf(x, ...)

## Default S3 method:
sbf(x, y, sbfControl = sbfControl(), ...)

## S3 method for class 'formula'
sbf(form, data, ..., subset, na.action, contrasts = NULL)

## S3 method for class 'recipe'
sbf(x, data, sbfControl = sbfControl(), ...)

## S3 method for class 'sbf'
predict(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sbf_+3A_x">x</code></td>
<td>
<p>a data frame containing training data where samples are in rows and
features are in columns. For the recipes method, <code>x</code> is a recipe object.</p>
</td></tr>
<tr><td><code id="sbf_+3A_...">...</code></td>
<td>
<p>for <code>sbf</code>: arguments passed to the classification or
regression routine (such as <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>). For
<code>predict.sbf</code>: augments cannot be passed to the prediction function
using <code>predict.sbf</code> as it uses the function originally specified for
prediction.</p>
</td></tr>
<tr><td><code id="sbf_+3A_y">y</code></td>
<td>
<p>a numeric or factor vector containing the outcome for each sample.</p>
</td></tr>
<tr><td><code id="sbf_+3A_sbfcontrol">sbfControl</code></td>
<td>
<p>a list of values that define how this function acts. See
<code><a href="#topic+sbfControl">sbfControl</a></code>. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="sbf_+3A_form">form</code></td>
<td>
<p>A formula of the form <code>y ~ x1 + x2 + ...</code></p>
</td></tr>
<tr><td><code id="sbf_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in <code>formula</code> are
preferentially to be taken.</p>
</td></tr>
<tr><td><code id="sbf_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the
training sample. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="sbf_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken if NAs are
found. The default action is for the procedure to fail. An alternative is
na.omit, which leads to rejection of cases with missing values on any
required variable. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="sbf_+3A_contrasts">contrasts</code></td>
<td>
<p>a list of contrasts to be used for some or all the factors
appearing as variables in the model formula.</p>
</td></tr>
<tr><td><code id="sbf_+3A_object">object</code></td>
<td>
<p>an object of class <code>sbf</code></p>
</td></tr>
<tr><td><code id="sbf_+3A_newdata">newdata</code></td>
<td>
<p>a matrix or data frame of predictors. The object must have
non-null column names</p>
</td></tr>
</table>


<h3>Details</h3>

<p>More details on this function can be found at
<a href="http://topepo.github.io/caret/feature-selection-using-univariate-filters.html">http://topepo.github.io/caret/feature-selection-using-univariate-filters.html</a>.
</p>
<p>This function can be used to get resampling estimates for models when
simple, filter-based feature selection is applied to the training data.
</p>
<p>For each iteration of resampling, the predictor variables are univariately
filtered prior to modeling. Performance of this approach is estimated using
resampling. The same filter and model are then applied to the entire
training set and the final model (and final features) are saved.
</p>
<p><code>sbf</code> can be used with &quot;explicit parallelism&quot;, where different
resamples (e.g. cross-validation group) can be split up and run on multiple
machines or processors. By default, <code>sbf</code> will use a single processor
on the host machine. As of version 4.99 of this package, the framework used
for parallel processing uses the <span class="pkg">foreach</span> package. To run the resamples
in parallel, the code for <code>sbf</code> does not change; prior to the call to
<code>sbf</code>, a parallel backend is registered with <span class="pkg">foreach</span> (see the
examples below).
</p>
<p>The modeling and filtering techniques are specified in
<code><a href="#topic+sbfControl">sbfControl</a></code>. Example functions are given in
<code><a href="#topic+lmSBF">lmSBF</a></code>.
</p>


<h3>Value</h3>

<p>for <code>sbf</code>, an object of class <code>sbf</code> with elements:
</p>
<table>
<tr><td><code>pred</code></td>
<td>
<p>if <code>sbfControl$saveDetails</code> is <code>TRUE</code>, this is a list
of predictions for the hold-out samples at each resampling iteration.
Otherwise it is <code>NULL</code></p>
</td></tr> <tr><td><code>variables</code></td>
<td>
<p>a list of variable names that
survived the filter at each resampling iteration</p>
</td></tr> <tr><td><code>results</code></td>
<td>
<p>a data
frame of results aggregated over the resamples</p>
</td></tr> <tr><td><code>fit</code></td>
<td>
<p>the final model
fit with only the filtered variables</p>
</td></tr> <tr><td><code>optVariables</code></td>
<td>
<p>the names of the
variables that survived the filter using the training set</p>
</td></tr> <tr><td><code>call</code></td>
<td>
<p>the
function call</p>
</td></tr> <tr><td><code>control</code></td>
<td>
<p>the control object</p>
</td></tr> <tr><td><code>resample</code></td>
<td>
<p>if
<code>sbfControl$returnResamp</code> is &quot;all&quot;, a data frame of the resampled
performance measures. Otherwise, <code>NULL</code></p>
</td></tr> <tr><td><code>metrics</code></td>
<td>
<p>a character
vector of names of the performance measures</p>
</td></tr> <tr><td><code>dots</code></td>
<td>
<p>a list of optional
arguments that were passed in</p>
</td></tr>
</table>
<p>For <code>predict.sbf</code>, a vector of predictions.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sbfControl">sbfControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(BloodBrain)

## Use a GAM is the filter, then fit a random forest model
RFwithGAM &lt;- sbf(bbbDescr, logBBB,
                 sbfControl = sbfControl(functions = rfSBF,
                                         verbose = FALSE,
                                         method = "cv"))
RFwithGAM

predict(RFwithGAM, bbbDescr[1:10,])

## classification example with parallel processing

## library(doMC)

## Note: if the underlying model also uses foreach, the
## number of cores specified above will double (along with
## the memory requirements)
## registerDoMC(cores = 2)

data(mdrr)
mdrrDescr &lt;- mdrrDescr[,-nearZeroVar(mdrrDescr)]
mdrrDescr &lt;- mdrrDescr[, -findCorrelation(cor(mdrrDescr), .8)]

set.seed(1)
filteredNB &lt;- sbf(mdrrDescr, mdrrClass,
                 sbfControl = sbfControl(functions = nbSBF,
                                         verbose = FALSE,
                                         method = "repeatedcv",
                                         repeats = 5))
confusionMatrix(filteredNB)

## End(Not run)


</code></pre>

<hr>
<h2 id='sbfControl'>Control Object for Selection By Filtering (SBF)</h2><span id='topic+sbfControl'></span>

<h3>Description</h3>

<p>Controls the execution of models with simple filters for feature selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sbfControl(
  functions = NULL,
  method = "boot",
  saveDetails = FALSE,
  number = ifelse(method %in% c("cv", "repeatedcv"), 10, 25),
  repeats = ifelse(method %in% c("cv", "repeatedcv"), 1, number),
  verbose = FALSE,
  returnResamp = "final",
  p = 0.75,
  index = NULL,
  indexOut = NULL,
  timingSamps = 0,
  seeds = NA,
  allowParallel = TRUE,
  multivariate = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sbfControl_+3A_functions">functions</code></td>
<td>
<p>a list of functions for model fitting, prediction and
variable filtering (see Details below)</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_method">method</code></td>
<td>
<p>The external resampling method: <code>boot</code>, <code>cv</code>,
<code>LOOCV</code> or <code>LGOCV</code> (for repeated training/test splits</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_savedetails">saveDetails</code></td>
<td>
<p>a logical to save the predictions and variable
importances from the selection process</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_number">number</code></td>
<td>
<p>Either the number of folds or number of resampling iterations</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_repeats">repeats</code></td>
<td>
<p>For repeated k-fold cross-validation only: the number of
complete sets of folds to compute</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_verbose">verbose</code></td>
<td>
<p>a logical to print a log for each external resampling
iteration</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_returnresamp">returnResamp</code></td>
<td>
<p>A character string indicating how much of the resampled
summary metrics should be saved. Values can be &ldquo;final&rdquo; or &ldquo;none&rdquo;</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_p">p</code></td>
<td>
<p>For leave-group out cross-validation: the training percentage</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_index">index</code></td>
<td>
<p>a list with elements for each external resampling iteration.
Each list element is the sample rows used for training at that iteration.</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_indexout">indexOut</code></td>
<td>
<p>a list (the same length as <code>index</code>) that dictates which
sample are held-out for each resample. If <code>NULL</code>, then the unique set
of samples not contained in <code>index</code> is used.</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_timingsamps">timingSamps</code></td>
<td>
<p>the number of training set samples that will be used to
measure the time for predicting samples (zero indicates that the prediction
time should not be estimated).</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_seeds">seeds</code></td>
<td>
<p>an optional set of integers that will be used to set the seed
at each resampling iteration. This is useful when the models are run in
parallel. A value of <code>NA</code> will stop the seed from being set within the
worker processes while a value of <code>NULL</code> will set the seeds using a
random set of integers. Alternatively, a vector of integers can be used. The
vector should have <code>B+1</code> elements where <code>B</code> is the number of
resamples. See the Examples section below.</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_allowparallel">allowParallel</code></td>
<td>
<p>if a parallel backend is loaded and available, should
the function use it?</p>
</td></tr>
<tr><td><code id="sbfControl_+3A_multivariate">multivariate</code></td>
<td>
<p>a logical; should all the columns of <code>x</code> be exposed
to the <code>score</code> function at once?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>More details on this function can be found at
<a href="http://topepo.github.io/caret/feature-selection-using-univariate-filters.html">http://topepo.github.io/caret/feature-selection-using-univariate-filters.html</a>.
</p>
<p>Simple filter-based feature selection requires function to be specified for
some operations.
</p>
<p>The <code>fit</code> function builds the model based on the current data set. The
arguments for the function must be: </p>
 <ul>
<li><p><code>x</code> the current
training set of predictor data with the appropriate subset of variables
(i.e. after filtering) </p>
</li>
<li><p><code>y</code> the current outcome data (either a
numeric or factor vector) </p>
</li>
<li><p><code>...</code> optional arguments to pass to the
fit function in the call to <code>sbf</code> </p>
</li></ul>
<p> The function should return a model
object that can be used to generate predictions.
</p>
<p>The <code>pred</code> function returns a vector of predictions (numeric or
factors) from the current model. The arguments are: </p>

<ul>
<li><p><code>object</code> the model generated by the <code>fit</code> function
</p>
</li>
<li><p><code>x</code> the current set of predictor set for the held-back samples </p>
</li></ul>

<p>The <code>score</code> function is used to return scores with names for each
predictor (such as a p-value). Inputs are: </p>
 <ul>
<li><p><code>x</code> the
predictors for the training samples. If <code>sbfControl()$multivariate</code> is
<code>TRUE</code>, this will be the full predictor matrix. Otherwise it is a
vector for a specific predictor.  </p>
</li>
<li><p><code>y</code> the current training
outcomes </p>
</li></ul>
<p> When <code>sbfControl()$multivariate</code> is <code>TRUE</code>, the
<code>score</code> function should return a named vector where
<code>length(scores) == ncol(x)</code>. Otherwise, the function's output should be
a single value. Univariate examples are give by <code><a href="#topic+anovaScores">anovaScores</a></code>
for classification and <code><a href="#topic+gamScores">gamScores</a></code> for regression and the
example below.
</p>
<p>The <code>filter</code> function is used to return a logical vector with names for
each predictor (<code>TRUE</code> indicates that the prediction should be
retained). Inputs are: </p>
 <ul>
<li><p><code>score</code> the output of the
<code>score</code> function </p>
</li>
<li><p><code>x</code> the predictors for the training samples
</p>
</li>
<li><p><code>y</code> the current training outcomes </p>
</li></ul>
<p> The function should return a
named logical vector.
</p>
<p>Examples of these functions are included in the package:
<code><a href="#topic+caretSBF">caretSBF</a></code>, <code><a href="#topic+lmSBF">lmSBF</a></code>, <code><a href="#topic+rfSBF">rfSBF</a></code>,
<code><a href="#topic+treebagSBF">treebagSBF</a></code>, <code><a href="#topic+ldaSBF">ldaSBF</a></code> and <code><a href="#topic+nbSBF">nbSBF</a></code>.
</p>
<p>The web page <a href="http://topepo.github.io/caret/">http://topepo.github.io/caret/</a> has more details and
examples related to this function.
</p>


<h3>Value</h3>

<p>a list that echos the specified arguments
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sbf">sbf</a></code>, <code><a href="#topic+caretSBF">caretSBF</a></code>, <code><a href="#topic+lmSBF">lmSBF</a></code>,
<code><a href="#topic+rfSBF">rfSBF</a></code>, <code><a href="#topic+treebagSBF">treebagSBF</a></code>, <code><a href="#topic+ldaSBF">ldaSBF</a></code> and
<code><a href="#topic+nbSBF">nbSBF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(BloodBrain)

## Use a GAM is the filter, then fit a random forest model
set.seed(1)
RFwithGAM &lt;- sbf(bbbDescr, logBBB,
                 sbfControl = sbfControl(functions = rfSBF,
                                         verbose = FALSE,
                                         seeds = sample.int(100000, 11),
                                         method = "cv"))
RFwithGAM


## A simple example for multivariate scoring
rfSBF2 &lt;- rfSBF
rfSBF2$score &lt;- function(x, y) apply(x, 2, rfSBF$score, y = y)

set.seed(1)
RFwithGAM2 &lt;- sbf(bbbDescr, logBBB,
                  sbfControl = sbfControl(functions = rfSBF2,
                                          verbose = FALSE,
                                          seeds = sample.int(100000, 11),
                                          method = "cv",
                                          multivariate = TRUE))
RFwithGAM2



## End(Not run)
</code></pre>

<hr>
<h2 id='scat'>Morphometric Data on Scat</h2><span id='topic+scat'></span><span id='topic+scat_orig'></span>

<h3>Description</h3>

<p>Reid (2015) collected data on animal feses in coastal California. The data
consist of DNA verified species designations as well as fields related to
the time and place of the collection and the scat itself. The data frame
<code>scat_orig</code> contains while <code>scat</code> contains data on the three main
species.
</p>


<h3>Value</h3>

<table>
<tr><td><code>scat_orig</code></td>
<td>
<p>the entire data set in the Supplemental Materials</p>
</td></tr>
<tr><td><code>scat</code></td>
<td>
<p>data on the three main species</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Reid, R. E. B. (2015). A morphometric modeling approach to
distinguishing among bobcat, coyote and gray fox scats. <em>Wildlife
Biology</em>, 21(5), 254-262
</p>

<hr>
<h2 id='segmentationData'>Cell Body Segmentation</h2><span id='topic+segmentationData'></span>

<h3>Description</h3>

<p>Hill, LaPan, Li and Haney (2007) develop models to predict which cells in a
high content screen were well segmented.  The data consists of 119 imaging
measurements on 2019. The original analysis used 1009 for training and 1010
as a test set (see the column called <code>Case</code>).
</p>


<h3>Details</h3>

<p>The outcome class is contained in a factor variable called <code>Class</code> with
levels &quot;PS&quot; for poorly segmented and &quot;WS&quot; for well segmented.
</p>
<p>The raw data used in the paper can be found at the Biomedcentral website.
Versions of caret &lt; 4.98 contained the original data. The version now
contained in <code>segmentationData</code> is modified. First, several discrete
versions of some of the predictors (with the suffix &quot;Status&quot;) were removed.
Second, there are several skewed predictors with minimum values of zero
(that would benefit from some transformation, such as the log). A constant
value of 1 was added to these fields: <code>AvgIntenCh2</code>,
<code>FiberAlign2Ch3</code>, <code>FiberAlign2Ch4</code>, <code>SpotFiberCountCh4</code> and
<code>TotalIntenCh2</code>.
</p>
<p>A binary version of the original data is at
<a href="http://topepo.github.io/caret/segmentationOriginal.RData">http://topepo.github.io/caret/segmentationOriginal.RData</a>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>segmentationData</code></td>
<td>
<p>data frame of cells</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Hill, LaPan, Li and Haney (2007). Impact of image segmentation on
high-content screening data quality for SK-BR-3 cells, <em>BMC
Bioinformatics</em>, Vol. 8, pg. 340,
<a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-340">https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-340</a>.
</p>

<hr>
<h2 id='SLC14_1'>Simulation Functions</h2><span id='topic+SLC14_1'></span><span id='topic+SLC14_2'></span><span id='topic+LPH07_1'></span><span id='topic+LPH07_2'></span><span id='topic+twoClassSim'></span>

<h3>Description</h3>

<p>This function simulates regression and classification data with truly
important predictors and irrelevant predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLC14_1(n = 100, noiseVars = 0, corrVars = 0, corrType = "AR1", corrValue = 0)

SLC14_2(n = 100, noiseVars = 0, corrVars = 0, corrType = "AR1", corrValue = 0)

LPH07_1(
  n = 100,
  noiseVars = 0,
  corrVars = 0,
  corrType = "AR1",
  corrValue = 0,
  factors = FALSE,
  class = FALSE
)

LPH07_2(n = 100, noiseVars = 0, corrVars = 0, corrType = "AR1", corrValue = 0)

twoClassSim(
  n = 100,
  intercept = -5,
  linearVars = 10,
  noiseVars = 0,
  corrVars = 0,
  corrType = "AR1",
  corrValue = 0,
  mislabel = 0,
  ordinal = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SLC14_1_+3A_n">n</code></td>
<td>
<p>The number of simulated data points</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_noisevars">noiseVars</code></td>
<td>
<p>The number of uncorrelated irrelevant predictors to be
included.</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_corrvars">corrVars</code></td>
<td>
<p>The number of correlated irrelevant predictors to be
included.</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_corrtype">corrType</code></td>
<td>
<p>The correlation structure of the correlated irrelevant
predictors. Values of &quot;AR1&quot; and &quot;exch&quot; are available (see Details below)</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_corrvalue">corrValue</code></td>
<td>
<p>The correlation value.</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_factors">factors</code></td>
<td>
<p>Should the binary predictors be converted to factors?</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_class">class</code></td>
<td>
<p>Should the simulation produce class labels instead of numbers?</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_intercept">intercept</code></td>
<td>
<p>The intercept, which controls the class balance. The
default value produces a roughly balanced data set when the other defaults
are used.</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_linearvars">linearVars</code></td>
<td>
<p>The number of linearly important effects. See Details
below.</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_mislabel">mislabel</code></td>
<td>
<p>The proportion of data that is possibly mislabeled. Only
used when <code>ordinal = FALSE</code>. See Details below.</p>
</td></tr>
<tr><td><code id="SLC14_1_+3A_ordinal">ordinal</code></td>
<td>
<p>Should an ordered factor be returned? See Details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first function (<code>twoClassSim</code>) generates two class data. The data
are simulated in different sets. First, two multivariate normal predictors
(denoted here as <code>A</code> and <code>B</code>) are created with a correlation our
about 0.65. They change the log-odds using main effects and an interaction:
</p>
<pre> intercept - 4A + 4B + 2AB </pre>
<p>The intercept is a parameter for the simulation and can be used to control
the amount of class imbalance.
</p>
<p>The second set of effects are linear with coefficients that alternate signs
and have values between 2.5 and 0.025. For example, if there were six
predictors in this set, their contribution to the log-odds would be
</p>
<pre> -2.50C + 2.05D -1.60E + 1.15F -0.70G + 0.25H </pre>
<p>The third set is a nonlinear function of a single predictor ranging between
[0, 1] called <code>J</code> here:
</p>
<pre> (J^3) + 2exp(-6(J-0.3)^2) </pre>
<p>The fourth set of informative predictors are copied from one of Friedman's
systems and use two more predictors (<code>K</code> and <code>L</code>):
</p>
<pre> 2sin(KL) </pre>
<p>All of these effects are added up to model the log-odds.
</p>
<p>When <code>ordinal = FALSE</code>, this is used to calculate the probability of a
sample being in the first class and a random uniform number is used to
actually make the assignment of the actual class. To mislabel the data, the
probability is reversed (i.e. <code>p = 1 - p</code>) before the random number
generation.
</p>
<p>For <code>ordinal = TRUE</code>, random normal errors are added to the linear
predictor (i.e. prior to computing the probability) and cut points (0.00,
0.20, 0.75, and 1.00) are used to bin the probabilities into classes
<code>"low"</code>, <code>"med"</code>, and <code>"high"</code> (despite the function's name).
</p>
<p>The remaining functions simulate regression data sets. <code>LPH07_1</code> and
<code>LPH07_2</code> are from van der Laan et al. (2007). The first function uses
random Bernoulli variables that have a 40% probability of being a value of
1. The true regression equation is:
</p>
<pre> 2*w_1*w_10 + 4*w_2*w_7 + 3*w_4*w_5 - 5*w_6*w_10 + 3*w_8*w_9 +
w_1*w_2*w_4 - 2*w_7*(1-w_6)*w_2*w_9 - 4*(1 - w_10)*w_1*(1-w_4) </pre>
<p>The simulated error term is a standard normal (i.e. Gaussian). The noise
variables are simulated in the same manner as described above but are made
binary based on whether the normal random variable is above or below 0. If
<code>factors = TRUE</code>, each of the predictors is coerced into a factor.
This simulation can also be adapted for classification using the option
<code>class = TRUE</code>. In this case, the outcome is converted to be a factor
by first computing the logit transformation of the equation above and using
uniform random numbers to assign the observed class.
</p>
<p>A second function (<code>LPH07_2</code>) uses 20 independent Gaussians with mean
zero and variance 16. The functional form here is:
</p>
<pre> x_1*x_2 + x_10^2 - x_3*x_17 - x_15*x_4 + x_9*x_5 + x_19 -
x_20^2 + x_9*x_8 </pre>
<p>The error term is also Gaussian with mean zero and variance 16.
</p>
<p>The function <code>SLC14_1</code> simulates a system from Sapp et al. (2014). All
informative predictors are independent Gaussian random variables with mean
zero and a variance of 9. The prediction equation is:
</p>
<pre> x_1 + sin(x_2) + log(abs(x_3)) + x_4^2 + x_5*x_6 +
I(x_7*x_8*x_9 &lt; 0) + I(x_10 &gt; 0) + x_11*I(x_11 &gt; 0) + sqrt(abs(x_12)) +
cos(x_13) + 2*x_14 + abs(x_15) + I(x_16 &lt; -1) + x_17*I(x_17 &lt; -1) - 2 * x_18
- x_19*x_20 </pre>
<p>The random error here is also Gaussian with mean zero and a variance of 9.
</p>
<p><code>SLC14_2</code> is also from Sapp et al. (2014). Two hundred independent
Gaussian variables are generated, each having mean zero and variance 16. The
functional form is
</p>
<pre> -1 + log(abs(x_1)) + ... + log(abs(x_200)) </pre>
<p>and the error term is Gaussian with mean zero and a variance of 25.
</p>
<p>For each simulation, the user can also add non-informative predictors to the
data. These are random standard normal predictors and can be optionally
added to the data in two ways: a specified number of independent predictors
or a set number of predictors that follow a particular correlation
structure. The only two correlation structure that have been implemented are
</p>
 <ul>
<li><p> compound-symmetry (aka exchangeable) where there is a
constant correlation between all the predictors
</p>
</li>
<li><p> auto-regressive 1 [AR(1)]. While there is no time component to these
data, this structure can be used to add predictors of varying levels of
correlation. For example, if there were 4 predictors and <code>r</code> was the
correlation parameter, the between predictor correlation matrix would be </p>
</li></ul>

<pre> | 1 sym | | r 1 | | r^2 r 1 | | r^3 r^2 r 1 | | r^4 r^3 r^2 r
1 | </pre>


<h3>Value</h3>

<p>a data frame with columns: </p>
<table>
<tr><td><code>Class</code></td>
<td>
<p>A factor with levels
&quot;Class1&quot; and &quot;Class2&quot;</p>
</td></tr> <tr><td><code>TwoFactor1</code>, <code>TwoFactor2</code></td>
<td>
<p>Correlated
multivariate normal predictors (denoted as <code>A</code> and <code>B</code> above)</p>
</td></tr>
<tr><td><code>Nonlinear1</code>, <code>Nonlinear2</code>, <code>Nonlinear3</code></td>
<td>
<p>Uncorrelated random uniform
predictors (<code>J</code>, <code>K</code> and <code>L</code> above).</p>
</td></tr> <tr><td><code>Linear1</code></td>
<td>
<p>Optional uncorrelated standard normal predictors (<code>C</code> through
<code>H</code> above)</p>
</td></tr><tr><td><code>list()</code></td>
<td>
<p>Optional uncorrelated standard normal
predictors (<code>C</code> through <code>H</code> above)</p>
</td></tr> <tr><td><code>Noise1</code></td>
<td>
<p>Optional
uncorrelated standard normal predictions</p>
</td></tr><tr><td><code>list()</code></td>
<td>
<p>Optional uncorrelated
standard normal predictions</p>
</td></tr> <tr><td><code>Corr1</code></td>
<td>
<p>Optional correlated multivariate
normal predictors (each with unit variances)</p>
</td></tr><tr><td><code>list()</code></td>
<td>
<p>Optional
correlated multivariate normal predictors (each with unit variances)</p>
</td></tr></table>
<p>.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>van der Laan, M. J., &amp; Polley Eric, C. (2007). Super learner.
Statistical Applications in Genetics and Molecular Biology, 6(1), 1-23.
</p>
<p>Sapp, S., van der Laan, M. J., &amp; Canny, J. (2014). Subsemble: an ensemble
method for combining subset-specific algorithm fits. Journal of Applied
Statistics, 41(6), 1247-1259.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
example &lt;- twoClassSim(100, linearVars = 1)
splom(~example[, 1:6], groups = example$Class)

</code></pre>

<hr>
<h2 id='spatialSign'>Compute the multivariate spatial sign</h2><span id='topic+spatialSign'></span><span id='topic+spatialSign.default'></span><span id='topic+spatialSign.matrix'></span><span id='topic+spatialSign.data.frame'></span>

<h3>Description</h3>

<p>Compute the spatial sign (a projection of a data vector to a
unit length circle). The spatial sign of a vector <code>w</code> is
<code>w /norm(w)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatialSign(x, ...)

## Default S3 method:
spatialSign(x, na.rm = TRUE, ...)

## S3 method for class 'matrix'
spatialSign(x, na.rm = TRUE, ...)

## S3 method for class 'data.frame'
spatialSign(x, na.rm = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatialSign_+3A_x">x</code></td>
<td>
<p>an object full of numeric data (which should probably
be scaled). Factors are not allowed. This could be a vector,
matrix or data frame.</p>
</td></tr>
<tr><td><code id="spatialSign_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
<tr><td><code id="spatialSign_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical; should missing data be removed when
computing the norm of the vector?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector, matrix or data frame with the same dim names
of the original data.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Serneels et al. Spatial sign preprocessing: a
simple way to impart moderate robustness to multivariate
estimators. J. Chem. Inf. Model (2006) vol. 46 (3) pp. 1402-1409
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
spatialSign(rnorm(5))

spatialSign(matrix(rnorm(12), ncol = 3))

# should fail since the fifth column is a factor
try(spatialSign(iris), silent = TRUE)

spatialSign(iris[,-5])

trellis.par.set(caretTheme())
featurePlot(iris[,-5], iris[,5], "pairs")
featurePlot(spatialSign(scale(iris[,-5])), iris[,5], "pairs")

</code></pre>

<hr>
<h2 id='summary.bagEarth'>Summarize a bagged earth or FDA fit</h2><span id='topic+summary.bagEarth'></span><span id='topic+summary.bagFDA'></span>

<h3>Description</h3>

<p>The function shows a summary of the results from a bagged earth model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bagEarth'
summary(object, ...)

## S3 method for class 'bagFDA'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.bagEarth_+3A_object">object</code></td>
<td>
<p>an object of class &quot;bagEarth&quot; or &quot;bagFDA&quot;</p>
</td></tr>
<tr><td><code id="summary.bagEarth_+3A_...">...</code></td>
<td>
<p>optional arguments (not used)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The out-of-bag statistics are summarized, as well as the distribution of the
number of model terms and number of variables used across all the bootstrap
samples.
</p>


<h3>Value</h3>

<p>a list with elements </p>
<table>
<tr><td><code>modelInfo</code></td>
<td>
<p>a matrix with the number of
model terms and variables used</p>
</td></tr> <tr><td><code>oobStat</code></td>
<td>
<p>a summary of the out-of-bag
statistics</p>
</td></tr> <tr><td><code>bmarsCall</code></td>
<td>
<p>the original call to <code>bagEarth</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(trees)
set.seed(9655)
fit &lt;- bagEarth(trees[,-3], trees[3])
summary(fit)

## End(Not run)

</code></pre>

<hr>
<h2 id='tecator'>Fat, Water and Protein Content of Meat Samples</h2><span id='topic+tecator'></span><span id='topic+absorp'></span><span id='topic+endpoints'></span>

<h3>Description</h3>

<p>&quot;These data are recorded on a Tecator Infratec Food and Feed Analyzer
working in the wavelength range 850 - 1050 nm by the Near Infrared
Transmission (NIT) principle. Each sample contains finely chopped pure meat
with different moisture, fat and protein contents.
</p>


<h3>Details</h3>

<p>If results from these data are used in a publication we want you to mention
the instrument and company name (Tecator) in the publication.  In addition,
please send a preprint of your article to
</p>
<p>Karin Thente, Tecator AB, Box 70, S-263 21 Hoganas, Sweden
</p>
<p>The data are available in the public domain with no responsibility from the
original data source. The data can be redistributed as long as this
permission note is attached.&quot;
</p>
<p>&quot;For each meat sample the data consists of a 100 channel spectrum of
absorbances and the contents of moisture (water), fat and protein.  The
absorbance is -log10 of the transmittance measured by the spectrometer. The
three contents, measured in percent, are determined by analytic chemistry.&quot;
</p>
<p>Included here are the traning, monitoring and test sets.
</p>


<h3>Value</h3>

<table>
<tr><td><code>absorp</code></td>
<td>
<p>absorbance data for 215 samples. The first 129 were
originally used as a training set</p>
</td></tr> <tr><td><code>endpoints</code></td>
<td>
<p>the percentages of
water, fat and protein</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
data(tecator)

splom(~endpoints)

# plot 10 random spectra
set.seed(1)
inSubset &lt;- sample(1:dim(endpoints)[1], 10)

absorpSubset &lt;- absorp[inSubset,]
endpointSubset &lt;- endpoints[inSubset, 3]

newOrder &lt;- order(absorpSubset[,1])
absorpSubset &lt;- absorpSubset[newOrder,]
endpointSubset &lt;- endpointSubset[newOrder]

plotColors &lt;- rainbow(10)

plot(absorpSubset[1,],
     type = "n",
     ylim = range(absorpSubset),
     xlim = c(0, 105),
     xlab = "Wavelength Index",
     ylab = "Absorption")

for(i in 1:10)
{
   points(absorpSubset[i,], type = "l", col = plotColors[i], lwd = 2)
   text(105, absorpSubset[i,100], endpointSubset[i], col = plotColors[i])
}
title("Predictor Profiles for 10 Random Samples")

</code></pre>

<hr>
<h2 id='thresholder'>Generate Data to Choose a Probability Threshold</h2><span id='topic+thresholder'></span>

<h3>Description</h3>

<p>This function uses the resampling results from a <code><a href="#topic+train">train</a></code>
object to generate performance statistics over a set of probability
thresholds for two-class problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thresholder(x, threshold, final = TRUE, statistics = "all")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thresholder_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+train">train</a></code> object where the values of
<code>savePredictions</code> was either <code>TRUE</code>, <code>"all"</code>,
or <code>"final"</code> in <code><a href="#topic+trainControl">trainControl</a></code>. Also, the 
control argument <code>clasProbs</code> should have been <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="thresholder_+3A_threshold">threshold</code></td>
<td>
<p>A numeric vector of candidate probability thresholds
between [0,1]. If the class probability corresponding to the first
level of the outcome is greater than the threshold, the data point
is classified as that level.</p>
</td></tr>
<tr><td><code id="thresholder_+3A_final">final</code></td>
<td>
<p>A logical: should only the final tuning parameters
chosen by <code><a href="#topic+train">train</a></code> be used when 
<code>savePredictions = 'all'</code>?</p>
</td></tr>
<tr><td><code id="thresholder_+3A_statistics">statistics</code></td>
<td>
<p>A character vector indicating which statistics to
calculate. See details below for possible choices; the default value
<code>"all"</code> computes all of these.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>statistics</code> designates the statistics to compute
for each probability threshold. One or more of the following statistics can
be selected:
</p>

<ul>
<li><p> Sensitivity
</p>
</li>
<li><p> Specificity
</p>
</li>
<li><p> Pos Pred Value
</p>
</li>
<li><p> Neg Pred Value
</p>
</li>
<li><p> Precision
</p>
</li>
<li><p> Recall
</p>
</li>
<li><p> F1
</p>
</li>
<li><p> Prevalence
</p>
</li>
<li><p> Detection Rate
</p>
</li>
<li><p> Detection Prevalence
</p>
</li>
<li><p> Balanced Accuracy
</p>
</li>
<li><p> Accuracy
</p>
</li>
<li><p> Kappa
</p>
</li>
<li><p> J
</p>
</li>
<li><p> Dist
</p>
</li></ul>

<p>For a description of these statistics (except the last two), see the
documentation of <code><a href="#topic+confusionMatrix">confusionMatrix</a></code>. The last two statistics
are Youden's J statistic and the distance to the best possible cutoff (i.e.
perfect sensitivity and specificity.
</p>


<h3>Value</h3>

<p>A data frame with columns for each of the tuning parameters
from the model along with an additional column called
<code>prob_threshold</code> for the probability threshold. There are
also columns for summary statistics averaged over resamples with
column names corresponding to the input argument <code>statistics</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(2444)
dat &lt;- twoClassSim(500, intercept = -10)
table(dat$Class)

ctrl &lt;- trainControl(method = "cv", 
                     classProbs = TRUE,
                     savePredictions = "all",
                     summaryFunction = twoClassSummary)

set.seed(2863)
mod &lt;- train(Class ~ ., data = dat, 
             method = "rda",
             tuneLength = 4,
             metric = "ROC",
             trControl = ctrl)

resample_stats &lt;- thresholder(mod, 
                              threshold = seq(.5, 1, by = 0.05), 
                              final = TRUE)

ggplot(resample_stats, aes(x = prob_threshold, y = J)) + 
  geom_point()
ggplot(resample_stats, aes(x = prob_threshold, y = Dist)) + 
  geom_point()
ggplot(resample_stats, aes(x = prob_threshold, y = Sensitivity)) + 
  geom_point() + 
  geom_point(aes(y = Specificity), col = "red")

## End(Not run)
</code></pre>

<hr>
<h2 id='train'>Fit Predictive Models over Different Tuning Parameters</h2><span id='topic+train'></span><span id='topic+train.default'></span><span id='topic+train.formula'></span><span id='topic+train.recipe'></span>

<h3>Description</h3>

<p>This function sets up a grid of tuning parameters for a number
of classification and regression routines, fits each model and
calculates a resampling based performance measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train(x, ...)

## Default S3 method:
train(
  x,
  y,
  method = "rf",
  preProcess = NULL,
  ...,
  weights = NULL,
  metric = ifelse(is.factor(y), "Accuracy", "RMSE"),
  maximize = ifelse(metric %in% c("RMSE", "logLoss", "MAE", "logLoss"), FALSE, TRUE),
  trControl = trainControl(),
  tuneGrid = NULL,
  tuneLength = ifelse(trControl$method == "none", 1, 3)
)

## S3 method for class 'formula'
train(form, data, ..., weights, subset, na.action = na.fail, contrasts = NULL)

## S3 method for class 'recipe'
train(
  x,
  data,
  method = "rf",
  ...,
  metric = ifelse(is.factor(y_dat), "Accuracy", "RMSE"),
  maximize = ifelse(metric %in% c("RMSE", "logLoss", "MAE"), FALSE, TRUE),
  trControl = trainControl(),
  tuneGrid = NULL,
  tuneLength = ifelse(trControl$method == "none", 1, 3)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_+3A_x">x</code></td>
<td>
<p>For the default method, <code>x</code> is an object where
samples are in rows and features are in columns. This could be a
simple matrix, data frame or other type (e.g. sparse matrix) but
must have column names (see Details below). Preprocessing using
the <code>preProcess</code> argument only supports matrices or data
frames. When using the recipe method, <code>x</code> should be an
unprepared <code><a href="recipes.html#topic+recipe">recipe</a></code> object that describes the model
terms (i.e. outcome, predictors, etc.) as well as any
pre-processing that should be done to the data. This is an
alternative approach to specifying the model. Note that, when
using the recipe method, any arguments passed to <code>preProcess</code>
will be ignored. See the links and example below for more details
using recipes.</p>
</td></tr>
<tr><td><code id="train_+3A_...">...</code></td>
<td>
<p>Arguments passed to the classification or
regression routine (such as
<code><a href="randomForest.html#topic+randomForest">randomForest</a></code>). Errors will occur if
values for tuning parameters are passed here.</p>
</td></tr>
<tr><td><code id="train_+3A_y">y</code></td>
<td>
<p>A numeric or factor vector containing the outcome for
each sample.</p>
</td></tr>
<tr><td><code id="train_+3A_method">method</code></td>
<td>
<p>A string specifying which classification or
regression model to use. Possible values are found using
<code>names(getModelInfo())</code>. See
<a href="http://topepo.github.io/caret/train-models-by-tag.html">http://topepo.github.io/caret/train-models-by-tag.html</a>. A
list of functions can also be passed for a custom model
function. See
<a href="http://topepo.github.io/caret/using-your-own-model-in-train.html">http://topepo.github.io/caret/using-your-own-model-in-train.html</a>
for details.</p>
</td></tr>
<tr><td><code id="train_+3A_preprocess">preProcess</code></td>
<td>
<p>A string vector that defines a pre-processing
of the predictor data. Current possibilities are &quot;BoxCox&quot;,
&quot;YeoJohnson&quot;, &quot;expoTrans&quot;, &quot;center&quot;, &quot;scale&quot;, &quot;range&quot;,
&quot;knnImpute&quot;, &quot;bagImpute&quot;, &quot;medianImpute&quot;, &quot;pca&quot;, &quot;ica&quot; and
&quot;spatialSign&quot;. The default is no pre-processing. See
<code><a href="#topic+preProcess">preProcess</a></code> and <code><a href="#topic+trainControl">trainControl</a></code> on the
procedures and how to adjust them. Pre-processing code is only
designed to work when <code>x</code> is a simple matrix or data frame.</p>
</td></tr>
<tr><td><code id="train_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of case weights. This argument
will only affect models that allow case weights.</p>
</td></tr>
<tr><td><code id="train_+3A_metric">metric</code></td>
<td>
<p>A string that specifies what summary metric will
be used to select the optimal model. By default, possible values
are &quot;RMSE&quot; and &quot;Rsquared&quot; for regression and &quot;Accuracy&quot; and
&quot;Kappa&quot; for classification. If custom performance metrics are
used (via the <code>summaryFunction</code> argument in
<code><a href="#topic+trainControl">trainControl</a></code>, the value of <code>metric</code> should
match one of the arguments. If it does not, a warning is issued
and the first metric given by the <code>summaryFunction</code> is
used. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train_+3A_maximize">maximize</code></td>
<td>
<p>A logical: should the metric be maximized or
minimized?</p>
</td></tr>
<tr><td><code id="train_+3A_trcontrol">trControl</code></td>
<td>
<p>A list of values that define how this function
acts. See <code><a href="#topic+trainControl">trainControl</a></code> and
<a href="http://topepo.github.io/caret/using-your-own-model-in-train.html">http://topepo.github.io/caret/using-your-own-model-in-train.html</a>.
(NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train_+3A_tunegrid">tuneGrid</code></td>
<td>
<p>A data frame with possible tuning values. The
columns are named the same as the tuning parameters. Use
<code><a href="#topic+getModelInfo">getModelInfo</a></code> to get a list of tuning parameters
for each model or see
<a href="http://topepo.github.io/caret/available-models.html">http://topepo.github.io/caret/available-models.html</a>.
(NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train_+3A_tunelength">tuneLength</code></td>
<td>
<p>An integer denoting the amount of granularity
in the tuning parameter grid. By default, this argument is the
number of levels for each tuning parameters that should be
generated by <code><a href="#topic+train">train</a></code>. If <code><a href="#topic+trainControl">trainControl</a></code>
has the option <code>search = "random"</code>, this is the maximum
number of tuning parameter combinations that will be generated
by the random search. (NOTE: If given, this argument must be
named.)</p>
</td></tr>
<tr><td><code id="train_+3A_form">form</code></td>
<td>
<p>A formula of the form <code>y ~ x1 + x2 + ...</code></p>
</td></tr>
<tr><td><code id="train_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in
<code>formula</code> or <code>recipe</code> are preferentially to be taken.</p>
</td></tr>
<tr><td><code id="train_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used
in the training sample. (NOTE: If given, this argument must be
named.)</p>
</td></tr>
<tr><td><code id="train_+3A_na.action">na.action</code></td>
<td>
<p>A function to specify the action to be taken
if NAs are found. The default action is for the procedure to
fail. An alternative is <code>na.omit</code>, which leads to rejection
of cases with missing values on any required variable. (NOTE: If
given, this argument must be named.)</p>
</td></tr>
<tr><td><code id="train_+3A_contrasts">contrasts</code></td>
<td>
<p>A list of contrasts to be used for some or all
the factors appearing as variables in the model formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>train</code> can be used to tune models by picking the
complexity parameters that are associated with the optimal
resampling statistics. For particular model, a grid of
parameters (if any) is created and the model is trained on
slightly different data for each candidate combination of tuning
parameters. Across each data set, the performance of held-out
samples is calculated and the mean and standard deviation is
summarized for each combination. The combination with the
optimal resampling statistic is chosen as the final model and
the entire training set is used to fit a final model.
</p>
<p>The predictors in <code>x</code> can be most any object as long as
the underlying model fit function can deal with the object
class. The function was designed to work with simple matrices
and data frame inputs, so some functionality may not work (e.g.
pre-processing). When using string kernels, the vector of
character strings should be converted to a matrix with a single
column.
</p>
<p>More details on this function can be found at
<a href="http://topepo.github.io/caret/model-training-and-tuning.html">http://topepo.github.io/caret/model-training-and-tuning.html</a>.
</p>
<p>A variety of models are currently available and are enumerated
by tag (i.e. their model characteristics) at
<a href="http://topepo.github.io/caret/train-models-by-tag.html">http://topepo.github.io/caret/train-models-by-tag.html</a>.
</p>
<p>More details on using recipes can be found at
<a href="http://topepo.github.io/caret/using-recipes-with-train.html">http://topepo.github.io/caret/using-recipes-with-train.html</a>.
Note that case weights can be passed into <code>train</code> using a
role of <code>"case weight"</code> for a single variable. Also, if
there are non-predictor columns that should be used when
determining the model's performance metrics, the role of
<code>"performance var"</code> can be used with multiple columns and
these will be made available during resampling to the
<code>summaryFunction</code> function.
</p>


<h3>Value</h3>

<p>A list is returned of class <code>train</code> containing:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>The chosen model.</p>
</td></tr> <tr><td><code>modelType</code></td>
<td>
<p>An
identifier of the model type.</p>
</td></tr> <tr><td><code>results</code></td>
<td>
<p>A data frame the
training error rate and values of the tuning parameters.</p>
</td></tr>
<tr><td><code>bestTune</code></td>
<td>
<p>A data frame with the final parameters.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The (matched) function call with dots expanded</p>
</td></tr>
<tr><td><code>dots</code></td>
<td>
<p>A list containing any ... values passed to the
original call</p>
</td></tr> <tr><td><code>metric</code></td>
<td>
<p>A string that specifies what
summary metric will be used to select the optimal model.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>The list of control parameters.</p>
</td></tr> <tr><td><code>preProcess</code></td>
<td>
<p>Either <code>NULL</code> or an object of class
<code><a href="#topic+preProcess">preProcess</a></code></p>
</td></tr> <tr><td><code>finalModel</code></td>
<td>
<p>A fit object using
the best parameters</p>
</td></tr> <tr><td><code>trainingData</code></td>
<td>
<p>A data frame</p>
</td></tr>
<tr><td><code>resample</code></td>
<td>
<p>A data frame with columns for each performance
metric. Each row corresponds to each resample. If leave-one-out
cross-validation or out-of-bag estimation methods are requested,
this will be <code>NULL</code>. The <code>returnResamp</code> argument of
<code><a href="#topic+trainControl">trainControl</a></code> controls how much of the resampled
results are saved.</p>
</td></tr> <tr><td><code>perfNames</code></td>
<td>
<p>A character vector of
performance metrics that are produced by the summary function</p>
</td></tr>
<tr><td><code>maximize</code></td>
<td>
<p>A logical recycled from the function arguments.</p>
</td></tr>
<tr><td><code>yLimits</code></td>
<td>
<p>The range of the training set outcomes.</p>
</td></tr>
<tr><td><code>times</code></td>
<td>
<p>A list of execution times: <code>everything</code> is for
the entire call to <code>train</code>, <code>final</code> for the final
model fit and, optionally, <code>prediction</code> for the time to
predict new samples (see <code><a href="#topic+trainControl">trainControl</a></code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Max Kuhn (the guts of <code>train.formula</code> were based
on Ripley's <code>nnet.formula</code>)
</p>


<h3>References</h3>

<p><a href="http://topepo.github.io/caret/">http://topepo.github.io/caret/</a>
</p>
<p>Kuhn (2008), &ldquo;Building Predictive Models in R Using the caret&rdquo;
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>)
</p>
<p><a href="https://topepo.github.io/recipes/">https://topepo.github.io/recipes/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+models">models</a></code>, <code><a href="#topic+trainControl">trainControl</a></code>,
<code><a href="#topic+update.train">update.train</a></code>, <code><a href="#topic+modelLookup">modelLookup</a></code>,
<code><a href="#topic+createFolds">createFolds</a></code>, <code><a href="recipes.html#topic+recipe">recipe</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

#######################################
## Classification Example

data(iris)
TrainData &lt;- iris[,1:4]
TrainClasses &lt;- iris[,5]

knnFit1 &lt;- train(TrainData, TrainClasses,
                 method = "knn",
                 preProcess = c("center", "scale"),
                 tuneLength = 10,
                 trControl = trainControl(method = "cv"))

knnFit2 &lt;- train(TrainData, TrainClasses,
                 method = "knn",
                 preProcess = c("center", "scale"),
                 tuneLength = 10,
                 trControl = trainControl(method = "boot"))


library(MASS)
nnetFit &lt;- train(TrainData, TrainClasses,
                 method = "nnet",
                 preProcess = "range",
                 tuneLength = 2,
                 trace = FALSE,
                 maxit = 100)

#######################################
## Regression Example

library(mlbench)
data(BostonHousing)

lmFit &lt;- train(medv ~ . + rm:lstat,
               data = BostonHousing,
               method = "lm")

library(rpart)
rpartFit &lt;- train(medv ~ .,
                  data = BostonHousing,
                  method = "rpart",
                  tuneLength = 9)

#######################################
## Example with a custom metric

madSummary &lt;- function (data,
                        lev = NULL,
                        model = NULL) {
  out &lt;- mad(data$obs - data$pred,
             na.rm = TRUE)
  names(out) &lt;- "MAD"
  out
}

robustControl &lt;- trainControl(summaryFunction = madSummary)
marsGrid &lt;- expand.grid(degree = 1, nprune = (1:10) * 2)

earthFit &lt;- train(medv ~ .,
                  data = BostonHousing,
                  method = "earth",
                  tuneGrid = marsGrid,
                  metric = "MAD",
                  maximize = FALSE,
                  trControl = robustControl)


#######################################
## Example with a recipe

data(cox2)

cox2 &lt;- cox2Descr
cox2$potency &lt;- cox2IC50

library(recipes)

cox2_recipe &lt;- recipe(potency ~ ., data = cox2) %&gt;%
  ## Log the outcome
  step_log(potency, base = 10) %&gt;%
  ## Remove sparse and unbalanced predictors
  step_nzv(all_predictors()) %&gt;%
  ## Surface area predictors are highly correlated so
  ## conduct PCA just on these.
  step_pca(contains("VSA"), prefix = "surf_area_",
           threshold = .95) %&gt;%
  ## Remove other highly correlated predictors
  step_corr(all_predictors(), -starts_with("surf_area_"),
            threshold = .90) %&gt;%
  ## Center and scale all of the non-PCA predictors
  step_center(all_predictors(), -starts_with("surf_area_")) %&gt;%
  step_scale(all_predictors(), -starts_with("surf_area_"))

set.seed(888)
cox2_lm &lt;- train(cox2_recipe,
                 data = cox2,
                 method = "lm",
                 trControl = trainControl(method = "cv"))

#######################################
## Parallel Processing Example via multicore package

## library(doMC)
## registerDoMC(2)

## NOTE: don't run models form RWeka when using
### multicore. The session will crash.

## The code for train() does not change:
set.seed(1)
usingMC &lt;-  train(medv ~ .,
                  data = BostonHousing,
                  method = "glmboost")

## or use:
## library(doMPI) or
## library(doParallel) or
## library(doSMP) and so on


## End(Not run)


</code></pre>

<hr>
<h2 id='train_model_list'>A List of Available Models in train</h2><span id='topic+train_model_list'></span><span id='topic+models'></span>

<h3>Description</h3>

<p>These models are included in the package via wrappers for <code><a href="#topic+train">train</a></code>. Custom models can also be created. See the URL below.
</p>
<p><strong>AdaBoost Classification Trees</strong> (<code>method = 'adaboost'</code>)
</p>
<p>For classification using package <span class="pkg">fastAdaboost</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>nIter</code>, numeric)
</p>
</li>
<li><p> Method (<code>method</code>, character)
</p>
</li></ul>

<p><strong>AdaBoost.M1</strong> (<code>method = 'AdaBoost.M1'</code>)
</p>
<p>For classification using packages <span class="pkg">adabag</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>mfinal</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li>
<li><p> Coefficient Type (<code>coeflearn</code>, character)
</p>
</li></ul>

<p><strong>Adaptive Mixture Discriminant Analysis</strong> (<code>method = 'amdai'</code>)
</p>
<p>For classification using package <span class="pkg">adaptDA</span> with tuning parameters:
</p>

<ul>
<li><p> Model Type (<code>model</code>, character)
</p>
</li></ul>

<p><strong>Adaptive-Network-Based Fuzzy Inference System</strong> (<code>method = 'ANFIS'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Adjacent Categories Probability Model for Ordinal Data</strong> (<code>method = 'vglmAdjCat'</code>)
</p>
<p>For classification using package <span class="pkg">VGAM</span> with tuning parameters:
</p>

<ul>
<li><p> Parallel Curves (<code>parallel</code>, logical)
</p>
</li>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p><strong>Bagged AdaBoost</strong> (<code>method = 'AdaBag'</code>)
</p>
<p>For classification using packages <span class="pkg">adabag</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>mfinal</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li></ul>

<p><strong>Bagged CART</strong> (<code>method = 'treebag'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">ipred</span>, <span class="pkg">plyr</span> and <span class="pkg">e1071</span> with no tuning parameters.
</p>
<p><strong>Bagged FDA using gCV Pruning</strong> (<code>method = 'bagFDAGCV'</code>)
</p>
<p>For classification using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>earth</code> package is fully loaded when this model is used. 
</p>
<p><strong>Bagged Flexible Discriminant Analysis</strong> (<code>method = 'bagFDA'</code>)
</p>
<p>For classification using packages <span class="pkg">earth</span> and <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Number of Terms (<code>nprune</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>earth</code> package is fully loaded when this model is used. 
</p>
<p><strong>Bagged Logic Regression</strong> (<code>method = 'logicBag'</code>)
</p>
<p>For classification and regression using package <span class="pkg">logicFS</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Leaves (<code>nleaves</code>, numeric)
</p>
</li>
<li><p> Number of Trees (<code>ntrees</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>logicFS</code> package is fully loaded when this model is used. 
</p>
<p><strong>Bagged MARS</strong> (<code>method = 'bagEarth'</code>)
</p>
<p>For classification and regression using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Terms (<code>nprune</code>, numeric)
</p>
</li>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>earth</code> package is fully loaded when this model is used. 
</p>
<p><strong>Bagged MARS using gCV Pruning</strong> (<code>method = 'bagEarthGCV'</code>)
</p>
<p>For classification and regression using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>earth</code> package is fully loaded when this model is used. 
</p>
<p><strong>Bagged Model</strong> (<code>method = 'bag'</code>)
</p>
<p>For classification and regression using package <span class="pkg">caret</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>vars</code>, numeric)
</p>
</li></ul>

<p><strong>Bayesian Additive Regression Trees</strong> (<code>method = 'bartMachine'</code>)
</p>
<p>For classification and regression using package <span class="pkg">bartMachine</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>num_trees</code>, numeric)
</p>
</li>
<li><p> Prior Boundary (<code>k</code>, numeric)
</p>
</li>
<li><p> Base Terminal Node Hyperparameter (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Power Terminal Node Hyperparameter (<code>beta</code>, numeric)
</p>
</li>
<li><p> Degrees of Freedom (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>Bayesian Generalized Linear Model</strong> (<code>method = 'bayesglm'</code>)
</p>
<p>For classification and regression using package <span class="pkg">arm</span> with no tuning parameters.
</p>
<p><strong>Bayesian Regularized Neural Networks</strong> (<code>method = 'brnn'</code>)
</p>
<p>For regression using package <span class="pkg">brnn</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Neurons (<code>neurons</code>, numeric)
</p>
</li></ul>

<p><strong>Bayesian Ridge Regression</strong> (<code>method = 'bridge'</code>)
</p>
<p>For regression using package <span class="pkg">monomvn</span> with no tuning parameters.
</p>
<p><strong>Bayesian Ridge Regression (Model Averaged)</strong> (<code>method = 'blassoAveraged'</code>)
</p>
<p>For regression using package <span class="pkg">monomvn</span> with no tuning parameters.
</p>
<p>Note: This model makes predictions by averaging the predictions based on the posterior estimates of the regression coefficients. While it is possible that some of these posterior estimates are zero for non-informative predictors, the final predicted value may be a function of many (or even all) predictors. 
</p>
<p><strong>Binary Discriminant Analysis</strong> (<code>method = 'binda'</code>)
</p>
<p>For classification using package <span class="pkg">binda</span> with tuning parameters:
</p>

<ul>
<li><p> Shrinkage Intensity (<code>lambda.freqs</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Classification Trees</strong> (<code>method = 'ada'</code>)
</p>
<p>For classification using packages <span class="pkg">ada</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>iter</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Generalized Additive Model</strong> (<code>method = 'gamboost'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">mboost</span>, <span class="pkg">plyr</span> and <span class="pkg">import</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> AIC Prune? (<code>prune</code>, character)
</p>
</li></ul>

<p>Note: The <code>prune</code> option for this model enables the number of iterations to be determined by the optimal AIC value across all iterations. See the examples in <code>?mboost::mstop</code>. If pruning is not used, the ensemble makes predictions using the exact value of the <code>mstop</code> tuning parameter value. 
</p>
<p><strong>Boosted Generalized Linear Model</strong> (<code>method = 'glmboost'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">plyr</span> and <span class="pkg">mboost</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> AIC Prune? (<code>prune</code>, character)
</p>
</li></ul>

<p>Note: The <code>prune</code> option for this model enables the number of iterations to be determined by the optimal AIC value across all iterations. See the examples in <code>?mboost::mstop</code>. If pruning is not used, the ensemble makes predictions using the exact value of the <code>mstop</code> tuning parameter value. 
</p>
<p><strong>Boosted Linear Model</strong> (<code>method = 'BstLm'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">bst</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Logistic Regression</strong> (<code>method = 'LogitBoost'</code>)
</p>
<p>For classification using package <span class="pkg">caTools</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>nIter</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Smoothing Spline</strong> (<code>method = 'bstSm'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">bst</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Tree</strong> (<code>method = 'blackboost'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">party</span>, <span class="pkg">mboost</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>mstop</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Tree</strong> (<code>method = 'bstTree'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">bst</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>C4.5-like Trees</strong> (<code>method = 'J48'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Confidence Threshold (<code>C</code>, numeric)
</p>
</li>
<li><p> Minimum Instances Per Leaf (<code>M</code>, numeric)
</p>
</li></ul>

<p><strong>C5.0</strong> (<code>method = 'C5.0'</code>)
</p>
<p>For classification using packages <span class="pkg">C50</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>trials</code>, numeric)
</p>
</li>
<li><p> Model Type (<code>model</code>, character)
</p>
</li>
<li><p> Winnow (<code>winnow</code>, logical)
</p>
</li></ul>

<p><strong>CART</strong> (<code>method = 'rpart'</code>)
</p>
<p>For classification and regression using package <span class="pkg">rpart</span> with tuning parameters:
</p>

<ul>
<li><p> Complexity Parameter (<code>cp</code>, numeric)
</p>
</li></ul>

<p><strong>CART</strong> (<code>method = 'rpart1SE'</code>)
</p>
<p>For classification and regression using package <span class="pkg">rpart</span> with no tuning parameters.
</p>
<p>Note: This CART model replicates the same process used by the <code>rpart</code> function where the model complexity is determined using the one-standard error method. This procedure is replicated inside of the resampling done by <code>train</code> so that an external resampling estimate can be obtained. 
</p>
<p><strong>CART</strong> (<code>method = 'rpart2'</code>)
</p>
<p>For classification and regression using package <span class="pkg">rpart</span> with tuning parameters:
</p>

<ul>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li></ul>

<p><strong>CART or Ordinal Responses</strong> (<code>method = 'rpartScore'</code>)
</p>
<p>For classification using packages <span class="pkg">rpartScore</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Complexity Parameter (<code>cp</code>, numeric)
</p>
</li>
<li><p> Split Function (<code>split</code>, character)
</p>
</li>
<li><p> Pruning Measure (<code>prune</code>, character)
</p>
</li></ul>

<p><strong>CHi-squared Automated Interaction Detection</strong> (<code>method = 'chaid'</code>)
</p>
<p>For classification using package <span class="pkg">CHAID</span> with tuning parameters:
</p>

<ul>
<li><p> Merging Threshold (<code>alpha2</code>, numeric)
</p>
</li>
<li><p> Splitting former Merged Threshold (<code>alpha3</code>, numeric)
</p>
</li>
<li> 
<p>Splitting former Merged Threshold (<code>alpha4</code>, numeric)
</p>
</li></ul>

<p><strong>Conditional Inference Random Forest</strong> (<code>method = 'cforest'</code>)
</p>
<p>For classification and regression using package <span class="pkg">party</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Conditional Inference Tree</strong> (<code>method = 'ctree'</code>)
</p>
<p>For classification and regression using package <span class="pkg">party</span> with tuning parameters:
</p>

<ul>
<li><p> 1 - P-Value Threshold (<code>mincriterion</code>, numeric)
</p>
</li></ul>

<p><strong>Conditional Inference Tree</strong> (<code>method = 'ctree2'</code>)
</p>
<p>For classification and regression using package <span class="pkg">party</span> with tuning parameters:
</p>

<ul>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li>
<li><p> 1 - P-Value Threshold (<code>mincriterion</code>, numeric)
</p>
</li></ul>

<p><strong>Continuation Ratio Model for Ordinal Data</strong> (<code>method = 'vglmContRatio'</code>)
</p>
<p>For classification using package <span class="pkg">VGAM</span> with tuning parameters:
</p>

<ul>
<li><p> Parallel Curves (<code>parallel</code>, logical)
</p>
</li>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p><strong>Cost-Sensitive C5.0</strong> (<code>method = 'C5.0Cost'</code>)
</p>
<p>For classification using packages <span class="pkg">C50</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>trials</code>, numeric)
</p>
</li>
<li><p> Model Type (<code>model</code>, character)
</p>
</li>
<li><p> Winnow (<code>winnow</code>, logical)
</p>
</li>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li></ul>

<p><strong>Cost-Sensitive CART</strong> (<code>method = 'rpartCost'</code>)
</p>
<p>For classification using packages <span class="pkg">rpart</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Complexity Parameter (<code>cp</code>, numeric)
</p>
</li>
<li><p> Cost (<code>Cost</code>, numeric)
</p>
</li></ul>

<p><strong>Cubist</strong> (<code>method = 'cubist'</code>)
</p>
<p>For regression using package <span class="pkg">Cubist</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Committees (<code>committees</code>, numeric)
</p>
</li>
<li><p> Number of Instances (<code>neighbors</code>, numeric)
</p>
</li></ul>

<p><strong>Cumulative Probability Model for Ordinal Data</strong> (<code>method = 'vglmCumulative'</code>)
</p>
<p>For classification using package <span class="pkg">VGAM</span> with tuning parameters:
</p>

<ul>
<li><p> Parallel Curves (<code>parallel</code>, logical)
</p>
</li>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p><strong>DeepBoost</strong> (<code>method = 'deepboost'</code>)
</p>
<p>For classification using package <span class="pkg">deepboost</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>num_iter</code>, numeric)
</p>
</li>
<li><p> Tree Depth (<code>tree_depth</code>, numeric)
</p>
</li>
<li><p> L1 Regularization (<code>beta</code>, numeric)
</p>
</li>
<li><p> Tree Depth Regularization (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Loss (<code>loss_type</code>, character)
</p>
</li></ul>

<p><strong>Diagonal Discriminant Analysis</strong> (<code>method = 'dda'</code>)
</p>
<p>For classification using package <span class="pkg">sparsediscrim</span> with tuning parameters:
</p>

<ul>
<li><p> Model (<code>model</code>, character)
</p>
</li>
<li><p> Shrinkage Type (<code>shrinkage</code>, character)
</p>
</li></ul>

<p><strong>Distance Weighted Discrimination with Polynomial Kernel</strong> (<code>method = 'dwdPoly'</code>)
</p>
<p>For classification using package <span class="pkg">kerndwd</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> q (<code>qval</code>, numeric)
</p>
</li>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li></ul>

<p><strong>Distance Weighted Discrimination with Radial Basis Function Kernel</strong> (<code>method = 'dwdRadial'</code>)
</p>
<p>For classification using packages <span class="pkg">kernlab</span> and <span class="pkg">kerndwd</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> q (<code>qval</code>, numeric)
</p>
</li>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li></ul>

<p><strong>Dynamic Evolving Neural-Fuzzy Inference System </strong> (<code>method = 'DENFIS'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Threshold (<code>Dthr</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Elasticnet</strong> (<code>method = 'enet'</code>)
</p>
<p>For regression using package <span class="pkg">elasticnet</span> with tuning parameters:
</p>

<ul>
<li><p> Fraction of Full Solution (<code>fraction</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Ensembles of Generalized Linear Models</strong> (<code>method = 'randomGLM'</code>)
</p>
<p>For classification and regression using package <span class="pkg">randomGLM</span> with tuning parameters:
</p>

<ul>
<li><p> Interaction Order (<code>maxInteractionOrder</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>randomGLM</code> package is fully loaded when this model is used. 
</p>
<p><strong>eXtreme Gradient Boosting</strong> (<code>method = 'xgbDART'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">xgboost</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>nrounds</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>max_depth</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>eta</code>, numeric)
</p>
</li>
<li><p> Minimum Loss Reduction (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Subsample Percentage (<code>subsample</code>, numeric)
</p>
</li>
<li><p> Subsample Ratio of Columns (<code>colsample_bytree</code>, numeric)
</p>
</li>
<li><p> Fraction of Trees Dropped (<code>rate_drop</code>, numeric)
</p>
</li>
<li><p> Prob. of Skipping Drop-out (<code>skip_drop</code>, numeric)
</p>
</li>
<li><p> Minimum Sum of Instance Weight (<code>min_child_weight</code>, numeric)
</p>
</li></ul>

<p><strong>eXtreme Gradient Boosting</strong> (<code>method = 'xgbLinear'</code>)
</p>
<p>For classification and regression using package <span class="pkg">xgboost</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>nrounds</code>, numeric)
</p>
</li>
<li><p> L2 Regularization (<code>lambda</code>, numeric)
</p>
</li>
<li><p> L1 Regularization (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>eta</code>, numeric)
</p>
</li></ul>

<p><strong>eXtreme Gradient Boosting</strong> (<code>method = 'xgbTree'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">xgboost</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>nrounds</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>max_depth</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>eta</code>, numeric)
</p>
</li>
<li><p> Minimum Loss Reduction (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Subsample Ratio of Columns (<code>colsample_bytree</code>, numeric)
</p>
</li>
<li><p> Minimum Sum of Instance Weight (<code>min_child_weight</code>, numeric)
</p>
</li>
<li><p> Subsample Percentage (<code>subsample</code>, numeric)
</p>
</li></ul>

<p><strong>Extreme Learning Machine</strong> (<code>method = 'elm'</code>)
</p>
<p>For classification and regression using package <span class="pkg">elmNN</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>nhid</code>, numeric)
</p>
</li>
<li><p> Activation Function (<code>actfun</code>, character)
</p>
</li></ul>

<p><strong>Factor-Based Linear Discriminant Analysis</strong> (<code>method = 'RFlda'</code>)
</p>
<p>For classification using package <span class="pkg">HiDimDA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Factors (<code>q</code>, numeric)
</p>
</li></ul>

<p><strong>Flexible Discriminant Analysis</strong> (<code>method = 'fda'</code>)
</p>
<p>For classification using packages <span class="pkg">earth</span> and <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Number of Terms (<code>nprune</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>earth</code> package is fully loaded when this model is used. 
</p>
<p><strong>Fuzzy Inference Rules by Descent Method</strong> (<code>method = 'FIR.DM'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules Using Chi's Method</strong> (<code>method = 'FRBCS.CHI'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Membership Function (<code>type.mf</code>, character)
</p>
</li></ul>

<p><strong>Fuzzy Rules Using Genetic Cooperative-Competitive Learning and Pittsburgh</strong> (<code>method = 'FH.GBML'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Max. Number of Rules (<code>max.num.rule</code>, numeric)
</p>
</li>
<li><p> Population Size (<code>popu.size</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules Using the Structural Learning Algorithm on Vague Environment</strong> (<code>method = 'SLAVE'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules via MOGUL</strong> (<code>method = 'GFS.FR.MOGUL'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li>
<li><p> Max. Tuning Iterations (<code>max.tune</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules via Thrift</strong> (<code>method = 'GFS.THRIFT'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Population Size (<code>popu.size</code>, numeric)
</p>
</li>
<li><p> Number of  Fuzzy Labels (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules with Weight Factor</strong> (<code>method = 'FRBCS.W'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Membership Function (<code>type.mf</code>, character)
</p>
</li></ul>

<p><strong>Gaussian Process</strong> (<code>method = 'gaussprLinear'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with no tuning parameters.
</p>
<p><strong>Gaussian Process with Polynomial Kernel</strong> (<code>method = 'gaussprPoly'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li></ul>

<p><strong>Gaussian Process with Radial Basis Function Kernel</strong> (<code>method = 'gaussprRadial'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li></ul>

<p><strong>Generalized Additive Model using LOESS</strong> (<code>method = 'gamLoess'</code>)
</p>
<p>For classification and regression using package <span class="pkg">gam</span> with tuning parameters:
</p>

<ul>
<li><p> Span (<code>span</code>, numeric)
</p>
</li>
<li><p> Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p>Note: Which terms enter the model in a nonlinear manner is determined by the number of unique values for the predictor. For example, if a predictor only has four unique values, most basis expansion method will fail because there are not enough granularity in the data. By default, a predictor must have at least 10 unique values to be used in a nonlinear basis expansion. Unlike other packages used by <code>train</code>, the <code>gam</code> package is fully loaded when this model is used. 
</p>
<p><strong>Generalized Additive Model using Splines</strong> (<code>method = 'bam'</code>)
</p>
<p>For classification and regression using package <span class="pkg">mgcv</span> with tuning parameters:
</p>

<ul>
<li><p> Feature Selection (<code>select</code>, logical)
</p>
</li>
<li><p> Method (<code>method</code>, character)
</p>
</li></ul>

<p>Note: Which terms enter the model in a nonlinear manner is determined by the number of unique values for the predictor. For example, if a predictor only has four unique values, most basis expansion method will fail because there are not enough granularity in the data. By default, a predictor must have at least 10 unique values to be used in a nonlinear basis expansion. Unlike other packages used by <code>train</code>, the <code>mgcv</code> package is fully loaded when this model is used. 
</p>
<p><strong>Generalized Additive Model using Splines</strong> (<code>method = 'gam'</code>)
</p>
<p>For classification and regression using package <span class="pkg">mgcv</span> with tuning parameters:
</p>

<ul>
<li><p> Feature Selection (<code>select</code>, logical)
</p>
</li>
<li><p> Method (<code>method</code>, character)
</p>
</li></ul>

<p>Note: Which terms enter the model in a nonlinear manner is determined by the number of unique values for the predictor. For example, if a predictor only has four unique values, most basis expansion method will fail because there are not enough granularity in the data. By default, a predictor must have at least 10 unique values to be used in a nonlinear basis expansion. Unlike other packages used by <code>train</code>, the <code>mgcv</code> package is fully loaded when this model is used. 
</p>
<p><strong>Generalized Additive Model using Splines</strong> (<code>method = 'gamSpline'</code>)
</p>
<p>For classification and regression using package <span class="pkg">gam</span> with tuning parameters:
</p>

<ul>
<li><p> Degrees of Freedom (<code>df</code>, numeric)
</p>
</li></ul>

<p>Note: Which terms enter the model in a nonlinear manner is determined by the number of unique values for the predictor. For example, if a predictor only has four unique values, most basis expansion method will fail because there are not enough granularity in the data. By default, a predictor must have at least 10 unique values to be used in a nonlinear basis expansion. Unlike other packages used by <code>train</code>, the <code>gam</code> package is fully loaded when this model is used. 
</p>
<p><strong>Generalized Linear Model</strong> (<code>method = 'glm'</code>)
</p>
<p>For classification and regression with no tuning parameters.
</p>
<p><strong>Generalized Linear Model with Stepwise Feature Selection</strong> (<code>method = 'glmStepAIC'</code>)
</p>
<p>For classification and regression using package <span class="pkg">MASS</span> with no tuning parameters.
</p>
<p><strong>Generalized Partial Least Squares</strong> (<code>method = 'gpls'</code>)
</p>
<p>For classification using package <span class="pkg">gpls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>K.prov</code>, numeric)
</p>
</li></ul>

<p><strong>Genetic Lateral Tuning and Rule Selection of Linguistic Fuzzy Systems</strong> (<code>method = 'GFS.LT.RS'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Population Size (<code>popu.size</code>, numeric)
</p>
</li>
<li><p> Number of  Fuzzy Labels (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>glmnet</strong> (<code>method = 'glmnet_h2o'</code>)
</p>
<p>For classification and regression using package <span class="pkg">h2o</span> with tuning parameters:
</p>

<ul>
<li><p> Mixing Percentage (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>glmnet</strong> (<code>method = 'glmnet'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">glmnet</span> and <span class="pkg">Matrix</span> with tuning parameters:
</p>

<ul>
<li><p> Mixing Percentage (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Gradient Boosting Machines</strong> (<code>method = 'gbm_h2o'</code>)
</p>
<p>For classification and regression using package <span class="pkg">h2o</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>ntrees</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>max_depth</code>, numeric)
</p>
</li>
<li><p> Min. Terminal Node Size (<code>min_rows</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>learn_rate</code>, numeric)
</p>
</li>
<li><p> Number of Randomly Selected Predictors (<code>col_sample_rate</code>, numeric)
</p>
</li></ul>

<p><strong>Greedy Prototype Selection</strong> (<code>method = 'protoclass'</code>)
</p>
<p>For classification using packages <span class="pkg">proxy</span> and <span class="pkg">protoclass</span> with tuning parameters:
</p>

<ul>
<li><p> Ball Size (<code>eps</code>, numeric)
</p>
</li>
<li><p> Distance Order (<code>Minkowski</code>, numeric)
</p>
</li></ul>

<p><strong>Heteroscedastic Discriminant Analysis</strong> (<code>method = 'hda'</code>)
</p>
<p>For classification using package <span class="pkg">hda</span> with tuning parameters:
</p>

<ul>
<li><p> Gamma (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Dimension of the Discriminative Subspace (<code>newdim</code>, numeric)
</p>
</li></ul>

<p><strong>High Dimensional Discriminant Analysis</strong> (<code>method = 'hdda'</code>)
</p>
<p>For classification using package <span class="pkg">HDclassif</span> with tuning parameters:
</p>

<ul>
<li><p> Threshold (<code>threshold</code>, character)
</p>
</li>
<li><p> Model Type (<code>model</code>, numeric)
</p>
</li></ul>

<p><strong>High-Dimensional Regularized Discriminant Analysis</strong> (<code>method = 'hdrda'</code>)
</p>
<p>For classification using package <span class="pkg">sparsediscrim</span> with tuning parameters:
</p>

<ul>
<li><p> Gamma (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Shrinkage Type (<code>shrinkage_type</code>, character)
</p>
</li></ul>

<p><strong>Hybrid Neural Fuzzy Inference System</strong> (<code>method = 'HYFIS'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Independent Component Regression</strong> (<code>method = 'icr'</code>)
</p>
<p>For regression using package <span class="pkg">fastICA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>n.comp</code>, numeric)
</p>
</li></ul>

<p><strong>k-Nearest Neighbors</strong> (<code>method = 'kknn'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kknn</span> with tuning parameters:
</p>

<ul>
<li><p> Max. Number of Neighbors (<code>kmax</code>, numeric)
</p>
</li>
<li><p> Distance (<code>distance</code>, numeric)
</p>
</li>
<li><p> Kernel (<code>kernel</code>, character)
</p>
</li></ul>

<p><strong>k-Nearest Neighbors</strong> (<code>method = 'knn'</code>)
</p>
<p>For classification and regression with tuning parameters:
</p>

<ul>
<li><p> Number of Neighbors (<code>k</code>, numeric)
</p>
</li></ul>

<p><strong>L2 Regularized Linear Support Vector Machines with Class Weights</strong> (<code>method = 'svmLinearWeights2'</code>)
</p>
<p>For classification using package <span class="pkg">LiblineaR</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Loss Function (<code>Loss</code>, character)
</p>
</li>
<li><p> Class Weight (<code>weight</code>, numeric)
</p>
</li></ul>

<p><strong>L2 Regularized Support Vector Machine (dual) with Linear Kernel</strong> (<code>method = 'svmLinear3'</code>)
</p>
<p>For classification and regression using package <span class="pkg">LiblineaR</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Loss Function (<code>Loss</code>, character)
</p>
</li></ul>

<p><strong>Learning Vector Quantization</strong> (<code>method = 'lvq'</code>)
</p>
<p>For classification using package <span class="pkg">class</span> with tuning parameters:
</p>

<ul>
<li><p> Codebook Size (<code>size</code>, numeric)
</p>
</li>
<li><p> Number of Prototypes (<code>k</code>, numeric)
</p>
</li></ul>

<p><strong>Least Angle Regression</strong> (<code>method = 'lars'</code>)
</p>
<p>For regression using package <span class="pkg">lars</span> with tuning parameters:
</p>

<ul>
<li><p> Fraction (<code>fraction</code>, numeric)
</p>
</li></ul>

<p><strong>Least Angle Regression</strong> (<code>method = 'lars2'</code>)
</p>
<p>For regression using package <span class="pkg">lars</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Steps (<code>step</code>, numeric)
</p>
</li></ul>

<p><strong>Least Squares Support Vector Machine</strong> (<code>method = 'lssvmLinear'</code>)
</p>
<p>For classification using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>tau</code>, numeric)
</p>
</li></ul>

<p><strong>Least Squares Support Vector Machine with Polynomial Kernel</strong> (<code>method = 'lssvmPoly'</code>)
</p>
<p>For classification using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li>
<li><p> Regularization Parameter (<code>tau</code>, numeric)
</p>
</li></ul>

<p><strong>Least Squares Support Vector Machine with Radial Basis Function Kernel</strong> (<code>method = 'lssvmRadial'</code>)
</p>
<p>For classification using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li>
<li><p> Regularization Parameter (<code>tau</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Discriminant Analysis</strong> (<code>method = 'lda'</code>)
</p>
<p>For classification using package <span class="pkg">MASS</span> with no tuning parameters.
</p>
<p><strong>Linear Discriminant Analysis</strong> (<code>method = 'lda2'</code>)
</p>
<p>For classification using package <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Discriminant Functions (<code>dimen</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Discriminant Analysis with Stepwise Feature Selection</strong> (<code>method = 'stepLDA'</code>)
</p>
<p>For classification using packages <span class="pkg">klaR</span> and <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Variables (<code>maxvar</code>, numeric)
</p>
</li>
<li><p> Search Direction (<code>direction</code>, character)
</p>
</li></ul>

<p><strong>Linear Distance Weighted Discrimination</strong> (<code>method = 'dwdLinear'</code>)
</p>
<p>For classification using package <span class="pkg">kerndwd</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> q (<code>qval</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Regression</strong> (<code>method = 'lm'</code>)
</p>
<p>For regression with tuning parameters:
</p>

<ul>
<li><p> intercept (<code>intercept</code>, logical)
</p>
</li></ul>

<p><strong>Linear Regression with Backwards Selection</strong> (<code>method = 'leapBackward'</code>)
</p>
<p>For regression using package <span class="pkg">leaps</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Predictors (<code>nvmax</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Regression with Forward Selection</strong> (<code>method = 'leapForward'</code>)
</p>
<p>For regression using package <span class="pkg">leaps</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Predictors (<code>nvmax</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Regression with Stepwise Selection</strong> (<code>method = 'leapSeq'</code>)
</p>
<p>For regression using package <span class="pkg">leaps</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Predictors (<code>nvmax</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Regression with Stepwise Selection</strong> (<code>method = 'lmStepAIC'</code>)
</p>
<p>For regression using package <span class="pkg">MASS</span> with no tuning parameters.
</p>
<p><strong>Linear Support Vector Machines with Class Weights</strong> (<code>method = 'svmLinearWeights'</code>)
</p>
<p>For classification using package <span class="pkg">e1071</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Class Weight (<code>weight</code>, numeric)
</p>
</li></ul>

<p><strong>Localized Linear Discriminant Analysis</strong> (<code>method = 'loclda'</code>)
</p>
<p>For classification using package <span class="pkg">klaR</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Nearest Neighbors (<code>k</code>, numeric)
</p>
</li></ul>

<p><strong>Logic Regression</strong> (<code>method = 'logreg'</code>)
</p>
<p>For classification and regression using package <span class="pkg">LogicReg</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Leaves (<code>treesize</code>, numeric)
</p>
</li>
<li><p> Number of Trees (<code>ntrees</code>, numeric)
</p>
</li></ul>

<p><strong>Logistic Model Trees</strong> (<code>method = 'LMT'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Iteratons (<code>iter</code>, numeric)
</p>
</li></ul>

<p><strong>Maximum Uncertainty Linear Discriminant Analysis</strong> (<code>method = 'Mlda'</code>)
</p>
<p>For classification using package <span class="pkg">HiDimDA</span> with no tuning parameters.
</p>
<p><strong>Mixture Discriminant Analysis</strong> (<code>method = 'mda'</code>)
</p>
<p>For classification using package <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Subclasses Per Class (<code>subclasses</code>, numeric)
</p>
</li></ul>

<p><strong>Model Averaged Naive Bayes Classifier</strong> (<code>method = 'manb'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li>
<li><p> Prior Probability (<code>prior</code>, numeric)
</p>
</li></ul>

<p><strong>Model Averaged Neural Network</strong> (<code>method = 'avNNet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">nnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li>
<li><p> Bagging (<code>bag</code>, logical)
</p>
</li></ul>

<p><strong>Model Rules</strong> (<code>method = 'M5Rules'</code>)
</p>
<p>For regression using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Pruned (<code>pruned</code>, character)
</p>
</li>
<li><p> Smoothed (<code>smoothed</code>, character)
</p>
</li></ul>

<p><strong>Model Tree</strong> (<code>method = 'M5'</code>)
</p>
<p>For regression using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Pruned (<code>pruned</code>, character)
</p>
</li>
<li><p> Smoothed (<code>smoothed</code>, character)
</p>
</li>
<li><p> Rules (<code>rules</code>, character)
</p>
</li></ul>

<p><strong>Monotone Multi-Layer Perceptron Neural Network</strong> (<code>method = 'monmlp'</code>)
</p>
<p>For classification and regression using package <span class="pkg">monmlp</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>hidden1</code>, numeric)
</p>
</li>
<li><p> Number of Models (<code>n.ensemble</code>, numeric)
</p>
</li></ul>

<p><strong>Multi-Layer Perceptron</strong> (<code>method = 'mlp'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li></ul>

<p><strong>Multi-Layer Perceptron</strong> (<code>method = 'mlpWeightDecay'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Multi-Layer Perceptron, multiple layers</strong> (<code>method = 'mlpWeightDecayML'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units layer1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units layer2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units layer3 (<code>layer3</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Multi-Layer Perceptron, with multiple layers</strong> (<code>method = 'mlpML'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units layer1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units layer2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units layer3 (<code>layer3</code>, numeric)
</p>
</li></ul>

<p><strong>Multi-Step Adaptive MCP-Net</strong> (<code>method = 'msaenet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">msaenet</span> with tuning parameters:
</p>

<ul>
<li><p> Alpha (<code>alphas</code>, numeric)
</p>
</li>
<li><p> Number of Adaptive Estimation Steps (<code>nsteps</code>, numeric)
</p>
</li>
<li><p> Adaptive Weight Scaling Factor (<code>scale</code>, numeric)
</p>
</li></ul>

<p><strong>Multilayer Perceptron Network by Stochastic Gradient Descent</strong> (<code>method = 'mlpSGD'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">FCNN4R</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> L2 Regularization (<code>l2reg</code>, numeric)
</p>
</li>
<li><p> RMSE Gradient Scaling (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>learn_rate</code>, numeric)
</p>
</li>
<li><p> Momentum (<code>momentum</code>, numeric)
</p>
</li>
<li><p> Learning Rate Decay (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Batch Size (<code>minibatchsz</code>, numeric)
</p>
</li>
<li><p> Number of Models (<code>repeats</code>, numeric)
</p>
</li></ul>

<p><strong>Multilayer Perceptron Network with Dropout</strong> (<code>method = 'mlpKerasDropout'</code>)
</p>
<p>For classification and regression using package <span class="pkg">keras</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Dropout Rate (<code>dropout</code>, numeric)
</p>
</li>
<li><p> Batch Size (<code>batch_size</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>lr</code>, numeric)
</p>
</li>
<li><p> Rho (<code>rho</code>, numeric)
</p>
</li>
<li><p> Learning Rate Decay (<code>decay</code>, numeric)
</p>
</li>
<li><p> Activation Function (<code>activation</code>, character)
</p>
</li></ul>

<p>Note: After <code>train</code> completes, the keras model object is serialized so that it can be used between R session. When predicting, the code will temporarily unsearalize the object. To make the predictions more efficient, the user might want to use <code>keras::unsearlize_model(object$finalModel$object)</code> in the current R session so that that operation is only done once. Also, this model cannot be run in parallel due to the nature of how tensorflow does the computations. Unlike other packages used by <code>train</code>, the <code>dplyr</code> package is fully loaded when this model is used. 
</p>
<p><strong>Multilayer Perceptron Network with Dropout</strong> (<code>method = 'mlpKerasDropoutCost'</code>)
</p>
<p>For classification using package <span class="pkg">keras</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Dropout Rate (<code>dropout</code>, numeric)
</p>
</li>
<li><p> Batch Size (<code>batch_size</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>lr</code>, numeric)
</p>
</li>
<li><p> Rho (<code>rho</code>, numeric)
</p>
</li>
<li><p> Learning Rate Decay (<code>decay</code>, numeric)
</p>
</li>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Activation Function (<code>activation</code>, character)
</p>
</li></ul>

<p>Note: After <code>train</code> completes, the keras model object is serialized so that it can be used between R session. When predicting, the code will temporarily unsearalize the object. To make the predictions more efficient, the user might want to use <code>keras::unsearlize_model(object$finalModel$object)</code> in the current R session so that that operation is only done once. Also, this model cannot be run in parallel due to the nature of how tensorflow does the computations. Finally, the cost parameter weights the first class in the outcome vector. Unlike other packages used by <code>train</code>, the <code>dplyr</code> package is fully loaded when this model is used. 
</p>
<p><strong>Multilayer Perceptron Network with Weight Decay</strong> (<code>method = 'mlpKerasDecay'</code>)
</p>
<p>For classification and regression using package <span class="pkg">keras</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> L2 Regularization (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Batch Size (<code>batch_size</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>lr</code>, numeric)
</p>
</li>
<li><p> Rho (<code>rho</code>, numeric)
</p>
</li>
<li><p> Learning Rate Decay (<code>decay</code>, numeric)
</p>
</li>
<li><p> Activation Function (<code>activation</code>, character)
</p>
</li></ul>

<p>Note: After <code>train</code> completes, the keras model object is serialized so that it can be used between R session. When predicting, the code will temporarily unsearalize the object. To make the predictions more efficient, the user might want to use <code>keras::unsearlize_model(object$finalModel$object)</code> in the current R session so that that operation is only done once. Also, this model cannot be run in parallel due to the nature of how tensorflow does the computations. Unlike other packages used by <code>train</code>, the <code>dplyr</code> package is fully loaded when this model is used. 
</p>
<p><strong>Multilayer Perceptron Network with Weight Decay</strong> (<code>method = 'mlpKerasDecayCost'</code>)
</p>
<p>For classification using package <span class="pkg">keras</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> L2 Regularization (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Batch Size (<code>batch_size</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>lr</code>, numeric)
</p>
</li>
<li><p> Rho (<code>rho</code>, numeric)
</p>
</li>
<li><p> Learning Rate Decay (<code>decay</code>, numeric)
</p>
</li>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Activation Function (<code>activation</code>, character)
</p>
</li></ul>

<p>Note: After <code>train</code> completes, the keras model object is serialized so that it can be used between R session. When predicting, the code will temporarily unsearalize the object. To make the predictions more efficient, the user might want to use <code>keras::unsearlize_model(object$finalModel$object)</code> in the current R session so that that operation is only done once. Also, this model cannot be run in parallel due to the nature of how tensorflow does the computations. Finally, the cost parameter weights the first class in the outcome vector. Unlike other packages used by <code>train</code>, the <code>dplyr</code> package is fully loaded when this model is used. 
</p>
<p><strong>Multivariate Adaptive Regression Spline</strong> (<code>method = 'earth'</code>)
</p>
<p>For classification and regression using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Terms (<code>nprune</code>, numeric)
</p>
</li>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>earth</code> package is fully loaded when this model is used. 
</p>
<p><strong>Multivariate Adaptive Regression Splines</strong> (<code>method = 'gcvEarth'</code>)
</p>
<p>For classification and regression using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>earth</code> package is fully loaded when this model is used. 
</p>
<p><strong>Naive Bayes</strong> (<code>method = 'naive_bayes'</code>)
</p>
<p>For classification using package <span class="pkg">naivebayes</span> with tuning parameters:
</p>

<ul>
<li><p> Laplace Correction (<code>laplace</code>, numeric)
</p>
</li>
<li><p> Distribution Type (<code>usekernel</code>, logical)
</p>
</li>
<li><p> Bandwidth Adjustment (<code>adjust</code>, numeric)
</p>
</li></ul>

<p><strong>Naive Bayes</strong> (<code>method = 'nb'</code>)
</p>
<p>For classification using package <span class="pkg">klaR</span> with tuning parameters:
</p>

<ul>
<li><p> Laplace Correction (<code>fL</code>, numeric)
</p>
</li>
<li><p> Distribution Type (<code>usekernel</code>, logical)
</p>
</li>
<li><p> Bandwidth Adjustment (<code>adjust</code>, numeric)
</p>
</li></ul>

<p><strong>Naive Bayes Classifier</strong> (<code>method = 'nbDiscrete'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li></ul>

<p><strong>Naive Bayes Classifier with Attribute Weighting</strong> (<code>method = 'awnb'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li></ul>

<p><strong>Nearest Shrunken Centroids</strong> (<code>method = 'pam'</code>)
</p>
<p>For classification using package <span class="pkg">pamr</span> with tuning parameters:
</p>

<ul>
<li><p> Shrinkage Threshold (<code>threshold</code>, numeric)
</p>
</li></ul>

<p><strong>Negative Binomial Generalized Linear Model</strong> (<code>method = 'glm.nb'</code>)
</p>
<p>For regression using package <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p><strong>Neural Network</strong> (<code>method = 'mxnet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">mxnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units in Layer 1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units in Layer 2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units in Layer 3 (<code>layer3</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>learning.rate</code>, numeric)
</p>
</li>
<li><p> Momentum (<code>momentum</code>, numeric)
</p>
</li>
<li><p> Dropout Rate (<code>dropout</code>, numeric)
</p>
</li>
<li><p> Activation Function (<code>activation</code>, character)
</p>
</li></ul>

<p>Note: The <code>mxnet</code> package is not yet on CRAN. See <a href="https://mxnet.apache.org/">https://mxnet.apache.org/</a> for installation instructions. 
</p>
<p><strong>Neural Network</strong> (<code>method = 'mxnetAdam'</code>)
</p>
<p>For classification and regression using package <span class="pkg">mxnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units in Layer 1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units in Layer 2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units in Layer 3 (<code>layer3</code>, numeric)
</p>
</li>
<li><p> Dropout Rate (<code>dropout</code>, numeric)
</p>
</li>
<li><p> beta1 (<code>beta1</code>, numeric)
</p>
</li>
<li><p> beta2 (<code>beta2</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>learningrate</code>, numeric)
</p>
</li>
<li><p> Activation Function (<code>activation</code>, character)
</p>
</li></ul>

<p>Note: The <code>mxnet</code> package is not yet on CRAN. See <a href="https://mxnet.apache.org/">https://mxnet.apache.org/</a> for installation instructions. Users are strongly advised to define <code>num.round</code> themselves. 
</p>
<p><strong>Neural Network</strong> (<code>method = 'neuralnet'</code>)
</p>
<p>For regression using package <span class="pkg">neuralnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units in Layer 1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units in Layer 2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units in Layer 3 (<code>layer3</code>, numeric)
</p>
</li></ul>

<p><strong>Neural Network</strong> (<code>method = 'nnet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">nnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Neural Networks with Feature Extraction</strong> (<code>method = 'pcaNNet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">nnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Non-Convex Penalized Quantile Regression</strong> (<code>method = 'rqnc'</code>)
</p>
<p>For regression using package <span class="pkg">rqPen</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Penalty Type (<code>penalty</code>, character)
</p>
</li></ul>

<p><strong>Non-Informative Model</strong> (<code>method = 'null'</code>)
</p>
<p>For classification and regression with no tuning parameters.
</p>
<p>Note: Since this model always predicts the same value, R-squared values will always be estimated to be NA. 
</p>
<p><strong>Non-Negative Least Squares</strong> (<code>method = 'nnls'</code>)
</p>
<p>For regression using package <span class="pkg">nnls</span> with no tuning parameters.
</p>
<p><strong>Oblique Random Forest</strong> (<code>method = 'ORFlog'</code>)
</p>
<p>For classification using package <span class="pkg">obliqueRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>obliqueRF</code> package is fully loaded when this model is used. 
</p>
<p><strong>Oblique Random Forest</strong> (<code>method = 'ORFpls'</code>)
</p>
<p>For classification using package <span class="pkg">obliqueRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>obliqueRF</code> package is fully loaded when this model is used. 
</p>
<p><strong>Oblique Random Forest</strong> (<code>method = 'ORFridge'</code>)
</p>
<p>For classification using package <span class="pkg">obliqueRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>obliqueRF</code> package is fully loaded when this model is used. 
</p>
<p><strong>Oblique Random Forest</strong> (<code>method = 'ORFsvm'</code>)
</p>
<p>For classification using package <span class="pkg">obliqueRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>obliqueRF</code> package is fully loaded when this model is used. 
</p>
<p><strong>Optimal Weighted Nearest Neighbor Classifier</strong> (<code>method = 'ownn'</code>)
</p>
<p>For classification using package <span class="pkg">snn</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Neighbors (<code>K</code>, numeric)
</p>
</li></ul>

<p><strong>Ordered Logistic or Probit Regression</strong> (<code>method = 'polr'</code>)
</p>
<p>For classification using package <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> parameter (<code>method</code>, character)
</p>
</li></ul>

<p><strong>Parallel Random Forest</strong> (<code>method = 'parRF'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">e1071</span>, <span class="pkg">randomForest</span>, <span class="pkg">foreach</span> and <span class="pkg">import</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>partDSA</strong> (<code>method = 'partDSA'</code>)
</p>
<p>For classification and regression using package <span class="pkg">partDSA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Terminal Partitions (<code>cut.off.growth</code>, numeric)
</p>
</li>
<li><p> Minimum Percent Difference (<code>MPD</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares</strong> (<code>method = 'kernelpls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares</strong> (<code>method = 'pls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares</strong> (<code>method = 'simpls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares</strong> (<code>method = 'widekernelpls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares Generalized Linear Models </strong> (<code>method = 'plsRglm'</code>)
</p>
<p>For classification and regression using package <span class="pkg">plsRglm</span> with tuning parameters:
</p>

<ul>
<li><p> Number of PLS Components (<code>nt</code>, numeric)
</p>
</li>
<li><p> p-Value threshold (<code>alpha.pvals.expli</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>plsRglm</code> package is fully loaded when this model is used. 
</p>
<p><strong>Patient Rule Induction Method</strong> (<code>method = 'PRIM'</code>)
</p>
<p>For classification using package <span class="pkg">supervisedPRIM</span> with tuning parameters:
</p>

<ul>
<li><p> peeling quantile (<code>peel.alpha</code>, numeric)
</p>
</li>
<li><p> pasting quantile (<code>paste.alpha</code>, numeric)
</p>
</li>
<li><p> minimum mass (<code>mass.min</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Discriminant Analysis</strong> (<code>method = 'pda'</code>)
</p>
<p>For classification using package <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Shrinkage Penalty Coefficient (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Discriminant Analysis</strong> (<code>method = 'pda2'</code>)
</p>
<p>For classification using package <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Degrees of Freedom (<code>df</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Linear Discriminant Analysis</strong> (<code>method = 'PenalizedLDA'</code>)
</p>
<p>For classification using packages <span class="pkg">penalizedLDA</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Number of Discriminant Functions (<code>K</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Linear Regression</strong> (<code>method = 'penalized'</code>)
</p>
<p>For regression using package <span class="pkg">penalized</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda1</code>, numeric)
</p>
</li>
<li><p> L2 Penalty (<code>lambda2</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Logistic Regression</strong> (<code>method = 'plr'</code>)
</p>
<p>For classification using package <span class="pkg">stepPlr</span> with tuning parameters:
</p>

<ul>
<li><p> L2 Penalty (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Complexity Parameter (<code>cp</code>, character)
</p>
</li></ul>

<p><strong>Penalized Multinomial Regression</strong> (<code>method = 'multinom'</code>)
</p>
<p>For classification using package <span class="pkg">nnet</span> with tuning parameters:
</p>

<ul>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Ordinal Regression</strong> (<code>method = 'ordinalNet'</code>)
</p>
<p>For classification using packages <span class="pkg">ordinalNet</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Mixing Percentage (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Selection Criterion (<code>criteria</code>, character)
</p>
</li>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p>Note: Requires ordinalNet package version &gt;= 2.0 
</p>
<p><strong>Polynomial Kernel Regularized Least Squares</strong> (<code>method = 'krlsPoly'</code>)
</p>
<p>For regression using package <span class="pkg">KRLS</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Principal Component Analysis</strong> (<code>method = 'pcr'</code>)
</p>
<p>For regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Projection Pursuit Regression</strong> (<code>method = 'ppr'</code>)
</p>
<p>For regression with tuning parameters:
</p>

<ul>
<li><p> Number of  Terms (<code>nterms</code>, numeric)
</p>
</li></ul>

<p><strong>Quadratic Discriminant Analysis</strong> (<code>method = 'qda'</code>)
</p>
<p>For classification using package <span class="pkg">MASS</span> with no tuning parameters.
</p>
<p><strong>Quadratic Discriminant Analysis with Stepwise Feature Selection</strong> (<code>method = 'stepQDA'</code>)
</p>
<p>For classification using packages <span class="pkg">klaR</span> and <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Variables (<code>maxvar</code>, numeric)
</p>
</li>
<li><p> Search Direction (<code>direction</code>, character)
</p>
</li></ul>

<p><strong>Quantile Random Forest</strong> (<code>method = 'qrf'</code>)
</p>
<p>For regression using package <span class="pkg">quantregForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Quantile Regression Neural Network</strong> (<code>method = 'qrnn'</code>)
</p>
<p>For regression using package <span class="pkg">qrnn</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>n.hidden</code>, numeric)
</p>
</li>
<li><p>  Weight Decay (<code>penalty</code>, numeric)
</p>
</li>
<li><p> Bagged Models? (<code>bag</code>, logical)
</p>
</li></ul>

<p><strong>Quantile Regression with LASSO penalty</strong> (<code>method = 'rqlasso'</code>)
</p>
<p>For regression using package <span class="pkg">rqPen</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Radial Basis Function Kernel Regularized Least Squares</strong> (<code>method = 'krlsRadial'</code>)
</p>
<p>For regression using packages <span class="pkg">KRLS</span> and <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li></ul>

<p><strong>Radial Basis Function Network</strong> (<code>method = 'rbf'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li></ul>

<p><strong>Radial Basis Function Network</strong> (<code>method = 'rbfDDA'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Activation Limit for Conflicting Classes (<code>negativeThreshold</code>, numeric)
</p>
</li></ul>

<p><strong>Random Ferns</strong> (<code>method = 'rFerns'</code>)
</p>
<p>For classification using package <span class="pkg">rFerns</span> with tuning parameters:
</p>

<ul>
<li><p> Fern Depth (<code>depth</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest</strong> (<code>method = 'ranger'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">e1071</span>, <span class="pkg">ranger</span> and <span class="pkg">dplyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Splitting Rule (<code>splitrule</code>, character)
</p>
</li>
<li><p> Minimal Node Size (<code>min.node.size</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest</strong> (<code>method = 'Rborist'</code>)
</p>
<p>For classification and regression using package <span class="pkg">Rborist</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>predFixed</code>, numeric)
</p>
</li>
<li><p> Minimal Node Size (<code>minNode</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest</strong> (<code>method = 'rf'</code>)
</p>
<p>For classification and regression using package <span class="pkg">randomForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest by Randomization</strong> (<code>method = 'extraTrees'</code>)
</p>
<p>For classification and regression using package <span class="pkg">extraTrees</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Number of  Random Cuts (<code>numRandomCuts</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest Rule-Based Model</strong> (<code>method = 'rfRules'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">randomForest</span>, <span class="pkg">inTrees</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Maximum Rule Depth (<code>maxdepth</code>, numeric)
</p>
</li></ul>

<p><strong>Regularized Discriminant Analysis</strong> (<code>method = 'rda'</code>)
</p>
<p>For classification using package <span class="pkg">klaR</span> with tuning parameters:
</p>

<ul>
<li><p> Gamma (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Regularized Linear Discriminant Analysis</strong> (<code>method = 'rlda'</code>)
</p>
<p>For classification using package <span class="pkg">sparsediscrim</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Method (<code>estimator</code>, character)
</p>
</li></ul>

<p><strong>Regularized Logistic Regression</strong> (<code>method = 'regLogistic'</code>)
</p>
<p>For classification using package <span class="pkg">LiblineaR</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Loss Function (<code>loss</code>, character)
</p>
</li>
<li><p> Tolerance (<code>epsilon</code>, numeric)
</p>
</li></ul>

<p><strong>Regularized Random Forest</strong> (<code>method = 'RRF'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">randomForest</span> and <span class="pkg">RRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Regularization Value (<code>coefReg</code>, numeric)
</p>
</li>
<li><p> Importance Coefficient (<code>coefImp</code>, numeric)
</p>
</li></ul>

<p><strong>Regularized Random Forest</strong> (<code>method = 'RRFglobal'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Regularization Value (<code>coefReg</code>, numeric)
</p>
</li></ul>

<p><strong>Relaxed Lasso</strong> (<code>method = 'relaxo'</code>)
</p>
<p>For regression using packages <span class="pkg">relaxo</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Penalty Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Relaxation Parameter (<code>phi</code>, numeric)
</p>
</li></ul>

<p><strong>Relevance Vector Machines with Linear Kernel</strong> (<code>method = 'rvmLinear'</code>)
</p>
<p>For regression using package <span class="pkg">kernlab</span> with no tuning parameters.
</p>
<p><strong>Relevance Vector Machines with Polynomial Kernel</strong> (<code>method = 'rvmPoly'</code>)
</p>
<p>For regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Relevance Vector Machines with Radial Basis Function Kernel</strong> (<code>method = 'rvmRadial'</code>)
</p>
<p>For regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li></ul>

<p><strong>Ridge Regression</strong> (<code>method = 'ridge'</code>)
</p>
<p>For regression using package <span class="pkg">elasticnet</span> with tuning parameters:
</p>

<ul>
<li><p> Weight Decay (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Ridge Regression with Variable Selection</strong> (<code>method = 'foba'</code>)
</p>
<p>For regression using package <span class="pkg">foba</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Variables Retained (<code>k</code>, numeric)
</p>
</li>
<li><p> L2 Penalty (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Robust Linear Discriminant Analysis</strong> (<code>method = 'Linda'</code>)
</p>
<p>For classification using package <span class="pkg">rrcov</span> with no tuning parameters.
</p>
<p><strong>Robust Linear Model</strong> (<code>method = 'rlm'</code>)
</p>
<p>For regression using package <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> intercept (<code>intercept</code>, logical)
</p>
</li>
<li><p> psi (<code>psi</code>, character)
</p>
</li></ul>

<p><strong>Robust Mixture Discriminant Analysis</strong> (<code>method = 'rmda'</code>)
</p>
<p>For classification using package <span class="pkg">robustDA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Subclasses Per Class (<code>K</code>, numeric)
</p>
</li>
<li><p> Model (<code>model</code>, character)
</p>
</li></ul>

<p><strong>Robust Quadratic Discriminant Analysis</strong> (<code>method = 'QdaCov'</code>)
</p>
<p>For classification using package <span class="pkg">rrcov</span> with no tuning parameters.
</p>
<p><strong>Robust Regularized Linear Discriminant Analysis</strong> (<code>method = 'rrlda'</code>)
</p>
<p>For classification using package <span class="pkg">rrlda</span> with tuning parameters:
</p>

<ul>
<li><p> Penalty Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Robustness Parameter (<code>hp</code>, numeric)
</p>
</li>
<li><p> Penalty Type (<code>penalty</code>, character)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>rrlda</code> package is fully loaded when this model is used. 
</p>
<p><strong>Robust SIMCA</strong> (<code>method = 'RSimca'</code>)
</p>
<p>For classification using package <span class="pkg">rrcovHD</span> with no tuning parameters.
</p>
<p>Note: Unlike other packages used by <code>train</code>, the <code>rrcovHD</code> package is fully loaded when this model is used. 
</p>
<p><strong>ROC-Based Classifier</strong> (<code>method = 'rocc'</code>)
</p>
<p>For classification using package <span class="pkg">rocc</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Variables Retained (<code>xgenes</code>, numeric)
</p>
</li></ul>

<p><strong>Rotation Forest</strong> (<code>method = 'rotationForest'</code>)
</p>
<p>For classification using package <span class="pkg">rotationForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Variable Subsets (<code>K</code>, numeric)
</p>
</li>
<li><p> Ensemble Size (<code>L</code>, numeric)
</p>
</li></ul>

<p><strong>Rotation Forest</strong> (<code>method = 'rotationForestCp'</code>)
</p>
<p>For classification using packages <span class="pkg">rpart</span>, <span class="pkg">plyr</span> and <span class="pkg">rotationForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Variable Subsets (<code>K</code>, numeric)
</p>
</li>
<li><p> Ensemble Size (<code>L</code>, numeric)
</p>
</li>
<li><p> Complexity Parameter (<code>cp</code>, numeric)
</p>
</li></ul>

<p><strong>Rule-Based Classifier</strong> (<code>method = 'JRip'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Optimizations (<code>NumOpt</code>, numeric)
</p>
</li>
<li><p> Number of  Folds (<code>NumFolds</code>, numeric)
</p>
</li>
<li><p> Min Weights (<code>MinWeights</code>, numeric)
</p>
</li></ul>

<p><strong>Rule-Based Classifier</strong> (<code>method = 'PART'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Confidence Threshold (<code>threshold</code>, numeric)
</p>
</li>
<li><p> Pruning (<code>pruned</code>, character)
</p>
</li></ul>

<p><strong>Self-Organizing Maps</strong> (<code>method = 'xyf'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kohonen</span> with tuning parameters:
</p>

<ul>
<li><p> Rows (<code>xdim</code>, numeric)
</p>
</li>
<li><p> Columns (<code>ydim</code>, numeric)
</p>
</li>
<li><p> Layer Weight (<code>user.weights</code>, numeric)
</p>
</li>
<li><p> Topology (<code>topo</code>, character)
</p>
</li></ul>

<p>Note: As of version 3.0.0 of the kohonen package, the argument <code>user.weights</code> replaces the old <code>alpha</code> parameter. <code>user.weights</code> is usually a vector of relative weights such as <code>c(1, 3)</code> but is parameterized here as a proportion such as <code>c(1-.75, .75)</code> where the .75 is the value of the tuning parameter passed to <code>train</code> and indicates that the outcome layer has 3 times the weight as the predictor layer. 
</p>
<p><strong>Semi-Naive Structure Learner Wrapper</strong> (<code>method = 'nbSearch'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Folds (<code>k</code>, numeric)
</p>
</li>
<li><p> Minimum Absolute Improvement (<code>epsilon</code>, numeric)
</p>
</li>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li>
<li><p> Final Smoothing Parameter (<code>final_smooth</code>, numeric)
</p>
</li>
<li><p> Search Direction (<code>direction</code>, character)
</p>
</li></ul>

<p><strong>Shrinkage Discriminant Analysis</strong> (<code>method = 'sda'</code>)
</p>
<p>For classification using package <span class="pkg">sda</span> with tuning parameters:
</p>

<ul>
<li><p> Diagonalize (<code>diagonal</code>, logical)
</p>
</li>
<li><p> shrinkage (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>SIMCA</strong> (<code>method = 'CSimca'</code>)
</p>
<p>For classification using packages <span class="pkg">rrcov</span> and <span class="pkg">rrcovHD</span> with no tuning parameters.
</p>
<p><strong>Simplified TSK Fuzzy Rules</strong> (<code>method = 'FS.HGD'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Single C5.0 Ruleset</strong> (<code>method = 'C5.0Rules'</code>)
</p>
<p>For classification using package <span class="pkg">C50</span> with no tuning parameters.
</p>
<p><strong>Single C5.0 Tree</strong> (<code>method = 'C5.0Tree'</code>)
</p>
<p>For classification using package <span class="pkg">C50</span> with no tuning parameters.
</p>
<p><strong>Single Rule Classification</strong> (<code>method = 'OneR'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with no tuning parameters.
</p>
<p><strong>Sparse Distance Weighted Discrimination</strong> (<code>method = 'sdwd'</code>)
</p>
<p>For classification using package <span class="pkg">sdwd</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda</code>, numeric)
</p>
</li>
<li><p> L2 Penalty (<code>lambda2</code>, numeric)
</p>
</li></ul>

<p><strong>Sparse Linear Discriminant Analysis</strong> (<code>method = 'sparseLDA'</code>)
</p>
<p>For classification using package <span class="pkg">sparseLDA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Predictors (<code>NumVars</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Sparse Mixture Discriminant Analysis</strong> (<code>method = 'smda'</code>)
</p>
<p>For classification using package <span class="pkg">sparseLDA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Predictors (<code>NumVars</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Number of  Subclasses (<code>R</code>, numeric)
</p>
</li></ul>

<p><strong>Sparse Partial Least Squares</strong> (<code>method = 'spls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">spls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>K</code>, numeric)
</p>
</li>
<li><p> Threshold (<code>eta</code>, numeric)
</p>
</li>
<li><p> Kappa (<code>kappa</code>, numeric)
</p>
</li></ul>

<p><strong>Spike and Slab Regression</strong> (<code>method = 'spikeslab'</code>)
</p>
<p>For regression using packages <span class="pkg">spikeslab</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Variables Retained (<code>vars</code>, numeric)
</p>
</li></ul>

<p>Note: Unlike other packages used by <code>train</code>, the <code>spikeslab</code> package is fully loaded when this model is used. 
</p>
<p><strong>Stabilized Linear Discriminant Analysis</strong> (<code>method = 'slda'</code>)
</p>
<p>For classification using package <span class="pkg">ipred</span> with no tuning parameters.
</p>
<p><strong>Stabilized Nearest Neighbor Classifier</strong> (<code>method = 'snn'</code>)
</p>
<p>For classification using package <span class="pkg">snn</span> with tuning parameters:
</p>

<ul>
<li><p> Stabilization Parameter (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Stacked AutoEncoder Deep Neural Network</strong> (<code>method = 'dnn'</code>)
</p>
<p>For classification and regression using package <span class="pkg">deepnet</span> with tuning parameters:
</p>

<ul>
<li><p> Hidden Layer 1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Hidden Layer 2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Hidden Layer 3 (<code>layer3</code>, numeric)
</p>
</li>
<li><p> Hidden Dropouts (<code>hidden_dropout</code>, numeric)
</p>
</li>
<li><p> Visible Dropout (<code>visible_dropout</code>, numeric)
</p>
</li></ul>

<p><strong>Stochastic Gradient Boosting</strong> (<code>method = 'gbm'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">gbm</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>n.trees</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>interaction.depth</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>shrinkage</code>, numeric)
</p>
</li>
<li><p> Min. Terminal Node Size (<code>n.minobsinnode</code>, numeric)
</p>
</li></ul>

<p><strong>Subtractive Clustering and Fuzzy c-Means Rules</strong> (<code>method = 'SBC'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Radius (<code>r.a</code>, numeric)
</p>
</li>
<li><p> Upper Threshold (<code>eps.high</code>, numeric)
</p>
</li>
<li><p> Lower Threshold (<code>eps.low</code>, numeric)
</p>
</li></ul>

<p><strong>Supervised Principal Component Analysis</strong> (<code>method = 'superpc'</code>)
</p>
<p>For regression using package <span class="pkg">superpc</span> with tuning parameters:
</p>

<ul>
<li><p> Threshold (<code>threshold</code>, numeric)
</p>
</li>
<li><p> Number of Components (<code>n.components</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Boundrange String Kernel</strong> (<code>method = 'svmBoundrangeString'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> length (<code>length</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Class Weights</strong> (<code>method = 'svmRadialWeights'</code>)
</p>
<p>For classification using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li>
<li><p> Weight (<code>Weight</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Exponential String Kernel</strong> (<code>method = 'svmExpoString'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> lambda (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Linear Kernel</strong> (<code>method = 'svmLinear'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Linear Kernel</strong> (<code>method = 'svmLinear2'</code>)
</p>
<p>For classification and regression using package <span class="pkg">e1071</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Polynomial Kernel</strong> (<code>method = 'svmPoly'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Radial Basis Function Kernel</strong> (<code>method = 'svmRadial'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Radial Basis Function Kernel</strong> (<code>method = 'svmRadialCost'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Radial Basis Function Kernel</strong> (<code>method = 'svmRadialSigma'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p>Note: This SVM model tunes over the cost parameter and the RBF kernel parameter sigma. In the latter case, using <code>tuneLength</code> will, at most, evaluate six values of the kernel parameter. This enables a broad search over the cost parameter and a relatively narrow search over <code>sigma</code> 
</p>
<p><strong>Support Vector Machines with Spectrum String Kernel</strong> (<code>method = 'svmSpectrumString'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> length (<code>length</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>The Bayesian lasso</strong> (<code>method = 'blasso'</code>)
</p>
<p>For regression using package <span class="pkg">monomvn</span> with tuning parameters:
</p>

<ul>
<li><p> Sparsity Threshold (<code>sparsity</code>, numeric)
</p>
</li></ul>

<p>Note: This model creates predictions using the mean of the posterior distributions but sets some parameters specifically to zero based on the tuning parameter <code>sparsity</code>. For example, when <code>sparsity = .5</code>, only coefficients where at least half the posterior estimates are nonzero are used. 
</p>
<p><strong>The lasso</strong> (<code>method = 'lasso'</code>)
</p>
<p>For regression using package <span class="pkg">elasticnet</span> with tuning parameters:
</p>

<ul>
<li><p> Fraction of Full Solution (<code>fraction</code>, numeric)
</p>
</li></ul>

<p><strong>Tree Augmented Naive Bayes Classifier</strong> (<code>method = 'tan'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Score Function (<code>score</code>, character)
</p>
</li>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li></ul>

<p><strong>Tree Augmented Naive Bayes Classifier Structure Learner Wrapper</strong> (<code>method = 'tanSearch'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Folds (<code>k</code>, numeric)
</p>
</li>
<li><p> Minimum Absolute Improvement (<code>epsilon</code>, numeric)
</p>
</li>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li>
<li><p> Final Smoothing Parameter (<code>final_smooth</code>, numeric)
</p>
</li>
<li><p> Super-Parent (<code>sp</code>, logical)
</p>
</li></ul>

<p><strong>Tree Augmented Naive Bayes Classifier with Attribute Weighting</strong> (<code>method = 'awtan'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Score Function (<code>score</code>, character)
</p>
</li>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li></ul>

<p><strong>Tree Models from Genetic Algorithms</strong> (<code>method = 'evtree'</code>)
</p>
<p>For classification and regression using package <span class="pkg">evtree</span> with tuning parameters:
</p>

<ul>
<li><p> Complexity Parameter (<code>alpha</code>, numeric)
</p>
</li></ul>

<p><strong>Tree-Based Ensembles</strong> (<code>method = 'nodeHarvest'</code>)
</p>
<p>For classification and regression using package <span class="pkg">nodeHarvest</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Interaction Depth (<code>maxinter</code>, numeric)
</p>
</li>
<li><p> Prediction Mode (<code>mode</code>, character)
</p>
</li></ul>

<p><strong>Variational Bayesian Multinomial Probit Regression</strong> (<code>method = 'vbmpRadial'</code>)
</p>
<p>For classification using package <span class="pkg">vbmp</span> with tuning parameters:
</p>

<ul>
<li><p> Theta Estimated (<code>estimateTheta</code>, character)
</p>
</li></ul>

<p><strong>Wang and Mendel Fuzzy Rules</strong> (<code>method = 'WM'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Membership Function (<code>type.mf</code>, character)
</p>
</li></ul>

<p><strong>Weighted Subspace Random Forest</strong> (<code>method = 'wsrf'</code>)
</p>
<p>For classification using package <span class="pkg">wsrf</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>



<h3>References</h3>

<p>&ldquo;Using your own model in <code><a href="#topic+train">train</a></code>&rdquo; (<a href="https://topepo.github.io/caret/using-your-own-model-in-train.html">https://topepo.github.io/caret/using-your-own-model-in-train.html</a>)</p>

<hr>
<h2 id='trainControl'>Control parameters for train</h2><span id='topic+trainControl'></span>

<h3>Description</h3>

<p>Control the computational nuances of the <code><a href="#topic+train">train</a></code> function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trainControl(
  method = "boot",
  number = ifelse(grepl("cv", method), 10, 25),
  repeats = ifelse(grepl("[d_]cv$", method), 1, NA),
  p = 0.75,
  search = "grid",
  initialWindow = NULL,
  horizon = 1,
  fixedWindow = TRUE,
  skip = 0,
  verboseIter = FALSE,
  returnData = TRUE,
  returnResamp = "final",
  savePredictions = FALSE,
  classProbs = FALSE,
  summaryFunction = defaultSummary,
  selectionFunction = "best",
  preProcOptions = list(thresh = 0.95, ICAcomp = 3, k = 5, freqCut = 95/5, uniqueCut =
    10, cutoff = 0.9),
  sampling = NULL,
  index = NULL,
  indexOut = NULL,
  indexFinal = NULL,
  timingSamps = 0,
  predictionBounds = rep(FALSE, 2),
  seeds = NA,
  adaptive = list(min = 5, alpha = 0.05, method = "gls", complete = TRUE),
  trim = FALSE,
  allowParallel = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trainControl_+3A_method">method</code></td>
<td>
<p>The resampling method: <code>"boot"</code>, <code>"boot632"</code>,
<code>"optimism_boot"</code>, <code>"boot_all"</code>,
<code>"cv"</code>, <code>"repeatedcv"</code>, <code>"LOOCV"</code>, <code>"LGOCV"</code> (for
repeated training/test splits), <code>"none"</code> (only fits one model to the
entire training set), <code>"oob"</code> (only for random forest, bagged trees,
bagged earth, bagged flexible discriminant analysis, or conditional tree
forest models), <code>timeslice</code>, <code>"adaptive_cv"</code>, <code>"adaptive_boot"</code> or
<code>"adaptive_LGOCV"</code></p>
</td></tr>
<tr><td><code id="trainControl_+3A_number">number</code></td>
<td>
<p>Either the number of folds or number of resampling iterations</p>
</td></tr>
<tr><td><code id="trainControl_+3A_repeats">repeats</code></td>
<td>
<p>For repeated k-fold cross-validation only: the number of
complete sets of folds to compute</p>
</td></tr>
<tr><td><code id="trainControl_+3A_p">p</code></td>
<td>
<p>For leave-group out cross-validation: the training percentage</p>
</td></tr>
<tr><td><code id="trainControl_+3A_search">search</code></td>
<td>
<p>Either <code>"grid"</code> or <code>"random"</code>, describing how the
tuning parameter grid is determined. See details below.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_initialwindow">initialWindow</code>, <code id="trainControl_+3A_horizon">horizon</code>, <code id="trainControl_+3A_fixedwindow">fixedWindow</code>, <code id="trainControl_+3A_skip">skip</code></td>
<td>
<p>possible arguments to
<code><a href="#topic+createTimeSlices">createTimeSlices</a></code> when method is <code>timeslice</code>.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_verboseiter">verboseIter</code></td>
<td>
<p>A logical for printing a training log.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_returndata">returnData</code></td>
<td>
<p>A logical for saving the data</p>
</td></tr>
<tr><td><code id="trainControl_+3A_returnresamp">returnResamp</code></td>
<td>
<p>A character string indicating how much of the resampled
summary metrics should be saved. Values can be <code>"final"</code>, <code>"all"</code>
or <code>"none"</code></p>
</td></tr>
<tr><td><code id="trainControl_+3A_savepredictions">savePredictions</code></td>
<td>
<p>an indicator of how much of the hold-out predictions
for each resample should be saved. Values can be either <code>"all"</code>,
<code>"final"</code>, or <code>"none"</code>. A logical value can also be used that
convert to <code>"all"</code> (for true) or <code>"none"</code> (for false).
<code>"final"</code> saves the predictions for the optimal tuning parameters.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_classprobs">classProbs</code></td>
<td>
<p>a logical; should class probabilities be computed for
classification models (along with predicted values) in each resample?</p>
</td></tr>
<tr><td><code id="trainControl_+3A_summaryfunction">summaryFunction</code></td>
<td>
<p>a function to compute performance metrics across
resamples. The arguments to the function should be the same as those in
<code><a href="#topic+defaultSummary">defaultSummary</a></code>. Note that if <code>method = "oob"</code> is used,
this option is ignored and a warning is issued.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_selectionfunction">selectionFunction</code></td>
<td>
<p>the function used to select the optimal tuning
parameter. This can be a name of the function or the function itself. See
<code><a href="#topic+best">best</a></code> for details and other options.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_preprocoptions">preProcOptions</code></td>
<td>
<p>A list of options to pass to <code><a href="#topic+preProcess">preProcess</a></code>.
The type of pre-processing (e.g. center, scaling etc) is passed in via the
<code>preProc</code> option in <code><a href="#topic+train">train</a></code>.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_sampling">sampling</code></td>
<td>
<p>a single character value describing the type of additional
sampling that is conducted after resampling (usually to resolve class
imbalances). Values are <code>"none"</code>, <code>"down"</code>, <code>"up"</code>,
<code>"smote"</code>, or <code>"rose"</code>. The latter two values require the
<span class="pkg">themis</span> and <span class="pkg">ROSE</span> packages, respectively. This argument can also be
a list to facilitate custom sampling and these details can be found on the
<span class="pkg">caret</span> package website for sampling (link below).</p>
</td></tr>
<tr><td><code id="trainControl_+3A_index">index</code></td>
<td>
<p>a list with elements for each resampling iteration. Each list
element is a vector of integers corresponding to the rows used for training
at that iteration.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_indexout">indexOut</code></td>
<td>
<p>a list (the same length as <code>index</code>) that dictates which
data are held-out for each resample (as integers). If <code>NULL</code>, then the
unique set of samples not contained in <code>index</code> is used.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_indexfinal">indexFinal</code></td>
<td>
<p>an optional vector of integers indicating which samples
are used to fit the final model after resampling. If <code>NULL</code>, then
entire data set is used.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_timingsamps">timingSamps</code></td>
<td>
<p>the number of training set samples that will be used to
measure the time for predicting samples (zero indicates that the prediction
time should not be estimated.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_predictionbounds">predictionBounds</code></td>
<td>
<p>a logical or numeric vector of length 2 (regression
only). If logical, the predictions can be constrained to be within the limit
of the training set outcomes. For example, a value of <code>c(TRUE, FALSE)</code>
would only constrain the lower end of predictions. If numeric, specific
bounds can be used. For example, if <code>c(10, NA)</code>, values below 10 would
be predicted as 10 (with no constraint in the upper side).</p>
</td></tr>
<tr><td><code id="trainControl_+3A_seeds">seeds</code></td>
<td>
<p>an optional set of integers that will be used to set the seed
at each resampling iteration. This is useful when the models are run in
parallel. A value of <code>NA</code> will stop the seed from being set within the
worker processes while a value of <code>NULL</code> will set the seeds using a
random set of integers. Alternatively, a list can be used. The list should
have <code>B+1</code> elements where <code>B</code> is the number of resamples, unless
<code>method</code> is <code>"boot632"</code> in which case <code>B</code> is the number of
resamples plus 1. The first <code>B</code> elements of the list should be vectors
of integers of length <code>M</code> where <code>M</code> is the number of models being
evaluated. The last element of the list only needs to be a single integer
(for the final model). See the Examples section below and the Details
section.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_adaptive">adaptive</code></td>
<td>
<p>a list used when <code>method</code> is <code>"adaptive_cv"</code>,
<code>"adaptive_boot"</code> or <code>"adaptive_LGOCV"</code>. See Details below.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_trim">trim</code></td>
<td>
<p>a logical. If <code>TRUE</code> the final model in
<code>object\$finalModel</code> may have some components of the object removed so
reduce the size of the saved object. The <code>predict</code> method will still
work, but some other features of the model may not work. <code>trim</code>ing will
occur only for models where this feature has been implemented.</p>
</td></tr>
<tr><td><code id="trainControl_+3A_allowparallel">allowParallel</code></td>
<td>
<p>if a parallel backend is loaded and available, should
the function use it?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When setting the seeds manually, the number of models being evaluated is
required. This may not be obvious as <code>train</code> does some optimizations
for certain models. For example, when tuning over PLS model, the only model
that is fit is the one with the largest number of components. So if the
model is being tuned over <code>comp in 1:10</code>, the only model fit is
<code>ncomp = 10</code>. However, if the vector of integers used in the
<code>seeds</code> arguments is longer than actually needed, no error is thrown.
</p>
<p>Using <code>method = "none"</code> and specifying more than one model in
<code><a href="#topic+train">train</a></code>'s <code>tuneGrid</code> or <code>tuneLength</code> arguments will
result in an error.
</p>
<p>Using adaptive resampling when <code>method</code> is either <code>"adaptive_cv"</code>,
<code>"adaptive_boot"</code> or <code>"adaptive_LGOCV"</code>, the full set of resamples
is not run for each model. As resampling continues, a futility analysis is
conducted and models with a low probability of being optimal are removed.
These features are experimental. See Kuhn (2014) for more details. The
options for this procedure are:
</p>
 <ul>
<li> <p><code>min</code>: the minimum number of resamples used before
models are removed </p>
</li>
<li> <p><code>alpha</code>: the confidence level of the one-sided
intervals used to measure futility </p>
</li>
<li> <p><code>method</code>: either generalized
least squares (<code>method = "gls"</code>) or a Bradley-Terry model (<code>method
= "BT"</code>) </p>
</li>
<li> <p><code>complete</code>: if a single parameter value is found before
the end of resampling, should the full set of resamples be computed for that
parameter. ) </p>
</li></ul>

<p>The option <code>search = "grid"</code> uses the default grid search routine. When
<code>search = "random"</code>, a random search procedure is used (Bergstra and
Bengio, 2012). See <a href="http://topepo.github.io/caret/random-hyperparameter-search.html">http://topepo.github.io/caret/random-hyperparameter-search.html</a> for
details and an example.
</p>
<p>The supported bootstrap methods are:
</p>

<ul>
<li> <p><code>"boot"</code>: the usual bootstrap.
</p>
</li>
<li> <p><code>"boot632"</code>: the 0.632 bootstrap estimator (Efron, 1983).
</p>
</li>
<li> <p><code>"optimism_boot"</code>: the optimism bootstrap estimator.
(Efron and Tibshirani, 1994).
</p>
</li>
<li> <p><code>"boot_all"</code>: all of the above (for efficiency,
but &quot;boot&quot; will be used for calculations).
</p>
</li></ul>

<p>The <code>"boot632"</code> method should not to be confused with the 0.632+
estimator proposed later by the same author.
</p>
<p>Note that if <code>index</code> or <code>indexOut</code> are specified, the label shown by <code>train</code> may not be accurate since these arguments supersede the <code>method</code> argument.
</p>


<h3>Value</h3>

<p>An echo of the parameters specified
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Efron (1983). &ldquo;Estimating the error rate of a prediction rule:
improvement on cross-validation&rdquo;. Journal of the American Statistical
Association, 78(382):316-331
</p>
<p>Efron, B., &amp; Tibshirani, R. J. (1994). &ldquo;An introduction to the bootstrap&rdquo;,
pages 249-252. CRC press.
</p>
<p>Bergstra and Bengio (2012), &ldquo;Random Search for Hyper-Parameter
Optimization&rdquo;, Journal of Machine Learning Research, 13(Feb):281-305
</p>
<p>Kuhn (2014), &ldquo;Futility Analysis in the Cross-Validation of Machine Learning
Models&rdquo; <a href="https://arxiv.org/abs/1405.6974">https://arxiv.org/abs/1405.6974</a>,
</p>
<p>Package website for subsampling:
<a href="https://topepo.github.io/caret/subsampling-for-class-imbalances.html">https://topepo.github.io/caret/subsampling-for-class-imbalances.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

## Do 5 repeats of 10-Fold CV for the iris data. We will fit
## a KNN model that evaluates 12 values of k and set the seed
## at each iteration.

set.seed(123)
seeds &lt;- vector(mode = "list", length = 51)
for(i in 1:50) seeds[[i]] &lt;- sample.int(1000, 22)

## For the last model:
seeds[[51]] &lt;- sample.int(1000, 1)

ctrl &lt;- trainControl(method = "repeatedcv",
                     repeats = 5,
                     seeds = seeds)

set.seed(1)
mod &lt;- train(Species ~ ., data = iris,
             method = "knn",
             tuneLength = 12,
             trControl = ctrl)


ctrl2 &lt;- trainControl(method = "adaptive_cv",
                      repeats = 5,
                      verboseIter = TRUE,
                      seeds = seeds)

set.seed(1)
mod2 &lt;- train(Species ~ ., data = iris,
              method = "knn",
              tuneLength = 12,
              trControl = ctrl2)


## End(Not run)

</code></pre>

<hr>
<h2 id='update.safs'>Update or Re-fit a SA or GA Model</h2><span id='topic+update.safs'></span><span id='topic+update.gafs'></span>

<h3>Description</h3>

<p><code>update</code> allows a user to over-ride the search iteration selection
process.
</p>
<p>Based on the results of plotting a <code><a href="#topic+gafs">gafs</a></code> or <code><a href="#topic+safs">safs</a></code>
object, these functions can be used to supersede the number of iterations
determined analytically from the resamples.
</p>
<p>Any values of <code>...</code> originally passed to <code><a href="#topic+gafs">gafs</a></code> or
<code><a href="#topic+safs">safs</a></code> are automatically passed on to the updated model (i.e.
they do not need to be supplied again to <code>update</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'safs'
update(object, iter, x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update.safs_+3A_object">object</code></td>
<td>
<p>An object produced by <code><a href="#topic+gafs">gafs</a></code> or <code><a href="#topic+safs">safs</a></code></p>
</td></tr>
<tr><td><code id="update.safs_+3A_iter">iter</code></td>
<td>
<p>a single numeric integer</p>
</td></tr>
<tr><td><code id="update.safs_+3A_x">x</code>, <code id="update.safs_+3A_y">y</code></td>
<td>
<p>the original training data used in the call to <code><a href="#topic+gafs">gafs</a></code>
or <code><a href="#topic+safs">safs</a></code>. Only required for non-recipe methods.</p>
</td></tr>
<tr><td><code id="update.safs_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code><a href="#topic+gafs">gafs</a></code> or <code><a href="#topic+safs">safs</a></code>
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gafs">gafs</a></code>, <code><a href="#topic+safs">safs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(1)
train_data &lt;- twoClassSim(100, noiseVars = 10)
test_data  &lt;- twoClassSim(10,  noiseVars = 10)

## A short example
ctrl &lt;- safsControl(functions = rfSA,
                    method = "cv",
                    number = 3)

rf_search &lt;- safs(x = train_data[, -ncol(train_data)],
                  y = train_data$Class,
                  iters = 3,
                  safsControl = ctrl)

rf_search2 &lt;- update(rf_search,
	                 iter = 1,
	                 x = train_data[, -ncol(train_data)],
                     y = train_data$Class)
rf_search2

## End(Not run)
</code></pre>

<hr>
<h2 id='update.train'>Update or Re-fit a Model</h2><span id='topic+update.train'></span>

<h3>Description</h3>

<p><code>update</code> allows a user to over-ride the tuning parameter selection
process by specifying a set of tuning parameters or to update the model
object to the latest version of this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'train'
update(object, param = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update.train_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="update.train_+3A_param">param</code></td>
<td>
<p>a data frame or named list of all tuning parameters</p>
</td></tr>
<tr><td><code id="update.train_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the model object was created with version 5.17-7 or earlier, the
underlying package structure was different. To make old <code><a href="#topic+train">train</a></code>
objects consistent with the new structure, use <code>param = NULL</code> to get
the same object back with updates.
</p>
<p>To update the model parameters, the training data must be stored in the
model object (see the option <code>returnData</code> in
<code><a href="#topic+trainControl">trainControl</a></code>. Also, all tuning parameters must be specified in
the <code>param</code> slot. All other options are held constant, including the
original pre-processing (if any), options passed in using code... and so on.
When printing, the verbiage &quot;The tuning parameter was set manually.&quot; is used
to describe how the tuning parameters were created.
</p>


<h3>Value</h3>

<p>a new <code><a href="#topic+train">train</a></code> object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train">train</a></code>, <code><a href="#topic+trainControl">trainControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(iris)
TrainData &lt;- iris[,1:4]
TrainClasses &lt;- iris[,5]

knnFit1 &lt;- train(TrainData, TrainClasses,
                 method = "knn",
                 preProcess = c("center", "scale"),
                 tuneLength = 10,
                 trControl = trainControl(method = "cv"))

update(knnFit1, list(.k = 3))

## End(Not run)
</code></pre>

<hr>
<h2 id='var_seq'>Sequences of Variables for Tuning</h2><span id='topic+var_seq'></span>

<h3>Description</h3>

<p>This function generates a sequence of <code>mtry</code> values for random forests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_seq(p, classification = FALSE, len = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_seq_+3A_p">p</code></td>
<td>
<p>The number of predictors</p>
</td></tr>
<tr><td><code id="var_seq_+3A_classification">classification</code></td>
<td>
<p>Is the outcome a factor (<code>classification = TRUE</code>
or numeric?)</p>
</td></tr>
<tr><td><code id="var_seq_+3A_len">len</code></td>
<td>
<p>The number of <code>mtry</code> values to generate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the number of predictors is less than 500, a simple sequence of values of
length <code>len</code> is generated between 2 and <code>p</code>. For larger numbers of
predictors, the sequence is created using <code>log2</code> steps.
</p>
<p>If <code>len = 1</code>, the defaults from the <code>randomForest</code> package are
used.
</p>


<h3>Value</h3>

<p>a numeric vector
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
var_seq(p = 100, len = 10)
var_seq(p = 600, len = 10)

</code></pre>

<hr>
<h2 id='varImp'>Calculation of variable importance for regression and classification models</h2><span id='topic+varImp'></span><span id='topic+varImp.train'></span><span id='topic+varImp.earth'></span><span id='topic+varImp.rpart'></span><span id='topic+varImp.randomForest'></span><span id='topic+varImp.gbm'></span><span id='topic+varImp.regbagg'></span><span id='topic+varImp.classbagg'></span><span id='topic+varImp.pamrtrained'></span><span id='topic+varImp.lm'></span><span id='topic+varImp.mvr'></span><span id='topic+varImp.bagEarth'></span><span id='topic+varImp.bagFDA'></span><span id='topic+varImp.RandomForest'></span><span id='topic+varImp.rfe'></span><span id='topic+varImp.dsa'></span><span id='topic+varImp.fda'></span><span id='topic+varImp.multinom'></span><span id='topic+varImp.cubist'></span><span id='topic+varImp.plsda'></span><span id='topic+varImp.JRip'></span><span id='topic+varImp.PART'></span><span id='topic+varImp.nnet'></span><span id='topic+varImp.C5.0'></span><span id='topic+varImp.glmnet'></span><span id='topic+varImp.glm'></span><span id='topic+varImp.avNNet'></span><span id='topic+varImp.RRF'></span><span id='topic+varImp.gam'></span><span id='topic+varImp.Gam'></span>

<h3>Description</h3>

<p>A generic method for calculating variable importance for objects produced by
<code>train</code> and method specific methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varImp(object, ...)

## S3 method for class 'bagEarth'
varImp(object, ...)

## S3 method for class 'bagFDA'
varImp(object, ...)

## S3 method for class 'C5.0'
varImp(object, ...)

## S3 method for class 'cubist'
varImp(object, weights = c(0.5, 0.5), ...)

## S3 method for class 'dsa'
varImp(object, cuts = NULL, ...)

## S3 method for class 'glm'
varImp(object, ...)

## S3 method for class 'glmnet'
varImp(object, lambda = NULL, ...)

## S3 method for class 'JRip'
varImp(object, ...)

## S3 method for class 'multinom'
varImp(object, ...)

## S3 method for class 'nnet'
varImp(object, ...)

## S3 method for class 'avNNet'
varImp(object, ...)

## S3 method for class 'PART'
varImp(object, ...)

## S3 method for class 'RRF'
varImp(object, ...)

## S3 method for class 'rpart'
varImp(object, surrogates = FALSE, competes = TRUE, ...)

## S3 method for class 'randomForest'
varImp(object, ...)

## S3 method for class 'gbm'
varImp(object, numTrees = NULL, ...)

## S3 method for class 'classbagg'
varImp(object, ...)

## S3 method for class 'regbagg'
varImp(object, ...)

## S3 method for class 'pamrtrained'
varImp(object, threshold, data, ...)

## S3 method for class 'lm'
varImp(object, ...)

## S3 method for class 'mvr'
varImp(object, estimate = NULL, ...)

## S3 method for class 'earth'
varImp(object, value = "gcv", ...)

## S3 method for class 'RandomForest'
varImp(object, ...)

## S3 method for class 'plsda'
varImp(object, ...)

## S3 method for class 'fda'
varImp(object, value = "gcv", ...)

## S3 method for class 'gam'
varImp(object, ...)

## S3 method for class 'Gam'
varImp(object, ...)

## S3 method for class 'train'
varImp(object, useModel = TRUE, nonpara = TRUE, scale = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varImp_+3A_object">object</code></td>
<td>
<p>an object corresponding to a fitted model</p>
</td></tr>
<tr><td><code id="varImp_+3A_...">...</code></td>
<td>
<p>parameters to pass to the specific <code>varImp</code> methods</p>
</td></tr>
<tr><td><code id="varImp_+3A_weights">weights</code></td>
<td>
<p>a numeric vector of length two that weighs the usage of
variables in the rule conditions and the usage in the linear models (see
details below).</p>
</td></tr>
<tr><td><code id="varImp_+3A_cuts">cuts</code></td>
<td>
<p>the number of rule sets to use in the model (for <code>partDSA</code>
only)</p>
</td></tr>
<tr><td><code id="varImp_+3A_lambda">lambda</code></td>
<td>
<p>a single value of the penalty parameter</p>
</td></tr>
<tr><td><code id="varImp_+3A_surrogates">surrogates</code></td>
<td>
<p>should surrogate splits contribute to the importance
calculation?</p>
</td></tr>
<tr><td><code id="varImp_+3A_competes">competes</code></td>
<td>
<p>should competing splits contribute to the importance
calculation?</p>
</td></tr>
<tr><td><code id="varImp_+3A_numtrees">numTrees</code></td>
<td>
<p>the number of iterations (trees) to use in a boosted tree
model</p>
</td></tr>
<tr><td><code id="varImp_+3A_threshold">threshold</code></td>
<td>
<p>the shrinkage threshold (<code>pamr</code> models only)</p>
</td></tr>
<tr><td><code id="varImp_+3A_data">data</code></td>
<td>
<p>the training set predictors (<code>pamr</code> models only)</p>
</td></tr>
<tr><td><code id="varImp_+3A_estimate">estimate</code></td>
<td>
<p>which estimate of performance should be used? See
<code><a href="pls.html#topic+mvrVal">mvrVal</a></code></p>
</td></tr>
<tr><td><code id="varImp_+3A_value">value</code></td>
<td>
<p>the statistic that will be used to calculate importance: either
<code>gcv</code>, <code>nsubsets</code>, or <code>rss</code></p>
</td></tr>
<tr><td><code id="varImp_+3A_usemodel">useModel</code></td>
<td>
<p>use a model based technique for measuring variable
importance?  This is only used for some models (lm, pls, rf, rpart, gbm, pam
and mars)</p>
</td></tr>
<tr><td><code id="varImp_+3A_nonpara">nonpara</code></td>
<td>
<p>should nonparametric methods be used to assess the
relationship between the features and response (only used with
<code>useModel = FALSE</code> and only passed to <code>filterVarImp</code>).</p>
</td></tr>
<tr><td><code id="varImp_+3A_scale">scale</code></td>
<td>
<p>should the importance values be scaled to 0 and 100?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For models that do not have corresponding <code>varImp</code> methods, see
<code><a href="#topic+filterVarImp">filterVarImp</a></code>.
</p>
<p>Otherwise:
</p>
<p><b>Linear Models</b>: the absolute value of the t-statistic for each model
parameter is used.
</p>
<p><b><code>glmboost</code></b> and <b><code>glmnet</code></b>: the absolute value of the coefficients
corresponding the the tuned model are used.
</p>
<p><b>Random Forest</b>: <code>varImp.randomForest</code> and
<code>varImp.RandomForest</code> are wrappers around the importance functions from
the <span class="pkg">randomForest</span> and <span class="pkg">party</span> packages, respectively.
</p>
<p><b>Partial Least Squares</b>: the variable importance measure here is based
on weighted sums of the absolute regression coefficients. The weights are a
function of the reduction of the sums of squares across the number of PLS
components and are computed separately for each outcome. Therefore, the
contribution of the coefficients are weighted proportionally to the
reduction in the sums of squares.
</p>
<p><b>Recursive Partitioning</b>: The reduction in the loss function (e.g. mean
squared error) attributed to each variable at each split is tabulated and
the sum is returned. Also, since there may be candidate variables that are
important but are not used in a split, the top competing variables are also
tabulated at each split. This can be turned off using the <code>maxcompete</code>
argument in <code>rpart.control</code>. This method does not currently provide
class-specific measures of importance when the response is a factor.
</p>
<p><b>Bagged Trees</b>: The same methodology as a single tree is applied to all
bootstrapped trees and the total importance is returned
</p>
<p><b>Boosted Trees</b>: <code>varImp.gbm</code> is a wrapper around the function
from that package (see the <span class="pkg">gbm</span> package vignette)
</p>
<p><b> Multivariate Adaptive Regression Splines</b>: MARS models include a
backwards elimination feature selection routine that looks at reductions in
the generalized cross-validation (GCV) estimate of error. The <code>varImp</code>
function tracks the changes in model statistics, such as the GCV, for each
predictor and accumulates the reduction in the statistic when each
predictor's feature is added to the model. This total reduction is used as
the variable importance measure. If a predictor was never used in any of the
MARS basis functions in the final model (after pruning), it has an
importance value of zero. Prior to June 2008, the package used an internal
function for these calculations. Currently, the <code>varImp</code> is a wrapper
to the <code><a href="earth.html#topic+evimp">evimp</a></code> function in the <code>earth</code> package.
There are three statistics that can be used to estimate variable importance
in MARS models. Using <code>varImp(object, value = "gcv")</code> tracks the
reduction in the generalized cross-validation statistic as terms are added.
However, there are some cases when terms are retained in the model that
result in an increase in GCV. Negative variable importance values for MARS
are set to zero.  Alternatively, using <code>varImp(object, value = "rss")</code>
monitors the change in the residual sums of squares (RSS) as terms are
added, which will never be negative.  Also, the option <code>varImp(object,
value =" nsubsets")</code>, which counts the number of subsets where the variable
is used (in the final, pruned model).
</p>
<p><b>Nearest shrunken centroids</b>: The difference between the class
centroids and the overall centroid is used to measure the variable influence
(see <code>pamr.predict</code>). The larger the difference between the class
centroid and the overall center of the data, the larger the separation
between the classes. The training set predictions must be supplied when an
object of class <code>pamrtrained</code> is given to <code>varImp</code>.
</p>
<p><b>Cubist</b>: The Cubist output contains variable usage statistics. It
gives the percentage of times where each variable was used in a condition
and/or a linear model. Note that this output will probably be inconsistent
with the rules shown in the output from
<code><a href="Cubist.html#topic+summary.cubist">summary.cubist</a></code>. At each split of the tree, Cubist
saves a linear model (after feature selection) that is allowed to have terms
for each variable used in the current split or any split above it. Quinlan
(1992) discusses a smoothing algorithm where each model prediction is a
linear combination of the parent and child model along the tree. As such,
the final prediction is a function of all the linear models from the initial
node to the terminal node. The percentages shown in the Cubist output
reflects all the models involved in prediction (as opposed to the terminal
models shown in the output). The variable importance used here is a linear
combination of the usage in the rule conditions and the model.
</p>
<p><b>PART</b> and <b>JRip</b>: For these rule-based models, the importance for
a predictor is simply the number of rules that involve the predictor.
</p>
<p><b>C5.0</b>: C5.0 measures predictor importance by determining the
percentage of training set samples that fall into all the terminal nodes
after the split. For example, the predictor in the first split automatically
has an importance measurement of 100 percent since all samples are affected
by this split. Other predictors may be used frequently in splits, but if the
terminal nodes cover only a handful of training set samples, the importance
scores may be close to zero. The same strategy is applied to rule-based
models and boosted versions of the model. The underlying function can also
return the number of times each predictor was involved in a split by using
the option <code>metric = "usage"</code>.
</p>
<p><b>Neural Networks</b>: The method used here is based on Gevrey et al
(2003), which uses combinations of the absolute values of the weights. For
classification models, the class-specific importances will be the same.
</p>
<p><b>Recursive Feature Elimination</b>: Variable importance is computed using
the ranking method used for feature selection. For the final subset size,
the importances for the models across all resamples are averaged to compute
an overall value.
</p>
<p><b>Feature Selection via Univariate Filters</b>, the percentage of resamples
that a predictor was selected is determined. In other words, an importance
of 0.50 means that the predictor survived the filter in half of the
resamples.
</p>


<h3>Value</h3>

<p>A data frame with class <code>c("varImp.train", "data.frame")</code> for
<code>varImp.train</code> or a matrix for other models.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Gevrey, M., Dimopoulos, I., &amp; Lek, S. (2003). Review and
comparison of methods to study the contribution of variables in artificial
neural network models. Ecological Modelling, 160(3), 249-264.
</p>
<p>Quinlan, J. (1992). Learning with continuous classes. Proceedings of the 5th
Australian Joint Conference On Artificial Intelligence, 343-348.
</p>

<hr>
<h2 id='varImp.gafs'>Variable importances for GAs and SAs</h2><span id='topic+varImp.gafs'></span><span id='topic+varImp.safs'></span>

<h3>Description</h3>

<p>Variable importance scores for <code><a href="#topic+safs">safs</a></code> and <code><a href="#topic+gafs">gafs</a></code>
objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gafs'
varImp(
  object,
  metric = object$control$metric["external"],
  maximize = object$control$maximize["external"],
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varImp.gafs_+3A_object">object</code></td>
<td>
<p>an <code><a href="#topic+safs">safs</a></code> or <code><a href="#topic+gafs">gafs</a></code> object</p>
</td></tr>
<tr><td><code id="varImp.gafs_+3A_metric">metric</code></td>
<td>
<p>a metric to compute importance (see Details below)</p>
</td></tr>
<tr><td><code id="varImp.gafs_+3A_maximize">maximize</code></td>
<td>
<p>are larger values of the metric better?</p>
</td></tr>
<tr><td><code id="varImp.gafs_+3A_...">...</code></td>
<td>
<p>not currently uses</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A crude measure of importance is computed for thee two search procedures. At
the end of a search process, the difference in the fitness values is
computed for models with and without each feature (based on the search
history). If a predictor has at least two subsets that include and did not
include the predictor, a t-statistic is computed (otherwise a value of
<code>NA</code> is assigned to the predictor).
</p>
<p>This computation is done separately for each resample and the t-statistics
are averaged (<code>NA</code> values are ignored) and this average is reported as
the importance. If the fitness value should be minimized, the negative value
of the t-statistic is used in the average.
</p>
<p>As such, the importance score reflects the standardized increase in fitness
that occurs when the predict is included in the subset. Values near zero (or
negative) indicate that the predictor may not be important to the model.
</p>


<h3>Value</h3>

<p>a data frame where the rownames are the predictor names and the
column is the average t-statistic
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>See Also</h3>

<p><code><a href="#topic+safs">safs</a></code>, <code><a href="#topic+gafs">gafs</a></code>
</p>

<hr>
<h2 id='xyplot.resamples'>Lattice Functions for Visualizing Resampling Results</h2><span id='topic+xyplot.resamples'></span><span id='topic+densityplot.resamples'></span><span id='topic+bwplot.resamples'></span><span id='topic+splom.resamples'></span><span id='topic+parallelplot.resamples'></span><span id='topic+dotplot.resamples'></span><span id='topic+ggplot.resamples'></span>

<h3>Description</h3>

<p>Lattice and ggplot functions for visualizing resampling results across models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'resamples'
xyplot(
  x,
  data = NULL,
  what = "scatter",
  models = NULL,
  metric = x$metric[1],
  units = "min",
  ...
)

## S3 method for class 'resamples'
parallelplot(x, data = NULL, models = x$models, metric = x$metric[1], ...)

## S3 method for class 'resamples'
splom(
  x,
  data = NULL,
  variables = "models",
  models = x$models,
  metric = NULL,
  panelRange = NULL,
  ...
)

## S3 method for class 'resamples'
densityplot(x, data = NULL, models = x$models, metric = x$metric, ...)

## S3 method for class 'resamples'
bwplot(x, data = NULL, models = x$models, metric = x$metric, ...)

## S3 method for class 'resamples'
dotplot(
  x,
  data = NULL,
  models = x$models,
  metric = x$metric,
  conf.level = 0.95,
  ...
)

## S3 method for class 'resamples'
ggplot(
  data = NULL,
  mapping = NULL,
  environment = NULL,
  models = data$models,
  metric = data$metric[1],
  conf.level = 0.95,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xyplot.resamples_+3A_x">x</code></td>
<td>
<p>an object generated by <code>resamples</code></p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_data">data</code></td>
<td>
<p>Only used for the <code>ggplot</code> method; an object generated by
<code>resamples</code></p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_what">what</code></td>
<td>
<p>for <code>xyplot</code>, the type of plot. Valid options are:
&quot;scatter&quot; (for a plot of the resampled results between two models),
&quot;BlandAltman&quot; (a Bland-Altman, aka MA plot between two models), &quot;tTime&quot; (for
the total time to run <code>train</code> versus the metric), &quot;mTime&quot; (for the time
to build the final model) or &quot;pTime&quot; (the time to predict samples - see the
<code>timingSamps</code> options in <code><a href="#topic+trainControl">trainControl</a></code>,
<code><a href="#topic+rfeControl">rfeControl</a></code>, or <code><a href="#topic+sbfControl">sbfControl</a></code>)</p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_models">models</code></td>
<td>
<p>a character string for which models to plot. Note:
<code>xyplot</code> requires one or two models whereas the other methods can plot
more than two.</p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_metric">metric</code></td>
<td>
<p>a character string for which metrics to use as conditioning
variables in the plot. <code>splom</code> requires exactly one metric when
<code>variables = "models"</code> and at least two when <code>variables =
"metrics"</code>.</p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_units">units</code></td>
<td>
<p>either &quot;sec&quot;, &quot;min&quot; or &quot;hour&quot;; which <code>what</code> is either
&quot;tTime&quot;, &quot;mTime&quot; or &quot;pTime&quot;, how should the timings be scaled?</p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_...">...</code></td>
<td>
<p>further arguments to pass to either
<code><a href="lattice.html#topic+histogram">histogram</a></code>,
<code><a href="lattice.html#topic+histogram">densityplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>, <code><a href="lattice.html#topic+xyplot">dotplot</a></code>
or <code><a href="lattice.html#topic+splom">splom</a></code></p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_variables">variables</code></td>
<td>
<p>either &quot;models&quot; or &quot;metrics&quot;; which variable should be
treated as the scatter plot variables?</p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_panelrange">panelRange</code></td>
<td>
<p>a common range for the panels. If <code>NULL</code>, the panel
ranges are derived from the values across all the models</p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_conf.level">conf.level</code></td>
<td>
<p>the confidence level for intervals about the mean
(obtained using <code><a href="stats.html#topic+t.test">t.test</a></code>)</p>
</td></tr>
<tr><td><code id="xyplot.resamples_+3A_mapping">mapping</code>, <code id="xyplot.resamples_+3A_environment">environment</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ideas and methods here are based on Hothorn et al. (2005) and Eugster et
al. (2008).
</p>
<p><code>dotplot</code> and <code>ggplot</code> plots the average performance value (with two-sided
confidence limits) for each model and metric.
</p>
<p><code>densityplot</code> and <code>bwplot</code> display univariate visualizations of
the resampling distributions while <code>splom</code> shows the pair-wise
relationships.
</p>


<h3>Value</h3>

<p>a lattice object
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Hothorn et al. The design and analysis of benchmark experiments.
Journal of Computational and Graphical Statistics (2005) vol. 14 (3) pp.
675-699
</p>
<p>Eugster et al. Exploratory and inferential analysis of benchmark
experiments. Ludwigs-Maximilians-Universitat Munchen, Department of
Statistics, Tech. Rep (2008) vol. 30
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resamples">resamples</a></code>, <code><a href="lattice.html#topic+xyplot">dotplot</a></code>,
<code><a href="lattice.html#topic+bwplot">bwplot</a></code>,
<code><a href="lattice.html#topic+histogram">densityplot</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>, <code><a href="lattice.html#topic+splom">splom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#load(url("http://topepo.github.io/caret/exampleModels.RData"))

resamps &lt;- resamples(list(CART = rpartFit,
                          CondInfTree = ctreeFit,
                          MARS = earthFit))

dotplot(resamps,
        scales =list(x = list(relation = "free")),
        between = list(x = 2))

bwplot(resamps,
       metric = "RMSE")

densityplot(resamps,
            auto.key = list(columns = 3),
            pch = "|")

xyplot(resamps,
       models = c("CART", "MARS"),
       metric = "RMSE")

splom(resamps, metric = "RMSE")
splom(resamps, variables = "metrics")

parallelplot(resamps, metric = "RMSE")



## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
