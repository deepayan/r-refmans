<!DOCTYPE html><html lang="en"><head><title>Help for package txshift</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {txshift}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bound_precision'><p>Bound Precision</p></a></li>
<li><a href='#bound_propensity'><p>Bound Generalized Propensity Score</p></a></li>
<li><a href='#confint.txshift'><p>Confidence Intervals for Counterfactual Mean Under Stochastic Intervention</p></a></li>
<li><a href='#eif'><p>Compute the Shift Parameter Estimate and the Efficient Influence Function</p></a></li>
<li><a href='#est_g_cens'><p>Estimate the Censoring Mechanism</p></a></li>
<li><a href='#est_g_exp'><p>Estimate the Exposure Mechanism via Generalized Propensity Score</p></a></li>
<li><a href='#est_Hn'><p>Estimate Auxiliary Covariate of Full Data Efficient Influence Function</p></a></li>
<li><a href='#est_Q'><p>Estimate the Outcome Mechanism</p></a></li>
<li><a href='#est_samp'><p>Estimate Probability of Censoring by Two-Phase Sampling</p></a></li>
<li><a href='#fit_fluctuation'><p>Fit One-Dimensional Fluctuation Model for Updating Initial Estimates</p></a></li>
<li><a href='#ipcw_eif_update'><p>Iterative IPCW Update Procedure of Augmented Efficient Influence Function</p></a></li>
<li><a href='#msm_vimshift'><p>Working marginal structural model for causal effects of an intervention grid</p></a></li>
<li><a href='#onestep_txshift'><p>One-Step Estimate of Counterfactual Mean of Stochastic Shift Intervention</p></a></li>
<li><a href='#plot.txshift_msm'><p>Plot working MSM for causal effects of an intervention grid</p></a></li>
<li><a href='#print.txshift'><p>Print Method for Counterfactual Mean of Stochastic Shift Intervention</p></a></li>
<li><a href='#print.txshift_msm'><p>Print Method for Marginal Structural Models</p></a></li>
<li><a href='#scale_to_original'><p>Transform values from the unit interval back to their original scale</p></a></li>
<li><a href='#scale_to_unit'><p>Transform values by scaling to the unit interval</p></a></li>
<li><a href='#shift_additive'><p>Simple Additive Modified Treatment Policy</p></a></li>
<li><a href='#tmle_txshift'><p>Targeted Minimum Loss Estimate of Counterfactual Mean of Stochastic Shift</p>
Intervention</a></li>
<li><a href='#txshift'><p>Efficient Estimate of Counterfactual Mean of Stochastic Shift Intervention</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Efficient Estimation of the Causal Effects of Stochastic
Interventions</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.8</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nima Hejazi &lt;nh@nimahejazi.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient estimation of the population-level causal effects of
    stochastic interventions on a continuous-valued exposure. Both one-step and
    targeted minimum loss estimators are implemented for the counterfactual mean
    value of an outcome of interest under an additive modified treatment policy,
    a stochastic intervention that may depend on the natural value of the
    exposure. To accommodate settings with outcome-dependent two-phase
    sampling, procedures incorporating inverse probability of censoring
    weighting are provided to facilitate the construction of inefficient and
    efficient one-step and targeted minimum loss estimators.  The causal
    parameter and its estimation were first described by Díaz and van der Laan
    (2013) &lt;<a href="https://doi.org/10.1111%2Fj.1541-0420.2011.01685.x">doi:10.1111/j.1541-0420.2011.01685.x</a>&gt;, while the multiply robust
    estimation procedure and its application to data from two-phase sampling
    designs is detailed in NS Hejazi, MJ van der Laan, HE Janes, PB Gilbert,
    and DC Benkeser (2020) &lt;<a href="https://doi.org/10.1111%2Fbiom.13375">doi:10.1111/biom.13375</a>&gt;. The software package
    implementation is described in NS Hejazi and DC Benkeser (2020)
    &lt;<a href="https://doi.org/10.21105%2Fjoss.02447">doi:10.21105/joss.02447</a>&gt;. Estimation of nuisance parameters may be
    enhanced through the Super Learner ensemble model in 'sl3', available for
    download from GitHub using 'remotes::install_github("tlverse/sl3")'.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, stringr, data.table, assertthat, mvtnorm, hal9001 (&ge;
0.4.1), haldensify (&ge; 0.2.1), lspline, ggplot2, scales,
latex2exp, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown, covr, future, future.apply,
origami (&ge; 1.0.3), ranger, Rsolnp, nnls</td>
</tr>
<tr>
<td>Enhances:</td>
<td>sl3 (&ge; 1.4.3)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/nhejazi/txshift">https://github.com/nhejazi/txshift</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/nhejazi/txshift/issues">https://github.com/nhejazi/txshift/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-09 21:44:37 UTC; nsh</td>
</tr>
<tr>
<td>Author:</td>
<td>Nima Hejazi <a href="https://orcid.org/0000-0002-7127-2789"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre, cph],
  David Benkeser <a href="https://orcid.org/0000-0002-1019-8343"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Iván Díaz <a href="https://orcid.org/0000-0001-9056-2047"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Jeremy Coyle <a href="https://orcid.org/0000-0002-9874-6649"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Mark van der Laan <a href="https://orcid.org/0000-0003-1432-5511"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb, ths]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-09 22:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bound_precision'>Bound Precision</h2><span id='topic+bound_precision'></span>

<h3>Description</h3>

<p>Bound Precision
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bound_precision(vals)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bound_precision_+3A_vals">vals</code></td>
<td>
<p><code>numeric</code> vector of values in the interval [0, 1] to be
bounded within arbitrary machine precision. The most common use of this
functionality is to avoid indeterminate or non-finite values after the
application <code>stats::qlogis</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bound values in the unit interval to machine precision in order to
avoid numerical instability issues in downstream computation.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of the same length as <code>vals</code>, where
the returned values are bounded to machine precision. This is intended to
avoid numerical instability issues.
</p>

<hr>
<h2 id='bound_propensity'>Bound Generalized Propensity Score</h2><span id='topic+bound_propensity'></span>

<h3>Description</h3>

<p>Bound Generalized Propensity Score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bound_propensity(vals)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bound_propensity_+3A_vals">vals</code></td>
<td>
<p><code>numeric</code> vector of propensity score estimate values. Note
that, for this parameter, the propensity score is (conditional) density and
so it ought not be bounded from above.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bound estimated values of the generalized propensity score (a
conditional density) to avoid numerical instability issues arising from
practical violations of the assumption of positivity.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of the same length as <code>vals</code>, where the
returned values are bounded such that the minimum is no lower than 1/n, for
the sample size n.
</p>

<hr>
<h2 id='confint.txshift'>Confidence Intervals for Counterfactual Mean Under Stochastic Intervention</h2><span id='topic+confint.txshift'></span>

<h3>Description</h3>

<p>Confidence Intervals for Counterfactual Mean Under Stochastic Intervention
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'txshift'
confint(object, parm = seq_len(object$psi), level = 0.95, ..., ci_mult = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confint.txshift_+3A_object">object</code></td>
<td>
<p>An object of class <code>txshift</code>, as produced by invoking
the function <code><a href="#topic+txshift">txshift</a></code>, for which a confidence interval is to
be computed.</p>
</td></tr>
<tr><td><code id="confint.txshift_+3A_parm">parm</code></td>
<td>
<p>A <code>numeric</code> vector indicating indices of <code>object$est</code>
for which to return confidence intervals.</p>
</td></tr>
<tr><td><code id="confint.txshift_+3A_level">level</code></td>
<td>
<p>A <code>numeric</code> indicating the level of the confidence
interval to be computed.</p>
</td></tr>
<tr><td><code id="confint.txshift_+3A_...">...</code></td>
<td>
<p>Other arguments. Not currently used.</p>
</td></tr>
<tr><td><code id="confint.txshift_+3A_ci_mult">ci_mult</code></td>
<td>
<p>Pre-computed multipliers for generating confidence intervals.
The default of <code>NULL</code> should generally NOT be changed and is only used
by the internal machinery for creating simultaneous confidence bands.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute confidence intervals for estimates produced by
<code><a href="#topic+txshift">txshift</a></code>.
</p>


<h3>Value</h3>

<p>A named <code>numeric</code> vector containing the parameter estimate from
a <code>txshift</code> object, alongside lower and upper Wald-style confidence
intervals at a specified coverage level.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(429153)
n_obs &lt;- 100
W &lt;- replicate(2, rbinom(n_obs, 1, 0.5))
A &lt;- rnorm(n_obs, mean = 2 * W, sd = 1)
Y &lt;- rbinom(n_obs, 1, plogis(A + W + rnorm(n_obs, mean = 0, sd = 1)))
txout &lt;- txshift(
  W = W, A = A, Y = Y, delta = 0.5,
  estimator = "tmle",
  g_exp_fit_args = list(
    fit_type = "hal", n_bins = 5,
    grid_type = "equal_mass",
    lambda_seq = exp(-1:-9)
  ),
  Q_fit_args = list(
    fit_type = "glm",
    glm_formula = "Y ~ ."
  )
)
confint(txout)
</code></pre>

<hr>
<h2 id='eif'>Compute the Shift Parameter Estimate and the Efficient Influence Function</h2><span id='topic+eif'></span>

<h3>Description</h3>

<p>Compute the Shift Parameter Estimate and the Efficient Influence Function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eif(
  Y,
  Qn,
  Hn,
  estimator = c("tmle", "onestep"),
  fluc_mod_out = NULL,
  C_samp = rep(1, length(Y)),
  ipc_weights = rep(1, length(Y))
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eif_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> vector of the observed outcomes.</p>
</td></tr>
<tr><td><code id="eif_+3A_qn">Qn</code></td>
<td>
<p>An object providing the value of the outcome evaluated after
imposing a shift in the treatment. This object is passed in after being
constructed by a call to the internal function <code>est_Q</code>.</p>
</td></tr>
<tr><td><code id="eif_+3A_hn">Hn</code></td>
<td>
<p>An object providing values of the auxiliary (&quot;clever&quot;) covariate,
constructed from the treatment mechanism and required for targeted minimum
loss-based estimation. This object object should be passed in after being
constructed by a call to the internal function <code>est_Hn</code>.</p>
</td></tr>
<tr><td><code id="eif_+3A_estimator">estimator</code></td>
<td>
<p>The type of estimator to be fit, either <code>"tmle"</code> for
targeted maximum likelihood estimation or <code>"onestep"</code> for a one-step
estimator.</p>
</td></tr>
<tr><td><code id="eif_+3A_fluc_mod_out">fluc_mod_out</code></td>
<td>
<p>An object giving values of the logistic tilting model
for targeted minimum loss estimation. This type of object should be the
output of the internal routines to perform this step of the TML estimation
procedure, as given by <code><a href="#topic+fit_fluctuation">fit_fluctuation</a></code>.</p>
</td></tr>
<tr><td><code id="eif_+3A_c_samp">C_samp</code></td>
<td>
<p>Indicator for missingness due to exclusion from second-phase
sample. Used for compatibility with the IPCW-TML estimation routine.</p>
</td></tr>
<tr><td><code id="eif_+3A_ipc_weights">ipc_weights</code></td>
<td>
<p>A <code>numeric</code> vector that gives inverse probability of
censoring weights for each observation. These are generated by invoking the
routines for estimating the censoring mechanism.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimate the value of the causal parameter alongside statistical
inference for the parameter estimate based on the efficient influence
function of the target parameter, which takes the following form:

</p>


<h3>Value</h3>

<p>A <code>list</code> containing the parameter estimate, estimated variance
based on the efficient influence function (EIF), the estimate of the EIF
incorporating inverse probability of censoring weights, and the estimate of
the EIF without the application of such weights.
</p>

<hr>
<h2 id='est_g_cens'>Estimate the Censoring Mechanism</h2><span id='topic+est_g_cens'></span>

<h3>Description</h3>

<p>Estimate the Censoring Mechanism
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_g_cens(
  C_cens,
  A,
  W,
  samp_weights = rep(1, length(C_cens)),
  fit_type = c("sl", "glm"),
  glm_formula = "C_cens ~ .",
  sl_learners = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="est_g_cens_+3A_c_cens">C_cens</code></td>
<td>
<p>A <code>numeric</code> vector of loss to follow-up indicators.</p>
</td></tr>
<tr><td><code id="est_g_cens_+3A_a">A</code></td>
<td>
<p>A <code>numeric</code> vector of observed exposure values.</p>
</td></tr>
<tr><td><code id="est_g_cens_+3A_w">W</code></td>
<td>
<p>A <code>numeric</code> matrix of observed baseline covariate values.</p>
</td></tr>
<tr><td><code id="est_g_cens_+3A_samp_weights">samp_weights</code></td>
<td>
<p>A <code>numeric</code> vector of observation-level sampling
weights, as produced by the internal procedure to estimate the two-phase
sampling mechanism <code><a href="#topic+est_samp">est_samp</a></code>.</p>
</td></tr>
<tr><td><code id="est_g_cens_+3A_fit_type">fit_type</code></td>
<td>
<p>A <code>character</code> indicating whether to use GLMs or Super
Learner to fit the censoring mechanism. If option &quot;glm&quot; is selected, the
argument <code>glm_formula</code> must NOT be <code>NULL</code>, instead containing a
model formula (as per <code><a href="stats.html#topic+glm">glm</a></code>) as a <code>character</code>. If
the option &quot;sl&quot; is selected, the argument <code>sl_learners</code> must NOT be
<code>NULL</code>; instead, an instantiated <span class="pkg">sl3</span> <code>Lrnr_sl</code> object,
specifying learners and a metalearner for the Super Learner fit, must be
provided. Consult the documentation of <span class="pkg">sl3</span> for details.</p>
</td></tr>
<tr><td><code id="est_g_cens_+3A_glm_formula">glm_formula</code></td>
<td>
<p>A <code>character</code> giving a <code><a href="stats.html#topic+formula">formula</a></code>
for fitting a (generalized) linear model via <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
<tr><td><code id="est_g_cens_+3A_sl_learners">sl_learners</code></td>
<td>
<p>Object containing a set of instantiated learners from the
<span class="pkg">sl3</span>, to be used in fitting an ensemble model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute the censoring mechanism for the observed data, in order to
apply a joint intervention for removing censoring by re-weighting.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of the propensity score for censoring.
</p>

<hr>
<h2 id='est_g_exp'>Estimate the Exposure Mechanism via Generalized Propensity Score</h2><span id='topic+est_g_exp'></span>

<h3>Description</h3>

<p>Estimate the Exposure Mechanism via Generalized Propensity Score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_g_exp(
  A,
  W,
  delta = 0,
  samp_weights = rep(1, length(A)),
  fit_type = c("hal", "sl"),
  sl_learners_density = NULL,
  haldensify_args = list(grid_type = "equal_range", lambda_seq = exp(seq(-1, -13,
    length = 300)))
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="est_g_exp_+3A_a">A</code></td>
<td>
<p>A <code>numeric</code> vector of observed exposure values.</p>
</td></tr>
<tr><td><code id="est_g_exp_+3A_w">W</code></td>
<td>
<p>A <code>numeric</code> matrix of observed baseline covariate values.</p>
</td></tr>
<tr><td><code id="est_g_exp_+3A_delta">delta</code></td>
<td>
<p>A <code>numeric</code> value identifying a shift in the observed
value of the exposure under which observations are to be evaluated.</p>
</td></tr>
<tr><td><code id="est_g_exp_+3A_samp_weights">samp_weights</code></td>
<td>
<p>A <code>numeric</code> vector of observation-level sampling
weights, as produced by the internal procedure to estimate the two-phase
sampling mechanism <code><a href="#topic+est_samp">est_samp</a></code>.</p>
</td></tr>
<tr><td><code id="est_g_exp_+3A_fit_type">fit_type</code></td>
<td>
<p>A <code>character</code> specifying whether to use Super Learner
(from <span class="pkg">sl3</span>) or the Highly Adaptive Lasso (from <span class="pkg">hal9001</span>) to
estimate the conditional exposure density.</p>
</td></tr>
<tr><td><code id="est_g_exp_+3A_sl_learners_density">sl_learners_density</code></td>
<td>
<p>Object containing a set of instantiated learners
from <span class="pkg">sl3</span>, to be used in fitting an ensemble model.</p>
</td></tr>
<tr><td><code id="est_g_exp_+3A_haldensify_args">haldensify_args</code></td>
<td>
<p>A <code>list</code> of argument to be directly passed to
<code><a href="haldensify.html#topic+haldensify">haldensify</a></code> when <code>fit_type</code> is set to
<code>"hal"</code>. Note that this invokes the Highly Adaptive Lasso instead of
Super Learner and is thus only feasible for relatively small data sets.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute the propensity score (exposure mechanism) for the observed
data, including the shift. This gives the propensity score for the observed
data (at the observed A) the counterfactual shifted exposure levels (at
A - delta, A + delta, and A + 2 * delta).
</p>


<h3>Value</h3>

<p>A <code>data.table</code> with four columns, containing estimates of the
generalized propensity score at a downshift (g(A - delta | W)), no shift
(g(A | W)), an upshift (g(A + delta) | W), and an upshift of magnitude two
(g(A + 2 delta) | W).
</p>

<hr>
<h2 id='est_Hn'>Estimate Auxiliary Covariate of Full Data Efficient Influence Function</h2><span id='topic+est_Hn'></span>

<h3>Description</h3>

<p>Estimate Auxiliary Covariate of Full Data Efficient Influence Function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_Hn(gn_exp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="est_Hn_+3A_gn_exp">gn_exp</code></td>
<td>
<p>An estimate of the exposure density (a generalized propensity
score) using the output provided by <code><a href="#topic+est_g_exp">est_g_exp</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute an estimate of the auxiliary covariate of the efficient
influence function required to update initial estimates through logistic
tilting models for targeted minimum loss estimation.
</p>


<h3>Value</h3>

<p>A <code>data.table</code> with two columns, containing estimates of the
auxiliary covariate at the natural value of the exposure H(A, W) and at the
shifted value of the exposure H(A + delta, W).
</p>

<hr>
<h2 id='est_Q'>Estimate the Outcome Mechanism</h2><span id='topic+est_Q'></span>

<h3>Description</h3>

<p>Estimate the Outcome Mechanism
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_Q(
  Y,
  C_cens = rep(1, length(Y)),
  A,
  W,
  delta = 0,
  samp_weights = rep(1, length(Y)),
  fit_type = c("sl", "glm"),
  glm_formula = "Y ~ .",
  sl_learners = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="est_Q_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> vector of observed outcomes.</p>
</td></tr>
<tr><td><code id="est_Q_+3A_c_cens">C_cens</code></td>
<td>
<p>A <code>numeric</code> vector of loss to follow-up indicators.</p>
</td></tr>
<tr><td><code id="est_Q_+3A_a">A</code></td>
<td>
<p>A <code>numeric</code> vector of observed exposure values.</p>
</td></tr>
<tr><td><code id="est_Q_+3A_w">W</code></td>
<td>
<p>A <code>numeric</code> matrix of observed baseline covariate values.</p>
</td></tr>
<tr><td><code id="est_Q_+3A_delta">delta</code></td>
<td>
<p>A <code>numeric</code> indicating the magnitude of the shift to be
computed for the exposure <code>A</code>. This is passed to the internal
<code><a href="#topic+shift_additive">shift_additive</a></code> and is currently limited to additive shifts.</p>
</td></tr>
<tr><td><code id="est_Q_+3A_samp_weights">samp_weights</code></td>
<td>
<p>A <code>numeric</code> vector of observation-level sampling
weights, as produced by the internal procedure to estimate the two-phase
sampling mechanism <code><a href="#topic+est_samp">est_samp</a></code>.</p>
</td></tr>
<tr><td><code id="est_Q_+3A_fit_type">fit_type</code></td>
<td>
<p>A <code>character</code> indicating whether to use GLMs or Super
Learner to fit the outcome regression. If the option &quot;glm&quot; is selected, the
argument <code>glm_formula</code> must NOT be <code>NULL</code>, instead containing a
model formula (as per <code><a href="stats.html#topic+glm">glm</a></code>) as a <code>character</code>. If
the option &quot;sl&quot; is selected, the argument <code>sl_learners</code> must NOT be
<code>NULL</code>; instead, an instantiated <span class="pkg">sl3</span> <code>Lrnr_sl</code> object,
specifying learners and a metalearner for the Super Learner fit, must be
provided. Consult the documentation of <span class="pkg">sl3</span> for details.</p>
</td></tr>
<tr><td><code id="est_Q_+3A_glm_formula">glm_formula</code></td>
<td>
<p>A <code>character</code> giving a <code><a href="stats.html#topic+formula">formula</a></code>
for fitting a (generalized) linear model via <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
<tr><td><code id="est_Q_+3A_sl_learners">sl_learners</code></td>
<td>
<p>Object containing a set of instantiated learners from the
<span class="pkg">sl3</span>, to be used in fitting an ensemble model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute the outcome regression for the observed data, including
with the shift imposed by the intervention. This returns the outcome
regression for the observed data (at A) and under the counterfactual shift
shift (at A + delta).
</p>


<h3>Value</h3>

<p>A <code>data.table</code> with two columns, containing estimates of the
outcome mechanism at the natural value of the exposure Q(A, W) and an
upshift of the exposure Q(A + delta, W).
</p>

<hr>
<h2 id='est_samp'>Estimate Probability of Censoring by Two-Phase Sampling</h2><span id='topic+est_samp'></span>

<h3>Description</h3>

<p>Estimate Probability of Censoring by Two-Phase Sampling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_samp(V, C_samp, fit_type = c("sl", "glm"), sl_learners = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="est_samp_+3A_v">V</code></td>
<td>
<p>A <code>numeric</code> vector, <code>matrix</code>, <code>data.frame</code> or
similar object giving the observed values of the covariates known to
potentially inform the sampling mechanism.</p>
</td></tr>
<tr><td><code id="est_samp_+3A_c_samp">C_samp</code></td>
<td>
<p>A <code>numeric</code> vector of observed values of the indicator
for inclusion in the second-phase sample.</p>
</td></tr>
<tr><td><code id="est_samp_+3A_fit_type">fit_type</code></td>
<td>
<p>A <code>character</code> indicating whether to perform the fit
using GLMs or a Super Learner ensemble model. If use of Super Learner is
desired, then the argument <code>sl_learners</code> must be provided.</p>
</td></tr>
<tr><td><code id="est_samp_+3A_sl_learners">sl_learners</code></td>
<td>
<p>An <span class="pkg">sl3</span> <code>Lrnr_sl</code> object, a Super Learner
ensemble or learner instantiated externally using <span class="pkg">sl3</span>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute estimates of the sampling probability for inclusion in the
the second-phase via the two-phase sampling mechanism. These estimates are
used for the creation of inverse probability weights.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of the estimated sampling mechanism.
</p>

<hr>
<h2 id='fit_fluctuation'>Fit One-Dimensional Fluctuation Model for Updating Initial Estimates</h2><span id='topic+fit_fluctuation'></span>

<h3>Description</h3>

<p>Fit One-Dimensional Fluctuation Model for Updating Initial Estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_fluctuation(
  Y,
  Qn_scaled,
  Hn,
  ipc_weights = rep(1, length(Y)),
  method = c("standard", "weighted"),
  flucmod_tol = 50
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_fluctuation_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> vector corresponding to an outcome variable.</p>
</td></tr>
<tr><td><code id="fit_fluctuation_+3A_qn_scaled">Qn_scaled</code></td>
<td>
<p>An object providing the value of the outcome evaluate
after inducing a shift in the exposure. This object should be passed in
after being constructed by a call to <code><a href="#topic+est_Q">est_Q</a></code>.</p>
</td></tr>
<tr><td><code id="fit_fluctuation_+3A_hn">Hn</code></td>
<td>
<p>An object providing values of the auxiliary (&quot;clever&quot;) covariate,
constructed from the treatment mechanism and required for targeted minimum
loss estimation. This object object should be passed in after being
constructed by a call to <code><a href="#topic+est_Hn">est_Hn</a></code>.</p>
</td></tr>
<tr><td><code id="fit_fluctuation_+3A_ipc_weights">ipc_weights</code></td>
<td>
<p>A <code>numeric</code> vector that gives inverse probability of
censoring weights for each observation. These are generated by invoking the
routines for estimating the censoring mechanism.</p>
</td></tr>
<tr><td><code id="fit_fluctuation_+3A_method">method</code></td>
<td>
<p>A <code>character</code> giving the type of regression to be used in
traversing the fluctuation sub-model. The available choices are &quot;weighted&quot;
and &quot;standard&quot;. Consult the literature for details on the differences.</p>
</td></tr>
<tr><td><code id="fit_fluctuation_+3A_flucmod_tol">flucmod_tol</code></td>
<td>
<p>A <code>numeric</code> indicating the largest value to be
tolerated in the fluctuation model for the targeted minimum loss estimator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Procedure for fitting a one-dimensional fluctuation model to update
the initial estimates of the outcome regression based on the auxiliary
covariate. These updated estimates are subsequently used to construct the
TML estimator of the counterfactual mean under a modified treatment policy.
</p>


<h3>Value</h3>

<p>A <code>list</code> containing the fluctuation model (a <code>glm</code> object)
produced by logistic regression, a <code>character</code> vector indicating the
type of fluctuation (whether the auxiliary covariates was used as a weight
or included directly in the model formula), the updated estimates of the
outcome regression under the shifted value of the exposure, and the updated
estimates of the outcome regression under the natural value of exposure.
</p>

<hr>
<h2 id='ipcw_eif_update'>Iterative IPCW Update Procedure of Augmented Efficient Influence Function</h2><span id='topic+ipcw_eif_update'></span>

<h3>Description</h3>

<p>Iterative IPCW Update Procedure of Augmented Efficient Influence Function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipcw_eif_update(
  data_internal,
  C_samp,
  V,
  ipc_mech,
  ipc_weights,
  Qn_estim,
  Hn_estim,
  estimator = c("tmle", "onestep"),
  fluctuation = NULL,
  flucmod_tol = 50,
  eif_reg_type = c("hal", "glm")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ipcw_eif_update_+3A_data_internal">data_internal</code></td>
<td>
<p>A <code>data.table</code> containing of the observations
selected into the second-phase sample.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_c_samp">C_samp</code></td>
<td>
<p>A <code>numeric</code> indicator for missingness due to exclusion
the from second-stage sample.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_v">V</code></td>
<td>
<p>A <code>data.table</code> giving the values across all observations of
all variables that play a role in the censoring mechanism.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_ipc_mech">ipc_mech</code></td>
<td>
<p>A <code>numeric</code> vector of the censoring mechanism estimates
all of the observations, only for the two-phase sampling mechanism. Note
well that these values do NOT account for censoring from loss to follow-up.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_ipc_weights">ipc_weights</code></td>
<td>
<p>A <code>numeric</code> vector of inverse probability of
censoring weights, including such weights for censoring due to loss to
follow-up. Without loss to follow-up, these are equivalent to <code>C_samp
/ ipc_mech</code> in an initial run of this procedure.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_qn_estim">Qn_estim</code></td>
<td>
<p>A <code>data.table</code> corresponding to the outcome regression.
This is produced by invoking the internal function <code>est_Q</code>.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_hn_estim">Hn_estim</code></td>
<td>
<p>A <code>data.table</code> corresponding to values produced in the
computation of the auxiliary (&quot;clever&quot;) covariate. This is produced easily
by invoking the internal function <code>est_Hn</code>.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_estimator">estimator</code></td>
<td>
<p>The type of estimator to be fit, either <code>"tmle"</code> for
targeted maximum likelihood estimation or <code>"onestep"</code> for a one-step
estimator.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_fluctuation">fluctuation</code></td>
<td>
<p>A <code>character</code> giving the type of regression to be
used in traversing the fluctuation submodel. The choices are &quot;weighted&quot; and
&quot;standard&quot;.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_flucmod_tol">flucmod_tol</code></td>
<td>
<p>A <code>numeric</code> indicating the largest value to be
tolerated in the fluctuation model for the targeted minimum loss estimator.</p>
</td></tr>
<tr><td><code id="ipcw_eif_update_+3A_eif_reg_type">eif_reg_type</code></td>
<td>
<p>Whether a flexible nonparametric function ought to be
used in the dimension-reduced nuisance regression of the targeting step for
the censored data case. By default, the method used is a nonparametric
regression based on the Highly Adaptive Lasso (from <span class="pkg">hal9001</span>). Set
this to <code>"glm"</code> to instead use a simple linear regression model. In
this step, the efficient influence function (EIF) is regressed against
covariates contributing to the censoring mechanism (i.e., EIF ~ V | C = 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An adaptation of the IPCW-TMLE for iteratively constructing an
efficient inverse probability of censoring weighted TML or one-step
estimator. The efficient influence function of the parameter and updating
the IPC weights in an iterative process, until a convergence criteria is
satisfied.
</p>


<h3>Value</h3>

<p>A <code>list</code> containing the estimated outcome mechanism, the fitted
fluctuation model for TML updates, the updated inverse probability of
censoring weights (IPCW), the updated estimate of the efficient influence
function, and the estimated IPCW component of the EIF.
</p>

<hr>
<h2 id='msm_vimshift'>Working marginal structural model for causal effects of an intervention grid</h2><span id='topic+msm_vimshift'></span>

<h3>Description</h3>

<p>Working marginal structural model for causal effects of an intervention grid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msm_vimshift(
  W,
  A,
  C_cens = rep(1, length(Y)),
  Y,
  C_samp = rep(1, length(Y)),
  V = NULL,
  delta_grid = seq(-0.5, 0.5, 0.5),
  msm_form = list(type = "linear", knot = NA),
  estimator = c("tmle", "onestep"),
  weighting = c("identity", "variance"),
  ci_level = 0.95,
  ci_type = c("marginal", "simultaneous"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="msm_vimshift_+3A_w">W</code></td>
<td>
<p>A <code>matrix</code>, <code>data.frame</code>, or similar containing a set of
baseline covariates.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_a">A</code></td>
<td>
<p>A <code>numeric</code> vector corresponding to a treatment variable. The
parameter of interest is defined as a location shift of this quantity.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_c_cens">C_cens</code></td>
<td>
<p>A <code>numeric</code> indicator for whether a given observation was
subject to censoring by way of loss to follow-up. The default assumes no
censoring due to loss to follow-up.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> vector of the observed outcomes.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_c_samp">C_samp</code></td>
<td>
<p>A <code>numeric</code> indicator for whether a given observation was
subject to censoring by being omitted from the second-stage sample, used to
compute an inverse probability of censoring weighted estimator in such
cases. The default assumes no censoring due to two-phase sampling.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_v">V</code></td>
<td>
<p>The covariates that are used in determining the sampling procedure
that gives rise to censoring. The default is <code>NULL</code> and corresponds to
scenarios in which there is no censoring (in which case all values in the
preceding argument <code>C</code> must be uniquely 1. To specify this, pass in a
NAMED <code>list</code> identifying variables amongst W, A, Y that are thought to
have played a role in defining the sampling/censoring mechanism (C).</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_delta_grid">delta_grid</code></td>
<td>
<p>A <code>numeric</code> vector giving the individual values of
the shift parameter used in computing each of the estimates.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_msm_form">msm_form</code></td>
<td>
<p>A <code>list</code> specifying the type of working MSM to fit to
summarize the counterfactual means. The <code>list</code> has two components:
(1) <code>"type"</code>, which may be either &quot;linear&quot; or &quot;piecewise&quot;, and (2)
<code>"knot"</code>, which, if specified, must be a value in <code>delta_grid</code>.
See examples for its use.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_estimator">estimator</code></td>
<td>
<p>The type of estimator to be fit, either <code>"tmle"</code> for
targeted maximum likelihood estimation or <code>"onestep"</code> for a one-step
augmented inverse probability weighted (AIPW) estimator.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_weighting">weighting</code></td>
<td>
<p>Whether to weight each parameter estimate by the inverse of
its variance (in order to improve stability of the resultant MSM fit) or to
simply weight all parameter estimates equally. The default is the option
<code>"identity"</code>, weighting all estimates identically.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_ci_level">ci_level</code></td>
<td>
<p>A <code>numeric</code> indicating the desired coverage level of
the confidence interval to be computed.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_ci_type">ci_type</code></td>
<td>
<p>Whether to construct a simultaneous confidence band covering
all parameter estimates at once or marginal confidence intervals covering
each parameter estimate separately. The default is to construct marginal
confidence intervals for each parameter estimate rather than a simultaneous
confidence band.</p>
</td></tr>
<tr><td><code id="msm_vimshift_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code><a href="#topic+txshift">txshift</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes estimates of the counterfactual mean over a grid of shift
stochastic interventions and fits a working marginal structural model to
summarize the trend through the counterfactual means as a function of the
specified shift intervention. The working marginal structural model may be
linear in the shift parameter or piecewise linear with a single knot point.
Provides support for two weighting schemes, may be used with either of the
one-step or TML estimators, and also allows the construction of marginal or
simultaneous confidence intervals.
</p>


<h3>Value</h3>

<p>A <code>list</code> containing estimates of the individual counterfactual
means over a grid in the shift parameters (<code>delta_grid</code>), alongside
the estimate of a marginal structural model that summarizes a trend through
these counterfactual means.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("sl3")) {
  n_obs &lt;- 100
  W &lt;- as.numeric(replicate(1, rbinom(n_obs, 1, 0.5)))
  A &lt;- as.numeric(rnorm(n_obs, mean = 2 * W, sd = 1))
  Y &lt;- rbinom(n_obs, 1, plogis(2 * A - W))
  msm &lt;- msm_vimshift(
    W = W, A = A, Y = Y, estimator = "tmle",
    g_exp_fit_args = list(
      fit_type = "sl",
      sl_learners_density = Lrnr_density_hse$new(Lrnr_glm$new())
    ),
    Q_fit_args = list(
      fit_type = "glm",
      glm_formula = "Y ~ ."
    ),
    delta_grid = seq(-1, 1, 0.25)
  )

  # fit a linear spline with knot at 0
  n_obs &lt;- 100
  W &lt;- as.numeric(replicate(1, rbinom(n_obs, 1, 0.5)))
  A &lt;- as.numeric(rnorm(n_obs, mean = 2 * W, sd = 1))
  Y &lt;- rbinom(n_obs, 1, plogis(0.1 * A * (A &gt;= 0) - 3 * A * (A &lt; 0) - W))
  msm &lt;- msm_vimshift(
    W = W, A = A, Y = Y, estimator = "tmle",
    g_exp_fit_args = list(
      fit_type = "sl",
      sl_learners_density = Lrnr_density_hse$new(Lrnr_glm$new())
    ),
    Q_fit_args = list(
      fit_type = "glm",
      glm_formula = "Y ~ ."
    ),
    delta_grid = seq(-1, 1, 0.25),
    msm_form = list(type = "piecewise", knot = 0)
  )
}
</code></pre>

<hr>
<h2 id='onestep_txshift'>One-Step Estimate of Counterfactual Mean of Stochastic Shift Intervention</h2><span id='topic+onestep_txshift'></span>

<h3>Description</h3>

<p>One-Step Estimate of Counterfactual Mean of Stochastic Shift Intervention
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onestep_txshift(
  data_internal,
  C_samp = rep(1, nrow(data_internal)),
  V = NULL,
  delta,
  samp_estim,
  gn_cens_weights,
  Qn_estim,
  Hn_estim,
  eif_reg_type = c("hal", "glm"),
  samp_fit_args,
  ipcw_efficiency = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="onestep_txshift_+3A_data_internal">data_internal</code></td>
<td>
<p>A <code>data.table</code> constructed internally by a call to
<code><a href="#topic+txshift">txshift</a></code>. This contains the data elements needed for computing
the one-step estimator.</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_c_samp">C_samp</code></td>
<td>
<p>A <code>numeric</code> indicator for whether a given observation was
included in the second-stage sample, used to compute an IPC-weighted
one-step estimator in cases where two-stage sampling is performed. Default
assumes no censoring due to sampling.</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_v">V</code></td>
<td>
<p>The covariates that are used in determining the sampling procedure
that gives rise to censoring. The default is <code>NULL</code> and corresponds to
scenarios in which there is no censoring (in which case all values in the
preceding argument <code>C</code> must be uniquely 1. To specify this, pass in a
NAMED <code>list</code> identifying variables amongst W, A, Y that are thought to
have played a role in defining the sampling/censoring mechanism (C).</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_delta">delta</code></td>
<td>
<p>A <code>numeric</code> value indicating the shift in the treatment to
be used in defining the target parameter. This is defined with respect to
the scale of the treatment (A).</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_samp_estim">samp_estim</code></td>
<td>
<p>An object providing the value of the censoring mechanism
evaluated across the full data. This object is passed in after being
constructed by a call to the internal function <code><a href="#topic+est_samp">est_samp</a></code>.</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_gn_cens_weights">gn_cens_weights</code></td>
<td>
<p>TODO: document</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_qn_estim">Qn_estim</code></td>
<td>
<p>An object providing the value of the outcome evaluated after
imposing a shift in the treatment. This object is passed in after being
constructed by a call to the internal function <code>est_Q</code>.</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_hn_estim">Hn_estim</code></td>
<td>
<p>An object providing values of the auxiliary (&quot;clever&quot;)
covariate, constructed from the treatment mechanism and required for
targeted minimum loss estimation. This object object should be passed in
after being constructed by a call to the internal function <code>est_Hn</code>.</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_eif_reg_type">eif_reg_type</code></td>
<td>
<p>Whether a flexible nonparametric function ought to be
used in the dimension-reduced nuisance regression of the targeting step for
the censored data case. By default, the method used is a nonparametric
regression based on the Highly Adaptive Lasso (from <span class="pkg">hal9001</span>). Set
this to <code>"glm"</code> to instead use a simple linear regression model.
In this step, the efficient influence function (EIF) is regressed against
covariates contributing to the censoring mechanism (i.e., EIF ~ V | C = 1).</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_samp_fit_args">samp_fit_args</code></td>
<td>
<p>A <code>list</code> of arguments, all but one of which are
passed to <code><a href="#topic+est_samp">est_samp</a></code>. For details, consult the documentation
for <code><a href="#topic+est_samp">est_samp</a></code>. The first element (i.e., <code>fit_type</code>) is
used to determine how this regression is fit: &quot;glm&quot; for generalized linear
model, &quot;sl&quot; for a Super Learner, and &quot;external&quot; for a user-specified input
of the form produced by <code><a href="#topic+est_samp">est_samp</a></code>.</p>
</td></tr>
<tr><td><code id="onestep_txshift_+3A_ipcw_efficiency">ipcw_efficiency</code></td>
<td>
<p>Whether to invoke an augmentation of the IPCW-TMLE
procedure that performs an iterative process to ensure efficiency of the
resulting estimate. The default is <code>TRUE</code>; set to <code>FALSE</code> to use
an IPC-weighted loss rather than the IPC-augmented influence function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Invokes the procedure to construct a one-step estimate of the
counterfactual mean under a modified treatment policy.
</p>


<h3>Value</h3>

<p>S3 object of class <code>txshift</code> containing the results of the
procedure to compute a one-step estimate of the treatment shift parameter.
</p>

<hr>
<h2 id='plot.txshift_msm'>Plot working MSM for causal effects of an intervention grid</h2><span id='topic+plot.txshift_msm'></span>

<h3>Description</h3>

<p>Plot working MSM for causal effects of an intervention grid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'txshift_msm'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.txshift_msm_+3A_x">x</code></td>
<td>
<p>Object of class <code>txshift_msm</code> as produced by a call to
<code><a href="#topic+msm_vimshift">msm_vimshift</a></code>.</p>
</td></tr>
<tr><td><code id="plot.txshift_msm_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>plot</code> as necessary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a visualization of the intervention-specific counterfactual
means as well as the working marginal structural model summarizing the
trend across posited values of the intervention.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("sl3")) {
  set.seed(3287)
  n_obs &lt;- 1000
  W &lt;- as.numeric(replicate(1, rbinom(n_obs, 1, 0.5)))
  A &lt;- as.numeric(rnorm(n_obs, mean = 2 * W, sd = 1))
  Y &lt;- rbinom(n_obs, 1, plogis(2 * A - W))
  msm &lt;- msm_vimshift(
    W = W, A = A, Y = Y, estimator = "tmle",
    g_exp_fit_args = list(
      fit_type = "sl",
      sl_learners_density = Lrnr_density_hse$new(Lrnr_glm$new())
    ),
    Q_fit_args = list(
      fit_type = "glm",
      glm_formula = "Y ~ ."
    ),
    delta_grid = seq(-1, 1, 0.25)
  )
  plot(msm)

  # fit a linear spline with knot at 0
  set.seed(8293)
  n_obs &lt;- 1000
  W &lt;- as.numeric(replicate(1, rbinom(n_obs, 1, 0.5)))
  A &lt;- as.numeric(rnorm(n_obs, mean = 2 * W, sd = 1))
  Y &lt;- rbinom(n_obs, 1, plogis(0.1 * A * (A &gt;= 0) - 3 * A * (A &lt; 0) - W))
  msm &lt;- msm_vimshift(
    W = W, A = A, Y = Y, estimator = "tmle",
    g_exp_fit_args = list(
      fit_type = "sl",
      sl_learners_density = Lrnr_density_hse$new(Lrnr_glm$new())
    ),
    Q_fit_args = list(
      fit_type = "glm",
      glm_formula = "Y ~ ."
    ),
    delta_grid = seq(-1, 1, 0.25),
    msm_form = list(type = "piecewise", knot = 0)
  )
  plot(msm)
}
</code></pre>

<hr>
<h2 id='print.txshift'>Print Method for Counterfactual Mean of Stochastic Shift Intervention</h2><span id='topic+print.txshift'></span>

<h3>Description</h3>

<p>Print Method for Counterfactual Mean of Stochastic Shift Intervention
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'txshift'
print(x, ..., ci_level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.txshift_+3A_x">x</code></td>
<td>
<p>An object of class <code>txshift</code>.</p>
</td></tr>
<tr><td><code id="print.txshift_+3A_...">...</code></td>
<td>
<p>Other options (not currently used).</p>
</td></tr>
<tr><td><code id="print.txshift_+3A_ci_level">ci_level</code></td>
<td>
<p>A <code>numeric</code> indicating the level of the confidence
interval to be computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> method for objects of class <code>txshift</code>.
</p>


<h3>Value</h3>

<p>None. Called for the side effect of printing an informative summary
of slots of objects of class <code>txshift</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("sl3")) {
  set.seed(429153)
  n_obs &lt;- 100
  W &lt;- replicate(2, rbinom(n_obs, 1, 0.5))
  A &lt;- rnorm(n_obs, mean = 2 * W, sd = 1)
  Y &lt;- rbinom(n_obs, 1, plogis(A + W + rnorm(n_obs, mean = 0, sd = 1)))
  txout &lt;- txshift(
    W = W, A = A, Y = Y, delta = 0.5,
    estimator = "tmle",
    g_exp_fit_args = list(
      fit_type = "sl",
      sl_learners_density = Lrnr_density_hse$new(Lrnr_glm$new())
    ),
    Q_fit_args = list(
      fit_type = "glm",
      glm_formula = "Y ~ ."
    )
  )
  print(txout)
}
</code></pre>

<hr>
<h2 id='print.txshift_msm'>Print Method for Marginal Structural Models</h2><span id='topic+print.txshift_msm'></span>

<h3>Description</h3>

<p>Print Method for Marginal Structural Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'txshift_msm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.txshift_msm_+3A_x">x</code></td>
<td>
<p>An object of class <code>txshift_msm</code>.</p>
</td></tr>
<tr><td><code id="print.txshift_msm_+3A_...">...</code></td>
<td>
<p>Other options (not currently used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> method for objects of class <code>txshift_msm</code>.
</p>


<h3>Value</h3>

<p>None. Called for the side effect of printing an informative summary
of slots of objects of class <code>txshift_msm</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("sl3")) {
  set.seed(3287)
  n_obs &lt;- 1000
  W &lt;- as.numeric(replicate(1, rbinom(n_obs, 1, 0.5)))
  A &lt;- as.numeric(rnorm(n_obs, mean = 2 * W, sd = 1))
  Y &lt;- rbinom(n_obs, 1, plogis(2 * A - W))
  msm &lt;- msm_vimshift(
    W = W, A = A, Y = Y, estimator = "tmle",
    g_exp_fit_args = list(
      fit_type = "sl",
      sl_learners_density = Lrnr_density_hse$new(Lrnr_glm$new())
    ),
    Q_fit_args = list(
      fit_type = "glm",
      glm_formula = "Y ~ ."
    ),
    delta_grid = seq(-1, 1, 0.25)
  )
  print(msm)
}
</code></pre>

<hr>
<h2 id='scale_to_original'>Transform values from the unit interval back to their original scale</h2><span id='topic+scale_to_original'></span>

<h3>Description</h3>

<p>Transform values from the unit interval back to their original scale
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scale_to_original(scaled_vals, max_orig, min_orig)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scale_to_original_+3A_scaled_vals">scaled_vals</code></td>
<td>
<p>A <code>numeric</code> vector corresponding to re-scaled values
in the unit interval, to be re-scaled to the original interval.</p>
</td></tr>
<tr><td><code id="scale_to_original_+3A_max_orig">max_orig</code></td>
<td>
<p>A <code>numeric</code> scalar value giving the maximum of the
values on the original scale.</p>
</td></tr>
<tr><td><code id="scale_to_original_+3A_min_orig">min_orig</code></td>
<td>
<p>A <code>numeric</code> scalar value giving the minimum of the
values on the original scale.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A back-transformation that returns values computed in the unit
interval to their original scale. This is used in re-scaling updated TML
estimates back to their natural scale. Undoes <code><a href="#topic+scale_to_unit">scale_to_unit</a></code>.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of the same length as <code>scaled_vals</code>,
where the values are re-scaled to lie in their original/natural interval.
</p>

<hr>
<h2 id='scale_to_unit'>Transform values by scaling to the unit interval</h2><span id='topic+scale_to_unit'></span>

<h3>Description</h3>

<p>Transform values by scaling to the unit interval
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scale_to_unit(vals)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scale_to_unit_+3A_vals">vals</code></td>
<td>
<p>A <code>numeric</code> vector corresponding to the observed values of
the variable of interest, to be re-scaled to the unit interval [0,1].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A transformation that scales an arbitrary set of input values to
the unit interval. See <code><a href="#topic+scale_to_original">scale_to_original</a></code> for a corresponding
backtransformation.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of the same length as <code>vals</code>, where the
values are re-scaled to lie in unit interval [0, 1].
</p>

<hr>
<h2 id='shift_additive'>Simple Additive Modified Treatment Policy</h2><span id='topic+shift_additive'></span>

<h3>Description</h3>

<p>Simple Additive Modified Treatment Policy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shift_additive(A, W = NULL, delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shift_additive_+3A_a">A</code></td>
<td>
<p>A <code>numeric</code> vector of observed treatment values.</p>
</td></tr>
<tr><td><code id="shift_additive_+3A_w">W</code></td>
<td>
<p>A <code>numeric</code> matrix of observed baseline covariate values.</p>
</td></tr>
<tr><td><code id="shift_additive_+3A_delta">delta</code></td>
<td>
<p>A <code>numeric</code> indicating the magnitude of the shift to be
computed for the treatment <code>A</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple modified treatment policy that modifes the observed value
of the exposure by shifting it by a value <code>delta</code>. Note that this
shifting function assumes support of A|W across all strata of W.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector containing the shifted exposure values.
</p>

<hr>
<h2 id='tmle_txshift'>Targeted Minimum Loss Estimate of Counterfactual Mean of Stochastic Shift
Intervention</h2><span id='topic+tmle_txshift'></span>

<h3>Description</h3>

<p>Targeted Minimum Loss Estimate of Counterfactual Mean of Stochastic Shift
Intervention
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tmle_txshift(
  data_internal,
  C_samp = rep(1, nrow(data_internal)),
  V = NULL,
  delta,
  samp_estim,
  gn_cens_weights,
  Qn_estim,
  Hn_estim,
  fluctuation = c("standard", "weighted"),
  max_iter = 10,
  eif_reg_type = c("hal", "glm"),
  samp_fit_args,
  ipcw_efficiency = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tmle_txshift_+3A_data_internal">data_internal</code></td>
<td>
<p>A <code>data.table</code> constructed internally by a call to
<code><a href="#topic+txshift">txshift</a></code>. This contains most of the data for computing the
targeted minimum loss (TML) estimator.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_c_samp">C_samp</code></td>
<td>
<p>A <code>numeric</code> indicator for whether a given observation was
included in the second-stage sample, used to compute an IPC-weighted
one-step estimator in cases where two-stage sampling is performed. Default
assumes no censoring due to sampling.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_v">V</code></td>
<td>
<p>The covariates that are used in determining the sampling procedure
that gives rise to censoring. The default is <code>NULL</code> and corresponds to
scenarios in which there is no censoring (in which case all values in the
preceding argument <code>C_samp</code> must be 1. To specify this, pass in a
NAMED <code>list</code> identifying variables amongst W, A, Y that are thought to
have played a role in defining the sampling mechanism.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_delta">delta</code></td>
<td>
<p>A <code>numeric</code> value indicating the shift in the treatment to
be used in defining the target parameter. This is defined with respect to
the scale of the treatment (A).</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_samp_estim">samp_estim</code></td>
<td>
<p>An object providing the value of the sampling mechanism
evaluated across the full data. This object is passed in after being
constructed by a call to the internal function <code><a href="#topic+est_samp">est_samp</a></code>.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_gn_cens_weights">gn_cens_weights</code></td>
<td>
<p>TODO: document</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_qn_estim">Qn_estim</code></td>
<td>
<p>An object providing the value of the outcome evaluated after
imposing a shift in the treatment. This object is passed in after being
constructed by a call to the internal function <code><a href="#topic+est_Q">est_Q</a></code>.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_hn_estim">Hn_estim</code></td>
<td>
<p>An object providing values of the auxiliary (&quot;clever&quot;)
covariate, constructed from the treatment mechanism and required for
targeted minimum loss-based estimation. This object object should be passed
in after being constructed by a call to <code><a href="#topic+est_Hn">est_Hn</a></code>.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_fluctuation">fluctuation</code></td>
<td>
<p>The method to be used in the submodel fluctuation step
(targeting step) to compute the TML estimator. The choices are &quot;standard&quot;
and &quot;weighted&quot; for where to place the auxiliary covariate in the logistic
tilting regression.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_max_iter">max_iter</code></td>
<td>
<p>A <code>numeric</code> integer giving the maximum number of steps
to be taken in iterating to a solution of the efficient influence function.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_eif_reg_type">eif_reg_type</code></td>
<td>
<p>Whether a flexible nonparametric function ought to be
used in the dimension-reduced nuisance regression of the targeting step for
the censored data case. By default, the method used is a nonparametric
regression based on the Highly Adaptive Lasso (from <span class="pkg">hal9001</span>).
Set this to <code>"glm"</code> to instead use a simple linear regression model.
In this step, the efficient influence function (EIF) is regressed against
covariates contributing to the censoring mechanism (i.e., EIF ~ V | C = 1).</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_samp_fit_args">samp_fit_args</code></td>
<td>
<p>A <code>list</code> of arguments, all but one of which are
passed to <code><a href="#topic+est_samp">est_samp</a></code>. For details, consult the documentation
for <code><a href="#topic+est_samp">est_samp</a></code>. The first element (i.e., <code>fit_type</code>) is
used to determine how this regression is fit: &quot;glm&quot; for generalized linear
model, &quot;sl&quot; for a Super Learner, and &quot;external&quot; for a user-specified input
of the form produced by <code><a href="#topic+est_samp">est_samp</a></code>.</p>
</td></tr>
<tr><td><code id="tmle_txshift_+3A_ipcw_efficiency">ipcw_efficiency</code></td>
<td>
<p>Whether to invoke an augmentation of the IPCW-TMLE
procedure that performs an iterative process to ensure efficiency of the
resulting estimate. The default is <code>TRUE</code>; set to <code>FALSE</code> to use
an IPC-weighted loss rather than the IPC-augmented influence function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Invokes the procedure to construct a targeted minimum loss estimate
(TMLE) of the counterfactual mean under a modified treatment policy.
</p>


<h3>Value</h3>

<p>S3 object of class <code>txshift</code> containing the results of the
procedure to compute a TML estimate of the treatment shift parameter.
</p>

<hr>
<h2 id='txshift'>Efficient Estimate of Counterfactual Mean of Stochastic Shift Intervention</h2><span id='topic+txshift'></span>

<h3>Description</h3>

<p>Efficient Estimate of Counterfactual Mean of Stochastic Shift Intervention
</p>


<h3>Usage</h3>

<pre><code class='language-R'>txshift(
  W,
  A,
  C_cens = rep(1, length(A)),
  Y,
  C_samp = rep(1, length(Y)),
  V = NULL,
  delta = 0,
  estimator = c("tmle", "onestep"),
  fluctuation = c("standard", "weighted"),
  max_iter = 10,
  samp_fit_args = list(fit_type = c("glm", "sl", "external"), sl_learners = NULL),
  g_exp_fit_args = list(fit_type = c("hal", "sl", "external"), lambda_seq = exp(seq(-1,
    -13, length = 300)), sl_learners_density = NULL),
  g_cens_fit_args = list(fit_type = c("glm", "sl", "external"), glm_formula =
    "C_cens ~ .^2", sl_learners = NULL),
  Q_fit_args = list(fit_type = c("glm", "sl", "external"), glm_formula = "Y ~ .^2",
    sl_learners = NULL),
  eif_reg_type = c("hal", "glm"),
  ipcw_efficiency = TRUE,
  samp_fit_ext = NULL,
  gn_exp_fit_ext = NULL,
  gn_cens_fit_ext = NULL,
  Qn_fit_ext = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="txshift_+3A_w">W</code></td>
<td>
<p>A <code>matrix</code>, <code>data.frame</code>, or similar containing a set of
baseline covariates.</p>
</td></tr>
<tr><td><code id="txshift_+3A_a">A</code></td>
<td>
<p>A <code>numeric</code> vector corresponding to a treatment variable. The
parameter of interest is defined as a location shift of this quantity.</p>
</td></tr>
<tr><td><code id="txshift_+3A_c_cens">C_cens</code></td>
<td>
<p>A <code>numeric</code> indicator for whether a given observation was
subject to censoring by way of loss to follow-up. The default assumes no
censoring due to loss to follow-up.</p>
</td></tr>
<tr><td><code id="txshift_+3A_y">Y</code></td>
<td>
<p>A <code>numeric</code> vector of the observed outcomes.</p>
</td></tr>
<tr><td><code id="txshift_+3A_c_samp">C_samp</code></td>
<td>
<p>A <code>numeric</code> indicator for whether a given observation was
subject to censoring by being omitted from the second-stage sample, used to
compute an inverse probability of censoring weighted estimator in such
cases. The default assumes no censoring due to two-phase sampling.</p>
</td></tr>
<tr><td><code id="txshift_+3A_v">V</code></td>
<td>
<p>The covariates that are used in determining the sampling procedure
that gives rise to censoring. The default is <code>NULL</code> and corresponds to
scenarios in which there is no censoring (in which case all values in the
preceding argument <code>C_samp</code> must be uniquely 1). To specify this, pass
in a <code>character</code> vector identifying variables amongst W, A, Y thought
to have impacted the definition of the sampling mechanism (C_samp). This
argument also accepts a <code>data.table</code> (or similar) object composed of
combinations of variables W, A, Y; use of this option is NOT recommended.</p>
</td></tr>
<tr><td><code id="txshift_+3A_delta">delta</code></td>
<td>
<p>A <code>numeric</code> value indicating the shift in the treatment to
be used in defining the target parameter. This is defined with respect to
the scale of the treatment (A).</p>
</td></tr>
<tr><td><code id="txshift_+3A_estimator">estimator</code></td>
<td>
<p>The type of estimator to be fit, either <code>"tmle"</code> for
targeted maximum likelihood or <code>"onestep"</code> for a one-step estimator.</p>
</td></tr>
<tr><td><code id="txshift_+3A_fluctuation">fluctuation</code></td>
<td>
<p>The method to be used in the submodel fluctuation step
(targeting step) to compute the TML estimator. The choices are &quot;standard&quot;
and &quot;weighted&quot; for where to place the auxiliary covariate in the logistic
tilting regression.</p>
</td></tr>
<tr><td><code id="txshift_+3A_max_iter">max_iter</code></td>
<td>
<p>A <code>numeric</code> integer giving the maximum number of steps
to be taken in iterating to a solution of the efficient influence function.</p>
</td></tr>
<tr><td><code id="txshift_+3A_samp_fit_args">samp_fit_args</code></td>
<td>
<p>A <code>list</code> of arguments, all but one of which are
passed to <code><a href="#topic+est_samp">est_samp</a></code>. For details, consult the documentation of
<code><a href="#topic+est_samp">est_samp</a></code>. The first element (i.e., <code>fit_type</code>) is used
to determine how this regression is fit: generalized linear model (&quot;glm&quot;)
or Super Learner (&quot;sl&quot;), and &quot;external&quot; a user-specified input of the form
produced by <code><a href="#topic+est_samp">est_samp</a></code>.</p>
</td></tr>
<tr><td><code id="txshift_+3A_g_exp_fit_args">g_exp_fit_args</code></td>
<td>
<p>A <code>list</code> of arguments, all but one of which are
passed to <code><a href="#topic+est_g_exp">est_g_exp</a></code>. For details, see the documentation of
<code><a href="#topic+est_g_exp">est_g_exp</a></code>. The 1st element (i.e., <code>fit_type</code>) specifies
how this regression is fit: <code>"hal"</code> to estimate conditional densities
via the highly adaptive lasso (via <span class="pkg">haldensify</span>), <code>"sl"</code> for
<span class="pkg">sl3</span> learners used to fit Super Learner ensembles to densities via
<span class="pkg">sl3</span>'s <code>Lrnr_haldensify</code> or similar, and <code>"external"</code> for
user-specified input of the form produced by <code><a href="#topic+est_g_exp">est_g_exp</a></code>.</p>
</td></tr>
<tr><td><code id="txshift_+3A_g_cens_fit_args">g_cens_fit_args</code></td>
<td>
<p>A <code>list</code> of arguments, all but one of which are
passed to <code><a href="#topic+est_g_cens">est_g_cens</a></code>. For details, see the documentation of
<code><a href="#topic+est_g_cens">est_g_cens</a></code>. The 1st element (i.e., <code>fit_type</code>) specifies
how this regression is fit: <code>"glm"</code> for a generalized linear model
or <code>"sl"</code> for <span class="pkg">sl3</span> learners used to fit a Super Learner ensemble
for the censoring mechanism, and <code>"external"</code> for user-specified input
of the form produced by <code><a href="#topic+est_g_cens">est_g_cens</a></code>.</p>
</td></tr>
<tr><td><code id="txshift_+3A_q_fit_args">Q_fit_args</code></td>
<td>
<p>A <code>list</code> of arguments, all but one of which are
passed to <code><a href="#topic+est_Q">est_Q</a></code>. For details, consult the documentation for
<code><a href="#topic+est_Q">est_Q</a></code>. The first element (i.e., <code>fit_type</code>) is used to
determine how this regression is fit: <code>"glm"</code> for a generalized linear
model for the outcome mechanism, <code>"sl"</code> for <span class="pkg">sl3</span> learners used
to fit a Super Learner for the outcome mechanism, and <code>"external"</code>
for user-specified input of the form produced by <code><a href="#topic+est_Q">est_Q</a></code>.</p>
</td></tr>
<tr><td><code id="txshift_+3A_eif_reg_type">eif_reg_type</code></td>
<td>
<p>Whether a flexible nonparametric function ought to be
used in the dimension-reduced nuisance regression of the targeting step for
the censored data case. By default, the method used is a nonparametric
regression based on the Highly Adaptive Lasso (from <span class="pkg">hal9001</span>). Set
this to <code>"glm"</code> to instead use a simple linear regression model. In
this step, the efficient influence function (EIF) is regressed against
covariates contributing to the censoring mechanism (i.e., EIF ~ V | C = 1).</p>
</td></tr>
<tr><td><code id="txshift_+3A_ipcw_efficiency">ipcw_efficiency</code></td>
<td>
<p>Whether to use an augmented inverse probability of
censoring weighted EIF estimating equation to ensure efficiency of the
resultant estimate. The default is <code>TRUE</code>; the inefficient estimation
procedure specified by <code>FALSE</code> is only supported for completeness.</p>
</td></tr>
<tr><td><code id="txshift_+3A_samp_fit_ext">samp_fit_ext</code></td>
<td>
<p>The results of an external fitting procedure used to
estimate the two-phase sampling mechanism, to be used in constructing the
inverse probability of censoring weighted TML or one-step estimator. The
input provided must match the output of <code><a href="#topic+est_samp">est_samp</a></code> exactly.</p>
</td></tr>
<tr><td><code id="txshift_+3A_gn_exp_fit_ext">gn_exp_fit_ext</code></td>
<td>
<p>The results of an external fitting procedure used to
estimate the exposure mechanism (generalized propensity score), to be used
in constructing the TML or one-step estimator. The input provided must
match the output of <code><a href="#topic+est_g_exp">est_g_exp</a></code> exactly.</p>
</td></tr>
<tr><td><code id="txshift_+3A_gn_cens_fit_ext">gn_cens_fit_ext</code></td>
<td>
<p>The results of an external fitting procedure used to
estimate the censoring mechanism (propensity score for missingness), to be
used in constructing the TML or one-step estimator. The input provided must
match the output of <code><a href="#topic+est_g_cens">est_g_cens</a></code> exactly.</p>
</td></tr>
<tr><td><code id="txshift_+3A_qn_fit_ext">Qn_fit_ext</code></td>
<td>
<p>The results of an external fitting procedure used to
estimate the outcome mechanism, to be used in constructing the TML or
one-step estimator. The input provided must match the output of
<code><a href="#topic+est_Q">est_Q</a></code> exactly; use of this argument is only recommended for
power users.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Construct a one-step estimate or targeted minimum loss estimate of
the counterfactual mean under a modified treatment policy, automatically
making adjustments for two-phase sampling when a censoring indicator is
included. Ensemble machine learning may be used to construct the initial
estimates of nuisance functions using <span class="pkg">sl3</span>.
</p>


<h3>Value</h3>

<p>S3 object of class <code>txshift</code> containing the results of the
procedure to compute a TML or one-step estimate of the counterfactual mean
under a modified treatment policy that shifts a continuous-valued exposure
by a scalar amount <code>delta</code>. These estimates can be augmented to be
consistent and efficient when two-phase sampling is performed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(429153)
n_obs &lt;- 100
W &lt;- replicate(2, rbinom(n_obs, 1, 0.5))
A &lt;- rnorm(n_obs, mean = 2 * W, sd = 1)
Y &lt;- rbinom(n_obs, 1, plogis(A + W + rnorm(n_obs, mean = 0, sd = 1)))
C_samp &lt;- rbinom(n_obs, 1, plogis(W + Y)) # two-phase sampling
C_cens &lt;- rbinom(n_obs, 1, plogis(rowSums(W) + 0.5))

# construct a TML estimate, ignoring censoring
tmle &lt;- txshift(
  W = W, A = A, Y = Y, delta = 0.5,
  estimator = "onestep",
  g_exp_fit_args = list(
    fit_type = "hal",
    n_bins = 3,
    lambda_seq = exp(seq(-1, -10, length = 50))
  ),
  Q_fit_args = list(
    fit_type = "glm",
    glm_formula = "Y ~ ."
  )
)
## Not run: 
# construct a TML estimate, accounting for censoring
tmle &lt;- txshift(
  W = W, A = A, C_cens = C_cens, Y = Y, delta = 0.5,
  estimator = "onestep",
  g_exp_fit_args = list(
    fit_type = "hal",
    n_bins = 3,
    lambda_seq = exp(seq(-1, -10, length = 50))
  ),
  g_cens_fit_args = list(
    fit_type = "glm",
    glm_formula = "C_cens ~ ."
  ),
  Q_fit_args = list(
    fit_type = "glm",
    glm_formula = "Y ~ ."
  )
)

# construct a TML estimate under two-phase sampling, ignoring censoring
ipcwtmle &lt;- txshift(
  W = W, A = A, Y = Y, delta = 0.5,
  C_samp = C_samp, V = c("W", "Y"),
  estimator = "onestep", max_iter = 3,
  samp_fit_args = list(fit_type = "glm"),
  g_exp_fit_args = list(
    fit_type = "hal",
    n_bins = 3,
    lambda_seq = exp(seq(-1, -10, length = 50))
  ),
  Q_fit_args = list(
    fit_type = "glm",
    glm_formula = "Y ~ ."
  ),
  eif_reg_type = "glm"
)

# construct a TML estimate acconting for two-phase sampling and censoring
ipcwtmle &lt;- txshift(
  W = W, A = A, C_cens = C_cens, Y = Y, delta = 0.5,
  C_samp = C_samp, V = c("W", "Y"),
  estimator = "onestep", max_iter = 3,
  samp_fit_args = list(fit_type = "glm"),
  g_exp_fit_args = list(
    fit_type = "hal",
    n_bins = 3,
    lambda_seq = exp(seq(-1, -10, length = 50))
  ),
  g_cens_fit_args = list(
    fit_type = "glm",
    glm_formula = "C_cens ~ ."
  ),
  Q_fit_args = list(
    fit_type = "glm",
    glm_formula = "Y ~ ."
  ),
  eif_reg_type = "glm"
)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
