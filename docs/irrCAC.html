<!DOCTYPE html><html lang="en"><head><title>Help for package irrCAC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {irrCAC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#altman'><p>Dataset describing the Altman's Benchmarking Scale</p></a></li>
<li><a href='#altman.bf'><p>Computing Altman's Benchmark Scale Membership Probabilities</p></a></li>
<li><a href='#bipolar.weights'><p>Function for computing the Bipolar Weights</p></a></li>
<li><a href='#bp.coeff.dist'><p>Brennan-Prediger's agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</p></a></li>
<li><a href='#bp.coeff.raw'><p>Brennan \&amp; Prediger's (BP) agreement coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</p></a></li>
<li><a href='#bp2.table'><p>Brenann-Prediger coefficient for 2 raters</p></a></li>
<li><a href='#cac.ben.gerry'><p>Ratings of 12 units from 2 raters named Ben and Gerry</p></a></li>
<li><a href='#cac.dist.g1g2'><p>Distribution of 4 raters by subject and by category, for 14 Subjects that belong to 2 groups &quot;G1&quot; and &quot;G2&quot;</p></a></li>
<li><a href='#cac.dist4cat'><p>Distribution of 4 raters by Category and Subject - Subjects allocated in 2 groups A and B.</p></a></li>
<li><a href='#cac.raw.g1g2'><p>Dataset of raw ratings from 4 Raters on 14 Subjects that belong to 2 groups named &quot;G1&quot; and &quot;G2&quot;</p></a></li>
<li><a href='#cac.raw.gender'><p>Rating Data from 4 Raters and 15 human Subjects, 9 of whom are female and 6 males.</p></a></li>
<li><a href='#cac.raw4raters'><p>Rating Data from 4 Raters and 12 Subjects.</p></a></li>
<li><a href='#cac.raw5obser'><p>Scores assigned by 5 observers to 20 experimental units.</p></a></li>
<li><a href='#circular.weights'><p>Function for computing the Circular Weights</p></a></li>
<li><a href='#conger.kappa.raw'><p>Conger's generalized kappa coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</p></a></li>
<li><a href='#cont3x3abstractors'><p>Distribution of 100 pregnant women by pregnancy type and by abstractor.</p></a></li>
<li><a href='#cont4x4diagnosis'><p>Distribution of 223 Psychiatric Patients by Type of of Psychiatric Disorder and Diagnosis Method.</p></a></li>
<li><a href='#distrib.6raters'><p>Distribution of 6 psychiatrists by Subject/patient and diagnosis Category.</p></a></li>
<li><a href='#fleiss'><p>Dataset describing Fleiss' Benchmarking Scale</p></a></li>
<li><a href='#fleiss.bf'><p>Computing Fleiss Benchmark Scale Membership Probabilities</p></a></li>
<li><a href='#fleiss.kappa.dist'><p>Fleiss' agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</p></a></li>
<li><a href='#fleiss.kappa.raw'><p>Fleiss' generalized kappa among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</p></a></li>
<li><a href='#gwet.ac1.dist'><p>Gwet's AC1/AC2 agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</p></a></li>
<li><a href='#gwet.ac1.raw'><p>Gwet's AC1/AC2 agreement coefficient among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</p></a></li>
<li><a href='#gwet.ac1.table'><p>Gwet's AC1/AC2 coefficient for 2 raters</p></a></li>
<li><a href='#identity.weights'><p>Function for computing the Identity Weights</p></a></li>
<li><a href='#kappa2.table'><p>Kappa coefficient for 2 raters</p></a></li>
<li><a href='#krippen.alpha.dist'><p>Krippendorff's agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</p></a></li>
<li><a href='#krippen.alpha.raw'><p>Krippendorff's alpha coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</p></a></li>
<li><a href='#krippen2.table'><p>Krippendorff's Alpha coefficient for 2 raters</p></a></li>
<li><a href='#landis.koch'><p>Dataset describing the Landis &amp; Koch Benchmarking Scale</p></a></li>
<li><a href='#landis.koch.bf'><p>Computing Landis-Koch Benchmark Scale Membership Probabilities</p></a></li>
<li><a href='#linear.weights'><p>Function for computing the Linear Weights</p></a></li>
<li><a href='#ordinal.weights'><p>Function for computing the Ordinal Weights</p></a></li>
<li><a href='#pa.coeff.dist'><p>Percent agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</p></a></li>
<li><a href='#pa.coeff.raw'><p>Percent agreement among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</p></a></li>
<li><a href='#pa2.table'><p>Percent Agreement coefficient for 2 raters</p></a></li>
<li><a href='#quadratic.weights'><p>Function for computing the Quadratic Weights</p></a></li>
<li><a href='#radical.weights'><p>Function for computing the Radical Weights</p></a></li>
<li><a href='#ratio.weights'><p>Function for computing the Ratio Weights</p></a></li>
<li><a href='#scott2.table'><p>Scott's coefficient for 2 raters</p></a></li>
<li><a href='#trim'><p>An r function for trimming leading and trealing blanks</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Author:</td>
<td>Kilem L. Gwet, Ph.D.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-08-28</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kilem L. Gwet &lt;gwet@agreestat.com&gt;</td>
</tr>
<tr>
<td>Title:</td>
<td>Computing Chance-Corrected Agreement Coefficients (CAC)</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculates various chance-corrected agreement coefficients (CAC) among 2 or more raters are provided. 
	Among the CAC coefficients covered are Cohen's kappa, Conger's kappa, Fleiss' kappa, Brennan-Prediger coefficient, Gwet's AC1/AC2 
	coefficients, and Krippendorff's alpha. Multiple sets of weights are proposed for computing weighted analyses. All of these statistical 
	procedures are described in details in Gwet, K.L. (2014,ISBN:978-0970806284): "Handbook of Inter-Rater Reliability," 4th edition, 
	Advanced Analytics, LLC.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-09-16 09:45:28 UTC; gwet6</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-09-23 15:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='altman'>Dataset describing the Altman's Benchmarking Scale</h2><span id='topic+altman'></span>

<h3>Description</h3>

<p>This dataset contains information describing the Altman scale for benchmarking chance-corrected agreement 
coefficients such as Gwet AC1/AC2, Kappa and many others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>altman
</code></pre>


<h3>Format</h3>

<p>Each row of this dataset describes an interval and the interpretation of the magnitude it represents.
</p>

<dl>
<dt>lb.AL</dt><dd><p>The interval lower bound</p>
</dd>
<dt>ub.AL</dt><dd><p>The interval upper bound</p>
</dd>
<dt>interp.AL</dt><dd><p>The interpretation</p>
</dd>
</dl>


<h3>Source</h3>

<p>Altman, D.G. (1991). <em>Practical Statistics for Medical Research</em>. Chapman and Hall.
</p>

<hr>
<h2 id='altman.bf'>Computing Altman's Benchmark Scale Membership Probabilities</h2><span id='topic+altman.bf'></span>

<h3>Description</h3>

<p>Computing Altman's Benchmark Scale Membership Probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>altman.bf(coeff, se, BenchDF = altman)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="altman.bf_+3A_coeff">coeff</code></td>
<td>
<p>A mandatory parameter representing the estimated value of an agreement coefficient.</p>
</td></tr>
<tr><td><code id="altman.bf_+3A_se">se</code></td>
<td>
<p>A mandatory parameter representing the agreement coefficient standard error.</p>
</td></tr>
<tr><td><code id="altman.bf_+3A_benchdf">BenchDF</code></td>
<td>
<p>An optional parameter that is a 3-column data frame containing the Altman's benchmark scale 
information. The 3 columns are the interval lower bound, upper bound, and their interpretation. The default value 
is a small file contained in the package and named <em>altman.RData</em>, which describes the official Altman's 
scale intervals and their interpretation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-column matrix containing the membership probabilities (c.f. <a href="http://agreestat.com/research_papers/inter-rater%20reliability%20study%20design1.pdf">http://agreestat.com/research_papers/inter-rater%20reliability%20study%20design1.pdf</a>)
</p>

<hr>
<h2 id='bipolar.weights'>Function for computing the Bipolar Weights</h2><span id='topic+bipolar.weights'></span>

<h3>Description</h3>

<p>Function for computing the Bipolar Weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bipolar.weights(categ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bipolar.weights_+3A_categ">categ</code></td>
<td>
<p>A mandatory parameter representing the vector of all possible ratings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of quadratic weights to be used for calculating the weighted coefficients.
</p>

<hr>
<h2 id='bp.coeff.dist'>Brennan-Prediger's agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</h2><span id='topic+bp.coeff.dist'></span>

<h3>Description</h3>

<p>Brennan-Prediger's agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bp.coeff.dist(ratings, weights = "unweighted", categ = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bp.coeff.dist_+3A_ratings">ratings</code></td>
<td>
<p>An <em>nxq</em> matrix / data frame containing the distribution of raters by subject and category. Each cell <em>(i,k)</em> contains the number of raters who classsified subject <em>i</em> into category <em>k</em>.</p>
</td></tr>
<tr><td><code id="bp.coeff.dist_+3A_weights">weights</code></td>
<td>
<p>is an optional parameter that is either a string variable or a matrix. The string describes one of the predefined 
weights and must take one of the values (&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number of posssible categories where a subject 
can be classified. If some of the q possible categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ. Otherwise, only the categories reported will be used.</p>
</td></tr>
<tr><td><code id="bp.coeff.dist_+3A_categ">categ</code></td>
<td>
<p>An optional parameter representing all categories available to raters during the experiment. This parameter may be useful if 
some categories were not used by any rater inspite of being available to the raters.</p>
</td></tr>
<tr><td><code id="bp.coeff.dist_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="bp.coeff.dist_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the following information: 
pa(the percent agreement),pe(the percent chance agreement),coeff(Brennan-Prediger coefficient),
stderr(the standard error of Brennan-Prediger coefficient),conf.int(the p-value of Brennan-Prediger coefficient), 
p.value(the p-value of Brennan-Prediger coefficient),coeff.name (&quot;Brennan-Prediger&quot;).
</p>


<h3>Source</h3>

<p>Brennan, R.L., and Prediger, D. J. (1981). &ldquo;Coefficient Kappa: some uses, misuses, and alternatives,&quot; 
<em>Educational and Psychological Measurement</em>, 41, 687-699.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "distrib.6raters" comes with this package. It represents the distribution of 6 raters 
#by subject and by category. Note that each row of this dataset sums to the number of raters, which
#is 6. You may this dataset as follows:
distrib.6raters
bp.coeff.dist(distrib.6raters) #BP coefficient, precision measures, weights &amp; list of categories
bp &lt;- bp.coeff.dist(distrib.6raters)$coeff #Yields Brennan-Prediger coefficient alone.
bp
q &lt;- ncol(distrib.6raters) #Number of categories
bp.coeff.dist(distrib.6raters,weights = quadratic.weights(1:q)) #Weighted BP with quadratic weights
</code></pre>

<hr>
<h2 id='bp.coeff.raw'>Brennan \&amp; Prediger's (BP) agreement coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</h2><span id='topic+bp.coeff.raw'></span>

<h3>Description</h3>

<p>Brennan \&amp; Prediger's (BP) agreement coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bp.coeff.raw(ratings, weights = "unweighted", categ.labels = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bp.coeff.raw_+3A_ratings">ratings</code></td>
<td>
<p>An nxr matrix / data frame of ratings where each column represents one rater and each row one subject.</p>
</td></tr>
<tr><td><code id="bp.coeff.raw_+3A_weights">weights</code></td>
<td>
<p>is a mandatory parameter that is either a string variable or a matrix. 
The string describes one of the predefined weights and must take one of the values 
(&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number 
of posssible categories where a subject can be classified. If some of the q possible 
categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ.labels. Otherwise, the program may not work.</p>
</td></tr>
<tr><td><code id="bp.coeff.raw_+3A_categ.labels">categ.labels</code></td>
<td>
<p>An optional vector parameter containing the list of all possible ratings. It may be useful in case some of the
possibe ratings are not used by any rater, they will still be used when calculating agreement coefficients. The default value is 
NULL. In this case, only categories reported by the raters are used in the
calculations.</p>
</td></tr>
<tr><td><code id="bp.coeff.raw_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value 
is 0.95.</p>
</td></tr>
<tr><td><code id="bp.coeff.raw_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction
to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data list containing 3 objects: (1) a one-row data frame containing various statistics including the requested agreement
coefficient, (2) the weight matrix used in the calculations if any, and (3) A vector of categories used in the analysis. These 
could be categories reported by the raters, or those available to the raters whether they used them or not.  The output data frame
contains the following variables: &quot;coeff.name&quot; (coefficient name), &quot;pa&quot; (the percent agreement), &quot;pe&quot; (the percent chance 
agreement), coeff.val (Brennan-Prediger coefficient estimate), &quot;coeff.se&quot; (standard error), &quot;conf.int&quot; (the confidence interval), 
&quot;p.value&quot;(Brennan-Prediger coefficient's p-value), &quot;w.name&quot;(the weights' identification).
</p>


<h3>References</h3>

<p>Brennan, R.L., \&amp; Prediger, D. J. (1981). &ldquo;Coefficient Kappa: some uses, misuses, and alternatives.&quot; <em>Educational and Psychological Measurement</em>, 41, 687-699.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cac.raw4raters" comes with this package. Analyze it as follows:
cac.raw4raters
bp.coeff.raw(cac.raw4raters) #BP coefficient, precision measures, weights &amp; categories
bp.coeff.raw(cac.raw4raters)$est #Brennan-Prediger coefficient with precision measures
bp &lt;- bp.coeff.raw(cac.raw4raters)$est$coeff.val #Yields Brennan-Prediger coefficient alone.
bp
bp.coeff.raw(cac.raw4raters, weights = "quadratic") #weighted Brennan-Prediger coefficient
</code></pre>

<hr>
<h2 id='bp2.table'>Brenann-Prediger coefficient for 2 raters</h2><span id='topic+bp2.table'></span>

<h3>Description</h3>

<p>Brenann-Prediger coefficient for 2 raters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bp2.table(ratings, weights = identity.weights(1:ncol(ratings)),
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bp2.table_+3A_ratings">ratings</code></td>
<td>
<p>A square table of ratings (assume no missing ratings).</p>
</td></tr>
<tr><td><code id="bp2.table_+3A_weights">weights</code></td>
<td>
<p>An optional matrix that contains the weights used in the weighted analysis. By default, this 
parameter contaings the identity weight matrix, which leads to the unweighted analysis.</p>
</td></tr>
<tr><td><code id="bp2.table_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter that specifies the confidence level used for constructing confidence 
intervals. By default the function assumes the standard value of 95%.</p>
</td></tr>
<tr><td><code id="bp2.table_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the finite population size if any. It is used to perform the finite
population correction to the standard error. It's default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the following 5 variables: coeff.name coeff.val coeff.se coeff.ci coeff.pval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cont3x3abstractors" comes with this package. Analyze it as follows:
bp2.table(cont3x3abstractors) #Yields Brennan-Prediger's coefficient along with precision measures
bp &lt;- bp2.table(cont3x3abstractors)$coeff.val #Yields Brennan-Prediger coefficient alone.
bp
q &lt;- nrow(cont3x3abstractors) #Number of categories
bp2.table(cont3x3abstractors,weights = quadratic.weights(1:q)) #Weighted BP coefficient
</code></pre>

<hr>
<h2 id='cac.ben.gerry'>Ratings of 12 units from 2 raters named Ben and Gerry</h2><span id='topic+cac.ben.gerry'></span>

<h3>Description</h3>

<p>This dataset contains ratings that 2 raters named Ben and Gerry assigned to 12 units distributed in 2 groups 
&quot;G1&quot; and &quot;G2&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac.ben.gerry
</code></pre>


<h3>Format</h3>

<p>Each row of this dataset describes an interval and the interpretation of the magnitude it represents.
</p>

<dl>
<dt>Group</dt><dd><p>Group Name</p>
</dd>
<dt>Units</dt><dd><p>Unit number</p>
</dd>
<dt>Ben</dt><dd><p>Ben's Ratings</p>
</dd>
<dt>Gerry</dt><dd><p>Gerry's Ratings</p>
</dd>
</dl>
   
<p>The first 2 columns &quot;Group&quot; and &quot;Units&quot; play a descriptive role here and are not used by any fucntion included in this
package. One will typically use cac.ben.gerry[,c(3,4)] or cac.ben.gerry[,c(&quot;Ben&quot;,&quot;Gerry&quot;)] as input 
dataset.</p>

<hr>
<h2 id='cac.dist.g1g2'>Distribution of 4 raters by subject and by category, for 14 Subjects that belong to 2 groups &quot;G1&quot; and &quot;G2&quot;</h2><span id='topic+cac.dist.g1g2'></span>

<h3>Description</h3>

<p>This dataset contains rating data in the form of a subject-level distribution of 4 raters by category the subject
was classified into. A total of 4 raters had to classify 14 subjects into one of 5 categories &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, and &quot;e&quot;. 
This dataset is different version of the more detailed cac.raw.g1g2 dataset. While cac.raw.g1g2 tells you
about the exact category into which each rater classified all subjects, cac.dist.g1g2 on the other hand, can only tell 
you how many raters classified a given subject into a particular category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac.dist.g1g2
</code></pre>


<h3>Format</h3>

<p>This dataset contains ratings obtained from an experiment where 4 raters classified 14 subjects into 5 
possible categories labeled as a, b, c, d, and e. None of the 4 raters scored all 14 units. Therefore, 
some missing ratings appear in each of the columns associated with the 4 raters.
</p>
<p>Note that only the the 4 last columns are to be used with the functions included in this package.  The first 2
columns only play a descriptive role and are not used in any calculation.
</p>

<dl>
<dt>Group</dt><dd><p>This variable represents the group name.</p>
</dd>
<dt>Units</dt><dd><p>This variable represents the unit number.</p>
</dd>
<dt>a</dt><dd><p>Number of raters who classified the subject represented by the row into category &quot;a&quot;</p>
</dd>
<dt>b</dt><dd><p>Number of raters who classified the subject represented by the row into category &quot;b&quot;</p>
</dd>
<dt>c</dt><dd><p>Number of raters who classified the subject represented by the row into category &quot;c&quot;</p>
</dd>
<dt>d</dt><dd><p>Number of raters who classified the subject represented by the row into category &quot;d&quot;</p>
</dd>
<dt>e</dt><dd><p>Number of raters who classified the subject represented by the row into category &quot;e&quot;</p>
</dd>
</dl>

<hr>
<h2 id='cac.dist4cat'>Distribution of 4 raters by Category and Subject - Subjects allocated in 2 groups A and B.</h2><span id='topic+cac.dist4cat'></span>

<h3>Description</h3>

<p>This dataset summarizes the ratings assigned by 4 raters who classified 15 subjects into one of 3 categories
named &quot;a&quot;, &quot;b&quot;, and &quot;c&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac.dist4cat
</code></pre>


<h3>Format</h3>

<p>This dataset has 15 rows (for the 15 subjects) and 4 columns. Only the last 3 columns representing the
categories into which subjects are classified are used in the calculations - unless the sub-group analysis is required.    
</p>

<dl>
<dt>Group</dt><dd><p>This variable repsents the subject number.</p>
</dd>
<dt>a</dt><dd><p>category a</p>
</dd>
<dt>b</dt><dd><p>Category b</p>
</dd>
<dt>c</dt><dd><p>Category c</p>
</dd>
</dl>

<hr>
<h2 id='cac.raw.g1g2'>Dataset of raw ratings from 4 Raters on 14 Subjects that belong to 2 groups named &quot;G1&quot; and &quot;G2&quot;</h2><span id='topic+cac.raw.g1g2'></span>

<h3>Description</h3>

<p>This dataset contains data from a reliability experiment where 4 raters identified as Rater1, Rater2, Rater3 and Rater4
scored 14 units on a 5-point alphabetical scale based on the values a, b, c, d and e. These 14 units are allocated to 
2 groups named G1 and G2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac.raw.g1g2
</code></pre>


<h3>Format</h3>

<p>This dataset contains ratings obtained from an experiment where 4 raters classified 14 subjects into 5 
possible categories labeled as a, b, c, d, and e. None of the 4 raters scored all 14 units. Therefore, 
some missing ratings appear in each of the columns associated with the 4 raters.
</p>
<p>Note that only the the 4 last columns are to be used with the functions included in this package.  The first 2
columns only play a descriptive role and are not used in any calculation.
</p>

<dl>
<dt>Group</dt><dd><p>This variable repsents the unit number.</p>
</dd>
<dt>Units</dt><dd><p>This variable repsents the unit number.</p>
</dd>
<dt>Rater1</dt><dd><p>All ratings from rater 1</p>
</dd>
<dt>Rater2</dt><dd><p>All ratings from rater 2</p>
</dd>
<dt>Rater3</dt><dd><p>All ratings from rater 3</p>
</dd>
<dt>Rater4</dt><dd><p>All ratings from rater 4</p>
</dd>
</dl>

<hr>
<h2 id='cac.raw.gender'>Rating Data from 4 Raters and 15 human Subjects, 9 of whom are female and 6 males.</h2><span id='topic+cac.raw.gender'></span>

<h3>Description</h3>

<p>This dataset contains data from a reliability experiment where 4 raters scored 15 units on a 3-point alphabetic scale 
based on the values a, b, and c.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac.raw.gender
</code></pre>


<h3>Format</h3>

<p>This dataset contains ratings obtained from an experiment where 4 raters classiffied 15 subjects into 3 
possible categories labeled as a, b, and c.
</p>
<p>Note that only the the 4 last columns are to be used with the functions included in this package.  The first 
column only plays a descriptive role and is not to be used in any calculation.
</p>

<dl>
<dt>Group</dt><dd><p>This variable repsents the unit number.</p>
</dd>
<dt>RaterA</dt><dd><p>All ratings from rater 1</p>
</dd>
<dt>RaterB</dt><dd><p>All ratings from rater 2</p>
</dd>
<dt>RaterC</dt><dd><p>All ratings from rater 3</p>
</dd>
<dt>RaterD</dt><dd><p>All ratings from rater 4</p>
</dd>
</dl>

<hr>
<h2 id='cac.raw4raters'>Rating Data from 4 Raters and 12 Subjects.</h2><span id='topic+cac.raw4raters'></span>

<h3>Description</h3>

<p>This dataset contains data from a reliability experiment where 5 observers scored 15 units on a 4-point numeric scale 
based on the values 0, 1, 2 and 3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac.raw4raters
</code></pre>


<h3>Format</h3>

<p>This dataset contains ratings obtained from an experiment where 4 raters classified 12 subjects into 5 
possible categories labeled as 1, 2, 3, 4, and 5. None of the 4 raters scored all 12 units. Therefore, 
some missing ratings in the form of &quot;NA&quot; appear in each of the columns associated with the 4 raters.
</p>
<p>Note that only the the 4 last columns are to be used with the functions included in this package.  The first 
column only plays a descriptive role and is not used in any calculation.
</p>

<dl>
<dt>Units</dt><dd><p>This variable repsents the unit number.</p>
</dd>
<dt>Rater1</dt><dd><p>All ratings from rater 1</p>
</dd>
<dt>Rater2</dt><dd><p>All ratings from rater 2</p>
</dd>
<dt>Rater3</dt><dd><p>All ratings from rater 3</p>
</dd>
<dt>Rater4</dt><dd><p>All ratings from rater 4</p>
</dd>
</dl>


<h3>Source</h3>

<p>Gwet, K.L. (2014) <em>Handbook of Inter-Rater Reliability</em>, 4th Edition, page #120. Advanced Analytics, LLC.
</p>

<hr>
<h2 id='cac.raw5obser'>Scores assigned by 5 observers to 20 experimental units.</h2><span id='topic+cac.raw5obser'></span>

<h3>Description</h3>

<p>This dataset contains data from a reliability experiment where 5 observers scored 15 units on a 4-point numeric scale 
based on the values 0, 1, 2 and 3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac.raw5obser
</code></pre>


<h3>Format</h3>

<p>This dataset has 15 rows (for the 15 subjects) and 6 columns. Only the last 5 columns associated with the 5
observers are used in the calculations. Of the 5 observers, only observer 3 scored all 15 units. Therefore, some missing
ratings in the form of &quot;NA&quot; appear in the columns associated with the remaining 4 observers.
</p>

<dl>
<dt>Unit</dt><dd><p>This variable repsents the unit number.</p>
</dd>
<dt>Observer1</dt><dd><p>All ratings from Observer 1</p>
</dd>
<dt>Observer2</dt><dd><p>All ratings from Observer 2</p>
</dd>
<dt>Observer3</dt><dd><p>All ratings from Observer 3</p>
</dd>
<dt>Observer4</dt><dd><p>All ratings from Observer 4</p>
</dd>
<dt>Observer5</dt><dd><p>All ratings from Observer 5</p>
</dd>
</dl>


<h3>Source</h3>

<p>Gwet, K.L. (2014) <em>Handbook of Inter-Rater Reliability</em>, 4th Edition. Advanced Analytics, LLC. 
<em>A larger version of this table can be found on page #125</em>
</p>

<hr>
<h2 id='circular.weights'>Function for computing the Circular Weights</h2><span id='topic+circular.weights'></span>

<h3>Description</h3>

<p>Function for computing the Circular Weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>circular.weights(categ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="circular.weights_+3A_categ">categ</code></td>
<td>
<p>A mandatory parameter representing the vector of all possible ratings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of quadratic weights to be used for calculating the weighted coefficients.
</p>

<hr>
<h2 id='conger.kappa.raw'>Conger's generalized kappa coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</h2><span id='topic+conger.kappa.raw'></span>

<h3>Description</h3>

<p>Conger's generalized kappa coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conger.kappa.raw(ratings, weights = "unweighted", categ.labels = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conger.kappa.raw_+3A_ratings">ratings</code></td>
<td>
<p>An nxr matrix / data frame of ratings where each column represents one rater and each row one subject.</p>
</td></tr>
<tr><td><code id="conger.kappa.raw_+3A_weights">weights</code></td>
<td>
<p>is a mandatory parameter that is either a string variable or a matrix. 
The string describes one of the predefined weights and must take one of the values 
(&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number 
of posssible categories where a subject can be classified. If some of the q possible 
categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ.labels. Otherwise, the program may not work.</p>
</td></tr>
<tr><td><code id="conger.kappa.raw_+3A_categ.labels">categ.labels</code></td>
<td>
<p>An optional vector parameter containing the list of all possible ratings. It may be useful in 
case some of the possibe ratings are not used by any rater, they will still be used when calculating agreement 
coefficients. The default value is NULL. In this case, only categories reported by the raters are used in the
calculations.</p>
</td></tr>
<tr><td><code id="conger.kappa.raw_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="conger.kappa.raw_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data list containing 3 objects: (1) a one-row data frame containing various statistics including the requested agreement
coefficient, (2) the weight matrix used in the calculations if any, and (3) A vector of categories used in the analysis. These 
could be categories reported by the raters, or those available to the raters whether they used them or not.  The output data frame
contains the following variables: &quot;coeff.name&quot; (coefficient name), &quot;pa&quot; (the percent agreement), &quot;pe&quot; (the percent chance 
agreement), coeff.val (Conger's Kappa estimate), &quot;coeff.se&quot; (standard error), &quot;conf.int&quot; (Conger Kappa's confidence 
interval), &quot;p.value&quot;(agreement coefficient's p-value), &quot;w.name&quot;(the weights' identification).
</p>


<h3>References</h3>

<p>Conger, A. J. (1980), &ldquo;Integration and Generalization of Kappas for Multiple Raters,&quot; <em>Psychological Bulletin</em>, 88, 322-328.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cac.raw4raters" comes with this package. Analyze it as follows:
cac.raw4raters
conger.kappa.raw(cac.raw4raters) #Conger's kappa, precision stats, weights &amp; categories
conger.kappa.raw(cac.raw4raters)$est #Conger's kappa with precision measures
conger &lt;- conger.kappa.raw(cac.raw4raters)$est$coeff.val #Yields Conger's kappa alone.
conger
conger.kappa.raw(cac.raw4raters, weights = "quadratic") #weighted Conger's kappa
</code></pre>

<hr>
<h2 id='cont3x3abstractors'>Distribution of 100 pregnant women by pregnancy type and by abstractor.</h2><span id='topic+cont3x3abstractors'></span>

<h3>Description</h3>

<p>This dataset contains pregnancy type data collected from 100 women who entered an Emergency Room with a positive 
pregnancy test and a second condition, which is either abdominal pain or vaginal bleeding. After reviewing their 
medical records, 2 reviewers (also referred to as abstractors) classified them into one of the following three pregnancy
categories: Ectopic Pregnancy (Ectopic), Abnormal Intrauterine pregnancy (AIU) and Normal Intrauterine Pregnancy 
(NIU).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cont3x3abstractors
</code></pre>


<h3>Format</h3>

<p>Each row of this dataset describes an interval and the interpretation of the magnitude it represents.
</p>

<dl>
<dt>Type</dt><dd><p>Pregnancy Type.  This variable is shown here for information only and is never used by any function 
in the irrCAC package.</p>
</dd>
<dt>Ectopic</dt><dd><p>Ectopic Pregnancy</p>
</dd>
<dt>AIU</dt><dd><p>Abnormal Intrauterine Pregnancy</p>
</dd>
<dt>NIU</dt><dd><p>Normal Intrauterine Pregnancy</p>
</dd>
</dl>


<h3>Source</h3>

<p>Gwet, K.L. (2014). <em>Handbook of Inter-Rater Reliability</em>, 4th Edition. Advanced Analytics, LLC.
</p>

<hr>
<h2 id='cont4x4diagnosis'>Distribution of 223 Psychiatric Patients by Type of of Psychiatric Disorder and Diagnosis Method.</h2><span id='topic+cont4x4diagnosis'></span>

<h3>Description</h3>

<p>This dataset shows the distribution of 223 psychiatric patients by diagnosis category and by the method used to 
obtain the diagnosis. The first method named &ldquo;Clinical Diagnosis&quot; (also known as &ldquo;Facility Diagnosis&quot;) is used 
in a service facility (e.g. public hospital, or a community unit) and does not rely on a rigorous application of 
research criteria. The second method known as &ldquo;Research Diagnosis&quot; is based on a strict application of research 
criteria. Column 1 contains the diagnosis categories into which patients are classified with Method 1.  The first
row on the other hand, shows categories into which patients are classified with Method 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cont4x4diagnosis
</code></pre>


<h3>Format</h3>

<p>This dataset contains a 4x4 squared table. The first column is never used in the calculations and only 
contains row names. Only the last 4 columns are used for computing agreement coefficients. 
</p>

<dl>
<dt>Diagnosis</dt><dd><p>Pregnancy Type. This variable is shown here for information only and is never used by any function 
in the irrCAC package.</p>
</dd>
<dt>Schizophrenia</dt><dd><p>Ectopic Pregnancy</p>
</dd>
<dt>Bipolar.Disorder</dt><dd><p>Abnormal Intrauterine Pregnancy</p>
</dd>
<dt>Depression</dt><dd><p>Normal Intrauterine Pregnancy</p>
</dd>
<dt>Other</dt><dd><p>Normal Intrauterine Pregnancy</p>
</dd>
</dl>


<h3>Source</h3>

<p>Gwet, K.L. (2014). <em>Handbook of Inter-Rater Reliability</em>, 4th Edition. Advanced Analytics, LLC.
</p>

<hr>
<h2 id='distrib.6raters'>Distribution of 6 psychiatrists by Subject/patient and diagnosis Category.</h2><span id='topic+distrib.6raters'></span>

<h3>Description</h3>

<p>This dataset summarizes the ratings assigned by 6 psychiatrists classifying 15 patients into one of five categories
named &quot;Depression&quot;, &quot;Personal Disorder&quot;, &quot;Schizophrenia&quot;, &quot;Neurosis&quot; and &quot;Other&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distrib.6raters
</code></pre>


<h3>Format</h3>

<p>This dataset has 15 rows (for the 15 subjects) and 7 columns. Only the last 6 columns representing the
categories into which subjects are classified are used in the calculations.    
</p>

<dl>
<dt>Subject</dt><dd><p>This variable repsents the subject number.</p>
</dd>
<dt>Personality.Disorder</dt><dd><p>Personality disorder category</p>
</dd>
<dt>Schizophrenia</dt><dd><p>Schizophrenia Category</p>
</dd>
<dt>Neurosis</dt><dd><p>Neurosis category</p>
</dd>
<dt>Other</dt><dd><p>&quot;Other&quot; category</p>
</dd>
</dl>


<h3>Source</h3>

<p>Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters, <em>Psychological Bulletin</em>, 76, 
378-382.
</p>

<hr>
<h2 id='fleiss'>Dataset describing Fleiss' Benchmarking Scale</h2><span id='topic+fleiss'></span>

<h3>Description</h3>

<p>This dataset contains information describing Fleiss' scale for benchmarking chance-corrected agreement 
coefficients such as Gwet AC1/AC2, Kappa and many others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fleiss
</code></pre>


<h3>Format</h3>

<p>Each row of this dataset describes an interval and the interpretation of the magnitude it represents.
</p>

<dl>
<dt>lb.FL</dt><dd><p>The interval lower bound</p>
</dd>
<dt>ub.FL</dt><dd><p>The interval upper bound</p>
</dd>
<dt>interp.FL</dt><dd><p>The interpretation</p>
</dd>
</dl>


<h3>Source</h3>

<p>Fleiss, J. L. (1981). Statistical Methods for Rates and Proportions. John Wiley &amp; Sons.
</p>

<hr>
<h2 id='fleiss.bf'>Computing Fleiss Benchmark Scale Membership Probabilities</h2><span id='topic+fleiss.bf'></span>

<h3>Description</h3>

<p>Computing Fleiss Benchmark Scale Membership Probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fleiss.bf(coeff, se, BenchDF = fleiss)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fleiss.bf_+3A_coeff">coeff</code></td>
<td>
<p>A mandatory parameter representing the estimated value of an agreement coefficient.</p>
</td></tr>
<tr><td><code id="fleiss.bf_+3A_se">se</code></td>
<td>
<p>A mandatory parameter representing the agreement coefficient standard error.</p>
</td></tr>
<tr><td><code id="fleiss.bf_+3A_benchdf">BenchDF</code></td>
<td>
<p>An optional parameter that is a 3-column data frame containing the Fleiss' benchmark scale information. 
The 3 columns are the interval lower bound, upper bound, and their interpretation. The default value is a small 
file contained in the package and named <em>fleiss.RData</em>, which describes the fleiss' scale intervales and their
interpretation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-column matrix containing the membership probabilities (c.f. <a href="http://agreestat.com/research_papers/inter-rater%20reliability%20study%20design1.pdf">http://agreestat.com/research_papers/inter-rater%20reliability%20study%20design1.pdf</a>)
</p>

<hr>
<h2 id='fleiss.kappa.dist'>Fleiss' agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</h2><span id='topic+fleiss.kappa.dist'></span>

<h3>Description</h3>

<p>Fleiss' agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fleiss.kappa.dist(ratings, weights = "unweighted", categ = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fleiss.kappa.dist_+3A_ratings">ratings</code></td>
<td>
<p>An <em>nxq</em> matrix / data frame containing the distribution of raters by subject and category. Each cell <em>(i,k)</em> contains the number of raters who classsified subject <em>i</em> into category <em>k</em>.</p>
</td></tr>
<tr><td><code id="fleiss.kappa.dist_+3A_weights">weights</code></td>
<td>
<p>is an optional parameter that is either a string variable or a matrix. The string describes one of the predefined 
weights and must take one of the values (&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number of posssible categories where a subject 
can be classified. If some of the q possible categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ. Otherwise, only the categories reported will be used.</p>
</td></tr>
<tr><td><code id="fleiss.kappa.dist_+3A_categ">categ</code></td>
<td>
<p>An optional parameter representing all categories available to raters during the experiment. This parameter may be useful if 
some categories were not used by any rater inspite of being available to the raters.</p>
</td></tr>
<tr><td><code id="fleiss.kappa.dist_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="fleiss.kappa.dist_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the following information: 
pa(the percent agreement),pe(the percent chance agreement),coeff(Fleiss' agreement coefficient),
stderr(the standard error of Fleiss' coefficient),conf.int(the confidence interval of Fleiss Kappa coefficient),
p.value(the p-value of Fleiss' coefficient),coeff.name (&quot;Fleiss&quot;).
</p>


<h3>Source</h3>

<p>Fleiss, J. L. (1981). <em>Statistical Methods for Rates and Proportions</em>. John Wiley &amp; Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "distrib.6raters" comes with this package. It represents the distribution of 6 raters 
#by subject and by category. Note that each row of this dataset sums to the number of raters, which
#is 6. You may this dataset as follows:
distrib.6raters
fleiss.kappa.dist(distrib.6raters) #Fleiss' kappa, precision measures, weights &amp; list of categories
fleiss &lt;- fleiss.kappa.dist(distrib.6raters)$coeff #Yields Fleiss' kappa alone.
fleiss
q &lt;- ncol(distrib.6raters) #Number of categories
fleiss.kappa.dist(distrib.6raters,weights = quadratic.weights(1:q)) #Weighted fleiss/quadratic wts
</code></pre>

<hr>
<h2 id='fleiss.kappa.raw'>Fleiss' generalized kappa among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</h2><span id='topic+fleiss.kappa.raw'></span>

<h3>Description</h3>

<p>Fleiss' generalized kappa among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fleiss.kappa.raw(ratings, weights = "unweighted", categ.labels = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fleiss.kappa.raw_+3A_ratings">ratings</code></td>
<td>
<p>An nxr matrix / data frame of ratings where each column represents one rater and each row one subject.</p>
</td></tr>
<tr><td><code id="fleiss.kappa.raw_+3A_weights">weights</code></td>
<td>
<p>is a mandatory parameter that is either a string variable or a matrix. 
The string describes one of the predefined weights and must take one of the values 
(&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number 
of posssible categories where a subject can be classified. If some of the q possible 
categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ.labels. Otherwise, the program may not work.</p>
</td></tr>
<tr><td><code id="fleiss.kappa.raw_+3A_categ.labels">categ.labels</code></td>
<td>
<p>An optional vector parameter containing the list of all possible ratings. It may be useful in 
case some of the possibe ratings are not used by any rater, they will still be used when calculating agreement 
coefficients. The default value is NULL. In this case, only categories reported by the raters are used in the
calculations.</p>
</td></tr>
<tr><td><code id="fleiss.kappa.raw_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="fleiss.kappa.raw_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data list containing 3 objects: (1) a one-row data frame containing various statistics including the 
requested agreement coefficient, (2) the weight matrix used in the calculations if any, and (3) the categories 
used in the analysis. These could be categories reported by the raters, or those that were available to the raters
whether they used them or not.  The output data frame contains the following variables: &quot;coeff.name&quot; 
(coefficient name-here it will be &quot;Fleiss' Kappa&quot;), &quot;pa&quot; (the percent agreement), &quot;pe&quot; (the percent chance agreement), coeff.val 
(the agreement coefficient estimate-Fleiss' Kappa), &quot;coeff.se&quot; (the standard error), &quot;conf.int&quot; (Fleiss Kappa's confidence 
interval), &quot;p.value&quot;(Fleiss Kappa's p-value), &quot;w.name&quot;(the weights' identification).
</p>


<h3>References</h3>

<p>Fleiss, J. L. (1981). <em>Statistical Methods for Rates and Proportions</em>. John Wiley \&amp; Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cac.raw4raters" comes with this package. Analyze it as follows:
cac.raw4raters
fleiss.kappa.raw(cac.raw4raters) #Fleiss' kappa, precision measures, weights &amp; categories
fleiss.kappa.raw(cac.raw4raters)$est #Yields Fleiss' kappa with precision measures
fleiss &lt;- fleiss.kappa.raw(cac.raw4raters)$est$coeff.val #Yields Fleiss' kappa alone.
fleiss
fleiss.kappa.raw(cac.raw4raters, weights = "quadratic") #weighted Fleiss' kappa/quadratic wts
</code></pre>

<hr>
<h2 id='gwet.ac1.dist'>Gwet's AC1/AC2 agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</h2><span id='topic+gwet.ac1.dist'></span>

<h3>Description</h3>

<p>Gwet's AC1/AC2 agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gwet.ac1.dist(ratings, weights = "unweighted", categ = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gwet.ac1.dist_+3A_ratings">ratings</code></td>
<td>
<p>An <em>nxq</em> matrix / data frame containing the distribution of raters by subject and category. Each cell <em>(i,k)</em> contains the number of raters who classsified subject <em>i</em> into category <em>k</em>.</p>
</td></tr>
<tr><td><code id="gwet.ac1.dist_+3A_weights">weights</code></td>
<td>
<p>is an optional parameter that is either a string variable or a matrix. The string describes one of the predefined 
weights and must take one of the values (&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number of posssible categories where a subject 
can be classified. If some of the q possible categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ. Otherwise, only the categories reported will be used.</p>
</td></tr>
<tr><td><code id="gwet.ac1.dist_+3A_categ">categ</code></td>
<td>
<p>An optional parameter representing all categories available to raters during the experiment. This parameter may be useful if 
some categories were not used by any rater inspite of being available to the raters.</p>
</td></tr>
<tr><td><code id="gwet.ac1.dist_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="gwet.ac1.dist_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the following information: pa(the percent agreement),pe(the percent chance agreement),
coeff(Gwet's AC1 or AC2 dependending on whether weights are used or not),stderr(the standard error of Gwet's coefficient),
conf.int(the confidence interval of Gwet's coefficient), p.value(the p-value of Gwet's coefficient),coeff.name (AC1/AC2).
</p>


<h3>Source</h3>

<p>Gwet, K. L. (2008). &ldquo;Computing inter-rater reliability and its variance in the presence of high agreement,&quot; 
<em>British Journal of Mathematical and Statistical Psychology</em>, 61, 29-48.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "distrib.6raters" comes with this package. It represents the distribution of 6 raters 
#by subject and by category. Note that each row of this dataset sums to the number of raters, which
#is 6. You may this dataset as follows:
distrib.6raters
gwet.ac1.dist(distrib.6raters) #AC1 coefficient, precision measures, weights &amp; list of categories
ac1 &lt;- gwet.ac1.dist(distrib.6raters)$coeff #Yields AC1 coefficient alone.
ac1
q &lt;- ncol(distrib.6raters) #Number of categories
gwet.ac1.dist(distrib.6raters,weights = quadratic.weights(1:q)) #AC2 with quadratic weights
</code></pre>

<hr>
<h2 id='gwet.ac1.raw'>Gwet's AC1/AC2 agreement coefficient among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</h2><span id='topic+gwet.ac1.raw'></span>

<h3>Description</h3>

<p>Gwet's AC1/AC2 agreement coefficient among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gwet.ac1.raw(ratings, weights = "unweighted", categ.labels = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gwet.ac1.raw_+3A_ratings">ratings</code></td>
<td>
<p>An nxr matrix / data frame of ratings where each column represents one rater and each row one subject.</p>
</td></tr>
<tr><td><code id="gwet.ac1.raw_+3A_weights">weights</code></td>
<td>
<p>is a mandatory parameter that is either a string variable or a matrix. 
The string describes one of the predefined weights and must take one of the values 
(&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number 
of posssible categories where a subject can be classified. If some of the q possible 
categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ.labels. Otherwise, the program may not work.</p>
</td></tr>
<tr><td><code id="gwet.ac1.raw_+3A_categ.labels">categ.labels</code></td>
<td>
<p>An optional vector parameter containing the list of all possible ratings. It may be useful 
in case some of the possibe ratings are not used by any rater, they will still be used when calculating agreement 
coefficients. The default value is NULL. In this case, only categories reported by the raters are used in the
calculations.</p>
</td></tr>
<tr><td><code id="gwet.ac1.raw_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="gwet.ac1.raw_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data list containing 3 objects: (1) a one-row data frame containing various statistics including the 
requested agreement coefficient, (2) the weight matrix used in the calculations if any, and (3) the categories 
used in the analysis. These could be categories reported by the raters, or those that were available to the raters
whether they used them or not.  The output data frame contains the following variables: &quot;coeff.name&quot; 
(coefficient name), &quot;pa&quot; (the percent agreement), &quot;pe&quot; (the percent chance agreement), coeff.val (the agreement coefficient 
estimate-AC1 or AC2), &quot;coeff.se&quot; (the standard error), &quot;conf.int&quot; (AC1/AC2 confidence interval), &quot;p.value&quot;
(Gwet AC1/AC2 p-value), &quot;w.name&quot;(the weights' identification).
</p>


<h3>References</h3>

<p>Gwet, K. L. (2008). &ldquo;Computing inter-rater reliability and its variance in the presence of high
agreement.&quot; <em>British Journal of Mathematical and Statistical Psychology</em>, 61, 29-48.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cac.raw4raters" comes with this package. Analyze it as follows:
cac.raw4raters
gwet.ac1.raw(cac.raw4raters) #AC1 coefficient, precision measures, weights &amp; categories
gwet.ac1.raw(cac.raw4raters)$est #Yields AC1 coefficient with precision measures
ac1 &lt;- gwet.ac1.raw(cac.raw4raters)$est$coeff.val #Yields AC1 coefficient alone.
ac1
gwet.ac1.raw(cac.raw4raters, weights = "quadratic") #AC2 coefficient with quadratic wts
</code></pre>

<hr>
<h2 id='gwet.ac1.table'>Gwet's AC1/AC2 coefficient for 2 raters</h2><span id='topic+gwet.ac1.table'></span>

<h3>Description</h3>

<p>Gwet's AC1/AC2 coefficient for 2 raters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gwet.ac1.table(ratings, weights = identity.weights(1:ncol(ratings)),
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gwet.ac1.table_+3A_ratings">ratings</code></td>
<td>
<p>A square table of ratings (assume no missing ratings).</p>
</td></tr>
<tr><td><code id="gwet.ac1.table_+3A_weights">weights</code></td>
<td>
<p>An optional matrix that contains the weights used in the weighted analysis. By default, this 
parameter contaings the identity weight matrix, which leads to the unweighted analysis.</p>
</td></tr>
<tr><td><code id="gwet.ac1.table_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter that specifies the confidence level used for constructing confidence 
intervals. By default the function assumes the standard value of 95%.</p>
</td></tr>
<tr><td><code id="gwet.ac1.table_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the finite population size if any. It is used to perform the finite
population correction to the standard error. It's default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the following 5 variables: coeff.name coeff.val coeff.se coeff.ci coeff.pval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cont3x3abstractors" comes with this package. Analyze it as follows:
gwet.ac1.table(cont3x3abstractors) #Yields AC1 along with precision measures
ac1 &lt;- gwet.ac1.table(cont3x3abstractors)$coeff.val #Yields AC1 coefficient alone.
ac1
q &lt;- nrow(cont3x3abstractors) #Number of categories
gwet.ac1.table(cont3x3abstractors,weights = quadratic.weights(1:q)) #AC2 with quadratic weights
</code></pre>

<hr>
<h2 id='identity.weights'>Function for computing the Identity Weights</h2><span id='topic+identity.weights'></span>

<h3>Description</h3>

<p>Function for computing the Identity Weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identity.weights(categ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="identity.weights_+3A_categ">categ</code></td>
<td>
<p>A mandatory parameter representing the vector of all possible ratings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of identity weights to be used for calculating the unweighted coefficients.
</p>

<hr>
<h2 id='kappa2.table'>Kappa coefficient for 2 raters</h2><span id='topic+kappa2.table'></span>

<h3>Description</h3>

<p>Kappa coefficient for 2 raters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kappa2.table(ratings, weights = identity.weights(1:ncol(ratings)),
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kappa2.table_+3A_ratings">ratings</code></td>
<td>
<p>A square or contingency table of ratings (assume no missing ratings). See the 2 datasets 
&quot;cont3x3abstractors&quot; and &quot;cont4x4diagnosis&quot; that come with this package as examples.</p>
</td></tr>
<tr><td><code id="kappa2.table_+3A_weights">weights</code></td>
<td>
<p>An optional matrix that contains the weights used in the weighted analysis.</p>
</td></tr>
<tr><td><code id="kappa2.table_+3A_conflev">conflev</code></td>
<td>
<p>An optional confidence level for confidence intervals. The default value is the traditional 0.95.</p>
</td></tr>
<tr><td><code id="kappa2.table_+3A_n">N</code></td>
<td>
<p>An optional population size.  The default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the following 5 variables: coeff.name coeff.val coeff.se coeff.ci coeff.pval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cont3x3abstractors" comes with this package. Analyze it as follows:
kappa2.table(cont3x3abstractors) #Yields Cohen's kappa along with precision measures
kappa &lt;- kappa2.table(cont3x3abstractors)$coeff.val #Yields Cohen's kappa alone.
kappa
q &lt;- nrow(cont3x3abstractors) #Number of categories
kappa2.table(cont3x3abstractors,weights = quadratic.weights(1:q))#weighted kappa/quadratic wts
</code></pre>

<hr>
<h2 id='krippen.alpha.dist'>Krippendorff's agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</h2><span id='topic+krippen.alpha.dist'></span>

<h3>Description</h3>

<p>Krippendorff's agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>krippen.alpha.dist(ratings, weights = "unweighted", categ = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="krippen.alpha.dist_+3A_ratings">ratings</code></td>
<td>
<p>An <em>nxq</em> matrix / data frame containing the distribution of raters by subject and category. Each cell <em>(i,k)</em> contains the number of raters who classsified subject <em>i</em> into category <em>k</em>.</p>
</td></tr>
<tr><td><code id="krippen.alpha.dist_+3A_weights">weights</code></td>
<td>
<p>is an optional parameter that is either a string variable or a matrix. The string describes one of the predefined 
weights and must take one of the values (&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number of posssible categories where a subject 
can be classified. If some of the q possible categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ. Otherwise, only the categories reported will be used.</p>
</td></tr>
<tr><td><code id="krippen.alpha.dist_+3A_categ">categ</code></td>
<td>
<p>An optional parameter representing all categories available to raters during the experiment. This parameter may be useful if 
some categories were not used by any rater inspite of being available to the raters.</p>
</td></tr>
<tr><td><code id="krippen.alpha.dist_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="krippen.alpha.dist_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the following information: 
pa(the percent agreement),pe(the percent chance agreement),coeff(Krippendorff's alpha),
stderr(the standard error of Krippendorff's coefficient),conf.int(the confidence interval of Krippendorff's alpha coefficient),
p.value(the p-value of Krippendorff's alpha), coeff.name (&quot;krippen alpha&quot;).
</p>


<h3>Source</h3>

<p>Gwet, K. (2014). <em>Handbook of Inter-Rater Reliability: The Definitive Guide to Measuring the Extent of Agreement Among 
Multiple Raters</em>, 4th Edition.  Advanced Analytics, LLC
Krippendorff (1970). &ldquo;Bivariate agreement coefficients for reliability of data,&quot; <em>Sociological Methodology</em>,2,139-150
Krippendorff (1980). <em>Content analysis: An introduction to its methodology (2nd ed.)</em>, New-bury Park, CA: Sage.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "distrib.6raters" comes with this package. It represents the distribution of 6 raters 
#by subject and by category. Note that each row of this dataset sums to the number of raters, which
#is 6. You may this dataset as follows:
distrib.6raters
krippen.alpha.dist(distrib.6raters) #Krippendorff's alpha, precision measures, weights &amp; categories
alpha &lt;- krippen.alpha.dist(distrib.6raters)$coeff #Yields Krippendorff's alpha coefficient alone.
alpha
q &lt;- ncol(distrib.6raters) #Number of categories
krippen.alpha.dist(distrib.6raters,weights = quadratic.weights(1:q)) #Weighted alpha
</code></pre>

<hr>
<h2 id='krippen.alpha.raw'>Krippendorff's alpha coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</h2><span id='topic+krippen.alpha.raw'></span>

<h3>Description</h3>

<p>Krippendorff's alpha coefficient for an arbitrary number of raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>krippen.alpha.raw(ratings, weights = "unweighted", categ.labels = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="krippen.alpha.raw_+3A_ratings">ratings</code></td>
<td>
<p>An nxr matrix / data frame of ratings where each column represents one rater and each row one subject.</p>
</td></tr>
<tr><td><code id="krippen.alpha.raw_+3A_weights">weights</code></td>
<td>
<p>is a mandatory parameter that is either a string variable or a matrix. 
The string describes one of the predefined weights and must take one of the values 
(&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number 
of posssible categories where a subject can be classified. If some of the q possible 
categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ.labels. Otherwise, the program may not work.</p>
</td></tr>
<tr><td><code id="krippen.alpha.raw_+3A_categ.labels">categ.labels</code></td>
<td>
<p>An optional vector parameter containing the list of all possible ratings. It may be useful in 
case some of the possibe ratings are not used by any rater, they will still be used when calculating agreement 
coefficients. The default value is NULL. In this case, only categories reported by the raters are used in the
calculations.</p>
</td></tr>
<tr><td><code id="krippen.alpha.raw_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="krippen.alpha.raw_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data list containing 3 objects: (1) a one-row data frame containing various statistics including the 
requested agreement coefficient-in this case, Krippendorff's alpha, (2) the weight matrix used in the calculations if any, and 
(3) the vector of categories used in the analysis. These could be categories reported by the raters, or those that were available 
to the raters whether they used them or not.  The output data frame contains the following variables: &quot;coeff.name&quot; (coefficient 
name), &quot;pa&quot; (the percent agreement), &quot;pe&quot; (the percent chance agreement), coeff.val (Krippendorff's alpha estimate), &quot;coeff.se 
(standard error), conf.int&quot; (Krippendorff alpha's confidence interval),&quot;p.value&quot; (Krippendorff alpha's p-value), &quot;w.name&quot; 
(the weights' identification).
</p>


<h3>References</h3>

<p>Gwet, K. (2014). <em>Handbook of Inter-Rater Reliability: The Definitive Guide to Measuring the Extent of Agreement Among Multiple Raters</em>, 4th Edition.  Advanced Analytics, LLC.<br /><br />
Krippendorff (1970). &ldquo;Bivariate agreement coefficients for reliability of data.&quot; <em>Sociological Methodology</em>,2,139-150.<br /><br />
Krippendorff (1980). <em>Content analysis: An introduction to its methodology</em> (2nd ed.), New-bury Park, CA: Sage.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cac.raw4raters" comes with this package. Analyze it as follows:
cac.raw4raters
krippen.alpha.raw(cac.raw4raters) #Alpha coeff. , precision measures, weights &amp; categories
krippen.alpha.raw(cac.raw4raters)$est #Krippendorff's alpha with precision measures
alpha &lt;- krippen.alpha.raw(cac.raw4raters)$est$coeff.val #Krippendorff's alpha alone.
alpha
krippen.alpha.raw(cac.raw4raters, weights = "quadratic") #weighted alpha/ quadratic wts
</code></pre>

<hr>
<h2 id='krippen2.table'>Krippendorff's Alpha coefficient for 2 raters</h2><span id='topic+krippen2.table'></span>

<h3>Description</h3>

<p>Krippendorff's Alpha coefficient for 2 raters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>krippen2.table(ratings, weights = identity.weights(1:ncol(ratings)),
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="krippen2.table_+3A_ratings">ratings</code></td>
<td>
<p>A square table of ratings (assume no missing ratings).</p>
</td></tr>
<tr><td><code id="krippen2.table_+3A_weights">weights</code></td>
<td>
<p>An optional matrix that contains the weights used in the weighted analysis. By default, this 
parameter contaings the identity weight matrix, which leads to the unweighted analysis.</p>
</td></tr>
<tr><td><code id="krippen2.table_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter that specifies the confidence level used for constructing confidence 
intervals. By default the function assumes the standard value of 95%.</p>
</td></tr>
<tr><td><code id="krippen2.table_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the finite population size if any. It is used to perform the finite
population correction to the standard error. It's default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the following 5 variables: coeff.name coeff.val coeff.se coeff.ci coeff.pval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cont3x3abstractors" comes with this package. Analyze it as follows:
krippen2.table(cont3x3abstractors) #Krippendorff's alpha along with precision measures
alpha &lt;- krippen2.table(cont3x3abstractors)$coeff.val #Krippendorff's alpha alone.
alpha
q &lt;- nrow(cont3x3abstractors) #Number of categories
krippen2.table(cont3x3abstractors,weights = quadratic.weights(1:q)) #Weighted alpha coefficient
</code></pre>

<hr>
<h2 id='landis.koch'>Dataset describing the Landis &amp; Koch Benchmarking Scale</h2><span id='topic+landis.koch'></span>

<h3>Description</h3>

<p>This dataset contains information describing the Landis &amp; Koch scale for benchmarking chance-corrected agreement 
coefficients such as Gwet AC1/AC2, Kappa and many others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>landis.koch
</code></pre>


<h3>Format</h3>

<p>Each row of this dataset describes an interval and the interpretation of the magnitude it represents.
</p>

<dl>
<dt>lb.LK</dt><dd><p>The interval lower bound</p>
</dd>
<dt>ub.LK</dt><dd><p>The interval upper bound</p>
</dd>
<dt>interp.LK</dt><dd><p>The interpretation</p>
</dd>
</dl>


<h3>Source</h3>

<p>Landis, J.R. &amp; Koch G. (1977). The measurement of observer agreement for categorical data, <em>Biometrics</em>, 
33, 159-174.
</p>

<hr>
<h2 id='landis.koch.bf'>Computing Landis-Koch Benchmark Scale Membership Probabilities</h2><span id='topic+landis.koch.bf'></span>

<h3>Description</h3>

<p>Computing Landis-Koch Benchmark Scale Membership Probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>landis.koch.bf(coeff, se, BenchDF = landis.koch)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="landis.koch.bf_+3A_coeff">coeff</code></td>
<td>
<p>A mandatory parameter representing the estimated value of an agreement coefficient.</p>
</td></tr>
<tr><td><code id="landis.koch.bf_+3A_se">se</code></td>
<td>
<p>A mandatory parameter representing the agreement coefficient standard error.</p>
</td></tr>
<tr><td><code id="landis.koch.bf_+3A_benchdf">BenchDF</code></td>
<td>
<p>An optional parameter that is a 3-column data frame containing the Landis \&amp; Koch's benchmark scale 
information. The 3 columns are the interval lower bound, upper bound, and their interpretation. The default value 
is a small file contained in the package and named <em>landis.koch.RData</em>, which describes the official 
Landis \&amp; Koch's scale intervals and their interpretation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-column matrix containing the membership probabilities (c.f. <a href="http://agreestat.com/research_papers/inter-rater%20reliability%20study%20design1.pdf">http://agreestat.com/research_papers/inter-rater%20reliability%20study%20design1.pdf</a>)
</p>

<hr>
<h2 id='linear.weights'>Function for computing the Linear Weights</h2><span id='topic+linear.weights'></span>

<h3>Description</h3>

<p>Function for computing the Linear Weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linear.weights(categ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="linear.weights_+3A_categ">categ</code></td>
<td>
<p>A mandatory parameter representing the vector of all possible ratings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of quadratic weights to be used for calculating the weighted coefficients.
</p>

<hr>
<h2 id='ordinal.weights'>Function for computing the Ordinal Weights</h2><span id='topic+ordinal.weights'></span>

<h3>Description</h3>

<p>Function for computing the Ordinal Weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordinal.weights(categ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ordinal.weights_+3A_categ">categ</code></td>
<td>
<p>A mandatory parameter representing the vector of all possible ratings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of quadratic weights to be used for calculating the weighted coefficients.
</p>

<hr>
<h2 id='pa.coeff.dist'>Percent agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.</h2><span id='topic+pa.coeff.dist'></span>

<h3>Description</h3>

<p>Percent agreement coefficient among multiple raters (2, 3, +) when the input dataset is the distribution of raters by subject and category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pa.coeff.dist(ratings, weights = "unweighted", categ = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pa.coeff.dist_+3A_ratings">ratings</code></td>
<td>
<p>An <em>nxq</em> matrix / data frame containing the distribution of raters by subject and category. Each cell <em>(i,k)</em> contains the number of raters who classsified subject <em>i</em> into category <em>k</em>.</p>
</td></tr>
<tr><td><code id="pa.coeff.dist_+3A_weights">weights</code></td>
<td>
<p>is an optional parameter that is either a string variable or a matrix. The string describes one of the predefined 
weights and must take one of the values (&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number of posssible categories where a subject 
can be classified. If some of the q possible categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ. Otherwise, only the categories reported will be used.</p>
</td></tr>
<tr><td><code id="pa.coeff.dist_+3A_categ">categ</code></td>
<td>
<p>An optional parameter representing all categories available to raters during the experiment. This parameter may be useful if 
some categories were not used by any rater inspite of being available to the raters.</p>
</td></tr>
<tr><td><code id="pa.coeff.dist_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="pa.coeff.dist_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the following information: 
pa(the percent agreement),pe(the percent chance agreement),coeff(Brennan-Prediger coefficient),
stderr(the standard error of Brennan-Prediger coefficient),conf.int(the p-value of Brennan-Prediger coefficient), 
p.value(the p-value of Brennan-Prediger coefficient),coeff.name (&quot;Brennan-Prediger&quot;).
</p>


<h3>Source</h3>

<p>Brennan, R.L., and Prediger, D. J. (1981). &ldquo;Coefficient Kappa: some uses, misuses, and alternatives,&quot; 
<em>Educational and Psychological Measurement</em>, 41, 687-699.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "distrib.6raters" comes with this package. It represents the distribution of 6 raters 
#by subject and by category. Note that each row of this dataset sums to the number of raters, which
#is 6. You may this dataset as follows:
distrib.6raters
pa.coeff.dist(distrib.6raters) #percent agreement, precision measures, weights&amp; list of categories
pa &lt;- pa.coeff.dist(distrib.6raters)$coeff #Yields the percent agreement coefficient alone.
pa
q &lt;- ncol(distrib.6raters) #Number of categories
pa.coeff.dist(distrib.6raters,weights = quadratic.weights(1:q)) #Weighted percent agreement
</code></pre>

<hr>
<h2 id='pa.coeff.raw'>Percent agreement among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.</h2><span id='topic+pa.coeff.raw'></span>

<h3>Description</h3>

<p>Percent agreement among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pa.coeff.raw(ratings, weights = "unweighted", categ.labels = NULL,
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pa.coeff.raw_+3A_ratings">ratings</code></td>
<td>
<p>An nxr matrix / data frame of ratings where each column represents one rater and each row one subject.</p>
</td></tr>
<tr><td><code id="pa.coeff.raw_+3A_weights">weights</code></td>
<td>
<p>is a mandatory parameter that is either a string variable or a matrix. 
The string describes one of the predefined weights and must take one of the values 
(&quot;quadratic&quot;, &quot;ordinal&quot;, &quot;linear&quot;, &quot;radical&quot;, &quot;ratio&quot;, &quot;circular&quot;, &quot;bipolar&quot;). 
If this parameter is a matrix then it must be a square matri qxq where q is the number 
of posssible categories where a subject can be classified. If some of the q possible 
categories are not used, then it is strobgly advised to specify the complete list of 
possible categories as a vector in parametr categ.labels. Otherwise, the program may not work.</p>
</td></tr>
<tr><td><code id="pa.coeff.raw_+3A_categ.labels">categ.labels</code></td>
<td>
<p>An optional vector parameter containing the list of all possible ratings. It may be useful 
in case some of the possibe ratings are not used by any rater, they will still be used when calculating agreement 
coefficients. The default value is NULL. In this case, only categories reported by the raters are used in the
calculations.</p>
</td></tr>
<tr><td><code id="pa.coeff.raw_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter representing the confidence level associated with the confidence interval. Its default value is 0.95.</p>
</td></tr>
<tr><td><code id="pa.coeff.raw_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the population size (if any). It may be use to perform the final population correction to the variance.  Its default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data list containing 3 objects: (1) a one-row data frame containing the estimates, (2) the weight matrix 
used in the calculations, and (3) the categories used in the analysis.  The data frame of estimates contains the 
following variables &quot;coeff.name&quot; (coefficient name), &quot;pa&quot; (the percent agreement), &quot;pe&quot; (percent chance-agreement-always equals 0),
&quot;coeff.val&quot; (agreement coefficient = pa), coeff.se (the percent agreement standard error), &quot;conf.int&quot; (the percent agreement confidence interval),
&quot;p.value&quot;(the percent agreement p-value), &quot;w.name&quot;(the weights' identification).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cac.raw4raters" comes with this package. Analyze it as follows:
cac.raw4raters
pa.coeff.raw(cac.raw4raters) #Percent agreement, precision measures, weights &amp; categories
pa.coeff.raw(cac.raw4raters)$est #Yields percent agreement with precision measures
pa &lt;- pa.coeff.raw(cac.raw4raters)$est$coeff.val #Yields percent agreement alone.
pa
pa.coeff.raw(cac.raw4raters, weights = "quadratic") #weighted percent agreement/quadratic weights
</code></pre>

<hr>
<h2 id='pa2.table'>Percent Agreement coefficient for 2 raters</h2><span id='topic+pa2.table'></span>

<h3>Description</h3>

<p>Percent Agreement coefficient for 2 raters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pa2.table(ratings, weights = identity.weights(1:ncol(ratings)),
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pa2.table_+3A_ratings">ratings</code></td>
<td>
<p>A square table of ratings (assume no missing ratings).</p>
</td></tr>
<tr><td><code id="pa2.table_+3A_weights">weights</code></td>
<td>
<p>An optional matrix that contains the weights used in the weighted analysis. By default, this 
parameter contaings the identity weight matrix, which leads to the unweighted analysis.</p>
</td></tr>
<tr><td><code id="pa2.table_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter that specifies the confidence level used for constructing confidence 
intervals. By default the function assumes the standard value of 95%.</p>
</td></tr>
<tr><td><code id="pa2.table_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the finite population size if any. It is used to perform the finite
population correction to the standard error. It's default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the following 5 variables: coeff.name coeff.val coeff.se coeff.ci coeff.pval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cont3x3abstractors" comes with this package. Analyze it as follows:
pa2.table(cont3x3abstractors) #Yields percent agreement along with precision measures
pa &lt;- pa2.table(cont3x3abstractors)$coeff.val #Yields percent agreement alone.
pa
q &lt;- nrow(cont3x3abstractors) #Number of categories
pa2.table(cont3x3abstractors,weights = quadratic.weights(1:q)) #Weighted percent agreement
</code></pre>

<hr>
<h2 id='quadratic.weights'>Function for computing the Quadratic Weights</h2><span id='topic+quadratic.weights'></span>

<h3>Description</h3>

<p>Function for computing the Quadratic Weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadratic.weights(categ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quadratic.weights_+3A_categ">categ</code></td>
<td>
<p>A mandatory parameter representing the vector of all possible ratings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of quadratic weights to be used for calculating the weighted coefficients.
</p>

<hr>
<h2 id='radical.weights'>Function for computing the Radical Weights</h2><span id='topic+radical.weights'></span>

<h3>Description</h3>

<p>Function for computing the Radical Weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>radical.weights(categ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="radical.weights_+3A_categ">categ</code></td>
<td>
<p>A mandatory parameter representing the vector of all possible ratings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of quadratic weights to be used for calculating the weighted coefficients.
</p>

<hr>
<h2 id='ratio.weights'>Function for computing the Ratio Weights</h2><span id='topic+ratio.weights'></span>

<h3>Description</h3>

<p>Function for computing the Ratio Weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ratio.weights(categ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ratio.weights_+3A_categ">categ</code></td>
<td>
<p>A mandatory parameter representing the vector of all possible ratings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of quadratic weights to be used for calculating the weighted coefficients.
</p>

<hr>
<h2 id='scott2.table'>Scott's coefficient for 2 raters</h2><span id='topic+scott2.table'></span>

<h3>Description</h3>

<p>Scott's coefficient for 2 raters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scott2.table(ratings, weights = identity.weights(1:ncol(ratings)),
  conflev = 0.95, N = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scott2.table_+3A_ratings">ratings</code></td>
<td>
<p>A square table of ratings (assume no missing ratings).</p>
</td></tr>
<tr><td><code id="scott2.table_+3A_weights">weights</code></td>
<td>
<p>An optional matrix that contains the weights used in the weighted analysis. By default, this parameter contaings the identity weight matrix, which leads to the unweighted analysis.</p>
</td></tr>
<tr><td><code id="scott2.table_+3A_conflev">conflev</code></td>
<td>
<p>An optional parameter that specifies the confidence level used for constructing confidence intervals. By default the function assumes the standard value of 95%.</p>
</td></tr>
<tr><td><code id="scott2.table_+3A_n">N</code></td>
<td>
<p>An optional parameter representing the finite population size if any. It is used to perform the finite population correction to the standard error. It's default value is infinity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the following 5 variables: coeff.name coeff.val coeff.se coeff.ci coeff.pval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The dataset "cont3x3abstractors" comes with this package. Analyze it as follows:
scott2.table(cont3x3abstractors) #Yields Scott's Pi coefficient along with precision measures
scott &lt;- scott2.table(cont3x3abstractors)$coeff.val #Yields Scott's coefficient alone.
scott
q &lt;- nrow(cont3x3abstractors) #Number of categories
scott2.table(cont3x3abstractors,weights = quadratic.weights(1:q)) #weighted Scott's coefficient
</code></pre>

<hr>
<h2 id='trim'>An r function for trimming leading and trealing blanks</h2><span id='topic+trim'></span>

<h3>Description</h3>

<p>An r function for trimming leading and trealing blanks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trim_+3A_x">x</code></td>
<td>
<p>is a string variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string variable where leading and trealing blanks are trimmed.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
