<!DOCTYPE html><html lang="en"><head><title>Help for package personalized</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {personalized}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#check.overlap'><p>Check propensity score overlap</p></a></li>
<li><a href='#create.augmentation.function'><p>Creation of augmentation functions</p></a></li>
<li><a href='#create.propensity.function'><p>Creation of propensity fitting function</p></a></li>
<li><a href='#fit.subgroup'><p>Fitting subgroup identification models</p></a></li>
<li><a href='#LaLonde'><p>National Supported Work Study Data</p></a></li>
<li><a href='#plot.subgroup_fitted'><p>Plotting results for fitted subgroup identification models</p></a></li>
<li><a href='#plotCompare'><p>Plot a comparison results for fitted or validated subgroup identification models</p></a></li>
<li><a href='#predict.subgroup_fitted'><p>Function to predict either benefit scores or treatment recommendations</p></a></li>
<li><a href='#print.individual_treatment_effects'><p>Printing individualized treatment effects</p></a></li>
<li><a href='#print.subgroup_fitted'><p>Printing results for fitted subgroup identification models</p></a></li>
<li><a href='#subgroup.effects'><p>Computes treatment effects within various subgroups</p></a></li>
<li><a href='#summarize.subgroups'><p>Summarizing covariates within estimated subgroups</p></a></li>
<li><a href='#summary.subgroup_fitted'><p>Summary of results for fitted subgroup identification models</p></a></li>
<li><a href='#treatment.effects'><p>Calculation of covariate-conditional treatment effects</p></a></li>
<li><a href='#validate.subgroup'><p>Validating fitted subgroup identification models</p></a></li>
<li><a href='#weighted.ksvm'><p>Fit weighted kernel svm model.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimation and Validation Methods for Subgroup Identification
and Personalized Medicine</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.7</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions for fitting and validation of models for subgroup
    identification and personalized medicine / precision medicine under the general subgroup
    identification framework of Chen et al. (2017) &lt;<a href="https://doi.org/10.1111%2Fbiom.12676">doi:10.1111/biom.12676</a>&gt;.
    This package is intended for use for both randomized controlled trials and
    observational studies and is described in detail in Huling and Yu (2021) 
    &lt;<a href="https://doi.org/10.18637%2Fjss.v098.i05">doi:10.18637/jss.v098.i05</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://jaredhuling.org/personalized/">https://jaredhuling.org/personalized/</a>,
<a href="https://arxiv.org/abs/1809.07905">https://arxiv.org/abs/1809.07905</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jaredhuling/personalized/issues">https://github.com/jaredhuling/personalized/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, nnet</td>
</tr>
<tr>
<td>Imports:</td>
<td>survival, methods, kernlab, foreach, xgboost</td>
</tr>
<tr>
<td>Depends:</td>
<td>glmnet (&ge; 2.0-13), mgcv, ggplot2, plotly</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-27 18:11:34 UTC; huling</td>
</tr>
<tr>
<td>Author:</td>
<td>Jared Huling <a href="https://orcid.org/0000-0003-0670-4845"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Aaron Potvien [ctb],
  Alexandros Karatzoglou [cph],
  Alex Smola [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jared Huling &lt;jaredhuling@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-27 20:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='check.overlap'>Check propensity score overlap</h2><span id='topic+check.overlap'></span>

<h3>Description</h3>

<p>Results in a plot to check whether the propensity score has adequate overlap between treatment groups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.overlap(
  x,
  trt,
  propensity.func,
  type = c("histogram", "density", "both"),
  bins = 50L,
  alpha = ifelse(type == "both", 0.35, 0.5)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.overlap_+3A_x">x</code></td>
<td>
<p>The design matrix (not including intercept term)</p>
</td></tr>
<tr><td><code id="check.overlap_+3A_trt">trt</code></td>
<td>
<p>treatment vector with each element equal to a 0 or a 1, with 1 indicating
treatment status is active.</p>
</td></tr>
<tr><td><code id="check.overlap_+3A_propensity.func">propensity.func</code></td>
<td>
<p>function that inputs the design matrix x and the treatment vector trt and outputs
the propensity score, ie Pr(trt = 1 | X = x). Function should take two arguments 1) x and 2) trt. See example below.
For a randomized controlled trial this can simply be a function that returns a constant equal to the proportion
of patients assigned to the treatment group, i.e.:
<code>propensity.func = function(x, trt) 0.5</code>.</p>
</td></tr>
<tr><td><code id="check.overlap_+3A_type">type</code></td>
<td>
<p>Type of plot to create. Options are either a histogram (<code>type = "histogram"</code>) for each treatment
group, a density (<code>type = "density"</code>) for each treatment group, or to plot both a density and histogram
(<code>type = "code"</code>)</p>
</td></tr>
<tr><td><code id="check.overlap_+3A_bins">bins</code></td>
<td>
<p>integer number of bins for histograms when <code>type = "histogram"</code></p>
</td></tr>
<tr><td><code id="check.overlap_+3A_alpha">alpha</code></td>
<td>
<p>value between 0 and 1 indicating transparency level (1 for solid, 0 for fully transparent)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 250
n.vars &lt;- 15
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.25 + 0.5 * x[,11] - 0.5 * x[,12]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

# create function for fitting propensity score model
prop.func &lt;- function(x, trt)
{
    # fit propensity score model
    propens.model &lt;- cv.glmnet(y = trt,
                               x = x, family = "binomial")
    pi.x &lt;- predict(propens.model, s = "lambda.min",
                    newx = x, type = "response")[,1]
    pi.x
}

check.overlap(x = x,
              trt = trt01,
              propensity.func = prop.func)

# now add density plot with histogram
check.overlap(x = x,
              trt = trt01,
              type = "both",
              propensity.func = prop.func)


# simulated non-randomized treatment with multiple levels
xbetat_1   &lt;- 0.15 + 0.5 * x[,9] - 0.25 * x[,12]
xbetat_2   &lt;- 0.15 - 0.5 * x[,11] + 0.25 * x[,15]
trt.1.prob &lt;- exp(xbetat_1) / (1 + exp(xbetat_1) + exp(xbetat_2))
trt.2.prob &lt;- exp(xbetat_2) / (1 + exp(xbetat_1) + exp(xbetat_2))
trt.3.prob &lt;- 1 - (trt.1.prob + trt.2.prob)
prob.mat &lt;- cbind(trt.1.prob, trt.2.prob, trt.3.prob)
trt    &lt;- apply(prob.mat, 1, function(rr) rmultinom(1, 1, prob = rr))
trt    &lt;- apply(trt, 2, function(rr) which(rr == 1))

# use multinomial logistic regression model with lasso penalty for propensity
propensity.multinom.lasso &lt;- function(x, trt)
{
    if (!is.factor(trt)) trt &lt;- as.factor(trt)
    gfit &lt;- cv.glmnet(y = trt, x = x, family = "multinomial")

    # predict returns a matrix of probabilities:
    # one column for each treatment level
    propens &lt;- drop(predict(gfit, newx = x, type = "response", s = "lambda.min",
                            nfolds = 5, alpha = 0))

    # return the probability corresponding to the
    # treatment that was observed
    probs &lt;- propens[,match(levels(trt), colnames(propens))]

    probs
}

check.overlap(x = x,
              trt = trt,
              type = "histogram",
              propensity.func = propensity.multinom.lasso)



</code></pre>

<hr>
<h2 id='create.augmentation.function'>Creation of augmentation functions</h2><span id='topic+create.augmentation.function'></span>

<h3>Description</h3>

<p>Creates an augmentation function that optionally utilizes cross-fitting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.augmentation.function(
  family,
  crossfit = TRUE,
  nfolds.crossfit = 10,
  cv.glmnet.args = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create.augmentation.function_+3A_family">family</code></td>
<td>
<p>The response type (see options in <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> help file)</p>
</td></tr>
<tr><td><code id="create.augmentation.function_+3A_crossfit">crossfit</code></td>
<td>
<p>A logical value indicating whether to use cross-fitting (<code>TRUE</code>) or not (<code>FALSE</code>).
Cross-fitting is more computationally intensive, but helps to prevent overfitting, see Chernozhukov, et al. (2018)</p>
</td></tr>
<tr><td><code id="create.augmentation.function_+3A_nfolds.crossfit">nfolds.crossfit</code></td>
<td>
<p>An integer specifying the number of folds to use for cross-fitting. Must be greater than 1</p>
</td></tr>
<tr><td><code id="create.augmentation.function_+3A_cv.glmnet.args">cv.glmnet.args</code></td>
<td>
<p>A list of NAMED arguments to pass to the <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code> function. For
example, <code>cv.glmnet.args = list(type.measure = "mse", nfolds = 10)</code>. See <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code> and <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
for all possible options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function which can be passed to the <code>augment.func</code> argument of the <code><a href="#topic+fit.subgroup">fit.subgroup</a></code> function.
</p>


<h3>References</h3>

<p>Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., &amp; Robins, J. (2018).
Double/debiased machine learning for treatment and structural parameters <a href="https://arxiv.org/abs/1608.00060">https://arxiv.org/abs/1608.00060</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for estimating ITRs and <code><a href="#topic+create.propensity.function">create.propensity.function</a></code> for creation of propensity functions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 500
n.vars &lt;- 15
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,7] - 0.5 * x[,9]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
# delta below drives treatment effect heterogeneity
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12] )
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13] + 0.5 * x[,15] ^ 2
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

aug.func &lt;- create.augmentation.function(family = "gaussian",
                                         crossfit = TRUE,
                                         nfolds.crossfit = 10,
                                         cv.glmnet.args = list(type.measure = "mae",
                                                               nfolds = 5))

prop.func &lt;- create.propensity.function(crossfit = TRUE,
                                        nfolds.crossfit = 10,
                                        cv.glmnet.args = list(type.measure = "auc",
                                                              nfolds = 5))
## Not run: 
subgrp.model &lt;- fit.subgroup(x = x, y = y,
                             trt = trt01,
                             propensity.func = prop.func,
                             augment.func = aug.func,
                             loss   = "sq_loss_lasso",
                             nfolds = 10)    # option for cv.glmnet (for ITR estimation)

summary(subgrp.model)

## End(Not run)

</code></pre>

<hr>
<h2 id='create.propensity.function'>Creation of propensity fitting function</h2><span id='topic+create.propensity.function'></span>

<h3>Description</h3>

<p>Creates an propensity function that optionally utilizes cross-fitting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.propensity.function(
  crossfit = TRUE,
  nfolds.crossfit = 10,
  cv.glmnet.args = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create.propensity.function_+3A_crossfit">crossfit</code></td>
<td>
<p>A logical value indicating whether to use cross-fitting (<code>TRUE</code>) or not (<code>FALSE</code>).
Cross-fitting is more computationally intensive, but helps to prevent overfitting, see Chernozhukov, et al. (2018)</p>
</td></tr>
<tr><td><code id="create.propensity.function_+3A_nfolds.crossfit">nfolds.crossfit</code></td>
<td>
<p>An integer specifying the number of folds to use for cross-fitting. Must be greater than 1</p>
</td></tr>
<tr><td><code id="create.propensity.function_+3A_cv.glmnet.args">cv.glmnet.args</code></td>
<td>
<p>A list of NAMED arguments to pass to the <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code> function. For
example, <code>cv.glmnet.args = list(type.measure = "mse", nfolds = 10)</code>. See <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code> and <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
for all possible options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function which can be passed to the <code>augment.func</code> argument of the <code><a href="#topic+fit.subgroup">fit.subgroup</a></code> function.
</p>


<h3>References</h3>

<p>Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., &amp; Robins, J. (2018).
Double/debiased machine learning for treatment and structural parameters <a href="https://arxiv.org/abs/1608.00060">https://arxiv.org/abs/1608.00060</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for estimating ITRs and <code><a href="#topic+create.propensity.function">create.propensity.function</a></code> for creation of propensity functions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 500
n.vars &lt;- 15
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,7] - 0.5 * x[,9]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
# delta below drives treatment effect heterogeneity
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12] )
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13] + 0.5 * x[,15] ^ 2
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

aug.func &lt;- create.augmentation.function(family = "gaussian",
                                         crossfit = TRUE,
                                         nfolds.crossfit = 10,
                                         cv.glmnet.args = list(type.measure = "mae",
                                                               nfolds = 5))

prop.func &lt;- create.propensity.function(crossfit = TRUE,
                                        nfolds.crossfit = 10,
                                        cv.glmnet.args = list(type.measure = "mae",
                                                              nfolds = 5))

subgrp.model &lt;- fit.subgroup(x = x, y = y,
                             trt = trt01,
                             propensity.func = prop.func,
                             augment.func = aug.func,
                             loss   = "sq_loss_lasso",
                             nfolds = 10)    # option for cv.glmnet (for ITR estimation)

summary(subgrp.model)

</code></pre>

<hr>
<h2 id='fit.subgroup'>Fitting subgroup identification models</h2><span id='topic+fit.subgroup'></span>

<h3>Description</h3>

<p>Fits subgroup identification model class of Chen, et al (2017)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.subgroup(
  x,
  y,
  trt,
  propensity.func = NULL,
  loss = c("sq_loss_lasso", "logistic_loss_lasso", "poisson_loss_lasso",
    "cox_loss_lasso", "owl_logistic_loss_lasso", "owl_logistic_flip_loss_lasso",
    "owl_hinge_loss", "owl_hinge_flip_loss", "sq_loss_lasso_gam",
    "poisson_loss_lasso_gam", "logistic_loss_lasso_gam", "sq_loss_gam",
    "poisson_loss_gam", "logistic_loss_gam", "owl_logistic_loss_gam",
    "owl_logistic_flip_loss_gam", "owl_logistic_loss_lasso_gam",
    "owl_logistic_flip_loss_lasso_gam", "sq_loss_xgboost", "custom"),
  method = c("weighting", "a_learning"),
  match.id = NULL,
  augment.func = NULL,
  fit.custom.loss = NULL,
  cutpoint = 0,
  larger.outcome.better = TRUE,
  reference.trt = NULL,
  retcall = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.subgroup_+3A_x">x</code></td>
<td>
<p>The design matrix (not including intercept term)</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_y">y</code></td>
<td>
<p>The response vector</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_trt">trt</code></td>
<td>
<p>treatment vector with each element equal to a 0 or a 1, with 1 indicating
treatment status is active.</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_propensity.func">propensity.func</code></td>
<td>
<p>function that inputs the design matrix x and the treatment vector trt and outputs
the propensity score, ie Pr(trt = 1 | X = x). Function should take two arguments 1) x and 2) trt. See example below.
For a randomized controlled trial this can simply be a function that returns a constant equal to the proportion
of patients assigned to the treatment group, i.e.:
<code>propensity.func = function(x, trt) 0.5</code>.</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_loss">loss</code></td>
<td>
<p>choice of both the M function from Chen, et al (2017) and potentially the penalty used for variable selection.
All <code>loss</code> options starting with <code>sq_loss</code> use M(y, v) = (v - y) ^ 2, all options starting with <code>logistic_loss</code> use
the logistic loss: M(y, v) = y * log(1 + exp{-v}), and all options starting with <code>cox_loss</code> use the negative partial likelihood loss for the Cox PH model.
All options ending with <code>lasso</code> have a lasso penalty added to the loss for variable selection. <code>sq_loss_lasso_gam</code>
and <code>logistic_loss_lasso_gam</code> first use the lasso to select variables and then fit a generalized additive model
with nonparametric additive terms for each selected variable. <code>sq_loss_gam</code> involves a squared error loss with a generalized additive model and no variable selection.
<code>sq_loss_xgboost</code> involves a squared error loss with a gradient-boosted decision trees model using <code>xgboost</code> for the benefit score; this
allows for flexible estimation using machine learning and can be useful when the underlying treatment-covariate interaction is complex. Must specify
<code>params</code>, <code>nrounds</code>, <code>nfold</code>, and optionally, <code>early_stopping_rounds</code>; see <code><a href="xgboost.html#topic+xgb.train">xgb.train</a></code> for details
</p>

<ul>
<li><p><strong>Continuous Outcomes</strong>
</p>

<ul>
<li><p><code>"sq_loss_lasso"</code> - M(y, v) = (v - y) ^ 2 with linear model and lasso penalty
</p>
</li>
<li><p><code>"owl_logistic_loss_lasso"</code>  - M(y, v) = ylog(1 + exp{-v}) (method of Regularized Outcome Weighted Subgroup Identification)
</p>
</li>
<li><p><code>"owl_logistic_flip_loss_lasso"</code>  - M(y, v) = |y|log(1 + exp{-sign(y)v})
</p>
</li>
<li><p><code>"owl_hinge_loss"</code>  - M(y, v) = ymax(0, 1 - v) (method of Estimating individualized treatment rules using outcome weighted learning)
</p>
</li>
<li><p><code>"owl_hinge_flip_loss"</code>  - M(y, v) = |y|max(0, 1 - sign(y)v) 
</p>
</li>
<li><p><code>"sq_loss_lasso_gam"</code> - M(y, v) = (v - y) ^ 2 with variables selected by lasso penalty and generalized additive model fit on the selected variables
</p>
</li>
<li><p><code>"sq_loss_gam"</code> - M(y, v) = (v - y) ^ 2 with generalized additive model fit on all variables
</p>
</li>
<li><p><code>"owl_logistic_loss_gam"</code>  - M(y, v) = ylog(1 + exp{-v}) with generalized additive model fit on all variables
</p>
</li>
<li><p><code>"owl_logistic_flip_loss_gam"</code>  - M(y, v) = |y|log(1 + exp{-sign(y)v}) with generalized additive model fit on all variables
</p>
</li>
<li><p><code>"owl_logistic_loss_lasso_gam"</code>  - M(y, v) = ylog(1 + exp{-v}) with variables selected by lasso penalty and generalized additive model fit on the selected variables
</p>
</li>
<li><p><code>"owl_logistic_flip_loss_lasso_gam"</code>  - M(y, v) = |y|log(1 + exp{-sign(y)v}) with variables selected by lasso penalty and generalized additive model fit on the selected variables
</p>
</li>
<li><p><code>"sq_loss_xgboost"</code> - M(y, v) = (v - y) ^ 2 with gradient-boosted decision trees model
</p>
</li></ul>

</li>
<li><p><strong>Binary Outcomes</strong>
</p>

<ul>
<li><p>All losses for continuous outcomes can be used plus the following:
</p>
</li>
<li><p><code>"logistic_loss_lasso"</code> - M(y, v) = -[yv - log(1 + exp{-v})] with with linear model and lasso penalty
</p>
</li>
<li><p><code>"logistic_loss_lasso_gam"</code> - M(y, v) = -[yv - log(1 + exp{-v})] with variables selected by lasso penalty and generalized additive model fit on the selected variables
</p>
</li>
<li><p><code>"logistic_loss_gam"</code> - M(y, v) = -[yv - log(1 + exp{-v})] with generalized additive model fit on all variables
</p>
</li></ul>

</li>
<li><p><strong>Count Outcomes</strong>
</p>

<ul>
<li><p>All losses for continuous outcomes can be used plus the following:
</p>
</li>
<li><p><code>"poisson_loss_lasso"</code> - M(y, v) = -[yv - exp(v)] with with linear model and lasso penalty
</p>
</li>
<li><p><code>"poisson_loss_lasso_gam"</code> - M(y, v) = -[yv - exp(v)] with variables selected by lasso penalty and generalized additive model fit on the selected variables
</p>
</li>
<li><p><code>"poisson_loss_gam"</code> - M(y, v) = -[yv - exp(v)] with generalized additive model fit on all variables
</p>
</li></ul>

</li>
<li><p><strong>Time-to-Event Outcomes</strong>
</p>

<ul>
<li><p><code>"cox_loss_lasso"</code> - M corresponds to the negative partial likelihood of the cox model with linear model and additionally a lasso penalty
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_method">method</code></td>
<td>
<p>subgroup ID model type. Either the weighting or A-learning method of Chen et al, (2017)</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_match.id">match.id</code></td>
<td>
<p>a (character, factor, or integer) vector with length equal to the number of observations in <code>x</code> indicating using integers or
levels of a factor vector which patients are
in which matched groups. Defaults to <code>NULL</code> and assumes the samples are not from a matched cohort. Matched
case-control groups can be created using any method (propensity score matching, optimal matching, etc). If each case
is matched with a control or multiple controls, this would indicate which case-control pairs or groups go together.
If <code>match.id</code> is supplied, then it is unecessary to specify a function via the <code>propensity.func</code> argument.
A quick usage example: if the first patient is a case and the second and third are controls matched to it, and the
fouth patient is a case and the fifth through seventh patients are matched with it, then the user should specify
<code>match.id = c(1,1,1,2,2,2,2)</code> or <code>match.id = c(rep("Grp1", 3),rep("Grp2", 4)) </code></p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_augment.func">augment.func</code></td>
<td>
<p>function which inputs the response <code>y</code>, the covariates <code>x</code>, and <code>trt</code> and outputs
predicted values (on the link scale) for the response using a model constructed with <code>x</code>. <code>augment.func()</code> can also be simply
a function of <code>x</code> and <code>y</code>. This function is used for efficiency augmentation.
When the form of the augmentation function is correct, it can provide efficient estimation of the subgroups. Some examples of possible
augmentation functions are:
</p>
<p>Example 1: <code>augment.func &lt;- function(x, y) {lmod &lt;- lm(y ~ x); return(fitted(lmod))}</code>
</p>
<p>Example 2:
</p>
<pre>
augment.func &lt;- function(x, y, trt) {
    data &lt;- data.frame(x, y, trt)
    lmod &lt;- lm(y ~ x * trt)
    ## get predictions when trt = 1
    data$trt &lt;- 1
    preds_1  &lt;- predict(lmod, data)

    ## get predictions when trt = -1
    data$trt &lt;- -1
    preds_n1 &lt;- predict(lmod, data)

    ## return predictions averaged over trt
    return(0.5 * (preds_1 + preds_n1))
}
</pre>
<p>For binary and time-to-event outcomes, make sure that predictions are returned on the scale of the predictors
</p>
<p>Example 3:
</p>
<pre>augment.func &lt;- function(x, y) {
        bmod &lt;- glm(y ~ x, family = binomial())
        return(predict(bmod, type = "link"))
    }
 </pre></td></tr>
<tr><td><code id="fit.subgroup_+3A_fit.custom.loss">fit.custom.loss</code></td>
<td>
<p>A function which <em>minimizes</em> a user-specified
custom loss function M(y,v) to be used in model fitting.
If provided, <code>fit.custom.loss</code> should take the modified
design matrix (which includes an intercept term)
as an argument and the responses and optimize a
custom weighted loss function.
</p>
<p>The loss function <code class="reqn">M(y, v)</code> to be minimized <strong>MUST</strong> meet
the following two criteria:
</p>

<ol>
<li> <p><code class="reqn">D_M(y, v) = \partial M(y, v)/\partial v </code> must be increasing in v for each fixed y. <code class="reqn">D_M(y, v)</code> is the partial
derivative of the loss function M(y, v) with respect to v
</p>
</li>
<li> <p><code class="reqn">D_M(y, 0)</code> is monotone in y
</p>
</li></ol>

<p>An example of a valid loss function is <code class="reqn">M(y, v) = (y - v)^2</code>. In this case <code class="reqn">D_M(y, v) = -2(y - v)</code>.
See Chen et al. (2017) for more details on the
restrictions on the loss function <code class="reqn">M(y, v)</code>.
</p>
<p>The provided function <strong>MUST</strong> return a list with the following elements:
</p>

<ul>
<li><p><code>predict</code> a function that inputs a design matrix and a 'type' argument for the type of predictions and outputs
a vector of predictions on the scale of the linear predictor. Note that the matrix provided to 'fit.custom.loss'
has a column appended to the first column of <code>x</code> corresponding to the treatment main effect.
Thus, the prediction function should deal with this,
e.g. <code>predict(model, cbind(1, x))</code>
</p>
</li>
<li><p><code>model</code>  a fitted model object returned by the underlying fitting function
</p>
</li>
<li><p><code>coefficients</code> if the underlying fitting function yields a vector of coefficient estimates, they should be provided here
</p>
</li></ul>

<p>The provided function <strong>MUST</strong> be a function
with the following arguments:
</p>

<ol>
<li><p><code>x</code> design matrix
</p>
</li>
<li><p><code>y</code> vector of responses
</p>
</li>
<li><p><code>weights</code> vector for observations weights. The underlying loss function <strong>MUST</strong> have samples weighted according
to this vector. See below example
</p>
</li>
<li><p><code>...</code> additional arguments passed via '<code>...</code>'. This can be used so that users can specify more arguments to the
underlying fitting function if so desired.
</p>
</li></ol>

<p>The provided function can also optionally take the following arguments:
</p>

<ul>
<li><p><code>match.id</code> vector of case/control cluster IDs. This is useful if cross validation is used in the underlying fitting function
in which case it is advisable to sample whole clusters randomly instead of individual observations.
</p>
</li>
<li><p><code>offset</code> if efficiency augmentation is used, the predictions from the outcome model from <code>augment.func</code>
will be provided via the <code>offset</code> argument, which can be used as an offset in the underlying fitting function
as a means of incorporating the efficiency augmentation model's predictions
</p>
</li>
<li><p><code>trt</code> vector of treatment statuses
</p>
</li>
<li><p><code>family</code> family of outcome
</p>
</li>
<li><p><code>n.trts</code> numer of treatment levels. Can be useful if there are more than 2 treatment levels
</p>
</li></ul>

<p>Example 1: Here we minimize <code class="reqn">M(y, v) = (y - v)^2</code>
</p>
<pre>
 fit.custom.loss &lt;- function(x, y, weights, ...) {
     df &lt;- data.frame(y = y, x)

     # minimize squared error loss with NO lasso penalty
     lmf &lt;- lm(y ~ x - 1, weights = weights,
               data = df, ...)

     # save coefficients
     cfs = coef(lmf)

     # create prediction function. Notice
     # how a column of 1's is appended
     # to ensure treatment main effects are included
     # in predictions
     prd = function(x, type = "response")
     {
         dfte &lt;- cbind(1, x)
         colnames(dfte) &lt;- names(cfs)
         predict(lmf, data.frame(dfte))
     }
     # return lost of required components
     list(predict = prd, model = lmf, coefficients = cfs)
 }
 </pre>
<p>Example 2: <code class="reqn">M(y, v) = y\exp(-v)</code>
</p>
<pre>
 fit.expo.loss &lt;- function(x, y, weights, ...)
 {
     ## define loss function to be minimized
     expo.loss &lt;- function(beta, x, y, weights) {
         sum(weights * y * exp(-drop(tcrossprod(x, t(beta) )))
     }

     # use optim() to minimize loss function
     opt &lt;- optim(rep(0, NCOL(x)), fn = expo.loss, x = x, y = y, weights = weights)

     coefs &lt;- opt$par

     pred &lt;- function(x, type = "response") {
         tcrossprod(cbind(1, x), t(coefs))
     }

     # return list of required components
     list(predict = pred, model = opt, coefficients = coefs)
 }
 </pre></td></tr>
<tr><td><code id="fit.subgroup_+3A_cutpoint">cutpoint</code></td>
<td>
<p>numeric value for patients with benefit scores above which
(or below which if <code>larger.outcome.better = FALSE</code>)
will be recommended to be in the treatment group. Can also set <code>cutpoint = "median"</code>, which will
use the median value of the benefit scores as the cutpoint or can set specific quantile values via <code>"quantx"</code>
where <code>"x"</code> is a number between 0 and 100 representing the quantile value; e.g. <code>cutpoint = "quant75"</code>
will use the 75th perent upper quantile of the benefit scores as the quantile.</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_larger.outcome.better">larger.outcome.better</code></td>
<td>
<p>boolean value of whether a larger outcome is better/preferable. Set to <code>TRUE</code>
if a larger outcome is better/preferable and set to <code>FALSE</code> if a smaller outcome is better/preferable. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_reference.trt">reference.trt</code></td>
<td>
<p>which treatment should be treated as the reference treatment. Defaults to the first level of <code>trt</code>
if <code>trt</code> is a factor or the first alphabetical or numerically first treatment level. Not used for multiple treatment fitting with OWL-type losses.</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_retcall">retcall</code></td>
<td>
<p>boolean value. if <code>TRUE</code> then the passed arguments will be saved. Do not set to <code>FALSE</code>
if the <code>validate.subgroup()</code> function will later be used for your fitted subgroup model. Only set to <code>FALSE</code>
if memory is limited as setting to <code>TRUE</code> saves the design matrix to the fitted object</p>
</td></tr>
<tr><td><code id="fit.subgroup_+3A_...">...</code></td>
<td>
<p>options to be passed to underlying fitting function. For all <code>loss</code> options with 'lasso',
this will be passed to <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>. For all <code>loss</code> options with 'gam', this will
be passed to <code><a href="mgcv.html#topic+gam">gam</a></code> from the <span class="pkg">mgcv</span> package
Note that for all <code>loss</code> options that use <code>gam()</code>
from the <span class="pkg">mgcv</span> package,
the user cannot supply the <code>gam</code> argument <code>method</code> because it is also an argument of <code>fit.subgroup</code>, so
instead, to change the <code>gam method</code> argument, supply <code>method.gam</code>, ie <code>method.gam = "REML"</code>.
</p>
<p>For all <code>loss</code> options with 'hinge', this will be passed to both <code><a href="#topic+weighted.ksvm">weighted.ksvm</a></code> and
<code><a href="kernlab.html#topic+ipop">ipop</a></code> from the <span class="pkg">kernlab</span> package</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"subgroup_fitted"</code>.
</p>
<table role = "presentation">
<tr><td><code>predict</code></td>
<td>
<p>A function that returns predictions of the covariate-conditional treatment effects </p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>An object returned by the underlying fitting function used. For example, if the lasso use used to fit
the underlying subgroup identification model, this will be an object returned by <code>cv.glmnet</code>. </p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p> If the underlying subgroup identification model is parametric, <code>coefficients</code> will contain
the estimated coefficients of the model. </p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produced the returned object. If <code>retcall = TRUE</code>, this will contain all objects
supplied to <code>fit.subgroup()</code></p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>The family corresponding to the outcome provided</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>The loss function used</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The method used (either weighting or A-learning)</p>
</td></tr>
<tr><td><code>propensity.func</code></td>
<td>
<p>The propensity score function used</p>
</td></tr>
<tr><td><code>larger.outcome.better</code></td>
<td>
<p>If larger outcomes are preferred for this model</p>
</td></tr>
<tr><td><code>cutpoint</code></td>
<td>
<p>Benefit score cutoff value used for determining subgroups</p>
</td></tr>
<tr><td><code>var.names</code></td>
<td>
<p>The names of all variables used</p>
</td></tr>
<tr><td><code>n.trts</code></td>
<td>
<p>The number of treatment levels</p>
</td></tr>
<tr><td><code>comparison.trts</code></td>
<td>
<p>All treatment levels other than the reference level</p>
</td></tr>
<tr><td><code>reference.trt</code></td>
<td>
<p>The reference level for the treatment. This should usually be the control group/level</p>
</td></tr>
<tr><td><code>trts</code></td>
<td>
<p>All treatment levels</p>
</td></tr>
<tr><td><code>trt.received</code></td>
<td>
<p>The vector of treatment assignments</p>
</td></tr>
<tr><td><code>pi.x</code></td>
<td>
<p>A vector of propensity scores</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>A vector of outcomes</p>
</td></tr>
<tr><td><code>benefit.scores</code></td>
<td>
<p>A vector of conditional treatment effects, i.e. benefit scores</p>
</td></tr>
<tr><td><code>recommended.trts</code></td>
<td>
<p>A vector of treatment recommendations (i.e. for each patient,
which treatment results in the best expected potential outcomes)</p>
</td></tr>
<tr><td><code>subgroup.trt.effects</code></td>
<td>
<p>(Biased) estimates of the conditional treatment effects
and conditional outcomes. These are essentially just empirical averages within
different combinations of treatment assignments and treatment recommendations</p>
</td></tr>
<tr><td><code>individual.trt.effects</code></td>
<td>
<p>estimates of the individual treatment effects as returned by
<code><a href="#topic+treat.effects">treat.effects</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Huling. J.D. and Yu, M. (2021), Subgroup Identification Using the personalized Package.
Journal of Statistical Software 98(5), 1-60. doi:10.18637/jss.v098.i05
</p>
<p>Chen, S., Tian, L., Cai, T. and Yu, M. (2017), A general statistical framework for subgroup identification
and comparative treatment scoring. Biometrics. doi:10.1111/biom.12676 <a href="https://doi.org/10.1111/biom.12676">doi:10.1111/biom.12676</a>
</p>
<p>Xu, Y., Yu, M., Zhao, Y. Q., Li, Q., Wang, S., &amp; Shao, J. (2015),
Regularized outcome weighted subgroup identification for differential treatment effects. Biometrics, 71(3), 645-653.
doi: 10.1111/biom.12322 <a href="https://doi.org/10.1111/biom.12322">doi:10.1111/biom.12322</a>
</p>
<p>Zhao, Y., Zeng, D., Rush, A. J., &amp; Kosorok, M. R. (2012),
Estimating individualized treatment rules using outcome weighted learning.
Journal of the American Statistical Association, 107(499), 1106-1118. doi: 10.1080/01621459.2012.695674
</p>


<h3>See Also</h3>

<p><code><a href="#topic+validate.subgroup">validate.subgroup</a></code> for function which creates validation results for subgroup
identification models, <code><a href="#topic+predict.subgroup_fitted">predict.subgroup_fitted</a></code> for a prediction function for fitted models
from <code>fit.subgroup</code>, <code><a href="#topic+plot.subgroup_fitted">plot.subgroup_fitted</a></code> for a function which plots
results from fitted models, and <code><a href="#topic+print.subgroup_fitted">print.subgroup_fitted</a></code>
for arguments for printing options for <code>fit.subgroup()</code>.
from <code>fit.subgroup</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 500
n.vars &lt;- 15
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,7] - 0.5 * x[,9]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
# delta below drives treatment effect heterogeneity
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12] )
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13] + 0.5 * x[,15] ^ 2
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

# binary outcomes
y.binary &lt;- 1 * (xbeta + rnorm(n.obs, sd = 2) &gt; 0 )

# count outcomes
y.count &lt;- round(abs(xbeta + rnorm(n.obs, sd = 2)))

# time-to-event outcomes
surv.time &lt;- exp(-20 - xbeta + rnorm(n.obs, sd = 1))
cens.time &lt;- exp(rnorm(n.obs, sd = 3))
y.time.to.event  &lt;- pmin(surv.time, cens.time)
status           &lt;- 1 * (surv.time &lt;= cens.time)

# create function for fitting propensity score model
prop.func &lt;- function(x, trt)
{
    # fit propensity score model
    propens.model &lt;- cv.glmnet(y = trt,
                               x = x, family = "binomial")
    pi.x &lt;- predict(propens.model, s = "lambda.min",
                    newx = x, type = "response")[,1]
    pi.x
}


####################  Continuous outcomes ################################


subgrp.model &lt;- fit.subgroup(x = x, y = y,
                           trt = trt01,
                           propensity.func = prop.func,
                           loss   = "sq_loss_lasso",
                           # option for cv.glmnet,
                           # better to use 'nfolds=10'
                           nfolds = 3)

summary(subgrp.model)

# estimates of the individual-specific
# treatment effect estimates:
subgrp.model$individual.trt.effects

# fit lasso + gam model with REML option for gam


subgrp.modelg &lt;- fit.subgroup(x = x, y = y,
                            trt = trt01,
                            propensity.func = prop.func,
                            loss   = "sq_loss_lasso_gam",
                            method.gam = "REML",     # option for gam
                            nfolds = 5)              # option for cv.glmnet

subgrp.modelg


####################  Using an augmentation function #####################
## augmentation funcions involve modeling the conditional mean E[Y|T, X]
## and returning predictions that are averaged over the treatment values
## return &lt;- 1/2 * (hat{E}[Y|T=1, X] + hat{E}[Y|T=-1, X])
##########################################################################

augment.func &lt;- function(x, y, trt) {
    data &lt;- data.frame(x, y, trt)
    xm &lt;- model.matrix(y~trt*x-1, data = data)

    lmod &lt;- cv.glmnet(y = y, x = xm)
    ## get predictions when trt = 1
    data$trt &lt;- 1
    xm &lt;- model.matrix(y~trt*x-1, data = data)
    preds_1  &lt;- predict(lmod, xm, s = "lambda.min")

    ## get predictions when trt = -1
    data$trt &lt;- -1
    xm &lt;- model.matrix(y~trt*x-1, data = data)
    preds_n1  &lt;- predict(lmod, xm, s = "lambda.min")

    ## return predictions averaged over trt
    return(0.5 * (preds_1 + preds_n1))
}


subgrp.model.aug &lt;- fit.subgroup(x = x, y = y,
                           trt = trt01,
                           propensity.func = prop.func,
                           augment.func    = augment.func,
                           loss   = "sq_loss_lasso",
                           # option for cv.glmnet,
                           # better to use 'nfolds=10'
                           nfolds = 3)              # option for cv.glmnet

summary(subgrp.model.aug)


####################  Binary outcomes ####################################

# use logistic loss for binary outcomes
subgrp.model.bin &lt;- fit.subgroup(x = x, y = y.binary,
                           trt = trt01,
                           propensity.func = prop.func,
                           loss   = "logistic_loss_lasso",
                           type.measure = "auc",    # option for cv.glmnet
                           nfolds = 3)              # option for cv.glmnet

subgrp.model.bin


####################  Count outcomes #####################################

# use poisson loss for count/poisson outcomes
subgrp.model.poisson &lt;- fit.subgroup(x = x, y = y.count,
                           trt = trt01,
                           propensity.func = prop.func,
                           loss   = "poisson_loss_lasso",
                           type.measure = "mse",    # option for cv.glmnet
                           nfolds = 3)              # option for cv.glmnet

subgrp.model.poisson


####################  Time-to-event outcomes #############################

library(survival)

subgrp.model.cox &lt;- fit.subgroup(x = x, y = Surv(y.time.to.event, status),
                           trt = trt01,
                           propensity.func = prop.func,
                           loss   = "cox_loss_lasso",
                           nfolds = 3)              # option for cv.glmnet

subgrp.model.cox



####################  Using custom loss functions ########################

## Use custom loss function for binary outcomes

fit.custom.loss.bin &lt;- function(x, y, weights, offset, ...) {
    df &lt;- data.frame(y = y, x)

    # minimize logistic loss with NO lasso penalty
    # with allowance for efficiency augmentation
    glmf &lt;- glm(y ~ x - 1, weights = weights,
                offset = offset, # offset term allows for efficiency augmentation
                family = binomial(), ...)

    # save coefficients
    cfs = coef(glmf)

    # create prediction function.
    prd = function(x, type = "response") {
         dfte &lt;- cbind(1, x)
         colnames(dfte) &lt;- names(cfs)
         ## predictions must be returned on the scale
         ## of the linear predictor
         predict(glmf, data.frame(dfte), type = "link")
    }
    # return lost of required components
    list(predict = prd, model = glmf, coefficients = cfs)
}


subgrp.model.bin.cust &lt;- fit.subgroup(x = x, y = y.binary,
                                 trt = trt01,
                                 propensity.func = prop.func,
                                 fit.custom.loss = fit.custom.loss.bin)

subgrp.model.bin.cust



## try exponential loss for
## positive outcomes

fit.expo.loss &lt;- function(x, y, weights, ...)
{
    expo.loss &lt;- function(beta, x, y, weights) {
        sum(weights * y * exp(-drop(x %*% beta)))
    }

    # use optim() to minimize loss function
    opt &lt;- optim(rep(0, NCOL(x)), fn = expo.loss, x = x, y = y, weights = weights)

    coefs &lt;- opt$par

    pred &lt;- function(x, type = "response") {
        tcrossprod(cbind(1, x), t(coefs))
    }

    # return list of required components
    list(predict = pred, model = opt, coefficients = coefs)
}


# use exponential loss for positive outcomes
subgrp.model.expo &lt;- fit.subgroup(x = x, y = y.count,
                                  trt = trt01,
                                  propensity.func = prop.func,
                                  fit.custom.loss = fit.expo.loss)

subgrp.model.expo



</code></pre>

<hr>
<h2 id='LaLonde'>National Supported Work Study Data</h2><span id='topic+LaLonde'></span>

<h3>Description</h3>

<p>The LaLonde dataset comes from the National Supported Work Study, which sought to
evaluate the effectiveness of an employment trainining program on wage increases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LaLonde
</code></pre>


<h3>Format</h3>

<p>A data frame with 722 observations and 12 variables:
</p>

<dl>
<dt>outcome</dt><dd><p>whether earnings in 1978 are larger than in 1975; 1 for yes, 0 for no</p>
</dd>
<dt>treat</dt><dd><p>whether the individual received the treatment; &quot;Yes&quot; or &quot;No&quot;</p>
</dd>
<dt>age</dt><dd><p>age in years</p>
</dd>
<dt>educ</dt><dd><p>education in years</p>
</dd>
<dt>black</dt><dd><p>black or not; factor with levels &quot;Yes&quot; or &quot;No&quot;</p>
</dd>
<dt>hisp</dt><dd><p>hispanic or not; factor with levels &quot;Yes&quot; or &quot;No&quot;</p>
</dd>
<dt>white</dt><dd><p>white or not; factor with levels &quot;Yes&quot; or &quot;No&quot;</p>
</dd>
<dt>marr</dt><dd><p>married or not; factor with levels &quot;Yes&quot; or &quot;No&quot;</p>
</dd>
<dt>nodegr</dt><dd><p>No high school degree; factor with levels &quot;Yes&quot; (for no HS degree) or &quot;No&quot;</p>
</dd>
<dt>log.re75</dt><dd><p>log of earnings in 1975</p>
</dd>
<dt>u75</dt><dd><p>unemployed in 1975; factor with levels &quot;Yes&quot; or &quot;No&quot;</p>
</dd>
<dt>wts.extrap</dt><dd><p>extrapolation weights to the 1978 Panel Study for Income Dynamics dataset</p>
</dd>
</dl>



<h3>Source</h3>

<p>The National Supported Work Study.
</p>


<h3>References</h3>

<p>LaLonde, R.J. 1986. &quot;Evaluating the econometric evaulations of training programs with experimental data.&quot; American Economic Review, Vol.76, No.4, pp. 604-620.
</p>
<p>Egami  N,  Ratkovic  M,  Imai  K  (2017). &quot;<span class="pkg">FindIt</span>:  Finding  Heterogeneous  Treatment  Effects.&quot; <code>R</code> package version 1.1.2, <a href="https://CRAN.R-project.org/package=FindIt">https://CRAN.R-project.org/package=FindIt</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LaLonde)
y &lt;- LaLonde$outcome

trt &lt;- LaLonde$treat

x.varnames &lt;- c("age", "educ", "black", "hisp", "white",
                "marr", "nodegr", "log.re75", "u75")

# covariates
data.x &lt;- LaLonde[, x.varnames]

# construct design matrix (with no intercept)
x &lt;- model.matrix(~ -1 + ., data = data.x)

const.propens &lt;- function(x, trt)
{
    mean.trt &lt;- mean(trt == "Trt")
    rep(mean.trt, length(trt))
}

subgrp_fit_w &lt;- fit.subgroup(x = x, y = y, trt = trt,
    loss = "logistic_loss_lasso",
    propensity.func = const.propens,
    cutpoint = 0,
    type.measure = "auc",
    nfolds = 10)

summary(subgrp_fit_w)
</code></pre>

<hr>
<h2 id='plot.subgroup_fitted'>Plotting results for fitted subgroup identification models</h2><span id='topic+plot.subgroup_fitted'></span><span id='topic+plot.subgroup_validated'></span>

<h3>Description</h3>

<p>Plots results for estimated subgroup treatment effects
</p>
<p>Plots validation results for estimated subgroup treatment effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subgroup_fitted'
plot(
  x,
  type = c("boxplot", "density", "interaction", "conditional"),
  avg.line = TRUE,
  ...
)

## S3 method for class 'subgroup_validated'
plot(
  x,
  type = c("boxplot", "density", "interaction", "conditional", "stability"),
  avg.line = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.subgroup_fitted_+3A_x">x</code></td>
<td>
<p>fitted object returned by <code>validate.subgroup()</code> or <code>fit.subgroup()</code> function</p>
</td></tr>
<tr><td><code id="plot.subgroup_fitted_+3A_type">type</code></td>
<td>
<p>type of plot. <code>"density"</code> results in a density plot for the results
across all observations (if <code>x</code> is from <code>fit.subgroup()</code>) or if <code>x</code> is from <code>validate.subgroup()</code>
across iterations of either the bootstrap or training/test re-fitting. For the latter
case the test results will be plotted. <code>"boxplot"</code> results in boxplots across all observations/iterations of either
the bootstrap or training/test re-fitting. For the latter
case the test results will be plotted. <code>"interaction"</code> creates an
interaction plot for the different subgroups (crossing lines here means a meaningful subgroup). For the interaction plot,
the intervals around each point represent +1 one SE
<code>"conditional"</code> For subgroup_fitted objects, plots smoothed (via a GAM smoother) means of the outcomes as a function of the estimated benefit score
separately for the treated and untreated groups. For subgroup_validated objects, boxplots of summary statistics
within subgroups will be plotted as subgroups are defined by different cutoffs of the benefit scores.
These cutoffs can be specified via the <code>benefit.score.quantiles</code> argument of
<code><a href="#topic+validate.subgroup">validate.subgroup</a></code>.</p>
</td></tr>
<tr><td><code id="plot.subgroup_fitted_+3A_avg.line">avg.line</code></td>
<td>
<p>boolean value of whether or not to plot a line for the average
value in addition to the density (only valid for <code>type = "density"</code>)</p>
</td></tr>
<tr><td><code id="plot.subgroup_fitted_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models.
</p>
<p><code><a href="#topic+validate.subgroup">validate.subgroup</a></code> for function which creates validation results
and <code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 250
n.vars &lt;- 15
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,11] - 0.5 * x[,13]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

# create function for fitting propensity score model
prop.func &lt;- function(x, trt)
{
    # fit propensity score model
    propens.model &lt;- cv.glmnet(y = trt,
                               x = x, family = "binomial")
    pi.x &lt;- predict(propens.model, s = "lambda.min",
                    newx = x, type = "response")[,1]
    pi.x
}

subgrp.model &lt;- fit.subgroup(x = x, y = y,
                           trt = trt01,
                           propensity.func = prop.func,
                           loss   = "sq_loss_lasso",
                           # option for cv.glmnet,
                           # better to use 'nfolds=10'
                           nfolds = 3)              # option for cv.glmnet

subgrp.model$subgroup.trt.effects

plot(subgrp.model)

plot(subgrp.model, type = "boxplot")

plot(subgrp.model, type = "interaction")

plot(subgrp.model, type = "conditional")

valmod &lt;- validate.subgroup(subgrp.model, B = 3,
                          method = "training_test",
                          benefit.score.quantiles = c(0.25, 0.5, 0.75),
                          train.fraction = 0.75)

plot(valmod)


plot(valmod, type = "interaction")

# see how summary statistics of subgroups change
# when the subgroups are defined based on different cutoffs
# (25th quantile of bene score, 50th, and 75th)
plot(valmod, type = "conditional")

# visualize the frequency of particular variables
# of being selected across the resampling iterations with
# 'type = "stability"'
# not run:
# plot(valmod, type = "stability")

</code></pre>

<hr>
<h2 id='plotCompare'>Plot a comparison results for fitted or validated subgroup identification models</h2><span id='topic+plotCompare'></span>

<h3>Description</h3>

<p>Plots comparison of results for estimated subgroup treatment effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCompare(
  ...,
  type = c("boxplot", "density", "interaction", "conditional"),
  avg.line = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCompare_+3A_...">...</code></td>
<td>
<p>the fitted (model or validation) objects to be plotted. Must be either
objects returned from <code>fit.subgroup()</code> or <code>validate.subgroup()</code></p>
</td></tr>
<tr><td><code id="plotCompare_+3A_type">type</code></td>
<td>
<p>type of plot. <code>"density"</code> results in a density plot for the results
across all observations (if <code>x</code> is from <code>fit.subgroup()</code>) or if <code>x</code> is from <code>validate.subgroup()</code>
across iterations of either the bootstrap or training/test re-fitting. For the latter
case the test results will be plotted. <code>"boxplot"</code> results in boxplots across all observations/iterations of either
the bootstrap or training/test re-fitting. For the latter
case the test results will be plotted. <code>"interaction"</code> creates an
interaction plot for the different subgroups (crossing lines here means a meaningful subgroup).
<code>"conditional"</code> plots smoothed (via a GAM smoother) means of the outcomes as a function of the estimated benefit score
separately for the treated and untreated groups.</p>
</td></tr>
<tr><td><code id="plotCompare_+3A_avg.line">avg.line</code></td>
<td>
<p>boolean value of whether or not to plot a line for the average
value in addition to the density (only valid for <code>type = "density"</code>)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models and
<code><a href="#topic+validate.subgroup">validate.subgroup</a></code> for function which creates validation results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 100
n.vars &lt;- 15
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,1] - 0.5 * x[,4]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

# create function for fitting propensity score model
prop.func &lt;- function(x, trt)
{
    # fit propensity score model
    propens.model &lt;- cv.glmnet(y = trt,
                               x = x, family = "binomial")
    pi.x &lt;- predict(propens.model, s = "lambda.min",
                    newx = x, type = "response")[,1]
    pi.x
}

subgrp.model &lt;- fit.subgroup(x = x, y = y,
                           trt = trt01,
                           propensity.func = prop.func,
                           loss   = "sq_loss_lasso",
                           # option for cv.glmnet,
                           # better to use 'nfolds=10'
                           nfolds = 3)              # option for cv.glmnet


subgrp.model.o &lt;- fit.subgroup(x = x, y = y,
                           trt = trt01,
                           propensity.func = prop.func,
                           # option for cv.glmnet,
                           # better to use 'nfolds=10'
                           loss   = "owl_logistic_flip_loss_lasso",
                           nfolds = 3)

plotCompare(subgrp.model, subgrp.model.o)

</code></pre>

<hr>
<h2 id='predict.subgroup_fitted'>Function to predict either benefit scores or treatment recommendations</h2><span id='topic+predict.subgroup_fitted'></span><span id='topic+predict.wksvm'></span>

<h3>Description</h3>

<p>Predicts benefit scores or treatment recommendations based on a fitted subgroup identification model
</p>
<p>Function to obtain predictions for weighted ksvm objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subgroup_fitted'
predict(
  object,
  newx,
  type = c("benefit.score", "trt.group"),
  cutpoint = 0,
  ...
)

## S3 method for class 'wksvm'
predict(object, newx, type = c("class", "linear.predictor"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.subgroup_fitted_+3A_object">object</code></td>
<td>
<p>fitted object returned by <code>validate.subgrp()</code> function.
</p>
<p>For <code>predict.wksvm()</code>, this should be a fitted <code>wksvm</code> object from the <code>weighted.ksvm()</code> function</p>
</td></tr>
<tr><td><code id="predict.subgroup_fitted_+3A_newx">newx</code></td>
<td>
<p>new design matrix for which predictions will be made</p>
</td></tr>
<tr><td><code id="predict.subgroup_fitted_+3A_type">type</code></td>
<td>
<p>type of prediction. <code>type = "benefit.score"</code> results in predicted benefit scores and
<code>type = "trt.group"</code> results in prediction of recommended treatment group.
</p>
<p>For <code>predict.wksvm()</code>, <code>type = 'class'</code> yields predicted
class and <code>type = 'linear.predictor'</code> yields estimated function (the sign of which is the estimated class)</p>
</td></tr>
<tr><td><code id="predict.subgroup_fitted_+3A_cutpoint">cutpoint</code></td>
<td>
<p>numeric value for patients with benefit scores above which
(or below which if <code>larger.outcome.better = FALSE</code>)
will be recommended to be in the treatment group. Can also set <code>cutpoint = "median"</code>, which will
use the median value of the benefit scores as the cutpoint or can set specific quantile values via <code>"quantx"</code>
where <code>"x"</code> is a number between 0 and 100 representing the quantile value; e.g. <code>cutpoint = "quant75"</code>
will use the 75th perent upper quantile of the benefit scores as the quantile.</p>
</td></tr>
<tr><td><code id="predict.subgroup_fitted_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models.
</p>
<p><code><a href="#topic+weighted.ksvm">weighted.ksvm</a></code> for fitting <code>weighted.ksvm</code> objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 500
n.vars &lt;- 15
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,11] - 0.5 * x[,3]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

# create function for fitting propensity score model
prop.func &lt;- function(x, trt)
{
    # fit propensity score model
    propens.model &lt;- cv.glmnet(y = trt,
                               x = x, family = "binomial")
    pi.x &lt;- predict(propens.model, s = "lambda.min",
                    newx = x, type = "response")[,1]
    pi.x
}

subgrp.model &lt;- fit.subgroup(x = x, y = y,
                            trt = trt01,
                            propensity.func = prop.func,
                            loss   = "sq_loss_lasso",
                            nfolds = 3)              # option for cv.glmnet

subgrp.model$subgroup.trt.effects
benefit.scores &lt;- predict(subgrp.model, newx = x, type = "benefit.score")

rec.trt.grp &lt;- predict(subgrp.model, newx = x, type = "trt.group")
</code></pre>

<hr>
<h2 id='print.individual_treatment_effects'>Printing individualized treatment effects</h2><span id='topic+print.individual_treatment_effects'></span>

<h3>Description</h3>

<p>Prints results for estimated subgroup treatment effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'individual_treatment_effects'
print(x, digits = max(getOption("digits") - 3, 3), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.individual_treatment_effects_+3A_x">x</code></td>
<td>
<p>a fitted object from either <code><a href="#topic+treat.effects">treat.effects</a></code> or <code><a href="#topic+treatment.effects">treatment.effects</a></code></p>
</td></tr>
<tr><td><code id="print.individual_treatment_effects_+3A_digits">digits</code></td>
<td>
<p>minimal number of significant digits to print.</p>
</td></tr>
<tr><td><code id="print.individual_treatment_effects_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from <code><a href="base.html#topic+print.default">print.default</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='print.subgroup_fitted'>Printing results for fitted subgroup identification models</h2><span id='topic+print.subgroup_fitted'></span><span id='topic+print.subgroup_validated'></span><span id='topic+print.subgroup_summary'></span>

<h3>Description</h3>

<p>Prints results for estimated subgroup treatment effects
</p>
<p>Prints summary results for estimated subgroup treatment effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subgroup_fitted'
print(x, digits = max(getOption("digits") - 3, 3), ...)

## S3 method for class 'subgroup_validated'
print(
  x,
  digits = max(getOption("digits") - 3, 3),
  sample.pct = FALSE,
  which.quant = NULL,
  ...
)

## S3 method for class 'subgroup_summary'
print(x, p.value = 0.001, digits = max(getOption("digits") - 3, 3), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.subgroup_fitted_+3A_x">x</code></td>
<td>
<p>a fitted object from either <code>fit.subgroup</code>, <code>validate.subgroup</code>, or <code>summarize.subgroups()</code></p>
</td></tr>
<tr><td><code id="print.subgroup_fitted_+3A_digits">digits</code></td>
<td>
<p>minimal number of significant digits to print.</p>
</td></tr>
<tr><td><code id="print.subgroup_fitted_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from <code><a href="base.html#topic+print.default">print.default</a></code>.</p>
</td></tr>
<tr><td><code id="print.subgroup_fitted_+3A_sample.pct">sample.pct</code></td>
<td>
<p>boolean variable of whether to print the percent of the test sample within each subgroup. If false
the sample size itself, not the percent is printed. This may not be informative if the test sample size is much different
from the total sample size</p>
</td></tr>
<tr><td><code id="print.subgroup_fitted_+3A_which.quant">which.quant</code></td>
<td>
<p>when <code>validate.subgroup()</code> is called with a vector of quantile values specified for <code>benefit.score.quantiles</code>,
i.e. <code>benefit.score.quantiles = c(0.25, 0.5, 0.75)</code>, the argument <code>which.quant</code> can be a vector of indexes specifying which
quantile cutoff value validation results to display, i.e. <code>which.quant = c(1,3)</code> in the above example results in the display of
validation results for subgroups defined by cutoff values of the benefit score defined by the 25th abnd 75th quantiles of the benefit score</p>
</td></tr>
<tr><td><code id="print.subgroup_fitted_+3A_p.value">p.value</code></td>
<td>
<p>a p-value threshold for mean differences below which covariates will be displayed. P-values are adjusted for
multiple comparisons by the Hommel approach. For example,
setting <code>p.value = 0.05</code> will display all covariates that have a significant difference between subgroups
with p-value less than 0.05. Defaults to 0.001.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+validate.subgroup">validate.subgroup</a></code> for function which creates validation results
and <code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models.
</p>
<p><code><a href="#topic+summarize.subgroups">summarize.subgroups</a></code> for function which summarizes subgroup covariate values
</p>

<hr>
<h2 id='subgroup.effects'>Computes treatment effects within various subgroups</h2><span id='topic+subgroup.effects'></span>

<h3>Description</h3>

<p>Computes treatment effects within various subgroups to estimate subgroup treatment effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subgroup.effects(
  benefit.scores,
  y,
  trt,
  pi.x,
  cutpoint = 0,
  larger.outcome.better = TRUE,
  reference.trt = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="subgroup.effects_+3A_benefit.scores">benefit.scores</code></td>
<td>
<p>vector of estimated benefit scores</p>
</td></tr>
<tr><td><code id="subgroup.effects_+3A_y">y</code></td>
<td>
<p>The response vector</p>
</td></tr>
<tr><td><code id="subgroup.effects_+3A_trt">trt</code></td>
<td>
<p>treatment vector with each element equal to a 0 or a 1, with 1 indicating
treatment status is active.</p>
</td></tr>
<tr><td><code id="subgroup.effects_+3A_pi.x">pi.x</code></td>
<td>
<p>The propensity score for each observation</p>
</td></tr>
<tr><td><code id="subgroup.effects_+3A_cutpoint">cutpoint</code></td>
<td>
<p>numeric value for patients with benefit scores above which
(or below which if <code>larger.outcome.better = FALSE</code>)
will be recommended to be in the treatment group. Can also set <code>cutpoint = "median"</code>, which will
use the median value of the benefit scores as the cutpoint or can set specific quantile values via <code>"quantx"</code>
where <code>"x"</code> is a number between 0 and 100 representing the quantile value; e.g. <code>cutpoint = "quant75"</code>
will use the 75th perent upper quantile of the benefit scores as the quantile.</p>
</td></tr>
<tr><td><code id="subgroup.effects_+3A_larger.outcome.better">larger.outcome.better</code></td>
<td>
<p>boolean value of whether a larger outcome is better. Set to <code>TRUE</code>
if a larger outcome is better and set to <code>FALSE</code> if a smaller outcome is better. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="subgroup.effects_+3A_reference.trt">reference.trt</code></td>
<td>
<p>index of which treatment is the reference (in the case of multiple treatments).
This should be known already, as for a <code>trt</code> with K-levels, there will be K-1 benefit scores (1 per column)
of <code>benefit.scores</code>, where each column is a comparison of each K-1 treatments with the reference treatment.
The default is the last level of <code>trt</code> if it is a factor.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models which generate
benefit scores.
</p>

<hr>
<h2 id='summarize.subgroups'>Summarizing covariates within estimated subgroups</h2><span id='topic+summarize.subgroups'></span><span id='topic+summarize.subgroups.default'></span><span id='topic+summarize.subgroups.subgroup_fitted'></span>

<h3>Description</h3>

<p>Summarizes covariate values within the estimated subgroups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize.subgroups(x, ...)

## Default S3 method:
summarize.subgroups(x, subgroup, ...)

## S3 method for class 'subgroup_fitted'
summarize.subgroups(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarize.subgroups_+3A_x">x</code></td>
<td>
<p>a fitted object from <code>fit.subgroup()</code> or a matrix of covariate values</p>
</td></tr>
<tr><td><code id="summarize.subgroups_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>summarize.subgroups</code> methods</p>
</td></tr>
<tr><td><code id="summarize.subgroups_+3A_subgroup">subgroup</code></td>
<td>
<p>vector of indicators of same length as the number of rows in x if x is a matrix.
A value of 1 in the ith position of <code>subgroup</code> indicates patient i is in the subgroup
of patients recommended the treatment and a value of 0 in the ith position of <code>subgroup</code> indicates patient i is in the subgroup
of patients recommended the control.
If x is a fitted object returned by <code>fit.subgroup()</code>, <code>subgroup</code> is not needed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The p-values shown are raw p-values and are not adjusted for multiple comparisons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models and
<code><a href="#topic+print.subgroup_summary">print.subgroup_summary</a></code> for arguments for printing options for <code>summarize.subgroups()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 1000
n.vars &lt;- 50
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,21] - 0.5 * x[,41]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

# create function for fitting propensity score model
prop.func &lt;- function(x, trt)
{
    # fit propensity score model
    propens.model &lt;- cv.glmnet(y = trt,
                               x = x, family = "binomial")
    pi.x &lt;- predict(propens.model, s = "lambda.min",
                    newx = x, type = "response")[,1]
    pi.x
}

subgrp.model &lt;- fit.subgroup(x = x, y = y,
                             trt = trt01,
                             propensity.func = prop.func,
                             loss   = "sq_loss_lasso",
                             nfolds = 5)    # option for cv.glmnet

comp &lt;- summarize.subgroups(subgrp.model)
print(comp, p.value = 0.01)

# or we can simply supply the matrix x and the subgroups
comp2 &lt;- summarize.subgroups(x, subgroup = 1 * (subgrp.model$benefit.scores &gt; 0))

print(comp2, p.value = 0.01)

</code></pre>

<hr>
<h2 id='summary.subgroup_fitted'>Summary of results for fitted subgroup identification models</h2><span id='topic+summary.subgroup_fitted'></span><span id='topic+summary.wksvm'></span>

<h3>Description</h3>

<p>Prints summary of results for estimated subgroup treatment effects
</p>
<p>Prints summary of results for estimated weighted ksvm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'subgroup_fitted'
summary(object, digits = max(getOption("digits") - 3, 3), ...)

## S3 method for class 'wksvm'
summary(object, digits = max(getOption("digits") - 3, 3), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.subgroup_fitted_+3A_object">object</code></td>
<td>
<p>a fitted object from either <code>fit.subgroup</code> or <code>validate.subgroup</code></p>
</td></tr>
<tr><td><code id="summary.subgroup_fitted_+3A_digits">digits</code></td>
<td>
<p>minimal number of significant digits to print.</p>
</td></tr>
<tr><td><code id="summary.subgroup_fitted_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from <code><a href="base.html#topic+print.default">print.default</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+validate.subgroup">validate.subgroup</a></code> for function which creates validation results
and <code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models.
</p>

<hr>
<h2 id='treatment.effects'>Calculation of covariate-conditional treatment effects</h2><span id='topic+treatment.effects'></span><span id='topic+treatment.effects.default'></span><span id='topic+treat.effects'></span><span id='topic+treatment.effects.subgroup_fitted'></span>

<h3>Description</h3>

<p>Calculates covariate conditional treatment effects using estimated benefit scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>treatment.effects(x, ...)

## Default S3 method:
treatment.effects(x, ...)

treat.effects(
  benefit.scores,
  loss = c("sq_loss_lasso", "logistic_loss_lasso", "poisson_loss_lasso",
    "cox_loss_lasso", "owl_logistic_loss_lasso", "owl_logistic_flip_loss_lasso",
    "owl_hinge_loss", "owl_hinge_flip_loss", "sq_loss_lasso_gam",
    "poisson_loss_lasso_gam", "logistic_loss_lasso_gam", "sq_loss_gam",
    "poisson_loss_gam", "logistic_loss_gam", "owl_logistic_loss_gam",
    "owl_logistic_flip_loss_gam", "owl_logistic_loss_lasso_gam",
    "owl_logistic_flip_loss_lasso_gam", "sq_loss_xgboost", "custom"),
  method = c("weighting", "a_learning"),
  pi.x = NULL,
  ...
)

## S3 method for class 'subgroup_fitted'
treatment.effects(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="treatment.effects_+3A_x">x</code></td>
<td>
<p>a fitted object from <code>fit.subgroup()</code></p>
</td></tr>
<tr><td><code id="treatment.effects_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="treatment.effects_+3A_benefit.scores">benefit.scores</code></td>
<td>
<p>vector of estimated benefit scores</p>
</td></tr>
<tr><td><code id="treatment.effects_+3A_loss">loss</code></td>
<td>
<p>loss choice USED TO CALCULATE <code>benefit.scores</code> of both the M function from Chen, et al (2017) and
potentially the penalty used for variable selection. See <code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for more details.</p>
</td></tr>
<tr><td><code id="treatment.effects_+3A_method">method</code></td>
<td>
<p>method choice USED TO CALCULATE <code>benefit.scores</code>. Either the <code>"weighting"</code> method or
<code>"a_learning"</code> method. See <code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for more details</p>
</td></tr>
<tr><td><code id="treatment.effects_+3A_pi.x">pi.x</code></td>
<td>
<p>The propensity score for each observation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A List with elements <code>delta</code> (if the treatment effects are a difference/contrast,
i.e. <code class="reqn">E[Y|T=1, X] - E[Y|T=-1, X]</code>) and <code>gamma</code> (if the treatment effects are a ratio,
i.e. <code class="reqn">E[Y|T=1, X] / E[Y|T=-1, X]</code>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models.
</p>
<p><code><a href="#topic+print.individual_treatment_effects">print.individual_treatment_effects</a></code> for printing of objects returned by
<code>treat.effects</code> or <code>treatment.effects</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 500
n.vars &lt;- 25
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,21] - 0.5 * x[,11]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

# time-to-event outcomes
surv.time &lt;- exp(-20 - xbeta + rnorm(n.obs, sd = 1))
cens.time &lt;- exp(rnorm(n.obs, sd = 3))
y.time.to.event  &lt;- pmin(surv.time, cens.time)
status           &lt;- 1 * (surv.time &lt;= cens.time)

# create function for fitting propensity score model
prop.func &lt;- function(x, trt)
{
    # fit propensity score model
    propens.model &lt;- cv.glmnet(y = trt,
                               x = x, family = "binomial")
    pi.x &lt;- predict(propens.model, s = "lambda.min",
                    newx = x, type = "response")[,1]
    pi.x
}

subgrp.model &lt;- fit.subgroup(x = x, y = y,
                             trt = trt01,
                             propensity.func = prop.func,
                             loss   = "sq_loss_lasso",
                             nfolds = 3)    # option for cv.glmnet

trt_eff &lt;- treatment.effects(subgrp.model)
str(trt_eff)

trt_eff


library(survival)
subgrp.model.cox &lt;- fit.subgroup(x = x, y = Surv(y.time.to.event, status),
                           trt = trt01,
                           propensity.func = prop.func,
                           loss   = "cox_loss_lasso",
                           nfolds = 3)              # option for cv.glmnet

trt_eff_c &lt;- treatment.effects(subgrp.model.cox)
str(trt_eff_c)

trt_eff_c

</code></pre>

<hr>
<h2 id='validate.subgroup'>Validating fitted subgroup identification models</h2><span id='topic+validate.subgroup'></span>

<h3>Description</h3>

<p>Validates subgroup treatment effects for fitted
subgroup identification model class of Chen, et al (2017)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate.subgroup(
  model,
  B = 50L,
  method = c("training_test_replication", "boot_bias_correction"),
  train.fraction = 0.75,
  benefit.score.quantiles = c(0.1666667, 0.3333333, 0.5, 0.6666667, 0.8333333),
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate.subgroup_+3A_model">model</code></td>
<td>
<p>fitted model object returned by <code>fit.subgroup()</code> function</p>
</td></tr>
<tr><td><code id="validate.subgroup_+3A_b">B</code></td>
<td>
<p>integer. number of bootstrap replications or refitting replications.</p>
</td></tr>
<tr><td><code id="validate.subgroup_+3A_method">method</code></td>
<td>
<p>validation method. <code>"boot_bias_correction"</code> for the bootstrap
bias correction method of Harrell, et al (1996) or <code>"training_test_replication"</code>
for repeated training and test splitting of the data (<code>train.fraction</code> should be specified
for this option)</p>
</td></tr>
<tr><td><code id="validate.subgroup_+3A_train.fraction">train.fraction</code></td>
<td>
<p>fraction (between 0 and 1) of samples to be used for training in
training/test replication. Only used for <code>method = "training_test_replication"</code></p>
</td></tr>
<tr><td><code id="validate.subgroup_+3A_benefit.score.quantiles">benefit.score.quantiles</code></td>
<td>
<p>a vector of quantiles (between 0 and 1) of the benefit score values
for which to return bootstrapped information about the subgroups. ie if one of the quantile values is 0.5, the
median value of the benefit scores will be used as a cutoff to determine subgroups and summary statistics
will be returned about these subgroups</p>
</td></tr>
<tr><td><code id="validate.subgroup_+3A_parallel">parallel</code></td>
<td>
<p>Should the loop over replications be parallelized? If <code>FALSE</code>, then no, if <code>TRUE</code>, then yes.
If user sets <code>parallel = TRUE</code> and the fitted <code>fit.subgroup()</code> object uses the parallel version of
an internal model, say for <code>cv.glmnet()</code>, then the internal parallelization will be overridden so as
not to create a conflict of parallelism.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates of various quantities conditional on subgroups and treatment statuses are provided and displayed
via the <code><a href="#topic+print.subgroup_validated">print.subgroup_validated</a></code> function:
</p>

<ol>
<li><p>&quot;Conditional expected outcomes&quot; The first results shown when printing
a <code>subgroup_validated</code> object are estimates of the expected outcomes conditional on
the estimated subgroups (i.e. which subgroup is 'recommended' by the model) and conditional
on treatment/intervention status. If there are two total treatment options, this results in a 2x2 table
of expected conditional outcomes. 
</p>
</li>
<li><p>&quot;Treatment effects conditional on subgroups&quot; The second results shown when printing
a <code>subgroup_validated</code> object are estimates of the expected outcomes conditional on
the estimated subgroups. If the treatment takes levels <code class="reqn">j \in \{1, \dots, K\}</code>, a total of <code class="reqn">K</code>
conditional treatment effects will be shown. For example, of the outcome is continuous, the
<code class="reqn">j</code>th conditional treatment effect is defined as <code class="reqn">E(Y|Trt = j, Subgroup=j) - E(Y|Trt = j, Subgroup =/= j)</code>,
where <code class="reqn">Subgroup=j</code> if treatment <code class="reqn">j</code> is recommended, i.e. treatment <code class="reqn">j</code> results in the largest/best
expected potential outcomes given the fitted model.
</p>
</li>
<li><p>&quot;Overall treatment effect conditional on subgroups &quot; The third quantity displayed shows the overall improvement
in outcomes resulting from all treatment recommendations. This is essentially an average over all of the
conditional treatment effects weighted by the proportion of the population recommended each respective
treatment level.
</p>
</li></ol>



<h3>Value</h3>

<p>An object of class <code>"subgroup_validated"</code>
</p>
<table role = "presentation">
<tr><td><code>avg.results</code></td>
<td>
<p>Estimates of average conditional treatment effects when
subgroups are determined based on the provided cutoff value for the benefit score. For example,
if <code>cutoff = 0</code> and there is a treatment and control only, then the treatment is
recommended if the benefit score is greater than 0.</p>
</td></tr>
<tr><td><code>se.results</code></td>
<td>
<p>Standard errors of the estimates from <code>avg.estimates</code></p>
</td></tr>
<tr><td><code>boot.results</code></td>
<td>
<p>Contains the individual results for each replication. <code>avg.results</code> is comprised
of averages of the values from <code>boot.results</code></p>
</td></tr>
<tr><td><code>avg.quantile.results</code></td>
<td>
<p>Estimates of average conditional treatment effects when
subgroups are determined based on different quntile cutoff values for the benefit score. For example,
if <code>benefit.score.quantiles = 0.75</code> and there is a treatment and control only, then the treatment is
recommended if the benefit score is greater than the 75th upper quantile of all benefit scores. If multiple quantile
values are provided, e.g. <code>benefit.score.quantiles = c(0.15, 0.5, 0.85)</code>, then results will be provided
for all quantile levels.</p>
</td></tr>
<tr><td><code>se.quantile.results</code></td>
<td>
<p>Standard errors corresponding to <code>avg.quantile.results</code></p>
</td></tr>
<tr><td><code>boot.results.quantiles</code></td>
<td>
<p>Contains the individual results for each replication. <code>avg.quantile.results</code> is comprised
of averages of the values from <code>boot.results.quantiles</code></p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>Family of the outcome. For example, <code>"gaussian"</code> for continuous outcomes</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Method used for subgroup identification model. Weighting or A-learning</p>
</td></tr>
<tr><td><code>n.trts</code></td>
<td>
<p>The number of treatment levels</p>
</td></tr>
<tr><td><code>comparison.trts</code></td>
<td>
<p>All treatment levels other than the reference level</p>
</td></tr>
<tr><td><code>reference.trt</code></td>
<td>
<p>The reference level for the treatment. This should usually be the control group/level</p>
</td></tr>
<tr><td><code>larger.outcome.better</code></td>
<td>
<p>If larger outcomes are preferred for this model</p>
</td></tr>
<tr><td><code>cutpoint</code></td>
<td>
<p>Benefit score cutoff value used for determining subgroups</p>
</td></tr>
<tr><td><code>val.method</code></td>
<td>
<p>Method used for validation</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>Number of replications used in the validation process</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>Number of observations in <code>x</code> provided to <code><a href="#topic+fit.subgroup">fit.subgroup</a></code></p>
</td></tr>
<tr><td><code>nvars</code></td>
<td>
<p>Number of variables in <code>x</code> provided to <code><a href="#topic+fit.subgroup">fit.subgroup</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chen, S., Tian, L., Cai, T. and Yu, M. (2017), A general statistical framework for subgroup identification
and comparative treatment scoring. Biometrics. doi:10.1111/biom.12676
</p>
<p>Harrell, F. E., Lee, K. L., and Mark, D. B. (1996). Tutorial in biostatistics multivariable prognostic models: issues in developing models,
evaluating assumptions and adequacy, and measuring and reducing errors. Statistics in medicine, 15, 361-387.
doi:10.1002/(SICI)1097-0258(19960229)15:4&lt;361::AID-SIM168&gt;3.0.CO;2-4
</p>
<p>Huling. J.D. and Yu, M. (2021), Subgroup Identification Using the personalized Package.
Journal of Statistical Software 98(5), 1-60. doi:10.18637/jss.v098.i05
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.subgroup">fit.subgroup</a></code> for function which fits subgroup identification models,
<code><a href="#topic+plot.subgroup_validated">plot.subgroup_validated</a></code> for plotting of validation results, and
<code><a href="#topic+print.subgroup_validated">print.subgroup_validated</a></code> for arguments for printing options for <code>validate.subgroup()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(personalized)

set.seed(123)
n.obs  &lt;- 500
n.vars &lt;- 20
x &lt;- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)


# simulate non-randomized treatment
xbetat   &lt;- 0.5 + 0.5 * x[,11] - 0.5 * x[,13]
trt.prob &lt;- exp(xbetat) / (1 + exp(xbetat))
trt01    &lt;- rbinom(n.obs, 1, prob = trt.prob)

trt      &lt;- 2 * trt01 - 1

# simulate response
delta &lt;- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
xbeta &lt;- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
xbeta &lt;- xbeta + delta * trt

# continuous outcomes
y &lt;- drop(xbeta) + rnorm(n.obs, sd = 2)

# create function for fitting propensity score model
prop.func &lt;- function(x, trt)
{
    # fit propensity score model
    propens.model &lt;- cv.glmnet(y = trt,
                               x = x, family = "binomial")
    pi.x &lt;- predict(propens.model, s = "lambda.min",
                    newx = x, type = "response")[,1]
    pi.x
}

subgrp.model &lt;- fit.subgroup(x = x, y = y,
                             trt = trt01,
                             propensity.func = prop.func,
                             loss   = "sq_loss_lasso",
                             # option for cv.glmnet,
                             # better to use 'nfolds=10'
                             nfolds = 3)


x.test &lt;- matrix(rnorm(10 * n.obs * n.vars, sd = 3), 10 * n.obs, n.vars)


# simulate non-randomized treatment
xbetat.test   &lt;- 0.5 + 0.5 * x.test[,11] - 0.5 * x.test[,13]
trt.prob.test &lt;- exp(xbetat.test) / (1 + exp(xbetat.test))
trt01.test    &lt;- rbinom(10 * n.obs, 1, prob = trt.prob.test)

trt.test      &lt;- 2 * trt01.test - 1

# simulate response
delta.test &lt;- 2 * (0.5 + x.test[,2] - x.test[,3] - x.test[,11] + x.test[,1] * x.test[,12])
xbeta.test &lt;- x.test[,1] + x.test[,11] - 2 * x.test[,12]^2 + x.test[,13]
xbeta.test &lt;- xbeta.test + delta.test * trt.test

y.test &lt;- drop(xbeta.test) + rnorm(10 * n.obs, sd = 2)

valmod &lt;- validate.subgroup(subgrp.model, B = 2,
                            method = "training_test",
                            train.fraction = 0.75)
valmod

print(valmod, which.quant = c(4, 5))

</code></pre>

<hr>
<h2 id='weighted.ksvm'>Fit weighted kernel svm model.</h2><span id='topic+weighted.ksvm'></span>

<h3>Description</h3>

<p>Fits weighted kernel SVM.  To be used for OWL with hinge loss (but can be used more generally)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.ksvm(
  y,
  x,
  weights,
  C = c(0.1, 0.5, 1, 2, 10),
  kernel = "rbfdot",
  kpar = "automatic",
  nfolds = 10,
  foldid = NULL,
  eps = 1e-08,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weighted.ksvm_+3A_y">y</code></td>
<td>
<p>The response vector (either a character vector, factor vector, or numeric vector with values in -1, 1)</p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_x">x</code></td>
<td>
<p>The design matrix (not including intercept term)</p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_weights">weights</code></td>
<td>
<p>vector of sample weights for weighted SVM</p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_c">C</code></td>
<td>
<p>cost of constraints violation, see <code><a href="kernlab.html#topic+ksvm">ksvm</a></code></p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_kernel">kernel</code></td>
<td>
<p>kernel function used for training and prediction. See <code><a href="kernlab.html#topic+ksvm">ksvm</a></code> and <code><a href="kernlab.html#topic+kernels">kernels</a></code></p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_kpar">kpar</code></td>
<td>
<p>list of hyperparameters for the kernel function. See <code><a href="kernlab.html#topic+ksvm">ksvm</a></code></p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_nfolds">nfolds</code></td>
<td>
<p>number of cross validation folds for selecting value of C</p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_foldid">foldid</code></td>
<td>
<p>optional vector of values between 1 and nfolds specifying which fold each observation is in. If specified, it will
override the <code>nfolds</code> argument.</p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_eps">eps</code></td>
<td>
<p>penalty nugget parameter. Defaults to <code>1e-8</code></p>
</td></tr>
<tr><td><code id="weighted.ksvm_+3A_...">...</code></td>
<td>
<p>extra arguments to be passed to <code><a href="kernlab.html#topic+ipop">ipop</a></code> from the kernlab package</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+predict.wksvm">predict.wksvm</a></code> for predicting from fitted <code>weighted.ksvm</code> objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(kernlab)

x &lt;- matrix(rnorm(200 * 2), ncol = 2)

y &lt;- 2 * (sin(x[,2]) ^ 2 * exp(-x[,2]) - 0.2 &gt; rnorm(200, sd = 0.1)) - 1

weights &lt;- runif(100, max = 1.5, min = 0.5)

wk &lt;- weighted.ksvm(x = x[1:100,], y = y[1:100],
                    C = c(0.1, 0.5, 1, 2),
                    nfolds = 5,
                    weights = weights[1:100])

pr &lt;- predict(wk, newx = x[101:200,])

mean(pr == y[101:200])

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
