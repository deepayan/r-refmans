<!DOCTYPE html><html lang="en"><head><title>Help for package variationalDCM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {variationalDCM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dina_data_gen'><p>Artificial data generating function for the DINA model based on the given Q-matrix</p></a></li>
<li><a href='#hm_dcm_data_gen'><p>Artificial data generating function for the hidden-Markov DCM based on the given Q-matrix</p></a></li>
<li><a href='#mc_dina_data_gen'><p>Artificial data generating function for the multiple-choice DINA model based on the given Q-matrix</p></a></li>
<li><a href='#mc_sim_Q'><p>Artificial Q-matrix for MC-DINA model</p></a></li>
<li><a href='#sim_Q_J30K3'><p>Artificial Q-matrix for 30 items 3 attributes</p></a></li>
<li><a href='#sim_Q_J80K5'><p>Artificial Q-matrix for 80 items 5 attributes</p></a></li>
<li><a href='#variationalDCM'><p>Variational Bayesian estimation for DCMs</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variational Bayesian Estimation for Diagnostic Classification
Models</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Enables computationally efficient parameters-estimation by variational Bayesian methods for various diagnostic classification models (DCMs). DCMs are a class of discrete latent variable models for classifying respondents into latent classes that typically represent distinct combinations of skills they possess. Recently, to meet the growing need of large-scale diagnostic measurement in the field of educational, psychological, and psychiatric measurements, variational Bayesian inference has been developed as a computationally efficient alternative to the Markov chain Monte Carlo methods, e.g., Yamaguchi and Okada (2020a) &lt;<a href="https://doi.org/10.1007%2Fs11336-020-09739-w">doi:10.1007/s11336-020-09739-w</a>&gt;, Yamaguchi and Okada (2020b) &lt;<a href="https://doi.org/10.3102%2F1076998620911934">doi:10.3102/1076998620911934</a>&gt;, Yamaguchi (2020) &lt;<a href="https://doi.org/10.1007%2Fs41237-020-00104-w">doi:10.1007/s41237-020-00104-w</a>&gt;, Oka and Okada (2023) &lt;<a href="https://doi.org/10.1007%2Fs11336-022-09884-4">doi:10.1007/s11336-022-09884-4</a>&gt;, and Yamaguchi and Martinez (2023) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12308">doi:10.1111/bmsp.12308</a>&gt;. To facilitate their applications, 'variationalDCM' is developed to provide a collection of recently-proposed variational Bayesian estimation methods for various DCMs.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Keiichiro Hijikata &lt;k.hijikata.1120@outlook.jp&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>mvtnorm, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/khijikata/variationalDCM">https://github.com/khijikata/variationalDCM</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/khijikata/variationalDCM/issues">https://github.com/khijikata/variationalDCM/issues</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Collate:</td>
<td>'data.R' 'dina.R' 'dino.R' 'hm_dcm.R' 'mc_dina.R' 'satu_dcm.R'
'variationalDCM.R' 'summary.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-25 13:54:29 UTC; khiji</td>
</tr>
<tr>
<td>Author:</td>
<td>Keiichiro Hijikata [aut, cre],
  Motonori Oka <a href="https://orcid.org/0000-0002-9867-8922"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Kazuhiro Yamaguchi
    <a href="https://orcid.org/0000-0001-8011-8575"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Kensuke Okada <a href="https://orcid.org/0000-0003-1663-5812"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-25 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dina_data_gen'>Artificial data generating function for the DINA model based on the given Q-matrix</h2><span id='topic+dina_data_gen'></span>

<h3>Description</h3>

<p><code>dina_data_gen()</code> returns the artificially generated item response data for the DINA model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dina_data_gen(Q, I, attr_cor = 0.1, s = 0.2, g = 0.2, seed = 17)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dina_data_gen_+3A_q">Q</code></td>
<td>
<p>the <code class="reqn">J \times K</code> binary matrix</p>
</td></tr>
<tr><td><code id="dina_data_gen_+3A_i">I</code></td>
<td>
<p>the number of assumed respondents</p>
</td></tr>
<tr><td><code id="dina_data_gen_+3A_attr_cor">attr_cor</code></td>
<td>
<p>the true value of the correlation among attributes (default: 0.1)</p>
</td></tr>
<tr><td><code id="dina_data_gen_+3A_s">s</code></td>
<td>
<p>the true value of the slip parameter (default: 0.2)</p>
</td></tr>
<tr><td><code id="dina_data_gen_+3A_g">g</code></td>
<td>
<p>the true value of the guessing parameter (default: 0.2)</p>
</td></tr>
<tr><td><code id="dina_data_gen_+3A_seed">seed</code></td>
<td>
<p>the seed value used for random number generation (default: 17)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including:
</p>

<dl>
<dt>X</dt><dd><p>the generated artificial item response data</p>
</dd>
<dt>att_pat</dt><dd><p>the generated true vale of the attribute mastery pattern</p>
</dd>
</dl>



<h3>References</h3>

<p>Oka, M., &amp; Okada, K. (2023). Scalable Bayesian Approach for the Dina
Q-Matrix Estimation Combining Stochastic Optimization and Variational Inference.
<em>Psychometrika</em>, 88, 302–331. <a href="https://doi.org/10.1007/s11336-022-09884-4">doi:10.1007/s11336-022-09884-4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load Q-matrix
Q = sim_Q_J80K5
sim_data = dina_data_gen(Q=Q,I=200)
</code></pre>

<hr>
<h2 id='hm_dcm_data_gen'>Artificial data generating function for the hidden-Markov DCM based on the given Q-matrix</h2><span id='topic+hm_dcm_data_gen'></span>

<h3>Description</h3>

<p><code>hm_dcm_data_gen()</code> returns the artificially generated item response data for the HM-DCM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hm_dcm_data_gen(
  I = 500,
  Q,
  min_theta = 0.2,
  max_theta = 0.8,
  att_cor = 0.1,
  seed = 17
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hm_dcm_data_gen_+3A_i">I</code></td>
<td>
<p>the number of assumed respondents</p>
</td></tr>
<tr><td><code id="hm_dcm_data_gen_+3A_q">Q</code></td>
<td>
<p>the <code class="reqn">J \times K</code> binary matrix</p>
</td></tr>
<tr><td><code id="hm_dcm_data_gen_+3A_min_theta">min_theta</code></td>
<td>
<p>the minimum value of the item parameter <code class="reqn">\theta_{jht}</code></p>
</td></tr>
<tr><td><code id="hm_dcm_data_gen_+3A_max_theta">max_theta</code></td>
<td>
<p>the maximum value of the item parameter <code class="reqn">\theta_{jht}</code></p>
</td></tr>
<tr><td><code id="hm_dcm_data_gen_+3A_att_cor">att_cor</code></td>
<td>
<p>the true value of the correlation among attributes (default: 0.1)</p>
</td></tr>
<tr><td><code id="hm_dcm_data_gen_+3A_seed">seed</code></td>
<td>
<p>the seed value used for random number generation (default: 17)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including:
</p>

<dl>
<dt>X</dt><dd><p>the generated artificial item response data</p>
</dd>
<dt>alpha_true</dt><dd><p>the generated true vale of the attribute mastery pattern, matrix form</p>
</dd>
<dt>alpha_patt_true</dt><dd><p>the generated true vale of the attribute mastery pattern, string form</p>
</dd>
</dl>



<h3>References</h3>

<p>Yamaguchi, K., &amp; Martinez, A. J. (2024). Variational Bayes
inference for hidden Markov diagnostic classification models. <em>British Journal
of Mathematical and Statistical Psychology</em>, 77(1), 55–79. <a href="https://doi.org/10.1111/bmsp.12308">doi:10.1111/bmsp.12308</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>indT = 3
Q = sim_Q_J30K3
hm_sim_Q = lapply(1:indT,function(time_point) Q)
hm_sim_data = hm_dcm_data_gen(Q=hm_sim_Q,I=200)

</code></pre>

<hr>
<h2 id='mc_dina_data_gen'>Artificial data generating function for the multiple-choice DINA model based on the given Q-matrix</h2><span id='topic+mc_dina_data_gen'></span>

<h3>Description</h3>

<p><code>mc_dina_data_gen()</code> returns the artificially generated item response data for the MC-DINA model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mc_dina_data_gen(I, Q, att_cor = 0.1, seed = 17)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mc_dina_data_gen_+3A_i">I</code></td>
<td>
<p>the number of assumed respondents</p>
</td></tr>
<tr><td><code id="mc_dina_data_gen_+3A_q">Q</code></td>
<td>
<p>the <code class="reqn">J \times K</code> binary matrix</p>
</td></tr>
<tr><td><code id="mc_dina_data_gen_+3A_att_cor">att_cor</code></td>
<td>
<p>the true value of the correlation among attributes (default: 0.1)</p>
</td></tr>
<tr><td><code id="mc_dina_data_gen_+3A_seed">seed</code></td>
<td>
<p>the seed value used for random number generation (default: 17)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including:
</p>

<dl>
<dt>X</dt><dd><p>the generated artificial item response data</p>
</dd>
<dt>att_pat</dt><dd><p>the generated true vale of the attribute mastery pattern</p>
</dd>
</dl>



<h3>References</h3>

<p>Yamaguchi, K. (2020). Variational Bayesian inference for the
multiple-choice DINA model. <em>Behaviormetrika</em>, 47(1), 159-187.
<a href="https://doi.org/10.1007/s41237-020-00104-w">doi:10.1007/s41237-020-00104-w</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load a simulated Q-matrix
mc_Q = mc_sim_Q
mc_sim_data = mc_dina_data_gen(Q=mc_Q,I=200)

</code></pre>

<hr>
<h2 id='mc_sim_Q'>Artificial Q-matrix for MC-DINA model</h2><span id='topic+mc_sim_Q'></span>

<h3>Description</h3>

<p>Artificial Q-matrix for a 30-item test measuring 5 attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mc_sim_Q
</code></pre>


<h3>Format</h3>

<p>A matrix with components
</p>

<dl>
<dt>column 1</dt><dd><p>Item number</p>
</dd>
<dt>column 2</dt><dd><p>Stem</p>
</dd>
<dt>column 3 to end</dt><dd><p>attributes</p>
</dd>
</dl>



<h3>References</h3>

<p>Yamaguchi, K. (2020). Variational Bayesian inference for the
multiple-choice DINA model. <em>Behaviormetrika</em>, 47(1), 159-187.
<a href="https://doi.org/10.1007/s41237-020-00104-w">doi:10.1007/s41237-020-00104-w</a>
</p>

<hr>
<h2 id='sim_Q_J30K3'>Artificial Q-matrix for 30 items 3 attributes</h2><span id='topic+sim_Q_J30K3'></span>

<h3>Description</h3>

<p>this matrix represents an artificial Q-matrix for 30 items and 3 attributes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_Q_J30K3
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 30 rows and 3 columns.
</p>


<h3>Source</h3>

<p>artificially simulated
</p>

<hr>
<h2 id='sim_Q_J80K5'>Artificial Q-matrix for 80 items 5 attributes</h2><span id='topic+sim_Q_J80K5'></span>

<h3>Description</h3>

<p>Artificial Q-matrix for a 80-item test measuring 5 attributes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_Q_J80K5
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 80 rows and 5 columns.
</p>


<h3>Source</h3>

<p>artificially simulated
</p>

<hr>
<h2 id='variationalDCM'>Variational Bayesian estimation for DCMs</h2><span id='topic+variationalDCM'></span><span id='topic+summary.variationalDCM'></span>

<h3>Description</h3>

<p><code>variationalDCM()</code> fits DCMs by VB algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variationalDCM(X, Q, model, max_it = 500, epsilon = 1e-04, verbose = TRUE, ...)

## S3 method for class 'variationalDCM'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variationalDCM_+3A_x">X</code></td>
<td>
<p><code class="reqn">N \times J</code> item response data for the DINA, DINO, MC-DINA,
and saturated DCM models. Alternatively, <code class="reqn">T</code>-length list or 3-dim array
whose elements are <code class="reqn">N \times J/T</code> binary item response data matrices
for the HM-DCM</p>
</td></tr>
<tr><td><code id="variationalDCM_+3A_q">Q</code></td>
<td>
<p><code class="reqn">J \times K</code> binary Q-matrix for the DINA, DINO, and saturated
DCM models. For the MC-DINA model, its size should be <code class="reqn">J \times (K+2)</code>.
Alternatively, <code class="reqn">T</code>-length list or 3-dim array whose elements are
<code class="reqn">J/T \times K</code> Q-matrices for the HM-DCM</p>
</td></tr>
<tr><td><code id="variationalDCM_+3A_model">model</code></td>
<td>
<p>specify one of &quot;dina&quot;, &quot;dino&quot;, &quot;mc_dina&quot;, &quot;satu_dcm&quot;, and
&quot;hm_dcm&quot;</p>
</td></tr>
<tr><td><code id="variationalDCM_+3A_max_it">max_it</code></td>
<td>
<p>Maximum number of iterations (default: <code>500</code>)</p>
</td></tr>
<tr><td><code id="variationalDCM_+3A_epsilon">epsilon</code></td>
<td>
<p>convergence tolerance for iterations (default: <code>1e-4</code>)</p>
</td></tr>
<tr><td><code id="variationalDCM_+3A_verbose">verbose</code></td>
<td>
<p>logical, controls whether to print progress (default:
<code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="variationalDCM_+3A_...">...</code></td>
<td>
<p>additional arguments such as hyperparameter values</p>
</td></tr>
<tr><td><code id="variationalDCM_+3A_object">object</code></td>
<td>
<p>the return of the <code>variationalDCM</code> function and the argument of our <code>summary</code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>variationalDCM</code> returns an object of class
<code>variationalDCM</code>. We provide the <code>summary</code> function to summarize a
result and users can check the following information:
</p>

<dl>
<dt>model_params</dt><dd><p>estimates of posteror means and posterior standard deviations of model parameters</p>
</dd>
<dt>attr_mastery_pat</dt><dd><p>MAP etimates of attribute mastery patterns</p>
</dd>
<dt>ELBO</dt><dd><p>resulting value of evidence lower bound</p>
</dd>
<dt>time</dt><dd><p>time spent in computation</p>
</dd>
</dl>



<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>summary(variationalDCM)</code>: print summary information
</p>
</li></ul>


<h3>variationalDCM</h3>

<p>The <code>variationalDCM()</code> function performs recently-developed
variational Bayesian inference for various DCMs. The current version can
support the DINA, DINO, MC-DINA, saturated DCM, HM-DCM models. We briefly
introduce additional arguments that are specific to each model.
</p>


<h3>DINA model</h3>

<p>The DINA model has two types of model parameters: slip
<code class="reqn">s_j</code> and guessing <code class="reqn">g_j</code> for <code class="reqn">j=1,\cdots,J</code>. We name the
hyperparameters for the DINA model: <code>delta_0</code> is a L-dimensional
vector, which is a hyperparameter <code class="reqn">\boldsymbol{\delta}^0</code> for the
Dirichlet distribution for the class mixing parameter
<code class="reqn">\boldsymbol{\pi}</code> (default: NULL). When <code>delta_0</code> is specified as
<code>NULL</code>, we set <code class="reqn">\boldsymbol{\delta}^0=\boldsymbol{1}_L</code>.
<code>alpha_s</code>, <code>beta_s</code>, <code>alpha_g</code>, and <code>beta_g</code> are
positive values. They are hyperparameters {<code class="reqn">\alpha_s</code>, <code class="reqn">\beta_s</code>,
<code class="reqn">\alpha_g</code>, <code class="reqn">\beta_g</code>} that determines the shape of prior beta
distribution for the slip and guessing parameters (default: NULL). When
they are specified as <code>NULL</code>, they are set <code class="reqn">1</code>.
</p>


<h3>DINO model</h3>

<p>The DINO model has the same model parameters
and hyperparameters as the DINA model.  We thus refer the readers to the DINA model.
</p>


<h3>MC-DINA model</h3>

<p>The MC-DINA model has additional arguments
<code>delta_0</code> and <code>a_0</code>. <code>a_0</code> corresponds to positive hyperparamters
<code class="reqn">\mathbf{a}_{jc^\prime}^0</code> for all <code class="reqn">j</code> and <code class="reqn">c^\prime</code>. <code>a_0</code> is by default set to <code>NULL</code>, and then it is specified as
<code class="reqn">1</code> for all elements.
</p>


<h3>Saturated DCM</h3>

<p>The saturated DCM is a generalized model such as
the G-DINA and GDM. In the saturated DCM, we have hyperparameters
<code class="reqn">\mathbf{A}^0</code> and <code class="reqn">\mathbf{B}^0</code> in addition to
<code class="reqn">\boldsymbol{\delta}^0</code>, which can be specified as arguments <code>A_0</code>
and <code>B_0</code>. They are specified by default as <code>NULL</code>, and then we
set weakly informative priors.
</p>


<h3>HM-DCM</h3>

<p>When <code>model</code> is specified as <code>"hm_dcm"</code>, users
have additional arguments <code>nondecreasing_attribute</code>,
<code>measurement_model</code>, <code>random_block_design</code>, <code>Test_versions</code>,
<code>Test_order</code>, <code>random_start</code>, <code>A_0</code>, <code>B_0</code>,
<code>delta_0</code>, and <code>omega_0</code>. Users can accommodate the
nondecreasing attribute constraint, which represents the assumption that
mastered attributes are not forgotten, by setting the logical valued
argument <code>nondecreasing_attribute</code> as <code>TRUE</code> (default:
<code>FALSE</code>). Users can also control the measurement model by specifying
<code>measurement_model</code> (default: <code>"general"</code>), and the current
version can deal with the HM-general DCM (<code>"general"</code>) and HM-DINA
(<code>"dina"</code>) models. This function can also handle the datasets
collected by a random block design by specifying the logical valued
argument <code>random_block_design</code> (default: <code>FALSE</code>). When it is
specified as <code>TRUE</code>, users must enter <code>Test_versions</code> and
<code>Test_order</code>. <code>Test_versions</code> is an argument indicating which
version of the test each respondent has been assigned to based on a random
block design, while <code>Test_order</code> indicates the sequence in which items
are rearranged based on the random block design. <code>A_0</code>, <code>B_0</code>,
<code>delta_0</code>, and <code>omega_0</code> correspond to hyperparameters
<code class="reqn">\mathbf{A}^0</code>, <code class="reqn">\mathbf{B}^0</code>, <code class="reqn">\boldsymbol{\delta}^0</code>, and
<code class="reqn">\boldsymbol{\Omega}^0</code>. <code class="reqn">\boldsymbol{\Omega}^0</code> is nonnegative
hyperparameters of Dirichlet distributions for attribute transition
probabilities. <code>omega_0</code> is by default set to <code>NULL</code>, and then
we set <code class="reqn">\boldsymbol{\Omega}^0=\mathbf{1}_L\mathbf{1}_L^\top</code>.
</p>


<h3>References</h3>

<p>Yamaguchi, K., &amp; Okada, K. (2020). Variational Bayes inference
for the DINA model. <em>Journal of Educational and Behavioral
Statistics</em>, 45(5), 569-597. <a href="https://doi.org/10.3102/1076998620911934">doi:10.3102/1076998620911934</a>
</p>
<p>Yamaguchi, K. (2020). Variational Bayesian inference for the
multiple-choice DINA model. <em>Behaviormetrika</em>, 47(1), 159-187.
<a href="https://doi.org/10.1007/s41237-020-00104-w">doi:10.1007/s41237-020-00104-w</a>
</p>
<p>Yamaguchi, K., Okada, K. (2020). Variational Bayes Inference Algorithm for
the Saturated Diagnostic Classification Model. <em>Psychometrika</em>, 85(4),
973–995. <a href="https://doi.org/10.1007/s11336-020-09739-w">doi:10.1007/s11336-020-09739-w</a>
</p>
<p>Yamaguchi, K., &amp; Martinez, A. J. (2024). Variational Bayes inference for
hidden Markov diagnostic classification models. <em>British Journal of
Mathematical and Statistical Psychology</em>, 77(1), 55–79.
<a href="https://doi.org/10.1111/bmsp.12308">doi:10.1111/bmsp.12308</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# fit the DINA model
Q = sim_Q_J80K5
sim_data = dina_data_gen(Q=Q,I=200)
res = variationalDCM(X=sim_data$X, Q=Q, model="dina")
summary(res)



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
