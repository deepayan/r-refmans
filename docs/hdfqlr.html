<!DOCTYPE html><html><head><title>Help for package hdfqlr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hdfqlr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as_hdfql_sequence'><p>Format Sequence For HDFql</p></a></li>
<li><a href='#create'><p>Create HDF Object</p></a></li>
<li><a href='#drop'><p>Drop HDF objects.</p></a></li>
<li><a href='#dtype_to_rtype'><p>HDF Data Type to R Type</p></a></li>
<li><a href='#execute_with_memory'><p>Execute With Memory</p></a></li>
<li><a href='#get_attr_names'><p>Get HDF Attribute Names</p></a></li>
<li><a href='#get_char_data'><p>Get Character Data</p></a></li>
<li><a href='#get_charset'><p>Get HDF Object Charset</p></a></li>
<li><a href='#get_cursor_values'><p>Value From Cursor</p></a></li>
<li><a href='#get_data'><p>Get Data</p></a></li>
<li><a href='#get_data_type'><p>Get HDF Object Data Type</p></a></li>
<li><a href='#get_dimension'><p>Get HDF Object Dimension</p></a></li>
<li><a href='#get_key'><p>Get List Keys or Values</p></a></li>
<li><a href='#get_object_type'><p>Get HDF Object Type</p></a></li>
<li><a href='#get_size'><p>Get HDF Object Size</p></a></li>
<li><a href='#hdfqlr'><p>hdfqlr: an HDF API based on HDFql</p></a></li>
<li><a href='#hql'><p>HDFql Wrapper Constants and Functions</p></a></li>
<li><a href='#hql_create'><p>Create HDF Files, Datasets or Attribute</p></a></li>
<li><a href='#hql_drop'><p>Drop HDF groups, datasets, and attributes</p></a></li>
<li><a href='#hql_file'><p>Access HDF Files</p></a></li>
<li><a href='#hql_flush'><p>Flush HDF Files</p></a></li>
<li><a href='#hql_is_loaded'><p>HDFql Library Status</p></a></li>
<li><a href='#hql_list'><p>List HDF Groups, Datasets or Attributes</p></a></li>
<li><a href='#hql_load'><p>Load HDFql DLLs</p></a></li>
<li><a href='#hql_read'><p>Read HDF Dataset or Attribute</p></a></li>
<li><a href='#hql_write'><p>Write HDF Dataset or Attribute</p></a></li>
<li><a href='#hql.paths'><p>HDFql Library Paths</p></a></li>
<li><a href='#int_to_char'><p>HDF Integer Output to Character</p></a></li>
<li><a href='#list_hdf'><p>List HDF Objects</p></a></li>
<li><a href='#path_from_options'><p>HDFql Default Path</p></a></li>
<li><a href='#recurse_groups'><p>Recursively Walk Group Structure</p></a></li>
<li><a href='#rtype_to_dtype'><p>R Type to HDF Data Type</p></a></li>
<li><a href='#set_char_data'><p>Set Character Data</p></a></li>
<li><a href='#set_data'><p>Set Data</p></a></li>
<li><a href='#set_paths'><p>HDFql Paths</p></a></li>
<li><a href='#stop_not_loaded'><p>HDFql Load Requirement</p></a></li>
<li><a href='#write'><p>Write HDF Object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Interface to 'HDFql' API</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6-2</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides an interface to 'HDFql' <a href="https://www.hdfql.com/">https://www.hdfql.com/</a> 
    and helper functions for reading data from and writing data to 'HDF5' files. 'HDFql' 
    provides a high-level language for managing 'HDF5' data that is platform independent.
    For more information, see the reference manual 
    <a href="https://www.hdfql.com/resources/HDFqlReferenceManual.pdf">https://www.hdfql.com/resources/HDFqlReferenceManual.pdf</a>.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bit64 (&ge; 0.9), knitr (&ge; 1.22), ggplot2 (&ge; 3.2),
microbenchmark (&ge; 1.4), testthat (&ge; 2.1.0), rmarkdown (&ge;
2.8)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>HDFql (&gt;= 2.1.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-06-11 04:23:11 UTC; michael</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael Koohafkan [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael Koohafkan &lt;michael.koohafkan@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-06-11 04:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='as_hdfql_sequence'>Format Sequence For HDFql</h2><span id='topic+as_hdfql_sequence'></span>

<h3>Description</h3>

<p>Format an integer sequence for selection with HDFql.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_hdfql_sequence(s)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_hdfql_sequence_+3A_s">s</code></td>
<td>
<p>An integer sequence.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of character representations of the integer sequence.
</p>

<hr>
<h2 id='create'>Create HDF Object</h2><span id='topic+create'></span><span id='topic+create_group'></span><span id='topic+create_dataset'></span><span id='topic+create_attribute'></span>

<h3>Description</h3>

<p>Generic helper for creating HDF objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create(
  what = c("FILE", "GROUP", "DATASET", "ATTRIBUTE"),
  path,
  data.type,
  size,
  overwrite = FALSE,
  parallel = FALSE
)

create_group(group, overwrite = FALSE)

create_dataset(
  dataset,
  data.type,
  size = NULL,
  overwrite = FALSE,
  parallel = FALSE
)

create_attribute(
  attribute,
  data.type,
  size = NULL,
  overwrite = FALSE,
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_+3A_what">what</code></td>
<td>
<p>The type of object to create.</p>
</td></tr>
<tr><td><code id="create_+3A_path">path</code></td>
<td>
<p>The target location of the object.</p>
</td></tr>
<tr><td><code id="create_+3A_data.type">data.type</code></td>
<td>
<p>The HDF data type of the dataset or attribute.</p>
</td></tr>
<tr><td><code id="create_+3A_size">size</code></td>
<td>
<p>The size (dimensions) of the dataset or attribute.
For <code>CHAR</code> datasets or attributes, the last element of <code>size</code>
is the string length.</p>
</td></tr>
<tr><td><code id="create_+3A_overwrite">overwrite</code></td>
<td>
<p>If <code>TRUE</code>, overwrite existing file, group,
attribute, or dataset.</p>
</td></tr>
<tr><td><code id="create_+3A_parallel">parallel</code></td>
<td>
<p>If <code>TRUE</code>, use parallel capabilities.</p>
</td></tr>
<tr><td><code id="create_+3A_group">group</code></td>
<td>
<p>The group to create.</p>
</td></tr>
<tr><td><code id="create_+3A_dataset">dataset</code></td>
<td>
<p>The dataset to create.</p>
</td></tr>
<tr><td><code id="create_+3A_attribute">attribute</code></td>
<td>
<p>The attribute to create.</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>create_group</code>: Create HDF group.
</p>
</li>
<li> <p><code>create_dataset</code>: Create HDF dataset.
</p>
</li>
<li> <p><code>create_attribute</code>: Create HDF attribute.
</p>
</li></ul>

<hr>
<h2 id='drop'>Drop HDF objects.</h2><span id='topic+drop'></span><span id='topic+hql_drop_dataset'></span><span id='topic+hql_drop_group'></span><span id='topic+hql_drop_attribute'></span><span id='topic+hql_drop_all_attributes'></span>

<h3>Description</h3>

<p>Drop HDF objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop(what = c("FILE", "GROUP", "DATASET", "ATTRIBUTE"), path)

hql_drop_dataset(dataset)

hql_drop_group(group, recursive = FALSE)

hql_drop_attribute(attribute)

hql_drop_all_attributes(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drop_+3A_path">path</code></td>
<td>
<p>The HDF dataset or group.</p>
</td></tr>
<tr><td><code id="drop_+3A_dataset">dataset</code></td>
<td>
<p>The dataset to drop.</p>
</td></tr>
<tr><td><code id="drop_+3A_group">group</code></td>
<td>
<p>The group to drop.</p>
</td></tr>
<tr><td><code id="drop_+3A_recursive">recursive</code></td>
<td>
<p>If <code>TRUE</code>, drop all child groups and datasets.</p>
</td></tr>
<tr><td><code id="drop_+3A_attribute">attribute</code></td>
<td>
<p>The attribute to drop.</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>hql_drop_dataset</code>: Drop HDF dataset.
</p>
</li>
<li> <p><code>hql_drop_group</code>: Drop HDF group.
</p>
</li>
<li> <p><code>hql_drop_attribute</code>: Drop HDF attribute.
</p>
</li>
<li> <p><code>hql_drop_all_attributes</code>: Drop all attributes from an HDF dataset or group.
</p>
</li></ul>

<hr>
<h2 id='dtype_to_rtype'>HDF Data Type to R Type</h2><span id='topic+dtype_to_rtype'></span>

<h3>Description</h3>

<p>HDF Data Type to R Type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtype_to_rtype(dtype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dtype_to_rtype_+3A_dtype">dtype</code></td>
<td>
<p>The HDF data type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The equivalent R class, or <code>NULL</code> if not found.
</p>

<hr>
<h2 id='execute_with_memory'>Execute With Memory</h2><span id='topic+execute_with_memory'></span>

<h3>Description</h3>

<p>Generic helper for executing HDFql operations using memory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>execute_with_memory(
  script,
  variable = NULL,
  direction = c("INTO", "FROM"),
  suffix = NULL,
  stop.on.error = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="execute_with_memory_+3A_script">script</code></td>
<td>
<p>The HDFQL operation to execute.
Do not include <code>FROM</code> or <code>INTO</code> statements.</p>
</td></tr>
<tr><td><code id="execute_with_memory_+3A_variable">variable</code></td>
<td>
<p>if not <code>NULL</code>, the variable to register for this operation.</p>
</td></tr>
<tr><td><code id="execute_with_memory_+3A_direction">direction</code></td>
<td>
<p>Either <code>"FROM"</code> or <code>"INTO"</code>. Ignored if <code>variable</code>
is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="execute_with_memory_+3A_suffix">suffix</code></td>
<td>
<p>Additional script specifications. This can be used for
post-processing (for SELECT operations) or for writing raw values
(for INSERT operations).</p>
</td></tr>
<tr><td><code id="execute_with_memory_+3A_stop.on.error">stop.on.error</code></td>
<td>
<p>If <code>TRUE</code>, return an error message if script
fails. If <code>FALSE</code>, return the HDFql error value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The script output, or <code>NULL</code>.
</p>

<hr>
<h2 id='get_attr_names'>Get HDF Attribute Names</h2><span id='topic+get_attr_names'></span>

<h3>Description</h3>

<p>Get HDF Attribute Names
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_attr_names(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_attr_names_+3A_path">path</code></td>
<td>
<p>The path of the dataset or group from which to
retrieve attribute names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of attribute names.
</p>

<hr>
<h2 id='get_char_data'>Get Character Data</h2><span id='topic+get_char_data'></span>

<h3>Description</h3>

<p>Get character data from HDF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_char_data(path, otype, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_char_data_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
<tr><td><code id="get_char_data_+3A_otype">otype</code></td>
<td>
<p>The HDF object type.</p>
</td></tr>
<tr><td><code id="get_char_data_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel processing functionality.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An R array.
</p>

<hr>
<h2 id='get_charset'>Get HDF Object Charset</h2><span id='topic+get_charset'></span>

<h3>Description</h3>

<p>Get HDF Object Charset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_charset(path, otype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_charset_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
<tr><td><code id="get_charset_+3A_otype">otype</code></td>
<td>
<p>The HDF object type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The HDF object charset.
</p>

<hr>
<h2 id='get_cursor_values'>Value From Cursor</h2><span id='topic+get_cursor_values'></span>

<h3>Description</h3>

<p>Generic helper for executing HDFql cursor operations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_cursor_values(script)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_cursor_values_+3A_script">script</code></td>
<td>
<p>The HDFQL operation to execute.
Do not include <code>FROM</code> or <code>INTO</code> statements.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The script output, or <code>NULL</code>.
</p>

<hr>
<h2 id='get_data'>Get Data</h2><span id='topic+get_data'></span>

<h3>Description</h3>

<p>Get data from HDF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_data(path, otype, transpose = TRUE, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_data_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
<tr><td><code id="get_data_+3A_otype">otype</code></td>
<td>
<p>The HDF object type.</p>
</td></tr>
<tr><td><code id="get_data_+3A_transpose">transpose</code></td>
<td>
<p>If <code>TRUE</code>, transpose the data.</p>
</td></tr>
<tr><td><code id="get_data_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel processing functionality.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An R array.
</p>

<hr>
<h2 id='get_data_type'>Get HDF Object Data Type</h2><span id='topic+get_data_type'></span>

<h3>Description</h3>

<p>Get HDF Object Data Type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_data_type(path, otype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_data_type_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
<tr><td><code id="get_data_type_+3A_otype">otype</code></td>
<td>
<p>The HDF object type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The HDF object data type.
</p>

<hr>
<h2 id='get_dimension'>Get HDF Object Dimension</h2><span id='topic+get_dimension'></span>

<h3>Description</h3>

<p>Get HDF Object Dimension
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_dimension(path, otype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_dimension_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
<tr><td><code id="get_dimension_+3A_otype">otype</code></td>
<td>
<p>The HDF object type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The HDF object dimensions.
</p>

<hr>
<h2 id='get_key'>Get List Keys or Values</h2><span id='topic+get_key'></span>

<h3>Description</h3>

<p>Get the value of a list key, or the key of a list value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_key(x, l, invert = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_key_+3A_x">x</code></td>
<td>
<p>A key or value.</p>
</td></tr>
<tr><td><code id="get_key_+3A_l">l</code></td>
<td>
<p>A named list.</p>
</td></tr>
<tr><td><code id="get_key_+3A_invert">invert</code></td>
<td>
<p>If <code>TRUE</code>, return the key associated with
the given value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A key or value.
</p>

<hr>
<h2 id='get_object_type'>Get HDF Object Type</h2><span id='topic+get_object_type'></span>

<h3>Description</h3>

<p>Get HDF Object Type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_object_type(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_object_type_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The HDF object type.
</p>

<hr>
<h2 id='get_size'>Get HDF Object Size</h2><span id='topic+get_size'></span>

<h3>Description</h3>

<p>Get HDF Object Size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_size(path, otype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_size_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
<tr><td><code id="get_size_+3A_otype">otype</code></td>
<td>
<p>The HDF object type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The HDF object size.
</p>

<hr>
<h2 id='hdfqlr'>hdfqlr: an HDF API based on HDFql</h2><span id='topic+hdfqlr'></span><span id='topic+hdfqlr-package'></span>

<h3>Description</h3>

<p>This package provides an R interface to HDF files using the
<a href="https://www.hdfql.com/">HDFql</a>.
</p>


<h3>Package options</h3>

<p>hdfqlr uses the following <code><a href="base.html#topic+options">options()</a></code> to configure behavior:
</p>

<ul>
<li> <p><code>hdfqlr.dir</code>: The HDFql install directory.
</p>
</li></ul>

<p>Alternatively, the HDFql install directory can be saved to an
environment variable <code>HDFQL_DIR</code>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Michael Koohafkan <a href="mailto:michael.koohafkan@gmail.com">michael.koohafkan@gmail.com</a>
</p>

<hr>
<h2 id='hql'>HDFql Wrapper Constants and Functions</h2><span id='topic+hql'></span>

<h3>Description</h3>

<p>Access the constants and functions provided by the
HDFql wrapper. The wrapper contents are stored in an
environment when the HDFql library is loaded and used
internally by hdfqlr to perform operations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql
</code></pre>


<h3>Format</h3>

<p>An object of class <code>environment</code> of length 1.
</p>


<h3>Details</h3>

<p>This environment is exported so that users
can directly use the HDFql wrapper functions.
The intended method of use is to <code><a href="base.html#topic+attach">attach()</a></code> the environment
to the search path. For more information on what is provided
by the wrapper, consult the
<a href="https://www.hdfql.com/#documentation">HDFql reference manual</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  attach(hql$wrapper)

## End(Not run)

</code></pre>

<hr>
<h2 id='hql_create'>Create HDF Files, Datasets or Attribute</h2><span id='topic+hql_create'></span><span id='topic+hql_create_file'></span><span id='topic+hql_create_group'></span>

<h3>Description</h3>

<p>Create HDF files and groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql_create_file(file, overwrite = FALSE, parallel = FALSE)

hql_create_group(group, overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hql_create_+3A_file">file</code></td>
<td>
<p>The HDF file to create.</p>
</td></tr>
<tr><td><code id="hql_create_+3A_overwrite">overwrite</code></td>
<td>
<p>If <code>TRUE</code>, overwrite existing file, group,
attribute, or dataset.</p>
</td></tr>
<tr><td><code id="hql_create_+3A_parallel">parallel</code></td>
<td>
<p>If <code>TRUE</code>, use parallel capabilities.</p>
</td></tr>
<tr><td><code id="hql_create_+3A_group">group</code></td>
<td>
<p>The group to create.</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>hql_create_file</code>: Create HDF file.
</p>
</li>
<li> <p><code>hql_create_group</code>: Create HDF group.
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>if(hql_is_loaded()) {
  tf = tempfile(fileext = ".h5")
  hql_create_file(tf)

  hql_use_file(tf)
  hql_create_group("group1")

  hql_close_file(tf)
}

</code></pre>

<hr>
<h2 id='hql_drop'>Drop HDF groups, datasets, and attributes</h2><span id='topic+hql_drop'></span>

<h3>Description</h3>

<p>Drop a datset, attribute, or group from an HDF file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(hql_is_loaded()){
  tf = tempfile(fileext = ".h5")
  hql_create_file(tf)

  hql_use_file(tf)
  x = rnorm(10)
  attr(x, "myattribute") = "some information"
  hql_write_dataset(x, "mygroup/mydataset")

  hql_drop_attribute("mygroup/mydataset/myattribute")
  hql_drop_dataset("mygroup/mydataset")
  hql_drop_group("mygroup")
  
  hql_close_file(tf)
}

</code></pre>

<hr>
<h2 id='hql_file'>Access HDF Files</h2><span id='topic+hql_file'></span><span id='topic+hql_use_file'></span><span id='topic+hql_close_file'></span>

<h3>Description</h3>

<p>Open (use) and close HDF files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql_use_file(file)

hql_close_file(file, all = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hql_file_+3A_file">file</code></td>
<td>
<p>The HDF file path.</p>
</td></tr>
<tr><td><code id="hql_file_+3A_all">all</code></td>
<td>
<p>If <code>TRUE</code>, close all open HDF files.</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>hql_use_file</code>: Open (use) an HDF file.
</p>
</li>
<li> <p><code>hql_close_file</code>: Close an HDF file.
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>if(hql_is_loaded()){
  tf = tempfile(fileext = ".h5")
  hql_create_file(tf)

  hql_use_file(tf)
  hql_flush()

  hql_close_file(tf)
}

</code></pre>

<hr>
<h2 id='hql_flush'>Flush HDF Files</h2><span id='topic+hql_flush'></span>

<h3>Description</h3>

<p>Flush HDF file(s) to write buffered data to the disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql_flush(global = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hql_flush_+3A_global">global</code></td>
<td>
<p>If <code>TRUE</code>, a global flush is performed and
and all open HDF files are flushed. If <code>FALSE</code>, a local
flush is performed and only the HDF file currently in use
is flushed.</p>
</td></tr>
</table>

<hr>
<h2 id='hql_is_loaded'>HDFql Library Status</h2><span id='topic+hql_is_loaded'></span>

<h3>Description</h3>

<p>Check if the HDFql library loaded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql_is_loaded()
</code></pre>


<h3>Value</h3>

<p>Logical <code>TRUE</code> if DLLs are found, <code>FALSE</code> otherwise.
</p>

<hr>
<h2 id='hql_list'>List HDF Groups, Datasets or Attributes</h2><span id='topic+hql_list'></span><span id='topic+hql_list_groups'></span><span id='topic+hql_list_datasets'></span><span id='topic+hql_list_attributes'></span>

<h3>Description</h3>

<p>List groups, datasets or attribute in an HDF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql_list_groups(path, recursive = FALSE)

hql_list_datasets(path, recursive = FALSE)

hql_list_attributes(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hql_list_+3A_path">path</code></td>
<td>
<p>The location of the dataset, attribute, or group
within the HDF file.</p>
</td></tr>
<tr><td><code id="hql_list_+3A_recursive">recursive</code></td>
<td>
<p>Recursively list child groups or datasets.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of paths.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>hql_list_groups</code>: List groups.
</p>
</li>
<li> <p><code>hql_list_datasets</code>: List datasets.
</p>
</li>
<li> <p><code>hql_list_attributes</code>: List Attributes
</p>
</li></ul>

<hr>
<h2 id='hql_load'>Load HDFql DLLs</h2><span id='topic+hql_load'></span><span id='topic+hql_unload'></span>

<h3>Description</h3>

<p>Load the HDFql library.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql_load(path)

hql_unload()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hql_load_+3A_path">path</code></td>
<td>
<p>The path to the HDFql installation.</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>hql_unload</code>: Unload HDFql Library.
</p>
</li></ul>

<hr>
<h2 id='hql_read'>Read HDF Dataset or Attribute</h2><span id='topic+hql_read'></span><span id='topic+hql_read_dataset'></span><span id='topic+hql_read_attribute'></span><span id='topic+hql_read_all_attributes'></span>

<h3>Description</h3>

<p>Read a dataset or attribute from an HDF file into memory.
</p>
<p>Generic helper for reading HDF objects into memory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql_read(what = c("DATASET", "ATTRIBUTE"), path, parallel = FALSE)

hql_read_dataset(path, include.attributes = TRUE, parallel = FALSE)

hql_read_attribute(path, parallel = FALSE)

hql_read_all_attributes(path, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hql_read_+3A_path">path</code></td>
<td>
<p>The location of the dataset, attribute, or group within the HDF file.</p>
</td></tr>
<tr><td><code id="hql_read_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel processing functionality.</p>
</td></tr>
<tr><td><code id="hql_read_+3A_include.attributes">include.attributes</code></td>
<td>
<p>If <code>TRUE</code>, include the dataset attributes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix.
</p>
<p>The attribute value.
</p>
<p>A named list of attributes.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>hql_read_dataset</code>: Read a dataset from an HDF file.
</p>
</li>
<li> <p><code>hql_read_attribute</code>: Read a single attribute from an HDF file.
</p>
</li>
<li> <p><code>hql_read_all_attributes</code>: Read attributes from an HDF file.
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>if(hql_is_loaded()){
  tf = tempfile(fileext = ".h5")
  hql_create_file(tf)

  hql_use_file(tf)
  x = matrix(rnorm(100), nrow = 20)
  hql_write_dataset(x, "dataset0")
  hql_write_attribute("normal", "dataset0/dist")
 y = month.name
 attr(y, "abbreviation") = month.abb
 attr(y, "number") = 1:12
 hql_write_dataset(y, "group1/dataset1")

hql_read_dataset("dataset0")
hql_read_dataset("group1/dataset1")
hql_read_attribute("group1/dataset1/abbreviation")
hql_read_all_attributes("group1/dataset1")

hql_close_file(tf)
}

</code></pre>

<hr>
<h2 id='hql_write'>Write HDF Dataset or Attribute</h2><span id='topic+hql_write'></span><span id='topic+hql_write_dataset'></span><span id='topic+hql_write_attribute'></span><span id='topic+hql_write_all_attributes'></span>

<h3>Description</h3>

<p>Write a dataset or attribute to an HDF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql_write_dataset(
  dataset,
  path,
  include.attributes = TRUE,
  overwrite = FALSE,
  parallel = FALSE
)

hql_write_attribute(attribute, path, overwrite = FALSE, parallel = FALSE)

hql_write_all_attributes(attributes, path, overwrite = FALSE, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hql_write_+3A_dataset">dataset</code></td>
<td>
<p>The dataset to write. The object must be coercible
to an array.</p>
</td></tr>
<tr><td><code id="hql_write_+3A_path">path</code></td>
<td>
<p>The location within the HDF file to write the dataset or attribute(s).</p>
</td></tr>
<tr><td><code id="hql_write_+3A_include.attributes">include.attributes</code></td>
<td>
<p>If <code>TRUE</code>, write the dataset attributes.</p>
</td></tr>
<tr><td><code id="hql_write_+3A_overwrite">overwrite</code></td>
<td>
<p>If <code>TRUE</code>, overwrite existing dataset or attribute.</p>
</td></tr>
<tr><td><code id="hql_write_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel processing functionality.</p>
</td></tr>
<tr><td><code id="hql_write_+3A_attribute">attribute</code></td>
<td>
<p>The attribute to write.</p>
</td></tr>
<tr><td><code id="hql_write_+3A_attributes">attributes</code></td>
<td>
<p>A list of attributes to write.</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>hql_write_dataset</code>: Write a dataset to an HDF file.
</p>
</li>
<li> <p><code>hql_write_attribute</code>: Write an attribute to an HDF file.
</p>
</li>
<li> <p><code>hql_write_all_attributes</code>: Write multiple attributes to an HDF file.
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>if(hql_is_loaded()){
  tf = tempfile(fileext = ".h5")
  hql_create_file(tf)

  hql_use_file(tf)
  x = matrix(rnorm(100), nrow = 20)
  hql_write_dataset(x, "dataset0")
  hql_write_attribute("normal", "dataset0/dist")

  y = month.name
  attr(y, "abbreviation") = month.abb
  hql_write_dataset(y, "group1/dataset1")

  hql_close_file(tf)
}

</code></pre>

<hr>
<h2 id='hql.paths'>HDFql Library Paths</h2><span id='topic+hql.paths'></span>

<h3>Description</h3>

<p>Environment containing information related to the
HDFql library on the user's system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hql.paths
</code></pre>


<h3>Format</h3>

<p>An object of class <code>environment</code> of length 4.
</p>

<hr>
<h2 id='int_to_char'>HDF Integer Output to Character</h2><span id='topic+int_to_char'></span>

<h3>Description</h3>

<p>Convert integer data from an HDF file to characters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>int_to_char(x, trim = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="int_to_char_+3A_x">x</code></td>
<td>
<p>An integer array.</p>
</td></tr>
<tr><td><code id="int_to_char_+3A_trim">trim</code></td>
<td>
<p>If <code>TRUE</code>, trim whitespace from the character data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character array.
</p>

<hr>
<h2 id='list_hdf'>List HDF Objects</h2><span id='topic+list_hdf'></span>

<h3>Description</h3>

<p>List HDF Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_hdf(what = c("GROUP", "DATASET", "ATTRIBUTE"), path)
</code></pre>

<hr>
<h2 id='path_from_options'>HDFql Default Path</h2><span id='topic+path_from_options'></span>

<h3>Description</h3>

<p>Retrieve the HDFql installation directory from existing options.
This function is used to automatically connect to HDFql without
needing to specify the installation path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>path_from_options(startup = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="path_from_options_+3A_startup">startup</code></td>
<td>
<p>If <code>TRUE</code>, indicates the paths are being
detected as part of package startup.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first looks for the R option <code>hdfqlr.dir</code>,
and second looks for the environment variable <code>HDFQL_DIR</code>.
</p>

<hr>
<h2 id='recurse_groups'>Recursively Walk Group Structure</h2><span id='topic+recurse_groups'></span><span id='topic+rev_recurse_groups'></span>

<h3>Description</h3>

<p>Recursively walk through HDF groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recurse_groups(path)

rev_recurse_groups(path)
</code></pre>

<hr>
<h2 id='rtype_to_dtype'>R Type to HDF Data Type</h2><span id='topic+rtype_to_dtype'></span>

<h3>Description</h3>

<p>R Type to HDF Data Type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rtype_to_dtype(rtype, stop.on.error = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rtype_to_dtype_+3A_rtype">rtype</code></td>
<td>
<p>The R class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The equivalent HDF data type, or <code>NULL</code> if not found.
</p>

<hr>
<h2 id='set_char_data'>Set Character Data</h2><span id='topic+set_char_data'></span>

<h3>Description</h3>

<p>Set character data in HDF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_char_data(x, path, otype, transpose = FALSE, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_char_data_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
<tr><td><code id="set_char_data_+3A_otype">otype</code></td>
<td>
<p>The HDF object type.</p>
</td></tr>
<tr><td><code id="set_char_data_+3A_transpose">transpose</code></td>
<td>
<p>If <code>TRUE</code>, transpose the data.</p>
</td></tr>
<tr><td><code id="set_char_data_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel processing functionality.</p>
</td></tr>
</table>

<hr>
<h2 id='set_data'>Set Data</h2><span id='topic+set_data'></span>

<h3>Description</h3>

<p>Set data in HDF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_data(x, path, otype, transpose = TRUE, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_data_+3A_path">path</code></td>
<td>
<p>The location of the object within the HDF file.</p>
</td></tr>
<tr><td><code id="set_data_+3A_otype">otype</code></td>
<td>
<p>The HDF object type.</p>
</td></tr>
<tr><td><code id="set_data_+3A_transpose">transpose</code></td>
<td>
<p>If <code>TRUE</code>, transpose the data.</p>
</td></tr>
<tr><td><code id="set_data_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel processing functionality.</p>
</td></tr>
</table>

<hr>
<h2 id='set_paths'>HDFql Paths</h2><span id='topic+set_paths'></span>

<h3>Description</h3>

<p>Set the partial paths to the HDFql library and wrapper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_paths()
</code></pre>

<hr>
<h2 id='stop_not_loaded'>HDFql Load Requirement</h2><span id='topic+stop_not_loaded'></span>

<h3>Description</h3>

<p>Return an error if the HDFql library is not loaded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stop_not_loaded()
</code></pre>

<hr>
<h2 id='write'>Write HDF Object</h2><span id='topic+write'></span>

<h3>Description</h3>

<p>Write HDF Object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write(what, x, path, overwrite = FALSE, parallel = FALSE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
