<!DOCTYPE html><html><head><title>Help for package HDLSSkST</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HDLSSkST}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#HDLSSkST-package'>
<p>Distribution-Free Exact High Dimensional Low Sample Size k-Sample Tests</p></a></li>
<li><a href='#AFStest'>
<p>k-Sample AFS Test of Equal Distributions</p></a></li>
<li><a href='#ARItest'>
<p>k-Sample ARI Test of Equal Distributions</p></a></li>
<li><a href='#BenHoch'>
<p>Benjamini-Hochbergs step-up-procedure (1995)</p></a></li>
<li><a href='#FStest'>
<p>k-Sample FS Test of Equal Distributions</p></a></li>
<li><a href='#gMADD'>
<p>Modified K-Means Algorithm by Using a New Dissimilarity Measure, MADD</p></a></li>
<li><a href='#gMADD_DI'>
<p>Modified K-Means Algorithm by Using a New Dissimilarity Measure, MADD and DUNN Index</p></a></li>
<li><a href='#Holm'>
<p>Holm's step-down-procedure (1979)</p></a></li>
<li><a href='#MTFStest'>
<p>k-Sample MTFS Test of Equal Distributions</p></a></li>
<li><a href='#MTRItest'>
<p>k-Sample MTRI Test of Equal Distributions</p></a></li>
<li><a href='#pmf'>
<p>Generalized Hypergeometric Probability</p></a></li>
<li><a href='#randfun'>
<p>Rand Index</p></a></li>
<li><a href='#rctab'><p> Generates an <code class="reqn">r\times c</code> Contingency Table</p></a></li>
<li><a href='#RItest'>
<p>k-Sample RI Test of Equal Distributions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Distribution-Free Exact High Dimensional Low Sample Size
k-Sample Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-02-01</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Biplab Paul &lt;paul.biplab497@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Testing homogeneity of k multivariate distributions is a classical and challenging problem in
             statistics, and this becomes even more challenging when the dimension of the data exceeds the sample size.
             We construct some tests for this purpose which are exact level (size) alpha tests based on clustering. 
             These tests are easy to implement and distribution-free in finite sample situations. Under appropriate 
             regularity conditions, these tests have the consistency property in HDLSS asymptotic regime, where the 
             dimension of data grows to infinity while the sample size remains fixed. We also consider a multiscale 
             approach, where the results for different number of partitions are aggregated judiciously. Details are in 
             Biplab Paul, Shyamal K De and Anil K Ghosh (2021) &lt;<a href="https://doi.org/10.1016%2Fj.jmva.2021.104897">doi:10.1016/j.jmva.2021.104897</a>&gt;; Soham Sarkar and Anil K Ghosh (2019) 
             &lt;<a href="https://doi.org/10.1109%2FTPAMI.2019.2912599">doi:10.1109/TPAMI.2019.2912599</a>&gt;; William M Rand (1971) &lt;<a href="https://doi.org/10.1080%2F01621459.1971.10482356">doi:10.1080/01621459.1971.10482356</a>&gt;;  
             Cyrus R Mehta and Nitin R Patel (1983) &lt;<a href="https://doi.org/10.2307%2F2288652">doi:10.2307/2288652</a>&gt;; Joseph C Dunn (1973) 
             &lt;<a href="https://doi.org/10.1080%2F01969727308546046">doi:10.1080/01969727308546046</a>&gt;; Sture Holm (1979) &lt;<a href="https://doi.org/10.2307%2F4615733">doi:10.2307/4615733</a>&gt;; 
             Yoav Benjamini and Yosef Hochberg (1995) &lt;<a href="https://doi.org/10.2307%2F2346101">doi:10.2307/2346101</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.3), stats, utils</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Author:</td>
<td>Biplab Paul [aut, cre],
  Shyamal K. De [aut],
  Anil K. Ghosh [aut]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-01 14:20:21 UTC; GOBINDO</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-02 08:00:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='HDLSSkST-package'>
Distribution-Free Exact High Dimensional Low Sample Size k-Sample Tests
</h2><span id='topic+HDLSSkST-package'></span>

<h3>Description</h3>

<p>Testing homogeneity of k (<code class="reqn">\geq 2</code>) multivariate distributions is a classical and challenging problem in statistics, and this becomes even more challenging when the dimension of the data exceeds the sample size. We construct some tests for this purpose which are exact level (size) <code class="reqn">\alpha</code> tests based on clustering. These tests are easy to implement and distribution-free in finite sample situations. Under appropriate regularity conditions, these tests have the consistency property in HDLSS asymptotic regime, where the dimension of data <code class="reqn">d</code> grows to <code class="reqn">\infty</code> while the sample size remains fixed. We also consider a multiscale approach, where the results for the different number of partitions are aggregated judiciously. This package includes eight tests, namely (i) RI test, (ii) FS test, (iii) MRI test, (iv) MFS test, (v) MTRI test , (vi) MTFS test, (vii) ARI test and (viii) AFS test. In MRI and MFS test, we modified the RI and FS test, respectively, using an estimated clustering number. In the multiscale approach (MTRI and MTFS), we use Holm's step-down-procedure (1979) and Benjamini-Hochberg FDR controlling procedure (1995).
</p>


<h3>Author(s)</h3>

<p>Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Soham Sarkar and Anil K Ghosh (2019). On perfect clustering of high dimension, low sample size data, <em>IEEE transactions on pattern analysis and machine intelligence</em>, doi:10.1109/TPAMI.2019.2912599.
</p>
<p>William M Rand (1971). Objective criteria for the evaluation of clustering methods, <em>Journal of the American Statistical association</em>, 66(336):846-850, doi:10.1080/01621459.1971.10482356.
</p>
<p>Cyrus R Mehta and Nitin R Patel (1983). A network algorithm for performing Fisher's exact test in rxc contingency tables, <em>Journal of the American Statistical Association</em>, 78(382):427-434, doi:10.2307/2288652.
</p>
<p>Joseph C Dunn (1973). A fuzzy relative of the isodata process and its use in detecting compact well-separated clusters, doi:10.1080/01969727308546046.
</p>
<p>Sture Holm (1979). A simple sequentially rejective multiple test procedure, <em>Scandinavian journal of statistics</em>, 65-70, doi:10.2307/4615733.
</p>
<p>Yoav Benjamini and Yosef Hochberg (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing, <em>Journal of the Royal statistical society: series B (Methodological)</em> 57.1: 289-300, doi: 10.2307/2346101.
</p>

<hr>
<h2 id='AFStest'>
k-Sample AFS Test of Equal Distributions
</h2><span id='topic+AFStest'></span>

<h3>Description</h3>

<p>Performs the distribution free exact k-sample test for equality of multivariate distributions in the HDLSS regime. This an aggregate test of the two sample versions of the FS test over <code class="reqn">\frac{k(k-1)}{2}</code> numbers of two-sample comparisons, and the test statistic is the minimum of these two sample FS test statistics. Holm's step-down-procedure (1979) and Benjamini-Hochberg procedure (1995) are applied for multiple testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AFStest(M, sizes, randomization = TRUE, clust_alg = "knwClustNo", kmax = 4,
multTest = "Holm", s_psi = 1, s_h = 1, lb = 1, n_sts = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AFStest_+3A_m">M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_sizes">sizes</code></td>
<td>

<p>vector of sample sizes
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_randomization">randomization</code></td>
<td>

<p>logical; if TRUE (default), randomization test and FALSE, non-randomization test
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_clust_alg">clust_alg</code></td>
<td>

<p><code>"knwClustNo"</code>(default) or <code>"estclustNo"</code>; modified K-means algorithm used for clustering
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_kmax">kmax</code></td>
<td>

<p>maximum value of total number of clusters to estimate total number of clusters for two-sample comparition, default: <code>4</code>
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_multtest">multTest</code></td>
<td>

<p><code>"HOlm"</code>(default) or <code>"BenHoch"</code>; different multiple tests
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_s_psi">s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_s_h">s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_lb">lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code>, default: <code class="reqn">1</code>  
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_n_sts">n_sts</code></td>
<td>

<p>number of simulation of the test statistic, default: <code class="reqn">1000</code>
</p>
</td></tr>
<tr><td><code id="AFStest_+3A_alpha">alpha</code></td>
<td>

<p>numeric, confidence level <code class="reqn">\alpha</code>, default: <code class="reqn">0.05</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>AFStest returns a list containing the following items:
</p>
<table>
<tr><td><code>AFSStat</code></td>
<td>
<p>value of the observed test statistic</p>
</td></tr>
<tr><td><code>AFCutoff</code></td>
<td>
<p>cut-off of the test</p>
</td></tr>
<tr><td><code>randomGamma</code></td>
<td>
<p>randomized coefficient of the test</p>
</td></tr>
<tr><td><code>decisionAFS</code></td>
<td>
<p>if returns <code class="reqn">1</code>, reject the null hypothesis and if returns <code class="reqn">0</code>, fails to reject the null hypothesis</p>
</td></tr>
<tr><td><code>multipleTest</code></td>
<td>
<p>indicates where two populations are different according to multiple tests</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Cyrus R Mehta and Nitin R Patel (1983). A network algorithm for performing Fisher's exact test in rxc contingency tables, <em>Journal of the American Statistical Association</em>, 78(382):427-434, doi:10.2307/2288652.
</p>
<p>Sture Holm (1979). A simple sequentially rejective multiple test procedure, <em>Scandinavian journal of statistics</em>, 65-70, doi:10.2307/4615733.
</p>
<p>Yoav Benjamini and Yosef Hochberg (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing, <em>Journal of the Royal statistical society: series B (Methodological)</em> 57.1: 289-300, doi: 10.2307/2346101.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # muiltivariate normal distribution:
  # generate data with dimension d = 500
  set.seed(151)
  n1=n2=n3=n4=10
  d = 500
  I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
  I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
  I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
  I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d) 
  X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
  #AFS test:
  results &lt;- AFStest(M=X, sizes = c(n1,n2,n3,n4))
  
   ## outputs:
   results$AFSStat
   #[1] 5.412544e-06

   results$AFCutoff
   #[1] 0.0109604

   results$randomGamma
   #[1] 0

   results$decisionAFS
   #[1] 1

   results$multipleTest
   #  Population.1 Population.2 rejected pvalues
   #1            1            2     TRUE       0
   #2            1            3     TRUE       0
   #3            1            4     TRUE       0
   #4            2            3     TRUE       0
   #5            2            4     TRUE       0
   #6            3            4     TRUE       0

</code></pre>

<hr>
<h2 id='ARItest'>
k-Sample ARI Test of Equal Distributions
</h2><span id='topic+ARItest'></span>

<h3>Description</h3>

<p>Performs the distribution free exact k-sample test for equality of multivariate distributions in the HDLSS regime. This an aggregate test of the two sample versions of the RI test over <code class="reqn">\frac{k(k-1)}{2}</code> numbers of two-sample comparisons, and the test statistic is the minimum of these two sample RI test statistics. Holm's step-down-procedure (1979) and Benjamini-Hochberg procedure (1995) are applied for multiple testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ARItest(M, sizes, randomization = TRUE, clust_alg = "knwClustNo", kmax = 4, 
multTest = "Holm", s_psi = 1, s_h = 1, lb = 1, n_sts = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ARItest_+3A_m">M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_sizes">sizes</code></td>
<td>

<p>vector of sample sizes
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_randomization">randomization</code></td>
<td>

<p>logical; if TRUE (default), randomization test and FALSE, non-randomization test
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_clust_alg">clust_alg</code></td>
<td>

<p><code>"knwClustNo"</code>(default) or <code>"estclustNo"</code>; modified K-means algorithm used for clustering
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_kmax">kmax</code></td>
<td>

<p>maximum value of total number of clusters to estimate total number of clusters for two-sample comparition, default: <code>4</code>
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_multtest">multTest</code></td>
<td>

<p><code>"HOlm"</code>(default) or <code>"BenHoch"</code>; different multiple tests
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_s_psi">s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_s_h">s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_lb">lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code>, default: <code class="reqn">1</code>  
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_n_sts">n_sts</code></td>
<td>

<p>number of simulation of the test statistic, default: <code class="reqn">1000</code>
</p>
</td></tr>
<tr><td><code id="ARItest_+3A_alpha">alpha</code></td>
<td>

<p>numeric, confidence level <code class="reqn">\alpha</code>, default: <code class="reqn">0.05</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ARItest returns a list containing the following items:
</p>
<table>
<tr><td><code>ARIStat</code></td>
<td>
<p>value of the observed test statistic</p>
</td></tr>
<tr><td><code>Cutoff</code></td>
<td>
<p>cut-off of the test</p>
</td></tr>
<tr><td><code>randomGamma</code></td>
<td>
<p>randomized coefficient of the test</p>
</td></tr>
<tr><td><code>decisionARI</code></td>
<td>
<p>if returns <code class="reqn">1</code>, reject the null hypothesis and if returns <code class="reqn">0</code>, fails to reject the null hypothesis</p>
</td></tr>
<tr><td><code>multipleTest</code></td>
<td>
<p>indicates where two populations are different according to multiple tests</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>William M Rand (1971). Objective criteria for the evaluation of clustering methods, <em>Journal of the American Statistical association</em>, 66(336):846-850, doi:10.1080/01621459.1971.10482356.
</p>
<p>Sture Holm (1979). A simple sequentially rejective multiple test procedure, <em>Scandinavian journal of statistics</em>, 65-70, doi:10.2307/4615733.
</p>
<p>Yoav Benjamini and Yosef Hochberg (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing, <em>Journal of the Royal statistical society: series B (Methodological)</em> 57.1: 289-300, doi: 10.2307/2346101.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # muiltivariate normal distribution:
  # generate data with dimension d = 500
  set.seed(151)
  n1=n2=n3=n4=10
  d = 500
  I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
  I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
  I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
  I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d) 
  X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
  #ARI test:
  results &lt;- ARItest(M=X, sizes = c(n1,n2,n3,n4))
  
   ## outputs:
   results$ARIStat
   #[1] 0

   results$ARICutoff
   #[1] 0.3368421

   results$randomGamma
   #[1] 0

   results$decisionARI
   #[1] 1

   results$multipleTest
   #  Population.1 Population.2 rejected pvalues
   #1            1            2     TRUE       0
   #2            1            3     TRUE       0
   #3            1            4     TRUE       0
   #4            2            3     TRUE       0
   #5            2            4     TRUE       0
   #6            3            4     TRUE       0

</code></pre>

<hr>
<h2 id='BenHoch'>
Benjamini-Hochbergs step-up-procedure (1995)
</h2><span id='topic+BenHoch'></span>

<h3>Description</h3>

<p>Benjamini-Hochbergs step-up-procedure (1995) for multiple tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BenHoch(pvalues, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BenHoch_+3A_pvalues">pvalues</code></td>
<td>

<p>vector of p-values
</p>
</td></tr>
<tr><td><code id="BenHoch_+3A_alpha">alpha</code></td>
<td>

<p>numeric, false discovery rate controling level <code class="reqn">\alpha</code>, default: <code class="reqn">0.05</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of <code class="reqn">0</code>s and <code class="reqn">1</code>s. <code class="reqn">0</code>: fails to reject the corresponding hypothesis and <code class="reqn">1</code>: reject the corresponding hypothesis
</p>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Yoav Benjamini and Yosef Hochberg (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing, <em>Journal of the Royal statistical society: series B (Methodological)</em> 57.1: 289-300, doi: 10.2307/2346101.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   # Benjamini-Hochbergs step-up-procedure:
   pvalues &lt;- c(0.50,0.01,0.001,0.69,0.02,0.05,0.0025)
   alpha &lt;- 0.05
   BenHoch(pvalues, alpha)

   ## outputs:
   #[1] 0 1 1 0 1 0 1
</code></pre>

<hr>
<h2 id='FStest'>
k-Sample FS Test of Equal Distributions
</h2><span id='topic+FStest'></span>

<h3>Description</h3>

<p>Performs the distribution free exact k-sample test for equality of multivariate distributions in the HDLSS regime.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FStest(M, labels, sizes, n_clust, randomization = TRUE, clust_alg = "knwClustNo", 
kmax = 2 * n_clust, s_psi = 1, s_h = 1, lb = 1, n_sts = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FStest_+3A_m">M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td></tr>
<tr><td><code id="FStest_+3A_labels">labels</code></td>
<td>

<p>length <code class="reqn">n</code> vector of membership index of observations
</p>
</td></tr>
<tr><td><code id="FStest_+3A_sizes">sizes</code></td>
<td>

<p>vector of sample sizes
</p>
</td></tr>
<tr><td><code id="FStest_+3A_n_clust">n_clust</code></td>
<td>

<p>number of the Populations
</p>
</td></tr>
<tr><td><code id="FStest_+3A_randomization">randomization</code></td>
<td>

<p>logical; if TRUE (default), randomization test and FALSE, non-randomization test
</p>
</td></tr>
<tr><td><code id="FStest_+3A_clust_alg">clust_alg</code></td>
<td>

<p><code>"knwClustNo"</code>(default) or <code>"estclustNo"</code>(for MFS test); modified K-means algorithm used for clustering
</p>
</td></tr>
<tr><td><code id="FStest_+3A_kmax">kmax</code></td>
<td>

<p>maximum value of total number of clusters to estimate total number of clusters in the whole observations, default: <code>2*n_clust</code>
</p>
</td></tr>
<tr><td><code id="FStest_+3A_s_psi">s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="FStest_+3A_s_h">s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="FStest_+3A_lb">lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code>, default: <code class="reqn">1</code> 
</p>
</td></tr>
<tr><td><code id="FStest_+3A_n_sts">n_sts</code></td>
<td>

<p>number of simulation of the test statistic, default: <code class="reqn">1000</code>
</p>
</td></tr>
<tr><td><code id="FStest_+3A_alpha">alpha</code></td>
<td>

<p>numeric, confidence level <code class="reqn">\alpha</code>, default: <code class="reqn">0.05</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>FStest returns a list containing the following items:
</p>
<table>
<tr><td><code>estClustLabel</code></td>
<td>
<p>a vector of length <code class="reqn">n</code> of estimated class membership index of all observations</p>
</td></tr>
<tr><td><code>obsCtyTab</code></td>
<td>
<p>observed contingency table</p>
</td></tr>
<tr><td><code>ObservedProb</code></td>
<td>
<p>value of the observed test statistic</p>
</td></tr>
<tr><td><code>FCutoff</code></td>
<td>
<p>cut-off of the test</p>
</td></tr>
<tr><td><code>randomGamma</code></td>
<td>
<p>randomized coefficient of the test</p>
</td></tr>
<tr><td><code>estPvalue</code></td>
<td>
<p>estimated p-value of the test</p>
</td></tr>
<tr><td><code>decisionF</code></td>
<td>
<p>if returns <code class="reqn">1</code>, reject the null hypothesis and if returns <code class="reqn">0</code>, fails to reject the null hypothesis</p>
</td></tr>
<tr><td><code>estClustNo</code></td>
<td>
<p>total number of the estimated classes</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Cyrus R Mehta and Nitin R Patel (1983). A network algorithm for performing Fisher's exact test in rxc contingency tables, <em>Journal of the American Statistical Association</em>, 78(382):427-434, doi:10.2307/2288652.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   # muiltivariate normal distribution:
   # generate data with dimension d = 500
   set.seed(151)
   n1=n2=n3=n4=10
   k = 4
   d = 500
   I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
   I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
   I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
   I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d) 
   levels &lt;- c(rep(0,n1), rep(1,n2), rep(2,n3), rep(3,n4)) 
   X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
   #FS test:
   results &lt;- FStest(M=X, labels=levels, sizes = c(n1,n2,n3,n4), n_clust = k)
  
   ## outputs:
   results$estClustLabel
   #[1] 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3

   results$obsCtyTab
   #      [,1] [,2] [,3] [,4]
   #[1,]   10    0    0    0
   #[2,]    0   10    0    0
   #[3,]    0    0   10    0
   #[4,]    0    0    0   10

   results$ObservedProb
   #[1] 2.125236e-22

   results$FCutoff
   #[1] 1.115958e-07

   results$randomGamma
   #[1] 0

   results$estPvalue
   #[1] 0

   results$decisionF
   #[1] 1

</code></pre>

<hr>
<h2 id='gMADD'>
Modified K-Means Algorithm by Using a New Dissimilarity Measure, MADD
</h2><span id='topic+gMADD'></span>

<h3>Description</h3>

<p>Performs modified K-means algorithm by using a new dissimilarity measure, called MADD, and provides estimated cluster (class) labels or memberships of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gMADD(s_psi, s_h, n_clust, lb, M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gMADD_+3A_s_psi">s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="gMADD_+3A_s_h">s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="gMADD_+3A_n_clust">n_clust</code></td>
<td>

<p>total number of the classes in the whole observations
</p>
</td></tr>
<tr><td><code id="gMADD_+3A_lb">lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code> 
</p>
</td></tr>
<tr><td><code id="gMADD_+3A_m">M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of length n of estimated cluster (class) labels of observations
</p>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Soham Sarkar and Anil K Ghosh (2019). On perfect clustering of high dimension, low sample size data, <em>IEEE transactions on pattern analysis and machine intelligence</em>, doi:10.1109/TPAMI.2019.2912599.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Modified K-means algorithm:
  # muiltivariate normal distribution
  # generate data with dimension d = 500
  set.seed(151)
  n1=n2=n3=n4=10
  d = 500
  I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
  I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
  I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
  I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d) 
  n_cl &lt;- 4
  X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
  gMADD(1,1,n_cl,1,X)
  
   ## outputs:
   #[1] 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3
</code></pre>

<hr>
<h2 id='gMADD_DI'>
Modified K-Means Algorithm by Using a New Dissimilarity Measure, MADD and DUNN Index
</h2><span id='topic+gMADD_DI'></span>

<h3>Description</h3>

<p>Performs modified K-means algorithm by using a new dissimilarity measure, called MADD and DUNN index, and provides estimated cluster (class) labels or memberships and corresponding DUNN index of the observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gMADD_DI(s_psi, s_h, kmax, lb, M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gMADD_DI_+3A_s_psi">s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="gMADD_DI_+3A_s_h">s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="gMADD_DI_+3A_kmax">kmax</code></td>
<td>

<p>maximum value of total number of clusters to estimate total number of clusters in the whole observations
</p>
</td></tr>
<tr><td><code id="gMADD_DI_+3A_lb">lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code>
</p>
</td></tr>
<tr><td><code id="gMADD_DI_+3A_m">M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>DUNN index is used for cluster validation, but here we use it to estimate total number of cluster <code class="reqn">k</code> by <code class="reqn">\hat k = argmax_{2\le k' \le k^*}DI(k')</code>. Here <code class="reqn">DI(k')</code> represents the DUNN index and we use <code class="reqn">k^*=2*k</code>.
</p>


<h3>Value</h3>

<p>a <code class="reqn">kmax \times (n+1)</code> matrix of the estimated cluster (class) labels and corresponding DUNN indexes of observations
</p>


<h3>Note</h3>

<p>The result of this gMADD_DI function is a matrix. The 1st row of this matrix doesn't provide anything about estimated class labels or DUNN index of observations since the DUNN index is only defined for <code class="reqn">k\ge 2</code>. The last column of this matrix represents the DUNN indexes. The estimated cluster labels of observations are calculated by finding out the corresponding row of maximum DUNN index.
</p>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Soham Sarkar and Anil K Ghosh (2019). On perfect clustering of high dimension, low sample size data, <em>IEEE transactions on pattern analysis and machine intelligence</em>, doi:10.1109/TPAMI.2019.2912599.
</p>
<p>Joseph C Dunn (1973). A fuzzy relative of the isodata process and its use in detecting compact well-separated clusters, doi:10.1080/01969727308546046.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Modified K-means algorithm:
  # muiltivariate normal distribution
  # generate data with dimension d = 500
  set.seed(151)
  n1=n2=n3=n4=10
  d = 500
  I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
  I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
  I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
  I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d) 
  n_cl &lt;- 4
  N &lt;- n1+n2+n3+n4
  X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
  dvec_di_mat &lt;-  gMADD_DI(1,1,2*n_cl,1,X)
  est_no_cl &lt;- which.max(dvec_di_mat[ ,(N+1)])
  dvec_di_mat[est_no_cl,1:N]

   ## outputs:
   #[1] 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3
   </code></pre>

<hr>
<h2 id='Holm'>
Holm's step-down-procedure (1979)
</h2><span id='topic+Holm'></span>

<h3>Description</h3>

<p>Holm's step-down-procedure (1979) for mutiple tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Holm(pvalues, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Holm_+3A_pvalues">pvalues</code></td>
<td>

<p>vector of p-values
</p>
</td></tr>
<tr><td><code id="Holm_+3A_alpha">alpha</code></td>
<td>

<p>numeric, family wise error rate controling level <code class="reqn">\alpha</code>, default: <code class="reqn">0.05</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of <code class="reqn">0</code>s and <code class="reqn">1</code>s. <code class="reqn">0</code>: fails to reject the corresponding hypothesis and <code class="reqn">1</code>: reject the corresponding hypothesis
</p>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Sture Holm (1979). A simple sequentially rejective multiple test procedure, <em>Scandinavian journal of statistics</em>, 65-70, doi:10.2307/4615733.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   # Holm's step down procedure:
   pvalues &lt;- c(0.50,0.01,0.001,0.69,0.02,0.05,0.0025)
   alpha &lt;- 0.05
   Holm(pvalues, alpha)

   ## outputs:
   #[1] 0 0 1 0 0 0 1
   
</code></pre>

<hr>
<h2 id='MTFStest'>
k-Sample MTFS Test of Equal Distributions
</h2><span id='topic+MTFStest'></span>

<h3>Description</h3>

<p>Performs the distribution free exact k-sample test for equality of multivariate distributions in the HDLSS regime. This test is a multiscale approach based on FS test, where the results for different number of partitions are aggregated judiciously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MTFStest(M, labels, sizes, k_max, multTest = "Holm", s_psi = 1, s_h = 1,
lb = 1, n_sts = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MTFStest_+3A_m">M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_labels">labels</code></td>
<td>

<p>length <code class="reqn">n</code> vector of membership index of observations
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_sizes">sizes</code></td>
<td>

<p>vector of sample sizes
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_k_max">k_max</code></td>
<td>

<p>maximum value of total number of clusters which is required for the test
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_multtest">multTest</code></td>
<td>

<p><code>"HOlm"</code>(default) or <code>"BenHoch"</code>; different multiple tests
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_s_psi">s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_s_h">s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_lb">lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code>, default: <code class="reqn">1</code> 
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_n_sts">n_sts</code></td>
<td>

<p>number of simulation of the test statistic, default: <code class="reqn">1000</code>
</p>
</td></tr>
<tr><td><code id="MTFStest_+3A_alpha">alpha</code></td>
<td>

<p>numeric, confidence level <code class="reqn">\alpha</code>, default: <code class="reqn">0.05</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>MTFStest returns a list containing the following items:
</p>
<table>
<tr><td><code>RIvec</code></td>
<td>
<p>a vector of the Rand indices based on different number of clusters</p>
</td></tr>
<tr><td><code>Pvalues</code></td>
<td>
<p>a vector of FS test p-values based on different number of clusters</p>
</td></tr>
<tr><td><code>decisionMTRI</code></td>
<td>
<p>if returns <code class="reqn">1</code>, reject the null hypothesis and if returns <code class="reqn">0</code>, fails to reject the null hypothesis</p>
</td></tr>
<tr><td><code>contTabs</code></td>
<td>
<p>a list of the observed contingency table based on different number of clusters</p>
</td></tr>
<tr><td><code>mulTestdec</code></td>
<td>
<p>a vector of <code class="reqn">0</code>s and <code class="reqn">1</code>s. <code class="reqn">0</code>: fails to reject the corresponding hypothesis and <code class="reqn">1</code>: reject the corresponding hypothesis</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Sture Holm (1979). A simple sequentially rejective multiple test procedure, <em>Scandinavian journal of statistics</em>, 65-70, doi:10.2307/4615733.
</p>
<p>Yoav Benjamini and Yosef Hochberg (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing, <em>Journal of the Royal statistical society: series B (Methodological)</em> 57.1: 289-300, doi: 10.2307/2346101.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # muiltivariate normal distribution:
  # generate data with dimension d = 500
  set.seed(151)
  n1=n2=n3=n4=10
  d = 500
  I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
  I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
  I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
  I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d)
  levels &lt;- c(rep(0,n1), rep(1,n2), rep(2,n3), rep(3,n4)) 
  X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
  #MTFS test:
  results &lt;- MTFStest(X, levels, c(n1,n2,n3,n4), 8)
  
   ## outputs:
   results$fpmfvec
   #[1] 7.254445e-12 6.137740e-16 2.125236e-22 2.125236e-22 2.125236e-22 2.125236e-22 2.125236e-22

   results$Pvalues
   #[1] 0 0 0 0 0 0 0

   results$decisionMTFS
   #[1] 1

   results$contTabs
   #$contTabs[[1]]
   #     [,1] [,2]
   #[1,]   10    0
   #[2,]   10    0
   #[3,]    0   10
   #[4,]    0   10

   #$contTabs[[2]]
   #    [,1] [,2] [,3]
   #[1,]   10    0    0
   #[2,]    0   10    0
   #[3,]    0    8    2
   #[4,]    0    0   10

   #$contTabs[[3]]
   #     [,1] [,2] [,3] [,4]
   #[1,]   10    0    0    0
   #[2,]    0   10    0    0
   #[3,]    0    0   10    0
   #[4,]    0    0    0   10

   #$contTabs[[4]]
   #     [,1] [,2] [,3] [,4] [,5]
   #[1,]   10    0    0    0    0
   #[2,]    0   10    0    0    0
   #[3,]    0    0    4    6    0
   #[4,]    0    0    0    0   10

   #$contTabs[[5]]
   #    [,1] [,2] [,3] [,4] [,5] [,6]
   #[1,]   10    0    0    0    0    0
   #[2,]    0   10    0    0    0    0
   #[3,]    0    0    4    6    0    0
   #[4,]    0    0    0    0    8    2

   #$contTabs[[6]]
   #     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
   #[1,]   10    0    0    0    0    0    0
   #[2,]    0    5    5    0    0    0    0
   #[3,]    0    0    0    4    6    0    0
   #[4,]    0    0    0    0    0    8    2

   #$contTabs[[7]]
   #     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
   #[1,]    8    2    0    0    0    0    0    0
   #[2,]    0    0    5    5    0    0    0    0
   #[3,]    0    0    0    0    4    6    0    0
   #[4,]    0    0    0    0    0    0    8    2


   results$mulTestdec
   #[1] 1 1 1 1 1 1 1
</code></pre>

<hr>
<h2 id='MTRItest'>
k-Sample MTRI Test of Equal Distributions
</h2><span id='topic+MTRItest'></span>

<h3>Description</h3>

<p>Performs the distribution free exact k-sample test for equality of multivariate distributions in the HDLSS regime. This test is a multiscale approach based on RI test, where the results for different number of partitions are aggregated judiciously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MTRItest(M, labels, sizes, k_max, multTest = "Holm", s_psi = 1, s_h = 1, 
lb = 1, n_sts = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MTRItest_+3A_m">M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_labels">labels</code></td>
<td>

<p>length <code class="reqn">n</code> vector of membership index of observations
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_sizes">sizes</code></td>
<td>

<p>vector of sample sizes
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_k_max">k_max</code></td>
<td>

<p>maximum value of total number of clusters which is required for the test
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_multtest">multTest</code></td>
<td>

<p><code>"HOlm"</code>(default) or <code>"BenHoch"</code>; different multiple tests
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_s_psi">s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_s_h">s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_lb">lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code>, default: <code class="reqn">1</code> 
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_n_sts">n_sts</code></td>
<td>

<p>number of simulation of the test statistic, default: <code class="reqn">1000</code>
</p>
</td></tr>
<tr><td><code id="MTRItest_+3A_alpha">alpha</code></td>
<td>

<p>numeric, confidence level <code class="reqn">\alpha</code>, default: <code class="reqn">0.05</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>MTRItest returns a list containing the following items:
</p>
<table>
<tr><td><code>RIvec</code></td>
<td>
<p>a vector of the Rand indices based on different number of clusters</p>
</td></tr>
<tr><td><code>Pvalues</code></td>
<td>
<p>a vector of RI test p-values based on different number of clusters</p>
</td></tr>
<tr><td><code>decisionMTRI</code></td>
<td>
<p>if returns <code class="reqn">1</code>, reject the null hypothesis and if returns <code class="reqn">0</code>, fails to reject the null hypothesis</p>
</td></tr>
<tr><td><code>contTabs</code></td>
<td>
<p>a list of the observed contingency table based on different number of clusters</p>
</td></tr>
<tr><td><code>mulTestdec</code></td>
<td>
<p>a vector of <code class="reqn">0</code>s and <code class="reqn">1</code>s. <code class="reqn">0</code>: fails to reject the corresponding hypothesis and <code class="reqn">1</code>: reject the corresponding hypothesis</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Sture Holm (1979). A simple sequentially rejective multiple test procedure, <em>Scandinavian journal of statistics</em>, 65-70, doi:10.2307/4615733.
</p>
<p>Yoav Benjamini and Yosef Hochberg (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing, <em>Journal of the Royal statistical society: series B (Methodological)</em> 57.1: 289-300, doi: 10.2307/2346101.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # muiltivariate normal distribution:
  # generate data with dimension d = 500
  set.seed(151)
  n1=n2=n3=n4=10
  d = 500
  I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
  I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
  I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
  I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d)
  levels &lt;- c(rep(0,n1), rep(1,n2), rep(2,n3), rep(3,n4)) 
  X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
  #MTRI test:
  results &lt;- MTRItest(X, levels, c(n1,n2,n3,n4), 8)
  
  ## outputs:
  results$RIvec
  #[1] 0.25641026 0.14871795 0.00000000 0.03076923 0.05128205 0.08333333 0.10384615

  results$Pvalues
  #[1] 0 0 0 0 0 0 0

  results$decisionMTRI
  #[1] 1

  results$contTabs
  #$contTabs[[1]]
  #     [,1] [,2]
  #[1,]   10    0
  #[2,]   10    0
  #[3,]    0   10
  #[4,]    0   10

  #$contTabs[[2]]
  #     [,1] [,2] [,3]
  #[1,]   10    0    0
  #[2,]    0   10    0
  #[3,]    0   10    0
  #[4,]    0    0   10

  #$contTabs[[3]]
  #     [,1] [,2] [,3] [,4]
  #[1,]   10    0    0    0
  #[2,]    0   10    0    0
  #[3,]    0    0   10    0
  #[4,]    0    0    0   10

  #$contTabs[[4]]
  #     [,1] [,2] [,3] [,4] [,5]
  #[1,]   10    0    0    0    0
  #[2,]    0   10    0    0    0
  #[3,]    0    0    4    6    0
  #[4,]    0    0    0    0   10

  #$contTabs[[5]]
  #     [,1] [,2] [,3] [,4] [,5] [,6]
  #[1,]   10    0    0    0    0    0
  #[2,]    0   10    0    0    0    0
  #[3,]    0    0    4    6    0    0
  #[4,]    0    0    0    0    8    2

  #$contTabs[[6]]
  #     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
  #[1,]   10    0    0    0    0    0    0
  #[2,]    0    5    5    0    0    0    0
  #[3,]    0    0    0    4    6    0    0
  #[4,]    0    0    0    0    0    8    2

  #$contTabs[[7]]
  #     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
  #[1,]    8    2    0    0    0    0    0    0
  #[2,]    0    0    5    5    0    0    0    0
  #[3,]    0    0    0    0    4    6    0    0
  #[4,]    0    0    0    0    0    0    8    2


  results$mulTestdec
  #[1] 1 1 1 1 1 1 1
</code></pre>

<hr>
<h2 id='pmf'>
Generalized Hypergeometric Probability
</h2><span id='topic+pmf'></span>

<h3>Description</h3>

<p>A function that provides the probability of observing an <code class="reqn">r\times c</code> contingency table using generalized hypergeometric probability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmf(M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmf_+3A_m">M</code></td>
<td>

<p><code class="reqn">r\times c</code> contingency table
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a single value between <code class="reqn">0</code> and <code class="reqn">1</code>
</p>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Cyrus R Mehta and Nitin R Patel (1983). A network algorithm for performing Fisher's exact test in rxc contingency tables, <em>Journal of the American Statistical Association</em>, 78(382):427-434, doi:10.2307/2288652.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   # Generalized hypergeometric probability of rxc Contingency Table:
   mat &lt;- matrix(1:20,5,4, byrow = TRUE)
   pmf(mat)

   ## outputs:
   #[1] 4.556478e-09
</code></pre>

<hr>
<h2 id='randfun'>
Rand Index
</h2><span id='topic+randfun'></span>

<h3>Description</h3>

<p>Measures to compare the dissimilarity of exact cluster labels (memberships) and estimated cluster labels (memberships) of the observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randfun(lvel, dv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randfun_+3A_lvel">lvel</code></td>
<td>

<p>exact cluster labels of the observations
</p>
</td></tr>
<tr><td><code id="randfun_+3A_dv">dv</code></td>
<td>

<p>estimated cluster labels of the observations
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a single value between 0 and 1
</p>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>William M Rand (1971). Objective criteria for the evaluation of clustering methods, <em>Journal of the American Statistical association</em>, 66(336):846-850, doi:10.1080/01621459.1971.10482356.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   # Measures of dissimilarity:
   exl &lt;- c(rep(0,5), rep(1,5), rep(2,5), rep(3,5))
   el &lt;- c(0,0,1,0,0,1,2,1,0,1,2,2,3,2,2,3,2,3,1,3)
   randfun(exl,el)

   ## outputs:
   #[1] 0.2368421
</code></pre>

<hr>
<h2 id='rctab'> Generates an <code class="reqn">r\times c</code> Contingency Table
</h2><span id='topic+rctab'></span>

<h3>Description</h3>

<p>A function that generates an <code class="reqn">r\times c</code> contingency table with the same marginal totals as given <code class="reqn">r\times c</code> contingency table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rctab(M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rctab_+3A_m">M</code></td>
<td>
<p><code class="reqn">r\times c</code> contingency table
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>generated <code class="reqn">r\times c</code> contingency table
</p>


<h3>Author(s)</h3>

<p>Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Cyrus R Mehta and Nitin R Patel (1983). A network algorithm for performing Fisher's exact test in rxc contingency tables, <em>Journal of the American Statistical Association</em>, 78(382):427-434, doi:10.2307/2288652.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generation of rxc Contingency Table:
   set.seed(151)
   mat &lt;- matrix(1:20,5,4, byrow = TRUE)
   rctab(mat)

   ## outputs:
   #      [,1] [,2] [,3] [,4]
   #[1,]    3    4    0    3
   #[2,]    4    5   10    7
   #[3,]    8    7   12   15
   #[4,]   18   16   13   11
   #[5,]   12   18   20   24
   </code></pre>

<hr>
<h2 id='RItest'>
k-Sample RI Test of Equal Distributions
</h2><span id='topic+RItest'></span>

<h3>Description</h3>

<p>Performs the distribution free exact k-sample test for equality of multivariate distributions in the HDLSS regime.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RItest(M, labels, sizes, n_clust, randomization = TRUE, clust_alg = "knwClustNo", 
kmax = 2 * n_clust, s_psi = 1, s_h = 1, lb = 1, n_sts = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RItest_+3A_m">M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td></tr>
<tr><td><code id="RItest_+3A_labels">labels</code></td>
<td>

<p>length <code class="reqn">n</code> vector of membership index of observations
</p>
</td></tr>
<tr><td><code id="RItest_+3A_sizes">sizes</code></td>
<td>

<p>vector of sample sizes
</p>
</td></tr>
<tr><td><code id="RItest_+3A_n_clust">n_clust</code></td>
<td>

<p>number of the Populations
</p>
</td></tr>
<tr><td><code id="RItest_+3A_randomization">randomization</code></td>
<td>

<p>logical; if TRUE (default), randomization test and FALSE, non-randomization test
</p>
</td></tr>
<tr><td><code id="RItest_+3A_clust_alg">clust_alg</code></td>
<td>

<p><code>"knwClustNo"</code>(default) or <code>"estclustNo"</code>(for MRI test); modified K-means algorithm used for clustering
</p>
</td></tr>
<tr><td><code id="RItest_+3A_kmax">kmax</code></td>
<td>

<p>maximum value of total number of clusters to estimate total number of clusters in the whole observations, default: <code>2*n_clust</code>
</p>
</td></tr>
<tr><td><code id="RItest_+3A_s_psi">s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="RItest_+3A_s_h">s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td></tr>
<tr><td><code id="RItest_+3A_lb">lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code>, default: <code class="reqn">1</code>  
</p>
</td></tr>
<tr><td><code id="RItest_+3A_n_sts">n_sts</code></td>
<td>

<p>number of simulation of the test statistic, default: <code class="reqn">1000</code>
</p>
</td></tr>
<tr><td><code id="RItest_+3A_alpha">alpha</code></td>
<td>

<p>numeric, confidence level <code class="reqn">\alpha</code>, default: <code class="reqn">0.05</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>RItest returns a list containing the following items:
</p>
<table>
<tr><td><code>estClustLabel</code></td>
<td>
<p>a vector of length <code class="reqn">n</code> of estimated class membership index of all observations</p>
</td></tr>
<tr><td><code>obsCtyTab</code></td>
<td>
<p>observed contingency table</p>
</td></tr>
<tr><td><code>ObservedRI</code></td>
<td>
<p>value of the observed test statistic</p>
</td></tr>
<tr><td><code>RICutoff</code></td>
<td>
<p>cut-off of the test</p>
</td></tr>
<tr><td><code>randomGamma</code></td>
<td>
<p>randomized coefficient of the test</p>
</td></tr>
<tr><td><code>estPvalue</code></td>
<td>
<p>estimated p-value of the test</p>
</td></tr>
<tr><td><code>decisionRI</code></td>
<td>
<p>if returns <code class="reqn">1</code>, reject the null hypothesis and if returns <code class="reqn">0</code>, fails to reject the null hypothesis</p>
</td></tr>
<tr><td><code>estClustNo</code></td>
<td>
<p>total number of the estimated classes</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>William M Rand (1971). Objective criteria for the evaluation of clustering methods, <em>Journal of the American Statistical association</em>, 66(336):846-850, doi:10.1080/01621459.1971.10482356.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # muiltivariate normal distribution:
  # generate data with dimension d = 500
  set.seed(151)
  n1=n2=n3=n4=10
  k = 4
  d = 500
  I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
  I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
  I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
  I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d) 
  levels &lt;- c(rep(0,n1), rep(1,n2), rep(2,n3), rep(3,n4)) 
  X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
  # RI test:
  results &lt;- RItest(M=X, labels=levels, sizes = c(n1,n2,n3,n4), n_clust = k)
  
   ## outputs:
   results$estClustLabel
   #[1] 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3

   results$obsCtyTab
   #      [,1] [,2] [,3] [,4]
   #[1,]   10    0    0    0
   #[2,]    0   10    0    0
   #[3,]    0    0   10    0
   #[4,]    0    0    0   10

   results$ObservedRI
   #[1] 0

   results$RICutoff
   #[1] 0.3307692

   results$randomGamma
   #[1] 0

   results$estPvalue
   #[1] 0

   results$decisionRI
   #[1] 1

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
