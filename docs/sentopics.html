<!DOCTYPE html><html><head><title>Help for package sentopics</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sentopics}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#sentopics-package'><p>Tools for joining sentiment and topic analysis (sentopics)</p></a></li>
<li><a href='#as.LDA'><p>Conversions from other packages to LDA</p></a></li>
<li><a href='#as.tokens.dfm'><p>Convert back a dfm to a tokens object</p></a></li>
<li><a href='#chainsDistances'><p>Distances between topic models (chains)</p></a></li>
<li><a href='#chainsScores'><p>Compute scores of topic models (chains)</p></a></li>
<li><a href='#coherence'><p>Coherence of estimated topics</p></a></li>
<li><a href='#compute_PicaultRenault_scores'><p>Compute scores using the Picault-Renault lexicon</p></a></li>
<li><a href='#ECB_press_conferences'><p>Corpus of press conferences from the European Central Bank</p></a></li>
<li><a href='#ECB_press_conferences_tokens'><p>Tokenized press conferences</p></a></li>
<li><a href='#fit.sentopicmodel'><p>Estimate a topic model</p></a></li>
<li><a href='#get_ECB_press_conferences'><p>Download press conferences from the European Central Bank</p></a></li>
<li><a href='#get_ECB_speeches'><p>Download and pre-process speeches from the European Central Bank</p></a></li>
<li><a href='#JST'><p>Create a Joint Sentiment/Topic model</p></a></li>
<li><a href='#LDA'><p>Create a Latent Dirichlet Allocation model</p></a></li>
<li><a href='#LDAvis'><p>Visualize a LDA model using <span class="pkg">LDAvis</span></p></a></li>
<li><a href='#LoughranMcDonald'><p>Loughran-McDonald lexicon</p></a></li>
<li><a href='#melt'><p>Replacement generic for <code>data.table::melt()</code></p></a></li>
<li><a href='#melt.sentopicmodel'><p>Melt for sentopicmodels</p></a></li>
<li><a href='#mergeTopics'><p>Merge topics into fewer themes</p></a></li>
<li><a href='#PicaultRenault'><p>Picault-Renault lexicon</p></a></li>
<li><a href='#PicaultRenault_data'><p>Regression dataset based on Picault &amp; Renault (2017)</p></a></li>
<li><a href='#plot.multiChains'><p>Plot the distances between topic models (chains)</p></a></li>
<li><a href='#plot.sentopicmodel'><p>Plot a topic model using Plotly</p></a></li>
<li><a href='#print.sentopicmodel'><p>Print method for sentopics models</p></a></li>
<li><a href='#proportion_topics'><p>Compute the topic or sentiment proportion time series</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#reset'><p>Re-initialize a topic model</p></a></li>
<li><a href='#rJST'><p>Create a Reversed Joint Sentiment/Topic model</p></a></li>
<li><a href='#sentiment_breakdown'><p>Breakdown the sentiment into topical components</p></a></li>
<li><a href='#sentiment_series'><p>Compute a sentiment time series</p></a></li>
<li><a href='#sentiment_topics'><p>Compute time series of topical sentiments</p></a></li>
<li><a href='#sentopicmodel'><p>Create a sentopic model</p></a></li>
<li><a href='#sentopics_date'><p>Internal date</p></a></li>
<li><a href='#sentopics_labels'><p>Setting topic or sentiment labels</p></a></li>
<li><a href='#sentopics_sentiment'><p>Internal sentiment</p></a></li>
<li><a href='#sentopics-conversions'><p>Internal conversions between <strong>sentopics</strong> models.</p></a></li>
<li><a href='#topWords'><p>Extract the most representative words from topics</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Joint Sentiment and Topic Analysis of Textual Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-04-17</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Olivier Delmarcelle &lt;delmarcelle.olivier@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A framework that joins topic modeling and sentiment analysis of
  textual data. The package implements a fast Gibbs sampling estimation of
  Latent Dirichlet Allocation (Griffiths and Steyvers (2004)
  &lt;<a href="https://doi.org/10.1073%2Fpnas.0307752101">doi:10.1073/pnas.0307752101</a>&gt;) and Joint Sentiment/Topic Model (Lin, He,
  Everson and Ruger (2012) &lt;<a href="https://doi.org/10.1109%2FTKDE.2011.48">doi:10.1109/TKDE.2011.48</a>&gt;). It offers a variety of
  helpers and visualizations to analyze the result of topic modeling. The
  framework also allows enriching topic models with dates and externally
  computed sentiment measures. A flexible aggregation scheme enables the
  creation of time series of sentiment or topical proportions from the enriched
  topic models. Moreover, a novel method jointly aggregates topic proportions
  and sentiment measures to derive time series of topical sentiment.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/odelmarcelle/sentopics/issues">https://github.com/odelmarcelle/sentopics/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/odelmarcelle/sentopics">https://github.com/odelmarcelle/sentopics</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.4.6), methods, generics, quanteda (&ge; 3.2.0),
data.table (&ge; 1.13.6), RcppHungarian</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, ggridges, plotly, RColorBrewer, xts, zoo, future,
future.apply, progressr, progress, testthat, covr, stm, lda,
topicmodels, seededlda, keyATM, LDAvis, servr, textcat,
stringr, sentometrics, spacyr, knitr, rmarkdown, webshot</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppProgress</td>
</tr>
<tr>
<td>RcppModules:</td>
<td>model_module</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-18 10:38:58 UTC; odlmarce</td>
</tr>
<tr>
<td>Author:</td>
<td>Olivier Delmarcelle
    <a href="https://orcid.org/0000-0003-4347-070X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Samuel Borms <a href="https://orcid.org/0000-0001-9533-1870"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Chengua Lin [cph] (Original JST implementation),
  Yulan He [cph] (Original JST implementation),
  Jose Bernardo [cph] (Original JST implementation),
  David Robinson [cph] (Implementation of reorder_within()),
  Julia Silge <a href="https://orcid.org/0000-0002-3671-836X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cph]
    (Implementation of reorder_within())</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-18 13:12:38 UTC</td>
</tr>
</table>
<hr>
<h2 id='sentopics-package'>Tools for joining sentiment and topic analysis (sentopics)</h2><span id='topic+sentopics'></span><span id='topic+sentopics-package'></span>

<h3>Description</h3>

<p><strong>sentopics</strong> provides function to easily estimate a range of
topic models and process their output. Particularly, it facilitates the
integration of topic analysis with a time dimension through time-series
generating functions. In addition, <strong>sentopics</strong> interacts with sentiment
analysis to compute the sentiment conveyed by topics. Finally, the package
implements a number of visualization helping interpreting the results of
topic models.
</p>


<h3>Usage</h3>

<p>Please refer to the vignettes for a comprehensive introduction to the
package functions.
</p>

<ul>
<li> <p><a href="../doc/Basic_usage.html">Basic usage</a>: Introduction to topic model estimation with <strong>sentopics</strong>
</p>
</li>
<li> <p><a href="../doc/Topical_time_series.html">Topical time series</a>: Integrate topic analysis with sentiment analysis along a time dimension
</p>
</li></ul>

<p>For further details, you may browse the package <a href="../html/00Index.html">documentation</a>.
</p>


<h3>Note</h3>

<p>Please cite the package in publications. Use
<code>citation("sentopics")</code>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Olivier Delmarcelle <a href="mailto:delmarcelle.olivier@gmail.com">delmarcelle.olivier@gmail.com</a> (<a href="https://orcid.org/0000-0003-4347-070X">ORCID</a>)
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Samuel Borms <a href="mailto:samuel.borms@unine.ch">samuel.borms@unine.ch</a> (<a href="https://orcid.org/0000-0001-9533-1870">ORCID</a>) [contributor]
</p>
</li>
<li><p> Chengua Lin <a href="mailto:chenghua.lin@abdn.ac.uk">chenghua.lin@abdn.ac.uk</a> (Original JST implementation) [copyright holder]
</p>
</li>
<li><p> Yulan He <a href="mailto:yulan.he@warwick.ac.uk">yulan.he@warwick.ac.uk</a> (Original JST implementation) [copyright holder]
</p>
</li>
<li><p> Jose Bernardo (Original JST implementation) [copyright holder]
</p>
</li>
<li><p> David Robinson <a href="mailto:admiral.david@gmail.com">admiral.david@gmail.com</a> (Implementation of reorder_within()) [copyright holder]
</p>
</li>
<li><p> Julia Silge <a href="mailto:julia.silge@gmail.com">julia.silge@gmail.com</a> (<a href="https://orcid.org/0000-0002-3671-836X">ORCID</a>) (Implementation of reorder_within()) [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/odelmarcelle/sentopics">https://github.com/odelmarcelle/sentopics</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/odelmarcelle/sentopics/issues">https://github.com/odelmarcelle/sentopics/issues</a>
</p>
</li></ul>


<hr>
<h2 id='as.LDA'>Conversions from other packages to LDA</h2><span id='topic+as.LDA'></span><span id='topic+as.LDA.STM'></span><span id='topic+as.LDA.LDA_Gibbs'></span><span id='topic+as.LDA.LDA_VEM'></span><span id='topic+as.LDA.textmodel_lda'></span><span id='topic+as.LDA_lda'></span><span id='topic+as.LDA.keyATM_output'></span>

<h3>Description</h3>

<p>These functions converts estimated models from other topic
modeling packages to the format used by <span class="pkg">sentopics</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.LDA(x, ...)

## S3 method for class 'STM'
as.LDA(x, docs, ...)

## S3 method for class 'LDA_Gibbs'
as.LDA(x, docs, ...)

## S3 method for class 'LDA_VEM'
as.LDA(x, docs, ...)

## S3 method for class 'textmodel_lda'
as.LDA(x, ...)

as.LDA_lda(list, docs, alpha, eta)

## S3 method for class 'keyATM_output'
as.LDA(x, docs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.LDA_+3A_x">x</code></td>
<td>
<p>an estimated topic model from <span class="pkg">stm</span>, <span class="pkg">topicmodels</span> or
<span class="pkg">seededlda</span>.</p>
</td></tr>
<tr><td><code id="as.LDA_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
<tr><td><code id="as.LDA_+3A_docs">docs</code></td>
<td>
<p>for some objects, the documents used to initialize the model.</p>
</td></tr>
<tr><td><code id="as.LDA_+3A_list">list</code></td>
<td>
<p>the list containing an estimated model from <span class="pkg">lda</span>.</p>
</td></tr>
<tr><td><code id="as.LDA_+3A_alpha">alpha</code></td>
<td>
<p>for <span class="pkg">lda</span> models, the document-topic mixture hyperparameter.
If missing, the hyperparameter will be set to <code>50/K</code>.</p>
</td></tr>
<tr><td><code id="as.LDA_+3A_eta">eta</code></td>
<td>
<p>for <span class="pkg">lda</span> models, the topic-word mixture hyperparameter. Other
packages refer to this hyperparameter as <em>beta</em>. If missing, the
hyperparameter will be set to <code>0.01</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some models do not store the topic assignment of each word (for
example, estimated through variational inference). For these, the
conversion is limited and some functionalities of <span class="pkg">sentopics</span> will be
disabled. The list of affected functions is subject to change and currently
includes <code><a href="#topic+fit.sentopicmodel">fit()</a></code>, <code><a href="#topic+mergeTopics">mergeTopics()</a></code> and <code><a href="#topic+rJST.LDA">rJST.LDA()</a></code>.
</p>
<p>Since models from the <span class="pkg">lda</span> package are simply lists of outputs, the
function <code>as.LDA_lda()</code> is not related to the other methods and should be
applied directly on lists containing a model.
</p>


<h3>Value</h3>

<p>A S3 list of class <code>LDA</code>, as if it was created and estimated using
<code><a href="#topic+LDA">LDA()</a></code> and <code><a href="#topic+fit.sentopicmodel">fit()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## stm
library("stm")
stm &lt;- stm(poliblog5k.docs, poliblog5k.voc, K=25,
           prevalence=~rating, data=poliblog5k.meta,
           max.em.its=2, init.type="Spectral")
as.LDA(stm, docs = poliblog5k.docs)

## lda
library("lda")
data("cora.documents")
data("cora.vocab")
lda &lt;- lda.collapsed.gibbs.sampler(cora.documents,
                                   5, ## Num clusters
                                   cora.vocab,
                                   100, ## Num iterations
                                   0.1,
                                   0.1)
LDA &lt;- as.LDA_lda(lda, docs = cora.documents, alpha = .1, eta = .1)

## topicmodels
data("AssociatedPress", package = "topicmodels")
lda &lt;- topicmodels::LDA(AssociatedPress[1:20,],
                        control = list(alpha = 0.1), k = 2)
LDA &lt;- as.LDA(lda, docs = AssociatedPress[1:20,])

## seededlda
library("seededlda")
lda &lt;- textmodel_lda(dfm(ECB_press_conferences_tokens),
                     k = 6, max_iter = 100)
LDA &lt;- as.LDA(lda)

## keyATM
library("keyATM")
data(keyATM_data_bills, package = "keyATM")
keyATM_docs &lt;- keyATM_read(keyATM_data_bills$doc_dfm)
out &lt;- keyATM(docs = keyATM_docs, model = "base",
              no_keyword_topics = 5,
              keywords = keyATM_data_bills$keywords)
LDA &lt;- as.LDA(out, docs = keyATM_docs)

</code></pre>

<hr>
<h2 id='as.tokens.dfm'>Convert back a dfm to a tokens object</h2><span id='topic+as.tokens.dfm'></span>

<h3>Description</h3>

<p>Convert back a dfm to a tokens object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dfm'
as.tokens(
  x,
  concatenator = NULL,
  tokens = NULL,
  ignore_list = NULL,
  case_insensitive = FALSE,
  padding = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.tokens.dfm_+3A_x">x</code></td>
<td>
<p><a href="quanteda.html#topic+dfm">quanteda::dfm</a> to be coerced</p>
</td></tr>
<tr><td><code id="as.tokens.dfm_+3A_concatenator">concatenator</code></td>
<td>
<p>only used for consistency with the generic</p>
</td></tr>
<tr><td><code id="as.tokens.dfm_+3A_tokens">tokens</code></td>
<td>
<p>optionally, the tokens from which the dfm was created.
Providing the initial tokens will ensure that the word order will be
respected in the coerced object.</p>
</td></tr>
<tr><td><code id="as.tokens.dfm_+3A_ignore_list">ignore_list</code></td>
<td>
<p>a character vector of words that should not be removed
from the initial tokens object. Useful to avoid removing some lexicon word
following the usage of <code><a href="quanteda.html#topic+dfm_trim">quanteda::dfm_trim()</a></code>.</p>
</td></tr>
<tr><td><code id="as.tokens.dfm_+3A_case_insensitive">case_insensitive</code></td>
<td>
<p>only used when the <code>tokens</code> argument is provided.
Default to <code>FALSE</code>. This function removes words in the initial <a href="#topic+tokens">tokens</a>
based on the remaining features in the <a href="quanteda.html#topic+dfm">dfm</a> object. This check is
case-sensitive by default, and can be relaxed by setting this argument to
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="as.tokens.dfm_+3A_padding">padding</code></td>
<td>
<p>if <code>TRUE</code>, leaves an empty string where the removed tokens
previously existed. The use of padding is encouraged to improve the
behavior of the coherence metrics (see <code><a href="#topic+coherence">coherence()</a></code>) that rely on word
positions.</p>
</td></tr>
<tr><td><code id="as.tokens.dfm_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a quanteda <a href="quanteda.html#topic+tokens">quanteda::tokens</a> object.
</p>


<h3>See Also</h3>

<p><code><a href="quanteda.html#topic+as.tokens">quanteda::as.tokens()</a></code> <code><a href="quanteda.html#topic+dfm">quanteda::dfm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("quanteda")
dfm &lt;- dfm(ECB_press_conferences_tokens, tolower = FALSE)
dfm &lt;- dfm_trim(dfm, min_termfreq = 200)
as.tokens(dfm)
as.tokens(dfm, tokens = ECB_press_conferences_tokens)
as.tokens(dfm, tokens = ECB_press_conferences_tokens, padding = FALSE)
</code></pre>

<hr>
<h2 id='chainsDistances'>Distances between topic models (chains)</h2><span id='topic+chainsDistances'></span>

<h3>Description</h3>

<p>Computes the distance between different estimates of a topic
model. Since the estimation of a topic model is random, the results may
largely differ as the process is repeated. This function allows to compute
the distance between distinct realizations of the estimation process.
Estimates are referred to as <em>chains</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chainsDistances(
  x,
  method = c("euclidean", "hellinger", "cosine", "minMax", "naiveEuclidean",
    "invariantEuclidean"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chainsDistances_+3A_x">x</code></td>
<td>
<p>a valid <code>multiChains</code> object, obtained through the estimation of a
topic model using <code><a href="#topic+fit.sentopicmodel">fit()</a></code> and the argument
<code>nChains</code> greater than <code>1</code>.</p>
</td></tr>
<tr><td><code id="chainsDistances_+3A_method">method</code></td>
<td>
<p>the method used to measure the distance between chains.</p>
</td></tr>
<tr><td><code id="chainsDistances_+3A_...">...</code></td>
<td>
<p>further arguments passed to internal distance functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>method</code> argument determines how are computed distance.
</p>

<ul>
<li> <p><code>euclidean</code> finds the pairs of topics that minimizes and returns the total
Euclidean distance.
</p>
</li>
<li> <p><code>hellinger</code> does the same but based on the Hellinger distance.
</p>
</li>
<li> <p><code>cosine</code> does the same but based on the Cosine distance.
</p>
</li>
<li> <p><code>minMax</code> computes the maximum distance among the best pairs of distances.
Inspired by the <em>minimum-matching distance</em> from Tang et al. (2014).
</p>
</li>
<li> <p><code>naiveEuclidean</code> computes the Euclidean distance without searching for the
best pairs of topics.
</p>
</li>
<li> <p><code>invariantEuclidean</code> computes the best pairs of topics for all allowed
permutations of topic indices. For JST and reversed-JST models, the two-
levels hierarchy of document-sentiment-topic leads some permutations of
indices to represent a drastically different outcome. This setting restricts
the set of permutations to the ones that do not change the interpretation of
the model. Equivalent to <code>euclidean</code> for LDA models.
</p>
</li></ul>



<h3>Value</h3>

<p>A matrix of distance between the elements of <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>References</h3>

<p>Tang, J., Meng, Z., Nguyen, X., Mei, Q., and Zhang, M. (2014).
<a href="https://proceedings.mlr.press/v32/tang14.html">Understanding the Limiting Factors of Topic Modeling via Posterior Contraction Analysis</a>. In
<em>Proceedings of the 31st International Conference on Machine Learning</em>, 32,
90&ndash;198.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.multiChains">plot.multiChains()</a></code> <code><a href="#topic+chainsScores">chainsScores()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- LDA(ECB_press_conferences_tokens)
model &lt;- fit(model, 10, nChains = 5)
chainsDistances(model)

</code></pre>

<hr>
<h2 id='chainsScores'>Compute scores of topic models (chains)</h2><span id='topic+chainsScores'></span>

<h3>Description</h3>

<p>Compute various scores (log likelihood, coherence) for a list of topic
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chainsScores(x, window = 110, nWords = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chainsScores_+3A_x">x</code></td>
<td>
<p>a valid <code>multiChains</code> object, obtained through the estimation of a
topic model using <code><a href="#topic+fit.sentopicmodel">fit()</a></code> and the argument
<code>nChains</code> greater than <code>1</code>.</p>
</td></tr>
<tr><td><code id="chainsScores_+3A_window">window</code></td>
<td>
<p>optional. If <code>NULL</code>, use the default window for each coherence
metric (10 for C_NPMI and 110 for C_V). It is possible to override these
default windows by providing an integer or <code>"boolean"</code> to this argument,
determining a new window size for all measures.</p>
</td></tr>
<tr><td><code id="chainsScores_+3A_nwords">nWords</code></td>
<td>
<p>the number of words used to compute coherence. See
<code><a href="#topic+coherence">coherence()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.table</code> with some statistics about each chain. For the
coherence metrics, the value shown is the mean coherence across all topics
of a chain
</p>


<h3>Parallelism</h3>

<p>When <code>nChains &gt; 1</code>, the function can take advantage of
<a href="future.apply.html#topic+future_lapply">future.apply::future_lapply</a> (if installed) to spread the computation over
multiple processes. This requires the specification of a parallel strategy
using <code><a href="future.html#topic+plan">future::plan()</a></code>. See the examples below.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chainsDistances">chainsDistances()</a></code> <code><a href="#topic+coherence">coherence()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- LDA(ECB_press_conferences_tokens[1:10])
model &lt;- fit(model, 10, nChains = 5)
chainsScores(model, window = 5)
chainsScores(model, window = "boolean")

# -- Parallel computation --
require(future.apply)
future::plan("multisession", workers = 2) # Set up 2 workers
chainsScores(model, window = "boolean")

future::plan("sequential") # Shut down workers

</code></pre>

<hr>
<h2 id='coherence'>Coherence of estimated topics</h2><span id='topic+coherence'></span>

<h3>Description</h3>

<p>Computes various coherence based metrics for topic models. It
assesses the quality of estimated topics based on co-occurrences of words.
For best results, consider cleaning the initial tokens object with <code>padding = TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coherence(
  x,
  nWords = 10,
  method = c("C_NPMI", "C_V"),
  window = NULL,
  NPMIs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coherence_+3A_x">x</code></td>
<td>
<p>a model created from the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> function and
estimated with <code><a href="#topic+fit.sentopicmodel">fit()</a></code></p>
</td></tr>
<tr><td><code id="coherence_+3A_nwords">nWords</code></td>
<td>
<p>the number of words in each topic used for evaluation.</p>
</td></tr>
<tr><td><code id="coherence_+3A_method">method</code></td>
<td>
<p>the coherence method used.</p>
</td></tr>
<tr><td><code id="coherence_+3A_window">window</code></td>
<td>
<p>optional. If <code>NULL</code>, use the default window for each coherence
metric (10 for C_NPMI and 110 for C_V). It is possible to override these
default windows by providing an integer or <code>"boolean"</code> to this argument,
determining a new window size for all measures. No effect is the <code>NPMIs</code>
argument is also provided.</p>
</td></tr>
<tr><td><code id="coherence_+3A_npmis">NPMIs</code></td>
<td>
<p>optional NPMI matrix. If provided, skip the computation of NPMI
between words, substantially decreasing computing time.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, only C_NPMI and C_V are documented. The implementation
follows Röder &amp; al. (2015). For C_NPMI, the sliding window is 10 whereas it
is 110 for C_V.
</p>


<h3>Value</h3>

<p>A vector or matrix containing the coherence score of each topic.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>References</h3>

<p>Röder, M., Both, A., &amp; Hinneburg, A. (2015). <a href="https://dl.acm.org/doi/10.1145/2684822.2685324">Exploring the Space of Topic Coherence Measures</a>. In <em>Proceedings
of the Eighth ACM International Conference on Web Search and Data Mining</em>,
399-–408.
</p>

<hr>
<h2 id='compute_PicaultRenault_scores'>Compute scores using the Picault-Renault lexicon</h2><span id='topic+compute_PicaultRenault_scores'></span>

<h3>Description</h3>

<p>Computes Monetary Policy and Economic Condition scores using the
Picault-Renault lexicon for central bank communication.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_PicaultRenault_scores(x, min_ngram = 2, return_dfm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_PicaultRenault_scores_+3A_x">x</code></td>
<td>
<p>a <a href="quanteda.html#topic+corpus">quanteda::corpus</a> object.</p>
</td></tr>
<tr><td><code id="compute_PicaultRenault_scores_+3A_min_ngram">min_ngram</code></td>
<td>
<p>the minimum length of n-grams considered in the computation</p>
</td></tr>
<tr><td><code id="compute_PicaultRenault_scores_+3A_return_dfm">return_dfm</code></td>
<td>
<p>if <code>TRUE</code>, returns the scaled word-per-document score under
two <a href="quanteda.html#topic+dfm">dfm</a>, on for the Monetary Policy and one for the Economic Condition
categories. If <code>FALSE</code>, returns the sum of all word scores per document.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computation is done on a per-document basis, such as each
document is scored with a value between -1 and 1. This is relevant to the
computation of the denominator of the score.
</p>
<p>It is possible to compute the score for paragraphs and sentences for a
<a href="quanteda.html#topic+corpus">quanteda::corpus</a> segmented using <a href="quanteda.html#topic+corpus_reshape">quanteda::corpus_reshape</a>. Segmenting a
corpus using <strong>quanteda</strong>'s helpers retain track to which document each
paragraph/sentence belong. However, in that case, it is possible that
paragraphs or sentences are scored outside the (-1,1) interval. In any
case, the of the paragraph/sentences scores averaged over documents will be
contained in the (-1,1) interval.
</p>


<h3>Value</h3>

<p>A matrix with two columns, indicating respectively the MP (Monetary
Policy) and EC (Economic Condition) scores of each document.
</p>


<h3>References</h3>

<p>Picault, M. &amp; Renault, T. (2017). <a href="https://www.sciencedirect.com/science/article/abs/pii/S0261560617301808">Words are not all created equal: A new measure of ECB communication</a>.
<em>Journal of International Money and Finance</em>, 79, 136&ndash;156.
</p>


<h3>See Also</h3>

<p><a href="#topic+PicaultRenault">PicaultRenault</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># on documents
docs &lt;- quanteda::corpus_reshape(ECB_press_conferences, "documents")
compute_PicaultRenault_scores(docs)

# on paragraphs
compute_PicaultRenault_scores(ECB_press_conferences)
</code></pre>

<hr>
<h2 id='ECB_press_conferences'>Corpus of press conferences from the European Central Bank</h2><span id='topic+ECB_press_conferences'></span>

<h3>Description</h3>

<p>A corpus of 260 ECB press conference, split into 4224
paragraphs. The corpus contains a number of <em>docvars</em> indicating the date
of the press conference and a measured sentiment based on the
Loughran-McDonald lexicon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ECB_press_conferences
</code></pre>


<h3>Format</h3>

<p>A <a href="quanteda.html#topic+corpus">quanteda::corpus</a> object.
</p>


<h3>Source</h3>

<p><a href="https://www.ecb.europa.eu/press/key/date/html/index.en.html">https://www.ecb.europa.eu/press/key/date/html/index.en.html</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ECB_press_conferences_tokens">ECB_press_conferences_tokens</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>docvars(ECB_press_conferences)

</code></pre>

<hr>
<h2 id='ECB_press_conferences_tokens'>Tokenized press conferences</h2><span id='topic+ECB_press_conferences_tokens'></span>

<h3>Description</h3>

<p>The pre-processed and tokenized version of the
<a href="#topic+ECB_press_conferences">ECB_press_conferences</a> corpus of press conferences. The processing
involved the following steps:
</p>

<ul>
<li><p> Subset paragraphs shorter than 10 words
</p>
</li>
<li><p> Removal of stop words
</p>
</li>
<li><p> Part-of-speech tagging, following which only nouns, proper nouns and
adjective were retained.
</p>
</li>
<li><p> Detection and merging of frequent compound words
</p>
</li>
<li><p> Frequency-based cleaning of rare and very common words
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ECB_press_conferences_tokens
</code></pre>


<h3>Format</h3>

<p>A <a href="quanteda.html#topic+tokens">quanteda::tokens</a> object.
</p>


<h3>Source</h3>

<p><a href="https://www.ecb.europa.eu/press/key/date/html/index.en.html">https://www.ecb.europa.eu/press/key/date/html/index.en.html</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ECB_press_conferences">ECB_press_conferences</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LDA(ECB_press_conferences_tokens)

</code></pre>

<hr>
<h2 id='fit.sentopicmodel'>Estimate a topic model</h2><span id='topic+fit.sentopicmodel'></span><span id='topic+grow'></span><span id='topic+fit.LDA'></span><span id='topic+fit.rJST'></span><span id='topic+fit.JST'></span><span id='topic+fit.multiChains'></span><span id='topic+grow.LDA'></span><span id='topic+grow.rJST'></span><span id='topic+grow.JST'></span><span id='topic+grow.sentopicmodel'></span><span id='topic+grow.multiChains'></span>

<h3>Description</h3>

<p>This function is used to estimate a topic model created by
<code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code>. In essence, this function iterates a Gibbs
sampler MCMC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sentopicmodel'
fit(
  object,
  iterations = 100,
  nChains = 1,
  displayProgress = TRUE,
  computeLikelihood = TRUE,
  seed = NULL,
  ...
)

## S3 method for class 'multiChains'
fit(
  object,
  iterations = 100,
  nChains = NULL,
  displayProgress = TRUE,
  computeLikelihood = TRUE,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.sentopicmodel_+3A_object">object</code></td>
<td>
<p>a model created with the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> function.</p>
</td></tr>
<tr><td><code id="fit.sentopicmodel_+3A_iterations">iterations</code></td>
<td>
<p>the number of iterations by which the model should be
fitted.</p>
</td></tr>
<tr><td><code id="fit.sentopicmodel_+3A_nchains">nChains</code></td>
<td>
<p>if set above 1, the model will be fitted multiple times
from various starting positions. Latent variables will be re-initialized if
<code>object</code> has not been fitted before.</p>
</td></tr>
<tr><td><code id="fit.sentopicmodel_+3A_displayprogress">displayProgress</code></td>
<td>
<p>if <code>TRUE</code>, a progress bar will be displayed indicating
the progress of the computation. When <code>nChains</code> is greater than 1, this
requires the package <span class="pkg">progressr</span> and optionally <span class="pkg">progress</span>.</p>
</td></tr>
<tr><td><code id="fit.sentopicmodel_+3A_computelikelihood">computeLikelihood</code></td>
<td>
<p>if set to <code>FALSE</code>, does not compute the likelihood
at each iteration. This can slightly decrease the computing time.</p>
</td></tr>
<tr><td><code id="fit.sentopicmodel_+3A_seed">seed</code></td>
<td>
<p>for reproducibility, a seed can be provided.</p>
</td></tr>
<tr><td><code id="fit.sentopicmodel_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods. Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>sentopicmodel</code> of the relevant model class if <code>nChains</code> is
unspecified or equal to 1. A <code>multiChains</code> object if <code>nChains</code> is greater
than 1.
</p>


<h3>Parallelism</h3>

<p>When <code>nChains &gt; 1</code>, the function can take advantage of
<a href="future.apply.html#topic+future_lapply">future.apply::future_lapply</a> (if installed) to spread the computation over
multiple processes. This requires the specification of a parallel strategy
using <code><a href="future.html#topic+plan">future::plan()</a></code>. See the examples below.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code>, <code><a href="#topic+rJST">rJST()</a></code>, <code><a href="#topic+reset">reset()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- rJST(ECB_press_conferences_tokens)
fit(model, 10)

# -- Parallel computation --
require(future.apply)
future::plan("multisession", workers = 2) # Set up 2 workers
fit(model, 10, nChains = 2)

future::plan("sequential") # Shut down workers
</code></pre>

<hr>
<h2 id='get_ECB_press_conferences'>Download press conferences from the European Central Bank</h2><span id='topic+get_ECB_press_conferences'></span>

<h3>Description</h3>

<p>This helper function automatically retrieve the full data set of
press conferences made available by the ECB. It implements a number of
pre-processing steps used to remove the Q&amp;A section from the text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ECB_press_conferences(
  years = 1998:2021,
  language = "en",
  data.table = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ECB_press_conferences_+3A_years">years</code></td>
<td>
<p>the years for which press conferences should be retrieved</p>
</td></tr>
<tr><td><code id="get_ECB_press_conferences_+3A_language">language</code></td>
<td>
<p>the language in which press conferences should be retrieved</p>
</td></tr>
<tr><td><code id="get_ECB_press_conferences_+3A_data.table">data.table</code></td>
<td>
<p>if TRUE, returns a <a href="data.table.html#topic+data.table">data.table</a>. Otherwise, return a list
in which each element is a press conference.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depending on the arguments, returns either a data.frame or a
<a href="quanteda.html#topic+tokens">quanteda::tokens</a> object containing press conferences of the ECB.
</p>

<hr>
<h2 id='get_ECB_speeches'>Download and pre-process speeches from the European Central Bank</h2><span id='topic+get_ECB_speeches'></span>

<h3>Description</h3>

<p>This helper function automatically retrieve the full data set of
speeches made available by the ECB. In addition, it implements a number of
pre-processing steps that may be turned on or off as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ECB_speeches(
  filter_english = TRUE,
  clean_footnotes = TRUE,
  compute_sentiment = TRUE,
  tokenize_w_POS = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ECB_speeches_+3A_filter_english">filter_english</code></td>
<td>
<p>if <code>TRUE</code>, attempts to select English speeches only
using <code><a href="textcat.html#topic+textcat">textcat::textcat()</a></code>.</p>
</td></tr>
<tr><td><code id="get_ECB_speeches_+3A_clean_footnotes">clean_footnotes</code></td>
<td>
<p>if <code>TRUE</code>, attempts to clean footnotes from speeches
texts using some regex patterns.</p>
</td></tr>
<tr><td><code id="get_ECB_speeches_+3A_compute_sentiment">compute_sentiment</code></td>
<td>
<p>if <code>TRUE</code>, computes the sentiment of each speech
using <code><a href="sentometrics.html#topic+compute_sentiment">sentometrics::compute_sentiment()</a></code> with the the Loughran &amp; McDonald
lexicon.</p>
</td></tr>
<tr><td><code id="get_ECB_speeches_+3A_tokenize_w_pos">tokenize_w_POS</code></td>
<td>
<p>if <code>TRUE</code>, tokenizes and apply Part-Of-Speech tagging
with <code><a href="spacyr.html#topic+spacy_parse">spacyr::spacy_parse()</a></code>. Nouns, adjectives and proper nouns are then
extracted from the parsed speeches to form a <code>tokens</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depending on the arguments, returns either a data.frame or a
<a href="quanteda.html#topic+tokens">quanteda::tokens</a> object containing speeches of the ECB.
</p>

<hr>
<h2 id='JST'>Create a Joint Sentiment/Topic model</h2><span id='topic+JST'></span>

<h3>Description</h3>

<p>This function initialize a Joint Sentiment/Topic model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JST(
  x,
  lexicon = NULL,
  S = 3,
  K = 5,
  gamma = 1,
  alpha = 5,
  beta = 0.01,
  gammaCycle = 0,
  alphaCycle = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="JST_+3A_x">x</code></td>
<td>
<p>tokens object containing the texts. A coercion will be attempted if <code>x</code> is not a tokens.</p>
</td></tr>
<tr><td><code id="JST_+3A_lexicon">lexicon</code></td>
<td>
<p>a <code>quanteda</code> dictionary with positive and negative categories</p>
</td></tr>
<tr><td><code id="JST_+3A_s">S</code></td>
<td>
<p>the number of sentiments</p>
</td></tr>
<tr><td><code id="JST_+3A_k">K</code></td>
<td>
<p>the number of topics</p>
</td></tr>
<tr><td><code id="JST_+3A_gamma">gamma</code></td>
<td>
<p>the hyperparameter of sentiment-document distribution</p>
</td></tr>
<tr><td><code id="JST_+3A_alpha">alpha</code></td>
<td>
<p>the hyperparameter of topic-document distribution</p>
</td></tr>
<tr><td><code id="JST_+3A_beta">beta</code></td>
<td>
<p>the hyperparameter of vocabulary distribution</p>
</td></tr>
<tr><td><code id="JST_+3A_gammacycle">gammaCycle</code></td>
<td>
<p>integer specifying the cycle size between two updates of
the hyperparameter alpha</p>
</td></tr>
<tr><td><code id="JST_+3A_alphacycle">alphaCycle</code></td>
<td>
<p>integer specifying the cycle size between two updates of
the hyperparameter alpha</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>rJST.LDA</code> methods enable the transition from a previously
estimated <a href="#topic+LDA">LDA</a> model to a sentiment-aware <code>rJST</code> model. The function
retains the previously estimated topics and randomly assigns sentiment to
every word of the corpus. The new model will retain the iteration count of
the initial <a href="#topic+LDA">LDA</a> model.
</p>


<h3>Value</h3>

<p>An S3 list containing the model parameter and the estimated mixture.
This object corresponds to a Gibbs sampler estimator with zero iterations.
The MCMC can be iterated using the <code><a href="#topic+fit.sentopicmodel">fit()</a></code>
function.
</p>

<ul>
<li> <p><code>tokens</code> is the tokens object used to create the model
</p>
</li>
<li> <p><code>vocabulary</code> contains the set of words of the corpus
</p>
</li>
<li> <p><code>it</code> tracks the number of Gibbs sampling iterations
</p>
</li>
<li> <p><code>za</code> is the list of topic assignment, aligned to the <code>tokens</code> object with
padding removed
</p>
</li>
<li> <p><code>logLikelihood</code> returns the measured log-likelihood at each iteration,
with a breakdown of the likelihood into hierarchical components as
attribute
</p>
</li></ul>

<p>The <code><a href="#topic+topWords">topWords()</a></code> function easily extract the most probables words of each
topic/sentiment.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>References</h3>

<p>Lin, C. and He, Y. (2009). <a href="https://dl.acm.org/doi/10.1145/1645953.1646003">Joint sentiment/topic model for sentiment analysis</a>. In <em>Proceedings
of the 18th ACM conference on Information and knowledge management</em>,
375&ndash;384.
</p>
<p>Lin, C., He, Y., Everson, R. and Ruger, S. (2012). <a href="https://ieeexplore.ieee.org/document/5710933">Weakly Supervised Joint Sentiment-Topic Detection from Text</a>.
<em>IEEE Transactions on Knowledge and Data Engineering</em>, 24(6), 1134–-1145.
</p>


<h3>See Also</h3>

<p>Fitting a model: <code><a href="#topic+fit.sentopicmodel">fit()</a></code>,
extracting top words: <code><a href="#topic+topWords">topWords()</a></code>
</p>
<p>Other topic models: 
<code><a href="#topic+LDA">LDA</a>()</code>,
<code><a href="#topic+rJST">rJST</a>()</code>,
<code><a href="#topic+sentopicmodel">sentopicmodel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># creating a JST model
JST(ECB_press_conferences_tokens)

# estimating a JST model including a lexicon
jst &lt;- JST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
jst &lt;- fit(jst, 100)
</code></pre>

<hr>
<h2 id='LDA'>Create a Latent Dirichlet Allocation model</h2><span id='topic+LDA'></span>

<h3>Description</h3>

<p>This function initialize a Latent Dirichlet Allocation model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LDA(x, K = 5, alpha = 1, beta = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LDA_+3A_x">x</code></td>
<td>
<p>tokens object containing the texts. A coercion will be attempted if <code>x</code> is not a tokens.</p>
</td></tr>
<tr><td><code id="LDA_+3A_k">K</code></td>
<td>
<p>the number of topics</p>
</td></tr>
<tr><td><code id="LDA_+3A_alpha">alpha</code></td>
<td>
<p>the hyperparameter of topic-document distribution</p>
</td></tr>
<tr><td><code id="LDA_+3A_beta">beta</code></td>
<td>
<p>the hyperparameter of vocabulary distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>rJST.LDA</code> methods enable the transition from a previously
estimated <a href="#topic+LDA">LDA</a> model to a sentiment-aware <code>rJST</code> model. The function
retains the previously estimated topics and randomly assigns sentiment to
every word of the corpus. The new model will retain the iteration count of
the initial <a href="#topic+LDA">LDA</a> model.
</p>


<h3>Value</h3>

<p>An S3 list containing the model parameter and the estimated mixture.
This object corresponds to a Gibbs sampler estimator with zero iterations.
The MCMC can be iterated using the <code><a href="#topic+fit.sentopicmodel">fit()</a></code>
function.
</p>

<ul>
<li> <p><code>tokens</code> is the tokens object used to create the model
</p>
</li>
<li> <p><code>vocabulary</code> contains the set of words of the corpus
</p>
</li>
<li> <p><code>it</code> tracks the number of Gibbs sampling iterations
</p>
</li>
<li> <p><code>za</code> is the list of topic assignment, aligned to the <code>tokens</code> object with
padding removed
</p>
</li>
<li> <p><code>logLikelihood</code> returns the measured log-likelihood at each iteration,
with a breakdown of the likelihood into hierarchical components as
attribute
</p>
</li></ul>

<p>The <code><a href="#topic+topWords">topWords()</a></code> function easily extract the most probables words of each
topic/sentiment.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>References</h3>

<p>Blei, D.M., Ng, A.Y. and Jordan, M.I. (2003). <a href="http://www.cs.columbia.edu/~blei/papers/BleiNgJordan2003.pdf">Latent Dirichlet Allocation</a>.
<em>Journal of Machine Learning Research</em>, 3, 993&ndash;1022.
</p>


<h3>See Also</h3>

<p>Fitting a model: <code><a href="#topic+fit.sentopicmodel">fit()</a></code>, extracting
top words: <code><a href="#topic+topWords">topWords()</a></code>
</p>
<p>Other topic models: 
<code><a href="#topic+JST">JST</a>()</code>,
<code><a href="#topic+rJST">rJST</a>()</code>,
<code><a href="#topic+sentopicmodel">sentopicmodel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># creating a model
LDA(ECB_press_conferences_tokens, K = 5, alpha = 0.1, beta = 0.01)

# estimating an LDA model
lda &lt;- LDA(ECB_press_conferences_tokens)
lda &lt;- fit(lda, 100)
</code></pre>

<hr>
<h2 id='LDAvis'>Visualize a LDA model using <span class="pkg">LDAvis</span></h2><span id='topic+LDAvis'></span>

<h3>Description</h3>

<p>This function call <span class="pkg">LDAvis</span> to create a dynamic visualization of an
estimated topic model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LDAvis(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LDAvis_+3A_x">x</code></td>
<td>
<p>an <code>LDA</code> model</p>
</td></tr>
<tr><td><code id="LDAvis_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="LDAvis.html#topic+createJSON">LDAvis::createJSON()</a></code> and
<code><a href="LDAvis.html#topic+serVis">LDAvis::serVis()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The CRAN release of <span class="pkg">LDAvis</span> does not support UTF-8 characters
and automatically reorder topics. To solve these two issues, please install
the development version of <span class="pkg">LDAvis</span> from github
(<code>devtools::install_github("cpsievert/LDAvis")</code>).
</p>


<h3>Value</h3>

<p>Nothing, called for its side effects.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.sentopicmodel">plot.sentopicmodel()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lda &lt;- LDA(ECB_press_conferences_tokens)
lda &lt;- fit(lda, 100)
LDAvis(lda)
</code></pre>

<hr>
<h2 id='LoughranMcDonald'>Loughran-McDonald lexicon</h2><span id='topic+LoughranMcDonald'></span>

<h3>Description</h3>

<p>The Loughran-McDonald lexicon for financial texts adapted for
usage in <strong>sentopics</strong>. The lexicon is enhanced with two list of
valence-shifting words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LoughranMcDonald
</code></pre>


<h3>Format</h3>

<p>A <a href="quanteda.html#topic+dictionary">quanteda::dictionary</a> containing two polarity categories (negative
and positive) and two valence-shifting categories (negator and amplifier).
</p>


<h3>Source</h3>

<p><a href="https://sraf.nd.edu/loughranmcdonald-master-dictionary/">https://sraf.nd.edu/loughranmcdonald-master-dictionary/</a> for the
lexicon and <a href="lexicon.html#topic+hash_valence_shifters">lexicon::hash_valence_shifters</a> for the valence shifters.
</p>


<h3>References</h3>

<p>Loughran, T. &amp; McDonald, B. (2011). <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1331573">When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks</a>. <em>The Journal of
Finance</em>, 66(1), 35&ndash;65.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+JST">JST()</a></code>, <code><a href="#topic+rJST">rJST()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>JST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)

</code></pre>

<hr>
<h2 id='melt'>Replacement generic for <code><a href="data.table.html#topic+melt.data.table">data.table::melt()</a></code></h2><span id='topic+melt'></span>

<h3>Description</h3>

<p>As of the CRAN release of the 1.14.8 version of <strong>data.table</strong>, the
<code><a href="data.table.html#topic+melt.data.table">data.table::melt()</a></code> function is not a generic. This function aims to
temporary provide a generic to this function, so that <code><a href="#topic+melt.sentopicmodel">melt.sentopicmodel()</a></code>
can be effectively dispatched when used. Expect this function to disappear
shortly after the release of <strong>data.table</strong> 1.14.9.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>melt(data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="melt_+3A_data">data</code></td>
<td>
<p>an object to melt</p>
</td></tr>
<tr><td><code id="melt_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An unkeyed <code>data.table</code> containing the molten data.
</p>


<h3>See Also</h3>

<p><code><a href="data.table.html#topic+melt.data.table">data.table::melt()</a></code>, <code><a href="#topic+melt.sentopicmodel">melt.sentopicmodel()</a></code>
</p>

<hr>
<h2 id='melt.sentopicmodel'>Melt for sentopicmodels</h2><span id='topic+melt.sentopicmodel'></span>

<h3>Description</h3>

<p>This function extracts the estimated document mixtures from a
topic model and returns them in a long <a href="data.table.html#topic+data.table">data.table</a> format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sentopicmodel'
melt(data, ..., include_docvars = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="melt.sentopicmodel_+3A_data">data</code></td>
<td>
<p>a model created from the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> function
and estimated with <code><a href="#topic+fit">fit()</a></code></p>
</td></tr>
<tr><td><code id="melt.sentopicmodel_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="melt.sentopicmodel_+3A_include_docvars">include_docvars</code></td>
<td>
<p>if <code>TRUE</code>, the melted result will also include the
<em>docvars</em> stored in the <a href="#topic+tokens">tokens</a> object provided at model initialization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="data.table.html#topic+data.table">data.table</a> in the long format, where each line is the estimated
proportion of a single topic/sentiment for a document. For JST and rJST
models, the probability is also decomposed into 'L1' and 'L2' layers,
representing the probability at each layer of the topic-sentiment
hierarchy.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>See Also</h3>

<p><code><a href="#topic+topWords">topWords()</a></code> for extracting representative words,
<code><a href="data.table.html#topic+melt.data.table">data.table::melt()</a></code> and <code><a href="data.table.html#topic+dcast.data.table">data.table::dcast()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># only returns topic proportion for LDA models
lda &lt;- LDA(ECB_press_conferences_tokens)
lda &lt;- fit(lda, 10)
melt(lda)

# includes sentiment for JST and rJST models
jst &lt;- JST(ECB_press_conferences_tokens)
jst &lt;- fit(jst, 10)
melt(jst)
</code></pre>

<hr>
<h2 id='mergeTopics'>Merge topics into fewer themes</h2><span id='topic+mergeTopics'></span>

<h3>Description</h3>

<p>This operation is especially useful for the analysis of the
model's output, by grouping together topics that share a common theme.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mergeTopics(x, merging_list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mergeTopics_+3A_x">x</code></td>
<td>
<p>a <code><a href="#topic+LDA">LDA()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> model.</p>
</td></tr>
<tr><td><code id="mergeTopics_+3A_merging_list">merging_list</code></td>
<td>
<p>a list where each element is an integer vector containing
the indices of topics to be merged. If named, the list's names become the
label of the aggregated themes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Topics are aggregated at the word assignment level. New
document-topic and topic-word probabilities are derived from the aggregated
assignments.
</p>
<p>Note that the output of this function does not constitute an estimated
topic model, but merely an aggregation to ease the analysis. It is not
advised to use <code><a href="#topic+fit.sentopicmodel">fit()</a></code> on the merged topic
model as it will radically affect the content and proportions of the new
themes.
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+LDA">LDA()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> model with the merged topics.
</p>


<h3>See Also</h3>

<p>sentopics_labels
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lda &lt;- LDA(ECB_press_conferences_tokens, K = 5)
lda &lt;- fit(lda, 100)
merging_list &lt;- list(
  c(1,5),
  2:4
)
mergeTopics(lda, merging_list)

# also possible with a named list
merging_list2 &lt;- list(
  mytheme_1 = c(1,5),
  mytheme_2 = 2:4
)
merged &lt;- mergeTopics(lda, merging_list2)
sentopics_labels(merged)

# implemented for rJST
rjst &lt;- rJST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
rjst &lt;- fit(rjst, 100)
mergeTopics(rjst, merging_list2)
</code></pre>

<hr>
<h2 id='PicaultRenault'>Picault-Renault lexicon</h2><span id='topic+PicaultRenault'></span>

<h3>Description</h3>

<p>The Picault-Renault lexicon, specialized in the analysis of
central bank communication. The lexicon identifies a large number of n-grams
and gives their probability to belong to six categories:
</p>

<ul>
<li><p> Monetary Policy - accommodative
</p>
</li>
<li><p> Monetary Policy - neutral
</p>
</li>
<li><p> Monetary Policy - restrictive
</p>
</li>
<li><p> Economic Condition - negative
</p>
</li>
<li><p> Economic Condition - neutral
</p>
</li>
<li><p> Economic Condition - positive
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>PicaultRenault
</code></pre>


<h3>Format</h3>

<p>A <a href="data.table.html#topic+data.table">data.table</a> object.
</p>


<h3>Source</h3>

<p><a href="http://www.cbcomindex.com/lexicon.php">http://www.cbcomindex.com/lexicon.php</a>
</p>


<h3>References</h3>

<p>Picault, M. &amp; Renault, T. (2017). <a href="https://www.sciencedirect.com/science/article/abs/pii/S0261560617301808">Words are not all created equal: A new measure of ECB communication</a>. <em>Journal of
International Money and Finance</em>, 79, 136&ndash;156.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compute_PicaultRenault_scores">compute_PicaultRenault_scores()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(PicaultRenault)

</code></pre>

<hr>
<h2 id='PicaultRenault_data'>Regression dataset based on Picault &amp; Renault (2017)</h2><span id='topic+PicaultRenault_data'></span>

<h3>Description</h3>

<p>A regression dataset built to partially replicate the result of
Picault &amp; Renault. This dataset contains, for each press conference
published after 2000:
</p>

<ul>
<li><p> The Main Refinancing Rate (MRR) of the ECB set following the press
conference
</p>
</li>
<li><p> The change in the MRR following the press conference
</p>
</li>
<li><p> The change in the MRR observed at the previous press conference
</p>
</li>
<li><p> The Bloomberg consensus on the announced MRR
</p>
</li>
<li><p> The Surprise brought by the announcement, computed as the Bloomberg
consensus minus the MRR following the conference
</p>
</li>
<li><p> The EURO STOXX 50 return on the day of the press conference
</p>
</li>
<li><p> The EURO STOXX 50 return on the day preceding the announcement
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>PicaultRenault_data
</code></pre>


<h3>Format</h3>

<p>An <a href="xts.html#topic+xts">xts::xts</a> object.
</p>


<h3>Source</h3>

<p>The data was manually prepared by the author of this package.
</p>


<h3>References</h3>

<p>Picault, M. &amp; Renault, T. (2017). <a href="https://www.sciencedirect.com/science/article/abs/pii/S0261560617301808">Words are not all created equal: A new measure of ECB communication</a>. <em>Journal of
International Money and Finance</em>, 79, 136&ndash;156.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(PicaultRenault_data)

</code></pre>

<hr>
<h2 id='plot.multiChains'>Plot the distances between topic models (chains)</h2><span id='topic+plot.multiChains'></span>

<h3>Description</h3>

<p>Plot the results of <code>chainsDistance(x)</code> using multidimensional
scaling. See <code><a href="#topic+chainsDistances">chainsDistances()</a></code> for details on the distance computation
and <code><a href="stats.html#topic+cmdscale">stats::cmdscale()</a></code> for the implementation of the multidimensional
scaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'multiChains'
plot(
  x,
  ...,
  method = c("euclidean", "hellinger", "cosine", "minMax", "naiveEuclidean",
    "invariantEuclidean")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.multiChains_+3A_x">x</code></td>
<td>
<p>a valid <code>multiChains</code> object, obtained through the estimation of a
topic model using <code><a href="#topic+fit.sentopicmodel">fit()</a></code> and the argument
<code>nChains</code> greater than <code>1</code>.</p>
</td></tr>
<tr><td><code id="plot.multiChains_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="plot.multiChains_+3A_method">method</code></td>
<td>
<p>the method used to measure the distance between chains.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, the coordinates of each topic model resulting from the
multidimensional scaling.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chainsDistances">chainsDistances()</a></code> <code><a href="stats.html#topic+cmdscale">cmdscale()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>models &lt;- LDA(ECB_press_conferences_tokens)
models &lt;- fit(models, 10, nChains = 5)
plot(models)
</code></pre>

<hr>
<h2 id='plot.sentopicmodel'>Plot a topic model using Plotly</h2><span id='topic+plot.sentopicmodel'></span>

<h3>Description</h3>

<p>Summarize and plot a <strong>sentopics</strong> model using a sunburst chart
from the <a href="plotly.html#topic+plotly">plotly::plotly</a> library.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sentopicmodel'
plot(x, nWords = 15, layers = 3, sort = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sentopicmodel_+3A_x">x</code></td>
<td>
<p>a model created from the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> function and
estimated with <code><a href="#topic+fit">fit()</a></code></p>
</td></tr>
<tr><td><code id="plot.sentopicmodel_+3A_nwords">nWords</code></td>
<td>
<p>the number of words per topic/sentiment to display in the outer
layer of the plot</p>
</td></tr>
<tr><td><code id="plot.sentopicmodel_+3A_layers">layers</code></td>
<td>
<p>specifies the number of layers for the sunburst chart. This
will restrict the output to the <code>layers</code> uppermost levels of the chart. For
example, setting <code>layers = 1</code> will only display the top level of the
hierarchy (topics for an LDA model).</p>
</td></tr>
<tr><td><code id="plot.sentopicmodel_+3A_sort">sort</code></td>
<td>
<p>if <code>TRUE</code>, sorts the plotted topics in a decreasing frequency.</p>
</td></tr>
<tr><td><code id="plot.sentopicmodel_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>plotly</code> sunburst chart.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+topWords">topWords()</a></code> <code><a href="#topic+LDAvis">LDAvis()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lda &lt;- LDA(ECB_press_conferences_tokens)
lda &lt;- fit(lda, 100)
plot(lda, nWords = 5)

# only displays the topic proportions
plot(lda, layers = 1)
</code></pre>

<hr>
<h2 id='print.sentopicmodel'>Print method for sentopics models</h2><span id='topic+print.sentopicmodel'></span><span id='topic+print.rJST'></span><span id='topic+print.LDA'></span><span id='topic+print.JST'></span>

<h3>Description</h3>

<p>Print methods for <strong>sentopics</strong> models. Once per session (or
forced by using <code>extended = TRUE</code>), it lists the most important function
related to <strong>sentopics</strong> models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sentopicmodel'
print(x, extended = FALSE, ...)

## S3 method for class 'rJST'
print(x, extended = FALSE, ...)

## S3 method for class 'LDA'
print(x, extended = FALSE, ...)

## S3 method for class 'JST'
print(x, extended = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sentopicmodel_+3A_x">x</code></td>
<td>
<p>the model to be printed</p>
</td></tr>
<tr><td><code id="print.sentopicmodel_+3A_extended">extended</code></td>
<td>
<p>if <code>TRUE</code>, extends the print to include some helpful related
functions. Automatically displayed once per session.</p>
</td></tr>
<tr><td><code id="print.sentopicmodel_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects (printing).
</p>

<hr>
<h2 id='proportion_topics'>Compute the topic or sentiment proportion time series</h2><span id='topic+proportion_topics'></span><span id='topic+plot_proportion_topics'></span>

<h3>Description</h3>

<p>Aggregate the topical or sentiment proportions at the document
level into time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportion_topics(
  x,
  period = c("year", "quarter", "month", "day", "identity"),
  rolling_window = 1,
  complete = TRUE,
  plot = c(FALSE, TRUE, "silent"),
  plot_ridgelines = TRUE,
  as.xts = TRUE,
  ...
)

plot_proportion_topics(
  x,
  period = c("year", "quarter", "month", "day"),
  rolling_window = 1,
  complete = TRUE,
  plot_ridgelines = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportion_topics_+3A_x">x</code></td>
<td>
<p>a <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> model populated with internal dates
and/or internal sentiment.</p>
</td></tr>
<tr><td><code id="proportion_topics_+3A_period">period</code></td>
<td>
<p>the sampling period within which the sentiment of documents
will be averaged. <code>period = "identity"</code> is a special case that will return
document-level variables before the aggregation happens. Useful to rapidly
compute topical sentiment at the document level.</p>
</td></tr>
<tr><td><code id="proportion_topics_+3A_rolling_window">rolling_window</code></td>
<td>
<p>if greater than 1, determines the rolling window to
compute a moving average of sentiment. The rolling window is based on the
period unit and rely on actual dates (i.e, is not affected by unequally
spaced data points).</p>
</td></tr>
<tr><td><code id="proportion_topics_+3A_complete">complete</code></td>
<td>
<p>if FALSE, only compute proportions at the upper level of the
topic model hierarchy (topics for <a href="#topic+rJST">rJST</a> and sentiment for <a href="#topic+JST">JST</a>). No
effect on <a href="#topic+LDA">LDA</a> models.</p>
</td></tr>
<tr><td><code id="proportion_topics_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, prints a plot of the time series and attaches it as an
attribute to the returned object. If <code>'silent'</code>, do not print the plot but
still attaches it as an attribute.</p>
</td></tr>
<tr><td><code id="proportion_topics_+3A_plot_ridgelines">plot_ridgelines</code></td>
<td>
<p>if <code>TRUE</code>, time series are plotted as ridgelines.
Requires <code>ggridges</code> package installed. If <code>FALSE</code>, the plot will use only
standards <code>ggplot2</code> functions. If the argument is missing and the package
<code>ggridges</code> is not installed, this will quietly switch to a <code>ggplot2</code>
output.</p>
</td></tr>
<tr><td><code id="proportion_topics_+3A_as.xts">as.xts</code></td>
<td>
<p>if <code>TRUE</code>, returns an <a href="xts.html#topic+xts">xts::xts</a> object. Otherwise, returns a
data.frame.</p>
</td></tr>
<tr><td><code id="proportion_topics_+3A_...">...</code></td>
<td>
<p>other arguments passed on to <code><a href="zoo.html#topic+rollapply">zoo::rollapply()</a></code> or <code><a href="base.html#topic+mean">mean()</a></code> and
<code><a href="stats.html#topic+sd">sd()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A time series of proportions, stored as an <a href="xts.html#topic+xts">xts::xts</a> object or as a
data.frame.
</p>


<h3>See Also</h3>

<p>sentopics_sentiment sentopics_date
</p>
<p>Other series functions: 
<code><a href="#topic+sentiment_breakdown">sentiment_breakdown</a>()</code>,
<code><a href="#topic+sentiment_series">sentiment_series</a>()</code>,
<code><a href="#topic+sentiment_topics">sentiment_topics</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lda &lt;- LDA(ECB_press_conferences_tokens)
lda &lt;- fit(lda, 100)
proportion_topics(lda)

# plot shortcut
plot_proportion_topics(lda, period = "month", rolling_window = 3)
# with or without ridgelines
plot_proportion_topics(lda, period = "month", plot_ridgelines = FALSE)

# also available for rJST and JST models
jst &lt;- JST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
jst &lt;- fit(jst, 100)
# including both layers
proportion_topics(jst)
# or not
proportion_topics(jst, complete = FALSE)
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+as.tokens'></span><span id='topic+fit'></span><span id='topic+docvars'></span><span id='topic+tokens'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+fit">fit</a></code></p>
</dd>
<dt>quanteda</dt><dd><p><code><a href="quanteda.html#topic+as.tokens">as.tokens</a></code>, <code><a href="quanteda.html#topic+docvars">docvars</a></code>, <code><a href="quanteda.html#topic+tokens">tokens</a></code></p>
</dd>
</dl>

<hr>
<h2 id='reset'>Re-initialize a topic model</h2><span id='topic+reset'></span>

<h3>Description</h3>

<p>This function is used re-initialize  a topic model, as if it was
created from <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or another model. The re-initialized model
retains its original parameter specification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reset(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reset_+3A_object">object</code></td>
<td>
<p>a model created from the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> function and
estimated with <code><a href="#topic+fit">fit()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>sentopicmodel</code> of the relevant model class, with the iteration count
reset to zero and re-initialized assignment of latent variables.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- LDA(ECB_press_conferences_tokens)
model &lt;- fit(model, 10)
reset(model)
</code></pre>

<hr>
<h2 id='rJST'>Create a Reversed Joint Sentiment/Topic model</h2><span id='topic+rJST'></span><span id='topic+rJST.default'></span><span id='topic+rJST.LDA'></span>

<h3>Description</h3>

<p>This function initialize a Reversed Joint Sentiment/Topic model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rJST(x, ...)

## Default S3 method:
rJST(
  x,
  lexicon = NULL,
  K = 5,
  S = 3,
  alpha = 1,
  gamma = 5,
  beta = 0.01,
  alphaCycle = 0,
  gammaCycle = 0,
  ...
)

## S3 method for class 'LDA'
rJST(x, lexicon = NULL, S = 3, gamma = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rJST_+3A_x">x</code></td>
<td>
<p>tokens object containing the texts. A coercion will be attempted if <code>x</code> is not a tokens.</p>
</td></tr>
<tr><td><code id="rJST_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="rJST_+3A_lexicon">lexicon</code></td>
<td>
<p>a <code>quanteda</code> dictionary with positive and negative categories</p>
</td></tr>
<tr><td><code id="rJST_+3A_k">K</code></td>
<td>
<p>the number of topics</p>
</td></tr>
<tr><td><code id="rJST_+3A_s">S</code></td>
<td>
<p>the number of sentiments</p>
</td></tr>
<tr><td><code id="rJST_+3A_alpha">alpha</code></td>
<td>
<p>the hyperparameter of topic-document distribution</p>
</td></tr>
<tr><td><code id="rJST_+3A_gamma">gamma</code></td>
<td>
<p>the hyperparameter of sentiment-document distribution</p>
</td></tr>
<tr><td><code id="rJST_+3A_beta">beta</code></td>
<td>
<p>the hyperparameter of vocabulary distribution</p>
</td></tr>
<tr><td><code id="rJST_+3A_alphacycle">alphaCycle</code></td>
<td>
<p>integer specifying the cycle size between two updates of
the hyperparameter alpha</p>
</td></tr>
<tr><td><code id="rJST_+3A_gammacycle">gammaCycle</code></td>
<td>
<p>integer specifying the cycle size between two updates of
the hyperparameter alpha</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>rJST.LDA</code> methods enable the transition from a previously
estimated <a href="#topic+LDA">LDA</a> model to a sentiment-aware <code>rJST</code> model. The function
retains the previously estimated topics and randomly assigns sentiment to
every word of the corpus. The new model will retain the iteration count of
the initial <a href="#topic+LDA">LDA</a> model.
</p>


<h3>Value</h3>

<p>An S3 list containing the model parameter and the estimated mixture.
This object corresponds to a Gibbs sampler estimator with zero iterations.
The MCMC can be iterated using the <code><a href="#topic+fit.sentopicmodel">fit()</a></code>
function.
</p>

<ul>
<li> <p><code>tokens</code> is the tokens object used to create the model
</p>
</li>
<li> <p><code>vocabulary</code> contains the set of words of the corpus
</p>
</li>
<li> <p><code>it</code> tracks the number of Gibbs sampling iterations
</p>
</li>
<li> <p><code>za</code> is the list of topic assignment, aligned to the <code>tokens</code> object with
padding removed
</p>
</li>
<li> <p><code>logLikelihood</code> returns the measured log-likelihood at each iteration,
with a breakdown of the likelihood into hierarchical components as
attribute
</p>
</li></ul>

<p>The <code><a href="#topic+topWords">topWords()</a></code> function easily extract the most probables words of each
topic/sentiment.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>References</h3>

<p>Lin, C. and He, Y. (2009). <a href="https://dl.acm.org/doi/10.1145/1645953.1646003">Joint sentiment/topic model for sentiment analysis</a>. In <em>Proceedings
of the 18th ACM conference on Information and knowledge management</em>,
375&ndash;384.
</p>
<p>Lin, C., He, Y., Everson, R. and Ruger, S. (2012). <a href="https://ieeexplore.ieee.org/document/5710933">Weakly Supervised Joint Sentiment-Topic Detection from Text</a>.
<em>IEEE Transactions on Knowledge and Data Engineering</em>, 24(6), 1134–-1145.
</p>


<h3>See Also</h3>

<p>Fitting a model: <code><a href="#topic+fit.sentopicmodel">fit()</a></code>, extracting
top words: <code><a href="#topic+topWords">topWords()</a></code>
</p>
<p>Other topic models: 
<code><a href="#topic+JST">JST</a>()</code>,
<code><a href="#topic+LDA">LDA</a>()</code>,
<code><a href="#topic+sentopicmodel">sentopicmodel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple rJST model
rJST(ECB_press_conferences_tokens)

# estimating a rJST model including lexicon
rjst &lt;- rJST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
rjst &lt;- fit(rjst, 100)

# from an LDA model:
lda &lt;- LDA(ECB_press_conferences_tokens)
lda &lt;- fit(lda, 100)

# creating a rJST model out of it
rjst &lt;- rJST(lda, lexicon = LoughranMcDonald)
# topic proportions remain identical
identical(lda$theta, rjst$theta)
# model should be iterated to estimate sentiment proportions
rjst &lt;- fit(rjst, 100)
</code></pre>

<hr>
<h2 id='sentiment_breakdown'>Breakdown the sentiment into topical components</h2><span id='topic+sentiment_breakdown'></span><span id='topic+plot_sentiment_breakdown'></span>

<h3>Description</h3>

<p>Break down the sentiment series obtained with
<code><a href="#topic+sentiment_series">sentiment_series()</a></code> into topical components. Sentiment is broken down at
the document level using estimated topic proportions, then processed to
create a time series and its components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentiment_breakdown(
  x,
  period = c("year", "quarter", "month", "day", "identity"),
  rolling_window = 1,
  scale = TRUE,
  scaling_period = c("1900-01-01", "2099-12-31"),
  plot = c(FALSE, TRUE, "silent"),
  as.xts = TRUE,
  ...
)

plot_sentiment_breakdown(
  x,
  period = c("year", "quarter", "month", "day"),
  rolling_window = 1,
  scale = TRUE,
  scaling_period = c("1900-01-01", "2099-12-31"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentiment_breakdown_+3A_x">x</code></td>
<td>
<p>a <code><a href="#topic+LDA">LDA()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> model populated with internal dates and/or
internal sentiment.</p>
</td></tr>
<tr><td><code id="sentiment_breakdown_+3A_period">period</code></td>
<td>
<p>the sampling period within which the sentiment of documents
will be averaged. <code>period = "identity"</code> is a special case that will return
document-level variables before the aggregation happens. Useful to rapidly
compute topical sentiment at the document level.</p>
</td></tr>
<tr><td><code id="sentiment_breakdown_+3A_rolling_window">rolling_window</code></td>
<td>
<p>if greater than 1, determines the rolling window to
compute a moving average of sentiment. The rolling window is based on the
period unit and rely on actual dates (i.e, is not affected by unequally
spaced data points).</p>
</td></tr>
<tr><td><code id="sentiment_breakdown_+3A_scale">scale</code></td>
<td>
<p>if <code>TRUE</code>, the resulting time series will be scaled to a mean of
zero and a standard deviation of 1. This argument also has the side effect
of attaching scaled sentiment values as <em>docvars</em> to the input object with
the <code style="white-space: pre;">&#8288;_scaled&#8288;</code> suffix.</p>
</td></tr>
<tr><td><code id="sentiment_breakdown_+3A_scaling_period">scaling_period</code></td>
<td>
<p>the date range over which the scaling should be
applied. Particularly useful to normalize only the beginning of the time
series.</p>
</td></tr>
<tr><td><code id="sentiment_breakdown_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, prints a plot of the time series and attaches it as an
attribute to the returned object. If <code>'silent'</code>, do not print the plot but
still attaches it as an attribute.</p>
</td></tr>
<tr><td><code id="sentiment_breakdown_+3A_as.xts">as.xts</code></td>
<td>
<p>if <code>TRUE</code>, returns an <a href="xts.html#topic+xts">xts::xts</a> object. Otherwise, returns a
data.frame.</p>
</td></tr>
<tr><td><code id="sentiment_breakdown_+3A_...">...</code></td>
<td>
<p>other arguments passed on to <code><a href="zoo.html#topic+rollapply">zoo::rollapply()</a></code> or <code><a href="base.html#topic+mean">mean()</a></code> and
<code><a href="stats.html#topic+sd">sd()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sentiment is broken down at the sentiment level assuming the
following composition: </p>
<p style="text-align: center;"><code class="reqn">s = \sum^K_{i=1} s_i \times \theta_i</code>
</p>
<p>, where
<code class="reqn">s_i</code> is the sentiment of topic i and <code class="reqn">theta_i</code> the proportion of
topic i in a given document. For an LDA model, the sentiment of each topic
is considered equal to the document sentiment (i.e. <code class="reqn">s_i = s \forall i
  \in K</code>). The topical sentiment attention, defined by <code class="reqn">s*_i = s_i \times
  \theta_i</code> represent the effective sentiment conveyed by a topic in a
document. The topical sentiment attention of all documents in a period are
averaged to compute the breakdown of the sentiment time series.
</p>


<h3>Value</h3>

<p>A time series of sentiment, stored as an <a href="xts.html#topic+xts">xts::xts</a> object or as a
data.frame.
</p>


<h3>See Also</h3>

<p>sentopics_sentiment sentopics_date
</p>
<p>Other series functions: 
<code><a href="#topic+proportion_topics">proportion_topics</a>()</code>,
<code><a href="#topic+sentiment_series">sentiment_series</a>()</code>,
<code><a href="#topic+sentiment_topics">sentiment_topics</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lda &lt;- LDA(ECB_press_conferences_tokens)
lda &lt;- fit(lda, 100)
sentiment_breakdown(lda)

# plot shortcut
plot_sentiment_breakdown(lda)

# also available for rJST models (with topic-level sentiment)
rjst &lt;- rJST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
rjst &lt;- fit(rjst, 100)
sentopics_sentiment(rjst, override = TRUE)
plot_sentiment_breakdown(rjst)
</code></pre>

<hr>
<h2 id='sentiment_series'>Compute a sentiment time series</h2><span id='topic+sentiment_series'></span>

<h3>Description</h3>

<p>Compute a sentiment time series based on the internal sentiment
and dates of a <code>sentopicmodel</code>. The time series computation supports
multiple sampling period and optionally allow computing a moving average.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentiment_series(
  x,
  period = c("year", "quarter", "month", "day"),
  rolling_window = 1,
  scale = TRUE,
  scaling_period = c("1900-01-01", "2099-12-31"),
  as.xts = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentiment_series_+3A_x">x</code></td>
<td>
<p>a <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> model populated with internal dates
and/or internal sentiment.</p>
</td></tr>
<tr><td><code id="sentiment_series_+3A_period">period</code></td>
<td>
<p>the sampling period within which the sentiment of documents
will be averaged. <code>period = "identity"</code> is a special case that will return
document-level variables before the aggregation happens. Useful to rapidly
compute topical sentiment at the document level.</p>
</td></tr>
<tr><td><code id="sentiment_series_+3A_rolling_window">rolling_window</code></td>
<td>
<p>if greater than 1, determines the rolling window to
compute a moving average of sentiment. The rolling window is based on the
period unit and rely on actual dates (i.e, is not affected by unequally
spaced data points).</p>
</td></tr>
<tr><td><code id="sentiment_series_+3A_scale">scale</code></td>
<td>
<p>if <code>TRUE</code>, the resulting time series will be scaled to a mean of
zero and a standard deviation of 1. This argument also has the side effect
of attaching scaled sentiment values as <em>docvars</em> to the input object with
the <code style="white-space: pre;">&#8288;_scaled&#8288;</code> suffix.</p>
</td></tr>
<tr><td><code id="sentiment_series_+3A_scaling_period">scaling_period</code></td>
<td>
<p>the date range over which the scaling should be
applied. Particularly useful to normalize only the beginning of the time
series.</p>
</td></tr>
<tr><td><code id="sentiment_series_+3A_as.xts">as.xts</code></td>
<td>
<p>if <code>TRUE</code>, returns an <a href="xts.html#topic+xts">xts::xts</a> object. Otherwise, returns a
data.frame.</p>
</td></tr>
<tr><td><code id="sentiment_series_+3A_...">...</code></td>
<td>
<p>other arguments passed on to <code><a href="zoo.html#topic+rollapply">zoo::rollapply()</a></code> or <code><a href="base.html#topic+mean">mean()</a></code> and
<code><a href="stats.html#topic+sd">sd()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A time series of sentiment, stored as an <a href="xts.html#topic+xts">xts::xts</a> or
data.frame.
</p>


<h3>See Also</h3>

<p>sentopics_sentiment sentopics_date
</p>
<p>Other series functions: 
<code><a href="#topic+proportion_topics">proportion_topics</a>()</code>,
<code><a href="#topic+sentiment_breakdown">sentiment_breakdown</a>()</code>,
<code><a href="#topic+sentiment_topics">sentiment_topics</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lda &lt;- LDA(ECB_press_conferences_tokens)
series &lt;- sentiment_series(lda, period = "month")

# JST and rJST models can use computed sentiment from the sentiment layer,
# but the model must be estimated first.
rjst &lt;- rJST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
sentiment_series(rjst)

sentopics_sentiment(rjst) &lt;- NULL ## remove existing sentiment
rjst &lt;- fit(rjst, 10) ## estimating the model is then needed
sentiment_series(rjst)

# note the presence of both raw and scaled sentiment values
# in the initial object
sentopics_sentiment(lda)
sentopics_sentiment(rjst)
</code></pre>

<hr>
<h2 id='sentiment_topics'>Compute time series of topical sentiments</h2><span id='topic+sentiment_topics'></span><span id='topic+plot_sentiment_topics'></span>

<h3>Description</h3>

<p>Derive topical time series of sentiment from a <code><a href="#topic+LDA">LDA()</a></code> or
<code><a href="#topic+rJST">rJST()</a></code> model. The time series are created by leveraging on estimated
topic proportions and internal sentiment (for <code>LDA</code> models) or topical
sentiment (for <code>rJST</code> models).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentiment_topics(
  x,
  period = c("year", "quarter", "month", "day", "identity"),
  rolling_window = 1,
  scale = TRUE,
  scaling_period = c("1900-01-01", "2099-12-31"),
  plot = c(FALSE, TRUE, "silent"),
  plot_ridgelines = TRUE,
  as.xts = TRUE,
  ...
)

plot_sentiment_topics(
  x,
  period = c("year", "quarter", "month", "day"),
  rolling_window = 1,
  scale = TRUE,
  scaling_period = c("1900-01-01", "2099-12-31"),
  plot_ridgelines = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentiment_topics_+3A_x">x</code></td>
<td>
<p>a <code><a href="#topic+LDA">LDA()</a></code> or <code><a href="#topic+rJST">rJST()</a></code> model populated with internal dates and/or
internal sentiment.</p>
</td></tr>
<tr><td><code id="sentiment_topics_+3A_period">period</code></td>
<td>
<p>the sampling period within which the sentiment of documents
will be averaged. <code>period = "identity"</code> is a special case that will return
document-level variables before the aggregation happens. Useful to rapidly
compute topical sentiment at the document level.</p>
</td></tr>
<tr><td><code id="sentiment_topics_+3A_rolling_window">rolling_window</code></td>
<td>
<p>if greater than 1, determines the rolling window to
compute a moving average of sentiment. The rolling window is based on the
period unit and rely on actual dates (i.e, is not affected by unequally
spaced data points).</p>
</td></tr>
<tr><td><code id="sentiment_topics_+3A_scale">scale</code></td>
<td>
<p>if <code>TRUE</code>, the resulting time series will be scaled to a mean of
zero and a standard deviation of 1. This argument also has the side effect
of attaching scaled sentiment values as <em>docvars</em> to the input object with
the <code style="white-space: pre;">&#8288;_scaled&#8288;</code> suffix.</p>
</td></tr>
<tr><td><code id="sentiment_topics_+3A_scaling_period">scaling_period</code></td>
<td>
<p>the date range over which the scaling should be
applied. Particularly useful to normalize only the beginning of the time
series.</p>
</td></tr>
<tr><td><code id="sentiment_topics_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, prints a plot of the time series and attaches it as an
attribute to the returned object. If <code>'silent'</code>, do not print the plot but
still attaches it as an attribute.</p>
</td></tr>
<tr><td><code id="sentiment_topics_+3A_plot_ridgelines">plot_ridgelines</code></td>
<td>
<p>if <code>TRUE</code>, time series are plotted as ridgelines.
Requires <code>ggridges</code> package installed. If <code>FALSE</code>, the plot will use only
standards <code>ggplot2</code> functions. If the argument is missing and the package
<code>ggridges</code> is not installed, this will quietly switch to a <code>ggplot2</code>
output.</p>
</td></tr>
<tr><td><code id="sentiment_topics_+3A_as.xts">as.xts</code></td>
<td>
<p>if <code>TRUE</code>, returns an <a href="xts.html#topic+xts">xts::xts</a> object. Otherwise, returns a
data.frame.</p>
</td></tr>
<tr><td><code id="sentiment_topics_+3A_...">...</code></td>
<td>
<p>other arguments passed on to <code><a href="zoo.html#topic+rollapply">zoo::rollapply()</a></code> or <code><a href="base.html#topic+mean">mean()</a></code> and
<code><a href="stats.html#topic+sd">sd()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A topical sentiment is computed at the document level for each
topic. For an LDA model, the sentiment of each topic is considered equal to
the document sentiment (i.e. <code class="reqn">s_i = s \forall i \in K</code>). For a rJST
model, these result from the proportions in the sentiment layer under each
topic. To compute the topical time series, the topical sentiment of all
documents in a period are aggregated according to their respective topic
proportion. For example, for a given topic, the topical sentiment in period
<code class="reqn">t</code> is computed using: </p>
<p style="text-align: center;"><code class="reqn">s_t = \frac{\sum_{d = 1}^D s_d \times
  \theta_d}{\sum_{d = 1}^D \theta_d}</code>
</p>
<p>, where <code class="reqn">s_d</code> is the sentiment of
the topic in document d and <code class="reqn">theta_d</code> the topic proportion in a
document d.
</p>


<h3>Value</h3>

<p>an <a href="xts.html#topic+xts">xts::xts</a> or data.frame containing the time series of topical
sentiments.
</p>


<h3>See Also</h3>

<p>sentopics_sentiment sentopics_date
</p>
<p>Other series functions: 
<code><a href="#topic+proportion_topics">proportion_topics</a>()</code>,
<code><a href="#topic+sentiment_breakdown">sentiment_breakdown</a>()</code>,
<code><a href="#topic+sentiment_series">sentiment_series</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lda &lt;- LDA(ECB_press_conferences_tokens)
lda &lt;- fit(lda, 100)
sentiment_topics(lda)

# plot shortcut
plot_sentiment_topics(lda, period = "month", rolling_window = 3)
# with or without ridgelines
plot_sentiment_topics(lda, period = "month", plot_ridgelines = FALSE)

# also available for rJST models with internal sentiment computation
rjst &lt;- rJST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
rjst &lt;- fit(rjst, 100)
sentopics_sentiment(rjst, override = TRUE)
sentiment_topics(rjst)
</code></pre>

<hr>
<h2 id='sentopicmodel'>Create a sentopic model</h2><span id='topic+sentopicmodel'></span>

<h3>Description</h3>

<p>The set of functions <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code>, <code><a href="#topic+rJST">rJST()</a></code> and
<code><a href="#topic+sentopicmodel">sentopicmodel()</a></code> are all wrappers to an unified C++ routine and attempt to
replicate their corresponding model. This function is the lower level
wrapper to the C++ routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentopicmodel(
  x,
  lexicon = NULL,
  L1 = 5,
  L2 = 3,
  L1prior = 1,
  L2prior = 5,
  beta = 0.01,
  L1cycle = 0,
  L2cycle = 0,
  reversed = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentopicmodel_+3A_x">x</code></td>
<td>
<p>tokens object containing the texts. A coercion will be attempted if <code>x</code> is not a tokens.</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_lexicon">lexicon</code></td>
<td>
<p>a <code>quanteda</code> dictionary with positive and negative categories</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_l1">L1</code></td>
<td>
<p>the number of labels in the first document mixture layer</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_l2">L2</code></td>
<td>
<p>the number of labels in the second document mixture layer</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_l1prior">L1prior</code></td>
<td>
<p>the first layer hyperparameter of document mixtures</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_l2prior">L2prior</code></td>
<td>
<p>the second layer hyperparameter of document mixtures</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_beta">beta</code></td>
<td>
<p>the hyperparameter of vocabulary distribution</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_l1cycle">L1cycle</code></td>
<td>
<p>integer specifying the cycle size between two updates of the hyperparameter L1prior</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_l2cycle">L2cycle</code></td>
<td>
<p>integer specifying the cycle size between two updates of the hyperparameter L2prior</p>
</td></tr>
<tr><td><code id="sentopicmodel_+3A_reversed">reversed</code></td>
<td>
<p>indicates on which dimension should <code>lexicon</code> apply. When
<code>reversed=FALSE</code>, the lexicon is applied on the first layer of the document
mixture (as in a JST model). When <code>reversed=TRUE</code>, the lexicon is applied to
the second layer of the document mixture (as in a reversed-JST model).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 list containing the model parameter and the estimated mixture.
This object corresponds to a Gibbs sampler estimator with zero iterations.
The MCMC can be iterated using the <code><a href="#topic+fit.sentopicmodel">fit()</a></code>
function.
</p>

<ul>
<li> <p><code>tokens</code> is the tokens object used to create the model
</p>
</li>
<li> <p><code>vocabulary</code> contains the set of words of the corpus
</p>
</li>
<li> <p><code>it</code> tracks the number of Gibbs sampling iterations
</p>
</li>
<li> <p><code>za</code> is the list of topic assignment, aligned to the <code>tokens</code> object with
padding removed
</p>
</li>
<li> <p><code>logLikelihood</code> returns the measured log-likelihood at each iteration,
with a breakdown of the likelihood into hierarchical components as
attribute
</p>
</li></ul>

<p>The <code><a href="#topic+topWords">topWords()</a></code> function easily extract the most probables words of each
topic/sentiment.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>See Also</h3>

<p>Fitting a model: <code><a href="#topic+fit.sentopicmodel">fit()</a></code>,
extracting top words: <code><a href="#topic+topWords">topWords()</a></code>
</p>
<p>Other topic models: 
<code><a href="#topic+JST">JST</a>()</code>,
<code><a href="#topic+LDA">LDA</a>()</code>,
<code><a href="#topic+rJST">rJST</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LDA(ECB_press_conferences_tokens)
rJST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
</code></pre>

<hr>
<h2 id='sentopics_date'>Internal date</h2><span id='topic+sentopics_date'></span><span id='topic+sentopics_date+3C-'></span>

<h3>Description</h3>

<p>Extract or replace the internal dates of a <code>sentopicmodel</code>. The
internal dates are used to create time series using the functions
<code><a href="#topic+sentiment_series">sentiment_series()</a></code> or <code><a href="#topic+sentiment_topics">sentiment_topics()</a></code>. Dates should be provided by
using <code>sentopics_date(x) &lt;- value</code> or by storing a '.date' docvars in
the <a href="#topic+tokens">tokens</a> object used to create the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentopics_date(x, include_docvars = FALSE)

sentopics_date(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentopics_date_+3A_x">x</code></td>
<td>
<p>a <code>sentopicmodel</code> created from the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code>, <code><a href="#topic+rJST">rJST()</a></code> or
<code><a href="#topic+sentopicmodel">sentopicmodel()</a></code> function</p>
</td></tr>
<tr><td><code id="sentopics_date_+3A_include_docvars">include_docvars</code></td>
<td>
<p>if <code>TRUE</code> the function will return all docvars stored
in the internal <code>tokens</code> object of the model</p>
</td></tr>
<tr><td><code id="sentopics_date_+3A_value">value</code></td>
<td>
<p>a <code>Date</code>-coercible vector of dates to input into the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame with the stored date per document.
</p>


<h3>Note</h3>

<p>The internal date is stored internally in the <em>docvars</em> of the topic
model. This means that dates may also be accessed through the <code><a href="#topic+docvars">docvars()</a></code>
function, although this is discouraged.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>See Also</h3>

<p>Other sentopics helpers: 
<code><a href="#topic+sentopics_labels">sentopics_labels</a>()</code>,
<code><a href="#topic+sentopics_sentiment">sentopics_sentiment</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example dataset already contains ".date" docvar
docvars(ECB_press_conferences_tokens)
# dates are automatically stored in the sentopicmodel object
lda &lt;- LDA(ECB_press_conferences_tokens)
sentopics_date(lda)

# dates can be removed or modified by the assignment operator
sentopics_date(lda) &lt;- NULL
sentopics_date(lda) &lt;- docvars(ECB_press_conferences_tokens, ".date")
</code></pre>

<hr>
<h2 id='sentopics_labels'>Setting topic or sentiment labels</h2><span id='topic+sentopics_labels'></span><span id='topic+sentopics_labels+3C-'></span>

<h3>Description</h3>

<p>Extract or replace the labels of a <code>sentopicmodel</code>. The replaced
labels will appear in most functions dealing with the output of the
<code>sentomicmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentopics_labels(x, flat = TRUE)

sentopics_labels(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentopics_labels_+3A_x">x</code></td>
<td>
<p>a <code>sentopicmodel</code> created from the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code>, <code><a href="#topic+rJST">rJST()</a></code> or
<code><a href="#topic+sentopicmodel">sentopicmodel()</a></code> function</p>
</td></tr>
<tr><td><code id="sentopics_labels_+3A_flat">flat</code></td>
<td>
<p>if FALSE, return a list of dimension labels instead of a
character vector.</p>
</td></tr>
<tr><td><code id="sentopics_labels_+3A_value">value</code></td>
<td>
<p>a list of future labels for the topic model. The list should be
named and contain a character vector for each dimension to label. See the
examples for a correct usage.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector of topic/sentiment labels.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>See Also</h3>

<p>mergeTopics
</p>
<p>Other sentopics helpers: 
<code><a href="#topic+sentopics_date">sentopics_date</a>()</code>,
<code><a href="#topic+sentopics_sentiment">sentopics_sentiment</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># by default, sentopics_labels() generate standard topic names
lda &lt;- LDA(ECB_press_conferences_tokens)
sentopics_labels(lda)

# to change labels, a named list must be provided
sentopics_labels(lda) &lt;- list(
 topic = paste0("superTopic", 1:lda$K)
)
sentopics_labels(lda)

# using NULL remove labels
sentopics_labels(lda) &lt;- NULL
sentopics_labels(lda)

# also works for JST/rJST models
jst &lt;- JST(ECB_press_conferences_tokens)
sentopics_labels(jst) &lt;- list(
  topic = paste0("superTopic", 1:jst$K),
  sentiment = c("negative", "neutral", "positive")
)
sentopics_labels(jst)

# setting flat = FALSE return a list or labels for each dimension
sentopics_labels(jst, flat = FALSE)
</code></pre>

<hr>
<h2 id='sentopics_sentiment'>Internal sentiment</h2><span id='topic+sentopics_sentiment'></span><span id='topic+sentopics_sentiment+3C-'></span>

<h3>Description</h3>

<p>Compute, extract or replace the internal sentiment of a
<code>sentopicmodel</code>. The internal sentiment is used to create time series using
the functions <code><a href="#topic+sentiment_series">sentiment_series()</a></code> or <code><a href="#topic+sentiment_topics">sentiment_topics()</a></code>. If the input
model contains a sentiment layer, sentiment can be computed directly from
the output of the model. Otherwise, sentiment obtained externally should be
added for each document.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentopics_sentiment(
  x,
  method = c("proportional", "proportionalPol"),
  override = FALSE,
  quiet = FALSE,
  include_docvars = FALSE
)

sentopics_sentiment(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentopics_sentiment_+3A_x">x</code></td>
<td>
<p>a <code>sentopicmodel</code> created from the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code>, <code><a href="#topic+rJST">rJST()</a></code> or
<code><a href="#topic+sentopicmodel">sentopicmodel()</a></code> function</p>
</td></tr>
<tr><td><code id="sentopics_sentiment_+3A_method">method</code></td>
<td>
<p>the method used to compute sentiment, see &quot;Methods&quot; below.
Ignored if an internal sentiment is already stored, unless <code>override</code> is
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="sentopics_sentiment_+3A_override">override</code></td>
<td>
<p>by default, the function computes sentiment only if no
internal sentiment is already stored within the <code>sentopicmodel</code> object.
This avoid, for example, erasing externally provided sentiment. Set to
<code>TRUE</code> to force computation of new sentiment values. Only useful for models
with a sentiment layer.</p>
</td></tr>
<tr><td><code id="sentopics_sentiment_+3A_quiet">quiet</code></td>
<td>
<p>if <code>FALSE</code>, print a message when internal sentiment is found.</p>
</td></tr>
<tr><td><code id="sentopics_sentiment_+3A_include_docvars">include_docvars</code></td>
<td>
<p>if <code>TRUE</code> the function will return all docvars stored
in the internal <code>tokens</code> object of the model</p>
</td></tr>
<tr><td><code id="sentopics_sentiment_+3A_value">value</code></td>
<td>
<p>a numeric vector of sentiment to input into the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computed sentiment varies depending on the model. For <a href="#topic+LDA">LDA</a>,
sentiment computation is not possible.
</p>
<p>For <a href="#topic+JST">JST</a>, the sentiment is computed on a per-document basis according to
the document-level sentiment mixtures.
</p>
<p>For a <a href="#topic+rJST">rJST</a> model, a sentiment is computed for each topic, resulting in
<code>K</code> sentiment values per document. In that case, the <code>.sentiment</code> column is
an average of the <code>K</code> sentiment values, weighted by they respective topical
proportions.
</p>


<h3>Value</h3>

<p>A data.frame with the stored sentiment per document.
</p>


<h3>Methods</h3>

<p>The function accepts two methods of computing sentiment:
</p>

<ul>
<li> <p><strong>proportional</strong> computes the difference between the estimated positive
and negative proportions for each document (and possibly each topic).
</p>
<p style="text-align: center;"><code class="reqn">positive - negative</code>
</p>

</li>
<li> <p><strong>proportionalPol</strong> computes the difference between positive and negative
proportions, divided by the sum of positive and negative proportions. As a
result, the computed sentiment lies within the (-1;1) interval.
</p>
<p style="text-align: center;"><code class="reqn">\frac{positive - negative}{positive + negative}</code>
</p>

</li></ul>

<p>Both methods will lead to the same result for a JST model containing only
negative and positive sentiments.
</p>


<h3>Note</h3>

<p>The internal sentiment is stored internally in the <em>docvars</em> of the
topic model. This means that sentiment may also be accessed through the
<code><a href="#topic+docvars">docvars()</a></code> function, although this is discouraged.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>See Also</h3>

<p>Other sentopics helpers: 
<code><a href="#topic+sentopics_date">sentopics_date</a>()</code>,
<code><a href="#topic+sentopics_labels">sentopics_labels</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example dataset already contains ".sentiment" docvar
docvars(ECB_press_conferences_tokens)
# sentiment is automatically stored in the sentopicmodel object
lda &lt;- LDA(ECB_press_conferences_tokens)
sentopics_sentiment(lda)

# sentiment can be removed or modified by the assignment operator
sentopics_sentiment(lda) &lt;- NULL
sentopics_sentiment(lda) &lt;- docvars(ECB_press_conferences_tokens, ".sentiment")

# for JST models, sentiment can be computed from the output of the model
jst &lt;- JST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
jst &lt;- fit(jst, 100)
sentopics_sentiment(jst, override = TRUE) # replace existing sentiment

## for rJST models one sentiment value is computed by topic
rjst &lt;- rJST(ECB_press_conferences_tokens, lexicon = LoughranMcDonald)
rjst &lt;- fit(rjst, 100)
sentopics_sentiment(rjst, override = TRUE)
</code></pre>

<hr>
<h2 id='sentopics-conversions'>Internal conversions between <strong>sentopics</strong> models.</h2><span id='topic+sentopics-conversions'></span><span id='topic+as.sentopicmodel'></span><span id='topic+as.rJST'></span><span id='topic+as.JST'></span>

<h3>Description</h3>

<p>Internal conversions between <strong>sentopics</strong> models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.sentopicmodel(x)

as.rJST(x)

as.JST(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentopics-conversions_+3A_x">x</code></td>
<td>
<p>A <strong>sentopics</strong> model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <strong>sentopics</strong> model of the relevant class
</p>

<hr>
<h2 id='topWords'>Extract the most representative words from topics</h2><span id='topic+topWords'></span><span id='topic+plot_topWords'></span>

<h3>Description</h3>

<p>Extract the top words in each topic/sentiment from a
<code>sentopicmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topWords(
  x,
  nWords = 10,
  method = c("frequency", "probability", "term-score", "FREX"),
  output = c("data.frame", "plot", "matrix"),
  subset,
  w = 0.5
)

plot_topWords(
  x,
  nWords = 10,
  method = c("frequency", "probability", "term-score", "FREX"),
  subset,
  w = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="topWords_+3A_x">x</code></td>
<td>
<p>a <code>sentopicmodel</code> created from the <code><a href="#topic+LDA">LDA()</a></code>, <code><a href="#topic+JST">JST()</a></code> or <code><a href="#topic+rJST">rJST()</a></code></p>
</td></tr>
<tr><td><code id="topWords_+3A_nwords">nWords</code></td>
<td>
<p>the number of top words to extract</p>
</td></tr>
<tr><td><code id="topWords_+3A_method">method</code></td>
<td>
<p>specify if a re-ranking function should be applied before
returning the top words. See Details for a description of each method.</p>
</td></tr>
<tr><td><code id="topWords_+3A_output">output</code></td>
<td>
<p>determines the output of the function</p>
</td></tr>
<tr><td><code id="topWords_+3A_subset">subset</code></td>
<td>
<p>allows to subset using a logical expression, as in <code><a href="base.html#topic+subset">subset()</a></code>.
Particularly useful to limit the number of observation on plot outputs. The
logical expression uses topic and sentiment <em>indices</em> rather than their
label. It is possible to subset on both topic and sentiment but adding a
<code>&amp;</code> operator between two expressions.</p>
</td></tr>
<tr><td><code id="topWords_+3A_w">w</code></td>
<td>
<p>only used when <code>method = "FREX"</code>. Determines the weight assigned to
the exclusivity score at the expense of the frequency score.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>"frequency"</code> ranks top words according to their frequency
within a topic. This method also reports the overall frequency of
each word. When returning a plot, the overall frequency is
represented with a grey bar.
</p>
<p><code>"probability"</code> uses the estimated topic-word mixture <code class="reqn">\phi</code> to
rank top words.
</p>
<p><code>"term-score"</code> implements the re-ranking method from Blei and
Lafferty (2009). This method down-weights terms that have high
probability in all topics using the following score:
</p>
<p style="text-align: center;"><code class="reqn">\text{term-score}_{k,v} = \phi_{k, v}\log\left(\frac{\phi_{k,
  v}}{\left(\prod^K_{j=1}\phi_{j,v}\right)^{\frac{1}{K}}}\right),</code>
</p>
<p> for
topic <code class="reqn">k</code>, vocabulary word <code class="reqn">v</code> and number of topics <code class="reqn">K</code>.
</p>
<p><code>"FREX"</code> implements the re-ranking method from Bischof and Airoldi
(2012). This method used the weight <code class="reqn">w</code> to balance between
topic-word probability and topic exclusivity using the following
score:
</p>
<p style="text-align: center;"><code class="reqn">\text{FREX}_{k,v}=\left(\frac{w}{\text{ECDF}\left(
  \frac{\phi_{k,v}}{\sum_{j=1}^K\phi_{k,v}}\right)}
  + \frac{1-w}{\text{ECDF}\left(\phi_{k,v}\right)} \right),</code>
</p>
<p> for
topic <code class="reqn">k</code>, vocabulary word <code class="reqn">v</code>, number of topics <code class="reqn">K</code> and
weight <code class="reqn">w</code>, where <code class="reqn">\text{ECDF}</code> is the empirical cumulative
distribution function.
</p>


<h3>Value</h3>

<p>The top words of the topic model. Depending on the output chosen, can
result in either a long-style data.frame, a <code>ggplot2</code> object or a matrix.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>References</h3>

<p>Blei, DM. and Lafferty, JD. (2009). <a href="https://www.taylorfrancis.com/chapters/edit/10.1201/9781420059458-12/topic-models-david-blei-john-la%EF%AC%80erty">Topic models.</a>. In <em>Text Mining</em>,
chapter 4, 101&ndash;124.
</p>
<p>Bischof JM. and Airoldi, EM. (2012). <a href="https://dl.acm.org/doi/10.5555/3042573.3042578">Summarizing Topical Content with Word Frequency and Exclusivity.</a>. In
<em>Proceedings of the 29th International Conference on International
Conference on Machine Learning</em>, ICML'12, 9&ndash;16.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+melt.sentopicmodel">melt.sentopicmodel()</a></code> for extracting estimated mixtures
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- LDA(ECB_press_conferences_tokens)
model &lt;- fit(model, 10)
topWords(model)
topWords(model, output = "matrix")
topWords(model, method = "FREX")
plot_topWords(model)
plot_topWords(model, subset = topic %in% 1:2)

jst &lt;- JST(ECB_press_conferences_tokens)
jst &lt;- fit(jst, 10)
plot_topWords(jst)
plot_topWords(jst, subset = topic %in% 1:2 &amp; sentiment == 3)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
