<!DOCTYPE html><html><head><title>Help for package pairwise</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pairwise}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#pairwise-package'><p>Rasch Model Parameters with pairwise</p></a></li>
<li><a href='#andersentest.pers'><p>Andersen's Likelihood Ratio Test for Object of class &quot;pers&quot;</p></a></li>
<li><a href='#bfi_cov'><p>Covariates to the bfiN Data</p></a></li>
<li><a href='#bfiN'><p>5 polytomous personality items</p></a></li>
<li><a href='#bfiN_miss'><p>5 polytomous personality items</p></a></li>
<li><a href='#catprob'><p>Category Probability Plots</p></a></li>
<li><a href='#cog'><p>Math PISA (2003) data</p></a></li>
<li><a href='#cogBOOKLET'><p>Booklet allocation table for Math PISA (2003) data</p></a></li>
<li><a href='#deltapar'><p>Compute delta parameters from thurstonian thresholds</p></a></li>
<li><a href='#DEU_PISA2012'><p>Data from PISA 2012 - German Sample</p></a></li>
<li><a href='#esc'><p>Expected Score Curves Plots</p></a></li>
<li><a href='#ftab'><p>Tabulating Answer Categories in Data</p></a></li>
<li><a href='#gif'><p>Graphical Item Fit Plots</p></a></li>
<li><a href='#grm'><p>Graphical Model Check</p></a></li>
<li><a href='#iff'><p>Item information function</p></a></li>
<li><a href='#KCT'><p>Knox Cube Test Data from Wright &amp; Stone (1979)</p></a></li>
<li><a href='#kft5'><p>Dichotomous example data in Rost 2004</p></a></li>
<li><a href='#logLik.pers'><p>S3 logLik for Object of class &quot;pers&quot;</p></a></li>
<li><a href='#lrtest.pers'><p>Likelihood Ratio Test for Object of class &quot;pers&quot;</p></a></li>
<li><a href='#make.incidenz'><p>Converting a booklet allocation table into a incidence matrix</p></a></li>
<li><a href='#Neoffi5'><p>Polytomous example data in Rost 2004</p></a></li>
<li><a href='#pair'><p>Item Parameter Calculation</p></a></li>
<li><a href='#pairSE'><p>Item Parameter Calculation with Standard Errors</p></a></li>
<li><a href='#pairwise.item.fit'><p>Item Fit Indices</p></a></li>
<li><a href='#pairwise.person.fit'><p>Person Fit Indices</p></a></li>
<li><a href='#pairwise.S'><p>The Fischer-Scheiblechner Statistic S on item level (Wald like Test)</p></a></li>
<li><a href='#pairwise.SepRel'><p>Person Separation Reliability</p></a></li>
<li><a href='#pers'><p>WLE - Rasch Person Parameter</p></a></li>
<li><a href='#plot.grm'><p>S3 Plotting Graphical Model Check</p></a></li>
<li><a href='#plot.pair'><p>S3 Plotting Thurstonian Thresholds</p></a></li>
<li><a href='#plot.pairSE'><p>S3 Plotting Thustonian Thresholds with SE</p></a></li>
<li><a href='#plot.pers'><p>S3 Plotting Person - Item Map</p></a></li>
<li><a href='#plot.rfa'><p>S3 Plotting Rasch Residual Factor Analysis</p></a></li>
<li><a href='#ptbis'><p>Point Biserial Correlations</p></a></li>
<li><a href='#Q'><p>Person Fit Index Q</p></a></li>
<li><a href='#q3'><p>Q3 Fit Statistic</p></a></li>
<li><a href='#residuals.pers'><p>S3 residuals for Object of class &quot;pers&quot;</p></a></li>
<li><a href='#rfa'><p>Rasch Residual Factor Analysis</p></a></li>
<li><a href='#sim200x3'><p>Simulated Data</p></a></li>
<li><a href='#simra'><p>Simulate Response Pattern under Dichotomous and Polytomous Rasch Model</p></a></li>
<li><a href='#summary.grm'><p>S3 Summary for graphical Model Check</p></a></li>
<li><a href='#summary.pair'><p>S3 Summary for Item Parameter</p></a></li>
<li><a href='#summary.pairS'><p>S3 Summary for S-Statistic Test (Wald Test)</p></a></li>
<li><a href='#summary.pairSE'><p>S3 Summary for Item Parameter with Standard Errors</p></a></li>
<li><a href='#summary.pairwiseSepRel'><p>S3 Summary for Person Separation Reliability</p></a></li>
<li><a href='#summary.pers'><p>S3 Summary for Thetas</p></a></li>
<li><a href='#summary.pifit'><p>S3 Summary for Item-Fit-Statistics</p></a></li>
<li><a href='#summary.ppfit'><p>S3 Summary for Person-Fit-Statistics</p></a></li>
<li><a href='#summary.q3'><p>S3 Summary for Q3 Fit Statistic</p></a></li>
<li><a href='#summary.rfa'><p>S3 Summary for Rasch Factor Analysis</p></a></li>
<li><a href='#tff'><p>Test information function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Joerg-Henrik Heine &lt;jhheine@googlemail.com&gt;</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Joerg-Henrik Heine &lt;jhheine@googlemail.com&gt;</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.1-0</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, methods</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Title:</td>
<td>Rasch Model Parameters by Pairwise Algorithm</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs the explicit calculation
    &ndash; not estimation! &ndash; of the Rasch item parameters for dichotomous and
    polytomous item responses, using a pairwise comparison approach. Person
    parameters (WLE) are calculated according to Warm's weighted likelihood
    approach.</td>
</tr>
<tr>
<td>Suggests:</td>
<td>psych</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-17 20:48:22 UTC; jhh</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-17 21:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='pairwise-package'>Rasch Model Parameters with pairwise</h2><span id='topic+pairwise-package'></span><span id='topic+pairwise'></span>

<h3>Description</h3>

<p>Performs the explicit calculation &ndash; not estimation! &ndash; of the Rasch item parameters for dichotomous and polytomous response formats using a pairwise comparison approach (see Heine &amp; Tarnai, 2015) a procedure that is based on the principle for item calibration introduced by Choppin (1968, 1985). On the basis of the item parameters, person parameters (WLE) are calculated according to Warm's weighted likelihood approach (Warm, 1989). Item- and person fit statistics and several functions for plotting are available.
</p>


<h3>Details</h3>

<p>In case of dichotomous answer formats the item parameter calculation for the Rasch Model (Rasch, 1960), is based on the construction of a pairwise comparison matrix M<em>nij</em> with entries f<em>ij</em> representing the number of respondents who got item <em>i</em> right and item <em>j</em> wrong according to Choppin's (1968, 1985) conditional pairwise algorithm. 
</p>
<p>For the calculation of the item thresholds and difficulty in case of polytomous answer formats, according to the Partial Credit Model (Masters, 1982), a generalization of the pairwise comparison algorithm is used. The construction of the pairwise comparison matrix is therefore extended to the comparison of answer frequencies for each category of each item. In this case, the pairwise comparison matrix M<em>nicjc</em> with entries f<em>icjc</em> represents the number of respondents who answered to item <em>i</em> in category <em>c</em> and to item <em>j</em> in category <em>c-1</em> widening Choppin's (1968, 1985) conditional  pairwise algorithm to polytomous item response formats. 
Within R this algorithm is simply realized by matrix multiplication.
</p>
<p>In general, for both polytomous and dichotomous response formats, the benefit in applying this algorithm lies in it's capability to return stable item parameter 'estimates' even when using data with a relative high amount of missing values, as long as the items are still proper linked together.
</p>
<p>The recent version of the package 'pairwise' computes item parameters for dichotomous and polytomous item responses  &ndash; and a mixture of both &ndash; according the partial credit model using the function <code><a href="#topic+pair">pair</a></code>.   
</p>
<p>Based on the explicit calculated item parameters for a dataset, the person parameters may thereupon be estimated using any estimation approach. The function <code><a href="#topic+pers">pers</a></code> implemented in the package uses Warm's weighted likelihood approach (WLE) for estimation of the person parameters (Warm, 1989). When assessing person characteristics (abilities) using (rotated) booklet designs an 'incidence' matrix should be used, giving the information if the respective item was in the booklet (coded 1) given to the person or not (coded 0). Such a matrix can be constructed (out of a booklet allocation table) using the function <code><a href="#topic+make.incidenz">make.incidenz</a></code>.
</p>
<p>Item- and person fit statistics, see functions <code><a href="#topic+pairwise.item.fit">pairwise.item.fit</a></code> and <code><a href="#topic+pairwise.person.fit">pairwise.person.fit</a></code> respectively, are calculated based on the squared and standardized residuals of observed and the expected person-item matrix. The implemented procedures for calculating the fit indices are based on the formulas given in Wright &amp; Masters, (1982, p. 100), with further clarification given at <code>http://www.rasch.org/rmt/rmt34e.htm</code>. 
</p>
<p>Further investigation of item fit can be done by using the function <code><a href="#topic+ptbis">ptbis</a></code> for point biserial correlations. For a graphical representation of the item fit, the function <code><a href="#topic+gif">gif</a></code> for plotting empirical and model derived category probability curves, or the function <code><a href="#topic+esc">esc</a></code> for plotting expected (and empirical) score curves, can be used.
</p>
<p>The function <code><a href="#topic+iff">iff</a></code> plots or returns values of the item information function and the function <code><a href="#topic+tff">tff</a></code> plots or returns values of the test information function.
</p>
<p>To detect multidimensionality within a set of Items a rasch residual factor analysis proposed by Wright (1996) and further discussed by Linacre (1998) can be performed using the function <code><a href="#topic+rfa">rfa</a></code>. 
</p>
<p>For a 'heuristic' model check the function <code><a href="#topic+grm">grm</a></code> makes the basic calculations for the graphical model check for dicho- or polytomous item response formats. The corresponding S3 plotting method is <code><a href="#topic+plot.grm">plot.grm</a></code>.
</p>


<h3>Author(s)</h3>

<p>Joerg-Henrik Heine &lt;jhheine@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Choppin, B. (1968). Item Bank using Samplefree Calibration. <em>Nature, 219</em>(5156), 870-872.
</p>
<p>Choppin, B. (1985). A fully conditional estimation procedure for Rasch model parameters. <em>Evaluation in Education, 9</em>(1), 29-42.
</p>
<p>Heine, J. H. &amp; Tarnai, Ch. (2015). Pairwise Rasch model item parameter recovery under sparse data conditions. <em>Psychological Test and Assessment Modeling, 57</em>(1), 3–36.
</p>
<p>Heine, J. H. &amp; Tarnai, Ch. (2011). Item-Parameter Bestimmung im Rasch-Modell bei unterschiedlichen Datenausfallmechanismen. <em>Referat im 17. Workshop 'Angewandte Klassifikationsanalyse'</em> [Item parameter determination in the Rasch model for different missing data mechanisms. Talk at 17. workshop 'Applied classification analysis'], Landhaus Rothenberge, Muenster, Germany 09.-11.11.2011
</p>
<p>Heine, J. H., Tarnai, Ch. &amp; Hartmann, F. G. (2011). Eine Methode zur Parameterbestimmung im Rasch-Modell bei fehlenden Werten. <em>Vortrag auf der 10. Tagung der Fachgruppe Methoden &amp; Evaluation der DGPs.</em> [A method for parameter estimation in the Rasch model for missing values. Paper presented at the 10th Meeting of the Section Methods &amp; Evaluation of DGPs.] Bamberg, Germany, 21.09.2011 - 23.09. 2011.
</p>
<p>Heine, J. H., &amp; Tarnai, Ch. (2013). Die Pairwise-Methode zur Parameterschätzung im ordinalen Rasch-Modell. <em>Vortrag auf der 11. Tagung der Fachgruppe Methoden &amp; Evaluation der DGPs.</em> [The pairwise method for parameter estimation in the ordinal Rasch model. Paper presented at the 11th Meeting of the Section Methods &amp; Evaluation of DGPs.] Klagenfurt, Austria, 19.09.2013 -  21.09. 2013.
</p>
<p>Linacre, J. M. (1998). Detecting multidimensionality: which residual data-type works best? <em>Journal of outcome measurement, 2</em>, 266–283.
</p>
<p>Masters, G. N. (1982). A Rasch model for partial credit scoring. <em>Psychometrika, 47</em>(2), 149-174.
</p>
<p>Rasch, G. (1960). <em>Probabilistic models for some intelligence and attainment tests.</em> Copenhagen: Danmarks pædagogiske Institut.
</p>
<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory. <em>Psychometrika, 54</em>(3), 427–450.
</p>
<p>Wright, B. D., &amp; Masters, G. N. (1982). <em>Rating Scale Analysis.</em> Chicago: MESA Press.
</p>
<p>Wright, B. D. (1996). Comparing Rasch measurement and factor analysis. <em>Structural Equation Modeling: A Multidisciplinary Journal, 3</em>(1), 3–24.
</p>

<hr>
<h2 id='andersentest.pers'>Andersen's Likelihood Ratio Test for Object of class &quot;pers&quot;</h2><span id='topic+andersentest.pers'></span>

<h3>Description</h3>

<p>The Andersen likelihood ratio test is based on splitting the dataset into subgroups of persons. One can argue that it is a significance testable version of the more descriptive graphical model check - see <code><a href="#topic+grm">grm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>andersentest.pers(
  pers_obj,
  split = "median",
  splitseed = "no",
  pot = NULL,
  zerocor = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="andersentest.pers_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class<code>"pers"</code> - see function <code><a href="#topic+pers">pers</a></code>.</p>
</td></tr>
<tr><td><code id="andersentest.pers_+3A_split">split</code></td>
<td>
<p>Specifies the splitting criterion. Basically there are three different options available - each with several modes - which are controlled by passing the corresponding character expression to the argument. 
</p>
<p>1) Using the rawscore for splitting into subsamples with the following modes: <code>split = "median"</code> median raw score split - high score group and low score group; <code>split = "mean"</code> mean raw score split - high score group and low score group.
Finaly <code>split = "score"</code> that is splitting <code>daten</code> into as many subsamples as there are raw score groups - discarding min and max (theoretical) score group - which matches the concept proposed by Andersen (1973).
</p>
<p>2) Dividing the persons in <code>daten</code> into subsamples with equal size by random allocation with the following modes: <code>split = "random"</code> (which is equivalent to <code>split = "random.2"</code>) divides persons into two subsamples with equal size. In general the number of desired subsamples must be expressed after the dot in the character expression - e.g. <code>split = "random.6"</code> divides persons into 6 subsamples (with equal size) by random allocation etc. 
</p>
<p>3) The third option is using a manifest variable as a splitting criterion. In this case a vector with the same length as number of cases in <code>daten</code> must be passed to the argument grouping the data into subsamples. This vector should be coded as <code>"factor"</code> or a <code>"numeric"</code> integer vector with min = 1.</p>
</td></tr>
<tr><td><code id="andersentest.pers_+3A_splitseed">splitseed</code></td>
<td>
<p>numeric, used for <code>set.seed(splitseed)</code> for random splitting - see argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="andersentest.pers_+3A_pot">pot</code></td>
<td>
<p>optional argument, at default (<code>pot=NULL</code>) setting is read from <code>pers_obj</code> - see description for <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="andersentest.pers_+3A_zerocor">zerocor</code></td>
<td>
<p>optional argument, at default (<code>zerocor=NULL</code>) setting is read from <code>pers_obj</code> - see description for <code><a href="#topic+pair">pair</a></code>.
</p>
<p>pot=pers_obj$pair$fuargs$pot, zerocor=pers_obj$pair$fuargs$zerocor</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Andersen (1973) proposed to split the dataset by [raw] score groups, which can be achieved setting the argument <code>split = "score"</code>. However as pointed out by Rost (2004) there might be several different splitting criteria for testing subsample invariance of the raschmodel. Thus the argument <code>split</code> provides some other options for splitting the data - see description of arguments.
</p>


<h3>Value</h3>

<p>A (list) object of class <code>"andersentest.pers"</code> ...
</p>


<h3>References</h3>

<p>Andersen, E. B. (1973). A goodness of fit test for the rasch model. <em>Psychometrika, 38</em>(1), 123–140.
</p>
<p>Rost, J. (2004). <em>Lehrbuch Testtheorie - Testkonstruktion</em> (2 nd Ed.) Huber: Bern.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(bfiN) # loading example data set
data(bfi_cov) # loading covariates to bfiN data set
model &lt;- pers(pair(bfiN,m=6))
andersentest.pers(model, split = bfi_cov$gender)
andersentest.pers(model, split = "random")
andersentest.pers(model, split = "median")
### unsing simulated data:
data("sim200x3")
model2 &lt;- pers(pair(sim200x3))
andersentest.pers(model2, split = "median")

## End(Not run)
</code></pre>

<hr>
<h2 id='bfi_cov'>Covariates to the bfiN Data
</h2><span id='topic+bfi_cov'></span>

<h3>Description</h3>

<p>Covaraites to the data from 2800 subjects answering to 5 neuroticism items of the bfi dataset originally included in the R-package <code>{psych}</code> - see <a href="https://cran.r-project.org/package=psych">https://cran.r-project.org/package=psych</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(bfi_cov)
</code></pre>


<h3>Format</h3>

<p>A <code>"data.frame"</code> containing 3 variables (gender, education, and age) for 2800 obsevations.
</p>


<h3>Details</h3>

<p>The covariates are in the same row (person) order as the responses to the 5 neuroticism items in the seperate datasets <code><a href="#topic+bfiN">bfiN</a></code> and <code><a href="#topic+bfiN_miss">bfiN_miss</a></code>.
The coding is as follows:
</p>

<dl>
<dt><code>gender</code></dt><dd><p>Males = 1, Females =2</p>
</dd>
<dt><code>education</code></dt><dd><p>1 = HS, 2 = finished HS, 3 = some college, 4 = college graduate 5 = graduate degree</p>
</dd>
<dt><code>age</code></dt><dd><p>age in years</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://cran.r-project.org/package=psych">https://cran.r-project.org/package=psych</a>
</p>


<h3>References</h3>

<p>Revelle, William (2015), psych: Procedures for Psychological, Psychometric, and Personality Research.<em>R package version 1.5.1</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bfi_cov)
dim(bfi_cov)
##############################################################
names(bfi_cov) # show all variable names of data
</code></pre>

<hr>
<h2 id='bfiN'>5 polytomous personality items
</h2><span id='topic+bfiN'></span>

<h3>Description</h3>

<p>Data from 2800 subjects answering to 5 neuroticism items with 6 answer categories (0-5) of the <code>bfi</code> dataset originally included in the R-package <code>{psych}</code> - see <a href="https://cran.r-project.org/package=psych">https://cran.r-project.org/package=psych</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(bfiN)
</code></pre>


<h3>Format</h3>

<p>A <code>"data.frame"</code> containing 5 variables and 2800 obsevations.
</p>


<h3>Details</h3>

<p>The other variables from the original <code>bfi</code> dataset were skipped and the categories are 'downcoded' to '0,1,2,3,4,5' to have a simple, ready to use example data frame. For further Information on the original dataset see R-package <code>{psych}</code>. 
</p>
<p>The category meanings (after downcoding) are as follows:
</p>

<dl>
<dt><code>score 0</code></dt><dd><p>Very Inaccurate</p>
</dd>
<dt><code>score 1</code></dt><dd><p>Moderately Inaccurate</p>
</dd>
<dt><code>score 2</code></dt><dd><p>Slightly Inaccurate</p>
</dd>
<dt><code>score 3</code></dt><dd><p>Slightly Accurate</p>
</dd>
<dt><code>score 4</code></dt><dd><p>Moderately Accurate</p>
</dd>
<dt><code>score 5</code></dt><dd><p>Very Accurate</p>
</dd>
</dl>

<p>The Item meanings are as follows:
</p>

<dl>
<dt><code>N1</code></dt><dd><p>Get angry easily.</p>
</dd>
<dt><code>N2</code></dt><dd><p>Get irritated easily.</p>
</dd>
<dt><code>N3</code></dt><dd><p>Have frequent mood swings.</p>
</dd>
<dt><code>N4</code></dt><dd><p>Often feel blue.</p>
</dd>
<dt><code>N5</code></dt><dd><p>Panic easily.</p>
</dd>
</dl>

<p>The covariates like gender, education and age are in a seperate dataset <code>cov_bfi</code>
</p>


<h3>Source</h3>

<p><a href="https://cran.r-project.org/package=psych">https://cran.r-project.org/package=psych</a>
</p>


<h3>References</h3>

<p>Revelle, William (2015), psych: Procedures for Psychological, Psychometric, and Personality Research.<em>R package version 1.5.1</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bfiN)
dim(bfiN)
##############################################################
names(bfiN) # show all variable names of data.frame bfiN
range(bfiN,na.rm=TRUE) # checking the valid response range

</code></pre>

<hr>
<h2 id='bfiN_miss'>5 polytomous personality items
</h2><span id='topic+bfiN_miss'></span>

<h3>Description</h3>

<p>Data from 2800 subjects answering to 5 neuroticism items with 6 answer categories (0-5) of the bfi dataset originally included in the R-package <code>{psych}</code> with artificial missing data (see details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(bfiN_miss)
</code></pre>


<h3>Format</h3>

<p>A <code>"data.frame"</code> containing 5 variables and 2800 obsevations.
</p>


<h3>Details</h3>

<p>This dataset is the same like the dataset <code>{bfiN}</code> included in this package, exept for the amount of missing data, which were additional created in that way, having aprox. 15% missing for each of the 5 variables by random.
</p>
<p>The other variables from the original bfi dataset were skipped and the categories are 'downcoded' to '0,1,2,3,4,5' to have a simple, ready to use example data frame. For further Information on the original dataset see R-package <code>{psych}</code>. 
The covariates like gender, education and age are in a seperate dataset <code>cov_bfi</code>
</p>


<h3>Source</h3>

<p><a href="https://cran.r-project.org/package=psych">https://cran.r-project.org/package=psych</a>
</p>


<h3>References</h3>

<p>Revelle, William (2015), psych: Procedures for Psychological, Psychometric, and Personality Research.<em>R package version 1.5.1</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bfiN_miss)
dim(bfiN_miss)
##############################################################
names(bfiN_miss) # show all variable names of data.frame bfiN_miss
range(bfiN_miss,na.rm=TRUE) # checking the valid response range
colSums(is.na(bfiN_miss))/dim(bfiN_miss)[1] # percentage of missing per variable
</code></pre>

<hr>
<h2 id='catprob'>Category Probability Plots</h2><span id='topic+catprob'></span>

<h3>Description</h3>

<p>plotting function for plotting category probability curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catprob(pair_obj, itemnumber = 1, ra = 4, plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="catprob_+3A_pair_obj">pair_obj</code></td>
<td>
<p>an object of class <code>"pair"</code> as a result from function <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="catprob_+3A_itemnumber">itemnumber</code></td>
<td>
<p>an integer, defining the number of the item to plot the respective category probability for. This is set to an arbitrary default value of <code>itemnumber = 1</code> to avoid error messages when you forget to choose an item to plot the expected score curves for.</p>
</td></tr>
<tr><td><code id="catprob_+3A_ra">ra</code></td>
<td>
<p>an integer, defining the (logit) range for x-axis</p>
</td></tr>
<tr><td><code id="catprob_+3A_plot">plot</code></td>
<td>
<p>a logical (default <code>plot = TRUE</code>), defining wether to supress plotting an just return a matrix of category probabilities</p>
</td></tr>
<tr><td><code id="catprob_+3A_...">...</code></td>
<td>
<p>arguments passed to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no details in the moment.
</p>


<h3>Value</h3>

<p>a plot or a matrix with category probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
data(sim200x3)
result &lt;- pair(sim200x3)
catprob(pair_obj = result, itemnumber = 2 )
data(bfiN)
result &lt;- pair(bfiN)
catprob(pair_obj = result, itemnumber = 3 )
</code></pre>

<hr>
<h2 id='cog'>Math PISA (2003) data
</h2><span id='topic+cog'></span>

<h3>Description</h3>

<p>Data from the german sample of the PISA 2003 survey, containing 31 dichotomous items from the math task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(cog)
</code></pre>


<h3>Format</h3>

<p>A data frame containing 34 variables and 4660 obsevations.
</p>


<h3>Details</h3>

<p>The first 3 variables are ID variables. For further Information on variables and their meaning see the codebook PDF file 
available at <code style="white-space: pre;">&#8288;https://www.oecd.org/pisa/pisaproducts/PISA12_cogn_codebook.pdf&#8288;</code>
</p>


<h3>References</h3>

<p>Database - PISA 2003, <em>Downloadable Data</em>, <code style="white-space: pre;">&#8288;https://www.oecd.org/pisa/data/pisa2012database-downloadabledata.htm&#8288;</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cog)
dim(cog)
##############################################################
names(cog) # show all variable names of data.frame cog
names(cog[,4:34]) # show the variable names of the math items
names(cog[,1:3]) # show the variable names of the ID variables

</code></pre>

<hr>
<h2 id='cogBOOKLET'>Booklet allocation table for Math PISA (2003) data
</h2><span id='topic+cogBOOKLET'></span>

<h3>Description</h3>

<p>a <code>data.frame</code> containing a booklet allocation table for the cognitive Data <code><a href="#topic+cog">cog</a></code> in this package, which holds 31 dichotomous items from the math task from the german sample of the PISA 2003 survey.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(cogBOOKLET)
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> containing 31 rows.
</p>


<h3>Details</h3>

<p>For further Information on variables and their meaning see the codebook PDF file 
available at <code style="white-space: pre;">&#8288;https://www.oecd.org/pisa/pisaproducts/PISA12_cogn_codebook.pdf&#8288;</code>
</p>


<h3>References</h3>

<p>Database - PISA 2003, <em>Downloadable Data</em>, <code style="white-space: pre;">&#8288;https://www.oecd.org/pisa/data/pisa2012database-downloadabledata.htm&#8288;</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cogBOOKLET)
cogBOOKLET
</code></pre>

<hr>
<h2 id='deltapar'>Compute delta parameters from thurstonian thresholds</h2><span id='topic+deltapar'></span>

<h3>Description</h3>

<p>Calculation of delta parameters or rather item step parameters from thurstonian threshold parameters returned by the function <code><a href="#topic+pair">pair</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deltapar(object, sigma = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deltapar_+3A_object">object</code></td>
<td>
<p>an object of class <code>"pair"</code> as resulting from item parameter calculation using the function <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="deltapar_+3A_sigma">sigma</code></td>
<td>
<p>a logical whether to return item difficulties (sigma) or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;Thurstone threshold&quot; or rather thurstonian threshold for a category corresponds to a point on the latent variable at which the probability of being observed in that category or above equals that of being observed in the categories below. Thus these thurstonian threshold parameters can be interpreted in an strait forward and easy way. However, some other computer programs related to Rasch analysis don't return thurstonian threshold parameters from their estimation procedure, but rather so called delta parameters for the item steps. The later are also known as &quot;step measures&quot;, &quot;step calibrations&quot;, &quot;step difficulties&quot;, &quot;tau parameters&quot;, and &quot;Rasch-Andrich thresholds&quot;. For a better comparability between different Rasch software and estimation procedures the thurstonian threshold parameters can be converted into delta or rather items step parameters.
</p>


<h3>Value</h3>

<p>If <code>sigma=TRUE</code> an object of class <code>c("data.frame", "deltapar")</code> containing delta parameters for items and their difficultie (first column). Otherwise a matrix containing only the delta parameters.
</p>


<h3>References</h3>

<p>Linacre J.M. (1992). Rasch-Andrich Thresholds and Rasch-Thurstone Thresholds. <em>Rasch Measurement Transactions</em>, 5:4, 191. https://www.rasch.org/rmt/rmt54r.htm
</p>
<p>Linacre J.M. (2001). Category, Step and Threshold: Definitions &amp; Disordering. <em>Rasch Measurement Transactions</em>, 15:1, 794. https://www.rasch.org/rmt/rmt151g.htm
</p>
<p>Adams, R. J., Wu, M. L., &amp; Wilson, M. (2012). The Rasch Rating Model and the Disordered Threshold Controversy. <em>Educational and Psychological Measurement, 72</em>(4), 547–573. https://doi.org/10.1177/0013164411432166
</p>
<p>Linacre J.M. (2006). Item Discrimination and Rasch-Andrich Thresholds. <em>Rasch Measurement Transactions</em>, 20:1, 1054. https://www.rasch.org/rmt/rmt201k.htm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######################
data(sim200x3) # loading reponse data
ip &lt;- pair(sim200x3,m = c(2,3,3)) # compute item parameters
summary(ip) # have a look at the results (thurstonian thresholds)
deltapar(ip) # compute delta parameters from these 
</code></pre>

<hr>
<h2 id='DEU_PISA2012'>Data from PISA 2012 - German Sample 
</h2><span id='topic+DEU_PISA2012'></span>

<h3>Description</h3>

<p>Selectetd data for 5001 'subjects' who participated in the PISA 2012 survey.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(DEU_PISA2012)
</code></pre>


<h3>Format</h3>

<p>A list containing ... .
</p>


<h3>Details</h3>

<p>The data is based on freely down loadable data on the official OECD page - see source. The general structure of the data in list format, is described in an PDF document available in the User guides, package vignettes and other documentation section. 
</p>


<h3>References</h3>

<p>Database - PISA 2003, <em>Downloadable Data</em>, <code style="white-space: pre;">&#8288;https://www.oecd.org/pisa/data/pisa2012database-downloadabledata.htm&#8288;</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################################################
data(DEU_PISA2012)
str(DEU_PISA2012)
</code></pre>

<hr>
<h2 id='esc'>Expected Score Curves Plots</h2><span id='topic+esc'></span>

<h3>Description</h3>

<p>plotting function for plotting expected score curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>esc(pers_obj, itemnumber = 1, integ = 6, ra = 4, nodes = 100, lwd = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="esc_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class <code>"pers"</code> as a result from function <code><a href="#topic+pers">pers</a></code>.</p>
</td></tr>
<tr><td><code id="esc_+3A_itemnumber">itemnumber</code></td>
<td>
<p>an integer, defining the number of the item to plot the respective categoy probability for. This is set to an arbitrary default value of <code>itemnumber = 1</code> to avoid error messages when you forget to choose an item to plot the expected score curves for.</p>
</td></tr>
<tr><td><code id="esc_+3A_integ">integ</code></td>
<td>
<p>either an integer defining the number of (ability) groups to integrate the empirical theta vector or the character expression <code>"all"</code> to plot the empirical theta distribution at the respective item score using symbols (see example).</p>
</td></tr>
<tr><td><code id="esc_+3A_ra">ra</code></td>
<td>
<p>an integer, defining the (logit) range for x-axis</p>
</td></tr>
<tr><td><code id="esc_+3A_nodes">nodes</code></td>
<td>
<p>numer of integration nodes</p>
</td></tr>
<tr><td><code id="esc_+3A_lwd">lwd</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="esc_+3A_...">...</code></td>
<td>
<p>arguments passed to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no details in the moment.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
data(bfiN)
result &lt;- pers(pair(bfiN))
esc(pers_obj=result,1,lwd=2) # plot for first item
esc(pers_obj=result,2,lwd=2) # plot for second item
for(i in 1:5){esc(pers_obj=result,i,lwd=2)}
#########
esc(pers_obj=result,2,integ="all",lwd=2) # plot for secod item

</code></pre>

<hr>
<h2 id='ftab'>Tabulating Answer Categories in Data</h2><span id='topic+ftab'></span>

<h3>Description</h3>

<p>function tabulating (answer) categories in <code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ftab(X, catgories = NULL, na.omit = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ftab_+3A_x">X</code></td>
<td>
<p>Data as a <code>"matrix"</code>, a <code>"data.frame"</code> or even a <code>"vector"</code> or <code>"factor"</code>. <code>"vector"</code> or <code>"factor"</code> are coerced to a <code>"data.frame"</code> with one column.</p>
</td></tr>
<tr><td><code id="ftab_+3A_catgories">catgories</code></td>
<td>
<p>optional a vector (<code>"numeric"</code> or <code>"character"</code>) containig the categories to tabulate. At default (<code>catgories=NULL</code>) the fuction looks for unique categories in <code>X</code>.</p>
</td></tr>
<tr><td><code id="ftab_+3A_na.omit">na.omit</code></td>
<td>
<p>logical (default: <code>na.omit=FALSE</code> ) wether to return frequencies for missing values, <code>NA</code>s.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>X</code> can either be a (<code>"numeric"</code> or <code>"character"</code>) <code>"matrix"</code> containing response vectors of persons (rows) or a <code>"data.frame"</code> containing <code>"numeric"</code>, <code>"character"</code> or <code>"factor"</code> variables (columns).
</p>


<h3>Value</h3>

<p>a <code>"matrix"</code> with category frequencies
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
data(bfiN)
ftab(bfiN)
data(sim200x3)
ftab(sim200x3)
</code></pre>

<hr>
<h2 id='gif'>Graphical Item Fit Plots</h2><span id='topic+gif'></span>

<h3>Description</h3>

<p>plotting function for plotting empirical and model derived category probability curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gif(pers_obj, itemnumber = 1, ra = 4, integ = "raw", kat = "all", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gif_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class <code>"pers"</code> as a result from function <code><a href="#topic+pers">pers</a></code>.</p>
</td></tr>
<tr><td><code id="gif_+3A_itemnumber">itemnumber</code></td>
<td>
<p>an integer, defining the number of the item to plot the respective categoy probability for. This is set to an arbitrary default value of <code>itemnumber = 1</code> to avoid error messages when you forget to choose an item to plot the expected score curves for.</p>
</td></tr>
<tr><td><code id="gif_+3A_ra">ra</code></td>
<td>
<p>an integer, defining the (logit) range for x-axis</p>
</td></tr>
<tr><td><code id="gif_+3A_integ">integ</code></td>
<td>
<p>either an integer, defining the number of integration points along the (logit) range on the x-axis to integrate the empirical theta values, or the character expression <code>"raw"</code> (default) which will use the rawscore groups as integration points.</p>
</td></tr>
<tr><td><code id="gif_+3A_kat">kat</code></td>
<td>
<p>either an integer, defining for which category the empirical category probabilities should be plotted over the model derived category probability curves, or the character expression <code>"all"</code> (default) which will plot the empirical category probabilities for all categories.</p>
</td></tr>
<tr><td><code id="gif_+3A_...">...</code></td>
<td>
<p>arguments passed to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no details in the moment.
</p>


<h3>Value</h3>

<p>a plot with category probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
data(bfiN)
pers_obj &lt;- pers(pair(bfiN))
#### plot empirical category probabilities
gif(pers_obj = pers_obj, itemnumber = 1 )
gif(pers_obj = pers_obj, itemnumber = 1 , integ=8) # integration over 8 points
gif(pers_obj = pers_obj, itemnumber = 1 , integ=8, kat=1) # only for category number 1
</code></pre>

<hr>
<h2 id='grm'>Graphical Model Check</h2><span id='topic+grm'></span>

<h3>Description</h3>

<p>This function makes the basic calculations for the graphical model check for dicho- or polytomous item response formats. It is more or less a wraper function, internaly calling the function <code><a href="#topic+pairSE">pairSE</a></code>. Several splitting options are available (see arguments).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grm(
  daten,
  m = NULL,
  w = NULL,
  split = "random",
  splitseed = "no",
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grm_+3A_daten">daten</code></td>
<td>
<p>a data.frame or matrix with optionaly named colums (names of items), potentially with missing values, comprising polytomous or dichotomous (or mixed category numbers) responses of <code>n</code> respondents (rows) on <code>k</code> items (colums) coded starting with 0 for lowest category to <em>m</em>-1 for highest category, with <em>m</em> beeing a vector (with length k) with the number of categories for the respective item.</p>
</td></tr>
<tr><td><code id="grm_+3A_m">m</code></td>
<td>
<p>an integer (will be recycled to a vector of length k) or a vector giving the number of response categories for all items - by default <code>m = NULL</code>, <code>m</code> is calculated from data, assuming that every response category is at least once present in data. For sparse data it is strongly recomended to explicitly define the number of categories by defining this argument.</p>
</td></tr>
<tr><td><code id="grm_+3A_w">w</code></td>
<td>
<p>an optional vector of case weights.</p>
</td></tr>
<tr><td><code id="grm_+3A_split">split</code></td>
<td>
<p>Specifies the splitting criterion. Basically there are three different options available - each with several modes - which are controlled by passing the corresponding character expression to the argument. 
</p>
<p>1) Using the rawscore for splitting into subsamples with the following modes: <code>split = "median"</code> median raw score split - high score group and low score group; <code>split = "mean"</code> mean raw score split - high score group and low score group.
</p>
<p>2) Dividing the persons in <code>daten</code> into subsamples with equal size by random allocation with the following modes: <code>split = "random"</code> (which is equivalent to <code>split = "random.2"</code>) divides persons into two subsamples with equal size. In general the number of desired subsamples must be expressed after the dot in the character expression - e.g. <code>split = "random.6"</code> divides persons into 6 subsamples (with equal size) by random allocation etc. 
</p>
<p>3) The third option is using a manifest variable as a splitting criterion. In this case a vector with the same length as number of cases in <code>daten</code> must be passed to the argument grouping the data into subsamples. This vector should be coded as <code>"factor"</code> or a <code>"numeric"</code> integer vector with min = 1.</p>
</td></tr>
<tr><td><code id="grm_+3A_splitseed">splitseed</code></td>
<td>
<p>numeric, used for <code>set.seed(splitseed)</code> for random splitting - see argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="grm_+3A_verbose">verbose</code></td>
<td>
<p>logical, if <code>verbose = TRUE</code> (default) a message about subsampling is sent to console when calculating standard errors.</p>
</td></tr>
<tr><td><code id="grm_+3A_...">...</code></td>
<td>
<p>additional arguments <code>nsample</code>, <code>size</code>, <code>seed</code>, <code>pot</code> for caling <code><a href="#topic+pairSE">pairSE</a></code> are passed through - see description for <code><a href="#topic+pairSE">pairSE</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data is splitted in two or more subsamples and then item thresholds, the parameter (Sigma) and their standard errors (SE) for the items according the PCM  are calculated for each subsample. Additional arguments (see description of function <code><a href="#topic+pairSE">pairSE</a></code>) for parameter calculation are passed through. 
</p>
<p>WARNING: When using data based on booklet designs with systematically missing values (by design) you have to ensure that in each of the booklet the maximum raw value to reach is equal while using the raw value as splitting criterion.
</p>


<h3>Value</h3>

<p>A (list) object of class <code>c("grm","list")</code> containing the item difficulty parameter sigma and their standard errors for two or more subsamples.
</p>


<h3>A note on standard errors</h3>

<p>Estimation of standard errors is done by repeated calculation of item parameters for subsamples of the given data. This procedure is mainly controlled by the arguments <code>nsample</code> and <code>size</code> (see arguments). With regard to calculation time, the argument <code>nsample</code> is the 'time killer'. On the other hand, things (estimation of standard errors) will not necessarily get better when choosing large values for <code>nsample</code>. For example choosing <code>nsample=400</code> will only result in minimal change for standard error estimation in comparison to (<code>nsample=30</code>) which is the default setting (see examples).
</p>


<h3>References</h3>

<p>description of function <code><a href="#topic+pairSE">pairSE</a></code><code>{pairwise}</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bfiN) # loading example data set

data(bfi_cov) # loading covariates to bfiN data set

# calculating itemparameters and SE for two random allocated subsamples
grm_gen &lt;- grm(daten=bfiN, split = bfi_cov$gender)
summary(grm_gen)
#### plot(grm_gen)

grm_med &lt;- grm(daten=bfiN, split = "median")
summary(grm_med)
#### plot(grm_med)

grm_ran&lt;-grm(daten=bfiN, split = "random") 

summary(grm_ran)

# some examples for plotting options
# plotting item difficulties for two subsamples against each other 
# with elipses for a CI = 95% .
#### plot(grm_ran) 

# using triangles as plotting pattern
#### plot(grm_ran,pch=2) 

#plotting without CI ellipses
#### plot(grm_ran,ci=0,pch=2) 

# plotting with item names
#### plot(grm_ran,itemNames=TRUE) 

# Changing the size of the item names
#### plot(grm_ran,itemNames=TRUE, cex.names = 1.3)

# Changing the color of the CI ellipses
plot(grm_ran,itemNames=TRUE, cex.names = .8, col.error="green")

###### example from details section 'Some Notes on Standard Errors' ########
## Not run: 
grm_def&lt;-grm(daten=bfiN, split = "random",splitseed=13)
plot(grm_def)
######
grm_400&lt;-grm(daten=bfiN, split = "random", splitseed=13 ,nsample=400)
plot(grm_400)

## End(Not run) 


</code></pre>

<hr>
<h2 id='iff'>Item information function</h2><span id='topic+iff'></span>

<h3>Description</h3>

<p>plotting function for plotting the Item information function(IIF).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iff(
  pair_obj,
  itemnumber = 1,
  x = NULL,
  plot = TRUE,
  cat = FALSE,
  lwd = 2,
  col = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iff_+3A_pair_obj">pair_obj</code></td>
<td>
<p>an object of class <code>"pair"</code> as a result from function <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="iff_+3A_itemnumber">itemnumber</code></td>
<td>
<p>an integer, defining the number of the item to plot the respective item information function for. This is set to an arbitrary default value of <code>itemnumber = 1</code> to avoid error messages when you forget to choose an item to plot the item information function for.</p>
</td></tr>
<tr><td><code id="iff_+3A_x">x</code></td>
<td>
<p>The value(s) of the latent variable, at which the IIF will be evaluated. <code>x</code> should be either a numeric vector of theta values or a single numeric value. If <code>x</code> is given as a single numeric value plotting is supressed. If not given (default), 99 values spaced evenly between -4 and +4 will be used, handy for plotting.</p>
</td></tr>
<tr><td><code id="iff_+3A_plot">plot</code></td>
<td>
<p>a logical (default <code>plot = TRUE</code>), defining wether to supress plotting an just return a matrix of the values of the Item information function.</p>
</td></tr>
<tr><td><code id="iff_+3A_cat">cat</code></td>
<td>
<p>a logical (default <code>cat = FALSE</code>), defining wether to plot or return the values of the Item information function based on item categories.</p>
</td></tr>
<tr><td><code id="iff_+3A_lwd">lwd</code></td>
<td>
<p>see parameters for <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="iff_+3A_col">col</code></td>
<td>
<p>see parameters for <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="iff_+3A_...">...</code></td>
<td>
<p>arguments passed to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no details in the moment.
</p>


<h3>Value</h3>

<p>a plot, a matrix or a single numeric with values of the Item information function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
data(sim200x3)
result &lt;- pair(sim200x3)
# IFF plot for Item No. 2 
iff(pair_obj = result, itemnumber = 2 ) 
# IFF plot for Categories of Item No. 2
iff(pair_obj = result, itemnumber = 2 ,cat=TRUE)
# IFF at theta=0 for Item No. 2 
iff(pair_obj = result, itemnumber = 2 ,x=0) 
# IFF at theta=0 for Categories of Item No. 2
iff(pair_obj = result, itemnumber = 2 ,x=0,cat=TRUE)
# IFF of Item No. 2 for a given range of thetas 
iff(pair_obj = result, itemnumber = 2 ,x=seq(0,4,.1)) 
# ... etc.
iff(pair_obj = result, itemnumber = 2 ,x=seq(0,4,.1),cat=TRUE) 
##### examples with other data ...
data(bfiN)
result &lt;- pair(bfiN)
iff(pair_obj = result, itemnumber = 3 )
iff(pair_obj = result, itemnumber = 3 ,cat=TRUE)
</code></pre>

<hr>
<h2 id='KCT'>Knox Cube Test Data from Wright &amp; Stone (1979)
</h2><span id='topic+KCT'></span>

<h3>Description</h3>

<p>Data from the Book 'Best Test Design' from Wright &amp; Stone (1979, p. 31, table 2.3.1) comprising responses from 35 subjects scored in 18 dichotomous items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(KCT)
</code></pre>


<h3>Format</h3>

<p>A <code>"data.frame"</code> containing 18 numeric variables (coded 0,1) and 35 obsevations.
</p>


<h3>Details</h3>

<p>The so called 'Knox Cube Test' was initially developed as a cube imitation test around 1913 by Howard A. Knox as a nonverbal test of intelligence to screen and identify potential immigrants with mental deficits at the Ellis Island immigration station in New York Harbor &ndash; see Richardson (2005) for a historical review. 
</p>
<p>Quoted from Wright &amp; Stone (1979):
</p>
<p>&quot;<em>Success on this subtest requires the application of visual attention and short-term memory to a simple sequencing task. It appears to be free from school-related tasks and hence to be an indicator of nonverbal intellectual capacity.</em>&quot; (Wright &amp; Stone 1979, p. 28).
</p>


<h3>References</h3>

<p>Wright, B. D. &amp; Stone, M. H. (1979). <em>Best Test Design: Rasch Measurement</em>. Chicago: MESA Press.
</p>
<p>Richardson, J. T. E. (2005). Knox’s cube imitation test: A historical review and an experimental analysis. <em>Brain and Cognition, 59</em>(2), 183–213. https://doi.org/10.1016/j.bandc.2005.06.001
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(KCT)
dim(KCT)
############# some item calibrations ###############
data(KCT)
IP_pair &lt;- pair(daten = KCT[,4:17], m = 2)
summary(IP_pair)
####################################################
####################################################
#########MIKE error message never received##########
####################################################
####################################################
</code></pre>

<hr>
<h2 id='kft5'>Dichotomous example data in Rost 2004
</h2><span id='topic+kft5'></span>

<h3>Description</h3>

<p>Data for 300 subjects answering to 5 dichotomous items out of 'Kognitiver Fähigkeits Test' [Cognitive Skills Test] (KFT - Gaedike &amp; Weinläder, 1976) . This data is used as an example in the textbook by J. Rost (2004) to demonstrate some principles of rasch measurement. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(kft5)
</code></pre>


<h3>Format</h3>

<p>A <code>"matrix"</code> containing 5 columns (variables) and 300 rows (obsevations).
</p>


<h3>Details</h3>

<p>The instrument KFT and the data are described in Rost (2004) at page 95.  
</p>


<h3>References</h3>

<p>Rost, J. (2004). <em>Lehrbuch Testtheorie - Testkonstruktion</em> (2 nd Ed.) Huber: Bern.
</p>
<p>Heller, K, Gaedike, A.-K &amp; Weinläder, H. (1976). <em>Kognitiver Fähigkeits-Test (KFT 4-13)</em>. Weinheim: Beltz.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(kft5)
dim(kft5)
###########
# frequencies
ftab(kft5)
# Itemparameter to be compared with Rost (2004), page 120.
summary(pair(kft5)) 
# Itemparameter to be compared with Rost (2004), page 120.
summary(pers(pair(kft5))) 
</code></pre>

<hr>
<h2 id='logLik.pers'>S3 logLik for Object of class &quot;pers&quot;</h2><span id='topic+logLik.pers'></span>

<h3>Description</h3>

<p>S3 logLik method to extract the log-likelihood for object of class<code>"pers"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pers'
logLik(object, sat = FALSE, p = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.pers_+3A_object">object</code></td>
<td>
<p>object of class<code>"pers"</code></p>
</td></tr>
<tr><td><code id="logLik.pers_+3A_sat">sat</code></td>
<td>
<p>a &quot;logical&quot; with default set to <code>sat=FALSE</code> to return the Log-Likelihood of the data for the unrestricted modell based on parameters estimated with function <code><a href="#topic+pers">pers</a></code>. If set to <code>sat=TRUE</code> the Log-Likelihood of the saturated model is returned instead.</p>
</td></tr>
<tr><td><code id="logLik.pers_+3A_p">p</code></td>
<td>
<p>a &quot;logical&quot; with default set to <code>p=FALSE</code> to return the category propabilities for the empirical data.</p>
</td></tr>
<tr><td><code id="logLik.pers_+3A_...">...</code></td>
<td>
<p>not used jet.</p>
</td></tr>
</table>

<hr>
<h2 id='lrtest.pers'>Likelihood Ratio Test for Object of class &quot;pers&quot;</h2><span id='topic+lrtest.pers'></span>

<h3>Description</h3>

<p>Function to perform a likelihood ratio test for the estimated model 'against' the saturated model for object of class<code>"pers"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrtest.pers(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrtest.pers_+3A_object">object</code></td>
<td>
<p>an object of class<code>"pers"</code> - see function <code><a href="#topic+pers">pers</a></code>.</p>
</td></tr>
<tr><td><code id="lrtest.pers_+3A_...">...</code></td>
<td>
<p>not used jet.</p>
</td></tr>
</table>

<hr>
<h2 id='make.incidenz'>Converting a booklet allocation table into a incidence matrix</h2><span id='topic+make.incidenz'></span>

<h3>Description</h3>

<p>This function converts a booklet allocation table (like in <code><a href="#topic+cogBOOKLET">cogBOOKLET</a></code>) into a incidence matrix used in the function <code><a href="#topic+pers">pers</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.incidenz(tab, bookid, item_order = NULL, info = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.incidenz_+3A_tab">tab</code></td>
<td>
<p>a booklet allocation table as a <code>data.frame</code>. The first column is assumed to contain the item names as a character vector (not a factor!) the other columns must be integer vectors containing the information in which booklet(s) the respective item is allocated.</p>
</td></tr>
<tr><td><code id="make.incidenz_+3A_bookid">bookid</code></td>
<td>
<p>a integer vector with the same length as the number of persons in the response data giving the information which booklet was assigned to each person.</p>
</td></tr>
<tr><td><code id="make.incidenz_+3A_item_order">item_order</code></td>
<td>
<p>optional a character vector with the item names in the order of the items in the response data (from first to last column in the response data). By default it is assumend that the item order in the booklet allocation table is already the same as in the response data.</p>
</td></tr>
<tr><td><code id="make.incidenz_+3A_info">info</code></td>
<td>
<p>logical default: <code>info=FALSE</code> to return just the incidence matrix. If set to <code>info=TRUE</code> more detailed information about the booklet design ist returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is assumed that there is an equal replicate factor for each item used, when constructing the bookletdesign - so every items occures with the same frequency over all booklets of the entire set of booklets.
</p>


<h3>Value</h3>

<p>an incidence matrix as an object of class &quot;matrix&quot; with 0,1 coding or a &quot;list&quot; with detailed information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#########################
data(cog);data(cogBOOKLET) # loading reponse and allocation data
table(cog$BOOKID)# show n persons per booklet
names(table(c(as.matrix(cogBOOKLET[,2:5])))) # show booklets in allocation data
d&lt;-(cog[cog$BOOKID!=14,]) # skip persons which got booklet No.14.
inc&lt;-make.incidenz(tab=cogBOOKLET, bookid=d$BOOKID) # make just the incidence matrix
inc  
make.incidenz(tab=cogBOOKLET, bookid=d$BOOKID, info=TRUE) # get some info too
# in this case not necessary but just to show
# using the (item) names in cog to secure the item order in incidence matrix:
make.incidenz(tab=cogBOOKLET, bookid=d$BOOKID, item_order=names(cog)[4:34])  
#######################
</code></pre>

<hr>
<h2 id='Neoffi5'>Polytomous example data in Rost 2004 
</h2><span id='topic+Neoffi5'></span>

<h3>Description</h3>

<p>Data for 1000 subjects answering to 5 polytomous items assessing neuroticism contained in the german version of the NEO&ndash;five&ndash;factor&ndash;inventory (NEOFFI) by Borkenau and Ostendorf (1991). This data is used as an example in the textbook by J. Rost (2004) to demonstrate some principles of rasch measurement. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(Neoffi5)
</code></pre>


<h3>Format</h3>

<p>A <code>"matrix"</code> containing 5 columns (variables) and 1000 rows (obsevations).
</p>


<h3>Details</h3>

<p>An detailed description of the data can be found in Rost (2004) at page 202.  
</p>


<h3>References</h3>

<p>Rost, J. (2004). <em>Lehrbuch Testtheorie - Testkonstruktion</em> (2 nd Ed.) Huber: Bern.
</p>
<p>Borkenau. P. &amp; Ostendorf F. (1991). Ein Fragebogen zur Erfassung fünf robuster Persönlichkeitsfaktoren. <em>Diagnostica, 37</em>, (1), 29&ndash;41.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Neoffi5)
dim(Neoffi5)
###########
# frequencies
ftab(Neoffi5)
# Itemparameter to be compared with Rost (2004), page 211.
summary(pair(Neoffi5)) 
# Itemparameter to be compared with Rost (2004), page 213.
summary(pers(pair(Neoffi5))) 
</code></pre>

<hr>
<h2 id='pair'>Item Parameter Calculation</h2><span id='topic+pair'></span>

<h3>Description</h3>

<p>This is the (new) main function for calculation of the item parameter for the dichotomous Rasch Model (Rasch, 1960) and its extension for polytomous items (thurstonian thresholds) according to the Partial Credit Model (Masters, 1982).
</p>
<p>The function implements a generalization (see Heine &amp; Tarnai, 2015) of the pairwise comparison approach, that is based on the principle for item calibration introduced by Choppin (1968, 1985) &ndash; see also (Wright &amp; Masters, 1982). The number of (response) categories may vary across items.
</p>
<p>Missing values up to an high amount in data are allowed, as long as items are proper linked together.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pair(
  daten,
  m = NULL,
  w = NULL,
  pot = TRUE,
  zerocor = TRUE,
  ccf = FALSE,
  likelihood = NULL,
  pot2 = 2,
  delta = TRUE,
  conv = 1e-04,
  maxiter = 3000,
  progress = TRUE,
  init = NULL,
  zerosum = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pair_+3A_daten">daten</code></td>
<td>
<p>a single <code>data.frame</code> or <code>matrix</code> or a <code>list</code> with every list entry holding a <code>data.frame</code> or <code>matrix</code>. Row and column names may represent the names of items (columns) and persons (rows). Missing values (<code>NA</code>) are allowed. Item responses can be polytomous or dichotomous (or a mixture of a varying number of categories across all items). Responses of <code>n</code> respondents (rows) on <code>k</code> items (colums) must be coded (scored) starting with 0 for lowest category to <em>m</em>-1 for highest category. If a list is assigned to this argument each <code>data.frame</code> or <code>matrix</code> as respective list entry must have the same dimensionality. See details and examples.</p>
</td></tr>
<tr><td><code id="pair_+3A_m">m</code></td>
<td>
<p>an integer (will be recycled to a vector of length k) or a vector giving the number of response categories for all items - by default <code>(m = NULL)</code>, <code>m</code> is calculated from data, assuming that every response category is at least once present in the data. For <em>'sparse' data</em> it is <em>strongly recomended</em> to explicitly <em>define the number of categories</em> by defining this argument.</p>
</td></tr>
<tr><td><code id="pair_+3A_w">w</code></td>
<td>
<p>an optional vector of case weights.</p>
</td></tr>
<tr><td><code id="pair_+3A_pot">pot</code></td>
<td>
<p>either a logical or an integer  &gt;= 2 defining the power to compute of the pairwise comparison matrix. If TRUE (default) a power of three of the pairwise comparison matrix is used for further calculations. If FALSE no powers are computed.</p>
</td></tr>
<tr><td><code id="pair_+3A_zerocor">zerocor</code></td>
<td>
<p>either a logical or an numeric value between &gt;0 and &lt;=1. If (in case of a logical) zerocor is set to TRUE (default) unobserved combinations (1-0, 0-1) in the data for each pair of items are given a frequency of one conf. proposal by Alexandrowicz (2011, p.373). As an alternative option a numeric value between &gt;0 and &lt;=1 can be assigned to unobserved combinations (1-0, 0-1) in the data for each pair of items (conf. to personal communication with A. Robitzsch; 29-03-2021).</p>
</td></tr>
<tr><td><code id="pair_+3A_ccf">ccf</code></td>
<td>
<p>logical with default <code>ccf=FALSE</code> to perform normal item parameter calculation, if set to <code>ccf=TRUE</code> just the conditional item (category) frequencies are returned.</p>
</td></tr>
<tr><td><code id="pair_+3A_likelihood">likelihood</code></td>
<td>
<p>either NULL (default) or a a character expression defining a likelihood estimation approach based on the pairwise comparison matrix. Currently only the so called MINCHI approach as described in Fischer (2006) is implemented , which can be selected by setting <code>likelihood="minchi"</code>.</p>
</td></tr>
<tr><td><code id="pair_+3A_pot2">pot2</code></td>
<td>
<p>ignored when <code>likelihood=NULL</code> (default).</p>
</td></tr>
<tr><td><code id="pair_+3A_delta">delta</code></td>
<td>
<p>ignored when <code>likelihood=NULL</code> (default).</p>
</td></tr>
<tr><td><code id="pair_+3A_conv">conv</code></td>
<td>
<p>ignored when <code>likelihood=NULL</code> (default).</p>
</td></tr>
<tr><td><code id="pair_+3A_maxiter">maxiter</code></td>
<td>
<p>ignored when <code>likelihood=NULL</code> (default).</p>
</td></tr>
<tr><td><code id="pair_+3A_progress">progress</code></td>
<td>
<p>ignored when <code>likelihood=NULL</code> (default).</p>
</td></tr>
<tr><td><code id="pair_+3A_init">init</code></td>
<td>
<p>ignored when <code>likelihood=NULL</code> (default).</p>
</td></tr>
<tr><td><code id="pair_+3A_zerosum">zerosum</code></td>
<td>
<p>ignored when <code>likelihood=NULL</code> (default).</p>
</td></tr>
<tr><td><code id="pair_+3A_...">...</code></td>
<td>
<p>additional parameters passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter calculation is based on the construction of a paired comparison matrix M<em>nicjc</em> with entries f<em>icjc</em> representing the number of respondents who answered to item <em>i</em> in category <em>c</em> and to item <em>j</em> in category <em>c-1</em> widening Choppin's (1968, 1985) conditional pairwise algorithm to polytomous item response formats. This algorithm is simply realized by matrix multiplication.
</p>
<p>To avoid numerical problems with off diagonal zero's when constructing the pairwise comparison matrix M<em>nij</em>, powers of the M<em>nicjc</em> matrix, can be used (Choppin, 1968, 1985). Using powers <em>k</em> of M<em>nicjc</em> - argument <code>pot=TRUE</code> (default), replaces the results of the direct comparisons between <em>i</em> and <em>j</em> with the sum of the indirect comparisons of <em>i</em> and <em>j</em> through an intermediate <em>k</em>.
In general, it is recommended to use the argument with default value <code>pot=TRUE</code>.
</p>
<p>If a list object is assigned to the argument <code>data</code>, the list entries (matrix or data.frame) must all have the same dimensionality. The individual list entries represent either <em>r</em> measurement times or raters. If such a list object is used, first the item parameters are calculated across all <em>r</em> measurement points or raters and additionally a threshold parameter is given for each of the <em>r</em> measurement points or raters (e.g. rater severity or overal item shift).
</p>
<p>For a graphic representation of the item 'estimates' the plotting S3 method <code><a href="#topic+plot.pair">plot.pair</a></code> is available. For plotting the item category probabilities the function <code><a href="#topic+catprob">catprob</a></code> can be used.
</p>


<h3>Value</h3>

<p>A (list) object of class <code>"pair"</code> containing the item category thresholds and difficulties sigma, also called item location.
</p>


<h3>References</h3>

<p>Choppin, B. (1968). Item Bank using Sample-free Calibration. <em>Nature, 219</em>(5156), 870-872.
</p>
<p>Choppin, B. (1985). A fully conditional estimation procedure for Rasch model parameters. <em>Evaluation in Education, 9</em>(1), 29-42.
</p>
<p>Heine, J. H. &amp; Tarnai, Ch. (2015). Pairwise Rasch model item parameter recovery under sparse data conditions. <em>Psychological Test and Assessment Modeling, 57</em>(1), 3–36.
</p>
<p>Alexandrowicz, R. W. (2011). 'GANZ RASCH': A Free Software for Categorical Data Analysis. <em>Social Science Computer Review, 30</em>(3), 369-379.
</p>
<p>Masters, G. (1982). A Rasch model for partial credit scoring. <em>Psychometrika, 47</em>(2), 149–174.
</p>
<p>Rasch, G. (1960). <em>Probabilistic models for some intelligence and attainment tests.</em> Copenhagen: Danmarks pædagogiske Institut.
</p>
<p>Wright, B. D., &amp; Masters, G. N. (1982). <em>Rating Scale Analysis.</em> Chicago: MESA Press.
</p>
<p>Fischer, Gerhard H. 2006. &quot;Rasch Models&quot;. Pp. 515–85 in Handbook of statistics (26): Psychometrics. Vol. 26, edited by C. R. Rao and S. Sinharay. Amsterdam: Elsevier.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bfiN) # loading example data set
# calculating itemparameters for 5 neuroticism items with 6 answer categories (0-5).
neuro_itempar&lt;-pair(daten = bfiN, m = 6) 
summary(neuro_itempar) 
summary(neuro_itempar, sortdif=TRUE) # ordered by difficulty 
# plotting threshold profiles for 5 neuroticism items.
plot(neuro_itempar) 
plot(neuro_itempar, sortdif=TRUE) # plotting ordered by difficulty 
################ with unequal number of categories 
data(sim200x3)
res&lt;-pair(sim200x3)
summary(res)
plot(res)
</code></pre>

<hr>
<h2 id='pairSE'>Item Parameter Calculation with Standard Errors</h2><span id='topic+pairSE'></span>

<h3>Description</h3>

<p>Calculation of the item parameters for dichotomous (difficulty) or polytomous items (thurstonian thresholds) and their standard errors (SE) respectively.
All parameters are calculated using a generalization (see Heine &amp; Tarnai, 2015) of the pairwise comparison algorithm (Choppin, 1968, 1985).
Missing values up to an high amount in data matrix are allowed, as long as items are proper linked together.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairSE(
  daten,
  m = NULL,
  w = NULL,
  nsample = 30,
  size = 0.5,
  seed = "no",
  pot = TRUE,
  zerocor = TRUE,
  verbose = TRUE,
  likelihood = NULL,
  pot2 = 2,
  delta = TRUE,
  conv = 1e-04,
  maxiter = 3000,
  progress = TRUE,
  init = NULL,
  zerosum = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairSE_+3A_daten">daten</code></td>
<td>
<p>a data.frame or matrix with optionaly named colums (names of items), potentially with missing values, comprising polytomous or dichotomous (or mixted category numbers) responses of <code>n</code> respondents (rows) on <code>k</code> items (colums) coded starting with 0 for lowest category to <em>m</em>-1 for highest category, with <em>m</em> beeing a vector (with length k) with the number of categories for the respective item.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_m">m</code></td>
<td>
<p>an integer (will be recycled to a vector of length k) or a vector giving the number of response categories for all items - by default <code>m = NULL</code>, <code>m</code> is calculated from data, assuming that every response category is at least once present in data. For sparse data it is strongly recomended to explicitly define the number of categories by defining this argument.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_w">w</code></td>
<td>
<p>an optional vector of case weights.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_nsample">nsample</code></td>
<td>
<p>numeric specifying the number of subsamples sampled from data, which is the number of replications of the parameter calculation. 
WARNING! specifying high values for <code>nsample</code> ( &gt; 100 ) may result in long computing time without leading to &quot;better&quot; estimates for SE. This may also be the case when choosing argument <code>size="jack"</code> (see argument <code>size</code>) in combination with large datasets (<em>N</em> &gt; 5000).</p>
</td></tr>
<tr><td><code id="pairSE_+3A_size">size</code></td>
<td>
<p>numeric with valid range between 0 and 1 (but not exactly 0 or 1) specifying the size of the subsample of <code>data</code> when bootstraping for SE estimation. As an alternative, <code>size</code> can be set to the character <code>"jack"</code> (<code>size="jack"</code>). This will set the subsample size to <em>N</em>-1 and set <code>nsample=N</code> (see argument <code>nsample</code>), with <em>N</em> beeing the number of persons in <code>daten</code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_seed">seed</code></td>
<td>
<p>numeric used for <code>set.seed(seed)</code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_pot">pot</code></td>
<td>
<p>either a logical or an integer  &gt;= 2 defining the power to compute of the pairwise comparison matrix. If TRUE (default) a power of three of the pairwise comparison matrix is used for further calculations. If FALSE no powers are computed.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_zerocor">zerocor</code></td>
<td>
<p>either a logical or an numeric value between &gt;0 and &lt;=1. If (in case of a logical) zerocor is set to TRUE (default) unobserved combinations (1-0, 0-1) in the data for each pair of items are given a frequency of one conf. proposal by Alexandrowicz (2011, p.373). As an alternative option a numeric value between &gt;0 and &lt;=1 can be assigned to unobserved combinations (1-0, 0-1) in the data for each pair of items (conf. to personal communication with A. Robitzsch; 29-03-2021).</p>
</td></tr>
<tr><td><code id="pairSE_+3A_verbose">verbose</code></td>
<td>
<p>logical, if <code>verbose = TRUE</code> (default) a message about subsampling is sent to console when calculating standard errors.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_likelihood">likelihood</code></td>
<td>
<p>see <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_pot2">pot2</code></td>
<td>
<p>see <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_delta">delta</code></td>
<td>
<p>see <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_conv">conv</code></td>
<td>
<p>see <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_maxiter">maxiter</code></td>
<td>
<p>see <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_progress">progress</code></td>
<td>
<p>see <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_init">init</code></td>
<td>
<p>see <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_zerosum">zerosum</code></td>
<td>
<p>see <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="pairSE_+3A_...">...</code></td>
<td>
<p>additional parameters passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter calculation is based on the construction of a paired comparison matrix M<em>nicjc</em> with entries f<em>icjc</em>, representing the number of respondents who answered to item <em>i</em> in category <em>c</em> and to item <em>j</em> in category <em>c-1</em> widening Choppin's (1968, 1985) conditional pairwise algorithm to polytomous item response formats. 
This algorithm is simply realized by matrix multiplication.
</p>
<p>Estimation of standard errors is done by repeated calculation of item parameters for sub samples of the given data. 
</p>
<p>To avoid numerical problems with off diagonal zeros when constructing the pairwise comparison matrix M<em>nicjc</em>, powers of the M<em>nicjc</em> matrix, can be used (Choppin, 1968, 1985). Using powers <em>k</em> of M<em>nicjc</em>, argument <code>pot=TRUE</code> (default), replaces the results of the direct comparisons between <em>i</em> and <em>j</em> with the sum of the indirect comparisons of <em>i</em> and <em>j</em> through an intermediate <em>k</em>.
</p>
<p>In general, it is recommended to use the argument with default value <code>pot=TRUE</code>.
</p>


<h3>Value</h3>

<p>A (list) object of class <code>c("pairSE","list")</code> containing the item category thresholds, difficulties sigma and their standard errors.
</p>


<h3>A note on standard errors</h3>

<p>Estimation of standard errors is done by repeated calculation of item parameters for subsamples of the given data. This procedure is mainly controlled by the arguments <code>nsample</code> and <code>size</code> (see arguments). With regard to calculation time, the argument <code>nsample</code> may be the 'time killer'. On the other hand, things (estimation of standard errors) will not necessarily get better when choosing large values for <code>nsample</code>. For example choosing <code>nsample=400</code> will only result in minimal change for standard error estimation in comparison to (<code>nsample=30</code>) which is the default setting (see examples).
</p>


<h3>References</h3>

<p>Choppin, B. (1968). Item Bank using Sample-free Calibration. <em>Nature, 219</em>(5156), 870-872.
</p>
<p>Choppin, B. (1985). A fully conditional estimation procedure for Rasch model parameters. <em>Evaluation in Education, 9</em>(1), 29-42.
</p>
<p>Heine, J. H. &amp; Tarnai, Ch. (2015). Pairwise Rasch model item parameter recovery under sparse data conditions. <em>Psychological Test and Assessment Modeling, 57</em>(1), 3–36.
</p>
<p>Alexandrowicz, R. W. (2011). 'GANZ RASCH': A Free Software for Categorical Data Analysis. <em>Social Science Computer Review, 30</em>(3), 369-379.
</p>
<p>Wright, B. D., &amp; Masters, G. N. (1982). <em>Rating Scale Analysis.</em> Chicago: MESA Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bfiN) # loading example data set

# calculating item parameters and their SE for 5 neuroticism items with 6 answer categories (0-5).
neuro_itempar&lt;-pairSE(daten = bfiN, m = 6) 
summary(neuro_itempar) # summary for result

# plotting item thresholds with with their CI = 95% 
plot(neuro_itempar)
plot(neuro_itempar,sortdif=TRUE)

###### example from details section 'Some Notes on Standard Errors' ########
neuro_itempar_400&lt;-pairSE(daten = bfiN, m = 6,nsample=400)
plot(neuro_itempar) 
plot(neuro_itempar_400) 
   
</code></pre>

<hr>
<h2 id='pairwise.item.fit'>Item Fit Indices</h2><span id='topic+pairwise.item.fit'></span>

<h3>Description</h3>

<p>function for calculating item fit indices. The procedures for calculating the fit indices are based on the formulas given in Wright &amp; Masters, (1982, P. 100), with further clarification given in <code>http://www.rasch.org/rmt/rmt34e.htm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.item.fit(pers_obj, na_treat = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.item.fit_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class <code>"pers"</code> as a result from function <code><a href="#topic+pers">pers</a></code></p>
</td></tr>
<tr><td><code id="pairwise.item.fit_+3A_na_treat">na_treat</code></td>
<td>
<p>value to be assigned to residual cells which have missing data in the original response matrix. default is set to <code>na_treat=NA</code> to ignore these cells in further calculations. An option is to set these residuals to 0 using <code>na_treat=0</code>, which implys that they are imputed as 'fitting data', i.e., zero residuals. This can attenuate contrasts (see. http://www.rasch.org/rmt/rmt142m.htm).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>contrary to many IRT software using Ml based item parameter estimation, <code>pairwise</code> will not exclude persons, showing perfect response vectors (e.g. c(0,0,0) for dataset with three variables), prior to the scaling. Therefor the fit statistics computed with <code>pairwise</code> may deviate somewhat from the fit statistics produced by IRT software using Ml based item parameter estimation (e.g. R-package <code>eRm</code>), depending on the amount of persons with perfect response vectors in the data.
</p>


<h3>Value</h3>

<p>an object of class <code>c("pifit", "data.frame")</code> containing item fit indices.
</p>


<h3>References</h3>

<p>Wright, B. D., &amp; Masters, G. N. (1982). <em>Rating Scale Analysis.</em> Chicago: MESA Press.
</p>
<p>Wright, B. D., &amp; Masters, G. N. (1990). Computation of OUTFIT and INFIT Statistics. <em>Rasch Measurement Transactions, 3</em>(4), 84–85.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
data(sim200x3)
result &lt;- pers(pair(sim200x3))
pairwise.item.fit(pers_obj=result) # item fit statistic
</code></pre>

<hr>
<h2 id='pairwise.person.fit'>Person Fit Indices</h2><span id='topic+pairwise.person.fit'></span>

<h3>Description</h3>

<p>function for calculating person fit indices. The procedures for calculating the fit indices are based on the formulas given in Wright &amp; Masters, (1982, P. 100), with further clarification given in <code>http://www.rasch.org/rmt/rmt34e.htm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.person.fit(pers_obj, na_treat = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.person.fit_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class <code>"pers"</code> as a result from function <code><a href="#topic+pers">pers</a></code>.</p>
</td></tr>
<tr><td><code id="pairwise.person.fit_+3A_na_treat">na_treat</code></td>
<td>
<p>value to be assigned to residual cells which have missing data in the original response matrix. default is set to <code>na_treat=NA</code> to ignore these cells in further calculations. An option is to set these residuals to 0 using <code>na_treat=0</code>, which implys that they are imputed as 'fitting data', i.e., zero residuals. This can attenuate contrasts (see. http://www.rasch.org/rmt/rmt142m.htm).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>contrary to many IRT software using ML based item parameter estimation, <code>pairwise</code> will not exclude persons, showing perfect response vectors (e.g. c(0,0,0) for dataset with three variables), prior to scaling. Therefor the fit statistics computed with <code>pairwise</code> may deviate somewhat from the fit statistics produced by IRT software using ML based item parameter estimation (e.g. R-package <code>eRm</code>), depending on the amount of persons with perfect response vectors in the data.
</p>


<h3>Value</h3>

<p>an object of class <code>c("ppfit", "data.frame")</code> containing person fit indices
</p>


<h3>References</h3>

<p>Wright, B. D., &amp; Masters, G. N. (1982). <em>Rating Scale Analysis.</em> Chicago: MESA Press.
</p>
<p>Wright, B. D., &amp; Masters, G. N. (1990). Computation of OUTFIT and INFIT Statistics. <em>Rasch Measurement Transactions, 3</em>(4), 84–85.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
data(sim200x3)
result &lt;- pers(pair(sim200x3))
pairwise.person.fit(pers_obj=result) # item fit statistic
</code></pre>

<hr>
<h2 id='pairwise.S'>The Fischer-Scheiblechner Statistic S on item level (Wald like Test)</h2><span id='topic+pairwise.S'></span>

<h3>Description</h3>

<p>This function calculates the S-statistic on item level proposed by Fischer and Scheiblechner (1970) on item level for dicho- or polytomous item response formats by splitting the data into two subsamples. For polytomous Items the test is performed on item category level. Several splitting options are available (see arguments). The S-statistic is also mentioned in van den Wollenberg, (1982) &ndash; an article in Psychometrika, which might be available more easily (see details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.S(
  daten,
  m = NULL,
  split = "random",
  splitseed = "no",
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.S_+3A_daten">daten</code></td>
<td>
<p>a data.frame or matrix with optionaly named colums (names of items), potentially with missing values, comprising polytomous or dichotomous (or mixed category numbers) responses of <code>n</code> respondents (rows) on <code>k</code> items (colums) coded starting with 0 for lowest category to <em>m</em>-1 for highest category, with <em>m</em> beeing a vector (with length k) with the number of categories for the respective item.</p>
</td></tr>
<tr><td><code id="pairwise.S_+3A_m">m</code></td>
<td>
<p>an integer (will be recycled to a vector of length k) or a vector giving the number of response categories for all items - by default <code>m = NULL</code>, <code>m</code> is calculated from data, assuming that every response category is at least once present in data. For sparse data it is strongly recomended to explicitly define the number of categories by defining this argument.</p>
</td></tr>
<tr><td><code id="pairwise.S_+3A_split">split</code></td>
<td>
<p>Specifies the splitting criterion. Basically there are three different options available - each with several modes - which are controlled by passing the corresponding character expression to the argument. 
</p>
<p>1) Using the rawscore for splitting into subsamples with the following modes: <code>split = "median"</code> median raw score split - high score group and low score group; <code>split = "mean"</code> mean raw score split - high score group and low score group.
</p>
<p>2) Dividing the persons in <code>daten</code> into subsamples with equal size by random allocation with the following modes: <code>split = "random"</code> (which is equivalent to <code>split = "random.2"</code>) divides persons into two subsamples with equal size. In general the number of desired subsamples must be expressed after the dot in the character expression - e.g. <code>split = "random.6"</code> divides persons into 6 subsamples (with equal size) by random allocation etc.
</p>
<p>3) The third option is using a manifest variable as a splitting criterion. In this case a vector with the same length as number of cases in <code>daten</code> must be passed to the argument grouping the data into subsamples. This vector should be coded as <code>"factor"</code> or a <code>"numeric"</code> integer vector with min = 1.</p>
</td></tr>
<tr><td><code id="pairwise.S_+3A_splitseed">splitseed</code></td>
<td>
<p>numeric, used for <code>set.seed(splitseed)</code> for random splitting - see argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="pairwise.S_+3A_verbose">verbose</code></td>
<td>
<p>logical, if <code>verbose = TRUE</code> (default) a message about subsampling is sent to console when calculating standard errors.</p>
</td></tr>
<tr><td><code id="pairwise.S_+3A_...">...</code></td>
<td>
<p>additional arguments <code>nsample</code>, <code>size</code>, <code>seed</code>, <code>pot</code> for caling <code><a href="#topic+pairSE">pairSE</a></code> are passed through - see description for <code><a href="#topic+pairSE">pairSE</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data is splitted in two subsamples and then item thresholds, the parameter (Sigma) and their standard errors (SE) for the items according the PCM (or RM in case of dichotonimies) are calculated for each subsample. This function internaly calls the function <code><a href="#topic+pairSE">pairSE</a></code>. Additional arguments (see description of function <code><a href="#topic+pairSE">pairSE</a></code>) for parameter calculation are passed through.
This item fit statistic is also (perhaps misleadingly) namend as 'Wald test' in other R-packages. The S-statistic, as implemented in <code>pairwise</code>, is defined according to Fischer and Scheiblechner (1970); see also equation (3) in van den Wollenberg, (1982), p. 124 in the following equation:
</p>
<p style="text-align: center;"><code class="reqn"> { S }_{ i }=\frac { { \hat { \sigma  }  }^{ (1) }_{ i }-{ \hat { \sigma  }  }^{ (2) }_{ i } }{  \sqrt { { \left( { { S } }^{ (1) }_{ \hat { \sigma  } _{ i } } \right)  }^{ 2 }+{ \left( { { S } }^{ (2) }_{ \hat { \sigma  } _{ i } } \right)  }^{ 2 }   } }  </code>
</p>

<p>where <code class="reqn">{\hat { \sigma  }  }^{ (1) }_{ i }</code> is the estimate of the item parameter of subsample 1, <code class="reqn">{\hat { \sigma  }  }^{ (2) }_{ i }</code> is the estimate of the item parameter of subsample 2 and <code class="reqn"> { S }^{ (1) }_{ \hat { \sigma  } _{ i } }</code> and <code class="reqn"> { S }^{ (2) }_{ \hat { \sigma  } _{ i } }</code> are the respective standard errors.
In Fischer (1974), p. 297, the resulting test statistic (as defined above) is labeled with <code class="reqn">Z_i</code>, as it is asymtotically normally distributed. Contrary to the 'Wald-type' test statistic <code class="reqn">W_i</code>, which was drived by Glas and Verhelst (2005) from the (general) <code class="reqn">\chi^2</code> distributed test of statistical hypotheses concerning several parameters, which was introduced by Wald (1943).
</p>


<h3>Value</h3>

<p>A (list) object of class <code>"pairS"</code> containing the test statistic and item difficulty parameter sigma and their standard errors for the two or more subsamples.
</p>


<h3>A note on standard errors</h3>

<p>Estimation of standard errors is done by repeated calculation of item parameters for subsamples of the given data. This procedure is mainly controlled by the arguments <code>nsample</code> and <code>size</code> (see arguments in <code><a href="#topic+pairSE">pairSE</a></code>). With regard to calculation time, the argument <code>nsample</code> is the 'time killer'. On the other hand, things (estimation of standard errors) will not necessarily get better when choosing large values for <code>nsample</code>. For example choosing <code>nsample=400</code> will only result in minimal change for standard error estimation in comparison to (<code>nsample=30</code>) which is the default setting (see examples).
</p>


<h3>References</h3>

<p>description of function <code><a href="#topic+pairSE">pairSE</a></code><code>{pairwise}</code>.
</p>
<p>Fischer, G. H., &amp; Scheiblechner, H. (1970). Algorithmen und Programme fuer das probabilistische Testmodell von Rasch. <em>Psychologische Beitrage</em>, (12), 23–51.
</p>
<p>van den Wollenberg, A. (1982). Two new test statistics for the rasch model. <em>Psychometrika, 47</em>(2), 123–140. https://doi.org/10.1007/BF02296270
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995). <em>Testing the Rasch Model</em>. In G. Fischer &amp; I. Molenaar (Eds.), Rasch models: Foundations, recent developments, and applications. New York: Springer.
</p>
<p>Wald, A. (1943). Tests of statistical hypotheses concerning several parameters when the number of observations is large. <em>Transactions of the American Mathematical Society, 54</em>(3), 426–482. https://doi.org/10.1090/S0002-9947-1943-0012401-3
</p>
<p>Fischer, G. H. (1974). <em>Einführung in die Theorie psychologischer Tests</em>. Bern: Huber.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########
data("kft5")
S_ran_kft &lt;- pairwise.S(daten = kft5,m = 2,split = "random")
summary(S_ran_kft)
summary(S_ran_kft,thres = FALSE)
#### polytomous examples
data(bfiN) # loading example data set
data(bfi_cov) # loading covariates to bfiN data set

# calculating itemparameters and SE for two subsamples by gender
S_gen &lt;- pairwise.S(daten=bfiN, split = bfi_cov$gender)
summary(S_gen)
summary(S_gen,thres = FALSE)

# other splitting criteria
## Not run: 
S_med &lt;- pairwise.S(daten=bfiN, split = "median")
summary(S_med)

S_ran&lt;-pairwise.S(daten=bfiN, split = "random")
summary(S_ran)

S_ran.4&lt;-pairwise.S(daten=bfiN, split = "random.4")
summary(S_ran.4) # currently not displayed

###### example from details section 'Some Notes on Standard Errors' ########
S_def&lt;-pairwise.S(daten=bfiN, split = "random",splitseed=13)
summary(S_def)
######
S_400&lt;-pairwise.S(daten=bfiN, split = "random", splitseed=13 ,nsample=400)
summary(S_400) 

## End(Not run)

</code></pre>

<hr>
<h2 id='pairwise.SepRel'>Person Separation Reliability</h2><span id='topic+pairwise.SepRel'></span>

<h3>Description</h3>

<p>This function calculates an Index of Person Separation, that is the proportion of person variance that is not due to error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.SepRel(pers_obj, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.SepRel_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class <code>"pers"</code> as a result from function <code><a href="#topic+pers">pers</a></code>.</p>
</td></tr>
<tr><td><code id="pairwise.SepRel_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical evaluating to TRUE or FALSE indicating whether NA values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>none
</p>


<h3>Value</h3>

<p>An object of class <code>c("pairwiseSepRel","list")</code>.
</p>


<h3>References</h3>

<p>Andrich, D. (1982). An index of person separation in latent trait theory, the traditional KR.20 index, and the Guttman scale response pattern. <em>Education Research and Perspectives, 9</em>(1), 95–104.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######################
########
data(bfiN) # loading reponse data
pers_obj &lt;- pers(pair(bfiN))
result &lt;- pairwise.SepRel(pers_obj)
result
str(result) # to see whats in ;-)
#### 
</code></pre>

<hr>
<h2 id='pers'>WLE - Rasch Person Parameter</h2><span id='topic+pers'></span>

<h3>Description</h3>

<p>This is the (new) main function for calculation of person estimates based on answering dichotomous or polytomous items according theRasch Model (Rasch, 1960) and Partial Credit Model (Masters, 1982), given the item parameters (object of class <code>"pair"</code> - as a result of <code><a href="#topic+pair">pair</a>()</code>) and and the datamatrix (argument <code>daten</code>) containing the person respose vectors (rows), using an WL approach, introduced by Warm (1989).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pers(
  itempar,
  daten = NULL,
  incidenz = NULL,
  na_treat = NULL,
  limit = 1e-05,
  iter = 50,
  Nrel = FALSE,
  tecout = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pers_+3A_itempar">itempar</code></td>
<td>
<p>The item parameter prior calculated or estimated. A list object of class <code>"pair"</code> as a result of applying the function <code><a href="#topic+pair">pair</a>()</code> to the data. Or an 'ordinary' <code>"matrix"</code> with <code>nrow = k</code> (number of items) and <code>ncol = m</code> (maximum number of thresholds), holding  the 'thurstonian' thresholds of the respective item. Some matrix entries may be <code>NA</code>, depending on the number of categories of the respective item.</p>
</td></tr>
<tr><td><code id="pers_+3A_daten">daten</code></td>
<td>
<p>A <code>"matrix"</code> (or <code>"data.frame"</code>) optionaly with named colums (names of items) and named rows (person IDs). This argument can be left empty when the argument itempar (above) is of class <code>"pair"</code>. <code>daten</code> holds polytomous or dichotomous (or mixted category numbers) responses of <code>n</code> respondents (rows) on <code>k</code> items (colums) coded starting with 0 for lowest category to <code>m-1</code> for highest category, with m beeing a vector (with length k) with the number of categories for the respective item. Responses in <code>daten</code> must be stored as <code>"integers"</code> (not <code>"factors"</code> !) and may have missing values.</p>
</td></tr>
<tr><td><code id="pers_+3A_incidenz">incidenz</code></td>
<td>
<p>This argument is only relevant when items are assigned to different booklets. For such a booklet-design a <code>"matrix"</code> should be assigned to this argument, with the same dimensions like <code>daten</code>, containig 0 and 1 integer codes, giving the information (for every person) if the respective item was in the respective booklet (coded 1) given to the person or not (coded 0).</p>
</td></tr>
<tr><td><code id="pers_+3A_na_treat">na_treat</code></td>
<td>
<p>optionaly an integer (vector) defining the type of treatment to missing responses in the argument <code>daten</code>. If set to <code>na_treat=NULL</code> (default) missing responses are treated as missings and the respective person is assigned to an corresponding missing group for estimation. An option is to set <code>na_treat</code> to any integer value between 0 (lowest category) and the numeric code for the maximum ctaegory of the respective item.</p>
</td></tr>
<tr><td><code id="pers_+3A_limit">limit</code></td>
<td>
<p>numeric giving the limit at which accuracy the WL-algorithm stops.</p>
</td></tr>
<tr><td><code id="pers_+3A_iter">iter</code></td>
<td>
<p>numeric giving the maximum numer of iteration to perform.</p>
</td></tr>
<tr><td><code id="pers_+3A_nrel">Nrel</code></td>
<td>
<p>logical with default set to <code>Nrel=FALSE</code> to include persons with perfect response vectors for calculating WLE reliability. If set to <code>Nrel=TRUE</code> persons with perfect response vectors are excluded for calculating WLE reliability.</p>
</td></tr>
<tr><td><code id="pers_+3A_tecout">tecout</code></td>
<td>
<p>logical default set to <code>FALSE</code>. If set to <code>TRUE</code> the result will be a (very) long list with estimation details for every case in <code>daten</code>. In case of a booklet-design the list entries will be divided by &quot;booklet&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no detail in the moment.
</p>


<h3>Value</h3>

<p>An object of class <code>c("pers", "data.frame")</code> or a (very long) <code>"list"</code> (when setting on <code>techout=TRUE</code>) containing the person parameters.
</p>


<h3>References</h3>

<p>Masters, G. (1982). A Rasch model for partial credit scoring. <em>Psychometrika, 47</em>(2), 149–174.
</p>
<p>Rasch, G. (1960). <em>Probabilistic models for some intelligence and attainment tests.</em> Copenhagen: Danmarks pædagogiske Institut.
</p>
<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory. <em>Psychometrika, 54</em>(3), 427–450.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>############
data(sim200x3)
result &lt;- pers(itempar=pair(sim200x3))
summary(result)
plot(result)
logLik(result) # Log-Likelihood for 'estimated' model
logLik(result, sat=TRUE) # Log-Likelihood for saturated model
AIC(logLik(result)) # AIC for 'estimated' model
AIC(logLik(result, sat=TRUE)) # AIC for saturated model
BIC(logLik(result)) # BIC for 'estimated' model
BIC(logLik(result, sat=TRUE)) # BIC for saturated model
###### following example requires package eRm ######
# require(eRm)
# # itemparameter with eRm:
# itempar_eRm &lt;- thresholds(PCM(sim200x3))$ threshtable[[1]][,2:3]
# # pairwise personparameter with eRm-itemparameter and data:
# summary(pers(itempar=itempar_eRm,daten=sim200x3))
# # eRm personparameter:
# person.parameter(PCM(sim200x3))
# # personparameter with pairwise:
# summary(pers(pair(sim200x3))) 
</code></pre>

<hr>
<h2 id='plot.grm'>S3 Plotting Graphical Model Check</h2><span id='topic+plot.grm'></span>

<h3>Description</h3>

<p>S3 plotting method for object of class<code>c("grm","list")</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grm'
plot(
  x,
  xymin = NULL,
  xymax = NULL,
  ci = 2,
  main = NULL,
  col.error = "blue",
  col.diag = "red",
  itemNames = TRUE,
  cex.names = 0.8,
  type = "b",
  xlab = NULL,
  ylab = NULL,
  pch = 43,
  las = 3,
  cex.axis = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.grm_+3A_x">x</code></td>
<td>
<p>object of class<code>c("grm","list")</code></p>
</td></tr>
<tr><td><code id="plot.grm_+3A_xymin">xymin</code></td>
<td>
<p>optional lower limit for xy-axis</p>
</td></tr>
<tr><td><code id="plot.grm_+3A_xymax">xymax</code></td>
<td>
<p>optional upper limit for xy-axis</p>
</td></tr>
<tr><td><code id="plot.grm_+3A_ci">ci</code></td>
<td>
<p>numeric defining confidence intervall for point estimator</p>
</td></tr>
<tr><td><code id="plot.grm_+3A_main">main</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.grm_+3A_col.error">col.error</code></td>
<td>
<p>vector of colors for error bars</p>
</td></tr>
<tr><td><code id="plot.grm_+3A_col.diag">col.diag</code></td>
<td>
<p>color for the diagonal of the plot</p>
</td></tr>
<tr><td><code id="plot.grm_+3A_itemnames">itemNames</code></td>
<td>
<p>logical wether to plot itemnames</p>
</td></tr>
<tr><td><code id="plot.grm_+3A_cex.names">cex.names</code></td>
<td>
<p>magnification factor for itemnames</p>
</td></tr>
<tr><td><code id="plot.grm_+3A_type">type</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.grm_+3A_xlab">xlab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.grm_+3A_ylab">ylab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.grm_+3A_pch">pch</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.grm_+3A_las">las</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.grm_+3A_cex.axis">cex.axis</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.grm_+3A_...">...</code></td>
<td>
<p>other parameters passed to plot</p>
</td></tr>
</table>

<hr>
<h2 id='plot.pair'>S3 Plotting Thurstonian Thresholds</h2><span id='topic+plot.pair'></span>

<h3>Description</h3>

<p>S3 plotting method for object of class<code>"pair"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pair'
plot(
  x,
  sortdif = FALSE,
  ra = "auto",
  main = NULL,
  col.lines = (1:dim(x$threshold)[2]),
  type = "b",
  xlab = "items",
  ylab = "logits",
  pch = (1:dim(x$threshold)[2]),
  las = 3,
  cex.axis = 0.8,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pair_+3A_x">x</code></td>
<td>
<p>object of class<code>"pair"</code></p>
</td></tr>
<tr><td><code id="plot.pair_+3A_sortdif">sortdif</code></td>
<td>
<p>logical wether to order items by difficulty</p>
</td></tr>
<tr><td><code id="plot.pair_+3A_ra">ra</code></td>
<td>
<p>either the character <code>"auto"</code> (default) or an numeric, defining the (logit) range for y-axis</p>
</td></tr>
<tr><td><code id="plot.pair_+3A_main">main</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pair_+3A_col.lines">col.lines</code></td>
<td>
<p>vector of colors for threshold profile lines</p>
</td></tr>
<tr><td><code id="plot.pair_+3A_type">type</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pair_+3A_xlab">xlab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pair_+3A_ylab">ylab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pair_+3A_pch">pch</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pair_+3A_las">las</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pair_+3A_cex.axis">cex.axis</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pair_+3A_...">...</code></td>
<td>
<p>other parameters passed to plot</p>
</td></tr>
</table>

<hr>
<h2 id='plot.pairSE'>S3 Plotting Thustonian Thresholds with SE</h2><span id='topic+plot.pairSE'></span>

<h3>Description</h3>

<p>S3 plotting method for object of class<code>c("pairSE","list")</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pairSE'
plot(
  x,
  ci = 2,
  sortdif = FALSE,
  ra = "auto",
  main = NULL,
  col.lines = 1:(dim(x$threshold)[2]),
  col.error = 1:(dim(x$threshold)[2]),
  type = "b",
  xlab = "items",
  ylab = "logits",
  pch = 20,
  las = 3,
  cex.axis = 0.8,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pairSE_+3A_x">x</code></td>
<td>
<p>object of class<code>c("pairSE","list")</code></p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_ci">ci</code></td>
<td>
<p>numeric defining confidence intervall for point estimator</p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_sortdif">sortdif</code></td>
<td>
<p>logical wether to order items by difficulty</p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_ra">ra</code></td>
<td>
<p>either the character <code>"auto"</code> (default) or an numeric, defining the (logit) range for y-axis</p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_main">main</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_col.lines">col.lines</code></td>
<td>
<p>vector of colors for threshold profile lines</p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_col.error">col.error</code></td>
<td>
<p>vector of colors for error bars</p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_type">type</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_xlab">xlab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_ylab">ylab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_pch">pch</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_las">las</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_cex.axis">cex.axis</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pairSE_+3A_...">...</code></td>
<td>
<p>other parameters passed to plot</p>
</td></tr>
</table>

<hr>
<h2 id='plot.pers'>S3 Plotting Person - Item Map</h2><span id='topic+plot.pers'></span>

<h3>Description</h3>

<p>S3 plotting method for object of class<code>"pers"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pers'
plot(
  x,
  ra = NULL,
  sortdif = FALSE,
  main = NULL,
  ylab = "Logits",
  itemNames = TRUE,
  fillCol = "grey60",
  lineCol = "grey40",
  cex = 0.7,
  pos = 4,
  breaks = "Sturges",
  pch = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pers_+3A_x">x</code></td>
<td>
<p>object of class<code>"pers"</code></p>
</td></tr>
<tr><td><code id="plot.pers_+3A_ra">ra</code></td>
<td>
<p>an integer, defining the (logit) range for y-axis</p>
</td></tr>
<tr><td><code id="plot.pers_+3A_sortdif">sortdif</code></td>
<td>
<p>logical wether to order items by difficulty</p>
</td></tr>
<tr><td><code id="plot.pers_+3A_main">main</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pers_+3A_ylab">ylab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.pers_+3A_itemnames">itemNames</code></td>
<td>
<p>logical wether to use itemnames in the resulting plot</p>
</td></tr>
<tr><td><code id="plot.pers_+3A_fillcol">fillCol</code></td>
<td>
<p>color for bar filling of the ability histogram</p>
</td></tr>
<tr><td><code id="plot.pers_+3A_linecol">lineCol</code></td>
<td>
<p>color for bar lines of the ability histogram</p>
</td></tr>
<tr><td><code id="plot.pers_+3A_cex">cex</code></td>
<td>
<p>see <code><a href="graphics.html#topic+text">text</a></code></p>
</td></tr>
<tr><td><code id="plot.pers_+3A_pos">pos</code></td>
<td>
<p>see <code><a href="graphics.html#topic+text">text</a></code></p>
</td></tr>
<tr><td><code id="plot.pers_+3A_breaks">breaks</code></td>
<td>
<p>see <code><a href="graphics.html#topic+hist">hist</a></code></p>
</td></tr>
<tr><td><code id="plot.pers_+3A_pch">pch</code></td>
<td>
<p>see <code><a href="graphics.html#topic+points">points</a></code></p>
</td></tr>
<tr><td><code id="plot.pers_+3A_...">...</code></td>
<td>
<p>other parameters passed to <code><a href="graphics.html#topic+hist">hist</a></code> and <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.rfa'>S3 Plotting Rasch Residual Factor Analysis</h2><span id='topic+plot.rfa'></span>

<h3>Description</h3>

<p>S3 plotting Method for object of class<code>"rfa"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rfa'
plot(
  x,
  com = 1,
  ra = "auto",
  main = NULL,
  labels = NULL,
  xlab = "logits",
  ylab = "loadings",
  srt = 0,
  cex.axis = 0.8,
  cex.text = 0.8,
  col.text = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rfa_+3A_x">x</code></td>
<td>
<p>object of class<code>"rfa"</code></p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_com">com</code></td>
<td>
<p>an integer giving the number of the principal component used for plotting</p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_ra">ra</code></td>
<td>
<p>either the character <code>"auto"</code> (default) or an numeric, defining the (logit) range for x-axis</p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_main">main</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_labels">labels</code></td>
<td>
<p>a character vector specifying the plotting pattern to use. see <code><a href="graphics.html#topic+text">text</a></code>. At default the itemnames are used.</p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_xlab">xlab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_ylab">ylab</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_srt">srt</code></td>
<td>
<p>see <code><a href="graphics.html#topic+text">text</a></code> or <code><a href="graphics.html#topic+par">par</a></code></p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_cex.axis">cex.axis</code></td>
<td>
<p>see <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_cex.text">cex.text</code></td>
<td>
<p>see argument <code>cex</code> in function <code><a href="graphics.html#topic+text">text</a></code></p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_col.text">col.text</code></td>
<td>
<p>see argument <code>col</code> in function <code><a href="graphics.html#topic+text">text</a></code></p>
</td></tr>
<tr><td><code id="plot.rfa_+3A_...">...</code></td>
<td>
<p>other parameters passed through.</p>
</td></tr>
</table>

<hr>
<h2 id='ptbis'>Point Biserial Correlations</h2><span id='topic+ptbis'></span>

<h3>Description</h3>

<p>Calculation of the point biserial correlations for dicho- or polytomous item categories with total scale (person parameter).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ptbis(y, daten = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ptbis_+3A_y">y</code></td>
<td>
<p>either an object of class <code>"pers"</code>, or an numeric vector as an result of any scaling approach (WLE, MLE, Rawscore, etc. ) relating to the Items (columns) in <code>daten</code>.</p>
</td></tr>
<tr><td><code id="ptbis_+3A_daten">daten</code></td>
<td>
<p>if argument y is not an object of class <code>"pers"</code>, a <code>"data.frame"</code>, potentially with missing values, comprising dicho- or polytomous items (columns).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no details in the moment.
</p>


<h3>Value</h3>

<p>An object of class <code>c("data.frame", "ptbis")</code> containing item statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######################
########
data(sim200x3) # loading reponse data
y &lt;- rowSums(sim200x3)
ptbis(y=y, daten=sim200x3)
#### 
result &lt;- pers(pair(sim200x3))
ptbis(y= result)
</code></pre>

<hr>
<h2 id='Q'>Person Fit Index Q</h2><span id='topic+Q'></span>

<h3>Description</h3>

<p>function for calculating the person fit index Q, which was proposed by Tarnai and Rost (1990).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Q(obj = NULL, data = NULL, threshold = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Q_+3A_obj">obj</code></td>
<td>
<p>an object of class <code>"pers"</code> or class <code>"pair"</code>as a result from function <code><a href="#topic+pers">pers</a></code> or <code><a href="#topic+pair">pair</a></code> respectively.</p>
</td></tr>
<tr><td><code id="Q_+3A_data">data</code></td>
<td>
<p>optional response data when object of class <code>"pers"</code> or class <code>"pair"</code> is not provided.</p>
</td></tr>
<tr><td><code id="Q_+3A_threshold">threshold</code></td>
<td>
<p>optional in case that object of class <code>"pers"</code> or class <code>"pair"</code> is not provided. Threshold values as matrix with row and columnnames !! &ndash; items as rows and thresholds as columns. Thresholds should be ordered from left to right, some items may have less thresholds than the others, in this case the respective row/column is filled with an NA value - see examples.</p>
</td></tr>
<tr><td><code id="Q_+3A_...">...</code></td>
<td>
<p>not used so far.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The person Q-index proposed by Tarnai and Rost, (1990) is solely based on the empirical responses and the item parameters. Thus the computation of person parameters using the function <code><a href="#topic+pers">pers</a></code> is not required - see examples. But for convenience return objects of both functions are accepted in function <code>Q</code>.
</p>


<h3>Value</h3>

<p>a vector holding the Q-index for every person.
</p>


<h3>References</h3>

<p>Tarnai, C., &amp; Rost, J. (1990). <em>Identifying aberrant response patterns in the Rasch model: the Q index</em>. Münster: ISF.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######################
data(bfiN) # get some data
ip &lt;- pair(daten = bfiN,m = 6) # item parameters according the partial credit model
Q(ip)

### with data an thresholds as external objects #####
threshold &lt;- matrix(seq(-3,3,length.out = 9),ncol = 3)
dimnames(threshold) &lt;- list(c("I1","I2","I3"),c("1","2","2"))
threshold
resp_vec &lt;- c(3,0,2,1,2,2,2,2,1,3,0,NA,NA,0,2,3,NA,2,NA,2,1,2,NA,1,2,2,NA)
resp_emp &lt;- matrix(resp_vec,ncol = 3,byrow = TRUE)
colnames(resp_emp) &lt;- c("I1","I2","I3")
resp_emp
Qindex &lt;- Q(data = resp_emp,threshold = threshold)
cbind(resp_emp,Qindex)

#### unequal number of thresholds ###################
threshold &lt;- matrix(seq(-3,3,length.out = 9),ncol = 3)
dimnames(threshold) &lt;- list(c("I1","I2","I3"),c("1","2","2"))
threshold[2,3] &lt;- NA

resp_vec &lt;- c(3,0,2,1,2,2,2,2,1,3,0,NA,NA,0,2,3,NA,2,NA,2,1,2,NA,1,2,2,NA)
resp_emp &lt;- matrix(resp_vec,ncol = 3,byrow = TRUE)
colnames(resp_emp) &lt;- c("I1","I2","I3")
resp_emp
Qindex &lt;- Q(data = resp_emp,threshold = threshold)
cbind(resp_emp,Qindex)
</code></pre>

<hr>
<h2 id='q3'>Q3 Fit Statistic</h2><span id='topic+q3'></span>

<h3>Description</h3>

<p>Calculation of Q3 fit statistic for the rasch model based on the residuals, which was proposed by Yen (1984).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>q3(
  pers_obj,
  na_treat = 0,
  use = "complete.obs",
  res = "stdr",
  method = "pearson"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="q3_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class <code>"pers"</code> as a result from function <code><a href="#topic+pers">pers</a></code>.</p>
</td></tr>
<tr><td><code id="q3_+3A_na_treat">na_treat</code></td>
<td>
<p>value to be assigned to residual cells which have missing data in the original response matrix. default is set to <code>na_treat=0</code> to set the residuals to 0, which implys that they are imputed as 'fitting data', i.e., zero residuals. This can attenuate contrasts (see. http://www.rasch.org/rmt/rmt142m.htm). An option is to set it to <code>na_treat=NA</code>.</p>
</td></tr>
<tr><td><code id="q3_+3A_use">use</code></td>
<td>
<p>a character string as used in function <code><a href="stats.html#topic+cor">cor</a></code> or <code><a href="stats.html#topic+cov">cov</a></code>, giving a method for computing covariances or correlations in the presence of missing values. This must be (an abbreviation of) one of the strings &quot;everything&quot;, &quot;all.obs&quot;, &quot;complete.obs&quot;, &quot;na.or.complete&quot;, or &quot;pairwise.complete.obs&quot;. The default is set to <code>use="complete.obs"</code> which will exclude cases by listwise deletion to keep the correlation matrix positive definit.</p>
</td></tr>
<tr><td><code id="q3_+3A_res">res</code></td>
<td>
<p>a character string defining which type of (rasch&ndash;) residual to analyze when computing the correlations. This must be (exactly) one of the strings &quot;sr&quot; for score residuals , &quot;stdr&quot; for standardised residuals, &quot;srsq&quot; for score residuals squared, or &quot;stdrsq&quot; for standardised residuals squared. The default is set to <code>res="stdr"</code> refering to Linacre (1998).</p>
</td></tr>
<tr><td><code id="q3_+3A_method">method</code></td>
<td>
<p>a character string as used in function <code><a href="stats.html#topic+cor">cor</a></code>, indicating which correlation coefficient  is to be computed. One of &quot;pearson&quot; (default), &quot;kendall&quot;, or &quot;spearman&quot;, can be abbreviated. The default is set to <code>method="pearson"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The lower level letter 'q' was used (intead of 'Q') for naming the function because the name 'Q3' was already used in another IRT package &ndash; namly <code>TAM</code>. As perhaps some users like to use both packages simultaniously, an alternative naming convention was choosen for 'pairwise'. No other details in the moment.
</p>


<h3>Value</h3>

<p>An object of class <code>c("Q3","list")</code>.
</p>


<h3>References</h3>

<p>Yen, W. M. (1984). Effects of Local Item Dependence on the Fit and Equating Performance of the Three-Parameter Logistic Model. <em>Applied Psychological Measurement, 8</em>(2), 125–145. https://doi.org/10.1177/014662168400800201
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######################
########
data(bfiN) # loading reponse data
pers_obj &lt;- pers(pair(bfiN))
result &lt;- q3(pers_obj)
str(result) # to see whats in ;-)
#### 
</code></pre>

<hr>
<h2 id='residuals.pers'>S3 residuals for Object of class &quot;pers&quot;</h2><span id='topic+residuals.pers'></span>

<h3>Description</h3>

<p>S3 residuals method to extract the (Rasch) residuals for object of class<code>"pers"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pers'
residuals(object, res = "sr", na_treat = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.pers_+3A_object">object</code></td>
<td>
<p>object of class<code>"pers"</code></p>
</td></tr>
<tr><td><code id="residuals.pers_+3A_res">res</code></td>
<td>
<p>a character string defining which type of (rasch–) residual to return. This must be (exactly) one of the strings &quot;exp&quot; for expected scores &quot;sr&quot; for score residuals (default), &quot;stdr&quot; for standardised residuals, &quot;srsq&quot; for score residuals squared, or &quot;stdrsq&quot; for standardised residuals squared. The default is set to res=&quot;sr&quot;.</p>
</td></tr>
<tr><td><code id="residuals.pers_+3A_na_treat">na_treat</code></td>
<td>
<p>value to be assigned to residual cells which have missing data in the original response matrix. Default is set to na_treat=0 to set the residuals to 0, which implys that they are imputed as 'fitting data', i.e., zero residuals. This can attenuate contrasts (see. http://www.rasch.org/rmt/rmt142m.htm). An option is to set it to na_treat=NA.</p>
</td></tr>
<tr><td><code id="residuals.pers_+3A_...">...</code></td>
<td>
<p>not used jet.</p>
</td></tr>
</table>

<hr>
<h2 id='rfa'>Rasch Residual Factor Analysis</h2><span id='topic+rfa'></span>

<h3>Description</h3>

<p>Calculation of the rasch residual factor analysis proposed by Wright (1996) and further discussed by Linacre (1998) to detect multidimensionality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfa(
  pers_obj,
  na_treat = 0,
  tr = FALSE,
  use = "complete.obs",
  res = "stdr",
  method = "pearson",
  cor = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rfa_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class <code>"pers"</code> as a result from function <code><a href="#topic+pers">pers</a></code>.</p>
</td></tr>
<tr><td><code id="rfa_+3A_na_treat">na_treat</code></td>
<td>
<p>value to be assigned to residual cells which have missing data in the original response matrix. default is set to <code>na_treat=0</code> to set the residuals to 0, which implys that they are imputed as 'fitting data', i.e., zero residuals. This can attenuate contrasts (see. http://www.rasch.org/rmt/rmt142m.htm). An option is to set it to <code>na_treat=NA</code>.</p>
</td></tr>
<tr><td><code id="rfa_+3A_tr">tr</code></td>
<td>
<p>a logical value indicating whether the data (the residual matrix) is transposed prior to  calculation. This would perform a person analysis rather than a item analysis. The default is set to item analysis.</p>
</td></tr>
<tr><td><code id="rfa_+3A_use">use</code></td>
<td>
<p>a character string as used in function <code><a href="stats.html#topic+cor">cor</a></code> or <code><a href="stats.html#topic+cov">cov</a></code>, giving a method for computing covariances or correlations in the presence of missing values. This must be (an abbreviation of) one of the strings &quot;everything&quot;, &quot;all.obs&quot;, &quot;complete.obs&quot;, &quot;na.or.complete&quot;, or &quot;pairwise.complete.obs&quot;. The default is set to <code>use="complete.obs"</code> which will exclude cases by listwise deletion to keep the correlation matrix positive definit.</p>
</td></tr>
<tr><td><code id="rfa_+3A_res">res</code></td>
<td>
<p>a character string defining which type of (rasch&ndash;) residual to analyze when computing covariances or correlations. This must be (exactly) one of the strings &quot;sr&quot; for score residuals , &quot;stdr&quot; for standardised residuals, &quot;srsq&quot; for score residuals squared, or &quot;stdrsq&quot; for standardised residuals squared. The default is set to <code>res="stdr"</code> refering to Linacre (1998).</p>
</td></tr>
<tr><td><code id="rfa_+3A_method">method</code></td>
<td>
<p>a character string as used in function <code><a href="stats.html#topic+cor">cor</a></code> or <code><a href="stats.html#topic+cov">cov</a></code>, indicating which correlation coefficient (or covariance) is to be computed. One of &quot;pearson&quot; (default), &quot;kendall&quot;, or &quot;spearman&quot;, can be abbreviated. The default is set to <code>method="pearson"</code>.</p>
</td></tr>
<tr><td><code id="rfa_+3A_cor">cor</code></td>
<td>
<p>a logical value indicating whether the calculation should use the correlation matrix or the covariance matrix.The default is set to <code>cor=TRUE</code> to use the correlation matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no details in the moment.
</p>


<h3>Value</h3>

<p>An object of class <code>c("rfa","list")</code>.
</p>


<h3>References</h3>

<p>Wright, B. D. (1996). Comparing Rasch measurement and factor analysis. <em>Structural Equation Modeling: A Multidisciplinary Journal, 3</em>(1), 3–24.
</p>
<p>Linacre, J. M. (1998). Detecting multidimensionality: which residual data-type works best? <em>Journal of outcome measurement, 2</em>, 266–283.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######################
########
data(bfiN) # loading reponse data
pers_obj &lt;- pers(pair(bfiN))
result &lt;- rfa(pers_obj)
summary(result)
plot(result)
#### 
</code></pre>

<hr>
<h2 id='sim200x3'>Simulated Data
</h2><span id='topic+sim200x3'></span>

<h3>Description</h3>

<p>Simulated data for 200 'subjects' 'answering' to 3 items with unequal number of categories &ndash; one dichotomous and two polytoumous items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(sim200x3)
</code></pre>


<h3>Format</h3>

<p>A data.frame containing 3 variables and 200 obsevations.
</p>


<h3>Details</h3>

<p>This simulated data is used as an example in the rasch module of the 'ALMO - Statistiksystem'. 
</p>


<h3>Source</h3>

<p><a href="http://www.almo-statistik.de/">http://www.almo-statistik.de/</a>
</p>


<h3>References</h3>

<p>Holm, K. (2014). ALMO Statistik-System. <em>P14.8 Das allgemeine ordinale Rasch-Modell</em> <a href="http://www.almo-statistik.de/download/Ordinales_Rasch_Modell.pdf">http://www.almo-statistik.de/download/Ordinales_Rasch_Modell.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sim200x3)
dim(sim200x3)
##############################################################
apply(sim200x3,2,table)
</code></pre>

<hr>
<h2 id='simra'>Simulate Response Pattern under Dichotomous and Polytomous Rasch Model</h2><span id='topic+simra'></span>

<h3>Description</h3>

<p>function for simulation of response patterns following the dichotomous and/or polytomous Rasch model based on the category probabilities given the model parameters.
At default, when just calling <code>simra()</code> 1 replication of responses to 5 items with difficulties -2, -1, 0, 1, 2 from 100 persons with ability drawn from N(0|1) are sampled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simra(
  itempar = matrix(seq(-2, 2, length = 5)),
  theta = 100,
  pers_obj = NULL,
  replicate = 1,
  seed = seq(1, replicate, 1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simra_+3A_itempar">itempar</code></td>
<td>
<p>a &quot;matrix&quot; with <code>nrow = k</code> (number of items) and ncol = m (maximum number of thresholds), holding the 'thurstonian' thresholds of the respective item. Some of the rightmost matrix entries may be NA, depending on the number of categories of the respective item.</p>
</td></tr>
<tr><td><code id="simra_+3A_theta">theta</code></td>
<td>
<p>either one of the following (1) a numeric vector of length <code>n</code> providing the values of the person parameter (ability) for <code>n</code> persons to be used in the simulation. (2) a integer defining the number of values <code>n</code> to draw from N(0|1).</p>
</td></tr>
<tr><td><code id="simra_+3A_pers_obj">pers_obj</code></td>
<td>
<p>an object of class <code>"pers"</code> as a result from function <code><a href="#topic+pers">pers</a></code>. If an object of class <code>"pers"</code> is assigned to this argument the model parameters in it are taken to simulate the responses. At default (<code>pers_obj = NULL</code>) simulation is done by considering the model parameters given in the other arguments (see above).</p>
</td></tr>
<tr><td><code id="simra_+3A_replicate">replicate</code></td>
<td>
<p>an integer defining how many replicates (data matrices) <code>r</code> to draw based on the model parameters.</p>
</td></tr>
<tr><td><code id="simra_+3A_seed">seed</code></td>
<td>
<p>a numeric vector with legnth of number of replications used for <code><a href="base.html#topic+set.seed">set.seed</a></code> prior to each replicate to keep the result repeatable. If <code>seed = NULL</code> no seed is set.</p>
</td></tr>
<tr><td><code id="simra_+3A_...">...</code></td>
<td>
<p>arguments passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no details in the moment.
</p>


<h3>Value</h3>

<p>an array with <code>dim(n,k,r)</code> response patterns (<code>k</code> items in colums <code>n</code> persons in rows and <code>r</code> replications in the third dimension).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
simra() # 100 dichotomous probabilistic response pattern
### 100 polytomous response pattern (4 items; each 4 answer categories)
v &lt;- c(-1.0,-0.5,0.0,0.5,-0.75,-0.25,0.25,0.75,-0.5,0.0,0.5,1.0)
itempar &lt;- matrix(v,nrow = 4,ncol = 3)
simra(itempar = itempar)
simra(itempar = itempar,replicate = 10) # draw 10 replications

</code></pre>

<hr>
<h2 id='summary.grm'>S3 Summary for graphical Model Check</h2><span id='topic+summary.grm'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>c("grm","list")</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grm'
summary(object, ci = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.grm_+3A_object">object</code></td>
<td>
<p>object of class<code>c("grm","list")</code></p>
</td></tr>
<tr><td><code id="summary.grm_+3A_ci">ci</code></td>
<td>
<p>numeric with default <code>ci=2</code> to return cinfidence intervalls for point estimator.</p>
</td></tr>
<tr><td><code id="summary.grm_+3A_...">...</code></td>
<td>
<p>other parameters passed trough</p>
</td></tr>
</table>

<hr>
<h2 id='summary.pair'>S3 Summary for Item Parameter</h2><span id='topic+summary.pair'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>"pair"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pair'
summary(object, sortdif = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pair_+3A_object">object</code></td>
<td>
<p>object of class<code>"pair"</code></p>
</td></tr>
<tr><td><code id="summary.pair_+3A_sortdif">sortdif</code></td>
<td>
<p>logical with default <code>sortdif=FALSE</code> whether to order items by difficulty.</p>
</td></tr>
<tr><td><code id="summary.pair_+3A_...">...</code></td>
<td>
<p>other parameters passed trough</p>
</td></tr>
</table>

<hr>
<h2 id='summary.pairS'>S3 Summary for S-Statistic Test (Wald Test)</h2><span id='topic+summary.pairS'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>"pairS"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pairS'
summary(object, thres = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pairS_+3A_object">object</code></td>
<td>
<p>object of class<code>"pairS"</code></p>
</td></tr>
<tr><td><code id="summary.pairS_+3A_thres">thres</code></td>
<td>
<p>logical whether to output results based on the thresholds</p>
</td></tr>
<tr><td><code id="summary.pairS_+3A_...">...</code></td>
<td>
<p>other parameters passed trough</p>
</td></tr>
</table>

<hr>
<h2 id='summary.pairSE'>S3 Summary for Item Parameter with Standard Errors</h2><span id='topic+summary.pairSE'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>c("pairSE","list")</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pairSE'
summary(object, sortdif = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pairSE_+3A_object">object</code></td>
<td>
<p>object of class<code>c("pairSE","list")</code></p>
</td></tr>
<tr><td><code id="summary.pairSE_+3A_sortdif">sortdif</code></td>
<td>
<p>logical with default <code>sortdif=FALSE</code> wether to order items by difficulty.</p>
</td></tr>
<tr><td><code id="summary.pairSE_+3A_...">...</code></td>
<td>
<p>other parameters passed trough</p>
</td></tr>
</table>

<hr>
<h2 id='summary.pairwiseSepRel'>S3 Summary for Person Separation Reliability</h2><span id='topic+summary.pairwiseSepRel'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>"pairwiseSepRel"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pairwiseSepRel'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pairwiseSepRel_+3A_object">object</code></td>
<td>
<p>object of class<code>"pairwiseSepRel"</code></p>
</td></tr>
<tr><td><code id="summary.pairwiseSepRel_+3A_...">...</code></td>
<td>
<p>other parameters passed trough</p>
</td></tr>
</table>

<hr>
<h2 id='summary.pers'>S3 Summary for Thetas</h2><span id='topic+summary.pers'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>"pers"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pers'
summary(object, short = TRUE, sortwle = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pers_+3A_object">object</code></td>
<td>
<p>object of class<code>"pers"</code></p>
</td></tr>
<tr><td><code id="summary.pers_+3A_short">short</code></td>
<td>
<p>logical with default <code>short=TRUE</code> - if set to <code>short=FALSE</code> a &quot;data.frame&quot; with WLE estimates (and their respective standard errors) for every row (person) in the original dataset will be returned.</p>
</td></tr>
<tr><td><code id="summary.pers_+3A_sortwle">sortwle</code></td>
<td>
<p>logical wether to order persons by ability - ignored when <code>short=TRUE</code></p>
</td></tr>
<tr><td><code id="summary.pers_+3A_...">...</code></td>
<td>
<p>other parameters passed trough</p>
</td></tr>
</table>

<hr>
<h2 id='summary.pifit'>S3 Summary for Item-Fit-Statistics</h2><span id='topic+summary.pifit'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>c("pifit", "data.frame" )</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pifit'
summary(
  object,
  sort = FALSE,
  by = "INFIT.ZSTD",
  decreasing = FALSE,
  relative = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pifit_+3A_object">object</code></td>
<td>
<p>object of class<code>"pifit", "data.frame" </code></p>
</td></tr>
<tr><td><code id="summary.pifit_+3A_sort">sort</code></td>
<td>
<p>logical with default <code>sort=FALSE</code> - if set to <code>sort=TRUE</code> items are ordered by absolute FIT.</p>
</td></tr>
<tr><td><code id="summary.pifit_+3A_by">by</code></td>
<td>
<p>character passing the type of Fit-Statistic to sort by - ignored when <code>sort=FALSE</code>. valid options are: <code>"INFIT.ZSTD"</code> (default), <code>"OUTFIT.MSQ"</code>, <code>"OUTFIT.ZSTD"</code> and <code>"INFIT.MSQ"</code>.</p>
</td></tr>
<tr><td><code id="summary.pifit_+3A_decreasing">decreasing</code></td>
<td>
<p>see <code><a href="base.html#topic+order">order</a></code></p>
</td></tr>
<tr><td><code id="summary.pifit_+3A_relative">relative</code></td>
<td>
<p>logical with default <code>relative=FALSE</code> to return the fit statistics as proposed by Wright &amp; Masters, (1982, P. 100) with no further modifications. If <code>relative=TRUE</code> the sample adjusted fit statistics are returned in a way that their mean (for the present sample) equals 1 using formula: fit_i+ = 1 – mean(fit).</p>
</td></tr>
<tr><td><code id="summary.pifit_+3A_...">...</code></td>
<td>
<p>other parameters passed trough - see <code><a href="base.html#topic+order">order</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Wright, B. D., &amp; Masters, G. N. (1982). <em>Rating Scale Analysis.</em> Chicago: MESA Press.
</p>
<p>Wright, B. D., &amp; Masters, G. N. (1990). Computation of OUTFIT and INFIT Statistics. <em>Rasch Measurement Transactions, 3</em>(4), 84–85.
</p>

<hr>
<h2 id='summary.ppfit'>S3 Summary for Person-Fit-Statistics</h2><span id='topic+summary.ppfit'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>c("ppfit", "data.frame" )</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ppfit'
summary(
  object,
  sort = FALSE,
  by = "INFIT.ZSTD",
  decreasing = FALSE,
  relative = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ppfit_+3A_object">object</code></td>
<td>
<p>object of class<code>"ppfit", "data.frame" </code></p>
</td></tr>
<tr><td><code id="summary.ppfit_+3A_sort">sort</code></td>
<td>
<p>logical with default <code>sort=FALSE</code> - if set to <code>sort=TRUE</code> persons are ordered by absolute FIT.</p>
</td></tr>
<tr><td><code id="summary.ppfit_+3A_by">by</code></td>
<td>
<p>character passing the type of Fit-Statistic to sort by - ignored when <code>sort=FALSE</code>. valid options are: <code>"INFIT.ZSTD"</code> (default), <code>"OUTFIT.MSQ"</code>, <code>"OUTFIT.ZSTD"</code> and <code>"INFIT.MSQ"</code>.</p>
</td></tr>
<tr><td><code id="summary.ppfit_+3A_decreasing">decreasing</code></td>
<td>
<p>see <code><a href="base.html#topic+order">order</a></code></p>
</td></tr>
<tr><td><code id="summary.ppfit_+3A_relative">relative</code></td>
<td>
<p>logical with default <code>relative=FALSE</code> to return the fit statistics as proposed by Wright &amp; Masters, (1982, P. 100) with no further modifications. If <code>relative=TRUE</code> the sample adjusted fit statistics are returned in a way that their mean (for the present sample) equals 1 using formula: fit_i+ = 1 – mean(fit).</p>
</td></tr>
<tr><td><code id="summary.ppfit_+3A_...">...</code></td>
<td>
<p>other parameters passed trough - see <code><a href="base.html#topic+order">order</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Wright, B. D., &amp; Masters, G. N. (1982). <em>Rating Scale Analysis.</em> Chicago: MESA Press.
</p>
<p>Wright, B. D., &amp; Masters, G. N. (1990). Computation of OUTFIT and INFIT Statistics. <em>Rasch Measurement Transactions, 3</em>(4), 84–85.
</p>

<hr>
<h2 id='summary.q3'>S3 Summary for Q3 Fit Statistic</h2><span id='topic+summary.q3'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>"q3"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'q3'
summary(object, maxrc = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.q3_+3A_object">object</code></td>
<td>
<p>object of class<code>"q3"</code></p>
</td></tr>
<tr><td><code id="summary.q3_+3A_maxrc">maxrc</code></td>
<td>
<p>numerical with default <code>maxrc=3</code> to specify the output of the maximum number of highest residual correlations in terms of absolute value.</p>
</td></tr>
<tr><td><code id="summary.q3_+3A_...">...</code></td>
<td>
<p>other parameters passed trough</p>
</td></tr>
</table>

<hr>
<h2 id='summary.rfa'>S3 Summary for Rasch Factor Analysis</h2><span id='topic+summary.rfa'></span>

<h3>Description</h3>

<p>S3 summary method for object of class<code>"pair"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rfa'
summary(object, sortdif = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rfa_+3A_object">object</code></td>
<td>
<p>object of class<code>"pair"</code></p>
</td></tr>
<tr><td><code id="summary.rfa_+3A_sortdif">sortdif</code></td>
<td>
<p>logical with default <code>sortdif=FALSE</code> wether to order items / persons by difficulty / ability.</p>
</td></tr>
<tr><td><code id="summary.rfa_+3A_...">...</code></td>
<td>
<p>other parameters passed trough</p>
</td></tr>
</table>

<hr>
<h2 id='tff'>Test information function</h2><span id='topic+tff'></span>

<h3>Description</h3>

<p>plotting function for plotting the test information function (TIF).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tff(
  pair_obj,
  items = NULL,
  x = NULL,
  main = "Test Information Function",
  plot = TRUE,
  cat = FALSE,
  lwd = 2,
  col = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tff_+3A_pair_obj">pair_obj</code></td>
<td>
<p>an object of class <code>"pair"</code> as a result from function <code><a href="#topic+pair">pair</a></code>.</p>
</td></tr>
<tr><td><code id="tff_+3A_items">items</code></td>
<td>
<p>optional a vector (character or numeric) identifying the items (according their order in the data) to use for plotting the test information function.</p>
</td></tr>
<tr><td><code id="tff_+3A_x">x</code></td>
<td>
<p>The value(s) of the latent variable, at which the TIF will be evaluated. <code>x</code> should be either a numeric vector of theta values or a single numeric value. If <code>x</code> is given as a single numeric value plotting is supressed. If not given (default), 99 values spaced evenly between -4 and +4 will be used, handy for plotting.</p>
</td></tr>
<tr><td><code id="tff_+3A_main">main</code></td>
<td>
<p>see parameters for <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="tff_+3A_plot">plot</code></td>
<td>
<p>a logical (default <code>plot = TRUE</code>), defining wether to supress plotting an just return a matrix of the values of the Item information function.</p>
</td></tr>
<tr><td><code id="tff_+3A_cat">cat</code></td>
<td>
<p>a logical (default <code>cat = FALSE</code>), defining wether to plot as an overlay to the Test information function the item category information functions based on item categories. If <code>cat = TRUE</code> and <code>plot = FALSE</code> the values of the item category information functions are returned.</p>
</td></tr>
<tr><td><code id="tff_+3A_lwd">lwd</code></td>
<td>
<p>see parameters for <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="tff_+3A_col">col</code></td>
<td>
<p>see parameters for <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="tff_+3A_...">...</code></td>
<td>
<p>arguments passed to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>no details in the moment.
</p>


<h3>Value</h3>

<p>a plot, a &quot;data.frame&quot; or a single numeric with values of the Test information function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########
data(sim200x3)
result &lt;- pair(sim200x3)
tff(pair_obj = result) # TIF plot 
tff(pair_obj = result, cat=TRUE) # TIF plot 
tff(pair_obj = result, items=c("V1","V3"), cat=TRUE) # TIF plot 
tff(pair_obj = result, x=0) # TIF at theta=0 
tff(pair_obj = result, x=seq(0,4,.1)) # TIF for a given range of Thetas
##### examples with other data ...
data(bfiN)
result &lt;- pair(bfiN)
tff(pair_obj = result)
tff(pair_obj = result, cat=TRUE) # TIF plot 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
