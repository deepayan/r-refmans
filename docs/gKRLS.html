<!DOCTYPE html><html><head><title>Help for package gKRLS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gKRLS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calculate_effects'><p>Marginal Effects</p></a></li>
<li><a href='#create_sketched_kernel'><p>Create the sketched kernel</p></a></li>
<li><a href='#estfun.gam'><p>Estimating Robust/Clustered Standard Errors with <code>mgcv</code></p></a></li>
<li><a href='#gKRLS'><p>Generalized Kernel Regularized Least Squares</p></a></li>
<li><a href='#legacy_marginal_effect'><p>Analytical Average Marginal Effects</p></a></li>
<li><a href='#ml_gKRLS'><p>Machine Learning with gKRLS</p></a></li>
<li><a href='#mlr3_gKRLS'><p>mlr3 integration</p></a></li>
<li><a href='#Predict.matrix.gKRLS.smooth'><p>Predict Methods for gKRLS smooth</p></a></li>
<li><a href='#smooth.construct.gKRLS.smooth.spec'><p>Constructor for gKRLS smooth</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Generalized Kernel Regularized Least Squares</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-4-17</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Description:</td>
<td>Kernel regularized least squares, also known as kernel ridge regression, 
    is a flexible machine learning method. This package implements this method by 
    providing a smooth term for use with 'mgcv' and uses random sketching to 
    facilitate scalable estimation on large datasets. It provides additional 
    functions for calculating marginal effects after estimation and for use with 
    ensembles ('SuperLearning'), double/debiased machine learning ('DoubleML'), 
    and robust/clustered standard errors ('sandwich'). Chang and Goplerud (2023)
    &lt;<a href="https://arxiv.org/abs/2209.14355">arXiv:2209.14355</a>&gt; provide further details.</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.6), Matrix, mlr3, R6</td>
</tr>
<tr>
<td>Depends:</td>
<td>mgcv, sandwich (&ge; 2.4.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>SuperLearner, mlr3misc, DoubleML, testthat</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mgoplerud/gKRLS">https://github.com/mgoplerud/gKRLS</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mgoplerud/gKRLS/issues">https://github.com/mgoplerud/gKRLS/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-19 20:11:46 UTC; MHG23</td>
</tr>
<tr>
<td>Author:</td>
<td>Qing Chang [aut],
  Max Goplerud [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Max Goplerud &lt;mgoplerud@pitt.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-20 09:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='calculate_effects'>Marginal Effects</h2><span id='topic+calculate_effects'></span><span id='topic+calculate_interactions'></span><span id='topic+get_individual_effects'></span><span id='topic+print.gKRLS_mfx'></span><span id='topic+summary.gKRLS_mfx'></span>

<h3>Description</h3>

<p>These functions calculate marginal effects or predicted values after
estimating a model with <code>gam</code> or <code>bam</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate_effects(
  model,
  data = NULL,
  variables = NULL,
  continuous_type = c("IQR", "minmax", "derivative", "onesd", "predict",
    "second_derivative"),
  conditional = NULL,
  individual = FALSE,
  vcov = NULL,
  raw = FALSE,
  use_original = FALSE,
  epsilon = 1e-07,
  verbose = FALSE
)

calculate_interactions(
  model,
  variables,
  QOI = c("AMIE", "ACE", "AME", "AIE"),
  ...
)

get_individual_effects(x)

## S3 method for class 'gKRLS_mfx'
print(x, ...)

## S3 method for class 'gKRLS_mfx'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate_effects_+3A_model">model</code></td>
<td>
<p>A model estimated using functions from <code>mgcv</code> (e.g.,
<code>gam</code> or <code>bam</code>).</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_data">data</code></td>
<td>
<p>A data frame that is used to calculate the marginal effect or set
to <code>NULL</code> which will employ the data used when estimating the model.
The default is <code>NULL</code>. Using a custom dataset may have unexpected
implications for continuous and character/factor variables. See &quot;WARNINGS&quot;
for more discussion.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_variables">variables</code></td>
<td>
<p>A character vector that specifies the variables for which to
calculate effects. The default, <code>NULL</code>, calculates effects for all
variables.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_continuous_type">continuous_type</code></td>
<td>
<p>A character value, with a default of <code>"IQR"</code>,
that indicates the type of marginal effects to estimate when the variable
is continuous (i.e. not binary, logical, factor, or character). Options are
<code>"IQR"</code> (compares the variable at its 25% and 75% percentile),
<code>"minmax"</code> (compares the variable at its minimum and maximum),
<code>"derivative"</code> (numerically approximates the derivative at each
observed value), <code>"second_derivative"</code> (numerically approximates the
second derivative at each observed value), <code>"onesd"</code> (compares one
standard deviation below and one standard deviation above the mean of the
variable). It also accepts a named list where each named element
corresponds to a continuous variable and has a two-length vector as each
element. The two values are then compared. If this is used, then all
continuous variables must have two values specified.
</p>
<p>A special option (<code>"predict"</code>) produces predictions (e.g.,
<code>predict(model, type = "response")</code>) at each observed value and then
averages them together. This, in conjunction with <code>conditional</code>,
provides a way of calculating quantities such as predicted probability
curves using an &quot;observed value&quot; approach (e.g., Hanmer and Kalkan 2013).
Examples are provided below.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_conditional">conditional</code></td>
<td>
<p>A data.frame or <code>NULL</code>. This is an analogue of
Stata's <code>at()</code> option and the <code>at</code> argument in the <code>margins</code>
package. For a marginal effect on some variable <code>"a"</code>, this specifies
fixed values for certain other covariates, e.g. <code>data.frame("b" = 0)</code>.
If <code>conditional</code> is <code>NULL</code>, all other covariates are held at
their observed value. If <code>conditional</code> is a data.frame, then each row
represents a different combination of covariate values to be held fixed,
and marginal effects are calculated separately for each row. Examples are
provided below.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_individual">individual</code></td>
<td>
<p>A logical value. <code>TRUE</code> calculates individual effects (i.e.
an effect for each observation in the <code>data</code>). The default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_vcov">vcov</code></td>
<td>
<p>A matrix that specifies the covariance matrix of the parameters.
The default, <code>NULL</code>, uses the standard covariance matrix from
<code>mgcv</code>. This can be used to specify clustered or robust standard
errors using output from (for example) <code>sandwich</code>.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_raw">raw</code></td>
<td>
<p>A logical value. <code>TRUE</code> returns the raw values used to
calculate the effect in addition to the estimated effect. The default is
<code>FALSE</code>. If <code>TRUE</code>, an additional column <code>...id</code> is present
in the estimated effects that reports whether the row corresponds to the
effect (<code>effect</code>), the first value (<code>raw_0</code>) or the second value
(<code>raw_1</code>) where <code>effect=raw_1 - raw_0</code>. For <code>"derivative"</code>,
this is further scaled by the step size. For <code>"second_derivative"</code>,
<code>effect=raw_2 - 2 * raw_1 + raw_0</code>, scaled by the step size; see the
discussion for <code>epsilon</code> for how the step size is calculated.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_use_original">use_original</code></td>
<td>
<p>A logical value that indicates whether to use the
estimation data (<code>TRUE</code>) or <code>data</code> (<code>FALSE</code>) when
calculating quantities such as the IQR for continuous variables or the
levels to examine for factor variables. Default (<code>FALSE</code>) uses the
provided data; if <code>data = NULL</code>, this is equivalent to using the
estimation data. The &quot;WARNINGS&quot; section provides more discussion of this
option.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_epsilon">epsilon</code></td>
<td>
<p>A numerical value that defines the step size when calculating
numerical derivatives (default of 1e-7).  For <code>"derivative"</code>, the step
size for the approximation is  <code class="reqn">h = \epsilon \cdot \mathrm{max}(1,
  \mathrm{max}(|x|))</code>, i.e. <code class="reqn">f'(x)
  \approx \frac{f(x+h) - f(x-h)}{2h}</code>. Please
see Leeper (2016) for more details.
</p>
<p>For <code>"second_derivative"</code>, the step size is <code class="reqn">h = [\epsilon \cdot
  \mathrm{max}(1, \mathrm{max}(|x|))]^{0.5}</code>, i.e. <code class="reqn">f''(x) \approx \frac{f(x+h) - 2 f(x) +
  f(x-h)}{h^2}</code></p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_verbose">verbose</code></td>
<td>
<p>A logical value that indicates whether to report progress when
calculating the marginal effects. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_qoi">QOI</code></td>
<td>
<p>A vector of quantities of interest calculate for
<code>calculate_interactions</code>. Options include <code>"AME"</code> (average
marginal effect), <code>"ACE"</code> (average combination effect), <code>"AIE"</code>
(average interaction effect) and <code>"AMIE"</code> (average marginal
interaction effect); see &quot;Details&quot; for more information. The default
setting calculates all four quantities.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_...">...</code></td>
<td>
<p>An argument used for <code>calculate_interactions</code> to pass
arguments to <code>calculate_effects</code>. It is unused for
<code>summary.gKRLS_mfx</code>.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_x">x</code></td>
<td>
<p>An object estimated using <code>calculate_effects</code>.</p>
</td></tr>
<tr><td><code id="calculate_effects_+3A_object">object</code></td>
<td>
<p>A model estimated using functions from <code>mgcv</code> (e.g.,
<code>gam</code> or <code>bam</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Overview:</b> <code>calculate_effects</code> returns a data.frame of
class <code>"gKRLS_mfx"</code> that reports the estimated average marginal effects
and standard errors. Other columns include <code>"type"</code> that reports the
type of marginal effect calculated. For families with multiple predicted
outcomes (e.g., multinomial), the column <code>"response"</code> numbers the
different outcomes in the same order as <code>predict.gam(object)</code> for the
specified family. Many (but not all) extended and generalized families from
<code>mgcv</code> are included.
</p>
<p>The <code>conditional</code> argument while setting <code>continuous_type =
"predict"</code> can be used to estimate predicted values at different covariate
strata (e.g., to create an &quot;observed value&quot; predicted probability curve for a
logistic regression). The examples provide an illustration.
</p>
<p><b>Interactions:</b> <code>calculate_interactions</code> provides some simple
functions for calculating interaction effects between variables. The default
quantities it can produce are listed below. Egami and Imai (2019) provide a
detailed exposition of these quantities. All marginalization is done using an
&quot;observed value&quot; approach, i.e. over the estimation data or a custom dataset
provided to <code>data</code>. </p>
 <ul>
<li><p>&quot;AME&quot; or Average Marginal Effect: 
This is the standard quantity reported from <code>calculate_effects</code>.
</p>
</li>
<li><p>&quot;ACE&quot; or Average Combination Effect:  This is the effect of changing
two variables simultaneously on the outcome. </p>
</li>
<li><p>&quot;AMIE&quot; or Average Marginal
Interaction Effect:  This is ACE minus each corresponding AME. </p>
</li>
<li><p>&quot;AIE&quot;
or Average Interaction Effect: This has a &quot;conditional effect&quot;
interpretation and reports the difference in average effect of one variable
(&quot;A&quot;) between two different levels of a second variable (&quot;B&quot;). </p>
</li></ul>

<p><b>Other Functions:</b> <code>get_individual_effects</code> extracts the
individual-level effects that are estimated if <code>individual=TRUE</code>.
</p>


<h3>Value</h3>

<p>Both <code>calculate_effects</code> and <code>calculate_interactions</code> return
data.frames. <code>calculate_effects</code> contains attributes&mdash;including the
ones noted below&mdash;that may be useful for other analyses. </p>

<ul>
<li><p>&quot;gradient&quot;:  This contains the gradients used to calculate the
standard error (via the delta method) for the estimates from
<code>calculate_effects</code>. There is one column for each quantity calculated in
the main object. The format of this object depends on the family used for
<code>gam</code> or <code>bam</code>. This could be used manually to calculate a standard error on the
difference between two estimated marginal effects.
</p>
</li>
<li><p>&quot;N_eff&quot;: The number of observations (in the estimation data) minus the
effective degrees of freedom. This is used when calculating p-values as the
degrees of freedom for the t-distribution. </p>
</li>
<li><p>&quot;N&quot;: The number of
observations. </p>
</li></ul>



<h3>WARNINGS</h3>

<p>Using a custom dataset for <code>data</code>, i.e. a dataset other than the
estimation data, may have unexpected implications. For continuous and
character/factor variables, the estimated marginal effects may depend on
the distribution of the variable in <code>data</code>. For example, if
<code>continuous_type="IQR"</code>, the variable <code>x1</code> is counterfactually
set to <code>quantile(data$x1, 0.25)</code> and <code>quantile(data$x1, 0.75)</code>
where <code>data</code> is provided by <code>calculate_effects</code> (versus the
estimation data). To force this range to be set based on the
<em>estimation</em> data, set <code>use_original=TRUE</code>.
</p>
<p>This default behavior if <code>data</code> is provided may be undesirable and
thus <code>calculate_effects</code> will issue a warning if this situation arises
and a custom <code>data</code> is provided. These settings are subject to change
in future releases.
</p>


<h3>References</h3>

<p>Egami, Naoki and Kosuke Imai. 2019. &quot;Causal Interaction in Factorial
Experiments: Application to Conjoint Analysis.&quot; <em>Journal of the American
Statistical Association</em>. 114(526):529-540.
</p>
<p>Hanmer, Michael J. and Kerem Ozan Kalkan. 2013. &quot;Behind the Curve: Clarifying
the Best Approach to Calculating Predicted Probabilities and Marginal Effects
from Limited Dependent Variable Models.&quot; <em>American Journal of Political
Science</em> 57(1): 263-277.
</p>
<p>Leeper, Thomas J. 2016. &quot;Interpreting Regression Results using Average
Marginal Effects with R's <code>margins</code>.&quot; Working paper available at
<a href="https://s3.us-east-2.amazonaws.com/tjl-sharing/assets/AverageMarginalEffects.pdf">https://s3.us-east-2.amazonaws.com/tjl-sharing/assets/AverageMarginalEffects.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(654)
n &lt;- 50
x1 &lt;- rnorm(n)
x2 &lt;- rnorm(n)
x3 &lt;- rnorm(n)
state &lt;- sample(letters[1:5], n, replace = TRUE)
y &lt;- 0.3 * x1 + 0.4 * x2 + 0.5 * x3 + rnorm(n)
data &lt;- data.frame(y, x1, x2, x3, state)

# Make character variables into factors for mgcv
data$state &lt;- factor(data$state)

# A gKRLS model
fit_gKRLS &lt;- mgcv::gam(y ~ state + s(x1, x2, x3, bs = "gKRLS"), data = data)

# calculate marginal effect using derivative
calculate_effects(fit_gKRLS, variables = "x1", continuous_type = "derivative")

# calculate marginal effect by specifying conditional variables
calculate_effects(fit_gKRLS,
  variables = "x1",
  conditional = data.frame(x2 = c(0.6, 0.8), x3 = 0.3)
)

# calculate interaction effects between two variables
# use the default setting ("IQR") for the baseline and
# comparison categories for each variable
calculate_interactions(fit_gKRLS,
   variables = list(c("x1", "x2")),
   QOI = c('AIE', 'AMIE')
)

# calculate marginal effect by specifying a factor conditional variable
# estimate the individual marginal effects
out &lt;- calculate_effects(fit_gKRLS,
  variables = "x1", individual = TRUE,
  conditional = data.frame(state = c("a", "b", "c")), continuous_type = "derivative"
)

# Extract the individual marginal effects:
# shorthand for attr(fit_main, 'individual')
get_individual_effects(out)

# calculated the average expected value across a grid of "x1"
# using an observed value approach for the other covariates
calculate_effects(fit_gKRLS, conditional = data.frame(x1 = c(0, 0.2, 0.4, 0.6)),
  continuous_type = 'predict'
)
</code></pre>

<hr>
<h2 id='create_sketched_kernel'>Create the sketched kernel</h2><span id='topic+create_sketched_kernel'></span>

<h3>Description</h3>

<p>Create the sketched kernel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_sketched_kernel(X_test, X_train, S, bandwidth)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_sketched_kernel_+3A_x_test">X_test</code></td>
<td>
<p>Test data</p>
</td></tr>
<tr><td><code id="create_sketched_kernel_+3A_x_train">X_train</code></td>
<td>
<p>Train data</p>
</td></tr>
<tr><td><code id="create_sketched_kernel_+3A_s">S</code></td>
<td>
<p>Sketch matrix</p>
</td></tr>
<tr><td><code id="create_sketched_kernel_+3A_bandwidth">bandwidth</code></td>
<td>
<p>Kernel bandwidth</p>
</td></tr>
</table>

<hr>
<h2 id='estfun.gam'>Estimating Robust/Clustered Standard Errors with <code>mgcv</code></h2><span id='topic+estfun.gam'></span>

<h3>Description</h3>

<p>This extracts the score of the log-likelihood for each observation for a
model estimated using <code>gam</code> or <code>bam</code>. It is necessary to allow
<code>mgcv</code> to work correctly with functions from <code>sandwich</code> to product
cluster or robust standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gam'
estfun(x, correct_df = TRUE, override_check = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estfun.gam_+3A_x">x</code></td>
<td>
<p>A model estimated using <code>gam</code> or <code>bam</code>.</p>
</td></tr>
<tr><td><code id="estfun.gam_+3A_correct_df">correct_df</code></td>
<td>
<p>The default, <code>TRUE</code>, adjusts <code>sandwich</code> to use the
effective degrees of freedom for <code>k</code> instead of the number of columns
of the design. <code>FALSE</code> uses <code>k</code>.</p>
</td></tr>
<tr><td><code id="estfun.gam_+3A_override_check">override_check</code></td>
<td>
<p>The default, <code>FALSE</code>, allows this function to be
used inside of <code>sandwich</code>. If only the matrix of scores is required,
set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="estfun.gam_+3A_...">...</code></td>
<td>
<p>Not used for <code>estfun.gam</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix used internally for <code>sandwich</code>.
</p>

<hr>
<h2 id='gKRLS'>Generalized Kernel Regularized Least Squares</h2><span id='topic+gKRLS'></span>

<h3>Description</h3>

<p>This page documents how to use <code>gKRLS</code> as part of a model estimated with
<code>mgcv</code>. Post-estimation functions to calculate marginal effects are
documented elsewhere, e.g. <a href="#topic+calculate_effects">calculate_effects</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gKRLS(
  sketch_method = "subsampling",
  standardize = "Mahalanobis",
  bandwidth = NULL,
  sketch_multiplier = 5,
  sketch_size_raw = NULL,
  sketch_prob = NULL,
  rescale_penalty = TRUE,
  truncate.eigen.tol = sqrt(.Machine$double.eps),
  demean_kernel = FALSE,
  remove_instability = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gKRLS_+3A_sketch_method">sketch_method</code></td>
<td>
<p>A string that specifies which kernel sketching method
should be used (default of <code>"subsampling"</code>). Options include
<code>"subsampling"</code>, <code>"gaussian"</code>, <code>"bernoulli"</code>, or
<code>"none"</code> (no sketching). Drineas et al. (2005) and Yang et al. (2017)
provide more details on these options.
</p>
<p>To force <code>"subsampling"</code> to select a specific set of observations, you
can provide a vector of row positions to <code>sketch_method</code>. This
manually sets the size of the sketching multiplier, implicitly overriding
other options in <code>gKRLS</code>. The examples provide an illustration.</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_standardize">standardize</code></td>
<td>
<p>A string that specifies how the data is standardized
before calculating the distance between observations. The default is
<code>"Mahalanobis"</code> (i.e., demeaned and transformed to have an identity
covariance matrix). Other options are <code>"scaled"</code> (all columns are
scaled to have mean zero and variance of one) or <code>"none"</code> (no
standardization).</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_bandwidth">bandwidth</code></td>
<td>
<p>A bandwidth <code class="reqn">P</code> for the kernel where each element of
the kernel <code class="reqn">(i,j)</code> is defined by <code class="reqn">\exp(-||x_i - x_j||^2_2/P)</code>.</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_sketch_multiplier">sketch_multiplier</code></td>
<td>
<p>A number that sets the size of the sketching
dimension: <code>sketch_multiplier * ceiling(N^(1/3))</code> where <code>N</code> is
the number of observations. The default is 5; Chang and Goplerud (2023)
find that increasing this to 15 may improve stability for certain complex
kernels. <code>sketch_size_raw</code> can directly set the size of the sketching
dimension.</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_sketch_size_raw">sketch_size_raw</code></td>
<td>
<p>A number to set the exact size of the sketching
dimension. The default, <code>NULL</code>, means that this argument is not used
and the size depends on the number of observations; see
<code>sketch_multiplier</code>. Exactly one of <code>sketch_size_raw</code> or
<code>sketch_multiplier</code> must be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_sketch_prob">sketch_prob</code></td>
<td>
<p>A probability for an element of the sketching matrix to
equal <code>1</code> when using Bernoulli sketching. Yang et al. (2017) provide
more details.</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_rescale_penalty">rescale_penalty</code></td>
<td>
<p>A logical value for whether the penalty should be
rescaled for numerical stability. See documentation for
<code>mgcv::smooth.spec</code> on the meaning of this term. The default is
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_truncate.eigen.tol">truncate.eigen.tol</code></td>
<td>
<p>A threshold to remove columns of the penalty
<code class="reqn">S K S^T</code> whose eigenvalues are small (below
<code>truncate.eigen.tol</code>). These columns are removed from the sketched
kernel and avoids instability due to numerically very small eigenvalues. The
default is <code>sqrt(.Machine$double.eps)</code>. This adjustment can be
disabled by setting <code>remove_instability = FALSE</code>.</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_demean_kernel">demean_kernel</code></td>
<td>
<p>A logical value that indicates whether columns of the
(sketched) kernel should be demeaned before estimation. The default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gKRLS_+3A_remove_instability">remove_instability</code></td>
<td>
<p>A logical value that indicates whether numerical
zeros (set via <code>truncate.eigen.tol</code>) should be removed when building
the penalty matrix. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Overview:</b> The <code>gKRLS</code> function should not be called directly. Its
options, described above, control how <code>gKRLS</code> is estimated. It should be
passed to <code>mgcv</code> as follows: <code>s(x1, x2, x3, bs = "gKRLS", xt =
gKRLS(...))</code>. Multiple kernels can be specified and have different
<code>gKRLS</code> arguments. It can also be used alongside the existing options
for <code>s()</code> in <code>mgcv</code>.
</p>
<p><b>Default Settings:</b> By default, <code>bs = "gKRLS"</code> uses Mahalanobis
distance between the observations, random sketching using subsampling
sketching (i.e., where the kernel is constructed using a random sample of the
observations; Yang et al. 2017) and a sketching dimension of <code>5 *
ceiling(N^(1/3))</code> where <code>N</code> is the number of observations. Chang and
Goplerud (2023) provide an exploration of alternative options.
</p>
<p><b>Notes:</b> Please note that variables must be separated with commas inside
of <code>s(...)</code> and that character variables should usually be passed as
factors to work smoothly with <code>mgcv</code>. When using this function with
<code>bam</code>, the sketching dimension uses <code>chunk.size</code> in place of
<code>N</code> and thus either <code>chunk.size</code> or <code>sketch_size_raw</code> must be used to cause
the sketching dimension to increase with <code>N</code>.
</p>


<h3>Value</h3>

<p><code>gKRLS</code> returns a named list with the elements in &quot;Arguments&quot;.
</p>


<h3>References</h3>

<p>Chang, Qing and Max Goplerud. 2023. &quot;Generalized Kernel Regularized Least
Squares&quot;. <a href="https://arxiv.org/abs/2209.14355">https://arxiv.org/abs/2209.14355</a>.
</p>
<p>Drineas, Petros and Mahoney, Michael W and Nello Cristianini. 2005. &quot;On the
Nyström Method for Approximating a Gram Matrix For Improved Kernel-Based
Learning&quot;. <em>Journal of Machine Learning Research</em> 6(12):2153-2175.
</p>
<p>Yang, Yun and Pilanci, Mert and Martin J. Wainwright. 2017. &quot;Randomized
Sketches for Kernels: Fast and Optimal Nonparametric Regression&quot;.
<em>Annals of Statistics</em> 45(3):991-1023.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 100
x1 &lt;- rnorm(n)
x2 &lt;- rnorm(n)
x3 &lt;- rnorm(n)
state &lt;- sample(letters[1:5], n, replace = TRUE)
y &lt;- 0.3 * x1 + 0.4 * x2 + 0.5 * x3 + rnorm(n)
data &lt;- data.frame(y, x1, x2, x3, state)
data$state &lt;- factor(data$state)
# A gKRLS model without fixed effects
fit_gKRLS &lt;- mgcv::gam(y ~ s(x1, x2, x3, bs = "gKRLS"), data = data)
summary(fit_gKRLS)
# A gKRLS model with fixed effects outside of the kernel
fit_gKRLS_FE &lt;- mgcv::gam(y ~ state + s(x1, x2, x3, bs = "gKRLS"), data = data)

# HC3 is not available for mgcv; this uses the effective degrees of freedom
# instead of the number of columns; see ?estfun.gam for details
robust &lt;- sandwich::vcovHC(fit_gKRLS, type = 'HC1')
cluster &lt;- sandwich::vcovCL(fit_gKRLS, cluster = data$state)

# Change default standardization to "scaled", sketch method to Gaussian,
# and alter sketching multiplier
fit_gKRLS_alt &lt;- mgcv::gam(y ~ s(x1, x2, x3,
  bs = "gKRLS",
  xt = gKRLS(
    standardize = "scaled",
    sketch_method = "gaussian",
    sketch_multiplier = 2
  )
),
data = data
)
# A model with multiple kernels
fit_gKRLS_2 &lt;- mgcv::gam(y ~ s(x1, x2, bs = 'gKRLS') + s(x1, x3, bs = 'gKRLS'), data = data)
# A model with a custom set of ids for sketching
id &lt;- sample(1:n, 5)
fit_gKRLS_custom &lt;- mgcv::gam(y ~ s(x1, bs = 'gKRLS', xt = gKRLS(sketch_method = id)), data = data)
# Note that the ids of the sampled observations can be extracted 
# from the fitted mgcv object
stopifnot(identical(id, fit_gKRLS_custom$smooth[[1]]$subsampling_id))
# calculate marginal effect (see ?calculate_effects for more examples)
calculate_effects(fit_gKRLS, variables = "x1")
</code></pre>

<hr>
<h2 id='legacy_marginal_effect'>Analytical Average Marginal Effects</h2><span id='topic+legacy_marginal_effect'></span>

<h3>Description</h3>

<p>This function is consider &quot;legacy&quot; and may be removed in future
updates. It calculates the (average) marginal effect and standard error by
taking the analytical derivative of the conditional expectation function
and only works in limited scenarios.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>legacy_marginal_effect(model, data = NULL, variables = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="legacy_marginal_effect_+3A_model">model</code></td>
<td>
<p>A model estimated using functions from <code>mgcv</code> (e.g., <code>gam</code> or <code>bam</code>).</p>
</td></tr>
<tr><td><code id="legacy_marginal_effect_+3A_data">data</code></td>
<td>
<p>A data frame that is used to calculate the marginal effect or set
to <code>NULL</code> which will employ the data used when estimating the model.
The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="legacy_marginal_effect_+3A_variables">variables</code></td>
<td>
<p>A character vector that specifies the variables for which to
calculate effects. The default, <code>NULL</code>, calculates effects for all
variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is designed to provide comparability with the original
<code>KRLS</code> package, but is rather limited in the scenarios where it can be
applied (e.g., limited families, limited specifications of linear
predictions, limited numbers of smooth/penalized terms, etc.)
</p>
<p>Because of these restrictions, users should rely on
<code>calculate_effects</code> as this function may be removed in future updates.
A numerical approximation to the derivative found analytically in this
function is provided in <a href="#topic+calculate_effects">calculate_effects</a>.
</p>


<h3>Value</h3>

<p>The function returns a list that contains the following elements:
</p>

<ul>
<li><p>&quot;ME_pointwise&quot;:  The marginal effects for each observation.
</p>
</li>
<li><p>&quot;ME_pointwise_var&quot;:  The variance for each pointwise marginal effect
in &quot;ME_pointwise&quot;.
</p>
</li>
<li><p>&quot;AME_pointwise&quot;:  The average marginal effect, i.e. the column
averages of &quot;ME_pointwise&quot;.
</p>
</li>
<li><p>&quot;AME_pointwise_var&quot;:  The variance of each average marginal effect.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(321)
n &lt;- 100
x1 &lt;- rnorm(n)
x2 &lt;- rnorm(n)
x3 &lt;- rnorm(n)
state &lt;- sample(letters, n, replace = TRUE)
y &lt;- 0.3 * x1 + 0.4 * x2 + 0.5 * x3 + rnorm(n)
data &lt;- data.frame(y, x1, x2, x3, state)

# A gKRLS model
fit_gKRLS &lt;- mgcv::gam(y ~ s(x1, x2, x3, bs = "gKRLS"), data = data)
# calculate marginal effect using derivative
legacy_marginal_effect(fit_gKRLS)

</code></pre>

<hr>
<h2 id='ml_gKRLS'>Machine Learning with gKRLS</h2><span id='topic+ml_gKRLS'></span><span id='topic+SL.mgcv'></span><span id='topic+predict.SL.mgcv'></span><span id='topic+add_bam_to_mlr3'></span>

<h3>Description</h3>

<p>This provides a number of functions to use <code>gKRLS</code> (and
<code>mgcv</code> more generally) as part of machine learning algorithms.
Integration into <code>SuperLearner</code> and <code>DoubleML</code> (and <code>mlr3</code>)
is described below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SL.mgcv(Y, X, newX, formula, family, obsWeights, bam = FALSE, ...)

## S3 method for class 'SL.mgcv'
predict(object, newdata, allow_missing_levels = TRUE, ...)

add_bam_to_mlr3()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ml_gKRLS_+3A_y">Y</code></td>
<td>
<p>This is not usually directly specified in <code>SL.mgcv</code>, see the
examples below and documentation in <code>SuperLearner</code> for more details.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_x">X</code></td>
<td>
<p>This is not usually directly specified in <code>SL.mgcv</code>, see the
examples below and documentation in <code>SuperLearner</code> for more details.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_newx">newX</code></td>
<td>
<p>This is not usually directly specified in <code>SL.mgcv</code>, see the
examples below and documentation in <code>SuperLearner</code> for more details.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_formula">formula</code></td>
<td>
<p>A formula used for <code>gam</code> or <code>bam</code> from
<code>mgcv</code>. This must be specified, see the examples.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_family">family</code></td>
<td>
<p>This is not usually directly specified in <code>SL.mgcv</code>, see
the examples below and documentation in <code>SuperLearner</code> for more
details.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_obsweights">obsWeights</code></td>
<td>
<p>This is not usually directly specified in <code>SL.mgcv</code>,
see the examples below and documentation in <code>SuperLearner</code> for more
details.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_bam">bam</code></td>
<td>
<p>A logical value for whether <code>mgcv::bam</code> should be used
instead of <code>mgcv::gam</code>. Default is <code>FALSE</code>. For large datasets,
this can dramatically improve estimation time. Wood et al. (2015) and
<code>mgcv</code> provide details on <code>bam</code>.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code>mgcv::gam</code> and <code>mgcv::bam</code>.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_object">object</code></td>
<td>
<p>This is not usually directly specified in <code>SL.mgcv</code>, see
the examples below and documentation in <code>SuperLearner</code> for more
details.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_newdata">newdata</code></td>
<td>
<p>This is not usually directly specified in <code>SL.mgcv</code>, see
the examples below and documentation in <code>SuperLearner</code> for more
details.</p>
</td></tr>
<tr><td><code id="ml_gKRLS_+3A_allow_missing_levels">allow_missing_levels</code></td>
<td>
<p>A logical variable that indicates whether missing
levels in factors are allowed for prediction. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Ensembles:</b> <code>SuperLearner</code> integration is provided by
<code>SL.mgcv</code> and the corresponding predict method. <code>mgcv::bam</code> can be
enabled by using <code>bam = TRUE</code>. A formula <b>without an outcome</b>
must be explicitly provided.
</p>
<p>Please note that it is often useful to load <code>SuperLearner</code> before
<code>gKRLS</code> or <code>mgcv</code> to avoid functions including <code>gam</code> and
<code>s</code> being masked from other packages.
</p>
<p><b>Double Machine Learning</b>: <code>DoubleML</code> integration is provided in
two ways. First, one could load <code>mlr3extralearners</code> to access
<code>regr.gam</code> and <code>classif.gam</code>.
</p>
<p>Second, this package provides <code>mgcv::bam</code> integration directly with a
slight adaption of the <code>mlr3extralearner</code> implementation (see
<code>?LearnerClassifBam</code> for more details). These can be either manually
added to the list of <code>mlr3</code> learners by calling
<code>add_bam_to_mlr3()</code> or direct usage. Examples are provided below. For
<code>classif.bam</code> and <code>regr.bam</code>, the formula argument is mandatory.
</p>


<h3>Value</h3>

<p>All three of the returned functions are usually called for use in
other functions, i.e. creating objects for use in <code>SuperLearner</code> or
adding <code>bam</code> models to <code>mlr3</code>.
</p>


<h3>References</h3>

<p>Wood, Simon N and Goude, Yannig and Simon Shaw. 2015. &quot;Generalized Additive
Models for Large Data Sets.&quot; <em>Journal of the Royal Statistical Society:
Series C (Applied Statistics)</em> 64(1):139-155.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(789)
N &lt;- 100
x1 &lt;- rnorm(N)
x2 &lt;- rbinom(N, size = 1, prob = .2)
y &lt;- x1^3 - 0.5 * x2 + rnorm(N, 0, 1)
y &lt;- y * 10
X &lt;- cbind(x1, x2, x1 + x2 * 3)
X &lt;- cbind(X, "x3" = rexp(nrow(X)))

if (requireNamespace("SuperLearner", quietly = TRUE)) {
# Estimate Ensemble with SuperLearner
  require(SuperLearner)
  sl_m &lt;- function(...) { SL.mgcv(formula = ~ x1 + x2 + x3, ...) }
  fit_SL &lt;- SuperLearner::SuperLearner(
    Y = y, X = data.frame(X),
    SL.library = "sl_m"
  )
  pred &lt;- predict(fit_SL, newdata = data.frame(X))
}
# Estimate Double/Debiased Machine Learning
if (requireNamespace("DoubleML", quietly = TRUE)) {
  require(DoubleML)
  # Load the models; for testing *ONLY* have multiplier of 2
  double_bam_1 &lt;- LearnerRegrBam$new()
  double_bam_1$param_set$values$formula &lt;- ~ s(x1, x3, bs = "gKRLS", 
    xt = gKRLS(sketch_multiplier = NULL, sketch_size_raw = 2))
  double_bam_2 &lt;- LearnerClassifBam$new()
  double_bam_2$param_set$values$formula &lt;- ~ s(x1, x3, bs = "gKRLS", 
    xt = gKRLS(sketch_multiplier = NULL, sketch_size_raw = 2))

  # Create data
  dml_data &lt;- DoubleMLData$new(
    data = data.frame(X, y),
    x_cols = c("x1", "x3"), y_col = "y",
    d_cols = "x2"
  )
  # Estimate effects treatment (works for other DoubleML methods)
  dml_est &lt;- DoubleMLIRM$new(
    data = dml_data,
    n_folds = 2,
    ml_g = double_bam_1,
    ml_m = double_bam_2
  )$fit()
}
</code></pre>

<hr>
<h2 id='mlr3_gKRLS'>mlr3 integration</h2><span id='topic+mlr3_gKRLS'></span><span id='topic+LearnerRegrBam'></span><span id='topic+LearnerClassifBam'></span>

<h3>Description</h3>

<p>This documents <code>LearnerRegrBam</code> and
<code>LearnerClassifBam</code> that allow for <code>mgcv::bam</code> to be used in
<code>mlr3</code> without explicitly loading <code>mlr3extralearners</code>. See
<a href="#topic+ml_gKRLS">ml_gKRLS</a> for examples of how to use this and <code>mlr3</code> for
discussion of the &quot;Learner&quot; objects.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code><a href="mlr3.html#topic+LearnerRegr">mlr3::LearnerRegr</a></code> -&gt; <code>LearnerRegrBam</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerRegrBam-new"><code>LearnerRegrBam$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerRegrBam-clone"><code>LearnerRegrBam$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerRegrBam-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this [R6][R6::R6Class] class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerRegrBam$new()</pre></div>


<hr>
<a id="method-LearnerRegrBam-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerRegrBam$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Super classes</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code><a href="mlr3.html#topic+LearnerClassif">mlr3::LearnerClassif</a></code> -&gt; <code>LearnerClassifBam</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerClassifBam-new"><code>LearnerClassifBam$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerClassifBam-clone"><code>LearnerClassifBam$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href='../../mlr3/html/Learner.html#method-Learner-format'><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href='../../mlr3/html/Learner.html#method-Learner-print'><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerClassifBam-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this [R6][R6::R6Class] class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerClassifBam$new()</pre></div>


<hr>
<a id="method-LearnerClassifBam-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerClassifBam$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Wood, Simon N and Goude, Yannig and Simon Shaw. 2015. &quot;Generalized Additive
Models for Large Data Sets.&quot; <em>Journal of the Royal Statistical Society:
Series C (Applied Statistics)</em> 64(1):139-155.
</p>

<hr>
<h2 id='Predict.matrix.gKRLS.smooth'>Predict Methods for gKRLS smooth</h2><span id='topic+Predict.matrix.gKRLS.smooth'></span>

<h3>Description</h3>

<p>Predict Methods for gKRLS smooth
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gKRLS.smooth'
Predict.matrix(object, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.matrix.gKRLS.smooth_+3A_object">object</code></td>
<td>
<p>a smooth object; see documentation for other methods in
<code>mgcv</code>.</p>
</td></tr>
<tr><td><code id="Predict.matrix.gKRLS.smooth_+3A_data">data</code></td>
<td>
<p>a data.frame; see documentation for other methods in
<code>mgcv</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='smooth.construct.gKRLS.smooth.spec'>Constructor for gKRLS smooth</h2><span id='topic+smooth.construct.gKRLS.smooth.spec'></span>

<h3>Description</h3>

<p>Constructor for gKRLS smooth
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gKRLS.smooth.spec'
smooth.construct(object, data, knots)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.construct.gKRLS.smooth.spec_+3A_object">object</code></td>
<td>
<p>a smooth object; see documentation for other methods in
<code>mgcv</code>.</p>
</td></tr>
<tr><td><code id="smooth.construct.gKRLS.smooth.spec_+3A_data">data</code></td>
<td>
<p>a data.frame; see documentation for other methods in
<code>mgcv</code>.</p>
</td></tr>
<tr><td><code id="smooth.construct.gKRLS.smooth.spec_+3A_knots">knots</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the function <a href="#topic+gKRLS">gKRLS</a> for details.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
