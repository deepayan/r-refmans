<!DOCTYPE html><html lang="en"><head><title>Help for package arc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {arc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#applyCut'><p>Apply Cut Points to Vector</p></a></li>
<li><a href='#applyCuts'><p>Apply Cut Points to Data Frame</p></a></li>
<li><a href='#cba'><p>CBA Classifier</p></a></li>
<li><a href='#cba_manual'><p>CBA Classifier from provided rules</p></a></li>
<li><a href='#cbaCSV'><p>Example CBA Workflow with CSV Input</p></a></li>
<li><a href='#cbaIris'><p>Test CBA Workflow on Iris Dataset</p></a></li>
<li><a href='#cbaIrisNumeric'><p>Test CBA Workflow on Iris Dataset with numeric target</p></a></li>
<li><a href='#CBARuleModel-class'><p>CBARuleModel</p></a></li>
<li><a href='#CBARuleModelAccuracy'><p>Prediction Accuracy</p></a></li>
<li><a href='#discretizeUnsupervised'><p>Unsupervised Discretization</p></a></li>
<li><a href='#discrNumeric'><p>Discretize Numeric Columns In Data frame</p></a></li>
<li><a href='#getAppearance'><p>Method that generates items for values in given data frame column.</p></a></li>
<li><a href='#getConfVectorForROC'><p>Returns vector with confidences for the positive class (useful for ROC or AUC computation)</p></a></li>
<li><a href='#humtemp'><p>Comfort level based on temperature and humidity of the environment</p></a></li>
<li><a href='#mdlp2'><p>Supervised Discretization</p></a></li>
<li><a href='#predict.CBARuleModel'><p>Apply Rule Model</p></a></li>
<li><a href='#prune'><p>Classifier Builder</p></a></li>
<li><a href='#topRules'><p>Rule Generation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Association Rule Classification</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Tomas Kliegr [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tomas Kliegr &lt;kliegr@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the Classification-based on
    Association Rules (CBA) algorithm for association rule classification.
    The package, also described in Hahsler et al. (2019) &lt;<a href="https://doi.org/10.32614%2FRJ-2019-048">doi:10.32614/RJ-2019-048</a>&gt;,
    contains several convenience methods that allow to automatically
    set CBA parameters (minimum confidence, minimum support) and it also natively
    handles numeric attributes by integrating a pre-discretization step.
    The rule generation phase is handled by the 'arules' package. 
    To further decrease the size of the CBA models produced by the 'arc' package, postprocessing by the 
    'qCBA' package is suggested.</td>
</tr>
<tr>
<td>Copyright:</td>
<td>The mdlp2.R script reuses parts of the code from the R
`discretization` package by HyunJi Kim (GPL license).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.3), arules (&ge; 1.7-4), R.utils, discretization</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kliegr/arc">https://github.com/kliegr/arc</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kliegr/arc/issues">https://github.com/kliegr/arc/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix (&ge; 0.5-0), methods, datasets</td>
</tr>
<tr>
<td>Suggests:</td>
<td>qCBA</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-17 12:58:41 UTC; tomas</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-17 15:52:37 UTC</td>
</tr>
</table>
<hr>
<h2 id='applyCut'>Apply Cut Points to Vector</h2><span id='topic+applyCut'></span>

<h3>Description</h3>

<p>Applies cut points to vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>applyCut(col, cuts, infinite_bounds, labels)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="applyCut_+3A_col">col</code></td>
<td>
<p>input vector with data.</p>
</td></tr>
<tr><td><code id="applyCut_+3A_cuts">cuts</code></td>
<td>
<p>vector with cutpoints.
There are several special values defined:
<code>NULL</code> indicates that no discretization will be performed, but the value will be converted to factor
<code>"All"</code> indicates all values will be merged into one.</p>
</td></tr>
<tr><td><code id="applyCut_+3A_infinite_bounds">infinite_bounds</code></td>
<td>
<p>a logical indicating how the bounds on the extremes should look like.
If set to <code>FALSE</code>, the leftmost/rightmost intervals will be bounded by the minimum and maximum in the respective column.
If set to <code>TRUE</code>, the leftmost/rightmost intervals will be bounded by negative and positive infinity.</p>
</td></tr>
<tr><td><code id="applyCut_+3A_labels">labels</code></td>
<td>
<p>a logical indicating whether the bins of the discretized data should be represented by integer codes or as interval notation using (a;b] when set to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with discretized data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+applyCuts">applyCuts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  applyCut(datasets::iris[[1]], c(3,6), TRUE, TRUE)
</code></pre>

<hr>
<h2 id='applyCuts'>Apply Cut Points to Data Frame</h2><span id='topic+applyCuts'></span>

<h3>Description</h3>

<p>Applies cut points to input data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>applyCuts(df, cutp, infinite_bounds, labels)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="applyCuts_+3A_df">df</code></td>
<td>
<p>input data frame.</p>
</td></tr>
<tr><td><code id="applyCuts_+3A_cutp">cutp</code></td>
<td>
<p>a list of vectors with cutpoints (for more information see <code><a href="#topic+applyCut">applyCut</a></code>).</p>
</td></tr>
<tr><td><code id="applyCuts_+3A_infinite_bounds">infinite_bounds</code></td>
<td>
<p>a logical indicating how the bounds on the extremes should look like (for more information see <code><a href="#topic+applyCut">applyCut</a></code>)</p>
</td></tr>
<tr><td><code id="applyCuts_+3A_labels">labels</code></td>
<td>
<p>a logical indicating whether the bins of the discretized data should be represented by integer codes or as interval notation using (a;b] when set to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>discretized data. If there was no discretization specified for some columns, these are returned as is.
</p>


<h3>See Also</h3>

<p>applyCut
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  applyCuts(datasets::iris, list(c(5,6), c(2,3), "All", NULL, NULL), TRUE, TRUE)

</code></pre>

<hr>
<h2 id='cba'>CBA Classifier</h2><span id='topic+cba'></span>

<h3>Description</h3>

<p>Learns a CBA rule set from supplied dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cba(train, classAtt, rulelearning_options = NULL, pruning_options = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cba_+3A_train">train</code></td>
<td>
<p>a data frame with data.</p>
</td></tr>
<tr><td><code id="cba_+3A_classatt">classAtt</code></td>
<td>
<p>the name of the class attribute.</p>
</td></tr>
<tr><td><code id="cba_+3A_rulelearning_options">rulelearning_options</code></td>
<td>
<p>custom options for the rule learning algorithm overriding the default values.
If not specified, the the   <a href="#topic+topRules">topRules</a> function is called and defaults specified there are used<br />
<code>target_rule_count</code> (int) mining stops when the resulting rule set contains this number of rules; <br />
<code>trim</code> (boolean) if set to TRUE and more than <code>target_rule_count</code> is discovered, only first <code>target_rule_count</code> rules will be returned. <br />
<code>minsupp</code> (float)  minimum support threshold  <br />
<code>minconf</code> (float) minimum confidence threshold <br />
<code>minlen</code> (int) minimum length of rules, minlen=1 corresponds to rule with empty antecedent and one item in consequent. In general, rules with empty antecedent are not desirable for the subsequent pruning algorithm, therefore the value of this parameter should be set at least to value 2. <br />
<code>maxlen</code>  (int) maximum length of rules, should be equal or higher than minlen. A higher value may decrease the number of iterations to obtain target_rule_count rules, but it also increases the risk of initial combinatorial explosion and subsequent memory crash of the apriori rule learner. <br />
<code>maxtime</code> (int) maximum number of seconds it should take 'apriori' to obtain rules. <br />
<code>find_conf_supp_thresholds</code> (boolean) whether to use automatic threshold detection or not. <br /></p>
</td></tr>
<tr><td><code id="cba_+3A_pruning_options">pruning_options</code></td>
<td>
<p>custom options for the pruning algorithm overriding the default values. <br /></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <a href="#topic+CBARuleModel">CBARuleModel</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Example using automatic threshold detection
 cba(datasets::iris, "Species", rulelearning_options = list(target_rule_count = 50000))
 # Example using manually set confidence and support thresholds
 rm &lt;- cba(datasets::iris, "Species", rulelearning_options = list(minsupp=0.01,
   minconf=0.5, minlen=1, maxlen=5, maxtime=1000, target_rule_count=50000, trim=TRUE,
   find_conf_supp_thresholds=FALSE))
 inspect(rm@rules)
</code></pre>

<hr>
<h2 id='cba_manual'>CBA Classifier from provided rules</h2><span id='topic+cba_manual'></span>

<h3>Description</h3>

<p>Learns a CBA rule set from supplied rules
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cba_manual(
  train_raw,
  rules,
  txns,
  rhs,
  classAtt,
  cutp,
  pruning_options = list(input_list_sorted_by_length = FALSE)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cba_manual_+3A_train_raw">train_raw</code></td>
<td>
<p>a data frame with raw data (numeric attributes are not discretized).</p>
</td></tr>
<tr><td><code id="cba_manual_+3A_rules">rules</code></td>
<td>
<p>Rules class instance  output by the apriori package</p>
</td></tr>
<tr><td><code id="cba_manual_+3A_txns">txns</code></td>
<td>
<p>Transactions class instance  passed to  the arules method invocation. Transactions are created over discretized data frame  - numeric values are replaced  with intervals such as &quot;(13;45]&quot;.</p>
</td></tr>
<tr><td><code id="cba_manual_+3A_rhs">rhs</code></td>
<td>
<p>character vectors giving the labels of the items which can appear in the RHS
($rhs element of the APappearance class instance passed to the arules call)</p>
</td></tr>
<tr><td><code id="cba_manual_+3A_classatt">classAtt</code></td>
<td>
<p>the name of the class attribute.</p>
</td></tr>
<tr><td><code id="cba_manual_+3A_cutp">cutp</code></td>
<td>
<p>list of cutpoints used to discretize data (required for application of the model on continuous data)</p>
</td></tr>
<tr><td><code id="cba_manual_+3A_pruning_options">pruning_options</code></td>
<td>
<p>custom options for the pruning algorithm overriding the default values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <a href="#topic+CBARuleModel">CBARuleModel</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(humtemp)
  data_raw&lt;-humtemp
  data_discr &lt;- humtemp

  #custom discretization
  data_discr[,1]&lt;-cut(humtemp[,1],breaks=seq(from=15,to=45,by=5))
  data_discr[,2]&lt;-cut(humtemp[,2],breaks=c(0,40,60,80,100))

  #change interval syntax from (15,20] to (15;20], which is required by MARC
  data_discr[,1]&lt;-as.factor(unlist(lapply(data_discr[,1], function(x) {gsub(",", ";", x)})))
  data_discr[,2]&lt;-as.factor(unlist(lapply(data_discr[,2], function(x) {gsub(",", ";", x)})))
  data_discr[,3] &lt;- as.factor(humtemp[,3])

  #mine rules
  classAtt="Class"
  appearance &lt;- getAppearance(data_discr, classAtt)
  txns_discr &lt;- as(data_discr, "transactions")
  rules &lt;- apriori(txns_discr, parameter =
   list(confidence = 0.5, support= 3/nrow(data_discr), minlen=1, maxlen=5), appearance=appearance)
  inspect(rules)


  rmCBA &lt;- cba_manual(data_raw,  rules, txns_discr, appearance$rhs,
  classAtt, cutp= list(), pruning_options=NULL)
  inspect (rmCBA@rules)
  prediction &lt;- predict(rmCBA,data_discr,discretize=FALSE)
  acc &lt;- CBARuleModelAccuracy(prediction, data_discr[[classAtt]])
  print(paste("Accuracy:",acc))
</code></pre>

<hr>
<h2 id='cbaCSV'>Example CBA Workflow with CSV Input</h2><span id='topic+cbaCSV'></span>

<h3>Description</h3>

<p>Learns a CBA rule set and saves the resulting rule set back to csv.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cbaCSV(
  path,
  outpath = NULL,
  classAtt = NULL,
  idcolumn = NULL,
  rulelearning_options = NULL,
  pruning_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cbaCSV_+3A_path">path</code></td>
<td>
<p>path to csv file with data.</p>
</td></tr>
<tr><td><code id="cbaCSV_+3A_outpath">outpath</code></td>
<td>
<p>path to write the rule set to.</p>
</td></tr>
<tr><td><code id="cbaCSV_+3A_classatt">classAtt</code></td>
<td>
<p>the name of the class attribute.</p>
</td></tr>
<tr><td><code id="cbaCSV_+3A_idcolumn">idcolumn</code></td>
<td>
<p>the name of the id column in the dataf ile.</p>
</td></tr>
<tr><td><code id="cbaCSV_+3A_rulelearning_options">rulelearning_options</code></td>
<td>
<p>custom options for the rule learning algorithm overriding the default values.</p>
</td></tr>
<tr><td><code id="cbaCSV_+3A_pruning_options">pruning_options</code></td>
<td>
<p>custom options for the pruning algorithm overriding the default values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <a href="#topic+CBARuleModel">CBARuleModel</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # cbaCSV("path-to-.csv")


</code></pre>

<hr>
<h2 id='cbaIris'>Test CBA Workflow on Iris Dataset</h2><span id='topic+cbaIris'></span>

<h3>Description</h3>

<p>Test workflow on iris dataset: learns a cba classifier on one &quot;train set&quot; fold , and applies it to the second  &quot;test set&quot; fold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cbaIris()
</code></pre>


<h3>Value</h3>

<p>Accuracy.
</p>

<hr>
<h2 id='cbaIrisNumeric'>Test CBA Workflow on Iris Dataset with numeric target</h2><span id='topic+cbaIrisNumeric'></span>

<h3>Description</h3>

<p>Test workflow on iris dataset: learns a cba classifier on one &quot;train set&quot; fold, and applies it to the second  &quot;test set&quot; fold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cbaIrisNumeric()
</code></pre>


<h3>Value</h3>

<p>Accuracy.
</p>

<hr>
<h2 id='CBARuleModel-class'>CBARuleModel</h2><span id='topic+CBARuleModel-class'></span><span id='topic+CBARuleModel'></span>

<h3>Description</h3>

<p>This class represents a rule-based classifier.
</p>


<h3>Slots</h3>


<dl>
<dt><code>rules</code></dt><dd><p>an object of class rules from arules package</p>
</dd>
<dt><code>cutp</code></dt><dd><p>list of cutpoints</p>
</dd>
<dt><code>classAtt</code></dt><dd><p>name of the target class attribute</p>
</dd>
<dt><code>attTypes</code></dt><dd><p>attribute types</p>
</dd>
</dl>

<hr>
<h2 id='CBARuleModelAccuracy'>Prediction Accuracy</h2><span id='topic+CBARuleModelAccuracy'></span>

<h3>Description</h3>

<p>Compares predictions with true labels and outputs accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CBARuleModelAccuracy(prediction, groundtruth)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CBARuleModelAccuracy_+3A_prediction">prediction</code></td>
<td>
<p>vector with predictions</p>
</td></tr>
<tr><td><code id="CBARuleModelAccuracy_+3A_groundtruth">groundtruth</code></td>
<td>
<p>vector with true labels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Accuracy
</p>

<hr>
<h2 id='discretizeUnsupervised'>Unsupervised Discretization</h2><span id='topic+discretizeUnsupervised'></span>

<h3>Description</h3>

<p>Discretizes provided numeric vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discretizeUnsupervised(
  data,
  labels = FALSE,
  infinite_bounds = FALSE,
  categories = 3,
  method = "cluster"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discretizeUnsupervised_+3A_data">data</code></td>
<td>
<p>input numeric vector.</p>
</td></tr>
<tr><td><code id="discretizeUnsupervised_+3A_labels">labels</code></td>
<td>
<p>a logical indicating whether the bins of the discretized data should be represented by integer codes or as interval notation using (a;b] when set to TRUE.</p>
</td></tr>
<tr><td><code id="discretizeUnsupervised_+3A_infinite_bounds">infinite_bounds</code></td>
<td>
<p>a logical indicating how the bounds on the extremes should look like.</p>
</td></tr>
<tr><td><code id="discretizeUnsupervised_+3A_categories">categories</code></td>
<td>
<p>number of categories (bins) to produce.</p>
</td></tr>
<tr><td><code id="discretizeUnsupervised_+3A_method">method</code></td>
<td>
<p>clustering method, one of &quot;interval&quot; (equal interval width), &quot;frequency&quot; (equal frequency), &quot;cluster&quot; (k-means clustering). See also documentation of the <code><a href="arules.html#topic+discretize">discretize</a></code> function from the arules package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Discretized data. If there was no discretization specified for some columns, these are returned as is.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  discretizeUnsupervised(datasets::iris[[1]])

</code></pre>

<hr>
<h2 id='discrNumeric'>Discretize Numeric Columns In Data frame</h2><span id='topic+discrNumeric'></span>

<h3>Description</h3>

<p>Can discretize both predictor columns in  data frame &ndash; using supervised algorithm MDLP (Fayyad &amp; Irani, 1993) &ndash; and the target class &ndash; using unsupervised algorithm (k-Means).
This R file contains fragments of code from the GPL-licensed R discretization package by HyunJi Kim.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discrNumeric(
  df,
  classatt,
  min_distinct_values = 3,
  unsupervised_bins = 3,
  discretize_class = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discrNumeric_+3A_df">df</code></td>
<td>
<p>a data frame with data.</p>
</td></tr>
<tr><td><code id="discrNumeric_+3A_classatt">classatt</code></td>
<td>
<p>name the class attribute in df</p>
</td></tr>
<tr><td><code id="discrNumeric_+3A_min_distinct_values">min_distinct_values</code></td>
<td>
<p>the minimum number of unique values a column needs to have to be subject to supervised discretization.</p>
</td></tr>
<tr><td><code id="discrNumeric_+3A_unsupervised_bins">unsupervised_bins</code></td>
<td>
<p>number of target bins for  discretizing the class attribute. Ignored when the class attribute is not numeric or when <code>discretize_class</code> is set to FALSE.</p>
</td></tr>
<tr><td><code id="discrNumeric_+3A_discretize_class">discretize_class</code></td>
<td>
<p>logical value indicating whether the class attribute should be discretized. Ignored when the class attribute is not numeric.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with two slots: <code>$cutp</code> with cutpoints and <code>$Disc.data</code> with discretization results
</p>


<h3>References</h3>

<p>Fayyad, U. M. and Irani, K. B. (1993). Multi-interval discretization of continuous-valued attributes for classification learning, Artificial intelligence 13, 1022–1027
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  discrNumeric(datasets::iris, "Species")

</code></pre>

<hr>
<h2 id='getAppearance'>Method that generates items for values in given data frame column.</h2><span id='topic+getAppearance'></span>

<h3>Description</h3>

<p>Method that generates items for values in given data frame column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAppearance(df, classAtt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getAppearance_+3A_df">df</code></td>
<td>
<p>a data frame contain column <code>classAtt</code>.</p>
</td></tr>
<tr><td><code id="getAppearance_+3A_classatt">classAtt</code></td>
<td>
<p>name of the column in <code>df</code> to generate items for.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>appearance object for mining classification rules
</p>


<h3>Examples</h3>

<pre><code class='language-R'>getAppearance(datasets::iris,"Species")

</code></pre>

<hr>
<h2 id='getConfVectorForROC'>Returns vector with confidences for the positive class (useful for ROC or AUC computation)</h2><span id='topic+getConfVectorForROC'></span>

<h3>Description</h3>

<p>Methods for computing ROC curves require a vector of confidences
of the positive class, while in CBA, the confidence returned by predict with
outputProbabilies = TRUE returns confidence for the predicted class.
This method converts the values to confidences for the positive class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getConfVectorForROC(confidences, predictedClass, positiveClass)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getConfVectorForROC_+3A_confidences">confidences</code></td>
<td>
<p>Vector of confidences</p>
</td></tr>
<tr><td><code id="getConfVectorForROC_+3A_predictedclass">predictedClass</code></td>
<td>
<p>Vector with predicted classes</p>
</td></tr>
<tr><td><code id="getConfVectorForROC_+3A_positiveclass">positiveClass</code></td>
<td>
<p>Positive class (String)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of confidence values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>predictedClass = c("setosa","virginica")
confidences = c(0.9,0.6)
baseClass="setosa"
getConfVectorForROC(confidences,predictedClass,baseClass)

# Further examples showing how ROC curve and AUC values can be computed
# using this function are available at project's GitHub homepage.
</code></pre>

<hr>
<h2 id='humtemp'>Comfort level based on temperature and humidity of the environment</h2><span id='topic+humtemp'></span>

<h3>Description</h3>

<p>A syntetic toy dataset. The variables are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(humtemp)
</code></pre>


<h3>Format</h3>

<p>A data frame with 34 rows and 3 variables
</p>


<h3>Details</h3>


<ul>
<li><p> Temperature.
</p>
</li>
<li><p> Humidity.
</p>
</li>
<li><p> Class. Comfort level
</p>
</li></ul>


<hr>
<h2 id='mdlp2'>Supervised Discretization</h2><span id='topic+mdlp2'></span>

<h3>Description</h3>

<p>Performs supervised discretization of numeric columns, except class, on the provided data frame. Uses the Minimum Description Length Principle algorithm (Fayyed and Irani, 1993) as implemented in the discretization package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdlp2(
  df,
  cl_index = NULL,
  handle_missing = FALSE,
  labels = FALSE,
  skip_nonnumeric = FALSE,
  infinite_bounds = FALSE,
  min_distinct_values = 3
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mdlp2_+3A_df">df</code></td>
<td>
<p>input data frame.</p>
</td></tr>
<tr><td><code id="mdlp2_+3A_cl_index">cl_index</code></td>
<td>
<p>index of the class variable. If not specified, the last column is used as the class variable.</p>
</td></tr>
<tr><td><code id="mdlp2_+3A_handle_missing">handle_missing</code></td>
<td>
<p>Setting to TRUE activates the following behaviour: if there are any missing observations in the column processed,
the input for discretization is a subset of data containing this column and target with rows containing missing values excuded.</p>
</td></tr>
<tr><td><code id="mdlp2_+3A_labels">labels</code></td>
<td>
<p>A logical indicating whether the bins of the discretized data should be represented by integer codes or as interval notation using (a;b] when set to TRUE.</p>
</td></tr>
<tr><td><code id="mdlp2_+3A_skip_nonnumeric">skip_nonnumeric</code></td>
<td>
<p>If set to TRUE, any non-numeric columns will be skipped.</p>
</td></tr>
<tr><td><code id="mdlp2_+3A_infinite_bounds">infinite_bounds</code></td>
<td>
<p>A logical indicating how the bounds on the extremes should look like.</p>
</td></tr>
<tr><td><code id="mdlp2_+3A_min_distinct_values">min_distinct_values</code></td>
<td>
<p>If a column contains less than specified number of distinct values, it is not discretized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Discretized data. If there were any non-numeric input columns they are returned as is. All returned columns except class are factors.
</p>


<h3>References</h3>

<p>Fayyad, U. M. and Irani, K. B. (1993). Multi-interval discretization of continuous-valued attributes for classification learning, Artificial intelligence 13, 1022–1027
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  mdlp2(datasets::iris) #gives the same result as mdlp(datasets::iris) from discretize package
  #uses Sepal.Length as target variable
  mdlp2(df=datasets::iris, cl_index = 1,handle_missing = TRUE, labels = TRUE,
  skip_nonnumeric = TRUE, infinite_bounds = TRUE, min_distinct_values = 30)

</code></pre>

<hr>
<h2 id='predict.CBARuleModel'>Apply Rule Model</h2><span id='topic+predict.CBARuleModel'></span>

<h3>Description</h3>

<p>Method that matches rule model against test data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CBARuleModel'
predict(
  object,
  data,
  discretize = TRUE,
  outputFiringRuleIDs = FALSE,
  outputConfidenceScores = FALSE,
  confScoreType = "ordered",
  positiveClass = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.CBARuleModel_+3A_object">object</code></td>
<td>
<p>a <a href="#topic+CBARuleModel">CBARuleModel</a> class instance</p>
</td></tr>
<tr><td><code id="predict.CBARuleModel_+3A_data">data</code></td>
<td>
<p>a data frame with data</p>
</td></tr>
<tr><td><code id="predict.CBARuleModel_+3A_discretize">discretize</code></td>
<td>
<p>boolean indicating whether the passed data should be discretized
using information in the passed @cutp slot of the ruleModel argument.</p>
</td></tr>
<tr><td><code id="predict.CBARuleModel_+3A_outputfiringruleids">outputFiringRuleIDs</code></td>
<td>
<p>if set to TRUE, instead of predictions, the function will return one-based IDs of  rules used to classify each instance (one rule per instance).</p>
</td></tr>
<tr><td><code id="predict.CBARuleModel_+3A_outputconfidencescores">outputConfidenceScores</code></td>
<td>
<p>if set to TRUE, instead of predictions, the function will return confidences of the firing rule</p>
</td></tr>
<tr><td><code id="predict.CBARuleModel_+3A_confscoretype">confScoreType</code></td>
<td>
<p>applicable only if 'outputConfidenceScores=TRUE', possible values 'ordered' for confidence computed only for training instances reaching this rule, or 'global' for standard rule confidence computed from the complete training data</p>
</td></tr>
<tr><td><code id="predict.CBARuleModel_+3A_positiveclass">positiveClass</code></td>
<td>
<p>This setting is only used if 'outputConfidenceScores=TRUE'. It should be used only for binary problems. In this
case, the confidence values are recalculated so that these are not confidence values of the predicted class (default behaviour of 'outputConfidenceScores=TRUE')
but rather confidence values associated with the class designated as positive</p>
</td></tr>
<tr><td><code id="predict.CBARuleModel_+3A_...">...</code></td>
<td>
<p>other arguments (currently not used)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with predictions.
</p>


<h3>See Also</h3>

<p><a href="#topic+cbaIris">cbaIris</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  set.seed(101)
  allData &lt;- datasets::iris[sample(nrow(datasets::iris)),]
  trainFold &lt;- allData[1:100,]
  testFold &lt;- allData[101:nrow(allData),]
  #increase for more accurate results in longer time
  target_rule_count &lt;- 1000
  classAtt &lt;- "Species"
  rm &lt;- cba(trainFold, classAtt, list(target_rule_count = target_rule_count))
  prediction &lt;- predict(rm, testFold)
  acc &lt;- CBARuleModelAccuracy(prediction, testFold[[classAtt]])
  message(acc)
  # get rules responsible for each prediction
  firingRuleIDs &lt;- predict(rm, testFold, outputFiringRuleIDs=TRUE)
  # show rule responsible for prediction of test instance no. 28
  inspect(rm@rules[firingRuleIDs[28]])
  # get prediction confidence (three different versions)
  rm@rules[firingRuleIDs[28]]@quality$confidence
  rm@rules[firingRuleIDs[28]]@quality$orderedConf
  rm@rules[firingRuleIDs[28]]@quality$cumulativeConf
</code></pre>

<hr>
<h2 id='prune'>Classifier Builder</h2><span id='topic+prune'></span>

<h3>Description</h3>

<p>An implementation of the CBA-CB M1 algorithm (Liu et al, 1998) adapted for R and arules package apriori implementation in place of CBA-RG.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prune(
  rules,
  txns,
  classitems,
  default_rule_pruning = TRUE,
  rule_window = 50000,
  greedy_pruning = FALSE,
  input_list_sorted_by_length = TRUE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prune_+3A_rules">rules</code></td>
<td>
<p>object of class rules from arules package</p>
</td></tr>
<tr><td><code id="prune_+3A_txns">txns</code></td>
<td>
<p>input object with transactions.</p>
</td></tr>
<tr><td><code id="prune_+3A_classitems">classitems</code></td>
<td>
<p>a list of items to appear in the consequent (rhs) of the rules.</p>
</td></tr>
<tr><td><code id="prune_+3A_default_rule_pruning">default_rule_pruning</code></td>
<td>
<p>boolean indicating whether default pruning should be performed. If set to TRUE, default pruning is performed as in the CBA algorithm.
If set to FALSE, default pruning is not performed i.e. all rules surviving data coverage pruning are kept. In either case, a default rule is added to the end of the classifier.</p>
</td></tr>
<tr><td><code id="prune_+3A_rule_window">rule_window</code></td>
<td>
<p>the number of rules to precompute for CBA data coverage pruning. The default value can be adjusted to decrease runtime.</p>
</td></tr>
<tr><td><code id="prune_+3A_greedy_pruning">greedy_pruning</code></td>
<td>
<p>setting to TRUE activates early stopping condition: pruning will be stopped on first rule on which total error increases.</p>
</td></tr>
<tr><td><code id="prune_+3A_input_list_sorted_by_length">input_list_sorted_by_length</code></td>
<td>
<p>indicates by default that the input rule list is sorted by antecedent length (as output by arules), if this param is set to false, the list will be resorted</p>
</td></tr>
<tr><td><code id="prune_+3A_debug">debug</code></td>
<td>
<p>output debug messages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class rules. Note that 'rules@quality' slot has been extended
with additional measures, specifically 'orderedConf', 'orderedSupp', and 'cumulativeConf'. The rules are output in the order
in which they are assumed to be applied in classification. Only the first applicable rule is used to
classify the instance. As a result, in addition to rule confidence &ndash; which is computed over the
whole training dataset &ndash; it makes sense to define order-sensitive confidence, which is computed
only from instances reaching the given rule as <code class="reqn">a/(a+b)</code>, where <code class="reqn">a</code> is the number of instances
matching both the antecedent and consequent (available in slot 'orderedSupp') and <code class="reqn">b</code> is the number of instances matching the antecedent, but
not matching the consequent of the given rule.  The cumulative confidence is an experimental measure,
which is computed as the accuracy of the rule list comprising the given rule and all higher priority
rules (rules with lower index) with uncovered instances excluded from the computation.
</p>


<h3>References</h3>

<p>Ma, Bing Liu Wynne Hsu Yiming. Integrating classification and association rule mining. Proceedings of the fourth international conference on knowledge discovery and data mining. 1998.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+topRules">topRules</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> #Example 1
  txns &lt;- as(discrNumeric(datasets::iris, "Species")$Disc.data,"transactions")
  appearance &lt;- getAppearance(datasets::iris,"Species")
  rules &lt;- apriori(txns, parameter = list(confidence = 0.5,
  support= 0.01, minlen= 2, maxlen= 4),appearance = appearance)
  prune(rules,txns, appearance$rhs)
  inspect(rules)

#Example 2
 utils::data(Adult) # this dataset comes with the arules package
 classitems &lt;- c("income=small","income=large")
 rules &lt;- apriori(Adult, parameter = list(supp = 0.3, conf = 0.5,
 target = "rules"), appearance=list(rhs=classitems, default="lhs"))
 # produces 25 rules
 rulesP &lt;- prune(rules,Adult,classitems)
 rulesP@quality # inspect rule quality measured including the new additions
 # Rules after data coverage pruning: 8
 # Performing default rule pruning.
 # Final rule list size:  6
</code></pre>

<hr>
<h2 id='topRules'>Rule Generation</h2><span id='topic+topRules'></span>

<h3>Description</h3>

<p>A wrapper for the apriori method from the arules package that iteratively changes mining parameters until a desired number of rules is obtained, all options are exhausted or a preset time limit is reached.
Within the arc package, this function serves as a replacement for the CBA Rule Generation algorithm (Liu et al, 1998) &ndash; without pessimistic pruning &ndash; with general apriori implementation provided by existing fast R package <strong>arules</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topRules(
  txns,
  appearance = list(),
  target_rule_count = 1000,
  init_support = 0,
  init_conf = 0.5,
  conf_step = 0.05,
  supp_step = 0.05,
  minlen = 2,
  init_maxlen = 3,
  iteration_timeout = 2,
  total_timeout = 100,
  max_iterations = 30,
  trim = TRUE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="topRules_+3A_txns">txns</code></td>
<td>
<p>input transactions.</p>
</td></tr>
<tr><td><code id="topRules_+3A_appearance">appearance</code></td>
<td>
<p>object named list or APappearance object (refer to arules package)</p>
</td></tr>
<tr><td><code id="topRules_+3A_target_rule_count">target_rule_count</code></td>
<td>
<p>the main stopping criterion, mining stops when the resulting rule set contains this number of rules.</p>
</td></tr>
<tr><td><code id="topRules_+3A_init_support">init_support</code></td>
<td>
<p>initial support.</p>
</td></tr>
<tr><td><code id="topRules_+3A_init_conf">init_conf</code></td>
<td>
<p>initial confidence.</p>
</td></tr>
<tr><td><code id="topRules_+3A_conf_step">conf_step</code></td>
<td>
<p>confidence will be changed by steps defined by this parameter.</p>
</td></tr>
<tr><td><code id="topRules_+3A_supp_step">supp_step</code></td>
<td>
<p>support will be changed by steps defined by this parameter.</p>
</td></tr>
<tr><td><code id="topRules_+3A_minlen">minlen</code></td>
<td>
<p>minimum length of rules, minlen=1 corresponds to rule with empty antecedent and one item in consequent. In general, rules with empty antecedent are not desirable for the subsequent pruning algorithm, therefore the value of this parameter should be set at least to value 2.</p>
</td></tr>
<tr><td><code id="topRules_+3A_init_maxlen">init_maxlen</code></td>
<td>
<p>maximum length of rules, should be equal or higher than minlen. A higher value may decrease the number of iterations to obtain target_rule_count rules, but it also increases the risk of initial combinatorial explosion and subsequent memory crash of the apriori rule learner.</p>
</td></tr>
<tr><td><code id="topRules_+3A_iteration_timeout">iteration_timeout</code></td>
<td>
<p>maximum number of seconds it should take apriori to obtain rules with current configuration/</p>
</td></tr>
<tr><td><code id="topRules_+3A_total_timeout">total_timeout</code></td>
<td>
<p>maximum number of seconds the mining should take.</p>
</td></tr>
<tr><td><code id="topRules_+3A_max_iterations">max_iterations</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="topRules_+3A_trim">trim</code></td>
<td>
<p>if set to TRUE and more than <code>target_rule_count</code> is discovered, only first <code>target_rule_count</code> rules will be returned.</p>
</td></tr>
<tr><td><code id="topRules_+3A_debug">debug</code></td>
<td>
<p>boolean indicating whether to output debug messages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class rules.
</p>


<h3>References</h3>

<p>Ma, Bing Liu Wynne Hsu Yiming. Integrating classification and association rule mining. Proceedings of the fourth international conference on knowledge discovery and data mining. 1998.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prune">prune</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
  utils::data(Adult)
  rules &lt;- topRules(Adult, appearance = list(), target_rule_count = 100,
  init_support = 0.5,init_conf = 0.9, minlen = 1, init_maxlen = 10)

# Example 2
  rules &lt;- topRules(as(discrNumeric(datasets::iris, "Species")$Disc.data,"transactions"),
  getAppearance(datasets::iris,"Species"))

# Example 3
  utils::data(datasets::iris)
  appearance &lt;- list(rhs =  c("Species=setosa", "Species=versicolor",
   "Species=virginica"), default="lhs")
  data &lt;- sapply(datasets::iris,as.factor)
  data &lt;- data.frame(data, check.names=FALSE)
  txns &lt;- as(data,"transactions")
  rules &lt;- topRules(txns, appearance)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
