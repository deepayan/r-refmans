<!DOCTYPE html><html><head><title>Help for package OptSig</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {OptSig}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#OptSig-package'>
<p>Optimal Level of Significance for Regression and Other Statistical Tests</p></a></li>
<li><a href='#data1'>
<p>Data for the U.S. production function estimation</p></a></li>
<li><a href='#Opt.sig.norm.test'>
<p>Optimal significance level calculation for the mean of a normal distribution (known variance)</p></a></li>
<li><a href='#Opt.sig.t.test'>
<p>Optimal significance level calculation for t-tests of means (one sample, two samples and paired samples)</p></a></li>
<li><a href='#OptSig.2p'>
<p>Optimal significance level calculation for the test for two proportions (same sample sizes)</p></a></li>
<li><a href='#OptSig.2p2n'>
<p>Optimal significance level calculation for the test for two proportions (different sample sizes)</p></a></li>
<li><a href='#OptSig.anova'>
<p>Optimal significance level calculation for balanced one-way analysis of variance tests</p></a></li>
<li><a href='#OptSig.Boot'>
<p>Optimal Significance Level for the F-test using the bootstrap</p></a></li>
<li><a href='#OptSig.BootWeight'>
<p>Weighted Optimal Significance Level for the F-test based on the bootstrap</p></a></li>
<li><a href='#OptSig.Chisq'>
<p>Optimal Significance Level for a Chi-square test</p></a></li>
<li><a href='#OptSig.F'>
<p>Optimal Significance Level for an F-test</p></a></li>
<li><a href='#OptSig.p'>
<p>Optimal significance level calculation for proportion tests (one sample)</p></a></li>
<li><a href='#OptSig.r'>
<p>Optimal significance level calculation for correlation test</p></a></li>
<li><a href='#OptSig.t2n'>
<p>Optimal significance level calculation for two samples (different sizes) t-tests of means</p></a></li>
<li><a href='#OptSig.Weight'>
<p>Weighted Optimal Significance Level for the F-test based on the assumption of normality in the error term</p></a></li>
<li><a href='#Power.Chisq'>
<p>Function to calculate the power of a Chi-square test</p></a></li>
<li><a href='#Power.F'>
<p>Function to calculate the power of an F-test</p></a></li>
<li><a href='#R.OLS'>
<p>Restricted OLS estimation and F-test</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Optimal Level of Significance for Regression and Other
Statistical Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>pwr</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-06-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Jae H. Kim &lt;jaekim8080@gmail.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jae H. Kim &lt;jaekim8080@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The optimal level of significance is calculated based on a decision-theoretic approach. The optimal level is chosen so that the expected loss from hypothesis testing is minimized. A range of statistical tests are covered, including the test for the population mean, population proportion, and a linear restriction in a multiple regression model. 
             The details are covered in Kim and Choi (2020) &lt;<a href="https://doi.org/10.1111%2Fabac.12172">doi:10.1111/abac.12172</a>&gt;, and Kim (2021) &lt;<a href="https://doi.org/10.1080%2F00031305.2020.1750484">doi:10.1080/00031305.2020.1750484</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-03 03:23:48 UTC; jh808</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-03 12:30:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='OptSig-package'>
Optimal Level of Significance for Regression and Other Statistical Tests
</h2><span id='topic+OptSig-package'></span><span id='topic+OptSig'></span>

<h3>Description</h3>

<p>The optimal level of significance is calculated based on a decision-theoretic approach. The optimal level is chosen so that the expected loss from hypothesis testing is minimized. A range of statistical tests are covered, including the test for the population mean, population proportion, and a linear restriction in a multiple regression model. 
             The details are covered in Kim and Choi (2020) &lt;doi:10.1111/abac.12172&gt;, and Kim (2021) &lt;doi:10.1080/00031305.2020.1750484&gt;. 
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> OptSig</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Optimal Level of Significance for Regression and Other Statistical Tests</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.2</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> pwr</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2022-06-29</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Jae H. Kim &lt;jaekim8080@gmail.com&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Jae H. Kim &lt;jaekim8080@gmail.com&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> The optimal level of significance is calculated based on a decision-theoretic approach. The optimal level is chosen so that the expected loss from hypothesis testing is minimized. A range of statistical tests are covered, including the test for the population mean, population proportion, and a linear restriction in a multiple regression model. 
             The details are covered in Kim and Choi (2020) &lt;doi:10.1111/abac.12172&gt;, and Kim (2021) &lt;doi:10.1080/00031305.2020.1750484&gt;. </td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
Opt.sig.norm.test       Optimal significance level calculation for the
                        mean of a normal distribution (known variance)
Opt.sig.t.test          Optimal significance level calculation for
                        t-tests of means (one sample, two samples and
                        paired samples)
OptSig-package          Optimal Level of Significance for Regression
                        and Other Statistical Tests
OptSig.2p               Optimal significance level calculation for the
                        test for two proportions (same sample sizes)
OptSig.2p2n             Optimal significance level calculation for the
                        test for two proportions (different sample
                        sizes)
OptSig.Boot             Optimal Significance Level for the F-test using
                        the bootstrap
OptSig.BootWeight       Weighted Optimal Significance Level for the
                        F-test based on the bootstrap
OptSig.Chisq            Optimal Significance Level for a Chi-square
                        test
OptSig.F                Optimal Significance Level for an F-test
OptSig.Weight           Weighted Optimal Significance Level for the
                        F-test based on the assumption of normality in
                        the error term
OptSig.anova            Optimal significance level calculation for
                        balanced one-way analysis of variance tests
OptSig.p                Optimal significance level calculation for
                        proportion tests (one sample)
OptSig.r                Optimal significance level calculation for
                        correlation test
OptSig.t2n              Optimal significance level calculation for two
                        samples (different sizes) t-tests of means
Power.Chisq             Function to calculate the power of a Chi-square
                        test
Power.F                 Function to calculate the power of an F-test
R.OLS                   Restricted OLS estimation and F-test
data1                   Data for the U.S. production function
                        estimation
</pre>
<p>The package accompanies the paper: Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach. Abacus. Wiley. 
</p>
<p>It oprovides functions for the optimal level of significance for the test for linear restiction in a regeression model. 
</p>
<p>Other basic statistical tests, including those for population mean and proportion, are also covered using the functions from the pwr package.
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim &lt;jaekim8080@gmail.com&gt;
</p>
<p>Maintainer: Jae H. Kim &lt;jaekim8080@gmail.com&gt;
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data1)
y=data1$lnoutput; x=cbind(data1$lncapital,data1$lnlabor)
# Restriction matrices to test for constant returns to scale
Rmat=matrix(c(0,1,1),nrow=1); rvec=matrix(0.94,nrow=1)
# Model Estimation and F-test
M=R.OLS(y,x,Rmat,rvec) 

# Degrees of Freedom and estimate of non-centrality parameter 
K=ncol(x)+1; T=length(y)
df1=nrow(Rmat);df2=T-K; NCP=M$ncp

# Optimal level of Significance: Under Normality
OptSig.F(df1,df2,ncp=NCP,p=0.5,k=1, Figure=TRUE)
</code></pre>

<hr>
<h2 id='data1'>
Data for the U.S. production function estimation
</h2><span id='topic+data1'></span>

<h3>Description</h3>

<p>US production, captal, labour in natrual logs for the year 2005
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data1")</code></pre>


<h3>Format</h3>

<p>A data frame with 51 observations on the following 3 variables.
</p>

<dl>
<dt><code>lnoutput</code></dt><dd><p>natrual log of output</p>
</dd>
<dt><code>lnlabor</code></dt><dd><p>natrual log of labor</p>
</dd>
<dt><code>lncapital</code></dt><dd><p>natrual log of capital</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data contains 51 observations for 50 US states and Washington DC
</p>


<h3>Source</h3>

<p>Gujarati, D. 2015, Econometrics by Example, Second edition, Palgrave.
</p>


<h3>References</h3>

<p>See Section 2.2 of Gujarari (2015)
</p>
<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach, Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data1)
</code></pre>

<hr>
<h2 id='Opt.sig.norm.test'>
Optimal significance level calculation for the mean of a normal distribution (known variance)
</h2><span id='topic+Opt.sig.norm.test'></span>

<h3>Description</h3>

<p>Computes the optimal significance level for the mean of a normal distribution (known variance)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Opt.sig.norm.test(ncp=NULL,d=NULL,n=NULL,p=0.5,k=1,alternative="two.sided",Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Opt.sig.norm.test_+3A_ncp">ncp</code></td>
<td>
<p>Non-centrality parameter</p>
</td></tr>
<tr><td><code id="Opt.sig.norm.test_+3A_d">d</code></td>
<td>
<p>Effect size, Cohen's d</p>
</td></tr>
<tr><td><code id="Opt.sig.norm.test_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code id="Opt.sig.norm.test_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="Opt.sig.norm.test_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="Opt.sig.norm.test_+3A_alternative">alternative</code></td>
<td>

<p>a character string specifying the alternative hypothesis, must be one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;</p>
</td></tr>
<tr><td><code id="Opt.sig.norm.test_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Refer to Kim and Choi (2020) for the details of k and p
</p>
<p>Either ncp or d value should be given. 
</p>
<p>In a general term, if X ~ N(mu,sigma^2); let H0:mu = mu0; and H1:mu = mu1; 
</p>
<p>ncp = sqrt(n)(mu1-mu0)/sigma
</p>
<p>d = (mu1-mu0)/sigma: Cohen's d
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Also refer to the manual for the pwr package
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2019).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.       
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim (using a function from the pwr package)
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Opt.sig.norm.test(d=0.2,n=60,alternative="two.sided")
</code></pre>

<hr>
<h2 id='Opt.sig.t.test'>
Optimal significance level calculation for t-tests of means (one sample, two samples and paired samples)
</h2><span id='topic+Opt.sig.t.test'></span>

<h3>Description</h3>

<p>Computes the optimal significance level for the test for t-tests of means 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Opt.sig.t.test(ncp=NULL,d=NULL,n=NULL,p=0.5,k=1,
             type="one.sample",alternative="two.sided",Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Opt.sig.t.test_+3A_ncp">ncp</code></td>
<td>
<p>Non-centrality parameter</p>
</td></tr>
<tr><td><code id="Opt.sig.t.test_+3A_d">d</code></td>
<td>
<p>Effect size</p>
</td></tr>
<tr><td><code id="Opt.sig.t.test_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code id="Opt.sig.t.test_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="Opt.sig.t.test_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="Opt.sig.t.test_+3A_type">type</code></td>
<td>
<p>Type of t test : one- two- or paired-sample</p>
</td></tr>
<tr><td><code id="Opt.sig.t.test_+3A_alternative">alternative</code></td>
<td>

<p>a character string specifying the alternative hypothesis, must be one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;
</p>
</td></tr>
<tr><td><code id="Opt.sig.t.test_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Refer to Kim and Choi (2020) for the details of k and p
</p>
<p>Either ncp or d value should be given, with the value of n. 
</p>
<p>In a general term, if X ~ N(mu,sigma^2); let H0:mu = mu0; and H1:mu = mu1; 
</p>
<p>ncp = sqrt(n)(mu1-mu0)/sigma
</p>
<p>d = (mu1-mu0)/sigma: Cohen's d
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Also refer to the manual for the pwr package
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.    
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim (using a function from the pwr package)
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Opt.sig.t.test(d=0.2,n=60,type="one.sample",alternative="two.sided")
</code></pre>

<hr>
<h2 id='OptSig.2p'>
Optimal significance level calculation for the test for two proportions (same sample sizes)
</h2><span id='topic+OptSig.2p'></span>

<h3>Description</h3>

<p>Computes the optimal significance level for the test for two proportions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.2p(ncp=NULL,h=NULL,n=NULL,p=0.5,k=1,alternative="two.sided",Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.2p_+3A_ncp">ncp</code></td>
<td>
<p>Non-centrality parameter</p>
</td></tr>
<tr><td><code id="OptSig.2p_+3A_h">h</code></td>
<td>
<p>Effect size, Cohen's h</p>
</td></tr>
<tr><td><code id="OptSig.2p_+3A_n">n</code></td>
<td>
<p>Number of observations (per sample)</p>
</td></tr>
<tr><td><code id="OptSig.2p_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.2p_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.2p_+3A_alternative">alternative</code></td>
<td>

<p>a character string specifying the alternative hypothesis, must be one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;
</p>
</td></tr>
<tr><td><code id="OptSig.2p_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Refer to Kim and Choi (2020) for the details of k and p
</p>
<p>Either ncp or h value should be specified. 
</p>
<p>For h, refer to Cohen (1988) or Champely (2017)
</p>
<p>In a general term, if X ~ N(mu,sigma^2); let H0:mu = mu0; and H1:mu = mu1; 
</p>
<p>ncp = sqrt(n)(mu1-mu0)/sigma
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Also refer to the manual for the pwr package,
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.    
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim (using a function from the pwr package)
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>OptSig.2p(h=0.2,n=60,alternative="two.sided")
</code></pre>

<hr>
<h2 id='OptSig.2p2n'>
Optimal significance level calculation for the test for two proportions (different sample sizes)
</h2><span id='topic+OptSig.2p2n'></span>

<h3>Description</h3>

<p>Computes the optimal significance level for the test for two proportions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.2p2n(ncp=NULL,h=NULL,n1=NULL,n2=NULL,p=0.5,k=1,alternative="two.sided",Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.2p2n_+3A_ncp">ncp</code></td>
<td>
<p>Non-centrality parameter</p>
</td></tr>
<tr><td><code id="OptSig.2p2n_+3A_h">h</code></td>
<td>
<p>Effect size, Cohen's h</p>
</td></tr>
<tr><td><code id="OptSig.2p2n_+3A_n1">n1</code></td>
<td>
<p>Number of observations (1st sample)</p>
</td></tr>
<tr><td><code id="OptSig.2p2n_+3A_n2">n2</code></td>
<td>
<p>Number of observations (2nd sample)</p>
</td></tr>
<tr><td><code id="OptSig.2p2n_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.2p2n_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.2p2n_+3A_alternative">alternative</code></td>
<td>

<p>a character string specifying the alternative hypothesis, must be one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;
</p>
</td></tr>
<tr><td><code id="OptSig.2p2n_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Refer to Kim and Choi (2020) for the details of k and p
</p>
<p>Either ncp or h value should be specified. 
</p>
<p>For h, refer to Cohen (1988) or Chapmely (2017)
</p>
<p>Assume X ~ N(mu,sigma^2); and let H0:mu = mu0; and H1:mu = mu1; 
</p>
<p>ncp = sqrt(n)(mu1-mu0)/sigma
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Also refer to the manual for the pwr package
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.     
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim (using a function from the pwr package)
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>OptSig.2p2n(h=0.30,n1=80,n2=245,alternative="greater")
  </code></pre>

<hr>
<h2 id='OptSig.anova'>
Optimal significance level calculation for balanced one-way analysis of variance tests
</h2><span id='topic+OptSig.anova'></span>

<h3>Description</h3>

<p>Computes the optimal significance level for the test for balanced one-way analysis of variance tests
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.anova(K = NULL, n = NULL, f = NULL, p = 0.5, k = 1, Figure = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.anova_+3A_k">K</code></td>
<td>
<p>Number of groups</p>
</td></tr>
<tr><td><code id="OptSig.anova_+3A_n">n</code></td>
<td>
<p>Number of observations (per group)</p>
</td></tr>
<tr><td><code id="OptSig.anova_+3A_f">f</code></td>
<td>
<p>Effect size</p>
</td></tr>
<tr><td><code id="OptSig.anova_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.anova_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.anova_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Refer to Kim and Choi (2020) for the details of k and p
</p>
<p>For the value of f, refer to Cohen (1988) or Champely (2017)
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Also refer to the manual for the pwr package
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.      
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim (using a function from the pwr package)
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>OptSig.anova(f=0.28,K=4,n=20)
</code></pre>

<hr>
<h2 id='OptSig.Boot'>
Optimal Significance Level for the F-test using the bootstrap
</h2><span id='topic+OptSig.Boot'></span>

<h3>Description</h3>

<p>The function calculates the optimal level of significance for the F-test 
</p>
<p>The bootstrap can be conducted using either iid resampling or wild bootstrap.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.Boot(y,x,Rmat,rvec,p=0.5,k=1,nboot=3000,wild=FALSE,Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.Boot_+3A_y">y</code></td>
<td>
<p> a matrix of dependent variable, T by 1</p>
</td></tr>
<tr><td><code id="OptSig.Boot_+3A_x">x</code></td>
<td>
<p> a matrix of K independent variable, T by K</p>
</td></tr>
<tr><td><code id="OptSig.Boot_+3A_rmat">Rmat</code></td>
<td>
<p> a matrix for J restrictions, J by (K+1) </p>
</td></tr>
<tr><td><code id="OptSig.Boot_+3A_rvec">rvec</code></td>
<td>
<p> a vector for restrictions, J by 1</p>
</td></tr>
<tr><td><code id="OptSig.Boot_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.Boot_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.Boot_+3A_nboot">nboot</code></td>
<td>
<p> the number of bootstrap iterations, the default is 3000</p>
</td></tr>
<tr><td><code id="OptSig.Boot_+3A_wild">wild</code></td>
<td>
<p> if TRUE, wild bootsrap is conducted; if FALSE (default), bootstrap is based on iid residual resampling</p>
</td></tr>
<tr><td><code id="OptSig.Boot_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default). No graph otherwise </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Kim and Choi (2020) 
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>crit.opt</code></td>
<td>
<p>Critical value at the optimal level</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Applicable to a linear regression model
</p>
<p>The black curve in the figure plots the denity under H0;
The blue curve in the figure plots the denity under H1. 
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach, Abacus, Wiley.
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data1)
# Define Y and X
y=data1$lnoutput; x=cbind(data1$lncapital,data1$lnlabor)

# Restriction matrices to test for constant returns to scale
Rmat=matrix(c(0,1,1),nrow=1); rvec=matrix(0.94,nrow=1)

OptSig.Boot(y,x,Rmat,rvec,p=0.5,k=1,nboot=1000,Figure=TRUE)

</code></pre>

<hr>
<h2 id='OptSig.BootWeight'>
Weighted Optimal Significance Level for the F-test based on the bootstrap
</h2><span id='topic+OptSig.BootWeight'></span>

<h3>Description</h3>

<p>The function calculates the weighted optimal level of significance for the F-test 
</p>
<p>The weights are obtained from the bootstrap distribution of the non-centrality parameter estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.BootWeight(y,x,Rmat,rvec,p=0.5,k=1,nboot=3000,wild=FALSE,Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.BootWeight_+3A_y">y</code></td>
<td>
<p> a matrix of dependent variable, T by 1</p>
</td></tr>
<tr><td><code id="OptSig.BootWeight_+3A_x">x</code></td>
<td>
<p> a matrix of K independent variable, T by K</p>
</td></tr>
<tr><td><code id="OptSig.BootWeight_+3A_rmat">Rmat</code></td>
<td>
<p> a matrix for J restrictions, J by (K+1) </p>
</td></tr>
<tr><td><code id="OptSig.BootWeight_+3A_rvec">rvec</code></td>
<td>
<p> a vector for restrictions, J by 1</p>
</td></tr>
<tr><td><code id="OptSig.BootWeight_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.BootWeight_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.BootWeight_+3A_nboot">nboot</code></td>
<td>
<p> the number of bootstrap iterations, the default is 3000</p>
</td></tr>
<tr><td><code id="OptSig.BootWeight_+3A_wild">wild</code></td>
<td>
<p> if TRUE, wild bootsrap is conducted (default); if FALSE, bootstrap is based on iid resampling</p>
</td></tr>
<tr><td><code id="OptSig.BootWeight_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE . No graph if FALSE (default) </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bootstrap can be conducted using either iid resampling or wild bootstrap.
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>crit.opt</code></td>
<td>
<p>Critical value at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Applicable to a linear regression model
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach. Abacus, Wiley.
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data1)
# Define Y and X
y=data1$lnoutput; x=cbind(data1$lncapital,data1$lnlabor)
# Restriction matrices to test for constant returns to scale
Rmat=matrix(c(0,1,1),nrow=1); rvec=matrix(0.94,nrow=1)

OptSig.Boot(y,x,Rmat,rvec,p=0.5,k=1,nboot=1000,Figure=TRUE)
</code></pre>

<hr>
<h2 id='OptSig.Chisq'>
Optimal Significance Level for a Chi-square test
</h2><span id='topic+OptSig.Chisq'></span>

<h3>Description</h3>

<p>The function calculates the optimal level of significance for a Ch-square test 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.Chisq(w=NULL, N=NULL, ncp=NULL, df, p = 0.5, k = 1, Figure = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.Chisq_+3A_w">w</code></td>
<td>
<p>Effect size, Cohen's w</p>
</td></tr>
<tr><td><code id="OptSig.Chisq_+3A_n">N</code></td>
<td>
<p>Total number of observations</p>
</td></tr>
<tr><td><code id="OptSig.Chisq_+3A_ncp">ncp</code></td>
<td>
<p> a value of the non-centality paramter</p>
</td></tr> 
<tr><td><code id="OptSig.Chisq_+3A_df">df</code></td>
<td>
<p> the degrees of freedom</p>
</td></tr>
<tr><td><code id="OptSig.Chisq_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.Chisq_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.Chisq_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Kim and Choi (2020) 
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>crit.opt</code></td>
<td>
<p>Critical value at the optimal level</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Applicable to any Chi-square test
Either ncp or w (with N) should be given. 
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.     
</p>


<h3>Author(s)</h3>

<p>Jae. H Kim
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Optimal level of Significance for the Breusch-Pagan test: Chi-square version
data(data1)                 # call the data: Table 2.1 of Gujarati (2015)

# Extract Y and X
y=data1$lnoutput; x=cbind(data1$lncapital,data1$lnlabor)

# Restriction matrices for the slope coefficents sum to 1
Rmat=matrix(c(0,1,1),nrow=1); rvec=matrix(1,nrow=1)

# Model Estimation
M=R.OLS(y,x,Rmat,rvec); print(M$coef)

# Breusch-Pagan test for heteroskedasticity
e = M$resid[,1]                  # residuals from unrestricted model estimation

# Restriction matrices for the slope coefficients being 0
Rmat=matrix(c(0,0,1,0,0,1),nrow=2); rvec=matrix(0,nrow=2)

# Model Estimation for the auxilliary regression
M1=R.OLS(e^2,x,Rmat,rvec); 

# Degrees of Freedom and estimate of non-centrality parameter 
df1=nrow(Rmat); NCP=M1$ncp

# LM stat and p-value
LM=nrow(data1)*M1$Rsq[1,1]
pval=pchisq(LM,df=df1,lower.tail = FALSE)

OptSig.Chisq(df=df1,ncp=NCP,p=0.5,k=1, Figure=TRUE)
</code></pre>

<hr>
<h2 id='OptSig.F'>
Optimal Significance Level for an F-test
</h2><span id='topic+OptSig.F'></span>

<h3>Description</h3>

<p>The function calculates the optimal level of significance for an F-test 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.F(df1, df2, ncp, p = 0.5, k = 1, Figure = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.F_+3A_df1">df1</code></td>
<td>
<p> the first degrees of freedom for the F-distribution</p>
</td></tr>
<tr><td><code id="OptSig.F_+3A_df2">df2</code></td>
<td>
<p> the second degrees of freedom for the F-distribution</p>
</td></tr>
<tr><td><code id="OptSig.F_+3A_ncp">ncp</code></td>
<td>
<p> a value of of the non-centality paramter</p>
</td></tr>
<tr><td><code id="OptSig.F_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.F_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.F_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Kim and Choi (2020) 
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>crit.opt</code></td>
<td>
<p>Critical value at the optimal level</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Applicable to any F-test, following F-distribution
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.      
</p>


<h3>Author(s)</h3>

<p>Jae. H Kim
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data1)
# Define Y and X
y=data1$lnoutput; x=cbind(data1$lncapital,data1$lnlabor)
# Restriction matrices to test for constant returns to scale
Rmat=matrix(c(0,1,1),nrow=1); rvec=matrix(0.94,nrow=1)
# Model Estimation and F-test
M=R.OLS(y,x,Rmat,rvec) 

# Degrees of Freedom and estimate of non-centrality parameter 
K=ncol(x)+1; T=length(y)
df1=nrow(Rmat);df2=T-K; NCP=M$ncp

# Optimal level of Significance: Under Normality
OptSig.F(df1,df2,ncp=NCP,p=0.5,k=1, Figure=TRUE)
</code></pre>

<hr>
<h2 id='OptSig.p'>
Optimal significance level calculation for proportion tests (one sample)
</h2><span id='topic+OptSig.p'></span>

<h3>Description</h3>

<p>Computes the optimal significance level for proportion tests (one sample)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.p(ncp=NULL,h=NULL,n=NULL,p=0.5,k=1,alternative="two.sided",Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.p_+3A_ncp">ncp</code></td>
<td>
<p>Non-centraity parameter</p>
</td></tr>
<tr><td><code id="OptSig.p_+3A_h">h</code></td>
<td>
<p>Effect size, Cohen's h</p>
</td></tr>
<tr><td><code id="OptSig.p_+3A_n">n</code></td>
<td>
<p>Number of observations (per sample)</p>
</td></tr>
<tr><td><code id="OptSig.p_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.p_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.p_+3A_alternative">alternative</code></td>
<td>

<p>a character string specifying the alternative hypothesis, must be one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;
</p>
</td></tr>
<tr><td><code id="OptSig.p_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Refer to Kim and Choi (2020) for the details of k and p
</p>
<p>Either ncp or h value should be given
</p>
<p>For h, refer to Cohen (1988) or Chapmely (2017)
</p>
<p>In a general term, if X ~ N(mu,sigma^2); let H0:mu = mu0; and H1:mu = mu1; 
</p>
<p>ncp = sqrt(n)(mu1-mu0)/sigma
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Also refer to the manual for the pwr package
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.        
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim (using a function from the pwr package)
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>OptSig.p(h=0.2,n=60,alternative="two.sided")
</code></pre>

<hr>
<h2 id='OptSig.r'>
Optimal significance level calculation for correlation test
</h2><span id='topic+OptSig.r'></span>

<h3>Description</h3>

<p>Computes the optimal significance level for the correlation test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.r(r=NULL,n=NULL,p=0.5,k=1,alternative="two.sided",Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.r_+3A_r">r</code></td>
<td>
<p>Linear correlation coefficient</p>
</td></tr>
<tr><td><code id="OptSig.r_+3A_n">n</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="OptSig.r_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.r_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II error, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.r_+3A_alternative">alternative</code></td>
<td>

<p>a character string specifying the alternative hypothesis, must be one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;
</p>
</td></tr>
<tr><td><code id="OptSig.r_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Refer to Kim and Choi (2020) for the details of k and p
</p>
<p>In a general term, if X ~ N(mu,sigma^2); let H0:mu = mu0; and H1:mu = mu1; 
</p>
<p>ncp = sqrt(n)(mu1-mu0)/sigma
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Also refer to the manual for the pwr package
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.     
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim (using a function from the pwr package)
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>OptSig.r(r=0.2,n=60,alternative="two.sided")
</code></pre>

<hr>
<h2 id='OptSig.t2n'>
Optimal significance level calculation for two samples (different sizes) t-tests of means
</h2><span id='topic+OptSig.t2n'></span>

<h3>Description</h3>

<p>Computes the optimal significance level for two samples (different sizes) t-tests of means
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.t2n(ncp=NULL,d=NULL,n1=NULL,n2=NULL,p=0.5,k=1,alternative="two.sided",Figure=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.t2n_+3A_ncp">ncp</code></td>
<td>
<p>Non-centrality parameter</p>
</td></tr>
<tr><td><code id="OptSig.t2n_+3A_d">d</code></td>
<td>
<p>Effect size</p>
</td></tr>
<tr><td><code id="OptSig.t2n_+3A_n1">n1</code></td>
<td>
<p>umber of observations in the first sample</p>
</td></tr>
<tr><td><code id="OptSig.t2n_+3A_n2">n2</code></td>
<td>
<p>umber of observations in the second sample</p>
</td></tr>
<tr><td><code id="OptSig.t2n_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.t2n_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.t2n_+3A_alternative">alternative</code></td>
<td>

<p>a character string specifying the alternative hypothesis, must be one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;
</p>
</td></tr>
<tr><td><code id="OptSig.t2n_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Refer to Kim and Choi (2020) for the details of k and p
</p>
<p>Either ncp or d value should be specified. 
</p>
<p>In a general term, if X ~ N(mu,sigma^2); let H0:mu = mu0; and H1:mu = mu1; 
</p>
<p>ncp = sqrt(n)(mu1-mu0)/sigma
</p>
<p>d = (mu1-mu0)/sigma: Cohen's d
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>beta.opt</code></td>
<td>
<p>Type II error probability at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Also refer to the manual for the pwr package
</p>
<p>The black curve in the figure is the line of enlightened judgement: see Kim and Choi (2020).
The red dot inticates the optimal significance level that minimizes the expected loss: (alpha.opt,beta.opt).
The blue horizontal line indicates the case of alpha = 0.05 as a reference point.       
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim (using a function from the pwr package)
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach: Abacus: a Journal of Accounting, Finance and Business Studies. Wiley.  
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
</p>
<p>Stephane Champely (2017). pwr: Basic Functions for Power Analysis. R package version 1.2-1.
https://CRAN.R-project.org/package=pwr
</p>


<h3>See Also</h3>

<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>OptSig.t2n(d=0.6,n1=90,n2=60,alternative="greater")
</code></pre>

<hr>
<h2 id='OptSig.Weight'>
Weighted Optimal Significance Level for the F-test based on the assumption of normality in the error term
</h2><span id='topic+OptSig.Weight'></span>

<h3>Description</h3>

<p>The function calculates the weighted optimal level of significance for the F-test 
</p>
<p>The weights are obtained from a folded-normal distribution with mean m and staradrd deviation delta
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptSig.Weight(df1, df2, m, delta = 2, p = 0.5, k = 1, Figure = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptSig.Weight_+3A_df1">df1</code></td>
<td>
<p> the first degrees of freedom for the F-distribution</p>
</td></tr>
<tr><td><code id="OptSig.Weight_+3A_df2">df2</code></td>
<td>
<p> the second degrees of freedom for the F-distribution</p>
</td></tr>
<tr><td><code id="OptSig.Weight_+3A_m">m</code></td>
<td>
<p> a value of of the non-centality paramter, the mean of the folded-normal distribution</p>
</td></tr>
<tr><td><code id="OptSig.Weight_+3A_delta">delta</code></td>
<td>
<p> standard deviation of the folded-normal distribution</p>
</td></tr>
<tr><td><code id="OptSig.Weight_+3A_p">p</code></td>
<td>
<p> prior probability for H0, default is p = 0.5</p>
</td></tr>
<tr><td><code id="OptSig.Weight_+3A_k">k</code></td>
<td>
<p> relative loss from Type I and II errors, k = L2/L1, default is k = 1</p>
</td></tr>
<tr><td><code id="OptSig.Weight_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Kim and Choi (2020) 
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha.opt</code></td>
<td>
<p>Optimal level of significance</p>
</td></tr>
<tr><td><code>crit.opt</code></td>
<td>
<p>Critical value at the optimal level</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The figure shows the folded-normal distribution
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach, Abacus, Wiley. 
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data1)
# Define Y and X
y=data1$lnoutput; x=cbind(data1$lncapital,data1$lnlabor)
# Restriction matrices to test for constant returns to scale
Rmat=matrix(c(0,1,1),nrow=1); rvec=matrix(0.94,nrow=1)
# Model Estimation and F-test
M=R.OLS(y,x,Rmat,rvec) 

# Degrees of Freedom and estimate of non-centrality parameter 
K=ncol(x)+1; T=length(y)
df1=nrow(Rmat);df2=T-K; NCP=M$ncp

OptSig.Weight(df1,df2,m=NCP,delta=3,p=0.5,k=1,Figure=TRUE)
</code></pre>

<hr>
<h2 id='Power.Chisq'>
Function to calculate the power of a Chi-square test
</h2><span id='topic+Power.Chisq'></span>

<h3>Description</h3>

<p>This function calculates the power of a Chi-square test, given the value of non-centrality parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Power.Chisq(df, ncp, alpha, Figure = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Power.Chisq_+3A_df">df</code></td>
<td>
<p> degree of freedom</p>
</td></tr>
<tr><td><code id="Power.Chisq_+3A_ncp">ncp</code></td>
<td>
<p> a value of of the non-centality paramter</p>
</td></tr>
<tr><td><code id="Power.Chisq_+3A_alpha">alpha</code></td>
<td>
<p> the level of significance</p>
</td></tr>
<tr><td><code id="Power.Chisq_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Kim and Choi (2020) 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Power</code></td>
<td>
<p>Power of the test</p>
</td></tr>
<tr><td><code>Crit.val</code></td>
<td>
<p>Critical value at alpha level of signifcance</p>
</td></tr>
</table>


<h3>Note</h3>

<p>See Application Section and Appendix of Kim and Choi (2017)
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach, Abacus, Wiley.
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Power.Chisq(df=5,ncp=5,alpha=0.05,Figure=TRUE)
</code></pre>

<hr>
<h2 id='Power.F'>
Function to calculate the power of an F-test
</h2><span id='topic+Power.F'></span>

<h3>Description</h3>

<p>This function calculates the power of an F-test, given the value of non-centrality parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Power.F(df1, df2, ncp, alpha, Figure = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Power.F_+3A_df1">df1</code></td>
<td>
<p> the first degrees of freedom for the F-distribution</p>
</td></tr>
<tr><td><code id="Power.F_+3A_df2">df2</code></td>
<td>
<p> the second degrees of freedom for the F-distribution</p>
</td></tr>
<tr><td><code id="Power.F_+3A_ncp">ncp</code></td>
<td>
<p> a value of of the non-centality paramter</p>
</td></tr>
<tr><td><code id="Power.F_+3A_alpha">alpha</code></td>
<td>
<p> the level of significance</p>
</td></tr>
<tr><td><code id="Power.F_+3A_figure">Figure</code></td>
<td>
<p> show graph if TRUE (default); No graph if FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Kim and Choi (2020) 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Power</code></td>
<td>
<p>Power of the test</p>
</td></tr>
<tr><td><code>Crit.val</code></td>
<td>
<p>Critical value at alpha level of signifcance</p>
</td></tr>
</table>


<h3>Note</h3>

<p>See Application Section and Appendix of Kim and Choi (2020)
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach, Abacus, Wiley.
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data1)
# Define Y and X
y=data1$lnoutput; x=cbind(data1$lncapital,data1$lnlabor)
# Restriction matrices to test for constant returns to scale
Rmat=matrix(c(0,1,1),nrow=1); rvec=matrix(0.94,nrow=1)
# Model Estimation and F-test
M=R.OLS(y,x,Rmat,rvec) 
# Degrees of Freedom and estimate of non-centrality parameter 
K=ncol(x)+1; T=length(y)
df1=nrow(Rmat);df2=T-K; NCP=M$ncp

Power.F(df1,df2,ncp=NCP,alpha=0.20747,Figure=TRUE)
</code></pre>

<hr>
<h2 id='R.OLS'>
Restricted OLS estimation and F-test
</h2><span id='topic+R.OLS'></span>

<h3>Description</h3>

<p>Function to calcuate the Restricted (under H0) OLS Estimators and F-test statistic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R.OLS(y, x, Rmat, rvec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R.OLS_+3A_y">y</code></td>
<td>
<p> a matrix of dependent variable, T by 1</p>
</td></tr>
<tr><td><code id="R.OLS_+3A_x">x</code></td>
<td>
<p> a matrix of K independent variable, T by K</p>
</td></tr>
<tr><td><code id="R.OLS_+3A_rmat">Rmat</code></td>
<td>
<p> a matrix for J restrictions, J by (K+1) </p>
</td></tr>
<tr><td><code id="R.OLS_+3A_rvec">rvec</code></td>
<td>
<p> a vector for restrictions, J by 1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rmat and rvec are the matrices for the linear restrictions, which a user should supply. 
</p>
<p>Refer to an econometrics textbook for details. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>coef</code></td>
<td>
<p>matrix of estimated coefficients, (K+1) by 2, under H1 and H0</p>
</td></tr>
<tr><td><code>RSq</code></td>
<td>
<p>R-square values under H1 and H0, 2 by 1</p>
</td></tr>
<tr><td><code>resid</code></td>
<td>
<p>residual vector under H1 and H0, T by 2</p>
</td></tr>
<tr><td><code>F.stat</code></td>
<td>
<p>F-statistic and p-value</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter, estimated by replaicing unknowns using OLS estimates</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function automatically adds an intercept, so the user need not include a vector of ones in x matrix.
</p>


<h3>Author(s)</h3>

<p>Jae H. Kim
</p>


<h3>References</h3>

<p>Kim and Choi, 2020, Choosing the Level of Significance: A Decision-theoretic Approach, Abacus, Wiley.
&lt;https://doi.org/10.1111/abac.12172&gt;
</p>


<h3>See Also</h3>

<p>Leamer, E. 1978, Specification Searches: Ad Hoc Inference with Nonexperimental Data, Wiley, New York.
</p>
<p>Kim, JH and Ji, P. 2015, Significance Testing in Empirical Finance: A Critical Review and Assessment, Journal of Empirical Finance 34, 1-14.
&lt;DOI:http://dx.doi.org/10.1016/j.jempfin.2015.08.006&gt;
</p>
<p>Kim, Jae H., 2020, Decision-theoretic hypothesis testing: A primer with R package OptSig, The American Statistician. 
&lt;https://doi.org/10.1080/00031305.2020.1750484.&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data1)
# Define Y and X
y=data1$lnoutput; x=cbind(data1$lncapital,data1$lnlabor)
# Restriction matrices to test for constant returns to scale
Rmat=matrix(c(0,1,1),nrow=1); rvec=matrix(1,nrow=1)
# Model Estimation and F-test
M=R.OLS(y,x,Rmat,rvec) 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
