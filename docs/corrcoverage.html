<!DOCTYPE html><html><head><title>Help for package corrcoverage</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {corrcoverage}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.zj_abf'><p>Internal function: Simulate nrep ABFs from joint Z-score vector</p></a></li>
<li><a href='#.zj_pp'><p>Simulate posterior probabilities of causality from joint</p>
Z-score vector</a></li>
<li><a href='#%&gt;%'><p>Pipe operator</p></a></li>
<li><a href='#approx.bf.p'><p>Find approx. Bayes factors (ABFs)</p></a></li>
<li><a href='#bf_func'><p>Calculate ABFs from Z scores</p></a></li>
<li><a href='#cor2'><p>Correlation matrix of SNPS</p></a></li>
<li><a href='#corrcov'><p>Corrected coverage estimate using Z-scores and MAFs</p></a></li>
<li><a href='#corrcov_bhat'><p>Corrected coverage estimate using estimated effect sizes and their standard errors</p></a></li>
<li><a href='#corrcov_CI'><p>Confidence interval for corrected coverage estimate using Z-scores and MAFs</p></a></li>
<li><a href='#corrcov_CI_bhat'><p>Confidence interval for corrected coverage estimate using estimated effect sizes and their standard errors</p></a></li>
<li><a href='#corrcov_nvar'><p>Corrected coverage estimate using Z-scores and MAFs (fixing nvar)</p></a></li>
<li><a href='#corrcov_nvar_bhat'><p>Corrected coverage estimate using estimated effect sizes and their standard errors (fixing nvar)</p></a></li>
<li><a href='#corrected_cov'><p>Corrected coverage estimate of the causal variant in the credible set</p></a></li>
<li><a href='#corrected_cs'><p>Corrected credible set using Z-scores and MAFs</p></a></li>
<li><a href='#corrected_cs_bhat'><p>Corrected credible set using estimated effect sizes and their standard errors</p></a></li>
<li><a href='#credset'><p>Credible set of genetic variants</p></a></li>
<li><a href='#credsetC'><p>Credible set of variants from matrix of PPs</p></a></li>
<li><a href='#credsetmat'><p>Obtain credible sets from a matrix of posterior probabilities</p></a></li>
<li><a href='#est_mu'><p>Estimate the true effect at the causal variant using Z-scores and MAFs</p></a></li>
<li><a href='#est_mu_bhat'><p>Estimate the true effect at the causal variant using estimated</p>
effect sizes and their standard errors</a></li>
<li><a href='#logsum'><p>logsum</p></a></li>
<li><a href='#logsum_matrix'><p>logsum rows of a matrix</p></a></li>
<li><a href='#ppfunc'><p>Find PPs of SNPs from Z-scores</p></a></li>
<li><a href='#ppfunc.mat'><p>Find PPs of SNPs from matrix of Z-scores</p></a></li>
<li><a href='#prop_cov'><p>Proportion of credible sets containing the causal variant</p></a></li>
<li><a href='#pvals_pp'><p>Find PPs for SNPs and null model from P-values and MAFs</p></a></li>
<li><a href='#Var.data.cc'><p>Variance of the estimated effect size for case-control data</p></a></li>
<li><a href='#z_sim'><p>Simulate marginal Z-scores from joint Z-score vector</p></a></li>
<li><a href='#z0_pp'><p>Find PPs for SNPs and null model from Z-scores and MAFs</p></a></li>
<li><a href='#zj_pp'><p>Simulate posterior probabilities of causality from joint Z-score vector</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Correcting the Coverage of Credible Sets from Bayesian Genetic
Fine Mapping</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Anna Hutchinson &lt;anna.hutchinson@mrc-bsu.cam.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Using a computationally efficient method, the package can
    be used to find the corrected coverage estimate of a credible set 
    of putative causal variants from Bayesian genetic fine-mapping. 
    The package can also be used to obtain a corrected credible set
    if required; that is, the smallest set of variants required such 
    that the corrected coverage estimate of the resultant credible set is  
    within some user defined accuracy of the desired coverage.
    Maller et al. (2012) &lt;<a href="https://doi.org/10.1038%2Fng.2435">doi:10.1038/ng.2435</a>&gt;,
    Wakefield (2009) &lt;<a href="https://doi.org/10.1002%2Fgepi.20359">doi:10.1002/gepi.20359</a>&gt;,
    Fortune and Wallace (2018) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbty898">doi:10.1093/bioinformatics/bty898</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://annahutch.github.io/corrcoverage">https://annahutch.github.io/corrcoverage</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/annahutch/corrcoverage/issues">https://github.com/annahutch/corrcoverage/issues</a></td>
</tr>
<tr>
<td>OS_type:</td>
<td>unix</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, dplyr, knitr, mvtnorm, rmarkdown, testthat, pkgdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, magrittr, stats, matrixStats, Rcpp</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++11</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-12-06 17:56:15 UTC; anna</td>
</tr>
<tr>
<td>Author:</td>
<td>Anna Hutchinson [aut, cre],
  Chris Wallace [aut],
  Kevin Kunzmann [ctb]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-12-06 23:20:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='.zj_abf'>Internal function: Simulate nrep ABFs from joint Z-score vector</h2><span id='topic+.zj_abf'></span>

<h3>Description</h3>

<p>Does not include posterior probabilities for null model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.zj_abf(Zj, int.Sigma, int.nrep, int.ERR, int.r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".zj_abf_+3A_zj">Zj</code></td>
<td>
<p>joint z vector</p>
</td></tr>
<tr><td><code id=".zj_abf_+3A_int.sigma">int.Sigma</code></td>
<td>
<p>internal sigma</p>
</td></tr>
<tr><td><code id=".zj_abf_+3A_int.nrep">int.nrep</code></td>
<td>
<p>internal nrep</p>
</td></tr>
<tr><td><code id=".zj_abf_+3A_int.err">int.ERR</code></td>
<td>
<p>internal error matrix</p>
</td></tr>
<tr><td><code id=".zj_abf_+3A_int.r">int.r</code></td>
<td>
<p>internal r</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of simulated ABFs, one simulation per row
</p>

<hr>
<h2 id='.zj_pp'>Simulate posterior probabilities of causality from joint
Z-score vector</h2><span id='topic+.zj_pp'></span>

<h3>Description</h3>

<p>Internal function: Simulate nrep posterior probabilities of causality from joint Z-score vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.zj_pp(Zj, int.Sigma, int.nrep, int.ERR, int.r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".zj_pp_+3A_zj">Zj</code></td>
<td>
<p>joint z vector</p>
</td></tr>
<tr><td><code id=".zj_pp_+3A_int.sigma">int.Sigma</code></td>
<td>
<p>internal sigma</p>
</td></tr>
<tr><td><code id=".zj_pp_+3A_int.nrep">int.nrep</code></td>
<td>
<p>internal nrep</p>
</td></tr>
<tr><td><code id=".zj_pp_+3A_int.err">int.ERR</code></td>
<td>
<p>internal error matrix</p>
</td></tr>
<tr><td><code id=".zj_pp_+3A_int.r">int.r</code></td>
<td>
<p>internal r</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Does not include posterior probabilities for null model
</p>


<h3>Value</h3>

<p>Matrix of simulated posterior probabilties of causality,
one simulation per row
</p>

<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>

<hr>
<h2 id='approx.bf.p'>Find approx. Bayes factors (ABFs)</h2><span id='topic+approx.bf.p'></span>

<h3>Description</h3>

<p>Wakefield's log asymptotic Bayes factor (lABF) with prior standard deviation of effect size as a parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>approx.bf.p(pvals, f, type, N, s, W = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="approx.bf.p_+3A_pvals">pvals</code></td>
<td>
<p>P-values</p>
</td></tr>
<tr><td><code id="approx.bf.p_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="approx.bf.p_+3A_type">type</code></td>
<td>
<p>Type of experiment ('quant' or 'cc')</p>
</td></tr>
<tr><td><code id="approx.bf.p_+3A_n">N</code></td>
<td>
<p>Total sample size</p>
</td></tr>
<tr><td><code id="approx.bf.p_+3A_s">s</code></td>
<td>
<p>Proportion of cases (N1/N0+N1), ignored if type=='quant'</p>
</td></tr>
<tr><td><code id="approx.bf.p_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter beta (W=0.2 default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>([Wakefield et al. 2009](https://onlinelibrary.wiley.com/doi/abs/10.1002/gepi.20359)
This function converts p-values to log ABFs, also reporting intermediate calculations
</p>


<h3>Value</h3>

<p>data.frame containing lABF and intermediate calculations
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000
z_scores &lt;- rnorm(nsnps, 0, 3)
p_values &lt;- 2 * pnorm( - abs ( z_scores ) )

## generate example LD matrix and MAFs
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
maf &lt;- colMeans(X)

approx.bf.p(pvals = p_values, f = maf, type = "cc", N = N0+N1, s = N1/(N0+N1))

</code></pre>

<hr>
<h2 id='bf_func'>Calculate ABFs from Z scores</h2><span id='topic+bf_func'></span>

<h3>Description</h3>

<p>Calculate ABFs from Z scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bf_func(z, V, W = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bf_func_+3A_z">z</code></td>
<td>
<p>Vector of Z-scores</p>
</td></tr>
<tr><td><code id="bf_func_+3A_v">V</code></td>
<td>
<p>Variance of the estimated effect size</p>
</td></tr>
<tr><td><code id="bf_func_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note, z and V should both be vectors or both be matrices
</p>


<h3>Value</h3>

<p>ABFs
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000
z_scores &lt;- rnorm(nsnps, 0, 3)

## generate example LD matrix and MAFs
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
maf &lt;- colMeans(X)

varbeta = Var.data.cc(f = maf, N = N0 + N1, s = 0.5)

bf_func(z_scores, V = varbeta)

</code></pre>

<hr>
<h2 id='cor2'>Correlation matrix of SNPS</h2><span id='topic+cor2'></span>

<h3>Description</h3>

<p>Correlation matrix of SNPs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor2_+3A_x">x</code></td>
<td>
<p>Phased haplotype matrix, rows as samples and columns as SNPs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Quick function to find a correlation matrix
</p>


<h3>Value</h3>

<p>Correlation matrix
</p>


<h3>Author(s)</h3>

<p>Chris Wallace
</p>

<hr>
<h2 id='corrcov'>Corrected coverage estimate using Z-scores and MAFs</h2><span id='topic+corrcov'></span>

<h3>Description</h3>

<p>Corrected coverage estimate using Z-scores and mafs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrcov(z, f, N0, N1, Sigma, thr, W = 0.2, nrep = 1000, pp0min = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrcov_+3A_z">z</code></td>
<td>
<p>Marginal Z-scores</p>
</td></tr>
<tr><td><code id="corrcov_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="corrcov_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="corrcov_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="corrcov_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
<tr><td><code id="corrcov_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for fine-mapping experiment</p>
</td></tr>
<tr><td><code id="corrcov_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="corrcov_+3A_nrep">nrep</code></td>
<td>
<p>The number of simulated posterior probability systems to consider for the corrected coverage estimate (default 1000)</p>
</td></tr>
<tr><td><code id="corrcov_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function only requires the marginal summary statistics from GWAS
</p>


<h3>Value</h3>

<p>Corrected coverage estimate
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000
z_scores &lt;- rnorm(nsnps, 0, 3) # simulate a vector of Z-scores

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

corrcov(z = z_scores, f = maf, N0, N1, Sigma = LD, thr = 0.95)

</code></pre>

<hr>
<h2 id='corrcov_bhat'>Corrected coverage estimate using estimated effect sizes and their standard errors</h2><span id='topic+corrcov_bhat'></span>

<h3>Description</h3>

<p>Corrected coverage estimate using estimated effect sizes and their standard errors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrcov_bhat(bhat, V, N0, N1, Sigma, thr, W = 0.2, nrep = 1000, pp0min = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrcov_bhat_+3A_bhat">bhat</code></td>
<td>
<p>Estimated effect sizes from single-SNP logistic regressions</p>
</td></tr>
<tr><td><code id="corrcov_bhat_+3A_v">V</code></td>
<td>
<p>Variance of estimated effect sizes</p>
</td></tr>
<tr><td><code id="corrcov_bhat_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="corrcov_bhat_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="corrcov_bhat_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
<tr><td><code id="corrcov_bhat_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for fine-mapping experiment</p>
</td></tr>
<tr><td><code id="corrcov_bhat_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="corrcov_bhat_+3A_nrep">nrep</code></td>
<td>
<p>The number of simulated posterior probability systems to consider for the corrected coverage estimate (default 1000)</p>
</td></tr>
<tr><td><code id="corrcov_bhat_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function only requires the marginal summary statistics from GWAS
</p>


<h3>Value</h3>

<p>Corrected coverage estimate
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps &lt;- 100
N0 &lt;- 1000 # number of controls
N1 &lt;- 1000 # number of cases

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

varbeta &lt;- Var.data.cc(f = maf, N = N0 + N1, s = N1/(N0+N1))

bhats = rnorm(nsnps, 0, 0.2) # log OR

corrcov_bhat(bhat = bhats, V = varbeta, N0, N1, Sigma = LD, thr = 0.95)

</code></pre>

<hr>
<h2 id='corrcov_CI'>Confidence interval for corrected coverage estimate using Z-scores and MAFs</h2><span id='topic+corrcov_CI'></span>

<h3>Description</h3>

<p>Obtain confidence interval for corrected coverage estimate using Z-scores and mafs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrcov_CI(
  z,
  f,
  N0,
  N1,
  Sigma,
  thr,
  W = 0.2,
  nrep = 1000,
  CI = 0.95,
  pp0min = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrcov_CI_+3A_z">z</code></td>
<td>
<p>Marginal Z-scores</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for fine-mapping experiment</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_nrep">nrep</code></td>
<td>
<p>The number of simulated posterior probability systems to consider for the corrected coverage estimate (nrep = 1000 default)</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_ci">CI</code></td>
<td>
<p>The size of the confidence interval (as a decimal)</p>
</td></tr>
<tr><td><code id="corrcov_CI_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Value</h3>

<p>CI for corrected coverage estimate
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


 # this is a long running example
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000
z_scores &lt;- rnorm(nsnps, 0, 3) # simulate a vector of Z-scores

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

corrcov_CI(z = z_scores, f = maf, N0, N1, Sigma = LD, thr = 0.95)


</code></pre>

<hr>
<h2 id='corrcov_CI_bhat'>Confidence interval for corrected coverage estimate using estimated effect sizes and their standard errors</h2><span id='topic+corrcov_CI_bhat'></span>

<h3>Description</h3>

<p>Obtain confidence interval for corrected coverage estimate using estimated effect sizes and their standard errors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrcov_CI_bhat(
  bhat,
  V,
  N0,
  N1,
  Sigma,
  thr,
  W = 0.2,
  nrep = 1000,
  CI = 0.95,
  pp0min = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrcov_CI_bhat_+3A_bhat">bhat</code></td>
<td>
<p>Estimated effect sizes from single-SNP logistic regressions</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_v">V</code></td>
<td>
<p>Variance of estimated effect sizes</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for fine-mapping experiment</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter beta</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_nrep">nrep</code></td>
<td>
<p>The number of simulated posterior probability systems to consider for the corrected coverage estimate (nrep = 1000 default)</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_ci">CI</code></td>
<td>
<p>The size of the confidence interval (as a decimal)</p>
</td></tr>
<tr><td><code id="corrcov_CI_bhat_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Value</h3>

<p>CI for corrected coverage estimate
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

 # this is a long running example
set.seed(1)
nsnps &lt;- 100
N0 &lt;- 5000 # number of controls
N1 &lt;- 5000 # number of cases

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

varbeta &lt;- Var.data.cc(f = maf, N = N0 + N1, s = N1/(N0+N1))

bhats = rnorm(nsnps,0,0.2) # log OR

corrcov_CI_bhat(bhat = bhats, V = varbeta, N0, N1, Sigma = LD)


</code></pre>

<hr>
<h2 id='corrcov_nvar'>Corrected coverage estimate using Z-scores and MAFs (fixing nvar)</h2><span id='topic+corrcov_nvar'></span>

<h3>Description</h3>

<p>Obtain corrected coverage estimate using Z-scores and mafs (limiting simulations used for estimation to those with correct nvar)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrcov_nvar(
  z,
  f,
  N0,
  N1,
  Sigma,
  nvar,
  thr,
  W = 0.2,
  nrep = 10000,
  pp0min = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrcov_nvar_+3A_z">z</code></td>
<td>
<p>Marginal Z-scores</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_nvar">nvar</code></td>
<td>
<p>The number of variants that simulated credible sets used for estimation should contain</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for fine-mapping experiment</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_nrep">nrep</code></td>
<td>
<p>The number of simulated posterior probability systems to consider for the corrected coverage estimate (nrep = 10000 default due to trimming)</p>
</td></tr>
<tr><td><code id="corrcov_nvar_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function requires the marginal summary statistics from GWAS and an nvar value. It should only be used when nvar is very low (&lt;3) and there is some evidence to suggest that only simulated credible sets with this nvar value should be used to derive the corrected coverage estimate.
</p>


<h3>Value</h3>

<p>Corrected coverage estimate
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000
z_scores &lt;- rnorm(nsnps, 0, 3) # simulate a vector of Z-scores

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

corrcov_nvar(z = z_scores, f = maf, N0, N1, Sigma = LD, thr = 0.95, nvar = 1, nrep = 100)

# note that nrep should be at least the default value (nrep = 10000) but is
# lower here for speed of computation

</code></pre>

<hr>
<h2 id='corrcov_nvar_bhat'>Corrected coverage estimate using estimated effect sizes and their standard errors (fixing nvar)</h2><span id='topic+corrcov_nvar_bhat'></span>

<h3>Description</h3>

<p>Obtain corrected coverage estimate using estimated effect sizes and their standard errors (limiting simulations used for estimation to those with correct nvar)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrcov_nvar_bhat(
  bhat,
  V,
  N0,
  N1,
  Sigma,
  nvar,
  thr,
  W = 0.2,
  nrep = 10000,
  pp0min = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrcov_nvar_bhat_+3A_bhat">bhat</code></td>
<td>
<p>Estimated effect sizes from single-SNP logistic regressions</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_v">V</code></td>
<td>
<p>Variance of estimated effect sizes</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_nvar">nvar</code></td>
<td>
<p>The number of variants that simulated credible sets used for estimation should contain</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for fine-mapping experiment</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_nrep">nrep</code></td>
<td>
<p>The number of simulated posterior probability systems to consider for the corrected coverage estimate (nrep = 10000 default due to trimming)</p>
</td></tr>
<tr><td><code id="corrcov_nvar_bhat_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function requires the marginal summary statistics from GWAS and an nvar value. It should only be used when nvar is very low ($&lt;3$) and there is some evidence to suggest that only simulated credible sets with this nvar value should be used to derive the corrected coverage estimate.
</p>


<h3>Value</h3>

<p>Corrected coverage estimate
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps &lt;- 100
N0 &lt;- 5000 # number of controls
N1 &lt;- 5000 # number of cases

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

varbeta &lt;- Var.data.cc(f = maf, N = N0 + N1, s = N1/(N0+N1))

bhats = rnorm(nsnps,0,0.2) # log OR

corrcov_nvar_bhat(bhat = bhats, V = varbeta, N0, N1, Sigma = LD, thr = 0.95, nvar = 1, nrep = 1000)

# note that nrep should be at least the default value (nrep = 10000) but is
# lower here for speed of computation

</code></pre>

<hr>
<h2 id='corrected_cov'>Corrected coverage estimate of the causal variant in the credible set</h2><span id='topic+corrected_cov'></span>

<h3>Description</h3>

<p>Corrected coverage estimate of the causal variant in the credible set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrected_cov(pp0, mu, V, Sigma, thr, W = 0.2, nrep = 1000, pp0min = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrected_cov_+3A_pp0">pp0</code></td>
<td>
<p>Posterior probabilities of SNPs</p>
</td></tr>
<tr><td><code id="corrected_cov_+3A_mu">mu</code></td>
<td>
<p>The true effect at the CV (estimate using corrcoverage::est_mu function)</p>
</td></tr>
<tr><td><code id="corrected_cov_+3A_v">V</code></td>
<td>
<p>Variance of the estimated effect size (can be obtained using coloc::Var.beta.cc function)</p>
</td></tr>
<tr><td><code id="corrected_cov_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
<tr><td><code id="corrected_cov_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for fine-mapping experiment</p>
</td></tr>
<tr><td><code id="corrected_cov_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (W=0.2 default)</p>
</td></tr>
<tr><td><code id="corrected_cov_+3A_nrep">nrep</code></td>
<td>
<p>Number of posterior probability systems to simulate for each variant considered causal (nrep = 1000 default)</p>
</td></tr>
<tr><td><code id="corrected_cov_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Requires an estimate of the true effect at the CV (e.g. use maximum absolute z-score or output from corrcoverage::est_mu function)
</p>


<h3>Value</h3>

<p>Corrected coverage estimate
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps &lt;- 100
N0 &lt;- 5000
N1 &lt;- 5000

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

## generate V (variance of estimated effect sizes)
varbeta &lt;- Var.data.cc(f = maf, N = 5000, s = 0.5)

pp &lt;- rnorm(nsnps, 0.2, 0.05)
pp &lt;- pp/sum(pp)

corrected_cov(pp0 = pp, mu = 4, V = varbeta, Sigma = LD, thr = 0.95, nrep = 100)

</code></pre>

<hr>
<h2 id='corrected_cs'>Corrected credible set using Z-scores and MAFs</h2><span id='topic+corrected_cs'></span>

<h3>Description</h3>

<p>Corrected credible set using Z-scores and MAFs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrected_cs(
  z,
  f,
  N0,
  N1,
  Sigma,
  W = 0.2,
  lower = 0,
  upper = 1,
  desired.cov,
  acc = 0.005,
  max.iter = 20,
  pp0min = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrected_cs_+3A_z">z</code></td>
<td>
<p>Z-scores</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_sigma">Sigma</code></td>
<td>
<p>Correlation matrix of SNPs</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_lower">lower</code></td>
<td>
<p>Lower threshold (default = 0)</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_upper">upper</code></td>
<td>
<p>Upper threshold (default = 1)</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_desired.cov">desired.cov</code></td>
<td>
<p>The desired coverage of the causal variant in the credible set</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_acc">acc</code></td>
<td>
<p>Accuracy of corrected coverage to desired coverage (default = 0.005)</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum iterations (default = 20)</p>
</td></tr>
<tr><td><code id="corrected_cs_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of variants in credible set, required threshold, the corrected coverage and the size of the credible set
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 # this is a long running example

# In this example, the function is used to find a corrected 95% credible set
# using Z-scores and MAFs, that is the smallest set of variants
# required such that the resultant credible set has coverage close to (/within
# some accuracy of) the "desired coverage" (here set to 0.95). Max.iter parameter
# defines the maximum number of iterations to try in the root bisection algorithm,
# this should be increased to ensure convergence to the desired coverage, but is set
# to 1 here for speed (and thus the resultant credible set will not be accurate).

set.seed(2)
nsnps = 200
N0 = 1000
N1 = 1000
z_scores &lt;- rnorm(nsnps, 0, 1) # simulate a vector of Z-scores

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

names(z_scores) &lt;- seq(1,length(z_scores))

corrected_cs(z = z_scores, f = maf, N0, N1, Sigma = LD, desired.cov = 0.9, max.iter = 1)
# max.iter set low for speed, should be set to at least
# the default to ensure convergence to desired coverage


</code></pre>

<hr>
<h2 id='corrected_cs_bhat'>Corrected credible set using estimated effect sizes and their standard errors</h2><span id='topic+corrected_cs_bhat'></span>

<h3>Description</h3>

<p>Corrected credible set using estimated effect sizes and their standard errors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrected_cs_bhat(
  bhat,
  V,
  N0,
  N1,
  Sigma,
  W = 0.2,
  lower = 0,
  upper = 1,
  desired.cov,
  acc = 0.005,
  max.iter = 20,
  pp0min = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrected_cs_bhat_+3A_bhat">bhat</code></td>
<td>
<p>Estimated effect sizes</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_v">V</code></td>
<td>
<p>Prior variance of estimated effect sizes</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_sigma">Sigma</code></td>
<td>
<p>Correlation matrix of SNPs</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_lower">lower</code></td>
<td>
<p>Lower threshold (default = 0)</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_upper">upper</code></td>
<td>
<p>Upper threshold (default = 1)</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_desired.cov">desired.cov</code></td>
<td>
<p>The desired coverage of the causal variant in the credible set</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_acc">acc</code></td>
<td>
<p>Accuracy of corrected coverage to desired coverage (default = 0.005)</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum iterations (default = 20)</p>
</td></tr>
<tr><td><code id="corrected_cs_bhat_+3A_pp0min">pp0min</code></td>
<td>
<p>Only average over SNPs with pp0 &gt; pp0min</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of variants in credible set, required threshold, the corrected coverage and the size of the credible set
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

 # this is a long running example

# In this example, the function is used to find a corrected 95% credible set
# using bhats and their standard errors, that is the smallest set of variants
# required such that the resultant credible set has coverage close to (/within
# some accuracy of) the "desired coverage" (here set to 0.95). Max.iter parameter
# defines the maximum number of iterations to try in the root bisection algorithm,
# this should be increased to ensure convergence to the desired coverage, but is set
# to 1 here for speed (and thus the resultant credible set will not be accurate).

set.seed(18)
nsnps &lt;- 100
N0 &lt;- 500 # number of controls
N1 &lt;- 500 # number of cases

# simulate fake haplotypes to obtain MAFs and LD matrix
## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

varbeta &lt;- Var.data.cc(f = maf, N = N0 + N1, s = N1/(N0+N1))

bhats = rnorm(nsnps,0,0.2) # log OR

names(bhats) &lt;- seq(1,length(bhats))

corrected_cs_bhat(bhat = bhats, V = varbeta, N0, N1, Sigma = LD, desired.cov = 0.9, max.iter = 1)
# max.iter set low for speed, should be set to at
# least the default to ensure convergence to desired coverage


</code></pre>

<hr>
<h2 id='credset'>Credible set of genetic variants</h2><span id='topic+credset'></span>

<h3>Description</h3>

<p>Credible set of putative causal variants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>credset(pp, CV, thr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="credset_+3A_pp">pp</code></td>
<td>
<p>Vector of posterior probabilities of causality</p>
</td></tr>
<tr><td><code id="credset_+3A_cv">CV</code></td>
<td>
<p>Optional parameter: Index of CV</p>
</td></tr>
<tr><td><code id="credset_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for credible set size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the CV parameter is supplied (index of causal variant) then the
output includes a binary indicator of whether the CV is contained in the set
</p>


<h3>Value</h3>

<p>list of the variants in the credible set, the claimed.cov (cumulative sum of the posterior probabilities of the variants forming the credible set), binary covered indicator (1 if CV is contained in the credible set) and nvar (number of variants in the set)
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps &lt;- 100
pp &lt;- rnorm(nsnps, 0.3, 0.05)
pp &lt;- pp/sum(pp)

credset(pp, thr = 0.9)

iCV &lt;- 71

credset(pp, CV = iCV, thr = 0.9)

</code></pre>

<hr>
<h2 id='credsetC'>Credible set of variants from matrix of PPs</h2><span id='topic+credsetC'></span>

<h3>Description</h3>

<p>Quick credset function for matrix of posterior probabilities (using RCpp)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>credsetC(pp, CV, thr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="credsetC_+3A_pp">pp</code></td>
<td>
<p>Matrix of posterior probabilities of causality (one row per system)</p>
</td></tr>
<tr><td><code id="credsetC_+3A_cv">CV</code></td>
<td>
<p>Vector of CV indices (one per system/row)</p>
</td></tr>
<tr><td><code id="credsetC_+3A_thr">thr</code></td>
<td>
<p>Minimum threshold for credible set size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data.frame of claimed coverage (sum of posterior probabilities of variants in the set), binary covered indicator and number of variants (nvar).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps &lt;- 100

# simulate matrix of posterior probabilities
# 1 simulation per row

pp &lt;- matrix(rnorm(nsnps*100, 0.3, 0.05), ncol = nsnps)
pp &lt;- pp/rowSums(pp)

iCV &lt;- rep(71, times = dim(pp)[1])

credsetC(pp, CV = iCV, thr = 0.9)

</code></pre>

<hr>
<h2 id='credsetmat'>Obtain credible sets from a matrix of posterior probabilities</h2><span id='topic+credsetmat'></span>

<h3>Description</h3>

<p>Obtain credible sets from a matrix of posterior probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>credsetmat(pp, iCV, threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="credsetmat_+3A_pp">pp</code></td>
<td>
<p>Matrix of posterior probabilities (one row for each simulation)</p>
</td></tr>
<tr><td><code id="credsetmat_+3A_icv">iCV</code></td>
<td>
<p>A vector of the indices of the CV</p>
</td></tr>
<tr><td><code id="credsetmat_+3A_threshold">threshold</code></td>
<td>
<p>The threshold to use to generate the credible set</p>
</td></tr>
</table>

<hr>
<h2 id='est_mu'>Estimate the true effect at the causal variant using Z-scores and MAFs</h2><span id='topic+est_mu'></span>

<h3>Description</h3>

<p>Estimate the true effect at the causal variant using Z-scores and MAFs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_mu(z, f, N0, N1, W = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_mu_+3A_z">z</code></td>
<td>
<p>Vector of marginal Z-scores</p>
</td></tr>
<tr><td><code id="est_mu_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="est_mu_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="est_mu_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="est_mu_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta, default 0.2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimate of the true effect at the causal variant
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
nsnps &lt;- 100
z_scores &lt;- rnorm(nsnps, 0, 3) # simulate a vector of Z-scores
N0 &lt;- 5000 # number of controls
N1 &lt;- 5000 # number of cases

maf &lt;- runif(nsnps, 0.05, 0.5)

est_mu(z = z_scores, f = maf, N0 = N0, N1 = N1)

</code></pre>

<hr>
<h2 id='est_mu_bhat'>Estimate the true effect at the causal variant using estimated
effect sizes and their standard errors</h2><span id='topic+est_mu_bhat'></span>

<h3>Description</h3>

<p>Estimate the true effect at the causal variant using estimated
effect sizes and their standard errors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_mu_bhat(bhat, V, N0, N1, p1 = 1e-04, W = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_mu_bhat_+3A_bhat">bhat</code></td>
<td>
<p>Vector of estimated effect sizes</p>
</td></tr>
<tr><td><code id="est_mu_bhat_+3A_v">V</code></td>
<td>
<p>Prior variance for estimated effect sizes</p>
</td></tr>
<tr><td><code id="est_mu_bhat_+3A_n0">N0</code></td>
<td>
<p>Number of controls</p>
</td></tr>
<tr><td><code id="est_mu_bhat_+3A_n1">N1</code></td>
<td>
<p>Number of cases</p>
</td></tr>
<tr><td><code id="est_mu_bhat_+3A_p1">p1</code></td>
<td>
<p>Prior probability a SNP is associated with the trait, default 1e-4</p>
</td></tr>
<tr><td><code id="est_mu_bhat_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimate of the true effect at the causal variant
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
nsnps &lt;- 100
N0 &lt;- 5000 # number of controls
N1 &lt;- 5000 # number of cases

maf &lt;- runif(nsnps, 0.05, 0.3)

varbeta &lt;- Var.data.cc(f = maf, N = N0 + N1, s = N1/(N0+N1))

bhats = rnorm(nsnps,0,0.2) # log(OR)

est_mu_bhat(bhat = bhats, V = varbeta, N0 = N0, N1 = N1)

</code></pre>

<hr>
<h2 id='logsum'>logsum</h2><span id='topic+logsum'></span>

<h3>Description</h3>

<p>Internal function, logsum
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logsum(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logsum_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the log of the sum of the exponentiated
logs taking out the max, i.e. insuring that the sum is not Inf
</p>


<h3>Value</h3>

<p>max(x) + log(sum(exp(x - max(x))))
</p>


<h3>Author(s)</h3>

<p>Chris Wallace
</p>

<hr>
<h2 id='logsum_matrix'>logsum rows of a matrix</h2><span id='topic+logsum_matrix'></span>

<h3>Description</h3>

<p>matrix-ified version of logsum to avoid needing apply()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logsum_matrix(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logsum_matrix_+3A_x">x</code></td>
<td>
<p>numeric matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>rowwise sums
</p>


<h3>Author(s)</h3>

<p>Chris Wallace
</p>

<hr>
<h2 id='ppfunc'>Find PPs of SNPs from Z-scores</h2><span id='topic+ppfunc'></span>

<h3>Description</h3>

<p>Posterior probabilities of causality from marginal Z-scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppfunc(z, V, W = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ppfunc_+3A_z">z</code></td>
<td>
<p>Vector of marginal Z-scores</p>
</td></tr>
<tr><td><code id="ppfunc_+3A_v">V</code></td>
<td>
<p>Variance of the estimated effect size (can be obtained using Var.beta.cc function)</p>
</td></tr>
<tr><td><code id="ppfunc_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (W = 0.2 default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function converts Z-scores to posterior probabilities of causality
i.e. not including the null model of no genetic effects,
so that the sum of the posterior probabilities for all variants is 1
</p>


<h3>Value</h3>

<p>Vector of posterior probabilities
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000
z_scores &lt;- rnorm(nsnps, 0, 3)

## generate example LD matrix and MAFs
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
maf &lt;- colMeans(X)

varbeta &lt;- Var.data.cc(f = maf, N = N0+N1, s = N1/(N0+N1))

res &lt;- ppfunc(z = z_scores, V = varbeta)
sum(res)
res

</code></pre>

<hr>
<h2 id='ppfunc.mat'>Find PPs of SNPs from matrix of Z-scores</h2><span id='topic+ppfunc.mat'></span>

<h3>Description</h3>

<p>Posterior probabilities of causality from matrix of marginal Z-scores (1 simulation per row)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppfunc.mat(zstar, V, W = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ppfunc.mat_+3A_zstar">zstar</code></td>
<td>
<p>Matrix of marginal z-scores, one replicate per row</p>
</td></tr>
<tr><td><code id="ppfunc.mat_+3A_v">V</code></td>
<td>
<p>Variance of the estimated effect size, one element per column of zstar</p>
</td></tr>
<tr><td><code id="ppfunc.mat_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function converts a matrix of Z-scores (one row per simulation) to posterior probabilities of causality,
not including the null model of no genetic effects,
so that the sum of the posterior probabilities for each simulation (each row) is 1.
</p>


<h3>Value</h3>

<p>Matrix of posterior probabilities of causality
</p>


<h3>Author(s)</h3>

<p>Chris Wallace
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000

## generate example LD matrix and MAFs
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
maf &lt;- colMeans(X)

varbeta &lt;- Var.data.cc(f = maf, N = N0+N1, s = N1/(N0+N1))

# simulate matrix of Z scores
# 1 simulation per row
z_scores &lt;- matrix(rnorm(nsnps*100, 0, 3), ncol = nsnps)

# each row is a vector of simulated PPs
res &lt;- ppfunc.mat(zstar = z_scores, V = varbeta)

rowSums(res)

</code></pre>

<hr>
<h2 id='prop_cov'>Proportion of credible sets containing the causal variant</h2><span id='topic+prop_cov'></span>

<h3>Description</h3>

<p>Proportion of simulated credible sets containing the causal variant
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prop_cov(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prop_cov_+3A_x">x</code></td>
<td>
<p>data.frame with a binary 'covered' column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Proportion of x with x = 1
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>

<hr>
<h2 id='pvals_pp'>Find PPs for SNPs and null model from P-values and MAFs</h2><span id='topic+pvals_pp'></span>

<h3>Description</h3>

<p>Posterior probabilities of causality from P-values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvals_pp(pvals, f, type, N, s, W = 0.2, p1 = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvals_pp_+3A_pvals">pvals</code></td>
<td>
<p>P-values of SNPs</p>
</td></tr>
<tr><td><code id="pvals_pp_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="pvals_pp_+3A_type">type</code></td>
<td>
<p>Type of experiment ('quant' or 'cc')</p>
</td></tr>
<tr><td><code id="pvals_pp_+3A_n">N</code></td>
<td>
<p>Total sample size</p>
</td></tr>
<tr><td><code id="pvals_pp_+3A_s">s</code></td>
<td>
<p>Proportion of cases (N1/N0+N1), ignored if type=='quant'</p>
</td></tr>
<tr><td><code id="pvals_pp_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="pvals_pp_+3A_p1">p1</code></td>
<td>
<p>Prior probability a SNP is associated with the trait (default 1e-4)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function converts p-values to posterior probabilities of causality, including the null model of no genetic effect
</p>


<h3>Value</h3>

<p>Posterior probabilities of null model (no genetic effect) and causality for each SNP
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000
z_scores &lt;- rnorm(nsnps, 0, 3)
p_values &lt;- 2 * pnorm( - abs ( z_scores ) )

## generate example LD matrix and MAFs
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
maf &lt;- colMeans(X)

res &lt;- pvals_pp(pvals = p_values, f = maf, type = "cc", N = N0+N1, s = N1/(N0+N1))
sum(res)
res


</code></pre>

<hr>
<h2 id='Var.data.cc'>Variance of the estimated effect size for case-control data</h2><span id='topic+Var.data.cc'></span>

<h3>Description</h3>

<p>Variance of the estimated effect size for case-control data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Var.data.cc(f, N, s)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Var.data.cc_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="Var.data.cc_+3A_n">N</code></td>
<td>
<p>Total sample size (N0+N1)</p>
</td></tr>
<tr><td><code id="Var.data.cc_+3A_s">s</code></td>
<td>
<p>Proportion of cases (N1/N0+N1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Variance of estimated effect size <code class="reqn">\hat{\beta}</code>, V.
</p>


<h3>Author(s)</h3>

<p>Chris Wallace
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
maf =  runif(100, 0.05, 0.5)
N0 = 5000 # number of controls
N1 = 5000 # number of cases

Var.data.cc(f = maf, N = N0 + N1, s = N1/(N0+N1))

</code></pre>

<hr>
<h2 id='z_sim'>Simulate marginal Z-scores from joint Z-score vector</h2><span id='topic+z_sim'></span>

<h3>Description</h3>

<p>Simulate marginal z-scores (<code class="reqn">Z_m</code>) from the joint z-scores (<code class="reqn">Z_j</code>) using <code class="reqn">E(Z_m) = Z_j \times \Sigma</code> and
<code class="reqn">Z* \sim MVN(E(Z_m), \Sigma)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>z_sim(Zj, Sigma, nrep)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="z_sim_+3A_zj">Zj</code></td>
<td>
<p>Vector of joint Z-scores (a vector of 0s except at the CV)</p>
</td></tr>
<tr><td><code id="z_sim_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
<tr><td><code id="z_sim_+3A_nrep">nrep</code></td>
<td>
<p>Number of Z-score systems to simulate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of simulated posterior probabilties, one simulation per row
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps &lt;- 100

# derive joint Z score vector
Zj &lt;- rep(0, nsnps)
iCV &lt;- 4 # index of CV
mu &lt;- 5 # true effect at CV
Zj[iCV] &lt;- mu

## generate example LD matrix
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)

res &lt;- z_sim(Zj, Sigma = LD, nrep = 100)
res[c(1:5), c(1:5)]

</code></pre>

<hr>
<h2 id='z0_pp'>Find PPs for SNPs and null model from Z-scores and MAFs</h2><span id='topic+z0_pp'></span>

<h3>Description</h3>

<p>Posterior probabilities of causality from marginal Z-scores with prior SD as a parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>z0_pp(z, f, type, N, s, W = 0.2, p1 = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="z0_pp_+3A_z">z</code></td>
<td>
<p>Marginal Z-scores of SNPs</p>
</td></tr>
<tr><td><code id="z0_pp_+3A_f">f</code></td>
<td>
<p>Minor allele frequencies</p>
</td></tr>
<tr><td><code id="z0_pp_+3A_type">type</code></td>
<td>
<p>Type of experiment ('quant' or 'cc')</p>
</td></tr>
<tr><td><code id="z0_pp_+3A_n">N</code></td>
<td>
<p>Total sample size</p>
</td></tr>
<tr><td><code id="z0_pp_+3A_s">s</code></td>
<td>
<p>Proportion of cases (N1/N0+N1), ignored if type=='quant'</p>
</td></tr>
<tr><td><code id="z0_pp_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="z0_pp_+3A_p1">p1</code></td>
<td>
<p>Prior probability a SNP is associated with the trait (default 1e-4)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Converts Z-scores to posterior probabilities of causality, including the null model of no genetic effects
</p>


<h3>Value</h3>

<p>Posterior probabilities of null model (no genetic effect) and causality for each SNP
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps = 100
N0 = 5000
N1 = 5000
z_scores &lt;- rnorm(nsnps, 0, 3)

## generate example LD matrix and MAFs
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
maf &lt;- colMeans(X)

res &lt;- z0_pp(z = z_scores, f = maf, type = "cc", N = N0+N1, s = N1/(N0+N1))
sum(res)
res

</code></pre>

<hr>
<h2 id='zj_pp'>Simulate posterior probabilities of causality from joint Z-score vector</h2><span id='topic+zj_pp'></span>

<h3>Description</h3>

<p>Simulate nrep marginal Z-scores from joint Z-scores and convert these to posterior probabilities of causality
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zj_pp(Zj, V, nrep = 1000, W = 0.2, Sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zj_pp_+3A_zj">Zj</code></td>
<td>
<p>Vector of joint Z-scores (0s except at CV)</p>
</td></tr>
<tr><td><code id="zj_pp_+3A_v">V</code></td>
<td>
<p>Variance of the estimated effect size (can be obtained using Var.beta.cc function)</p>
</td></tr>
<tr><td><code id="zj_pp_+3A_nrep">nrep</code></td>
<td>
<p>Number of posterior probability systems to simulate (default 1000)</p>
</td></tr>
<tr><td><code id="zj_pp_+3A_w">W</code></td>
<td>
<p>Prior for the standard deviation of the effect size parameter, beta (default 0.2)</p>
</td></tr>
<tr><td><code id="zj_pp_+3A_sigma">Sigma</code></td>
<td>
<p>SNP correlation matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Does not include posterior probabilities for null model
</p>


<h3>Value</h3>

<p>Matrix of simulated posterior probabilties, one simulation per row
</p>


<h3>Author(s)</h3>

<p>Anna Hutchinson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
nsnps &lt;- 100
Zj &lt;- rep(0, nsnps)
iCV &lt;- 4 # index of CV
mu &lt;- 5 # true effect at CV
Zj[iCV] &lt;- mu

## generate example LD matrix and MAFs
library(mvtnorm)
nsamples = 1000

simx &lt;- function(nsnps, nsamples, S, maf=0.1) {
    mu &lt;- rep(0,nsnps)
    rawvars &lt;- rmvnorm(n=nsamples, mean=mu, sigma=S)
    pvars &lt;- pnorm(rawvars)
    x &lt;- qbinom(1-pvars, 1, maf)
}

S &lt;- (1 - (abs(outer(1:nsnps,1:nsnps,`-`))/nsnps))^4
X &lt;- simx(nsnps,nsamples,S)
LD &lt;- cor2(X)
maf &lt;- colMeans(X)

## generate V (variance of estimated effect sizes)
varbeta &lt;- Var.data.cc(f = maf, N = 5000, s = 0.5)

res &lt;- zj_pp(Zj, V = varbeta, nrep = 5, W = 0.2, Sigma = LD)

res[c(1:5), c(1:5)]


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
