<!DOCTYPE html><html><head><title>Help for package av</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="/home/deepayan/Rinstall/R-devel/lib/R/doc/html/R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {av}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#av_video_images'><p>Convert video to images</p></a></li>
<li><a href='#capturing'><p>Record Video from Graphics Device</p></a></li>
<li><a href='#demo'><p>Demo Video</p></a></li>
<li><a href='#encoding'><p>Encode or Convert Audio / Video</p></a></li>
<li><a href='#formats'><p>AV Formats</p></a></li>
<li><a href='#info'><p>Video Info</p></a></li>
<li><a href='#logging'><p>Logging</p></a></li>
<li><a href='#read_audio_fft'><p>Read audio binary and frequency data</p></a></li>
<li><a href='#window functions'><p>Window functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Working with Audio and Video in R</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Bindings to 'FFmpeg' <a href="http://www.ffmpeg.org/">http://www.ffmpeg.org/</a> AV library for working with 
    audio and video in R. Generates high quality video from images or R graphics with 
    custom audio. Also offers high performance tools for reading raw audio, creating
    'spectrograms', and converting between countless audio / video formats. This package 
    interfaces directly to the C API and does not require any command line utilities.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://ropensci.r-universe.dev/av">https://ropensci.r-universe.dev/av</a>, <a href="https://docs.ropensci.org/av/">https://docs.ropensci.org/av/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ropensci/av/issues">https://github.com/ropensci/av/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>FFmpeg (&gt;= 3.2); with at least libx264 and lame
(mp3) drivers. MacOS Homebrew: ffmpeg. Debian/Ubuntu:
libavfilter-dev. Fedora/CentOS: either ffmpeg-free-devel or
(via https://rpmfusion.org) ffmpeg-devel.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics</td>
</tr>
<tr>
<td>Config/pkgdown:</td>
<td>seewave, ggplot2, phonTools, signal, tuneR</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, ps, ggplot2, gapminder</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-04 22:26:50 UTC; jeroen</td>
</tr>
<tr>
<td>Author:</td>
<td>Jeroen Ooms <a href="https://orcid.org/0000-0002-4035-0289"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jeroen Ooms &lt;jeroen@berkeley.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-05 00:30:03 UTC</td>
</tr>
<tr>
<td>Built:</td>
<td>R 4.4.0; x86_64-pc-linux-gnu; 2024-01-02 07:12:51 UTC; unix</td>
</tr>
</table>
<hr>
<h2 id='av_video_images'>Convert video to images</h2><span id='topic+av_video_images'></span>

<h3>Description</h3>

<p>Splits a video file in a set of image files. Default image format is
jpeg which has good speed and compression. Use <code>format = "png"</code> for
losless images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>av_video_images(video, destdir = tempfile(), format = "jpg", fps = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="av_video_images_+3A_video">video</code></td>
<td>
<p>an input video</p>
</td></tr>
<tr><td><code id="av_video_images_+3A_destdir">destdir</code></td>
<td>
<p>directory where to save the png files</p>
</td></tr>
<tr><td><code id="av_video_images_+3A_format">format</code></td>
<td>
<p>image format such as <code>png</code> or <code>jpeg</code>, must be available from <code>av_encoders()</code></p>
</td></tr>
<tr><td><code id="av_video_images_+3A_fps">fps</code></td>
<td>
<p>sample rate of images. Use <code>NULL</code> to get all images.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For large input videos you can set fps to sample only a limited number
of images per second. This also works with fractions, for example <code>fps = 0.2</code>
will output one image for every 5 sec of video.
</p>

<hr>
<h2 id='capturing'>Record Video from Graphics Device</h2><span id='topic+capturing'></span><span id='topic+av_capture_graphics'></span><span id='topic+av_spectrogram_video'></span>

<h3>Description</h3>

<p>Runs the expression and captures all plots into a video. The <a href="av.html#topic+av_spectrogram_video">av_spectrogram_video</a>
function is a wrapper that plots data from <a href="av.html#topic+read_audio_fft">read_audio_fft</a> with a moving bar and
background audio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>av_capture_graphics(
  expr,
  output = "output.mp4",
  width = 720,
  height = 480,
  framerate = 1,
  vfilter = "null",
  audio = NULL,
  verbose = TRUE,
  ...
)

av_spectrogram_video(
  audio,
  output = "output.mp4",
  framerate = 25,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="capturing_+3A_expr">expr</code></td>
<td>
<p>an R expression that generates the graphics to capture</p>
</td></tr>
<tr><td><code id="capturing_+3A_output">output</code></td>
<td>
<p>name of the output file. File extension must correspond to a known
container format such as <code>mp4</code>, <code>mkv</code>, <code>mov</code>, or <code>flv</code>.</p>
</td></tr>
<tr><td><code id="capturing_+3A_width">width</code></td>
<td>
<p>width in pixels of the graphics device</p>
</td></tr>
<tr><td><code id="capturing_+3A_height">height</code></td>
<td>
<p>height in pixels of the graphics device</p>
</td></tr>
<tr><td><code id="capturing_+3A_framerate">framerate</code></td>
<td>
<p>video framerate in frames per seconds. This is the input fps, the
output fps may be different if you specify a filter that modifies speed or interpolates
frames.</p>
</td></tr>
<tr><td><code id="capturing_+3A_vfilter">vfilter</code></td>
<td>
<p>a string defining an ffmpeg filter graph. This is the same parameter
as the <code>-vf</code> argument in the <code>ffmpeg</code> command line utility.</p>
</td></tr>
<tr><td><code id="capturing_+3A_audio">audio</code></td>
<td>
<p>path to media file with audio stream</p>
</td></tr>
<tr><td><code id="capturing_+3A_verbose">verbose</code></td>
<td>
<p>emit some output and a progress meter counting processed images. Must
be <code>TRUE</code> or <code>FALSE</code> or an integer with a valid <a href="av.html#topic+av_log_level">av_log_level</a>.</p>
</td></tr>
<tr><td><code id="capturing_+3A_...">...</code></td>
<td>
<p>extra graphics parameters passed to <code><a href="grDevices.html#topic+png">png()</a></code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other av: 
<code><a href="utils.html#topic+demo">demo</a>()</code>,
<code><a href="av.html#topic+encoding">encoding</a></code>,
<code><a href="av.html#topic+formats">formats</a></code>,
<code><a href="av.html#topic+info">info</a></code>,
<code><a href="av.html#topic+logging">logging</a></code>,
<code><a href="av.html#topic+read_audio_fft">read_audio_fft</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(gapminder)
library(ggplot2)
makeplot &lt;- function(){
  datalist &lt;- split(gapminder, gapminder$year)
  lapply(datalist, function(data){
    p &lt;- ggplot(data, aes(gdpPercap, lifeExp, size = pop, color = continent)) +
      scale_size("population", limits = range(gapminder$pop)) + geom_point() + ylim(20, 90) +
      scale_x_log10(limits = range(gapminder$gdpPercap)) + ggtitle(data$year) + theme_classic()
    print(p)
  })
}

# Play 1 plot per sec, and use an interpolation filter to convert into 10 fps
video_file &lt;- file.path(tempdir(), 'output.mp4')
av_capture_graphics(makeplot(), video_file, 1280, 720, res = 144, vfilter = 'framerate=fps=10')
av::av_media_info(video_file)
# utils::browseURL(video_file)
</code></pre>

<hr>
<h2 id='demo'>Demo Video</h2><span id='topic+demo'></span><span id='topic+av_demo'></span>

<h3>Description</h3>

<p>Generates random video for testing purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>av_demo(
  output = "demo.mp4",
  width = 960,
  height = 720,
  framerate = 5,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="demo_+3A_output">output</code></td>
<td>
<p>name of the output file. File extension must correspond to a known
container format such as <code>mp4</code>, <code>mkv</code>, <code>mov</code>, or <code>flv</code>.</p>
</td></tr>
<tr><td><code id="demo_+3A_width">width</code></td>
<td>
<p>width in pixels of the graphics device</p>
</td></tr>
<tr><td><code id="demo_+3A_height">height</code></td>
<td>
<p>height in pixels of the graphics device</p>
</td></tr>
<tr><td><code id="demo_+3A_framerate">framerate</code></td>
<td>
<p>video framerate in frames per seconds. This is the input fps, the
output fps may be different if you specify a filter that modifies speed or interpolates
frames.</p>
</td></tr>
<tr><td><code id="demo_+3A_verbose">verbose</code></td>
<td>
<p>emit some output and a progress meter counting processed images. Must
be <code>TRUE</code> or <code>FALSE</code> or an integer with a valid <a href="av.html#topic+av_log_level">av_log_level</a>.</p>
</td></tr>
<tr><td><code id="demo_+3A_...">...</code></td>
<td>
<p>other parameters passed to <a href="av.html#topic+av_capture_graphics">av_capture_graphics</a>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other av: 
<code><a href="av.html#topic+capturing">capturing</a></code>,
<code><a href="av.html#topic+encoding">encoding</a></code>,
<code><a href="av.html#topic+formats">formats</a></code>,
<code><a href="av.html#topic+info">info</a></code>,
<code><a href="av.html#topic+logging">logging</a></code>,
<code><a href="av.html#topic+read_audio_fft">read_audio_fft</a>()</code>
</p>

<hr>
<h2 id='encoding'>Encode or Convert Audio / Video</h2><span id='topic+encoding'></span><span id='topic+av_encode_video'></span><span id='topic+av'></span><span id='topic+av_video_convert'></span><span id='topic+av_audio_convert'></span>

<h3>Description</h3>

<p>Encodes a set of images into a video, using custom container format, codec, fps,
<a href="https://ffmpeg.org/ffmpeg-filters.html#Video-Filters">video filters</a>, and audio
track. If input contains video files, this effectively combines and converts them
to the specified output format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>av_encode_video(
  input,
  output = "output.mp4",
  framerate = 24,
  vfilter = "null",
  codec = NULL,
  audio = NULL,
  verbose = TRUE
)

av_video_convert(video, output = "output.mp4", verbose = TRUE)

av_audio_convert(
  audio,
  output = "output.mp3",
  format = NULL,
  channels = NULL,
  sample_rate = NULL,
  start_time = NULL,
  total_time = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encoding_+3A_input">input</code></td>
<td>
<p>a vector with image or video files. A video input file is treated
as a series of images. All input files should have the same width and height.</p>
</td></tr>
<tr><td><code id="encoding_+3A_output">output</code></td>
<td>
<p>name of the output file. File extension must correspond to a known
container format such as <code>mp4</code>, <code>mkv</code>, <code>mov</code>, or <code>flv</code>.</p>
</td></tr>
<tr><td><code id="encoding_+3A_framerate">framerate</code></td>
<td>
<p>video framerate in frames per seconds. This is the input fps, the
output fps may be different if you specify a filter that modifies speed or interpolates
frames.</p>
</td></tr>
<tr><td><code id="encoding_+3A_vfilter">vfilter</code></td>
<td>
<p>a string defining an ffmpeg filter graph. This is the same parameter
as the <code>-vf</code> argument in the <code>ffmpeg</code> command line utility.</p>
</td></tr>
<tr><td><code id="encoding_+3A_codec">codec</code></td>
<td>
<p>name of the video codec as listed in <a href="av.html#topic+av_encoders">av_encoders</a>. The
default is <code>libx264</code> for most formats, which usually the best choice.</p>
</td></tr>
<tr><td><code id="encoding_+3A_audio">audio</code></td>
<td>
<p>audio or video input file with sound for the output video</p>
</td></tr>
<tr><td><code id="encoding_+3A_verbose">verbose</code></td>
<td>
<p>emit some output and a progress meter counting processed images. Must
be <code>TRUE</code> or <code>FALSE</code> or an integer with a valid <a href="av.html#topic+av_log_level">av_log_level</a>.</p>
</td></tr>
<tr><td><code id="encoding_+3A_video">video</code></td>
<td>
<p>input video file with optionally also an audio track</p>
</td></tr>
<tr><td><code id="encoding_+3A_format">format</code></td>
<td>
<p>a valid format name from the list of <code>av_muxers()</code>. Default
<code>NULL</code> tries to guess a format from the file extension.</p>
</td></tr>
<tr><td><code id="encoding_+3A_channels">channels</code></td>
<td>
<p>number of output channels. Default <code>NULL</code> is to match input</p>
</td></tr>
<tr><td><code id="encoding_+3A_sample_rate">sample_rate</code></td>
<td>
<p>output sampling rate. Default <code>NULL</code> is to match input</p>
</td></tr>
<tr><td><code id="encoding_+3A_start_time">start_time</code></td>
<td>
<p>number greater than 0, seeks in the input file to position.</p>
</td></tr>
<tr><td><code id="encoding_+3A_total_time">total_time</code></td>
<td>
<p>approximate number of seconds at which to limit the duration
of the output file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The target container format is automatically determined from the file extension of
the output file, for example <code>mp4</code>, <code>mkv</code>, <code>mov</code>, or <code>flv</code>. Most systems also
support <code>gif</code> output, but the compression~quality for gif is quite bad.
The <a href="https://cran.r-project.org/package=gifski">gifski</a> package is better suited
for generating animated gif files.
</p>
<p>It is recommended to use let ffmpeg choose the suitable codec for a given container
format. Most video formats default to the <code>libx264</code> video codec which has excellent
compression and works on all modern <a href="https://caniuse.com/#search=h264">browsers</a>,
operating systems, and digital TVs.
</p>
<p>It is safe to interrupt the encoding process by pressing CTRL+C, or via <a href="base.html#topic+setTimeLimit">setTimeLimit</a>.
When the encoding is interrupted, the output stream is properly finalized and all open
files and resources are properly closed.
</p>


<h3>See Also</h3>

<p>Other av: 
<code><a href="av.html#topic+capturing">capturing</a></code>,
<code><a href="utils.html#topic+demo">demo</a>()</code>,
<code><a href="av.html#topic+formats">formats</a></code>,
<code><a href="av.html#topic+info">info</a></code>,
<code><a href="av.html#topic+logging">logging</a></code>,
<code><a href="av.html#topic+read_audio_fft">read_audio_fft</a>()</code>
</p>

<hr>
<h2 id='formats'>AV Formats</h2><span id='topic+formats'></span><span id='topic+av_encoders'></span><span id='topic+av_decoders'></span><span id='topic+av_filters'></span><span id='topic+av_muxers'></span><span id='topic+av_demuxers'></span>

<h3>Description</h3>

<p>List supported filters, codecs and container formats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>av_encoders()

av_decoders()

av_filters()

av_muxers()

av_demuxers()
</code></pre>


<h3>Details</h3>

<p>Encoders and decoders convert between raw video/audio frames and compressed stream
data for storage or transfer. However such a compressed data stream by itself does
not constitute a valid video format yet. Muxers are needed to interleave one or more
audio/video/subtitle streams, along with timestamps, metadata, etc, into a proper
file format, such as mp4 or mkv.
</p>
<p>Conversely, demuxers are needed to read a file format into the separate data streams
for subsequent decoding into raw audio/video frames. Most operating systems natively
support demuxing and decoding common formats and codecs, needed to play those videos.
However for encoding and muxing such videos, ffmpeg must have been configured with
specific external libraries for a given codec or format.
</p>


<h3>See Also</h3>

<p>Other av: 
<code><a href="av.html#topic+capturing">capturing</a></code>,
<code><a href="utils.html#topic+demo">demo</a>()</code>,
<code><a href="av.html#topic+encoding">encoding</a></code>,
<code><a href="av.html#topic+info">info</a></code>,
<code><a href="av.html#topic+logging">logging</a></code>,
<code><a href="av.html#topic+read_audio_fft">read_audio_fft</a>()</code>
</p>

<hr>
<h2 id='info'>Video Info</h2><span id='topic+info'></span><span id='topic+av_media_info'></span><span id='topic+av_video_info'></span>

<h3>Description</h3>

<p>Get video info such as width, height, format, duration and framerate.
This may also be used for audio input files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>av_media_info(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="info_+3A_file">file</code></td>
<td>
<p>path to an existing file</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other av: 
<code><a href="av.html#topic+capturing">capturing</a></code>,
<code><a href="utils.html#topic+demo">demo</a>()</code>,
<code><a href="av.html#topic+encoding">encoding</a></code>,
<code><a href="av.html#topic+formats">formats</a></code>,
<code><a href="av.html#topic+logging">logging</a></code>,
<code><a href="av.html#topic+read_audio_fft">read_audio_fft</a>()</code>
</p>

<hr>
<h2 id='logging'>Logging</h2><span id='topic+logging'></span><span id='topic+av_log_level'></span>

<h3>Description</h3>

<p>Get or set the <a href="https://www.ffmpeg.org/doxygen/4.0/group__lavu__log__constants.html">log level</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>av_log_level(set = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logging_+3A_set">set</code></td>
<td>
<p>new <a href="https://www.ffmpeg.org/doxygen/4.0/group__lavu__log__constants.html">log level</a> value</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other av: 
<code><a href="av.html#topic+capturing">capturing</a></code>,
<code><a href="utils.html#topic+demo">demo</a>()</code>,
<code><a href="av.html#topic+encoding">encoding</a></code>,
<code><a href="av.html#topic+formats">formats</a></code>,
<code><a href="av.html#topic+info">info</a></code>,
<code><a href="av.html#topic+read_audio_fft">read_audio_fft</a>()</code>
</p>

<hr>
<h2 id='read_audio_fft'>Read audio binary and frequency data</h2><span id='topic+read_audio_fft'></span><span id='topic+read_audio_bin'></span>

<h3>Description</h3>

<p>Reads raw audio data from any common audio or video format. Use <a href="av.html#topic+read_audio_bin">read_audio_bin</a> to
get raw PCM audio samples, or <a href="av.html#topic+read_audio_fft">read_audio_fft</a> to stream-convert directly into
frequency domain (spectrum) data using FFmpeg built-in FFT.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_audio_fft(
  audio,
  window = hanning(1024),
  overlap = 0.75,
  sample_rate = NULL,
  start_time = NULL,
  end_time = NULL
)

read_audio_bin(
  audio,
  channels = NULL,
  sample_rate = NULL,
  start_time = NULL,
  end_time = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_audio_fft_+3A_audio">audio</code></td>
<td>
<p>path to the input sound or video file containing the audio stream</p>
</td></tr>
<tr><td><code id="read_audio_fft_+3A_window">window</code></td>
<td>
<p>vector with weights defining the moving <a href="av.html#topic+hanning">fft window function</a>.
The length of this vector is the size of the window and hence determines the output
frequency range.</p>
</td></tr>
<tr><td><code id="read_audio_fft_+3A_overlap">overlap</code></td>
<td>
<p>value between 0 and 1 of overlap proportion between moving fft windows</p>
</td></tr>
<tr><td><code id="read_audio_fft_+3A_sample_rate">sample_rate</code></td>
<td>
<p>downsample audio to reduce FFT output size. Default keeps sample
rate from the input file.</p>
</td></tr>
<tr><td><code id="read_audio_fft_+3A_start_time">start_time</code>, <code id="read_audio_fft_+3A_end_time">end_time</code></td>
<td>
<p>position (in seconds) to cut input stream to be processed.</p>
</td></tr>
<tr><td><code id="read_audio_fft_+3A_channels">channels</code></td>
<td>
<p>number of output channels, set to 1 to convert to mono sound</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently <a href="av.html#topic+read_audio_fft">read_audio_fft</a> automatically converts input audio to mono channel such
that we get a single matrix. Use the <code>plot()</code> method on data returned by <a href="av.html#topic+read_audio_fft">read_audio_fft</a>
to show the spectrogram. The <a href="av.html#topic+av_spectrogram_video">av_spectrogram_video</a> generates a video that plays
the audio while showing an animated spectrogram with moving status bar, which is
very cool.
</p>


<h3>See Also</h3>

<p>Other av: 
<code><a href="av.html#topic+capturing">capturing</a></code>,
<code><a href="utils.html#topic+demo">demo</a>()</code>,
<code><a href="av.html#topic+encoding">encoding</a></code>,
<code><a href="av.html#topic+formats">formats</a></code>,
<code><a href="av.html#topic+info">info</a></code>,
<code><a href="av.html#topic+logging">logging</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use a 5 sec fragment
wonderland &lt;- system.file('samples/Synapsis-Wonderland.mp3', package='av')

# Read initial 5 sec as as frequency spectrum
fft_data &lt;- read_audio_fft(wonderland, end_time = 5.0)
dim(fft_data)

# Plot the spectrogram
plot(fft_data)

# Show other parameters
dim(read_audio_fft(wonderland, end_time = 5.0, hamming(2048)))
dim(read_audio_fft(wonderland, end_time = 5.0, hamming(4096)))
</code></pre>

<hr>
<h2 id='window+20functions'>Window functions</h2><span id='topic+window+20functions'></span><span id='topic+hanning'></span><span id='topic+hamming'></span><span id='topic+blackman'></span><span id='topic+bartlett'></span><span id='topic+welch'></span><span id='topic+flattop'></span><span id='topic+bharris'></span><span id='topic+bnuttall'></span><span id='topic+sine'></span><span id='topic+nuttall'></span><span id='topic+bhann'></span><span id='topic+lanczos'></span><span id='topic+gauss'></span><span id='topic+tukey'></span><span id='topic+dolph'></span><span id='topic+cauchy'></span><span id='topic+parzen'></span><span id='topic+bohman'></span>

<h3>Description</h3>

<p>Several common <a href="https://en.wikipedia.org/wiki/Window_function">windows function</a>
generators. The functions return a vector of weights to use in <a href="av.html#topic+read_audio_fft">read_audio_fft</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hanning(n)

hamming(n)

blackman(n)

bartlett(n)

welch(n)

flattop(n)

bharris(n)

bnuttall(n)

sine(n)

nuttall(n)

bhann(n)

lanczos(n)

gauss(n)

tukey(n)

dolph(n)

cauchy(n)

parzen(n)

bohman(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="window+2B20functions_+3A_n">n</code></td>
<td>
<p>size of the window (number of weights to generate)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Window functions
plot(hanning(1024), type = 'l', xlab = 'window', ylab = 'weight')
lines(hamming(1024), type = 'l', col = 'red')
lines(bartlett(1024), type = 'l', col = 'blue')
lines(welch(1024), type = 'l', col = 'purple')
lines(flattop(1024), type = 'l', col = 'darkgreen')
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
