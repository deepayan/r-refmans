<!DOCTYPE html><html lang="en"><head><title>Help for package mada</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mada}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mada-package'>
<p>Meta-Analysis of diagnostic accuracy studies</p>
mada</a></li>
<li><a href='#AUC'>
<p>Area under the curve (AUC)</p></a></li>
<li><a href='#CIrho'>
<p>Confidence intervals for Spearman's <code class="reqn">\rho</code>.</p></a></li>
<li><a href='#cochran.Q'>
<p>Cochran's Q statistic</p></a></li>
<li><a href='#crosshair'>
<p>Crosshair plot</p></a></li>
<li><a href='#forest'>
<p>Forest plot for univariate measures</p></a></li>
<li><a href='#mada-data'><p>Diagnostic accuracy data</p></a></li>
<li><a href='#madad'>
<p>Descriptive statistics for meta-analysis of diagnostic accuracy</p></a></li>
<li><a href='#madauni'>
<p>Meta-Analyisis of univariate measures of diagnostic accuracy</p></a></li>
<li><a href='#madauni-class'>
<p>Methods for the class <code>madauni</code>.</p></a></li>
<li><a href='#mslSROC'>
<p>Plot the Moses-Shapiro-Littenberg SROC curve</p></a></li>
<li><a href='#phm'>
<p>Diagnostic Meta-Analysis with the proportional hazards model approach of Holling et.al (2012)</p></a></li>
<li><a href='#phm-class'>
<p>Methods for <code>phm</code> objects.</p></a></li>
<li><a href='#predv_d'>
<p>Estimation of Distributions of Predictive Values Based on Prevalence Probability Distributions and Pooled Sensitivities and Specificities</p></a></li>
<li><a href='#predv_d-class'>
<p>Methods for the class <code>predv_d</code>.</p></a></li>
<li><a href='#predv_r'>
<p>Estimation of Distributions of Predictive Values Based on Prevalence Ranges and Pooled Sensitivities and Specificities</p></a></li>
<li><a href='#predv_r-class'>
<p>Methods for the class <code>predv_r</code>.</p></a></li>
<li><a href='#reitsma'>
<p>Fit the bivariate model of Reitsma et al. (2005) and extensions.</p></a></li>
<li><a href='#reitsma-class'>
<p>Methods for <code>reitsma</code> objects.</p></a></li>
<li><a href='#ROCellipse'>
<p>Confidence Regions on ROC space</p></a></li>
<li><a href='#rsSROC'>
<p>Plot the Ruecker-Schumacher (2010) SROC curve</p></a></li>
<li><a href='#sens'><p>Sensitivity, Specificity and False Positive Rate</p></a></li>
<li><a href='#SummaryPts'>
<p>Use the Zwindermann &amp; Bossuyt (2008) MCMC procedure to generate summary points (positive and negative likelihood ratio, diagnostic odds ratio) for the Reitsma et al. (2005) bivariate model</p></a></li>
<li><a href='#talpha'>
<p>The <code class="reqn">t_\alpha</code> transformation as a link function for binary GLMs.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Meta-Analysis of Diagnostic Accuracy</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.11</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-07-11</td>
</tr>
<tr>
<td>Author:</td>
<td>Philipp Doebler with contributions from Bernardo Sousa-Pinto</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions for diagnostic meta-analysis. Next to basic analysis and visualization the bivariate Model of Reitsma et al. (2005) that is equivalent to the HSROC of Rutter &amp; Gatsonis (2001) can be fitted. A new approach based to diagnostic meta-analysis of Holling et al. (2012) is also available. Standard methods like summary, plot and so on are provided.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), stats, mvtnorm, ellipse, mvmeta, metafor</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td>r-forge.r-project.org/projects/mada/</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-15 19:24:21 UTC; doebler</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-15 19:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mada-package'>
Meta-Analysis of diagnostic accuracy studies
mada
</h2><span id='topic+mada-package'></span><span id='topic+mada'></span>

<h3>Description</h3>

<p>This package provides functions for diagnostic meta-analysis. Next to basic analysis and visualization the bivariate Model of Reitsma et al. (2005) that is equivalent to the HSROC of Rutter&amp;Gatsonis (2001) can be fitted. A new approach based to diagnostic meta-analysis of Holling et al. (2012) is also available. Standard methods like summary, plot and so on are provided.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> mada</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.5.8</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2017-10-06</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The package provides tools for the meta-analysis of diagnostic accuracy data. For this the number true positives (TP), false negatives (FN), true negatives (TN) and false postives (FP) for each study must be known. The package can fit the bivariate model of Reitsma et al (2005), a bivariate random effects model. This model has been shown by Harbord et al. (2007) to be equivalent to the HSROC proposed by Rutter &amp; Gatsonis (2001). We approach  this model as a linear mixed effects model to avoid the complications of non-linear mixed effects model. The main function to fit such model is <code><a href="#topic+reitsma">reitsma</a></code> and standard methods are available for the output of this function.
</p>


<h3>Author(s)</h3>

<p>Author and Maintainer: Philipp Doebler
</p>


<h3>References</h3>

<p>Rutter, C., &amp; Gatsonis, C. (2001). &ldquo;A hierarchical regression approach to meta-analysis of
diagnostic test accuracy evaluations.&rdquo; <em>Statistics in Medicine</em>, <b>20</b>, 2865&ndash;2884.
</p>
<p>Reitsma, J., Glas, A., Rutjes, A., Scholten, R., Bossuyt, P., &amp; Zwinderman, A. (2005).
&ldquo;Bivariate analysis of sensitivity and specificity produces informative summary
measures in diagnostic reviews.&rdquo; <em>Journal of Clinical Epidemiology</em>, <b>58</b>, 982&ndash;990.
</p>
<p>Harbord, R., Deeks, J., Egger, M., Whiting, P., &amp; Sterne, J. (2007). &ldquo;A unification of
models for meta-analysis of diagnostic accuracy studies.&rdquo; <em>Biostatistics</em>, <b>8</b>, 239&ndash;251.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reitsma">reitsma</a></code>
</p>

<hr>
<h2 id='AUC'>
Area under the curve (AUC)
</h2><span id='topic+AUC'></span><span id='topic+auc'></span><span id='topic+AUC.default'></span><span id='topic+AUC.reitsma'></span><span id='topic+AUC.phm'></span>

<h3>Description</h3>

<p>Calculates the area under the curve given a function or a fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
AUC(x, fpr = 1:99/100, ...)
## S3 method for class 'phm'
AUC(x, level = 0.95, ...)
## S3 method for class 'reitsma'
AUC(x, fpr = 1:99/100, sroc.type = "ruttergatsonis", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AUC_+3A_x">x</code></td>
<td>
<p>a function with range and domain in ROC space (default method) or an object of class <code><a href="#topic+phm">phm</a></code> or <code><a href="#topic+reitsma">reitsma</a></code>.</p>
</td></tr>
<tr><td><code id="AUC_+3A_fpr">fpr</code></td>
<td>
<p>numeric vector, points on which the (S)ROC curve is evaluated</p>
</td></tr>
<tr><td><code id="AUC_+3A_level">level</code></td>
<td>
<p>numeric, confidence level for the calculations of confidence intervals.
</p>
</td></tr>
<tr><td><code id="AUC_+3A_sroc.type">sroc.type</code></td>
<td>
<p>character, which SROC curve should be used to calculate the AUC? Besides the default <code>ruttergatsonis</code> the option <code>naive</code> is available.</p>
</td></tr>
<tr><td><code id="AUC_+3A_...">...</code></td>
<td>
<p>further arguments, currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The area under the curve is calculated using the trapezoidal rule. The argument <code>fpr</code> is the grid on which the (S)ROC curve is evaluated. In many cases the default grid will contain points on which the SROC curve can only be calculated by extrapolation; however if only a subinterval is specified a <em>partial AUC</em> is calculated and the AUC value might differ substantially.
</p>
<p>For <code><a href="#topic+phm">phm</a></code> objects the AUC and its confidence interval is calculated analytically, for <code><a href="#topic+reitsma">reitsma</a></code> objects a call to the default method is invoked.
</p>


<h3>Value</h3>

<p>An object of the class <code>AUC</code> which is really a list with component <code>AUC</code> and an optional component <code>ci</code>, which is currently only available from the <code>AUC</code> method for <code><a href="#topic+phm">phm</a></code> ojects.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AuditC)
AUC(phm(AuditC))
</code></pre>

<hr>
<h2 id='CIrho'>
Confidence intervals for Spearman's <code class="reqn">\rho</code>.
</h2><span id='topic+CIrho'></span>

<h3>Description</h3>

<p>Using Fisher's z-transformation (<code><a href="base.html#topic+atanh">atanh</a></code>) and the classic normal approximation confidence intervals for a vector of correlations is computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CIrho(rho, N, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CIrho_+3A_rho">rho</code></td>
<td>
<p>numeric vector, must be between -1 and 1.</p>
</td></tr>
<tr><td><code id="CIrho_+3A_n">N</code></td>
<td>
<p>integer vector, sample sizes.
</p>
</td></tr>
<tr><td><code id="CIrho_+3A_level">level</code></td>
<td>
<p>numeric, confidence level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with first column <code>rho</code> and two further columns with the lower and upper bound. 
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CIrho(c(0.34,0.19), c(22, 48), level = 0.80)
</code></pre>

<hr>
<h2 id='cochran.Q'>
Cochran's Q statistic
</h2><span id='topic+cochran.Q'></span>

<h3>Description</h3>

<p>Given estimates from primary studies and the weights of the single studies calculate Cochran's Q as a measure of heterogeneity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cochran.Q(x, weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cochran.Q_+3A_x">x</code></td>
<td>
<p>numeric, typically a vector of effect sizes like (log-)OR</p>
</td></tr>
<tr><td><code id="cochran.Q_+3A_weights">weights</code></td>
<td>
<p>numeric, see Details</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In fixed effects settings the weights are often inverse proportional to the variances of the primary studies. Cochran's Q is known to have low power to detect heterogeneity.
</p>


<h3>Value</h3>

<p>A named vector of length 3. First element is <code>Q</code> followed by the <code>p-value</code> and the degrees of freedom.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>

<hr>
<h2 id='crosshair'>
Crosshair plot
</h2><span id='topic+crosshair'></span><span id='topic+crosshair.default'></span>

<h3>Description</h3>

<p>Produces a crosshair plot or adds such a plot to an existing plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
crosshair(x, correction = 0.5, level = 0.95, method = "wilson",
                      xlim = c(0,1), ylim = c(0,1), length = 0.1, pch = 1, 
                      add = FALSE, suppress = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crosshair_+3A_x">x</code></td>
<td>
<p>a data frame with variables including <code>TP</code>, <code>FN</code>, <code>FP</code>, <code>TN</code>, alternatively a matrix with column names including these.</p>
</td></tr>
<tr><td><code id="crosshair_+3A_correction">correction</code></td>
<td>
<p>numeric, continuity correction applied to zero cells.</p>
</td></tr>
<tr><td><code id="crosshair_+3A_level">level</code></td>
<td>
<p>numeric, confidence level for the calculations of confidence intervals.
</p>
</td></tr>
<tr><td><code id="crosshair_+3A_method">method</code></td>
<td>
<p>character, method used to calculate the confidence intervals for sensitivities, specificities and false positive rates. One of <code>"wald"</code>, <code>"wilson"</code>, <code>"agresti-coull"</code>, <code>"jeffreys"</code>, <code>"modified wilson"</code>, <code>"modified jeffreys"</code>, <code>"clopper-pearson"</code>, <code>"arcsine"</code>, <code>"logit"</code>, <code>"witting"</code></p>
</td></tr>  
<tr><td><code id="crosshair_+3A_xlim">xlim</code></td>
<td>
<p>part of ROC space to be plotted</p>
</td></tr>
<tr><td><code id="crosshair_+3A_ylim">ylim</code></td>
<td>
<p>part of ROC space to be plotted</p>
</td></tr>
<tr><td><code id="crosshair_+3A_length">length</code></td>
<td>
<p>length of &quot;whiskers&quot; of the crosshair.</p>
</td></tr>
<tr><td><code id="crosshair_+3A_pch">pch</code></td>
<td>
<p>Symbol used to plot point estimates. Use <code>pch = ""</code> to suppress plotting point estimates.</p>
</td></tr>
<tr><td><code id="crosshair_+3A_add">add</code></td>
<td>
<p>logical, should the plot be added to the current plot?</p>
</td></tr>
<tr><td><code id="crosshair_+3A_suppress">suppress</code></td>
<td>
<p>logical, should the warnings produced by the internal call to <code>madad</code> be suppressed? Defaults to <code>TRUE</code>, since only the diagnostic accuracies and their confidence intervals are used in subsequent calculations.</p>
</td></tr>
<tr><td><code id="crosshair_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Crosshair plots go back to Phillips et al. (2010). Note that for fits of the <code><a href="#topic+reitsma">reitsma</a></code> function a crosshair method is available to plot pooled estimate, see <code><a href="#topic+reitsma-class">reitsma-class</a></code>.
</p>


<h3>Value</h3>

<p>Besides plotting, the function returns an invisible <code>NULL</code>.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Phillips, B., Stewart, L.A., &amp; Sutton, A.J. (2010). &ldquo;'Cross hairs' plots for diagnostic meta-analysis.&rdquo; <em>Research Synthesis Methods</em>, <b>1</b>, 308&ndash;315.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ROCellipse">ROCellipse</a></code>, <code><a href="#topic+reitsma-class">reitsma-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AuditC)
crosshair(AuditC)
</code></pre>

<hr>
<h2 id='forest'>
Forest plot for univariate measures
</h2><span id='topic+forest'></span><span id='topic+forestmada'></span><span id='topic+forest.madad'></span><span id='topic+forest.madauni'></span>

<h3>Description</h3>

<p>Produce a forest plot. Includes graphical summary of results if applied to output of suitable model-fitting function. <code>forest</code> methods for <code><a href="#topic+madad">madad</a></code> and <code><a href="#topic+madauni">madauni</a></code> objects are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'madad'
forest(x, type = "sens", log = FALSE, ...)
## S3 method for class 'madauni'
forest(x, log = TRUE, ...)
forestmada(x, ci, plotci = TRUE, main = "Forest plot", xlab = NULL,
          digits = 2L,  snames = NULL, subset = NULL, pch = 15, 
          cex = 1, cipoly = NULL, polycol = NA, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forest_+3A_x">x</code></td>
<td>
<p>an object for which a <code>forest</code> method exists or (in the case of <code>foresmada</code>) a vector of point estimates.</p>
</td></tr>
<tr><td><code id="forest_+3A_ci">ci</code></td>
<td>
<p>numeric matrix, each row corresponds to a confidence interval (the first column being the lower bound and the second the upper).</p>
</td></tr>
<tr><td><code id="forest_+3A_plotci">plotci</code></td>
<td>
<p>logical, should the effects sizes and their confidence intervals be added to the plot (as text)?</p>
</td></tr>
<tr><td><code id="forest_+3A_main">main</code></td>
<td>
<p>character, heading of plot.</p>
</td></tr>
<tr><td><code id="forest_+3A_xlab">xlab</code></td>
<td>
<p>label of x-axis.</p>
</td></tr>
<tr><td><code id="forest_+3A_digits">digits</code></td>
<td>
<p>integer, number of digits for axis labels and confidence intervals.</p>
</td></tr>
<tr><td><code id="forest_+3A_snames">snames</code></td>
<td>
<p>character vector, study names. If <code>NULL</code>, generic study names are generated.</p>
</td></tr>
<tr><td><code id="forest_+3A_subset">subset</code></td>
<td>
<p>integer vector, allows to study only a subset of studies in the plot. One can also reorder the studies with the help of this argument.</p>
</td></tr>
<tr><td><code id="forest_+3A_pch">pch</code></td>
<td>
<p>integer, plotting symbol, defaults to a small square. Also see <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.</p>
</td></tr>
<tr><td><code id="forest_+3A_cex">cex</code></td>
<td>
<p>numeric, scaling parameter for study names and confidence intervals.</p>
</td></tr>
<tr><td><code id="forest_+3A_cipoly">cipoly</code></td>
<td>
<p>logical vector, which confidence interval should be plotted as a polygon? Useful for summary estimates. If set to <code>NULL</code>, regular confidence intervals will be used.</p>
</td></tr>
<tr><td><code id="forest_+3A_polycol">polycol</code></td>
<td>
<p>color of the polygon(s), passed on to <code><a href="graphics.html#topic+polygon">polygon</a></code>. The default value of <code>NA</code> implies no color.</p>
</td></tr>
<tr><td><code id="forest_+3A_type">type</code></td>
<td>
<p>character, one of <code>sens</code>, <code>spec</code>, <code>negLR</code>, <code>posLR</code> or <code>DOR</code>.</p>
</td></tr>
<tr><td><code id="forest_+3A_log">log</code></td>
<td>
<p>logical, should the log-transformed values be plotted?</p>
</td></tr>
<tr><td><code id="forest_+3A_...">...</code></td>
<td>
<p>arguments to be passed on to <code>forestmada</code> and further on to other plotting functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces a forest plot to graphically assess heterogeneity. Note that <code>forestmada</code> is called internally, so that the <code>...</code> argument can be used to pass on arguments to this function; see the examples. 
</p>


<h3>Value</h3>

<p>Returns and invisible <code>NULL</code>.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+madad">madad</a></code>, <code><a href="#topic+madauni">madauni</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AuditC)

## Forest plot of log DOR with random effects summary estimate
forest(madauni(AuditC))

## Forest plot of negative likelihood ratio (no log transformation)
## color of the polygon: light grey 
## draw the individual estimate as filled circles
forest(madauni(AuditC, type = "negLR"), 
       log = FALSE, polycol = "lightgrey", pch = 19)

## Paired forest plot of sensitivities and specificities
## Might look ugly if device region is too small
old.par &lt;- par()
AuditC.d &lt;- madad(AuditC)

plot.new()
par(fig = c(0, 0.5, 0, 1), new = TRUE)
forest(AuditC.d, type = "sens", xlab = "Sensitivity")
par(fig = c(0.5, 1, 0, 1),  new = TRUE)
forest(AuditC.d, type = "spec", xlab = "Specificity")

par(old.par)

## Including study names
## Using Letters as dummies
forest(AuditC.d, type = "spec",  xlab = "Specificity",
      snames = LETTERS[1:14])

</code></pre>

<hr>
<h2 id='mada-data'>Diagnostic accuracy data</h2><span id='topic+mada-data'></span><span id='topic+AuditC'></span><span id='topic+Dementia'></span><span id='topic+IAQ'></span><span id='topic+SAQ'></span><span id='topic+skin_tests'></span><span id='topic+smoking'></span>

<h3>Description</h3>

<p>Six data frames with diagnostic accuracy data from binary test outcomes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("AuditC")
data("Dementia")
data("IAQ")
data("SAQ")
data("skin_tests")
data("smoking")
</code></pre>


<h3>Format</h3>

<p>Six data frames with frequencies of true positives, false negatives, false positives and true negatives. The data set <code>smoking</code> combines the <code>IAQ</code> and <code>SAQ</code> data sets and these are the only ones with variables in addition to the frequencies. 
</p>

<dl>
<dt>TP</dt><dd><p>numeric. number of true positives</p>
</dd>  
<dt>FN</dt><dd><p>numeric. number of false negatives</p>
</dd>  
<dt>FP</dt><dd><p>numeric. number of false positives</p>
</dd>  
<dt>TN</dt><dd><p>numeric. number of true negatives</p>
</dd>  
<dt>type</dt><dd><p>factor. self-administered (SAQ) or interviewer-administered questionnaire (IAQ)</p>
</dd>
<dt>author</dt><dd><p>factor. Author(s) of review and year</p>
</dd>
<dt>study_id</dt><dd><p>numeric. ID variable for study</p>
</dd>
<dt>result_id</dt><dd><p>integer. ID variable for (dependent) 2x2-tables from the same study</p>
</dd>
<dt>population</dt><dd><p>factor. general (G) or student (S) population</p>
</dd>
</dl>



<h3>Details</h3>

<p>The <code>AuditC</code> data is from Kriston et al. (2008). The <code>Dementia</code> from Mitchell (2009) and the <code>SAQ</code> and <code>IAQ</code> data are subsets from the data in Patrick et al. (1994), while <code>smoking</code> is the complete data. The <code>skin_tests</code> data is part of the data from Sousa-Pinto et al. (2021) and concerns the accuracy of penicillin allergy skin tests.
</p>


<h3>Source</h3>

<p>Kriston, L., H\&quot;oelzel, L., Weiser, A., Berner, M., &amp; Haerter, M. (2008).&ldquo; Meta-analysis: Are 3
Questions Enough to Detect Unhealthy Alcohol Use?&rdquo; <em> Annals of Internal Medicine</em>,
<b>149</b>, 879&ndash;888.
</p>
<p>Mitchell, A. (2009). &ldquo;A meta-analysis of the accuracy of the mini-mental state examination
in the detection of dementia and mild cognitive impairment.&rdquo; <em>Journal of Psychiatric
Research</em>, <b>43</b>, 411&ndash;431.
</p>
<p>Patrick, D., Cheadle, A., Thompson, D., Diehr, P., Koepsell, T., &amp; Kinne, S. (1994). &ldquo;The
validity of self-reported smoking: a review and meta-analysis.&rdquo; <em>American Journal of
Public Health</em>, <b>84</b>, 1086&ndash;1093.
</p>
<p>Sousa-Pinto, B., Tarrio, I., Blumenthal, K.G., Araujo, L., Azevedo, L.F., Delgado, L. &amp; Fonseca, J.A. (2021). &ldquo;Accuracy of penicillin allergy diagnostic tests: A systematic review and meta-analysis.&rdquo; <em>Journal of Allergy and Clinical Immunology</em>, <b>147</b>, 296&ndash;308.
</p>

<hr>
<h2 id='madad'>
Descriptive statistics for meta-analysis of diagnostic accuracy
</h2><span id='topic+madad'></span><span id='topic+madad-class'></span><span id='topic+print.madad'></span>

<h3>Description</h3>

<p>Given the frequencies of true positives, false negative, false positives and true negatives from primary diagnostic studies <code>madad</code> calculates various summary statistics. Apart from sensitivities, specificities and false positive rates the function also calculates the diagnostic odds ratio (DOR) and the positve and negative likelihood ratios, together with their respective confidence intervals. Also two hypothesis tests are calculated: one testing the equality of the sensitivities and the same for the false positive rates. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>madad(x = NULL, TP, FN, FP, TN, level = 0.95, correction = 0.5, 
  correction.control = "all", method = "wilson", yates = TRUE, 
  suppress = TRUE, ...)

## S3 method for class 'madad'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="madad_+3A_x">x</code></td>
<td>
<p>any object that can be converted to a data frame with integer variables <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>, alternatively a matrix with column names including <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>.</p>
</td></tr>
<tr><td><code id="madad_+3A_tp">TP</code></td>
<td>
<p>vector of integers, ingored if <code>X</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="madad_+3A_fn">FN</code></td>
<td>
<p>vector of integers, ingored if <code>X</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="madad_+3A_fp">FP</code></td>
<td>
<p>vector of integers, ingored if <code>X</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="madad_+3A_tn">TN</code></td>
<td>
<p>vector of integers, ingored if <code>X</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="madad_+3A_correction">correction</code></td>
<td>
<p>numeric, continuity correction applied to zero cells.</p>
</td></tr>
<tr><td><code id="madad_+3A_correction.control">correction.control</code></td>
<td>
<p>character, if set to <code>"all"</code> (the default) the continuity correction is added to the whole data if only one cell in one study is zero. If set to <code>"single"</code> the correction is only applied to rows of the data which have a zero.</p>
</td></tr>
<tr><td><code id="madad_+3A_level">level</code></td>
<td>
<p>numeric, confidence level for the calculations of confidence intervals.</p>
</td></tr>
<tr><td><code id="madad_+3A_method">method</code></td>
<td>
<p>character, method used to calculate the confidence intervals for sensitivities, specificities and false positive rates. One of <code>"wald"</code>, <code>"wilson"</code>, <code>"agresti-coull"</code>, <code>"jeffreys"</code>, <code>"modified wilson"</code>, <code>"modified jeffreys"</code>, <code>"clopper-pearson"</code>, <code>"arcsine"</code>, <code>"logit"</code>, <code>"witting"</code></p>
</td></tr>
<tr><td><code id="madad_+3A_yates">yates</code></td>
<td>
<p>logical, should a Yates correction be used for testing the equality of sensitivities and specificities?</p>
</td></tr>
<tr><td><code id="madad_+3A_digits">digits</code></td>
<td>
<p>integer, to what decimal place is the output to be rounded?</p>
</td></tr>
<tr><td><code id="madad_+3A_suppress">suppress</code></td>
<td>
<p>logical, suppress the warning that is generated by <code><a href="stats.html#topic+prop.test">prop.test</a></code> when Chi-square approximation may be incorrect.</p>
</td></tr> 
<tr><td><code id="madad_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on the other funtions (currently none).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All calculations are performed using the continuity corrected cell counts, so if there are zero cells, the sensitivities and specificities not equal to 1. This can be avoided by setting <code>correction.control</code> to  <code>"none"</code>.
</p>
<p>The test for the equality of sensitivities and its counterpart for the specificities is based on <code><a href="stats.html#topic+prop.test">prop.test</a></code>. This function will occasionally output warnings.
</p>


<h3>Value</h3>

<p>An object of class <code>madad</code> which is essentially a list with the following components:
</p>
<table role = "presentation">
<tr><td><code>sens</code></td>
<td>
<p>A list of two components, <code>sens</code> (the sensitivities) and <code>sens.ci</code> the confidence intervals (a matrix with 2 columns).</p>
</td></tr>
<tr><td><code>spec</code></td>
<td>
<p>A list of two components, <code>spec</code> (the specificities) and <code>spec.ci</code> the confidence intervals (a matrix with 2 columns).</p>
</td></tr>
<tr><td><code>fpr</code></td>
<td>
<p>A list of two components, <code>fpr</code> (the false positive rates) and <code>fpr.ci</code> the confidence intervals (a matrix with 2 columns).</p>
</td></tr>
<tr><td><code>sens.htest</code></td>
<td>
<p>An object of class <code>htest</code>.</p>
</td></tr>
<tr><td><code>spec.htest</code></td>
<td>
<p>An object of class <code>htest</code>.</p>
</td></tr>
<tr><td><code>DOR</code></td>
<td>
<p>A list of two components, <code>DOR</code> the diagnostic odds ratios and <code>DOR.ci</code> the confidence intervals (a matrix with 2 columns).</p>
</td></tr>
<tr><td><code>posLR</code></td>
<td>
<p>A list of two components, <code>posLR</code> the positive likelihood ratios and <code>posLR.ci</code> the confidence intervals (a matrix with 2 columns).</p>
</td></tr>
<tr><td><code>negLR</code></td>
<td>
<p>A list of two components, <code>negLR</code> the negative likelihood ratios and <code>negLR.ci</code> the confidence intervals (a matrix with 2 columns).</p>
</td></tr>
<tr><td><code>cor_sens_fpr</code></td>
<td>
<p>numeric, the correlation of the sensitivities and false-positive rates.</p>
</td></tr>
<tr><td><code>level</code></td>
<td>
<p>numeric</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>character</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>character vector, if the main argument of <code>madad</code> is a data frame with a variable <code>names</code> these names are stored here.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>integer, number of primary studies.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame, with columns <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>character, name of the main argument.</p>
</td></tr>
<tr><td><code>correction</code></td>
<td>
<p>numeric</p>
</td></tr>
<tr><td><code>correction.control</code></td>
<td>
<p>character</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+madauni">madauni</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AuditC)
AuditC.d &lt;- madad(AuditC)
print(AuditC.d, digits = 2) #round everything to 2 digits
</code></pre>

<hr>
<h2 id='madauni'>
Meta-Analyisis of univariate measures of diagnostic accuracy
</h2><span id='topic+madauni'></span>

<h3>Description</h3>

<p>The classic strategy to meta-analysis of diagnostic accuracy data is to pool a univariate measure of accuracy like the diagnostic odds ratio, the positive likelihood ratio or the negative likelihood ratio. For fixed effect estimation a Mantel-Haenszel estimator is implemented and for random effect estimation a DerSimonian-Laird estimator is available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>madauni(x, type = "DOR", method = "DSL", suppress = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="madauni_+3A_x">x</code></td>
<td>
<p>any object that can be converted to a data frame with integer variables <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>, alternatively a matrix with column names including <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>.</p>
</td></tr>
<tr><td><code id="madauni_+3A_type">type</code></td>
<td>
<p>character, what effect size should be pooled? Either <code>"DOR"</code>, <code>"posLR"</code> or <code>"negLR"</code>.</p>
</td></tr>
<tr><td><code id="madauni_+3A_method">method</code></td>
<td>
<p>character, method of estimation. Either <code>"MH"</code> or <code>"DSL"</code>.</p>
</td></tr>
<tr><td><code id="madauni_+3A_suppress">suppress</code></td>
<td>
<p>logical, should warnings produced by the internal call to <code><a href="#topic+madad">madad</a></code> be suppressed?</p>
</td></tr>
<tr><td><code id="madauni_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on to <code><a href="#topic+madad">madad</a></code>, for example <code>correction.control</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First note that the function <code><a href="#topic+madad">madad</a></code> is used to calculate effect measures. You can pass on arguments to this function via the <code>...</code> arguments. This is especially useful for the <code>correction.control</code> and <code>correction</code> arguments, see the example.
</p>
<p>The Mantel-Haenszel method performs fixed effect estimation of the effect sizes. For the DOR the variance of this estimator is calculated according to Robins et al. (1986) and for the likelihood ratios the variance is based on Greenland et al. (1985).
</p>
<p>The DerSimonian-Laird method performs a random effects meta-analysis. For this <code class="reqn">\tau^2</code>, the variance of the log-transformed effect size (DOR, positive or negative likelihood ratio) is calculated by the DerSimonian and Laird (1986) method. The confidence interval for <code class="reqn">\tau^2</code> is derived by inverting the Q-Test of Viechtbauer (2007).
</p>
<p>Zwindermann and Bossuyt (2008) argue, that univariate summary points like the likelihood ratios should be derived from the bivariate model of Reitsma et al (2005). The function <code><a href="#topic+SummaryPts">SummaryPts</a></code>, using output of <code><a href="#topic+reitsma">reitsma</a></code> supports this approach.
</p>


<h3>Value</h3>

<p>An object of class <code>madauni</code>, for which some standard methods are available, see <code><a href="#topic+madauni-class">madauni-class</a></code></p>


<h3>Note</h3>

<p>Performing univariate meta-analysis of diagnostic studies can not be recommended anymore now that bivariate methods are available, at least not if a reasonable number of primary studies is availabel. The package <code>mada</code> provides this functionality for exploratory purposes and for meta-analysis of a small number of studies. The prefered way is to use <code><a href="#topic+reitsma">reitsma</a></code> in conjunction with <code><a href="#topic+SummaryPts">SummaryPts</a></code>.
</p>
<p>The default value of <code>correction.control</code> used <code><a href="#topic+madad">madad</a></code> (and hence in the calculation of the effect sizes for <code>madauni</code>) is <code>"all"</code>, i.e. the continuity correction is added to all studies if any has a zero cell. This is a different default value than the <code>metafor</code> package uses. Set <code>correction.control</code> to <code>"single"</code> to arrive at the same values. 
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>References</h3>

<p>DerSimonian, R. and Laird, N. (1986). &ldquo;Meta-analysis in clinical trials.&rdquo; <em>Controlled clinical trials</em>, <b>7</b>, 177&ndash;188.
</p>
<p>Greenland, S. and Robins, J.M. (1985). &ldquo;Estimation of a Common Effect Parameter from Sparse Follow-Up Data.&rdquo; <em>Biometrics</em>, <b>41</b>, 55&ndash;68. 
</p>
<p>Reitsma, J., Glas, A., Rutjes, A., Scholten, R., Bossuyt, P., &amp; Zwinderman, A. (2005).
&ldquo;Bivariate analysis of sensitivity and specificity produces informative summary
measures in diagnostic reviews.&rdquo; <em>Journal of Clinical Epidemiology</em>, <b>58</b>, 982&ndash;990.
</p>
<p>Robins, J. and Greenland, S. and Breslow, N.E. (1986). &ldquo;A general estimator for the variance of the Mantel-Haenszel odds ratio.&rdquo; <em>American Journal of Epidemiology</em>, <b>124</b>, 719&ndash;723.
</p>
<p>Viechtbauer, W. (2007). &ldquo;Confidence intervals for the amount of heterogeneity in meta-analysis.&rdquo; <em>Statistics in Medicine</em>, <b>26</b>, 37&ndash;52.
</p>
<p>Zwinderman, A., &amp; Bossuyt, P. (2008). &ldquo;We should not pool diagnostic likelihood ratios
in systematic reviews.&rdquo;<em>Statistics in Medicine</em>, <b>27</b>, 687&ndash;697.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+madauni-class">madauni-class</a></code>, <code><a href="#topic+reitsma">reitsma</a></code>, <code><a href="#topic+SummaryPts">SummaryPts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AuditC)

## First example: DOR meta-analysis
AuditC.uni &lt;- madauni(AuditC)
summary(AuditC.uni)

## Second example: sensitivity analysis
## Do continuity corrections make a difference?
AuditC.uni_low &lt;- madauni(AuditC, correction = 0.1)
AuditC.uni_single &lt;-  madauni(AuditC, 
          correction.control = "single") ## default is "all"
confint(AuditC.uni)
confint(AuditC.uni_low)
confint(AuditC.uni_single)
</code></pre>

<hr>
<h2 id='madauni-class'>
Methods for the class <code>madauni</code>.
</h2><span id='topic+madauni-class'></span><span id='topic+summary.madauni-class'></span><span id='topic+print.madauni'></span><span id='topic+vcov.madauni'></span><span id='topic+summary.madauni'></span><span id='topic+print.summary.madauni'></span>

<h3>Description</h3>

<p>Various methods for the output of the function <code><a href="#topic+madauni">madauni</a></code>. Also the default method <code><a href="stats.html#topic+confint">confint</a></code> works for this class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'madauni'
print(x, digits = 3, ...)
## S3 method for class 'madauni'
vcov(object, ...)
## S3 method for class 'madauni'
summary(object, level = 0.95, ...)
## S3 method for class 'summary.madauni'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="madauni-class_+3A_x">x</code></td>
<td>
<p>An object of class <code>madauni</code>.</p>
</td></tr>
<tr><td><code id="madauni-class_+3A_object">object</code></td>
<td>
<p>An object of class <code>madauni</code>.</p>
</td></tr>
<tr><td><code id="madauni-class_+3A_level">level</code></td>
<td>
<p>numeric, the confidence level for the confidence intervals in the summary.</p>
</td></tr>
<tr><td><code id="madauni-class_+3A_digits">digits</code></td>
<td>
<p>integer indicating the number of decimal places to round to.</p>
</td></tr>
<tr><td><code id="madauni-class_+3A_...">...</code></td>
<td>
<p>arguments to be passed to methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.madauni</code> returns a list of class <code>summary.madauni</code> which is printed with <code>print.summary.madauni</code>.</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+madauni">madauni</a></code>
</p>

<hr>
<h2 id='mslSROC'>
Plot the Moses-Shapiro-Littenberg SROC curve
</h2><span id='topic+mslSROC'></span>

<h3>Description</h3>

<p>The approach to SROC curve modeling is described in the paper of Moses, Shapiro and Littenberg (1993). It is considered outdated and is included in <code>mada</code> so that users can reproduce older results and compare different SROC curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mslSROC(data = NULL, subset=NULL,
  TP="TP", FN="FN", FP="FP", TN="TN", 
  fpr = NULL, extrapolate = FALSE, 
  correction = 0.5, correction.control = "all",
  add = FALSE, lty = 1, lwd = 1, col = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mslSROC_+3A_data">data</code></td>
<td>
<p>any object that can be converted to a data frame with integer variables for observed frequencies of true positives, false negatives, false positives and true negatives. The names of the variables  are provided by the arguments <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code> (see their defaults). Alternatively the data can be a matrix with column names including <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>. If no <code>data</code> is specified, the function will check the <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code> arguments.
</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_tp">TP</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_fn">FN</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_fp">FP</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_tn">TN</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_subset">subset</code></td>
<td>
<p>the rows of <code>data</code> to be used as a subset in all calculations. If <code>NULL</code> (the default) then the complete data is considered.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_fpr">fpr</code></td>
<td>
<p>Points between 0 and 1 on which to draw the SROC curve. Should be tightly spaced. If set to <code>NULL</code>, the default, it will be the vector of numbers <code>0.01, 0.02, ..., 0.99</code> and is truncated if the <code>extrapolate</code> argument is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_extrapolate">extrapolate</code></td>
<td>
<p>logical, should the SROC curve be extrapolated beyond the region where false positive rates are observed?</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_correction">correction</code></td>
<td>
<p>numeric, continuity correction applied if zero cells</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_correction.control">correction.control</code></td>
<td>
<p>character, if set to <code>"all"</code> (the default) the continuity correction is added to the whole data if only one cell in one study is zero. If set to <code>"single"</code> the correction is only applied to rows of the data which have a zero.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_add">add</code></td>
<td>
<p>logical, should the SROC curve be added to an existing plot?</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_lty">lty</code></td>
<td>
<p>line type, see <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_lwd">lwd</code></td>
<td>
<p>line width, see <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_col">col</code></td>
<td>
<p>color of SROC, see <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="mslSROC_+3A_...">...</code></td>
<td>
<p>arguments to be passed on to plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details are found in the paper of Moses, Shapiro and Littenberg (1993).
</p>


<h3>Value</h3>

<p>Besides plotting the SROC, an <code><a href="base.html#topic+invisible">invisible</a></code> list is returned which contains the parameters of the SROC.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Moses L.E., Shapiro D., &amp; Littenberg B. (1993) &ldquo;Combining independent studies of a diagnostic test into a summary ROC curve: data-analytic approaches and some additional considerations.&rdquo; <em>Statistics in Medicine</em>, <b>12</b>, 1293&ndash;1316.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reitsma-class">reitsma-class</a></code>, <code><a href="#topic+talpha">talpha</a></code>, <code><a href="#topic+SummaryPts">SummaryPts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## First Example
data(Dementia)
ROCellipse(Dementia)
mslSROC(Dementia, add = TRUE) # Add the MSL-SROC to this plot

## Second Example
# Make a fancy plot and look at the coefficients
msl_Dementia &lt;- mslSROC(Dementia, col = 3, lwd = 3, lty = 3)
msl_Dementia$A2 # intercept on logit SROC space
msl_Dementia$B2 # slope on logit SROC space
</code></pre>

<hr>
<h2 id='phm'>
Diagnostic Meta-Analysis with the proportional hazards model approach of Holling et.al (2012)
</h2><span id='topic+phm'></span><span id='topic+phm.default'></span>

<h3>Description</h3>

<p>The function fits the model of Holling et al. (2012). The adjusted profile maximum likelihood estimator (APMLE) is implemented for homogeneity and heterogeneity of primary studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phm(data, ...)
## Default S3 method:
phm(data = NULL, subset=NULL, 
    TP="TP", FN="FN", FP="FP", TN="TN",  
    correction = 0.5, correction.control = "all", 
    hetero = TRUE, estimator = "APMLE", l = 100, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phm_+3A_data">data</code></td>
<td>
<p>any object that can be converted to a data frame with integer variables <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>, alternatively a matrix with column names including <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>.
</p>
</td></tr>
<tr><td><code id="phm_+3A_subset">subset</code></td>
<td>
<p>the rows of <code>data</code> to be used as a subset in all calculations. If <code>NULL</code> (the default) then the complete data is considered.</p>
</td></tr>  
<tr><td><code id="phm_+3A_tp">TP</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="phm_+3A_fn">FN</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="phm_+3A_fp">FP</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="phm_+3A_tn">TN</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="phm_+3A_correction">correction</code></td>
<td>
<p>numeric, continuity correction applied if zero cells</p>
</td></tr>
<tr><td><code id="phm_+3A_correction.control">correction.control</code></td>
<td>
<p>character, if set to <code>"all"</code> (the default) the continuity correction is added to the whole data if only one cell in one study is zero. If set to <code>"single"</code> the correction is only applied to rows of the data which have a zero.</p>
</td></tr>
<tr><td><code id="phm_+3A_hetero">hetero</code></td>
<td>
<p>logical, should heterogeneity of studies be assumed? Will fit model for homogeneity otherwise.</p>
</td></tr>
<tr><td><code id="phm_+3A_estimator">estimator</code></td>
<td>
<p>character, determines estimator used. Currently only <code>APMLE</code> is available.</p>
</td></tr>
<tr><td><code id="phm_+3A_l">l</code></td>
<td>
<p>interger, number of iterations for fixed point algorithm</p>
</td></tr>
<tr><td><code id="phm_+3A_...">...</code></td>
<td>
<p>arguments passed on to other functions (currently not used)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model of Holling et al. (2012) assumes that the relationship between false positive rates <code class="reqn">u</code> and and sensitivities <code class="reqn">p</code> can be described by
</p>
<p style="text-align: center;"><code class="reqn">u^\theta = p,</code>
</p>

<p>where <code class="reqn">\theta</code> is the diagnostic accuracy parameter. If homogeneity of the studies can be assumed, <code class="reqn">\theta</code> is estimated as a fixed effect. Under heterogeneity a random effect with variance <code class="reqn">\tau^2</code> describes the variation of the diagnostic accuracy parameter in the population of studies. Since the error of each observed <code class="reqn">\theta</code> depends only on the sample size and <code class="reqn">\theta</code> the model has only one parameter in the case of homogeneity and two parameters under heterogeneity, making it suitable for diagnostic meta-analysis with low sample size. Estimation proceeds by a fixed point algorithm derived from the adjusted profile likelihood. More details on the computational approach can be found in Holling et al. (2012).
</p>


<h3>Value</h3>

<p>An object of the class <code>phm</code> for which many standard methods are available. See <code><a href="#topic+phm-class">phm-class</a></code> for details.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;, 
Walailuck Boehning (original implementation of estimation algorithm)
</p>


<h3>References</h3>

<p>Holling, H., Boehning W., Boehning, D. (2012) &ldquo;Meta-Analysis of Diagnostic Studies based upon SROC-Curves: a Mixed Model Approach using a Proportional Hazards Model.&rdquo; <em>Statistical Modelling</em>, <b>12</b>, 347???-375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+phm-class">phm-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AuditC)
(fit &lt;- phm(AuditC))
summary(fit)
plot(fit)
</code></pre>

<hr>
<h2 id='phm-class'>
Methods for <code>phm</code> objects.
</h2><span id='topic+phm-class'></span><span id='topic+sroc.phm'></span><span id='topic+plot.phm'></span><span id='topic+summary.phm'></span><span id='topic+print.phm'></span>

<h3>Description</h3>

<p>Objects of the class <code><a href="#topic+phm">phm</a></code> are output by the function with the same name. Apart from standard methods the function <code>sroc</code> provides SROC curves and confidence bands for model fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'phm'
print(x, ...)
## S3 method for class 'phm'
summary(object, level = 0.95, ...)
## S3 method for class 'phm'
sroc(fit, fpr = 1:99/100, ...)
## S3 method for class 'phm'
plot(x, extrapolate = FALSE, confband = TRUE, level = 0.95,
     ylim = c(0,1), xlim = c(0,1), sroclty = 1, sroclwd = 1, 
     confbandlty = 2, confbandlwd = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phm-class_+3A_x">x</code></td>
<td>
<p>a <code>phm</code> object.</p>
</td></tr>
<tr><td><code id="phm-class_+3A_object">object</code></td>
<td>
<p>a <code>phm</code> object.</p>
</td></tr>
<tr><td><code id="phm-class_+3A_fit">fit</code></td>
<td>
<p>a <code>phm</code> object.</p>
</td></tr>
<tr><td><code id="phm-class_+3A_level">level</code></td>
<td>
<p>numeric, the confidence level for calculations of confidence intervals (<code>summary</code>) or confidence bands (<code>plot</code>).</p>
</td></tr>
<tr><td><code id="phm-class_+3A_fpr">fpr</code></td>
<td>
<p>numeric, the false positives rates for which to calculate the predicted sensitivities.</p>
</td></tr>
<tr><td><code id="phm-class_+3A_extrapolate">extrapolate</code></td>
<td>
<p>logical, should the sroc curve be plotted beyond the observed false positive rates?</p>
</td></tr>
<tr><td><code id="phm-class_+3A_confband">confband</code></td>
<td>
<p>logical, should confidence bands be plotted?</p>
</td></tr>
<tr><td><code id="phm-class_+3A_ylim">ylim</code></td>
<td>
<p>numeric of length 2, which section of the sensitivities to plot?</p>
</td></tr>
<tr><td><code id="phm-class_+3A_xlim">xlim</code></td>
<td>
<p>numeric of length 2, which section of the false positive rates to plot?</p>
</td></tr>
<tr><td><code id="phm-class_+3A_sroclty">sroclty</code></td>
<td>
<p>integer, line type of the SROC curve</p>
</td></tr>
<tr><td><code id="phm-class_+3A_sroclwd">sroclwd</code></td>
<td>
<p>integer, line width of the SROC curve</p>
</td></tr>  
<tr><td><code id="phm-class_+3A_confbandlty">confbandlty</code></td>
<td>
<p>integer, line type of the SROC curve's confidence band</p>
</td></tr>
<tr><td><code id="phm-class_+3A_confbandlwd">confbandlwd</code></td>
<td>
<p>integer, line width of the SROC curve's confidence band</p>
</td></tr>  
<tr><td><code id="phm-class_+3A_...">...</code></td>
<td>
<p>arguments to be passed on to other functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The SROC curve is derived from the model formula.  The confidence bands are calculated from the bounds of the confidence interval for the diagnostic accuracy parameter <code class="reqn">\theta</code>. The parameter and its confidence interval are then also used to calculate the AUC and partial AUC using the formulae
</p>
<p style="text-align: center;"><code class="reqn">
AUC(a,b) = \int_a^bu^\theta\mathrm{d}u = \frac{1}{\theta+1}[b^{\theta+1}-a^{\theta+1}],
</code>
</p>

<p style="text-align: center;"><code class="reqn">
AUC = AUC(0,1)
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
pAUC = \frac{1}{b-a}AUC(a,b),
</code>
</p>

<p>where <code class="reqn">a</code> is the lower bound of the observed false positive rates and <code class="reqn">b</code> the upper.
</p>


<h3>Value</h3>

<p>The <code>sroc</code> function returns a matrix ready for plotting. Each row corresponds to one point in ROC space.</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Holling, H., Boehning D., Boehning, W. (2012) &ldquo;Meta-Analysis of Diagnostic Studies based upon SROC-Curves: a Mixed Model Approach using a Proportional Hazards Model.&rdquo; <em>Statistical Modelling</em>, <b>12</b>, 347&ndash;375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+phm">phm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data(AuditC)
# fit model
fit &lt;- phm(AuditC)
#calculate a SROC curve, but do not plot it
sroc.AuditC &lt;- sroc(fit)
# plot the SROC curve in ROC space as a line
plot(sroc.AuditC, type = "l")
# Fancy version using plot
plot(fit)
</code></pre>

<hr>
<h2 id='predv_d'>
Estimation of Distributions of Predictive Values Based on Prevalence Probability Distributions and Pooled Sensitivities and Specificities
</h2><span id='topic+predv_d'></span>

<h3>Description</h3>

<p>Estimation of projected summary predictive values based on a prevalence probability distribution and pooled (meta-analytical) sensitivities and specificities. Probability distributions for negative and positive predictive values are obtained.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predv_d(x,prop_m,prop_sd,zb=TRUE,n_iter=100000,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predv_d_+3A_x">x</code></td>
<td>
<p>dataset containing data from the primary studies. It must correspond to any object that can be converted to a data frame with integer variables <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>, alternatively a matrix with column names including <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>. These respectively concern the numbers of true positives, true negatives, false positives, and false negatives for each primary study)</p>
</td></tr>
<tr><td><code id="predv_d_+3A_prop_m">prop_m</code></td>
<td>
<p>mean value of the prevalence probability distribution. It must be stated as a proportion (i.e., as a numeric value between 0 and 1). If both prop_m and prop_sd are not defined, a probability distribution for the prevalence based on available primary studies' data will be computed (see details).</p>
</td></tr>
<tr><td><code id="predv_d_+3A_prop_sd">prop_sd</code></td>
<td>
<p>standard-deviation of the prevalence probability distribution. It must be stated as a value between 0 and 1.  If both prop_m and prop_sd are not defined, a probability distribution for the prevalence based on available primary studies' data will be computed (see details).</p>
</td></tr>
<tr><td><code id="predv_d_+3A_zb">zb</code></td>
<td>
<p>logical. If TRUE (default), the Zwindermann &amp; Bossuyt approach will be used to generate samples for observed sensitivities and false positive rate (as in SummaryPts function). If FALSE, beta distributions will be obtained based on 95 percent confidence interval bounds of pooled sensitivities and specificities (while this latter approach may not take fully into account the correlation between sensitivity and false positive rate, it may lead to faster results).</p>
</td></tr>
<tr><td><code id="predv_d_+3A_n_iter">n_iter</code></td>
<td>
<p>number of simulations being performed. Default value is 100,000.</p>
</td></tr>
<tr><td><code id="predv_d_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on to <code><a href="#topic+predv_d">predv_d</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predv_d function projects summary predictive values distributions from (i) a prevalence probability distribution, and (ii) pooled sensitivities and specificities obtained in the context of diagnostic test accuracy meta-analysis using a bivariate random-effects model.
The bivariate random-effects model is equivalent to the hierarchical summary receiver operating characteristic model. By default, a sampling-based approach is used to generate samples for observed sensitivities and false positive rates. From these samples, and based on the prevalences probability distribution being considered, distributions of predictive values will be obtained based on the application of the Bayes theorem.
The prevalence probability distribution can be obtained by providing a value for the mean (argument prop_m) and a value for the standard-deviation (argument prop_sd).
If both prop_m and prop_sd are missing/not defined, a probability distribution for the prevalence based on available primary studies' data will be computed. That is, random-effects meta-analysis of log-transformed prevalences will be performed (using metafor) using data from included primary studies; the pooled results will then be used to obtain the probability distribution for prevalences. This may be a suboptimal option (as there may be considerable heterogeneity, diagnostic accuracy primary studies may not be the best ones to estimate the prevalence of a disease/condition...) compared to user-defined arguments, particularly if good prevalence studies exist.
</p>
<p><b>Guided example</b>
</p>
<p>The dataset skin_tests contains results from a set of primary studies assessing the accuracy of skin tests for diagnosing penicillin allergy (they are part of the data analysed by Sousa-Pinto et al [2021]).
This dataset contains four columns, displaying - for each primary study - the number of true positives (TP), true negatives (TN), false positives (FP) and false negatives (FN).
Let us now assume that the prevalence of penicillin allergy can be modeled by a probability distribution, having a mean of 0.05 (5 percent) and a standard-deviation of 0.015. Distributions of negative and positive predictive values can be estimated by:
</p>
<p><code>predv_d(x=skin_tests,prop_m=0.05,prop_sd=0.015,zb=TRUE)</code>
</p>
<p>For negative predictive values, we obtain a probability distribution defined by a mean value of 0.96 and a standard-deviation of 0.01 (95 percent credible interval=0.93-0.98).
For positive predictive values, we obtain a probability distribution defined by a mean value of 0.31 and a standard-deviation of 0.12 (95 percent credible interval=0.11-0.57).
Values may differ slightly from the ones just described, as we are dealing with simulation results.
</p>
<p>If we had no information on how the prevalence of penicillin allergy could be modeled by a probability distribution, we would opt for solely relying on data provided by included primary studies:
</p>
<p><code>predv_d(x=skin_tests)</code>
</p>
<p>In that case, in addition to the results, we would get an warning message stating that considerable heterogeneity was found when doing meta-analysis of prevalences. Results should be carefully interpreted.
</p>


<h3>Value</h3>

<p>An object of class <code>predv_d</code>, for which some standard methods are available, see <code><a href="#topic+predv_d-class">predv_d-class</a></code>. Some of the obtainable components include:
</p>
<table role = "presentation">
<tr><td><code>SummaryData</code></td>
<td>
<p>A dataframe displaying the mean, standard-deviation (SD) and percentiles (p) for the probability distribution of the summary negative predictive values (&quot;NPV&quot; row) and positive predictive values (&quot;PPV&quot; row).</p>
</td></tr>
<tr><td><code>results_pred</code></td>
<td>
<p>A dataframe displaying the results for all samples.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Bernardo Sousa-Pinto &lt;bernardo@med.up.pt&gt;
</p>


<h3>References</h3>

<p>Reitsma, J., Glas, A., Rutjes, A., Scholten, R., Bossuyt, P., &amp; Zwinderman, A. (2005).
&ldquo;Bivariate analysis of sensitivity and specificity produces informative summary
measures in diagnostic reviews.&rdquo; <em>Journal of Clinical Epidemiology</em>, <b>58</b>, 982&ndash;990.
</p>
<p>Zwinderman, A., &amp; Bossuyt, P. (2008). &ldquo;We should not pool diagnostic likelihood ratios in  systematic reviews.&rdquo; <em>Statistics in Medicine</em>, <b>27</b>, 687&ndash;697.
</p>
<p>Sousa-Pinto, B., Tarrio, I., Blumenthal, K.G., Azevedo, L.F., Delgado, L., &amp; Fonseca, J.A. (2021). &ldquo;Accuracy of penicillin allergy diagnostic tests: A systematic review and meta-analysis.&rdquo; <em>Journal of Allergy and Clinical Immunology</em>, <b>147</b>, 296&ndash;308.
</p>
<p>Joseph L, Belisle P. (2017). &ldquo;Computing Beta distribution parameters.&rdquo; [Internet] Accessible at: https://www.medicine.mcgill.ca/epidemiology/Joseph/PBelisle/BetaParmsFromQuantiles.html
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reitsma">reitsma</a></code>,
<code><a href="#topic+SummaryPts">SummaryPts</a></code>,
<code><a href="#topic+predv_r">predv_r</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(skin_tests)
pred_skin_tests &lt;- predv_d(x=skin_tests,prop_m=0.05,prop_sd=0.015,zb=TRUE)
pred_skin_tests
</code></pre>

<hr>
<h2 id='predv_d-class'>
Methods for the class <code>predv_d</code>.
</h2><span id='topic+predv_d-class'></span><span id='topic+summary.predv_d-class'></span><span id='topic+print.predv_d'></span><span id='topic+summary.predv_d'></span>

<h3>Description</h3>

<p>Various methods for the output of the function <code><a href="#topic+predv_d">predv_d</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predv_d'
print(x, xlim_npv=c(0,1),xlim_ppv=c(0,1), ...)
## S3 method for class 'predv_d'
summary(object, xlim_npv=c(0,1),xlim_ppv=c(0,1), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predv_d-class_+3A_x">x</code></td>
<td>
<p>An object of class <code>predv_d</code>.</p>
</td></tr>
<tr><td><code id="predv_d-class_+3A_object">object</code></td>
<td>
<p>An object of class <code>predv_d</code>.</p>
</td></tr>
<tr><td><code id="predv_d-class_+3A_xlim_npv">xlim_npv</code></td>
<td>
<p>limits of the x-axis for the plot on projected negative predictive values. Default is c(0,1).</p>
</td></tr>
<tr><td><code id="predv_d-class_+3A_xlim_ppv">xlim_ppv</code></td>
<td>
<p>limits of the x-axis for the plot on projected positive predictive values. Default is c(0,1).</p>
</td></tr>
<tr><td><code id="predv_d-class_+3A_...">...</code></td>
<td>
<p>arguments to be passed to methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.predv_d</code> returns a list of class <code>summary.predv_d</code>.</p>


<h3>Author(s)</h3>

<p>Bernardo Sousa-Pinto &lt;bernardo@med.up.pt&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+predv_d">predv_d</a></code>
</p>

<hr>
<h2 id='predv_r'>
Estimation of Distributions of Predictive Values Based on Prevalence Ranges and Pooled Sensitivities and Specificities
</h2><span id='topic+predv_r'></span>

<h3>Description</h3>

<p>Estimation of projected summary predictive values based on a prevalence range and pooled (meta-analytical) sensitivities and specificities. A probability distribution for the negative and positive predictive values are obtained for each prevalence value within a predetermined range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predv_r(x,prop_min,prop_max,zb=TRUE,n_iter=100000,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predv_r_+3A_x">x</code></td>
<td>
<p>dataset containing data from the primary studies. It must correspond to any object that can be converted to a data frame with integer variables <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>, alternatively a matrix with column names including <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>. These respectively concern the numbers of true positives, true negatives, false positives, and false negatives for each primary study)</p>
</td></tr>
<tr><td><code id="predv_r_+3A_prop_min">prop_min</code></td>
<td>
<p>minimum prevalence value being considered. It must be stated as a proportion (i.e., as a numeric value between 0 and 1). If both prop_min and prop_max are not defined, a prevalence range based on available primary studies' data will be computed (see details).</p>
</td></tr>
<tr><td><code id="predv_r_+3A_zb">zb</code></td>
<td>
<p>logical. If TRUE (default), the Zwindermann &amp; Bossuyt approach will be used to generate samples for observed sensitivities and false positive rate (as in SummaryPts function). If FALSE, beta distributions will be obtained based on 95 percent confidence interval bounds of pooled sensitivities and specificities (while this latter approach may not take fully into account the correlation between sensitivity and false positive rate, it may lead to faster results).</p>
</td></tr>
<tr><td><code id="predv_r_+3A_prop_max">prop_max</code></td>
<td>
<p>maximum prevalence value being considered. It must be stated as a proportion (i.e., as a numeric value between 0 and 1). If both prop_min and prop_max are not defined, a prevalence range based on available primary studies' data will be computed (see details).</p>
</td></tr>
<tr><td><code id="predv_r_+3A_n_iter">n_iter</code></td>
<td>
<p>number of simulations being performed. Default value is 100,000.</p>
</td></tr>
<tr><td><code id="predv_r_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on to <code><a href="#topic+predv_r">predv_r</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predv_r function projects summary predictive values from (i) a prevalence range, and (ii) pooled sensitivities and specificities obtained in the context of diagnostic test accuracy meta-analysis using a bivariate random-effects model.
The bivariate random-effects model is equivalent to the hierarchical summary receiver operating characteristic model. By default, a sampling-based approach is used to generate samples for observed sensitivities and false positive rate. From these samples, and for each prevalence value within the range being considered, distributions of predictive values will be obtained based on the application of the Bayes theorem.
The prevalence range can be user-defined, by providing a value for the minimum (argument prop_min) and a value for the maximum value of that range (argument prop_max).
If both prop_min and prop_max are missing/not defined, a prevalence range based on available primary studies' data will be computed. That is, the lowest and highest frequency of patients with disease/condition across included primary studies will be considered. This may be a suboptimal option compared to user-defined arguments, particularly if good prevalence studies are available.
</p>
<p><b>Guided example</b>
</p>
<p>The dataset skin_tests contains results from a set of primary studies assessing the accuracy of skin tests for diagnosing penicillin allergy (they are part of the data analysed by Sousa-Pinto et al [2021]).
This dataset contains four columns, displaying - for each primary study - the number of true positives (TP), true negatives (TN), false positives (FP) and false negatives (FN).
Let us assume that the prevalence of penicillin allergy ranges between 0.01 and 0.10 (1 and 10 percent). Pooled negative and positive predictive values can be estimated by:
</p>
<p><code>predv_r(x=skin_tests,prop_min=0.01,prop_max=0.15,zb=TRUE)</code>
</p>
<p>The results indicate that the point estimates for the negative predictive value range between 0.88 (prevalence=0.15) and 0.99 (prevalence=0.01).
For the positive predictive value, point estimates range between 0.09 (prevalence=0.01) and 0.59 (prevalence=0.15), although uncertainty is particularly high for the latter estimate (95 percent credible interval=0.36-0.80).
Values may differ slightly from the ones just described, as we are dealing with simulation results.
</p>
<p>If we had no information on how the prevalence range of penicillin allergy, we would opt for solely relying on data provided by included primary studies:
</p>
<p><code>pred_skin_tests1 &lt;- predv_r(x=skin_tests)</code>
</p>


<h3>Value</h3>

<p>An object of class <code>predv_r</code>, for which some standard methods are available, see <code><a href="#topic+predv_r-class">predv_r-class</a></code>. Some of the obtainable components include:
</p>
<table role = "presentation">
<tr><td><code>NPV</code></td>
<td>
<p>A dataframe displaying the mean, standard-deviation (SD) and percentiles (p) for the probability distribution of negative predictive values for each prevalence value within the defined range.</p>
</td></tr>
<tr><td><code>PPV</code></td>
<td>
<p>A dataframe displaying the mean, standard-deviation (SD) and percentiles (p) for the probability distribution of positive predictive values for each prevalence value within the defined range.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Bernardo Sousa-Pinto &lt;bernardo@med.up.pt&gt;
</p>


<h3>References</h3>

<p>Reitsma, J., Glas, A., Rutjes, A., Scholten, R., Bossuyt, P., &amp; Zwinderman, A. (2005).
&ldquo;Bivariate analysis of sensitivity and specificity produces informative summary
measures in diagnostic reviews.&rdquo; <em>Journal of Clinical Epidemiology</em>, <b>58</b>, 982&ndash;990.
</p>
<p>Zwinderman, A., &amp; Bossuyt, P. (2008). &ldquo;We should not pool diagnostic likelihood ratios in  systematic reviews.&rdquo; <em>Statistics in Medicine</em>, <b>27</b>, 687&ndash;697.
</p>
<p>Sousa-Pinto, B., Tarrio, I., Blumenthal, K.G., Azevedo, L.F., Delgado, L., &amp; Fonseca, J.A. (2021). &ldquo;Accuracy of penicillin allergy diagnostic tests: A systematic review and meta-analysis.&rdquo; <em>Journal of Allergy and Clinical Immunology</em>, <b>147</b>, 296&ndash;308.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reitsma">reitsma</a></code>,
<code><a href="#topic+SummaryPts">SummaryPts</a></code>,
<code><a href="#topic+predv_d">predv_d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(skin_tests)
pred_skin_tests &lt;- predv_r(x=skin_tests,prop_min=0.01,prop_max=0.15,zb=TRUE)
pred_skin_tests
</code></pre>

<hr>
<h2 id='predv_r-class'>
Methods for the class <code>predv_r</code>.
</h2><span id='topic+predv_r-class'></span><span id='topic+summary.predv_r-class'></span><span id='topic+print.predv_r'></span><span id='topic+summary.predv_r'></span>

<h3>Description</h3>

<p>Various methods for the output of the function <code><a href="#topic+predv_r">predv_r</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predv_r'
print(x, ylim_npv=c(0,1),ylim_ppv=c(0,1), ...)
## S3 method for class 'predv_r'
summary(object, ylim_npv=c(0,1),ylim_ppv=c(0,1), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predv_r-class_+3A_x">x</code></td>
<td>
<p>An object of class <code>predv_r</code>.</p>
</td></tr>
<tr><td><code id="predv_r-class_+3A_object">object</code></td>
<td>
<p>An object of class <code>predv_r</code>.</p>
</td></tr>
<tr><td><code id="predv_r-class_+3A_ylim_npv">ylim_npv</code></td>
<td>
<p>limits of the y-axis for the plot on projected negative predictive values. Default is c(0,1).</p>
</td></tr>
<tr><td><code id="predv_r-class_+3A_ylim_ppv">ylim_ppv</code></td>
<td>
<p>limits of the y-axis for the plot on projected positive predictive values. Default is c(0,1).</p>
</td></tr>
<tr><td><code id="predv_r-class_+3A_...">...</code></td>
<td>
<p>arguments to be passed to methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.predv_r</code> returns a list of class <code>summary.predv_r</code>.</p>


<h3>Author(s)</h3>

<p>Bernardo Sousa-Pinto &lt;bernardo@med.up.pt&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+predv_r">predv_r</a></code>
</p>

<hr>
<h2 id='reitsma'>
Fit the bivariate model of Reitsma et al. (2005) and extensions.
</h2><span id='topic+reitsma'></span><span id='topic+reitsma.default'></span>

<h3>Description</h3>

<p>The function fits the bivariate model of Reitsma et al. (2005) that Harbord et al. (2007) have shown to be equivalent to the HSROC of Rutter&amp;Gatsonis (2001). We specify the model as a linear mixed model with known variances of the random effects, similar to the computational approach by Reitsma et al. (2005). Variance components are estimated by restricted maximum likelihood (REML) as a default but ML estimation is available as well. In addition meta-regression is possible and the use of other transformations than the logit, using the approach of Doebler et al. (2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reitsma(data, ...)
## Default S3 method:
reitsma(data = NULL, subset=NULL, formula = NULL,
         TP="TP", FN="FN", FP="FP", TN="TN", 
         alphasens = 1, alphafpr = 1, 
         correction = 0.5, correction.control = "all",
         method = "reml",  
         control = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reitsma_+3A_data">data</code></td>
<td>
<p>any object that can be converted to a data frame with integer variables for observed frequencies of true positives, false negatives, false positives and true negatives. The names of the variables  are provided by the arguments <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code> (see their defaults). Alternatively the data can be a matrix with column names including <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>. If no <code>data</code> is specified, the function will check the <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code> arguments.
</p>
</td></tr>
<tr><td><code id="reitsma_+3A_tp">TP</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="reitsma_+3A_fn">FN</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="reitsma_+3A_fp">FP</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="reitsma_+3A_tn">TN</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="reitsma_+3A_subset">subset</code></td>
<td>
<p>the rows of <code>data</code> to be used as a subset in all calculations. If <code>NULL</code> (the default) then the complete data is considered.</p>
</td></tr>  
<tr><td><code id="reitsma_+3A_formula">formula</code></td>
<td>
<p>Formula for meta-regression using standard <code><a href="stats.html#topic+formula">formula</a></code>. The left hand side of this formula must be <code>cbind(tsens, tfpr)</code> and if <code>formula</code> is <code>NULL</code> (the default), then the formula <code>cbind(tsens, tfpr) ~ 1</code> is used, i.e. a model without covariates.</p>
</td></tr>
<tr><td><code id="reitsma_+3A_alphasens">alphasens</code></td>
<td>
<p>Transformation parameter for (continuity corrected) sensitivities, see details. If set to 1 (the default) the logit transformation is used.</p>
</td></tr>
<tr><td><code id="reitsma_+3A_alphafpr">alphafpr</code></td>
<td>
<p>Transformation parameter for (continuity corrected) false positive rates, see details</p>
</td></tr>
<tr><td><code id="reitsma_+3A_correction">correction</code></td>
<td>
<p>numeric, continuity correction applied if zero cells</p>
</td></tr>
<tr><td><code id="reitsma_+3A_correction.control">correction.control</code></td>
<td>
<p>character, if set to <code>"all"</code> (the default) the continuity correction is added to the whole data if only one cell in one study is zero. If set to <code>"single"</code> the correction is only applied to rows of the data which have a zero.</p>
</td></tr>
<tr><td><code id="reitsma_+3A_method">method</code></td>
<td>
<p>character, either <code>"fixed"</code>, <code>"ml"</code>, <code>"mm"</code>, <code>"vc"</code> or <code>"reml"</code> (the default)</p>
</td></tr>
<tr><td><code id="reitsma_+3A_control">control</code></td>
<td>
<p>a list of control parameters, see the documentation of <code><a href="mvmeta.html#topic+mvmeta">mvmeta</a></code></p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code id="reitsma_+3A_...">...</code></td>
<td>
<p>arguments to be passed on to other functions, currently ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a first step the observed frequencies are continuity corrected if values of 0 or 1 would result for the sensitivity or false positive rate otherwise. Then the sensitivities and false positive rates are transformed using the transformation
</p>
<p style="text-align: center;"><code class="reqn">
x \mapsto t_\alpha(x) := \alpha\log(x) - (2-\alpha)\log(1-x).
</code>
</p>

<p>Note that for <code class="reqn">\alpha=1</code>, the default value, the logit transformation results, i.e. the approach of Reitsma et al. (2005). A bivariate random effects model is then fitted to the pairs of transformed sensitivities and false positive rates.
</p>
<p>Parameter estimation makes use of the fact that the fixed effect parameters can be profiled in the likelihood. Internally the function <code><a href="mvmeta.html#topic+mvmeta">mvmeta</a></code> is called. Currently only standard errors for the fixed effects are available. Note that when using <code>method = "mm"</code> or <code>method = "vc"</code>, no likelihood can be computed and hence no AIC or BIC values.
</p>
<p>If you want other summary points like negative or positive likelihood ratios, see <code><a href="#topic+SummaryPts">SummaryPts</a></code>, while for positive or negative predictive values, see <code><a href="#topic+predv_r">predv_r</a></code> and <code><a href="#topic+predv_d">predv_d</a></code>.
</p>


<h3>Value</h3>

<p>An object of the class <code>reitsma</code> for which many standard methods are available. See <code><a href="#topic+reitsma-class">reitsma-class</a></code> for details.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Rutter, C., &amp; Gatsonis, C. (2001). &ldquo;A hierarchical regression approach to meta-analysis of
diagnostic test accuracy evaluations.&rdquo; <em>Statistics in Medicine</em>, <b>20</b>, 2865&ndash;2884.
</p>
<p>Reitsma, J., Glas, A., Rutjes, A., Scholten, R., Bossuyt, P., &amp; Zwinderman, A. (2005).
&ldquo;Bivariate analysis of sensitivity and specificity produces informative summary
measures in diagnostic reviews.&rdquo; <em>Journal of Clinical Epidemiology</em>, <b>58</b>, 982&ndash;990.
</p>
<p>Harbord, R., Deeks, J., Egger, M., Whiting, P., &amp; Sterne, J. (2007). &ldquo;A unification of
models for meta-analysis of diagnostic accuracy studies.&rdquo; <em>Biostatistics</em>, <b>8</b>, 239&ndash;251.
</p>
<p>Doebler, P., Holling, H., Boehning, D. (2012) &ldquo;A Mixed Model Approach to Meta-Analysis of Diagnostic Studies with Binary Test Outcome.&rdquo; <em>Psychological Methods</em>, to appear
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reitsma-class">reitsma-class</a></code>, <code><a href="#topic+talpha">talpha</a></code>, <code><a href="#topic+SummaryPts">SummaryPts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Dementia)
(fit &lt;- reitsma(Dementia))
summary(fit)
plot(fit)

## Meta-Regression
data(smoking) # contains more than one 2x2-table
## reduce to subset of independent 2x2-tables by using the 
## first table from each study only
smoking1 &lt;- subset(smoking, smoking$result_id == 1)
## use type of questionnaire as covariate
(fit &lt;- reitsma(smoking1, formula = cbind(tsens, tfpr) ~ type))
summary(fit) ## sensitivities significantly lower for SAQ
</code></pre>

<hr>
<h2 id='reitsma-class'>
Methods for <code>reitsma</code> objects.
</h2><span id='topic+reitsma-class'></span><span id='topic+sroc'></span><span id='topic+mcsroc'></span><span id='topic+sroc.reitsma'></span><span id='topic+mcsroc.reitsma'></span><span id='topic+ROCellipse.reitsma'></span><span id='topic+crosshair.reitsma'></span><span id='topic+plot.reitsma'></span><span id='topic+summary.reitsma'></span><span id='topic+print.reitsma'></span><span id='topic+anova.reitsma'></span><span id='topic+print.anova.reitsma'></span>

<h3>Description</h3>

<p>Objects of the class <code><a href="#topic+reitsma">reitsma</a></code> are output by the function with the same name. Apart from standard methods the functions <code>sroc</code>, <code>mcsroc</code> and <code>ROCellipse</code> provide SROC curves and confidence regions for fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'reitsma'
print(x, digits = 4, ...)
## S3 method for class 'reitsma'
summary(object, level = 0.95, sroc.type = "ruttergatsonis", ...)
## S3 method for class 'reitsma'
sroc(fit, fpr = 1:99/100, type = "ruttergatsonis", return_function = FALSE, ...)
## S3 method for class 'reitsma'
mcsroc(fit, fpr = 1:99/100, replications = 10000, lambda = 100, ...)
## S3 method for class 'reitsma'
ROCellipse(x, level = 0.95, add = FALSE, pch = 1, ...)
## S3 method for class 'reitsma'
crosshair(x, level = 0.95, length = 0.1, pch = 1, ...)
## S3 method for class 'reitsma'
plot(x, extrapolate = FALSE, plotsumm = TRUE, level = 0.95, 
     ylim = c(0,1), xlim = c(0,1), pch = 1, sroclty = 1, sroclwd = 1, 
     predict = FALSE, predlty = 3, predlwd = 1, type = "ruttergatsonis", ...)
## S3 method for class 'reitsma'
anova(object, fit2, ...)
## S3 method for class 'anova.reitsma'
print(x, digits = 4, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reitsma-class_+3A_x">x</code></td>
<td>
<p>a <code>reitsma</code> object.</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_object">object</code></td>
<td>
<p>a <code>reitsma</code> object.</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_fit">fit</code></td>
<td>
<p>a <code>reitsma</code> object.</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_fit2">fit2</code></td>
<td>
<p>a <code>reitsma</code> object.</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_digits">digits</code></td>
<td>
<p>number of decimal digits to print.</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_level">level</code></td>
<td>
<p>numeric, the level for calculations of confidence intervals (<code>summary</code>) or regions (<code>ROCellipse</code>)</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_sroc.type">sroc.type</code></td>
<td>
<p>character, which SROC curve should be used to calculate the AUC in the summary? Besides the default <code>ruttergatsonis</code> the option <code>naive</code> is available.</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_return_function">return_function</code></td>
<td>
<p>logical. Should a function on ROC space be returned or the values at the points given by <code>fpr</code>?</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_fpr">fpr</code></td>
<td>
<p>numeric, the false positives rates for which to calculate the predicted sensitivities</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_replications">replications</code></td>
<td>
<p>integer, the number of replications for the Monte-Carlo SROC curve</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_lambda">lambda</code></td>
<td>
<p>numeric, the parameter lambda of the Monte-Carlo run, see details</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_add">add</code></td>
<td>
<p>logical, should the confidence region be added to the current plot? If set to <code>FALSE</code> a matrix of points of the ellipse is returned</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_extrapolate">extrapolate</code></td>
<td>
<p>logical, should the SROC curve be plotted beyond the observed false positive rates?</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_plotsumm">plotsumm</code></td>
<td>
<p>logical, should the summary pair of sensitivity and false positive rate together with its confidence region be plotted?</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_length">length</code></td>
<td>
<p>positve numeric, length of the &quot;whiskers&quot; of the crosshairs.</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_ylim">ylim</code></td>
<td>
<p>numeric of length 2, which section of the sensitivities to plot?</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_xlim">xlim</code></td>
<td>
<p>numeric of length 2, which section of the false positive rates to plot?</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_pch">pch</code></td>
<td>
<p>integer, symbol for the pair of mean sensitivity and false positive rate</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_sroclty">sroclty</code></td>
<td>
<p>integer, line type of the SROC curve</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_sroclwd">sroclwd</code></td>
<td>
<p>integer, line width of the SROC curve</p>
</td></tr>  
<tr><td><code id="reitsma-class_+3A_predict">predict</code></td>
<td>
<p>logical, draw prediction region?</p>
</td></tr>  
<tr><td><code id="reitsma-class_+3A_predlty">predlty</code></td>
<td>
<p>integer, line type of prediction region</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_predlwd">predlwd</code></td>
<td>
<p>integer, line width of prediction region</p>
</td></tr>  
<tr><td><code id="reitsma-class_+3A_type">type</code></td>
<td>
<p>character, type of SROC curve to plot. Can be either the generalization of the Rutter &amp; Gatsonis (2001) SROC curve (see below) or the naive curve implied the bivariate model.</p>
</td></tr>
<tr><td><code id="reitsma-class_+3A_...">...</code></td>
<td>
<p>arguments to be passed on to other functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence regions of <code>ROCellipse</code> are first calculated as ellipses on logit-ROC space, so the back-transformed regions that are output are not necessarily ellipses. The Monte-Carlo SROC curves are generated from random samples from the fitted model and a <code><a href="stats.html#topic+lowess">lowess</a></code> smooth through them is output. Many computational details are to be found in Doebler et al. (2012).
</p>
<p>The <code>summary</code> function for <code>reitsma</code> objects also contains the five parameters of the HSROC model by Rutter &amp; Gatsonis (2001) if no regression is performed. These values are calculated by using the formulae from Harbord et al. (2007).
</p>
<p>The <code>plot</code> method for <code>reitsma</code> objects will plot the generalization of the Rutter-Gatsonis curve.
</p>
<p>If you require positive or negative likelihood ratios, you should use <code><a href="#topic+SummaryPts">SummaryPts</a></code>. If you require positive or negative predictive values, see <code><a href="#topic+predv_r">predv_r</a></code> and <code><a href="#topic+predv_d">predv_d</a></code>.
</p>


<h3>Value</h3>

<p><code>sroc</code> returns a  matrix ready for plotting. Each row corresponds to one point in ROC space. <code>mcsroc</code> returns a <code><a href="stats.html#topic+lowess">lowess</a></code> smooth. <code>ROCellipse</code> returns a list, the first element being a matrix of points in ROC space that delimit the confidence region and the second is the point estimate of the pair of sensitivity and false positive rate in ROC space.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Doebler, P., Holling, H., Boehning, D. (2012) &ldquo;A Mixed Model Approach to Meta-Analysis of Diagnostic Studies with Binary Test Outcome.&rdquo; <em>Psychological Methods</em>, to appear
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reitsma">reitsma</a></code>, <code><a href="#topic+SummaryPts">SummaryPts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data(Dementia)
# fit model
fit &lt;- reitsma(Dementia)
# calculate a confidence region but do not plot it
cr.Dementia &lt;- ROCellipse(fit)
#calculate a SROC curve
sroc.Dementia &lt;- sroc(fit)
# plot the confidence region in ROC space as a line
plot(cr.Dementia$ROCellipse, type = "l", xlim = c(0,1), ylim = c(0,1))
# add the point estimate of the mean
points(cr.Dementia$fprsens)
# add the SROC curve
lines(sroc.Dementia)

</code></pre>

<hr>
<h2 id='ROCellipse'>
Confidence Regions on ROC space
</h2><span id='topic+ROCellipse'></span><span id='topic+ROCellipse.default'></span>

<h3>Description</h3>

<p>Plot individual confidence regions for the estimate from each primary study on ROC space or add such regions to an existing plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
ROCellipse(x, correction = 0.5, level = 0.95, 
           xlim = c(0, 1), ylim = c(0, 1), method = "wilson", 
           pch = 1, add = FALSE, corr = 0, suppress = TRUE, 
           ellipsecol = "grey", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ROCellipse_+3A_x">x</code></td>
<td>
<p>a data frame with variables including <code>TP</code>, <code>FN</code>, <code>FP</code>, <code>TN</code>, alternatively a matrix with column names including these.</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_correction">correction</code></td>
<td>
<p>numeric, continuity correction applied to zero cells.</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_level">level</code></td>
<td>
<p>numeric, confidence level for the calculations of confidence intervals.
</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_xlim">xlim</code></td>
<td>
<p>numeric of length 2, which portion of ROC space should be plotted? All reasonable values should be within (0,1).</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_ylim">ylim</code></td>
<td>
<p>numeric of length 2, which portion of ROC space should be plotted? All reasonable values should be within (0,1).</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_method">method</code></td>
<td>
<p>character, method used to calculate the confidence intervals for sensitivities, specificities and false positive rates. One of <code>"wald"</code>, <code>"wilson"</code>, <code>"agresti-coull"</code>, <code>"jeffreys"</code>, <code>"modified wilson"</code>, <code>"modified jeffreys"</code>, <code>"clopper-pearson"</code>, <code>"arcsine"</code>, <code>"logit"</code>, <code>"witting"</code></p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_pch">pch</code></td>
<td>
<p>Symbol used to plot point estimates. Use <code>pch = ""</code> to suppress plotting point estimates.</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_add">add</code></td>
<td>
<p>logical, should the plot be added to the current plot?</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_corr">corr</code></td>
<td>
<p>numeric or character, the correlation assumed in the calculation of the confidence ellipsoids on logit-ROC space. If set to <code>"logit"</code>, the correlation of the logit-transformed sensitivities and false positive rates will be used in the correlations. See details for further explanation.</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_suppress">suppress</code></td>
<td>
<p>logical, should the warnings produced by the internal call to <code>madad</code> be suppressed? Defaults to <code>TRUE</code>, since only the diagnostic accuracies and their confidence intervals are used in subsequent calculations.</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_ellipsecol">ellipsecol</code></td>
<td>
<p>The color used for plotting the ellipses.</p>
</td></tr>
<tr><td><code id="ROCellipse_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confindence regions are ellipses on logit-ROC space, hence the name of the function. The standard deviations underlying confidence intervals for the sensitivities and false positive rates are used to determine the scale of the ellipses on logit-ROC space. These ellipses get backtransformed to ROC space and plotted. As a default no correlation is assumed on logit-ROC space.
</p>
<p>The objects of class <code><a href="#topic+reitsma">reitsma</a></code> have their own <code>ROCellipse</code> method to add a confidence region for the pooled estimate, see <code><a href="#topic+reitsma-class">reitsma-class</a></code>.
</p>


<h3>Value</h3>

<p>Besides plotting an invisble <code>NULL</code> is returned.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crosshair">crosshair</a></code>, <code><a href="#topic+reitsma-class">reitsma-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AuditC)
ROCellipse(AuditC)
</code></pre>

<hr>
<h2 id='rsSROC'>
Plot the Ruecker-Schumacher (2010) SROC curve
</h2><span id='topic+rsSROC'></span>

<h3>Description</h3>

<p>Assuming that a weighted Youden index is maximized in all primary studies, the Ruecker-Schumacher approach estimates individual ROC curves and then averages them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsSROC(data = NULL, subset=NULL,
  TP="TP", FN="FN", FP="FP", TN="TN", 
  lambda = "from_bivariate",                  
  fpr = NULL, extrapolate = FALSE, plotstudies = FALSE,
  correction = 0.5, correction.control = "all",
  add = FALSE, lty = 1, lwd = 1, col = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rsSROC_+3A_data">data</code></td>
<td>
<p>any object that can be converted to a data frame with integer variables for observed frequencies of true positives, false negatives, false positives and true negatives. The names of the variables  are provided by the arguments <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code> (see their defaults). Alternatively the data can be a matrix with column names including <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code>. If no <code>data</code> is specified, the function will check the <code>TP</code>, <code>FN</code>, <code>FP</code> and <code>TN</code> arguments.
</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_tp">TP</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_fn">FN</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_fp">FP</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_tn">TN</code></td>
<td>
<p>character or integer: name for vector of integers that is a variable of <code>data</code> or a vector of integers. If <code>data</code> is not <code>NULL</code>, names are expected, otherwise integers are.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_subset">subset</code></td>
<td>
<p>the rows of <code>data</code> to be used as a subset in all calculations. If <code>NULL</code> (the default) then the complete data is considered.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_lambda">lambda</code></td>
<td>
<p>numeric or <code>"from_bivariate"</code>, the weight of the weighted Youden index. Must be between 0 and 1. If set to <code>"from_bivariate"</code>, the <code><a href="#topic+reitsma">reitsma</a></code> function is used to calculate lambda from the data.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_fpr">fpr</code></td>
<td>
<p>Points between 0 and 1 on which to draw the SROC curve. Should be tightly spaced. If set to <code>NULL</code>, the default, it will be the vector of numbers <code>0.01, 0.02, ..., 0.99</code> and is truncated if the <code>extrapolate</code> argument is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_extrapolate">extrapolate</code></td>
<td>
<p>logical, should the SROC curve be extrapolated beyond the region where false positive rates are observed?</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_plotstudies">plotstudies</code></td>
<td>
<p>logical, should the ROC curves for the individual studies be added to the plot? The plot will become crowded if set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_correction">correction</code></td>
<td>
<p>numeric, continuity correction applied if zero cells</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_correction.control">correction.control</code></td>
<td>
<p>character, if set to <code>"all"</code> (the default) the continuity correction is added to the whole data if only one cell in one study is zero. If set to <code>"single"</code> the correction is only applied to rows of the data which have a zero.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_add">add</code></td>
<td>
<p>logical, should the SROC curve be added to an existing plot?</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_lty">lty</code></td>
<td>
<p>line type, see <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_lwd">lwd</code></td>
<td>
<p>line width, see <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_col">col</code></td>
<td>
<p>color of SROC, see <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="rsSROC_+3A_...">...</code></td>
<td>
<p>arguments to be passed on to plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details are found in the paper of Ruecker and Schumacher (2010).
</p>


<h3>Value</h3>

<p>Besides plotting the SROC, an <code><a href="base.html#topic+invisible">invisible</a></code> list is returned which contains the parameters of the SROC.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt; 
Original code kindly supplied by G. Ruecker.
</p>


<h3>References</h3>

<p>Ruecker G., &amp; Schumacher M. (2010) &ldquo;Summary ROC curve based on a weighted Youden index for selecting an optimal cutpoint in meta-analysis of diagnostic accuracy.&rdquo; <em>Statistics in Medicine</em>, <b>29</b>, 3069&ndash;3078.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reitsma-class">reitsma-class</a></code>, <code><a href="#topic+talpha">talpha</a></code>, <code><a href="#topic+SummaryPts">SummaryPts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## First Example
data(Dementia)
ROCellipse(Dementia)
rsSROC(Dementia, add = TRUE) # Add the RS-SROC to this plot

## Second Example
# Make a crowded plot and look at the coefficients
rs_Dementia &lt;- rsSROC(Dementia, col = 3, lwd = 3, lty = 3, 
                      plotstudies = TRUE)
rs_Dementia$lambda
rs_Dementia$aa # intercepts of primary studies on logit ROC space
rs_Dementia$bb # slopes 
</code></pre>

<hr>
<h2 id='sens'>Sensitivity, Specificity and False Positive Rate</h2><span id='topic+sens'></span><span id='topic+fpr'></span><span id='topic+spec'></span>

<h3>Description</h3>

<p>Calculate basic measures of diagnostic accuracy for a number of studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sens(x)
spec(x)
fpr(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sens_+3A_x">x</code></td>
<td>
<p>a data frame with variables including <code>TP</code>, <code>FN</code>, <code>FP</code>, <code>TN</code>, alternatively a matrix with column names including these.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are the basic building blocks of many procedures to assess diagnostic accuracy. For a decent summary of  set of primary studies it is better to use <code><a href="#topic+madad">madad</a></code>, for graphical summaries <code><a href="#topic+crosshair">crosshair</a></code> and <code><a href="#topic+ROCellipse">ROCellipse</a></code> are available.
</p>


<h3>Value</h3>

<p>A numeric vector.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+madad">madad</a></code>, <code><a href="#topic+crosshair">crosshair</a></code>, <code>link{ROC.ellipse}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(AuditC)
plot(fpr(AuditC), sens(AuditC), main = "AUDIT-C data on ROC space",
     ylab = "Sensitivity", xlab = "False Positive Rate")
</code></pre>

<hr>
<h2 id='SummaryPts'>
Use the Zwindermann &amp; Bossuyt (2008) MCMC procedure to generate summary points (positive and negative likelihood ratio, diagnostic odds ratio) for the Reitsma et al. (2005) bivariate model
</h2><span id='topic+SummaryPts'></span><span id='topic+SummaryPts.default'></span><span id='topic+SummaryPts.reitsma'></span><span id='topic+print.SummaryPts'></span><span id='topic+summary.SummaryPts'></span>

<h3>Description</h3>

<p>Zwindermann &amp; Bossuyt (2008) argue that likelihood ratios should not be pooled by univariate meta-analysis. They propose a sampling based approach that uses the parameters of a fit to the bivariate model (implemented in <code><a href="#topic+reitsma">reitsma</a></code>) to generate samples for observed sensitivities and false positive rates. From these samples the quantities of interest (and their confidence intervals) are estimated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SummaryPts(object, ...)
## Default S3 method:
SummaryPts(object, mu,Sigma,alphasens = 1, alphafpr = 1,
                           n.iter = 10^6, FUN, ...)
## S3 method for class 'reitsma'
SummaryPts(object, n.iter = 10^6, FUN = NULL, ...)
## S3 method for class 'SummaryPts'
print(x, ...)
## S3 method for class 'SummaryPts'
summary(object, level = 0.95, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SummaryPts_+3A_object">object</code></td>
<td>
<p>an object for which a method exists</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_x">x</code></td>
<td>
<p>An object of class <code>SummaryPts</code></p>
</td></tr>  
<tr><td><code id="SummaryPts_+3A_mu">mu</code></td>
<td>
<p>numeric of length 2, expected to be the mean parameter of a bivariate model</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_sigma">Sigma</code></td>
<td>
<p>2x2 variance covariance matrix, expected to be the matrix representing the standard error of <code>mu</code>  and the covariance of these two estimates</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_alphasens">alphasens</code></td>
<td>
<p>numeric, alpha parameter for the sensitivities. Amounts to logit transformation if set to 1 (the default). See <code><a href="#topic+reitsma">reitsma</a></code>.</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_alphafpr">alphafpr</code></td>
<td>
<p>numeric, alpha parameter for the false positive rates. Amounts to logit transformation if set to 1 (the default). See <code><a href="#topic+reitsma">reitsma</a></code>.</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_n.iter">n.iter</code></td>
<td>
<p>number of samples</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_fun">FUN</code></td>
<td>
<p>A list of functions with 2 arguments (<code>sens</code> and <code>fpr</code>); if set to <code>NULL</code> in <code>SummaryPts.reitsma</code>, the positive, negative and inverse negative likelihood ratios are calculated and also the diagnostic odds ratio (DOR). See the example on how to supply other functions.</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_level">level</code></td>
<td>
<p>numeric, confidence level for confidence intervals</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_digits">digits</code></td>
<td>
<p>number of significant digits to display</p>
</td></tr>
<tr><td><code id="SummaryPts_+3A_...">...</code></td>
<td>
<p>arguments to be passed on to other functions, currently ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Samples are generated from a bivariate normal using <code>rmvnorm</code>. Note that the FUN argument
</p>


<h3>Value</h3>

<p>An object of the class <code>SummaryPts</code> for which <code>print</code> and <code>summary</code> methods are available.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Reitsma, J., Glas, A., Rutjes, A., Scholten, R., Bossuyt, P., &amp; Zwinderman, A. (2005).
&ldquo;Bivariate analysis of sensitivity and specificity produces informative summary
measures in diagnostic reviews.&rdquo; <em>Journal of Clinical Epidemiology</em>, <b>58</b>, 982&ndash;990.
</p>
<p>Zwinderman, A., &amp; Bossuyt, P. (2008). &ldquo;We should not pool diagnostic likelihood ratios
in systematic reviews.&rdquo;<em>Statistics in Medicine</em>, <b>27</b>, 687&ndash;697.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reitsma">reitsma</a></code>, <code><a href="#topic+talpha">talpha</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Dementia)
(fit &lt;- reitsma(Dementia))
mcmc_sum &lt;- SummaryPts(fit, n.iter = 10^3)
## n.iter should be larger in applications!
mcmc_sum #just the means
summary(mcmc_sum) # 95% CIs by default
summary(mcmc_sum, level = 0.80, digits = 5) ## more digits, smaller CIs

## Supplying other functions

# Example 1: theta parameter of proportional hazards model 
# see "phm" in mada's documentation for details on theta 
theta &lt;- function(sens,fpr){log(sens) / log(fpr)}
theta_sum &lt;- SummaryPts(fit, FUN = list(theta = theta), n.iter = 10^3)
## n.iter should be larger in applications!
summary(theta_sum)
# compare with phm:
summary(phm(Dementia)) # the two estimators almost agree in this example

# Example 2: Youden index
Youden &lt;- function(sens, fpr){sens - fpr}
Youden_sum &lt;- SummaryPts(fit, FUN = list(Youden = Youden), , n.iter = 10^3)
## n.iter should be larger in applications!
summary(Youden_sum)
</code></pre>

<hr>
<h2 id='talpha'>
The <code class="reqn">t_\alpha</code> transformation as a link function for binary GLMs.
</h2><span id='topic+talpha'></span>

<h3>Description</h3>

<p>A parametric link function, i.e. a family of link functions intended for binary data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>talpha(alpha, verbose = FALSE,
  splineinv = TRUE, eps = 2 * .Machine$double.eps, maxit = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="talpha_+3A_alpha">alpha</code></td>
<td>
<p>numeric, must be larger than 0 and smaller than 2.</p>
</td></tr>
<tr><td><code id="talpha_+3A_verbose">verbose</code></td>
<td>
<p>logical, warn if truncation occurs when link function or inverse are used.
</p>
</td></tr>
<tr><td><code id="talpha_+3A_splineinv">splineinv</code></td>
<td>
<p>logical, use spline interpolation for calculation of inverse link?</p>
</td></tr>
<tr><td><code id="talpha_+3A_eps">eps</code></td>
<td>
<p>if splineinv is <code>FALSE</code>, a Newton-Raphson algorithm is run to calculate the inverse. The argument <code>eps</code> determines when to terminate this algorithm. Ignored if splineinv is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="talpha_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations for Newton-Raphson. Ignored if splineinv is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"link-glm"</code>, see <code><a href="stats.html#topic+family">family</a></code> and <code><a href="stats.html#topic+family">family</a></code>. Intended for use with <code><a href="stats.html#topic+glm">glm</a></code>.
</p>


<h3>Author(s)</h3>

<p>Philipp Doebler &lt;philipp.doebler@googlemail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>canonical &lt;- binomial(link = talpha(1)) # logit-link
talpha_fam &lt;- function(alpha)binomial(link = talpha(alpha)) # talpha family
## A call to glm might look like this: glm(formula, family = talpha_fam(1.5))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
