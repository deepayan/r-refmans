<!DOCTYPE html><html lang="en"><head><title>Help for package popsom7</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {popsom7}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#map.build'><p>Build Map</p></a></li>
<li><a href='#map.convergence'><p>SOM Quality Assessment</p></a></li>
<li><a href='#map.fitted'><p>Fit Observations</p></a></li>
<li><a href='#map.marginal'><p>Plot Marginal Distribution</p></a></li>
<li><a href='#map.position'><p>Compute Map Positions for Given Points</p></a></li>
<li><a href='#map.predict'><p>Compute Classification Labels for Given Points</p></a></li>
<li><a href='#map.significance'><p>Compute Significance of Features</p></a></li>
<li><a href='#map.starburst'><p>Generate Starburst For Map</p></a></li>
<li><a href='#map.summary'><p>Summary Object for Map</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>Title:</td>
<td>A Fast, User-Friendly Implementation of Self-Organizing Maps
(SOMs)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lutz Hamel &lt;lutzhamel@uri.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods for building self-organizing maps (SOMs) with a number of distinguishing features such automatic centroid detection and cluster visualization using starbursts.  For more details see the paper "Improved Interpretability of the Unified Distance Matrix with Connected Components" by Hamel and Brown (2011) in &lt;ISBN:1-60132-168-6&gt;.  The package provides user-friendly access to two models we construct: (a) a SOM model and (b) a centroid based clustering model. The package also exposes a number of quality metrics for the quantitative evaluation of the map, Hamel (2016) &lt;<a href="https://doi.org/10.1007%2F978-3-319-28518-4_4">doi:10.1007/978-3-319-28518-4_4</a>&gt;.  Finally, we reintroduced our fast, vectorized training algorithm for SOM with substantial improvements. It is about an order of magnitude faster than the canonical, stochastic C implementation &lt;<a href="https://doi.org/10.1007%2F978-3-030-01057-7_60">doi:10.1007/978-3-030-01057-7_60</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/lutzhamel/popsom7">https://github.com/lutzhamel/popsom7</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lutzhamel/popsom7/issues">https://github.com/lutzhamel/popsom7/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>fields, graphics, ggplot2, hash, stats, som, grDevices</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-02 13:59:25 UTC; ubuntu</td>
</tr>
<tr>
<td>Author:</td>
<td>Lutz Hamel [aut, cre],
  Benjamin Ott [aut],
  Gregory Breard [aut],
  Robert Tatoian [aut],
  Michael Eiger [aut],
  Vishakh Gopu [aut]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-02 16:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='map.build'>Build Map</h2><span id='topic+map.build'></span>

<h3>Description</h3>

<p>Construct a self-organizing map and return an object of class &lsquo;map&rsquo;</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.build(data,labels=NULL,xdim=10,ydim=5,
          alpha=0.3,train=1000,normalize=FALSE,
          seed=NULL,minimal=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.build_+3A_data">data</code></td>
<td>
<p>A dataframe where each row contains an unlabeled training instance.</p>
</td></tr>
<tr><td><code id="map.build_+3A_labels">labels</code></td>
<td>
<p>A vector or dataframe with one label for each observation in data.</p>
</td></tr>
<tr><td><code id="map.build_+3A_xdim">xdim</code></td>
<td>
<p>The x-dimension of the map.</p>
</td></tr>
<tr><td><code id="map.build_+3A_ydim">ydim</code></td>
<td>
<p>The y-dimension of the map.</p>
</td></tr>
<tr><td><code id="map.build_+3A_alpha">alpha</code></td>
<td>
<p>The learning rate, should be a value greater than zero and less or equal to one.</p>
</td></tr>
<tr><td><code id="map.build_+3A_train">train</code></td>
<td>
<p>The number of training iterations.</p>
</td></tr>
<tr><td><code id="map.build_+3A_normalize">normalize</code></td>
<td>
<p>Boolean switch indicating whether or not to normalize the data.</p>
</td></tr>
<tr><td><code id="map.build_+3A_seed">seed</code></td>
<td>
<p>A seed value for repeatablity of random initialization and selection.</p>
</td></tr>
<tr><td><code id="map.build_+3A_minimal">minimal</code></td>
<td>
<p>Boolean switch indicating whether to build a &lsquo;map.minimal&rsquo; or &lsquo;map&rsquo; object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function &lsquo;map.build&rsquo; constructs an object of type &lsquo;map&rsquo;. The object contains two models: (1) A self-organizing map model expressed through its trained neurons and its quality of fit can be ascertained by the &lsquo;convergence&rsquo; (see below). (2) A cluster model expressed by the discovered centroids.  The quality of these models can be ascertained by the &lsquo;map convergence&rsquo;, &lsquo;within cluster sum of squares&rsquo;, and the &lsquo;between cluster sum of squares&rsquo; (see below). </p>


<h3>Value</h3>

<p>An object of type &lsquo;map&rsquo;.  The object has the following member fields:
</p>

<dl>
<dt>data</dt><dd><p>Data frame contining the possibly normalized training data.</p>
</dd>
<dt>labels</dt><dd><p>Vector of labels, one for each observation in data or NULL if no labels were given.</p>
</dd>
<dt>xdim</dt><dd><p>The x dimension of the neuron map.</p>
</dd>
<dt>ydim</dt><dd><p>The y dimension of the neuron map.</p>
</dd>
<dt>alpha</dt><dd><p>The given learning rate for the neural network.</p>
</dd>
<dt>train</dt><dd><p>The training iterations applied to the neural network.</p>
</dd>
<dt>neurons</dt><dd><p>A list of neurons for the network. The dimensionality of this
data frame is the same as the training data.  The following two formulas
come in handy when working with the neural data.  The first set of computations
provide the x and y coordinate on the map of the neuron in row &lsquo;rowix&rsquo; of the &lsquo;neurons&rsquo; data frame,
</p>
<pre>
    x &lt;- (rowix-1)%%map$xdim+1
    y &lt;- (rowix-1)%/%map$xdim+1
</pre>
<p>The second formula computes the row of the neuron in position (x,y) on the map,
</p>
<pre>
    rowix &lt;- x+(y-1)*map$xdim
</pre></dd>
<dt>heat</dt><dd><p>This is the representation of the map which is the basis for the &lsquo;starburst&rsquo; plot.</p>
</dd>
<dt>fitted.obs</dt><dd><p>List of indexes of the best matching neuron for each observation.  Each index is an row index into the &lsquo;neuron&rsquo; data frame.</p>
</dd>
<dt>centroids</dt><dd><p>This is a data frame of (x,y)-locations where each cell points
to the the (x,y)-location on the map where the corresponding centroid
is located.  Centroids point to themselves.</p>
</dd>
<dt>unique.centroids</dt><dd><p>A vector of actual centroid (x,y)-locations on the map. Hint: to compute the number of clusters on the map take the length of this vector.</p>
</dd>
<dt>centroid.labels</dt><dd><p>A data frame where the (x,y)-locations of actual centroids have a label associated with them. All other locations are NULL. If the training data is unlabeled  then popsom invents a label for each centroid.</p>
</dd>
<dt>label.to.centroid</dt><dd><p>A label-to-centroid lookup table (hash). A lookup in this table will return a list of indexes into the &lsquo;unique.centroids&rsquo; table. Note: a label can be associated with multiple centroids.</p>
</dd>
<dt>centroid.obs</dt><dd><p>A vector of lists of observations per centroid indexed
by the centroid number from &lsquo;unique.centroids&rsquo;.  The observations on the list are row numbers of the &lsquo;data&rsquo; data frame.</p>
</dd>
<dt>convergence</dt><dd><p>A quality measure of how well the map fits the training data.</p>
</dd>
<dt>wcss</dt><dd><p>The average &lsquo;within cluster sum of squares&rsquo;. This is the average
distance variance within the clusters of the underlying cluster model.</p>
</dd>
<dt>bcss</dt><dd><p>The &lsquo;between cluster sum of squares&rsquo;.  This is the distance
variance between the cluster centroids of the underlying cluster model.</p>
</dd>
</dl>



<h3>Note</h3>

<p>If the &lsquo;minimal&rsquo; switch is set to TRUE then a &lsquo;map.minimal&rsquo; object is returned which only contains the trained neurons together with the training parameters. Observe that none of the POPSOM interface functions will work with this kind of object. </p>


<h3>Note</h3>

<p>If your training data is unlabeled popsom will automatically
generate a label for each of the centroids it discovers.</p>


<h3>Author(s)</h3>

<p>Lutz Hamel, Benjamin Ott, Gregory Breard</p>


<h3>References</h3>

<p>VSOM: Efficient, Stochastic Self-Organizing Map Training, Lutz Hamel, Intelligent Systems Conference (IntelliSys) 2018, K. Arai et al. (Eds.): Intelligent Systems and Applications, Advances in Intelligent Systems and Computing 869, pp 805-821, Springer, 2018.
</p>
<p>Self-Organizing Map Convergence, Robert Tatoian and Lutz Hamel. Proceedings of the 2016 International Conference on Data Mining (DMIN'16), pp92-98, July 25-28, 2016, Las Vegas, Nevada, USA, ISBN: 1-60132-431-6, CSREA Press.
</p>
<p>Evaluating Self-Organizing Map Quality Measures as Convergence Criteria, Gregory Breard and Lutz Hamel, Proceedings of the 2018 International Conference on Data Science (ICDATA'18), Robert Stahlbock, Gary M. Weiss, Mahmoud Abou-Nasr (Eds.), ISBN: 1-60132-481-2, pp 86-92, CSREA Press, 2018.
</p>
<p>SOM Quality Measures: An Efficient Statistical Approach, Lutz Hamel, Proceedings of the 11th International Workshop WSOM 2016, Houston, Texas USA, E. Merenyi et al. (eds.), Advances in Self-Organizing Maps and Learning Vector Quantization, Advances in Intelligent Systems and Computing 428, Springer, pp 49-59, DOI 10.1007/978-3-319-28518-4_4, 2016.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># training data
data(iris)
df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

# build a map
m &lt;- map.build(df,labels,xdim=15,ydim=10,train=10000,seed=42)

# look at the characteristics of the maps
map.summary(m)

# plot the map
map.starburst(m)
</code></pre>

<hr>
<h2 id='map.convergence'>SOM Quality Assessment</h2><span id='topic+map.convergence'></span>

<h3>Description</h3>

<p>Evaluate the quality of a SOM using embedding accuracy and estimated topographical accuracy.</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.convergence(map,conf.int=.95,k=50,verb=TRUE,ks=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.convergence_+3A_map">map</code></td>
<td>
<p>an object of type 'map'.</p>
</td></tr>
<tr><td><code id="map.convergence_+3A_conf.int">conf.int</code></td>
<td>
<p>is the confidence interval of the quality assessment.</p>
</td></tr>
<tr><td><code id="map.convergence_+3A_k">k</code></td>
<td>
<p>number of samples to use in the computation of the estimated topographical accuracy.</p>
</td></tr>
<tr><td><code id="map.convergence_+3A_verb">verb</code></td>
<td>
<p>if true reports the two convergence components separately, otherwise it will report a linear combination of the two indices.</p>
</td></tr>
<tr><td><code id="map.convergence_+3A_ks">ks</code></td>
<td>
<p>if true uses the Kolmogorov-Smirnov convergence test otherwise a convergence test based on variance and means is performed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single value or a pair of values: 1) embedding accuracy 2) estimated topographic accuracy.
The structure of the return value depends on the 'verb' switch.
</p>


<h3>Author(s)</h3>

<p>Lutz Hamel</p>


<h3>References</h3>

<p>&quot;SOM Quality Measures: A Statistical Approach,&quot;
Lutz Hamel, WSOM16, 2016.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

## set data frame and labels
df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

## build a map
m &lt;- map.build(df, labels, xdim=15, ydim=10, train=1000)

## map quality
map.convergence(m)

</code></pre>

<hr>
<h2 id='map.fitted'>Fit Observations</h2><span id='topic+map.fitted'></span>

<h3>Description</h3>

<p>Computes a vector of labels assigned to each of the observations in the training data through the constructed cluster model.  If the training data is unlabeled then machine-generated labels are used.</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.fitted(map)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.fitted_+3A_map">map</code></td>
<td>
<p>An object of type 'map'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted labels, one for each observations in the training data.</p>


<h3>Author(s)</h3>

<p>Lutz Hamel</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

m &lt;- map.build(df,labels,xdim=15,ydim=10,train=10000)

map.fitted(m)
</code></pre>

<hr>
<h2 id='map.marginal'>Plot Marginal Distribution</h2><span id='topic+map.marginal'></span>

<h3>Description</h3>

<p>Generate a plot that shows the marginal probability distribution of the neurons and data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.marginal(map,marginal)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.marginal_+3A_map">map</code></td>
<td>
<p>An object of type 'map'.</p>
</td></tr>
<tr><td><code id="map.marginal_+3A_marginal">marginal</code></td>
<td>
<p>The name of a training data dimension or index.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Lutz Hamel, Robert Tatoian</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

## set data frame and labels
df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

## build a map
m &lt;- map.build(df,labels,xdim=15,ydim=10,train=10000)

## display marginal distribution of dimension 1
map.marginal(m,1)
</code></pre>

<hr>
<h2 id='map.position'>Compute Map Positions for Given Points</h2><span id='topic+map.position'></span>

<h3>Description</h3>

<p>Compute the (x,y)-positions of points on the map.</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.position(map,points)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.position_+3A_map">map</code></td>
<td>
<p>An object of type 'map'.</p>
</td></tr>
<tr><td><code id="map.position_+3A_points">points</code></td>
<td>
<p>A data frame of points to be mapped.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with (x,y)-positions.  The data frame has two columns:
</p>

<dl>
<dt>x-dim</dt><dd><p>The x-position of the corresponding point in the 'points' data frame.</p>
</dd>
<dt>y-dim</dt><dd><p>The y-position of the corresponding point in the 'points' data frame.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Lutz Hamel</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

m &lt;- map.build(df,labels,xdim=15,ydim=10,train=10000)

map.position(m,df)
</code></pre>

<hr>
<h2 id='map.predict'>Compute Classification Labels for Given Points</h2><span id='topic+map.predict'></span>

<h3>Description</h3>

<p>Compute classification labels for points in a given data frame using the underlying clustering model.  If the training data is unlabeled then machine-generated labels are used.</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.predict(map,points)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.predict_+3A_map">map</code></td>
<td>
<p>An object of type 'map'.</p>
</td></tr>
<tr><td><code id="map.predict_+3A_points">points</code></td>
<td>
<p>A data frame of points to be classified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with classification results.  The data frame has two columns:
</p>

<dl>
<dt>Label</dt><dd><p>The assigned label to the observation at the same row in the 'points' data frame.</p>
</dd>
<dt>Confidence</dt><dd><p>A confidence value assigned to the label prediction.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Lutz Hamel</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

m &lt;- map.build(df,labels,xdim=15,ydim=10,train=10000)

map.predict(m,df)
</code></pre>

<hr>
<h2 id='map.significance'>Compute Significance of Features</h2><span id='topic+map.significance'></span>

<h3>Description</h3>

<p>Computes the relative significance of each feature and plots it.</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.significance(map,graphics=FALSE,feature.labels=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.significance_+3A_map">map</code></td>
<td>
<p>An object of type 'map'.</p>
</td></tr>
<tr><td><code id="map.significance_+3A_graphics">graphics</code></td>
<td>
<p>A switch that controls whether a plot is generated or not.</p>
</td></tr>
<tr><td><code id="map.significance_+3A_feature.labels">feature.labels</code></td>
<td>
<p>A switch to allow the plotting of feature names vs feature indices.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If graphics=FALSE a vector containing the significance for each feature is returned.</p>


<h3>Note</h3>

<p>We use a Bayesian approach to compute the relative significance of features based on
variance.</p>


<h3>Author(s)</h3>

<p>Lutz Hamel</p>


<h3>References</h3>

<p>Bayesian Probability Approach to Feature Significance for Infrared Spectra of Bacteria,
Lutz Hamel, Chris W. Brown, Applied Spectroscopy, Volume 66, Number 1, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

m &lt;- map.build(df,labels,xdim=15,ydim=10,train=10000)

## show the relative feature significance
map.significance(m)
</code></pre>

<hr>
<h2 id='map.starburst'>Generate Starburst For Map</h2><span id='topic+map.starburst'></span>

<h3>Description</h3>

<p>Generate a starburst representation of the clusters on the heat map for the
self-organizing map model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.starburst(map)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.starburst_+3A_map">map</code></td>
<td>
<p>An object of type 'map'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Lutz Hamel, Benjamin Ott, Gregory Breard, Robert Tatoian, Vishakh Gopu</p>


<h3>References</h3>

<p>Improved Interpretability of the Unified Distance Matrix with Connected Components,
Lutz Hamel and Chris W. Brown. Proceeding of the 7th International Conference on
Data Mining (DMIN'11), July 18-21, 2011, Las Vegas Nevada, USA, ISBN: 1-60132-168-6, pp338-343,
CSREA Press, 2011.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

m &lt;- map.build(df,labels,xdim=15,ydim=10,train=10000)

map.starburst(m)
</code></pre>

<hr>
<h2 id='map.summary'>Summary Object for Map</h2><span id='topic+map.summary'></span>

<h3>Description</h3>

<p>Generate a summary object for 'map' objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>map.summary(map,verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="map.summary_+3A_map">map</code></td>
<td>
<p>An object of type 'map'.</p>
</td></tr>
<tr><td><code id="map.summary_+3A_verb">verb</code></td>
<td>
<p>A switch controlling the output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type 'summary.map' which contains two structures:
</p>

<dl>
<dt>training.parameters</dt><dd><p>A dataframe containing the parameters the map was trained with.</p>
</dd>
<dt>quality.assessments</dt><dd><p>A dataframe containing the quality assessments of the map. In particular, it
contains the 'convergence'  of the map which is a linear combination of variance capture  and
topographic fidelity of the map. A value close to 1 means a converged map (for more details
see the reference below).  Furthermore, it contains the 'separation' of the clusters.
This is computed by the formula,
</p>
<pre> 1 - wcss/bcss</pre>
<p>In general, a value close to 1 means well separated clusters.</p>
</dd>
</dl>

<p>If 'verb' is TRUE the summar.map object will be formatted and printed to the screen, otherwise
it will be returned as a data structure.
</p>


<h3>Author(s)</h3>

<p>Lutz Hamel</p>


<h3>References</h3>

<p>Self-Organizing Map Convergence, Robert Tatoian and Lutz Hamel. Proceedings of the 2016 International Conference on Data Mining (DMIN'16), pp92-98, July 25-28, 2016, Las Vegas, Nevada, USA, ISBN: 1-60132-431-6, CSREA Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

## set data frame and labels
df &lt;- subset(iris,select=-Species)
labels &lt;- subset(iris,select=Species)

## build a map
m &lt;- map.build(df,labels,xdim=15,ydim=10,train=10000)

## compute a summary object and display it
s &lt;- map.summary(m,verb=FALSE)
s
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
