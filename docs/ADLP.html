<!DOCTYPE html><html><head><title>Help for package ADLP</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ADLP}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adlp_partition'><p>Accident and Development period Adjusted Linear Pools partition function</p></a></li>
<li><a href='#calc_adlp_component'><p>Accident and Development period Adjusted Linear Pools Component Models</p></a></li>
<li><a href='#custom_model'><p>Custom Model Wrapper</p></a></li>
<li><a href='#MM_optim'><p>Minorization-Maximisation Algorithm performed to fit the ADLPs</p></a></li>
<li><a href='#predict.adlp'><p>Accident and Development period Adjusted Linear Pools (ADLP) Functions</p></a></li>
<li><a href='#print.adlp'><p>Accident and Development period Adjusted Linear Pools (ADLP) Models</p></a></li>
<li><a href='#print.adlp_component'><p>Accident and Development period Adjusted Linear Pools Component Models</p></a></li>
<li><a href='#print.adlp_components'><p>Accident and Development period Adjusted Linear Pools Component Models</p></a></li>
<li><a href='#test_adlp_component'><p>Test ADLP Component</p></a></li>
<li><a href='#test_claims_dataset'><p>Claims Data in data.frame Format</p></a></li>
<li><a href='#train_val_split'><p>Train-Validation Split of Claims Triangle</p></a></li>
<li><a href='#train_val_split_by_AP'><p>Train-Validation Split by Accident Period</p></a></li>
<li><a href='#train_val_split_method1'><p>Train-Validation Split by Accident Period Method 1</p></a></li>
<li><a href='#train_val_split_method2'><p>Train-Validation Split by Accident Period Method 2</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Accident and Development Period Adjusted Linear Pools for
Actuarial Stochastic Reserving</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Benjamin Avanzi [aut],
  William Ho [aut],
  Yanfeng Li [aut, cre],
  Bernard Wong [aut],
  Alan Xian [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yanfeng Li &lt;yanfeng.li@student.unsw.edu.au&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Loss reserving generally focuses on identifying a single model that can generate superior predictive performance. However, different loss reserving models specialise in capturing different aspects of loss data.
    This is recognised in practice in the sense that results from different models are often considered, and sometimes combined. For instance, actuaries may take a weighted average of the prediction outcomes from
    various loss reserving models, often based on subjective assessments.
        This package allows for the use of a systematic framework to objectively combine (i.e. ensemble) multiple stochastic loss reserving models such that the strengths offered by different models can be utilised effectively. Our
    framework is developed in Avanzi et al. (2023). Firstly, our criteria model combination considers the full distributional properties of the ensemble and not just the central
    estimate - which is of particular importance in the reserving context. Secondly, our framework is that it is tailored for the features inherent to reserving data. These include, for instance, accident, development,
    calendar, and claim maturity effects. Crucially, the relative importance and scarcity of data across accident periods renders the problem distinct from the traditional ensemble techniques in statistical learning.
        Our framework is illustrated with a complex synthetic dataset. In the results, the optimised ensemble outperforms both (i) traditional model selection strategies, and (ii) an equally weighted ensemble. In
    particular, the improvement occurs not only with central estimates but also relevant quantiles, such as the 75th percentile of reserves (typically of interest to both insurers and regulators).
    Reference: Avanzi B, Li Y, Wong B, Xian A (2023) "Ensemble distributional forecasting for insurance loss reserving" &lt;<a href="https://doi.org/10.48550%2FarXiv.2206.08541">doi:10.48550/arXiv.2206.08541</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/agi-lab/ADLP">https://github.com/agi-lab/ADLP</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/agi-lab/ADLP/issues">https://github.com/agi-lab/ADLP/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, tidyverse, SynthETIC (&ge; 1.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-18 07:21:50 UTC; jimli</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-18 19:23:01 UTC</td>
</tr>
</table>
<hr>
<h2 id='adlp_partition'>Accident and Development period Adjusted Linear Pools partition function</h2><span id='topic+adlp_partition'></span><span id='topic+adlp_partition_none'></span><span id='topic+adlp_partition_ap'></span>

<h3>Description</h3>

<p>General framework for any user-defined function for partitions of
claims triangle data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adlp_partition(df, ...)

adlp_partition_none(df)

adlp_partition_ap(df, tri.size, size = 1, weights = rep(1, size))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adlp_partition_+3A_df">df</code></td>
<td>
<p>data.frame format of claims and related information for each cell.
Dataframe will have columns <code>origin</code> and <code>dev</code> as columns 1 and 2 respectively.</p>
</td></tr>
<tr><td><code id="adlp_partition_+3A_...">...</code></td>
<td>
<p>Other parameters used to calculate ADLP partitions</p>
</td></tr>
<tr><td><code id="adlp_partition_+3A_tri.size">tri.size</code></td>
<td>
<p>Triangle size in claims</p>
</td></tr>
<tr><td><code id="adlp_partition_+3A_size">size</code></td>
<td>
<p>Number of partitions</p>
</td></tr>
<tr><td><code id="adlp_partition_+3A_weights">weights</code></td>
<td>
<p>a vector of weights for the size of each partition.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>adlp_partition_none</code> is the default functionality with no partitions. This is
equivalent to the standard linear pooling.
</p>
<p><code>adlp_partition_ap</code> will partition the claims triangle by accident period,
Where the choice of accident period to partition will be determined to most
closely resemble the desired <code>weights</code>.
</p>
<p>The choice of accident period relies on a greedy algorithm that aims to find the
accident period that provides the amount of cells that is larger or equal to the
desired split.
</p>


<h3>Value</h3>

<p>List containing the <code>df</code> as a result of the partitions.
</p>


<h3>See Also</h3>

<p><a href="#topic+adlp_partition_none">adlp_partition_none</a>,
<a href="#topic+adlp_partition_ap">adlp_partition_ap</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("test_claims_dataset")
adlp_partition_none(test_claims_dataset)

data("test_claims_dataset")
adlp_partition_ap(test_claims_dataset, tri.size = 40, size = 3)

</code></pre>

<hr>
<h2 id='calc_adlp_component'>Accident and Development period Adjusted Linear Pools Component Models</h2><span id='topic+calc_adlp_component'></span><span id='topic+calc_adlp_component_lst'></span>

<h3>Description</h3>

<p>Accident and Development period Adjusted Linear Pools Component Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_adlp_component(
  component,
  newdata,
  y = NULL,
  model = c("train", "full"),
  calc = c("pdf", "cdf", "mu", "sim")
)

calc_adlp_component_lst(
  components_lst,
  newdata,
  model = c("train", "full"),
  calc = c("pdf", "cdf", "mu", "sim"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_adlp_component_+3A_component">component</code></td>
<td>
<p>Object of class <code>adlp_component</code></p>
</td></tr>
<tr><td><code id="calc_adlp_component_+3A_newdata">newdata</code></td>
<td>
<p>Claims Triangle and other information. <code>data.frame</code> format of
claims and related information for each cell. Dataframe will have columns
<code>origin</code> and <code>dev</code> as columns 1 and 2 respectively.</p>
</td></tr>
<tr><td><code id="calc_adlp_component_+3A_y">y</code></td>
<td>
<p>Optional vector of <code>y</code> to be used in pdf or cdf calculations. Will
default to the response fetched by <code>model.frame</code>.</p>
</td></tr>
<tr><td><code id="calc_adlp_component_+3A_model">model</code></td>
<td>
<p>Whether the training component model or the full component model
should be used</p>
</td></tr>
<tr><td><code id="calc_adlp_component_+3A_calc">calc</code></td>
<td>
<p>Type of calculation to perform</p>
</td></tr>
<tr><td><code id="calc_adlp_component_+3A_components_lst">components_lst</code></td>
<td>
<p>List of objects of class <code>adlp_component</code></p>
</td></tr>
<tr><td><code id="calc_adlp_component_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed into <code>calc_adlp_component</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calls the specified function for an object of class <code>adlp_component</code>.
</p>
<p><code>calc_adlp_component_lst</code> is a wrapper for <code>calc_adlp_component</code> for each
component in the list <code>components_lst</code>. This wrapper also contains functionality
to signal the component that causes an error if it is occuring downstream.
</p>


<h3>Value</h3>

<p>The result of the evaluated function on the <code>adlp_component</code>. This
would be a vector with the same length as rows on <code>newdata</code> with the
calculations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(test_adlp_component)

newdata &lt;-  test_adlp_component$model_train$data
pdf_data = calc_adlp_component(test_adlp_component, newdata = newdata,
                          model = "train", calc = "pdf")

data(test_adlp_component)
test_component1 &lt;- test_adlp_component
test_component2 &lt;- test_adlp_component
test_components &lt;- adlp_components(
    component1 = test_component1,
    component2 = test_component2
)

newdata &lt;-  test_adlp_component$model_train$data
pdf_data = calc_adlp_component_lst(test_components, newdata = newdata,
                          model = "train", calc = "pdf")
</code></pre>

<hr>
<h2 id='custom_model'>Custom Model Wrapper</h2><span id='topic+custom_model'></span><span id='topic+update.custom_model'></span>

<h3>Description</h3>

<p>Function to define basic functionality needed for a custom model that does
not fit the general framework of models that align with <a href="#topic+adlp_component">adlp_component</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>custom_model(formula, data, ...)

## S3 method for class 'custom_model'
update(object, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="custom_model_+3A_formula">formula</code></td>
<td>
<p>Formula needed that defines all variables required for the model</p>
</td></tr>
<tr><td><code id="custom_model_+3A_data">data</code></td>
<td>
<p>data to update custom model</p>
</td></tr>
<tr><td><code id="custom_model_+3A_...">...</code></td>
<td>
<p>Additional variables for update</p>
</td></tr>
<tr><td><code id="custom_model_+3A_object">object</code></td>
<td>
<p>Object of type <code style="white-space: pre;">&#8288;custom model&#8288;</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Custom model should support the S3 method <code>formula</code> and <code>update</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>custom_model</code>. <code>custom_model</code> is a list that
stores the required formula to update the model and the data used to update
the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("test_claims_dataset")
custom_model &lt;- custom_model(claims~., data=test_claims_dataset)


</code></pre>

<hr>
<h2 id='MM_optim'>Minorization-Maximisation Algorithm performed to fit the ADLPs</h2><span id='topic+MM_optim'></span>

<h3>Description</h3>

<p>The Minorization-Maximization algorithm aims to optimize a
surrogate objective function that approximates the Log Score. This approach
typically results in fast and stable convergence, while ensuring that
combination weights adhere to the constraints of being non-negative and
summing to one. For detailed description of the algorithm, one might refer
to: Conflitti, De Mol, and Giannone (2015)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MM_optim(w_init, dat, niter = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MM_optim_+3A_w_init">w_init</code></td>
<td>
<p>initial weights for each ADLP</p>
</td></tr>
<tr><td><code id="MM_optim_+3A_dat">dat</code></td>
<td>
<p>matrix of densities for each ADLP</p>
</td></tr>
<tr><td><code id="MM_optim_+3A_niter">niter</code></td>
<td>
<p>maximum number of iterations. Defaults to 500</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>mm_optim</code>. <code>mm_optim</code> is a list that stores the
results of the MM algorithm performed, including the final parameters, the
final loss and numer of iterations.
</p>


<h3>References</h3>

<p>Conflitti, Cristina, Christine De Mol, and Domenico Giannone. &quot;Optimal combination of survey forecasts.&quot; International Journal of Forecasting 31.4 (2015): 1096-1103.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>w_init &lt;- rep(1/3, 3)
set.seed(1)
density_data &lt;- matrix(runif(9), nrow = 3, ncol = 3)
MM_optim(w_init, density_data, niter = 500)

</code></pre>

<hr>
<h2 id='predict.adlp'>Accident and Development period Adjusted Linear Pools (ADLP) Functions</h2><span id='topic+predict.adlp'></span><span id='topic+adlp_func'></span><span id='topic+adlp_dens'></span><span id='topic+adlp_logS'></span><span id='topic+adlp_CRPS'></span><span id='topic+adlp_simulate'></span>

<h3>Description</h3>

<p>Family of functions used to support ADLP inference and prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'adlp'
predict(object, newdata = NULL, ...)

adlp_dens(adlp, newdata, model = c("train", "full"))

adlp_logS(adlp, newdata, model = c("train", "full"), epsilon = 1e-06)

adlp_CRPS(
  adlp,
  newdata,
  response_name,
  model = c("train", "full"),
  lower = 1,
  upper = NULL,
  sample_n = 2000
)

adlp_simulate(n, adlp, newdata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.adlp_+3A_object">object</code></td>
<td>
<p>Object of class <code>adlp</code></p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_newdata">newdata</code></td>
<td>
<p>Data to perform the function on</p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_...">...</code></td>
<td>
<p>Other parameters to pass onto predict</p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_adlp">adlp</code></td>
<td>
<p>Object of class <code>adlp</code></p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_model">model</code></td>
<td>
<p>Whether the <code>train</code> or <code>full</code> model should be used in function</p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_epsilon">epsilon</code></td>
<td>
<p>Offset added to the density before calculating the log</p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_response_name">response_name</code></td>
<td>
<p>The column name of the response variable; in string format</p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_lower">lower</code></td>
<td>
<p>The lower limit to calculate CRPS; the default value is set to be 1</p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_upper">upper</code></td>
<td>
<p>The upper limit to calculate CRPS; the default value is set to be
twice the maximum value of the response variable in the dataset</p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_sample_n">sample_n</code></td>
<td>
<p>The number of evenly spaced values to sample between lower
and upper range of numeric integration used to calculate CRPS. This sample
function is designed to constrain memory usage during the computation of
CRPS, particularly when dealing with large response variables.</p>
</td></tr>
<tr><td><code id="predict.adlp_+3A_n">n</code></td>
<td>
<p>number of simulations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predicts the central estimates based on the ADLP component models and weights.
</p>
<p>Calculates the probability density ad each point, given <code>newdata</code>.
</p>
<p>Calculates the log score, which is the log of the probability density, with
an offset <code>epsilon</code> to handle zero densities.
Log Score is a strictly proper scoring rule.
For full discussion of the mathematical details and
advantages of Log Score, one might refer to Gneiting and Raftery (2007)
</p>
<p>Continuously Ranked Probability Score (CRPS) is calculated for each data point.
<code>lower</code> and <code>upper</code> are used as limits when approximating the integral.
CRPS is a strictly proper scoring rule.
For full discussion of the mathematical details and
advantages of CRPS, one might refer to Gneiting and Raftery (2007).
The CRPS function has been discretized in this context to ensure
adaptability to various distributions.
For details, one might refer to
Gneiting and Ranjan (2011)
</p>
<p>Simulations of ADLP predictions, given component models and ADLP weights.
</p>


<h3>Value</h3>

<p><code>data.frame</code> of results, where the first and second columns correspond
to the <code style="white-space: pre;">&#8288;$origin&#8288;</code> and <code style="white-space: pre;">&#8288;$dev&#8288;</code> columns from the triangles. An index column for
<code>simulation #</code> is also included when simulating ADLP.
</p>


<h3>References</h3>

<p>Gneiting, T., Raftery, A. E., 2007. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association 102 (477), 359–378.
</p>
<p>Gneiting, T., Ranjan, R., 2011. Comparing density forecasts using threshold-and quantile-weighted scoring rules. Journal of Business &amp; Economic Statistics 29 (3), 411–422.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(test_adlp_component)
test_component1 &lt;- test_adlp_component
test_component2 &lt;- test_adlp_component
test_components &lt;- adlp_components(
    component1 = test_component1,
    component2 = test_component2
)

newdata &lt;- test_component1$model_train$data

test_adlp &lt;- adlp(test_components, newdata = newdata,
    partition_func = adlp_partition_ap, tri.size = 40, size = 3)

test_adlp_dens &lt;- adlp_dens(test_adlp, newdata, "full")

data(test_adlp_component)
test_component1 &lt;- test_adlp_component
test_component2 &lt;- test_adlp_component
test_components &lt;- adlp_components(
    component1 = test_component1,
    component2 = test_component2
)

newdata &lt;- test_component1$model_train$data

test_adlp &lt;- adlp(test_components, newdata = newdata,
    partition_func = adlp_partition_ap, tri.size = 40, size = 3)

test_adlp_logs &lt;- adlp_logS(test_adlp, newdata, "full")

data(test_adlp_component)
test_component1 &lt;- test_adlp_component
test_component2 &lt;- test_adlp_component
test_components &lt;- adlp_components(
    component1 = test_component1,
    component2 = test_component2
)

newdata &lt;- test_component1$model_train$data

test_adlp &lt;- adlp(test_components, newdata = newdata,
    partition_func = adlp_partition_ap, tri.size = 40, size = 3)

test_adlp_crps &lt;- adlp_CRPS(test_adlp, newdata, "full", response_name = "claims", sample_n = 100)

data(test_adlp_component)
test_component1 &lt;- test_adlp_component
test_component2 &lt;- test_adlp_component
test_components &lt;- adlp_components(
    component1 = test_component1,
    component2 = test_component2
)

newdata &lt;- test_component1$model_train$data

test_adlp &lt;- adlp(test_components, newdata = newdata,
    partition_func = adlp_partition_ap, tri.size = 40, size = 3)

test_adlp_sim &lt;- adlp_simulate(10, test_adlp, newdata=newdata)

</code></pre>

<hr>
<h2 id='print.adlp'>Accident and Development period Adjusted Linear Pools (ADLP) Models</h2><span id='topic+print.adlp'></span><span id='topic+adlp'></span>

<h3>Description</h3>

<p>Class to estimate an ADLP model fitted by Minorization-Maximisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'adlp'
print(x, ...)

adlp(components_lst, newdata, partition_func, param_tol = 1e-16, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.adlp_+3A_x">x</code></td>
<td>
<p>Object of class <code>adlp</code></p>
</td></tr>
<tr><td><code id="print.adlp_+3A_...">...</code></td>
<td>
<p>Other named parameters passed onto further functions</p>
</td></tr>
<tr><td><code id="print.adlp_+3A_components_lst">components_lst</code></td>
<td>
<p>List of <code>adlp_components</code></p>
</td></tr>
<tr><td><code id="print.adlp_+3A_newdata">newdata</code></td>
<td>
<p>Validation data to fit the ADLP partitions on</p>
</td></tr>
<tr><td><code id="print.adlp_+3A_partition_func">partition_func</code></td>
<td>
<p>Partition function used to subset the data. ADLP weights
will be generated for each partition. To specify partition preferences,
set the parameter to <code>adlp_partition_none</code> if no partitioning is required.
For partitioning the claims triangle by accident periods with predetermined weights,
use <code>adlp_partition_ap</code>. Alternatively, users can create a custom partition
function by defining the cut-off accident period for each subset manually.</p>
</td></tr>
<tr><td><code id="print.adlp_+3A_param_tol">param_tol</code></td>
<td>
<p>Tolerance for weights. Any value less than tolerance in
magnitude is assumed zero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="#topic+adlp_component">adlp_component</a> and <a href="#topic+adlp_components">adlp_components</a>
objects for more information on required format for inputs.
</p>
<p>See <a href="#topic+adlp_partition">adlp_partition</a> for information on valid partition
functions.
</p>
<p>For an understanding of how partitions affect the performance of the ADLP ensemble,
one might refer to Avanzi, Li, Wong and Xian (2022)
</p>


<h3>Value</h3>

<p>Object of class <code>adlp</code>. This object has the following components:
</p>

<dl>
<dt>components_lst</dt><dd><p>adlp_components; List of adlp_components, see
also <code>adlp_components</code></p>
</dd>
<dt>model_weights</dt><dd><p>vector; vector of model weights fitted for each
component</p>
</dd>
<dt>partition_func</dt><dd><p>function; Partition function used to fit the
components</p>
</dd>
<dt>optim_MM</dt><dd><p>mm_optim; Details related to the MM algorithm
see also <code>MM_optim()</code></p>
</dd>
<dt>newdata</dt><dd><p>data.frame; Data.frame used to fit the ADLP</p>
</dd>
</dl>



<h3>References</h3>

<p>Avanzi, B., Li, Y., Wong, B., &amp; Xian, A. (2022). Ensemble distributional forecasting for insurance loss reserving. arXiv preprint arXiv:2206.08541.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(test_adlp_component)
test_component1 &lt;- test_adlp_component
test_component2 &lt;- test_adlp_component
test_components &lt;- adlp_components(
    component1 = test_component1,
    component2 = test_component2
)

newdata &lt;- test_component1$model_train$data

test_adlp &lt;- adlp(test_components, newdata = newdata, response_name = "claims",
    partition_func = adlp_partition_ap, tri.size = 40, size = 3)


</code></pre>

<hr>
<h2 id='print.adlp_component'>Accident and Development period Adjusted Linear Pools Component Models</h2><span id='topic+print.adlp_component'></span><span id='topic+adlp_component'></span>

<h3>Description</h3>

<p>Class to store component models and related functions required for ADLP
estimation, prediction and goodness of fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'adlp_component'
print(x, ...)

adlp_component(
  model_train,
  model_full,
  calc_dens,
  calc_mu,
  calc_cdf,
  sim_fun,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.adlp_component_+3A_x">x</code></td>
<td>
<p>Object of class <code>adlp_component</code></p>
</td></tr>
<tr><td><code id="print.adlp_component_+3A_...">...</code></td>
<td>
<p>Other named parameters required for the model or any of its
related functions to run.</p>
</td></tr>
<tr><td><code id="print.adlp_component_+3A_model_train">model_train</code></td>
<td>
<p>Model trained on training data</p>
</td></tr>
<tr><td><code id="print.adlp_component_+3A_model_full">model_full</code></td>
<td>
<p>Model trained on all in-sample data</p>
</td></tr>
<tr><td><code id="print.adlp_component_+3A_calc_dens">calc_dens</code></td>
<td>
<p>function to calculate the pdf of each point</p>
</td></tr>
<tr><td><code id="print.adlp_component_+3A_calc_mu">calc_mu</code></td>
<td>
<p>function to calculate the estimated mean of each point</p>
</td></tr>
<tr><td><code id="print.adlp_component_+3A_calc_cdf">calc_cdf</code></td>
<td>
<p>function to calculate the cdf of each point</p>
</td></tr>
<tr><td><code id="print.adlp_component_+3A_sim_fun">sim_fun</code></td>
<td>
<p>function to simulate new from</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Component models <code>model_train</code> and <code>model_full</code> are designed to be objects of
class <code>glm</code>, <code>lm</code>, or similar. The models would desirably have a S3 method for
'formula. For models that do not fit under this umbrella,
see <a href="#topic+custom_model">custom_model</a>. For a potential list of candidate models,
one might refer to Avanzi, Li, Wong and Xian (2022).
</p>
<p>Functions as assumed to have the following parameter naming convention:
</p>

<ul>
<li><p><code>y</code> as the response variable
</p>
</li>
<li><p><code>model</code> as the modeling object <code>model_train</code> or <code>model_full</code>
</p>
</li>
<li><p><code>newdata</code> to designate new data
</p>
</li></ul>

<p>Other inputs not in this list will need to be intialised with the <code>adlp_component</code>
</p>


<h3>Value</h3>

<p>Object of class <code>adlp_component</code>
</p>


<h3>References</h3>

<p>Avanzi, B., Li, Y., Wong, B., &amp; Xian, A. (2022). Ensemble distributional forecasting for insurance loss reserving. arXiv preprint arXiv:2206.08541.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("test_claims_dataset")

train_val &lt;- train_val_split_method1(
    df = test_claims_dataset,
    tri.size = 40,
    val_ratio = 0.3,
    test = TRUE
)
train_data &lt;- train_val$train
valid_data &lt;- train_val$valid
insample_data &lt;- rbind(train_data, valid_data)

base_model1 &lt;- glm(formula = claims~factor(dev),
                   family=gaussian(link = "identity"), data=train_data)

base_model1_full &lt;- update(base_model1, data = insample_data)

dens_normal &lt;- function(y, model, newdata){
    pred_model &lt;- predict(model, newdata=newdata, type="response", se.fit=TRUE)
    mu &lt;- pred_model$fit
    sigma &lt;- pred_model$residual.scale
    return(dnorm(x=y, mean=mu, sd=sigma))
}

cdf_normal&lt;-function(y, model, newdata){
    pred_model &lt;- predict(model, newdata=newdata, type="response", se.fit=TRUE)
    mu &lt;- pred_model$fit
    sigma &lt;- pred_model$residual.scale
    return(pnorm(q=y, mean=mu, sd=sigma))
}

mu_normal&lt;-function(model, newdata){
    mu &lt;- predict(model, newdata=newdata, type="response")
    mu &lt;- pmax(mu, 0)
    return(mu)
}

sim_normal&lt;-function(model, newdata){
    pred_model &lt;- predict(model, newdata=newdata, type="response", se.fit=TRUE)
    mu &lt;- pred_model$fit
    sigma &lt;- pred_model$residual.scale

    sim &lt;- rnorm(length(mu), mean=mu, sd=sigma)
    sim &lt;- pmax(sim, 0)
    return(sim)
}

base_component1 = adlp_component(
    model_train = base_model1,
    model_full = base_model1_full,
    calc_dens = dens_normal,
    calc_cdf = cdf_normal,
    calc_mu = mu_normal,
    sim_fun = sim_normal
)

</code></pre>

<hr>
<h2 id='print.adlp_components'>Accident and Development period Adjusted Linear Pools Component Models</h2><span id='topic+print.adlp_components'></span><span id='topic+adlp_components'></span>

<h3>Description</h3>

<p>Accident and Development period Adjusted Linear Pools Component Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'adlp_components'
print(x, ...)

adlp_components(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.adlp_components_+3A_x">x</code></td>
<td>
<p>Object of class <code>adlp_components</code></p>
</td></tr>
<tr><td><code id="print.adlp_components_+3A_...">...</code></td>
<td>
<p>Individual <code>adlp_components</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Class to structure a list of <a href="#topic+adlp_components">adlp_components</a>.
</p>


<h3>Value</h3>

<p>An object of class <code>adlp_components</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(test_adlp_component)
test_component1 &lt;- test_adlp_component
test_component2 &lt;- test_adlp_component
test_components &lt;- adlp_components(
    component1 = test_component1,
    component2 = test_component2
)

</code></pre>

<hr>
<h2 id='test_adlp_component'>Test ADLP Component</h2><span id='topic+test_adlp_component'></span>

<h3>Description</h3>

<p>A <code>adlp_component</code> object created for examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_adlp_component
</code></pre>


<h3>Format</h3>

<p>A <code>adlp_component</code> format, see <a href="#topic+adlp_component">adlp_component</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_adlp_component
</code></pre>

<hr>
<h2 id='test_claims_dataset'>Claims Data in data.frame Format</h2><span id='topic+test_claims_dataset'></span>

<h3>Description</h3>

<p>A data.frame of claims, with the corresponding Accident Period (<code>origin</code>)
and Development Period (<code>dev</code>). A <code>calendar</code> column is also included (as the
sum of <code>dev</code> and <code>origin</code>. This format is required for the ADLP package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_claims_dataset
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 4 components:
</p>

<dl>
<dt>origin</dt><dd><p>Accident Period</p>
</dd>
<dt>dev</dt><dd><p>Development Period</p>
</dd>
<dt>calendar</dt><dd><p>Accident Period + Development Period</p>
</dd>
<dt>claims</dt><dd><p>Claim amount</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>test_claims_dataset$claims
</code></pre>

<hr>
<h2 id='train_val_split'>Train-Validation Split of Claims Triangle</h2><span id='topic+train_val_split'></span>

<h3>Description</h3>

<p>General framework for any user-defined training/validation/testing split of
claims triangle data. The ADLP package contains three default splitting algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_val_split(df, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_val_split_+3A_df">df</code></td>
<td>
<p>Claims Triangle and other information. <code>data.frame</code> format of
claims and related information for each cell. Dataframe will have columns
<code>origin</code> and <code>dev</code> as columns 1 and 2 respectively.</p>
</td></tr>
<tr><td><code id="train_val_split_+3A_...">...</code></td>
<td>
<p>Other parameters used to calculate train/test splitting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing <code style="white-space: pre;">&#8288;$train&#8288;</code>, <code style="white-space: pre;">&#8288;$valid&#8288;</code>, <code style="white-space: pre;">&#8288;$test&#8288;</code>, which should partition
the input <code>df</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+train_val_split_by_AP">train_val_split_by_AP</a>,
<a href="#topic+train_val_split_method1">train_val_split_method1</a>,
<a href="#topic+train_val_split_method2">train_val_split_method2</a>
</p>

<hr>
<h2 id='train_val_split_by_AP'>Train-Validation Split by Accident Period</h2><span id='topic+train_val_split_by_AP'></span>

<h3>Description</h3>

<p>Function for training/validation splitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_val_split_by_AP(df, accident_periods, max_dev_periods, test = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_val_split_by_AP_+3A_df">df</code></td>
<td>
<p>Claims Triangle and other information. <code>data.frame</code> format of
claims and related information for each cell. Dataframe will have columns
<code>origin</code> and <code>dev</code> as columns 1 and 2 respectively.</p>
</td></tr>
<tr><td><code id="train_val_split_by_AP_+3A_accident_periods">accident_periods</code></td>
<td>
<p>Vector of accident periods. Will be equivalent to
<code>1:Triangle_Size</code></p>
</td></tr>
<tr><td><code id="train_val_split_by_AP_+3A_max_dev_periods">max_dev_periods</code></td>
<td>
<p>Vector of development periods</p>
</td></tr>
<tr><td><code id="train_val_split_by_AP_+3A_test">test</code></td>
<td>
<p>Returns the test set if <code>TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assigns training set defined by a maximum development period for each
accident period: <code class="reqn">(x_{ij} &lt;= MaxDP(i))</code>.
</p>
<p>Validation set is therefore cells outside of this period but within the
upper triangle. The test set is all observations in the lower triangle.
</p>


<h3>Value</h3>

<p>List containing <code style="white-space: pre;">&#8288;$train&#8288;</code>, <code style="white-space: pre;">&#8288;$valid&#8288;</code>, <code style="white-space: pre;">&#8288;$test&#8288;</code>, which should partition
the input <code>df</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+train_val_split">train_val_split</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("test_claims_dataset")

train_val &lt;- train_val_split_by_AP(
    df = test_claims_dataset,
    accident_periods = 1:40,
    max_dev_periods = 40:1,
    test = TRUE
)

</code></pre>

<hr>
<h2 id='train_val_split_method1'>Train-Validation Split by Accident Period Method 1</h2><span id='topic+train_val_split_method1'></span>

<h3>Description</h3>

<p>Function for training/validation splitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_val_split_method1(df, tri.size, val_ratio, test = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_val_split_method1_+3A_df">df</code></td>
<td>
<p>Claims Triangle and other information. <code>data.frame</code> format of
claims and related information for each cell. Dataframe will have columns
<code>origin</code> and <code>dev</code> as columns 1 and 2 respectively.</p>
</td></tr>
<tr><td><code id="train_val_split_method1_+3A_tri.size">tri.size</code></td>
<td>
<p>Triangle size.</p>
</td></tr>
<tr><td><code id="train_val_split_method1_+3A_val_ratio">val_ratio</code></td>
<td>
<p>Value between 0 and 1 as the approximate size of validation
set.</p>
</td></tr>
<tr><td><code id="train_val_split_method1_+3A_test">test</code></td>
<td>
<p>Returns the test set if <code>TRUE</code> .</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximates the validation set by taking the <code>n</code> most recent calendar years
as validation to best fit <code>val_ratio</code>.
</p>
<p>Validation set is therefore cells outside of this period but within the
upper triangle. The test set is all observations in the lower triangle.
</p>
<p>Note that accident period 1 and development period 1 will always be within
the training set.
</p>


<h3>Value</h3>

<p>List containing <code style="white-space: pre;">&#8288;$train&#8288;</code>, <code style="white-space: pre;">&#8288;$valid&#8288;</code>, <code style="white-space: pre;">&#8288;$test&#8288;</code>, which should partition
the input <code>df</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+train_val_split">train_val_split</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("test_claims_dataset")

train_val &lt;- train_val_split_method1(
    df = test_claims_dataset,
    tri.size = 40,
    val_ratio = 0.3,
    test = TRUE
)

</code></pre>

<hr>
<h2 id='train_val_split_method2'>Train-Validation Split by Accident Period Method 2</h2><span id='topic+train_val_split_method2'></span>

<h3>Description</h3>

<p>Function for training/validation splitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_val_split_method2(df, tri.size, val_ratio, test = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_val_split_method2_+3A_df">df</code></td>
<td>
<p>Claims Triangle and other information. <code>data.frame</code> format of
claims and related information for each cell. Dataframe will have columns
<code>origin</code> and <code>dev</code> as columns 1 and 2 respectively.</p>
</td></tr>
<tr><td><code id="train_val_split_method2_+3A_tri.size">tri.size</code></td>
<td>
<p>Triangle size.</p>
</td></tr>
<tr><td><code id="train_val_split_method2_+3A_val_ratio">val_ratio</code></td>
<td>
<p>Value between 0 and 1 as the approximate size of validaiton
set.</p>
</td></tr>
<tr><td><code id="train_val_split_method2_+3A_test">test</code></td>
<td>
<p>Returns the test set if <code>TRUE</code> .</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximates the validation set by defining the training set as the cells
below the function <code class="reqn">((b^{1/a} - x^{1/a})^a)</code>. Where <code class="reqn">b</code> is equal to
the triangle size and <code class="reqn">a</code> is optimised to best fit <code>val_ratio</code>.
</p>
<p>The training set is therefore cells outside of this period but within the
upper triangle. The test set is all observations in the lower triangle.
</p>
<p>Note that accident period 1 and development period 1 will always be within
the training set.
</p>


<h3>Value</h3>

<p>List containing <code style="white-space: pre;">&#8288;$train&#8288;</code>, <code style="white-space: pre;">&#8288;$valid&#8288;</code>, <code style="white-space: pre;">&#8288;$test&#8288;</code>, which should partition
the input <code>df</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+train_val_split">train_val_split</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("test_claims_dataset")

train_val &lt;- train_val_split_method1(
    df = test_claims_dataset,
    tri.size = 40,
    val_ratio = 0.3,
    test = TRUE
)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
