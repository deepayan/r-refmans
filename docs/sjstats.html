<!DOCTYPE html><html lang="en"><head><title>Help for package sjstats</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sjstats}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#anova_stats'><p>Effect size statistics for anova</p></a></li>
<li><a href='#auto_prior'><p>Create default priors for brms-models</p></a></li>
<li><a href='#boot_ci'><p>Standard error and confidence intervals for bootstrapped estimates</p></a></li>
<li><a href='#bootstrap'><p>Generate nonparametric bootstrap replications</p></a></li>
<li><a href='#chi_squared_test'><p>Chi-Squared test</p></a></li>
<li><a href='#chisq_gof'><p>Compute model quality</p></a></li>
<li><a href='#cramers_v'><p>Measures of association for contingency tables</p></a></li>
<li><a href='#cv'><p>Compute model quality</p></a></li>
<li><a href='#cv_error'><p>Test and training error from model cross-validation</p></a></li>
<li><a href='#design_effect'><p>Design effects for two-level mixed models</p></a></li>
<li><a href='#efc'><p>Sample dataset from the EUROFAMCARE project</p></a></li>
<li><a href='#find_beta'><p>Determining distribution parameters</p></a></li>
<li><a href='#gmd'><p>Gini's Mean Difference</p></a></li>
<li><a href='#inequ_trend'><p>Compute trends in status inequalities</p></a></li>
<li><a href='#is_prime'><p>Find prime numbers</p></a></li>
<li><a href='#kruskal_wallis_test'><p>Kruskal-Wallis test</p></a></li>
<li><a href='#mann_whitney_test'><p>Mann-Whitney test</p></a></li>
<li><a href='#nhanes_sample'><p>Sample dataset from the National Health and Nutrition Examination Survey</p></a></li>
<li><a href='#prop'><p>Proportions of values in a vector</p></a></li>
<li><a href='#r2'><p>Deprecated functions</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#samplesize_mixed'><p>Sample size for linear mixed models</p></a></li>
<li><a href='#se_ybar'><p>Standard error of sample mean for mixed models</p></a></li>
<li><a href='#survey_median'><p>Weighted statistics for variables</p></a></li>
<li><a href='#svyglm.nb'><p>Survey-weighted negative binomial generalised linear model</p></a></li>
<li><a href='#svyglm.zip'><p>Survey-weighted zero-inflated Poisson model</p></a></li>
<li><a href='#t_test'><p>Student's t test</p></a></li>
<li><a href='#table_values'><p>Expected and relative table values</p></a></li>
<li><a href='#var_pop'><p>Calculate population variance and standard deviation</p></a></li>
<li><a href='#weight'><p>Weight a variable</p></a></li>
<li><a href='#wilcoxon_test'><p>Wilcoxon rank sum test</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Collection of Convenient Functions for Common Statistical
Computations</td>
</tr>
<tr>
<td>Version:</td>
<td>0.19.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel Lüdecke &lt;d.luedecke@uke.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Collection of convenient functions for common statistical computations,
             which are not directly provided by R's base or stats packages.
             This package aims at providing, first, shortcuts for statistical measures, 
             which otherwise could only be calculated with additional effort 
             (like Cramer's V, Phi, or effect size statistics like Eta or Omega squared), 
             or for which currently no functions available. Second, another focus 
             lies on weighted variants of common statistical measures and tests 
             like weighted standard error, mean, t-test, correlation, and more.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4), utils</td>
</tr>
<tr>
<td>Imports:</td>
<td>datawizard, effectsize (&ge; 0.8.8), insight, parameters,
performance, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>brms, car, coin, ggplot2, lme4, MASS, pscl, pwr, survey,
testthat</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://strengejacke.github.io/sjstats/">https://strengejacke.github.io/sjstats/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/strengejacke/sjstats/issues">https://github.com/strengejacke/sjstats/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-14 08:43:22 UTC; Daniel</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel Lüdecke <a href="https://orcid.org/0000-0002-8895-3206"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-14 09:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='anova_stats'>Effect size statistics for anova</h2><span id='topic+anova_stats'></span>

<h3>Description</h3>

<p>Returns the (partial) eta-squared, (partial) omega-squared,
epsilon-squared statistic or Cohen's F for all terms in an anovas.
<code>anova_stats()</code> returns a tidy summary, including all these statistics
and power for each term.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anova_stats(model, digits = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anova_stats_+3A_model">model</code></td>
<td>
<p>A fitted anova-model of class <code>aov</code> or <code>anova</code>. Other
models are coerced to <code><a href="stats.html#topic+anova">anova</a></code>.</p>
</td></tr>
<tr><td><code id="anova_stats_+3A_digits">digits</code></td>
<td>
<p>Amount of digits for returned values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with all statistics is returned (excluding confidence intervals).
</p>


<h3>References</h3>

<p>Levine TR, Hullett CR (2002): Eta Squared, Partial Eta Squared, and Misreporting of Effect Size in Communication Research.
<br /> <br />
Tippey K, Longnecker MT (2016): An Ad Hoc Method for Computing Pseudo-Effect Size for Mixed Model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load sample data
data(efc)

# fit linear model
fit &lt;- aov(
  c12hour ~ as.factor(e42dep) + as.factor(c172code) + c160age,
  data = efc
)
anova_stats(car::Anova(fit, type = 2))

</code></pre>

<hr>
<h2 id='auto_prior'>Create default priors for brms-models</h2><span id='topic+auto_prior'></span>

<h3>Description</h3>

<p>This function creates default priors for brms-regression
models, based on the same automatic prior-scale adjustment as in
<span class="pkg">rstanarm</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auto_prior(formula, data, gaussian, locations = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="auto_prior_+3A_formula">formula</code></td>
<td>
<p>A formula describing the model, which just needs to contain
the model terms, but no notation of interaction, splines etc. Usually,
you want only those predictors in the formula, for which automatic
priors should be generated. Add informative priors afterwards to the
returned <code>brmsprior</code>-object.</p>
</td></tr>
<tr><td><code id="auto_prior_+3A_data">data</code></td>
<td>
<p>The data that will be used to fit the model.</p>
</td></tr>
<tr><td><code id="auto_prior_+3A_gaussian">gaussian</code></td>
<td>
<p>Logical, if the outcome is gaussian or not.</p>
</td></tr>
<tr><td><code id="auto_prior_+3A_locations">locations</code></td>
<td>
<p>A numeric vector with location values for the priors. If
<code>locations = NULL</code>, <code>0</code> is used as location parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>auto_prior()</code> is a small, convenient function to create
some default priors for brms-models with automatically adjusted prior
scales, in a similar way like <span class="pkg">rstanarm</span> does. The default scale for
the intercept is 10, for coefficients 2.5. If the outcome is gaussian,
both scales are multiplied with <code>sd(y)</code>. Then, for categorical
variables, nothing more is changed. For numeric variables, the scales
are divided by the standard deviation of the related variable.
<br /> <br />
All prior distributions are <em>normal</em> distributions. <code>auto_prior()</code>
is intended to quickly create default priors with feasible scales. If
more precise definitions of priors is necessary, this needs to be done
directly with brms-functions like <code>set_prior()</code>.
</p>


<h3>Value</h3>

<p>A <code>brmsprior</code>-object.
</p>


<h3>Note</h3>

<p>As <code>auto_prior()</code> also sets priors on the intercept, the model
formula used in <code>brms::brm()</code> must be rewritten to something like
<code>y ~ 0 + intercept ...</code>, see <code><a href="brms.html#topic+set_prior">set_prior</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(efc)
efc$c172code &lt;- as.factor(efc$c172code)
efc$c161sex &lt;- as.factor(efc$c161sex)

mf &lt;- formula(neg_c_7 ~ c161sex + c160age + c172code)
auto_prior(mf, efc, TRUE)

## compare to
# m &lt;- rstanarm::stan_glm(mf, data = efc, chains = 2, iter = 200)
# ps &lt;- prior_summary(m)
# ps$prior_intercept$adjusted_scale
# ps$prior$adjusted_scale

## usage
# ap &lt;- auto_prior(mf, efc, TRUE)
# brm(mf, data = efc, prior = ap)

# add informative priors
mf &lt;- formula(neg_c_7 ~ c161sex + c172code)

auto_prior(mf, efc, TRUE) +
  brms::prior(normal(.1554, 40), class = "b", coef = "c160age")

# example with binary response
efc$neg_c_7d &lt;- ifelse(efc$neg_c_7 &lt; median(efc$neg_c_7, na.rm = TRUE), 0, 1)
mf &lt;- formula(neg_c_7d ~ c161sex + c160age + c172code + e17age)
auto_prior(mf, efc, FALSE)

</code></pre>

<hr>
<h2 id='boot_ci'>Standard error and confidence intervals for bootstrapped estimates</h2><span id='topic+boot_ci'></span><span id='topic+boot_se'></span><span id='topic+boot_p'></span><span id='topic+boot_est'></span>

<h3>Description</h3>

<p>Compute nonparametric bootstrap estimate, standard error,
confidence intervals and p-value for a vector of bootstrap
replicate estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot_ci(data, select = NULL, method = c("dist", "quantile"), ci.lvl = 0.95)

boot_se(data, select = NULL)

boot_p(data, select = NULL)

boot_est(data, select = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot_ci_+3A_data">data</code></td>
<td>
<p>A data frame that containts the vector with bootstrapped
estimates, or directly the vector (see 'Examples').</p>
</td></tr>
<tr><td><code id="boot_ci_+3A_select">select</code></td>
<td>
<p>Optional, unquoted names of variables (as character vector)
with bootstrapped estimates. Required, if either <code>data</code> is a data frame
(and no vector), and only selected variables from <code>data</code> should be processed.</p>
</td></tr>
<tr><td><code id="boot_ci_+3A_method">method</code></td>
<td>
<p>Character vector, indicating if confidence intervals should be
based on bootstrap standard error, multiplied by the value of the quantile
function of the t-distribution (default), or on sample quantiles of the
bootstrapped values. See 'Details' in <code>boot_ci()</code>. May be abbreviated.</p>
</td></tr>
<tr><td><code id="boot_ci_+3A_ci.lvl">ci.lvl</code></td>
<td>
<p>Numeric, the level of the confidence intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods require one or more vectors of bootstrap replicate
estimates as input.
</p>

<ul>
<li> <p><code>boot_est()</code>: returns the bootstrapped estimate, simply by computing
the mean value of all bootstrap estimates.
</p>
</li>
<li> <p><code>boot_se()</code>: computes the nonparametric bootstrap standard error by
calculating the standard deviation of the input vector.
</p>
</li>
<li><p> The mean value of the input vector and its standard error is used by
<code>boot_ci()</code> to calculate the lower and upper confidence interval,
assuming a t-distribution of bootstrap estimate replicates (for
<code>method = "dist"</code>, the default, which is
<code style="white-space: pre;">&#8288;mean(x) +/- qt(.975, df = length(x) - 1) * sd(x)&#8288;</code>); for
<code>method = "quantile"</code>, 95\
confidence intervals (<code>quantile(x, probs = c(0.025, 0.975))</code>). Use
<code>ci.lvl</code> to change the level for the confidence interval.
</p>
</li>
<li><p> P-values from <code>boot_p()</code> are also based on t-statistics, assuming normal
distribution.
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame with either bootstrap estimate, standard error, the
lower and upper confidence intervals or the p-value for all bootstrapped
estimates.
</p>


<h3>References</h3>

<p>Carpenter J, Bithell J. Bootstrap confdence intervals: when, which, what? A practical guide for medical statisticians. Statist. Med. 2000; 19:1141-1164
</p>


<h3>See Also</h3>

<p>[]<code>bootstrap()</code>] to generate nonparametric bootstrap samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(efc)
bs &lt;- bootstrap(efc, 100)

# now run models for each bootstrapped sample
bs$models &lt;- lapply(
  bs$strap,
  function(.x) lm(neg_c_7 ~ e42dep + c161sex, data = .x)
)

# extract coefficient "dependency" and "gender" from each model
bs$dependency &lt;- vapply(bs$models, function(x) coef(x)[2], numeric(1))
bs$gender &lt;- vapply(bs$models, function(x) coef(x)[3], numeric(1))

# get bootstrapped confidence intervals
boot_ci(bs$dependency)

# compare with model fit
fit &lt;- lm(neg_c_7 ~ e42dep + c161sex, data = efc)
confint(fit)[2, ]

# alternative function calls.
boot_ci(bs$dependency)
boot_ci(bs, "dependency")
boot_ci(bs, c("dependency", "gender"))
boot_ci(bs, c("dependency", "gender"), method = "q")


# compare coefficients
mean(bs$dependency)
boot_est(bs$dependency)
coef(fit)[2]
</code></pre>

<hr>
<h2 id='bootstrap'>Generate nonparametric bootstrap replications</h2><span id='topic+bootstrap'></span>

<h3>Description</h3>

<p>Generates <code>n</code> bootstrap samples of <code>data</code> and
returns the bootstrapped data frames as list-variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap(data, n, size)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrap_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_n">n</code></td>
<td>
<p>Number of bootstraps to be generated.</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_size">size</code></td>
<td>
<p>Optional, size of the bootstrap samples. May either be a number
between 1 and <code>nrow(data)</code> or a value between 0 and 1 to sample
a proportion of observations from <code>data</code> (see 'Examples').</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, each bootstrap sample has the same number of observations
as <code>data</code>. To generate bootstrap samples without resampling
same observations (i.e. sampling without replacement), use
<code>size</code> to get bootstrapped data with a specific number
of observations. However, specifying the <code>size</code>-argument is much
less memory-efficient than the bootstrap with replacement. Hence,
it is recommended to ignore the <code>size</code>-argument, if it is
not really needed.
</p>


<h3>Value</h3>

<p>A data frame with one column: a list-variable
<code>strap</code>, which contains resample-objects of class <code>sj_resample</code>.
These resample-objects are lists with three elements:
</p>

<ol>
<li><p> the original data frame, <code>data</code>
</p>
</li>
<li><p> the rownmumbers <code>id</code>, i.e. rownumbers of <code>data</code>, indicating the resampled rows with replacement
</p>
</li>
<li><p> the <code>resample.id</code>, indicating the index of the resample (i.e. the position of the <code>sj_resample</code>-object in the list <code>strap</code>)
</p>
</li></ol>



<h3>Note</h3>

<p>This function applies nonparametric bootstrapping, i.e. the function
draws samples with replacement.
<br /> <br />
There is an <code>as.data.frame</code>- and a <code>print</code>-method to get or
print the resampled data frames. See 'Examples'. The <code>as.data.frame</code>-
method automatically applies whenever coercion is done because a data
frame is required as input. See 'Examples' in <code><a href="#topic+boot_ci">boot_ci</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot_ci">boot_ci</a></code> to calculate confidence intervals from
bootstrap samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(efc)
bs &lt;- bootstrap(efc, 5)

# now run models for each bootstrapped sample
lapply(bs$strap, function(x) lm(neg_c_7 ~ e42dep + c161sex, data = x))

# generate bootstrap samples with 600 observations for each sample
bs &lt;- bootstrap(efc, 5, 600)

# generate bootstrap samples with 70% observations of the original sample size
bs &lt;- bootstrap(efc, 5, .7)

# compute standard error for a simple vector from bootstraps
# use the `as.data.frame()`-method to get the resampled
# data frame
bs &lt;- bootstrap(efc, 100)
bs$c12hour &lt;- unlist(lapply(bs$strap, function(x) {
  mean(as.data.frame(x)$c12hour, na.rm = TRUE)
}))

# bootstrapped standard error
boot_se(bs, "c12hour")

# bootstrapped CI
boot_ci(bs, "c12hour")
</code></pre>

<hr>
<h2 id='chi_squared_test'>Chi-Squared test</h2><span id='topic+chi_squared_test'></span>

<h3>Description</h3>

<p>This function performs a <code class="reqn">\chi^2</code> test for contingency
tables or tests for given probabilities. The returned effects sizes are
Cramer's V for tables with more than two rows or columns, Phi (<code class="reqn">\phi</code>)
for 2x2 tables, and Fei (פ) for tests against
given probabilities (see <em>Ben-Shachar et al. 2023</em>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chi_squared_test(
  data,
  select = NULL,
  by = NULL,
  probabilities = NULL,
  weights = NULL,
  paired = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chi_squared_test_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="chi_squared_test_+3A_select">select</code></td>
<td>
<p>Name(s) of the continuous variable(s) (as character vector)
to be used as samples for the test. <code>select</code> can be one of the following:
</p>

<ul>
<li> <p><code>select</code> can be used in combination with <code>by</code>, in which case <code>select</code> is
the name of the continous variable (and <code>by</code> indicates a grouping factor).
</p>
</li>
<li> <p><code>select</code> can also be a character vector of length two or more (more than
two names only apply to <code>kruskal_wallis_test()</code>), in which case the two
continuous variables are treated as samples to be compared. <code>by</code> must be
<code>NULL</code> in this case.
</p>
</li>
<li><p> If <code>select</code> select is of length <strong>two</strong> and <code>paired = TRUE</code>, the two samples
are considered as <em>dependent</em> and a paired test is carried out.
</p>
</li>
<li><p> If <code>select</code> specifies <strong>one</strong> variable and <code>by = NULL</code>, a one-sample test
is carried out (only applicable for <code>t_test()</code> and <code>wilcoxon_test()</code>)
</p>
</li>
<li><p> For <code>chi_squared_test()</code>, if <code>select</code> specifies <strong>one</strong> variable and
both <code>by</code> and <code>probabilities</code> are <code>NULL</code>, a one-sample test against given
probabilities is automatically conducted, with equal probabilities for
each level of <code>select</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="chi_squared_test_+3A_by">by</code></td>
<td>
<p>Name of the variable indicating the groups. Required if <code>select</code>
specifies only one variable that contains all samples to be compared in the
test. If <code>by</code> is not a factor, it will be coerced to a factor. For
<code>chi_squared_test()</code>, if <code>probabilities</code> is provided, <code>by</code> must be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="chi_squared_test_+3A_probabilities">probabilities</code></td>
<td>
<p>A numeric vector of probabilities for each cell in the
contingency table. The length of the vector must match the number of cells
in the table, i.e. the number of unique levels of the variable specified
in <code>select</code>. If <code>probabilities</code> is provided, a chi-squared test for given
probabilities is conducted. Furthermore, if <code>probabilities</code> is given, <code>by</code>
must be <code>NULL</code>. The probabilities must sum to 1.</p>
</td></tr>
<tr><td><code id="chi_squared_test_+3A_weights">weights</code></td>
<td>
<p>Name of an (optional) weighting variable to be used for the test.</p>
</td></tr>
<tr><td><code id="chi_squared_test_+3A_paired">paired</code></td>
<td>
<p>Logical, if <code>TRUE</code>, a McNemar test is conducted for 2x2 tables.
Note that <code>paired</code> only works for 2x2 tables.</p>
</td></tr>
<tr><td><code id="chi_squared_test_+3A_...">...</code></td>
<td>
<p>Additional arguments passed down to <code><a href="stats.html#topic+chisq.test">chisq.test()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is a wrapper around <code><a href="stats.html#topic+chisq.test">chisq.test()</a></code> and
<code><a href="stats.html#topic+fisher.test">fisher.test()</a></code> (for small expected values) for contingency tables, and
<code>chisq.test()</code> for given probabilities. When <code>probabilities</code> are provided,
these are rescaled to sum to 1 (i.e. <code>rescale.p = TRUE</code>). When <code>fisher.test()</code>
is called, simulated p-values are returned (i.e. <code>simulate.p.value = TRUE</code>,
see <code>?fisher.test</code>). If <code>paired = TRUE</code> and a 2x2 table is provided,
a McNemar test (see <code><a href="stats.html#topic+mcnemar.test">mcnemar.test()</a></code>) is conducted.
</p>
<p>The weighted version of the chi-squared test is based on the a weighted
table, using <code><a href="stats.html#topic+xtabs">xtabs()</a></code> as input for <code>chisq.test()</code>.
</p>
<p>Interpretation of effect sizes are based on rules described in
<code><a href="effectsize.html#topic+interpret_r">effectsize::interpret_phi()</a></code>, <code><a href="effectsize.html#topic+interpret_r">effectsize::interpret_cramers_v()</a></code>,
and <code><a href="effectsize.html#topic+interpret_r">effectsize::interpret_fei()</a></code>. Use these function directly to get other
interpretations, by providing the returned effect size as argument, e.g.
<code>interpret_phi(0.35, rules = "gignac2016")</code>.
</p>


<h3>Value</h3>

<p>A data frame with test results. The returned effects sizes are
Cramer's V for tables with more than two rows or columns, Phi (<code class="reqn">\phi</code>)
for 2x2 tables, and Fei (פ) for tests against
given probabilities.
</p>


<h3>Which test to use</h3>

<p>The following table provides an overview of which test to use for different
types of data. The choice of test depends on the scale of the outcome
variable and the number of samples to compare.</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Samples</strong> </td><td style="text-align: left;"> <strong>Scale of Outcome</strong> </td><td style="text-align: left;"> <strong>Significance Test</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>mann_whitney_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> binary (only 2x2) </td><td style="text-align: left;"> <code>chi_squared_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>kruskal_wallis_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <code>datawizard::means_by_group()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <em>not yet implemented</em> (1) </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <em>not yet implemented</em> (2) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>(1) More than two dependent samples are considered as <em>repeated measurements</em>.
For ordinal or not-normally distributed outcomes, these samples are
usually tested using a <code><a href="stats.html#topic+friedman.test">friedman.test()</a></code>, which requires the samples
in one variable, the groups to compare in another variable, and a third
variable indicating the repeated measurements (subject IDs).
</p>
<p>(2) More than two dependent samples are considered as <em>repeated measurements</em>.
For normally distributed outcomes, these samples are usually tested using
a ANOVA for repeated measurements. A more sophisticated approach would
be using a linear mixed model.
</p>


<h3>References</h3>


<ul>
<li><p> Ben-Shachar, M.S., Patil, I., Thériault, R., Wiernik, B.M.,
Lüdecke, D. (2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data
That Use the Chi‑Squared Statistic. Mathematics, 11, 1982.
<a href="https://doi.org/10.3390/math11091982">doi:10.3390/math11091982</a>
</p>
</li>
<li><p> Bender, R., Lange, S., Ziegler, A. Wichtige Signifikanztests.
Dtsch Med Wochenschr 2007; 132: e24–e25
</p>
</li>
<li><p> du Prel, J.B., Röhrig, B., Hommel, G., Blettner, M. Auswahl statistischer
Testverfahren. Dtsch Arztebl Int 2010; 107(19): 343–8
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+t_test">t_test()</a></code> for parametric t-tests of dependent and independent samples.
</p>
</li>
<li> <p><code><a href="#topic+mann_whitney_test">mann_whitney_test()</a></code> for non-parametric tests of unpaired (independent)
samples.
</p>
</li>
<li> <p><code><a href="#topic+wilcoxon_test">wilcoxon_test()</a></code> for Wilcoxon rank sum tests for non-parametric tests
of paired (dependent) samples.
</p>
</li>
<li> <p><code><a href="#topic+kruskal_wallis_test">kruskal_wallis_test()</a></code> for non-parametric tests with more than two
independent samples.
</p>
</li>
<li> <p><code><a href="#topic+chi_squared_test">chi_squared_test()</a></code> for chi-squared tests (two categorical variables,
dependent and independent).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
data(efc)
efc$weight &lt;- abs(rnorm(nrow(efc), 1, 0.3))

# Chi-squared test
chi_squared_test(efc, "c161sex", by = "e16sex")

# weighted Chi-squared test
chi_squared_test(efc, "c161sex", by = "e16sex", weights = "weight")

# Chi-squared test for given probabilities
chi_squared_test(efc, "c161sex", probabilities = c(0.3, 0.7))

</code></pre>

<hr>
<h2 id='chisq_gof'>Compute model quality</h2><span id='topic+chisq_gof'></span>

<h3>Description</h3>

<p>For logistic regression models, performs a Chi-squared
goodness-of-fit-test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisq_gof(x, prob = NULL, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chisq_gof_+3A_x">x</code></td>
<td>
<p>A numeric vector or a <code>glm</code>-object.</p>
</td></tr>
<tr><td><code id="chisq_gof_+3A_prob">prob</code></td>
<td>
<p>Vector of probabilities (indicating the population probabilities)
of the same length as <code>x</code>'s amount of categories / factor levels.
Use <code>nrow(table(x))</code> to determine the amount of necessary values
for <code>prob</code>. Only used, when <code>x</code> is a vector, and not a
<code>glm</code>-object.</p>
</td></tr>
<tr><td><code id="chisq_gof_+3A_weights">weights</code></td>
<td>
<p>Vector with weights, used to weight <code>x</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For vectors, this function is a convenient function for the
<code>chisq.test()</code>, performing goodness-of-fit test. For
<code>glm</code>-objects, this function performs a goodness-of-fit test.
A well-fitting model shows <em>no</em> significant difference between the
model and the observed data, i.e. the reported p-values should be
greater than 0.05.
</p>


<h3>Value</h3>

<p>For vectors, returns the object of the computed <code><a href="stats.html#topic+chisq.test">chisq.test</a></code>.
For <code>glm</code>-objects, an object of class <code>chisq_gof</code> with
following values: <code>p.value</code>, the p-value for the goodness-of-fit test;
<code>z.score</code>, the standardized z-score for the goodness-of-fit test;
<code>rss</code>, the residual sums of squares term and <code>chisq</code>, the pearson
chi-squared statistic.
</p>


<h3>References</h3>

<p>Hosmer, D. W., &amp; Lemeshow, S. (2000). Applied Logistic Regression. Hoboken, NJ, USA: John Wiley &amp; Sons, Inc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(efc)
efc$neg_c_7d &lt;- ifelse(efc$neg_c_7 &lt; median(efc$neg_c_7, na.rm = TRUE), 0, 1)
m &lt;- glm(
  neg_c_7d ~ c161sex + barthtot + c172code,
  data = efc,
  family = binomial(link = "logit")
)

# goodness-of-fit test for logistic regression
chisq_gof(m)

# goodness-of-fit test for vectors against probabilities
# differing from population
chisq_gof(efc$e42dep, c(0.3,0.2,0.22,0.28))

# equal to population
chisq_gof(efc$e42dep, prop.table(table(efc$e42dep)))

</code></pre>

<hr>
<h2 id='cramers_v'>Measures of association for contingency tables</h2><span id='topic+cramers_v'></span><span id='topic+cramer'></span><span id='topic+cramers_v.formula'></span><span id='topic+phi'></span><span id='topic+crosstable_statistics'></span><span id='topic+xtab_statistics'></span>

<h3>Description</h3>

<p>This function calculates various measure of association for
contingency tables and returns the statistic and p-value.
Supported measures are Cramer's V, Phi, Spearman's rho,
Kendall's tau and Pearson's r.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cramers_v(tab, ...)

cramer(tab, ...)

## S3 method for class 'formula'
cramers_v(
  formula,
  data,
  ci.lvl = NULL,
  n = 1000,
  method = c("dist", "quantile"),
  ...
)

phi(tab, ...)

crosstable_statistics(
  data,
  x1 = NULL,
  x2 = NULL,
  statistics = c("auto", "cramer", "phi", "spearman", "kendall", "pearson", "fisher"),
  weights = NULL,
  ...
)

xtab_statistics(
  data,
  x1 = NULL,
  x2 = NULL,
  statistics = c("auto", "cramer", "phi", "spearman", "kendall", "pearson", "fisher"),
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cramers_v_+3A_tab">tab</code></td>
<td>
<p>A <code><a href="base.html#topic+table">table()</a></code> or <code><a href="stats.html#topic+ftable">ftable()</a></code>. Tables of class <code><a href="stats.html#topic+xtabs">xtabs()</a></code> and
other will be coerced to <code>ftable</code> objects.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_...">...</code></td>
<td>
<p>Other arguments, passed down to the statistic functions
<code><a href="stats.html#topic+chisq.test">chisq.test()</a></code>, <code><a href="stats.html#topic+fisher.test">fisher.test()</a></code> or <code><a href="stats.html#topic+cor.test">cor.test()</a></code>.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_formula">formula</code></td>
<td>
<p>A formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> is a
numeric variable giving the data values and <code>rhs</code> a factor giving the
corresponding groups.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_data">data</code></td>
<td>
<p>A data frame or a table object. If a table object, <code>x1</code> and
<code>x2</code> will be ignored. For Kendall's <em>tau</em>, Spearman's <em>rho</em> or Pearson's
product moment correlation coefficient, <code>data</code> needs to be a data frame.
If <code>x1</code> and <code>x2</code> are not specified, the first two columns of the data
frames are used as variables to compute the crosstab.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_ci.lvl">ci.lvl</code></td>
<td>
<p>Scalar between 0 and 1. If not <code>NULL</code>, returns a data
frame including lower and upper confidence intervals.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_n">n</code></td>
<td>
<p>Number of bootstraps to be generated.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_method">method</code></td>
<td>
<p>Character vector, indicating if confidence intervals should be
based on bootstrap standard error, multiplied by the value of the quantile
function of the t-distribution (default), or on sample quantiles of the
bootstrapped values. See 'Details' in <code>boot_ci()</code>. May be abbreviated.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_x1">x1</code></td>
<td>
<p>Name of first variable that should be used to compute the
contingency table. If <code>data</code> is a table object, this argument will be
irgnored.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_x2">x2</code></td>
<td>
<p>Name of second variable that should be used to compute the
contingency table. If <code>data</code> is a table object, this argument will be
irgnored.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_statistics">statistics</code></td>
<td>
<p>Name of measure of association that should be computed. May
be one of <code>"auto"</code>, <code>"cramer"</code>, <code>"phi"</code>, <code>"spearman"</code>, <code>"kendall"</code>,
<code>"pearson"</code> or <code>"fisher"</code>. See 'Details'.</p>
</td></tr>
<tr><td><code id="cramers_v_+3A_weights">weights</code></td>
<td>
<p>Name of variable in <code>x</code> that indicated the vector of weights
that will be applied to weight all observations. Default is <code>NULL</code>, so no
weights are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The p-value for Cramer's V and the Phi coefficient are based
on <code>chisq.test()</code>. If any expected value of a table cell is smaller than 5,
or smaller than 10 and the df is 1, then <code>fisher.test()</code> is used to compute
the p-value, unless <code>statistics = "fisher"</code>; in this case, the use of
<code>fisher.test()</code> is forced to compute the p-value. The test statistic is
calculated with <code>cramers_v()</code> resp. <code>phi()</code>.
</p>
<p>Both test statistic and p-value for Spearman's rho, Kendall's tau and
Pearson's r are calculated with <code>cor.test()</code>.
</p>
<p>When <code>statistics = "auto"</code>, only Cramer's V or Phi are calculated, based on
the dimension of the table (i.e. if the table has more than two rows or
columns, Cramer's V is calculated, else Phi).
</p>


<h3>Value</h3>

<p>For <code><a href="#topic+phi">phi()</a></code>, the table's Phi value. For [<code style="white-space: pre;">&#8288;cramers_v()]&#8288;</code>, the
table's Cramer's V.
</p>
<p>For <code>crosstable_statistics()</code>, a list with following components:
</p>

<ul>
<li> <p><code>estimate</code>: the value of the estimated measure of association.
</p>
</li>
<li> <p><code>p.value</code>: the p-value for the test.
</p>
</li>
<li> <p><code>statistic</code>: the value of the test statistic.
</p>
</li>
<li> <p><code>stat.name</code>: the name of the test statistic.
</p>
</li>
<li> <p><code>stat.html</code>: if applicable, the name of the test statistic, in HTML-format.
</p>
</li>
<li> <p><code>df</code>: the degrees of freedom for the contingency table.
</p>
</li>
<li> <p><code>method</code>: character string indicating the name of the measure of association.
</p>
</li>
<li> <p><code>method.html</code>: if applicable, the name of the measure of association, in HTML-format.
</p>
</li>
<li> <p><code>method.short</code>: the short form of association measure, equals the <code>statistics</code>-argument.
</p>
</li>
<li> <p><code>fisher</code>: logical, if Fisher's exact test was used to calculate the p-value.
</p>
</li></ul>



<h3>References</h3>

<p>Ben-Shachar, M.S., Patil, I., Thériault, R., Wiernik, B.M.,
Lüdecke, D. (2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data
That Use the Chi‑Squared Statistic. Mathematics, 11, 1982.
<a href="https://doi.org/10.3390/math11091982">doi:10.3390/math11091982</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Phi coefficient for 2x2 tables
tab &lt;- table(sample(1:2, 30, TRUE), sample(1:2, 30, TRUE))
phi(tab)

# Cramer's V for nominal variables with more than 2 categories
tab &lt;- table(sample(1:2, 30, TRUE), sample(1:3, 30, TRUE))
cramer(tab)

# formula notation
data(efc)
cramer(e16sex ~ c161sex, data = efc)

# bootstrapped confidence intervals
cramer(e16sex ~ c161sex, data = efc, ci.lvl = .95, n = 100)

# 2x2 table, compute Phi automatically
crosstable_statistics(efc, e16sex, c161sex)

# more dimensions than 2x2, compute Cramer's V automatically
crosstable_statistics(efc, c172code, c161sex)

# ordinal data, use Kendall's tau
crosstable_statistics(efc, e42dep, quol_5, statistics = "kendall")

# calcilate Spearman's rho, with continuity correction
crosstable_statistics(efc,
  e42dep,
  quol_5,
  statistics = "spearman",
  exact = FALSE,
  continuity = TRUE
)
</code></pre>

<hr>
<h2 id='cv'>Compute model quality</h2><span id='topic+cv'></span>

<h3>Description</h3>

<p>Compute the coefficient of variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv_+3A_x">x</code></td>
<td>
<p>Fitted linear model of class <code>lm</code>, <code>merMod</code> (<span class="pkg">lme4</span>)
or <code>lme</code> (<span class="pkg">nlme</span>).</p>
</td></tr>
<tr><td><code id="cv_+3A_...">...</code></td>
<td>
<p>More fitted model objects, to compute multiple coefficients of
variation at once.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The advantage of the cv is that it is unitless. This allows
coefficient of variation to be compared to each other in ways
that other measures, like standard deviations or root mean
squared residuals, cannot be.
</p>


<h3>Value</h3>

<p>Numeric, the coefficient of variation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(efc)
fit &lt;- lm(barthtot ~ c160age + c12hour, data = efc)
cv(fit)

</code></pre>

<hr>
<h2 id='cv_error'>Test and training error from model cross-validation</h2><span id='topic+cv_error'></span><span id='topic+cv_compare'></span>

<h3>Description</h3>

<p><code>cv_error()</code> computes the root mean squared error from a model fitted
to kfold cross-validated test-training-data. <code>cv_compare()</code>
does the same, for multiple formulas at once (by calling <code>cv_error()</code>
for each formula).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_error(data, formula, k = 5)

cv_compare(data, formulas, k = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv_error_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="cv_error_+3A_formula">formula</code></td>
<td>
<p>The formula to fit the linear model for the test and training data.</p>
</td></tr>
<tr><td><code id="cv_error_+3A_k">k</code></td>
<td>
<p>The number of folds for the kfold-crossvalidation.</p>
</td></tr>
<tr><td><code id="cv_error_+3A_formulas">formulas</code></td>
<td>
<p>A list of formulas, to fit linear models for the test and training data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>cv_error()</code> first generates cross-validated test-training pairs, using
<code><a href="modelr.html#topic+crossv_kfold">crossv_kfold</a></code> and then fits a linear model, which
is described in <code>formula</code>, to the training data. Then, predictions
for the test data are computed, based on the trained models.
The <em>training error</em> is the mean value of the <code><a href="#topic+rmse">rmse</a></code> for
all <em>trained</em> models; the <em>test error</em> is the rmse based on all
residuals from the test data.
</p>


<h3>Value</h3>

<p>A data frame with the root mean squared errors for the training and test data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(efc)
cv_error(efc, neg_c_7 ~ barthtot + c161sex)

cv_compare(efc, formulas = list(
  neg_c_7 ~ barthtot + c161sex,
  neg_c_7 ~ barthtot + c161sex + e42dep,
  neg_c_7 ~ barthtot + c12hour
))

</code></pre>

<hr>
<h2 id='design_effect'>Design effects for two-level mixed models</h2><span id='topic+design_effect'></span>

<h3>Description</h3>

<p>Compute the design effect (also called <em>Variance Inflation Factor</em>)
for mixed models with two-level design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>design_effect(n, icc = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="design_effect_+3A_n">n</code></td>
<td>
<p>Average number of observations per grouping cluster (i.e. level-2 unit).</p>
</td></tr>
<tr><td><code id="design_effect_+3A_icc">icc</code></td>
<td>
<p>Assumed intraclass correlation coefficient for multilevel-model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula for the design effect is simply <code>(1 + (n - 1) * icc)</code>.
</p>


<h3>Value</h3>

<p>The design effect (Variance Inflation Factor) for the two-level model.
</p>


<h3>References</h3>

<p>Bland JM. 2000. Sample size in guidelines trials. Fam Pract. (17), 17-20.
<br /> <br />
Hsieh FY, Lavori PW, Cohen HJ, Feussner JR. 2003. An Overview of Variance Inflation Factors for Sample-Size Calculation. Evaluation and the Health Professions 26: 239-257. <a href="https://doi.org/10.1177/0163278703255230">doi:10.1177/0163278703255230</a>
<br /> <br />
Snijders TAB. 2005. Power and Sample Size in Multilevel Linear Models. In: Everitt BS, Howell DC (Hrsg.). Encyclopedia of Statistics in Behavioral Science. Chichester, UK: John Wiley and Sons, Ltd. <a href="https://doi.org/10.1002/0470013192.bsa492">doi:10.1002/0470013192.bsa492</a>
<br /> <br />
Thompson DM, Fernald DH, Mold JW. 2012. Intraclass Correlation Coefficients Typical of Cluster-Randomized Studies: Estimates From the Robert Wood Johnson Prescription for Health Projects. The Annals of Family Medicine;10(3):235-40. <a href="https://doi.org/10.1370/afm.1347">doi:10.1370/afm.1347</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Design effect for two-level model with 30 observations per
# cluster group (level-2 unit) and an assumed intraclass
# correlation coefficient of 0.05.
design_effect(n = 30)

# Design effect for two-level model with 24 observation per cluster
# group and an assumed intraclass correlation coefficient of 0.2.
design_effect(n = 24, icc = 0.2)

</code></pre>

<hr>
<h2 id='efc'>Sample dataset from the EUROFAMCARE project</h2><span id='topic+efc'></span>

<h3>Description</h3>

<p>German data set from the European study on family care of older people.
</p>


<h3>References</h3>

<p>Lamura G, Döhner H, Kofahl C, editors. Family carers of older people in Europe: a six-country comparative study. Münster: LIT, 2008.
</p>

<hr>
<h2 id='find_beta'>Determining distribution parameters</h2><span id='topic+find_beta'></span><span id='topic+find_beta2'></span><span id='topic+find_cauchy'></span><span id='topic+find_normal'></span>

<h3>Description</h3>

<p><code>find_beta()</code>, <code>find_normal()</code> and <code>find_cauchy()</code> find the
shape, mean and standard deviation resp. the location and scale parameters
to describe the beta, normal or cauchy distribution, based on two
percentiles. <code>find_beta2()</code> finds the shape parameters for a Beta
distribution, based on a probability value and its standard error
or confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_beta(x1, p1, x2, p2)

find_beta2(x, se, ci, n)

find_cauchy(x1, p1, x2, p2)

find_normal(x1, p1, x2, p2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_beta_+3A_x1">x1</code></td>
<td>
<p>Value for the first percentile.</p>
</td></tr>
<tr><td><code id="find_beta_+3A_p1">p1</code></td>
<td>
<p>Probability of the first percentile.</p>
</td></tr>
<tr><td><code id="find_beta_+3A_x2">x2</code></td>
<td>
<p>Value for the second percentile.</p>
</td></tr>
<tr><td><code id="find_beta_+3A_p2">p2</code></td>
<td>
<p>Probability of the second percentile.</p>
</td></tr>
<tr><td><code id="find_beta_+3A_x">x</code></td>
<td>
<p>Numeric, a probability value between 0 and 1. Typically indicates
a prevalence rate of an outcome of interest; Or an integer value
with the number of observed events. In this case, specify <code>n</code>
to indicate the toral number of observations.</p>
</td></tr>
<tr><td><code id="find_beta_+3A_se">se</code></td>
<td>
<p>The standard error of <code>x</code>. Either <code>se</code> or <code>ci</code> must
be specified.</p>
</td></tr>
<tr><td><code id="find_beta_+3A_ci">ci</code></td>
<td>
<p>The upper limit of the confidence interval of <code>x</code>. Either
<code>se</code> or <code>ci</code> must be specified.</p>
</td></tr>
<tr><td><code id="find_beta_+3A_n">n</code></td>
<td>
<p>Numeric, number of total observations. Needs to be specified, if
<code>x</code> is an integer (number of observed events), and no
probability. See 'Examples'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions can be used to find parameter for various distributions,
to define prior probabilities for Bayesian analyses. <code>x1</code>, <code>p1</code>, <code>x2</code> and
<code>p2</code> are parameters that describe two quantiles. Given this knowledge, the
distribution parameters are returned.
</p>
<p>Use <code>find_beta2()</code>, if the known parameters are, e.g. a prevalence rate or
similar probability, and its standard deviation or confidence interval. In
this case. <code>x</code> should be a probability, for example a prevalence rate of a
certain event. <code>se</code> then needs to be the standard error for this probability.
Alternatively, <code>ci</code> can be specified, which should indicate the upper limit
of the confidence interval od the probability (prevalence rate) <code>x</code>. If the
number of events out of a total number of trials is known (e.g. 12 heads out
of 30 coin tosses), <code>x</code> can also be the number of observed events, while <code>n</code>
indicates the total amount of trials (in the above example, the function
call would be: <code>find_beta2(x = 12, n = 30)</code>).
</p>


<h3>Value</h3>

<p>A list of length two, with the two distribution parameters than can
be used to define the distribution, which (best) describes
the shape for the given input parameters.
</p>


<h3>References</h3>

<p>Cook JD. Determining distribution parameters from quantiles. 2010: Department of Biostatistics, Texas (<a href="https://www.johndcook.com/quantiles_parameters.pdf">PDF</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example from blogpost:
# https://www.johndcook.com/blog/2010/01/31/parameters-from-percentiles/
# 10% of patients respond within 30 days of treatment
# and 80% respond within 90 days of treatment
find_normal(x1 = 30, p1 = .1, x2 = 90, p2 = .8)
find_cauchy(x1 = 30, p1 = .1, x2 = 90, p2 = .8)

parms &lt;- find_normal(x1 = 30, p1 = .1, x2 = 90, p2 = .8)
curve(
  dnorm(x, mean = parms$mean, sd = parms$sd),
  from = 0, to = 200
)

parms &lt;- find_cauchy(x1 = 30, p1 = .1, x2 = 90, p2 = .8)
curve(
  dcauchy(x, location = parms$location, scale = parms$scale),
  from = 0, to = 200
)


find_beta2(x = .25, ci = .5)

shapes &lt;- find_beta2(x = .25, ci = .5)
curve(dbeta(x, shapes[[1]], shapes[[2]]))

# find Beta distribution for 3 events out of 20 observations
find_beta2(x = 3, n = 20)

shapes &lt;- find_beta2(x = 3, n = 20)
curve(dbeta(x, shapes[[1]], shapes[[2]]))

</code></pre>

<hr>
<h2 id='gmd'>Gini's Mean Difference</h2><span id='topic+gmd'></span>

<h3>Description</h3>

<p><code>gmd()</code> computes Gini's mean difference for a numeric vector
or for all numeric vectors in a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmd(x, select = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gmd_+3A_x">x</code></td>
<td>
<p>A vector or data frame.</p>
</td></tr>
<tr><td><code id="gmd_+3A_select">select</code></td>
<td>
<p>Optional, names of variables as character vector that should be
selected for further processing. Required, if <code>x</code> is a data frame (and no vector)
and only selected variables from <code>x</code> should be processed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For numeric vectors, Gini's mean difference. For non-numeric vectors
or vectors of length &lt; 2, returns <code>NA</code>.
</p>


<h3>Note</h3>

<p>Gini's mean difference is defined as the mean absolute difference between
any two distinct elements of a vector. Missing values from <code>x</code> are silently
removed.
</p>


<h3>References</h3>

<p>David HA. Gini's mean difference rediscovered. Biometrika 1968(55): 573-575
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(efc)
gmd(efc$e17age)
gmd(efc, c("e17age", "c160age", "c12hour"))

</code></pre>

<hr>
<h2 id='inequ_trend'>Compute trends in status inequalities</h2><span id='topic+inequ_trend'></span>

<h3>Description</h3>

<p>This method computes the proportional change of absolute
(rate differences) and relative (rate ratios) inequalities
of prevalence rates for two different status groups, as proposed
by Mackenbach et al. (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inequ_trend(data, prev.low, prev.hi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inequ_trend_+3A_data">data</code></td>
<td>
<p>A data frame that contains the variables with prevalence rates for both low
and high status groups (see 'Examples').</p>
</td></tr>
<tr><td><code id="inequ_trend_+3A_prev.low">prev.low</code></td>
<td>
<p>The name of the variable with the prevalence rates for
the low status groups.</p>
</td></tr>
<tr><td><code id="inequ_trend_+3A_prev.hi">prev.hi</code></td>
<td>
<p>The name of the variable with the prevalence rates for
the hi status groups.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the time trend of prevalence rates of an outcome for two status
groups (e.g. the mortality rates for people with lower and higher
socioeconomic status over 40 years), this function computes the
proportional change of absolute and relative inequalities, expressed
in changes in rate differences and rate ratios. The function implements
the algorithm proposed by <em>Mackenbach et al. 2015</em>.
</p>


<h3>Value</h3>

<p>A data frame with the prevalence rates as well as the values for the
proportional change in absolute (<code>rd</code>) and relative (<code>rr</code>)
ineqqualities.
</p>


<h3>References</h3>

<p>Mackenbach JP, Martikainen P, Menvielle G, de Gelder R. 2015. The Arithmetic of Reducing Relative and Absolute Inequalities in Health: A Theoretical Analysis Illustrated with European Mortality Data. Journal of Epidemiology and Community Health 70(7): 730-36. <a href="https://doi.org/10.1136/jech-2015-207018">doi:10.1136/jech-2015-207018</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# This example reproduces Fig. 1 of Mackenbach et al. 2015, p.5

# 40 simulated time points, with an initial rate ratio of 2 and
# a rate difference of 100 (i.e. low status group starts with a
# prevalence rate of 200, the high status group with 100)

# annual decline of prevalence is 1% for the low, and 3% for the
# high status group

n &lt;- 40
time &lt;- seq(1, n, by = 1)
lo &lt;- rep(200, times = n)
for (i in 2:n) lo[i] &lt;- lo[i - 1] * .99

hi &lt;- rep(100, times = n)
for (i in 2:n) hi[i] &lt;- hi[i - 1] * .97

prev.data &lt;- data.frame(lo, hi)

# print values
inequ_trend(prev.data, "lo", "hi")

# plot trends - here we see that the relative inequalities
# are increasing over time, while the absolute inequalities
# are first increasing as well, but later are decreasing
# (while rel. inequ. are still increasing)
plot(inequ_trend(prev.data, "lo", "hi"))

</code></pre>

<hr>
<h2 id='is_prime'>Find prime numbers</h2><span id='topic+is_prime'></span>

<h3>Description</h3>

<p>This functions checks whether a number is, or numbers in a
vector are prime numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_prime(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_prime_+3A_x">x</code></td>
<td>
<p>An integer, or a vector of integers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> for each prime number in <code>x</code>, <code>FALSE</code> otherwise.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is_prime(89)
is_prime(15)
is_prime(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))

</code></pre>

<hr>
<h2 id='kruskal_wallis_test'>Kruskal-Wallis test</h2><span id='topic+kruskal_wallis_test'></span>

<h3>Description</h3>

<p>This function performs a Kruskal-Wallis rank sum test, which is
a non-parametric method to test the null hypothesis that the population median
of all of the groups are equal. The alternative is that they differ in at
least one. Unlike the underlying base R function <code>kruskal.test()</code>, this
function allows for weighted tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kruskal_wallis_test(data, select = NULL, by = NULL, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kruskal_wallis_test_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="kruskal_wallis_test_+3A_select">select</code></td>
<td>
<p>Name(s) of the continuous variable(s) (as character vector)
to be used as samples for the test. <code>select</code> can be one of the following:
</p>

<ul>
<li> <p><code>select</code> can be used in combination with <code>by</code>, in which case <code>select</code> is
the name of the continous variable (and <code>by</code> indicates a grouping factor).
</p>
</li>
<li> <p><code>select</code> can also be a character vector of length two or more (more than
two names only apply to <code>kruskal_wallis_test()</code>), in which case the two
continuous variables are treated as samples to be compared. <code>by</code> must be
<code>NULL</code> in this case.
</p>
</li>
<li><p> If <code>select</code> select is of length <strong>two</strong> and <code>paired = TRUE</code>, the two samples
are considered as <em>dependent</em> and a paired test is carried out.
</p>
</li>
<li><p> If <code>select</code> specifies <strong>one</strong> variable and <code>by = NULL</code>, a one-sample test
is carried out (only applicable for <code>t_test()</code> and <code>wilcoxon_test()</code>)
</p>
</li>
<li><p> For <code>chi_squared_test()</code>, if <code>select</code> specifies <strong>one</strong> variable and
both <code>by</code> and <code>probabilities</code> are <code>NULL</code>, a one-sample test against given
probabilities is automatically conducted, with equal probabilities for
each level of <code>select</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="kruskal_wallis_test_+3A_by">by</code></td>
<td>
<p>Name of the variable indicating the groups. Required if <code>select</code>
specifies only one variable that contains all samples to be compared in the
test. If <code>by</code> is not a factor, it will be coerced to a factor. For
<code>chi_squared_test()</code>, if <code>probabilities</code> is provided, <code>by</code> must be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="kruskal_wallis_test_+3A_weights">weights</code></td>
<td>
<p>Name of an (optional) weighting variable to be used for the test.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function simply is a wrapper around <code><a href="stats.html#topic+kruskal.test">kruskal.test()</a></code>. The
weighted version of the Kruskal-Wallis test is based on the <strong>survey</strong> package,
using <code><a href="survey.html#topic+svyranktest">survey::svyranktest()</a></code>.
</p>


<h3>Value</h3>

<p>A data frame with test results.
</p>


<h3>Which test to use</h3>

<p>The following table provides an overview of which test to use for different
types of data. The choice of test depends on the scale of the outcome
variable and the number of samples to compare.</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Samples</strong> </td><td style="text-align: left;"> <strong>Scale of Outcome</strong> </td><td style="text-align: left;"> <strong>Significance Test</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>mann_whitney_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> binary (only 2x2) </td><td style="text-align: left;"> <code>chi_squared_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>kruskal_wallis_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <code>datawizard::means_by_group()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <em>not yet implemented</em> (1) </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <em>not yet implemented</em> (2) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>(1) More than two dependent samples are considered as <em>repeated measurements</em>.
For ordinal or not-normally distributed outcomes, these samples are
usually tested using a <code><a href="stats.html#topic+friedman.test">friedman.test()</a></code>, which requires the samples
in one variable, the groups to compare in another variable, and a third
variable indicating the repeated measurements (subject IDs).
</p>
<p>(2) More than two dependent samples are considered as <em>repeated measurements</em>.
For normally distributed outcomes, these samples are usually tested using
a ANOVA for repeated measurements. A more sophisticated approach would
be using a linear mixed model.
</p>


<h3>References</h3>


<ul>
<li><p> Bender, R., Lange, S., Ziegler, A. Wichtige Signifikanztests.
Dtsch Med Wochenschr 2007; 132: e24–e25
</p>
</li>
<li><p> du Prel, J.B., Röhrig, B., Hommel, G., Blettner, M. Auswahl statistischer
Testverfahren. Dtsch Arztebl Int 2010; 107(19): 343–8
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+t_test">t_test()</a></code> for parametric t-tests of dependent and independent samples.
</p>
</li>
<li> <p><code><a href="#topic+mann_whitney_test">mann_whitney_test()</a></code> for non-parametric tests of unpaired (independent)
samples.
</p>
</li>
<li> <p><code><a href="#topic+wilcoxon_test">wilcoxon_test()</a></code> for Wilcoxon rank sum tests for non-parametric tests
of paired (dependent) samples.
</p>
</li>
<li> <p><code><a href="#topic+kruskal_wallis_test">kruskal_wallis_test()</a></code> for non-parametric tests with more than two
independent samples.
</p>
</li>
<li> <p><code><a href="#topic+chi_squared_test">chi_squared_test()</a></code> for chi-squared tests (two categorical variables,
dependent and independent).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(efc)
# Kruskal-Wallis test for elder's age by education
kruskal_wallis_test(efc, "e17age", by = "c172code")

# when data is in wide-format, specify all relevant continuous
# variables in `select` and omit `by`
set.seed(123)
wide_data &lt;- data.frame(
  scale1 = runif(20),
  scale2 = runif(20),
  scale3 = runif(20)
)
kruskal_wallis_test(wide_data, select = c("scale1", "scale2", "scale3"))

# same as if we had data in long format, with grouping variable
long_data &lt;- data.frame(
  scales = c(wide_data$scale1, wide_data$scale2, wide_data$scale3),
  groups = rep(c("A", "B", "C"), each = 20)
)
kruskal_wallis_test(long_data, select = "scales", by = "groups")
# base R equivalent
kruskal.test(scales ~ groups, data = long_data)
</code></pre>

<hr>
<h2 id='mann_whitney_test'>Mann-Whitney test</h2><span id='topic+mann_whitney_test'></span>

<h3>Description</h3>

<p>This function performs a Mann-Whitney test (or Wilcoxon rank
sum test for <em>unpaired</em> samples). Unlike the underlying base R function
<code>wilcox.test()</code>, this function allows for weighted tests and automatically
calculates effect sizes. For <em>paired</em> (dependent) samples, or for one-sample
tests, please use the <code>wilcoxon_test()</code> function.
</p>
<p>A Mann-Whitney test is a non-parametric test for the null hypothesis that two
<em>independent</em> samples have identical continuous distributions. It can be used
for ordinal scales or when the two continuous variables are not normally
distributed. For large samples, or approximately normally distributed variables,
the <code>t_test()</code> function can be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mann_whitney_test(
  data,
  select = NULL,
  by = NULL,
  weights = NULL,
  mu = 0,
  alternative = "two.sided",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mann_whitney_test_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="mann_whitney_test_+3A_select">select</code></td>
<td>
<p>Name(s) of the continuous variable(s) (as character vector)
to be used as samples for the test. <code>select</code> can be one of the following:
</p>

<ul>
<li> <p><code>select</code> can be used in combination with <code>by</code>, in which case <code>select</code> is
the name of the continous variable (and <code>by</code> indicates a grouping factor).
</p>
</li>
<li> <p><code>select</code> can also be a character vector of length two or more (more than
two names only apply to <code>kruskal_wallis_test()</code>), in which case the two
continuous variables are treated as samples to be compared. <code>by</code> must be
<code>NULL</code> in this case.
</p>
</li>
<li><p> If <code>select</code> select is of length <strong>two</strong> and <code>paired = TRUE</code>, the two samples
are considered as <em>dependent</em> and a paired test is carried out.
</p>
</li>
<li><p> If <code>select</code> specifies <strong>one</strong> variable and <code>by = NULL</code>, a one-sample test
is carried out (only applicable for <code>t_test()</code> and <code>wilcoxon_test()</code>)
</p>
</li>
<li><p> For <code>chi_squared_test()</code>, if <code>select</code> specifies <strong>one</strong> variable and
both <code>by</code> and <code>probabilities</code> are <code>NULL</code>, a one-sample test against given
probabilities is automatically conducted, with equal probabilities for
each level of <code>select</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mann_whitney_test_+3A_by">by</code></td>
<td>
<p>Name of the variable indicating the groups. Required if <code>select</code>
specifies only one variable that contains all samples to be compared in the
test. If <code>by</code> is not a factor, it will be coerced to a factor. For
<code>chi_squared_test()</code>, if <code>probabilities</code> is provided, <code>by</code> must be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mann_whitney_test_+3A_weights">weights</code></td>
<td>
<p>Name of an (optional) weighting variable to be used for the test.</p>
</td></tr>
<tr><td><code id="mann_whitney_test_+3A_mu">mu</code></td>
<td>
<p>The hypothesized difference in means (for <code>t_test()</code>) or location
shift (for <code>wilcoxon_test()</code> and <code>mann_whitney_test()</code>). The default is 0.</p>
</td></tr>
<tr><td><code id="mann_whitney_test_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>. See <code>?t.test</code>
and <code>?wilcox.test</code>.</p>
</td></tr>
<tr><td><code id="mann_whitney_test_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>wilcox.test()</code> (for unweighted
tests, i.e. when <code>weights = NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is based on <code><a href="stats.html#topic+wilcox.test">wilcox.test()</a></code> and <code><a href="coin.html#topic+LocationTests">coin::wilcox_test()</a></code>
(the latter to extract effect sizes). The weighted version of the test is
based on <code><a href="survey.html#topic+svyranktest">survey::svyranktest()</a></code>.
</p>
<p>Interpretation of the effect size <strong>r</strong>, as a rule-of-thumb:
</p>

<ul>
<li><p> small effect &gt;= 0.1
</p>
</li>
<li><p> medium effect &gt;= 0.3
</p>
</li>
<li><p> large effect &gt;= 0.5
</p>
</li></ul>

<p><strong>r</strong> is calcuated as <code class="reqn">r = \frac{|Z|}{\sqrt{n1 + n2}}</code>.
</p>


<h3>Value</h3>

<p>A data frame with test results. The function returns p and Z-values
as well as effect size r and group-rank-means.
</p>


<h3>Which test to use</h3>

<p>The following table provides an overview of which test to use for different
types of data. The choice of test depends on the scale of the outcome
variable and the number of samples to compare.</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Samples</strong> </td><td style="text-align: left;"> <strong>Scale of Outcome</strong> </td><td style="text-align: left;"> <strong>Significance Test</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>mann_whitney_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> binary (only 2x2) </td><td style="text-align: left;"> <code>chi_squared_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>kruskal_wallis_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <code>datawizard::means_by_group()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <em>not yet implemented</em> (1) </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <em>not yet implemented</em> (2) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>(1) More than two dependent samples are considered as <em>repeated measurements</em>.
For ordinal or not-normally distributed outcomes, these samples are
usually tested using a <code><a href="stats.html#topic+friedman.test">friedman.test()</a></code>, which requires the samples
in one variable, the groups to compare in another variable, and a third
variable indicating the repeated measurements (subject IDs).
</p>
<p>(2) More than two dependent samples are considered as <em>repeated measurements</em>.
For normally distributed outcomes, these samples are usually tested using
a ANOVA for repeated measurements. A more sophisticated approach would
be using a linear mixed model.
</p>


<h3>References</h3>


<ul>
<li><p> Ben-Shachar, M.S., Patil, I., Thériault, R., Wiernik, B.M.,
Lüdecke, D. (2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data
That Use the Chi‑Squared Statistic. Mathematics, 11, 1982.
<a href="https://doi.org/10.3390/math11091982">doi:10.3390/math11091982</a>
</p>
</li>
<li><p> Bender, R., Lange, S., Ziegler, A. Wichtige Signifikanztests.
Dtsch Med Wochenschr 2007; 132: e24–e25
</p>
</li>
<li><p> du Prel, J.B., Röhrig, B., Hommel, G., Blettner, M. Auswahl statistischer
Testverfahren. Dtsch Arztebl Int 2010; 107(19): 343–8
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+t_test">t_test()</a></code> for parametric t-tests of dependent and independent samples.
</p>
</li>
<li> <p><code><a href="#topic+mann_whitney_test">mann_whitney_test()</a></code> for non-parametric tests of unpaired (independent)
samples.
</p>
</li>
<li> <p><code><a href="#topic+wilcoxon_test">wilcoxon_test()</a></code> for Wilcoxon rank sum tests for non-parametric tests
of paired (dependent) samples.
</p>
</li>
<li> <p><code><a href="#topic+kruskal_wallis_test">kruskal_wallis_test()</a></code> for non-parametric tests with more than two
independent samples.
</p>
</li>
<li> <p><code><a href="#topic+chi_squared_test">chi_squared_test()</a></code> for chi-squared tests (two categorical variables,
dependent and independent).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
data(efc)
# Mann-Whitney-U tests for elder's age by elder's sex.
mann_whitney_test(efc, "e17age", by = "e16sex")
# base R equivalent
wilcox.test(e17age ~ e16sex, data = efc)

# when data is in wide-format, specify all relevant continuous
# variables in `select` and omit `by`
set.seed(123)
wide_data &lt;- data.frame(scale1 = runif(20), scale2 = runif(20))
mann_whitney_test(wide_data, select = c("scale1", "scale2"))
# base R equivalent
wilcox.test(wide_data$scale1, wide_data$scale2)
# same as if we had data in long format, with grouping variable
long_data &lt;- data.frame(
  scales = c(wide_data$scale1, wide_data$scale2),
  groups = as.factor(rep(c("A", "B"), each = 20))
)
mann_whitney_test(long_data, select = "scales", by = "groups")
# base R equivalent
wilcox.test(scales ~ groups, long_data)

</code></pre>

<hr>
<h2 id='nhanes_sample'>Sample dataset from the National Health and Nutrition Examination Survey</h2><span id='topic+nhanes_sample'></span>

<h3>Description</h3>

<p>Selected variables from the National Health and Nutrition Examination
Survey that are used in the example from Lumley (2010), Appendix E.
See <code><a href="#topic+svyglm.nb">svyglm.nb</a></code> for examples.
</p>


<h3>References</h3>

<p>Lumley T (2010). Complex Surveys: a guide to analysis using R. Wiley
</p>

<hr>
<h2 id='prop'>Proportions of values in a vector</h2><span id='topic+prop'></span><span id='topic+props'></span>

<h3>Description</h3>

<p><code>prop()</code> calculates the proportion of a value or category
in a variable. <code>props()</code> does the same, but allows for
multiple logical conditions in one statement. It is similar
to <code>mean()</code> with logical predicates, however, both
<code>prop()</code> and <code>props()</code> work with grouped data frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prop(data, ..., weights = NULL, na.rm = TRUE, digits = 4)

props(data, ..., na.rm = TRUE, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prop_+3A_data">data</code></td>
<td>
<p>A data frame. May also be a grouped data frame (see 'Examples').</p>
</td></tr>
<tr><td><code id="prop_+3A_...">...</code></td>
<td>
<p>One or more value pairs of comparisons (logical predicates). Put
variable names the left-hand-side and values to match on the
right hand side. Expressions may be quoted or unquoted. See
'Examples'.</p>
</td></tr>
<tr><td><code id="prop_+3A_weights">weights</code></td>
<td>
<p>Vector of weights that will be applied to weight all observations.
Must be a vector of same length as the input vector. Default is
<code>NULL</code>, so no weights are used.</p>
</td></tr>
<tr><td><code id="prop_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, whether to remove NA values from the vector when the
proportion is calculated. <code>na.rm = FALSE</code> gives you the raw
percentage of a value in a vector, <code>na.rm = TRUE</code> the valid
percentage.</p>
</td></tr>
<tr><td><code id="prop_+3A_digits">digits</code></td>
<td>
<p>Amount of digits for returned values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>prop()</code> only allows one logical statement per comparison,
while <code>props()</code> allows multiple logical statements per comparison.
However, <code>prop()</code> supports weighting of variables before calculating
proportions, and comparisons may also be quoted. Hence, <code>prop()</code>
also processes comparisons, which are passed as character vector
(see 'Examples').
</p>


<h3>Value</h3>

<p>For one condition, a numeric value with the proportion of the values
inside a vector. For more than one condition, a data frame with one column
of conditions and one column with proportions. For grouped data frames,
returns a data frame with one column per group with grouping categories,
followed by one column with proportions per condition.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(efc)

# proportion of value 1 in e42dep
prop(efc, e42dep == 1)

# expression may also be completely quoted
prop(efc, "e42dep == 1")

# use "props()" for multiple logical statements
props(efc, e17age &gt; 70 &amp; e17age &lt; 80)

# proportion of value 1 in e42dep, and all values greater
# than 2 in e42dep, including missing values. will return a data frame
prop(efc, e42dep == 1, e42dep &gt; 2, na.rm = FALSE)

# for factors or character vectors, use quoted or unquoted values
library(datawizard)
# convert numeric to factor, using labels as factor levels
efc$e16sex &lt;- to_factor(efc$e16sex)
efc$n4pstu &lt;- to_factor(efc$n4pstu)

# get proportion of female older persons
prop(efc, e16sex == female)

# get proportion of male older persons
prop(efc, e16sex == "male")

# "props()" needs quotes around non-numeric factor levels
props(efc,
  e17age &gt; 70 &amp; e17age &lt; 80,
  n4pstu == 'Care Level 1' | n4pstu == 'Care Level 3'
)

# also works with pipe-chains
efc |&gt; prop(e17age &gt; 70)
efc |&gt; prop(e17age &gt; 70, e16sex == 1)

</code></pre>

<hr>
<h2 id='r2'>Deprecated functions</h2><span id='topic+r2'></span><span id='topic+cohens_f'></span><span id='topic+eta_sq'></span><span id='topic+epsilon_sq'></span><span id='topic+omega_sq'></span><span id='topic+scale_weights'></span><span id='topic+robust'></span><span id='topic+icc'></span><span id='topic+p_value'></span><span id='topic+se'></span><span id='topic+means_by_group'></span><span id='topic+mean_n'></span>

<h3>Description</h3>

<p>A list of deprecated functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r2(x)

cohens_f(x, ...)

eta_sq(x, ...)

epsilon_sq(x, ...)

omega_sq(x, ...)

scale_weights(x, ...)

robust(x, ...)

icc(x)

p_value(x, ...)

se(x, ...)

means_by_group(x, ...)

mean_n(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r2_+3A_x">x</code></td>
<td>
<p>An object.</p>
</td></tr>
<tr><td><code id="r2_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing.
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+mse'></span><span id='topic+rmse'></span><span id='topic+link_inverse'></span><span id='topic+weighted_sd'></span><span id='topic+weighted_mean'></span><span id='topic+weighted_median'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>datawizard</dt><dd><p><code><a href="datawizard.html#topic+weighted_mean">weighted_mean</a></code>, <code><a href="datawizard.html#topic+weighted_mean">weighted_median</a></code>, <code><a href="datawizard.html#topic+weighted_mean">weighted_sd</a></code></p>
</dd>
<dt>insight</dt><dd><p><code><a href="insight.html#topic+link_inverse">link_inverse</a></code></p>
</dd>
<dt>performance</dt><dd><p><code><a href="performance.html#topic+performance_mse">mse</a></code>, <code><a href="performance.html#topic+performance_rmse">rmse</a></code></p>
</dd>
</dl>

<hr>
<h2 id='samplesize_mixed'>Sample size for linear mixed models</h2><span id='topic+samplesize_mixed'></span><span id='topic+smpsize_lmm'></span>

<h3>Description</h3>

<p>Compute an approximated sample size for linear mixed models
(two-level-designs), based on power-calculation for standard
design and adjusted for design effect for 2-level-designs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>samplesize_mixed(
  eff.size,
  df.n = NULL,
  power = 0.8,
  sig.level = 0.05,
  k,
  n,
  icc = 0.05
)

smpsize_lmm(
  eff.size,
  df.n = NULL,
  power = 0.8,
  sig.level = 0.05,
  k,
  n,
  icc = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samplesize_mixed_+3A_eff.size">eff.size</code></td>
<td>
<p>Effect size.</p>
</td></tr>
<tr><td><code id="samplesize_mixed_+3A_df.n">df.n</code></td>
<td>
<p>Optional argument for the degrees of freedom for numerator. See 'Details'.</p>
</td></tr>
<tr><td><code id="samplesize_mixed_+3A_power">power</code></td>
<td>
<p>Power of test (1 minus Type II error probability).</p>
</td></tr>
<tr><td><code id="samplesize_mixed_+3A_sig.level">sig.level</code></td>
<td>
<p>Significance level (Type I error probability).</p>
</td></tr>
<tr><td><code id="samplesize_mixed_+3A_k">k</code></td>
<td>
<p>Number of cluster groups (level-2-unit) in multilevel-design.</p>
</td></tr>
<tr><td><code id="samplesize_mixed_+3A_n">n</code></td>
<td>
<p>Optional, number of observations per cluster groups
(level-2-unit) in multilevel-design.</p>
</td></tr>
<tr><td><code id="samplesize_mixed_+3A_icc">icc</code></td>
<td>
<p>Expected intraclass correlation coefficient for multilevel-model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size calculation is based on a power-calculation for the
standard design. If <code>df.n</code> is not specified, a power-calculation
for an unpaired two-sample t-test will be computed (using
<code><a href="pwr.html#topic+pwr.t.test">pwr.t.test</a></code> of the <a href="https://CRAN.R-project.org/package=pwr"><span class="pkg">pwr</span></a>-package).
If <code>df.n</code> is given, a power-calculation for general linear models
will be computed (using <code><a href="pwr.html#topic+pwr.f2.test">pwr.f2.test</a></code> of the
<span class="pkg">pwr</span>-package). The sample size of the standard design
is then adjusted for the design effect of two-level-designs (see
<code><a href="#topic+design_effect">design_effect</a></code>). Thus, the sample size calculation is appropriate
in particular for two-level-designs (see <cite>Snijders 2005</cite>). Models that
additionally include repeated measures (three-level-designs) may work
as well, however, the computed sample size may be less accurate.
</p>


<h3>Value</h3>

<p>A list with two values: The number of subjects per cluster, and the
total sample size for the linear mixed model.
</p>


<h3>References</h3>

<p>Cohen J. 1988. Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.
<br /> <br />
Hsieh FY, Lavori PW, Cohen HJ, Feussner JR. 2003. An Overview of Variance Inflation Factors for Sample-Size Calculation. Evaluation and the Health Professions 26: 239-257.
<br /> <br />
Snijders TAB. 2005. Power and Sample Size in Multilevel Linear Models. In: Everitt BS, Howell DC (Hrsg.). Encyclopedia of Statistics in Behavioral Science. Chichester, UK: John Wiley and Sons, Ltd.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Sample size for multilevel model with 30 cluster groups and a small to
# medium effect size (Cohen's d) of 0.3. 27 subjects per cluster and
# hence a total sample size of about 802 observations is needed.
samplesize_mixed(eff.size = .3, k = 30)

# Sample size for multilevel model with 20 cluster groups and a medium
# to large effect size for linear models of 0.2. Five subjects per cluster and
# hence a total sample size of about 107 observations is needed.
samplesize_mixed(eff.size = .2, df.n = 5, k = 20, power = .9)

</code></pre>

<hr>
<h2 id='se_ybar'>Standard error of sample mean for mixed models</h2><span id='topic+se_ybar'></span>

<h3>Description</h3>

<p>Compute the standard error for the sample mean for mixed models,
regarding the extent to which clustering affects the standard errors.
May be used as part of the multilevel power calculation for cluster sampling
(see <cite>Gelman and Hill 2007, 447ff</cite>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>se_ybar(fit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="se_ybar_+3A_fit">fit</code></td>
<td>
<p>Fitted mixed effects model (<code><a href="lme4.html#topic+merMod">merMod</a></code>-class).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The standard error of the sample mean of <code>fit</code>.
</p>


<h3>References</h3>

<p>Gelman A, Hill J. 2007. Data analysis using regression and multilevel/hierarchical models. Cambridge, New York: Cambridge University Press
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fit &lt;- lmer(Reaction ~ 1 + (1 | Subject), sleepstudy)
se_ybar(fit)

</code></pre>

<hr>
<h2 id='survey_median'>Weighted statistics for variables</h2><span id='topic+survey_median'></span><span id='topic+weighted_correlation'></span><span id='topic+weighted_correlation.default'></span><span id='topic+weighted_correlation.formula'></span><span id='topic+weighted_se'></span>

<h3>Description</h3>

<p><code>weighted_se()</code> computes weighted standard errors of a variable or for
all variables of a data frame. <code>survey_median()</code> computes the median for
a variable in a survey-design (see [<code style="white-space: pre;">&#8288;survey::svydesign()]&#8288;</code>).
<code>weighted_correlation()</code> computes a weighted correlation for a two-sided
alternative hypothesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survey_median(x, design)

weighted_correlation(data, ...)

## Default S3 method:
weighted_correlation(data, x, y, weights, ci.lvl = 0.95, ...)

## S3 method for class 'formula'
weighted_correlation(formula, data, ci.lvl = 0.95, ...)

weighted_se(x, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="survey_median_+3A_x">x</code></td>
<td>
<p>(Numeric) vector or a data frame. For <code>survey_median()</code> or <code>weighted_ttest()</code>,
the bare (unquoted) variable name, or a character vector with the variable name.</p>
</td></tr>
<tr><td><code id="survey_median_+3A_design">design</code></td>
<td>
<p>An object of class <code><a href="survey.html#topic+svydesign">svydesign</a></code>, providing
a specification of the survey design.</p>
</td></tr>
<tr><td><code id="survey_median_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="survey_median_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="survey_median_+3A_y">y</code></td>
<td>
<p>Optional, bare (unquoted) variable name, or a character vector with
the variable name.</p>
</td></tr>
<tr><td><code id="survey_median_+3A_weights">weights</code></td>
<td>
<p>Bare (unquoted) variable name, or a character vector with
the variable name of the numeric vector of weights. If <code>weights = NULL</code>,
unweighted statistic is reported.</p>
</td></tr>
<tr><td><code id="survey_median_+3A_ci.lvl">ci.lvl</code></td>
<td>
<p>Confidence level of the interval.</p>
</td></tr>
<tr><td><code id="survey_median_+3A_formula">formula</code></td>
<td>
<p>A formula of the form <code>lhs ~ rhs1 + rhs2</code> where <code>lhs</code> is a
numeric variable giving the data values and <code>rhs1</code> a factor with two
levels giving the corresponding groups and <code>rhs2</code> a variable with weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The weighted (test) statistic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(efc)
weighted_se(efc$c12hour, abs(runif(n = nrow(efc))))

# survey_median ----
# median for variables from weighted survey designs
data(nhanes_sample)

des &lt;- survey::svydesign(
  id = ~SDMVPSU,
  strat = ~SDMVSTRA,
  weights = ~WTINT2YR,
  nest = TRUE,
  data = nhanes_sample
)
survey_median(total, des)
survey_median("total", des)

</code></pre>

<hr>
<h2 id='svyglm.nb'>Survey-weighted negative binomial generalised linear model</h2><span id='topic+svyglm.nb'></span>

<h3>Description</h3>

<p><code>svyglm.nb()</code> is an extension to the <a href="https://CRAN.R-project.org/package=survey"><span class="pkg">survey</span></a>-package
to fit survey-weighted negative binomial models. It uses
<code><a href="survey.html#topic+svymle">svymle</a></code> to fit sampling-weighted
maximum likelihood estimates, based on starting values provided
by <code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>, as proposed by <em>Lumley
(2010, pp249)</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svyglm.nb(formula, design, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="svyglm.nb_+3A_formula">formula</code></td>
<td>
<p>An object of class <code>formula</code>, i.e. a symbolic description
of the model to be fitted. See 'Details' in <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
<tr><td><code id="svyglm.nb_+3A_design">design</code></td>
<td>
<p>An object of class <code><a href="survey.html#topic+svydesign">svydesign</a></code>, providing
a specification of the survey design.</p>
</td></tr>
<tr><td><code id="svyglm.nb_+3A_...">...</code></td>
<td>
<p>Other arguments passed down to <code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details on the computation method, see Lumley (2010), Appendix E
(especially 254ff.)
<br /> <br />
<span class="pkg">sjstats</span> implements following S3-methods for <code>svyglm.nb</code>-objects:
<code>family()</code>, <code>model.frame()</code>, <code>formula()</code>, <code>print()</code>,
<code>predict()</code> and <code>residuals()</code>. However, these functions have some
limitations:
</p>

<ul>
<li><p><code>family()</code> simply returns the family-object from the
underlying <code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>-model.
</p>
</li>
<li><p>The <code>predict()</code>-method just re-fits the <code>svyglm.nb</code>-model
with <code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>, overwrites the <code>$coefficients</code>
from this model-object with the coefficients from the returned
<code><a href="survey.html#topic+svymle">svymle</a></code>-object and finally calls
<code><a href="stats.html#topic+predict.glm">predict.glm</a></code> to compute the predicted values.
</p>
</li>
<li><p><code>residuals()</code> re-fits the <code>svyglm.nb</code>-model with
<code><a href="MASS.html#topic+glm.nb">glm.nb</a></code> and then computes the Pearson-residuals
from the <code>glm.nb</code>-object.
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <code><a href="survey.html#topic+svymle">svymle</a></code> and <code>svyglm.nb</code>,
with some additional information about the model.
</p>


<h3>References</h3>

<p>Lumley T (2010). Complex Surveys: a guide to analysis using R. Wiley
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ------------------------------------------
# This example reproduces the results from
# Lumley 2010, figure E.7 (Appendix E, p256)
# ------------------------------------------
if (require("survey")) {
  data(nhanes_sample)

  # create survey design
  des &lt;- svydesign(
    id = ~SDMVPSU,
    strat = ~SDMVSTRA,
    weights = ~WTINT2YR,
    nest = TRUE,
    data = nhanes_sample
  )

  # fit negative binomial regression
  fit &lt;- svyglm.nb(total ~ factor(RIAGENDR) * (log(age) + factor(RIDRETH1)), des)

  # print coefficients and standard errors
  fit
}
</code></pre>

<hr>
<h2 id='svyglm.zip'>Survey-weighted zero-inflated Poisson model</h2><span id='topic+svyglm.zip'></span>

<h3>Description</h3>

<p><code>svyglm.zip()</code> is an extension to the <a href="https://CRAN.R-project.org/package=survey"><span class="pkg">survey</span></a>-package
to fit survey-weighted zero-inflated Poisson models. It uses
<code><a href="survey.html#topic+svymle">svymle</a></code> to fit sampling-weighted
maximum likelihood estimates, based on starting values provided
by <code><a href="pscl.html#topic+zeroinfl">zeroinfl</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svyglm.zip(formula, design, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="svyglm.zip_+3A_formula">formula</code></td>
<td>
<p>An object of class <code>formula</code>, i.e. a symbolic description
of the model to be fitted. See 'Details' in <code><a href="pscl.html#topic+zeroinfl">zeroinfl</a></code>.</p>
</td></tr>
<tr><td><code id="svyglm.zip_+3A_design">design</code></td>
<td>
<p>An object of class <code><a href="survey.html#topic+svydesign">svydesign</a></code>, providing
a specification of the survey design.</p>
</td></tr>
<tr><td><code id="svyglm.zip_+3A_...">...</code></td>
<td>
<p>Other arguments passed down to <code><a href="pscl.html#topic+zeroinfl">zeroinfl</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Code modified from https://notstatschat.rbind.io/2015/05/26/zero-inflated-poisson-from-complex-samples/.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="survey.html#topic+svymle">svymle</a></code> and <code>svyglm.zip</code>,
with some additional information about the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("survey")) {
  data(nhanes_sample)
  set.seed(123)
  nhanes_sample$malepartners &lt;- rpois(nrow(nhanes_sample), 2)
  nhanes_sample$malepartners[sample(1:2992, 400)] &lt;- 0

  # create survey design
  des &lt;- svydesign(
    id = ~SDMVPSU,
    strat = ~SDMVSTRA,
    weights = ~WTINT2YR,
    nest = TRUE,
    data = nhanes_sample
  )

  # fit negative binomial regression
  fit &lt;- svyglm.zip(
    malepartners ~ age + factor(RIDRETH1) | age + factor(RIDRETH1),
    des
  )

  # print coefficients and standard errors
  fit
}
</code></pre>

<hr>
<h2 id='t_test'>Student's t test</h2><span id='topic+t_test'></span>

<h3>Description</h3>

<p>This function performs a Student's t test for two independent
samples, for paired samples, or for one sample. It's a parametric test for
the null hypothesis that the means of two independent samples are equal, or
that the mean of one sample is equal to a specified value. The hypothesis
can be one- or two-sided.
</p>
<p>Unlike the underlying base R function <code>t.test()</code>, this function allows for
weighted tests and automatically calculates effect sizes. Cohen's <em>d</em> is
returned for larger samples (n &gt; 20), while Hedges' <em>g</em> is returned for
smaller samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_test(
  data,
  select = NULL,
  by = NULL,
  weights = NULL,
  paired = FALSE,
  mu = 0,
  alternative = "two.sided"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="t_test_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="t_test_+3A_select">select</code></td>
<td>
<p>Name(s) of the continuous variable(s) (as character vector)
to be used as samples for the test. <code>select</code> can be one of the following:
</p>

<ul>
<li> <p><code>select</code> can be used in combination with <code>by</code>, in which case <code>select</code> is
the name of the continous variable (and <code>by</code> indicates a grouping factor).
</p>
</li>
<li> <p><code>select</code> can also be a character vector of length two or more (more than
two names only apply to <code>kruskal_wallis_test()</code>), in which case the two
continuous variables are treated as samples to be compared. <code>by</code> must be
<code>NULL</code> in this case.
</p>
</li>
<li><p> If <code>select</code> select is of length <strong>two</strong> and <code>paired = TRUE</code>, the two samples
are considered as <em>dependent</em> and a paired test is carried out.
</p>
</li>
<li><p> If <code>select</code> specifies <strong>one</strong> variable and <code>by = NULL</code>, a one-sample test
is carried out (only applicable for <code>t_test()</code> and <code>wilcoxon_test()</code>)
</p>
</li>
<li><p> For <code>chi_squared_test()</code>, if <code>select</code> specifies <strong>one</strong> variable and
both <code>by</code> and <code>probabilities</code> are <code>NULL</code>, a one-sample test against given
probabilities is automatically conducted, with equal probabilities for
each level of <code>select</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="t_test_+3A_by">by</code></td>
<td>
<p>Name of the variable indicating the groups. Required if <code>select</code>
specifies only one variable that contains all samples to be compared in the
test. If <code>by</code> is not a factor, it will be coerced to a factor. For
<code>chi_squared_test()</code>, if <code>probabilities</code> is provided, <code>by</code> must be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="t_test_+3A_weights">weights</code></td>
<td>
<p>Name of an (optional) weighting variable to be used for the test.</p>
</td></tr>
<tr><td><code id="t_test_+3A_paired">paired</code></td>
<td>
<p>Logical, whether to compute a paired t-test for dependent
samples.</p>
</td></tr>
<tr><td><code id="t_test_+3A_mu">mu</code></td>
<td>
<p>The hypothesized difference in means (for <code>t_test()</code>) or location
shift (for <code>wilcoxon_test()</code> and <code>mann_whitney_test()</code>). The default is 0.</p>
</td></tr>
<tr><td><code id="t_test_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>. See <code>?t.test</code>
and <code>?wilcox.test</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Interpretation of effect sizes are based on rules described in
<code><a href="effectsize.html#topic+interpret_cohens_d">effectsize::interpret_cohens_d()</a></code> and <code><a href="effectsize.html#topic+interpret_cohens_d">effectsize::interpret_hedges_g()</a></code>.
Use these function directly to get other interpretations, by providing the
returned effect size (<em>Cohen's d</em> or <em>Hedges's g</em> in this case) as argument,
e.g. <code>interpret_cohens_d(0.35, rules = "sawilowsky2009")</code>.
</p>


<h3>Value</h3>

<p>A data frame with test results. Effectsize Cohen's <em>d</em> is returned
for larger samples (n &gt; 20), while Hedges' <em>g</em> is returned for smaller samples.
</p>


<h3>Which test to use</h3>

<p>The following table provides an overview of which test to use for different
types of data. The choice of test depends on the scale of the outcome
variable and the number of samples to compare.</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Samples</strong> </td><td style="text-align: left;"> <strong>Scale of Outcome</strong> </td><td style="text-align: left;"> <strong>Significance Test</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>mann_whitney_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> binary (only 2x2) </td><td style="text-align: left;"> <code>chi_squared_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>kruskal_wallis_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <code>datawizard::means_by_group()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <em>not yet implemented</em> (1) </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <em>not yet implemented</em> (2) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>(1) More than two dependent samples are considered as <em>repeated measurements</em>.
For ordinal or not-normally distributed outcomes, these samples are
usually tested using a <code><a href="stats.html#topic+friedman.test">friedman.test()</a></code>, which requires the samples
in one variable, the groups to compare in another variable, and a third
variable indicating the repeated measurements (subject IDs).
</p>
<p>(2) More than two dependent samples are considered as <em>repeated measurements</em>.
For normally distributed outcomes, these samples are usually tested using
a ANOVA for repeated measurements. A more sophisticated approach would
be using a linear mixed model.
</p>


<h3>References</h3>


<ul>
<li><p> Bender, R., Lange, S., Ziegler, A. Wichtige Signifikanztests.
Dtsch Med Wochenschr 2007; 132: e24–e25
</p>
</li>
<li><p> du Prel, J.B., Röhrig, B., Hommel, G., Blettner, M. Auswahl statistischer
Testverfahren. Dtsch Arztebl Int 2010; 107(19): 343–8
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+t_test">t_test()</a></code> for parametric t-tests of dependent and independent samples.
</p>
</li>
<li> <p><code><a href="#topic+mann_whitney_test">mann_whitney_test()</a></code> for non-parametric tests of unpaired (independent)
samples.
</p>
</li>
<li> <p><code><a href="#topic+wilcoxon_test">wilcoxon_test()</a></code> for Wilcoxon rank sum tests for non-parametric tests
of paired (dependent) samples.
</p>
</li>
<li> <p><code><a href="#topic+kruskal_wallis_test">kruskal_wallis_test()</a></code> for non-parametric tests with more than two
independent samples.
</p>
</li>
<li> <p><code><a href="#topic+chi_squared_test">chi_squared_test()</a></code> for chi-squared tests (two categorical variables,
dependent and independent).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
data(sleep)
# one-sample t-test
t_test(sleep, "extra")
# base R equivalent
t.test(extra ~ 1, data = sleep)

# two-sample t-test, by group
t_test(mtcars, "mpg", by = "am")
# base R equivalent
t.test(mpg ~ am, data = mtcars)

# paired t-test
t_test(mtcars, c("mpg", "hp"), paired = TRUE)
# base R equivalent
t.test(mtcars$mpg, mtcars$hp, data = mtcars, paired = TRUE)

</code></pre>

<hr>
<h2 id='table_values'>Expected and relative table values</h2><span id='topic+table_values'></span>

<h3>Description</h3>

<p>This function calculates a table's cell, row and column percentages as
well as expected values and returns all results as lists of tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table_values(tab, digits = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="table_values_+3A_tab">tab</code></td>
<td>
<p>Simple <code><a href="base.html#topic+table">table</a></code> or <code><a href="stats.html#topic+ftable">ftable</a></code> of which
cell, row and column percentages as well as expected values are calculated.
Tables of class <code><a href="stats.html#topic+xtabs">xtabs</a></code> and other will be coerced to
<code>ftable</code> objects.</p>
</td></tr>
<tr><td><code id="table_values_+3A_digits">digits</code></td>
<td>
<p>Amount of digits for the table percentage values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(Invisibly) returns a list with four tables:
</p>

<ol>
<li> <p><code>cell</code> a table with cell percentages of <code>tab</code>
</p>
</li>
<li> <p><code>row</code> a table with row percentages of <code>tab</code>
</p>
</li>
<li> <p><code>col</code> a table with column percentages of <code>tab</code>
</p>
</li>
<li> <p><code>expected</code> a table with expected values of <code>tab</code>
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- table(sample(1:2, 30, TRUE), sample(1:3, 30, TRUE))
# show expected values
table_values(tab)$expected
# show cell percentages
table_values(tab)$cell

</code></pre>

<hr>
<h2 id='var_pop'>Calculate population variance and standard deviation</h2><span id='topic+var_pop'></span><span id='topic+sd_pop'></span>

<h3>Description</h3>

<p>Calculate the population variance or standard deviation of a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_pop(x)

sd_pop(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="var_pop_+3A_x">x</code></td>
<td>
<p>(Numeric) vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike <code><a href="stats.html#topic+var">var</a></code>, which returns the sample variance,
<code>var_pop()</code> returns the population variance. <code>sd_pop()</code>
returns the standard deviation based on the population variance.
</p>


<h3>Value</h3>

<p>The population variance or standard deviation of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(efc)

# sampling variance
var(efc$c12hour, na.rm = TRUE)
# population variance
var_pop(efc$c12hour)

# sampling sd
sd(efc$c12hour, na.rm = TRUE)
# population sd
sd_pop(efc$c12hour)
</code></pre>

<hr>
<h2 id='weight'>Weight a variable</h2><span id='topic+weight'></span><span id='topic+weight2'></span>

<h3>Description</h3>

<p>These functions weight the variable <code>x</code> by
a specific vector of <code>weights</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weight(x, weights, digits = 0)

weight2(x, weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weight_+3A_x">x</code></td>
<td>
<p>(Unweighted) variable.</p>
</td></tr>
<tr><td><code id="weight_+3A_weights">weights</code></td>
<td>
<p>Vector with same length as <code>x</code>, which
contains weight factors. Each value of <code>x</code> has a
specific assigned weight in <code>weights</code>.</p>
</td></tr>
<tr><td><code id="weight_+3A_digits">digits</code></td>
<td>
<p>Numeric value indicating the number of decimal places to be
used for rounding the weighted values. By default, this value is
<code>0</code>, i.e. the returned values are integer values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>weight2()</code> sums up all <code>weights</code> values of the associated
categories of <code>x</code>, whereas <code>weight()</code> uses a
<code><a href="stats.html#topic+xtabs">xtabs</a></code> formula to weight cases. Thus, <code>weight()</code>
may return a vector of different length than <code>x</code>.
</p>


<h3>Value</h3>

<p>The weighted <code>x</code>.
</p>


<h3>Note</h3>

<p>The values of the returned vector are in sorted order, whereas the values'
order of the original <code>x</code> may be spread randomly. Hence, <code>x</code> can't be
used, for instance, for further cross tabulation. In case you want to have
weighted contingency tables or (grouped) box plots etc., use the <code>weightBy</code>
argument of most functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>v &lt;- sample(1:4, 20, TRUE)
table(v)
w &lt;- abs(rnorm(20))
table(weight(v, w))
table(weight2(v, w))

set.seed(1)
x &lt;- sample(letters[1:5], size = 20, replace = TRUE)
w &lt;- runif(n = 20)

table(x)
table(weight(x, w))

</code></pre>

<hr>
<h2 id='wilcoxon_test'>Wilcoxon rank sum test</h2><span id='topic+wilcoxon_test'></span>

<h3>Description</h3>

<p>This function performs Wilcoxon rank sum tests for one sample
or for two <em>paired</em> (dependent) samples. For <em>unpaired</em> (independent)
samples, please use the <code>mann_whitney_test()</code> function.
</p>
<p>A Wilcoxon rank sum test is a non-parametric test for the null hypothesis
that two samples have identical continuous distributions. The implementation
in <code>wilcoxon_test()</code> is only used for <em>paired</em>, i.e. <em>dependent</em> samples. For
independent (unpaired) samples, use <code>mann_whitney_test()</code>.
</p>
<p><code>wilcoxon_test()</code> can be used for ordinal scales or when the continuous
variables are not normally distributed. For large samples, or approximately
normally distributed variables, the <code>t_test()</code> function can be used (with
<code>paired = TRUE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wilcoxon_test(
  data,
  select = NULL,
  by = NULL,
  weights = NULL,
  mu = 0,
  alternative = "two.sided",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wilcoxon_test_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="wilcoxon_test_+3A_select">select</code></td>
<td>
<p>Name(s) of the continuous variable(s) (as character vector)
to be used as samples for the test. <code>select</code> can be one of the following:
</p>

<ul>
<li> <p><code>select</code> can be used in combination with <code>by</code>, in which case <code>select</code> is
the name of the continous variable (and <code>by</code> indicates a grouping factor).
</p>
</li>
<li> <p><code>select</code> can also be a character vector of length two or more (more than
two names only apply to <code>kruskal_wallis_test()</code>), in which case the two
continuous variables are treated as samples to be compared. <code>by</code> must be
<code>NULL</code> in this case.
</p>
</li>
<li><p> If <code>select</code> select is of length <strong>two</strong> and <code>paired = TRUE</code>, the two samples
are considered as <em>dependent</em> and a paired test is carried out.
</p>
</li>
<li><p> If <code>select</code> specifies <strong>one</strong> variable and <code>by = NULL</code>, a one-sample test
is carried out (only applicable for <code>t_test()</code> and <code>wilcoxon_test()</code>)
</p>
</li>
<li><p> For <code>chi_squared_test()</code>, if <code>select</code> specifies <strong>one</strong> variable and
both <code>by</code> and <code>probabilities</code> are <code>NULL</code>, a one-sample test against given
probabilities is automatically conducted, with equal probabilities for
each level of <code>select</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="wilcoxon_test_+3A_by">by</code></td>
<td>
<p>Name of the variable indicating the groups. Required if <code>select</code>
specifies only one variable that contains all samples to be compared in the
test. If <code>by</code> is not a factor, it will be coerced to a factor. For
<code>chi_squared_test()</code>, if <code>probabilities</code> is provided, <code>by</code> must be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="wilcoxon_test_+3A_weights">weights</code></td>
<td>
<p>Name of an (optional) weighting variable to be used for the test.</p>
</td></tr>
<tr><td><code id="wilcoxon_test_+3A_mu">mu</code></td>
<td>
<p>The hypothesized difference in means (for <code>t_test()</code>) or location
shift (for <code>wilcoxon_test()</code> and <code>mann_whitney_test()</code>). The default is 0.</p>
</td></tr>
<tr><td><code id="wilcoxon_test_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>. See <code>?t.test</code>
and <code>?wilcox.test</code>.</p>
</td></tr>
<tr><td><code id="wilcoxon_test_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>wilcox.test()</code> (for unweighted
tests, i.e. when <code>weights = NULL</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with test results. The function returns p and Z-values
as well as effect size r and group-rank-means.
</p>


<h3>Which test to use</h3>

<p>The following table provides an overview of which test to use for different
types of data. The choice of test depends on the scale of the outcome
variable and the number of samples to compare.</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Samples</strong> </td><td style="text-align: left;"> <strong>Scale of Outcome</strong> </td><td style="text-align: left;"> <strong>Significance Test</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   1 </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> binary / nominal </td><td style="text-align: left;"> <code>chi_squared_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>mann_whitney_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, independent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> binary (only 2x2) </td><td style="text-align: left;"> <code>chi_squared_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>wilcoxon_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   2, dependent </td><td style="text-align: left;"> continuous, normal </td><td style="text-align: left;"> <code>t_test(paired=TRUE)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <code>kruskal_wallis_test()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, independent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <code>datawizard::means_by_group()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous, not normal </td><td style="text-align: left;"> <em>not yet implemented</em> (1) </td>
</tr>
<tr>
 <td style="text-align: left;">
   &gt;2, dependent </td><td style="text-align: left;"> continuous,     normal </td><td style="text-align: left;"> <em>not yet implemented</em> (2) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>(1) More than two dependent samples are considered as <em>repeated measurements</em>.
For ordinal or not-normally distributed outcomes, these samples are
usually tested using a <code><a href="stats.html#topic+friedman.test">friedman.test()</a></code>, which requires the samples
in one variable, the groups to compare in another variable, and a third
variable indicating the repeated measurements (subject IDs).
</p>
<p>(2) More than two dependent samples are considered as <em>repeated measurements</em>.
For normally distributed outcomes, these samples are usually tested using
a ANOVA for repeated measurements. A more sophisticated approach would
be using a linear mixed model.
</p>


<h3>References</h3>


<ul>
<li><p> Bender, R., Lange, S., Ziegler, A. Wichtige Signifikanztests.
Dtsch Med Wochenschr 2007; 132: e24–e25
</p>
</li>
<li><p> du Prel, J.B., Röhrig, B., Hommel, G., Blettner, M. Auswahl statistischer
Testverfahren. Dtsch Arztebl Int 2010; 107(19): 343–8
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+t_test">t_test()</a></code> for parametric t-tests of dependent and independent samples.
</p>
</li>
<li> <p><code><a href="#topic+mann_whitney_test">mann_whitney_test()</a></code> for non-parametric tests of unpaired (independent)
samples.
</p>
</li>
<li> <p><code><a href="#topic+wilcoxon_test">wilcoxon_test()</a></code> for Wilcoxon rank sum tests for non-parametric tests
of paired (dependent) samples.
</p>
</li>
<li> <p><code><a href="#topic+kruskal_wallis_test">kruskal_wallis_test()</a></code> for non-parametric tests with more than two
independent samples.
</p>
</li>
<li> <p><code><a href="#topic+chi_squared_test">chi_squared_test()</a></code> for chi-squared tests (two categorical variables,
dependent and independent).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
data(mtcars)
# one-sample test
wilcoxon_test(mtcars, "mpg")
# base R equivalent, we set exact = FALSE to avoid a warning
wilcox.test(mtcars$mpg ~ 1, exact = FALSE)

# paired test
wilcoxon_test(mtcars, c("mpg", "hp"))
# base R equivalent, we set exact = FALSE to avoid a warning
wilcox.test(mtcars$mpg, mtcars$hp, paired = TRUE, exact = FALSE)

# when `by` is specified, each group must be of same length
data(iris)
d &lt;- iris[iris$Species != "setosa", ]
wilcoxon_test(d, "Sepal.Width", by = "Species")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
