<!DOCTYPE html><html lang="en"><head><title>Help for package MetaNLP</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MetaNLP}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#delete_stop_words'><p>Delete stop words</p></a></li>
<li><a href='#delete_words'><p>Delete list of words</p></a></li>
<li><a href='#MetaNLP'><p>Natural Language Processing for Meta Analysis</p></a></li>
<li><a href='#plot+2CMetaNLP+2Cmissing-method'><p>Create word cloud from MetaNLP-object</p></a></li>
<li><a href='#read_test_data'><p>Read and adapt test data</p></a></li>
<li><a href='#replace_special_characters'><p>Replace special characters in column names</p></a></li>
<li><a href='#select_features'><p>Select features via elasticnet regularization</p></a></li>
<li><a href='#summary+2CMetaNLP-method'><p>Summary of MetaNLP-objects</p></a></li>
<li><a href='#write_csv'><p>Save the document-term matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Natural Language Processing for Meta Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Given a CSV file with titles and abstracts, the package creates a
    document-term matrix that is lemmatized and stemmed and can directly be used to
    train machine learning methods for automatic title-abstract screening in the
    preparation of a meta analysis.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0), covr, wordcloud,
vdiffr</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, tm, textstem, methods, lexicon, utils</td>
</tr>
<tr>
<td>Collate:</td>
<td>MetaNLP.R util.R delete_functions.R feature_selection.R
useful_functions.R</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/imbi-heidelberg/MetaNLP/issues">https://github.com/imbi-heidelberg/MetaNLP/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/imbi-heidelberg/MetaNLP">https://github.com/imbi-heidelberg/MetaNLP</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-07 13:18:33 UTC; pilz</td>
</tr>
<tr>
<td>Author:</td>
<td>Nico Bruder <a href="https://orcid.org/0009-0004-9522-2075"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Samuel Zimmermann <a href="https://orcid.org/0009-0000-4828-9294"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Johannes Vey <a href="https://orcid.org/0000-0002-2610-9667"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Maximilian Pilz <a href="https://orcid.org/0000-0002-9685-1613"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Institute of Medical Biometry - University of Heidelberg [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Maximilian Pilz &lt;maximilian.pilz@itwm.fraunhofer.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-07 13:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='delete_stop_words'>Delete stop words</h2><span id='topic+delete_stop_words'></span><span id='topic+delete_stop_words+2CMetaNLP-method'></span>

<h3>Description</h3>

<p>Usually, stop words do not offer useful information in the classification
whether a paper should be included or excluded
from a meta-analysis. Thus, such words should not be part of the document-term
matrix. This function allows the user to automatically delete stop words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delete_stop_words(object, ...)

## S4 method for signature 'MetaNLP'
delete_stop_words(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="delete_stop_words_+3A_object">object</code></td>
<td>
<p>A MetaNLP object, whose data frame is to be modified.</p>
</td></tr>
<tr><td><code id="delete_stop_words_+3A_...">...</code></td>
<td>
<p>Language of the stop words. Defaults to &quot;english&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows to delete stop words from different languages. Supported
languages are <code>english</code>, <code>french</code>, <code>german</code>, <code>russian</code> and
<code>spanish</code>. Language names are case sensitive.
</p>


<h3>Value</h3>

<p>An object of class <code>MetaNLP</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
obj &lt;- MetaNLP(path)
obj &lt;- delete_stop_words(obj, "english")

</code></pre>

<hr>
<h2 id='delete_words'>Delete list of words</h2><span id='topic+delete_words'></span><span id='topic+delete_words+2CMetaNLP+2Ccharacter-method'></span>

<h3>Description</h3>

<p>There can be words that do not offer additional information
in the classification whether a paper should be included or excluded
from a meta-analysis. Thus, such words should not be part of the document-term
matrix. This function allows the user to remove these columns of the word
count matrix by specifying a vector of words to delete.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delete_words(object, delete_list)

## S4 method for signature 'MetaNLP,character'
delete_words(object, delete_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="delete_words_+3A_object">object</code></td>
<td>
<p>A MetaNLP object, whose data frame is to be modified</p>
</td></tr>
<tr><td><code id="delete_words_+3A_delete_list">delete_list</code></td>
<td>
<p>A character vector containing the words to be deleted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The words in <code>delete_list</code> can be given like they appear in the
text. They are lemmatized and stemmed by <code>delete_words</code> to match the
columns of the document-term matrix.
</p>


<h3>Value</h3>

<p>An object of class <code>MetaNLP</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
obj &lt;- MetaNLP(path)
del_words &lt;- c("beautiful", "considering", "found")
obj &lt;- delete_words(obj, del_words)


</code></pre>

<hr>
<h2 id='MetaNLP'>Natural Language Processing for Meta Analysis</h2><span id='topic+MetaNLP'></span><span id='topic+MetaNLP-class'></span>

<h3>Description</h3>

<p>The <span class="pkg">MetaNLP</span> package provides methods to quickly transform a
CSV-file with titles and abstracts to an R data frame that can be
used for automatic title-abstract screening using machine learning.
</p>
<p>A <code>MetaNLP</code> object is the base class of the package <span class="pkg">MetaNLP</span>.
It is initialized by passing the path to a CSV file and constructs
a data frame whose column names are the words that occur in the titles
and abstracts and whose cells contain the word frequencies for each
paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MetaNLP(
  file,
  bounds = c(2, Inf),
  word_length = c(3, Inf),
  language = "english",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MetaNLP_+3A_file">file</code></td>
<td>
<p>Either the path to the CSV file or a data frame containing the
abstracts</p>
</td></tr>
<tr><td><code id="MetaNLP_+3A_bounds">bounds</code></td>
<td>
<p>An integer vector of length 2. The first value specifies
the minimum number of appearances of a word to become a column of the word
count matrix, the second value specifies the maximum number.
Defaults to <code>c(2, Inf)</code>.</p>
</td></tr>
<tr><td><code id="MetaNLP_+3A_word_length">word_length</code></td>
<td>
<p>An integer vector of length 2. The first value specifies
the minimum number of characters of a word to become a column of the word
count matrix, the second value specifies the maximum number.
Defaults to <code>c(3, Inf)</code>.</p>
</td></tr>
<tr><td><code id="MetaNLP_+3A_language">language</code></td>
<td>
<p>The language for lemmatization and stemming. Supported
languages are <code>english</code>, <code>french</code>, <code>german</code>, <code>russian</code> and
<code>spanish</code>. For non-english languages make sure that the csv
which is processed has the correct encoding.</p>
</td></tr>
<tr><td><code id="MetaNLP_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to <code>read.csv2</code>, e.g. when
&quot;,&quot; should be used as a separator or when the encoding should be changed.
See <a href="utils.html#topic+read.table">read.table</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An object of class <code>MetaNLP</code> contains a slot data_frame where
the document-term matrix is stored as a data frame.
The CSV file must have a column <code>ID</code> to identify each paper, a column
<code>title</code> with the belonging titles of the papers and a column
<code>abstract</code> which contains the abstracts. If the CSV stores training data,
a column <code>decision</code> should exist, indicating whether an abstract
is included in the meta analysis. This column does not need to exist, because
there is no decision for test data yet. Allowed values in this column are
either &quot;yes&quot; and &quot;no&quot; or &quot;include&quot; and &quot;exclude&quot; or &quot;maybe&quot;. The value &quot;maybe&quot;
is handled as a &quot;yes&quot;/&quot;include&quot;.
</p>


<h3>Value</h3>

<p>An object of class <code>MetaNLP</code>
</p>


<h3>Note</h3>

<p>To ensure correct processing of the data when there are special characters
(e.g. &quot;é&quot; or &quot;ü&quot;), make sure that the csv-file is correctly encoded
as <code>UTF-8</code>.
The stemming algorithm makes use of the C libstemmer library generated by
Snowball. When german texts are stemmed, umlauts are replaced by their
non-umlaut equivalent, so &quot;ä&quot; becomes &quot;a&quot; etc.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Maximilian Pilz <a href="mailto:maximilian.pilz@itwm.fraunhofer.de">maximilian.pilz@itwm.fraunhofer.de</a> (<a href="https://orcid.org/0000-0002-9685-1613">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Nico Bruder <a href="mailto:brudernico@gmail.com">brudernico@gmail.com</a> (<a href="https://orcid.org/0009-0004-9522-2075">ORCID</a>)
</p>
</li>
<li><p> Samuel Zimmermann <a href="mailto:zimmermann@imbi.uni-heidelberg.de">zimmermann@imbi.uni-heidelberg.de</a> (<a href="https://orcid.org/0009-0000-4828-9294">ORCID</a>)
</p>
</li>
<li><p> Johannes Vey <a href="mailto:vey@imbi.uni-heidelberg.de">vey@imbi.uni-heidelberg.de</a> (<a href="https://orcid.org/0000-0002-2610-9667">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Institute of Medical Biometry - University of Heidelberg [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/imbi-heidelberg/MetaNLP">https://github.com/imbi-heidelberg/MetaNLP</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/imbi-heidelberg/MetaNLP/issues">https://github.com/imbi-heidelberg/MetaNLP/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
obj &lt;- MetaNLP(path)

</code></pre>

<hr>
<h2 id='plot+2CMetaNLP+2Cmissing-method'>Create word cloud from MetaNLP-object</h2><span id='topic+plot+2CMetaNLP+2Cmissing-method'></span>

<h3>Description</h3>

<p>This method creates a word cloud from a MetaNLP object. The word size
indicates the frequency of the words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'MetaNLP,missing'
plot(
  x,
  y = NULL,
  max.words = 70,
  colors = c("snow4", "darkgoldenrod1", "turquoise4", "tomato"),
  decision = c("total", "include", "exclude"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot+2B2CMetaNLP+2B2Cmissing-method_+3A_x">x</code></td>
<td>
<p>A MetaNLP object to plot</p>
</td></tr>
<tr><td><code id="plot+2B2CMetaNLP+2B2Cmissing-method_+3A_y">y</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="plot+2B2CMetaNLP+2B2Cmissing-method_+3A_max.words">max.words</code></td>
<td>
<p>Maximum number of words in the word cloud</p>
</td></tr>
<tr><td><code id="plot+2B2CMetaNLP+2B2Cmissing-method_+3A_colors">colors</code></td>
<td>
<p>Character vector with the colors in</p>
</td></tr>
<tr><td><code id="plot+2B2CMetaNLP+2B2Cmissing-method_+3A_decision">decision</code></td>
<td>
<p>Stratify word cloud by decision. Default is no stratification.</p>
</td></tr>
<tr><td><code id="plot+2B2CMetaNLP+2B2Cmissing-method_+3A_...">...</code></td>
<td>
<p>Additional parameters for <a href="wordcloud.html#topic+wordcloud">wordcloud</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
obj &lt;- MetaNLP(path)
plt &lt;- plot(obj)

</code></pre>

<hr>
<h2 id='read_test_data'>Read and adapt test data</h2><span id='topic+read_test_data'></span><span id='topic+read_test_data+2CMetaNLP-method'></span>

<h3>Description</h3>

<p>This function takes a MetaNLP object (the training data) and the
test data. The function creates the document-term matrix from the test data
and matches the columns of the given training MetaNLP object with the columns
of the test document-term matrix. This means that columns, which do appear
in the test document-term matrix but not in the training document-term matrix are
removed; columns that appear in the training document-term matrix but not in the
test document-term matrix are added as a column consisting of zeros.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_test_data(object, ...)

## S4 method for signature 'MetaNLP'
read_test_data(object, file, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_test_data_+3A_object">object</code></td>
<td>
<p>The MetaNLP object created from the training data.</p>
</td></tr>
<tr><td><code id="read_test_data_+3A_...">...</code></td>
<td>
<p>Further arguments to <code>MetaNLP</code>.</p>
</td></tr>
<tr><td><code id="read_test_data_+3A_file">file</code></td>
<td>
<p>Either the path to the test data csv, the data frame containing
the papers or a MetaNLP object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class MetaNLP
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path_train &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
path_test &lt;- system.file("extdata", "test_data_changed.csv", package = "MetaNLP", mustWork = TRUE)
obj_train &lt;- MetaNLP(path_train)
obj_test &lt;- MetaNLP(path_test)
to_test_obj &lt;- read_test_data(obj_train, obj_test)

</code></pre>

<hr>
<h2 id='replace_special_characters'>Replace special characters in column names</h2><span id='topic+replace_special_characters'></span><span id='topic+replace_special_characters+2CMetaNLP-method'></span>

<h3>Description</h3>

<p>When using non-english languages, the column names of the document-term matrix
can contain special characters. These might lead to encoding problems, when
this matrix is used to train a machine learning model. This functions
automatically replaces all special characters by the nearest equivalent
character, e.g. &quot;é&quot; would be replaced by &quot;e&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_special_characters(object)

## S4 method for signature 'MetaNLP'
replace_special_characters(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="replace_special_characters_+3A_object">object</code></td>
<td>
<p>An object of class MetaNLP.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class MetaNLP, where the column names do not have
special characters anymore.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
obj &lt;- MetaNLP(path, language = "french")
obj &lt;- replace_special_characters(obj)

</code></pre>

<hr>
<h2 id='select_features'>Select features via elasticnet regularization</h2><span id='topic+select_features'></span><span id='topic+select_features+2CMetaNLP-method'></span>

<h3>Description</h3>

<p>As the document-term matrix quickly grows with an increasing number of abstracts,
it can easily reach several thousand columns. Thus, it can be important to
extract the columns that carry most of the information in the decision making
process. This function uses a generalized linear model combined with
elasticnet regularization to extract these features. In contrast to a usual
regression model or a L2 penalty (ridge regression), elasticnet (and LASSO)
sets some regression parameters to 0. Thus, the selected features are exactly
the features with a non-zero entry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_features(object, ...)

## S4 method for signature 'MetaNLP'
select_features(object, alpha = 0.8, lambda = "avg", seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_features_+3A_object">object</code></td>
<td>
<p>An object of class <code>MetaNLP</code></p>
</td></tr>
<tr><td><code id="select_features_+3A_...">...</code></td>
<td>
<p>Additional arguments for <a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a>. An important
option might be <code>type.measure</code> to specify which loss is used when
the cross validation is executed.</p>
</td></tr>
<tr><td><code id="select_features_+3A_alpha">alpha</code></td>
<td>
<p>The elastic net mixing parameter, with <code class="reqn">0\leq \alpha \leq 1</code>.
<code>alpha = 1</code> then equals the lasso penalty, <code>alpha = 0</code> is the ridge
penalty.</p>
</td></tr>
<tr><td><code id="select_features_+3A_lambda">lambda</code></td>
<td>
<p>The weight parameter of the penalty. The possible values are
<code>"avg", "min", "1se"</code> or a numeric value which directly determines
<code class="reqn">\lambda</code>. When choosing <code>"avg", "min"</code> or <code>"1se"</code>, cross
validation is executed to determine <code class="reqn">\lambda</code>.
Note that cross validation uses random folds, so the results are not necessarily
replicable.
&quot;avg&quot; calls <code>select_features</code> 10 times, computes the <code class="reqn">\lambda</code> which
minimizes the loss for each iteration and then uses the median of these
values as the final value, for which the objective function is
minimized. <code>"min"</code> and <code>"1se"</code> carry out the cross validation just
once and <code class="reqn">\lambda</code> is either the value, for which the cross-validated
error is minimized (option <code>"min"</code>) or the value, that gives
the most regularized model such that the cross-validated error is within
one standar error of the minimum (option <code>"1se"</code>).</p>
</td></tr>
<tr><td><code id="select_features_+3A_seed">seed</code></td>
<td>
<p>A numeric value which is used as a local seed for this function.
Default is <code>seed = NULL</code>, so no seed is set.
Setting a seed leads to replicable results of
the cross validation, such that each call of <code>select_features</code> selects
the same columns. If a seed is set, the option <code>lambda = "avg"</code>
yields the same results as <code>lambda = "min"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computational aspects are executed by the <code>glmnet</code>
package. At first, a model is fitted via <a href="glmnet.html#topic+glmnet">glmnet</a>. The
elastic net parameter <code class="reqn">\alpha</code> can be specified by the user. The
parameter <code class="reqn">\lambda</code>, which determines the weight of the penalty, can
either be chosen via cross validation (using <a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a> or by
giving a numeric value.
</p>


<h3>Value</h3>

<p>An object of class <code>MetaNLP</code>, where the columns were selected
via elastic net.
</p>


<h3>Note</h3>

<p>By using a fix value for <code>lambda</code>, the number of features which should
be selected can easily be adjusted by the parameter <code>alpha</code>. The smaller
one chooses <code>alpha</code>, the more columns will still be present in the
resulting data frame, the higher one chooses <code>alpha</code>, the less
columns will be chosen.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
obj &lt;- MetaNLP(path)
obj2 &lt;- select_features(obj, alpha = 0.7, lambda = "min")


</code></pre>

<hr>
<h2 id='summary+2CMetaNLP-method'>Summary of MetaNLP-objects</h2><span id='topic+summary+2CMetaNLP-method'></span>

<h3>Description</h3>

<p>Returns a quick overview over the <code class="reqn">n</code> most frequent word stems structured
into included and excluded papers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'MetaNLP'
summary(object, n = 5, stop_words = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary+2B2CMetaNLP-method_+3A_object">object</code></td>
<td>
<p>An object of class MetaNLP.</p>
</td></tr>
<tr><td><code id="summary+2B2CMetaNLP-method_+3A_n">n</code></td>
<td>
<p>Number of most frequent words to be displayed.</p>
</td></tr>
<tr><td><code id="summary+2B2CMetaNLP-method_+3A_stop_words">stop_words</code></td>
<td>
<p>Boolean to decide whether stop words shall be included in
the summary. <code>stop_words = TRUE</code> means, that stop words are included.</p>
</td></tr>
<tr><td><code id="summary+2B2CMetaNLP-method_+3A_...">...</code></td>
<td>
<p>Additional parameters for <code>delete_stop_words</code> (e.g. language
of the stop words).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of most frequent words.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
obj &lt;- MetaNLP(path)
summary(obj, n = 8)

</code></pre>

<hr>
<h2 id='write_csv'>Save the document-term matrix</h2><span id='topic+write_csv'></span><span id='topic+write_csv+2CMetaNLP-method'></span>

<h3>Description</h3>

<p>This function can be used to save the document-term matrix of a MetaNLP object
as a csv-file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_csv(object, ...)

## S4 method for signature 'MetaNLP'
write_csv(object, path, type = c("train", "test"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write_csv_+3A_object">object</code></td>
<td>
<p>An object of class MetaNLP.</p>
</td></tr>
<tr><td><code id="write_csv_+3A_...">...</code></td>
<td>
<p>Additional arguments for <a href="utils.html#topic+write.table">write.table</a>, e.g. encoding
as <code>UTF-8</code>.</p>
</td></tr>
<tr><td><code id="write_csv_+3A_path">path</code></td>
<td>
<p>Path where to save the csv.</p>
</td></tr>
<tr><td><code id="write_csv_+3A_type">type</code></td>
<td>
<p>Specifies if the document-term matrix should be saved as
&quot;train_wcm.csv&quot; or &quot;test_wcm.csv&quot;. If the user wants to use another file name,
the whole path including the file name should be given as the <code>path</code>
argument</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a path to a specific folder is given (but the path name does not end with
&quot;.csv&quot;), the file is saved in this folder as &quot;train_wcm.csv&quot; or &quot;test_wcm.csv&quot;.
By providing a path ending with &quot;.csv&quot;, the user can override the default
naming convention and the file is saved according to this path.
</p>


<h3>Value</h3>

<p>nothing
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("extdata", "test_data.csv", package = "MetaNLP", mustWork = TRUE)
obj &lt;- MetaNLP(path)
obj2 &lt;- delete_stop_words(obj)
write_path &lt;- tempdir()
write_csv(obj2, path = write_path)
file.remove(file.path(write_path, "train_wcm.csv"))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
